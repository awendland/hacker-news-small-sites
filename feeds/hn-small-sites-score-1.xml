<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 1]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 1. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sun, 10 Jan 2021 12:57:57 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-1.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sun, 10 Jan 2021 12:57:57 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Olympic History]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25683519">thread link</a>) | @ColinWright
<br/>
January 8, 2021 | https://jollydata.blog/posts/2021-01-01-olympic-history/ | <a href="https://web.archive.org/web/*/https://jollydata.blog/posts/2021-01-01-olympic-history/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<h2 id="introduction">Introduction</h2>
<p>This is an analysis of historical data on the Modern Olympic Games. The first Olympiad of the Modern Era organized by the IOC<a href="#fn1" id="fnref1" role="doc-noteref"><sup>1</sup></a> were held at Athens in 1896. Inclined readers might want to read the extensive <a href="https://en.wikipedia.org/wiki/Olympic_Games#Modern_Games">Wikipedia article</a>.</p>
<p>For the summary and the conclusions you can skip the analysis and jump to <a href="#conclusions-and-summary">Conclusions and Summary</a>.</p>
<p><strong>Important note:</strong> I’m not a real follower of the Olympic Games in general, nor did I follow up with any of the disciplines and athletes in particular before. If any of my “findings” are well known facts in the world of the Olympic Games, please excuse my ignorance and enjoy, that this fact is also represented in the underlying data.</p>
<h2 id="idea-and-materials">Idea and Materials</h2>
<div>
<div>
<p><span>The Idea</span></p>
<p>A question came to my mind when finding the Olympic Games dataset on <em>kaggle</em>: “Can money buy medals?”<a href="#fn2" id="fnref2" role="doc-noteref"><sup>2</sup></a></p>
<p>Other questions I had from the beginning were:</p>
<ul>
<li>How did the disciplines change over time?</li>
<li>What are the top scoring nations?</li>
<li>What factors improve the odds to win a medal: for this, population figures and economic data from <em>gapminder</em> will be called in.</li>
</ul>
<p>As you’ll see, more interesting findings will be found on the way.</p>
<p>At the time of writing there are 206 NOCs<a href="#fn3" id="fnref3" role="doc-noteref"><sup>3</sup></a> regularly sending athletes to the competitions. The number grew over time, so not all current NOCs are included in the analysis. This development is one of the aspects I’ll focus on.</p>
</div>
<div>
<p><span>Historical Olympic Data</span></p>
<p>The <a href="https://www.kaggle.com/heesoo37/120-years-of-olympic-history-athletes-and-results">dataset</a> comprises biographical data on the participating athletes (age, gender, body measurements, …), the disciplines and specific events they attended as well as the medals they won. This is one of the more popular datasets on <em>kaggle</em>, and many have worked on this before me. I hope to bring some new aspects in, by combining the data with the gapminder dataset.</p>
<h4 id="acknowledgements">Acknowledgements</h4>
<p>The data was hosted on <a href="https://www.kaggle.com/heesoo37/120-years-of-olympic-history-athletes-and-results">kaggle</a> by <a href="https://www.kaggle.com/heesoo37">rgriffin</a> under a <a href="https://creativecommons.org/publicdomain/zero/1.0/">CC0: Public domain</a> license. The data was scraped from <a href="http://www.sports-reference.com/">http://www.sports-reference.com/</a>. The scripts <em>rgriffin</em> developed to scrape and rectangle the data can be found in this <a href="https://github.com/rgriff23/Olympic_history">github repo</a>. The credits and thanks for composing the data go to <em>rgriffin</em> and to the people at www.sports-reference.com for collecting them in the first place.</p>
</div>
<div>
<p><span>Population and Economic Data</span></p>
<p>To analyze the influence of population size and economic markers on the “outcome” of the Olympic contenders I used <a href="https://www.gapminder.org/data/">data</a> from the gapminder foundation. They use data e.g.&nbsp;from the World Bank “to fight devastating ignorance with a fact-based worldview everyone can understand”<a href="#fn4" id="fnref4" role="doc-noteref"><sup>4</sup></a>. They achieve this e.g.&nbsp;by <a href="https://www.ted.com/talks/hans_rosling_let_my_dataset_change_your_mindset?utm_campaign=tedspread&amp;utm_medium=referral&amp;utm_source=tedcomshare">giving</a> <a href="https://www.ted.com/talks/hans_and_ola_rosling_how_not_to_be_ignorant_about_the_world?utm_campaign=tedspread&amp;utm_medium=referral&amp;utm_source=tedcomshare">talks</a> and offering teaching materials. They also provide the public with the underlying data.</p>
<h4 id="attribution">Attribution</h4>
<p>The above mentioned data is FREE DATA FROM WORLD BANK VIA <a href="https://www.gapminder.org/">GAPMINDER.ORG</a>, released under the <a href="https://creativecommons.org/licenses/by/4.0/">CC-BY LICENSE</a></p>
</div>
</div>
<h2 id="athletes-and-nocs-over-time">Athletes and NOCs over time</h2>
<p>First, let’s load the required packages, read the data, enrich the NOC data with the corresponding continent…</p>
<div data-layout="l-body">
<div>
<pre><code><span><a href="https://rdrr.io/r/base/library.html">library</a></span><span>(</span><span><a href="http://tidyverse.tidyverse.org/">"tidyverse"</a></span><span>)</span>
<span><a href="https://rdrr.io/r/base/library.html">library</a></span><span>(</span><span><a href="https://github.com/rstudio/rmarkdown">"rmarkdown"</a></span><span>)</span>
<span><a href="https://rdrr.io/r/base/library.html">library</a></span><span>(</span><span><a href="https://github.com/vincentarelbundock/countrycode">"countrycode"</a></span><span>)</span>


<span># read the olympic data</span>
<span>athlete_events</span> <span>&lt;-</span> <span>read_csv</span><span>(</span><span>"../../../data_sources/2021_olympic/athlete_events.csv"</span>,
                 col_types <span>=</span> <span>cols</span><span>(</span>
                   ID <span>=</span> <span>col_character</span><span>(</span><span>)</span>,
                   Name <span>=</span> <span>col_character</span><span>(</span><span>)</span>,
                   Sex <span>=</span> <span>col_factor</span><span>(</span>levels <span>=</span> <span><a href="https://rdrr.io/r/base/c.html">c</a></span><span>(</span><span>"M"</span>,<span>"F"</span><span>)</span><span>)</span>,
                   Age <span>=</span>  <span>col_integer</span><span>(</span><span>)</span>,
                   Height <span>=</span> <span>col_double</span><span>(</span><span>)</span>,
                   Weight <span>=</span> <span>col_double</span><span>(</span><span>)</span>,
                   Team <span>=</span> <span>col_character</span><span>(</span><span>)</span>,
                   NOC <span>=</span> <span>col_character</span><span>(</span><span>)</span>,
                   Games <span>=</span> <span>col_character</span><span>(</span><span>)</span>,
                   Year <span>=</span> <span>col_integer</span><span>(</span><span>)</span>,
                   Season <span>=</span> <span>col_factor</span><span>(</span>levels <span>=</span> <span><a href="https://rdrr.io/r/base/c.html">c</a></span><span>(</span><span>"Summer"</span>,<span>"Winter"</span><span>)</span><span>)</span>,
                   City <span>=</span> <span>col_character</span><span>(</span><span>)</span>,
                   Sport <span>=</span> <span>col_character</span><span>(</span><span>)</span>,
                   Event <span>=</span> <span>col_character</span><span>(</span><span>)</span>,
                   Medal <span>=</span> <span>col_factor</span><span>(</span>levels <span>=</span> <span><a href="https://rdrr.io/r/base/c.html">c</a></span><span>(</span><span>"Gold"</span>,<span>"Silver"</span>,<span>"Bronze"</span><span>)</span><span>)</span>
                 <span>)</span>
<span>)</span>

<span># read in the NOC regions data</span>
<span>noc_regions</span> <span>&lt;-</span> <span>read_csv</span><span>(</span><span>"../../../data_sources/2021_olympic/noc_regions.csv"</span><span>)</span>

<span># enrich the NOC data with the corresponding continent</span>
<span>noc_regions</span><span>$</span><span>continent</span> <span>&lt;-</span> <span><a href="https://rdrr.io/pkg/countrycode/man/countrycode.html">countrycode</a></span><span>(</span>sourcevar <span>=</span> <span>noc_regions</span><span>$</span><span>region</span>,
                                     origin <span>=</span> <span>"country.name"</span>,
                                    destination <span>=</span> <span>"continent"</span><span>)</span>
   
<span># manually correct the last missing continent data   </span>
<span>noc_regions</span> <span>&lt;-</span> <span>noc_regions</span> <span>%&gt;%</span> 
  <span>mutate</span><span>(</span>continent <span>=</span> <span><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span>(</span><span>NOC</span> <span>%in%</span> <span><a href="https://rdrr.io/r/base/c.html">c</a></span><span>(</span><span>"FSM"</span>, <span>"TUV"</span><span>)</span>, <span>"Oceania"</span>, <span>continent</span><span>)</span>,
         continent <span>=</span> <span><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span>(</span><span>NOC</span> <span>==</span> <span>"BOL"</span>, <span>"Americas"</span>, <span>continent</span><span>)</span>,
         continent <span>=</span> <span><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span>(</span><span>NOC</span> <span>==</span> <span>"KOS"</span>, <span>"Europe"</span>, <span>continent</span><span>)</span>,
         continent <span>=</span> <span><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span>(</span><span><a href="https://rdrr.io/r/base/NA.html">is.na</a></span><span>(</span><span>continent</span><span>)</span>, <span>"Other"</span>, <span>continent</span><span>)</span>,
         <span># in the athletes_events data the NOC code for Singapore is SGP, not SIN:</span>
         NOC <span>=</span> <span><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span>(</span><span>NOC</span> <span>==</span> <span>"SIN"</span>, <span>"SGP"</span>, <span>NOC</span><span>)</span> 
         <span>)</span>
</code></pre>
</div>
</div>
<p>…and then inspect the data.</p>
<h3 id="inspecting-the-historic-data">Inspecting the Historic Data</h3>
<div>
<div>
<p><span>Story line</span></p>
<p>There are 271116 rows and 15 variables in this dataset. The table below only shows the first 100 rows. As you can see, there are many NA’s, especially in the body measurement columns, as this was not systematically recorded in the early Olympic Games. As I’m not focussing on these columns, I can ignore this for the moment.</p>

<div data-layout="l-body">
<details>
<summary>Show code</summary>
<div>
<pre><code><span>athlete_events</span> <span>%&gt;%</span> 
  <span>distinct</span><span>(</span><span>Year</span>, <span>Season</span>, <span>Sport</span><span>)</span> <span>%&gt;%</span> 
  <span>count</span><span>(</span><span>Year</span>, <span>Season</span><span>)</span> <span>%&gt;%</span> 
  <span>ggplot</span><span>(</span><span>aes</span><span>(</span><span>Year</span>, <span>n</span><span>)</span><span>)</span> <span>+</span>
    <span>geom_col</span><span>(</span>fill <span>=</span> <span>"#646ECA"</span><span>)</span> <span>+</span>
    <span>facet_grid</span><span>(</span><span>Season</span> <span>~</span> <span>.</span><span>)</span> <span>+</span>
    <span>annotate</span><span>(</span><span>"rect"</span>, xmin <span>=</span> <span>1914</span>, xmax <span>=</span> <span>1918</span>, 
             ymin <span>=</span> <span>0</span>, ymax <span>=</span> <span>35</span>, alpha <span>=</span> <span>0.2</span><span>)</span> <span>+</span>
    <span>annotate</span><span>(</span><span>"text"</span>, x <span>=</span> <span>1916</span>, y <span>=</span> <span>27</span>, label <span>=</span> <span>"WW I"</span>, size <span>=</span> <span>2</span><span>)</span> <span>+</span>
    <span>annotate</span><span>(</span><span>"rect"</span>,xmin <span>=</span> <span>1939</span>, xmax <span>=</span> <span>1945</span>, 
             ymin <span>=</span> <span>0</span>, ymax <span>=</span> <span>35</span>, alpha <span>=</span> <span>0.2</span><span>)</span> <span>+</span>
    <span>annotate</span><span>(</span><span>"text"</span>, x <span>=</span> <span>1942</span>, y <span>=</span> <span>27</span>, label <span>=</span> <span>"WW II"</span>, size <span>=</span> <span>2</span><span>)</span> <span>+</span>
    <span>labs</span><span>(</span>title <span>=</span> <span>"Number of sports included in the Olympic Games over the years"</span>, y <span>=</span> <span>"Number of sports"</span><span>)</span><span>+</span>
    <span>theme_minimal</span><span>(</span><span>)</span> <span>+</span>
    <span>theme</span><span>(</span>text <span>=</span> <span>element_text</span><span>(</span>
        family <span>=</span> <span>"Cabin"</span><span>)</span>,
      plot.title <span>=</span> <span>element_text</span><span>(</span>
        face <span>=</span> <span>"bold"</span>,
        hjust <span>=</span> <span>0</span><span>)</span>,
      axis.title <span>=</span> <span>element_text</span><span>(</span>
        face <span>=</span> <span>"bold"</span>,
        size <span>=</span> <span>rel</span><span>(</span><span>1</span><span>)</span><span>)</span>,
      axis.text <span>=</span> <span>element_text</span><span>(</span>
        face <span>=</span> <span>"bold"</span>,
        size <span>=</span> <span>rel</span><span>(</span><span>0.85</span><span>)</span><span>)</span><span>)</span>
</code></pre>
</div>
</details>
<div><p><span id="fig:unnamed-chunk-3"></span>
<img src="https://jollydata.blog/posts/2021-01-01-olympic-history/olympic-history_files/figure-html5/unnamed-chunk-3-1.png" alt="The number of sports included to the games varied over time. Since the 1980s the number grew with each year until the year 2000. During the last five events (2000, 2004, 2008, 2012 and 2016) the number was almost stable at 34 during summer events and 15 during winter events. WW I / II: Breaks due to World Wars I and II." width="624"></p><p>
Figure 1: The number of sports included to the games varied over time. Since the 1980s the number grew with each year until the year 2000. During the last five events (2000, 2004, 2008, 2012 and 2016) the number was almost stable at 34 during summer events and 15 during winter events. WW I / II: Breaks due to World Wars I and II.
</p>
</div>
</div>
<div data-layout="l-body">
<details>
<summary>Show code</summary>
<div>
<pre><code><span>athlete_events</span> <span>%&gt;%</span>
  <span>distinct</span><span>(</span><span>Year</span>, <span>Season</span>, <span>NOC</span><span>)</span> <span>%&gt;%</span>
  <span>left_join</span><span>(</span><span>noc_regions</span><span>)</span> <span>%&gt;%</span> 
  <span>count</span><span>(</span><span>Year</span>, <span>Season</span>, <span>continent</span><span>)</span> <span>%&gt;%</span>
  <span>ggplot</span><span>(</span><span>aes</span><span>(</span><span>Year</span>, <span>n</span>, fill <span>=</span> <span>continent</span><span>)</span><span>)</span> <span>+</span>
    <span>geom_col</span><span>(</span><span>)</span> <span>+</span>
    <span>scale_fill_brewer</span><span>(</span>palette <span>=</span> <span>"Pastel1"</span><span>)</span> <span>+</span>
    <span>facet_grid</span><span>(</span><span>Season</span> <span>~</span> <span>.</span><span>)</span> <span>+</span>
    <span>labs</span><span>(</span>title <span>=</span> <span>"Number of NOCs participating in the Olympic Games over the years"</span>, y <span>=</span> <span>"Number of NOCs"</span><span>)</span> <span>+</span>
    <span>annotate</span><span>(</span><span>"rect"</span>, xmin <span>=</span> <span>1914</span>, xmax <span>=</span> <span>1918</span>, 
             ymin <span>=</span> <span>0</span>, ymax <span>=</span> <span>200</span>, alpha <span>=</span> <span>0.2</span><span>)</span> <span>+</span>
    <span>annotate</span><span>(</span><span>"text"</span>, x <span>=</span> <span>1916</span>, y <span>=</span> <span>150</span>, label <span>=</span> <span>"WW I"</span>, size <span>=</span> <span>2</span><span>)</span> <span>+</span>
    <span>annotate</span><span>(</span><span>"rect"</span>,xmin <span>=</span> <span>1939</span>, xmax <span>=</span> <span>1945</span>, 
             ymin <span>=</span> <span>0</span>, ymax <span>=</span> <span>200</span>, alpha <span>=</span> <span>0.2</span><span>)</span> <span>+</span>
    <span>annotate</span><span>(</span><span>"text"</span>, x <span>=</span> <span>1942</span>, y <span>=</span> <span>150</span>, label <span>=</span> <span>"WW II"</span>, size <span>=</span> <span>2</span><span>)</span> <span>+</span>
    <span>theme_minimal</span><span>(</span><span>)</span> <span>+</span>
    <span>theme</span><span>(</span>legend.position <span>=</span> <span>"bottom"</span><span>)</span> <span>+</span>
    <span>theme</span><span>(</span>text <span>=</span> <span>element_text</span><span>(</span>
        family <span>=</span> <span>"Cabin"</span><span>)</span>,
      plot.title <span>=</span> <span>element_text</span><span>(</span>
        face <span>=</span> <span>"bold"</span>,
        hjust <span>=</span> <span>0</span><span>)</span>,
      axis.title <span>=</span> <span>element_text</span><span>(</span>
        <span># color = rgb(105, 105, 105, maxColorValue = 255),</span>
        face <span>=</span> <span>"bold"</span>,
        size <span>=</span> <span>rel</span><span>(</span><span>1</span><span>)</span><span>)</span>,
      axis.text <span>=</span> <span>element_text</span><span>(</span>
        <span># color = rgb(105, 105, 105, maxColorValue = 255),</span>
        face <span>=</span> <span>"bold"</span>,
        size <span>=</span> <span>rel</span><span>(</span><span>0.85</span><span>)</span><span>)</span><span>)</span>
</code></pre>
</div>
</details>
<div><p><span id="fig:unnamed-chunk-4"></span>
<img src="https://jollydata.blog/posts/2021-01-01-olympic-history/olympic-history_files/figure-html5/unnamed-chunk-4-1.png" alt="The number of NOCs that participated in the Olympic Games over time. WW I / II: Breaks due to World Wars I and II." width="624"></p><p>
Figure 2: The number of NOCs that participated in the Olympic Games over time. WW I / II: Breaks due to World Wars I and II.
</p>
</div>
</div>
</div>
<div>
<p><span>Below deck</span></p>
<p>It is always good practice to read the manual or other explanatory material provided by the author of the dataset especially to know what the variables represent. In addition I like to comprehend a few critical components myself to facilitate the later analysis. In this case I wanted to understand the way, the medals for each competition are implemented in the dataset.</p>
<h4 id="events-and-medals">Events and Medals</h4>
<p>From inspecting the data we can see, that each row corresponds to an athlete participating in a single event, where ‘event’ means a particular match or competition where medals are awarded in the end. So e.g.&nbsp;the Sport “Judo” comprises separate weight classes each for female and male athletes and there are bronze, silver and gold medals within each event. For men’s Judo the Events in 2016 were: Judo Men’s Half-Middleweight, Judo Men’s Extra-Lightweight, Judo Men’s Heavyweight, Judo Men’s Half-Lightweight, Judo Men’s Lightweight, Judo Men’s Half-Heavyweight, Judo Men’s Middleweight.</p>
<p>If no medal was won, the ‘Medal’ column is NA, otherwise the value is either “Bronze”, “Silver” or “Gold”.</p>
<div data-layout="l-body">
<details>
<summary>Show code</summary>
<div>
<pre><code><span># Filter for men's judo events from 2016.</span>
<span>mens_judo_events_2016</span> <span>&lt;-</span><span><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span>(</span><span>athlete_events</span>, <span><a href="https://rdrr.io/r/base/grep.html">grepl</a></span><span>(</span><span>Event</span>, pattern <span>=</span> <span>"^Judo Men's"</span><span>)</span>, <span>Year</span> <span>==</span> <span>2016</span><span>)</span> <span>%&gt;%</span> 
  <span>select</span><span>(</span><span>Event</span>, <span>Medal</span>, <span>Name</span>, <span>Year</span><span>)</span>
</code></pre>
</div>
</details>
</div>
<p>As a quick test, let’s see if there are any duplicates or wrong medal attributions in the men’s judo sport in 2016.</p>
<div data-layout="l-body">
<details>
<summary>Show code</summary>
<div>
<pre><code><span># check if for each event only one gold/silver/bronze medal were awarded</span>
<span>mens_judo_events_2016</span> <span>%&gt;%</span> 
  <span><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span>(</span><span>!</span><span><a href="https://rdrr.io/r/base/NA.html">is.na</a></span><span>(</span><span>Medal</span><span>)</span><span>)</span> <span>%&gt;%</span> 
  <span>group_by</span><span>(</span><span>Event</span><span>)</span> <span>%&gt;%</span> 
  <span>count</span><span>(</span><span>Medal</span><span>)</span> <span>%&gt;%</span> 
  <span>arrange</span><span>(</span><span>desc</span><span>(</span><span>n</span><span>)</span><span>)</span> <span>%&gt;%</span> 
  <span><a href="https://rdrr.io/pkg/rmarkdown/man/paged_table.html">paged_table</a></span><span>(</span><span>)</span>
</code></pre>
</div>
</details>

</div>
<p>This was rather unexpected for a single competitor discipline: in all events two bronze medals were awarded. A quick research revealed, that this is not an error in the data collection, but rather a feature of the Judo Competitions due to the selection process during the final rounds.<a href="#fn5" id="fnref5" role="doc-noteref"><sup>5</sup></a></p>
<p>We should definitely keep this in mind, in case we touch this sport in a later step!</p>
<p>To check if there is a similar “problem” in any other sport, I repeated the above analysis regardless of the event and year:</p>
<div data-layout="l-body">
<details>
<summary>Show code</summary>
<div>
<pre><code><span>athlete_events</span> <span>%&gt;%</span> 
  <span>select</span><span>(</span><span>Games</span>, <span>Event</span>, <span>Medal</span>, <span>Name</span>, <span>Year</span><span>)</span> <span>%&gt;%</span> 
  <span><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span>(</span><span>!</span><span><a href="https://rdrr.io/r/base/NA.html">is.na</a></span><span>(</span><span>Medal</span><span>)</span><span>)</span> <span>%&gt;%</span> 
  <span>group_by</span><span>(</span><span>Games</span>, <span>Event</span><span>)</span> <span>%&gt;%</span> 
  <span>count</span><span>(</span><span>Medal</span><span>)</span> <span>%&gt;%</span> 
  <span><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span>(</span><span>n</span> <span>&gt;</span> <span>1</span><span>)</span> <span>%&gt;%</span> 
  <span>arrange</span><span>(</span><span>desc</span><span>(</span><span>n</span><span>)</span><span>)</span> <span>%&gt;%</span> 
  <span><a href="https://rdrr.io/pkg/rmarkdown/man/paged_table.html">paged_ta…</a></span></code></pre></div></details></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jollydata.blog/posts/2021-01-01-olympic-history/">https://jollydata.blog/posts/2021-01-01-olympic-history/</a></em></p>]]>
            </description>
            <link>https://jollydata.blog/posts/2021-01-01-olympic-history/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25683519</guid>
            <pubDate>Fri, 08 Jan 2021 11:14:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Zero to $50000 in six months: growing Ritza, a technical publishing company]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25683401">thread link</a>) | @sixhobbits
<br/>
January 8, 2021 | https://sixhobbits.github.io/hugoblog/posts/2020-retrospective/ | <a href="https://web.archive.org/web/*/https://sixhobbits.github.io/hugoblog/posts/2020-retrospective/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>For more background, you can find previous retrospectives for
<a href="https://sixhobbits.github.io/hugoblog/posts/2019-retrospective/"><!-- raw HTML omitted -->2019<!-- raw HTML omitted --></a>,
<a href="https://sixhobbits.github.io/hugoblog/posts/2020-q1-retrospective/"><!-- raw HTML omitted -->Q1
2020<!-- raw HTML omitted --></a>,
<a href="https://sixhobbits.github.io/hugoblog/posts/2020-04-retrospective/"><!-- raw HTML omitted -->April
2020<!-- raw HTML omitted --></a>,
and <a href="https://sixhobbits.github.io/hugoblog/posts/2020-05-retrospective/"><!-- raw HTML omitted -->May
2020<!-- raw HTML omitted --></a>.</p>
<p>In July, I founded <a href="https://ritza.co/">Ritza</a> - a technical publishing company that offers
(very) technical content marketing, developer advocacy as a service, and
a bunch of related publishing services. What does that mean exactly? We
publish ebooks, documentation, and blog articles, usually with the goal
of helping developers or technical managers in some way. For example, we
did <a href="https://codewithrepl.it/"><!-- raw HTML omitted -->https://codewithrepl.it<!-- raw HTML omitted --></a> as a
companion website for <a href="https://repl.it/"><!-- raw HTML omitted -->Repl.it<!-- raw HTML omitted --></a>. We offer this
content on a subscription basis.</p>
<p>The title is clickbait: I’ve been working on Ritza for quite a bit
longer than 6 months, but it only became ‘real’ in July this year as a
registered business which I was devoting 100% of my time to, and – from
what I’ve seen in Maker circles – writing about how you got your
initial revenue is the best way to 2x your revenue, so the title is also
an experiment in some ways.</p>
<p>I’ve gained a lot by reading about
<a href="https://www.coryzue.com/open/"><!-- raw HTML omitted -->other<!-- raw HTML omitted --></a>
<a href="https://twitter.com/SahinKevin/status/1334142235051520000"><!-- raw HTML omitted -->people’s<!-- raw HTML omitted --></a>
<a href="https://themakingof.carrd.co/"><!-- raw HTML omitted -->transparent<!-- raw HTML omitted --></a>
<a href="https://nomadlist.com/open"><!-- raw HTML omitted -->revenues<!-- raw HTML omitted --></a>. That said, talking about
money is still weird for me, and I think it’s harder to be fully
transparent when offering services instead of a SaaS - there is more
customized pricing both in charging for work and paying contractors and
talking money is a sure way to get emotions up and make people feel like
they got a bad deal.</p>
<p>Here are some high level figures for the last 6 months to get it out of
the way.</p>
<h2 id="revenue">Revenue</h2>
<p>Ritza made between $6000 and $14000 revenue each month between July and
December, with a total revenue of around $58000 for the last two
quarters of 2020.</p>
<p>This was below my target of hitting $20000/month in 2020, but –
especially given circumstances – this was way better than my worst case
predictions. There was no clear overall trend, but a definite drop off
in November and December, with July and October being our best
performing months.</p>
<p>All of our contracts are month-to-month and one client went quiet in
October. While most of our revenue comes from recurring contracts, we
also did some one-off work in July through October, but none in November
or December.</p>
<p>Nearly all of our costs are from paying writers, editors, and designers.
We additionally spent money on office space that we don’t use (over
$500/month for coworking space that is tied to my ‘visa facilitation’,
which is a requirement for my visa in the Netherlands), and accounting
costs. We pay a few dollars a month for various online services, such as
GSuite and various domains, and we have credits on DigitalOcean and AWS
which take care of all of our hosting for now. We also recently picked
up a subscription to <a href="https://www.semrush.com/"><!-- raw HTML omitted -->SemRush<!-- raw HTML omitted --></a> - a tool
that I think is overpriced and slightly shady, but which has proven its use
in better understanding what people are searching for.</p>
<p>Overall, this revenue allows me to pay myself a ‘salary’ that pays rent
in Europe, with more cash than my previous job as Head of Technology for
a South African EdTech startup.</p>
<p>That said, my plan B after quitting my previous role was to find a full
time job remotely or in Europe. I shopped around a bit and did some
interviews for roles that were offering $150k-$200k/year + benefits so
in terms of opportunity cost I am still ‘losing’ for now and it remains
to be seen how far Ritza can scale with its current business model.</p>
<h2 id="experiments-and-content">Experiments and content</h2>
<p>Our bread-and-butter service is producing technical content: writing
<a href="https://codewithrepl.it/"><!-- raw HTML omitted -->tutorials<!-- raw HTML omitted --></a> and
<a href="https://datarevenue.com/en-blog"><!-- raw HTML omitted -->blog<!-- raw HTML omitted --></a>
<a href="https://virtasant.com/blog/data-lake-vs-data-warehouse/"><!-- raw HTML omitted -->content<!-- raw HTML omitted --></a>.
While our mission is to unlock marketing budgets “for good” by making
this content available for free, we have also helped companies produce
and improve internal proprietary content that they then sell.</p>
<p>On the side, I have been playing around with the idea of building online
tools to help with producing and publishing content. None of these got
the attention they needed to get off the ground, but they remain on the
back burner as ideas I’d still like to work on. They included</p>
<ul>
<li>
<p><strong><a href="https://vsgraphs.ritza.co/"><!-- raw HTML omitted -->‘vs’ Graphs<!-- raw HTML omitted --></a> -</strong> a tool
inspired by <a href="https://medium.com/applied-data-science/the-google-vs-trick-618c8fd5359f"><!-- raw HTML omitted -->this
article<!-- raw HTML omitted --></a>.
I built this because I needed it - especially for writing articles
about ‘hot’ spaces like MLOps and DevOps, it’s easy to get
overwhelmed by the sheer number of tools, products, and services.
This visualisation makes it easy to explore a new area and find
the most popular products, as well as to find out how a specific
product ‘fits in’ (“Oh X plays in the same space as SageMaker”).
This is also useful to write ‘<a href="https://datarevenue.com/en-blog/data-dashboarding-streamlit-vs-dash-vs-shiny-vs-voila"><!-- raw HTML omitted -->x vs y vs
z<!-- raw HTML omitted --></a>’
articles, which turn out to be very low hanging fruit in terms of
ranking well on Google. If you’ve ever tried to find out how two
products or services compare and found yourself frustrated at all
the low quality ‘alternativeTo-like’ pages you’ll know why these
articles are useful, and I ended up also building a <a href="http://versus.ritza.co/"><!-- raw HTML omitted -->related
tool<!-- raw HTML omitted --></a> to outline these articles
automatically. The fun part about this was that I built it in a
single train ride using only my iPad and repl.it, which felt like
a big step in the direction of being able to code as a nomad.</p>
</li>
<li>
<p><strong><a href="https://ratemycopy.ritza.co/"><!-- raw HTML omitted -->Rate my Copy<!-- raw HTML omitted --></a></strong> - Also while
researching products and services, I got annoyed at how cliched
most landing page copy is, and even more annoyed by how
uninformative it is. I scraped over 20000 landing pages for online
products and services and built a database of the most commonly
used cliches.</p>
</li>
<li>
<p><strong><a href="https://ritza.co/experiments/opinionated-tutorial-publisher.html"><!-- raw HTML omitted -->Opinionated tutorial
Publisher<!-- raw HTML omitted --></a></strong> -
while most of our clients have their own systems already in place
to host the content we produce, I was frustrated at how hard it
was to generate a lightweight, good looking page with writing,
code samples, and images. There’s a long way to go on the design
still, but some of the other pieces are in place.</p>
</li>
</ul>
<p>I won’t link to all the content we produced in 2020, but some highlights
are</p>
<ul>
<li>
<p><strong><a href="https://www.codewithrepl.it/"><!-- raw HTML omitted -->CodeWithRepl.it<!-- raw HTML omitted --></a> -</strong> a set
of tutorials, also in book form. This was very well received on
reddit and continues to rank well for a variety of search terms. I
am strongly against most kinds of tracking, but caved at the end
of the year and installed Plausible Analytics on it, which also
makes it easy to share publicly everything we track:
<a href="https://plausible.io/codewithrepl.it"><!-- raw HTML omitted -->https://plausible.io/codewithrepl.it<!-- raw HTML omitted --></a>.
Traffic has died off a lot at the end of the year (based on some
server logs analytics I did), but rankings continue to improve and
I think the content is in pretty good shape now (we’ve done
several sets of updates since initially publishing it).</p>
</li>
<li>
<p><strong><a href="https://datarevenue.com/en-blog"><!-- raw HTML omitted -->DataRevenue Blog<!-- raw HTML omitted --></a></strong> -
This is the project I’ve personally learned the most from this
year, writing about everything from general machine learning
through BioTech (I didn’t even know what Metabolomics was in 2019,
so there was a steep learning curve to write some of the articles
about that).</p>
</li>
</ul>
<h2 id="growing-a-team">Growing a team</h2>
<p>While we initially mainly worked ad-hoc with contractors on various
projects, towards the end of the year Ritza started feeling like a real
company with a core team. <a href="https://dev.to/eugenedorfling/technical-writing-internship-it-can-only-get-better-from-here-10ma"><!-- raw HTML omitted -->Eugene
Dorfling<!-- raw HTML omitted --></a>
joined in October for a full time internship and is continuing in 2021
as an Associate Developer Advocate. Several other freelancers have
regularly worked on projects throughout the year. I’m still trying to
figure out if the next full time hire should be a senior writer (to take
over some of the writing I am doing), or a managing editor (to help out
with client feedback and all the nitty-gritty but super important
aspects of getting from ‘first draft’ to ‘production’), but I’m leaning
more towards the latter.</p>
<h2 id="what-is-ritza">What IS Ritza?</h2>
<p>Friends and family still don’t really understand what Ritza is. I get a
lot of “uh, so you make IT manuals, right? Isn’t that just telling
people to turn stuff off and on again until it works?”</p>
<p>Ritza is probably closest to a ‘content marketing agency’ at this stage.
But I really dislike most content marketing agencies. Not to name and
shame, but there’s definitely decent demand for very low cost content
such as
<a href="https://contentfly.com/blog/tag/content-sample/"><!-- raw HTML omitted -->https://contentfly.com/blog/tag/content-sample/<!-- raw HTML omitted --></a>,
and I honestly can’t see how that adds any value to the world at all, so
I want to avoid being pulled in that direction or associated with
content like that.</p>
<p>My initial response to this was to try to move towards “Developer
Advocacy as a Service”, but it doesn’t really roll off the tongue, and
I’m not sure that “Developer Advocacy” is actually a job that will
survive the Tech Bubble I’m convinced we’re in.</p>
<p>Towards the end of the year, it became clear that Ritza is simply a
publishing company (or at least the very beginnings of one). We are
slowly becoming experts in the entire publishing pipeline, from sourcing
high quality writing, through editing, designing, publishing, and
distributing. While we have started out with a strong focus on technical
content, there’s no reason that that has to remain a core focus forever.
I’ve had pretty mediocre experiences with technical publishing companies
like PacktPub and I believe non-tech publishers that have existed for
decades or centuries are even more in need of a bit of modernization.</p>
<p>I previously helped my Dad publish his first book of (hilarious)
<a href="http://leanpub.com/doctor"><!-- raw HTML omitted -->memoirs as a Doctor in Africa<!-- raw HTML omitted --></a> and
during the slower period between Christmas and New Year now I spent some
time tweaking the landing page, making a sample available, and doing
some marketing. So far, all I’ve done is burn $50 on Reddit ads that led
to zero sales, but I think with some experimentation with different
distribution channels there’s more potential. Stay tuned.</p>

        </div></div>]]>
            </description>
            <link>https://sixhobbits.github.io/hugoblog/posts/2020-retrospective/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25683401</guid>
            <pubDate>Fri, 08 Jan 2021 10:46:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Modern education for a level playing field]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25683281">thread link</a>) | @skalberg
<br/>
January 8, 2021 | https://function29.com/posts/modern-education-for-a-level-playing-field/ | <a href="https://web.archive.org/web/*/https://function29.com/posts/modern-education-for-a-level-playing-field/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><div><p>The COVID pandemic made me think about how arcaic the current education system is. I should say, the current <em>delivery</em> of education. The core idea for a fairer education relies in a sort of <a href="https://www.khanacademy.org/">Khan Academy</a>, but at the state level. Traditional teachers won’t be replaced by a classroom computer, but would see their role reshaped: from teachers to facilitators. For example, a 1-hour class might include a 40min video of the subject delivered by a top specialist followed by 20min of classroom activities and Q&amp;As.</p><p>The current delivery of educational subjects is in the hands of an army of teachers. The quality of teaching is highly variable, and the schools with the best ratings are usually the ones in rich neighborhoods. Good ratings on a school can alone make or break the real estate market, driving house prices and rents in the nearby radius. Public schools should provide a level playing field for everyone, but this is not the case, and never has been. Rich parents can afford higher rents while poorer families are driven in the outskirsts of a city, where lower rated schools usually are. Public housing in high-income areas have historically provided a solution for this, but the chance of being accepted in a specific public housing project are still highly randomized.</p><p>During the second wave of the COVID pandemic in the UK in January 2021, the schools were again shut down. Interestingly, the <a href="https://www.bbc.co.uk/teach">BBC started broadcasting curriculum-mapped lessons</a> on primary and secondary school subjects, for free. If we were to push this concept to its very limit, imagine what a country like the UK could be able to offer to its pupils. The best of the best delivered to anyone. A physics lesson delivered by Prof. Brian Cox, a science lesson on evolutionary byology delivered by Richard Dawkins or Sir David Attenborough, an english class delivered by Stephen Fry. This is already happening in higher education and in the workplace anyways - learning and training has been remote for ages now. But this shouldn’t be the end of the classroom as the social aspect of school is as important as the educational one. Teachers could see their role reshaped towards being educators or classroom facilitators, answering pupils questions and coordinating classroom activities.</p><p>I’ve grown up in Europe, where education is generally considered quite good. My school experience up to College has been scarred by mediocrity, with some notable horrific experiences and a couple of teachers who became like mentors to me. I’m sure a lot of people can relate to my experience. Later in life and like many like me, I self-taught myself software engineering using YouTube, Coursera and online material. I’ve had the chance to follow the best courses from the best teachers at Stanford, MIT and so on. Being a drop-out from College I was even able to complete my degree by re-enlisting 10 years later and rather than going back to the classroom, I was studying the subject on Khan Academy and textbooks. The potential of a unified, highest-quality possible education delivery for everyone is immense. The solution is not necessarily remote learning, but the tools given by remote learning.</p><p>I wonder whether in the aftermath of the pandemic and the combination of widespread use of conferencing tools, unified delivery of learning might become a serious subject of discussion to build a fairer future for our children.</p></div></article></div></div>]]>
            </description>
            <link>https://function29.com/posts/modern-education-for-a-level-playing-field/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25683281</guid>
            <pubDate>Fri, 08 Jan 2021 10:22:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to do important but not urgent work]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25683260">thread link</a>) | @vitabenes
<br/>
January 8, 2021 | https://www.deprocrastination.co/blog/how-to-do-important-but-not-urgent-work | <a href="https://web.archive.org/web/*/https://www.deprocrastination.co/blog/how-to-do-important-but-not-urgent-work">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p><img src="https://www.deprocrastination.co/assets/illustrations/procrastination_work_no.png" alt="Q2 Time: how to work without a looming deadline"></p><p>You have work to do, but the deadline is in a couple of weeks or months. Or you have no deadline at all.</p><p>How do you do great work every day instead of the usual last-minute push before a deadline?<br>A vitally important question in the era of knowledge work.</p><h3>The mythical land of Q2, the important but not urgent</h3><p>This post is all about the Q2 of the Eisenhower matrix - the part that many procrastinators never get around to.</p><p><img src="https://www.deprocrastination.co/assets/illustrations/eisenhower_Q2.png" alt="Eisenhower Matrix"></p><p>It's a shame because Q2 is where all the future-focused, strategic work lies: learning new skills, investing into new endeavors, working on new branches of a business,...</p><p><strong>Q2 is the quadrant of potential.</strong></p><p>Without spending time in Q2 frequently, we tread water in life, doing only the things that we've always done, or that we're forced into at the last minute. Just enough to get by, but not to go to bed with a sense of pride.</p><p>Let's change this.</p><p>We'll start with the first obstacle to working on non-urgent important tasks—the reactive habit of&nbsp;<em>checking</em>.</p><h2>Why checking things became a default habit</h2><p>If you have Internet access, you probably developed this simple habit:</p><p><em>When I get bored, I check ___________.</em></p><p>This is a problem.</p><p>Work often isn't engaging at the beginning of a session. It can seem onerous, never-ending, and boring (before you get into the problem-solving mode).</p><p>If you always have an easy way to get distracted, you'll take it. Often.</p><p>When you&nbsp;<em>check</em>&nbsp;a site or app, you get a bit of dopamine - a feel-good neurochemical.</p><p>This dopamine hit makes it addictive to check stuff. Just the possibility of something new, random, or unexpected is exciting, even if that new thing ends up being a work email.</p><p>Checking things is the cornerstone of&nbsp;<strong>a reactive work style:</strong></p><ul><li>You never do something unless it's in reply to someone else.</li><li>You wait for others to remind you multiple times to do something.</li><li>You refresh inboxes constantly and keep them open at all times.</li><li>When you find yourself bored, you immediately check something.</li></ul><p><strong>This way of working is devoid of initiative. It's an addiction to new information disguised as being "responsive."</strong></p><p>Nothing non-urgent ever gets done.</p><p>How can we get ourselves to do it?</p><h2>2 ways to do non-urgent work</h2><p>The first way is to make Q2 feel like Q1 - to make it urgent. There's a variety of ways to do it.</p><p>The second way is to choose to work on Q2 because you can.</p><h2>1. Make Q2 feel like Q1</h2><p>When we're on a deadline, we spring into action.</p><p>The consequences of not acting become clear: we'll get fired, fail a class, or ruin a relationship...</p><p>The fear of these scenarios is visceral. It drives us to finally get things done.</p><p>While reliance on this fear is not ideal, we can use it.</p><h3>Create consequences for your actions (or lack thereof)</h3><p>If you know that without a deadline, you don't work, create deadlines.</p><p>There are many ways of doing this:</p><ul><li><strong>Tell your coworker you'll do something.</strong><br>If you tell a coworker that you'll have done something by Tuesday, they will expect you to deliver. If you don't, you'll cause them to be disappointed or angry. That's a clear consequence.</li><li><strong>Promise publicly you'll do something.</strong><br>If you promise on social media or any other public forum that you'll do something by a certain time, you're putting your reputation at risk.</li><li><strong>Schedule an event you don't want to miss.</strong><br>If it's 3PM and you schedule a fancy dinner with your partner at 6PM, it becomes clear that you have only the next 3 hours to get things done (unless you want to miss the dinner). Having more events in your schedule highlights the space available for work. If there's little time for delays, you'll probably adapt and not delay.</li><li><strong>Sign up for&nbsp;<a target="_blank" href="https://www.stickk.com/">Stickk</a>&nbsp;or&nbsp;<a target="_blank" href="https://www.beeminder.com/">Beeminder.</a></strong><br>Both of these services allow you to make a financial bet against yourself. They also help you put your goals into a concrete format. Losing your own money if you don’t do something can be a powerful motivating force.</li></ul><p>Besides these ways of creating a deadline for yourself, you can also heighten your awareness of not working when you're meant to.</p><h3>Create a crystal clear sense of "Now I focus"</h3><p>When a deadline is looming over us, we feel this visceral feeling of "now I really need to work."</p><p>Suddenly, every available hour is an hour we can use to work. Having so much to do and so little time to do it makes us use every minute.</p><p>In other words, it becomes crystal clear to us that&nbsp;<strong>now is the time to focus.</strong></p><p>We can use other tools to get to that feeling.</p><h4>Work alongside others</h4><p>Our environment shapes our behavior in a profound way. Imagine you're working next to a coworker who's focusing intensely. They can also see your screen when they occasionally glance away from their work.</p><p>Would that inspire you to focus a bit more?</p><p>The research says yes.&nbsp;<a href="http://www.jstor.org/stable/10.1086/497818?seq=1#page_scan_tab_contents">One study</a>&nbsp;found that the presence of another person improves performance by 16-32%. Interestingly, the study notes: "low productivity workers are the most sensitive to the behavior of peers."</p><p>Now, if you can't use this in your physical environment and work with your coworker, or partner, you can use a service like&nbsp;<a target="_blank" href="https://www.focusmate.com/">Focusmate.</a></p><p>It allows you to work with 50 minute sessions with others who want to focus on their work.</p><p>You can try the service for free and see if it helps you.</p><h4>Make a grand gesture</h4><p><img src="https://www.deprocrastination.co/assets/tips/hotel.png" referrerpolicy="no-referrer" alt="5 Star hotel"></p><p>A slightly more esoteric way of boosting your awareness of "now I work" is to make a grand gesture.</p><p>Cal Newport describes this strategy in Deep Work and uses the example of J K Rowling.</p><p>When Rowling was stuck writing The Goblet of Fire, she decided to check into a 5 star hotel.</p><p>A stay in a hotel like that is expensive. You can spend hundreds of dollars every day.</p><p>For Rowling, the whole purpose of staying in that hotel was to write. If she was paying thousands of pounds every week, it heightened her awareness time passing. She was paying for every minute, so she'd better produce something worth it.</p><p>Now, this grand gesture is not available to all of us, but another is:&nbsp;<strong>a trip.</strong></p><p>To help himself decide whether to start his online training program AltMBA, Seth Godin went into the desert for a few days with his friends.</p><p>He had one objective for himself: decide.</p><p>He thought about the project, wrote about it, and ultimately decided to commit and do it.</p><p>Could you take a trip somewhere as an opportunity to make a decision you’ve been putting off?</p><p>If you don't want to make yourself work using the above, the other choice is creating a routine in your life to take on non-urgent work without pressure.</p><h2>2. Choosing to work now</h2><h3>Make time for Q2 or it won't happen</h3><p>The anti-dote to reactive site and app checking is&nbsp;<strong>consciously blocking out big uninterrupted chunks of time.</strong></p><p>Our mind works best when we focus on 1 task for an extended period of time, without interruptions.</p><p>If you have email or social media open at all times, you'll get interrupted.</p><h3>Decide to set specific times aside</h3><p>When was the last time you had 2+ hours to work on non-urgent tasks? A time when you didn’t check any distractions and had no one interrupt you?</p><p>If you have to starch your memory extensively to find an answer, then it may be time for a change.</p><p>Uninterrupted time is crucial for productivity, particularly when it comes to dealing with complex or ambiguous tasks.</p><p>It’s also crucial to specify what you’re going to work on. Without a clear intention, the urgent work and unproductive habits will take over.</p><p>The simplest way to do this is to put a big block on the calendar and put what you need to do as the title. You can also add any links or notes to the description.</p><p>When in your week can you do this? When can you make time for futures oriented, important work?</p><h3>Choose to work because you can</h3><p>The last point may well be the most important one. Much of our time, we don’t choose to work. We’re forced to do so by our circumstances. That puts us in a defensive position.</p><p>But we can actively&nbsp;<em>choose</em>&nbsp;to do work. Choose to write that email. Choose to reach out to someone. Choose to start working on the next project. Go on offense.</p><p>Fear is the default motivator for many of us. If I don't do this, I will [insert unpleasant consequences here].</p><p>There are other ways, other internal narratives that we can use.</p><p>"I'm doing this because I have the time and I'm alert and able.""I'll do this because the sooner I do it, the better.""I'll get this done now because it would be awesome if it existed."</p><p>Instead of focusing on what happens if you&nbsp;<em>don't</em>&nbsp;do something, focus on what happens if you&nbsp;<em>do</em>.</p><p>Switch from the fear of consequences to desire for a specific awesome version of the future.</p><p><strong>When you do block out a 2 hour block of time and find yourself with nothing urgent to do, choose to work.</strong>&nbsp;Because you can. Because you want to create something awesome. Because it will make you happy at the end of the day, week, month, and year.</p><p>Don't wait until circumstances force you, go on offense now!</p><h2>Summary</h2><p>There are 2 main ways to get non-urgent work done:</p><ol start=""><li>Make it feel urgent.</li><li>Choose to do it.</li></ol><p>To make work feel more urgent, you can:</p><ul><li><p>Create consequences for your inaction.</p><ul><li>Tell your coworker you'll do something.</li><li>Promise publicly you'll do something.</li><li>Schedule an event you don't want to miss.</li><li>Sign up for&nbsp;<a target="_blank" href="https://www.stickk.com/">Stickk</a>&nbsp;or&nbsp;<a target="_blank" href="https://www.beeminder.com/">Beeminder.</a></li></ul></li><li><p>Make yourself hyper-aware of not taking action.</p><ul><li>Work alongside others with&nbsp;<a target="_blank" href="https://www.focusmate.com/">Focusmate.</a></li><li>Make not taking action feel wasteful to yourself (scrolling social media in a 5 star hotel).</li></ul></li></ul><p>To choose to do non-urgent work:</p><ul><li>Block out big uninterrupted chunks of time for non-urgent work.</li><li>Assign specific times to specific tasks.</li><li>When you have the opportunity, choose to work because you can.</li></ul><p>Pick 1 strategy out of this article and apply it today!</p></article></div>]]>
            </description>
            <link>https://www.deprocrastination.co/blog/how-to-do-important-but-not-urgent-work</link>
            <guid isPermaLink="false">hacker-news-small-sites-25683260</guid>
            <pubDate>Fri, 08 Jan 2021 10:16:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Zenodo open data repository (CERN)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25683140">thread link</a>) | @amai
<br/>
January 8, 2021 | https://www.eui.eu/Research/Library/ResearchGuides/Economics/Statistics/DataPortal/Zenodo | <a href="https://web.archive.org/web/*/https://www.eui.eu/Research/Library/ResearchGuides/Economics/Statistics/DataPortal/Zenodo">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="mainContent">
<div>
<div>
<ul>
<li></li>
<li><a href="#Datadescription">Resource description</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</li>
<li><a href="#Timeperiod">Time period</a></li>
<li><a href="#Supportlinks">Support&nbsp;links</a></li>
<li><a href="#Howtoaccessdata">How to access data</a></li>
</ul>

<hr>
<h5><a id="Datadescription"><strong>Resource description</strong></a></h5>
<p><a href="https://www.zenodo.org/"><img alt="Zenodo" height="84" width="150" src="https://www.eui.eu/Images/Images-2011/Research/Library/ResearchGuides/Economics/DataLogos/Zenodo150x84.jpg">Zenodo</a>&nbsp;is a multi-disciplinary open repository maintained by <a href="https://home.cern/fr">CERN.</a>&nbsp;Datasets, documents and other research materials can be located via the&nbsp;<a href="https://www.zenodo.org/">Zenodo&nbsp;search&nbsp;engine.</a></p>
<p>Scholars from any research discipline can upload data in any file format. A&nbsp;digital object identifier (DOI) is automatically assigned to all Zenodo files. Details on how to assign metadata&nbsp;to research datasets are in section 5(c) of the EUI Library <a title="EUI Library Research Data Guide" href="https://www.eui.eu/Research/Library/ResearchDataServices/Guide">Research Data Guide. </a>For assistance, write to <a href="https://www.eui.eu/cdn-cgi/l/email-protection#46342335222732270623332f682333"><span data-cfemail="5a283f293e3b2e3b1a3f2f33743f2f">[email&nbsp;protected]</span></a></p>
<p>In April 2020, Zenodo launched a&nbsp;<a href="https://zenodo.org/communities/covid-19/search?page=1&amp;size=20">Coronavirus Research Community - COVID-19</a>&nbsp;accepting data from all scientific disciplines and sub-disciplines.</p>
<p>Zenodo is compliant with the data management requirements of&nbsp;<a href="https://ec.europa.eu/programmes/horizon2020/en/what-horizon-2020">Horizon 2020</a>&nbsp;and <a href="https://ec.europa.eu/info/horizon-europe-next-research-and-innovation-framework-programme_en">Horizon Europe,</a>&nbsp;the&nbsp;EU's research and innovation funding programmes. "The <a href="https://www.openaire.eu/">OpenAIRE</a> project, in the vanguard of the open access and open data movements in Europe, was commissioned by the EC to support their nascent Open Data policy by providing a catch-all repository for EC funded research. <a href="https://home.cern/fr">CERN</a>&nbsp;an OpenAIRE partner and pioneer in open source, open access and open data, provides this capability."</p>

<hr>
<h5><a id="Timeperiod"><strong>Time period </strong></a></h5>
<ul>
<li>Data coverage is indicated in file-level metadata, varying by dataset</li>
<li>Zenodo&nbsp;was launched&nbsp;in 2013.</li>
</ul>

<hr>
<h5><a id="Supportlinks"><strong>Support links</strong></a></h5>
<ul>
<li>Zenodo features are introduced in <a href="https://www.zenodo.org/features">this quick reference guide</a></li>
<li>Data access and reposit services are explained on <a href="https://www.zenodo.org/about">this Zenodo page</a></li>
<li>Policies on access, use, reposit and licensing are explained in <a href="https://www.zenodo.org/policies">this Zenodo directory.</a></li>
</ul>

<hr>
<h5><a id="Howtoaccessdata"><strong>How to access data </strong></a></h5>
<ul>
<li>Locate datasets via&nbsp;<a href="https://www.zenodo.org/">Zenodo ElasticSearch</a></li>
<li>Browse datasets&nbsp;via the <a href="https://www.zenodo.org/communities/">Zenodo communities directory.</a></li>
</ul>

<hr>
<p><a title="Research Data Services" href="https://www.eui.eu/Research/Library/ResearchDataServices">Data homepage</a></p>

</div>

</div>
</div><div id="pageBottom">
<div id="pagetools">
<p>Page last updated on 27 October 2020</p>
</div>


</div></div>]]>
            </description>
            <link>https://www.eui.eu/Research/Library/ResearchGuides/Economics/Statistics/DataPortal/Zenodo</link>
            <guid isPermaLink="false">hacker-news-small-sites-25683140</guid>
            <pubDate>Fri, 08 Jan 2021 09:49:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Quorum Availability]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25683117">thread link</a>) | @fanf2
<br/>
January 8, 2021 | http://brooker.co.za/blog/2021/01/06/quorum-availability.html | <a href="https://web.archive.org/web/*/http://brooker.co.za/blog/2021/01/06/quorum-availability.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post">


<p>It's counterintuitive, but is it right?</p>


<p>In our paper <a href="https://www.usenix.org/conference/nsdi20/presentation/brooker">Millions of Tiny Databases</a>, we say this about the availability of quorum systems of various sizes:</p>

<blockquote><p>As illustrated in Figure 4, smaller cells offer lower availability in the face of small numbers of uncorrelated node failures, but better availability when the proportion of node failure exceeds 50%. While such high failure rates are rare, they do happen in practice, and a key design concern for Physalia.</p></blockquote>

<p>And this is what Figure 4 looks like:</p>

<p><img src="https://mbrooker-blog-images.s3.amazonaws.com/mtb_fig_4.png" alt=""></p>

<p>The context here is that a <em>cell</em> is a Paxos cluster, and the system needs a majority quorum for the cluster to be able to process requests<sup><a href="#foot1">1</a></sup>. A cluster of one box needs one box available, five boxes need three available and so on. The surprising thing here is the claim that having smaller clusters is actually <em>better</em> if the probability of any given machine failing is very high. The paper doesn't explain it well, and I've gotten a few questions about it. This post attempts to do better.</p>

<p>Let's start by thinking about what happens for a cluster of one machine (<em>n=1</em>), in a datacenter of <em>N</em> machines (for very large <em>N</em>). We then fail each machine independently with probability <em>p</em>. What is the probability that our one machine failed? That's trivial: it's <em>p</em>. Now, let's take all <em>N</em> machines and put them into a cluster of <em>n=N</em>. What's the probability that a majority of the cluster is available? For large <em>N</em>, it's 1 for <em>p &lt; 0.5</em>, and 0 for <em>p &gt; 0.5</em>. If less than half the machines fail, less than half have failed. If more than half the machines fail, more than half have failed. Ok?</p>

<p><img src="https://mbrooker-blog-images.s3.amazonaws.com/quorum_avail_a.png" alt=""></p>

<p>Notice how a cluster size of 1 is worse than N up until <em>p = 0.5</em> then better after. <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.38.5629&amp;rep=rep1&amp;type=pdf">Peleg and Wool</a> say:</p>

<blockquote><p>... for <em>0 &lt; p &lt; ½</em> the most available NDC<sup><a href="#foot2">2</a></sup> is shown to be the "democracy" (namely, the minimal majority system), while the "monarchy" (singleton system) is least available. Due to symmetry, the picture reverses for <em>½ &lt; p &lt; 1</em>.</p></blockquote>

<p>Here, the <em>minimal majority system</em> is the one I'd call a <em>majority quorum</em>, and is used by Physalia (and, indeed, most Paxos implementations). The <em>monarchy</em> is where you have one leader node.</p>

<p>What about real practical cluster sizes like <em>n=3</em>, 5, and 7? There are three ways we can do this math. In <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.38.5629&amp;rep=rep1&amp;type=pdf">The Availability of Quorum Systems</a>, Peleg and Wool derive closed-form solutions to this problem<sup><a href="#foot3">3</a></sup>. Our second approach is to observe that the failures of the nodes are Bernoulli trials with probability <em>p</em>, and therefore we can read the answer to "what is the probability that 0 or 1 of 3 fail for probability <em>p</em>" from the distribution function of the <a href="https://en.wikipedia.org/wiki/Binomial_distribution">binomial distribution</a>. Finally, we can be lazy and do it with Monte Carlo. That's normally my favorite method, because it's easier to include correlation and various "what if?" questions as we go.</p>

<p>Whichever way you calculate it, what do you expect it to look like? For small <em>n</em> you may expect it to be closer in shape to <em>n=1</em>, and for large <em>n</em> you may expect it to approach the shape of <em>n=N</em>. If that's what you expect, you'd be right.</p>

<p><img src="https://mbrooker-blog-images.s3.amazonaws.com/quorum_avail_b.png" alt=""></p>

<p>I'll admit that I find this result deeply deeply counter-intuitive. I think it's right, because I've approached it multiple ways, but it still kind of bends my mind a little. That may just be me. I've discussed it with friends and colleagues over the years, and they seem to think it matches their intuition. It's counter-intuitive to me because it suggests that smaller <em>n</em> (smaller clusters, or smaller cells in Physalia's parlance) is better for high <em>p</em>! If you think a lot of your boxes are going to fail, you may get better availability (not durability, though) from smaller clusters.</p>

<p>Weird.</p>

<p><strong>Correlation to the rescue!</strong></p>

<p>It's not often that my statistical intuition is saved by introducing correlation, but in this case it helps. I'd argue that, in practice, that you only lose machines in an uncorrelated Bernoulli trial way for small <em>p</em>. Above a certain <em>p</em>, it's likely that the failures have some shared cause (power, network, clumsy people, etc) and so the failures are likely to be correlated in some way. In which case, we're back into the game we're playing with Physalia of avoiding those correlated failures by optimizing placement.</p>

<p>In many other kinds of systems, like ones you deploy across multiple datacenters (we'd call that <em>regional</em> in AWS, deployed across multiple <em>availability zones</em>), you end up treating the datacenters as units of failure. In that case, for 3 datacenters you'd pick something like <em>n=9</em> because you can keep quorum after the failure of an entire datacenter (3 machines) and any one other machine. As soon as there's correlation, the math above is mostly useless and the correlation's cause is all that really matters.</p>

<p>Availability also isn't the only thing to think about with cluster size for quorum systems. Durability, latency, cost, operations, and contention on leader election also come into play. Those are topics for another post (or section 2.2 of <a href="https://www.usenix.org/conference/nsdi20/presentation/brooker">Millions of Tiny Databases</a>).</p>

<p><strong>Updates</strong></p>

<p>JP Longmore sent me this intuitive explanation, which makes a lot of sense:</p>

<blockquote><p>Probability of achieving a quorum will increase when removing 2 nodes from a cluster, each with failure rate p&gt;.5, since on average you're removing 2 bad nodes instead of 2 good nodes. Other cases with 1 good node &amp; 1 bad node don't change the outcome (quorum/not). Repeat reasoning till N=1 or all remaining nodes have p&lt;=.5 (if failure rate isn’t uniform).</p></blockquote>

<p><strong>Footnotes</strong></p>

<ol>
<li><a name="foot1"></a> Physalia uses a very naive Paxos implementation, intentionally optimized for testability and simplicity. The quorum intersection requirements of Paxos (or Paxos-like protocols) are more subtle than this, and work like Heidi Howard et al's <a href="https://fpaxos.github.io/">Flexible Paxos</a> has been pushing the envelope here recently. <a href="https://arxiv.org/pdf/1608.06696v1.pdf">Flexible Paxos:  Quorum intersection revisited</a> is a good place to start.</li>
<li><a name="foot2"></a> Here, an NDC is a <em>non-dominated coterie</em>, and a <em>coterie</em> is a set of groups of nodes (like <em>{{a, b}, {b, c}, {a, c}}</em>). See Definition 2.2 in <a href="https://www.cs.purdue.edu/homes/bb/cs542-20Spr/readings/reliability/How%20to%20assign%20Votes-JACM-garcia-molina.pdf">How to Assign Votes in a Distributed System</a> for the technical definition of domination. What's important, though, is that for each <em>dominated coterie</em> there's a <em>non-dominated coterie</em> that provides the same mutual exclusion properties, but superior availability under partitions. The details are not particularly important here, but are very interesting if you want to do tricky things with quorum intersection.</li>
<li><a name="foot3"></a> Along with a whole lot of other interesting facts about quorums, majority quorums and other things. It's a very interesting paper. Another good read in this space is Garcia-Molina and Barbara's <a href="https://www.cs.purdue.edu/homes/bb/cs542-20Spr/readings/reliability/How%20to%20assign%20Votes-JACM-garcia-molina.pdf">How to Assign Votes in a Distributed System</a>, which both does a better job than Peleg and Wool of defining the terms it uses, but also explores the general idea of assigning <em>votes</em> to machines, rather than simply forming quorums of machines. As you read it, it's worth remembering that it predates Paxos, and many of the terms might not mean what you expect.</li>
</ol>


</div></div>]]>
            </description>
            <link>http://brooker.co.za/blog/2021/01/06/quorum-availability.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25683117</guid>
            <pubDate>Fri, 08 Jan 2021 09:43:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Signal, thank you for not collecting my data. But I won’t use you]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25682981">thread link</a>) | @rukshn
<br/>
January 8, 2021 | https://ruky.me/2021/01/08/signal-thank-you-for-not-collecting-my-data-but-i-wont-use-you/ | <a href="https://web.archive.org/web/*/https://ruky.me/2021/01/08/signal-thank-you-for-not-collecting-my-data-but-i-wont-use-you/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>Facebook has given an ultimatum for WhatsApp users to either share their data with Facebook or leave the service. And that date is February 8th.</p>
<p>One of the most appealing things about WhatsApp is it’s end to end encryption. Even though their are other chat apps, no one provides end to end encryption to chats by default other than WhatsApp and Signal. </p>
<p>Not even Telegram provide encryption by default, and you need to start a secret chat to enable end to end encryption.</p>
<p>One of the most important things in iOS 14 is the ability for users see what kind of data apps are collecting from their users. </p>
<p>So in light of all this I went through the top 10 social networking/chat apps to see how much data they are collecting in comparison to Signal, and explain why I won’t use Signal and what we can do instead.</p>
<h2>The top 10 social media/chat apps</h2>

<figure><img data-attachment-id="146" data-permalink="https://ruky.me/2021/01/08/signal-thank-you-for-not-collecting-my-data-but-i-wont-use-you/img_1621/" data-orig-file="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_1621.png?fit=828%2C1792&amp;ssl=1" data-orig-size="828,1792" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="img_1621" data-image-description="" data-medium-file="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_1621.png?fit=139%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_1621.png?fit=473%2C1024&amp;ssl=1" loading="lazy" width="473" height="1024" src="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_1621.png?resize=473%2C1024&amp;ssl=1" alt="" srcset="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_1621.png?resize=473%2C1024&amp;ssl=1 473w, https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_1621.png?resize=139%2C300&amp;ssl=1 139w, https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_1621.png?resize=768%2C1662&amp;ssl=1 768w, https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_1621.png?resize=710%2C1536&amp;ssl=1 710w, https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_1621.png?w=828&amp;ssl=1 828w" sizes="(max-width: 473px) 100vw, 473px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_1621.png?resize=473%2C1024&amp;ssl=1 473w, https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_1621.png?resize=139%2C300&amp;ssl=1 139w, https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_1621.png?resize=768%2C1662&amp;ssl=1 768w, https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_1621.png?resize=710%2C1536&amp;ssl=1 710w, https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_1621.png?w=828&amp;ssl=1 828w" data-lazy-src="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_1621.png?resize=473%2C1024&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP/yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 "></figure>
<h2>Telegram</h2>
<p>Telegram is one of the better apps when we compare with the others in this group. They collect relatively small amount of data.</p>
<p>It is currently the number 1 in my region, Telegram is extremely popular in my region because it provides a great way to share pirated content. </p>
<p>There is no limit to the file size that you can upload on Telegram, and there is no limit for the number of users that a Telegram group can have.</p>
<p>This makes it an ideal place for people to share pirated copies of movies, games, songs in groups with hundreds of users.</p>
<figure><img data-attachment-id="157" data-permalink="https://ruky.me/2021/01/08/signal-thank-you-for-not-collecting-my-data-but-i-wont-use-you/image/" data-orig-file="https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image.jpg?fit=473%2C598&amp;ssl=1" data-orig-size="473,598" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="image" data-image-description="" data-medium-file="https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image.jpg?fit=237%2C300&amp;ssl=1" data-large-file="https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image.jpg?fit=473%2C598&amp;ssl=1" loading="lazy" width="473" height="598" src="https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image.jpg?resize=473%2C598&amp;ssl=1" alt="" srcset="https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image.jpg?w=473&amp;ssl=1 473w, https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image.jpg?resize=237%2C300&amp;ssl=1 237w" sizes="(max-width: 473px) 100vw, 473px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image.jpg?w=473&amp;ssl=1 473w, https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image.jpg?resize=237%2C300&amp;ssl=1 237w" data-lazy-src="https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image.jpg?resize=473%2C598&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP/yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 "></figure>
<p>I’m bit reluctant to use Telegram due to its poor user interface, and its connections to Russia.</p>
<p>To clarify what I meant by poor user interface, on the android device that I tried Telegram, I was unable to select multiple chats, and deleting a chat is a multi step process. It doesn’t have to be that complicated.</p>
<h2><strong>WhatsApp</strong> </h2>
<p>WhatsApp is currently the number 2 in my region, and when compared with Telegram, WhatsApp is collecting a decent amount of data to track you.</p>
<figure><img data-attachment-id="158" data-permalink="https://ruky.me/2021/01/08/signal-thank-you-for-not-collecting-my-data-but-i-wont-use-you/image-1/" data-orig-file="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/image-1.jpg?fit=473%2C701&amp;ssl=1" data-orig-size="473,701" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="image-1" data-image-description="" data-medium-file="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/image-1.jpg?fit=202%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/image-1.jpg?fit=473%2C701&amp;ssl=1" loading="lazy" width="473" height="701" src="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/image-1.jpg?resize=473%2C701&amp;ssl=1" alt="" srcset="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/image-1.jpg?w=473&amp;ssl=1 473w, https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/image-1.jpg?resize=202%2C300&amp;ssl=1 202w" sizes="(max-width: 473px) 100vw, 473px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/image-1.jpg?w=473&amp;ssl=1 473w, https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/image-1.jpg?resize=202%2C300&amp;ssl=1 202w" data-lazy-src="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/image-1.jpg?resize=473%2C701&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP/yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 "></figure>
<h2>Facebook and <strong>Messenger</strong> </h2>
<p>Facebook is a vacuumed of user data, they collect everything that they can get their hands on.</p>
<p>The Messenger app is also no different to the Facebook app. I’m not installing either of them, no matter how much Facebook mobile website tries to funnel me to installing their Messenger app.</p>
<figure><img data-attachment-id="159" data-permalink="https://ruky.me/2021/01/08/signal-thank-you-for-not-collecting-my-data-but-i-wont-use-you/image-2/" data-orig-file="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/image-2.jpg?fit=473%2C880&amp;ssl=1" data-orig-size="473,880" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="image-2" data-image-description="" data-medium-file="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/image-2.jpg?fit=161%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/image-2.jpg?fit=473%2C880&amp;ssl=1" loading="lazy" width="473" height="880" src="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/image-2.jpg?resize=473%2C880&amp;ssl=1" alt="" srcset="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/image-2.jpg?w=473&amp;ssl=1 473w, https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/image-2.jpg?resize=161%2C300&amp;ssl=1 161w" sizes="(max-width: 473px) 100vw, 473px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/image-2.jpg?w=473&amp;ssl=1 473w, https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/image-2.jpg?resize=161%2C300&amp;ssl=1 161w" data-lazy-src="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/image-2.jpg?resize=473%2C880&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP/yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 "></figure>
<figure><img data-attachment-id="160" data-permalink="https://ruky.me/2021/01/08/signal-thank-you-for-not-collecting-my-data-but-i-wont-use-you/image-3/" data-orig-file="https://i1.wp.com/ruky.me/wp-content/uploads/2021/01/image-3.jpg?fit=473%2C784&amp;ssl=1" data-orig-size="473,784" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="image-3" data-image-description="" data-medium-file="https://i1.wp.com/ruky.me/wp-content/uploads/2021/01/image-3.jpg?fit=181%2C300&amp;ssl=1" data-large-file="https://i1.wp.com/ruky.me/wp-content/uploads/2021/01/image-3.jpg?fit=473%2C784&amp;ssl=1" loading="lazy" width="473" height="784" src="https://i1.wp.com/ruky.me/wp-content/uploads/2021/01/image-3.jpg?resize=473%2C784&amp;ssl=1" alt="" srcset="https://i1.wp.com/ruky.me/wp-content/uploads/2021/01/image-3.jpg?w=473&amp;ssl=1 473w, https://i1.wp.com/ruky.me/wp-content/uploads/2021/01/image-3.jpg?resize=181%2C300&amp;ssl=1 181w" sizes="(max-width: 473px) 100vw, 473px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/ruky.me/wp-content/uploads/2021/01/image-3.jpg?w=473&amp;ssl=1 473w, https://i1.wp.com/ruky.me/wp-content/uploads/2021/01/image-3.jpg?resize=181%2C300&amp;ssl=1 181w" data-lazy-src="https://i1.wp.com/ruky.me/wp-content/uploads/2021/01/image-3.jpg?resize=473%2C784&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP/yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 "></figure>
<h2>IMO</h2>
<p>IMO is also a chat app with a niche audience. Even though it’s not popular in the USA, IMO is quite popular in Southeast Asia as a platform to share adult content, like a live cam website.</p>
<p>But it too has chat capabilities just like any other chat app, and it too collects a decent amount of user data, even more than WhatsApp.</p>
<figure><img data-attachment-id="161" data-permalink="https://ruky.me/2021/01/08/signal-thank-you-for-not-collecting-my-data-but-i-wont-use-you/image-4/" data-orig-file="https://i1.wp.com/ruky.me/wp-content/uploads/2021/01/image-4.jpg?fit=473%2C842&amp;ssl=1" data-orig-size="473,842" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="image-4" data-image-description="" data-medium-file="https://i1.wp.com/ruky.me/wp-content/uploads/2021/01/image-4.jpg?fit=169%2C300&amp;ssl=1" data-large-file="https://i1.wp.com/ruky.me/wp-content/uploads/2021/01/image-4.jpg?fit=473%2C842&amp;ssl=1" loading="lazy" width="473" height="842" src="https://i1.wp.com/ruky.me/wp-content/uploads/2021/01/image-4.jpg?resize=473%2C842&amp;ssl=1" alt="" srcset="https://i1.wp.com/ruky.me/wp-content/uploads/2021/01/image-4.jpg?w=473&amp;ssl=1 473w, https://i1.wp.com/ruky.me/wp-content/uploads/2021/01/image-4.jpg?resize=169%2C300&amp;ssl=1 169w" sizes="(max-width: 473px) 100vw, 473px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/ruky.me/wp-content/uploads/2021/01/image-4.jpg?w=473&amp;ssl=1 473w, https://i1.wp.com/ruky.me/wp-content/uploads/2021/01/image-4.jpg?resize=169%2C300&amp;ssl=1 169w" data-lazy-src="https://i1.wp.com/ruky.me/wp-content/uploads/2021/01/image-4.jpg?resize=473%2C842&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP/yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 "></figure>
<h2>Viber</h2>
<p>When it comes to my friends and relatives Viber is the second most popular chat app behind WhatsApp and Facebook Messenger.</p>
<p>Especially girls love using Viber because of the large variety of stickers, that they can select in the app.</p>
<p>Personally, I don’t like using viber, and find it too bloated. Yes, the stickers are nice, but what I need is a chat app, not a sticker app.</p>
<p>And it appears Viber is also collecting lot of data as well.</p>
<figure><img data-attachment-id="162" data-permalink="https://ruky.me/2021/01/08/signal-thank-you-for-not-collecting-my-data-but-i-wont-use-you/image-5/" data-orig-file="https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image-5.jpg?fit=473%2C896&amp;ssl=1" data-orig-size="473,896" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="image-5" data-image-description="" data-medium-file="https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image-5.jpg?fit=158%2C300&amp;ssl=1" data-large-file="https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image-5.jpg?fit=473%2C896&amp;ssl=1" loading="lazy" width="473" height="896" src="https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image-5.jpg?resize=473%2C896&amp;ssl=1" alt="" srcset="https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image-5.jpg?w=473&amp;ssl=1 473w, https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image-5.jpg?resize=158%2C300&amp;ssl=1 158w" sizes="(max-width: 473px) 100vw, 473px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image-5.jpg?w=473&amp;ssl=1 473w, https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image-5.jpg?resize=158%2C300&amp;ssl=1 158w" data-lazy-src="https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image-5.jpg?resize=473%2C896&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP/yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 "></figure>
<p><strong>I’m skipping Parent control app, because even though listed as a chat app it does not appear to look like a chat app.</strong></p>
<h2>Signal</h2>
<p>When it comes to chat apps, it’s unbelievable to see that Signal is basically not collecting any user data.</p>
<p>They also provide end to end encrypted chats by default.</p>
<p>The lack of collecting user data is a sign that they don’t need to sell user data as a way to make money. </p>
<p>Signal is currently depending on <a rel="noreferrer noopener" href="https://signal.org/donate" target="_blank">donations</a>, and even if they find other ways to monetize the service, as long as they are not collecting data, we can be sure that our data is not being used to monetize the service.</p>
<figure><img data-attachment-id="163" data-permalink="https://ruky.me/2021/01/08/signal-thank-you-for-not-collecting-my-data-but-i-wont-use-you/image-6/" data-orig-file="https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image-6.jpg?fit=473%2C672&amp;ssl=1" data-orig-size="473,672" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="image-6" data-image-description="" data-medium-file="https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image-6.jpg?fit=211%2C300&amp;ssl=1" data-large-file="https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image-6.jpg?fit=473%2C672&amp;ssl=1" loading="lazy" width="473" height="672" src="https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image-6.jpg?resize=473%2C672&amp;ssl=1" alt="" srcset="https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image-6.jpg?w=473&amp;ssl=1 473w, https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image-6.jpg?resize=211%2C300&amp;ssl=1 211w" sizes="(max-width: 473px) 100vw, 473px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image-6.jpg?w=473&amp;ssl=1 473w, https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image-6.jpg?resize=211%2C300&amp;ssl=1 211w" data-lazy-src="https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image-6.jpg?resize=473%2C672&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP/yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 "></figure>
<h2>BOTIM</h2>
<p>I have not used the BOTIM and I have no idea why it’s there in the charts ahead of other chat apps like WeChat and Line.</p>
<p>Maybe BOTIM has a niche audience that I don’t know about.</p>
<figure><img data-attachment-id="164" data-permalink="https://ruky.me/2021/01/08/signal-thank-you-for-not-collecting-my-data-but-i-wont-use-you/image-7/" data-orig-file="https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image-7.jpg?fit=473%2C832&amp;ssl=1" data-orig-size="473,832" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="image-7" data-image-description="" data-medium-file="https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image-7.jpg?fit=171%2C300&amp;ssl=1" data-large-file="https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image-7.jpg?fit=473%2C832&amp;ssl=1" loading="lazy" width="473" height="832" src="https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image-7.jpg?resize=473%2C832&amp;ssl=1" alt="" srcset="https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image-7.jpg?w=473&amp;ssl=1 473w, https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image-7.jpg?resize=171%2C300&amp;ssl=1 171w" sizes="(max-width: 473px) 100vw, 473px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image-7.jpg?w=473&amp;ssl=1 473w, https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image-7.jpg?resize=171%2C300&amp;ssl=1 171w" data-lazy-src="https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image-7.jpg?resize=473%2C832&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP/yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 "></figure>
<h2>Why <strong>I’</strong>n not/<strong>can’t</strong> use Signal</h2>
<p>I love to use Signal, I wish everyone can use Signal, and I wish I can use Signal, but I just can’t.</p>
<p>I have installed any tried using Signal couple of times, but whenever I install it it’s basically a ghost town. No one is using it and I can’t convince anyone else to join, because none of their friends on Signal either.</p>
<p>The network effect on WhatsApp is strong, and almost all of my non techie regular WhatsApp users will just accept the new TOS and will share their data with Facebook. They just want a chat app and that is what WhatsApp is providing.</p>
<p>Even if I install Signal, I will be the only one in my network using it. And no one will be willing to use Signal just to chat with me.</p>
<p>I will try to keep my personal messages away from WhatsApp as much as possible, but. I won’t be able to leave my WhatsApp groups. I will use iMessages whenever I’m chatting with someone with an Apple device.</p>
<h2>What we <strong>actually</strong> need</h2>
<p>What we actually need is not Signal, WhatsApp or Telegram. What we need is a protocol, just like email but for chat and apps that build on top of this protocol.</p>
<p>There are such protocols, but no major company is willing to use them for their chat apps.</p>
<p>If we have such protocol, then we will be able to switch apps with ease, without having to worry about the network effect or losing out chats just like we can do with our emails.</p>
<p>So please everyone try to invest on a protocol, not on an individual app.</p>
</div></div>]]>
            </description>
            <link>https://ruky.me/2021/01/08/signal-thank-you-for-not-collecting-my-data-but-i-wont-use-you/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25682981</guid>
            <pubDate>Fri, 08 Jan 2021 09:16:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Midnight Commander Visualized]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25682923">thread link</a>) | @pro_methe5
<br/>
January 8, 2021 | https://www.visualsource.net/repo/github.com/MidnightCommander/mc | <a href="https://web.archive.org/web/*/https://www.visualsource.net/repo/github.com/MidnightCommander/mc">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.visualsource.net/repo/github.com/MidnightCommander/mc</link>
            <guid isPermaLink="false">hacker-news-small-sites-25682923</guid>
            <pubDate>Fri, 08 Jan 2021 09:05:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Where is the “average” person in each US state?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25682905">thread link</a>) | @marwahaha
<br/>
January 8, 2021 | https://marwahaha.github.io/ca-center/viewer | <a href="https://web.archive.org/web/*/https://marwahaha.github.io/ca-center/viewer">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://marwahaha.github.io/ca-center/viewer</link>
            <guid isPermaLink="false">hacker-news-small-sites-25682905</guid>
            <pubDate>Fri, 08 Jan 2021 09:00:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OpenBSD Router Guide – Hakk.gg]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25682743">thread link</a>) | @rodrigo975
<br/>
January 8, 2021 | https://hakk.gg/openbsd-router-guide | <a href="https://web.archive.org/web/*/https://hakk.gg/openbsd-router-guide">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
<div>
<p>Network segmenting firewall, DHCP, DNS with Unbound, domain blocking and much more</p>
<h2><span id="Introduction">Introduction</span></h2>
<div>
<p>In this guide we’re going to take a look at how we can use cheap and “low end” hardware to build an amazing OpenBSD router with firewalling capabilities, segmented local area networks, DNS with domain blocking, DHCP and more.</p>
<p>We will use a setup in which the router segments the local area network (LAN) into three separate networks, one for the grown-ups in the house, one for the children, and one for public facing servers, such as a private web server or mail server. We will also look at how we can use DNS to block out ads, porn, and other websites on the Internet. The OpenBSD router can also be used on small to mid-size offices.</p>
</div>
<h2 id="why-a-firewall"><span id="Why_a_firewall">Why a firewall?</span></h2>
<p>Almost no matter how you connect to the Internet from your home or office, you need a real firewall between you and the modem or router that your ISP has provided you with.</p>
<p>Very rarely do consumer-grade modems or routers get firmware updates and they are often vulnerable to&nbsp;<a href="https://en.wikipedia.org/wiki/Home_router#Security">network attacks</a>&nbsp;that turns these devices into&nbsp;<a href="https://en.wikipedia.org/wiki/Botnet">botnets</a>, such like the&nbsp;<a href="https://en.wikipedia.org/wiki/Mirai_(malware)">Mirai malware</a>. Many consumer-grade modems and routers is to blame for some of the largest&nbsp;<a href="https://en.wikipedia.org/wiki/Distributed_denial_of_service_attack">distributed denial of service (DDoS) attacks</a>.</p>
<p>A firewall between you and your ISP modem or router cannot protect your modem or router device against attacks, but it can protect your computers and devices on the inside of the network, and it can help you monitor and control the traffic that comes and goes to and from your local network.</p>
<p>Without a firewall between your local network and the ISP modem or router you could basically consider this an open door policy, like leaving the door to your house wide open, because you cannot trust the equipment from your ISP.</p>
<p>It is always a really good idea to put a real firewall between your local network and the Internet, and with OpenBSD you get an very solid solution.</p>
<h2 id="the-hardware"><span id="The_hardware">The hardware</span></h2>
<p>You don’t have to buy expensive hardware to get an effective router and firewall for your house or office. Even with cheap and “low end” hardware you can get a very solid solution.</p>
<p>I have build multiple solutions with the&nbsp;<a href="https://www.asrock.com/mb/Intel/Q1900DC-ITX/">ASRock Q1900DC-ITX</a>&nbsp;motherboard that comes with an Intel Quad-Core Celeron processor.</p>
<p><img src="https://hakk.gg/wp-content/themes/veen/assets/images/transparent.gif" data-lazy="true" data-src="https://www.unixsheikh.com/includes/img/asrock-q1900dc-itx.png" alt="ASRock Q1900DC-ITX motherboard"></p>
<p>I’ll admit, it’s a pretty “crappy” motherboard, but it gets the job done and I have several builds that have run very solid for many years on gigabit networks with full saturation and the firewall, DNS, etc. working “overtime” and the CPU hardly breaks a sweat.</p>
<p>The ASRock Q1900DC-ITX motherboard has the advantage that it comes with a DC-In Jack that is compatible with a 9~19V power adapter, making it very power saving. Unfortunatly the ASRock Q1900DC-ITX motherboard is no longer made, but I’m just using it as an example, I have used several other cheap boards as well.</p>
<p>I have also used the ASRock Q1900-ITX (it doesn’t come with the DC-In Jack) combined with a PicoPSU.</p>
<p><img src="https://hakk.gg/wp-content/themes/veen/assets/images/transparent.gif" data-lazy="true" data-src="https://www.unixsheikh.com/includes/img/picopsu.png" alt="PicoPSU power supply"></p>
<p>You can find different brands and versions of the PicoPSU, some are better quality than others. I have two different brands, the original and a cheaper knockoff, both performs very well and they save quite a bit of power contrary to running with a normal power supply.</p>
<p>Last, I am using a cheap Intel knockoff quad port NIC found on Ebay like this one:</p>
<p><img src="https://hakk.gg/wp-content/themes/veen/assets/images/transparent.gif" data-lazy="true" data-src="https://www.unixsheikh.com/includes/img/intel-quad-nic.png" alt="Intel Quad NIC"></p>
<p>I know it is better to use quality hardware, especially on a network that you care about, but this tutorial is about how you can get away with using fairly cheep hardware and still get an extremely useful product that will continue to serve you well for many years – at least that is my experience.</p>
<p>I recommend that you look for a low power mini ITX board with hardware&nbsp;<a href="https://www.openbsd.org/amd64.html">supported by OpenBSD</a>, such as an Intel Celeron or Intel i3 processor. These boards are typically cheap, less power hungry, and they don’t take up much space. I don’t recommend using the Intel Atom CPU if you have a gigabit network as they usually choke because they can’t handle the amount of traffic, but your mileage may vary.</p>
<p>You might also need a couple of cheap gigabit switches for the segmented local network, at least if you have more than one computer you want to connect to the same LAN 🙂</p>
<h2 id="why-openbsd"><span id="Why_OpenBSD">Why OpenBSD?</span></h2>
<p>In truth, you can get a similar setup with one of the other&nbsp;<a href="https://en.wikipedia.org/wiki/Comparison_of_BSD_operating_systems">BSD flavors</a>&nbsp;or one of the many different&nbsp;<a href="https://en.wikipedia.org/wiki/Linux_distribution">Linux distribution</a>, but&nbsp;<a href="https://www.openbsd.org/">OpenBSD</a>&nbsp;is specifically very well suited and designed for this kind of task. Not only does it come with all the needed software in the base install, but it also has significantly better security and tons of improved mitigations already build-in into the operating system. I&nbsp;<a href="https://www.unixsheikh.com/articles/openbsd-is-fantastic.html">highly recommend</a>&nbsp;OpenBSD over any other operating system for this kind of task.</p>
<p>This guide is not going to show you how to install OpenBSD. If you haven’t done that before I recommend you spin up some kind of virtual machine or see if you have some unused and supported hardware laying around you can play with. OpenBSD is one of the easiest and quickest operating systems to install. Don’t be afraid of the non-gui approach, once you have tried it you will really appreciate the simplicity. Use the default settings when in doubt.</p>
<p>Before you endeavor on this journey make sure to reference the OpenBSD documentation! Not only is everything very well documented, but you will most likely find all the answers you need right there. Read the&nbsp;<a href="https://www.openbsd.org/faq/index.html">OpenBSD FAQ</a>&nbsp;and take a look at the different&nbsp;<a href="https://man.openbsd.org/">manual pages</a>&nbsp;for the software we’re going to use.</p>
<p>Another really useful place to find general information about OpenBSD is the&nbsp;<a href="https://marc.info/?l=openbsd-misc">OpenBSD mailing list archives</a>. Also make sure to stay up to date with relevant information by subscribing to the&nbsp;<a href="https://www.openbsd.org/mail.html">Announcements and security advisories</a>&nbsp;mailing list.</p>
<p>Last, but not least, please consider&nbsp;<a href="https://www.openbsd.org/donations.html">supporting OpenBSD</a>! Even if you don’t use OpenBSD on a daily basis, but perhaps make use of&nbsp;<a href="https://www.openssh.com/">OpenSSH</a>&nbsp;on Linux, then you’re really using software from the OpenBSD project. Consider making a small, but steady donation to support the further development of all the great software the OpenBSD developers make!</p>
<h2 id="the-network"><span id="The_network">The network</span></h2>
<p>A router is basically a device that regulate network traffic between two or more separate networks. The router will ensure that network traffic intended for the local network doesn’t run out into the wild on the Internet, and traffic on the Internet, that is not intended for your local network, stays on the Internet.</p>
<p><b>NOTE:</b><br>
A router is sometimes also referred to as a gateway, which generally is alright, but in truth a real gateway joins dissimilar systems, while a router joins similar networks. An example of a gateway would be a device that joins a PC network with a telecommunications network.</p>
<p>In this tutorial we’re building a router and we have 4 networks of the same type to work with. One is the Internet and the other three are the internally segmented local area networks (LANs). Some people prefer to work with virtual LANs, but in this tutorial we’re going to use the quad port NIC from the illustration above. You can achieve the same result by using multiple one port NICs if you prefer that, you just have to make sure that you have enough room and free PCI slots on the motherboard. You can also use the Ethernet port on the motherboard itself, but it depends on the driver and support for the device. I have had no problems using the Realtek PCI gigabit Ethernet controller that normally comes with many motherboards even though I recommend Intel over Realtek.</p>
<p>Of course you don’t have to segment the network into several parts if you don’t need that, and it will be very easy to change the settings from this guide, but I have decided to use this approach in order to show you how you can protect your children by segmenting their network into a separate LAN that not only gets ad and porn blocking using DNS blocking (all the segments gets that), but you can even whitelist the parts of the Internet you want them to have access to. The last part about whitelisting is difficult and generally not recommended unless your children requires only very limited access, but it is doable with some work, and the guide is going to show you one way you can do that.</p>
<p>This is an illustration of the network we’re going to setup:</p>
<pre><code>
                       Internet
                          |
                    xxx.xxx.xxx.xxx
                    ISP Modem (WAN)
                      10.24.0.23
                          |
                       OpenBSD
                      10.24.0.50
                  (router/firewall)
                          |
     -------------------------------------------
     |                    |                    |
    NIC1                 NIC2                 NIC3
192.168.1.1          192.168.2.1          192.168.3.1
LAN1 switch          LAN2 switch          LAN3 switch
     |                    |                    |
     -- 192.168.1.x       -- 192.168.2.x       -- 192.168.3.2
     |  Grown-up PC       |  Child PC1         |  Public web server
                          |
                          -- 192.168.2.x
                          |  Child PC2
</code></pre>
<p>The IP addresses that begins with 10.24.0 are whatever IP addresses your ISP router or modem gives you, it may be something very different. The IP addresses beginning with 192.168 are the IP addresses that we’re going to use in the guide for our local area network (LAN).</p>
<p>The guide does not deal with any kind of wireless connectivity. Wireless chip firmware is notoriously buggy and exploitable and I recommend you don’t use any kind of wireless connectivity, if you can do without. If you do require wireless connectivity I strongly recommend that you disable wireless access from the ISP modem or router completely (if possible), and then buy the best wireless router you can find and put it behind the firewall in an isolated segment instead. That way should your wireless device ever be compromised you can better control the outcome and limit the damage. You can further setup the wireless router such that any devices connected to it have their own IPs that pass directly through the wireless router, but at …</p></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hakk.gg/openbsd-router-guide">https://hakk.gg/openbsd-router-guide</a></em></p>]]>
            </description>
            <link>https://hakk.gg/openbsd-router-guide</link>
            <guid isPermaLink="false">hacker-news-small-sites-25682743</guid>
            <pubDate>Fri, 08 Jan 2021 08:24:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Routing and Firewalling Vlans with FreeBSD – Klara Inc]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25682645">thread link</a>) | @rodrigo975
<br/>
January 8, 2021 | https://klarasystems.com/articles/routing-and-firewalling-vlans-with-freebsd/ | <a href="https://web.archive.org/web/*/https://klarasystems.com/articles/routing-and-firewalling-vlans-with-freebsd/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>




<div>
<h2><strong>In this article we are going to look at and integrate two network isolation technologies, VLANs and VNET. VLANs are common place, and if you have done some network management or design then you are likely to have interacted with them. The second are FreeBSDs VNET virtual network stacks, a powerful network stack isolation technology that gives FreeBSD jails super powers.</strong></h2>



<p>Ethernet VLAN (standardised by <a href="https://en.wikipedia.org/wiki/IEEE_802.1Q">IEEE 802.1Q</a>) are an extension to Ethernet and provide an essential method for scaling network deployments. They are used in all environments to enable reuse of common infrastructure by isolating portions of networks from each other. VLANs allow the reuse of common cables, switches and routers to carry completely different networks. It is common to have data that must be separated from different networks carried on common cables until their VLAN tags are finally stripped at a gateway switch or router.</p>



<p>VLANs are implemented by inserting a 4-byte (32 bit) field into the Ethernet header, this field is referred to as the VLAN tag. The VLAN tag has a 12 bit VLAN ID field that carries a VLAN number. There can be up to 4096 VLAN IDs present in a network. Two VLAN IDs, 0 (0x0) and 4095 (0xFFF) are reserved. 0 is used to indicate that no VLAN ID is in use and the use of 0xFFF can be implementation defined.</p>



<div><figure><img data-attachment-id="3205" data-permalink="https://klarasystems.com/articles/routing-and-firewalling-vlans-with-freebsd/image-1/" data-orig-file="https://i2.wp.com/klarasystems.com/wp-content/uploads/2021/01/image-1.png?fit=420%2C45&amp;ssl=1" data-orig-size="420,45" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-1" data-image-description="" data-medium-file="https://i2.wp.com/klarasystems.com/wp-content/uploads/2021/01/image-1.png?fit=300%2C32&amp;ssl=1" data-large-file="https://i2.wp.com/klarasystems.com/wp-content/uploads/2021/01/image-1.png?fit=420%2C45&amp;ssl=1" loading="lazy" width="420" height="45" src="https://i2.wp.com/klarasystems.com/wp-content/uploads/2021/01/image-1.png?resize=420%2C45&amp;ssl=1" alt="" srcset="https://i2.wp.com/klarasystems.com/wp-content/uploads/2021/01/image-1.png?w=420&amp;ssl=1 420w, https://i2.wp.com/klarasystems.com/wp-content/uploads/2021/01/image-1.png?resize=300%2C32&amp;ssl=1 300w" sizes="(max-width: 420px) 100vw, 420px" data-recalc-dims="1"></figure></div>











<p>VLAN tags are automatically added and removed by devices with VLAN support. FreeBSD implements VLANs as child devices cloned from a parent device (this can be a real network interface such as an em(4) device or virtual vtnet(4) device). Typically, we name these cloned devices with the VLAN ID or number that the handle. In this article we will talk about VLAN interfaces that are created with this scheme, so VLAN number 5 on vtnet0 is vtnet0.5. This convention makes it much easier to track which devices are doing what in a system.</p>



<h4><strong>Using VLANs on FreeBSD</strong></h4>



<p>There are a few ways to build test networks to experiment with VLANs and FreeBSD, we can use real hardware; a couple of machines and some switches, but that makes it hard to provide an example that can be reproduced by everyone. We can also use a FreeBSD host, either physical or virtual with bridge, epair and tap interfaces. If you have a physical machine for testing we can use bhyve virtual machines, but if all you have is a virtual FreeBSD machine you can reproduce this network using VNET jails.</p>



<p>Logically our test setup looks like two hosts connected directly with an Ethernet cable so if this network resembles your environment it should be plenty:</p>



<figure><img data-attachment-id="3207" data-permalink="https://klarasystems.com/articles/routing-and-firewalling-vlans-with-freebsd/image-2-2/" data-orig-file="https://i1.wp.com/klarasystems.com/wp-content/uploads/2021/01/image-2.png?fit=420%2C182&amp;ssl=1" data-orig-size="420,182" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-2" data-image-description="" data-medium-file="https://i1.wp.com/klarasystems.com/wp-content/uploads/2021/01/image-2.png?fit=300%2C130&amp;ssl=1" data-large-file="https://i1.wp.com/klarasystems.com/wp-content/uploads/2021/01/image-2.png?fit=420%2C182&amp;ssl=1" loading="lazy" width="420" height="182" src="https://i1.wp.com/klarasystems.com/wp-content/uploads/2021/01/image-2.png?resize=420%2C182&amp;ssl=1" alt="" srcset="https://i1.wp.com/klarasystems.com/wp-content/uploads/2021/01/image-2.png?w=420&amp;ssl=1 420w, https://i1.wp.com/klarasystems.com/wp-content/uploads/2021/01/image-2.png?resize=300%2C130&amp;ssl=1 300w" sizes="(max-width: 420px) 100vw, 420px" data-recalc-dims="1"></figure>



<p>For the examples in this article we are going to use virtual machines connected together using tap and bridge interfaces and jails with epair interfaces on those virtual machines. Our example machines are called hostA and hostB, they are virtual machines with tap interfaces connected together through a bridge interface. On top of this we will build up a larger network inside using epair, bridge and jails. This setup could carry over to physical machines in the same data center or if connected together with a tunnel like GRE or IPsec, different data centers.</p>



<figure><img data-attachment-id="3209" data-permalink="https://klarasystems.com/articles/routing-and-firewalling-vlans-with-freebsd/image-3/" data-orig-file="https://i2.wp.com/klarasystems.com/wp-content/uploads/2021/01/image-3.png?fit=420%2C164&amp;ssl=1" data-orig-size="420,164" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-3" data-image-description="" data-medium-file="https://i2.wp.com/klarasystems.com/wp-content/uploads/2021/01/image-3.png?fit=300%2C117&amp;ssl=1" data-large-file="https://i2.wp.com/klarasystems.com/wp-content/uploads/2021/01/image-3.png?fit=420%2C164&amp;ssl=1" loading="lazy" width="420" height="164" src="https://i2.wp.com/klarasystems.com/wp-content/uploads/2021/01/image-3.png?resize=420%2C164&amp;ssl=1" alt="" srcset="https://i2.wp.com/klarasystems.com/wp-content/uploads/2021/01/image-3.png?w=420&amp;ssl=1 420w, https://i2.wp.com/klarasystems.com/wp-content/uploads/2021/01/image-3.png?resize=300%2C117&amp;ssl=1 300w" sizes="(max-width: 420px) 100vw, 420px" data-recalc-dims="1"></figure>



<p>The vtnet1 interfaces on both hostA and hostB are connected together with a bridge. Both are in the 10.0.128.0/24, with the hostA at 10.0.128.1 and hostB at 10.0.128.2. We can ping to perform a simple test to verify that traffic can pass between the two virtual machines via the bridge before we add VLANs into the mix.</p>



<pre><code>    root@hostA #  ping -c 1 10.0.128.2
    PING 10.0.128.2 (10.0.128.2): 56 data bytes
    64 bytes from 10.0.128.2: icmp_seq=0 ttl=64 time=2.647 ms

    --- 10.0.128.2 ping statistics ---
    1 packets transmitted, 1 packets received, 0.0% packet loss
    round-trip min/avg/max/stddev = 2.647/2.647/2.647/0.000 ms
</code></pre>



<p>We create a VLAN interface from a parent device dynamically using ifconfig or statically using cloned_interfaces in rc.conf (see <a href="https://www.freebsd.org/doc/handbook/network-vlan.html">the FreeBSD handbook</a> and <a href="https://www.freebsd.org/cgi/man.cgi?vlan">vlan(4) man page</a> for more information). We create the VLAN device with a name and indicate the parent device and VLAN number that will be used.</p>



<pre><code>    root@hostA # ifconfig vtnet1.5 create vlan 5 vlandev vtnet1 
    root@hostA # ifconfig vtnet1.5 inet 10.0.64.1/24 up
</code></pre>



<p>Once the interface is created we can configure it the way we would with any other interface in FreeBSD. We need to create a matching VLAN device on the hostB so we can experiment with VLAN tags.</p>



<pre><code>    root@hostB # ifconfig vtnet1.5 create vlan 5 vlandev vtnet1 
    root@hostB # ifconfig vtnet1.5 inet 10.0.64.2/24 up
</code></pre>



<h4><strong>Packet Captures for Debugging VLANs</strong></h4>



<p>While VLANs are not particularly complex technically, their ability to add new isolated networks also tends to add an extra layer of complexity and really reinforces confusion when you have to debug networking issues.</p>



<div data-columns="3" data-layout="50-25-25"><div>




<div><div>
<p>Did you know?</p>



<h2>You can maximize the <strong>power of your FreeBSD</strong> infrastructure with our <strong>Support Subscription!</strong></h2>




</div></div>




</div></div>



<p>For a parent interface we can see all the traffic that passes through it along with its link layer headers by running tcpdump with with -e flag. To avoid locking out the console on a busy remote system it can be a good idea to only capture a limited number of packets (add the -c flag with a count such as 1000 to do this).</p>



<pre><code>    # tcpdump -c 1000 -i vtnet1 -e</code></pre>



<p>Traffic from the parent interface, captured on the parent interface (in our example traffic to the 10.0.128.0/24 subnet) will appear without any VLAN tag and so will traffic captured on the VLAN interface (traffic on the 10.0.64.0/24 subnet). This is because the parent device will send and receive raw untagged traffic and the child VLAN device will strip away the tag before processing any further:</p>



<pre><code>    root@hostA #  tcpdump -i vtnet1 -e
    Password:
    tcpdump: verbose output suppressed, use -v or -vv for full protocol decode
    listening on vtnet1, link-type EN10MB (Ethernet), capture size 262144 bytes
    19:49:55.906340 00:a0:98:67:03:ce (oui Unknown) &gt; 00:a0:98:05:09:2c (oui Unknown), ethertype IPv4 (0x0800), length 98: 10.0.128.1 &gt; 10.0.128.2: ICMP echo request, id 38148, seq 0, length 64
    19:49:55.908913 00:a0:98:05:09:2c (oui Unknown) &gt; 00:a0:98:67:03:ce (oui Unknown), ethertype IPv4 (0x0800), length 98: 10.0.128.2 &gt; 10.0.128.1: ICMP echo reply, id 38148, seq 0, length 64
    ^C
    2 packets captured
    2 packets received by filter
    0 packets dropped by kernel

    root@hostA # tcpdump -i vtnet1.5 -e
    tcpdump: verbose output suppressed, use -v or -vv for full protocol decode
    listening on vtnet1.5, link-type EN10MB (Ethernet), capture size 262144 bytes
    19:58:17.234282 00:a0:98:67:03:ce (oui Unknown) &gt; 00:a0:98:05:09:2c (oui Unknown), ethertype IPv4 (0x0800), length 98: 10.0.64.1 &gt; 10.0.64.2: ICMP echo request, id 30725, seq 0, length 64
    19:58:17.238527 00:a0:98:05:09:2c (oui Unknown) &gt; 00:a0:98:67:03:ce (oui Unknown), ethertype IPv4 (0x0800), length 98: 10.0.64.2 &gt; 10.0.64.1: ICMP echo reply, id 30725, seq 0, length 64
    ^C
    2 packets captured
    2 packets received by filter
    0 packets dropped by kernel
</code></pre>



<p>However, traffic on the parent interface that has a VLAN tag (traffic to 10.0.64.0/24 subnet) will show up in captures on that interface with the tag:</p>



<pre><code>    root@hostA # tcpdump -i vtnet1 -e  
    tcpdump: verbose output suppressed, use -v or -vv for full protocol decode
    listening on vtnet1, link-type EN10MB (Ethernet), capture size 262144 bytes
    19:59:12.596875 00:a0:98:67:03:ce (oui Unknown) &gt; 00:a0:98:05:09:2c (oui Unknown), ethertype 802.1Q (0x8100), length 102: vlan 5, p 0, ethertype IPv4, 10.0.64.1 &gt; 10.0.64.2: ICMP echo request, id 33029, seq 0, length 64
    19:59:12.600823 00:a0:98:05:09:2c (oui Unknown) &gt; 00:a0:98:67:03:ce (oui Unknown), ethertype 802.1Q (0x8100), length 102: vlan 5, p 0, ethertype IPv4, 10.0.64.2 &gt; 10.0.64.1: ICMP echo reply, id 33029, seq 0, length 64
    ^C
    2 packets captured
    2 packets received by filter
    0 packets dropped by kernel
</code></pre>



<p>Comparing these two captures you can see that when the VLAN tag isn’t present (such as when we capture on vtnet1.5) tcpdump doesn’t tell us there is no tag, it doesn’t say anything about VLANs at all. If you find yourself lost and start to wonder if VLANs have broken down, double check you are capturing in the correct place.</p>



<p>If you are not used to looking at its output, <em>tcpdump</em> isn’t the friendliest. You can always write the capture to a file (with the -w flag) and pull it back to your desktop and view with <em>Wireshark</em> or use <em>tshark</em> with the <em>-V</em> flag to get very verbose per field descriptions.</p>



<p>Our test network has two distinct /24 networks running over the same shared infrastructure (here a bridge device).</p>



<h4><strong>Combining VLANs and VNETs</strong></h4>



<p>FreeBSD jails are an excellent way to isolate software and give us the ability to run multiple logical machines on a single host with minimal overhead, VNETs enhance jails further and give them a full network stack. The network stack that the jail sees is almost identical to one that the host machine would see and the jail is able to manage and firewall this network in the same ways.</p>



<p>In a similar way to how we can isolate traffic from multiple applications or customers we can use jails and VNETs to give root level control over how that traffic is managed. VNET jails and VLANs make it possible for us to allow customers in a multi-tenant hosting scenario to have firewall level access over their traffic while isolating other customers traffic from their view. We might use this as we connect hosted applications together over physically separate machines either in another rack or in a data center on the other side of the planet.</p>



<h4><strong>Using VLANs with VNET Jails</strong></h4>



<p>Here we have a short example how to integrate VLANs into a jailed setup that will allow a customer to control the firewalling of traffic (there are more detailed instructions in this article on<a> </a><strong>“Virtualising Networks with FreeBSD VNET Jails</strong>“.</p>



<div data-columns="3" data-layout="50-25-25"><div>




<div><div>
<p>Did you know?</p>



<h2>We wrote about VNETs before in “<strong>Vi…</strong></h2></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://klarasystems.com/articles/routing-and-firewalling-vlans-with-freebsd/">https://klarasystems.com/articles/routing-and-firewalling-vlans-with-freebsd/</a></em></p>]]>
            </description>
            <link>https://klarasystems.com/articles/routing-and-firewalling-vlans-with-freebsd/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25682645</guid>
            <pubDate>Fri, 08 Jan 2021 08:06:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What's the difference between tilde (~) and caret (^) in the package.json file]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25682617">thread link</a>) | @jimmyk99
<br/>
January 7, 2021 | https://qirolab.com/questions/whats-the-difference-between-a-tilde-and-a-caret-in-the-packagejson-file | <a href="https://web.archive.org/web/*/https://qirolab.com/questions/whats-the-difference-between-a-tilde-and-a-caret-in-the-packagejson-file">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text" v-pre=""><p>For that first, you have to understand <a href="https://semver.org/" title="Semantic Versioning" target="_blank" rel="nofollow noreferrer noopener noreferrer">Semantic Versioning</a>. It is divided into three sections separated by a dot.</p>
<pre><code>1.0.2
major.minor.patch
</code></pre>
<p>Major, minor, and patch represent the different releases of a package.</p>
<ul>
<li>
<strong>MAJOR</strong> version when you make incompatible API changes,</li>
<li>
<strong>MINOR</strong> version when you add functionality in a backward-compatible manner, and</li>
<li>
<strong>PATCH</strong> version when you make backward-compatible bug fixes.</li>
</ul>
<p><code>~version</code> <strong>"Approximately equivalent to version"</strong>, will update you to all future <strong>patch</strong> versions, without incrementing the minor version. it means to install version <code>1.0.2</code> or the latest patch version such as <code>1.0.4</code>.</p>
<p><code>^version</code> <strong>"Compatible with version"</strong>, will update you to all future <strong>minor/patch</strong> versions, without incrementing the major version. It means to install version <code>1.0.2</code> or the latest minor or patch version such as <code>1.1.0</code>.</p>
</div></div>]]>
            </description>
            <link>https://qirolab.com/questions/whats-the-difference-between-a-tilde-and-a-caret-in-the-packagejson-file</link>
            <guid isPermaLink="false">hacker-news-small-sites-25682617</guid>
            <pubDate>Fri, 08 Jan 2021 07:58:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Collections: That Dothraki Horde, Part IV: Screamers and Howlers]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25682359">thread link</a>) | @Illniyar
<br/>
January 7, 2021 | https://acoup.blog/2021/01/08/collections-that-dothraki-horde-part-iv-screamers-and-howlers/ | <a href="https://web.archive.org/web/*/https://acoup.blog/2021/01/08/collections-that-dothraki-horde-part-iv-screamers-and-howlers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>This is the fourth part of a four part (<a href="https://acoup.blog/2020/12/04/collections-that-dothraki-horde-part-i-barbarian-couture/">I</a>, <a href="https://acoup.blog/2020/12/11/collections-that-dothraki-horde-part-ii-subsistence-on-the-hoof/">II</a>, <a href="https://acoup.blog/2020/12/18/collections-that-dothraki-horde-part-iii-horse-fiddles/">III</a>) look at the Dothraki from George R. R. Martin’s <em>A Song of Ice and Fire</em> and HBO’s <em>Game of Thrones</em>.  We’re looking at, in particular, if Martin’s claim that the Dothraki are “an amalgam of a number of steppe and plains cultures” can be sustained in the face of even basic knowledge about historical Steppe and Great Plains nomadic peoples.</p>



<p>Last week, we <a href="https://acoup.blog/2020/12/18/collections-that-dothraki-horde-part-iii-horse-fiddles/">concluded </a>that the vast majority of Dothraki culture, social organization, economic practices and family structure are effectively completely untethered from the historical realities of effectively any of the literally dozens of historical Great Plains Native Americans or Steppe nomads.  This week, we’re going to close out our look by discussing Dothraki warfare.  We’ll start with the visual – weapons and armor – and then move to the conceptual – strategy, operations and tactics.</p>



<p>And as always, if you like what you are reading here, please share it; if you really like it, you can support me on <a href="https://www.patreon.com/user?u=20122096">Patreon</a>. And if you want updates whenever a new post appears, you can click below for email updates or follow me on twitter (@BretDevereaux) for updates as to new posts as well as my occasional ancient history, foreign policy or military history musings.</p>






<p>Finally, as a reminder both of what we are investigating, <strong>the key statement we are really assessing here is <a href="https://www.westeros.org/Citadel/SSM/Entry/6040/">this one by George R.R. Martin</a>:</strong></p>



<blockquote><p>The Dothraki were actually fashioned as an amalgam of a number of steppe and plains cultures… Mongols and Huns, certainly, but also Alans, Sioux, Cheyenne, and various other Amerindian tribes… seasoned with a dash of pure fantasy.</p></blockquote>



<p>It is not the <em>existence</em> of a fantasy culture which draws our attention, but the explicit declaration that this fantasy culture is not merely inspired, but ‘fashioned as an amalgam’ of real cultures, which both existed in the past <em>and still exist today</em>, with only ‘a dash of pure fantasy.’  That line is important, to be clear, <strong>because it presents the fictional Dothraki as a statement on historical Native American and Eurasian nomads</strong> and – when combined with Martin’s statements that he relies on history to inform his work – that this statement is based in some sort of historical reality.</p>



<p>Which it isn’t.  But we’re getting ahead of ourselves.</p>



<h2>Where There’s a Whip…</h2>



<p>The Dothraki are described as having three main weapons: <strong>bows </strong>(<em>AGoT</em>, 86, 555, 558, 597, 669), <strong>whips </strong>(<em>AGoT</em>, 86, 194, 493, 555, 596, 669) and a <strong>curved sword called an <em>arakh</em></strong> (<em>AGoT</em> 85, 86, 327, 493, 555, 556, 559, 560, 596, 597, 669, 674); <strong>of these, the <em>arakh</em> is clearly the most prominent</strong> (I am sure I have missed a reference to a weapon here or there, but I hope the citations here give some sense of the relative weight each is given – the <em>arakh</em> is the most frequently mentioned by some distance).  When a Dothraki warrior enters <em>Vaes Dothrak</em>, each, “unbelted his <em>arakh</em> and handed it to a waiting slave, and any other weapons he carried as well” – after the <em>arakh</em>, the other weapons are seemingly afterthoughts (<em>AGoT</em>, 327).  The prominence of the <em>arakh</em> in the narrative is underscored by the fact that it is the only one of these weapons whose name we learn in Dothraki, or which is described in terms of its shape or special function (<em>AGoT</em>, 85), while the bows and whips remain just bows and whips (ironic, as it was Steppe <em>bows</em>, not Steppe swords, which were unusual).</p>



<p>We might dismiss this as simply an accident of Daenerys’ perspective – that, being Westerosi, she focuses on the weapon most meaningful to the Westerosi – but that’s clearly not true.  After all, the <strong>offering of an <em>arakh</em> is how Daenerys’ loyal followers demonstrate their fealty to her</strong>, in a ceremony that is clearly Dothraki, not Westerosi (<em>AGoT</em>, 674).  It is also, I should note,<a href="https://awoiaf.westeros.org/index.php/Arakh"> the only weapon we see <em>non</em>-Dothraki using that is clearly identified as being foreign and typical of the Dothraki</a>.  It remains special through the eyes of multiple point-of-view characters, including military men.</p>



<p>(And, as an aside, now that we are this far in, it seems obvious but worth saying that the fact that Martin has no Dothraki viewpoint characters in his narrative is hardly a saving grace; it merely intensifies the ‘view of a savage culture from outside’ effect.  As we’ll see, this makes perfect sense given what seem to be the actual inspirations for his depiction.)</p>



<p><strong>The prominence of a curved iron (or steel) sword lets us rule out a Great Plains Native American inspiration for this kit right out</strong>; the sword was never a significant part of Plains Native American armament (the lack of tool-metal production in the Americas prior to European contact means that there was no indigenous sword-making tradition, although the <a href="https://en.wikipedia.org/wiki/Macuahuitl"><em>maquahuitl</em> </a>represents a clever sort of ‘sharpened club’ design).  Even after contact, it’s hard to avoid the conclusion that the expense of trading for a sword wouldn’t have been justified by its utility over a steel axe which might also double as a tool (on axes, see W. Lee, “The Military Revolution of Native North America: Firearms, Forts and Politics” in <em>Empires and Indigenes</em> (2011), 62-3).  <strong>So we must turn to the Eurasian Steppe</strong>.</p>



<p><strong>And immediately we run into problems</strong>, not that any of these weapons are <em>wrong</em> per se, but <strong>that their proportion and prominence is all mixed up and that there are other, far more important weapons missing.</strong></p>



<p><strong>For a Steppe nomad, by far, above and away, the most important weapon was the bow.</strong>  The Armenians literally called the Mongols “the nation of archers” (May, <em>Mongol Art of War</em>, 43).  Nomads spent the most time learning the bow (May, <em>op. cit.</em> 42-49) and it was the one indispensable weapon.  Indeed, so indispensable that nomads were generally required to have several; the <em>Liao Shi</em> records that Khitan nomad warriors were required to possess four bows and 400 arrows, while John de Plano Carpini reports that the Mongols all needed to have 2-3 bows and three larger quivers (May, <em>op. cit. </em>49-50).  <strong>The Steppe bow itself would also have looked unusual in both shape and construction</strong> to a Westerosi observer either strung or unstrung – they were composite bows, made with a wood core, a backing of horn and a rigid end-piece (called a <em>siyah</em> in Arabic) and were generally drawn with the use of a thumb-ring to reduce strain on the thumb (May, <em>op. cit.</em>, 50-1).  This unique construction allowed these bows to reach draw weights and launch energies equivalent to the far larger yew longbows of England and Wales and still be compact enough to use from horseback.</p>



<div><figure><img data-attachment-id="5819" data-permalink="https://acoup.blog/ilkhanidhorsearcher-2/" data-orig-file="https://acoupdotblog.files.wordpress.com/2021/01/ilkhanidhorsearcher.jpg" data-orig-size="450,350" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="ilkhanidhorsearcher" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2021/01/ilkhanidhorsearcher.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2021/01/ilkhanidhorsearcher.jpg?w=450" src="https://acoupdotblog.files.wordpress.com/2021/01/ilkhanidhorsearcher.jpg?w=450" alt="" srcset="https://acoupdotblog.files.wordpress.com/2021/01/ilkhanidhorsearcher.jpg 450w, https://acoupdotblog.files.wordpress.com/2021/01/ilkhanidhorsearcher.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2021/01/ilkhanidhorsearcher.jpg?w=300 300w" sizes="(max-width: 450px) 100vw, 450px"><figcaption><a href="https://en.wikipedia.org/wiki/Mongols#/media/File:IlkhanidHorseArcher.jpg">Via Wikipedia</a>, a 13th century Mongol horse archer.  Lightly armored, he carries a bow (and a fancy hat) but no sword.</figcaption></figure></div>



<p>(I should note that the bow was <em>also</em> the paramount weapon for the Native American horse-borne nomads of the Great Plains, at least until it came into competition with firearms, though my understanding is that Native American bows were not as powerful as Steppe bows).</p>



<div><figure><img loading="lazy" data-attachment-id="5821" data-permalink="https://acoup.blog/minolta-dsc/" data-orig-file="https://acoupdotblog.files.wordpress.com/2021/01/naadam_women_archery.jpg" data-orig-size="1920,2560" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;3.2&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;DiMAGE A1&quot;,&quot;caption&quot;:&quot;Minolta DSC&quot;,&quot;created_timestamp&quot;:&quot;1118415959&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;12.91796875&quot;,&quot;iso&quot;:&quot;100&quot;,&quot;shutter_speed&quot;:&quot;0.0003125&quot;,&quot;title&quot;:&quot;Minolta DSC&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="Minolta DSC" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2021/01/naadam_women_archery.jpg?w=225" data-large-file="https://acoupdotblog.files.wordpress.com/2021/01/naadam_women_archery.jpg?w=768" src="https://acoupdotblog.files.wordpress.com/2021/01/naadam_women_archery.jpg?w=768" alt="" width="596" height="795" srcset="https://acoupdotblog.files.wordpress.com/2021/01/naadam_women_archery.jpg?w=768 768w, https://acoupdotblog.files.wordpress.com/2021/01/naadam_women_archery.jpg?w=596 596w, https://acoupdotblog.files.wordpress.com/2021/01/naadam_women_archery.jpg?w=1192 1192w, https://acoupdotblog.files.wordpress.com/2021/01/naadam_women_archery.jpg?w=113 113w, https://acoupdotblog.files.wordpress.com/2021/01/naadam_women_archery.jpg?w=225 225w" sizes="(max-width: 596px) 100vw, 596px"><figcaption><a href="https://en.wikipedia.org/wiki/Mongols#/media/File:Naadam_women_archery.jpg">Via Wikipedia</a>, a modern Mongolian woman taking part in an archery contest.  You can see here the unique shape and multi-part construction of the Steppe bow (notice how the material on the tips, the belly and the spine of the bow are all different) which allows it so much power in such a small frame.<br>Also, notice the very nice and colorful traditional Mongolian clothing – not leather and rough furs!</figcaption></figure></div>



<p><strong>But even after the bow, the sword is not first.  Or even close to first.</strong>  Or, indeed, <em>even on the list</em>!  The Khitan regulations I mentioned included four bows, two spears (one ‘long’ and one ‘short’), a club, an axe and a halberd, but no sword.  John de Plano Carpini describes the full kit as two or three bows with quivers, an axe, ropes, and swords <em>only for the wealthy</em> (May. <em>op. cit.</em>, 50).  Speaking more broadly, May notes that spears (used as lances from horseback) seem universal in accounts of the Mongols, but “accounts are contradictory regarding whether these [swords] were universally used” (May, <em>op. cit.</em>, 52).  While May supposes that the <em>ughurgh-a</em>, the Mongolian lasso, might have been used in combat – and it may well have – we have no definitive evidence of it.  If it was ever a weapon, it doesn’t seem to have been an important one.</p>



<p><strong>In short, while the Dothraki’s weapons are an <em>arakh</em>-sword, a whip, and a bow in that order, the Mongol’s chief weapons were his bow, followed by his backup bow, followed by his <em>other </em>backup bow, followed by his spear, and then his axe and only then followed by a sword, should he have one, which he might well not</strong>.  The reason for preferring an axe or a spear for the humble nomad should not be too surprising – iron in quantity could be hard to get on the Steppe.  Spears and axes are not only weapons, but also useful hunting and survival tools; swords are generally weapons only.  <a href="https://acoup.blog/2020/09/18/collections-iron-how-did-they-make-it-part-i-mining/">Nomads generally cannot do their own metal working</a>, so swords would have to be imported.  Moreover, even in a melee, the first recourse would be to a spear, <a href="https://acoup.blog/2020/05/08/collections-the-battle-of-helms-deep-part-ii-total-warg/">whose reach on horseback was a huge advantage</a>,<strong> making a sword an expensive imported foreign luxury <em>backup</em> weapon with no additional utility</strong>.  Nevertheless, it’s clear that Steppe nomads, once successful and moving into agrarian areas, liked to acquire swords – swords are effective weapons! – but the sword was about the furthest thing from the core of Mongol culture the way the <em>arakh</em> is practically the <em>symbol</em> of Dothraki culture.</p>



<figure><img data-attachment-id="5816" data-permalink="https://acoup.blog/langshiming_mao/" data-orig-file="https://acoupdotblog.files.wordpress.com/2021/01/langshiming_mao.jpg" data-orig-size="1920,1118" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="langshiming_mao" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2021/01/langshiming_mao.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2021/01/langshiming_mao.jpg?w=1024" src="https://acoupdotblog.files.wordpress.com/2021/01/langshiming_mao.jpg?w=1024" alt="" srcset="https://acoupdotblog.files.wordpress.com/2021/01/langshiming_mao.jpg?w=1024 1024w, https://acoupdotblog.files.wordpress.com/2021/01/langshiming_mao.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2021/01/langshiming_mao.jpg?w=300 300w, https://acoupdotblog.files.wordpress.com/2021/01/langshiming_mao.jpg?w=768 768w, https://acoupdotblog.files.wordpress.com/2021/01/langshiming_mao.jpg 1920w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption><a href="https://en.wikipedia.org/wiki/Mongols#/media/File:Langshiming_mao.JPG">Via Wikipedia</a>, a relatively late Mongol soldier (c. 1755) nevertheless shows nearly the full kit, including mail body defense, a long spear for use on horseback, arrows (the bow in its bow-case would have been on the other side) and, this being the 1700s, a musket.</figcaption></figure>



<p><strong>The other issue, of course, is the <em>arakh</em> itself.</strong>  Martin describes the weapons as “long razor-sharp blades, half sword and half scythe” (<em>AGoT</em>, 85) and goes back to that scythe analogy (e.g. <em>ASoS</em>, 245).  It seems generally asserted that what Martin means by this is something close to a scimitar (I have to confess, I haven’t found anywhere that Martin says …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://acoup.blog/2021/01/08/collections-that-dothraki-horde-part-iv-screamers-and-howlers/">https://acoup.blog/2021/01/08/collections-that-dothraki-horde-part-iv-screamers-and-howlers/</a></em></p>]]>
            </description>
            <link>https://acoup.blog/2021/01/08/collections-that-dothraki-horde-part-iv-screamers-and-howlers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25682359</guid>
            <pubDate>Fri, 08 Jan 2021 07:10:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[US to modify H1B visa selection process – wages, skill level to get priority]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25682309">thread link</a>) | @LopRabbit
<br/>
January 7, 2021 | https://www.businessinsider.in/international/news/us-to-modify-h1b-visa-selection-process-wages-skill-level-to-get-priority-over-lottery-system/articleshow/80164510.cms | <a href="https://web.archive.org/web/*/https://www.businessinsider.in/international/news/us-to-modify-h1b-visa-selection-process-wages-skill-level-to-get-priority-over-lottery-system/articleshow/80164510.cms">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div id="datatxt80164510read"><div data-den="denmark"><div><p>The United States on Thursday announced that it will modify the selection process for H-1B visa, giving priority to salary and skills instead of the current lottery procedures. 
</p><p>
 The final rule to be published in the federal register on January 8, officials said, is aimed to protect the economic interests of US workers and better ensure the most highly skilled foreign workers benefit from the temporary employment programme. 
</p><p>
     The H-1B visa is a non-immigrant visa that allows US companies to employ foreign workers in specialty occupations that require theoretical or technical expertise. The technology companies depend on it to hire tens of thousands of employees each year from countries like India and China. 
</p><p> Modifying the H-1B cap selection process will incentivise employers to offer higher salaries, and/or petition for higher-skilled positions, and establish a more certain path for businesses to achieve personnel needs and remain globally competitive, said </p><keyword keytype="Company" smid="0" usetype="2" keywordseo="US-Citizenship-and-Immigration-Services" actualkeyword="US Citizenship and Immigration Services">US Citizenship and Immigration Services</keyword><p>. 
</p><p>
     The final rule will be effective 60 days after its publication in the Federal Register. The next H-1B visa filing season is slated to start on April 1. 
</p><p>
 "The H-1B temporary visa programme has been exploited and abused by employers primarily seeking to fill entry-level positions and reduce overall business costs," said </p><keyword keytype="Company" smid="0" usetype="2" keywordseo="USCIS" actualkeyword="USCIS">USCIS</keyword><p> Deputy Director for Policy Joseph Edlow. 
</p><p><span>Advertisement</span></p><figure><div></div></figure><hr><p> "The current H-1B random selection process makes it difficult for businesses to plan their hiring, fails to leverage the programme to compete for the best and brightest international workforce, and has predominantly resulted in the annual influx of foreign labor placed in low-wage positions at the expense of US workers," he said. 
</p><p>
 This effort will only affect H-1B registrations (or petitions, if the registration process is suspended) submitted by prospective petitioners seeking to file H-1B cap-subject petitions. 
</p><p>
     It will be implemented for both the H-1B regular cap and the H-1B advanced degree exemption, but it will not change the order of selection between the two as established by the H-1B registration final rule, USCIS said. 
</p><p> The </p><keyword keytype="Company" smid="0" usetype="2" keywordseo="Department-of-Homeland-Security" keynameseo="department-of-homeland-security" actualkeyword="department of homeland security">Department of Homeland Security</keyword><p> had previously published a notice of proposed rulemaking on November 2, 2020. It carefully considered the public comments received before deciding to publish the proposed regulations as a final rule, USCIS said. 
</p><p>
     According to the final rule, a version of which was released by Department of Homeland Security, Instead, a registration system that faithfully implements the Immigration and Nationality Act (INA) while prioritising registrations based on wage level within each cap will incentivize H-1B employers to offer higher wages, or to petition for positions requiring higher skills and higher-skilled aliens that are commensurate with higher wage levels, to increase the likelihood of selection and eligibility to file an H-1B cap-subject petition. 
</p><p>
 Moreover, it will maximize H-1B cap allocations, so that they more likely will go to the best and brightest workers; and it will disincentivise abuse of the H-1B programme to fill relatively lower-paid, lower-skilled positions, which is a significant problem under the present selection system, it said. 
</p><p> "While administering a random lottery system is reasonable, it is inconsiderate of Congress's statutory purposes for the H-1B program and its administration," said the final rule. 
</p><p>
 The changes in this final rule will apply to all registrations, including those for the advanced degree exemption, submitted on or after the effective date of the final rule. 
</p><p>
     As per Congressional-mandated cap, USCIS in one year can issue a maximum of 65,000 H-1B visas. It can also issue another 20,000 H-1B visas to those foreign students who have completed higher studies from a US university in STEM subjects. 
</p><p> During the public notice period, the department said, several commenters expressed support for the rule and the need to stop visa fraud, abuse, and flooding of petitions by certain staffing or consulting companies. 
</p><p>
     One commenter said the proposed rule would disincentivize companies from abusing the H-1B programme and harming US workers. Other commenters said the proposed rule would decrease potential visa abuse by employers and make sure all workers were paid according to their skillset as employers no longer would be able to lower labor expenses by hiring foreign workers. 
</p><p>
 Another said that the proposed rule would have a positive impact on US employees and college educated US citizens who take out loans for their education by making it harder for technology companies to discriminate against US citizens; US workers are being laid off in large numbers because corporations are outsourcing for profits; and the proposed rule is necessary because Indian corporations are acquiring US jobs, it said. 
</p>
<p><strong>SEE ALSO: <a href="https://www.businessinsider.in/stock-market/news/tcs-ongc-tata-power-punjab-national-bank-nhpc-and-other-top-stocks-to-watch/articleshow/80164057.cms">TCS’ market share, ONGC’s borrowing, Tata Power gets new territories⁠— these and other top stocks to watch</a></strong>
<a href="https://www.businessinsider.in/tech/news/whatsapp-is-forcing-users-to-share-personal-data-with-facebook-and-elon-musk-is-urging-people-to-switch-to-signal-a-smaller-encrypted-messaging-app/articleshow/80156317.cms">WhatsApp is forcing users to share personal data with Facebook, and Elon Musk is urging people to switch to Signal, a smaller encrypted messaging app</a>
<br>
</p></div></div></div></div></div>]]>
            </description>
            <link>https://www.businessinsider.in/international/news/us-to-modify-h1b-visa-selection-process-wages-skill-level-to-get-priority-over-lottery-system/articleshow/80164510.cms</link>
            <guid isPermaLink="false">hacker-news-small-sites-25682309</guid>
            <pubDate>Fri, 08 Jan 2021 07:02:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tips for a New Engineering Manager]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25681979">thread link</a>) | @alexhunterlang
<br/>
January 7, 2021 | https://n2infinityandbeyond.com/2021/01/07/tips-for-a-new-engineering-manager/ | <a href="https://web.archive.org/web/*/https://n2infinityandbeyond.com/2021/01/07/tips-for-a-new-engineering-manager/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Welcome to the new world of engineering management! You’ve entered a brave new world that will be significantly different than your life as an individual contributor. Here are some tips I’ve learned over time.</p>



<p>You have one goal: <strong>maximize your team’s productive work</strong>.</p>



<p>That’s it. Do that and you will succeed. Do anything else and you fail. Life is simple.</p>



<p>Let’s break that down into a few key ideas.</p>



<h2>Maximize Your Team Member’s Potential</h2>



<p>First, let’s assess the type of engineers you may have on your team.</p>



<ul><li><strong>Solid</strong> = Can solve well defined problems.</li><li><strong>Bad</strong> = Can’t solve well defined problems.</li><li><strong>Junior</strong> = Bad engineers but have the excuse of being very early in their career or being put into a new situation.</li><li><strong>Leaders</strong> = Can determine the problems that need to be solved and help others get the necessary work done.</li></ul>



<p>How should you manage the different types of engineers?</p>



<p><strong>Engineering Leaders</strong>. If you are a new manager, you are likely the only Leader in your team. If you are lucky enough to have team members that are Leaders, your life will be easy. Just keep giving them tough problems and stay out of their way.</p>



<p><strong>Solid Engineers</strong>. These engineers will hopefully make up most of your team. They can tackle well defined problems, so to maximize their current utility, work on giving them the minimum definition they need and then get out of their way. To maximize their long term success, you want to try and turn Solid Engineers into Leaders. One way to do this is to keep giving them tougher problems with less definition and let them grow into Leaders.</p>



<p><strong>Bad Engineers. </strong>Hopefully you don’t inherit any Bad Engineers. If you do, you need to quickly assess whether it is worth the management effort to get them to Solid Engineers, or get them off your team (either by firing or a transfer to another team).</p>



<p><strong>Junior Engineers. </strong>As a new manager, you are likely to have several Junior Engineers. I’ve found that everyone is happiest if both the Junior Engineer and yourself acknowledge that Junior Engineers do not produce useful work today. Instead, both the Junior Engineer and yourself should focus your efforts on turning them into a Solid Engineer as soon as possible. As a manager, you can accelerate their growth by (1) giving them training tasks, i.e. tasks that may not be the most relevant to your team’s productivity today, but help them grow as an individual and (2) giving them extra 1 on 1 attention. While this extra effort will consume significant time now, you can have a Solid Engineer within a few months. Plus, this extra effort is nothing compared to the effort you would later need to spend to move someone from a Bad Engineer to Solid Engineer.</p>



<h2>Maximize Your Team Output</h2>



<p>Now that we have covered the basics of maximizing individual team member’s performance, let’s move on to some tips for maximizing your whole team’s output.</p>



<h3>Your Output</h3>



<p>First, you need to plan that your personal coding output will basically be zero. You may occasionally do some coding, but you need to remember that you are judged on your team’s output now, not just your own. So any coding project you do needs to be weighed against the opportunity cost of you spending that same amount of time improving your team members. I’ve found that this likely means you will only end up coding (1) early prototypes, (2) refactorings, or (3) nice to have projects. Instead, you need to switch to thinking about your team’s output.</p>



<h3>Meetings</h3>



<p>As a new manager, your life can easily be consumed by meetings. You will now be in charge of 1:1s and team meetings, and also get invited to lots of cross team meetings. My biggest regret as an early manager is saying yes to every meeting. I personally am fine with delegating work, but my weakness was that I still wanted to know everything that was going on. Before you know it, you will spend all day running from meeting to meeting. This is bad for three reasons: (1) you don’t have time to think, (2) you can’t adapt to emergencies and (3) your team members will become too shy to schedule 1:1s with you since they assume you are doing something important.&nbsp;&nbsp;</p>



<p>So fight the good fight and minimize the number of meetings. I advocate the following meeting philosophy:</p>



<ul><li>All meetings should have a predefined agenda, even 1:1s.</li><li>Have the minimum number of people in the meeting (ie prefer 1:1s or small groups)</li><li>Minimize the number of meetings that are just status updates. Most of these can likely be replaced by email, Slack, or a document.</li><li>Group meetings into blocks. I’ve had success with the following type of meeting schedule:<ul><li>Monday AM: Sprint starts / big team meetings.</li><li>Monday PM: 1:1s.</li><li>Tuesday: No recurring meetings.</li><li>Wednesday: Cross team meetings.</li><li>Thursday: No recurring meetings.</li><li>Friday AM: Sprint check ins / sprint end meetings.</li><li>Friday PM: 1:1s.</li></ul></li></ul>



<h3>Documents</h3>



<p>A well written document is one of your two new best friends. The power of a well written document is that it (1) forces you to clarify your thoughts, (2) provides a clear documentation trail and (3) prevents you from repeating yourself. There is nothing worse than having a meeting with a lot of people that leads to some very important decisions, but then no one can seem to remember what those decisions are. Write, write, and write some more.&nbsp;</p>



<h2>Do Productive Work</h2>



<p>At this point your team should be doing lots of work. But how do you guarantee that this work is productive? Let me introduce you to your second new best friend: <a href="https://www.whatmatters.com/get-started/">Objectives and Key Results</a>.&nbsp;</p>



<p>The main principles of OKRs are:</p>



<ul><li>Objectives should be clearly defined aspirational goals</li><li>Key results are specific quantitative measures</li><li>Each objective should be supported by 3-5 key results</li><li>Ideally key results can be measured on a 0-100% scale</li><li>To make key results push the boundaries of your team, it is recommended that<ul><li>A key result is considered achieved if &gt;=70% is achieved</li><li>Key results are not tied to pay</li></ul></li></ul>



<p>Many companies use a mix of yearly and quarterly OKRs. I personally find the quarter OKRs most useful as a management tool. The yearly OKRs are more useful for upper management to set clear company wide goals, but I’ve found that setting yearly team goals are not very useful unless they directly tie into a company OKR. Instead, I would focus on writing solid quarterly team OKRs.</p>



<p>For OKRs to truly work, you need to get buy in from the whole team. In order to get buy in, you should:</p>



<ol><li>Do the necessary prep work to deeply understand the company priorities and OKRs.</li><li>Involve your team members in developing the team OKRs.</li><li>Set up a central dashboard to track your progress on OKRs.</li><li>Make that dashboard a central part of your meetings. Kick off team meetings by looking at the dashboard and calling out progress.</li><li>Have a retrospective at the end of the recording period to understand why your team succeeded or failed to achieve OKRs.</li><li>Rinse and repeat. Your first several quarters of OKRs likely won’t go well. But please don’t give up until you have tried for at least 4 quarters in a row.</li></ol>



<h2>Final Thoughts</h2>



<p>Good luck, hope these tips help!</p>
			
			
						</div></div>]]>
            </description>
            <link>https://n2infinityandbeyond.com/2021/01/07/tips-for-a-new-engineering-manager/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25681979</guid>
            <pubDate>Fri, 08 Jan 2021 06:02:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building an Air Filtration System for a 3D Printer]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25680448">thread link</a>) | @michaeltbuss
<br/>
January 7, 2021 | https://mikebuss.com/2021/01/06/3d-printer-filtration/ | <a href="https://web.archive.org/web/*/https://mikebuss.com/2021/01/06/3d-printer-filtration/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div class="page">
  
  
    <p>How I used a microcontroller, a fan, and a bunch of sensors to create a smart filtration system.</p>
  

  <p>January 06, 2021 | <a href="https://mikebuss.com/">Mike Buss</a></p>
</div><div class="page">
  
<figure>

    <a href="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/enclosure1.jpg">

<picture>
    
    <source data-srcset="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/enclosure1.webp" type="image/webp">
    
    <img data-src="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/enclosure1.jpg" alt="" data-srcset="    /assets/resized/enclosure1-480x325.jpg 480w,    /assets/resized/enclosure1-960x650.jpg 960w,    /assets/resized/enclosure1-1200x812.jpg 1200w,/assets/images/posts/3d-printer-filtration/enclosure1.jpg 2000w" src="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/enclosure1.jpg" srcset="    https://mikebuss.com/assets/resized/enclosure1-480x325.jpg 480w,    https://mikebuss.com/assets/resized/enclosure1-960x650.jpg 960w,    https://mikebuss.com/assets/resized/enclosure1-1200x812.jpg 1200w,https://mikebuss.com/assets/images/posts/3d-printer-filtration/enclosure1.jpg 2000w">
</picture>
</a>


</figure>

<p>I was thinking of projects to work on, and I thought, gee, it would be nice if our 3D printer didn’t kill us <a href="#risks-footnote"><sup>1</sup></a>.</p>

<p>I had researched the potential health side effects of owning a 3D printer when I bought it - it turns out they can malfunction and catch fire or release <a href="https://en.wikipedia.org/wiki/Volatile_organic_compound">harmful chemicals</a> into the air - but I made excuses. I’m only printing in <a href="https://en.wikipedia.org/wiki/Polylactic_acid">Polyactic Acid</a> (PLA), one of the least harmful filaments - it’s probably fine. Sure, maybe it releases some tiny plastic into the air, but it’s a big room, and sometimes I keep the windows open. Our smoke detectors are brand new and well tested. We’re <em>probably fine</em>.</p>

<p>Now that we welcomed <a href="https://mikebuss.com/2020/10/08/welcome-theodore/">Theodore</a>, our now 3-month-old, into the world, I wanted to be on the safe side. So, I set out to build an air filtration system and some other safety features.</p>

<hr>

<h2 id="the-start-of-an-idea">The Start of an Idea</h2>

<p>As with most of my hobby projects, it started out simple. I thought of strapping a fan to a HEPA filter and maybe adding a carbon filter for extra protection. Then I thought: wouldn’t it be cool if it turned on and off automatically when a print started? Surely that wouldn’t be too difficult to build.</p>

<p>And wouldn’t it be even better if the system could tell when the volatile organic compounds (VOC) levels were high and adjust the fan speed accordingly? Since the goal is to make this box less likely to kill everyone in our sleep, why not add a fire sensor and an electric cutoff?</p>

<figure>

    <a href="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/fan2.jpg">

<picture>
    
    <source data-srcset="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/fan2.webp" type="image/webp">
    
    <img data-src="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/fan2.jpg" alt="" data-srcset="    /assets/resized/fan2-480x360.jpg 480w,    /assets/resized/fan2-960x720.jpg 960w,    /assets/resized/fan2-1200x900.jpg 1200w,/assets/images/posts/3d-printer-filtration/fan2.jpg 2000w" src="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/fan2.jpg" srcset="    https://mikebuss.com/assets/resized/fan2-480x360.jpg 480w,    https://mikebuss.com/assets/resized/fan2-960x720.jpg 960w,    https://mikebuss.com/assets/resized/fan2-1200x900.jpg 1200w,https://mikebuss.com/assets/images/posts/3d-printer-filtration/fan2.jpg 2000w">
</picture>
</a>


<figcaption>The fan I started with: a 140mm NZXT fan for PC's.</figcaption>

</figure>

<p>Eventually, I landed on building a totally ridiculous, completely overkill air filtration system for our 3D printer that probably wasn’t necessary in the first place. And it was lots of fun.</p>

<p>Here’s how I did it.</p>

<hr>

<h2 id="sketching-it-out">Sketching It Out</h2>

<p>I’m a firm believer in “measure twice, cut once”, so I started with a sketch of the system. I measured my 3D printer - an <a href="https://ultimaker.com/3d-printers/ultimaker-s3">Ultimaker S3</a> - and jotted down a plan for the top enclosure. Then, I sketched out what components I wanted to use and how they’d connect.</p>

<figure>

    <a href="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/sketches.png">

<picture>
    
    <source data-srcset="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/sketches.webp" type="image/webp">
    
    <img data-src="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/sketches.png" alt="" data-srcset="    /assets/resized/sketches-480x240.png 480w,    /assets/resized/sketches-960x480.png 960w,    /assets/resized/sketches-1200x600.png 1200w,/assets/images/posts/3d-printer-filtration/sketches.png 2000w" src="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/sketches.png" srcset="    https://mikebuss.com/assets/resized/sketches-480x240.png 480w,    https://mikebuss.com/assets/resized/sketches-960x480.png 960w,    https://mikebuss.com/assets/resized/sketches-1200x600.png 1200w,https://mikebuss.com/assets/images/posts/3d-printer-filtration/sketches.png 2000w">
</picture>
</a>


<figcaption>The final product has changed since these sketches.</figcaption>

</figure>

<p>Next, I printed the parts I needed to assemble the box and the filtration panel. Isn’t it cool how a printer can print things to augment itself? Next step: <a href="https://en.wikipedia.org/wiki/Skynet_(Terminator)">Skynet</a>.</p>

<figure>

    <a href="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/printing.png">

<picture>
    
    <source data-srcset="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/printing.webp" type="image/webp">
    
    <img data-src="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/printing.png" alt="" data-srcset="    /assets/resized/printing-480x269.png 480w,    /assets/resized/printing-960x539.png 960w,    /assets/resized/printing-1200x674.png 1200w,    /assets/resized/printing-2000x1123.png 2000w,/assets/images/posts/3d-printer-filtration/printing.png 2494w" src="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/printing.png" srcset="    https://mikebuss.com/assets/resized/printing-480x269.png 480w,    https://mikebuss.com/assets/resized/printing-960x539.png 960w,    https://mikebuss.com/assets/resized/printing-1200x674.png 1200w,    https://mikebuss.com/assets/resized/printing-2000x1123.png 2000w,https://mikebuss.com/assets/images/posts/3d-printer-filtration/printing.png 2494w">
</picture>
</a>


<figcaption>Everything except the electronics and Lexan was printed.</figcaption>

</figure>

<hr>

<h2 id="building-the-partial-enclosure">Building the Partial Enclosure</h2>

<p>I bought some Lexan from Home Depot, scored the sheets with a box cutter, and snapped them off using the edge of my workbench. It worked surprisingly well.</p>

<p>If you plan to do this at home, <em>wear protective gear</em>, including glasses.</p>

<figure>

    <a href="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/lexan1.jpg">

<picture>
    
    <source data-srcset="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/lexan1.webp" type="image/webp">
    
    <img data-src="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/lexan1.jpg" alt="" data-srcset="    /assets/resized/lexan1-480x360.jpg 480w,    /assets/resized/lexan1-960x720.jpg 960w,    /assets/resized/lexan1-1200x900.jpg 1200w,/assets/images/posts/3d-printer-filtration/lexan1.jpg 2000w" src="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/lexan1.jpg" srcset="    https://mikebuss.com/assets/resized/lexan1-480x360.jpg 480w,    https://mikebuss.com/assets/resized/lexan1-960x720.jpg 960w,    https://mikebuss.com/assets/resized/lexan1-1200x900.jpg 1200w,https://mikebuss.com/assets/images/posts/3d-printer-filtration/lexan1.jpg 2000w">
</picture>
</a>


<figcaption>I used Lexan because it was readily available at the local Home Depot.</figcaption>

</figure>

<p>After cutting the Lexan, I connected all the pieces with 3D-printed parts. Special thanks to <a href="https://www.thingiverse.com/core2/designs">Hans Peter</a> for building something similar and releasing the <a href="https://www.thingiverse.com/thing:3357829">designs</a> on Thingiverse.</p>

<figure>

    <a href="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/enclosure-connectors-1.jpg">

<picture>
    
    <source data-srcset="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/enclosure-connectors-1.webp" type="image/webp">
    
    <img data-src="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/enclosure-connectors-1.jpg" alt="" data-srcset="    /assets/resized/enclosure-connectors-1-480x640.jpg 480w,    /assets/resized/enclosure-connectors-1-960x1280.jpg 960w,    /assets/resized/enclosure-connectors-1-1200x1600.jpg 1200w,/assets/images/posts/3d-printer-filtration/enclosure-connectors-1.jpg 2000w" src="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/enclosure-connectors-1.jpg" srcset="    https://mikebuss.com/assets/resized/enclosure-connectors-1-480x640.jpg 480w,    https://mikebuss.com/assets/resized/enclosure-connectors-1-960x1280.jpg 960w,    https://mikebuss.com/assets/resized/enclosure-connectors-1-1200x1600.jpg 1200w,https://mikebuss.com/assets/images/posts/3d-printer-filtration/enclosure-connectors-1.jpg 2000w">
</picture>
</a>


<figcaption>The connecting parts were 3D printed.</figcaption>

</figure>

<figure>

    <a href="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/empty-enclosure1.jpg">

<picture>
    
    <source data-srcset="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/empty-enclosure1.webp" type="image/webp">
    
    <img data-src="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/empty-enclosure1.jpg" alt="" data-srcset="    /assets/resized/empty-enclosure1-480x360.jpg 480w,    /assets/resized/empty-enclosure1-960x720.jpg 960w,    /assets/resized/empty-enclosure1-1200x900.jpg 1200w,/assets/images/posts/3d-printer-filtration/empty-enclosure1.jpg 2000w" src="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/empty-enclosure1.jpg" srcset="    https://mikebuss.com/assets/resized/empty-enclosure1-480x360.jpg 480w,    https://mikebuss.com/assets/resized/empty-enclosure1-960x720.jpg 960w,    https://mikebuss.com/assets/resized/empty-enclosure1-1200x900.jpg 1200w,https://mikebuss.com/assets/images/posts/3d-printer-filtration/empty-enclosure1.jpg 2000w">
</picture>
</a>


<figcaption>The final Lexan enclosure.</figcaption>

</figure>

<p>Now that I had the shell, it was time for the guts: the electronics.</p>

<hr>

<h2 id="wiring-everything-up">Wiring Everything Up</h2>

<p>The first rule of wiring electronics is don’t accidentally put 12V into a pin that expects 5V. You’ll get lots of smoke and heat and generally feel bad. After you’ve learned that rule, continue reading.</p>

<figure>

    <a href="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/electronics.png">

<picture>
    
    <source data-srcset="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/electronics.webp" type="image/webp">
    
    <img data-src="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/electronics.png" alt="" data-srcset="    /assets/resized/electronics-480x240.png 480w,    /assets/resized/electronics-960x480.png 960w,    /assets/resized/electronics-1200x600.png 1200w,/assets/images/posts/3d-printer-filtration/electronics.png 2000w" src="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/electronics.png" srcset="    https://mikebuss.com/assets/resized/electronics-480x240.png 480w,    https://mikebuss.com/assets/resized/electronics-960x480.png 960w,    https://mikebuss.com/assets/resized/electronics-1200x600.png 1200w,https://mikebuss.com/assets/images/posts/3d-printer-filtration/electronics.png 2000w">
</picture>
</a>


<figcaption>No electronics project would be complete without a prototype that looks like a rat's nest (top right). I cleaned this up later!</figcaption>

</figure>

<p>I managed to assemble a gaggle of electronics that all needed power. Some needed 12V to work. Others needed 3.3V. Some were controlled with <a href="https://en.wikipedia.org/wiki/Pulse-width_modulation">pulse width modulation</a>, others with <a href="https://en.wikipedia.org/wiki/I%C2%B2C">I2C</a>. Getting them powered and conducting a symphony of functions was, in my opinion, the best part of this project.</p>

<p>I started with a 12V 3A <a href="https://www.amazon.com/gp/product/B07HNV6SBJ/ref=ppx_yo_dt_b_search_asin_title?ie=UTF8&amp;psc=1">power supply</a>. This, wired into my <a href="https://store.arduino.cc/usa/nano-33-iot">Arduino Nano 33 IoT</a>, a <a href="https://www.amazon.com/gp/product/B01M0E6SQM/ref=ppx_yo_dt_b_search_asin_title?ie=UTF8&amp;psc=1">relay</a>, and (via the relay) the fan, gave life to the essential components. I could now turn the fan on and off through the Arduino, but only at full speed.</p>

<figure>

    <a href="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/fan-relay.png">

<picture>
    
    <source data-srcset="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/fan-relay.webp" type="image/webp">
    
    <img data-src="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/fan-relay.png" alt="" data-srcset="    /assets/resized/fan-relay-480x240.png 480w,    /assets/resized/fan-relay-960x480.png 960w,    /assets/resized/fan-relay-1200x600.png 1200w,/assets/images/posts/3d-printer-filtration/fan-relay.png 2000w" src="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/fan-relay.png" srcset="    https://mikebuss.com/assets/resized/fan-relay-480x240.png 480w,    https://mikebuss.com/assets/resized/fan-relay-960x480.png 960w,    https://mikebuss.com/assets/resized/fan-relay-1200x600.png 1200w,https://mikebuss.com/assets/images/posts/3d-printer-filtration/fan-relay.png 2000w">
</picture>
</a>


<figcaption>Without the relay (bottom right), the fan could only be slowed down, not stopped completely.</figcaption>

</figure>

<p>To control the fan’s speed, I connected its PWM pin to a PWM pin on the Arduino. It took some math to change the Arduino’s built-in PWM frequency to 25 kHz, but the slower fan speed significantly reduced noise.</p>

<p>Now that the Arduino could control the fan, I wanted to have it start and stop automatically. To do this, I used the built-in WiFi module poll the <a href="https://support.ultimaker.com/hc/en-us/articles/360012087619-Using-the-Ultimaker-APIs">Ultimaker S3’s API</a> periodically.</p>

<figure>

    <a href="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/api2.jpeg">

<picture>
    
    <source data-srcset="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/api2.webp" type="image/webp">
    
    <img data-src="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/api2.jpeg" alt="" data-srcset="    /assets/resized/api2-480x360.jpeg 480w,    /assets/resized/api2-960x720.jpeg 960w,    /assets/resized/api2-1200x900.jpeg 1200w,/assets/images/posts/3d-printer-filtration/api2.jpeg 2000w" src="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/api2.jpeg" srcset="    https://mikebuss.com/assets/resized/api2-480x360.jpeg 480w,    https://mikebuss.com/assets/resized/api2-960x720.jpeg 960w,    https://mikebuss.com/assets/resized/api2-1200x900.jpeg 1200w,https://mikebuss.com/assets/images/posts/3d-printer-filtration/api2.jpeg 2000w">
</picture>
</a>


<figcaption>The Ultimaker S3 comes with an excellent API.</figcaption>

</figure>

<p>Then, because everyone loves data, I added some logging to my creation. I equipped the inside and outside of the chamber with sensors that measure temperature, humidity, and VOC levels. This data is sent over WiFi to a server running on my <a href="https://en.wikipedia.org/wiki/Network-attached_storage">NAS</a> (a <a href="https://www.amazon.com/Synology-bay-DiskStation-DS918-Diskless/dp/B075N1Z9LT">Synology DS918+</a>). Eventually, I’d like to use this data in real-time to control the fan speed, but for now, it’s just filed away along with information on what was printed and when.</p>

<figure>

    <a href="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/sensors1.jpg">

<picture>
    
    <source data-srcset="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/sensors1.webp" type="image/webp">
    
    <img data-src="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/sensors1.jpg" alt="" data-srcset="    /assets/resized/sensors1-480x360.jpg 480w,    /assets/resized/sensors1-960x720.jpg 960w,    /assets/resized/sensors1-1200x900.jpg 1200w,/assets/images/posts/3d-printer-filtration/sensors1.jpg 2000w" src="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/sensors1.jpg" srcset="    https://mikebuss.com/assets/resized/sensors1-480x360.jpg 480w,    https://mikebuss.com/assets/resized/sensors1-960x720.jpg 960w,    https://mikebuss.com/assets/resized/sensors1-1200x900.jpg 1200w,https://mikebuss.com/assets/images/posts/3d-printer-filtration/sensors1.jpg 2000w">
</picture>
</a>


<figcaption>The temperature and humidity (left) and air quality (right) sensors.</figcaption>

</figure>

<p>Adding two temperature sensors was a little tricky, considering they share the same hardcoded I2C address. Because of this, the Arduino can’t address them individually. My solution was to use an <a href="https://learn.adafruit.com/adafruit-tca9548a-1-to-8-i2c-multiplexer-breakout/overview">I2C multiplexer</a> to let me switch between sensors and query them individually.</p>

<p>While all of this is happening, the Arduino is also checking a flame sensor that hovers over the printer. If this sensor detects a fire, the power to the Ultimaker is immediately shut off, and a piezo alarm starts blaring. It’s not as cool as those <a href="https://shop3duniverse.com/products/3d-print-clean-automatic-fire-suppression-add-on">automatic fire suppression</a> kits you can buy, but the alarm can be heard throughout the house.</p>

<figure>

    <a href="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/breadboard.jpeg">

<picture>
    
    <source data-srcset="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/breadboard.webp" type="image/webp">
    
    <img data-src="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/breadboard.jpeg" alt="" data-srcset="    /assets/resized/breadboard-480x360.jpeg 480w,    /assets/resized/breadboard-960x720.jpeg 960w,    /assets/resized/breadboard-1200x900.jpeg 1200w,/assets/images/posts/3d-printer-filtration/breadboard.jpeg 2000w" src="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/breadboard.jpeg" srcset="    https://mikebuss.com/assets/resized/breadboard-480x360.jpeg 480w,    https://mikebuss.com/assets/resized/breadboard-960x720.jpeg 960w,    https://mikebuss.com/assets/resized/breadboard-1200x900.jpeg 1200w,https://mikebuss.com/assets/images/posts/3d-printer-filtration/breadboard.jpeg 2000w">
</picture>
</a>


<figcaption>The flame sensor (left) will report if it detects a fire in the print chamber. This photo was taken when I was still breadboarding the prototype.</figcaption>

</figure>

<hr>

<figure>

    <a href="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/enclosure2.jpg">

<picture>
    
    <source data-srcset="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/enclosure2.webp" type="image/webp">
    
    <img data-src="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/enclosure2.jpg" alt="" data-srcset="    /assets/resized/enclosure2-480x306.jpg 480w,    /assets/resized/enclosure2-960x612.jpg 960w,    /assets/resized/enclosure2-1200x765.jpg 1200w,/assets/images/posts/3d-printer-filtration/enclosure2.jpg 1976w" src="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/enclosure2.jpg" srcset="    https://mikebuss.com/assets/resized/enclosure2-480x306.jpg 480w,    https://mikebuss.com/assets/resized/enclosure2-960x612.jpg 960w,    https://mikebuss.com/assets/resized/enclosure2-1200x765.jpg 1200w,https://mikebuss.com/assets/images/posts/3d-printer-filtration/enclosure2.jpg 1976w">
</picture>
</a>


</figure>

<figure>

    <a href="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/dark.jpg">

<picture>
    
    <source data-srcset="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/dark.webp" type="image/webp">
    
    <img data-src="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/dark.jpg" alt="" data-srcset="    /assets/resized/dark-480x315.jpg 480w,    /assets/resized/dark-960x630.jpg 960w,    /assets/resized/dark-1200x788.jpg 1200w,/assets/images/posts/3d-printer-filtration/dark.jpg 1962w" src="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/dark.jpg" srcset="    https://mikebuss.com/assets/resized/dark-480x315.jpg 480w,    https://mikebuss.com/assets/resized/dark-960x630.jpg 960w,    https://mikebuss.com/assets/resized/dark-1200x788.jpg 1200w,https://mikebuss.com/assets/images/posts/3d-printer-filtration/dark.jpg 1962w">
</picture>
</a>


</figure>

<p>You can find the parts I used <a href="https://mikebuss.com/assets/downloads/Smart_Enclosure_Hardware_Components.pdf">here</a>.</p>

<p>All said and done, this project was fun to build and gives my wife and me some peace of mind. If you’ve created something similar, I would love to <a href="mailto:mike@mikebuss.com">hear about it</a>!</p>

<hr>

<p><small><a name="risks-footnote"></a>1. OK, OK, a 3D printer probably won’t kill you. But, research suggests there are health concerns with the particles emitted by the heating element.</small></p>


  <hr>

  <div>
    
      
      <p><a href="https://mikebuss.com/2020/10/08/welcome-theodore/">Welcoming Our First</a></p>
      <p>Today, my wife and I welcomed Theodore Frederick Buss into the world!</p>
    
    
    
      <p>No newer posts.</p>
    
  </div>

  <hr>

  <div>
    <div>
      
      <p><a href="https://mikebuss.com/about">Mike Buss</a> is a software engineer from Ohio who works primarily in the healthcare space. His <a href="https://mikebuss.com/work">work</a> has been <a href="https://mikebuss.com/2014/03/24/featured-apple/">featured</a> on Apple.com and helped hundreds of thousands of patients. In his spare time, he writes about software development and <a href="https://mikebuss.com/writing/">more</a>.</p>
      
      <p>Follow <a href="https://twitter.com/michaeltbuss">@michaeltbuss</a> on Twitter as he continues to document his software development journey.</p>
    </div>
  </div>

</div></div>]]>
            </description>
            <link>https://mikebuss.com/2021/01/06/3d-printer-filtration/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25680448</guid>
            <pubDate>Fri, 08 Jan 2021 01:55:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Over 100 Scientists and Doctors Call for Increased Vitamin D to Combat Covid-19]]>
            </title>
            <description>
<![CDATA[
Score 109 | Comments 82 (<a href="https://news.ycombinator.com/item?id=25680282">thread link</a>) | @kpfleger
<br/>
January 7, 2021 | https://vitamindforall.org/letter.html | <a href="https://web.archive.org/web/*/https://vitamindforall.org/letter.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><span>#VitaminDforAll </span><span>(for questions or fact checking assistance, contact press@vitaminDforAll.org)</span></p><p id="h.mjz6soj7f435"><span>Over 100 </span><span>Scientists, Doctors, &amp; Leading Authorities</span><span>&nbsp;Call For </span><span>Increased</span><span>&nbsp;Vitamin D Use To Combat COVID-19</span></p><p><span>[Residents of the USA: Text “VitaminDforAll” to 50409 to send this to your state’s governor.]</span></p><p><span>Research shows low vitamin D levels almost certainly promote COVID-19 infections, hospitalizations, and deaths. Given its safety, </span><span>w</span><span>e call for immediate widespread increased vitamin D intakes</span><span>.</span></p><p><span>Vitamin D modulates thousands of genes and many aspects of immune function, both innate and adaptive. The scientific evidence</span><span>1</span><span>&nbsp;shows that:</span></p><p><span>Vitamin D is well known to be essential, but most people do not get enough. Two common definitions of inadequacy are deficiency &lt; 20ng/ml (50nmol/L), the target of most governmental organizations, and insufficiency &lt; 30ng/ml (75nmol/L), the target of several medical societies &amp; experts.</span><span>2</span><span>&nbsp;Too many people have levels below these targets. </span><span>Rates of vitamin D deficiency &lt;20ng/ml exceed 33% of the population in most of the world, and most estimates of insufficiency &lt;30ng/ml are well over 50% (but much higher in many countries).</span><span>3</span><span>&nbsp;Rates are even higher in winter, and several groups have notably worse deficiency: the overweight, those with dark skin (especially far from the equator), and care home residents. These same groups face increased COVID-19 risk.</span></p><p><span>It has been shown that 3875 IU (97mcg) daily is required for 97.5% of people to reach 20ng/ml, and 6200 IU (155mcg) for 30ng/ml,</span><span>4</span><span>&nbsp;intakes far above all national guidelines. Unfortunately, the report that set the US RDA included an admitted statistical error in which required intake was calculated to be ~10x too low.</span><span>4</span><span>&nbsp;Numerous calls in the academic literature to raise official recommended intakes had not yet resulted in increases by the time SARS-CoV-2 arrived. Now, many papers indicate that vitamin D affects COVID-19 more strongly than most other health conditions, with increased risk at levels &lt; 30ng/ml (75nmol/L) and severely greater risk &lt; 20ng/ml (50nmol/L).</span><span>1</span></p><p><span>Evidence to date </span><span>suggests </span><span>the possibility that the COVID-19 pandemic sustains itself in large part &nbsp;through infection of those with low vitamin D, and that deaths are concentrated largely in those with deficiency. The mere possibility that this is so should compel urgent gathering of more vitamin D data. </span><span>Even without more data</span><span>, </span><span>the </span><span>preponderance </span><span>of evidence indicates that </span><span>increased vitamin D would help reduce infections, hospitalizations, ICU admissions, &amp; deaths</span><span>.</span></p><p><span>Decades of safety data show that vitamin D has very low risk: </span><span>Toxicity would be extremely rare with the recommendations here. The risk of insufficient levels far outweighs any risk from levels that seem to provide most of the protection against COVID-19, and this is notably different from drugs. Vitamin D is much safer than steroids, such as dexamethasone, the most widely accepted treatment to have also demonstrated a large COVID-19 benefit. Vitamin D’s safety is more like that of face masks. </span><span>There is no need to wait for further clinical trials to increase use of something so safe, </span><span>especially when remedying high rates of deficiency/insufficiency should already be a priority</span><span>.</span></p><p><span>Therefore, we call on all governments, doctors, and healthcare workers worldwide to immediately recommend and implement efforts appropriate to their adult populations to increase vitamin D, at least until the end of the pandemic. Specifically to:</span></p><p><span>Many factors are known to predispose individuals to higher risk from exposure to SARS-CoV-2, such as age, being male, comorbidities, etc., but </span><span>inadequate</span><span>&nbsp;v</span><span>itamin D is by far the most easily and quickly </span><span>modifiable</span><span>&nbsp;risk factor with abundant evidence to support a large effect</span><span>. Vitamin D is inexpensive and has negligible risk compared to the considerable risk of COVID-19.</span></p><p><span>5</span><span>&nbsp;The following include 4000 IU within their tolerable intakes in official guidelines: NAM (US, Canada), SACN (UK), EFSA (Europe), Endocrine Society (international), Nordic countries, The Netherlands, Australia &amp; New Zealand, UAE, and the American Geriatrics Soc. (USA, elderly). No major agency specifies a lower tolerable intake limit. The US NAM said 4000 IU “is likely to pose no risk of adverse health effects to almost all individuals.” See also [</span><span><a href="https://pubmed.ncbi.nlm.nih.gov/32180081/">Giustina et al ‘20</a></span><span>].</span></p><p><span>The signatories below endorse this letter. Affiliations do not imply endorsement of the letter by the institutions themselves.</span></p><p><span>This letter takes no position on other public health measures besides vitamin D. Personal views of individual signatories on any other matter do not represent the group as a whole.</span></p><p><span>All signatories declare no conflicts of interest except as noted.</span></p><p><span>To emphasize: </span><span>The organizing signatories have no conflicts of interest in this area (financial or otherwise)</span><span>, nor have they done research in this area prior to 2020.</span></p><div><tbody><tr><td colspan="1" rowspan="1"><p><span>Signatories (185)</span></p></td><td colspan="1" rowspan="1"><p><span>recom- mended intake</span></p></td><td colspan="1" rowspan="1"><p><span>personal daily intake</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Karl Pfleger</span><span>, PhD AI &amp; Computer Science, Stanford. Former Google Data Scientist. Biotechnology Investor, AgingBiotech.info, San Francisco, CA, USA. (organizing signatory)</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>7000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Gareth Davies</span><span>, PhD Medical Physics, Imperial College, London, UK. Codex World’s Top 50 Innovator 2019. Independent Researcher. Lead author of “</span><span><a href="https://www.medrxiv.org/content/10.1101/2020.05.01.20087965v3">Evidence Supports a Causal Role for Vitamin D Status in COVID-19 Outcomes</a></span><span>.” (organizing signatory)</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>10,000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Bruce W Hollis</span><span>, PhD. Professor of Pediatrics, Medical University of South Carolina, USA.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>6000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Barbara J Boucher</span><span>, MD, FRCP (London). </span><span>Honorary Professor (Medicine), Blizard Institute, Bart's &amp; The London School of Medicine and Dentistry, Queen Mary University of London, UK. </span><span>(significantly contributing signatory)</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>2000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Ashley Grossman</span><span>, MD FRCP FMedSci. Emeritus Professor of Endocrinology, University of Oxford, UK. Professor of Neuroendocrinology, Barts and the London School of Medicine. 2020 Endocrine Society Laureate Award.</span></p></td><td colspan="1" rowspan="1"><p><span>2000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>2200 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Gerry Schwalfenberg</span><span>, MD, CCFP, FCFP. Assistant Clinical Professor in Family Medicine, University of Alberta, Canada.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>5000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Giovanna Muscogiuri</span><span>, MD PhD. Associate Editor, European Journal of Clinical Nutrition. </span><span>Department of Clinical Medicine and Surgery, Section of Endocrinology, University "Federico II" of Naples, Naples, Italy.</span><span>.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>1000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Michael F. Holick</span><span>, PhD MD. Professor Medicine, Physiology and Biophysics and Molecular Medicine, Director Vitamin D, Skin and Bone Research Laboratory, Boston University Medical Center, USA. (6000 IU) </span><span>Disclosure: Consultant Biogena and speaker's Bureau Abbott Inc.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>6000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. John Umhau</span><span>, MD, MPH. CDR, USPHS (ret). </span><span>President, Academy of Medicine of Washington, DC, USA. Ex-NIH: c</span><span>o-author of the first peer-reviewed report linking vitamin D deficiency with acute respiratory infection.</span><span>&nbsp;</span><span>(significantly contributing signatory)</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>5000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. </span><span>Pawel</span><span>&nbsp;</span><span>Pludowski</span><span>, MD, dr hab. Associate Professor, Biochemistry, Radioimmunology and Experimental Medicine, Children’s Memorial Health Institute, Warsaw, Poland. Chair, European Vitamin D Association (EVIDAS) [non-profit].</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>2000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Cedric F. Garland</span><span>, DrPH. Professor Emeritus, Department of Family Medicine and Public Health, University of California, San Diego, USA.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>6000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Jose M. Benlloch</span><span>, Professor, Director of the Institute for Instrumentation on Molecular Imaging, CSIC-UPV, Valencia, Spain.</span></p></td><td colspan="1" rowspan="1"><p><span>2000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>3000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Samantha Kimball</span><span>, PhD, MLT. Professor, St. Mary's University, Calgary, Alberta, Canada. Research Director, GrassrootsHealth Nutrient Research Institute [non-profit].</span><span>&nbsp;</span><span>(significantly contributing signatory)</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>6000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. William B. Grant</span><span>, PhD Physics, U. of California, Berkeley. Director at Sunlight, Nutrition, and Health Research Center [non-profit], San Francisco, CA, USA. </span><span>Disclosure: Receives funding from Bio-Tech Pharmacal, Inc.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>5300 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Carol L. Wagner,</span><span>&nbsp;MD. Professor, Medical University of South Carolina, USA.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>5000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Paul Marik</span><span>, MD, FCCP, FCCM. </span><span>Chief of Pulmonary and Critical Care Medicine and Professor of Medicine</span><span>, Eastern Virginia Medical School, Norfolk, VA, USA.</span></p></td><td colspan="1" rowspan="1"><p><span>2000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>2000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Morry Silberstein</span><span>, MD. Associate Professor, Curtin University, Australia.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Vatsal Thakkar</span><span>, MD. Founder, Reimbursify, NY, USA. &nbsp;Former faculty, NYU and Vanderbilt. &nbsp;Op-Ed writer on Vitamin D and COVID-19.</span><span>&nbsp;</span><span>(significantly contributing signatory)</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>10,000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Peter H Cobbold</span><span>, PhD. Emeritus Professor, Cell Biology, University of Liverpool, UK.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Afrozul Haq</span><span>, PhD. Professor Dept of Food Technology, Jamia Hamdard University, New Delhi, India.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>2000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Barry H. Thompson</span><span>, MD, FAAP, FACMG. Clinical Associate Professor (Pediatrics), Uniformed Services University of the Health Sciences, Bethesda, MD, USA.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>5000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Reinhold Vieth</span><span>, PhD, FCACB. Professor, Departments of Nutritional Sciences and Laboratory Medicine &amp; Pathobiology, University of Toronto, Canada. Director (retired), Bone and Mineral Group Laboratory, Mt Sinai Hospital. </span><span>Disclosure: </span><span>Receives patent royalties from Ddrops (an infant vitamin D supplement).</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Linda Benskin</span><span>, PhD, RN, SRN(Ghana), CWCN, CWS, DAPWCA. Independent Researcher for Tropical Developing Countries and Ferris Mfg. Corp, Texas, USA. </span><span>(significantly contributing signatory)</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Jim O’Neill</span><span>, CEO, SENS Research Foundation. Former principal associate deputy secretary of Health and Human Services, USA.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>6000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Eric Feigl-Ding</span><span>, PhD. Epidemiologist &amp; Health Economist. Senior Fellow, Federation of American Scientists. USA.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>5000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Rt Hon David Davis MP</span><span>, Member of Parliament (Conservative Party). BSc, Joint Hons Molecular Science / Computer Science, Warwick University, UK.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>6000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Rupa Huq MP,</span><span>&nbsp;Member of Parliament (Labour Party). PhD, Cultural Studies, University of East London, UK.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Susan J Whiting</span><span>, PhD. Professor Emerita, University of Saskatchewan, Canada.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Richard Mazess</span><span>. PhD. Emeritus Professor, University of Wisconsin, Madison, USA.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>5000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Helga Rhein</span><span>, MD (retired). </span><span>Sighthill…</span></p></td></tr></tbody></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vitamindforall.org/letter.html">https://vitamindforall.org/letter.html</a></em></p>]]>
            </description>
            <link>https://vitamindforall.org/letter.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25680282</guid>
            <pubDate>Fri, 08 Jan 2021 01:34:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Avoiding instruction cache misses (2019)]]>
            </title>
            <description>
<![CDATA[
Score 49 | Comments 8 (<a href="https://news.ycombinator.com/item?id=25680125">thread link</a>) | @nkurz
<br/>
January 7, 2021 | https://paweldziepak.dev/2019/06/21/avoiding-icache-misses/ | <a href="https://web.archive.org/web/*/https://paweldziepak.dev/2019/06/21/avoiding-icache-misses/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div role="main"><div><article><p>Modern processors are quite complex, with many parts having the potential to become a bottleneck. It is relatively easy to reason about the performance of short pieces of code, especially if memory effects are kept to a minimum. Both static analysis tools like LLVM MCA and microbenchmarks can provide a lot of information in such cases. However, the behaviour of the whole program is not just the sum of those small parts. As the code becomes larger and more complex other effects start appearing. One of such potential problems are excessive instruction cache misses.</p><p>Every program has different properties, and those large-scale effects will affect it differently. However, if its job is to execute complex logic on a small amount of data, the instruction cache is likely to become a problem at some point. The actual impact may vary significantly from codebase to codebase, which is why I won’t show any numbers in this article. Let’s consider this just a collection of ideas, but it is not easy to tell how much any of them will help for a given application.</p><p>First, let’s have a quick look at the processor front end. Below is a simplified diagram of how it is arranged in Skylake, the numbers between units are the maxima per cycle.</p><p><img loading="lazy" width="630" height="860" src="https://paweldziepak.dev/static/icache-front-end.min.2e73578fff.svg" alt="CPU front end"></p><p>Each cycle the processor fetches up to 16 bytes from the instruction cache using information from the Branch Prediction Unit to predict the control flow. The pre-decode unit determines instruction lengths and puts up to five of them in the Instruction Queue. From the Instruction Queue, up to 5 instructions (with macro-fusion) are brought each cycle to the decoders. There is one complex decoder that can handle instructions that translate to up to 4 µops and 3 simple decoders that can handle only single-µop instructions. In total, all decoders are limited to producing no more than 5 µops each cycle. Instructions that require more than 4 µops go through Microcode Sequence ROM, which emits 4 µops per cycle, and while it is active, the decoders are disabled. There is also Decoded ICache (<abbr title="Decoded Stream Buffer">DSB</abbr>) which caches decoded µops. It can emit up to 6 µops each cycle. All µops, regardless of their source, end up in the Instruction Decode Queue (IDQ). The Loop Stream Detector (LSD) detects small loops and keeps them in the queue, so that no fetched, decodes or reads from the DSB are needed during the duration of the loop. IDQ is the last part of the front end, and the queued µops continue to the back end.</p><p>From the instruction cache point of view, the front end has two weaknesses. Firstly, instructions are processed in-order which can severely limit the processor ability to hide latencies of cache misses. HyperThreading can make sure that this part of the processor still does some useful work, but it is also the source of the second problem – all resources, including the L1 instruction cache and µop cache are shared between the hardware threads.</p><p>Modern processors provide various metrics that help monitor their behaviour. However, the task of extracting the relevant data requires a proper approach if it is to be done efficiently. Top-down analysis is invaluable with helping to understand microarchitectural phenomena in large codebases. The idea is to monitor program behaviour with the <abbr title="Performance Monitoring Unit">PMU</abbr> counters and identify the bottleneck starting with the major functional parts of the CPU and then digging deeper narrowing down on the exact source of the problem. It can be done in an automated way by tools like VTune or toplev.</p><pre><code>FE    Frontend_Bound:                                      39.48 +-  0.00 % Slots
BE    Backend_Bound:                                       16.19 +-  0.00 % Slots
    This category represents fraction of slots where no uops are
    being delivered due to a lack of required resources for
    accepting new uops in the Backend...
FE    Frontend_Bound.Frontend_Latency:                     24.92 +-  0.00 % Slots
FE    Frontend_Bound.Frontend_Bandwidth:                   13.45 +-  0.00 % Slots
FE    Frontend_Bound.Frontend_Latency.ICache_Misses:       14.45 +-  0.00 % Clocks &lt;==
    This metric represents fraction of cycles the CPU was
    stalled due to instruction cache misses...
    Sampling events:  frontend_retired.l2_miss:pp frontend_retired.l1i_miss:pp
FE    Frontend_Bound.Frontend_Latency.ITLB_Misses:          8.71 +-  0.00 % Clocks
    This metric represents fraction of cycles the CPU was
    stalled due to instruction TLB misses...
    Sampling events:  frontend_retired.stlb_miss:pp frontend_retired.itlb_miss:pp
FE    Frontend_Bound.Frontend_Latency.Branch_Resteers:      8.42 +-  0.00 % Clocks_Est
    This metric represents fraction of cycles the CPU was
    stalled due to Branch Resteers...
    Sampling events:  br_misp_retired.all_branches:u
FE    Frontend_Bound.Frontend_Bandwidth.MITE:              31.93 +-  0.00 % CoreClocks
    This metric represents Core fraction of cycles in which CPU
	was likely limited due to the MITE pipeline (Legacy Decode
    Pipeline)...
</code></pre><p>Above is an example of a toplev result. We can see that the instruction cache misses were the dominating bottleneck. Unsurprisingly instruction TLB misses also show up. On the front end bandwidth side of things, toplev points to the legacy decode pipeline. That makes perfect sense if the instructions are supplied from DSB or LSD, then there are no instruction fetches, and no cache misses.</p><p>Sometimes, the final summary may not provide sufficient information if there are changes in the code behaviour during the test. When that’s the case, a graph is likely to be a much more helpful way of presenting the results.</p><p><img loading="lazy" width="950" height="950" src="https://paweldziepak.dev/static/icache-toplev.min.2b465fdb6f.svg" alt="toplev"></p><p>Tools like toplev are great for initial identification of the problem, but once that’s done what we need is a right way for comparing different solutions. Ultimately, the most important metric is the actual performance of the program in a real-life workload. toplev still can be helpful as it shows the balance between different performance-limiting factors. What also can be useful is <code>perf stat</code> which can show the performance counter statistics. The event most relevant for us is <code>L1-icache-load-misses</code>, though there are more model-specific registers that may be of interest.</p><p>Now, that we know how to diagnose excessive instruction cache misses, let’s see what can be done to deal with this problem.</p><h2 id="avoiding-work">Avoiding work</h2><p>If the number of executed instructions is the problem, the most obvious solution is to try to reduce that number. Obviously, that’s much easier said than done, but there are some common patterns for dealing with this issue. One example would be prepared statements in databases. The general idea is that if a client knows it will send requests that have some commonality, it can tell the database engine early that the requests are going to match specific templates. This information allows the server to do as much work as possible during the preparation stage, thus reducing the amount of logic that needs to be executed for each individual request.</p><p>Extracting common patterns doesn’t have to be explicit. A server or any other kind of an application which actions depend on the user input could attempt to look for repeating patterns and cache some common parts. This is a very vague idea and most likely won’t be easily implementable in a lot of applications, but in some cases may be quite a natural solution. It also shows the main problem with the “just do less” approach – it is very application specific. On the plus, side, if this can be done, it is likely to help with the overall performance, not just the instruction cache misses.</p><p>Another potential problem is making sure that the preparation phase can really do something to help during the execution phase. If that means pre-computing some values, then it’s simple. However, if the only thing that preparation gives us is the knowledge which code paths are going to be exercised and which branches taken during the execution, it is going to be harder to take benefit from it. One option is to have some specialised code for the most common paths, C++ templates may come in handy here. If it is not easy to determine what may be the most common paths, then a just-in-time compiler may be used to generate code in the preparation stage.<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p><h2 id="batching-work">Batching work</h2><p>So far, we have been trying to reduce the number of executed instructions, by taking advantage of some earlier knowledge to avoiding repeating the same work. In other words, we have introduced two stages:</p><ul><li>preparation, which is performed rarely and, consequently, less performance critical</li><li>execution, which is done many times and is expected to dominate overall performance</li></ul><p>The way this can help with the instruction cache misses is that the execution stage, being smaller, is more likely to fit in the instruction cache. Whether this brings any measurable benefits depends highly on the type of the application and how much logic can be moved from execution to preparation stages.</p><p>We have already split our processing pipeline into preparation and execution stage. If the execution stage can fit in the instruction cache, we are done. However, often, that’s not the case. What we can do to improve the situation more is to split the execution into more stages. This time the goal is not to reuse work as it was with the preparation, but to group entities that need to have the same code executed for them. In other words, if the processing pipeline consists of steps A, B and C the idea is to separate them, add a queue in front of each of those stages, and then cycle through those stages each time handling multiple elements from the queue. Connections between the stages don’t have to be one-to-one, any directed graph is fine.</p><p><img loading="lazy" width="756" height="331" src="https://paweldziepak.dev/static/icache-seda.min.7259b25adc.svg" alt="SEDA diagram"></p><p>In the diagram above, there is one stage that feeds tasks to one of two stages. This could be, for example, a front-end of a database server. The first stage does some initial request processing and then, depending on whether it is a read or write, puts it in the appropriate queue. Each stage processes requests in batches, the first one warms up the instruction …</p></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://paweldziepak.dev/2019/06/21/avoiding-icache-misses/">https://paweldziepak.dev/2019/06/21/avoiding-icache-misses/</a></em></p>]]>
            </description>
            <link>https://paweldziepak.dev/2019/06/21/avoiding-icache-misses/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25680125</guid>
            <pubDate>Fri, 08 Jan 2021 01:15:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CO2 already emitted will warm Earth beyond climate targets, study finds]]>
            </title>
            <description>
<![CDATA[
Score 304 | Comments 187 (<a href="https://news.ycombinator.com/item?id=25679618">thread link</a>) | @colinprince
<br/>
January 7, 2021 | https://www.cbc.ca/news/technology/climate-targets-1.5861537 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/technology/climate-targets-1.5861537">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>The amount of baked-in global warming, from carbon pollution already in the air, is enough to blow past international agreed upon goals to limit climate change, a new study finds. But it can be delayed for centuries if governments takes action.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.4922800.1543350548!/cpImage/httpImage/image.jpg_gen/derivatives/16x9_780/us-coal-s-decline.jpg"></p></div><figcaption>Smoke and steam rise from the smokestack of a coal-fired power plant near Ordos in northern China's Inner Mongolia Autonomous Region in 2015.  A new study estimates that 2.3 C of warming is inevitable, but can be delayed for centuries if the world quickly stops emitting extra greenhouse gases from the burning of coal, oil and natural gas, the study's authors say.<!-- --> <!-- -->(Mark Schiefelbein/Associated Press)</figcaption></figure><p><span><p>The amount of baked-in global warming, from carbon pollution already in the air, is enough to blow past international agreed upon goals to limit climate change, a new study finds.</p>  <p>But it's not game over because, while that amount of warming may be inevitable, it can be delayed for centuries if the world quickly stops emitting extra greenhouse gases from the burning of coal, oil and natural gas, the study's authors say.</p>  <p>For decades, scientists have talked about so-called "committed warming" or the increase in future temperature based on past carbon dioxide emissions that stay in the atmosphere for well over a century. It's like the distance a speeding car travels after the brakes are applied.</p>  <p>But Monday's <a href="https://www.nature.com/articles/s41558-020-00955-x">study in the journal Nature Climate Change</a> calculates that a bit differently and now figures the carbon pollution already put in the air will push global temperatures to about 2.3 degrees Celsius (4.1 degrees Fahrenheit) of warming since pre-industrial times.</p>  <p>Previous estimates, including those accepted by international science panels, were about a degree Celsius (1.8 degrees Fahrenheit) less than that amount of committed warming.</p>  <p>International climate agreements set goals of limiting warming to 2 C&nbsp;(3.6 F) since pre-industrial times, with the more ambitious goal of limiting it to 1.5 C&nbsp;(2.7 F) added in Paris in 2015. The world has already warmed about 1.1 C&nbsp;(2 F).</p>  <p>"You've got some ... global warming inertia that's going to cause the climate system to keep warming, and that's essentially what we're calculating," said study co-author Andrew Dessler, a climate scientist at Texas A&amp;M University. "Think about the climate system like the Titanic. It's hard to turn the ship when you see the icebergs."</p>  <p>Dessler and colleagues at the Lawrence Livermore National Lab and Nanjing University in China calculated committed warming to take into account that the world has warmed at different rates in different places and that places that haven't warmed as fast are destined to catch up.</p>    <p>Places such as the Southern Ocean, surrounding Antarctica are a bit cooler, and that difference creates low-lying clouds that reflect more sun away from earth, keeping these places cooler. But this situation can't keep going indefinitely because physics dictates that cooler locations will warm up more and when they do, the clouds will dwindle and more heating will occur, Dessler said.</p>  <p>Previous studies were based on the cooler spots staying that way, but Dessler and colleagues say that's not likely.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5693652.1597940952!/cpImage/httpImage/image.jpg_gen/derivatives/original_300/greenland-record-melt.jpg 300w,https://i.cbc.ca/1.5693652.1597940952!/cpImage/httpImage/image.jpg_gen/derivatives/original_460/greenland-record-melt.jpg 460w,https://i.cbc.ca/1.5693652.1597940952!/cpImage/httpImage/image.jpg_gen/derivatives/original_620/greenland-record-melt.jpg 620w,https://i.cbc.ca/1.5693652.1597940952!/cpImage/httpImage/image.jpg_gen/derivatives/original_780/greenland-record-melt.jpg 780w,https://i.cbc.ca/1.5693652.1597940952!/cpImage/httpImage/image.jpg_gen/derivatives/original_1180/greenland-record-melt.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5693652.1597940952!/cpImage/httpImage/image.jpg_gen/derivatives/original_780/greenland-record-melt.jpg"></p></div><figcaption>In this Aug. 16, 2019 file photo, icebergs float away as the sun rises near Kulusuk, Greenland. Greenland lost a record amount of ice that year. The world has already warmed 1.1 C since pre-industrial times.<!-- --> <!-- -->(Felipe Dana/The Associated Press)</figcaption></figure></span></p>  <h2>More research needed, outside experts say</h2>  <p>Outside experts said the work is based on compelling reasoning, but want more research to show that it's true. Breakthrough Institute climate scientist Zeke Hausfather said the new work fits better with climate models than observational data.</p>  <p>Just because the world is bound to get more warming than international goals, that doesn't mean all is lost in the fight against global warming, said Dessler, who cautioned against what he called "climate doomers."</p>  <p>If the world gets to net zero carbon emissions soon, 2 degrees of global warming could be delayed enough so that it won't happen for centuries, giving society time to adapt or even come up with technological fixes, he said.</p>  <p>"If we don't, we're going to blow through (climate goals) in a few decades," Dessler said. "It's really the rate of warming that makes climate change so terrible. If we got a few degrees over 100,000 years, that would not be that big a deal. We can deal with that. But a few degrees over 100 years is really bad."</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/technology/climate-targets-1.5861537</link>
            <guid isPermaLink="false">hacker-news-small-sites-25679618</guid>
            <pubDate>Fri, 08 Jan 2021 00:23:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Go Forth and Azlo]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25679475">thread link</a>) | @Seich
<br/>
January 7, 2021 | https://www.azlo.com/blog/go-forth-and-azlo | <a href="https://web.archive.org/web/*/https://www.azlo.com/blog/go-forth-and-azlo">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <div>
    <div>
      <div>
        
      
        <div>
          
          <p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p><img src="https://www.azlo.com/hs-fs/hubfs/blog-Azlo%20farewell-lg.jpg?width=876&amp;name=blog-Azlo%20farewell-lg.jpg" alt="blog-Azlo farewell-lg" width="876" srcset="https://www.azlo.com/hs-fs/hubfs/blog-Azlo%20farewell-lg.jpg?width=438&amp;name=blog-Azlo%20farewell-lg.jpg 438w, https://www.azlo.com/hs-fs/hubfs/blog-Azlo%20farewell-lg.jpg?width=876&amp;name=blog-Azlo%20farewell-lg.jpg 876w, https://www.azlo.com/hs-fs/hubfs/blog-Azlo%20farewell-lg.jpg?width=1314&amp;name=blog-Azlo%20farewell-lg.jpg 1314w, https://www.azlo.com/hs-fs/hubfs/blog-Azlo%20farewell-lg.jpg?width=1752&amp;name=blog-Azlo%20farewell-lg.jpg 1752w, https://www.azlo.com/hs-fs/hubfs/blog-Azlo%20farewell-lg.jpg?width=2190&amp;name=blog-Azlo%20farewell-lg.jpg 2190w, https://www.azlo.com/hs-fs/hubfs/blog-Azlo%20farewell-lg.jpg?width=2628&amp;name=blog-Azlo%20farewell-lg.jpg 2628w" sizes="(max-width: 876px) 100vw, 876px"></p>
<p><strong>By Cameron Peake</strong></p>
<!--more-->
<div><p>You may have heard by now that BBVA US, Azlo’s parent bank, has made the strategic decision to <a href="https://www.azlo.com/blog/azlo-status-update"><span>close Azlo’s business</span></a>. After more than four years dedicated to building unparalleled digital banking services for founders, freelancers, and small business owners, we still firmly believe in our vision: giving every small business owner the opportunity to survive and thrive.</p><p>As founders and entrepreneurs ourselves, we know that there can always be unexpected bumps on the entrepreneurial journey, and we’re sorry that we won’t be alongside our inspiring community of entrepreneurs as they grow and flourish.&nbsp;</p><p>In creating Azlo, we worked hard every day to give entrepreneurs and small business owners a helping hand whenever they needed it — whether that was through offering a free online bank account, bringing innovative features like digital Envelopes to life, or hosting informative webinars featuring industry-leading experts. Wherever we could, we wanted to level the playing field and help founders from all walks of life have their best chance at success.</p><p>I’ve been encouraged at the progress that has been made recently, even in the face of a pandemic and a mounting sense of economic uncertainty. The Black Lives Matter movement gave long-deserved and widespread recognition to Black entrepreneurs and encouraged many consumers to seek out and support their businesses. We have been proud to showcase our customers’ businesses — as we did with our <a href="https://www.azlo.com/customers-catalog/"><span>Customer Shopping Catalog</span></a> — and help entrepreneurs learn from each other through the <a href="https://www.azlo.com/blog/category/entrepreneurs/"><span>stories</span></a> you told us.</p><p>This has been a journey we’ve been privileged to be on with all of you. Thank you for being part of our community, to propel us forward, and make us a better business. To our founders, our innovators, and our supporters — you are what makes this world great.&nbsp;</p><p>On a closing note, many ask what “Azlo” means. It’s a play on “<em>Hazlo,</em>” which means “get it done” in Spanish. This phrase to us is the essence of entrepreneurship <span>—</span> you push through the blood, sweat, and tears to reach your goal in whatever way possible. So, to our community:<span>&nbsp;</span><em>Hazlo</em> <span>— </span>we can’t wait to see what you’ll achieve.</p></div></span>
        </p></div>
        
        
        
        <hr>
        
        
        
        
        
        
        <hr>
        <p><a href="https://www.azlo.com/blog"><img src="https://www.azlo.com/hubfs/raw_assets/public/Azlo_July2020_v2/images/icon-arrow-left.svg" alt="Icon arrow left">Back to Blog</a>
      </p></div>  
    </div>
  </div>
  
  
  
</div></div>]]>
            </description>
            <link>https://www.azlo.com/blog/go-forth-and-azlo</link>
            <guid isPermaLink="false">hacker-news-small-sites-25679475</guid>
            <pubDate>Fri, 08 Jan 2021 00:03:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building Arm 64-bit XNU (Darwin 20) – random blog]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25679406">thread link</a>) | @tambourine_man
<br/>
January 7, 2021 | https://threedots.ovh/blog/2021/01/building-arm-64-bit-xnu-darwin-20/ | <a href="https://web.archive.org/web/*/https://threedots.ovh/blog/2021/01/building-arm-64-bit-xnu-darwin-20/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-114">

	

	<div>
		
<p>Assuming that instructions from <a href="https://kernelshaman.blogspot.com/2021/01/building-xnu-for-macos-big-sur-1101.html">https://kernelshaman.blogspot.com/2021/01/building-xnu-for-macos-big-sur-1101.html</a> were already followed including for the iPhoneOS target…</p>



<p>The patch:</p>



<pre><code>diff --git a/config/Private.exports b/config/Private.exports
index 28b023dd..ebaba915 100644
--- a/config/Private.exports
+++ b/config/Private.exports
@@ -589,15 +589,6 @@ _current_persona_get
 _persona_put
 _pffinddomain:_pffinddomain_old
 _pffindproto:_pffindproto_old
-_pmap_claim_reserved_ppl_page
-_pmap_free_reserved_ppl_page
-_pmap_in_ppl
-_pmap_is_trust_cache_loaded
-_pmap_load_legacy_trust_cache
-_pmap_load_image4_trust_cache
-_pmap_lockdown_image4_slab
-_pmap_lookup_in_static_trust_cache
-_pmap_lookup_in_loaded_trust_caches
 _port_name_to_task
 _port_name_to_thread
 _post_sys_powersource
diff --git a/makedefs/MakeInc.def b/makedefs/MakeInc.def
index d53f3e1a..6e646215 100644
--- a/makedefs/MakeInc.def
+++ b/makedefs/MakeInc.def
@@ -65,8 +65,8 @@ MACHINE_FLAGS_ARM64_S8000 = -DARM64_BOARD_CONFIG_S8000
 MACHINE_FLAGS_ARM64_S8001 = -DARM64_BOARD_CONFIG_S8001
 MACHINE_FLAGS_ARM_T8002 = -DARM_BOARD_CONFIG_T8002
 MACHINE_FLAGS_ARM_T8004 = -DARM_BOARD_CONFIG_T8004
-MACHINE_FLAGS_ARM64_T8010 = -DARM64_BOARD_CONFIG_T8010 -mcpu=hurricane
-MACHINE_FLAGS_ARM64_T8011 = -DARM64_BOARD_CONFIG_T8011 -mcpu=hurricane
+MACHINE_FLAGS_ARM64_T8010 = -DARM64_BOARD_CONFIG_T8010 -mcpu=apple-a10
+MACHINE_FLAGS_ARM64_T8011 = -DARM64_BOARD_CONFIG_T8011 -mcpu=apple-a10
 MACHINE_FLAGS_ARM64_BCM2837 = -DARM64_BOARD_CONFIG_BCM2837
 
 
diff --git a/osfmk/arm64/amcc_rorgn.c b/osfmk/arm64/amcc_rorgn.c
index 35128d53..fe0c6f80 100644
--- a/osfmk/arm64/amcc_rorgn.c
+++ b/osfmk/arm64/amcc_rorgn.c
@@ -42,7 +42,6 @@
 #include &lt;arm/pmap.h&gt;
 #include &lt;arm64/tlb.h&gt;
 #include &lt;arm64/amcc_rorgn.h&gt;
-#include &lt;memmap_types.h&gt;
 
 #if HIBERNATION
 #include &lt;arm64/pal_hibernate.h&gt;
diff --git a/osfmk/arm64/locore.s b/osfmk/arm64/locore.s
index b18a335e..1996e094 100644
--- a/osfmk/arm64/locore.s
+++ b/osfmk/arm64/locore.s
@@ -27,7 +27,6 @@
  */
 
 #include &lt;machine/asm.h&gt;
-#include &lt;arm64/hv/hv_regs.h&gt;
 #include &lt;arm64/machine_routines_asm.h&gt;
 #include &lt;arm64/proc_reg.h&gt;
 #include &lt;pexpert/arm64/board_config.h&gt;
diff --git a/pexpert/pexpert/arm64/board_config.h b/pexpert/pexpert/arm64/board_config.h
index 01265fdf..7adb0f23 100644
--- a/pexpert/pexpert/arm64/board_config.h
+++ b/pexpert/pexpert/arm64/board_config.h
@@ -81,7 +81,7 @@
 #define MAX_L2_CLINE                   7
 
 #if DEVELOPMENT || DEBUG
-#define PMAP_CS                        1
+//#define PMAP_CS                        1
 #define PMAP_CS_ENABLE                 0
 #endif
 #endif  /* ARM64_BOARD_CONFIG_T8010 */
@@ -94,7 +94,7 @@
 #define MAX_CPU_CLUSTERS               1
 
 #if DEVELOPMENT || DEBUG
-#define PMAP_CS                        1
+//#define PMAP_CS                        1
 #define PMAP_CS_ENABLE                 0
 #endif
 #endif  /* ARM64_BOARD_CONFIG_T8011 */
@@ -109,7 +109,7 @@
 #define BROKEN_FRIGGING_SLEEP          1 /* Spurious wake: See rdar://problem/29762505 */
 
 #if DEVELOPMENT || DEBUG
-#define PMAP_CS                        1
+//#define PMAP_CS                        1
 #define PMAP_CS_ENABLE                 0
 #endif
 #endif  /* ARM64_BOARD_CONFIG_T8015 */
@@ -126,8 +126,8 @@
 #define T8020_DART_ALLOW_BYPASS        (1 &lt;&lt; 1) /* DART allows translation bypass in certain cases */
 #define XNU_MONITOR_NVME_PPL           1 /* NVMe PPL plugin for secure pmap runtime */
 #define XNU_MONITOR_ANS2_SART          1 /* ANS2 SART plugin for secure pmap runtime */
-#define PMAP_CS                        1
-#define PMAP_CS_ENABLE                 1
+//#define PMAP_CS                        1
+//#define PMAP_CS_ENABLE                 1
 #endif  /* ARM64_BOARD_CONFIG_T8020 */
 
 #ifdef ARM64_BOARD_CONFIG_T8006
@@ -151,8 +151,8 @@
 #define T8020_DART_ALLOW_BYPASS        (1 &lt;&lt; 1) /* DART allows translation bypass in certain cases */
 #define XNU_MONITOR_NVME_PPL           1 /* NVMe PPL plugin for secure pmap runtime */
 #define XNU_MONITOR_ANS2_SART          1 /* ANS2 SART plugin for secure pmap runtime */
-#define PMAP_CS                        1
-#define PMAP_CS_ENABLE                 1
+//#define PMAP_CS                        1
+//#define PMAP_CS_ENABLE                 1
 #define PREFER_ARM64_32_BINARIES
 #define PEXPERT_NO_3X_IMAGES           1
 #endif /* ARM64_BOARD_CONFIG_T8006 */
@@ -169,8 +169,8 @@
 #define T8020_DART_ALLOW_BYPASS        (1 &lt;&lt; 1) /* DART allows translation bypass in certain cases */
 #define XNU_MONITOR_NVME_PPL           1 /* NVMe PPL plugin for secure pmap runtime */
 #define XNU_MONITOR_ANS2_SART          1 /* ANS2 SART plugin for secure pmap runtime */
-#define PMAP_CS                        1
-#define PMAP_CS_ENABLE                 1
+//#define PMAP_CS                        1
+//#define PMAP_CS_ENABLE                 1
 #endif  /* ARM64_BOARD_CONFIG_T8027 */
 
 #ifdef ARM64_BOARD_CONFIG_T8028
@@ -185,8 +185,8 @@
 #define T8020_DART_ALLOW_BYPASS        (1 &lt;&lt; 1) /* DART allows translation bypass in certain cases */
 #define XNU_MONITOR_NVME_PPL           1 /* NVMe PPL plugin for secure pmap runtime */
 #define XNU_MONITOR_ANS2_SART          1 /* ANS2 SART plugin for secure pmap runtime */
-#define PMAP_CS                        1
-#define PMAP_CS_ENABLE                 1
+//#define PMAP_CS                        1
+//#define PMAP_CS_ENABLE                 1
 #endif  /* ARM64_BOARD_CONFIG_T8028 */
 
 #ifdef ARM64_BOARD_CONFIG_T8030
@@ -202,8 +202,8 @@
 #define XNU_MONITOR_NVME_PPL           1 /* NVMe PPL plugin for secure pmap runtime */
 #define XNU_MONITOR_ANS2_SART          1 /* ANS2 SART plugin for secure pmap runtime */
 #define XNU_MONITOR_UAT_PPL            1 /* UAT PPL plugin for secure pmap runtime */
-#define PMAP_CS                        1
-#define PMAP_CS_ENABLE                 1
+//#define PMAP_CS                        1
+//#define PMAP_CS_ENABLE                 1
 #endif  /* ARM64_BOARD_CONFIG_T8030 */
</code></pre>



<p>The build command line:</p>



<pre><code>make SDKROOT=iphoneos  ARCH_CONFIGS=ARM64 KERNEL_CONFIGS=DEBUG MACHINE_CONFIGS=T8010 ARCH_STRING_FOR_CURRENT_MACHINE_CONFIG=arm64 USE_WERROR=0</code></pre>



<p>Of course, without kexts that’s not very useful for now… and most macOS arm64 stuff isn’t included yet.</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article></div>]]>
            </description>
            <link>https://threedots.ovh/blog/2021/01/building-arm-64-bit-xnu-darwin-20/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25679406</guid>
            <pubDate>Thu, 07 Jan 2021 23:55:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Steam's login method is kinda interesting]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25679209">thread link</a>) | @todsacerdoti
<br/>
January 7, 2021 | https://owlspace.xyz/cybersec/steam-login/ | <a href="https://web.archive.org/web/*/https://owlspace.xyz/cybersec/steam-login/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><article><header></header><p>How do you send a password over the internet? You acquire a SSL certificate and let TLS do the job of securely transporting the password from client to server. Of course it’s not as cut-and-dry as I’m making it out to be, but the gist of it holds true and stood the test of time. This hasn’t always been this way though, and one incredibly popular storefront on the world wide web prefers to add a little extra to this day. I’ll be discussing Steam’s unique method of logging in their users, and go down a deep rabbit hole of fascinating implementation details.</p><h3 id="pointing-out-the-obvious">Pointing out the obvious</h3><p>I found a StackOverflow question from 2013 <a href="https://stackoverflow.com/questions/1582894/how-to-send-password-securely-over-http">asking how to securely send a password over HTTP</a>. The answers are pretty unanimous: get a SSL certificate. Here’s an experiment: set up your favorite traffic-capturing proxy, browse to a service you frequently use, log in with your account (or preferably a throwaway), and inspect the requests. You will most certainly find that your username and password are sent as-is in a HTTP request body. The only reason this works is because your connection to the server is encrypted using TLS.</p><figure><img src="https://owlspace.xyz/images/steam-rsa/so-real-host.png" alt="StackOverflow user asking what to do if a webhost doesn't support SSL certificates, told to move to a real webhost"><figcaption><p>Weird to think that this used to be an issue</p></figcaption></figure><p>The internet was a different place though in the early 2010s, let alone the many years prior. We now have services like <a href="https://letsencrypt.org/">Let’s Encrypt</a> which issue SSL certificates free of charge for a period of three months, with automatic renewals if desired. There really wasn’t much of a way around acquiring a SSL certificate for money, but usually with extended validity and support. You could certainly argue that there is a price to be paid for the security and privacy of your users, but that didn’t stop questions like the one I linked from appearing.</p><p>Now that we all agree that TLS is important, let’s switch it up. Let’s pretend we cannot send a password over HTTPS and have to somehow make it work with plain HTTP, while also providing users with some level of security. There’s the <code>Authorization</code> header which is standardized and widely accepted. However, in conjunction with the “Basic” HTTP Authentication scheme, it provides no security if used in plain HTTP.</p><p>There are tried and tested challenge-response algorithms, most notably <a href="https://en.wikipedia.org/wiki/Secure_Remote_Password_protocol">SRP</a> which is designed to do password-based authentication without ever actually sending the password, but you probably have to implement them yourself and a slight oversight could cause serious harm. You could also defer authentication to an external service. “Sign in with service XYZ” is commonly used, but comes with its own ramifications. All things considered, it’s not trivial to send secrets over an inheretly insecure connection.</p><p>So when me and a friend took Steam apart in search for traces of personally identifiable information, I was surprised to see that Steam’s login page doesn’t only rely on TLS to ensure that your password stays protected.</p><h3 id="crypto-cherry-on-top">Crypto cherry on top</h3><p>Again, grab your favorite traffic-capturing proxy and navigate to <a href="https://store.steampowered.com/login">Steam’s login page</a>. Enter your username and password and you will (hopefully) be asked to enter a one-time token generated by your preferred two-factor authentication method. You can stop right there, because the magic I want to point out has already happened. You’ll find that pressing the login button launches a request against an odd endpoint: <code>/login/getrsakey</code>, followed by <code>/login/dologin</code>.</p><figure><img src="https://owlspace.xyz/images/steam-rsa/getrsa-call.png" alt="Requests to fetch script assets, acquire RSA key and perform login"><figcaption><p>All relevant assets and requests in succession</p></figcaption></figure><p>Inspect the request for <code>/login/getrsakey</code> and you’ll find a JSON-formatted response, containing fields with names that should look very familiar to anyone who’s briefly dealt with public key cryptography. You’re given a RSA public key, though the exact values might look a bit odd. It’s clear that <code>publickey_mod</code> and <code>publickey_exp</code> define the modulus and the exponent used in encryption, but the former is given in hexadecimal while the latter appears to be given in binary (I’ll get back on that later). There’s also a timestamp which has no immediately recognizable starting point. As to what the purpose of <code>token_gid</code> is, I have no clue yet.</p><div><pre><code data-lang="json"><span>{</span>
    <span>"success"</span><span>:</span><span>true</span><span>,</span>
    <span>"publickey_mod"</span><span>:</span><span>"c85ba44d5a3608561cb289795ac93b34d4b9b4326f9c09d1d19a9923e2d136b8..."</span><span>,</span>
    <span>"publickey_exp"</span><span>:</span><span>"010001"</span><span>,</span>
    <span>"timestamp"</span><span>:</span><span>"1260462250000"</span><span>,</span>
    <span>"token_gid"</span><span>:</span><span>"2701e0b0a4be3635"</span>
<span>}</span>
</code></pre></div><p>The login page pulls some scripts on load. There is the main login handler contained in <code>login.js</code> which is completely unobfuscated, so anyone can just analyze it and find out what it does. The site also loads some additional dependencies, namely <code>jsbn.js</code> and <code>rsa.js</code>.</p><p>A quick search for the name mentioned in the first line of <code>jsbn.js</code> reveals that these two scripts are the work of <a href="http://www-cs-students.stanford.edu/~tjw/">Tom Wu</a> — a MIT and Stanford graduate who likes software engineering and computer cryptography. They released <code>jsbn.js</code> and <code>rsa.js</code> as pure JavaScript implementations of arbitrary precision integers and RSA encryption/decryption respectively. You’ll also find that these libraries have had their most recent updates in 2005 and 2013 which is a bit of information I’ll come back to later. For now, just keep it in mind.</p><h3 id="going-down-the-rsabbit-hole">Going down the r(s)abbit hole</h3><p>So now that we have all relevant assets, let’s dig around in <code>login.js</code>. The code is a bit of a mess with lots of callbacks and proxied function calls, but it turns out the parts of interest can be easily condensed. In essence, the script can be boiled down to a couple of steps, each step assuming that everything went fine in the previous step.</p><ol><li>The user enters their username and password and presses the login button.</li><li><code>DoLogin</code> is called, which checks if the login mask was filled out correctly and launches a request against <code>/login/getrsakey</code>.</li><li><code>OnRSAKeyResponse</code> is called. This checks if the response is well-formed.</li><li><code>GetAuthCode</code> is called. It runs some platform-specific code in case there are any 2FA measures active on the user’s account.</li><li><code>OnAuthCodeResponse</code> is called. This is where the password is encrypted using RSA and the request against <code>/login/dologin</code> is prepared and executed.</li><li><code>OnLoginResponse</code> is called. The user is logged in and redirected to the Steam storefront.</li></ol><p>The code in <code>OnAuthCodeResponse</code> shows why the requested public key is formatted the way that it is. Starting at line 387 in the source file, the modulus and exponent of the <code>/login/getrsakey</code> response are passed as-is to the RSA library. The user’s password is then encrypted with the given public key and added to the request against <code>/login/dologin</code> in the subsequent login step.</p><div><pre><code data-lang="js"><span>var</span> <span>pubKey</span> <span>=</span> <span>RSA</span><span>.</span><span>getPublicKey</span><span>(</span><span>results</span><span>.</span><span>publickey_mod</span><span>,</span> <span>results</span><span>.</span><span>publickey_exp</span><span>);</span>
<span>var</span> <span>username</span> <span>=</span> <span>this</span><span>.</span><span>m_strUsernameCanonical</span><span>;</span>
<span>var</span> <span>password</span> <span>=</span> <span>form</span><span>.</span><span>elements</span><span>[</span><span>'password'</span><span>].</span><span>value</span><span>;</span>
<span>password</span> <span>=</span> <span>password</span><span>.</span><span>replace</span><span>(</span><span>/[^\x00-\x7F]/g</span><span>,</span> <span>''</span><span>);</span> <span>// remove non-standard-ASCII characters
</span><span></span><span>var</span> <span>encryptedPassword</span> <span>=</span> <span>RSA</span><span>.</span><span>encrypt</span><span>(</span><span>password</span><span>,</span> <span>pubKey</span><span>);</span>
</code></pre></div><p>I copied the source files onto my local machine to explore the RSA library a little bit. Both the modulus and the exponent are passed to the function <code>RSAPublicKey</code> which behaves like a constructor in the “pre-class” JavaScript era. <code>RSAPublicKey</code> simply wraps both values into instances of <code>BigInteger</code> provided by the <code>jsbn.js</code> script. It was to my surprise that the exponent is actually not represented in binary but, just like the modulus, in hexadecimal. (Also, turns out <code>0x010001</code> is a <a href="https://stackoverflow.com/questions/6098381/what-are-common-rsa-sign-exponent">very common encryption exponent</a> in RSA implementations.) So now it’s clear that the password encryption is based on 2048-bit RSA with an encryption exponent of 65537.</p><div><pre><code data-lang="js"><span>let</span> <span>r</span> <span>=</span> <span>RSA</span><span>.</span><span>getPublicKey</span><span>(</span><span>"c85ba44d5a360856..."</span> <span>/* insert your own long modulus here */</span><span>,</span> <span>"010001"</span><span>);</span>
<span>console</span><span>.</span><span>log</span><span>(</span><span>r</span><span>.</span><span>encryptionExponent</span><span>.</span><span>toString</span><span>());</span> <span>// =&gt; "65537"
</span><span></span><span>console</span><span>.</span><span>log</span><span>(</span><span>r</span><span>.</span><span>modulus</span><span>.</span><span>bitLength</span><span>());</span> <span>// =&gt; 2048
</span></code></pre></div><p>Moving on to the <code>timestamp</code> field. The <code>/login/getrsakey</code> response contains an <code>Expires</code> header. It references a date in the past, meaning that the response is absolutely not meant to be cached or persisted in any way. If you check back on <code>/login/getrsakey</code> over a longer period of time, you’ll notice that the public key changes ever so often and, as such, its timestamp value too. This means there’s only a limited time frame in which a certain Steam-issued RSA public key can be used to authenticate.</p><p>This becomes even more evident when examining the subsequent request against <code>/login/dologin</code>. Among many other things, it contains the username, encrypted password as well as the timestamp of the issued RSA public key. Trying to perform a login attempt while altering the timestamp fails as expected. But more importantly, it’s also not possible to reuse an older public key, even if the password is correctly encrypted.</p><p>I went one step further and <a href="https://gist.github.com/JoogsWasTaken/8a8e60859e1721255c57e9185eb6cb10">wrote a simple Python script to collect public keys</a> over the span of three days using a throwaway account. I let it run every five minutes using a cronjob. The goal was to check just how often Steam’s public keys change and to hopefully find out how the <code>timestamp</code> field behaves.</p><figure><img src="https://owlspace.xyz/images/steam-rsa/sqlite-pubkeys.png" alt="SQLite database containing public keys sourced from Steam"><figcaption><p>Lots and lots and lots of public keys</p></figcaption></figure><p>I found that the public key changes every 12 entries, meaning that it’s safe to assume that they rotate every hour. The encryption exponent stays the same — no surprises here. More intriguing however is the aforementioned <code>timestamp</code> field. For every 12 public keys, the value of the <code>timestamp</code> increases by a certain amount, namely 3600000000 and then some. And what’s more is that this number wraps around after some period of time as can be seen in the following image. Be warned, because all of what I’m about to say is highly speculative.</p><figure><img src="https://owlspace.xyz/images/steam-rsa/sqlite-wraparound.png" alt="Public key entries where the timestamp value wraps around in-between"><figcaption><p>Timestamp field wrapping around</p></figcaption></figure><p>I found that 3600000000 microseconds is equal to one hour, making me assume that the value of the <code>timestamp</code> field is, in fact, given in microseconds. However, I already hinted at the fact that the timestamp value doesn’t increase by one hour exactly with every new public key. In my own data, I observed that the difference between two successive timestamps is one hour plus 1 to 2.6 seconds, with most being in the order of about 1.05 to 1.25 seconds. But this raises another interesting possibility.</p><p>Let’s assume that a new public key is generated every hour plus one second. If I query the public key …</p></article></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://owlspace.xyz/cybersec/steam-login/">https://owlspace.xyz/cybersec/steam-login/</a></em></p>]]>
            </description>
            <link>https://owlspace.xyz/cybersec/steam-login/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25679209</guid>
            <pubDate>Thu, 07 Jan 2021 23:37:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I built this static site with Next.js]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25678811">thread link</a>) | @city41
<br/>
January 7, 2021 | https://mattgreer.dev/articles/how-i-built-this-static-site-with-nextjs/ | <a href="https://web.archive.org/web/*/https://mattgreer.dev/articles/how-i-built-this-static-site-with-nextjs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main"><div><h2 id="some-quick-terminology">Some quick terminology</h2><p>Some common HTML rendering terms</p><ul><li><strong>Client Side Rendering:</strong> <span>(CSR)</span> This is the default way React renders all HTML, inside the user's browser.</li><li><strong>Server Side Rendering:</strong> <span>(SSR)</span> With SSR a server is used to build the page when a user requests it. The page gets rendered on the server, but deciding what to render can happen on the fly.</li><li><strong>Static Site Generation:</strong> <span>(SSG)</span> SSG has the pages render their HTML at build time. They then get served up to users as plain old HTML files.</li></ul><h2 id="a-standard-nextjs-site">A standard Next.JS site</h2><p>If you take a look at this site's <a tabindex="0" href="https://github.com/city41/mattgreer.dev">codebase</a>, you'll find a very typical Next.JS site. In order to keep the site static, I ensure every page is capable of using SSG, which mostly boils down to never using <a tabindex="0" href="https://nextjs.org/docs/basic-features/data-fetching#getserversideprops-server-side-rendering"><code>getServerSideProps</code></a>. Its presence tells Next a page should use SSR.</p><p>If you want to know more, Next has good documentation. Their <a tabindex="0" href="https://nextjs.org/learn/basics/create-nextjs-app">Create a Next.JS App tutorial</a> will get you familiar with Next itself, then from there you can learn about how to do <a tabindex="0" href="https://nextjs.org/docs/basic-features/pages#static-generation-recommended">SSG here</a> and <a tabindex="0" href="https://nextjs.org/docs/basic-features/data-fetching">SSR here</a>.</p><h2 id="next-export">next export</h2><p>If your entire site can be statically built, then you can tell Next to do just that with the command <code>next build &amp;&amp; next export</code>. After running this command, you will find the site output at <code>&lt;project root&gt;/.next/server/pages</code>. You can take this directory and host it on say GitHub pages or an S3 bucket.</p><h3 id="but-i-just-use-vercel">But, I just use Vercel</h3><p><a tabindex="0" href="https://vercel.com/">Vercel</a>, the creators of Next, provide a hosting solution that handles Next apps perfectly (as you would expect). Since it's free for hobby and personal sites, I just use that instead of using <code>next export</code>.</p><h2 id="removing-the-react-javascript">Removing the React JavaScript</h2><p>Static Next pages still load React at runtime. Just like any other Next page, React will kick in and walk the DOM, integrating itself into the page and turning the page into a live React app. This is known as hydration.</p><p>Hydration is wasteful and not needed if the page is truly static. You can tell Next to skip all of this by adding this config object to the page:</p><p><code><p><span>export</span><span>&nbsp;<wbr></span><span>const</span><span>&nbsp;<wbr>config&nbsp;<wbr></span><span>=</span><span>&nbsp;<wbr></span><span>{</span><span></span></p><p><span>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>unstable_runtimeJS</span><span>:</span><span>&nbsp;<wbr></span><span>false</span><span></span></p><p><span></span><span>}</span><span>;</span><span></span></p></code></p><p><a tabindex="0" href="https://github.com/city41/mattgreer.dev/blob/main/pages/about.tsx#L4">Here is an example</a>.</p><p>This is prefixed with unstable because this config setting <a tabindex="0" href="https://github.com/vercel/next.js/pull/11949">was recently introduced</a>. It is experimental at this point and likely to change, I would not recommend it for anything mission critical.</p><p>With this config in place, the page will only have HTML, CSS and any bespoke JavaScript you add yourself (more on this below).</p><h2 id="using-nexts-link-component">Using Next's Link component</h2><p>Normally, Next's <code>&lt;Link&gt;</code> is how you link between pages in your app. Using it for a fully static site is questionable though, as it ends up doing nothing at all. If you do use it, keep in mind you <em>must</em> set the <code>passHref</code> prop</p><p><code><p><span>&lt;</span><span>Link</span><span>&nbsp;<wbr>href</span><span>=</span><span>"http://zombo.com"</span><span>&nbsp;<wbr>passHref</span><span>&gt;</span><span></span></p><p><span>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr></span><span>&lt;</span><span>a</span><span>&gt;</span><span>checkout&nbsp;<wbr></span><span>Zombo</span><span>&lt;</span><span>/</span><span>a</span><span>&gt;</span><span></span></p><p><span></span><span>&lt;</span><span>/</span><span>Link</span><span>&gt;</span><span></span></p></code></p><p>Otherwise the <code>a</code> tag will not get the href, making the link dead when you build the site. This is especially tricky because the Link will work just fine in dev mode without <code>passHref</code>.</p><h2 id="sprinkling-in-a-little-js">Sprinkling in a little JS</h2><p>With React removed, I need to add JS myself for any interactivity I want. At the bottom of every page is a theme switcher, which uses JavaScript. The <a tabindex="0" href="https://mattgreer.dev/">front page</a> also uses JavaScript for a canvas graphic (if you are not on a phone). For these, I just added in JavaScript the old fashion way. Remember <code>querySelector</code> and <code>addEventListener</code>? 😃</p><p>To do this, I write the needed JavaScript in a standalone file, and then bring it into the page with <code>dangerouslySetInnerHTML</code>.</p><p>It's not very dangerous as it is being done at build time.</p><p><code><p><span>import</span><span>&nbsp;<wbr></span><span>React</span><span>&nbsp;<wbr></span><span>from</span><span>&nbsp;<wbr></span><span>'react'</span><span>;</span><span></span></p><p><span></span><span>type</span><span>&nbsp;<wbr></span><span>BespokeJavaScriptProps</span><span>&nbsp;<wbr></span><span>=</span><span>&nbsp;<wbr></span><span>{</span><span></span></p><p><span>&nbsp;<wbr>&nbsp;<wbr>prop1</span><span>:</span><span>&nbsp;<wbr></span><span>string</span><span>;</span><span></span></p><p><span>&nbsp;<wbr>&nbsp;<wbr>prop2</span><span>:</span><span>&nbsp;<wbr></span><span>boolean</span><span>;</span><span></span></p><p><span></span><span>}</span><span>;</span><span></span></p><p><span></span><span>function</span><span>&nbsp;<wbr></span><span>myBespokeJavaScript</span><span>(</span><span>props</span><span>:</span><span>&nbsp;<wbr>BespokeJavaScriptProps</span><span>)</span><span>&nbsp;<wbr></span><span>{</span><span></span></p><p><span></span><span>}</span><span></span></p><p><span></span><span>function</span><span>&nbsp;<wbr></span><span>BespokeJavaScript</span><span>(</span><span>props</span><span>:</span><span>&nbsp;<wbr>BespokeJavaScriptProps</span><span>)</span><span>&nbsp;<wbr></span><span>{</span><span></span></p><p><span>&nbsp;<wbr>&nbsp;<wbr></span><span>return</span><span>&nbsp;<wbr></span><span>(</span><span></span></p><p><span>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr></span><span>&lt;</span><span>script</span></p><p><span>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr></span><span>type</span><span>=</span><span>"text/javascript"</span><span></span></p><p><span>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>dangerouslySetInnerHTML</span><span>=</span><span>{</span><span>{</span><span></span></p><p><span>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>__html</span><span>:</span><span>&nbsp;<wbr></span><span>`</span><span>${</span><span>myBespokeJavaScript</span><span>.</span><span>toString</span><span>(</span><span>)</span><span>}</span><span>;</span></p><p><span>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>myBespokeJavaScript(</span><span>${</span><span>JSON</span><span>.</span><span>stringify</span><span>(</span><span>props</span><span>)</span><span>}</span><span>)</span><span>`</span><span>,</span><span></span></p><p><span>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr></span><span>}</span><span>}</span><span>&gt;</span><span></span></p><p><span>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr></span><span>&lt;</span><span>/</span><span>script</span><span>&gt;</span><span></span></p><p><span>&nbsp;<wbr>&nbsp;<wbr></span><span>)</span><span>;</span><span></span></p><p><span></span><span>}</span><span></span></p><p><span></span><span>export</span><span>&nbsp;<wbr></span><span>{</span><span>&nbsp;<wbr></span><span>BespokeJavaScript</span><span>&nbsp;<wbr></span><span>}</span><span>;</span><span></span></p></code></p><p>Then somewhere else, I just add it to the page as a standard React component, ie <code>&lt;BespokeJavaScript/&gt;</code></p><h3 id="downsides-and-gotchas">Downsides and Gotchas</h3><p>This approach has several problems, some more thought is needed.</p><ul><li><p>The JavaScript gets inlined into every page that needs it. Every page on this site has its own copy of the theme switcher code. Since it's very short, I don't mind <em>too much</em> in this case.</p></li><li><p>The bespoke code does not get minimized or polyfilled. If you look at the source for this page, you can see the theme switcher code almost exactly as I wrote it, whitespace and all.</p></li><li><p>Also, Next does not understand this code. During development, it does not get updated with fast refresh, and I also need to account for dev mode in the code itself. This admittedly is a pretty annoying gotcha.</p></li></ul><p>I might plug away at this more and see if I can make improvements. But since my bespoke JS is so minimal, I'm not too bothered (yet...). I am also going to wait to see how <a tabindex="0" href="https://reactjs.org/blog/2020/12/21/data-fetching-with-react-server-components.html">server side components</a> play out, as they may impact my approach.</p><h2 id="opting-back-into-react">Opting back into React</h2><p><code>unstable_Runtimejs</code> is applied per page. If a page needs React, it's easy to turn it back on. This website is brand new, but I do have plans for more interactive pages and for those I will opt back into React.</p><h2 id="i-like-it">I like it</h2><p>So far I <em>really</em> like this approach to building websites. React and Next offer such an excellent development experience. My HTML is always properly formed. I get type checking with TypeScript. I can extract commonalities into components. I don't have to worry as much about pulling in large libraries (such as the syntax highlighting library), as only the resulting HTML is saved. I can also use Next plugins to accomplish common tasks such as image minification.</p><p>Not to mention all of the standard "no JavaScript" bonuses apply too: better SEO, usually more performant, no need to worry about client side routing snafus, Hacker News doesn't yell at you, etc.</p><div><div><h3>About me</h3><p>I am a<!-- --> <a tabindex="0" href="https://mattgreer.dev/hire-me/">freelance software engineer</a> <!-- -->with a focus on web development. I also enjoy game dev as a hobby. Previously I worked for Netflix and Microsoft.</p></div></div></div></div></div>]]>
            </description>
            <link>https://mattgreer.dev/articles/how-i-built-this-static-site-with-nextjs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25678811</guid>
            <pubDate>Thu, 07 Jan 2021 22:54:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[“We need a well equipped press corps to keep us informed.”]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25678291">thread link</a>) | @nillium
<br/>
January 7, 2021 | https://blog.nillium.com/defending-journalism-to-defend-the-republic/ | <a href="https://web.archive.org/web/*/https://blog.nillium.com/defending-journalism-to-defend-the-republic/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://images.unsplash.com/photo-1575320181282-9afab399332c?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDI2fHxjYXBpdG9sfGVufDB8fHw&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000 300w,
                            https://images.unsplash.com/photo-1575320181282-9afab399332c?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDI2fHxjYXBpdG9sfGVufDB8fHw&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000 600w,
                            https://images.unsplash.com/photo-1575320181282-9afab399332c?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDI2fHxjYXBpdG9sfGVufDB8fHw&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000 1000w,
                            https://images.unsplash.com/photo-1575320181282-9afab399332c?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDI2fHxjYXBpdG9sfGVufDB8fHw&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://images.unsplash.com/photo-1575320181282-9afab399332c?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDI2fHxjYXBpdG9sfGVufDB8fHw&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000" alt="Defending Journalism to Defend the Republic">
            </figure>

            <section>
                <div>
                    <p>Today is a difficult day in America, a difficult day to be an American.</p><p>Watching the videos of my fellow countrymen breaking windows to get into the U.S. Capitol, seeing the photos of our elected lawmakers huddling under chairs in the House chamber: these are images of our very democracy under attack -- all in an attempt to disrupt what is usually a ceremonial certification of an election.</p><p>As sad and disappointing as the situation is, what is worse is what got us here. &nbsp;Disinformation is real. The vilification of the news media is real. &nbsp;At some point in the last few years, we’ve bifurcated reality, politicizing verifiable facts and even the act of journalism itself.</p><figure><blockquote data-width="550"><p lang="en" dir="ltr">After I called them rioters just now on air, the crowd converged on the area press had gathered so we took off. This is a mob of violent rioters, no other way to put it.</p>— Alexander Marquardt (@MarquardtA) <a href="https://twitter.com/MarquardtA/status/1346940341409226754?ref_src=twsrc%5Etfw">January 6, 2021</a></blockquote>

</figure><p>America is a democracy -- a government by the people, for the people. &nbsp;And in order for the people to govern themselves, we need a well equipped press corps to keep us informed. &nbsp;There cannot be two sets of facts, two universes of truth. &nbsp;We need the reliable journalists to win, to keep us informed, so we can debate ideas, not facts.</p><p>Reporting is not a political act, but it’s also not simply stenography for the powerful. &nbsp;Digging, investigating, holding those in power accountable -- these are the ideals that journalism holds in the highest regard. </p><p>Most who work for reputable news organizations are obsessive in their caution to limit any appearance of impropriety. &nbsp;They adhere to strict editorial standards that the audience is largely unaware of. They are bound by policies and standards that guide how and what they report all designed to ensure credibility in the information they share.</p><p>And yet, disinformation runs wild. &nbsp;The downside of a platform where anyone can post anything, is that anyone can post anything. &nbsp;</p><p>I know many people do not like to pay for news. &nbsp;Frankly, it makes fiscal sense not to when you view it as a commodity and so much is available for free. &nbsp;But when news is commoditized, and taken from an aggregator or a social network, the provenance &nbsp;-- and credibility - can be a gamble.</p><p>It also means that there is ever less money funding the responsible reporting that we need so much. &nbsp;There are technical means to disable ads; there are methods to sneak around paywalls. &nbsp;But each of these actions means that journalism is ever so slightly less economically viable, with dire consequences.</p><p>Newspapers go bankrupt. &nbsp;</p><p>News websites turn to clickbait to attract the remaining ad-viewing traffic they so desperately need.</p><p>And others who abide by no ethics step up to fill the void, which can lead to plagiarizing total fabrication or conspiracy minded fantasists, breathlessly reporting the intricate details of insane theories about the dark side of our leaders. </p><p>All of this makes trust in all media decline (even those that are obsessively reliable), makes the profession less viable, and makes our democracy less informed.</p><p>All of this makes today’s scenes on Capitol Hill possible.</p><p>Journalism is not the enemy. &nbsp;It is the shield that protects us from those that wish to turn us against each other.</p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.nillium.com/defending-journalism-to-defend-the-republic/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25678291</guid>
            <pubDate>Thu, 07 Jan 2021 22:08:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Spark on Kubernetes for NLP at Scale]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25678165">thread link</a>) | @natpat
<br/>
January 7, 2021 | https://www.benevolent.com/engineering-blog/spark-on-kubernetes-for-nlp-at-scale | <a href="https://web.archive.org/web/*/https://www.benevolent.com/engineering-blog/spark-on-kubernetes-for-nlp-at-scale">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><div><h3>A lot of the work we do at Benevolent is powered by the insights and relationships we extract directly from scientific literature. We ingest, normalize and process millions of papers. </h3><p>The information discovered from these papers is used heavily in our drug discovery programs: from being used as features for Machine Learning driven target identification, to highlighting the best evidence to show directly to our drug discovers as they triage potential targets.<br>The pipeline that processes our corpus of literature isn’t simple. We use multiple NLP techniques, from rule based systems to more complex AI systems that consider over a billion sentences. This pipeline must be robust, fast, and flexible; our AI Researchers and Data Scientists need the freedom to experiment and try out new ideas across the corpus quickly and easily. To this end, the majority of our pipeline leverages two pieces of technology: <a href="https://spark.apache.org/">Apache Spark</a> and <a href="https://kubernetes.io/">Kubernetes</a>.</p><p>‍</p><h5><strong>Why Spark?</strong></h5><p>The Spark Python DataFrame API exposes your data as a table/dataframe, in a similar way to pandas.</p><figure><p><img src="https://uploads-ssl.webflow.com/5ea88781be15eaddffecc8d7/5f2d4bfb10ff924922a3719c_Code.png" alt=""></p></figure><p>Spark DataFrames have a number of great features, including support for schemas, complex/nested types, and a full featured API for transforming datasets. Spark also supports UDFs (User Defined Functions), which allows us to drop into custom Python functions and transform rows directly in Python. This allows more complex data transformation to be expressed in Python, which is often simpler and allows the use of external packages.<br></p><p>But the best feature of Spark is its incredible parallelizability. A Spark script will run equally well on your laptop on 1000 rows, or on a 20 node cluster with millions of rows. It’s at the heart of everything Spark does, and it just works. There are a number of options for how to run Spark on a multi-node cluster; at Benevolent, we’ve opted to run on Kubernetes.</p><h5><strong>Why Kubernetes?</strong></h5><p>Kubernetes is at the heart of all the engineering we do at Benevolent. We made the decision to run everything on Kubernetes very early on, and as we’ve grown, our use of Kubernetes has grown too. We’ve moved from a cluster running in a cupboard on-premises, to off-site server space, to multiple AWS EKS clusters. Everything is Dockerised, and everything runs on a Kubernetes cluster: our internal web apps, our CI/CD pipelines, our GPU jobs, and our Spark pipelines.<br></p><p>But it wasn’t always like this. Until about a year ago, we ran our Spark pipelines on AWS’s managed platform for Spark workloads: EMR.</p><h5><strong>The Dark Ages</strong></h5><p>EMR is pretty good at what it does, and as we only used it for Spark workloads we didn’t even scratch the surface of what it can do. That being said, there were a number of issues we found with EMR, which eventually led us to move our Spark workloads to Kubernetes. Some of these issues might have been solved since we moved.<br></p><p>Issues we encountered with EMR:</p><ul role="list"><li>No support for using Docker Images.</li><li>Logs were in a nest of S3 paths.</li><li>Startup times for a cluster were long, especially when rebuilding the AMI/Image.</li><li>Pipelines were defined in JSON, which got clunky with complex pipelines.</li><li>Experimentation was not easy, as long startup times meant quick iteration was impossible.<br></li></ul><p>As our Spark pipelines got longer and more complicated, we found EMR getting more difficult to use. While we were building more tooling on top of EMR, the rest of the company was sharing tools and improving on their use of Kubernetes. This finally led us to investigating if we could run Spark on Kubernetes.</p><h5><strong>The Renaissance</strong></h5><p>Spark on Kubernetes is a simple concept, but it has some tricky details to get right. In general, the process is as follows:</p><ul role="list"><li>A Spark Driver starts running in a Pod in Kubernetes.</li><li>The Driver contacts the Kubernetes API server to start Executor Pods.</li><li>The Executors connect to the Driver and start work.<br></li></ul><p>From there, the process continues as normal. As mentioned though, there are some specific details and settings that need to be considered when running Spark on Kubernetes.</p><p>‍<br></p><h6><em>Client vs Cluster mode</em></h6><p>Spark has two modes for running on an external cluster: client and cluster mode. Cluster mode is the simplest, where the <strong><em>spark-submit</em></strong> command simply starts a Driver Pod inside the cluster, then waits for it to complete. However, we found this had a flaw - if the Spark job failed for any reason, the Driver Pod would exit with an exit code of 1, but the spark-submit command wouldn’t pass that failure on, and exited with an exit code of 0. This meant we had no way of capturing if a job had succeeded or failed, without resorting to something like inspecting the logs.&nbsp;<br></p><p>Client mode, on the other hand, runs the Driver process directly where you run the <strong><em>spark-submit</em></strong> command. This means setting a lot of the settings on the Driver Pod yourself, as well as providing a way for the Executors to communicate with the Driver. However, you get complete control over the Pod which the Spark Driver runs in.</p><p>‍<br></p><h6><em>Service Discovery</em>‍</h6><p>Once running in client mode, the Executors need some way to communicate with the Driver Pod. Headless services are perfect for this, as you can start a single service, match the selectors on the service and the Driver Pod, then access the Pod directly through its hostname. We’ve found headless services to be useful on a number of occasions - see the <a href="https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/#pod-s-hostname-and-subdomain-fields" target="_blank">official Kubernetes documentation</a> for a full explanation.<br></p><p>‍</p><h6><em>S3 access</em></h6><p>S3 is the backbone of all the data we have at Benevolent. Spark uses the Hadoop file system to access files, which also allows access to S3 through the AWS Java SDK. This has two parts:&nbsp;</p><p>1) Access credentials setup for S3 access.</p><p>2) Choosing the right implementation of the S3 protocol to allow efficient access to data from Spark Executors.<br></p><p>Access credentials can be solved in various ways in Kubernetes and Spark.</p><ul role="list"><li>The simplest is to set up raw AWS credentials in Kubernetes secrets, and then supply these to the Spark Driver and Executors via environment variables.&nbsp;</li><li>An alternative to this is to use IAM roles that can be configured to have specific access rights in S3. This requires a service called <strong><em>kube2iam</em></strong> running in each node in your cluster. We have found this service very unreliable and have recently stopped using it.&nbsp;</li><li>The third alternative is to use Kubernetes service accounts that have specific rights. Until Spark 3, it wasn’t possible to set a separate service account for Executors; however, we have now found that this is the most reliable and secure way to authenticate.<br></li></ul><p>The second part of the<strong><em> S3</em></strong> access is to set up a Hadoop file system implementation for S3. AWS Java SDK has an implementation for S3 protocol called <strong><em>s3a</em></strong>. It works very well except it breaks the commonly used protocol name <strong><em>‘s3’.</em></strong> For a long time we had some internal mappings to allow users to use <strong><em>s3://</em></strong> URIs that were internally translated to<strong><em> s3a://</em></strong>. Then, we realised you can set a specific file system implementation for any URI protocol. This magic made all the mappings unnecessary:<br></p><p><strong><em>"--conf", "spark.hadoop.fs.s3.impl=org.apache.hadoop.fs.s3a.S3AFileSystem"</em></strong><br></p><p>We instructed Spark to use the <strong><em>s3a</em></strong> file system implementation for S3 protocol.<br></p><p>‍</p><h6><em>Notebooks on S3</em></h6><p>Many of our Researchers and Data Scientists need to take a closer look at the data we process and produce. Due to the size of the data and to maintain a high security standard, the data needs to be saved in S3. Jupyter notebooks are an industry standard for investigating and running experiments, and we wanted a seamless experience where a notebook could be run on Kubernetes, access all the data on S3, and run Spark workloads on Kubernetes.<br></p><p>Our solution for this is a custom Helm chart, which allows users to start and stop their own private instance. These notebooks are backed by S3, and preloaded with our mono-repo, Rex. Rex provides a helper function which provides a Spark Session with any number of Executors, set up to run on Kubernetes just like the rest of our production workloads.</p><p>‍<br></p><h5><strong>Conclusion</strong></h5><p>Running Spark on Kubernetes is extremely powerful, but getting it to work seamlessly requires some tricky setup and configuration. However, once it is working well, the power and flexibility it provides is second to none.</p><p><strong>Nathan Patel &amp; Juha Iso-Sipilä</strong></p></div></div></div></div></div></div>]]>
            </description>
            <link>https://www.benevolent.com/engineering-blog/spark-on-kubernetes-for-nlp-at-scale</link>
            <guid isPermaLink="false">hacker-news-small-sites-25678165</guid>
            <pubDate>Thu, 07 Jan 2021 21:59:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OpenBSD: High-Availability Firewalling]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25678102">thread link</a>) | @rodrigo975
<br/>
January 7, 2021 | http://yetiops.net/posts/openbsd-firewall-ha/ | <a href="https://web.archive.org/web/*/http://yetiops.net/posts/openbsd-firewall-ha/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <p>While most posts on this site usually concern Linux, I have a bit of a soft spot for OpenBSD.</p>
<p>OpenBSD is an operating system from the Unix lineage, started in Bell Labs many years ago, eventually giving rise to the Berkley Software Distribution (BSD). The most known versions of BSD are NetBSD (who focus on portability, running on pretty much any hardware), FreeBSD (who focus on covering as many purposes as possible) and OpenBSD (who focus on security, sometimes at the expense of performance).</p>
<p>OpenBSD has (in my opinion) amazing documentation, and with a combination of their <code>man</code> pages and example configuration (eg <code>/etc/examples</code> is full of configuration examples), you can get most of the included daemons working.</p>
<p>OpenBSD also provides quite a comprehensive suite of software already bundled in, everything from routing daemons, web servers, firewalling, mail servers and much more.</p>
<p>In this post, I’m going to cover how you can setup a pair of OpenBSD machines to run as a highly-available firewall pair.</p>
<h2 id="diagram">Diagram</h2>
<p><img src="https://yetiops.net/img/openbsd-fw.png" alt="OpenBSD Firewalling"></p>
<p>In the diagram, we have a client machine (running on Debian 10), a server (<strong>net-01</strong>) and two OpenBSD virtual machines.</p>
<h2 id="installing-openbsd">Installing OpenBSD</h2>
<p>To set up OpenBSD, you will be presented with a text-based installer with a number of options to choose from. I won’t go into details here, as the OpenBSD <a href="https://www.openbsd.org/faq/faq4.html">FAQ</a> can cover every aspect of it. Summing up my chosen options though: -</p>
<ul>
<li>Three main networks
<ul>
<li>hvn2 - The link between the firewalls (running in the <code>169.254.0.0/31</code> range)</li>
<li>hvn3 - The link to the server (running in the <code>192.0.2.0/24</code> range)</li>
<li>hvn4 - The link to the client (running in the <code>192.168.99.0/24</code> range)</li>
</ul>
</li>
<li>Only installing a minimal file set, with no <strong>X11</strong> dependencies, or the text-based games file sets</li>
<li>Automatic partioning</li>
</ul>
<h2 id="setting-up-the-the-firewalls">Setting up the the firewalls</h2>
<p>To get the firewalls running, we need to setup the following daemons: -</p>
<ul>
<li><code>pf(4)</code> - PF, or Packet Filter, the OpenBSD packet filtering daemon</li>
<li><code>carp(4)</code> - CARP, or Common Address Redundancy Protocol, for highly available IPs (like VRRP or Cisco’s HSRP)</li>
</ul>
<p>We also need to do the following: -</p>
<ul>
<li>Add the correct IPs to each interface</li>
<li>Allow IP forwarding through the firewalls</li>
<li>Enable the <code>pfsync(4)</code> device, to sync state between the firewalls</li>
<li>Create the <code>carp(4)</code> interfaces</li>
<li>Define the <code>pf(4)</code> ruleset</li>
</ul>
<h3 id="setting-up-the-ip-interfaces">Setting up the IP interfaces</h3>
<p>To define an interface in OpenBSD, you create a file called <code>hostname.$INTERFACE-NAME</code>, replacing <strong>$INTERFACE-NAME</strong> with your interfaces (eg <strong>hvn2</strong>, <strong>vio1</strong>), in the <code>/etc</code> directory.</p>
<p>To demonstrate this, see below: -</p>
<div><pre><code data-lang="bash"><span>## hostname.hvn2</span>
inet 169.254.0.1 255.255.255.254

<span>## hostname.hvn3</span>
inet 192.0.2.10 255.255.255.0

<span>## hostname.hvn4</span>
inet 192.168.99.1 255.255.255.0
</code></pre></div><p>You can also supply the network mask in hexadecimal format (eg a <code>/24</code> would be <code>0xffffff00</code>). To enable the interfaces, you can use <code>doas sh /etc/netstart hvn2</code>.</p>
<p>You should now be able to see the interfaces: -</p>
<div><pre><code data-lang="bash">$ ifconfig hvn2
hvn2: flags<span>=</span>8a43&lt;UP,BROADCAST,RUNNING,ALLMULTI,SIMPLEX,MULTICAST&gt; mtu <span>1500</span>
        lladdr 00:15:5d:f4:91:ef
        index <span>3</span> priority <span>0</span> llprio <span>3</span>
        media: Ethernet manual
        status: active
        inet 169.254.0.1 netmask 0xfffffffe

$ ifconfig hvn3 
hvn3: flags<span>=</span>8b43&lt;UP,BROADCAST,RUNNING,PROMISC,ALLMULTI,SIMPLEX,MULTICAST&gt; mtu <span>1500</span>
        lladdr 00:15:5d:f4:91:f3
        index <span>4</span> priority <span>0</span> llprio <span>3</span>
        media: Ethernet manual
        status: active
        inet 192.0.2.10 netmask 0xffffff00 broadcast 192.0.2.255

$ ifconfig hvn4 
hvn4: flags<span>=</span>8b43&lt;UP,BROADCAST,RUNNING,PROMISC,ALLMULTI,SIMPLEX,MULTICAST&gt; mtu <span>1500</span>
        lladdr 00:15:5d:f4:91:f4
        index <span>5</span> priority <span>0</span> llprio <span>3</span>
        media: Ethernet manual
        status: active
        inet 192.168.99.1 netmask 0xffffff00 broadcast 192.168.99.255

</code></pre></div><p>You’ll need to ensure that each firewall has a different IP on it’s interfaces (i.e. using <code>192.168.99.2/24</code> on <strong>hvn4</strong> on the second firewall) so that they do not conflict.</p>
<h3 id="wait-what-is-doas">Wait, what is <code>doas</code>?</h3>
<p><code>doas(1)</code> is a privilege escalation utility, used to temporarily elevate a user’s privileges, to allow them to perform commands that they typically cannot as a normal user. For those familiar with <code>sudo</code>, it is very similar. The reason for its existence is a smaller codebase than <code>sudo</code> to maintain, and also the configuration syntax is quite simple.</p>
<p>This is a good example of OpenBSD choosing tools that they can maintain and audit easily, rather than using external tools (or maintaing their own fork). For other examples, see the choice of their own <code>httpd(8)</code> over NGINX, or <code>bgpd(4)</code> over Quagga/BIRD.</p>
<p>To get a simple version of <code>doas(1)</code> running, you can look at the <code>/etc/examples</code> directory for a sample <code>doas.conf</code> file. Copy this to <code>/etc/doas.conf</code>, and edit it to your tastes.</p>
<div><pre><code data-lang="bash"><span>## $OpenBSD: doas.conf,v 1.1 2016/09/03 11:58:32 pirofti Exp $</span>
<span>## Configuration sample file for doas(1).</span>
<span>## See doas.conf(5) for syntax and examples.</span>

<span>## Non-exhaustive list of variables needed to build release(8) and ports(7)</span>
<span>##permit nopass setenv { \</span>
<span>##    FTPMODE PKG_CACHE PKG_PATH SM_PATH SSH_AUTH_SOCK \</span>
<span>##    DESTDIR DISTDIR FETCH_CMD FLAVOR GROUP MAKE MAKECONF \</span>
<span>##    MULTI_PACKAGES NOMAN OKAY_FILES OWNER PKG_DBDIR \</span>
<span>##    PKG_DESTDIR PKG_TMPDIR PORTSDIR RELEASEDIR SHARED_ONLY \</span>
<span>##    SUBPACKAGE WRKOBJDIR SUDO_PORT_V1 } :wsrc</span>

<span>## Allow wheel by default</span>
permit keepenv :wheel
</code></pre></div><p>The above does nothing more than allow the <strong>wheel</strong> group to use <code>doas(1)</code>. I add my user into the <strong>wheel</strong> group, and from then on I can use <code>doas(1)</code> to my hearts content.</p>
<h3 id="setting-up-pfsync4">Setting up <code>pfsync(4)</code></h3>
<p>For truly highly available firewalls, you need something that will synchronize the state between them. This is because if you just failover to another machine, the second machine would have no idea of what existing TCP connections are active, what UDP connections have been seen recently (eg VoIP calls) and how many hits each rule has seen (important for monitoring).</p>
<p>OpenBSD provides the <code>pfsync(4)</code> utility, which does exactly that. To quote the <code>man</code> page for <code>pfsync(4)</code></p>
<blockquote>
<p>If configured with a physical synchronisation interface, pfsync will also send state changes out on that interface, and insert state changes received on that interface from other systems into the state table.</p>
</blockquote>
<p>So if you have this running on an interface dedicated between two machines, they will share state information.</p>
<p>To make this work, you configure another <code>hostname.$INTERFACE-NAME</code> file, except this time it will be <code>hostname.pfsync</code>. The contents of the file will look something like the below: -</p>
<div><pre><code data-lang="bash">$ cat /etc/hostname.pfsync0                                                                                         
up syncdev hvn2
</code></pre></div><p>This is the same on both firewalls. If you run <code>tcpdump(8)</code> on <strong>hvn2</strong> while the firewall is in operation, you will see numerous state messages passing between the two firewalls (try running <code>tcpdump -i hvn2</code> during operation to see).</p>
<h3 id="allow-ip-forwarding">Allow IP Forwarding</h3>
<p>IP Forwarding is configured within the <code>/etc/sysctl.conf</code> file as such: -</p>
<div><pre><code data-lang="bash">$ cat /etc/sysctl.conf
net.inet.ip.forwarding<span>=</span><span>1</span>
</code></pre></div><p>Without this, traffic will not work through the firewalls, so make sure you enable this!</p>
<h3 id="add-carp4-for-redundancy">Add <code>carp(4)</code> for redundancy</h3>
<p>Unless you use devices that support routing protocols, or can failover between multiple default gateways, you’ll need to target an IP that can reside on both firewalls. In the Cisco world, they use <strong>HSRP</strong> (Hot Standby Router Protocol). The RFC version of <strong>HSRP</strong> is known as <strong>VRRP</strong> (Virtual Router Redundancy Protocol). However, despite <strong>VRRP</strong> being an RFC standard, it is patent-encumbered, meaning some elements of it are covered by patents (owned by Cisco).</p>
<p>Due to this, the OpenBSD developers implemented <strong>CARP</strong> instead. <strong>CARP</strong> does not infringe on any Cisco patents, although it does still use a few traits of VRRP (eg the IP Protocol number and Virtual MAC Addresses). This does mean that if you have <strong>VRRP</strong> and <strong>CARP</strong> on the same network, you will need to use different VRRP Group IDs and CARP Virtual Host IDs for them to coexist.</p>
<p>Again, to setup a <code>carp(4)</code> interface on the primary firewall, you use the <code>hostname.$INTERFACE-NAME</code> files. To demonstrate, see below: -</p>
<div><pre><code data-lang="bash"><span>## hostname.carp1</span>
inet 192.0.2.1 255.255.255.0 192.0.2.255 vhid <span>1</span> carpdev hvn3 pass hvn3pass

<span>## hostname carp2</span>
inet 192.168.99.254 255.255.255.0 192.168.99.255 vhid <span>1</span> carpdev hvn4 pass hvn4pass 
</code></pre></div><p>The syntax is as follows: -</p>
<p><code>inet $VIRTUAL-IP $SUBNET-MASK $BROADCAST-ADDRESS vhid $CARP-VIRTUAL-HOST-ID carpdev $PHYSICAL-INTERFACE pass $PASSWORD</code></p>
<p>You need to ensure the Virtual IP is in the same network as the interface it is running on. The Physical Interface parameter is used to tie the <strong>CARP</strong> virtual interface to a physical interface.</p>
<p>Again, use <code>doas /etc/netstart carpN</code> to start the interfaces: -</p>
<div><pre><code data-lang="bash">$ ifconfig carp1
carp1: flags<span>=</span>8843&lt;UP,BROADCAST,RUNNING,SIMPLEX,MULTICAST&gt; mtu <span>1500</span>
        lladdr 00:00:5e:00:01:01
        index <span>8</span> priority <span>15</span> llprio <span>3</span>
        carp: MASTER carpdev hvn3 vhid <span>1</span> advbase <span>1</span> advskew <span>0</span>
        groups: carp
        status: master
        inet 192.0.2.1 netmask 0xffffff00 broadcast 192.0.2.255

$ ifconfig carp2
carp2: flags<span>=</span>8843&lt;UP,BROADCAST,RUNNING,SIMPLEX,MULTICAST&gt; mtu <span>1500</span>
        lladdr 00:00:5e:00:01:01
        index <span>9</span> priority <span>15</span> llprio <span>3</span>
        carp: MASTER carpdev hvn4 vhid <span>1</span> advbase <span>1</span> advskew <span>0</span>
        groups: carp
        status: master
        inet 192.168.99.254 netmask 0xffffff00 broadcast 192.168.99.255
</code></pre></div><p>Notice in the above that it shows the status of the interface (in this case, the <strong>MASTER</strong>).</p>
<p>The syntax for the <code>hostname</code> files on the secondary firewall differs slightly: -</p>
<div><pre><code data-lang="bash"><span>## hostname.carp1</span>
inet 192.0.2.1 255.255.255.0 192.0.2.255 vhid <span>1</span> carpdev hvn3 pass hvn3pass advskew <span>128</span>

<span>## hostname.carp2</span>
inet 192.168.99.254 255.255.255.0 192.168.99.255 vhid <span>1</span> carpdev hvn4 pass hvn4pass advskew <span>128</span>
</code></pre></div><p>The primary difference is the <code>advskew</code> parameter. This is used to set a “priority” or “weight” on the interface, higher being less preferred.</p>
<p>The interface output on the secondary firewall looks like this: -</p>
<div><pre><code data-lang="bash">$ ifconfig carp1
carp1: flags<span>=</span>8843&lt;UP,BROADCAST,RUNNING,SIMPLEX,MULTICAST&gt; mtu <span>1500</span>
        lladdr 00:00:5e:00:01:01
        index <span>8</span> priority <span>15</span> llprio <span>3</span>
        carp: BACKUP carpdev …</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://yetiops.net/posts/openbsd-firewall-ha/">http://yetiops.net/posts/openbsd-firewall-ha/</a></em></p>]]>
            </description>
            <link>http://yetiops.net/posts/openbsd-firewall-ha/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25678102</guid>
            <pubDate>Thu, 07 Jan 2021 21:54:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Five Pressures of Leadership in OSS]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25677766">thread link</a>) | @alexellisuk
<br/>
January 7, 2021 | https://blog.alexellis.io/the-5-pressures-of-leadership/ | <a href="https://web.archive.org/web/*/https://blog.alexellis.io/the-5-pressures-of-leadership/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
    <article>

        

        <section>
            <div><p>In this post I want to introduce the reader to five pressures that I have encountered over the past five years of building, leading, and maintaining Open Source Software (OSS) with community. This essay is primarily about being a leader in Open Source, but I believe <a href="https://www.amazon.co.uk/How-Survive-Thrive-Church-Leader/dp/1854247611">it applies outside of technology</a> too.</p>
<blockquote>
<p>My aim is to foster understanding and empathy between contributors, community members, users, and maintainers. I would also like for maintainers and leaders in Open Source to feel a sense of solidarity in their shared burden.</p>
</blockquote>
<p>It is often said that Open Source Software is not sustainable, because it has no inherent business model, but I believe there are other pressures that leaders experience which when left unchecked may lead to "burn-out".</p>
<p>I'll briefly describe what I believe leadership means before introducing each of the pressures and how they may be experienced. It's my opinion that the examples apply beyond Open Source Software and the technology industry. I will then sum up the pressures and make a case for sustainable leadership.</p>
<p>As a disclaimer, I've generalised my experience and what I've shared here. I am not referring to any one person, even if you can identify with what I'm saying.</p>
<h2 id="whatisleadership">What is leadership?</h2>
<p>The Oxford English Dictionary defines leadership as a noun:</p>
<ul>
<li>
<p>the action of leading a group of people or an organization.</p>
<p>Synonymns: guidance, direction, authority, control, management, superintendence, supervision; organization, government, orchestration, initiative, influence</p>
</li>
<li>
<p>the state or position of being a leader.</p>
<p>Synonymns: headship, directorship, direction, governorship, governance, administration, jurisdiction, captaincy, superintendency, control, ascendancy, rule, command, power, mastery, domination, dominion, premiership, sovereignty</p>
</li>
</ul>
<p>It is clear from the sheer amount of synonymns for the term, that the word itself can have many meanings and nauances. I would also suggest that the our own experiences and culture may project specific expectations and connotations.</p>
<p>For some Open Source maintainers, leadership may start unintentionally. A developer may become inspired to build an idea into a project and by default is the director and administrator. All of the control rests with them and at this stage the project is likely to be classed as be a Proof of Concept (PoC), an experiment or a "side-project." Other people are unlikely to be involved, but that may change quickly. The maintainer is the de factor leader in their team of one.</p>
<p>Some projects remain in this state, but others may draw in users and contributors who in turn volunteer their time, ideas, and energy to advance the project. The maintainer must now set a direction, communicate it, and begin to decide how to govern the project. For me mirroring the style of other maintainers and leaders I knew helped significantly. In my experience these skills can be learned "on the job", but it's easy to get things wrong.</p>
<p>In most companies there are two tracks for a career - either as an individual contributor or as a people-manager. Individual Contributors tend to be builders of things and have very technical work. They may also lead a team or hold responsibility depending on their level of seniority. <a href="https://www.amazon.co.uk/Managing-Humans-Humorous-Software-Engineering/dp/1430243147">People managers have a very different set of skills</a> and deliver results for the business through delegation and by constantly communicating across teams.</p>
<p>In a corporation you are likely to have a very clearly defined role and hierarchy to fall into, but as an Open Source leader and maintainer your work will be a mixture of the two tracks.</p>
<p>This is an apt time to introduce the first pressure: unclear boundaries.</p>
<h2 id="1unclearboundaries">1. Unclear boundaries</h2>
<p>What is your role? What does it say on LinkedIn, and on your business cards? Does that differ from what you actually do on a day to day basis? Do you work 1 in 3 weekends? Are you on rotation for on-call duties? Do you have reports?</p>
<p>As a leader of a community and an Open Source project, there is no job description and there are no set hours. One of the synomymns for leadership is governance, and that can cover how you and the project operate. I started to define a model for governance with a "Contributing Guide" which explains the process for raising an issue or requesting a change.</p>
<p>People who come to the project now look to me and the other primary contributors to operate within that governance model and for that reason it is important to do so. Some may not be aware of the processes and some even chose to ignore them. I believe that leaders need to be flexible, but if they say one thing and to do another continually, then it sets a confusing example for others to follow.</p>
<p>When I began I enjoyed the interest in my projects from users and contributors from all around the world. People would contact me at all hours of the day and night and I wanted to reply to every notification and email within minutes, if I could. I quickly found that I wouldn't be able to keep that up.</p>
<p>Having no clear hours means that unless you are careful, that you are actually on-call 27/4, 365 days, even when you're on vacation.</p>
<p>If left unchecked then unclear boundaries can lead to an intermingling of the leader's self with the project and team. I believe that this is understandable given the investment and stake the leader has, but gaining validation and self-worth through the success or failure, growth rate or decline of something outside of their control is a recipe for burning out.</p>
<p>Rather than being able to celebrate past achivements, the leader may start to feel pressure to grow the project to compete with similar product offerings. Those products may be built by companies with well-staffed teams and 7-figure budget, so it is not unly unatainable, but unfair.</p>
<p>The pressure of unclear boundaries means that users and other contributors may bring unreasonable expectations to your door and you may feel obliged to do what is asked of you.</p>
<h2 id="2pay">2. Pay</h2>
<p>Whilst the curve for leadership positions within a corporation inflects up steeply, this is simply a different matter in Open Source and those involved in other types of public service.</p>
<p>In my opinion there is no clear business model for Open Source Software, which means there is also no reason for someone to pay me for maintaining or building that software. A friend recently explained this to me in terms of "value capture", which I found immensely useful.</p>
<p>OSS allows companies and other OSS projects to stand on the tall shoulders of those that came before, and to either enhance or to put a new spin on prior work. That means capturing and amplifying existing value for something new.</p>
<p>In the same way that I cannot and will not be able to afford to pay the Golang development team for their many years of efforts that I leverage in my work. It seems equally unlikely that an end-user company will be able to pay me for the value I have created for them, that they capture and amplified in their business.</p>
<blockquote>
<p>It is liberating to remove the unrealistic and unreasonable expectation that end-user companies should pay us for our work.</p>
</blockquote>
<p>Given that maintaining and building features for OSS can take a significant amount of time, this leaves maintainers with only a few options. Such as the following:</p>
<ul>
<li>Work full-time for a company, and overtime for the OSS project in your evenings and weekends</li>
<li>Work part-time consulting through your own company, and part-time without pay for your OSS project</li>
<li>Find a co-founder, seek out investment, and build a commercial product from the project</li>
<li>Don't earn a salary at all, and work for full-time without pay on the OSS project</li>
<li>Close the OSS project, or pass the mantle on to someone else</li>
</ul>
<p>There are some exceptions where developers are recruited and paid to work on Open Source projects for a variety of reasons. This is much different than a maintainer being hired specifically to maintain and build the project they lead.</p>
<p>You will also note that I did not include <a href="https://github.com/users/alexellis/sponsorship">"sponsorship" as an option</a>, this is because in my experience sponsorship is a hard sell and difficult to do meaningfully. I currently view sponsorship as a top-up mechanism to part-time consulting, rather than as a means to an end.</p>
<p>Whichever option a maintainer picks, there will always be a significant amount of money left on the table. This is a pressure that can build over time, especially when compared to peers working for a company.</p>
<h2 id="3workingwithvolunteers">3. Working with volunteers</h2>
<p>Has anyone ever asked you to do them a favour?</p>
<p>It may be something as simple as getting a latte for a colleague on your coffee run, helping your neighbour move house, giving your wife a lift to work because her car is in at the mechanic's, reaching into your pocket to give change to someone on the street, going bowling for a work outing, or even setting up a new printer for a relative.</p>
<p>How did you feel about the ask? "It depends" you say. It depends on the relationship, how much it inconveniences you, and what you may get back in return. I know that if it's my turn to buy dinner, next time I meet my friend, he will be paying.</p>
<p>With the example of taking my wife to work, it's highly unlikely that I'd flake. I can't think of anything I'd rather do less than setting up a relative's printer and I would easily change my mind about the work bowling trip.</p>
<p>I believe that when leading an Open Source project or a community, that volunteers are essential to its success. As a maintainer, your pay is already below par and funding is unlikely to be bountiful. So relying on goodwill, favours, and external contributions become ever more important as the project grows. Not to mention that to grow and extend the impact of your project, you will need to delegate responsibility and duties to other people.</p>
<p>Other leaders will be quick to tell you to "just delegate". In my experience delegation is key to growing a community and for motivating others to act not only in their own interest, but for the common good.</p>
<p>If a maintainer starts a project on their own, then it may be hard …</p></div></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.alexellis.io/the-5-pressures-of-leadership/">https://blog.alexellis.io/the-5-pressures-of-leadership/</a></em></p>]]>
            </description>
            <link>https://blog.alexellis.io/the-5-pressures-of-leadership/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25677766</guid>
            <pubDate>Thu, 07 Jan 2021 21:28:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[iPhone 12 magnets deactivating implanted defibrillators in cardiac patients]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 8 (<a href="https://news.ycombinator.com/item?id=25677717">thread link</a>) | @efunkem
<br/>
January 7, 2021 | http://www.medmalreviewer.com/does-the-iphone-12-deactivate-implantable-cardioverter-defibrillators/ | <a href="https://web.archive.org/web/*/http://www.medmalreviewer.com/does-the-iphone-12-deactivate-implantable-cardioverter-defibrillators/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<div data-elementor-type="wp-post" data-elementor-id="3642" data-elementor-settings="[]">
						<div>
							<div>
							<section data-id="d29a4f4" data-element_type="section">
						<div>
							<div>
					
				<div data-id="d4df9de" data-element_type="column">
			<div>
							<div>
						<div data-id="82f4b7d" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>An interesting article came out <a href="https://www.heartrhythmjournal.com/article/S1547-5271(20)31227-3/fulltext?fbclid=IwAR3DokV5V8f8G-LYlKwXFDjdIE5Jf9w4B5KAgpv0vRJ8P2--ZvOfyQO802k">a few days ago in Heart Rhythm</a>, raising concern that new hardware in the iPhone 12 may deactivate implanted cardioverter defibrillators (ICDs).&nbsp;</p>
<p>In short, the concern is that an array of magnets in the phone may turn off the life-saving function of these cardiac devices.</p>
<p>This “MagSafe” technology was already used elsewhere, but this is the first time it has been incorporated into an iPhone.</p>
<p>Nearly all ICDs will stop shocking a patient when placed near a sufficiently strong magnet.&nbsp;</p>
<p>Pacemakers exposed to a magnet are set to a pre-programmed mode that varies by manufacturer, usually with a rate of 65-80bpm.&nbsp;</p>
<p>Ask any Emergency Medicine physician and they will be able to point you to a blue circular magnet used for this exact purpose.&nbsp;</p></div>
				</div>
				</div>
						</div>
					</div>
		</div>
				
								</div>
					</div>
		</section>
				<section data-id="50b654d" data-element_type="section">
						<div>
							<div>
					
				<div data-id="7506540" data-element_type="column">
			<div>
							<div>
						<div data-id="074d5bd" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><img width="800" height="812" src="http://www.medmalreviewer.com/wp-content/uploads/2021/01/Magnet.jpg" alt="" loading="lazy" srcset="http://www.medmalreviewer.com/wp-content/uploads/2021/01/Magnet.jpg 819w, http://www.medmalreviewer.com/wp-content/uploads/2021/01/Magnet-296x300.jpg 296w, http://www.medmalreviewer.com/wp-content/uploads/2021/01/Magnet-768x779.jpg 768w, http://www.medmalreviewer.com/wp-content/uploads/2021/01/Magnet-500x507.jpg 500w, http://www.medmalreviewer.com/wp-content/uploads/2021/01/Magnet-800x812.jpg 800w" sizes="(max-width: 800px) 100vw, 800px">											</p>
				</div>
				</div>
						</div>
					</div>
		</div>
				
								</div>
					</div>
		</section>
				<section data-id="a778930" data-element_type="section">
						<div>
							<div>
					
				<div data-id="c5b38f5" data-element_type="column">
			<div>
							<div>
						<div data-id="7ba4163" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>A patient with a malfunctioning pacemaker or defibrillator may be suffering numerous inappropriate shocks. The magnet comes in very handy in these situations.</p>
<p>However, a patient that goes into ventricular tachycardia (among other life-threatening cardiac rhythms) will need their device to work appropriately, delivering a shock to save their life.</p>
<p>If this issue is reproduceable in other patients, an iPhone 12 carried in a front shirt pocket has the chance to inactivate the device and block life-saving electrical therapy.&nbsp;</p>
<p>The authors demonstrated this (<a href="https://www.heartrhythmjournal.com/article/S1547-5271(20)31227-3/fulltext?fbclid=IwAR3DokV5V8f8G-LYlKwXFDjdIE5Jf9w4B5KAgpv0vRJ8P2--ZvOfyQO802k">picture from their publication</a>) using an iPhone 12 on a real patient with an ICD:</p>
</div>
				</div>
				</div>
						</div>
					</div>
		</div>
				
								</div>
					</div>
		</section>
				<section data-id="c205503" data-element_type="section">
						<div>
							<div>
					
				<div data-id="253ec3d" data-element_type="column">
			<div>
							<div>
						<div data-id="e92e1ac" data-element_type="widget" data-widget_type="image.default">
				<div>
					<div>
							<figure>
										<img width="499" height="556" src="http://www.medmalreviewer.com/wp-content/uploads/2021/01/gr1_lrg-1.jpg" alt="" loading="lazy" srcset="http://www.medmalreviewer.com/wp-content/uploads/2021/01/gr1_lrg-1.jpg 499w, http://www.medmalreviewer.com/wp-content/uploads/2021/01/gr1_lrg-1-269x300.jpg 269w" sizes="(max-width: 499px) 100vw, 499px">											<figcaption></figcaption>
										</figure>
					</div>
				</div>
				</div>
						</div>
					</div>
		</div>
				
								</div>
					</div>
		</section>
				<section data-id="6a3c0ef" data-element_type="section">
						<div>
							<div>
					
				<div data-id="9263bf4" data-element_type="column">
			<div>
							<div>
						<div data-id="e311c1c" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>Green arrow: iPhone 12 placed over ICD<br>Red arrow: Interrogation device – “SUSPENDED: Magnet Present”<br>Yellow arrow: Magnetic ring in iPhone 12</p>
				</div>
				</div>
						</div>
					</div>
		</div>
				
								</div>
					</div>
		</section>
				<section data-id="5370fb2" data-element_type="section">
						
		</section>
				<section data-id="2bfc3bb" data-element_type="section">
						
		</section>
				<section data-id="7669176" data-element_type="section">
						<div>
							<div>
					
				<div data-id="58dae32" data-element_type="column">
			<div>
							<div>
						<div data-id="c785851" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><img width="800" height="666" src="http://www.medmalreviewer.com/wp-content/uploads/2021/01/Breakdown-Phone.jpg" alt="" loading="lazy" srcset="http://www.medmalreviewer.com/wp-content/uploads/2021/01/Breakdown-Phone.jpg 829w, http://www.medmalreviewer.com/wp-content/uploads/2021/01/Breakdown-Phone-300x250.jpg 300w, http://www.medmalreviewer.com/wp-content/uploads/2021/01/Breakdown-Phone-768x639.jpg 768w, http://www.medmalreviewer.com/wp-content/uploads/2021/01/Breakdown-Phone-500x416.jpg 500w, http://www.medmalreviewer.com/wp-content/uploads/2021/01/Breakdown-Phone-800x666.jpg 800w" sizes="(max-width: 800px) 100vw, 800px">											</p>
				</div>
				</div>
						</div>
					</div>
		</div>
				
								</div>
					</div>
		</section>
				<section data-id="a783810" data-element_type="section">
						<div>
							<div>
					
				<div data-id="5a8a0ce" data-element_type="column">
			<div>
							<div>
						<div data-id="f5d8fdd" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>Notice the similar circular layout between the iPhone and the standard blue medical magnet.</p>
<p>Physicians should be aware of this issue. While there is no active litigation related to this, it is a very high risk situation.&nbsp;<span>&nbsp;</span></p></div>
				</div>
				</div>
						</div>
					</div>
		</div>
				
								</div>
					</div>
		</section>
				<section data-id="fa63cd5" data-element_type="section">
						
		</section>
				<section data-id="a87a621" data-element_type="section">
						<div>
							<div>
					
				<div data-id="2b0d0b5" data-element_type="column">
			<div>
							<div>
						<div data-id="bff2ed2" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>MedMalReviewer Opinion:</p>
<p>1. This is unlikely to result in medical malpractice litigation against any individual physician. However, it does place the manufacturer at risk for product liability.&nbsp;</p>
<p>2. ED physicians should keep this in mind for patients with out-of-hospital cardiac arrest. These patients should be completely exposed during the code, removing all clothing and foreign objects.&nbsp;</p>
<p>3. For patients with pacemakers, consider that any unusual or unexplained symptoms could have been explained by a transient switch in pacemaker mode while their phone was nearby. Interrogating the pacemaker will help shed light on this.</p></div>
				</div>
				</div>
						</div>
					</div>
		</div>
				
								</div>
					</div>
		</section>
				<section data-id="3d300b0" data-element_type="section">
						
		</section>
				<section data-id="508993e" data-element_type="section">
						<div>
							<div>
					
				<div data-id="86adb72" data-element_type="column">
			<div>
							<div>
						<div data-id="63012ba" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>Check out these real-life medical malpractice cases:</p>
<p><a href="http://www.medmalreviewer.com/case-13-cervical-fusion/">Case 13: Cervical Fusion</a> – A patient suffers an unexpected cardiac arrest during a neck surgery.&nbsp;</p>
<p><a href="http://www.medmalreviewer.com/case-15-ski-accident/">Case 15: Ski Accident</a> – A patient on blood thinners crashes and hits her head while skiing.</p></div>
				</div>
				</div>
						</div>
					</div>
		</div>
				
								</div>
					</div>
		</section>
				<section data-id="207a1e5" data-element_type="section">
						
		</section>
				<section data-id="c177169" data-element_type="section">
						<div>
							<div>
					
				<div data-id="e09ce0e" data-element_type="column">
			<div>
							<div>
						<div data-id="5227a13" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>Read expert witness opinions from malpractice lawsuits:</p>
<p><a href="https://expertwitness.substack.com/p/expert-witness-case-34">Expert Witness Case #34</a>&nbsp;– Urologist accidentally ligates artery instead of vas deferens during vasectomy. Patient loses testicle.</p>
<p><a href="https://expertwitness.substack.com/p/expert-witness-case-32">Expert Witness Case #32</a>&nbsp;– Patient admitted with DKA develops severe leg pain. Long delays in care result in amputation.</p></div>
				</div>
				</div>
						</div>
					</div>
		</div>
				
								</div>
					</div>
		</section>
				<section data-id="5586f05" data-element_type="section">
						
		</section>
						</div>
						</div>
					</div>
				
			</div></div>]]>
            </description>
            <link>http://www.medmalreviewer.com/does-the-iphone-12-deactivate-implantable-cardioverter-defibrillators/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25677717</guid>
            <pubDate>Thu, 07 Jan 2021 21:24:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What React Gets Wrong]]>
            </title>
            <description>
<![CDATA[
Score 31 | Comments 67 (<a href="https://news.ycombinator.com/item?id=25677648">thread link</a>) | @jehna1
<br/>
January 7, 2021 | https://thejunkland.com/blog/what-react-gets-wrong.html | <a href="https://web.archive.org/web/*/https://thejunkland.com/blog/what-react-gets-wrong.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><p>React is the de-facto tool for frontend web development. It has a rich ecosystem and a well-known company to back it up. Despite all of this, I think they still get a ton of stuff wrong. This post is about my personal views and things I think React is already a too slow-moving giant to fix.</p><h2 id="the-syntax">The syntax</h2><p>React has such an awful API that they needed to create a whole new programming language syntax to overcome it: The <code>React.createElement</code> API. Most of the time it's hidden behind JSX that's transpiled onto <code>React.createElement</code> calls.</p><p>You either only ever write JSX when working with React, or you get frustrated with the amount of clutter that gets to your codebase from all that repetition that provides no value to the reader.</p><pre><code>Reat.createElement(<span>'html'</span>, <span>null</span>,
  React.createElement(<span>'body'</span>, <span>null</span>,
    React.createElement(<span>'div'</span>, <span>null</span>,
      React.createElement(...)
    )
  )
)
</code></pre><p>I think a much better way is to follow what SwiftUI and Flutter are doing: Move the element's name from argument to be the function's name:</p><pre><code>html(
  body(
    div(...)
  )
)
</code></pre><p>This does not only remove unnecessary clutter, but removes the need for any compilation step.</p><h2 id="create-react-app">create-react-app</h2><p>Next up us a monstrosity that's nowadays accepted by many to be a "best practice" for getting started with a React project. The problem being, that React ecosystem is such a complex beast that they created a bootstrap project so you can get anything done in a meaningful time. Just pray that you don't need to eject it any time soon.</p><p>Just to give you an idea of the absurdness of this situation: create-react-app creates a "hello world" project for you that downloads <strong>2.5 million lines of Javascript code</strong> to your machine. For a hello world app.</p><p>I have strong feelings about fighting complexity by adding more complexity, and this sure smells like something you should not be doing in 2021.</p><p>Instead we should be thinking about where our browsers and server ecosystems are nowadays and if we could make the bootstrapping <em>simpler</em>. Browsers <a href="https://caniuse.com/es6-module">know how to handle imports nowadays</a>, and the module format is <a href="https://nodejs.org/api/esm.html">also part of Node.js</a> without any preprocessing, so you don't necessarily need a build step to get those working.</p><p>Modern browsers are really good with on-the-fly compression like gzip <a href="https://caniuse.com/brotli">and even brotli</a>, so minification is not so much of an issue. Your CDN should anyways be optimizing compression of your static assets.</p><p>Another point being that React is over 100kb when minified (including React DOM because you can't do that much without it). Imagine how much unminified code you could fit in 100kb if you used something that doesn't need to be built at all.</p><h2 id="react-is-not-just-a-view-rendering-library-anymore">React is not just a view rendering library anymore</h2><p>React used to be only a good frontend rendering library with JSX. Nowadays you're signing up for a framework with its own plugin ecosystem, hooks, fibers, suspense, and other obscure future features like <a href="https://reactjs.org/blog/2020/12/21/data-fetching-with-react-server-components.html">server components</a>.</p><p>We've changed from doing <em>model-view-controller</em> to using all-consuming views that perform both business logic and create side effects. Views have become the top-level entity that controls everything else.</p><p>Remember the old saying "UI is a function of state"? React used to be a good implementation of this, but nowadays it's more of "UI that handles your state".</p><p>I think a good view rendering library should do just one thing well: Render the UI based on the app's state. It should not care where the state is, and most importantly it should not handle the state itself. Otherwise we'll end up with things like bloated class components or <em>"suddenly global state and black magic is fine"</em> type of hooks inside otherwise pure functions.</p><p>Instead you should be handling your business logic, side effects and data gathering some place else, and use proper separation of concerns to model your application's logic.</p><h2 id="imagine-a-better-world">Imagine a better world</h2><p>So how would a better React alternative look in 2021? I made a small prototype library called <a href="https://www.npmjs.com/package/longwood">Longwood</a> based on above principles, and a hello world looks like this:</p><pre><code><span>&lt;<span>html</span>&gt;</span>
  <span>&lt;<span>body</span>&gt;</span>
    <span>&lt;<span>div</span> <span>id</span>=<span>"app"</span>&gt;</span><span>&lt;/<span>div</span>&gt;</span>
    <span>&lt;<span>script</span> <span>type</span>=<span>"module"</span>&gt;</span><span>
      <span>import</span> { div, text } <span>from</span> <span>'https://cdn.skypack.dev/longwood'</span>

      <span>const</span> render = div(text(<span>'Hello world!'</span>))
      render(<span>document</span>.getElementById(<span>'app'</span>))
    </span><span>&lt;/<span>script</span>&gt;</span>
  <span>&lt;/<span>body</span>&gt;</span>
<span>&lt;/<span>html</span>&gt;</span>
</code></pre><p><a href="https://codesandbox.io/s/unruffled-star-xs16e?file=/index.html">▶️ Try it out at CodeSandbox.io</a></p><p>That's all the code you need. No precompilation, no build steps, no downloading of 2.5 million lines of code to get started. You can open a text editor, save the code as an <code>index.html</code> file, open it in a browser and it works.</p><p>You have the same power of Javascript to compose your views as with React, and there's a <a href="https://www.npmjs.com/package/longwood-usestate">separate state management library</a> to get started if you're coming from React. But moreover <em>it's okay to handle your state however you want</em>. It's just a rendering library. It can be used for just a small portion of your site if you want. It even supports server-side rendering out of the box (with jsdom).</p><p>Since you're going to ask, here are a couple of examples:</p><ul><li><a href="https://codesandbox.io/s/competent-swartz-beoub?file=/src/TodoComponent.ts">React style Todo app</a></li><li><a href="https://links.thejunkland.com/">Rendering 1000+ rows of data with Longwood</a><ul><li><a href="https://links.thejunkland.com/react/">Same example done with create-react-app</a></li></ul></li></ul><h2 id="to-wrap-up">To wrap up</h2><p>We’ve come a long way since the web 2.0 times. jQuery made the world a better place by making DOM manipulation easier. AngularJS made the world a better place by introducing data binding to the masses. But all great increments seem to fade at some point to welcome better alternatives.</p><p>Will the future be bright for Longwood? I have no idea, it’s a single-person project and at the moment has one production site running on it. But I hope it demonstrates a point that we can do things even better in the future if we keep innovating and cherry-picking the good stuff from others.</p><p>Happy hacking.</p><p><a href="https://twitter.com/intent/tweet?text=%22What%20React%20gets%20wrong%22%20by%20@luotojesse%20https://thejunkland.com/blog/what-react-gets-wrong.html" target="_blank" rel="noopener">Tweet</a></p></article></div></div>]]>
            </description>
            <link>https://thejunkland.com/blog/what-react-gets-wrong.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25677648</guid>
            <pubDate>Thu, 07 Jan 2021 21:19:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Real Problems with Functional Languages]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25677402">thread link</a>) | @wingspan
<br/>
January 7, 2021 | https://blog.darklang.com/real-problems-with-functional-languages/ | <a href="https://web.archive.org/web/*/https://blog.darklang.com/real-problems-with-functional-languages/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


            <section>
                <div>
                    <h2 id="and-their-influence-on-dark">And their influence on Dark</h2><p><br>After two decades of coding professionally in a dozen languages, I’ve come to a conclusion about static and dynamic types:</p><ul><li>Static types help you ensure that your changes work, especially for changes that span large parts of the program. This leads to long-term productivity gains from reduction in errors, as well as code that works better.</li><li>The lack of static types in dynamic languages allows you to prototype quicker and iterate faster. It also makes your code more readable.</li></ul><p>The result is a productivity quagmire. Static languages bring the cost of type-safety to every line of code that is written, slowing development of new features and concepts. Dynamic languages’ lack of type safety produces significant costs down the line, eating the productivity benefit of the early quick prototyping.</p><p>In Dark, we want the advantages of both. We want to take a type-safe core with long-term productivity gains and risk-reduction, and use tooling to enable the quick prototyping and readable code that you get from dynamic languages.</p><p><a href="https://medium.com/darklang/the-design-of-dark-59f5d38e52d2" rel="noopener">Dark</a> has a number of features that are different from regular programming languages. A quick intro:</p><ul><li>Dark’s goal is to remove accidental complexity from coding. We want you to write backend services quickly and safely, with little to no overhead.</li><li>Dark is for building backends — you typically write HTTP handlers and we handle the deployment and infrastructure.</li><li>Dark combines an editor, language and infrastructure, and we use the tight integration to overcome common limitations in programming languages.</li><li>Dark doesn’t have a compilation step or separate compiler/interpreter. Instead, the editor updates with errors and warnings as you type (it also prevents syntax errors and some type errors).</li><li>Dark is designed for continuous delivery — the practice of frequently making small, low-risk changes. Code that you write is deployed to “production” (typically behind a feature flag) immediately after being written.</li></ul><p>Statically-typed functional languages (hereafter FPs, with apologies to Lispers) are amazing. They have a property that exists almost nowhere else: once it compiles, it usually works first try. We obviously want this property in Dark, so we made Dark a statically-typed functional language.</p><p><em><em>(If you’re already very familiar with statically-typed functional languages, you can </em></em><a href="https://medium.com/darklang/real-problems-with-functional-languages-efe668c5264a" rel="noopener"><em><em>skip this section</em></em></a><em><em> without missing much.)</em></em></p><h2 id="type-safety">Type safety</h2><p>In FPs, the compiler checks if all the types line up, and if you’ve handled every possible edge case about your type. When you make a change, the compiler tells you every single place you need to change, which you need to figure out for yourself in dynamic languages. Importantly, that safety comes for free — you don’t have to write millions of unit tests to get it. The result is that small changes across large scale systems are pretty risk free. You can still get the logic wrong, but the plumbing is guaranteed to behave as expected.</p><h2 id="nulls">Nulls</h2><p>In almost every non-FP language, including Java, C, C++, Go, Python, Ruby, PHP, Erlang, Javascript, Clojure, Scala, SQL, C#, and Objective-C, any value can be null, and it can be extremely challenging to reason about whether a particular variable is or isn’t null in practice. Nulls cause program crashes when functions and methods are called on them, when they are indexed, and when their fields are accessed.</p><pre><code>function leadPlayer(players) {
  if (players.length &lt;= 0)
    return null;
  return players[0];
}
function chooseCaptain(players) {
  // throw a NullPointerException if the `players` list is empty.
  leadPlayer(players).setCaptain(true);
}</code></pre><p>In the Java/Javascript-ish code above, the type system doesn’t protect against the NullPointerException when we expected an object but get a null.</p><p>FPs replace nulls with an Option type (called <a href="https://guide.elm-lang.org/error_handling/maybe.html" rel="noopener nofollow">Maybe in Elm</a> and <a href="https://wiki.haskell.org/Maybe" rel="noopener nofollow">Haskell</a>, <a href="https://learning-rust.github.io/docs/e3.option_and_result.html" rel="noopener nofollow">Option in Rust</a>, <a href="https://danielwestheide.com/blog/2012/12/19/the-neophytes-guide-to-scala-part-5-the-option-type.html" rel="noopener nofollow">Scala</a>, and <a href="https://dev.realworldocaml.org/guided-tour.html#scrollNav-3-3" rel="noopener nofollow">OCaml</a>/<a href="https://fsharpforfunandprofit.com/posts/the-option-type/" rel="noopener nofollow">F#</a>, and <a href="https://hackernoon.com/swift-optionals-explained-simply-e109a4297298" rel="noopener nofollow">Optional in Swift</a>). The Option type encodes in the type system that a value can be null. If the value is not an Option, then it cannot be null.</p><p>Every time you have an Option, the compiler requires you to handle both potential cases: if it is a real value, or if it’s not. Since the compiler won’t let you access a field or index or call a method on a null value, that entire class of errors is removed.</p><pre><code>function leadPlayer(players) {
  match players with
  | [] -&gt;
    return Nothing
  | head :: rest -&gt; // an array with 1 or more elements
    return (Just head)
}
function chooseCaptain(players) {
  match leadPlayer(players) with
  | Just player -&gt;
      player.setCaptain(true); // we know this can't be null
  | Nothing -&gt;
      // don't throw an exception
}</code></pre><p>As we can see, the FP version of the same code requires the <code>null</code> (called <code>Nothing</code> in our examples) to be handled.</p><h2 id="exceptions">Exceptions</h2><p>Similarly, in most languages, any operation can cause an exception. Even Java with its checked exceptions has a category of exceptions (RuntimeExceptions) that can happen anywhere, including the beloved <code>NullPointerException</code>. Exceptions are so pervasive that it’s basically impossible to have a single line of code that is known to be exception-free — and even if it is, you won’t have a compiler to tell you that.</p><p>Here’s an example of some simple Python code that will throw an exception if <code>a</code>or <code>b</code>are strings which are not valid ints:</p><pre><code>sum = int(a) + int(b);</code></pre><p>FPs commonly use a Result type instead of exceptions (or C/Go error codes). A Result is a value which is either a valid value or an error. Like the Option type, the compiler sees every Result and requires you to handle the potential error, knowing that you cannot do your regular type operations on an error.</p><p>Here’s the same in an Elm-like language with result types. As you can see, this requires you to handle both the errors of <code>a</code>and <code>b</code>.</p><pre><code>match String.toInt a, String.toInt b with
| Ok a, Ok b -&gt;
    sum = a + b
| _ -&gt;
    Debug.log(“Error parsing integers);
    sum = 0</code></pre><p>By removing both nulls and exceptions, FPs remove a huge set of possible errors, and allow developers the safety of knowing that their programs work. Most importantly, that knowledge comes from automatic tooling, not manually writing test cases.</p><h2 id="implementation-in-dark">Implementation in Dark</h2><p>Dark takes influence from FPs, and Dark programs are fully type-checked. Dark’s type system allows us to find everywhere that a change needs to propagate, and tells you whether your types line up or not.</p><p>We also use Results and Options instead of exceptions and nulls, to avoid all the problems that come from those language features.</p><p>Unfortunately, these benefits come with significant frustrations and downsides, which current functional languages have — in our opinion — poor solutions for.</p><h2 id="type-checking-in-dark">Type checking in Dark</h2><p>In most FP compilers, your whole program either compiles or it doesn’t, making it difficult to make small scale changes. If I’m programming in Python, and I want to test out a quick hacky change in some component, I can do that immediately to discover whether the hack will even solve my problem.</p><p>Not so in FP. If I change a type in a FP, it might take me an hour to change every use of that type so that my program can even compile. And that’s assuming I’m stubbing out any logic that I don’t want to handle just yet. There’s little I find more frustrating than discovering in step 2 that the type changes I diligently propagated in step 1 were wrong and that I wasted the last hour.</p><p>Dark is designed for continuous delivery. As such, we don’t like requiring you to make large scale changes across your program, like changing a type everywhere. Instead, we want you to quickly discover that bad ideas won’t work, without first requiring you to propagate the type changes throughout your program.</p><p>Dark has a deliberately small compilation unit (the amount of code which is compiled together, and therefore which must be type checked together). You can make changes in a single HTTP route without having to make it type check with the rest of your program. This lowers the amount of type changes that you need to make to test out a single change.</p><p>The way this works is that you don’t actually change types in Dark. Instead, you make a copy of the type, and make your changes on that new copy. This allows you to prototype with the new type and test your change easily, making cheap iterations (and new types) as you try out new ideas. Once you are confident in your new type, you replace the uses of the old type (with semi-automated tooling to handle all the changes, including changes that are way down the call-stack).</p><p>As a result, you get the benefits of type checking, along with the benefits of cheap prototyping and quick iteration.</p><h2 id="option-result-types-in-dark">Option/Result types in Dark</h2><p>If I want to use a value wrapped in an Option or Result, I must first unwrap it, and then handle the failure case. This ensures that my code handles all errors and edge cases, but also adds costs to prototyping and iteration. If I want to make a quick hack in Python or Javascript, I can ignore nulls and errors on the first pass as I prototype and develop my algorithm. Not so with static types — in fact, often I’m forced to do low-level restructuring of my code to handle Options and Results.</p><p>Consider the code I have to add to my prototype in our Elm-like example:</p><pre><code>match String.toInt a, String.toInt b with
| Ok a, Ok b -&gt;
  sum = a + b
| _ -&gt;
  Debug.log(“Error parsing integers);
  sum = 0</code></pre><p>The Python code was significantly faster to write (though it has bugs that we want to ignore during our prototype).</p><p>Dark uses a concept from <a href="https://fsharpforfunandprofit.com/" rel="noopener nofollow">Scott Wlaschin</a> called “<a href="https://fsharpforfunandprofit.com/rop/" rel="noopener nofollow">Railway Oriented Programming</a>” to reduce this complexity. ROP is a metaphor where the error values of Results and Options form an alternate execution path through the program, called an Error Rail. When an error happens, the execution in the main body stops and instead passes over to the Error Rail.</p><p>Dark takes the ROP metaphor and makes a literal version of it in our editor. If you call a function in Dark that returns a <code>Nothing</code>(the name of the null-ish value of our Option type), …</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.darklang.com/real-problems-with-functional-languages/">https://blog.darklang.com/real-problems-with-functional-languages/</a></em></p>]]>
            </description>
            <link>https://blog.darklang.com/real-problems-with-functional-languages/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25677402</guid>
            <pubDate>Thu, 07 Jan 2021 21:01:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Open Letter to the Communications of the ACM]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25677275">thread link</a>) | @gnarbarian
<br/>
January 7, 2021 | https://researchers.one/articles/20.12.00004 | <a href="https://web.archive.org/web/*/https://researchers.one/articles/20.12.00004">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://researchers.one/articles/20.12.00004</link>
            <guid isPermaLink="false">hacker-news-small-sites-25677275</guid>
            <pubDate>Thu, 07 Jan 2021 20:50:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Simple Password Framework: Strong Passwords, Easy to Remember]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25677255">thread link</a>) | @300
<br/>
January 7, 2021 | https://jovica.org/posts/the_password_framework/ | <a href="https://web.archive.org/web/*/https://jovica.org/posts/the_password_framework/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <header>
    
  </header>
  <small>
      

  </small>
  

  <p>We all need to use passwords. Everyone should use password managers. Most of
us don’t. This guide will give you the framework to create many strong passwords
which are easy to remember.</p>

<p><strong>## Step #1: The Base password</strong></p>
<p>First you need a base password.</p>
<p>Think of 3 of your favorite things. Choose something positive.<br>
For example, I like to read, eat pizza and listen to Nick Cave.<br>
So that gives me: <code>KindlePizzaCave</code></p>
<p>Now separate each word with your favorite special character.
Let’s say I like money, so I’ll use that for this example. And I get: <code>Kindle$Pizza$Cave$</code></p>
<p>Now add a familiar number which you’ll always remember.<br>
Your postal code, birth year or something similar.<br>
Whatever it is, just remember that <strong>method</strong>.</p>
<p>For example, if my postal code would be 113355, I could use that, and get: <code>Kindle$Pizza$Cave113355</code></p>
<p>This easy method gives you a pretty long password.
It also satisfies all of the requirements of a strong password: stuff like upper and lower case characters, numbers, special characters, etc.</p>
<p>And you get all of this without even thinking about it really.<br>
This can be your BASE password. It a pretty strong password.</p>
<p>Now, the worst thing you could do is to use this awesome password for all of your accounts.
Just trust me, and don’t do that.</p>
<p>There’s a better solution.</p>

<p><strong>## Step 2: Self explanatory passwords</strong></p>
<p>So let’s say, I use a password <code>Kindle$Pizza$Cave113355</code> for my primary email account. That’s easy to remember. I use it only there, and that’s it.</p>
<p>Now, you can make your strong password unique with a special identifier for each of your accounts.
It sounds complicated, it’s not really.</p>
<p>For example, I use Twitter. I could use <code>TW</code> or something like that. I can add it at the beginning, end or even split it up. So, my password for Twitter could be: <code>TW$Kindle$Pizza$Cave113355</code></p>
<p>For Facebook, I could have: <code>Fb$Kindle$Pizza$Cave113355</code></p>
<p>You’re really just typing things you like, and remembering a method you chose.</p>

<p><strong>## Step 3: Time to change passwords?</strong></p>
<p>Most of the cybersecurity professionals will tell you that updating your passwords regularly is a good practice. Well, that’s not really true anymore.
But that’s a topic for another post.</p>
<p>So, whether you’re forced to change your passwords at work, or you just think it’s time for you to update your passwords, this framework makes it very easy.</p>
<p>All you need to do is to change your <strong>method</strong>.
So, for example, if I’d be really lazy, I could just shift things around, and from my old password for Twitter <code>TW$Kindle$Pizza$Cave113355</code> get to new one: <code>113355$Kindle$Pizza$Cave$TW</code>.</p>
<p>And that’s usually good enough.</p>
<p>But it’s recommended that you change the key words of your password.
You can use your favorite quote, or pretty much anything easy for you to remember.
Then just follow the same method.</p>

<p><strong>## Further steps</strong></p>
<p>You might wonder, “what if an attacker gets my password and sees my method?”</p>
<p>Yeah, that is a risk for sure, which we could analyze.<br>
You’d need to figure out your threat model.<br>
I will teach you how to do that in one of the next posts.</p>
<p>But for 99% of people online, this is a really great way to have long, unique passwords.</p>
<p>Here’s one last thing you should do today:</p>
<p>Step 1</p>
<p>Go to <a href="https://haveibeenpwned.com/Passwords">https://haveibeenpwned.com/Passwords</a> and type your password.
If you see a message like “Good news — no pwnage found!”, you’ll know that your password is not among the list of currently known breached passwords.</p>
<p>That’s good. It means that your password (and your method) is not leaked, and it’s still a secret known only to you.</p>
<p>Step 2</p>
<p>Go to <a href="https://haveibeenpwned.com/">https://haveibeenpwned.com/</a> and type your email.
This way you can check if your email was leaked in some of the big, known data breaches.
If yes - change the passwords on the breached accounts immediately.</p>
<p>Also, once you sign up, if your email ever appears in some of the breach known to <a href="https://haveibeenpwned.com/">https://haveibeenpwned.com</a> - you’ll get an email notification about it, which is awesome.</p>
<hr>




<p>You're welcome to join my private <a href="https://jovica.org/list">email list</a> or follow me on <a href="https://twitter.com/jovica">Twitter</a>.</p>



</div></div>]]>
            </description>
            <link>https://jovica.org/posts/the_password_framework/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25677255</guid>
            <pubDate>Thu, 07 Jan 2021 20:48:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A simple process beats a perfect process]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25676886">thread link</a>) | @mcrittenden
<br/>
January 7, 2021 | https://critter.blog/2021/01/07/a-simple-process-beats-a-perfect-process/ | <a href="https://web.archive.org/web/*/https://critter.blog/2021/01/07/a-simple-process-beats-a-perfect-process/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
	<p><a href="#content">Skip to content</a></p><!-- #masthead -->

	
	<div id="content">

	<div id="primary">
		<main id="main">

		

<article id="post-3830">
	<!-- .entry-header -->

	<div>
		
<p>Choose the simple and good process over the <a href="https://critter.blog/2020/08/06/productivity-porn/">complicated and perfect</a> process. The value of universal understanding outweighs the value of accounting for every possible edge case and gotcha.</p>



<p>I like to talk about processes in terms of <em><a href="https://critter.blog/2020/12/22/power-in-naming-things/">recite-ability</a></em>. If everyone involved in the process can’t recite it off the top of their head, try to simplify it. </p>



<p>Look at the humble Kanban board with <em>Todo</em>, <em>Doing</em>, and <em>Done</em> columns. Everyone knows which column their ticket should be in. There are only 3 of them! Simple!</p>



<p>That’s why we should think long and hard before adding that <em>In Review</em> column or the <em>Awaiting Deploy</em> column. Those should only be created when <a href="https://critter.blog/2020/12/17/stop-solving-problems-nobody-complained-about/">not having them becomes <em>torture</em></a>. Each one makes the process that much less recite-able. If a team’s board has so many columns that the average team member can’t recite them all from memory, that’s trouble.</p>



<p>The 80/20 rule applies, as always. If I can get 80% of the value of a process with 20% of the complexity, then that’s a tradeoff I’ll take almost every time. Of course there are exceptions, but I find that they aren’t as common as we’d expect. </p>



<p>I know it feels safer to account for everything so that there’s nothing left open to interpretation. But then we’ve just replaced one problem (“if X is true the we’ll have to do Y manually and that allows for human error!”) with <a href="https://critter.blog/2020/12/10/the-tragedy-of-the-commons-in-software-development/">a worse problem</a> (“nobody <a href="https://critter.blog/2020/12/01/never-underestimate-peoples-ability-to-not-hear-you/">deeply understands this</a> so they’re making mistakes or ignoring it altogether”).</p>



<p>One of my favorite rules for <a href="https://critter.blog/2020/06/10/spotting-broken-processes/">spotting broken processes</a> is: <em>when times get tough, if people run away from the process instead of towards it, it’s broken</em>. And when people are freaking out, they run away from complexity and towards simplicity.</p>



<p>So strive for simple. A simple process is a happy process.</p>




	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article><!-- #post-3830 -->
			<!-- .post-nav-wrapper -->
		
		</main><!-- #main -->
	</div><!-- #primary -->


<!-- #secondary -->

	</div><!-- #content -->

	
	<!-- #colophon -->
</div></div>]]>
            </description>
            <link>https://critter.blog/2021/01/07/a-simple-process-beats-a-perfect-process/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25676886</guid>
            <pubDate>Thu, 07 Jan 2021 20:24:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I automated my Coffee Grinder]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25676720">thread link</a>) | @flomei
<br/>
January 7, 2021 | https://www.flomei.de/en/blog/2021/01/07/how-i-automated-my-coffee-grinder/ | <a href="https://web.archive.org/web/*/https://www.flomei.de/en/blog/2021/01/07/how-i-automated-my-coffee-grinder/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
  <section>
    <article>
      <header>
        
        
      </header>

      <div>
      	

<h2 id="making-coffee-and-what-influences-it">Making Coffee and what influences it</h2>

<p>There are not many better things than a good espresso to start your day… Ok, before I lose myself in talking about coffee (or espresso), its brewing, and what I’ve learned over the last five years about it, I will take a shortcut.</p>

<p>Coffee is complex! Lots of factors influence whether you have a cup of delicious coffee or just dark, hot water with a bitter taste. In the end, you’ll want to have as many factors as constant as possible. Only in this way you can change single parameters and check whether it improves or worsens your coffee. That’s the foundation of scientific work but it’s also useful for brewing coffee.</p>

<p>One important factor is the coffee grounds. There are lots of factors, like how fine you grind, but also the amount you use and how much force you use to compact the ground in your espresso machine and so on. In the end we want to use the same grind settings and the same amount for each shot we pull from our machines.</p>

<h2 id="coffee-grinders-in-general">Coffee grinders in general…</h2>

<p>Fixing the grind setting is the smaller problem. You’ll dial it in on your grinder and will only change it when you try new beans. The amount of coffee grounds you’ll use depends on which technique you are using for brewing, but generally it’s the easiest way to simply weigh your grounded beans. You can either weigh the beans before grinding and grind them all or grind some, weigh, grind some more and so on…</p>

<p>So called “automatic grinders” shorten this process. They’ll usually grind “dose wise”, normally based on a timer. That leaves some variation for the amount, but this can usually be neglected. I am aware of only one grinder that actually weighs the grinded beans, all other grinders use timers.</p>

<p>I’m owning a small electric grinder for some time now, precisely <a href="https://amzn.to/3mWQoES#aff">a Lelit PL043 MMI.</a> It’s a nice little grinder, doing a good job especially in regards of its low price (coffee gear often is <em>really expensive</em>). Sadly this is not an automatic grinder, so you’ll have to stop grinding manually (and weigh afterwards).</p>

<p>As I’m a morning grouch and was annoyed by weighing the grounds in the morning, an automation was needed. The little Lelit needed to be transformed into an automatic grinder.</p>

<h2 id="checking-the-status-quo">Checking the status quo</h2>

<p>I’ve already expected that the inside of this grinder is not very complex, before actually opening the case. One switch on the side to turn the grinder on and off and a single push switch for the motor which grinds the beans. Of course both are connected to mains voltage, so having pushed/closed both switches will get the motor running. It looks somewhat like the following.</p>

<p><img src="https://www.flomei.de/assets/2021/01/schaltplan-lelit-pl043mmi.png" alt="Circuit diagram Lelit PL043 MMI"></p>

<p>Although there are not many components in place, space is at a premium in the grinder. The metal body tightly encloses the motor so there’s not much space left for the upcoming modifications.</p>

<h2 id="transformation-to-an-automatic-grinder">Transformation to an automatic grinder</h2>

<p>The grinder will be outfitted with a microcontroller from the Arduino ecosystem. The already existent touch switch will start a “grind program”, where the Arduino will hold the circuit closed through a relais.</p>

<p>Another touch switch allows the user to switch between three different modes (the grind programs: single dose - double dose - manual), two LEDs will show the selected mode.</p>

<p>Single and double dose are timed programs, the manual mode will engage the motor for a quarter second, so holding on to the switch will engange a somewhat “continous grinding”.</p>

<p>The supply voltage for the microcontroller, the relais and anything else will be provided by a small power supply which transforms main voltage into 5 V DC. Due to the limited space inside of the grinder, the power supply will sit on the backside of the grinder like a backpack.</p>

<p>The baseplate of the mill will also be equipped with two touch switches which can be used to increase or decrease the grinding time in the selected program. The selected values will be saved in the EEPROM of the Arduino and loaded when powering the grinder. This way, you can always work with the previous settings right from the start.</p>

<p>The circuit diagram for those modifications looks somewhat like the following, I have left out various resistors for a better overview.</p>

<p><img src="https://www.flomei.de/assets/2021/01/schaltplan-lelit-pl043mmi-automatik.png" alt="Circuit diagram Lelit PL043 MMI &quot;Automatic&quot;"></p>

<p>Some more pictures from the transformation will follow.</p>

<p><em>First tests of the circuit on a breadboard.</em></p>

<p><img src="https://www.flomei.de/assets/2021/01/lelit-automatik-1.jpg" alt="First tests of the circuit on a breadboard."></p>

<p><em>As already mentioned: Very little space in the grinder itself. Cable management was improved later on.</em></p>

<p><img src="https://www.flomei.de/assets/2021/01/lelit-automatik-2.jpg" alt="As already mentioned: Very little space in the grinder itself. Cable management was improved later on."></p>

<p><em>Switches for setting the timer, seated in the baseplate of the grinder.</em></p>

<p><img src="https://www.flomei.de/assets/2021/01/lelit-automatik-3.jpg" alt="Switches for setting the timer, seated in the baseplate of the grinder."></p>

<p><em>Small power supply mounted like a backpack on the back of the grinder. Provides power for the Arduino etc.</em></p>

<p><img src="https://www.flomei.de/assets/2021/01/lelit-automatik-4.jpg" alt="Small power supply mounted like a backpack on the back of the grinder. Provides power for the Arduino etc."></p>

<p><em>Final result: LEDs for displaying the selected mode, metal switch to change the operation mode.</em></p>

<p><img src="https://www.flomei.de/assets/2021/01/lelit-automatik-5.jpg" alt="Final result: LEDs for displaying the selected mode, metal switch to change the operation mode."></p>

<h2 id="results">Results</h2>

<p>The modification works great. I was worried that my timed control might be too unprecice and the amount of grounded beans could vary a lot. After some testing, I found that the result differs +/- 0.3 gram per grind run, which is totally fine for me.</p>

<p>I also like that the modification is not very obvious. The metal switch and the somewhat dimmed LEDs almost look like they were always in place. Only the power supply is a little downside for the optics, but as my grinder sits quite closely to the wall this is not a big deal either for me.</p>

<p>As I only had to buy the power supply, all the other parts were laying around from other projects, this modification was relative cheap with around 8 Euro.</p>

<p>I have uploaded <a href="https://gitlab.com/www-flomei-de/coffeegrinder">the source code to Gitlab,</a> in case anybody is interested in doing a similar build or wants to use parts of my code.</p>

<p>And: If you are not interested in tinkering with coffee grinders: Lelit has a very similar grinder with an automatic mode: It’s called <a href="https://amzn.to/3aSGPV8#aff">Lelit PL044 MMT.</a> Besides that there are also lots of other great automatic grinders available on the market.</p>

      </div>
    </article>

    <hr>
    
    <hr>

  </section>

      </div></div>]]>
            </description>
            <link>https://www.flomei.de/en/blog/2021/01/07/how-i-automated-my-coffee-grinder/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25676720</guid>
            <pubDate>Thu, 07 Jan 2021 20:14:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Replacing OpenSSL, Part 1: WolfSSL]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25676671">thread link</a>) | @StreamBright
<br/>
January 7, 2021 | https://danyspin97.org/blog/replacing-openssl-part-1-wolfssl/ | <a href="https://web.archive.org/web/*/https://danyspin97.org/blog/replacing-openssl-part-1-wolfssl/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>This post highlight my experiment of replacing OpenSSL cryptographic library
with its embedded competitor: <code>wolfssl</code>.</p><p><em><strong>Prerequites</strong></em>: <em>Basic knowledge about C/C++ programming</em>.</p><h2 id="a-bit-of-background-about-openssl">A bit of background about OpenSSL</h2><p>OpenSSL is one of the most crucial libraries on a Unix system: it performs
cryptographic functions and it provides <em>Transport Layer Security</em> (<em>TLS</em>) and <em>Secure Sockets Layer</em> (<em>SSL</em>) protocols to applications.</p><p>According to the <em>Arch Linux</em> <a href="https://archlinux.org/packages/core/x86_64/openssl/">OpenSSL package</a>, <strong>355</strong> packages, out of the
<em>11523</em> available, depend on it. You can find it installed on any Unix system
(and on Windows too!).</p><p>It started in 1998 as a fork of <a href="https://en.wikipedia.org/wiki/SSLeay">SSLeay</a> and it has been in development since.
Two full-time developers work on it, as well as many volunteers.</p><p>Fast forward to 2014: a <em><a href="https://en.wikipedia.org/wiki/Common_Vulnerabilities_and_Exposures">CVE</a></em> had been issued regarding a high risk
vulnerability found in OpenSSL. It has been given the name <strong><a href="https://heartbleed.com/">Heartbleed</a></strong>,
because it has been found in the <em>TLS</em>/<em>DTLS</em> heartbeat extension (<a href="https://tools.ietf.org/html/rfc6520">RFC6520</a>).
This vulnerability allowed attackers to steal sensitive data, such as secret
keys, user names and passwords.</p><p>All the community turned to the OpenSSL project, weighting its implementation
and security policy. Heartbleed have been promptly fixed, but there could be new
vulnerabilities in the future, if security was not properly prioritized during
development.</p><p>At this point, OpenBSD’s folks forked OpenSSL and started a new project:
<a href="https://www.libressl.org/">LibreSSL</a>. It primary goals were to <strong>modernize the codebase and to improve
its security</strong>. This new project hasn’t been adopted by big distributions such
Ubuntu and Arch Linux; instead smaller distributions (at that time) replaced
OpenSSL with LibreSSL on their default configuration, such as Alpine and Void.</p><p>In the last years, LibreSSL have seen a decline in its usage. Alpine switched
back to OpenSSL (<a href="https://lists.alpinelinux.org/~alpine/devel/%3C20181011171746.4c01f758%40ncopa-desktop.copa.dup.pw%3E">link to the thread</a>). Many people and distributions are
considering doing the same, since OpenSSL got the improvement that LibreSSL
aimed for. And it’s still the <em>de facto standard</em> cryptographic library on Unix.</p><h2 id="why-replacing-openssl-now">Why replacing OpenSSL now?</h2><p>OpenSSL works fine, there is no denying that. Every software has <em>out of the box
support for it</em> so it costs no effort in term of additional mainteinance.
However, there are <strong>newer and lighter TLS and SSL implementations</strong>, which many
folks might prefer over the heavy OpenSSL’s one. I, too, prefer lightweight
libraries.</p><p>I am uninstalling LibreSSL on my systems, therefore this might be the perfect
time to experiment with something different. I have found an interesting (and
well done!) library called <em><strong><a href="https://wolfssl.com/">wolfSSL</a></strong></em> that claims to have an <em>OpenSSL
compatibility layer</em>. It also claims to be 20 times smaller than OpenSSL.</p><h2 id="installation">Installation</h2><p><strong>wolfSSL</strong> is a small C library; It uses <em>autotools</em> to build and <strong>CMake</strong>
support is being added (sigh!). Upon running <code>configure</code>, I am overwhelmed by
the quantity of compile options available.</p><figure><img src="https://danyspin97.org/img/replacing-openssl-part-1-wolfssl/wolf-ssl-configure.jpg" alt=""><figcaption>some of the wolfSSL configure options</figcaption></figure><p>Fortunately, there is one comfy option which I’ve used
when compiling wolfSSL: <code>--enable-all</code>. It enables all options, including
the OpenSSL compatibility layer and leaves out the <em>SSL 3</em> protocol.</p><p>Upon completing the build and installation (which takes a couple of
minutes), a library <code>libwolfssl.so</code> will be installed into <code>/usr/lib</code>, as
well as a pkgconfig file (<code>wolfssl.pc</code>) and all the headers.</p><h2 id="out-of-the-box-support">Out of the box support</h2><p>Key applications provide support for different SSL implementations other than
OpenSSL. For example <em>curl</em> supports <em>mbedTLS</em>, <em>BearSSL</em> and our <strong>wolfSSL</strong>.
To compile <em>curl</em> using wolfSSL, we just need to add <code>--with-ssl=wolfssl</code> and
we’re done. I am aware of only two packages that have out of the box support
for wolfSSL and they are <em>curl</em> and <em><a href="https://gitlab.com/gnuwget/wget2">wget2</a></em> (not the legacy version!).</p><h2 id="openssl-compatibility">OpenSSL compatibility</h2><p><code>--enable-all</code> configure option enabled the OpenSSL compatibility layer.
To use this layer, according to the <a href="https://www.wolfssl.com/docs/wolfssl-manual/ch13/">documentation</a>, we need to link the wolfssl
library manually by adding <code>-lwolfssl</code> as link argument. We also need to
include the path <code>/usr/include/wolfssl</code> so that the OpenSSL headers in
<code>/usr/include/wolfssl/openssl</code> will be picked up.</p><p>This way both wolfSSL and OpenSSL can coexist on the same system and the latter
can be replaced on a per project basis. However, that’s not what we want since
want to replace OpenSSL at a system level.</p><p>Adding the link flag to each package on the system or patching one by one
is not an option as it would take too much time. Let’s instead apply some
workarounds.</p><p>First, we create a symlink for the headers:</p><div><pre><code data-lang="bash">$ sudo ln -sf /usr/include/wolfssl/openssl /usr/include/openssl
</code></pre></div><p>Then we create a symlink for each library. OpenSSL provides the following
libraries:</p><ul><li><code>libssl.so</code></li><li><code>libcrypto.so</code></li></ul><p>So we can run:</p><div><pre><code data-lang="bash">$ sudo ln -sf /usr/lib/libwolfssl.so /usr/lib/libssl.so
$ sudo ln -sf /usr/lib/libwolfssl.so /usr/lib/libcrypto.so
</code></pre></div><h3 id="fixing-pkg-config">Fixing pkg-config</h3><p>Some software rely on pkg-config for checking OpenSSL dependency since
it provides the following pkg-config files:</p><ul><li><code>libssl.pc</code></li><li><code>libcrypto.pc</code></li><li><code>openssl.pc</code></li></ul><p>My system doesn’t currently have either OpenSSL or LibreSSL installed, so any
attempt to include OpenSSL by using pkg-config will fail. We can fix this by
adding a pkg-config file in <code>/usr/lib/pkgconfig/openssl.pc</code>:</p><pre><code>prefix=/usr/x86_64-pc-linux-musl
includedir=${prefix}/include/wolfssl

Name: openssl
Description: wolfssl C library.
Version: 4.6.0
Requires: wolfssl
Cflags: -I${includedir}
</code></pre><p>Our pkg-config file will include the correct directory containing the OpenSSL
headers. It will also import cflags and link flags from the wolfssl pkg-config.
Let’s try if it works as intended:</p><div><pre><code data-lang="bash">$ pkg-config --cflags --libs openssl
-I/usr/x86_64-pc-linux-musl/include/wolfssl -lwolfssl
</code></pre></div><p>Yes! Now we just need create symlinks the other two pkg-config files:</p><div><pre><code data-lang="bash">$ sudo ln -sf /usr/lib/pkgconfig/openssl.pc /usr/lib/pkgconfig/libssl.pc
$ sudo ln -sf /usr/lib/pkgconfig/openssl.pc /usr/lib/pkgconfig/libcrypto.pc
</code></pre></div><p>Now we’re ready to compile system packages.</p><h2 id="compiling-system-packages">Compiling system packages</h2><p>Before actually going further into the various compile results, there are few
general changes that I’ve done:</p><ol><li>Include the default <code>/usr/include/wolfssl/option.h</code> provided in
<code>/usr/include/wolfssl/wolfcrypt/setting.h</code>. This way we will have a bunch of
defines already included that enable many wolfSSL features.</li><li>Remove some defines from <code>option.h</code> that disable old OpenSSL features, like
old SSL names. While I understand that these features are plainly old (or even
deprecated), projects will still use them as long as they haven’t been
removed upstream.</li><li>Define <code>OPENSSL_NO_WHIRPOOL</code> in the same header as above, since this feature
ins’t implemented in wolfSSL. There are other <code>OPENSSL_NO_*</code> defines there for
unimplemented features, but this one was missing.</li></ol><h3 id="wget">wget</h3><p><em><a href="https://www.gnu.org/software/wget/">wget</a></em>, which comes installed on any Unix system, is the first software we’ll
try building with wolfSSL and its OpenSSL compatibility layer.</p><figure><img src="https://danyspin97.org/img/replacing-openssl-part-1-wolfssl/wget-error-1.jpg" alt=""><figcaption>wget compile error</figcaption></figure><p>wget complains about two undeclared identifiers:</p><ul><li><code>CONF_MFLAGS_DEFAULT_SECTION</code></li><li><code>CONF_MFLAGS_IGNORE_MISSING_FILE</code></li></ul><p>We can fix this by adding the defines from the OpenSSL file <code>openssl/conf.h</code>
to <code>/usr/include/wolfssl/option.h</code>:</p><div><pre><code data-lang="c"><span># define CONF_MFLAGS_IGNORE_MISSING_FILE 0x10
</span><span># define CONF_MFLAGS_DEFAULT_SECTION     0x20
</span></code></pre></div><figure><img src="https://danyspin97.org/img/replacing-openssl-part-1-wolfssl/wget-error-2.jpg" alt=""><figcaption>wget link-time errors about missing symbols</figcaption></figure><p>We arrived at link-time, that’s huge! However, there are 8 undefined symbols:
6 symbols about unimplemented features in wolfSSL, such as <code>i2d_x509_PUBKEY</code>
and <code>a2i_IPADDRESS</code>; 2 symbols regarding wolfSSL functions. The latter could
probably be fixed by adding the proper compile time option to wolfSSL, like
<code>--enable-sslv3</code>.</p><h3 id="rhash">rhash</h3><p>rhash is an utility that calculates and verifies message digests, such as
<em>SHA256</em> and <em>MD5</em>. It is required by CMake, so we can consider it an essential
package. Compiling rhash led to many errors. Let’s look in depth at some of
them.</p><figure><img src="https://danyspin97.org/img/replacing-openssl-part-1-wolfssl/rhash-error-1.jpg" alt=""><figcaption>rhash compile error about RIPEMD160_CTX</figcaption></figure><p><em>rhash</em> uses <code>RIPEMD160_CTX</code> which is not implemented by wolfSSL.</p><figure><img src="https://danyspin97.org/img/replacing-openssl-part-1-wolfssl/rhash-error-2.jpg" alt=""><figcaption>rhash compile error about WOLFSSL_MD5_CTX</figcaption></figure><p>This time, rhash access a member of <code>MD5_CTX</code> (which wolfSSL has replaced by
<code>WOLFSSL_MD5_CTX</code>) using <code>offsetof</code>. The original <code>MD5_CTX</code> struct looks like
this:</p><div><pre><code data-lang="c"><span>typedef</span> <span>struct</span> <span>MD5state_st</span> <span>{</span>
    <span>MD5_LONG</span> <span>A</span><span>,</span> <span>B</span><span>,</span> <span>C</span><span>,</span> <span>D</span><span>;</span>
    <span>MD5_LONG</span> <span>Nl</span><span>,</span> <span>Nh</span><span>;</span>
    <span>MD5_LONG</span> <span>data</span><span>[</span><span>MD5_LBLOCK</span><span>];</span>
    <span>unsigned</span> <span>int</span> <span>num</span><span>;</span>
<span>}</span> <span>MD5_CTX</span><span>;</span>
</code></pre></div><p><code>WOLFSSL_MD5_CTX</code> instead looks like this:</p><div><pre><code data-lang="c"><span>typedef</span> <span>struct</span> <span>WOLFSSL_MD5_CTX</span> <span>{</span>
    <span>/* big enough to hold wolfcrypt md5, but check on init */</span>
<span>#ifdef STM32_HASH
</span><span></span>    <span>void</span><span>*</span> <span>holder</span><span>[(</span><span>112</span> <span>+</span> <span>WC_ASYNC_DEV_SIZE</span> <span>+</span> <span>sizeof</span><span>(</span><span>STM32_HASH_Context</span><span>))</span> <span>/</span> <span>sizeof</span><span>(</span><span>void</span><span>*</span><span>)];</span>
<span>#else
</span><span></span>    <span>void</span><span>*</span> <span>holder</span><span>[(</span><span>112</span> <span>+</span> <span>WC_ASYNC_DEV_SIZE</span><span>)</span> <span>/</span> <span>sizeof</span><span>(</span><span>void</span><span>*</span><span>)];</span>
<span>#endif
</span><span></span><span>}</span> <span>WOLFSSL_MD5_CTX</span><span>;</span>
</code></pre></div><p>I think that this incosistency between OpenSSL and wolfSSL structs <em>will</em>
happen again with different data types.</p><h3 id="libssh2">libssh2</h3><p>From the official <a href="https://www.libssh2.org/">libssh2</a> site:</p><blockquote><p><em>libssh2 a client-side C library implementing the SSH2 protocol</em></p></blockquote><p>curl has a hard dependency on libssh2, so we can consider it another essential
package.</p><figure><img src="https://danyspin97.org/img/replacing-openssl-part-1-wolfssl/libssh2-error-1.jpg" alt=""><figcaption>libssh2 build errors</figcaption></figure><p>This time there are only 2 errors, both about unimplemented features:
<code>EVP_bf_cbc</code> and <code>EVP_cast5_cbc</code>. The man pages are the best source of
information about OpenSSL functions; we can browse them by running:</p><div><pre><code data-lang="bash">$ man EVP
$ man EVP_bf_cbc
$ man EVP_cast5_cbc
</code></pre></div><p>Let’s split the names and study each part:</p><ul><li><code>EVP</code> is a high-level interface to cryptographic functions</li><li><code>bf</code> and <code>cast5</code> are the name of the algorithms, <em><a href="https://en.wikipedia.org/wiki/Blowfish_(cipher)">blowfish</a></em> and <em><a href="https://en.wikipedia.org/wiki/CAST-128">CAST</a></em>
respectively.</li><li><code>cbc</code>, <em><a href="https://en.wikipedia.org/wiki/Block_cipher_mode_of_operation#:~:text=Cipher%20block%20chaining%20(CBC),-CBC&amp;text=In%20CBC%20mode%2C%20each%20block,used%20in%20the%20first%20block.">Cipher Block Chaining</a></em>, is a mode of operation that tells OpenSSL
to operate on each block seperately from the others.</li></ul><p>Operating cryptographic functions in <em>CBC</em> mode isn’t really safe nor the
two algorithms above are really popular, so I understand why wolfSSL developers
might have prioritized other things over implementing the two functions above.</p><h3 id="ffmpeg">ffmpeg</h3><p><em><a href="https://ffmpeg.org/">ffmpeg</a></em> is a powerful library and a collection of utilities for handling
images, audio and videos. It is required by <em>Firefox</em>, <em>Chromium</em>, <em>mpv</em> and
another hundred and a half software (at least). We surely don’t want a system
without this library.</p><figure><img src="https://danyspin97.org/img/replacing-openssl-part-1-wolfssl/ffmpeg-error.jpg" alt=""><figcaption>ffmpeg build error</figcaption></figure><p>This time there is only one error (but others may still pop up later while
building!). The function <code>BN_sub_word</code> is missing. According to the man pages,
it is the arithmetic function that perform subtractions on big integers.
This seems pretty straightforward …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://danyspin97.org/blog/replacing-openssl-part-1-wolfssl/">https://danyspin97.org/blog/replacing-openssl-part-1-wolfssl/</a></em></p>]]>
            </description>
            <link>https://danyspin97.org/blog/replacing-openssl-part-1-wolfssl/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25676671</guid>
            <pubDate>Thu, 07 Jan 2021 20:11:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting Things Done]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25676428">thread link</a>) | @cyb_
<br/>
January 7, 2021 | https://raccoon.onyxbits.de/blog/secret-getting-things-done/ | <a href="https://web.archive.org/web/*/https://raccoon.onyxbits.de/blog/secret-getting-things-done/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>Ok, I am running an open source project here. What’s my workload? Short summary:</p>

<ul>
<li>Operate a server (no, <a href="https://raccoon.onyxbits.de/blog/why-not-use-github">hosting on GitHub is not an option</a>)</li>
<li>Blogging (it’s a self promotion thing, don’t ask).</li>
<li>Actual software development (researching Google Play, writing code, writing docs)</li>
<li>Dealing with the “fun” side of running a business (aka the legal shit).</li>
</ul>

<p>How do I manage to find time for all of this? <a href="https://francescocirillo.com/pages/pomodoro-technique">Pomodoro Technique</a>? Nah, much easier: good old blasphemy!</p>

<h2 id="blasphemy">Blasphemy?!</h2>

<p>Yep! I just refuse to use any kind of messenger. I don’t do Slack, Skype, Twitter, Facebook or whatever’s the hot shit right now. I won’t even answer the phone, unless it’s a scheduled call. The only way to communicate with me is either in person or via email. For me, it’s a simple rule of life: if it allows you to ring me up, then you can’t reach me through it.</p><figure>
  <a href="https://raccoon.onyxbits.de/blog/secret-getting-things-done/callbell.jpeg">
    <img src="https://raccoon.onyxbits.de/blog/secret-getting-things-done/callbell.jpeg">
  </a>
  
  <figcaption>Think: messenger app</figcaption>
  
</figure>
                             
                             

<p><i>… dafuq?!</i></p>

<p>Told you, it was blasphemy.</p>

<p>Here’s the thing: the mind needs about half an hour to enter “the zone”, the state in which creative work can happen and it only takes a short distraction to drop out of it again. We are living in this strange, hyper connected world, in which most of us are totally convinced that we should have things that go “beep” in order to alert us to “important” things, that need to be taken care of right away (as if the one thing we are currently working on wasn’t important). In my book, everything that is able to draw attention is by definition a distraction and therefore a productivity killer, not a productivity tool. By switching to “email only”, I avoid the problem. Plain and simple.</p>

<p>When I’m busy typing out a thought. Be it a blog post, a piece of code or even a reply to an email, then there’s no way in hell, I’d allow anyone to interrupt me to take care of whatever they think needs to be taken care instead. People can wait. No cutting in line. I will always finish a train of thought first and only then check my mail folder to see if something <strong>important</strong> came up in the meantime. <u>Paid work</u> is prioritized, everything else gets postponed till I can make time for it. If stuff piles up, so be it. If something (eventually) falls off the pile, even better. I don’t loose sleep over missing deadlines for anything that’s optional.</p>

<p>And that, quite unspectacularly, is how I get things done. I simply don’t buy into the modern belief of being on call <sup>24</sup>⁄<sub>7</sub>. <abbr title="Fear Of Loosing Out">FOMO</abbr> my ass. I chose when to handle things, not someone else.</p>
</div></div>]]>
            </description>
            <link>https://raccoon.onyxbits.de/blog/secret-getting-things-done/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25676428</guid>
            <pubDate>Thu, 07 Jan 2021 19:56:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Elegancy of Go's Error Handling]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25676097">thread link</a>) | @vhakulinen
<br/>
January 7, 2021 | https://thingsthatkeepmeupatnight.dev/posts/golang-http-handler-errors/ | <a href="https://web.archive.org/web/*/https://thingsthatkeepmeupatnight.dev/posts/golang-http-handler-errors/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
        <p>Every so often, go’s error handling pops up in various forums and everyone seems
to have an opinion about it. Some say they should be more like throwable
exceptions, others prefer sum types like rust’s <code>Result&lt;T, E&gt;</code>. While I’ve gone
with the sum type <a href="https://dev.to/duunitori/mimicing-rust-s-result-type-in-typescript-3pn1">approach in typescript</a>,
I still like the way go handles errors.</p>
<p>That said, figuring out how to <em>really</em> handle errors can take some time (with
or without sum types/exceptions). In this post, I’ll be walking through one
approach on handling errors in go’s <code>http.Handler</code>.</p>

<p>The error values can be frustrating if you expect them to scale out “just like
that” without repeating themselves. Usual example goes something like this:</p>
<div><pre><code data-lang="golang"><span>func</span> copyfile(src, dst) <span>error</span> {
	fsrc, err := os.Open(src)
	<span>if</span> err != <span>nil</span> {
		<span>return</span> err
	}
	<span>defer</span> fsrc.Close()

	fdst, err := os.Open(src)
	<span>if</span> err != <span>nil</span> {
		<span>return</span> err
	}
	<span>defer</span> fdst.Close()

	err := io.Copy(fdst, fsrc)

	<span>return</span> err
}
</code></pre></div><p>Thats not so bad, and I’m quite sure that most of you have seen example like
that before. But let’s take a look at similar situation that might occur in a
<code>http.Hanlder</code>:</p>
<div><pre><code data-lang="golang"><span>func</span> handleThing(w http.ResponseWriter, r *http.Request) {
	<span>// Our path is something like /thing/3
</span><span></span>	id, err := idFromPath(r.URL.Path)
	<span>if</span> err != <span>nil</span> {
		http.Error(w, http.StatusText(http.StatusBadRequest), http.StatusNotFound)
		<span>return</span>
	}

	thing, err := store.GetThingByID(id)
	<span>if</span> err != <span>nil</span> {
		<span>// The error might be sql.NoRows, or it might be something else.
</span><span></span>		<span>if</span> store.IsNotFoundErr(err) {
			http.Error(w, http.StatusText(http.StatusNotFound), http.StatusNotFound)
			<span>return</span>
		}
		log.Printf(<span>"Failed to get a thing: %v"</span>, err)
		http.Error(w, http.StatusText(http.StatusInternalServerError), http.StatusInternalServerError)
		<span>return</span>
	}

	acc := AccountFromRequest(r)
	<span>if</span> acc == <span>nil</span> {
		<span>// No account attached to the request's session -&gt; permission denied.
</span><span></span>		http.Error(w, http.StatusText(http.StatusForbidden), http.StatusForbidden)
		<span>return</span>
	}

	has, err := thing.HasPermissionToView(acc)
	<span>if</span> err != <span>nil</span> {
		<span>// For some reason, we failed to check permissions. Better log it.
</span><span></span>		log.Printf(<span>"Failed to check permissions: %v"</span>, err)
		http.Error(w, http.StatusText(http.StatusInternalServerError), http.StatusInternalServerError)
		<span>return</span>
	}

	<span>if</span> !has {
		<span>// Permission denied.
</span><span></span>		http.Error(w, http.StatusText(http.StatusForbidden), http.StatusForbidden)
		<span>return</span>
	}

	<span>// All good, send data to the client.
</span><span></span>	respond(w, r, decodeThing(thing))
}
</code></pre></div><p>Theres some functions that you’ll have to imagine is defined somewhere, but the
functionality is this:</p>
<ul>
<li>Extract ID from URL</li>
<li>Use that ID to get the thing from database</li>
<li>Check if the client has permission to view the thing</li>
<li>Give the thing to the client</li>
</ul>
<p>This functionality probably repeats itself for other resource types, so it gets
repetitive quite fast. Imagine doing the same for resources like foo, bar,
account and so on! Same functionality can be written in Django like this:</p>
<div><pre><code data-lang="python"><span>def</span> handle_thing(request):
    id = id_or_bad_request(request)
    thing = thing_or_404(id)

    account = account_or_forbidden(request)

    <span>if</span> <span>not</span> thing.has_permission(account):
        <span>raise</span> Forbidden()

    <span>return</span> JsonResponse(...)
</code></pre></div><p>Now that’s quite a lot simpler, thanks to throwable errors and how they
can be used to disrupt the code’s flow. <code>id_or_bad_request</code>, <code>thing_or_404</code> and
<code>account_or_forbidden</code> all throw an error that someone catches somewhere higher
and does the appropriate thing, like respond with correct status code and log
any errors.</p>

<p>Keeping that python code in mind, let’s think what we could do in our go code to
get it a bit more terse:</p>
<ul>
<li>When an error occurs, we just want to “throw” it somewhere. It usually is a
client error, but not always. Perhaps someone else can figure that out?</li>
<li>If a non client error occurs, it needs to be logged somewhere</li>
<li>Someone else should be able figure out the <code>http.Error</code> calls</li>
</ul>
<p>Golang’s <a href="https://blog.golang.org/error-handling-and-go">error handling and Go</a>
talks a bit about error handling in your http handlers and gives the following
example:</p>
<div><pre><code data-lang="golang"><span>func</span> viewRecord(w http.ResponseWriter, r *http.Request) <span>error</span> {
    c := appengine.NewContext(r)
    key := datastore.NewKey(c, <span>"Record"</span>, r.FormValue(<span>"id"</span>), 0, <span>nil</span>)
    record := new(Record)
    <span>if</span> err := datastore.Get(c, key, record); err != <span>nil</span> {
        <span>return</span> err
    }
    <span>return</span> viewTemplate.Execute(w, record)
}

<span>// NOTE: the following is my adapted version from the example's ServeHTTP to a
</span><span>// middleware/wrapper
</span><span></span>
<span>type</span> HandlerE = <span>func</span>(w http.ResponseWriter, r *http.Request) <span>error</span>

<span>func</span> WithError(h HandlerE) http.HandlerFunc {
	<span>return</span> <span>func</span>(w http.ResponseWriter, r *http.Request) {
		<span>if</span> err := h(w, r); err != <span>nil</span> {
			http.Error(w, err.Error(), 500)
		}
	}
}
</code></pre></div><p>That already solves one of our problems, which is the <code>http.Error</code> call. But
sometimes we don’t want to expose detailed errors to the client, so I would
replace the actual message with just a generic internal server error message.
Also, logging the reasons for internal server errors is important, so that you
can figure out what went wrong.</p>

<p>We want to return an error from our <em>actual</em> <code>http.Handler</code>, but somehow
instruct the <code>WithError</code> wrapper function to respond correctly to the client
when it gets an error, and on some errors log the errors. Something like this:</p>
<div><pre><code data-lang="golang"><span>func</span> WithError(h HandlerE) http.HandlerFunc {
	<span>return</span> <span>func</span>(w http.ResponseWriter, r *http.Request) {
		<span>if</span> err := h(w, r); err != <span>nil</span> {

			<span>if</span> is404err(err) {
				http.Error(w, <span>"not found"</span>, 404)
				<span>return</span>
			}

			<span>if</span> isBadRequest(err) {
				http.Error(w, <span>"bad request"</span>, 400)
				<span>return</span>
			}

			<span>// Some other special cases...
</span><span></span>			<span>// ...
</span><span></span>
			log.Printf(<span>"Something went wrong: %v"</span>, err)

			http.Error(w, <span>"Internal server error"</span>, 500)
		}
	}
}
</code></pre></div><p>Hmm, those “other special” cases might come and go and might get quite specific
for some handlers. Also, we’d still need to write those <code>is404err</code> and
<code>isBadRequest</code> handlers and whatever will follow. We can do much better with an
interface:</p>
<div><pre><code data-lang="golang"><span>type</span> ErrorResponder <span>interface</span> {
    <span>// RespondError writes an error message to w. If it doesn't know what to
</span><span></span>    <span>// respond, it returns false.
</span><span></span>	RespondError(w http.ResponseWriter, r *http.Request) <span>bool</span>
}
</code></pre></div><p>With this interface we can do quite powerful things. Our <code>WithError</code> turns into
this:</p>
<div><pre><code data-lang="fallback">
func WithError(h HandlerE) http.HandlerFunc {
	return func(w http.ResponseWriter, r *http.Request) {
		if err := h(w, r); err != nil {
			if er, ok := err.(ErrorResponder); ok {
				if er.RespondError(w, r) {
					return
				}
			}

			log.Printf("Something went wrong: %v", err)

			http.Error(w, "Internal server error", 500)
		}
	}
}
</code></pre></div><p>Notice how our special cases just disappeared? They are now just another
implementation(s) of <code>ErrorResponder</code>. This is what would our <code>Not found</code> and <code>Bad request</code> errors now looks like:</p>
<div><pre><code data-lang="golang">
<span>// BadRequest error responds with bad request status code, and optionally with
</span><span>// a json body.
</span><span></span><span>type</span> BadRequestError <span>struct</span> {
	err  <span>error</span>
	body <span>interface</span>{}
}

<span>func</span> BadRequest(err <span>error</span>) *BadRequestError {
	<span>return</span> &amp;BadRequestError{err: err}
}

<span>func</span> BadRequestWithBody(body <span>interface</span>{}) *BadRequestError {
	<span>return</span> &amp;BadRequestError{body: body}
}

<span>func</span> (e *BadRequestError) RespondError(w http.ResponseWriter, r *http.Request) <span>bool</span> {
	<span>if</span> e.body == <span>nil</span> {
		http.Error(w, http.StatusText(http.StatusBadRequest), http.StatusBadRequest)
	} <span>else</span> {
		w.WriteHeader(http.StatusBadRequest)

		w.Header().Set(<span>"Content-Type"</span>, <span>"application/json"</span>)
		err := json.NewEncoder(w).Encode(e.body)

		<span>if</span> err != <span>nil</span> {
			log.Printf(<span>"Failed to encode a response: %v"</span>, err)
		}
	}

	<span>return</span> <span>true</span>
}

<span>func</span> (e *BadRequestError) Error() <span>string</span> {
	<span>return</span> e.err.Error()
}

<span>// Maybe404Error responds with not found status code, if its supplied error
</span><span>// is sql.ErrNoRows.
</span><span></span><span>type</span> Maybe404Error <span>struct</span> {
	err <span>error</span>
}

<span>func</span> Maybe404(err <span>error</span>) *Maybe404Error {
	<span>return</span> &amp;Maybe404Error{err: err}
}

<span>func</span> (e *Maybe404Error) Error() <span>string</span> {
	<span>return</span> fmt.Sprintf(<span>"Maybe404: %v"</span>, e.err.Error())
}

<span>func</span> (e *Maybe404Error) Is404() <span>bool</span> {
	<span>return</span> errors.Is(e.err, sql.ErrNoRows)
}

<span>func</span> (e *Maybe404Error) RespondError(w http.ResponseWriter, r *http.Request) <span>bool</span> {
	<span>if</span> !e.Is404() {
		<span>return</span> <span>false</span>
	}

	http.Error(w, http.StatusText(http.StatusNotFound), http.StatusNotFound)
	<span>return</span> <span>true</span>
}
</code></pre></div><p>You could easily write more <code>ErrorResponder</code>s for permission denied errors and
much more.</p>

<p>With <code>ErrorResponder</code> and <code>WithError</code>, we can reduce our earlier <code>handleThing</code>
handler into this:</p>
<div><pre><code data-lang="golang"><span>func</span> handleThing(w http.ResponseWriter, r *http.Request) <span>error</span> {
	<span>// Our path is something like /thing/3
</span><span></span>	id, err := idFromPath(r.URL.Path)
	<span>if</span> err != <span>nil</span> {
		<span>// Literally bad request. We could use BadRequestWithBody to
</span><span></span>		<span>// respond with a fancy information for the client.
</span><span></span>		<span>return</span> BadRequest(err)
	}

	thing, err := store.GetThingByID(id)
	<span>if</span> err != <span>nil</span> {
		<span>// Likely a not found issue, but something else might have gone wrong.
</span><span></span>		<span>// Maybe404Error handles both cases.
</span><span></span>		<span>return</span> Maybe404(err)
	}

	acc := AccountFromRequest(r)
	<span>if</span> acc == <span>nil</span> {
		<span>// No account attached to the request. Client needs to authenticate.
</span><span></span>		<span>return</span> AuthenticationRequired()
	}

	has, err := thing.HasPermissionToView(acc)
	<span>if</span> err != <span>nil</span> {
		<span>// Something actually went wrong. Error will be logged and 500 message
</span><span></span>		<span>// sent to the client.
</span><span></span>		<span>return</span> err
	}

	<span>if</span> !has {
		<span>// Client doesn't have permission to view this resource.
</span><span></span>		<span>return</span> PermissionDenied()
	}

	<span>// All good, send data to the client.
</span><span></span>	respond(w, r, decodeThing(thing))
}

<span>func</span> main() {
	...
	mux.Handle(<span>"/thing/"</span>, WithError(handleThing))
	...
}
</code></pre></div><p>Thats a lot better! I’ll leave it as an exercise to the reader to combine the
auth and permission checking. Another exercise is to do a bit better logging
than just “Something went wrong: <em>error</em>” in the WithError function. Perhaps log
the path and requester, or use trace ids?</p>
<p>With all this, we can now:</p>
<ul>
<li>“throw” errors somewhere</li>
<li>Someone else is figuring out the <code>http.Error</code> calls</li>
<li>Non client errors are logged</li>
</ul>

<p>Sometimes I’m amazed just by how simple (yet powerful) go’s error type is. Other
times I’m banging my head against the wall because I can’t figure out how to use
that simplicity. The solution presented in …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thingsthatkeepmeupatnight.dev/posts/golang-http-handler-errors/">https://thingsthatkeepmeupatnight.dev/posts/golang-http-handler-errors/</a></em></p>]]>
            </description>
            <link>https://thingsthatkeepmeupatnight.dev/posts/golang-http-handler-errors/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25676097</guid>
            <pubDate>Thu, 07 Jan 2021 19:35:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Will Trump complete his first term?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25675949">thread link</a>) | @donut2d
<br/>
January 7, 2021 | https://polymarket.com/market/will-trump-complete-his-first-term | <a href="https://web.archive.org/web/*/https://polymarket.com/market/will-trump-complete-his-first-term">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://polymarket.com/market/will-trump-complete-his-first-term</link>
            <guid isPermaLink="false">hacker-news-small-sites-25675949</guid>
            <pubDate>Thu, 07 Jan 2021 19:25:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CVE-2021-3011: Key recovery on Google Titan Key]]>
            </title>
            <description>
<![CDATA[
Score 225 | Comments 71 (<a href="https://news.ycombinator.com/item?id=25675556">thread link</a>) | @hexa-
<br/>
January 7, 2021 | https://ninjalab.io/a-side-journey-to-titan/ | <a href="https://web.archive.org/web/*/https://ninjalab.io/a-side-journey-to-titan/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<div>
					<div>
							<section id="blog">
				<article id="post-747" class="page">
		<div>
		
<center><h3> <a href="https://ninjalab.io/wp-content/uploads/2021/01/a_side_journey_to_titan.pdf" target="_blank" rel="noopener noreferrer">Download the Writeup<center><img src="https://ninjalab.io/wp-content/uploads/2021/01/Titan_Bluetooth_EM_probe.png"></center>
</a></h3></center><br>

<h3>Abstract</h3>
<p><span> The <a href="https://store.google.com/product/titan_security_key" target="_blank" rel="noopener noreferrer"><i>Google Titan Security Key</i></a> is a FIDO U2F hardware device proposed by Google (available since July 2018) as a two-factor authentication token to sign in to applications (e.g. your Google account). Our work describes a side-channel attack that targets the <i>Google Titan Security Key</i>’s secure element (the NXP A700X chip) by the observation of its local electromagnetic radiations during ECDSA signatures (the core cryptographic operation of the FIDO U2F protocol). In other words, an attacker can create a clone of a legitimate <i>Google Titan Security Key</i>.</span></p>

<p><span> To understand the NXP ECDSA implementation, find a vulnerability and design a key-recovery attack, we had to make a quick stop on <i>Rhea</i> (NXP J3D081 JavaCard smartcard). Freely available on the web, this product looks very much like the NXP A700X chip and uses the same cryptographic library. <i>Rhea</i>, as an open JavaCard platform, gives us more control to study the ECDSA engine.</span></p>

<p><span> We could then show that the electromagnetic side-channel signal bears partial information about the ECDSA ephemeral key. The sensitive information is recovered with a non-supervised machine learning method and plugged into a customized lattice-based attack scheme.</span></p>

<p><span> Finally, 4000 ECDSA observations were enough to recover the (known) secret key on <i>Rhea</i> and validate our attack process. It was then applied on the <i>Google Titan Security Key</i> with success (this time by using 6000 observations) as we were able to extract the long term ECDSA private key linked to a FIDO U2F account created for the experiment.</span></p>

<h3>Cautionary Note</h3>
<p><span> Two-factor authentication tokens (like FIDO U2F hardware devices) primary goal is to fight phishing attacks. Our attack requires physical access to the <i>Google Titan Security Key</i>, expensive equipment, custom software, and technical skills.</span></p>

<p><span> <b>Thus, as far as our study goes, it is still safer to use your <i>Google Titan Security Key</i> or other impacted products as FIDO U2F two-factor authentication token to sign in to applications rather than not using one.</b></span></p>

<p><span> Nevertheless, this work shows that the <i>Google Titan Security Key</i> (and other impacted products) would not avoid unnoticed security breach by attackers willing to put enough effort into it. Users that face such a threat should probably switch to other FIDO U2F hardware security keys, where no vulnerability has yet been discovered.</span></p>

<h3>Discovered By</h3>
<p><span> Victor lomné (NinjaLab) and Thomas Roche (NinjaLab).<br>
with the help of Camille Mutschler (NinjaLab) and Dr. Laurent Imbert (LIRMM, CNRS).</span></p>

<h3>List of Impacted Products</h3>
<ul>
<li> Google Titan Security Key (all versions) </li>
<li> Yubico Yubikey Neo </li>
<li> Feitian FIDO NFC USB-A / K9 </li>
<li> Feitian MultiPass FIDO / K13 </li>
<li> Feitian ePass FIDO USB-C / K21 </li>
<li> Feitian FIDO NFC USB-C / K40 </li>
<li> NXP J3D081_M59_DF and variants </li>
<li> NXP J3A081 and variants </li>
<li> NXP J2E081_M64 and variants </li>
<li> NXP J3D145_M59 and variants </li>
<li> NXP J3D081_M59 and variants </li>
<li> NXP J3E145_M64 and variants </li>
<li> NXP J3E081_M64_DF and variants </li>
</ul>


<h3>Further Notes</h3>
<p><span>
1. The impacted Yubico Yubikey Neo is an old product no more available for sale. All FIDO U2F Yubico Yubikeys currently available on their webstore are based on a newer secure element from Infineon, and are not impacted by our work to our knowledge.
</span></p>
<p><span>
2. The NXP P5 / SmartMX secure microcontroller family and its associated cryptographic library (up to v2.9) impacted by our work is quite old. Since, NXP has released two new generations of secure microcontroller families, the “NXP P60 / SmartMX2” family and now the “NXP P70 / SmartMX3” family. Both are Common Criteria certified (with recent certification process), and are not impacted by our work to our knowledge.
</span></p>

<h3>CVE</h3>
<p><span> 
We assigned <a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-3011" target="_blank" rel="noopener noreferrer">CVE-2021-3011</a>
</span></p>
	</div><!--/.blog-post-entry.markup-format-->
</article><!--/#post-747.blog-post-->
			</section><!--/#blog-->
		</div><!--/.col-sm-7-->
			</div><!--/.row-->
</div></div>]]>
            </description>
            <link>https://ninjalab.io/a-side-journey-to-titan/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25675556</guid>
            <pubDate>Thu, 07 Jan 2021 19:00:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Libbpf-rs: eBPF for the Rust ecosystem]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25675109">thread link</a>) | @danobi
<br/>
January 7, 2021 | https://dxuuu.xyz/libbpf-rs.html | <a href="https://web.archive.org/web/*/https://dxuuu.xyz/libbpf-rs.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://dxuuu.xyz/libbpf-rs.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25675109</guid>
            <pubDate>Thu, 07 Jan 2021 18:27:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bitcoin Has Passed $40k]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25674953">thread link</a>) | @electic
<br/>
January 7, 2021 | https://blockmodo.com/quotes/BTC | <a href="https://web.archive.org/web/*/https://blockmodo.com/quotes/BTC">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://blockmodo.com/quotes/BTC</link>
            <guid isPermaLink="false">hacker-news-small-sites-25674953</guid>
            <pubDate>Thu, 07 Jan 2021 18:17:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Help! My Bitcoin was stolen! Why “Bitcoin recovery” services are scams]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25674723">thread link</a>) | @HeroicLife
<br/>
January 7, 2021 | https://walletrecovery.info/my-bitcoin-was-stolen-can-you-help/ | <a href="https://web.archive.org/web/*/https://walletrecovery.info/my-bitcoin-was-stolen-can-you-help/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Billions of dollars in Bitcoin are stolen every year.&nbsp; If you’re a victim of Bitcoin theft or a scam, read this article first.</p>
<p>I will tell you why most “recovery” services are scams, and what you should actually do.</p>
<h3><strong>Can a Bitcoin recovery service help get my stolen Bitcoin/Ethereum/etc back?</strong></h3>
<p>The first and most important thing you should know is <strong>that there is absolutely no way to reverse confirmed Bitcoin/cryptocurrency transactions</strong>.&nbsp; Once a transaction is confirmed on the Blockchain, there is no way to reverse it.</p>
<p><strong>Beware of “Bitcoin recovery” scams</strong></p>
<p>There are many “Bitcoin recovery” services that claim to be able to return stolen Bitcoin.&nbsp; They will have all kinds of explanations of how they do this.</p>
<p>Here is a debunking of the most common recovery methods:</p>
<h3><strong>Lawyers:&nbsp;</strong></h3>
<p><strong>What they promise: </strong>we will prosecute thieves and force them to return stolen Bitcoin</p>
<p><strong>Why it won’t work:&nbsp;</strong></p>
<p>In almost all cases, you won’t know the identity of the people who stole your Bitcoin. It’s nearly impossible to find out the real-world identity of the owner of a given Bitcoin address.</p>
<p>Even if you have a name, email address, “registered trading account,” website, etc, it will be very difficult to obtain the cooperation of the police in getting their real-world identity.</p>
<p>The police don’t care about “small scale” theft. In most cases, the thieves will be in a different country than you.&nbsp; Furthermore, unlike cash, there is no paper trail to follow.&nbsp; Bitcoin/cryptocurrency is generally considered “property” rather than money, and hacking isn’t given the same weight as theft of physical goods.&nbsp; All of this makes authorities unlikely to pursue cases.</p>
<p>Even when the identity of the thieves is definitely known, the Bitcoin is rarely returned. The only cases where Bitcoin has been recovered in theft has been in a class-action lawsuit (such as with Mt Gox). Even then, it usually takes thousands of victims, at least tens of millions of dollars stolen, expensive attorneys, and many years.</p>
<p>I’m not saying it’s impossible. Just don’t expect to send a random lawyer $5000-$10,000 (typical “recovery” fees) and anything useful to happen. It’s a scam.</p>
<h3><strong>“Ethical hackers”</strong></h3>
<p><strong>What they promise:</strong> we will hack the thieves and get them to return your Bitcoin.</p>
<p><strong>Why it won’t work:</strong></p>
<p>First, anyone who was able to steal your money is already a sophisticated hacker. Most “hackers” prey on the technologically ignorant.&nbsp; Anyone capable of stealing your Bitcoin probably knows the tricks of so-called “ethical hackers”.</p>
<p>Second, it’s nearly impossible to find out the real-world identity from a Bitcoin address or an email address.&nbsp; If the U.S. government struggles to find find out who operates darknet markets, what hope has some hacker you paid $1000?</p>
<p>Third, even an “ethical hacker” has to break into someone else’s systems — and probably break some laws in the process. If they could someone break into people’s computers to get their Bitcoin, why should they return it to you?&nbsp; Why do they need you at all?&nbsp; If they can hack people’s computers to steal Bitcoin, they are just as likely to steal yours.</p>
<p>There are no credible, independent reports of anyone successfully doing this. “Ethical hackers” that return Bitcoin for cash upfront simply do not exist.&nbsp; It’s a scam.</p>
<h3><strong>Blockchain hackers</strong></h3>
<p><strong>What they promise:</strong> we will hack Bitcoin or brute force your private key to reverse the transaction and return your Bitcoin.</p>
<p><strong>Why it won’t work:</strong></p>
<p>The market cap of Bitcoin is nearly $700 billion dollars.&nbsp; Every single Bitcoin transaction and address is public.&nbsp; If someone could steal or reverse a Bitcoin transaction, they wouldn’t be helping you.&nbsp; <a href="https://99bitcoins.com/bitcoin/rich-list/">They would be going after the richest Bitcoin wallets worth tens of billions of dollars.</a> Of course, once it got out that Bitcoin could be hacked, the exploit would either be patched, or Bitcoin would become worthless.</p>
<p>No matter how brilliant they claim to be, it’s a scam.</p>
<h3><strong>Chainalysis</strong></h3>
<p><strong>What they claim:</strong> we will trace Bitcoin transaction to the service holding them, and force them to return your money.</p>
<p><strong>Why it won’t work:</strong></p>
<p>Chainalysis is a real thing.&nbsp; <a href="https://www.chainalysis.com/">There are companies</a> that keep databases of addresses used by criminals and gambling sites, and help exchanges ban those customers.&nbsp;&nbsp;Unfortunately, they can’t help you for a few reasons:</p>
<p>First, they have expensive products for businesses and governments than the random recovery service you found online probably doesn’t have access to.</p>
<p>Second, the most they can do is trace which major exchange or business got your Bitcoin.&nbsp; At this point, you would need the cooperation of the exchange to tell you which customer made that deposit.&nbsp; That cooperation is impossible to obtain without a court order, which as previously explained is nearly impossible to obtain.&nbsp; Furthermore, thieves don’t use cooperative exchanges in the first place, since they require <a href="https://www.wikiwand.com/en/Know_your_customer">KYC. </a>If they want to cash out, they are going to use some less-reputable service in a country that probably does not cooperate with your government.</p>
<p>Third, once your crypto hits an exchange, it’s impossible to trace what a given customer does with it next.&nbsp; If someone simply deposits Bitcoin with an exchange, you will never know when they take it out or move it.&nbsp; This is because exchanges combine all their funds, so your stolen Bitcoin will be given to whoever requests a withdrawal first.&nbsp; It will not be withdrawn by the person who deposited it.</p>
<p>Fourth, criminals don’t keep Bitcoin at exchanges.&nbsp; In my experience, they will either sit on it for years or cash it out immediately. They are not stupid enough to keep it where it can be confiscated, however unlikely that is.</p>
<p>It’s a scam.</p>
<h3><strong>Conclusion:&nbsp;</strong></h3>
<p>It is nearly impossible to return your stolen cryptocurrency.&nbsp; Don’t lose more of your money in vain.</p>
<p><strong>Am I wrong?&nbsp; Are there other “recovery” methods I forgot to mention? Please let me know below.</strong></p>
<h3><strong>So what should I do?</strong></h3>
<p>First, there is a small qualification that <strong>unconfirmed transactions can be reversed or canceled</strong>.&nbsp; In a few cases, I’ve been able to reverse transactions that haven’t confirmed yet.&nbsp; It’s rare and requires immediate action.&nbsp; Usually, this happens with wallets that receive mining payments, as they require much higher fees to confirm.</p>
<p>Second, if your Bitcoin keys, logins, seed, etc have been leaked or exposed, but the thieves have not yet sent it away, you must act <strong>immediately&nbsp;</strong>to transfer it to a new private wallet.</p>
<p>Third, realize that if someone has stolen your Bitcoin, you may still be vulnerable to theft. You probably did something wrong or were exploited by someone who can do it again.</p>
<p>Don’t go out and buy more Bitcoin.&nbsp; You need to <a href="https://walletrecovery.info/ten-essential-security-practices-to-keep-your-bitcoin-safe/">perform a security audit</a> to understand how it was stolen. You may have a keylogger tracking all your keystrokes, or a root exploit that allows someone to access all your files.&nbsp; Educate yourself. Learn about <a href="https://walletrecovery.info/watch-out-for-these-five-common-bitcoin-cryptocurrency-scams/">the most common cryptocurrency scams</a>. At a minimum,&nbsp; <a href="https://walletrecovery.info/how-to-safely-store-bitcoin-and-other-cryptocurrencies/">read my article on how to safely store Bitcoin</a>.</p>
<p>Fourth, make sure your crypto was really stolen.&nbsp; You should see a transaction to an address that does not belong to you on a date/time you did not make any transactions.&nbsp;&nbsp;<strong><a href="https://walletrecovery.info/contact-us/">If you’re not sure, ask for help</a></strong>.&nbsp; If you don’t see an outgoing transaction, it was probably not stolen – you’re doing something wrong.</p>
<p>Fifth, if your Bitcoin was stolen, and you held it before August 2017, check to see if the BCH/BSV forks have been claimed.&nbsp; Do this immediately, before the crooks do.</p>
 </div></div>]]>
            </description>
            <link>https://walletrecovery.info/my-bitcoin-was-stolen-can-you-help/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25674723</guid>
            <pubDate>Thu, 07 Jan 2021 18:04:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Book Review: Machine Learning Design Patterns]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25674710">thread link</a>) | @cl42
<br/>
January 7, 2021 | https://phaseai.com/resources/machine-learning-design-patterns | <a href="https://web.archive.org/web/*/https://phaseai.com/resources/machine-learning-design-patterns">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

     
     <p><i>By Wojciech Gryc on January 6, 2021</i>
     
     </p><p><i>TLDR:</i> This book is a fantastic introduction to the terminology and architecture options for building ML-driven products and services. If you are new to the field or are a technology leader who needs to brush up on their ML terminology and options, then this book is for you. Experts in the field looking to innovate on model performance might want to look elsewhere.
     
     </p><hr>
     
     <p>An oft-overlooked area of data science is the actual architecture of machine learning systems. It’s easy to get excited about the latest algorithms and ML packages, but broader <i>operationalization</i> of the system is taken for granted. If you are a data scientist aspiring to work in product with companies shipping productized ML models, then <a href="https://learning.oreilly.com/library/view/machine-learning-design/9781098115777/" target="_blank"><i>Machine Learning Design Patterns</i></a> is worth a perusal.
     
     </p><p>The book addresses an issue that we at Phase AI see constantly: terminology in this space is still new, and the way we describe design patterns – let alone use them – is inconsistent. Worse still, a poorly architected ML product could introduce so many problems down that line that it all but guarantees failure for a startup or product launch. It’s wonderful to see the authors try and address this.

     </p><p>The majority of the book (chapters 2 through 7) provides an overview of common approaches to discussing and addressing machine learning problems. This includes data ingestion, cleaning, modeling, and even the ethics of AI. Each chapter has a set important terms and approaches (i.e., the design patterns); it provides definitions for the design pattern, and examples of how one can implement the design pattern and address common issues with it.

     </p><p>Let’s look at data preparation (Chapter 2, <i>Data Representation Design Patterns</i>) as an example. The authors provide an overview of how different types of variables can be represented for machine learning problems. This includes concepts like one-hot encoding, feature embedding, multimodal inputs, and more. One can write 1000s of pages on the topics in each chapter, so this is really more about terminology and a general introduction.

     </p><p>In addition to standardization of terminology, the book presents helpful diagrams on how to structure ML-driven products and pipelines. Figure 8-5, shown below, is a good example of this. These diagrams are critical to understanding the architecture and design patterns powering ML projects, and I hope more VPs of Engineering and Architecture document, review, and promote such diagrams within their ML-driven product and service organizations… Such documentation is the only way architecture principles will maintain their integrity as teams scale and team members come and go.<br>&nbsp;

    </p><center><img src="https://phaseai.com/static/img/scr-ml-design-pattern.png"><br><i>Figure 8-5 showing how to build out an end-to-end ML architecture and pipeline, from data exploration to providing a full model in production.</i><br>&nbsp;</center>
    
    <p>My biggest qualm with the book is that much of it is spent laying the groundwork for the field, and as such, only one chapter focuses on how the design patterns in this book could be used for building solutions to common problems. I would love to see a few chapters dedicated to in-depth analysis of architectures (or options) for performant product recommendation systems, or a fraud model at a bank, or something else. This could be a good opportunity for a sequel.

    </p><p>The question remains, however: who is this book for? If you are just learning ML or data science, you might benefit from a skim, but I would suggest you focus on learning the core skills of data science. If you are now entering the world of product management, architecting solutions, or leading an ML team, then these concepts are vital; if you are not familiar with them, then this is a good place to start. Similarly, if you are a technology manager or leader who doesn’t have much experience with ML, then this book will provide a nice foundation for your work.

     </p></div></div>]]>
            </description>
            <link>https://phaseai.com/resources/machine-learning-design-patterns</link>
            <guid isPermaLink="false">hacker-news-small-sites-25674710</guid>
            <pubDate>Thu, 07 Jan 2021 18:02:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Will Trump be suspended from Twitter before April 1, 2021?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25674580">thread link</a>) | @donut2d
<br/>
January 7, 2021 | https://polymarket.com/market/will-president-trump-be-suspended-from-twitter-before-april-1-2021 | <a href="https://web.archive.org/web/*/https://polymarket.com/market/will-president-trump-be-suspended-from-twitter-before-april-1-2021">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://polymarket.com/market/will-president-trump-be-suspended-from-twitter-before-april-1-2021</link>
            <guid isPermaLink="false">hacker-news-small-sites-25674580</guid>
            <pubDate>Thu, 07 Jan 2021 17:56:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gettin' Ziggy with It on the Pi Zero]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25674206">thread link</a>) | @jorangreef
<br/>
January 7, 2021 | https://www.kamelasa.dev/programming/gettin-ziggy-with-it-pi-zero/ | <a href="https://web.archive.org/web/*/https://www.kamelasa.dev/programming/gettin-ziggy-with-it-pi-zero/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <header>
          <p><a href="https://www.kamelasa.dev/">kamelåså</a>
            <span>special topics in calamity something or other</span>
          </p>
        </header>
        
      </div>
    </div><div><article>
    

    <section>
        <p>Alright, you can read the article first and shoot me later for a title like that, and what will inevitably become a series of Zig-based puns.</p>
<p>Zig, for the unaware, is a fancy language that looks to be to C what Rust is to C++. Honestly, I recommend you read the summary on the main page<a href="#fn1" id="fnref1" role="doc-noteref"><sup>1</sup></a> to find out more yourself, as the best I can do is to just parrot what has already been written. However, you can see it as a valid <em>alternative</em> to C and Zig itself has claimed that it wants to be a better version of C than C itself. An ambitious challenge, for sure. To that end, Zig itself ships its own C compiler.</p>
<p>I’ve been interested in giving Zig a spin for quite a while, and once my Raspberry Pi Zero W<a href="#fn2" id="fnref2" role="doc-noteref"><sup>2</sup></a> and OLED display<a href="#fn3" id="fnref3" role="doc-noteref"><sup>3</sup></a> arrived in the post, I decided that this would be my best opportunity to try it out. I’m not really going to cover the process of wiring up the hardware, suffice to say that once you’ve got your Pi Zero you’ll need to be able to SSH into it, and that you’ll need a [solderless] GPIO header<a href="#fn4" id="fnref4" role="doc-noteref"><sup>4</sup></a> to plug the OLED display into. I recommend the Zero <strong>W</strong> because the W means ‘WiFi’, which means that if you connect it to your network you can SSH in without faffing around with USB cables and what not. It’s not a requirement, though.</p>
<p>With that out of the way, let’s see if we can write something in Zig to power this little display. It’s going to be a simple program that simply fills the entire screen by turning the pixels from black (off) to white (on). As an extra challenge, we will do this without pulling in dependencies like WiringPi<a href="#fn5" id="fnref5" role="doc-noteref"><sup>5</sup></a>, or relying on existing drivers, as lovely as they are.</p>
<p>Instead, we will be directly using the i<sup>2</sup>c dev interface<a href="#fn6" id="fnref6" role="doc-noteref"><sup>6</sup></a>. If you’re using Debian and/or Ubuntu on your Pi and your own machine, you can grab these libraries with a simple <code>sudo apt install i2c-dev</code>. You will need to enable i<sup>2</sup>c on your Pi separately though, through <code>sudo raspi-config</code><a href="#fn7" id="fnref7" role="doc-noteref"><sup>7</sup></a>.</p>
<p>Ready to… get Ziggy with it? Oh, I bet you are. 😋 If you want to skip to the end and just grab the code, though, you can find this all on GitHub<a href="#fn8" id="fnref8" role="doc-noteref"><sup>8</sup></a>. I called it Stardust, like <em>Zig</em>gy Stardust. Get it?</p>
<p>🥁</p>
<hr>
<h2 id="hello-pi.">Hello, Pi.</h2>
<p>The first and most complicated part of any low-level project is the bit where you try and establish a build system of some sorts. We’re going to forget about that completely for now and apply some elbow-grease to the situation.</p>
<p>The next step is to define a <code>main</code> function that grabs a file descriptor (or handle) corresponding to our OLED display. According to the aforementioned dev interface docs, we’ll need to open a file and check it with <code>ioctl</code>.</p>
<pre><code>const std = @import("std");

const c = @cImport({
  @cInclude("linux/i2c.h");
  @cInclude("linux/i2c-dev.h");
  @cInclude("sys/ioctl.h");
});

const i2c_device = "/dev/i2c-1"; // this is assumed correct on a Pi Zero, but may be i2c-0 on an older Pi.
const i2c_addr: c_int = 0x3c; // this is typed as a C-style int for ABI compatibility with C

pub fn main() !void {
  const stdout = std.io.getStdOut().outStream();

  const fd = try fs.openFileAbsolute(i2c_device, fs.File.OpenFlags{ .write = true, .read = true });
  defer fd.close();

  if (c.ioctl(fd.handle, c.I2C_SLAVE, i2c_addr) &lt; 0)) {
    try stdout.print("ioctl failed, errno: {}\n", c.errno);
  }

  stdout.print("Init successful.\n", .{});
}</code></pre>
<p>You might have noticed something odd: we’re not really writing much Zig here, it’s practically 95% interop with C. The beauty of Zig is that this interop is so simple and intuitive that it’s the <em>easiest</em> way to get started if you’re going to be linking against existing C libraries. Get the software working first, abstract it later, as they say, and you might already start to get an idea of what we could convert into idiomatic Zig libraries in future.</p>
<p>The actual Zig code you see though, is quite different to the C stuff. That <code>defer fd.close()</code>, for example, <em>ensures</em> that the file descriptor we opened up will be closed when we’re done. If we don’t do that, then it’ll stay open and there’ll be a leak.</p>
<p>There’s also the <code>try</code> macro, used in combination with the <code>!void</code> return type, which will be super familiar if you’ve written some Rust and have dealt with option types. It’s short hand for executing the code and catching/dealing with the error, with <code>!void</code> being another shorthand for <code>anyerror!void</code>, namely: this function returns either nothing, or an error if there is one.</p>
<p>WHat we’ve actually done, however, is open the device file <code>/dev/i2c-1</code>, and then used the <code>ioctl</code> library to specify which device in particular we want to talk to. You can find out this value by running <code>i2cdevice -y 1</code>, like so:</p>
<pre><code>pi@raspberrypi:~ $ i2cdetect -y 1
     0  1  2  3  4  5  6  7  8  9  a  b  c  d  e  f
00:          -- -- -- -- -- -- -- -- -- -- -- -- --
10: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --
20: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --
30: -- -- -- -- -- -- -- -- -- -- -- -- 3c -- -- --
40: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --
50: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --
60: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --
70: -- -- -- -- -- -- -- --</code></pre>

<p>We’re at a good point now to try and compile this thing and then run it on the Pi. If we get the message ‘Init successful.’ then we’re golden.</p>
<hr>
<h2 id="build-and-push">Build and Push</h2>
<p>Zig comes with a nice little build system out of the box, but we’re not going to use it right now because it’s a work in progress. I’ll leave that as an exercise to you, the reader, and I urge you to contribute any documentation you come up with to Zig. Instead, we’ll use the CLI which is just as powerful and, gracefully, a bit more discoverable for our purposes.</p>
<p>Are you writing this code on the Pi itself? Probably not, I imagine, and nor do you need to.</p>
<blockquote>
<p>Cross-compiling is a first-class use case</p>
<p>Andrew Kelley, Creator of Zig</p>
</blockquote>
<p>Let’s build a binary, then. Save your code into a file, say, <code>stardust.zig</code> and then proceed.</p>
<pre><code>zig build-exe stardust.zig  -target arm-linux-musleabihf -mcpu arm1176jzf_s -O ReleaseSafe -lc</code></pre>
<p>To unpack that a little, the <code>target</code> is a triplet stating that we want to build this using the musl<a href="#fn9" id="fnref9" role="doc-noteref"><sup>9</sup></a> libc ABI, on a 32bit ARM architecture. <code>mcpu</code> goes along with that to make sure the resulting binary will work on our Pi Zero. I grabbed these values from an issue on Zig’s github repo<a href="#fn10" id="fnref10" role="doc-noteref"><sup>10</sup></a>, so credit goes to the author of that issue for unintentionally guiding me forward.</p>
<p>Passing the optimiser flag (<code>-O</code>) isn’t strictly necessary, so you can omit this if you require a debug build and stack traces with errors.</p>
<p><code>-lc</code> basically says that this binary needs to be linked against libc.</p>
<p>Once the build finishes, you should find a shiny new executable called <code>stardust</code> in the same directory as your code. You can get it onto your Pi with <code>scp</code>, like so:</p>
<pre><code>scp stardust pi@raspberrypi:~/stardust</code></pre>

<p>SSH into your Pi after that, and try and run it! Does it return successfully? I hope so!</p>
<p>Let’s move on and make this kitten purr. Meow 🐈.</p>
<hr>
<h2 id="getting-this-show-on-the-road">Getting this show on the road</h2>
<p>In true <em>draw the rest of the fucking owl</em> fashion<a href="#fn11" id="fnref11" role="doc-noteref"><sup>11</sup></a>, what follows is a bit of a code-dump since the primary method of communicating with your OLED display is to, literally, write a few bytes to a file. The registers available and what can be written to them are often described in a meticulously detailed datasheet<a href="#fn12" id="fnref12" role="doc-noteref"><sup>12</sup></a>, but they’re not exactly light reading and we can save a bit of time by grabbing the info from elsewhere. A lot of the constants that follow are gracefully derived from those listed in a certain <code>owenosborn</code>’s wiringPi-based driver.<a href="#fn13" id="fnref13" role="doc-noteref"><sup>13</sup></a>. Credit where credit’s due, eh.</p>
<pre><code>const SET_CONTRAST = 0x81;
const SET_DISPLAY_ALL_ON_RESUME = 0xA4;
const SET_DISPLAY_ALL_ON = 0xA5;
const SET_NORMAL_DISPLAY = 0xA6;
const SET_INVERT_DISPLAY = 0xA7;
const SET_DISPLAY_OFF = 0xAE;
const SET_DISPLAY_ON = 0xAF;
const SET_DISPLAY_OFFSET = 0xD3;
const SET_COLUMN_ADDR = 0x21;
const SET_PAGE_ADDR = 0x22;
const SET_COM_PINS = 0xDA;
const SET_VCOM_DETECT = 0xDB;
const SET_DISPLAY_CLOCK_FREQ = 0xD5;
const SET_PRECHARGE = 0xD9;
const SET_MULTIPLEX_RATIO = 0xA8;
const SET_LOW_COLUMN = 0x00;
const SET_HIGH_COLUMN = 0x10;
const SET_START_LINE = 0x40;
const SET_START_PAGE = 0xB0;
const SET_MEMORY_MODE = 0x20;
const SET_COM_SCAN_INC = 0xC0;
const SET_COM_SCAN_DEC = 0xC8;
const SET_SEG_REMAP = 0xA0;
const SET_CHARGE_PUMP = 0x8D;</code></pre>
<p>The registers available to an i<sup>2</sup>c compatible device will depend on the device itself, so it’s not really safe to copy and paste these without knowing exactly what you’re dealing with. This is driver level code so it’s not like you’ll get some fancy validation error if you write the wrong bytes, you’ll more likely fuck it up and burn down your house<a href="#fn14" id="fnref14" role="doc-noteref"><sup>14</sup></a>.</p>
<p>Next we’ll want to init the display and get it into a clean state, with the cursor pointing at the first pixel.</p>
<pre><code>fn init_display(fd: fs.File) !void {
    const cmds = [_]u8{
        SET_MULTIPLEX_RATIO, 0x3F,                   0x00,
        SET_START_LINE,      SET_SEG_REMAP,          SET_COM_SCAN_DEC,
        SET_COM_PINS,        0x32,                   SET_DISPLAY_ALL_ON_RESUME,
        SET_NORMAL_DISPLAY,  SET_DISPLAY_CLOCK_FREQ, 0x80,
        SET_CHARGE_PUMP,     0x14,                   SET_MEMORY_MODE,
        0x20,
    };

    inline for (cmds) |cmd| {
        _ = try fd.write(&amp;[2]u8{ 0x00, cmd });
    }
}

fn display_off(fd: fs.File) !void {
    _ = try fd.write(&amp;[2]u8{ 0x00, SET_DISPLAY_OFF });
}

fn display_on(fd: fs.File) !void {
    _ = try fd.write(&amp;[2]u8{ 0x00, SET_DISPLAY_ON });
}

fn reset_cursor(fd: fs.File) !void {
    const cmds = [_]u8{
        SET_COLUMN_ADDR,
        0x00,
        0x7F,
        SET_PAGE_ADDR,
        0x00,
        0x07,
    };

    inline for (cmds) |cmd| {
        _ = try fd.write(&amp;[2]u8{ 0x00, cmd });
    }
}</code></pre>
<p>Wow, actual Zig code! The formatting may look a little odd because that’s what <code>zig fmt</code> decides is appropriate.</p>
<p><code>init_display</code> is quite a complex beast that issues a whole series of commands that sets up the display for further use. A more …</p></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.kamelasa.dev/programming/gettin-ziggy-with-it-pi-zero/">https://www.kamelasa.dev/programming/gettin-ziggy-with-it-pi-zero/</a></em></p>]]>
            </description>
            <link>https://www.kamelasa.dev/programming/gettin-ziggy-with-it-pi-zero/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25674206</guid>
            <pubDate>Thu, 07 Jan 2021 17:33:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Have you considered the alternative? (2017)]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25674100">thread link</a>) | @MattJ100
<br/>
January 7, 2021 | https://homebrewserver.club/have-you-considered-the-alternative.html | <a href="https://web.archive.org/web/*/https://homebrewserver.club/have-you-considered-the-alternative.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
<blockquote>
<p>“Remember, when advertising is involved you the user are the product. […]
When people ask us why we charge for WhatsApp, we say ‘Have you considered the alternative?’“</p>
</blockquote>
<p><small>Brian Acton and Jan Koum, June 2012<sup id="fnref:1"><a href="#fn:1">1</a></sup> </small></p>
<blockquote>
<p>“Facebook today announced that it has reached a definitive agreement to acquire WhatsApp, a rapidly growing cross-platform mobile messaging company,
for a total of approximately $16 billion, including $4 billion in cash and approximately $12 billion worth of Facebook shares.”</p>
</blockquote>
<p><small> Facebook Newsroom, February  2014<sup id="fnref:2"><a href="#fn:2">2</a></sup></small></p>
<blockquote>
<p>“[B]y coordinating more with Facebook, we’ll be able to do things like track basic metrics about how often people use our services and better fight spam on WhatsApp.
And by connecting your phone number with Facebook’s systems, Facebook can offer better friend suggestions and show you more relevant ads if you have an account with them.”</p>
</blockquote>
<p><small> Brian Acton and Jan Koum, August 2016<sup id="fnref:3"><a href="#fn:3">3</a></sup></small></p>
<hr>

<p>WhatsApp started out full of dreams: “we want WhatsApp to be the product that keeps you awake…and that you reach for in the morning. No one jumps up from a nap and runs to see an advertisement”<sup id="fnref:4"><a href="#fn:4">4</a></sup>. When they thought of WhatsApp, Brian Acton and Jan Koum were very keen on <em>not</em> selling our user data for targeted advertisement purposes. So they charged a nominal rate for the use of their service, rightfully pointing out the hidden cost of using free services.</p>
<p>In the year of 2014 however, WhatsApp was bought by Facebook, thus joining the social network’s happy and expanding family of venture capital investments, a family including Instagram, purchased in April 2012, and Oculus VR, purchased the month before. At the time, many, and with good reason, worried about the changes this acquisition could entail for WhatsApp. Eventually, in August 2016, WhatsApp users everywhere learned about what was in fact unavoidable. The company that built its reputation upon an ad-free ethic, would now be sharing private user information with Facebook, its parent company. So we, the users, are the product after all, and as expected, this is presented in the form of an <em>improvement</em> of the user experience. Thanks to the tighter coordination between WhatsApp and Facebook, we can now more easily find our friends or see more valuable messages from the companies that truly matter to us. Of course, small footnote, these ‘benefits’ comes at the price of sharing our phone number and other private data with Facebook—though, trusting their word, not the content of the messages themselves.</p>
<p>Facebook does this for the simple reason that it needs to increase its market share on mobile devices<sup id="fnref:5"><a href="#fn:5">5</a></sup>; the family of Whatsapp, Facebook and Instagram are all <em>different</em> channels leading to this same purpose. One of the consequences of this is that while Facebook’s chat function can still be used on their mobile website, plans are that we will soon be forced to install Facebook Messenger should we wish to continue using it on our mobile phones<sup id="fnref:6"><a href="#fn:6">6</a></sup>. Once again, in a stroke of pure genius and creativity, this move is being marketed as a way to provide us with the best experience ever.  And we can use it with just a phone number, we don’t even need a Facebook account. That way, their user base expands along with their profits.</p>
<p>Every time there is a breach of user trust —read: a change in the Terms of Service— or news regarding network surveillance, people are on the lookout for an alternative, and rightfully so. In these moments there are many also willing to promote such <em>alternatives</em>, usually in the form of yet another disruptive app.  After the purchase of Whatsapp, for example, Telegram was advertised as the alternative. After it became clear that Telegram had dreadful security, people promoted Viber. Then Snapchat, then Threema, then Allo and now Signal. There is a reason why we’re falling into this pattern of needing alternatives to the alternatives. And that is because…</p>

<p>There’s a tendency to oversimplify the issues related to the use of these apps as merely a privacy matter, and not even that is sufficiently addressed. While each of the aforementioned apps are alternative companies and brands, what these alternatives all have in common is that they share the same model. A model that revolves around centralized services, vendor lock-in and marketing related surveillance, and all of that within a neoliberal context of the free market. These alternatives therefore promote themselves as more than just an alternative, but also as competing products, usually highlighting a particular feature lacking in rivals’ products. Remember that ill-fated, super cool, nice looking alternative to Facebook, Ello? It gained a lot of traction out of legitimate concerns with Facebook’s modus operandi, promoting itself as an alternative for its nice features and its promise not to use advertising. But as Aral Balkan was quick to point out, allowing investments by venture capital firms meant the project was dead before it really began<sup id="fnref:7"><a href="#fn:7">7</a></sup>. Taking these investments, which allowed them to scale as a platform, also meant that they would, at some point, <em>have</em> to make a lot of money for their investors. How? By selling ad space or information about their users. The reason the pattern keeps repeating itself is not because the makers of these apps always secretly intended to sell your data while saying they wouldn’t. The reason is that they have no choice within the economic system they choose to operate in.</p>

<p>The latest competitive feature—one might even say, marketing trick—to make concerned users switch from one alternative to another is cryptography, the act of coding messages during communication. This strategy works well because the vast majority of people are not really informed when it comes down to the technicalities of cryptography, so this discourse mostly serves to throw bedazzling sparkles in our eyes. To be sure, cryptography is fundamental for privacy. However, the main privacy threat in the context of using these apps isn’t the potential of a government eavesdropping on our communications. The privacy threat is the wholesale and increasing dependence on centralized services which revolve around the surveillance and monetization of user information. In 2016, both WhatsApp and Facebook Messenger enabled end-to-end encryption<a href="http://homebrewserver.club/beginners-guide-to-xmpp-speak.html#e2e"><sup>?</sup></a> to address increasing privacy concerns. Adding <em>crypto</em> to a communication app in this case merely obfuscates a concern about the hegemony of these platforms. In essence, the issue of privacy is much larger than just the lack of cryptography; the conditions that threaten privacy are structural and economic and not resolved by a <em>patch</em> or a new feature.</p>
<p>This issue is further stressed when looking at the question of metadata, that is to say, data about data, which in the case of communication applications is everything but the communication data itself. When WhatsApp started sharing, among other things, its users’ phone numbers with its parent company, Facebook, it went to great lengths to guarantee us that the content of our messages was still perfectly secure, impossible to be read by both WhatsApp and Facebook. The argument stating that “It’s only metadata, don’t worry” has been however debunked numerous times. Even though these platforms would love us to believe otherwise, metadata is neither a trivial disposable by-product, nor it is anonymous. And assuming that the crypto is sound and that the app running this crypto is not flawed, cross-referencing several databases containing metadata will always produce an array of very personal information, that in itself is much more valuable than encrypted naked selfies. Thus it should be no surprise that former NSA director Michael Hayden infamously said in 2012 “we kill based on metadata”<sup id="fnref:8"><a href="#fn:8">8</a></sup> and later argued in 2015 that metadata should be the main area of focus of surveillance activities, and not the creation of backdoors within crypto, or the banning of the latter<sup id="fnref:9"><a href="#fn:9">9</a></sup>.</p>
<p>In short, both Whatsapp and FacebookMessenger can afford to deploy end-to-end encryption for your messages because it won’t hurt their bottom line, which is making money based on the surveillance of your behavior and your social graph. Adding crypto thus merely patches your privacy worries, but not the threat to it.</p>

<p>The end-to-end encryption enabled in WhatsApp and Facebook Messenger has been developed by Open Whisper Systems, a non-profit run by crypto-celebrity Moxie Marlinspike. OWS also developed the algorithm for their own instant messaging application, Signal, and then open-sourced it. Signal itself is now the latest app being promoted as an alternative to WhatsApp and is hailed as the panacea of both security and usability. It even has the backing of members of the dissident elite such as Edward Snowden.</p>
<p>While OWS provides thorough expertise in the field of cryptography, Marlinspike is currently advocating centralisation as the only answer towards user-friendly, fast and secure messaging apps. Decentralisation, according to him, has no place in the modern world and apparently hampers innovation. However, some of his arguments have not remained unchallenged. In particular, where Marlinspike accuses federation of stalling evolution<sup id="fnref:11"><a href="#fn:11">11</a></sup>, Daniel Gultsch<sup id="fnref:12"><a href="#fn:12">12</a></sup> provides a counter argument by using the Web as an example of successfully federated system<a href="http://homebrewserver.club/beginners-guide-to-xmpp-speak.html#federated"><sup>?</sup></a>. Furthermore, Gultsch states that the problem is not that federation doesn’t adapt, but rather that there are problems with its implementation for a very significant reason: software developers working on federated systems mostly work for free in their spare time or with little means, given the difficulty to monetise a system which design can only succeed if it is open and can be appropriated easily beyond its original scope, and thus making its capitalisation particularly challenging. In that sense, the most interesting aspect of this debate is that while Marlinspike seems to defend his product from a technological perspective, Gultsch’s counter argument moves back the discussion to the context of political economy.</p>
<p>Dani…</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://homebrewserver.club/have-you-considered-the-alternative.html">https://homebrewserver.club/have-you-considered-the-alternative.html</a></em></p>]]>
            </description>
            <link>https://homebrewserver.club/have-you-considered-the-alternative.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25674100</guid>
            <pubDate>Thu, 07 Jan 2021 17:27:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[RubyGems Bitcoin Stealing Malware Postmortem]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25674098">thread link</a>) | @vinnyglennon
<br/>
January 7, 2021 | https://mensfeld.pl/2020/12/rubygems-bitcoin-stealing-malware-postmortem/ | <a href="https://web.archive.org/web/*/https://mensfeld.pl/2020/12/rubygems-bitcoin-stealing-malware-postmortem/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://mensfeld.pl/2020/12/rubygems-bitcoin-stealing-malware-postmortem/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25674098</guid>
            <pubDate>Thu, 07 Jan 2021 17:27:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Migrating Your Open Source Builds Off of Travis CI]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25674056">thread link</a>) | @agbell
<br/>
January 7, 2021 | https://blog.earthly.dev/migrating-from-travis/ | <a href="https://web.archive.org/web/*/https://blog.earthly.dev/migrating-from-travis/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <div>
                    <p>Starting in early December, a mad dash has been underway to migrate open-source projects off of Travis CI. What happened and where should you move your project to?</p><figure><img src="https://blog.earthly.dev/content/images/2021/01/Screen-Shot-2021-01-05-at-3.42.32-PM.png" alt=""><figcaption><a href="https://twitter.com/james_hilliard/status/1336081776691843072">Jame's Hilliard on Twitter</a></figcaption></figure><p>If you're not familiar with Travis CI, it's a build company that has been powering the continuous integration (CI) of many open source projects since it launched in 2011. &nbsp;It was the first build solution that was free for open source use and that easily integrated into GitHub.</p><h2 id="what-happened">What Happened?</h2><p>In 2019 Travis was acquired by a private equity group and many engineers were let go.</p><figure><blockquote data-width="550"><p lang="en" dir="ltr">So apparently Travis CI is being strip-mined immediately after their acquisition by Idera. Sorry, I mean after "joining the Idera family" 🙄 <a href="https://t.co/CE5ERp1RsY">https://t.co/CE5ERp1RsY</a> A bunch of talented people are waking up to termination letters. Absolutely shameful. <a href="https://t.co/BbBRPdnswe">https://t.co/BbBRPdnswe</a></p>— Senior Oops Engineer (@ReinH) <a href="https://twitter.com/ReinH/status/1098663375985229825?ref_src=twsrc%5Etfw">February 21, 2019</a></blockquote>

</figure><p>Then, on Nov 2, 2020, Travis CI announced the end of its unlimited support for open-source projects: </p><blockquote>For those of you who have been building on public repositories (on travis-ci.com, with no paid subscription), we will upgrade you to our trial (free) plan with a 10K credit allotment.</blockquote><blockquote><strong>When your credit allotment runs out - we’d love for you to consider which of our plans will meet your needs.</strong> - <a href="https://blog.travis-ci.com/2020-11-02-travis-ci-new-billing">Travis CI blogpost</a></blockquote><p>The reason behind the change is stated to be abuse by crypto-miners:</p><blockquote>However, in recent months we have encountered significant abuse of the intention of this offering (increased activity of cryptocurrency miners, TOR nodes operators etc.). </blockquote><p> However, many feel the real reason is that the acquirer is aiming for profitability at all costs and supporting the open-source community represents a significant cost.</p><blockquote>My previous company was on Travis, and as soon as I saw that Travis was purchased by private equity, I knew the downward spiral had begun and I recommended we move to something else. Not surprised that this is happening a couple of years later...my understanding is that private equity will tend towards slowing/stopping development after acquisition to cut costs/headcount, and then squeeze the remaining value from what's left, so this is in-line with that playbook. &nbsp;- <a href="https://news.ycombinator.com/item?id=25340486">rpdillion on hacker news</a></blockquote><h2 id="why-it-matters">Why it Matters</h2><blockquote>The open source movement runs on the heroic efforts of not enough people doing too much work. They need help. - <a href="https://www.wired.com/author/clive-thompson">CLIVE THOMPSON</a></blockquote><p>Many open-source projects are still using Travis and open-source maintainers are notoriously overworked. &nbsp;Time spent migrating builds is time not spent on other things. &nbsp;Large well-maintained projects will likely quickly transition but for many smaller projects, an abrupt change in a service they depend on is a huge challenge. </p><h2 id="where-to-move-to">Where To Move To</h2><figure><img src="https://blog.earthly.dev/content/images/2021/01/Screen-Shot-2021-01-06-at-4.53.01-PM.png" alt="" srcset="https://blog.earthly.dev/content/images/size/w600/2021/01/Screen-Shot-2021-01-06-at-4.53.01-PM.png 600w, https://blog.earthly.dev/content/images/size/w1000/2021/01/Screen-Shot-2021-01-06-at-4.53.01-PM.png 1000w, https://blog.earthly.dev/content/images/size/w1600/2021/01/Screen-Shot-2021-01-06-at-4.53.01-PM.png 1600w, https://blog.earthly.dev/content/images/size/w2400/2021/01/Screen-Shot-2021-01-06-at-4.53.01-PM.png 2400w" sizes="(min-width: 720px) 720px"></figure><p>If you maintain an open-source project that uses TravisCI and are hoping to get off it, then assuming you have the time to migrate, there are actually many viable options.</p><h3 id="option-run-your-own-builds">Option: Run Your Own Builds</h3><p>You can find some <a href="https://medium.com/google-developers/how-to-run-travisci-locally-on-docker-822fc6b2db2e">scattered</a> <a href="https://stackoverflow.com/a/35972902">instructions</a> <a href="https://stackoverflow.com/a/35972902">online</a> for running Travis builds yourself. There are mixed reports on the stability and feasibility of this approach, but if your adventurous you could try to setup your own Travis CI build executor on your own hardware.</p><p>A better option, if you want to run the builds on your own hardware is to look at something like <a href="https://buildkite.com/">Buildkite</a> or <a href="https://about.gitlab.com/stages-devops-lifecycle/continuous-integration/https://about.gitlab.com/stages-devops-lifecycle/continuous-integration/">GitLab CI</a>.</p><h3 id="option-circle-ci">Option: Circle CI</h3><p>A better option is Circle CI, a Travis CI competitor which still offers a free plan. &nbsp; </p><p>Circle CI offers 400,000 build credits per month to any open-source public repository. &nbsp;This is their free plan and limits concurrency to 1 job at a time. They also have an easy GitHub integration and no application process. &nbsp;</p><p>They also allow use of the free plan with private repositories. This makes it a great choice if your project is not actually open-source. More details <a href="https://circleci.com/open-source/">can be found here</a>.</p><h3 id="best-option-github-actions">Best Option: Github Actions</h3><figure><img src="https://blog.earthly.dev/content/images/2021/01/Screen-Shot-2021-01-06-at-5.12.18-PM.png" alt="" srcset="https://blog.earthly.dev/content/images/size/w600/2021/01/Screen-Shot-2021-01-06-at-5.12.18-PM.png 600w, https://blog.earthly.dev/content/images/size/w1000/2021/01/Screen-Shot-2021-01-06-at-5.12.18-PM.png 1000w, https://blog.earthly.dev/content/images/size/w1600/2021/01/Screen-Shot-2021-01-06-at-5.12.18-PM.png 1600w, https://blog.earthly.dev/content/images/size/w2400/2021/01/Screen-Shot-2021-01-06-at-5.12.18-PM.png 2400w" sizes="(min-width: 720px) 720px"></figure><p>An even better option is Github Actions, a cloud CI system directly from GitHub. &nbsp;Github is at the center of many open source projects and this makes it a natural choice for CI. &nbsp;</p><p>Github Actions (GHA) is newer than either TravisCI or Circle CI, having launched in late 2018. </p><p>GHA offers very generous build credits, 20 concurrent build jobs per project and no limit on build time used. &nbsp; If your pipeline can be run in parallel this concurrency can really be a great enabler. &nbsp;The only limitation I was able to find is that the build may last no longer than 6 hours in total. </p><p>If your project is hosted on GitHub, then to me, GHA seems like the best bet right now. More details about the open-source plan can <a href="https://docs.github.com/en/free-pro-team@latest/actions/reference/usage-limits-billing-and-administration">be found here</a>.</p><h3 id="summary-of-open-source-plans">Summary of Open Source Plans</h3><!--kg-card-begin: html--><table>
<thead>
<tr>
<th>Service</th>
<th>Open Source Offering</th>
</tr>
</thead>
<tbody>
<tr>
<td>Travis CI</td>
<td><a href="https://blog.travis-ci.com/2020-11-02-travis-ci-new-billing">1000 minutes total with application process for more</a></td></tr><tr>
<td>Circle CI</td>
    <td><a href="https://circleci.com/open-source/">1 concurrent build at a time</a></td>
</tr>
<tr>
<td>GitHub Actions</td>
    <td><a href="https://docs.github.com/en/free-pro-team@latest/actions/reference/usage-limits-billing-and-administration">20 concurrent build jobs per project</a></td>
</tr>

</tbody></table><!--kg-card-end: html--><h2 id="don-t-let-this-happen-again">Don't Let This Happen Again</h2><p>So GitHub has a generous build plan, but moving your CI process is not easy or free. &nbsp;The more complex your build, the harder porting from one cloud CI to another is going to be. &nbsp;If you move to GHA and then GHA stops being a viable option in the future then this whole effort will have to be repeated. &nbsp;</p><h2 id="neutral-build-specifications">Neutral Build Specifications</h2><figure><img src="https://blog.earthly.dev/content/images/2021/01/Screen-Shot-2021-01-06-at-4.58.54-PM.png" alt="" srcset="https://blog.earthly.dev/content/images/size/w600/2021/01/Screen-Shot-2021-01-06-at-4.58.54-PM.png 600w, https://blog.earthly.dev/content/images/size/w1000/2021/01/Screen-Shot-2021-01-06-at-4.58.54-PM.png 1000w, https://blog.earthly.dev/content/images/size/w1600/2021/01/Screen-Shot-2021-01-06-at-4.58.54-PM.png 1600w, https://blog.earthly.dev/content/images/size/w2400/2021/01/Screen-Shot-2021-01-06-at-4.58.54-PM.png 2400w" sizes="(min-width: 720px) 720px"></figure><p>How can you minimize the effort of moving from build platform to another?</p><p>My suggestion is to keep as much logic as possible out of the proprietary build definition. Instead, define it in an open-source format that you can execute anywhere.</p><h3 id="makefiles-and-dockerfiles">Makefiles and Dockerfiles</h3><p>One way to build a CI neutral build definition is to use a makefile and a dockerfile. &nbsp;The makefile contains the various steps of your build pipeline and you run it inside a docker container which installs any needed dependencies. &nbsp;<a href="https://github.com/qmk/qmk_firmware">QMK</a> is a popular open-source project that uses this approach.</p><figure><pre><code>FROM qmkfm/base_container

VOLUME /qmk_firmware
WORKDIR /qmk_firmware
COPY . .

CMD make all:default</code></pre><figcaption><a href="https://github.com/qmk/qmk_firmware/blob/master/Dockerfile">QMK</a> Docker File for executing the full build</figcaption></figure><h3 id="earthly">Earthly</h3><p>This is the Earthly blog, and I am an Earthly contributor, but in my totally biased opinion, it deserves a mention as an neurtal format for defining a build. The Elixir web framework <a href="https://github.com/phoenixframework/phoenix/blob/master/Earthfile">Phoenix is a great example to take a look at</a>.</p><p>Earthly is like a makefile where each step is containerized and dependencies are explicitly declared. &nbsp;</p><figure><pre><code>FROM golang:1.13-alpine3.11

build:
	COPY main.go .
	RUN go build main.go
	SAVE ARTIFACT main AS LOCAL main
    
lint: 
	...</code></pre><figcaption>Example build steps for a <a href="https://github.com/earthly/earthly/blob/main/examples/go/Earthfile">go application</a></figcaption></figure><h2 id="other-interesting-options">Other Interesting Options</h2><h3 id="easier-migration-from-travis-to-gha">Easier Migration from Travis to GHA</h3><p>Migrating your build out of Travis might take a little work. &nbsp;If you aren't interested in a neutral format, <a href="https://github.com/marketplace/actions/run-travis-yml">this GHA action</a> might make it easier. &nbsp;</p><blockquote>This action setups environment variables specified in the <code>.travis.yml</code> file and then runs <em>one</em> of the (potentially) many build jobs within the test build stage.</blockquote><h3 id="serverless-builds">Serverless Builds</h3><p> Another interesting option if you are feeling adventurous is using AWS lambda as your build executor. &nbsp;I have no idea how feasible this is, however, <a href="https://github.com/StanfordSNR/gg">the gg project</a> from Stanford looks interesting. &nbsp;It attempts to use AWS lambdas for running builds at the maximum possible parallelism. &nbsp;</p><h2 id="take-aways">Take Aways</h2><p>You probably need to move your open-source project's builds off of Travis CI. If you host it on GitHub, GitHub Actions is probably a good choice.</p><p>There is a risk that the GHA offer will disappear as well. &nbsp;You can protect yourself from that by defining your build in an open format that is easy to move around. &nbsp;All build problems can be solved by another layer of abstraction.</p><p>If you are going that route, I think <a href="http://earthly.dev/">Earthly</a> is a great option, but as I said, I am biased.</p>
                </div>
            </section></div>]]>
            </description>
            <link>https://blog.earthly.dev/migrating-from-travis/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25674056</guid>
            <pubDate>Thu, 07 Jan 2021 17:25:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dissecting the Apple M1 GPU, part I]]>
            </title>
            <description>
<![CDATA[
Score 484 | Comments 106 (<a href="https://news.ycombinator.com/item?id=25673631">thread link</a>) | @caution
<br/>
January 7, 2021 | https://rosenzweig.io/blog/asahi-gpu-part-1.html | <a href="https://web.archive.org/web/*/https://rosenzweig.io/blog/asahi-gpu-part-1.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<header><p>7 Jan 2021</p></header><p>Apple’s latest line of Macs includes their in-house “M1” system-on-chip, featuring a custom GPU. This poses a problem for those of us in the <a href="https://asahilinux.org/">Asahi Linux</a> project who wish to run Linux on our devices, as this custom Apple GPU has neither public documentation nor open source drivers. Some speculate it might descend from PowerVR GPUs, as used in older iPhones, while others believe the GPU to be completely custom. But rumours and speculations are no fun when we can peek under the hood ourselves!</p>
<p>A few weeks ago, I purchased a Mac Mini with an M1 GPU as a development target to study the instruction set and command stream, to understand the GPU’s architecture at a level not previously publicly understood, and ultimately to accelerate the development of a Mesa driver for the hardware. Today I’ve reached my first milestone: I now understand enough of the instruction set to disassemble simple shaders with a free and open-source tool chain, <a href="https://github.com/AsahiLinux/gpu">released on GitHub here</a>.</p>
<p>The process for decoding the instruction set and command stream of the GPU parallels the same process I used for reverse-engineering Mali GPUs in the Panfrost project, originally pioneered by the Lima, Freedreno, and Nouveau free software driver projects. Typically, for Linux or Android driver reverse-engineering, a small wrap library will be written to inject into a test application via <code>LD_PRELOAD</code> that hooks key system calls like <code>ioctl</code> and <code>mmap</code> in order to analyze user-kernel interactions. Once the “submit command buffer” call is issued, the library can dump all (mapped) shared memory for offline analysis.</p>
<p>The same overall process will work for the M1, but there are some macOSisms that need to be translated. First, there is no <code>LD_PRELOAD</code> on macOS; the equivalent is <code>DYLD_INSERT_LIBRARIES</code>, which has some extra security features which are easy enough to turn off for our purposes. Second, while the standard Linux/BSD system calls do exist on macOS, they are not used for graphics drivers. Instead, Apple’s own <code>IOKit</code> framework is used for both kernel and userspace drivers, with the critical entry point of <code>IOConnectCallMethod</code>, an analogue of <code>ioctl</code>. These differences are easy enough to paper over, but they do add a layer of distance from the standard Linux tooling.</p>
<p>The bigger issue is orienting ourselves in the IOKit world. Since Linux is under a copyleft license, (legal) kernel drivers are open source, so the <code>ioctl</code> interface is public, albeit vendor-specific. macOS’s kernel (XNU) being under a permissive license brings no such obligations; the kernel interface is proprietary and undocumented. Even after wrapping <code>IOConnectCallMethod</code>, it took some elbow grease to identify the three critical calls: memory allocation, command buffer creation, and command buffer submission. Wrapping the allocation and creation calls is essential for tracking GPU visible memory (what we are interested in studying), and wrapping the submission call is essential for timing the memory dump.</p>
<p>With those obstacles cleared, we can finally get to the shader binaries, black boxes in themselves. However, the process from here on out is standard: start with the simplest fragment or compute shader possible, make a small change in the input source code, and compare the output binaries. Iterating on this process is tedious but will quickly reveal key structures, including opcode numbers.</p>
<p>The findings of the process documented in the free software disassembler confirm a number of traits of the GPU:</p>
<p>One, this is a scalar architecture. Unlike some GPUs that are scalar for 32-bits but vectorized for 16-bits, the M1’s GPU is scalar at all bit sizes. Yet Metal optimization resources imply 16-bit arithmetic should be significantly faster, in addition to a reduction of register usage leading to higher thread count (occupancy). This suggests the hardware is superscalar, with more 16-bit ALUs than 32-bit ALUs, allowing the part to benefit from low-precision graphics shaders much more than competing chips can, while removing a great deal of complexity from the compiler.</p>
<p>Two, this seems to handle scheduling in hardware, common among desktop GPUs but less so in the embedded space. This again makes the compiler simpler at the expense of more hardware. Instructions seem to have minimal encoding overhead, unlike other architectures which need to pad out instructions with <em>nop</em>’s to accommodate highly constrained instruction sets.</p>
<p>Three, various modifiers are supported. Floating point ALUs can do clamps (saturate), negates, and absolute value modifiers “for free”, a common shader architecture trait. Further, most (all?) instructions can type-convert between 16-bit and 32-bit “for free” on both the destination and the sources, which allows the compiler to be much more aggressive about using 16-bit operations without risking conversion overheads. On the integer side, various bitwise complements and shifts are allowed on certain instructions for free. None of this is unique to Apple’s design, but it’s worth noting all the same.</p>
<p>Finally, not all ALU instructions have the same timing. Instructions like <code>imad</code>, used to multiply two integers and add a third, are avoided in favour of repeated <code>iadd</code> integer addition instructions where possible. This also suggests a superscalar architecture; software-scheduled designs like those I work on for my day job cannot exploit differences in pipeline length, inadvertently slowing down simple instructions to match the speed of complex ones.</p>
<p>From my prior experience working with GPUs, I continue to expect to find some eldritch horror waiting in the instruction set, to balloon compiler complexity. Though the above work currently covers only a small surface area of the instruction set, so far everything seems sound. There are no convoluted optimization tricks, but doing away with the trickery is creating a streamlined, efficient design that does one thing and does it well. Maybe Apple’s hardware engineers discovered it’s hard to beat simplicity.</p>
<p>Alas, a shader tool chain isn’t much use without an open-source userspace driver. Next up: dissecting the command stream!</p>
<p><em>Disclaimer: This work is a hobby project, conducted based on public information. Opinions expressed may not reflect those of my employer.</em></p>
<p><a href="https://rosenzweig.io/">Back to home</a></p>
</div>]]>
            </description>
            <link>https://rosenzweig.io/blog/asahi-gpu-part-1.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25673631</guid>
            <pubDate>Thu, 07 Jan 2021 17:01:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My stack is HTML+CSS]]>
            </title>
            <description>
<![CDATA[
Score 211 | Comments 164 (<a href="https://news.ycombinator.com/item?id=25673495">thread link</a>) | @zdw
<br/>
January 7, 2021 | https://blog.steren.fr/2020/my-stack-will-outlive-yours/ | <a href="https://web.archive.org/web/*/https://blog.steren.fr/2020/my-stack-will-outlive-yours/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
  <article>
	<header>
		
		<time date="2020-12-22">December 2020</time>
	</header>

		<p>
		My stack requires no maintenance, has perfect Lighthouse scores, will never have any security vulnerability, is based on open standards, is portable, has an instant dev loop, has no build step and… will outlive any other stack.
		</p>
		<p>
		It’s not LAMP, Wordpress, Rails, MEAN, Jamstack... I don’t do CSR (Client-side rendering), SSR (Server Side Rendering), SSG (Static Site Generation)...
		</p>
		<p>
		My stack is <b>HTML+CSS</b>.
		</p>
		<p>
		And because my sources are in git, pushed to GitHub, <a href="https://pages.github.com/">GitHub Pages</a> is my host.
		</p>
		<p>
		Of course, I’m being a bit provocative here. I should rather say that, for some specific use cases, I concluded that to get top performances and to guatantee long term support, HTML+CSS was the best choice, instead on relying on technologies currently more popular. Because I’m done rewriting my site every couple of years.
		</p>

		<h3>Why HTML+CSS?</h3>
		<p>
		It all started with <a href="https://labs.steren.fr/">a blog</a>, that I was hosting on Wordpress.com (which is "Wordpress-as-a-Service", because the last thing I want to do is administer a Wordpress installation on my own server). I <strong>paid</strong> Wordpress.com to do one job: host my blog. And one day I looked at its sources and Lighthouse scores:
		</p>
		<figure>
			<img src="https://blog.steren.fr/2020/my-stack-will-outlive-yours/wordpress-sources.png" alt="Sources of my Wordpress.com blog, showing a lot of inlined unreadable scripts">
			<figcaption>Sources of my Wordpress.com blog, what is all this?</figcaption>
		</figure>
		<figure>
			<img src="https://blog.steren.fr/2020/my-stack-will-outlive-yours/wordpress-lighthouse.png" alt="Lighthouse scores of my Wordpress.com blog, showing 19/100 for Performance">
			<figcaption>Lighthouse score of my blog hosted on Wordpress.com</figcaption>
		</figure>
		<p>
		What have we done?
		</p>
		<p>
		Sure, these are the problems of one specific blogging platform. I’m pretty sure others are better, at least in terms of performance. But isn’t there something fundamentally wrong if displaying a short text with images takes seconds, loads countless render-blocking scripts, and has unreadable sources?
		</p>
		<p>
		My requirements were:
		</p>
		<ol>
			<li>performance</li>
			<li>simplicity</li>
			<li>long long term support</li>
		</ol>
		<p>
		It was time to say goodbye to Wordpress. I didn’t need 99% of its features anyway. Other blogging platforms didn’t meet expectations either (I seriously have no idea why so many people publish on Medium… behind a login wall). I looked at static site generators like Jekyll, Hugo, 11ty, but all of these require tooling installed, have a build step and will ultimately need some updates or be abandonned by their maintainer. What if we also get rid of these?
		</p>
		<p>
		The best tool is no tool, the best build step is no build step, the best update is no update. HTML gives us all that, and more.
		</p>

		<figure>
			<img src="https://blog.steren.fr/2020/my-stack-will-outlive-yours/lighthouse-score-pure-html-css.svg" alt="Lighthouse score of 100">
			<figcaption>Lighthouse score of this page</figcaption>
		</figure>

		<h3>What is the HTML+CSS stack good for?</h3>
		<p>
		Let’s first differentiate between what I call a web <em>page</em> and a web <em>app</em>: The goal of a web <em>page</em> is to serve content, on the other hand, the goal of a web <em>app</em> is to enable the user to perform interactive tasks. Of course, there are in-betweens, often in the form of content that might need customization depending on the logged in user and content that might allow some interactions.
		</p>
		<p>
		HTML+CSS fits the web <em>page</em> use case. Wow, what a revelation! It might seem obvious, but it seems we’ve all forgotten this these days. HTML+CSS does not fit the web <em>app </em>use case, or any in between.
		</p>
		<p>
		We said a web <em>page</em> serves content, but let’s dive into more concrete use cases:
		</p>
		<ul>
			<li>Product / Company / Business landing page and marketing sites</li>
			<li>Personal portfolio / bio</li>
			<li>Blog</li>
			<li>Documentation</li>
		</ul>

		<h3>How to develop for HTML+CSS?</h3>
		<p>
		Authoring a pure HTML+CSS site can be done in any text editor, in any environment (any desktop OS, any smartphone, or even directly using GitHub’s single file editor) and previewed by simply opening the file in any browser.
		</p>
		<p>
		Keep the HTML of every page minimal and semantic. First, because there is no need for countless of &lt;div&gt;, but then because it makes sources more readable and easier to edit. See for example the <a href="https://github.com/steren/blog/blob/master/2020/my-stack-will-outlive-yours/index.html">HTML sources of this page</a>: a total of 150 lines, 100 lines are for the content, the rest is metadata and page structure, nothing extra. 
		</p>
		<p>
		For consistency, all pages that need to share the same style can point to the same CSS file. This avoids  duplication when it comes to styling (but note that loading this file creates an extra HTTP request, which could be avoided if style was inlined).
		</p>
		<p>
		When not cluttered with unnecessary scripts, divs or classes, I have no issue writing HTML directly. Yes, the paragraph tags are a bit annoying and distracting, but proper indentation and syntax highlighting mitigate this.
		<br>
		Sometimes, for drafting long blog articles, I’m working in Google Docs, and when I’m happy, export the content to clean HTML using an add-on. Google Docs is awesome for collaboration, with powerful suggestions and commenting system. That’s ideal for the “draft” phase. 
		<br>
		Because all content is in git, final review and approval can be done via GitHub pull requests.
		</p>
		<p>
		When I publish a new page, I need to link to it manually from the index page. I’m OK with that. It’s done in one line. It also allows me to have more control over when I want the page to be “published”.
		</p>
		<p>
		I don't need to pay for custom themes, I have complete freedom in the style and layout of my site.
		I can embed anything I want without being restricted by the choice of the hosting platform: SVG images, 3D models, interactive JS experiences. 
		</p>
		<p>
		Creating a new page requires to clone an existing one.
		So... if I don’t use any templating system, how do I update my header, footer or nav? Well, simply by using the ”Replace in files” feature of any good text editor. They don’t need frequent updates anyway. The benefits of using a templating system is not worth the cost of introducing the tooling it requires.
		</p>
		
		<h3>In conclusion</h3>
		<p>
		You don’t need  Wordpress, or Hugo to put a blog online, or Angular, React or Next.js to put a web page online. Raw HTML and CSS do the job.
		</p>
		<p>
		That being said, you’ll need to pick up some tooling or framework if you want to build a web app or add more interactivity or customization to your web pages. And for that, I’m very glad to see that frameworks now seem to be prioritizing performance, notably by prioritizing serving the content first and leveraging caching whenever possible. The era of “download 5MB of JS first and then download content from a REST API” seems to be over for content web pages. (I personally think it’s still OK to do so for web apps, as the user’s intent and expectations are different).
		</p>
		<p>
		Is the “HTML+CSS only” approach a bit extreme? A bit, it’s basically saying “all software is terrible, how can I minimize my dependencies on software”. Web standards are a model of backward compatibility. I’m pretty confident that my web pages written in raw HTML+CSS will have no issue being accessed and authored 10 years from now, without me having to do anything.
		</p>  
	</article>
</div></div>]]>
            </description>
            <link>https://blog.steren.fr/2020/my-stack-will-outlive-yours/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25673495</guid>
            <pubDate>Thu, 07 Jan 2021 16:54:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reducing Docker Image Size Particularly for Kubernetes Environments]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25673388">thread link</a>) | @sequoia
<br/>
January 7, 2021 | https://sequoia.makes.software/reducing-docker-image-size-particularly-for-kubernetes-environments/ | <a href="https://web.archive.org/web/*/https://sequoia.makes.software/reducing-docker-image-size-particularly-for-kubernetes-environments/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="content"><h2 id="one-day-on-slack-">
    <a href="#one-day-on-slack-">
      
    </a>
    One Day on Slack...</h2><blockquote>
<p>1.3gb for a web app?! The size of your Docker image is getting out of control!</p>
</blockquote>
<p>Uh-oh... The infrastructure team is <em>calling you out</em> for your Docker image size! Larger images means...</p>
<ul>
<li><a href="https://kubernetes.io/docs/concepts/workloads/controllers/garbage-collection/">Garbage collection of stale images &amp; containers</a> takes longer*</li>
<li>Node storage runs out faster*</li>
<li>It takes longer to build the image</li>
<li>It takes longer to send the image over the wire</li>
</ul>
<p>All of these are small problems but <strong>they add up!</strong> So your image is too big–don't panic! Following a few simple steps, you can cut your Docker image down to size in next to no time.</p>
<p>*<em>this post assumes you are running Docker images in Kubernetes.</em></p>
<h2 id="contents-of-this-post">
    <a href="#contents-of-this-post">
      
    </a>
    Contents of This Post</h2><ol>
<li><a href="#analyzing-your-image">Analyzing your image to see why it's big</a></li>
<li><a href="#chopping-your-image-in-twain">Chopping your image in two</a></li>
<li><a href="#cleaning-up-image-contents">Cleaning up image contents</a></li>
</ol>
<h2 id="analyzing-your-image">
    <a href="#analyzing-your-image">
      
    </a>
    Analyzing Your Image</h2><p>How big is your image? Assuming you've run <code>docker build</code> to build your image locally, this is easy to check with <code>docker images</code>:</p>
<pre><code>➜ docker images
REPOSITORY                           TAG      IMAGE ID      CREATED       SIZE
gcr.io/ns-1/toodle-app               d82c28d  e4f0fd00de6d  4 months ago  1.32GB
gcr.io/ns-2/go-af                    v0.12.1  d665db43eb95  4 months ago  911MB
</code></pre>
<p>Our <code>toodle-app</code> image is <code>1.32 GB</code>. But why is it so big? To figure that out, we'll use a handy tool called <a href="https://github.com/wagoodman/dive">dive</a> to analyze the image layer by layer.</p>
<pre><code>➜ dive gcr.io/ns-1/toodle-app:d82c28d
Image Source: docker://gcr.io/ns-1/toodle-app:d82c28d
Fetching image... (this can take a while for large images)
</code></pre>
<p>When it completes it will show a view like this:</p>
<p><img src="https://sequoia.makes.software/img/docker-dive-1.png" alt="dive command output"></p>
<p>There's a lot going on here!</p>
<ul>
<li>The top-left panel shows you <strong>layers</strong>, each of which corresponds to a Dockerfile command. (If the command if it's truncated, find the <em>full</em> command below in the "Layer Details" section.)</li>
<li>The right column shows the filesystem tree for the <strong>currently selected layer</strong>–more on this later</li>
<li>The bottom left is <strong>Image Details</strong> and does not change as you navigate through the layers</li>
</ul>
<p>Use the arrow keys to navigate up and down in the currently selected pane. Use <code>tab</code> to switch from the Layers pane to Current Layer Contents and back. Here I've pressed the down arrow several times to get to the 309 MB <code>RUN make build/bin/server</code> layer, then used <code>tab</code> to switch focus to the Current Layer Contents panel:</p>
<p><img src="https://sequoia.makes.software/img/docker-dive-2.png" alt="dive command output: &quot;RUN make build/bin/server&quot; layer"></p>
<p>By default, the Current Layer Contents shows you a full tree of the filesystem up to and including the selected layer. What's typically more useful when analyzing your image size by layer is to see what files were added by <em>that</em> layer. Use <code>ctrl+u</code> (see "^U Unmodified" in the bottom right of the screenshot) to toggle that option <em>off</em>, which <strong>hides files unmodified by the current layer</strong>. This leaves visible only files that were Added, Removed, or Modified by <em>this</em> layer:</p>
<p><img src="https://sequoia.makes.software/img/docker-dive-3.png" alt="dive command output: &quot;RUN make build/bin/server&quot; layer with unmodified files hidden"></p>
<p>Hello, what's this–this layer (which runs <code>go build</code> to build the actual toodle-app binary) add 309MB, but 237MB of that is <a href="https://golang.org/ref/mod#module-cache">go mod cache</a>, which <strong>we do not need after the binary has been built!</strong></p>
<p>Now we know why this layer is larger than it should be and we can see about cleaning it up (we'll do this <a href="#remove-build-tools-and-assets-after-the-build-completes">below</a>). Repeat the process for other large layers, or just poke around and see what each layer is adding or modifying.</p>
<p>Now that we know how to figure out <em>why</em> it's big, let's look at some strategies to cut down an image's size...</p>
<h2 id="chopping-your-image-in-twain">
    <a href="#chopping-your-image-in-twain">
      
    </a>
    Chopping Your Image in Twain</h2><p>When we build a project inside a docker image, each of the things we pull or copy into that image falls into one of two categories:</p>
<ol>
<li>Stuff we need to <strong>build</strong> the application</li>
<li>Stuff we need to <strong>run</strong> the application</li>
</ol>
<p>Some of the things we add to our toodle-app image, above:</p>
<ul>
<li><code>make</code>: needed to <strong>build</strong> the application</li>
<li><code>gcc</code>: needed to <strong>build</strong> the application</li>
<li>go modules: needed to <strong>build</strong> the application</li>
<li><code>nginx</code>: needed to <strong>run</strong> the application</li>
<li><code>./build/client/strings</code>: needed to <strong>run</strong> the application</li>
<li>the <code>build/bin/server</code> binary we create: needed to <strong>run</strong> the application</li>
</ul>
<p>The stuff we need only at build time (<code>make</code>, <code>gcc</code>, etc.) <strong>does not need to be shipped as part of the image</strong> because <strong>it is not needed at runtime</strong>. We could uninstall <code>make</code> <code>gcc</code> etc. after running the build, but there is an even cleaner way: <strong>create one image just for building the application and one image just for running the application</strong>.</p>
<p>This has become a common pattern, and there are two ways to do this:</p>
<h3 id="two-separate-docker-files-em-old-approach-should-not-be-needed-anymore-em-">
    <a href="#two-separate-docker-files-em-old-approach-should-not-be-needed-anymore-em-">
      
    </a>
    Two Separate Docker Files ❌ <em>(old approach, should not be needed anymore)</em></h3><p>With this approach you have one "builder" image and a separate "runtime" image. From a high level:</p>
<ol>
<li>A <code>Dockerfile.builder</code> Dockerfile defines your "builder" image. This builds an image based on....</li>
<li>A <em>separate</em> runtime <code>Dockerfile</code> contains <em>only</em> runtime dependencies</li>
</ol>
<p>Your CI step (e.g. on Google Cloud Build) loads the "Builder" image and <em>runs docker inside that image</em> to produce your runtime image.</p>
<h3 id="multi-stage-builds-em-current-approach-use-this-one-em-em-em-">
    <a href="#multi-stage-builds-em-current-approach-use-this-one-em-em-em-">
      
    </a>
    Multi-Stage Builds ✅ <em>(current approach: use this one</em> 😄<em>)</em></h3><p><a href="https://docs.docker.com/develop/develop-images/multistage-build/">Multi-Stage Builds</a> vastly simplify this process! A multi-stage docker file has multiple <code>FROM</code> commands, the first one for the "builder" and the second one for the "runtime." Basically you install all the build dependencies in your builder, run your build, then in the runtime build you <code>COPY</code> the build artifact into your runtime image which you can then deploy.</p>
<pre><code>

<span>FROM</span> golang:<span>1.7</span>.<span>3</span> AS sequoiasbuilder
<span>WORKDIR</span><span> /tmp/foo
</span><span>COPY</span><span> src/main.go . 
</span>

go build -o my-application ./main.go



<span>FROM</span> alpine:latest 
<span>WORKDIR</span><span> /root/
</span>

<span>COPY</span><span> --from=sequoiasbuilder /tmp/foo/my-application .
</span><span>CMD</span><span> [<span>"./my-application"</span>]</span>
</code></pre>
<p>Now only those things necessary for runtime will be shipped to kubernetes, and the go binary (and all the go modules that <code>go build</code> pulled in) etc. are discarded! Read <a href="https://docs.docker.com/develop/develop-images/multistage-build/">this short article</a> for more.</p>
<h3 id="which-one-to-use-a-note-on-layer-caching">
    <a href="#which-one-to-use-a-note-on-layer-caching">
      
    </a>
    Which one to use? A note on layer caching</h3><p>The main reason to use the "multiple dockerfiles" approach is because the underlying "builder" image can be built once and reused across many builds. But Docker image layers by default, so why would you need this? You would need this if <strong>your (<abbr title="Continuous Integration">CI</abbr>) build environment is discarding Docker image layers after each build</strong>, as Google Cloud Platform does by default. Discard docker images after each build = build from scratch each time.</p>
<p>There is a simple fix for this, however: the Kaniko builder allows layers to be <strong>stored, cached, and reused.</strong></p>
<p>❗️ On <abbr title="Google Cloud Build">GCB</abbr>, using Kaniko is recommended for <strong>both</strong> builder <strong>and</strong> multi-stage patterns. <a href="https://cloud.google.com/cloud-build/docs/kaniko-cache">Read more.</a></p>
<h2 id="cleaning-up-image-contents">
    <a href="#cleaning-up-image-contents">
      
    </a>
    Cleaning Up Image Contents</h2><p>Assuming you don't go the Multi-Stage route (above), or even if you did, you may be able to reduce your image size by <strong>removing stuff you don't actually need</strong>.</p>
<h3 id="ensure-you-em-actually-need-em-everything-you-39-ve-added">
    <a href="#ensure-you-em-actually-need-em-everything-you-39-ve-added">
      
    </a>
    Ensure you <em>actually need</em> everything you've added</h3><p>Did you start building your dockerfile by copying an existing one? If so, perhaps you have a command like this near the top</p>
<pre><code><span>RUN</span><span> apk add --no-cache make git curl bash nginx pkgconfig zeromq-dev \
     gcc musl-dev autoconf automake build-base libtool python</span>
</code></pre>
<p>Check that you <em>actually need</em> all these things! Some may be cruft from another project, or the dependency may have been replaced. <strong>This is especially important if you're building off a shared "base" image file.</strong> When using a shared base image, it's very likely that there's stuff in there you don't need. Easy money!</p>
<h3 id="remove-build-tools-and-assets-after-the-build-completes">
    <a href="#remove-build-tools-and-assets-after-the-build-completes">
      
    </a>
    Remove build tools and assets after the build completes</h3><p>As we saw above using <code>dive</code>, the toodle-app <code>go build</code> was downloading <strong>and caching</strong> 237 MB of go modules, which were needed during the build but not after:</p>
<pre><code>│ Current Layer Contents ├──────────────────────────────────────
Permission     UID:GID       Size  Filetree
drwxr-xr-x         0:0      72 MB  ├── mosmos
drwxr-xr-x         0:0      72 MB  │   └── toodle-app
drwxr-xr-x         0:0      72 MB  │       └── build
drwxr-xr-x         0:0      72 MB  │           └── bin
-rwxr-xr-x         0:0      72 MB  │               └── server
drwx------         0:0     237 MB  └── root
drwxr-xr-x         0:0     237 MB      └── .cache
drwxr-xr-x         0:0     237 MB          └── go-build
</code></pre>
<p>The following change fixed this problem in toodle-app:</p>
<pre><code><span>- RUN make build/bin/server</span>
<span>+ RUN make build/bin/server &amp;&amp; go clean -cache</span>
</code></pre>
<p>Other examples of this are removing <code>gcc</code>/<code>make</code>/<code>webpack</code> or removing <code>dev-dependencies</code> for a JavaScript project.</p>
<h3 id="remove-static-assets-when-possible">
    <a href="#remove-static-assets-when-possible">
      
    </a>
    Remove static assets when possible</h3><p>You may have static assets in your image that rarely change and are not actually needed <em>within</em> the application. For example, the toodle-app image contains various reports and media assets:</p>
<pre><code>-rw-r--r--         0:0      12 MB                  ├── MarketReport.pdf
-rw-r--r--         0:0      12 MB                  ├── EconReport.pdf
-rw-r--r--         0:0      34 MB                  ├── Toodle-MediaKit.zip
drwxr-xr-x         0:0     4.3 MB                  ├── press-releases
</code></pre>
<p>It's not huge, but this is 62MB that gets pulled by the Kubernetes controller for <em>every</em> deployment and copied into <em>every</em> container (the image upon which this post is based was running on 268 containers at the time of writing), all of which need garbage collection... it adds up!!</p>
<h2 id="conclusion">
    <a href="#conclusion">
      
    </a>
    Conclusion</h2><p>Making your images smaller is easy, it improves infrastructure performance and it saves money. What's not to like? If you've got more tips for shaving bits off your image size, drop me a line &amp; I'll add them below!</p>
<em> 
📝 Comments? Please email them to my <tt>protonmail.com</tt> address, username <tt>sequoiam</tt></em></section></div>]]>
            </description>
            <link>https://sequoia.makes.software/reducing-docker-image-size-particularly-for-kubernetes-environments/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25673388</guid>
            <pubDate>Thu, 07 Jan 2021 16:47:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No meetings, no deadlines, no full-time employees]]>
            </title>
            <description>
<![CDATA[
Score 1176 | Comments 401 (<a href="https://news.ycombinator.com/item?id=25673275">thread link</a>) | @sahillavingia
<br/>
January 7, 2021 | https://sahillavingia.com/work | <a href="https://web.archive.org/web/*/https://sahillavingia.com/work">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><label>Jan 7, 2021 • 10 min read</label><h2>No Meetings, No Deadlines, No Full-Time Employees</h2><p>I started Gumroad in 2011. In 2015, we reached a peak of 23 full-time employees. In 2016, after <a href="https://sahillavingia.com/reflecting">failing</a> to raise more money, I ended up back where I began: a one-person company.</p><p>Today, when I’m asked how many people work at Gumroad, I respond with “ten or so.” That’s how I convert the number of people we have into what others expect. But the truth is more complicated:</p><p>If we include everyone who works on Gumroad, it’s 25.</p><p>If we include full-time employees, it’s none. Not even me.</p><p>We have no meetings, and no deadlines either.</p><p>And it’s working: our creators earn over $175 million a year, and we generate $11 million in annualized revenue, growing 85% year-over-year.</p><p><img src="https://sahillavingia.com/2020-earnings.png"></p><p>That said, I don’t expect anyone to copy our way of working wholesale. We got here on accident, not some grand plan.</p><p>However, I do think there are pieces of our story and the way we work that could benefit other companies, their people, and–most importantly–their customers.</p><h2>Freedom at all costs</h2><p>After the layoffs in 2015, even though the team shrunk, Gumroad itself continued to grow.</p><p><img src="https://sahillavingia.com/2018-earnings.png"></p><p>But hiring people full-time and leasing a new office in San Francisco to work out of was untenable. Instead, I found an Indian firm called <a href="https://bigbinary.com/">BigBinary</a> and hired a few engineers as contractors.</p><p>These contractors saved the company. They fixed bugs and maintained the site while I answered support tickets, designed features, and wrote about new initatives.</p><p>Eventually, I hired back the same customer support person we had from before the layoffs, this time via an hourly contracting agreement too.</p><p>Meanwhile, I <a href="https://sahillavingia.com/bubble">moved to Utah</a> and attempted to become a full-time creator.</p><p>While Gumroad was no longer on track to become a billion-dollar company, I acquired a new asset: time. I used that time to take classes on writing and painting.</p><p>Because I was burned out and didn’t want to think about working any more than I needed to, I instituted a no-meeting, no-deadline culture.</p><p>For me, it was no longer about growth at all costs, but “freedom at all costs.”</p><p>This way, Gumroad stayed profitable, I could take a much-needed break to explore my hobbies, and the product continued to improve over time.</p><p><img src="https://sahillavingia.com/operating.png"></p><h2>How we work</h2><p>Today, working at Gumroad resembles working on an open source project like Rails. Except it’s neither open source, nor unpaid.</p><p>Instead of having meetings, people “talk” to each other via GitHub, Notion, and (occasionally) Slack, expecting responses within 24 hours. Because there are no standups or “syncs” and some projects can involve expensive feedback loops to collaborate, working this way requires clear and thoughtful communication.</p><p>Everyone writes well, and writes <em>a lot</em>.</p><p>There are no deadlines either. We ship incrementally, and launch things whenever the stuff in development is better than what’s currently in production. The occasional exception does exist, such as a tax deadline, but as a rule, I try not to tell anyone what to do or how fast to do it. When someone new joins the company, they do what everyone else does: go into our Notion queue, pick a task, and get to work, asking for clarification when needed.</p><p>Instead of setting quarterly goals or using OKRs, we move towards a single north star: maximizing how much money creators earn. It’s simple and measurable, allowing anyone in the company to do the math on how much a feature or bug-fix might be worth.</p><p>But we don’t prioritize ruthlessly.</p><p>People can work on what’s fun or rely on their intuition, because as long as we remain profitable and keep shipping, we tend to get to the important stuff eventually. Our <a href="https://www.notion.so/gumroad/Roadmap-ce2ad07c483046e7941227ad7810730d">public roadmap</a> helps Gumroad's creators hold us accountable.</p><p>We ship big things this way too.</p><p>In November 2020, we shipped <a href="https://gumroad.com/gumroad/p/introducing-gumroad-memberships">Gumroad Memberships</a>, a year in the works and now used by hundreds of creators to earn over $1,500,000 per month.</p><p>This is a screenshot from our roadmap to show what it looks like in practice:</p><p><img src="https://sahillavingia.com/memberships-roadmap.png"></p><p>For more, I recorded <a href="https://www.youtube.com/watch?v=2PcIC1DKBU0">an hour-long video</a> about how we ship something as large as Gumroad Memberships.</p><p>Gumroad engineer Helen Hood, who shipped Memberships, says, “it’s one of the biggest product launches of my career, and we shipped it without a single meeting or video call. I've worked at your typical startup, with an open floor plan, lots of whiteboards, standups and sprint planning, beers after work. I’ve also worked on a remote team with little communication and engineers largely siloed on their own projects. The way we work at Gumroad is ideal for me. It lets me maximize my productive hours, and clock out when I've hit my limit.”</p><p>Those are the broad strokes, but we’ve published more specific documentation about the way we work:</p><ul><li><a href="https://www.notion.so/gumroad/How-do-we-decide-what-to-work-on-f2064b8ab16c4cbcac1077e16c8cf33b">How do we decide what to work on?</a><p>“At the end of the day there's a lot of emotion that goes into Gumroad, that's not dissimilar from an art project. We sometimes pick what's fun and feels good to work on! We love listening to creators! We don't do tons of data analysis to decide what's worth working on.”</p></li><li><a href="https://www.notion.so/gumroad/How-do-we-communicate-06f2032bfdae4552a38149c99c68e3df">How do we communicate?</a><p>“Turn off all notifications from your phone!”</p></li><li><a href="https://www.notion.so/gumroad/What-does-working-at-Gumroad-feel-like-7d9fd1c9548245a58afe5569d76a7960">What does working at Gumroad feel like?</a><p>“We ship incrementally, iteratively, and have one massive tentpole launch a year. Every month we see how much creators got paid, then we move on. The journey is the fun part, we're not waiting to arrive at some destination.”</p></li><li><a href="https://www.notion.so/gumroad/What-s-not-so-good-at-Gumroad-847e3c285b1f45ab955ebacf52867900">What’s not so good at Gumroad?</a><p>“There's not a lot of room for growth. We're staying profitable, and not planning to double the team every year. While there will likely be a few leadership roles, there aren't plenty of them and they aren't built into the career path of working at Gumroad.”</p></li></ul><p>Gumroad’s Chris Maximin says, “this way to work is responsible for the highest level of productivity I've ever experienced. The ability to focus on actual work creates a virtuous circle benefiting both the company and the workers: 1) the company does not have to pay expensive engineers to sit around in endless, useless meetings, and 2) the engineers get to do more and learn more, which benefits them in the long term.”</p><p>This isn’t just for engineers.</p><p>Justin Mikolay, a writer at Gumroad, ships each of our <a href="https://gumroad.com/l/BCMDz">Creator Spotlights</a> this way, even though each one requires at least three people–plus the creator.</p><p><em>Everything</em> is handled this way: support, risk, content, growth, product prioritization, board decks, design feedback, and more.</p><h2>Minimum viable culture</h2><p>This way of working isn’t for everyone.</p><p>There are no retreats planned, and no social channels in Slack. There are limited opportunities for growth. And we can’t compete with the comp packages that big tech companies can provide.</p><p>But we can compete–and win–on flexibility.</p><p><a href="https://twitter.com/sidyadav">Sid Yadav</a>, former VP of Product at Teachable, joined Gumroad in 2018.</p><p>In his words, “most entrepreneurs have two options: work a full-time job and hustle nights/weekends, or leave your job and risk everything to start the company. Gumroad provided a third way: I could contract 20-35 hours a week, and for a couple days a week, incubate ideas and work on my next thing.”</p><p>In 2020, Sid left Gumroad to start his own creator economy company, <a href="https://circle.so/">Circle</a>, together with former Gumroad coworker <a href="https://community.circle.so/u/45ef416b">Rudy Santino</a>:</p><blockquote><p lang="en" dir="ltr">I’m starting a new company: <a href="https://t.co/BW40WmGBlF">https://t.co/BW40WmGBlF</a>! I’ll be sharing more about it in the coming weeks, but today I wanted to show gratitude to the life situation that made this possible: contracting for a flexible remote startup — <a href="https://twitter.com/gumroad?ref_src=twsrc%5Etfw">@gumroad</a>. It wouldn’t have happened without it.</p>— Sid Yadav (@sidyadav) <a href="https://twitter.com/sidyadav/status/1216761573479473152?ref_src=twsrc%5Etfw">January 13, 2020</a></blockquote> <p>Working on Gumroad isn't a majority of anyone's identity.</p><p>People work at Gumroad as little as they need to sustain the other parts of their lives they prefer to spend their time and energy on: a creative side-hustle, their family, or anything else.</p><p>Gumroad engineer Nathan Chan says, “I produce more value for my time than at any other company in my career, and I’m able to fully participate in parenting and watching my kiddo grow up.”</p><p>That includes me.</p><p>From 2011 to 2016, building Gumroad was my singular focus in life. But today, it is just a part of my life, like a hobby might be. For example, I paint for fun, and every once in a while, I sell a painting.</p><h2>A company of creators</h2><p>One day, out of the blue, I received an email from <a href="https://twitter.com/dvassallo">Daniel Vassallo</a>. I knew Daniel; he was a creator who had made over $250,000 on Gumroad in less than a year.</p><p>He was already using the product–so he understood what problems Gumroad ought to solve next–and he had some ideas for how he could help out:</p><blockquote>I love Gumroad (and I’m living off it!), I enjoy product scoping and strategy, and I think I can take over your PM tasks. I would only be able to dedicate around 2hrs/day on average, but I’d be available daily. Don’t know if this is the type of commitment you had in mind, but I figured if there’s a place where this arrangement can work, it’s Gumroad :)</blockquote><p>It was a perfect fit. Daniel became our new Head of Product.</p><p>It can be a great deal for Gumroad too. Before Daniel quit his job at Amazon, he was making over $400,000 a year. We pay him $120,000 a year.</p><p>How? He works ten hours a week for us. In his words:</p><blockquote><p lang="en" dir="ltr">Almost nobody is seeing this trend as an opportunity to work less, rather than to earn more. <a href="https://t.co/U9YBqp1ebn">https://t.co/U9YBqp1ebn</a></p>— Daniel Vassallo (@dvassallo) <a href="https://twitter.com/dvassallo/status/1334288446697865216?ref_src=twsrc%5Etfw">December 3, 2020</a></blockquote> <h2>Getting paid</h2><p>In practice, we pay everyone hourly based on their role. The range varies from $50 (customer support) to $250 (Head of Product) an hour.</p><p>Recently I standardized our rates world-wide:</p><blockquote><p lang="en" dir="ltr">🌍🌎🌏 Excited to announce we've deprecated all location-based pay! Gumroad will now pay you the same salary, no matter if you live in San Francisco, Bangalore, Lagos, or anywhere else.</p>— Sahil (@shl) <a href="https://twitter.com/shl/status/1334201934702493697?ref_src=twsrc%5Etfw">December 2, 2020</a></blockquote> <p>This rate is agreed upon during our interview process:</p><ol><li>Apply via a form.</li><li>An unpaid, few-hour challenge, that resembles the high-level work we do at Gumroad. This may include breaking down a large shipment (like Gumroad Memberships) into its atomic parts, planning the schema associated with a new feature, or writing up a Help Center article.</li><li>A paid, few-week trial period, that resembles the day-to-day work we do at Gumroad. This may …</li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sahillavingia.com/work">https://sahillavingia.com/work</a></em></p>]]>
            </description>
            <link>https://sahillavingia.com/work</link>
            <guid isPermaLink="false">hacker-news-small-sites-25673275</guid>
            <pubDate>Thu, 07 Jan 2021 16:41:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What the 2020 election taught us about user research]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25672937">thread link</a>) | @darsoli
<br/>
January 7, 2021 | https://solitaired.com/what-the-2020-election-taught-us-about-user-research | <a href="https://web.archive.org/web/*/https://solitaired.com/what-the-2020-election-taught-us-about-user-research">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>By November 5, 2020, as election results continued to be tallied, it was becoming certain that Joe Biden would go on to become the winner of the 2020 US presidential election. But the outcome was far more nail-biting than expected. After all, surveys projected him to win by <a href="https://projects.fivethirtyeight.com/polls/president-general/national/">8% points nationally</a>, high single digit margins in all swing states, including by 8.4% in Wisconsin 7.9%, in Michigan, and 2.5% in Florida.</p>
<p>Bidenâ€™s presumed strength was such that even when gold-rated pollster Anne Selzer came out with a <a href="https://www.desmoinesregister.com/story/news/politics/iowa-poll/2020/10/31/election-2020-iowa-poll-president-donald-trump-leads-joe-biden/6061937002/">+7 Trump rating in Iowa</a>, she was loudly panned â€” NYTimesâ€™ Nate Cohn <a href="https://twitter.com/Nate_Cohn/status/1322684447817453569">commented</a> â€œSelzer can be wrong, and has been before,â€� with other commentators piling on as well.</p>
<p>What happened of course was different. Trump outperformed polling by 6% in Florida, 7.7% in Wisconsin, and 7.3% in Ohio. Seltzer of Iowa ended up right, when Trump beat the Iowa consensus polling by 6.9%.</p>
<p>Whatâ€™s shocking in these results isnâ€™t that polls can be off â€” that happens. Whatâ€™s shocking is the breadth of the error, across presidential, senatorial, and house levels; across geographies; across pollsters. This miss was in the same direction, of the same intensity, as the miss in 2016, despite all the hand-wringing and adjustments and model updates that happened in the interim.</p>
<p>How did the most generously-funded, highest-quality, and highest-frequency election polling in history get it wrong? While the eulogy is still being written, many theories point to a fundamental problem â€” a response sample that turned out to be non-random.</p>
<p>For anyone who has taken a beginnerâ€™s statistics course, the foundation of all calculations rely on random sampling. Confidence intervals and margins of error are meaningless if your sample isnâ€™t random.</p>
<p>While weâ€™d like to believe polls are random samples â€” they are not. Non-responsive bias and self-selection are two of many ways samples can be improperly collected; <a href="https://www.nytimes.com/2020/11/10/upshot/polls-what-went-wrong.html">a leading theory</a> is that Trump voter social disaffection led to the polling misses.</p>
<p>We, the voting public, believed that polling firms who were well-funded and staffed to the brim with PhDs, would figure out techniques around this. As is now obvious, that assumption was dead wrong, as wrong in 2020 as it was in 2016.</p>
<h2 id="whatdoestheelectionresulthavetodowithuserresearch">What does the election result have to do with user research?</h2>
<p>If the best polling firms in the world can come to the wrong conclusions, what does this mean for user research?</p>
<p>User research often manifests itself as independent functions within larger corporations. Or, it refers to the products of companies like User Leap, User Testing, and others who promote the idea of â€œcontinuousâ€� research, promising Web app developers with the data they need to understand how users use their product.</p>
<div>

  <p><img src="https://defbnszqe1hwm.cloudfront.net/images/survey-box.png"><br>
  <span>Does this <a href="https://www.google.com/search?q=foresee+survey&amp;tbm=isch&amp;ved=2ahUKEwja8Ournu_tAhVKsFMKHQGHDKgQ2-cCegQIABAA&amp;oq=foresee+s&amp;gs_lcp=CgNpbWcQARgAMgQIIxAnMgIIADICCAAyAggAMgIIADIGCAAQCBAeMgYIABAIEB4yBggAEAgQHjIECAAQGDIECAAQGDoECAAQQzoFCAAQsQM6CAgAELEDEIMBOgcIABCxAxBDUNJhWKFsYORwaAFwAHgAgAFdiAGGBZIBAjEwmAEAoAEBqgELZ3dzLXdpei1pbWfAAQE&amp;sclient=img&amp;ei=PA7pX9riH8rgzgKBjrLACg&amp;bih=699&amp;biw=1440&amp;hl=en#imgrc=pySAZ-pP94o7hM&amp;imgdii=CoQbW0vptoztuM">annoying window</a> ring a bell?</span>

</p></div>
<p>Regardless of the tool, these approaches have the same fault at their core â€” the lack of a random sample. Most users dismiss survey prompts on web sites. Most users will never fork over our time to conduct an in-person research survey. The people that do respond are self-selecting by definition â€” maybe theyâ€™re overly pissed off about something or maybe theyâ€™re bored, but theyâ€™re definitely not random.</p>
<p>If the data youâ€™re using isnâ€™t randomly sampled, your conclusions are going to be invalid. And that can be costly â€” for your time, your team, and your business.</p>
<h2 id="howdoyoudouserresearchtherightway">How do you do user research the right way?</h2>
<h3 id="lookatyouranalyticsmorecarefully">Look at your analytics more carefully.</h3>
<p>User research purports to answer â€œwhyâ€� people behave in the ways that you see them behave in your analytics. But as we know, the whys are based on non-random samples and therefore are unsound.</p>
<p>The good news is, analytics tools like Google Analytics (or <a href="https://usefathom.com/" rel="nofollow">Fathom</a> for the privacy-minded) track nearly all users, so thereâ€™s no need to randomly sample (and when they do, itâ€™s a real random sample). They also go a long way to answer the â€œwhys.â€� Sometimes metrics differ by desktop or mobile â€” which points to device type as influential. Sometimes metrics differ by browser, which could point to specific browser bugs. With the right cut of the data, an analytics tool can often answer the why through data alone. In our case, to develop our product roadmap, we used search trends and our internal analytics to get insights that solitaire players also played <a href="https://solitaired.com/mahjong">Mahjong</a>, <a href="https://solitaired.com/freecell">FreeCell</a>, and <a href="https://solitaired.com/spider">Spider Solitaire</a>.</p>
<p>Going further, tools like HotJar record randomly-sampled screens and create heatmaps, so you can actually see what a random sample of users does on your site, which arguably is multiples more valuable than getting a response from a self-selected user or someone in a user research lab. (Note, the privacy-minded out there may not like these sorts of recording software tools â€” which is a worthy debate to have).</p>
<h3 id="experimentmore">Experiment more.</h3>
<p>Ultimately, what someone may say in a survey or explain in a lab will differ from how theyâ€™ll react in real life. The only way to know if something is working is to try it. There are many low-cost ways to try new things, including a/b testing and painted door testing (link to other post), that will minimize the time it takes for you to learn about user behavior.</p>
<p>The benefits of experimentation go beyond simply user-testing. Building an organization that can execute tests quickly means that you can iterate faster. Waiting for user research feedback can often have the opposite effect â€” adding an additional bottleneck into an often already complex software development process. <a href="https://thestartup.substack.com/p/unicorn-traits" rel="nofollow">Innovating early and often is good</a>.</p>
<h3 id="builduserresearchintoyourui">Build user research into your UI.</h3>
<p>Some sites, like Stitchfix, donâ€™t guess what their users want â€” they just ask. Integrating a survey into the actual user experience, which more or less forces users to respond and reduces bias, is another way of learning a userâ€™s intent.</p>

<h2 id="whendoestraditionaluserresearchwork">When does traditional user research work?</h2>
<p>One of the few times when user research is beneficial is when you donâ€™t need a random sample â€” aka, you have big, enterprise customers that account for a majority of your revenue.</p>
<p>Another area where user research can be important is when you have zero product and are only exploring a market. Here, however, the most important part is building relationships with potential customers â€” user research here is less about actual product workflows and more about building the customer relationships you need to get started.</p>
<p>Most importantly, user research is not just a standard stage in the product development process, where you are interviewing individual customers and relying on non-random feedback. User research should be thought about more holistically, encompassing all the tools that you have, and relying on the ones that can give you a more complete picture of user behavior â€” that includes analytics, experimentation, and data-yielding product workflows. Perhaps Googleâ€™s embrace of <a href="https://careers.google.com/jobs/results/96893097926894278-quantitative-user-experience-researcher/">quantitative user research</a> will move product development further in this direction.</p></div></div></div></div>]]>
            </description>
            <link>https://solitaired.com/what-the-2020-election-taught-us-about-user-research</link>
            <guid isPermaLink="false">hacker-news-small-sites-25672937</guid>
            <pubDate>Thu, 07 Jan 2021 16:21:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Elon Musk throws a jab at Facebook, suggests using Signal instead of WhatsApp]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25672773">thread link</a>) | @CarCooler
<br/>
January 7, 2021 | https://www.teslaoracle.com/2021/01/07/elon-musk-suggests-signal-instead-whatsapp-jabs-facebook/ | <a href="https://web.archive.org/web/*/https://www.teslaoracle.com/2021/01/07/elon-musk-suggests-signal-instead-whatsapp-jabs-facebook/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
			<figure data-amp-original-style="margin-bottom:30px;">
            <figcaption data-amp-original-style="border:1px dotted blue; margin:2px 0; text-align:center;">Advertisement</figcaption>
            <amp-ad width="100vw" height="320" type="adsense" data-ad-client="ca-pub-0923072950810999" data-ad-slot="4076643206" data-auto-format="rspv" data-full-width="" i-amphtml-layout="fixed">
              
            </amp-ad>
            </figure>
				<!-- .Adsense Ad -->

		
<p>At an early hour of the morning, Tesla &amp; SpaceX CEO Elon Musk tweeted “Use Signal” — the precursor for this tweet was an earlier reply to WhatsApp’s recent policy that forcefully asks to comply to data sharing with Facebook.</p>



<figure></figure>



<div><figure><a href="https://evannex.com/?ref=Iqtidar_TeslaOracle_EVANNEX_Banner" target="_blank" rel="sponsored noopener noreferrer"><amp-img src="https://www.teslaoracle.com/wp-content/uploads/2020/10/evannex_googlead_300x250.jpg" alt="" width="300" height="250" layout="intrinsic" i-amphtml-layout="intrinsic"><img src="https://www.teslaoracle.com/wp-content/uploads/2020/10/evannex_googlead_300x250.jpg" alt="" width="300" height="250" data-old-src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzI1MCcgd2lkdGg9JzMwMCcgeG1sbnM9J2h0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnJyB2ZXJzaW9uPScxLjEnLz4="></amp-img></a><figcaption>– Sponsored –</figcaption></figure></div>



<figure><div>
<amp-twitter width="600" height="480" layout="responsive" data-tweetid="1347165930674012168" data-width="550" data-dnt="true" i-amphtml-layout="responsive"><i-amphtml-sizer></i-amphtml-sizer><blockquote data-width="550" data-dnt="true" placeholder=""><p lang="en" dir="ltr">Yes exactly. Time to switch to Signal, folks. Open-source and independent. E2E encrypted (WhatsApp's encryption is based on the Signal protocol). Supports groups and video call now.</p>— Pranay Pathole (@PPathole) <a href="https://twitter.com/PPathole/status/1347165930674012168?ref_src=twsrc%5Etfw">January 7, 2021</a></blockquote></amp-twitter>
</div></figure>



<p>WhatsApp is actually owned by Facebook Inc. (FB), now Facebook is apparently trying to widen its human data research to the next level. With the past scandals like Cambridge Analytica, the social media platform’s credibility has been shaken.</p>



<p>Interestingly, the Cambridge Analytica scandal surfaced within a few weeks after Elon Musk <a href="https://www.theverge.com/2018/3/23/17156402/elon-musk-deleted-tesla-and-spacex-facebook-pages-twitter-challenge" target="_blank" rel="noreferrer noopener">ordered</a> to remove <a href="https://www.teslaoracle.com/topic/spacex/">SpaceX</a>, <a href="https://www.teslaoracle.com/">Tesla</a>, and his official page from Facebook. Musk has been a staunch opposer of Facebook and regularly criticizes the social media platform for bad user experience and possible misuse of personal data.</p>



<div><figure><amp-img width="465" height="1024" src="https://www.teslaoracle.com/wp-content/uploads/2021/01/WhatsApp-2021-Agreement.jpg" alt="WhatsApp 2021 agreement screenshot." srcset="https://www.teslaoracle.com/wp-content/uploads/2021/01/WhatsApp-2021-Agreement.jpg 465w, https://www.teslaoracle.com/wp-content/uploads/2021/01/WhatsApp-2021-Agreement-136x300.jpg 136w" sizes="(max-width: 465px) 100vw, 465px" layout="intrinsic" disable-inline-width="" i-amphtml-layout="intrinsic"><img loading="lazy" width="465" height="1024" src="https://www.teslaoracle.com/wp-content/uploads/2021/01/WhatsApp-2021-Agreement.jpg" alt="WhatsApp 2021 agreement screenshot." srcset="https://www.teslaoracle.com/wp-content/uploads/2021/01/WhatsApp-2021-Agreement.jpg 465w, https://www.teslaoracle.com/wp-content/uploads/2021/01/WhatsApp-2021-Agreement-136x300.jpg 136w" sizes="(max-width: 465px) 100vw, 465px" data-old-src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzEwMjQnIHdpZHRoPSc0NjUnIHhtbG5zPSdodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZycgdmVyc2lvbj0nMS4xJy8+"></amp-img><figcaption>WhatsApp 2021 terms of use asking for mandatory data sharing compliance with Facebook. Source: <a href="https://www.xda-developers.com/whatsapp-updates-terms-privacy-policy-mandate-data-sharing-facebook/" target="_blank" rel="noreferrer noopener">XDA</a></figcaption></figure></div>



<figure>
<amp-ad width="100vw" height="320" type="adsense" data-ad-client="ca-pub-0923072950810999" data-ad-slot="7514654329" data-auto-format="rspv" data-full-width="" i-amphtml-layout="fixed">
  
</amp-ad>
</figure>



<p>In the new WhatsApp terms of use agreement (screenshot above), it’s clearly mentioned that if you do not agree with Facebook data sharing otherwise you will not be granted permission to use WhatsApp (a little rephrased I know but that’s what Facebook meant actually).</p>



<p>Now with WhatsApp’s mandatory data sharing with Facebook, <a href="https://www.teslaoracle.com/topic/elon-musk/">Elon Musk</a> decided to give a boost to Signal Private Messenger. As of this writing, Signal Messenger 570k+ users on Google Playstore vs. 127 million+ WhatsApp users. With Musk’s more than 41 million followers on Twitter, the number of Signal users is likely to hike in the coming hours, days, and weeks.</p>



<p>Another interesting bit is that Elon Musk has now <a href="https://www.bloomberg.com/news/articles/2021-01-06/musk-close-to-surpassing-bezos-as-world-s-richest-person" target="_blank" rel="noreferrer noopener">become</a> the world’s richest person with Tesla stock reaching an all-time high of $796.12 ($3,980.6 pre-split) at the time of this writing.</p>



<p>However, Signal offers real end-to-end encryption for enhanced security and privacy. <a href="https://signal.org/" target="_blank" rel="noreferrer noopener nofollow">Signal Messenger</a> has no social media partners to share data for profit and that’s even better.</p>



<p>The dilemma is, how we are going to convince our friends and family to migrate to Signal when they are addicted to WhatsApp, I don’t see that happening very soon.</p>



<p>For more interesting stories about Elon Musk, Tesla, and SpaceX, follow us on:<br><a rel="noreferrer noopener" href="https://news.google.com/publications/CAAqBwgKMOarmgswgLayAw" target="_blank">Google News</a>&nbsp;|&nbsp;<a rel="noreferrer noopener nofollow" href="https://flipboard.com/@TeslaOracle" target="_blank">Flipboard</a>&nbsp;|&nbsp;<a rel="noreferrer noopener nofollow" href="https://feedly.com/i/subscription/feed%2Fhttps%3A%2F%2Fwww.teslaoracle.com%2Ffeed%2F" target="_blank">RSS (Feedly)</a></p>
		<!-- Adsense Matched -->
        <figure>
        <amp-ad width="100vw" height="320" type="adsense" data-ad-client="ca-pub-0923072950810999" data-ad-slot="9763094783" data-auto-format="mcrspv" data-full-width="" i-amphtml-layout="fixed">
          
        </amp-ad>
        </figure><!-- Adsense Matched End -->
		</div></div>]]>
            </description>
            <link>https://www.teslaoracle.com/2021/01/07/elon-musk-suggests-signal-instead-whatsapp-jabs-facebook/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25672773</guid>
            <pubDate>Thu, 07 Jan 2021 16:15:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Overlappable Instances]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25672455">thread link</a>) | @gbrown_
<br/>
January 7, 2021 | https://lukasz-golebiewski.github.io/haskell/effects/2021/01/06/overlappable-instances.html | <a href="https://web.archive.org/web/*/https://lukasz-golebiewski.github.io/haskell/effects/2021/01/06/overlappable-instances.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>There are many patterns, styles and libraries which can be chosen for dealing with effects in Haskell. Today I’ll try to bring closer one of them.</p>

<p>Let’s start off with a very simple program written using tagless final style.
The program inserts a value “1” into the store under the key “key1” and then tries to retrieve it using operations defined in the <code>Store</code> type class. It logs what is happening while doing the above thanks to the <code>Logger</code>.
The instances needed for <code>IO</code> are added only to make the whole thing compile, the implementations aren’t very useful (for now!)</p>

<div><div><pre><code><span>{-# LANGUAGE DerivingStrategies,UndecidableInstances #-}</span>
<span>{-# LANGUAGE GeneralizedNewtypeDeriving, FlexibleContexts #-}</span>
<span>{-# LANGUAGE MultiParamTypeClasses, FlexibleInstances #-}</span>
<span>module</span> <span>Effects.Overlapping</span> <span>where</span>

<span>import</span> <span>Prelude</span> <span>hiding</span> <span>(</span><span>log</span><span>)</span>

<span>class</span> <span>Store</span> <span>m</span> <span>where</span>
  <span>put</span> <span>::</span> <span>k</span> <span>-&gt;</span> <span>a</span> <span>-&gt;</span> <span>m</span> <span>()</span>
  <span>get</span> <span>::</span> <span>k</span> <span>-&gt;</span> <span>m</span> <span>(</span><span>Maybe</span> <span>a</span><span>)</span>

<span>class</span> <span>Logger</span> <span>m</span> <span>where</span>
  <span>log</span> <span>::</span> <span>msg</span> <span>-&gt;</span> <span>m</span> <span>()</span>

<span>program</span> <span>::</span>
     <span>Monad</span> <span>m</span>
  <span>=&gt;</span> <span>Logger</span> <span>m</span>
  <span>=&gt;</span> <span>Store</span> <span>m</span>
  <span>=&gt;</span> <span>m</span> <span>()</span>
<span>program</span> <span>=</span> <span>do</span>
  <span>put</span> <span>key1</span> <span>val1</span>
  <span>log</span> <span>$</span> <span>"Inserted value: "</span> <span>&lt;&gt;</span> <span>show</span> <span>val1</span> <span>&lt;&gt;</span> <span>" under key: "</span> <span>&lt;&gt;</span> <span>key1</span>
  <span>maybeV</span> <span>&lt;-</span> <span>get</span> <span>key1</span>
  <span>case</span> <span>maybeV</span> <span>of</span>
    <span>Just</span> <span>v</span> <span>-&gt;</span> <span>log</span> <span>$</span> <span>"Retrieved: "</span> <span>&lt;&gt;</span> <span>v</span>
    <span>Nothing</span> <span>-&gt;</span> <span>log</span> <span>"No data found"</span>
  <span>where</span>
    <span>key1</span> <span>=</span> <span>"key1"</span>
    <span>val1</span> <span>::</span> <span>Integer</span>
    <span>val1</span> <span>=</span> <span>1</span>

<span>instance</span> <span>Store</span> <span>IO</span> <span>where</span>
  <span>put</span> <span>_</span> <span>_</span> <span>=</span> <span>pure</span> <span>()</span>
  <span>get</span> <span>_</span> <span>=</span> <span>pure</span> <span>Nothing</span>

<span>instance</span> <span>Logger</span> <span>IO</span> <span>where</span>
  <span>log</span> <span>_</span> <span>=</span> <span>pure</span> <span>()</span>

<span>main</span> <span>::</span> <span>IO</span> <span>()</span>
<span>main</span> <span>=</span> <span>program</span>
</code></pre></div></div>
<p>This is clearly limiting, because we are allowed to have only one typeclass instance for a given monad transformer. If we would like to have a NoOp instance and a real-world instance, we have to use newtype wrappers. Let’s add aliases then for our not-so-useful instances like this:</p>

<div><div><pre><code><span>newtype</span> <span>NoOpStoreT</span> <span>m</span> <span>a</span> <span>=</span> <span>NoOpStoreT</span> <span>{</span> <span>runNoOpStoreT</span> <span>::</span> <span>m</span> <span>a</span> <span>}</span>
  <span>deriving</span> <span>newtype</span> <span>(</span><span>Functor</span><span>,</span> <span>Applicative</span><span>,</span> <span>Monad</span><span>)</span>

<span>instance</span> <span>Monad</span> <span>m</span> <span>=&gt;</span> <span>Store</span> <span>(</span><span>NoOpStoreT</span> <span>m</span><span>)</span> <span>where</span>
  <span>put</span> <span>_</span> <span>_</span> <span>=</span> <span>pure</span> <span>()</span>
  <span>get</span> <span>_</span> <span>=</span> <span>pure</span> <span>Nothing</span>

<span>newtype</span> <span>NoOpLoggerT</span> <span>m</span> <span>a</span> <span>=</span> <span>NoOpLoggerT</span> <span>{</span> <span>runNoOpLoggerT</span> <span>::</span> <span>m</span> <span>a</span> <span>}</span>
  <span>deriving</span> <span>newtype</span> <span>(</span><span>Functor</span><span>,</span> <span>Applicative</span><span>,</span> <span>Monad</span><span>)</span>

<span>instance</span> <span>Monad</span> <span>m</span> <span>=&gt;</span> <span>Logger</span> <span>(</span><span>NoOpLoggerT</span> <span>m</span><span>)</span> <span>where</span>
  <span>log</span> <span>_</span> <span>=</span> <span>pure</span> <span>()</span>

<span>main</span> <span>::</span> <span>IO</span> <span>()</span>
<span>main</span> <span>=</span> <span>runNoOpStoreT</span> <span>.</span> <span>runNoOpLoggerT</span> <span>$</span> <span>program</span>
</code></pre></div></div>
<p>Compilation fails with the following error:</p>
<div><div><pre><code>    • No instance for (Store (NoOpLoggerT (NoOpStoreT IO)))
        arising from a use of ‘program’
</code></pre></div></div>
<p>Okay then, let’s add what the compiler is asking for</p>
<div><div><pre><code><span>instance</span> <span>Monad</span> <span>m</span> <span>=&gt;</span> <span>Store</span> <span>(</span><span>NoOpLoggerT</span> <span>m</span><span>)</span> <span>where</span>
  <span>put</span> <span>_</span> <span>_</span> <span>=</span> <span>pure</span> <span>()</span>
  <span>get</span> <span>_</span> <span>=</span> <span>pure</span> <span>Nothing</span>
</code></pre></div></div>
<p>This compiles and runs fine. But let’s see what happens if we reverse the application of transformers:</p>
<div><div><pre><code><span>main</span> <span>::</span> <span>IO</span> <span>()</span>
<span>main</span> <span>=</span> <span>runNoOpLoggerT</span> <span>.</span> <span>runNoOpStoreT</span> <span>$</span> <span>program</span>
</code></pre></div></div>
<p>results in:</p>
<div><div><pre><code>    • No instance for (Logger (NoOpStoreT (NoOpLoggerT IO)))
        arising from a use of ‘program’
</code></pre></div></div>
<p>After adding it in a similar manner we’ll arrive at the infamous O(n^2) instances problem!</p>
<div><div><pre><code><span>instance</span> <span>Monad</span> <span>m</span> <span>=&gt;</span> <span>Logger</span> <span>(</span><span>NoOpStoreT</span> <span>m</span><span>)</span> <span>where</span>
  <span>log</span> <span>_</span> <span>=</span> <span>pure</span> <span>()</span>
</code></pre></div></div>
<p>This gets painful really quickly when we add more classes and transformers.
Overlappable transformer instances to the rescue! Adding these both for <code>Store</code> and <code>Logger</code> makes it possible to get rid of boilerplate and allow us to stack our transformers in any<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> order! Let’s start with <code>Logger</code>:</p>

<div><div><pre><code><span>instance</span> <span>MonadTrans</span> <span>NoOpStoreT</span> <span>where</span>
  <span>lift</span> <span>a</span> <span>=</span> <span>NoOpStoreT</span> <span>a</span>

<span>instance</span> <span>(</span><span>Logger</span> <span>m</span><span>,</span> <span>MonadTrans</span> <span>t</span><span>,</span> <span>Monad</span> <span>m</span><span>)</span> <span>=&gt;</span> <span>Logger</span> <span>(</span><span>t</span> <span>m</span><span>)</span> <span>where</span>
  <span>log</span> <span>a</span> <span>=</span> <span>lift</span> <span>$</span> <span>log</span> <span>a</span>

<span>instance</span> <span>Monad</span> <span>m</span> <span>=&gt;</span> <span>Logger</span> <span>(</span><span>NoOpLoggerT</span> <span>m</span><span>)</span> <span>where</span>
  <span>log</span> <span>_</span> <span>=</span> <span>pure</span> <span>()</span>
</code></pre></div></div>
<p>We’ve defined a new instance. It is going to be available only if when a <code>Logger</code> instance already exists for <code>m</code> and we know how to wrap this monad <code>m</code> using <code>t</code>. For this to be true we need to add a <code>MonadTrans</code> instance for our <code>NoOpStoreT</code>. Thanks to this we don’t have to write all n^2 instances by hand. But the compiler has a problem now:</p>

<div><div><pre><code>   • Overlapping instances for Logger (NoOpLoggerT IO)
        arising from a use of ‘program’
      Matching instances:
        instance (Logger m, MonadTrans t, Monad m) =&gt; Logger (t m)
          -- Defined at ...
        instance Monad m =&gt; Logger (NoOpLoggerT m)
          -- Defined at ...

</code></pre></div></div>
<p>We need to tell it, that whenever two instances could be used “arising from the use of program”, one of them is less specific, and labeled using the <code>{-# OVERLAPPABLE #-}</code> pragma. Now the code compiles fine.</p>

<p>Let’s do the same for <code>Store</code> thus arriving at:</p>
<div><div><pre><code><span>newtype</span> <span>NoOpStoreT</span> <span>m</span> <span>a</span> <span>=</span> <span>NoOpStoreT</span> <span>{</span> <span>runNoOpStoreT</span> <span>::</span> <span>m</span> <span>a</span> <span>}</span>
  <span>deriving</span> <span>newtype</span> <span>(</span><span>Functor</span><span>,</span> <span>Applicative</span><span>,</span> <span>Monad</span><span>)</span>

<span>instance</span> <span>Monad</span> <span>m</span> <span>=&gt;</span> <span>Store</span> <span>(</span><span>NoOpStoreT</span> <span>m</span><span>)</span> <span>where</span>
  <span>put</span> <span>_</span> <span>_</span> <span>=</span> <span>pure</span> <span>()</span>
  <span>get</span> <span>_</span> <span>=</span> <span>pure</span> <span>Nothing</span>

<span>instance</span> <span>{-# OVERLAPPABLE #-}</span> <span>(</span><span>Store</span> <span>m</span><span>,</span> <span>MonadTrans</span> <span>t</span><span>,</span> <span>Monad</span> <span>m</span><span>)</span> <span>=&gt;</span> <span>Store</span> <span>(</span><span>t</span> <span>m</span><span>)</span> <span>where</span>
  <span>put</span> <span>a</span> <span>b</span> <span>=</span> <span>lift</span> <span>$</span> <span>put</span> <span>a</span> <span>b</span>
  <span>get</span> <span>a</span> <span>=</span> <span>lift</span> <span>$</span> <span>get</span> <span>a</span>

<span>instance</span> <span>MonadTrans</span> <span>NoOpStoreT</span> <span>where</span>
  <span>lift</span> <span>a</span> <span>=</span> <span>NoOpStoreT</span> <span>a</span>


<span>newtype</span> <span>NoOpLoggerT</span> <span>m</span> <span>a</span> <span>=</span> <span>NoOpLoggerT</span> <span>{</span> <span>runNoOpLoggerT</span> <span>::</span> <span>m</span> <span>a</span> <span>}</span>
  <span>deriving</span> <span>newtype</span> <span>(</span><span>Functor</span><span>,</span> <span>Applicative</span><span>,</span> <span>Monad</span><span>)</span>

<span>instance</span> <span>{-# OVERLAPPABLE #-}</span> <span>(</span><span>Logger</span> <span>m</span><span>,</span> <span>MonadTrans</span> <span>t</span><span>,</span> <span>Monad</span> <span>m</span><span>)</span> <span>=&gt;</span> <span>Logger</span> <span>(</span><span>t</span> <span>m</span><span>)</span> <span>where</span>
  <span>log</span> <span>a</span> <span>=</span> <span>lift</span> <span>$</span> <span>log</span> <span>a</span>

<span>instance</span> <span>MonadTrans</span> <span>NoOpLoggerT</span> <span>where</span>
  <span>lift</span> <span>a</span> <span>=</span> <span>NoOpLoggerT</span> <span>a</span>

<span>instance</span> <span>Monad</span> <span>m</span> <span>=&gt;</span> <span>Logger</span> <span>(</span><span>NoOpLoggerT</span> <span>m</span><span>)</span> <span>where</span>
  <span>log</span> <span>_</span> <span>=</span> <span>pure</span> <span>()</span>

</code></pre></div></div>
<p>Now we can run the effects in any<sup id="fnref:1:1" role="doc-noteref"><a href="#fn:1">1</a></sup> order. Both:</p>

<div><div><pre><code><span>main</span> <span>::</span> <span>IO</span> <span>()</span>
<span>main</span> <span>=</span> <span>runNoOpLoggerT</span> <span>.</span> <span>runNoOpStoreT</span> <span>$</span> <span>program</span>
</code></pre></div></div>
<p>and</p>
<div><div><pre><code><span>main</span> <span>::</span> <span>IO</span> <span>()</span>
<span>main</span> <span>=</span> <span>runNoOpStoreT</span> <span>.</span> <span>runNoOpLoggerT</span> <span>$</span> <span>program</span>
</code></pre></div></div>
<p>compile and run just fine.</p>

<p>Now let’s add some more useful instances for our classes. An implementation of a <code>Store</code> backed by a <code>Map</code> and a <code>Logger</code> capable of writing to stdout. The classes and the program had to be modified a bit in order to make the whole thing compile with the backing <code>Map</code> and <code>MonadState</code>. Luckily the existing instances didn’t need to be modified much and the end result looks like this:</p>

<div><div><pre><code><span>module</span> <span>Effects.Overlapping</span> <span>where</span>

<span>import</span> <span>Prelude</span> <span>hiding</span> <span>(</span><span>log</span><span>,</span> <span>lookup</span><span>)</span>

<span>import</span> <span>Control.Monad.Trans.Class</span> <span>(</span><span>MonadTrans</span><span>,</span> <span>lift</span><span>)</span>
<span>import</span> <span>Control.Monad.Trans.State</span> <span>(</span><span>evalStateT</span><span>)</span>
<span>import</span> <span>Control.Monad.IO.Class</span> <span>(</span><span>MonadIO</span><span>,</span> <span>liftIO</span><span>)</span>
<span>import</span> <span>Control.Monad.State.Class</span> <span>qualified</span> <span>as</span> <span>MS</span> <span>(</span><span>MonadState</span><span>,</span> <span>modify</span><span>,</span> <span>get</span><span>)</span>
<span>import</span> <span>Data.Map.Strict</span> <span>(</span><span>Map</span><span>,</span> <span>empty</span><span>,</span> <span>insert</span><span>,</span> <span>lookup</span><span>)</span>

<span>class</span> <span>Store</span> <span>m</span> <span>k</span> <span>v</span> <span>where</span>
  <span>put</span> <span>::</span> <span>k</span> <span>-&gt;</span> <span>v</span> <span>-&gt;</span> <span>m</span> <span>()</span>
  <span>get</span> <span>::</span> <span>k</span> <span>-&gt;</span> <span>m</span> <span>(</span><span>Maybe</span> <span>v</span><span>)</span>

<span>class</span> <span>Logger</span> <span>m</span> <span>a</span> <span>where</span>
  <span>log</span> <span>::</span> <span>a</span> <span>-&gt;</span> <span>m</span> <span>()</span>

<span>program</span> <span>::</span>
     <span>Monad</span> <span>m</span>
  <span>=&gt;</span> <span>Logger</span> <span>m</span> <span>String</span>
  <span>=&gt;</span> <span>Store</span> <span>m</span> <span>String</span> <span>Integer</span>
  <span>=&gt;</span> <span>m</span> <span>()</span>
<span>program</span> <span>=</span> <span>do</span>
  <span>put</span> <span>key1</span> <span>val1</span>
  <span>log</span> <span>$</span> <span>"Inserted value: "</span> <span>&lt;&gt;</span> <span>show</span> <span>val1</span> <span>&lt;&gt;</span> <span>" under key: "</span> <span>&lt;&gt;</span> <span>key1</span>
  <span>maybeV</span> <span>&lt;-</span> <span>get</span> <span>key1</span>
  <span>case</span> <span>maybeV</span> <span>::</span> <span>Maybe</span> <span>Integer</span> <span>of</span>
    <span>Just</span> <span>val</span> <span>-&gt;</span> <span>log</span> <span>$</span> <span>"Retrieved: "</span> <span>&lt;&gt;</span> <span>show</span> <span>val</span>
    <span>Nothing</span> <span>-&gt;</span> <span>log</span> <span>"No data found"</span>
  <span>where</span>
    <span>key1</span> <span>::</span> <span>String</span>
    <span>key1</span> <span>=</span> <span>"key1"</span>
    <span>val1</span> <span>::</span> <span>Integer</span>
    <span>val1</span> <span>=</span> <span>1</span>

<span>----------------------------------------------------------------------------------------</span>
<span>newtype</span> <span>NoOpStoreT</span> <span>m</span> <span>a</span> <span>=</span> <span>NoOpStoreT</span> <span>{</span> <span>runNoOpStoreT</span> <span>::</span> <span>m</span> <span>a</span> <span>}</span>
  <span>deriving</span> <span>newtype</span> <span>(</span><span>Functor</span><span>,</span> <span>Applicative</span><span>,</span> <span>Monad</span><span>)</span>

<span>instance</span> <span>Monad</span> <span>m</span> <span>=&gt;</span> <span>Store</span> <span>(</span><span>NoOpStoreT</span> <span>m</span><span>)</span> <span>k</span> <span>v</span> <span>where</span>
  <span>put</span> <span>_</span> <span>_</span> <span>=</span> <span>pure</span> <span>()</span>
  <span>get</span> <span>_</span> <span>=</span> <span>pure</span> <span>Nothing</span>

<span>instance</span> <span>{-# OVERLAPPABLE #-}</span> <span>(</span><span>Store</span> <span>m</span> <span>k</span> <span>v</span><span>,</span> <span>MonadTrans</span> <span>t</span><span>,</span> <span>Monad</span> <span>m</span><span>)</span> <span>=&gt;</span> <span>Store</span> <span>(</span><span>t</span> <span>m</span><span>)</span> <span>k</span> <span>v</span> <span>where</span>
  <span>put</span> <span>a</span> <span>b</span> <span>=</span> <span>lift</span> <span>$</span> <span>put</span> <span>a</span> <span>b</span>
  <span>get</span> <span>a</span> <span>=</span> <span>lift</span> <span>$</span> <span>get</span> <span>a</span>

<span>instance</span> <span>MonadTrans</span> <span>NoOpStoreT</span> <span>where</span>
  <span>lift</span> <span>a</span> <span>=</span> <span>NoOpStoreT</span> <span>a</span>

<span>newtype</span> <span>StoreT</span> <span>m</span> <span>a</span> <span>=</span> <span>StoreT</span> <span>{</span> <span>runStoreT</span> <span>::</span> <span>m</span> <span>a</span> <span>}</span>
  <span>deriving</span> <span>newtype</span> <span>(</span><span>Functor</span><span>,</span> <span>Applicative</span><span>,</span> <span>Monad</span><span>,</span> <span>MonadIO</span><span>,</span> <span>MS</span><span>.</span><span>MonadState</span> <span>s</span><span>)</span>

<span>instance</span> <span>(</span><span>Ord</span> <span>k</span><span>,</span> <span>MS</span><span>.</span><span>MonadState</span> <span>(</span><span>Map</span> <span>k</span> <span>v</span><span>)</span> <span>m</span><span>,</span> <span>Monad</span> <span>m</span><span>)</span> <span>=&gt;</span> <span>Store</span> <span>(</span><span>StoreT</span> <span>m</span><span>)</span> <span>k</span> <span>v</span> <span>where</span>
  <span>put</span> <span>key</span> <span>value</span> <span>=</span> <span>MS</span><span>.</span><span>modify</span> <span>(</span><span>insert</span> <span>key</span> <span>value</span><span>)</span>
  <span>get</span> <span>key</span> <span>=</span> <span>fmap</span> <span>(</span><span>lookup</span> <span>key</span><span>)</span> <span>MS</span><span>.</span><span>get</span>

<span>instance</span> <span>MonadTrans</span> <span>StoreT</span> <span>where</span>
  <span>lift</span> <span>a</span> <span>=</span> <span>StoreT</span> <span>a</span>

<span>----------------------------------------------------------------------------------------</span>
<span>newtype</span> <span>NoOpLoggerT</span> <span>m</span> <span>a</span> <span>=</span> <span>NoOpLoggerT</span> <span>{</span> <span>runNoOpLoggerT</span> <span>::</span> <span>m</span> <span>a</span> <span>}</span>
  <span>deriving</span> <span>newtype</span> <span>(</span><span>Functor</span><span>,</span> <span>Applicative</span><span>,</span> <span>Monad</span><span>)</span>

<span>instance</span> <span>{-# OVERLAPPABLE #-}</span> <span>(</span><span>Logger</span> <span>m</span> <span>a</span><span>,</span> <span>MonadTrans</span> <span>t</span><span>,</span> <span>Monad</span> <span>m</span><span>)</span> <span>=&gt;</span> <span>Logger</span> <span>(</span><span>t</span> <span>m</span><span>)</span> <span>a</span> <span>where</span>
  <span>log</span> <span>a</span> <span>=</span> <span>lift</span> <span>$</span> <span>log</span> <span>a</span>

<span>instance</span> <span>MonadTrans</span> <span>NoOpLoggerT</span> <span>where</span>
  <span>lift</span> <span>a</span> <span>=</span> <span>NoOpLoggerT</span> <span>a</span>

<span>instance</span> <span>Monad</span> <span>m</span> <span>=&gt;</span> <span>Logger</span> <span>(</span><span>NoOpLoggerT</span> <span>m</span><span>)</span> <span>a</span> <span>where</span>
  <span>log</span> <span>_</span> <span>=</span> <span>pure</span> <span>()</span>

<span>newtype</span> <span>LoggerT</span> <span>m</span> <span>a</span> <span>=</span> <span>LoggerT</span> <span>{</span> <span>runLoggerT</span> <span>::</span> <span>m</span> <span>a</span> <span>}</span>
  <span>deriving</span> <span>newtype</span> <span>(</span><span>Functor</span><span>,</span> <span>Applicative</span><span>,</span> <span>Monad</span><span>,</span> <span>MonadIO</span><span>,</span> <span>MS</span><span>.</span><span>MonadState</span> <span>s</span><span>)</span>

<span>instance</span> <span>MonadTrans</span> <span>LoggerT</span> <span>where</span>
  <span>lift</span> <span>a</span> <span>=</span> <span>LoggerT</span> <span>a</span>

<span>instance</span> <span>(</span><span>Show</span> <span>a</span><span>,</span> <span>MonadIO</span> <span>m</span><span>)</span> <span>=&gt;</span> <span>Logger</span> <span>(</span><span>LoggerT</span> <span>m</span><span>)</span> <span>a</span> <span>where</span>
  <span>log</span> <span>msg</span> <span>=</span> <span>liftIO</span> <span>$</span> <span>putStrLn</span> <span>(</span><span>show</span> <span>msg</span><span>)</span>

<span>runMapStoreT</span> <span>=</span> <span>flip</span> <span>evalStateT</span> <span>(</span><span>empty</span> <span>::</span> <span>Map</span> <span>String</span> <span>Integer</span><span>)</span> <span>.</span> <span>runStoreT</span>

<span>main</span> <span>::</span> <span>IO</span> <span>()</span>
<span>main</span> <span>=</span> <span>do</span>
  <span>putStrLn</span> <span>"Running the program..."</span>
  <span>runMapStoreT</span> <span>.</span> <span>runLoggerT</span> <span>$</span> <span>program</span>
  <span>putStrLn</span> <span>"Done"</span>

</code></pre></div></div>
<p>Now we can do some more useful things with our program and stack transformers according to our needs.
Hope you enjoyed the read :-)</p>



  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://lukasz-golebiewski.github.io/haskell/effects/2021/01/06/overlappable-instances.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25672455</guid>
            <pubDate>Thu, 07 Jan 2021 15:58:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cartography in R with Rayshader and Open Street Map: A Tutorial]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25672197">thread link</a>) | @tylermw
<br/>
January 7, 2021 | https://www.tylermw.com/adding-open-street-map-data-to-rayshader-maps-in-r/ | <a href="https://web.archive.org/web/*/https://www.tylermw.com/adding-open-street-map-data-to-rayshader-maps-in-r/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
		<a href="#content">Skip to content</a>

	<div id="boxed-wrapper">
		
		<div id="wrapper">
			
			
				
			<header>
				
				
			</header>
							
				
		
				
				
			
			

						<main id="main">
				<div>

<section id="content">
	
					<article id="post-3287">
						
														
						
																									<div>
				





<meta charset="utf-8">
<meta name="generator" content="pandoc">
<meta http-equiv="X-UA-Compatible" content="IE=EDGE">


<meta name="author" content="Tyler Morgan-Wall">

<meta name="date" content="2020-12-27">

<title>osm</title>






<meta name="viewport" content="width=device-width, initial-scale=1">














<p><span>T</span>his post is a tutorial on how to add Open Street Map data to maps made with rayshader in R. Rayshader is a package for 2D and 3D visualization in R, specializing in generating beautiful maps using many various hillshading techniques (see these posts <a href="https://www.tylermw.com/making-beautiful-maps/">[1]</a> <a href="https://www.tylermw.com/a-step-by-step-guide-to-making-3d-maps-with-satellite-imagery-in-r/">[2]</a> <a href="https://www.tylermw.com/3d-maps-with-rayshader/">[3]</a>) directly from elevation data. It does this by providing the user with a wide variety of techniques: traditional lambertian shading, raytracing, ambient occlusion, hypsometric tinting (cartography-speak for mapping color to elevation), texture shading, and spherical aspect color shading.</p>
<div><img src="https://www.tylermw.com/wp-content/uploads/2021/01/examples-1.jpg"></div>
<center><div>Figure 1: Different hillshading methods. Left to right: Lambertian shading, raytracing, ambient occlusion, height shading, texture shading, sphere shading.</div></center>

<p>These techniques can be combined to create stunning maps in a few lines of R code, but that’s only half the story: a beautiful map is just a vehicle to deliver other information. Roads, trails, parking lots, water fountains, restrooms, the nearest Arbys: a map is a tool to build your mental model for a region. These features can be added to rayshader maps via data overlays: we first generate our base map using some combination of the above hillshading techniques, and then we layer our data on top. Rayshader provides you with functions to easily add polygons, lines, and points that represent your data directly onto your map.</p>
<div><img src="https://www.tylermw.com/wp-content/uploads/2021/01/generate_examples-1.jpg"></div>
<center><div>Figure 2: Adding polygon and line overlays to a map in 2D in rayshader.</div></center>
<p>You also need a source of data, and luckily we live in a universe where Open Street Map (OSM) exists: a free, open, user-generated map of pretty much everything in the world. If you have some highly specialized dataset, you might not be able to find it on OSM, but for the basics (trails, roads, rivers, streams, landmarks and buildings) it’s fairly comprehensive.</p>
<p>Knowing the data exists is only half the battle: you also need a way to load the data into R. And thankfully, Mark Padgham (along with many others and the rOpenSci project) have given us the <code>osmdata</code> package, a package that allows you to easily query and pull data from OSM in a few lines of code directly from R. You provide it with a lat/long bounding box and a specific feature you want to pull, and it will return an object containing everything that matches your query in that area.</p>



<p>Let’s jump into an example. We’ll use elevation data from Bryce Canyon in Utah (courtesy of Tom Patterson via <a href="http://shadedrelief.com/SampleElevationModels/">shadedrelief.com</a>), since National Parks tend to have a nice mix of interesting topography, trails, streams, and other features.</p>

<div><img src="https://www.tylermw.com/wp-content/uploads/2021/01/bryce.jpg"></div>
<center><div>Figure 3: A picture from a post-PhD defense trip I took to Bryce Canyon National Park in 2015. Remember travel?</div></center>
<p>Let’s start by loading the data and required packages. We’ll transform the spatial data structure extracted by raster into a regular R matrix using rayshader’s <code>raster_to_matrix()</code> function.</p>
<pre><code>install.packages("remotes")
remotes::install_github("tylermorganwall/rayshader")
remotes::install_github("tylermorganwall/rayimage")

library(rayshader)
library(raster)
library(osmdata)
library(sf)
library(dplyr)
library(ggplot2)

bryce = raster("Bryce_Canyon.tif")
bryce_mat = raster_to_matrix(bryce)</code></pre>
<p>We can also create a smaller version of this matrix for quick prototyping with the rayshader <code>resize_matrix()</code> function. This test matrix will be 1/4th the size of the full matrix.</p>
<pre><code>bryce_small = resize_matrix(bryce_mat,0.25)</code></pre>
<p>Now, let’s build our base map with rayshader. Let’s see what this data looks like with a basic color to elevation mapping.</p>
<pre><code>bryce_small %&gt;% 
  height_shade() %&gt;% 
  plot_map()</code></pre>
<div><img src="https://www.tylermw.com/wp-content/uploads/2021/01/initialplot-1.jpg" width="1608"></div>
<p>We’ll mix this layer with a spherical aspect shading color layer to enhance it using <code>sphere_shade()</code>.</p>
<pre><code>bryce_small %&gt;% 
  height_shade() %&gt;% 
  add_overlay(sphere_shade(bryce_small, texture = "desert", 
                           zscale=4, colorintensity = 5), alphalayer=0.5) %&gt;%
  plot_map()</code></pre>
<div><img src="https://www.tylermw.com/wp-content/uploads/2021/01/sphereplot-1.jpg" width="1608"></div>
<p>We can also overlay a standard hillshade to better define the terrain. We’ll get this by using the <code>lamb_shade()</code> function, which adds Lambertian (cosine) shading. The zscale parameter in `lamb_shade()` controls the amount of vertical exaggeration and thus the intensity of the hillshade.</p>
<pre><code>bryce_small %&gt;% 
  height_shade() %&gt;% 
  add_overlay(sphere_shade(bryce_small, texture = "desert", 
                           zscale=4, colorintensity = 5), alphalayer=0.5) %&gt;%
  add_shadow(lamb_shade(bryce_small,zscale = 6),0) %&gt;%
  plot_map()</code></pre>
<div><img src="https://www.tylermw.com/wp-content/uploads/2021/01/lambplot-1.jpg" width="1608"></div>
<p>Now we'll add a layer using the <code>texture_shade()</code> function, which adds shadows calculated by <a href="http://www.textureshading.com/Home.html">Leland Brown’s “texture shading” method</a>. This better defines ridges and drainage networks, which aren’t well-captured by Lambertian shading.</p>
<pre><code>bryce_small %&gt;% 
  height_shade() %&gt;% 
  add_overlay(sphere_shade(bryce_small, texture = "desert", 
                           zscale=4, colorintensity = 5), alphalayer=0.5) %&gt;%
  add_shadow(lamb_shade(bryce_small,zscale=6), 0) %&gt;%
  add_shadow(texture_shade(bryce_small,detail=8/10,contrast=9,brightness = 11), 0.1) %&gt;%
  plot_map()</code></pre>
<div><img src="https://www.tylermw.com/wp-content/uploads/2021/01/textureplot-1.jpg" width="1608"></div>
<p>Finally, we’ll add an ambient occlusion layer to our base map. This will darken valleys to account for less scattered atmospheric light reaching the valley floor. This adds a nice texture to our map, particularly to the valleys between the steep ridges.</p>
<pre><code>bryce_small %&gt;% 
  height_shade() %&gt;% 
  add_overlay(sphere_shade(bryce_small, texture = "desert", 
                           zscale=4, colorintensity = 5), alphalayer=0.5) %&gt;%
  add_shadow(lamb_shade(bryce_small,zscale=6), 0) %&gt;%
  add_shadow(ambient_shade(bryce_small), 0) %&gt;%
  add_shadow(texture_shade(bryce_small,detail=8/10,contrast=9,brightness = 11), 0.1) %&gt;%
  plot_map()</code></pre>
<div><img src="https://www.tylermw.com/wp-content/uploads/2021/01/ambientplot-1.jpg" width="1608"></div>
<p>Now we have our base map! We’ll zoom into our area of interest by creating a lat/long bounding box. To get these coordinates, I just went to Google Maps and picked the bottom left and top right corners, and pulled out the lat/long values. I wrote a short function that takes these values and transforms them into the coordinate system used in the original <code>bryce</code> object, which we then crop, convert to a matrix, and then plot. We’ll also save this map to a variable to use later, so we don’t have to recompute the base layer each time.</p>
<pre><code>lat_range   = c(37.614998, 37.629084)
long_range = c(-112.174228, -112.156230)

convert_coords = function(lat,long, from = CRS("+init=epsg:4326"), to) {
  data = data.frame(long=long, lat=lat)
  coordinates(data) &lt;- ~ long+lat
  proj4string(data) = from
  #Convert to coordinate system specified by EPSG code
  xy = data.frame(sp::spTransform(data, to))
  colnames(xy) = c("x","y")
  return(unlist(xy))
}

crs(bryce)</code></pre>
<pre><code>## CRS arguments:
##  +proj=utm +zone=12 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m
## +no_defs</code></pre>
<pre><code>utm_bbox = convert_coords(lat = lat_range, long=long_range, to = crs(bryce))
utm_bbox</code></pre>
<pre><code>##        x1        x2        y1        y2 
##  396367.4  397975.2 4163747.9 4165291.0</code></pre>
<pre><code>extent(bryce)</code></pre>
<pre><code>## class      : Extent 
## xmin       : 395998.5 
## xmax       : 399998.5 
## ymin       : 4161774 
## ymax       : 4165574</code></pre>
<pre><code>extent_zoomed = extent(utm_bbox[1], utm_bbox[2], utm_bbox[3], utm_bbox[4])
bryce_zoom = crop(bryce, extent_zoomed)
bryce_zoom_mat = raster_to_matrix(bryce_zoom)

base_map = bryce_zoom_mat %&gt;% 
  height_shade() %&gt;%
  add_overlay(sphere_shade(bryce_zoom_mat, texture = "desert", colorintensity = 5), alphalayer=0.5) %&gt;%
  add_shadow(lamb_shade(bryce_zoom_mat), 0) %&gt;%
  add_shadow(ambient_shade(bryce_zoom_mat),0) %&gt;% 
  add_shadow(texture_shade(bryce_zoom_mat,detail=8/10,contrast=9,brightness = 11), 0.1)

plot_map(base_map)</code></pre>
<div><img src="https://www.tylermw.com/wp-content/uploads/2021/01/osm_data-1.jpg" width="1608"></div>
<p>Great! We now have our zoomed-in base map. Let’s start adding OSM features to it.</p>
<p>You can see what features are available in OSM by calling the <code>available_features()</code> function. We’re first going to pull the <code>highway</code> feature in our region. Despite the name, <code>highway</code> represents more than major roads: it’s a feature that represents all types of roads and footpaths. We’ll build a query to the OSM Overpass API by passing in our lat/long bounding box (with a slight order change required for that API) to <code>opq()</code>, adding a feature with <code>add_osm_feature()</code>, and then convert the object to a simple features (sf) object with <code>osmdata_sf()</code>.</p>
<pre><code>osm_bbox = c(long_range[1],lat_range[1], long_range[2],lat_range[2])

bryce_highway = opq(osm_bbox) %&gt;% 
  add_osm_feature("highway") %&gt;% 
  osmdata_sf() 
bryce_highway</code></pre>
<pre><code>## Object of class 'osmdata' with:
##                  $bbox : 37.614998,-112.174228,37.629084,-112.15623
##         $overpass_call : The call submitted to the overpass API
##                  $meta : metadata including timestamp and version numbers
##            $osm_points : 'sf' Simple Features Collection with 2140 points
##             $osm_lines : 'sf' Simple Features Collection with 94 linestrings
##          $osm_polygons : 'sf' Simple Features Collection with 5 polygons
##        $osm_multilines : NULL
##     $osm_multipolygons : NULL</code></pre>
<p>This returns a list with several <code>sf</code> objects contained within: points, lines, and polygons. The data comes in lat/long coordinates, so we need to convert it to <code>bryce</code>’s coordinate system. Let’s plot the lines in ggplot to preview what data we have.</p>
<pre><code>bryce_lines = st_transform(bryce_highway$osm_lines, crs=crs(bryce))

ggplot(bryce_lines,aes(color=osm_id)) + 
  geom_sf() +
  theme(legend.position = "none") +
  labs(title = "Open Street Map `highway` attribute in Bryce Canyon National Park")</code></pre>

<p>Now, let’s add it to our map using rayshader’s <code>generate_line_overlay()</code> function, which takes an <code>sf</code> object with <code>LINESTRING</code> geometry and creates a semi-transparent overlay (which we then overlay with <code>add_overlay()</code>). You might notice that the above geometry extends far beyond the bounds of our scene, but that won’t matter—the <code>generate_*_overlay()</code> functions will crop the data down the region specified in <code>extent</code>.</p>
<pre><code>base_map %&gt;% 
  add_overlay(generate_line_overlay(bryce_lines,extent = extent_zoomed,</code></pre></div></article></section></div></main></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.tylermw.com/adding-open-street-map-data-to-rayshader-maps-in-r/">https://www.tylermw.com/adding-open-street-map-data-to-rayshader-maps-in-r/</a></em></p>]]>
            </description>
            <link>https://www.tylermw.com/adding-open-street-map-data-to-rayshader-maps-in-r/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25672197</guid>
            <pubDate>Thu, 07 Jan 2021 15:38:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google Anthos vs. Cast AI Comparison: Who Wins?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25672035">thread link</a>) | @Cytergyny
<br/>
January 7, 2021 | https://resources.cast.ai/blog/google-anthos-vs-cast-ai-comparison | <a href="https://web.archive.org/web/*/https://resources.cast.ai/blog/google-anthos-vs-cast-ai-comparison">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<div data-widget-type="blog_content" data-x="0" data-w="12">
<div>
    <div>
      <h6>
        
        
        
        
        
        3 min read
        
      </h6>
        

        <p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p>The idea that you can build an app in one place and then deploy it across multiple clouds is an enticing one. Th<span>at’s why multi-cloud solutions are on the rise today. They promise to help developers in expanding th</span><span>eir cloud portfolios and battle for the industry’s attention.</span></p>
<!--more-->
<p><img src="https://resources.cast.ai/hubfs/cast%20vs%20anthos-png.png">If you’re looking for the right m<span>anaged service that makes multi-cloud possible, we’ve got something for you. Here’s a detailed comparison of Google Anthos and CAST AI showing you two completely different multi-cloud approaches.&nbsp;</span></p>
<div><p>While Google Anthos uses a more complicated approach and you need to create a cluster for each cloud, CAST AI offers a more advanced way to solve this multi-cloud riddle - one cluster spread across multiple clouds.</p></div>
<h2>Google Anthos vs. CAST AI - feature comparison<p><img src="https://resources.cast.ai/hs-fs/hubfs/CAst_vs_anthos1%20(1).png?width=750&amp;name=CAst_vs_anthos1%20(1).png" alt="CAst_vs_anthos1 (1)" width="750" srcset="https://resources.cast.ai/hs-fs/hubfs/CAst_vs_anthos1%20(1).png?width=375&amp;name=CAst_vs_anthos1%20(1).png 375w, https://resources.cast.ai/hs-fs/hubfs/CAst_vs_anthos1%20(1).png?width=750&amp;name=CAst_vs_anthos1%20(1).png 750w, https://resources.cast.ai/hs-fs/hubfs/CAst_vs_anthos1%20(1).png?width=1125&amp;name=CAst_vs_anthos1%20(1).png 1125w, https://resources.cast.ai/hs-fs/hubfs/CAst_vs_anthos1%20(1).png?width=1500&amp;name=CAst_vs_anthos1%20(1).png 1500w, https://resources.cast.ai/hs-fs/hubfs/CAst_vs_anthos1%20(1).png?width=1875&amp;name=CAst_vs_anthos1%20(1).png 1875w, https://resources.cast.ai/hs-fs/hubfs/CAst_vs_anthos1%20(1).png?width=2250&amp;name=CAst_vs_anthos1%20(1).png 2250w" sizes="(max-width: 750px) 100vw, 750px"></p></h2>
<h2>Google Anthos: one cluster on a single cloud, one tool for 3 clouds</h2>
<p>Anthos is Google’s new managed service offering for multi-cloud environments launched in 2019. Apart from access to multiple clouds, it offers hybrid cloud infrastructures or even a combination of on-premises and cloud-based functionalities.</p>
<p>Anthos is a meta-service that groups Kubernetes clusters by configuration and policy. Every cluster is independent - it has its own control plane, points of ingress, deployments, and configurations. This means that developers must continuously synchronize the clusters.&nbsp;</p>
<p>However, Anthos comes with cloud environments that are configured and may behave in a drastically different manner. While using Google, it offers a mostly streamlined experience. But try it on AWS or on-premises setup, and you’ll see that management is hard to automate. It requires ample knowledge of the destination cloud.</p>

<h2>CAST AI: one cluster on many clouds, unified multi-cloud for 3 clouds</h2>
<p>When you create a multi-cloud cluster with CAST AI, you get a single logical Kubernetes cluster connected across multiple cloud services. The solution creates a virtual multi-cloud private network using your VPN of choice or direct fiber connectivity between clouds.&nbsp;</p>
<p>CAST AI abstracts away the differences between compute, network, ingress and load balancing, and storage. As a result, you get an open and non-proprietary Kubernetes implementation for immediate production purposes.</p>
<h2><br><strong>What about cost optimization?</strong></h2>
<p><span><img src="https://resources.cast.ai/hs-fs/hubfs/CAst_vs_anthos3-png.png?width=746&amp;name=CAst_vs_anthos3-png.png" width="746" srcset="https://resources.cast.ai/hs-fs/hubfs/CAst_vs_anthos3-png.png?width=373&amp;name=CAst_vs_anthos3-png.png 373w, https://resources.cast.ai/hs-fs/hubfs/CAst_vs_anthos3-png.png?width=746&amp;name=CAst_vs_anthos3-png.png 746w, https://resources.cast.ai/hs-fs/hubfs/CAst_vs_anthos3-png.png?width=1119&amp;name=CAst_vs_anthos3-png.png 1119w, https://resources.cast.ai/hs-fs/hubfs/CAst_vs_anthos3-png.png?width=1492&amp;name=CAst_vs_anthos3-png.png 1492w, https://resources.cast.ai/hs-fs/hubfs/CAst_vs_anthos3-png.png?width=1865&amp;name=CAst_vs_anthos3-png.png 1865w, https://resources.cast.ai/hs-fs/hubfs/CAst_vs_anthos3-png.png?width=2238&amp;name=CAst_vs_anthos3-png.png 2238w" sizes="(max-width: 746px) 100vw, 746px"></span></p>

<p>CAST AI has a heavy focus on optimization and cost of operation. Similar to GKE, CAST provides a set of out-of-the-box auto-scalers. Scaling a CAST AI cluster is controlled through customer defined policies. The CAST AI cost optimization engine focuses on ensuring that the best possible compute instances are used for currently deployed workloads. This includes the use of spot and preemptive instances when they are available to lower overall costs.</p>
<div><p>CAST AI’s multi-cloud solution does not require a special configuration management / synchronization service because of the One Cluster approach. Configurations are synchronized across clouds utilizing the underlying etcd data store that naturally supports multiple distributed master nodes.</p><p><img src="https://resources.cast.ai/hs-fs/hubfs/CAst_vs_anthos2-png-1.png?width=748&amp;name=CAst_vs_anthos2-png-1.png" width="748" srcset="https://resources.cast.ai/hs-fs/hubfs/CAst_vs_anthos2-png-1.png?width=374&amp;name=CAst_vs_anthos2-png-1.png 374w, https://resources.cast.ai/hs-fs/hubfs/CAst_vs_anthos2-png-1.png?width=748&amp;name=CAst_vs_anthos2-png-1.png 748w, https://resources.cast.ai/hs-fs/hubfs/CAst_vs_anthos2-png-1.png?width=1122&amp;name=CAst_vs_anthos2-png-1.png 1122w, https://resources.cast.ai/hs-fs/hubfs/CAst_vs_anthos2-png-1.png?width=1496&amp;name=CAst_vs_anthos2-png-1.png 1496w, https://resources.cast.ai/hs-fs/hubfs/CAst_vs_anthos2-png-1.png?width=1870&amp;name=CAst_vs_anthos2-png-1.png 1870w, https://resources.cast.ai/hs-fs/hubfs/CAst_vs_anthos2-png-1.png?width=2244&amp;name=CAst_vs_anthos2-png-1.png 2244w" sizes="(max-width: 748px) 100vw, 748px"></p></div>
<p>One cluster spread across multiple clouds is a more evolved approach to multi-cloud. Dealing with a single multi-cloud cluster is easier than having to constantly synchronize your clusters and only taking advantage of common configuration or policies.&nbsp;</p>
<p><span><span>Multi-cloud doesn’t have to be hard.</span> Explore your options and try out CAST AI </span><a href="https://console.cast.ai/signup?utm_source=internal&amp;utm_medium=blog&amp;utm_campaign=kubernetes_log_processing_4_challenges">here</a><span>.&nbsp;</span></p>
<p>We’re offering free cloud credentials to help you build your first multi-cloud clusters and play around with our infrastructure for a limited time. <a href="https://castai-community.slack.com/" rel="noopener">Just join our community on Slack.</a></p></span>
        </p>
        
            
        

        <div>
            <p><img alt="Leon Kuperman" src="https://f.hubspotusercontent00.net/hubfs/6978602/0.jpeg" data-src="https://f.hubspotusercontent00.net/hubfs/6978602/0.jpeg" data-srcset="https://f.hubspotusercontent00.net/hubfs/6978602/0.jpeg">
            </p>
            <div>
                <h4>Written by </h4>
                <p>Co-founder and CTO, CAST AI

Formerly Vice President of Security Products OCI at Oracle, Leon’s professional experience spans across tech companies such as IBM, Truition, and HostedPCI. He founded and served as the CTO of Zenedge, an enterprise security company protecting large enterprises with a cloud WAF. 

Leon has 20+ years of experience in product management, software design, and development, all the way through to production deployment. 

He is an authority on cloud computing, web application security and Payment Card Industry Data Security Standard (PCI DSS), e-commerce, and web application architecture. </p>
                
                    
                
            </div>
        </div>
        
        
    </div>
</div></div>

</div><!--end row-->
</div></div>]]>
            </description>
            <link>https://resources.cast.ai/blog/google-anthos-vs-cast-ai-comparison</link>
            <guid isPermaLink="false">hacker-news-small-sites-25672035</guid>
            <pubDate>Thu, 07 Jan 2021 15:21:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I built an intercom for my 6 yo to keep us connected during quarantine]]>
            </title>
            <description>
<![CDATA[
Score 169 | Comments 119 (<a href="https://news.ycombinator.com/item?id=25671919">thread link</a>) | @daylankifky
<br/>
January 7, 2021 | https://chordata.cc/blog/open-source-intercom-for-kids/ | <a href="https://web.archive.org/web/*/https://chordata.cc/blog/open-source-intercom-for-kids/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<!-- .entry-container -->

			<div>
				
<pre><em>Today we’ll take a turn and showcase a personal project developed by our Tech Lead, Bruno, who took the multiple hours of lockdown we experienced last year and turned them into an initiative that allowed him to communicate with his 6 year old daughter. Below you’ll be able to review his experience and gather all of the details of his project (in case you want to replicate his system).</em></pre>



<p>In terms of social interactions, 2020 was an odd year, with cyclic lockdowns and openings. <strong>Keeping in touch with our close ones was one of the main challenges for all of us</strong>. The lockdowns are a bizarre experience in itself, but one of the strangest parts for me was when I topped it all up with a fever. It ended up being just a regular flu in the end, but for precaution my doctor ordered me to lock me down in a room for two weeks. Being there just a few meters away from my family and not being able to hug them or have a direct conversation was <strong>hard for all of us, but especially for my six-year-old daughter who wasn’t able to wrap her head around the reasons we couldn’t just see each other.</strong></p>



<p>So this time I decided to build something for her to keep us in touch in case something similar happens. The basic concept is a <strong>simplified interface for a Telegram voice chat with only a few (big) buttons: it should allow to easily and intuitively send and receive voice messages</strong>. Of course having a raspberry-pi as the core of this device was a no-brainer, since It has everything that’s needed for the project: WiFi connectivity, low level interface to control leds and buttons, and of course a complete OS where to run a Python interpreter to control everything.</p>



<div><figure><img src="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_blueprint-300x217.jpg" alt="" width="538" height="389" srcset="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_blueprint-300x217.jpg 300w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_blueprint-1024x739.jpg 1024w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_blueprint-768x555.jpg 768w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_blueprint-640x462.jpg 640w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_blueprint-100x72.jpg 100w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_blueprint.jpg 1108w" sizes="(max-width: 538px) 100vw, 538px"></figure></div>



<h3>TUI</h3>



<p>A good idea when dealing with electronic projects is to <strong>start small and have a proof of concept working before getting all the components</strong> and wire the whole thing together. In this case I started by creating the main program but replacing the physical button interface with a <em>TUI</em> (terminal user interface). The code can be found <a href="https://gitlab.com/daylanKifky/daddy-box-python-module" target="_blank" rel="noreferrer noopener">in this repository</a>, you should be able to test it by running it using the <code>--tui</code> flag like this:</p>



<pre>python -m daddy_box --tui</pre>



<div><figure><img src="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_tui.jpg" alt="" srcset="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_tui.jpg 575w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_tui-300x242.jpg 300w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_tui-100x81.jpg 100w" sizes="(max-width: 575px) 100vw, 575px"></figure></div>



<h3>Telegram bot setup</h3>



<p>The first time you run it you will need to give it a telegram bot key. Follow <a href="https://core.telegram.org/bots#3-how-do-i-create-a-bot" target="_blank" rel="noreferrer noopener">this steps</a> to create your instance of a Bot, and then run it with the <code>--setup-bot</code> flag and input the information the <em>BotFather</em> gave you.</p>



<p>You should now be able to search for the bot’s username in telegram and exchange some messages with it. You will first find that you get “not allowed” responses. The <strong>idea behind this bot is to exchange messages privately with just one user</strong>, so you have to tell the bot which is the allowed user id to interact with.</p>



<p>Take a look at the terminal where the bot is running, you will see some printed messages like this one:</p>



<div><figure><img src="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_user_id.png" alt="" srcset="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_user_id.png 571w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_user_id-300x66.png 300w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_user_id-100x22.png 100w" sizes="(max-width: 571px) 100vw, 571px"></figure></div>



<p>Copy your user-id from there and give it to the bot using the <code>--setup-user</code> flag.  You should now be able to send and receive voice messages, so we are ready to start with the physical part of the project.</p>







<h3>Raspberry pi HAT</h3>



<p>When doing a one-shot project like this I normally use breadboards or perfboards to assemble all the components. I used that approach a bunch of times in the past to handle a few backlitghted buttons, and the process was always frustrating: I ended up spending lots of time with the soldering and wiring of the components. So this time I decided to actually do what I promised myself each one of those times: design a <strong>breakout HAT for the raspberry with screw terminals where to easily connect everything.</strong></p>



<p>Since I was at it I added a darlington array and a number of selectable power sources in order to potentially handle bigger loads. I designed it in Kicad and then ordered a few PCBs. You can find the project files <a href="https://gitlab.com/daylanKifky/daddy-box-raspberry-pi-hat" target="_blank" rel="noreferrer noopener">here</a>.</p>



<div><figure><img src="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_HAT-1024x681.jpg" alt="" width="583" height="388" srcset="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_HAT-1024x681.jpg 1024w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_HAT-300x199.jpg 300w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_HAT-768x511.jpg 768w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_HAT-640x425.jpg 640w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_HAT-100x66.jpg 100w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_HAT.jpg 1053w" sizes="(max-width: 583px) 100vw, 583px"></figure></div>



<h3>Audio</h3>



<p>One little detail I wasn’t taking into consideration when I started the project was the fact that a <strong>raspberry pi doesn’t have an audio input</strong>.<strong> So I had to buy an USB microphone.</strong> A cheap one from a local store did the trick. I removed all the plastic parts and shortened the cable to avoid unnecessary EM interference.</p>



<div><figure><img src="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_mic.jpg" alt="" width="322" height="443" srcset="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_mic.jpg 581w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_mic-218x300.jpg 218w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_mic-349x480.jpg 349w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_mic-73x100.jpg 73w" sizes="(max-width: 322px) 100vw, 322px"></figure></div>



<p>Before using it I also tried a small USB audio card but I had a lot of conflicts being raised by <a rel="noreferrer noopener" href="http://people.csail.mit.edu/hubert/pyaudio/" target="_blank">pyaudio,</a> the library I used to handle the recording and playing of audio files in python.</p>



<p>For the audio output I connected a small speaker directly to the RPi audio output jack. The volume is a little low, but it gets the work done.</p>



<h3>Final assembly</h3>



<p>Once the PCBs and all the components arrived it was time to replace the <em>TUI</em> with a Button UI. I used the handy <a href="https://gpiozero.readthedocs.io/en/stable/" target="_blank" rel="noreferrer noopener">gpiozero</a> library to handle button press and leds. For the external case I used a shoe box to which I made holes for the buttons and speaker.</p>



<div>
<div>
<figure><img src="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly1-1024x576.jpg" alt="" srcset="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly1-1024x576.jpg 1024w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly1-300x169.jpg 300w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly1-768x432.jpg 768w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly1-640x360.jpg 640w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly1-100x56.jpg 100w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly1.jpg 1422w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>




</div>



<div>
<figure><img src="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly2-1024x576.jpg" alt="" srcset="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly2-1024x576.jpg 1024w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly2-300x169.jpg 300w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly2-768x432.jpg 768w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly2-640x360.jpg 640w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly2-100x56.jpg 100w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly2.jpg 1422w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>
</div>
</div>



<div><figure><img src="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly3-1024x576.jpg" alt="" width="493" height="277" srcset="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly3-1024x576.jpg 1024w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly3-300x169.jpg 300w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly3-768x432.jpg 768w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly3-640x360.jpg 640w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly3-100x56.jpg 100w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly3.jpg 1422w" sizes="(max-width: 493px) 100vw, 493px"></figure></div>



<p>Once everything was set and tested I disassembled and packed all the components inside the box, wrapped the whole thing as a gift to prepare it for the best part.</p>



<h3>XMAS</h3>



<p>I gave the box as a present to my daughter to be opened on Christmas eve without telling her what the purpose of all those parts were. <strong>The next morning we spent a couple of hours putting it all together, so she discovered the purpose of the device, its final shape and got a glimpse of the internal functionality during the process.</strong></p>



<div><figure><img src="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assemblykid-1024x576.jpg" alt="" width="510" height="286" srcset="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assemblykid-1024x576.jpg 1024w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assemblykid-300x169.jpg 300w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assemblykid-768x432.jpg 768w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assemblykid-640x360.jpg 640w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assemblykid-100x56.jpg 100w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assemblykid.jpg 1422w" sizes="(max-width: 510px) 100vw, 510px"></figure></div>



<p>When it was done my kid liked it way more than I could ever expect. What I conceived as an utilitary tool to keep us connected when I wasn’t close soon became a part of a game of exchanging messages about every little action in the everyday routine, even when we are just a few meters away 😅.&nbsp;</p>



<p>So I’m quite happy with the result. Not only did this object help strengthen our relationship, it ended up being a <strong>cool way to transmit the hacker-maker values and habits to a young mind.</strong></p>



<p>I hope some of you find this useful and if you try to build this at home I would love to know how it went for you, please share your experience in <a href="https://forum.chordata.cc/">our forum</a> using the <em>offtopic</em> tag.</p>



<p>And above all, have a great starting of the year!</p>



<figure><img src="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_final-1024x576.jpg" alt="" srcset="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_final-1024x576.jpg 1024w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_final-300x169.jpg 300w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_final-768x432.jpg 768w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_final-640x360.jpg 640w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_final-100x56.jpg 100w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_final.jpg 1422w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>
			</div><!-- .entry-content -->

			
		</div></div>]]>
            </description>
            <link>https://chordata.cc/blog/open-source-intercom-for-kids/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25671919</guid>
            <pubDate>Thu, 07 Jan 2021 15:11:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Science vs. Engineering]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25671767">thread link</a>) | @sandes
<br/>
January 7, 2021 | http://santiagodebus.com/science-vs-engineering#2 | <a href="https://web.archive.org/web/*/http://santiagodebus.com/science-vs-engineering#2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>http://santiagodebus.com/science-vs-engineering#2</link>
            <guid isPermaLink="false">hacker-news-small-sites-25671767</guid>
            <pubDate>Thu, 07 Jan 2021 14:58:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[German Foreign Minister: Those Who Incite Bear Responsibility]]>
            </title>
            <description>
<![CDATA[
Score 67 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25671401">thread link</a>) | @dakna
<br/>
January 7, 2021 | https://www.spiegel.de/international/world/german-foreign-minister-heiko-maas-those-who-incite-bear-responsibility-a-9e808002-67ee-4175-93b0-a01bf8e6dde2 | <a href="https://web.archive.org/web/*/https://www.spiegel.de/international/world/german-foreign-minister-heiko-maas-those-who-incite-bear-responsibility-a-9e808002-67ee-4175-93b0-a01bf8e6dde2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>The images of the storming of the Capitol Building in Washington, D.C., are painful to the soul of every friend of democracy. The democratic world is shocked and appalled. But that’s not enough. We need all democrats around the world to stand shoulder to shoulder. The struggle against narrow-minded delusion, against intolerance, against the division of our societies is our common struggle. Indeed, it would be self-righteous to point the finger solely at America right now. Here in Germany, too, in <a target="_blank" rel="noopener noreferrer" href="https://www.spiegel.de/international/germany/when-far-right-hatred-turns-into-terrorism-a-e58ac378-bc7c-442e-a024-c801296d2b9c" data-link-flag="english">Hanau</a>, <a target="_blank" rel="noopener noreferrer" href="https://www.spiegel.de/international/germany/far-right-terrorism-in-germany-shooting-exposes-lapses-in-security-apparatus-a-1291075.html" data-link-flag="english">Halle </a>and on the steps of Reichstag (in coronavirus protests last summer), we have seen how agitation and inflammatory words can spark hateful deeds.</p><div>
<p>This should be extremely clear: Those who, like Trump, have spent years using words to constantly inflame and incite their own supporters, ultimately bear responsibility for this attack on the heart of American democracy. We see all around the world what happens when radical populists come to power and systematically stir up resentment against democratic institutions. Yes, democracy thrives on contradiction, even disagreement. But it dies when brute force silences the other, when sheer hatred breaks all bounds of decency and respect.</p><p>The radical mob does not represent the majority in the United States. The vast majority of American voters stand firmly behind democracy and voted decisively against a right-wing populist. And it’s not just Donald Trump who needs to finally accept that. Every Republican with a modicum of responsibility needs to finally repudiate Trump once and for all. The American courts have ruled clearly that this was a lawful election. Those who disrespect that election result are disrespecting their own people.</p>
</div><div>
<p>America’s strength is its diversity. It is admired around the world for the freedom of its democracy. U.S. president-elect Joe Biden knows this. His call yesterday for mutual respect and reconciliation were the soothing words of a president. And the confirmation of the election of Joe Biden and Kamala Harris by the U.S. Congress was the best democratic response to those who sowed chaos and discord in Washington yesterday.</p><p>As friends of America and as friends of democracy, we wish Joe Biden and Kamala Harris great strength in the difficult task of overcoming America’s division. We stand together with them in the fight for democracy. In keeping with the quintessential American motto: "E pluribus unum" – out of many, one.</p>
<p><span><svg aria-labelledby="title-96c1fa78-0685-4f94-b192-d76eb79d3cf9" width="10" height="20" viewBox="0 0 10 20" fill="none" xmlns="http://www.w3.org/2000/svg" role="img"><title id="title-96c1fa78-0685-4f94-b192-d76eb79d3cf9">Icon: Der Spiegel</title><g id="l-s-flag-96c1fa78-0685-4f94-b192-d76eb79d3cf9"><path id="vector-96c1fa78-0685-4f94-b192-d76eb79d3cf9" d="M9.85 16.293v-8H3.212V4.667h3.533v2.24h3.212v-3.2C9.85 2.747 8.993 2 8.03 2H1.713C.749 2 0 2.747 0 3.707v7.253h6.638v4.373H3.105v-2.986H0v3.84c0 .96.75 1.706 1.713 1.706H8.03c.963.107 1.82-.64 1.82-1.6z" fill="#000"></path></g></svg>
</span>
</p></div></div>]]>
            </description>
            <link>https://www.spiegel.de/international/world/german-foreign-minister-heiko-maas-those-who-incite-bear-responsibility-a-9e808002-67ee-4175-93b0-a01bf8e6dde2</link>
            <guid isPermaLink="false">hacker-news-small-sites-25671401</guid>
            <pubDate>Thu, 07 Jan 2021 14:30:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The links between the Trump administration and critical theory]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25671391">thread link</a>) | @thinkingemote
<br/>
January 7, 2021 | https://outsidertheory.com/theorycels-in-trumpworld/ | <a href="https://web.archive.org/web/*/https://outsidertheory.com/theorycels-in-trumpworld/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>As I have explored previously, various commentators in the early Trump era attempted to <a href="https://www.vox.com/features/2019/11/11/18273141/postmodernism-donald-trump-lyotard-baudrillard">link</a> the new president to the body of thought often known as “postmodern theory.” As a recap of this discussion, I will quote here from some of my <a href="https://arcdigital.media/the-irony-poisoner-88d3f15232b9">prior writing</a> on the subject:</p><p>“In early 2017 . . . Steve Bannon, a White House strategist at the time, <a href="https://www.washingtonpost.com/politics/top-wh-strategist-vows-a-daily-fight-for-deconstruction-of-the-administrative-state/2017/02/23/03f6b8da-f9ea-11e6-bf01-d47f8cf9b643_story.html">proclaimed</a> that the Trump administration would undertake the ‘deconstruction of the administrative state.’ Bannon’s invocation of this old buzzword of critical theory led to plenty of <a href="https://twitter.com/HeerJeet/status/834922404216360961">humorous</a> <a href="https://twitter.com/garymmorris/status/835132954712104962">Twitter takes</a>, many linking [deconstructive literary theorist Paul] de Man to Trump’s postmodern White House.</p><p>“Conservatives usually repudiate postmodernism, but this was not the first time an improbable alliance between these nemeses had been suggested. At least since a George W. Bush aide <a href="https://en.wikipedia.org/wiki/Reality-based_community">dismissed</a> ‘the reality-based community,’ the notion that there is a ‘<a href="https://arcdigital.media/the-rise-of-post-modern-conservatism-53cf8651b052">postmodern turn</a>’ on the right has gained a certain currency. Many have found further evidence of a synthesis of conservatism and postmodernism in certain glib pronouncements emerging out of the Trump orbit, from Kellyanne Conway’s ‘alternative facts’ to Rudy Giuliani’s ‘truth isn’t truth.’”</p><p>Now, as the Trump era draws to a close, I would like to discuss a more concrete and, in my view, more interesting aspect of the admittedly tenuous linkage between Trump and “theory.” This is the presence of several individuals in the orbit of his White House who, in contrast to “folk postmodernists” like Conway and Giuliani, have an intellectual background and a sustained interest in “theory.”</p><p>I will focus on three such figures, but first, I will consider one other with a powerful spectral presence in the Trump-aligned political realm: Andrew Breitbart. Breitbart died before Trump’s political rise, but the eponymous publication he founded became an unofficial house organ of Trump’s campaign as well as a feeder of staff to his administration. One <em>Breitbart</em> alumna who ended up in the White House will be my second subject: Julia Hahn, previously a student of philosophy and psychoanalysis. Next, I’ll consider Darren Beattie, a former Trump speechwriter who wrote a doctoral dissertation on Martin Heidegger. Finally, I’ll return briefly to the theoretical interests of the so-called “philosopher-CEO” Peter Thiel, who has made regular appearances in my writing in the past. Thiel was never part of Trump’s administration, but he was an influential supporter, delegate, convention speaker, and member of the transition team in 2016.</p><h4>Andrew Breitbart</h4><p>Breitbart deserves mention here because although he helped establish the negative tenor of much of the contemporary right’s attitude to “theory,” he also pointed towards a different relationship between right-wing insurgents and the body of thought referred to by that term. In his 2011 autobiography <em>Righteous Indignation</em>, Breitbart wrote about his induction into “cultural Marxism” in college, specifically the work of the Frankfurt School theorists Theodor Adorno, Max Horkheimer, and Herbert Marcuse, and his later realization that “it was everywhere, from the mainstream media to Hollywood to the educational system to the government.” He describes critical theory as a “mission to destroy society and culture using the Marxist dialectic.”</p><p>It is worth quoting Breitbart at greater length on this subject:</p><p>“[Critical theory] was . . . a theory of criticizing everyone and everything everywhere. It was an attempt to tear down the social fabric by using all the social sciences (sociology, psychology, economics, political science, etc.); it was an infinite and unending criticism of the status quo, adolescent rebellion against all established social rules and norms.”</p><p>This passage should be read against the grain of its overt anti-theory stance. Elsewhere, Breitbart tells us that American society and politics is controlled by the “Democrat-Media Complex,” the “the power structure of Hollywood, Washington, and New York,” which is infused with cultural Marxism. How does one respond to this? Presumably by way of  a “ruthless criticism of all that exists” – in other words, by using the methods that Breitbart views as the main vice of critical theory; perhaps, also, by engaging in “adolescent rebellion against all established social rules and norms,” which is to say, against the politically correct dogmas of hegemonic liberalism. (Breitbart’s publication, recall, went on to employ Milo Yiannopolous.)</p><p>This is the real task Breitbart sets for himself and for the American right, and in this way, he seeks to learn from the “cultural Marxists” he repudiates. This means learning from his enemies, the cultural Marxists, in order to defeat them, since “[a]s it stands, the Frankfurt School–taught left is fighting the political battle on both the political and the cultural battlefields. Conservatives are fighting it only on the political battlefield.” Breitbart’s famous motto, “Politics is downstream from culture,” proceeds from its founder’s belief that the right should embrace the approach he attributes to critical theory to reclaim the culture from the “Democrat-Media Complex.” (As is often noted, the motto is Breitbart’s spin on the work of the Italian political theorist Antonio Gramsci, a key figure in his “cultural Marxism” narrative.) To borrow the Hegelian terminology his Frankfurt School nemeses might find congenial, Breitbart set out to “negate the negation.”</p><p>What’s difficult to determine from <em>Righteous Indignation</em> is how fully Breitbart believes the just-so story he relates about a handful of relatively obscure philosophers single-handedly undermining American society by slowly meming their ideas into the mainstream through the universities. Perhaps this is a conscious act of mythmaking carried out in the service of Breitbart’s own meme warfare counterattack. Regardless, his ambivalent relationship to “theory” – both his primary antagonist and a crucial inspiration for his project – set the stage for later developments in the Trump era.</p><h4>Julia Hahn</h4><p>Julia Hahn is, as of the writing of this post, still Special Assistant to the President, having outlasted many other White House staffers. This includes the man who brought her into Trump’s orbit: Steve Bannon, Andrew Breitbart’s friend and successor at the media empire he launched. Hahn wrote for <em>Breitbart</em> throughout the 2016 primary and general elections, prior to entering the Trump administration. She was best known for her polemical coverage of establishment Republicans like Paul Ryan and for incendiary immigration reporting that repeatedly drew attention to crimes committed by immigrants.</p><p>What brings Hahn to our attention here, however, is her <a href="https://thepointmag.com/politics/uchicago-bannons-bannons-bannon/">prior career</a> as a student at the University of Chicago. Less than two years before taking a job at <em>Breitbart</em>, Hahn, as an undergraduate, appeared on a panel discussion at Chicago related to the work of Leo Bersani, a crucial figure in the development of queer theory. The video of this session is still available on <a href="https://youtu.be/39FMKMdoM18?t=2246">Youtube</a>. The moderator who introduces Hahn to the audience situates her research “at the intersection of psychoanalysis and post-Foucauldian philosophical inquiry” and explains that her senior thesis explores “how psychoanalysis reveals flaws in the neo-Kantian conception of autonomy.”</p><p>Hahn breaks the ice at the beginning of her presentation with a joke about anal sex (a theoretical interest of Bersani’s), then delivers a precisely argued reassessment of French social theorist Michel Foucault’s critique of Freudian psychoanalysis. For background, Foucault’s critique of psychoanalysis goes approximately as follows: Freud believed that by working through repressed desires in speech, suffering people might find relief from the harmful effects of repression; but according to Foucault, rather than offering liberation through the release of pent-up desires, psychoanalysis <em>produced</em> those desires as discursive phenomena available to be monitored by power for the purpose of social control; in this sense, it amounted to a new strategy of social discipline comparable to the Catholic confessional. Hahn’s goal is to nuance Foucault’s critique by showing that Freud anticipated some elements of it, and to propose a model of psychoanalysis that survives Foucauldian scrutiny. In the course of this discussion, Hahn argues that Foucault’s account of psychoanalysis as a technique of power does not truly discredit it. Power is unavoidable, she says; “the problem,” as she reads Foucault, “is when power becomes rigid, and leads to states of what he calls domination.”</p><p>Given Hahn’s later career, it’s hard not to hear a faint echo here of Andrew Breitbart’s attack on the “Democrat-Media Complex.” Perhaps someone deeply invested in Foucault’s criticism of the diffuse, invisible ways in which power is exercised in the modern world, as Hahn appeared to be, might find some appeal in Andrew Breitbart’s account of the full-spectrum liberal “domination” of education, entertainment, and other industries and institutions, just as Breitbart himself was unmistakably attracted to aspects of the “culture industry” critique of the Frankfurt School theorists he detested.</p><p>Hahn’s presentation gives the impression of a nuanced and even-handed style of thought that contrasts with her overtly propagandistic work for <em>Breitbart</em>. Yet her paper might be read as offering a preemptive retort to this criticism, which goes something like this: no doubt, <em>Breitbart</em> is a purveyor of political propaganda, just as Freudian psychoanalysis is a technique of power. But if, as Foucault argues (and Breitbart would concur), the operations of power are omnipresent, perhaps university lectures and subtle literary essays are no less propagandistic than incendiary anti-immigration screeds. Hence, just as, for Hahn, the investment of psychoanalysis in power relations does not discredit it, especially if it can offer a means for resisting “domination,” the same might be said of outrage clickbait. Indeed, the latter’s …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://outsidertheory.com/theorycels-in-trumpworld/">https://outsidertheory.com/theorycels-in-trumpworld/</a></em></p>]]>
            </description>
            <link>https://outsidertheory.com/theorycels-in-trumpworld/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25671391</guid>
            <pubDate>Thu, 07 Jan 2021 14:29:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pachyderm 1.12 GA – New ways to aggregate data from multiple sources and more]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25671355">thread link</a>) | @PachydermInc
<br/>
January 7, 2021 | https://pachdm.com/3bg5UJw | <a href="https://web.archive.org/web/*/https://pachdm.com/3bg5UJw">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main-content"><article><div><div><p><img src="https://pachdm.com/images/blog-images/Pachyderm-1-12-announcment.jpg" alt="Pachyderm 1.12 GA Announcement"></p><p>2020 was a crazy year, to say the least. That’s why we thought it best not to tempt fate by trying to squeeze in a major release during the last few weeks of December. And so, with a renewed sense of optimism, and 2020 now officially in the history books (hooray!), we’re excited to announce the release of Pachyderm 1.12.</p><p>Here’s a look at what’s new:</p><h3 id="new-pipeline-input-type-groups">New Pipeline Input Type: Groups</h3><p>Groups give you a brand new way to combine data from multiple sources on Pachyderm. Similar to a database <em>group-by</em>, <strong><a href="https://docs.pachyderm.com/latest/concepts/pipeline-concepts/datum/group/">Groups in Pachyderm</a></strong> are a special type of pipeline input that enables you to aggregate files from one or more Pachyderm repositories via a particular naming pattern. For example:</p><p><strong>Groups within a single repo</strong></p><pre><code>$ pachctl list file repo@master
/labs/patientID1-labID1.txt
/labs/patientID2-labID1.txt
/labs/patientID1-labID2.txt
/labs/patientID3-labID1.txt
</code></pre><p>By configuring our pipeline input type to <code>group</code> and defining our <code>capture group</code> to match on <code>patientID</code>, we can <strong>aggregate all of patientID1 lab results into a single datum</strong> and create separate datums for all of patient 2 and 3. Neat!</p><p>Where Pachyderm Groups really start to shine is when you want to combine data from multiple repos and return the result as a single datum to be processed independently. For example, imagine we have a retail department store chain with multiple stores and different repos storing purchase information, return information and store identity information:</p><p><strong>Groups using multiple repos</strong></p><pre><code>Repo 1: Purchases
/ORDERW078929_STOREID2.txt file 64B  
/ORDERW080231_STOREID5.txt file 65B  
...
</code></pre><pre><code>Repo 2: Returns
NAME                       TYPE SIZE 
/ORDERW080231_STOREID5.txt file 65B  
/ORDERW080520_STOREID1.txt file 65B  
...
</code></pre><pre><code>Repo 3: Stores
/STOREID1.txt file 85B  
/STOREID2.txt file 85B  
/STOREID3.txt file 84B
</code></pre><p>Let’s say we wanted to get a list of all transactions (purchases or returns) grouped by storeID. Thanks to the new Pachyderm Group input type, this is easy. We simply specify our matching criteria and let Pachyderm handle the rest.</p><p>For those familiar with Pachyderm <code>joins</code>, you might be wondering how groups are different? In a nutshell, <code>joins</code> will return a single datum per match. Groups, on the other hand, will return all matches as a single datum.</p><p><strong><a href="https://pachdm.com/3omRJX0">Try groups out for yourself with this great example.</a></strong></p><h3 id="automated-deferred-processing-with-triggers">Automated Deferred Processing with Triggers</h3><p>Another exciting addition to Pachyderm 1.12 is Triggers, which gives users greater control over how and when to process data.</p><p>Take our retail example from earlier. Throughout the day we have lots of transactions happening; for each transaction the company has to pay anywhere from 1-3% of the total plus a flat fee to the bank (aka interchange-rates). A Pachyderm Trigger could help reduce those costs by automatically deferring each transaction’s processing using a predefined set of criteria – For example, every night at 10pm, or in batches of 20.</p><p>Now, instead of paying a processing fee for each transaction, we only pay it once. Cha ching!</p><p><strong><a href="https://pachdm.com/3pPjWG6">Give Pachyderm Triggers a try.</a></strong></p><h3 id="pachyderm-112-enterprise-additions">Pachyderm 1.12 Enterprise Additions:</h3><p>Pachyderm Enterprise includes everything mentioned so far as well as a few other goodies:</p><ul><li><a href="https://pachdm.com/3be5i7c">Group support for OIDC</a></li><li>Auth-enabled Extract/Restore</li></ul><h3 id="other-noteworthy-items">Other Noteworthy Items:</h3><p><strong><a href="https://pachdm.com/35gQUYm">Improved Spouts</a></strong>
We re-architected spouts to improve stability and security while also making it easier to integrate with external data sources.</p><p><strong><a href="https://pachdm.com/2MxA0hm">New “outer joins”</a></strong>
Where inner joins in Pachyderm will only return matched results, outer joins will return a result regardless of whether there’s a match or not.</p><p><strong><a href="https://pachdm.com/35gkDAA"><code>pachctl list datum</code></a></strong>
Now includes a dry run option for testing glob patterns.</p><p><strong><a href="https://pachdm.com/2Xjun8S"><code>pachctl update pipeline</code></a></strong>
Now supports transactions.</p><p>Interested in learning more about Pachyderm? <strong><a href="https://pachdm.com/3ogNTP3">Schedule some time with one of our experts</a></strong></p></div></div></article></div></div>]]>
            </description>
            <link>https://pachdm.com/3bg5UJw</link>
            <guid isPermaLink="false">hacker-news-small-sites-25671355</guid>
            <pubDate>Thu, 07 Jan 2021 14:27:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DOS Era PC Game Programmer's Encyclopedia]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25671184">thread link</a>) | @postit
<br/>
January 7, 2021 | http://qzx.com/pc-gpe/ | <a href="https://web.archive.org/web/*/http://qzx.com/pc-gpe/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<p>Welcome to the PC Game Programmer's Encyclopedia on the World Wide Web!</p>


<hr>





<hr>


<h2><a href="ftp://x2ftp.oulu.fi/pub/msdos/programming/gpe/" target="_top">PC-GPE archive</a></h2>

<h2>Download PC-GPE v1.0</h2>
	<p><a href="ftp://x2ftp.oulu.fi/pub/msdos/programming/gpe/pcgpe10.zip" target="_top">DOS</a>
	/ <a href="ftp://x2ftp.oulu.fi/pub/msdos/programming/gpe/wpcgpe10.zip" target="_top">Windows</a></p>

<h2>Download PC-GPE v1.0a Patch</h2>
	<p><a href="ftp://x2ftp.oulu.fi/pub/msdos/programming/gpe/patch10a.txt" target="_top">DOS</a></p>


<hr>


<p>Special thanks go out to Mark Feldman for putting together the PC-GPE, and to all the
authors who contributed to PC-GPE. Thank you very much!</p>

<p><b>This page was created with the permission of
<a href="http://www.geocities.com/SiliconValley/2151/" target="_top">Mark Feldman</a>, the author of
<a href="http://www.geocities.com/SiliconValley/2151/pcgpe.html" target="_top">PC-GPE</a>.</b></p>


<hr>


<p>Visit
<a href="http://brix-os.sf.net/library" target="_top">http://brix-os.sf.net/library</a>
for more programming information.</p>


<hr>


<p><i>Created: 09/29/95 - Ben Wright</i></p>
<p><i>Modified: 8dec2001 - Brand Huntsman</i></p>

<hr><p><a href="http://qzx.com/"><img src="http://qzx.com/images/minilogo.gif" width="93" height="57" alt="QZx.com"></a></p></div></div>]]>
            </description>
            <link>http://qzx.com/pc-gpe/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25671184</guid>
            <pubDate>Thu, 07 Jan 2021 14:10:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Analyzing CVE-2020-16040]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25671152">thread link</a>) | @todsacerdoti
<br/>
January 7, 2021 | https://faraz.faith/2021-01-07-cve-2020-16040-analysis/ | <a href="https://web.archive.org/web/*/https://faraz.faith/2021-01-07-cve-2020-16040-analysis/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <div>
    <div>
      <article role="main">
	      

<p>I recently analyzed a really cool N-day vulnerability in V8 and wanted to blog about it since I learned a lot while analyzing it.</p>



<p>On the 24th of November, a <a href="https://chromium-review.googlesource.com/c/v8/v8/+/2557498">very interesting V8 commit</a> was made visible as part of <a href="https://crbug.com/1150649">Chromium Issue 1150649</a> (which is still restricted). The commit patched a bug in the Simplified Lowering Phase of V8’s optimizing JIT compiler, TurboFan. The latest version of V8 that this bug affects is version <strong>8.9.40</strong>. I will be using this as the unpatched version for analysis, and I will be comparing things like Turbolizer output against version <strong>8.9.41</strong>, where the bug is fixed.</p>

<p>The patch also included a nice regression test that showcased how to trigger the bug. It did not however grant any immediate exploitable primitives, so some work would need to be done to figure out whether the bug is exploitable at all (and how to exploit it).</p>

<p>Prior to analyzing this bug, I hadn’t really ever looked at the Simplified Lowering Phase in detail, so I took this as the perfect opportunity to learn about it. There was also the added benefit of having to look at all the optimization phases that come <em>after</em> the Simplified Lowering Phase in order to figure out whether this bug was exploitable or not. This would mean there would be tons of new things for me to learn, and that’s really all I aim for at the end of the day.</p>



<p>Before actually starting to analyze the bug, it is helpful to have some background knowledge of V8 and TurboFan. In this case, having some knowledge of how TurboFan works, and more specifically knowledge of how the Simplified Lowering Phase works would be extremely helpful.</p>

<p><a href="https://twitter.com/__x86">Jeremy Fetiveau (@__x86)</a> recently <a href="https://doar-e.github.io/blog/2020/11/17/modern-attacks-on-the-chrome-browser-optimizations-and-deoptimizations/">wrote a blog post that I would highly recommend</a>. It has a section that talks about how the Simplified Lowering Phase works in TurboFan. There are also a few other blog posts on that same blog (as well as online elsewhere) that cover topics like TurboFan’s typer, and etc.</p>

<p>Although I’ll try to explain everything that’s required to understand this specific bug, feel free to refer to other resources to understand what I’m trying to say. Information about complex topics is often really difficult to relay in a manner that’s comprehensible by everyone.</p>

<p><strong>It is also highly recommended that you follow along somehow by reading a lot of the code yourself on your local machine. It’s impossible for me to show every single bit of code that’s needed to get the right information across to everyone, so it will be useful to be able to refer to the code whenever you are confused about anything.</strong></p>



<p>The first thing that I always do when analyzing any bug is to gather all the information that I initially have, and try to come up with some exploratory questions that I’ll hopefully be able to answer after I’m done with my analysis. The exploratory nature of the questions should force me to really read a lot of code to come up with the answers.</p>

<p>How does this apply to this bug? Well, for starters, we have the patch, a commit message, and regression test. The regression test especially is very useful. If I didn’t have the regression test handy, then the first thing I’d do is try to figure out how to trigger the bug (which is easier said than done with something as complex as V8 / TurboFan). Since we have the regression test in this case though, I’ll just leave the whole “how to come up with a proof of concept” for another blog post.</p>

<p>Looking at the commit message, we see that it states the following:</p>

<div><div><pre><code>[compiler] Fix a bug in SimplifiedLowering

SL's VisitSpeculativeIntegerAdditiveOp was setting Signed32 as restriction type even when 
relying on a Word32 truncation in order to skip the overflow check. This is not sound.
</code></pre></div></div>

<p>By itself, without any prior knowledge about the Simplified Lowering Phase, this might be difficult to understand. We do know that the patch modified a function called <code>VisitSpeculativeIntegerAdditiveOp</code>, and that it has a nice comment that provides a bit more information:</p>

<div><div><pre><code><span>+    // Using Signed32 as restriction type amounts to promising there won't be
+    // signed overflow. This is incompatible with relying on a Word32
+    // truncation in order to skip the overflow check.
+    Type const restriction =
+        truncation.IsUsedAsWord32() ? Type::Any() : Type::Signed32();
</span></code></pre></div></div>

<p>Right here, we have a few different terms such as “restriction type”, “Word32 truncation”, etc, that we have to learn about, but it should be pretty logical to conclude that the effect of the bug is this: the engine makes a promise and says that a signed integer overflow will not take place, but the actual outcome is that a signed integer overflow <em>does</em> take place.</p>

<p>Knowing this, let’s have a look at the regression test now. I added my own <code>assertTrue</code> and <code>assertFalse</code> functions to it so that I could actually run it (I believe ClusterFuzz does this automatically). Here is the modified poc:</p>

<div><div><pre><code><span>// Copyright 2020 the V8 project authors. All rights reserved.</span>
<span>// Use of this source code is governed by a BSD-style license that can be</span>
<span>// found in the LICENSE file.</span>

<span>// Flags: --allow-natives-syntax</span>

<span>function</span> <span>assertTrue</span><span>(</span><span>c</span><span>)</span> <span>{</span>
    <span>if</span> <span>(</span><span>!</span><span>c</span><span>)</span> <span>{</span> <span>throw</span> <span>"</span><span>Assertion failed</span><span>"</span><span>;</span> <span>}</span>
<span>}</span>

<span>function</span> <span>assertFalse</span><span>(</span><span>c</span><span>)</span> <span>{</span>
    <span>assertTrue</span><span>(</span><span>!</span><span>c</span><span>);</span>
<span>}</span>

<span>function</span> <span>foo</span><span>(</span><span>a</span><span>)</span> <span>{</span>
  <span>var</span> <span>y</span> <span>=</span> <span>0x7fffffff</span><span>;</span>  <span>// 2^31 - 1</span>

  <span>// Widen the static type of y (this condition never holds).</span>
  <span>if</span> <span>(</span><span>a</span> <span>==</span> <span>NaN</span><span>)</span> <span>y</span> <span>=</span> <span>NaN</span><span>;</span>

  <span>// The next condition holds only in the warmup run. It leads to Smi</span>
  <span>// (SignedSmall) feedback being collected for the addition below.</span>
  <span>if</span> <span>(</span><span>a</span><span>)</span> <span>y</span> <span>=</span> <span>-</span><span>1</span><span>;</span>

  <span>const</span> <span>z</span> <span>=</span> <span>(</span><span>y</span> <span>+</span> <span>1</span><span>)</span><span>|</span><span>0</span><span>;</span>
  <span>return</span> <span>z</span> <span>&lt;</span> <span>0</span><span>;</span>
<span>}</span>

<span>%</span><span>PrepareFunctionForOptimization</span><span>(</span><span>foo</span><span>);</span>
<span>assertFalse</span><span>(</span><span>foo</span><span>(</span><span>true</span><span>));</span>
<span>%</span><span>OptimizeFunctionOnNextCall</span><span>(</span><span>foo</span><span>);</span>
<span>assertTrue</span><span>(</span><span>foo</span><span>(</span><span>false</span><span>));</span>
</code></pre></div></div>

<p>Looking at the code itself, we can quickly determine the following about the function <code>foo</code>:</p>

<ol>
  <li>A variable <code>y</code> is set to <code>0x7fffffff</code>, which is <code>INT_MAX</code>.</li>
  <li>Some TurboFan specific stuff is done which allows the bug to be triggered (we’ll get into all of this later).</li>
  <li>A variable <code>z</code> is set to <code>(y + 1)|0</code>.</li>
  <li>The return statement is supposed to return <code>false</code> for the first call to <code>foo</code> (The argument <code>a</code> will be <code>true</code>, so <code>y</code> will be set to <code>-1</code>, which will cause <code>z</code> to be set to <code>y+1 == -1+1 == 0</code>), which it does correctly.</li>
  <li>For the second call to <code>foo</code>, <code>a</code> will be <code>false</code>, so <code>z</code> will be set to <code>y+1 == 0x7fffffff+1 == 0x80000000</code>. Based on the regression test, it seems this addition should yield the negative number <code>-2147483648</code>, which should cause the function to return <code>true</code> as this negative number is less than 0.</li>
  <li>However, if you run this regression test, you’ll see that the final <code>assertTrue</code> will fail. We can conclude that the bug supposedly causes the engine to incorrectly assume that an integer overflow hasn’t occurred, when in fact it has (we haven’t verified yet that it has, but we will later).</li>
</ol>

<p>Based on this information, I came up with the following questions that I will need to have answered after I’ve finished analyzing the bug:</p>

<ul>
  <li>
    <p>The “static type” of <code>y</code> is widened initially. The question is, how does this work? What is the “static type”, and why does it need to be widened here?</p>
  </li>
  <li>
    <p>In the warmup run (i.e the initial call to <code>foo</code>), <code>SignedSmall</code> feedback is collected by setting <code>y</code> to <code>-1</code>. Again, why is this required here? How does this specific line of code collect <code>SignedSmall</code> feedback?</p>
  </li>
  <li>
    <p>Why is <code>z</code> set to <code>(y + 1)|0</code>? More specifically, why is it bitwise OR’d with <code>0</code>?</p>
  </li>
</ul>

<p>These are the three questions I started with. It’s these questions that help give me a goal to work towards. Even though I had the initial goal of “analyse and understand this bug”, it’s not as achievable because it’s so broad. Specific questions like these allow me to focus on one thing at a time, and as I figure out the answers, I’ll slowly figure out the bug itself, which is the real end goal here.</p>



<p>Before I started with answering the questions though, I wanted to quickly compare the Turbolizer graphs between the unpatched and patched versions of V8 to see exactly what effect the patch had on the engine. I won’t go into detail about how to use Turbolizer as there are many blog posts and guides out there.</p>

<p>When I looked at the graphs, I noted that the graphs looked the exact same during the Escape Analysis phase (which runs right before the Simplified Lowering Phase). I’ll only be showing the relevant parts of the graph here.</p>

<p>Escape Analysis Phase:</p>

<p><img src="https://faraz.faith/images/cve-2020-16040/1.png" alt=""></p>

<p>A difference in the graph only shows in the Simplified Lowering Phase. Here are the Simplified Lowering phases of both versions:</p>

<p>Unpatched Simplified Lowering Phase:</p>

<p><img src="https://faraz.faith/images/cve-2020-16040/2.png" alt=""></p>

<p>Patched Simplified Lowering Phase:</p>

<p><img src="https://faraz.faith/images/cve-2020-16040/3.png" alt=""></p>

<p>It’s immediately evident that the <code>NumberLessThan</code> node from the Escape Analysis Phase has been changed to a <code>Uint32LessThan</code> node in the unpatched version’s Simplified Lowering Phase, whereas it has been changed to an <code>Int32LessThan</code> node in the patched version’s Simplified Lowering Phase.</p>

<p>This node is used for the final <code>return z &lt; 0</code> comparison. Presumably, the <code>Uint32LessThan</code> node means that TurboFan has failed to notice the integer overflow that occurs during the addition, as it attempts to compare the two numbers as unsigned 32-bit integers.</p>

<p>In contrast, the patched version’s Simplified Lowering Phase will correctly compare the two numbers as signed 32-bit integers using the <code>Int32LessThan</code> node. This is the correct way to do it since the addition does indeed yield a negative number.</p>



<p>At this point, I started ticking the questions off one at a time. The process for this is somewhat tedious, but I just essentially pick one of the questions and do whatever it takes to answer it.</p>

<p>For example, let’s take the first question - <strong>Why is it required to widen the static type of <code>y</code>?</strong></p>

<ol>
  <li>Comment out the line of code that widens the static type of <code>y</code>. Generate a Turbolizer graph with the modified poc, and compare the original Turbolizer graph with it. What differences do you see?</li>
  <li>Trace through the code for both cases, making extensive use of GDB to get debug output (such as to see the nodes’ types, see what execution paths are taken, etc).</li>
  <li>Find the exact point in the code where the …</li></ol></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://faraz.faith/2021-01-07-cve-2020-16040-analysis/">https://faraz.faith/2021-01-07-cve-2020-16040-analysis/</a></em></p>]]>
            </description>
            <link>https://faraz.faith/2021-01-07-cve-2020-16040-analysis/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25671152</guid>
            <pubDate>Thu, 07 Jan 2021 14:07:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Predictions for Agriculture 2020s Decade]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25671102">thread link</a>) | @kickout
<br/>
January 7, 2021 | https://thinkingagriculture.io/predictions-for-the-2020s-decade/ | <a href="https://web.archive.org/web/*/https://thinkingagriculture.io/predictions-for-the-2020s-decade/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
		<div id="content">

	<div id="primary">
		<main id="main">
			
<article id="post-233" itemtype="https://schema.org/CreativeWork" itemscope="">
	<div>
		
		<!-- .entry-header -->

		
		<div itemprop="text">
			
<p>As the new year turns over, people in all industries have been making predictions about what they think will happen. Predictions are mostly free and fun to do, so I’ll make some decade long predictions since the scale I’m interested and agriculture in general tend to move slower than other industries. Most of these are quantifiable enough to be called success or failure when 2030 rolls around.</p>



<ul><li>Maize production in the United States peaks in first half and then dramatically falls in second half. I predict maize acreage to be somewhere below 50M planted acres in the years 2028 and 2029.</li><li>95% of corn ethanol plants in operation today will shutter due to insolvency and corn ethanol production in 2029 is 1/100 of its 2020 production levels.</li><li>Brazil grows 50% more soybean acres than the United States. Currently, the ratio has been hovering close to 1:1 with rapid gains on the Brazilian side. This ratio will turn to 1.5/1 in favor of our Brazilians friends. I predict acreages in 2029 to be around ~120 million acres planted in Brazil, and ~80 acres planted in the United States .</li><li>Chemical herbicides will be rendered all but useless for maize, soybean, cotton in both the United States and Brazil. This will signal the resurrection of robust public breeding programs for these crops, or the formation of <a rel="noreferrer noopener" href="https://www.cimmyt.org/" data-type="URL" data-id="https://www.cimmyt.org/" target="_blank">CIMMYT</a>-type enterprises. Whatever chemicals are applied, are done using UAVs or level 4-type autonomous machines.</li><li>To fill the void of ineffective chemical herbicides, first generation autonomous weeding robots will hit market at scale in the back half of the decade.</li><li>There will be a severe <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Soybean_rust" data-type="URL" data-id="https://en.wikipedia.org/wiki/Soybean_rust" target="_blank">soybean rust</a> outbreak in Brazil, devastating production.</li><li>There will be 50M acres of farmland that are enrolled in a ‘Farming as a Service’ program. I take this to mean the farmer will not make a individual decision on anything; they will simply execute a playbook provided by a company designed to maximize profitability. The profitability will be guaranteed up to a level, with any additional gains to be kept by the company.</li><li>There will be ~100M acres (roughly 1/3 of U.S. cropland) that have <span>living plants</span> growing on their soil continuously throughout the calendar year–with minimal effects on the ‘main’ crop. This will be accomplished with optimized cover crop species mechanization and genetics.</li><li>Tesla, Amazon, Google, Microsoft, or Apple starts up (or acquires) an ‘official’ agriculture division.</li><li>Applying fertilizer on crops becomes regulated in the United States. There will be limits on how much (and when) farmers can apply and some old techniques will be banned because of inefficiency. This will be done to protect water quality.</li><li>Sub-Saharan Africa (SSA) doubles the productivity of the crops it currently grows. Only political instability is preventing SSA from competing with the Midwest region of the United States and Brazil.</li><li>Greenhouse (or contained structures) production of leafy green vegetable increases 5x.</li><li>CRISPR-Cas9 edited crops are plagued by worldwide regulatory gridlock. The success stories will be closed supply chains (i.e. farm to table type operations).</li><li>The price for a ton of sequestered carbon <span>on farmland</span> will average $100 dollars (<a rel="noreferrer noopener" href="https://nori.com/" data-type="URL" data-id="https://nori.com/" target="_blank">assuming it’s currently ~$15</a>). There will be millions of acres (of cropland) that fetch $200 per ton.</li><li>The ’boutique’ fruits/vegetable portfolio intensifies (i.e.<a rel="noreferrer noopener" href="https://cosmiccrisp.com/" data-type="URL" data-id="https://cosmiccrisp.com/" target="_blank"> Cosmic Crisp apples</a>, <a rel="noreferrer noopener" href="https://grapery.biz/" data-type="URL" data-id="https://grapery.biz/" target="_blank">cotton candy grapes</a>, sweet mini peppers). Several legacy varieties will completely disappear or are produced at 1 or 2 orders of magnitude lower (e.g Red Delicious apples, Russet potatoes, etc.).</li><li>Alternate meat products (Impossible Burger, Beyond Meat, etc.) won’t exceed 10% of total meat consumption for any year in the 2020s.</li><li>United States <a rel="noreferrer noopener" href="https://www.ers.usda.gov/topics/farm-economy/land-use-land-value-tenure/farmland-value/" data-type="URL" data-id="https://www.ers.usda.gov/topics/farm-economy/land-use-land-value-tenure/farmland-value/" target="_blank">average farmland value</a> exceeds $5,000 per acre. This will be driven by the price paid for carbon sequestration efficiently competing with pasture and annual crop production acres for use. </li></ul>



<p>There are probably dozens more predictions I can make, but predictions are low risk and harmless. It will take serious teams of people to build out these solutions and actually <span>deliver</span> them at the proper scale for agriculture. </p>
		</div><!-- .entry-content -->

					<!-- .entry-meta -->
				</div><!-- .inside-article -->
</article><!-- #post-## -->
		</main><!-- #main -->
	</div><!-- #primary -->

	
	</div><!-- #content -->
</div></div>]]>
            </description>
            <link>https://thinkingagriculture.io/predictions-for-the-2020s-decade/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25671102</guid>
            <pubDate>Thu, 07 Jan 2021 14:02:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Font previews in command line with Python]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25670993">thread link</a>) | @jajjarax
<br/>
January 7, 2021 | https://fontpreview.readthedocs.io/en/latest/ | <a href="https://web.archive.org/web/*/https://fontpreview.readthedocs.io/en/latest/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
    <nav data-toggle="wy-nav-shift">
      <div>
        <div>
          

          
            <p><a href="#" alt="Documentation Home"> fontpreview
          

          
            
            <img src="https://fontpreview.readthedocs.io/en/latest/_static/fp.png" alt="Logo">
          
          </a></p><p>
                latest
              </p>
            
          

          


          
        </div>

        
        <div data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p><span>Contents:</span></p>
<ul>
<li><a href="https://fontpreview.readthedocs.io/en/latest/install.html">Installation</a></li>
<li><a href="https://fontpreview.readthedocs.io/en/latest/example.html">Example</a></li>
<li><a href="https://fontpreview.readthedocs.io/en/latest/cli.html">Command line</a></li>
<li><a href="https://fontpreview.readthedocs.io/en/latest/package.html">fontpreview package</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift">

      
      <nav aria-label="top navigation">
        
          <i data-toggle="wy-nav-top"></i>
          <a href="#">fontpreview</a>
        
      </nav>


      <div>
        
        <div>
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul>
    
      <li><a href="#"></a> »</li>
        
      <li>Welcome to fontpreview’s documentation!</li>
    
    
      <li>
        
            
            
              <a href="https://github.com/MatteoGuadrini/fontpreview/blob/master/docs/source/index.rst"> Edit on GitHub</a>
            
          
        
      </li>
    
  </ul>

  
  <hr>
</div>
          <div role="main" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div id="welcome-to-fontpreview-s-documentation">

<p><em>fontpreview</em> is a python library, which allows you to create simple and advanced previews of specific fonts.</p>
<p>In addition, the library includes some classes that allow the advanced creation of preview pages of the characters that make up a font.</p>
<div>
<p><span>Contents:</span></p>
<ul>
<li><a href="https://fontpreview.readthedocs.io/en/latest/install.html">Installation</a><ul>
<li><a href="https://fontpreview.readthedocs.io/en/latest/install.html#python">Python</a></li>
<li><a href="https://fontpreview.readthedocs.io/en/latest/install.html#id1">Installation</a></li>
</ul>
</li>
<li><a href="https://fontpreview.readthedocs.io/en/latest/example.html">Example</a><ul>
<li><a href="https://fontpreview.readthedocs.io/en/latest/example.html#fontpreview-example">FontPreview example</a></li>
<li><a href="https://fontpreview.readthedocs.io/en/latest/example.html#fontbanner-example">FontBanner example</a></li>
<li><a href="https://fontpreview.readthedocs.io/en/latest/example.html#fontlogo-example">FontLogo example</a></li>
<li><a href="https://fontpreview.readthedocs.io/en/latest/example.html#fontwall-example">FontWall example</a></li>
<li><a href="https://fontpreview.readthedocs.io/en/latest/example.html#fontpage-example">FontPage example</a></li>
<li><a href="https://fontpreview.readthedocs.io/en/latest/example.html#fontpagetemplate-example">FontPageTemplate example</a></li>
<li><a href="https://fontpreview.readthedocs.io/en/latest/example.html#fontbooklet-example">FontBooklet example</a></li>
<li><a href="https://fontpreview.readthedocs.io/en/latest/example.html#declarative-object-creation">Declarative object creation</a></li>
</ul>
</li>
<li><a href="https://fontpreview.readthedocs.io/en/latest/cli.html">Command line</a><ul>
<li><a href="https://fontpreview.readthedocs.io/en/latest/cli.html#simple-usage">Simple usage</a></li>
<li><a href="https://fontpreview.readthedocs.io/en/latest/cli.html#advanced-usage">Advanced usage</a></li>
</ul>
</li>
<li><a href="https://fontpreview.readthedocs.io/en/latest/package.html">fontpreview package</a><ul>
<li><a href="https://fontpreview.readthedocs.io/en/latest/fontpreview.html">fontpreview modules</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div id="indices-and-tables">

<ul>
<li><p><a href="https://fontpreview.readthedocs.io/en/latest/genindex.html"><span>Index</span></a></p></li>
<li><p><a href="https://fontpreview.readthedocs.io/en/latest/py-modindex.html"><span>Module Index</span></a></p></li>
<li><p><a href="https://fontpreview.readthedocs.io/en/latest/search.html"><span>Search Page</span></a></p></li>
</ul>
</div>


           </div>
           
          </div>
          

        </div>
      </div>

    </section>

  </div></div>]]>
            </description>
            <link>https://fontpreview.readthedocs.io/en/latest/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25670993</guid>
            <pubDate>Thu, 07 Jan 2021 13:53:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Friendship ended with Monads: Testing out Algebraic effects in OCaml]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25670916">thread link</a>) | @matt_d
<br/>
January 7, 2021 | https://gopiandcode.uk/logs/log-bye-bye-monads-algebraic-effects.html | <a href="https://web.archive.org/web/*/https://gopiandcode.uk/logs/log-bye-bye-monads-algebraic-effects.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<article role="article">

<small>
<time datetime="2021-01-01T07:56:45+00:00">January</time>
<time datetime="2021-01-01T07:56:45+00:00">01</time>
<time datetime="2021-01-01T07:56:45+00:00">2021</time>
</small>
<a href="file:///home/kirang/org/html/tags.html#ocaml"><small>#ocaml</small></a>
<a href="file:///home/kirang/org/html/tags.html#effects"><small>#effects</small></a>
<a href="file:///home/kirang/org/html/tags.html#animations"><small>#animations</small></a>
<a href="file:///home/kirang/org/html/tags.html#game"><small>#game</small></a>
<div id="text-orgeddd4fe">
<p>
Recently, I had the pleasure of talking with KC Sivaramakrishnan - one
of the lead developers of the OCaml multicore project - when he came
to NUS to give us a talk on his work on multicore and a potential new
language feature for OCaml: <b>Algebraic effects</b>.  At a high level, the
run-down on algebraic effects is that they can be considered as a sort
of alternative to monads,<sup><a id="fnr.1" href="#fn.1">1</a></sup> however with the key benefit that they
<i>play a lot nicer</i> with existing direct-style code and thus might be a
<i>more fluid</i> and <i>ergonomic</i> tool.  One of my most surprising takeaways
from meeting KC was in realising the significant amount of progress
that had already been made on implementing algebraic effects in
OCaml - in fact, algebraic effects, far from just being a far-off
pipe-dream (cough, modular implicits, cough), are actually at a point
where it is possible (<i>fairly easy even</i>) to play with them right now
(albeit using an experimental fork of the OCaml compiler).
</p>

<p>
Indeed, this is exactly what I have been working on over the past few
weeks - so moved was I by the world of possibilities opened up by this
development, I immediately set about experimenting on inserting
algebraic effects into various OCaml projects that I happened have
handy at the time.  Over the course of these experiments, I ended up
considering the application of algebraic effects to functional game
development, and in the process stumbled upon a rather elegant pattern
for representing animations in a functional style.  In fact, this
pattern actually ended up solving a longstanding issue I was having
with managing the control flow for animations alongside game logic,
and so I think it forms a rather nice setting for exploring the
benefits of algebraic effects, hence this post.
</p>

 


<p>
In the rest of this blog post, I'm going to provide a <i>gentle
introduction</i> to algebraic effects, provided in the context of their
use in implementing <b>functional game animations</b> - we'll look at using
algebraic effects to implement 3 different case studies of <i>relatively
complex</i> animations (see above) for games in a fluid and elegant way.
Hopefully, through exploring these case-studies, you should be able to
gain a better understanding of the pros and cons of algebraic effects
and why they are certainly something to be excited about.
</p>

<p>
The executable code for the entire blog post can be found at:<sup><a id="fnr.2" href="#fn.2">2</a></sup> <a href="https://gitlab.com/gopiandcode/ocaml-game-animations-with-algebraic-effects">https://gitlab.com/gopiandcode/ocaml-game-animations-with-algebraic-effects</a>
</p>
</div>

<div id="outline-container-orgbc783f7">
<h3 id="orgbc783f7">The vision: Functional Game Development</h3>
<div id="text-orgbc783f7">
<p>
While our final code uses a mix of functional and imperative code (as
is idiomatic OCaml style), our journey really begins in the world of
pure functional games.
</p>

<div> 
<p><img src="https://gopiandcode.uk/images/functional_update.png" alt="functional_update.png"></p><div><p> 
Fundamentally, functional games work by separating
the execution of a game into two distinct functions representing the main phases of the game loop:
</p>
<ul>
<li><b>an update function</b> that takes user input and time and updates the state of the world</li>
<li><b>a draw function</b> that displays the current state of the world to the
screen.</li>
</ul>
<p>
The idea here is that while the state of the game may change over time, the individual update and draw functions are pure and referentially transparent, and thus come with all the usual benefits of functional code (modularity and compositionality, reusable code, easier to reason about etc.).
</p></div> 
</div> 


<p>
To see these ideas in practice, suppose we wanted to implement a simple menu for a game:
</p><p><img src="https://gopiandcode.uk/images/a_game_menu.png" alt="a_game_menu.png">
</p> 


<p>
Following the functional approach, we could define the state of our menu as follows:
</p>
<div>
<pre><span>type</span> <span>menu</span> <span>=</span> <span>{</span> selected<span>:</span> int<span>;</span> options<span>:</span> string list<span>;</span> <span>}</span>
</pre>
</div>

<p>
Using this fairly simple state, we can easily
write a pure draw function for the menu as follows:
</p>
<div>
<pre><span>let</span> <span>draw_item</span><span> </span><span>~</span><span>pos </span><span>~</span><span>is_active txt</span> <span>=</span> <span>...</span> <span>(* </span><span>draw an individual menu item </span><span>*)</span>

<span>let</span> <span>draw</span> <span>{</span>selected<span>;</span>options<span>}</span> <span>=</span>
    <span>List.</span>iteri <span>(</span><span>fun</span> <span>ind option</span> <span>-&gt;</span>  
       draw_item <span>~pos</span><span>:</span>ind <span>~is_active</span><span>:(</span>ind <span>=</span> selected<span>)</span> option
    <span>)</span> options
</pre>
</div>

<p>
Similarly, if we wanted to make the menu respond to user inputs, we
can write a functional update operation for the menu as follows:
</p>
<div>
<pre><span>let</span> <span>update</span><span> menu key</span> <span>=</span> 
   <span>let</span> <span>len</span> <span>=</span> length menu.options <span>in</span>
   <span>let</span> <span>next</span><span> pos</span> <span>=</span> <span>(</span>pos <span>+</span> 1<span>)</span> <span>mod</span> len <span>in</span>
   <span>let</span> <span>prev</span><span> pos</span> <span>=</span> <span>(</span>pos <span>-</span> 1 <span>+</span> len<span>)</span> <span>mod</span> len <span>in</span>
   <span>match</span> key <span>with</span>
   <span>|</span> <span>Up</span> <span>-&gt;</span> <span>{</span>menu <span>with</span> selected <span>=</span> next menu.selected<span>}</span>
   <span>|</span> <span>Down</span> <span>-&gt;</span> <span>{</span>menu <span>with</span> selected <span>=</span> prev menu.selected<span>}</span>
</pre>
</div>

<p>
Hooking these all up together, the main loop for our program might then look as follows:
</p>
<div>
<pre><span>let</span> <span>main</span><span> </span><span>()</span> <span>:</span> <span>unit</span> <span>=</span> 
   <span>let</span> <span>rec</span> <span>loop</span><span> menu</span> <span>=</span> 
      draw menu<span>;</span>
      <span>let</span> <span>input</span> <span>=</span> get_input <span>()</span> <span>in</span>
      <span>let</span> <span>menu</span> <span>=</span> update menu input <span>in</span>
      loop menu <span>in</span>
   loop <span>{</span>selected<span>=</span>0<span>;</span> options<span>=[</span><span>"A"</span><span>;</span> <span>"B"</span><span>;</span> <span>"C"</span><span>]}</span>
</pre>
</div>

<p>
And tada! We now have a fully functional menu that <i>dynamically</i>
responds and updates to user inputs, and we were able to do it all
without having to ever dirty our hands with any <b>evil impure code</b>.
</p>

<p><img src="https://gopiandcode.uk/images/functional_menu.png" alt="functional_menu.png">
</p> 


<p>
Functional game development sounds great, right?
</p>
</div>
</div>

<div id="outline-container-orge7daf0a">
<h3 id="orge7daf0a">The challenge: Managing animations</h3>
<div id="text-orge7daf0a">
<p>
The stuff that I presented in the previous section is nothing new -
there are countless prior blog posts and videos on the web that all
describe this style of a game engine, and it paints a very pretty
picture.
</p>

<p>
Unfortunately, I am afraid to say, not all is as it seems in the land
of functional game development, and when you start using this
methodology to develop any kind of <i>non-trivial</i> games, you can quickly
find yourself running into edge-cases, and one <i>particularly nefarious</i>
example of such issues is handling animations.
</p>

<p>
Returning back to our running example of a game menu, suppose we now
wanted to come back and add a <i>simple</i> quality of life feature to our
menu - nothing complex, just a <b>fade-in</b> between states of the menu.
</p>

<p>
In other words, when the user presses a button, there should be small
<b>time-delay</b> as the menu <i>gradually transitions</i> from the original state
to the new one:
</p>

<p><img src="https://gopiandcode.uk/images/functional_animation.png" alt="functional_animation.png"> 
</p> 


<p>
<i>Okay, sure - that's not a complex transformation - so this should be
simple to implement within our framework, right?</i>
</p>

<div> 
<p><img src="https://gopiandcode.uk/images/functional_update_q.png" alt="functional_update_q.png"></p><div> 


<p>
<b>Unfortunately, no.</b>
</p>

<p>
Our methodology so far was based entirely around the assumption that
the update function is <i>pure</i> and <i>stateless</i> and should be called on each
frame of the game.
</p>

<p>
As such, if we were to return a new menu with the next item selected
when the user presses down, the <b>transformation would be immediate</b>
rather than the <i>gradual change</i> we want.
</p>

<p>
<i>So what exactly should we return from our update function then?</i>
</p></div> 
</div> 


<p>
If one were to strictly adhere to the functional game development
paradigm, then one hacky way to achieve this would be to explicitly
track the state of animations in the menu.
</p>

<p>
For example, we can update our definition of menu to be as follows:
</p>
<div>
<pre><span>type</span> <span>time</span> <span>=</span> int
<span>type</span> <span>state</span> <span>=</span> <span>Static</span> <span>of</span> int <span>|</span> <span>MovingBetween</span> <span>of</span> int <span>*</span> int <span>*</span> time
<span>type</span> <span>menu</span> <span>=</span> <span>{</span> selected<span>:</span> state<span>;</span> options<span>:</span> string list<span>;</span> <span>}</span>
</pre>
</div>

<p>
The idea here is that the <code>state</code> type tracks the two possible states of the menu and its animations:
</p>
<ul>
<li>either the animation is complete and the menu is static</li>
<li>or the menu is in the middle of an animation between two states
with some amount of <code>time</code> (in ms) remaining.</li>
</ul>

<p>
With this change, we can then write our update function as follows
(now updated to take an additional time parameter tracking the time
between frames):
</p>
<div>
<pre><span>let</span> <span>update</span><span> menu key delta</span> <span>=</span> 
  <span>let</span> <span>len</span> <span>=</span> length menu.options <span>in</span>
  <span>let</span> <span>next</span><span> pos</span> <span>=</span> <span>(</span>pos <span>+</span> 1<span>)</span> <span>mod</span> len <span>in</span>
  <span>let</span> <span>prev</span><span> pos</span> <span>=</span> <span>(</span>pos <span>-</span> 1 <span>+</span> len<span>)</span> <span>mod</span> len <span>in</span>
  <span>match</span> menu.state <span>with</span>
  <span>|</span> <span>MovingBetween</span> <span>(</span>old_ind<span>,</span>new_ind<span>,</span> remaining<span>)</span> <span>-&gt;</span>
    <span>let</span> <span>remaining</span> <span>=</span> remaining <span>-</span> delta <span>in</span>
    <span>if</span> remaining <span>&lt;</span> 0 <span>(* </span><span>is animation completed? </span><span>*)</span>
    <span>then</span> <span>{</span>menu <span>with</span> selected <span>=</span> <span>Static</span> new_ind<span>}</span> <span>(* </span><span>yes: return to static </span><span>*)</span>
    <span>else</span> <span>{</span>menu <span>with</span> selected <span>=</span> <span>MovingBetween</span> <span>(</span>old_ind<span>,</span> new_ind<span>,</span> remaining<span>)}</span>
  <span>|</span> <span>Static</span> ind <span>-&gt;</span>
    <span>match</span> key <span>with</span> <span>(* </span><span>only process inputs when animations completed </span><span>*)</span>
    <span>|</span> <span>Up</span> <span>-&gt;</span> <span>{</span>menu <span>with</span> selected <span>=</span> <span>MovingBetween</span> <span>(</span>ind<span>,</span> next menu.selected<span>,</span> 100<span>)}</span>
    <span>|</span> <span>Down</span> <span>-&gt;</span> <span>{</span>menu <span>with</span> selected <span>=</span> <span>MovingBetween</span> <span>(</span>ind<span>,</span> prev menu.selected<span>,</span> 100<span>)}</span>
</pre>
</div>
<p>
So this will work decently well, however, we're now starting to mix
our animation code with the logic of the program, making it harder to
understand and also more probable for bugs to creep in.  Additionally,
while this happens to work for our simple example, the pattern isn't
scalable - adding more animations would require rewriting the entire
function.
</p>

<p>
Clearly, taking this purely functional approach to games development
has some <b>serious difficulties</b> with managing animations, but it would
be unfair to say that this is uniquely due to the functional
approach:
</p>

<p><b><i>The challenge of balancing animations flow with logic is inherent to the domain</i></b>
</p>


<p>
For the rest of this blog post, we'll shift gears to investigate how
algebraic effects can be used to implement animations when dealing
with a slightly more imperative game structure, however this is mainly
to simplify the implementation: the core ideas presented below can be
easily ported to a pure implementation.
</p>
</div>
</div>

<div id="outline-container-org0873648">
<h3 id="org0873648">Algebraic effects to the rescue</h3>
<div id="text-org0873648">
<p>
Taking a step back from our previous example, the fundamental issue
was that we were trying to mix <b>two</b> separate threads of control - one
for the core logic, and a separate one for the animation - in other
words, what we need is some kind of <b>non-local control flow</b>.
</p>

<p>
….as it just so happens, this is exactly the functionality that
algebraic effects provide.
</p>
</div>

<div id="outline-container-org7da722a">
<h4 id="org7da722a">What are algebraic effects?</h4>
<div id="text-org7da722a">
<p>
We'll sidestep a more detailed discussion of the theory, and instead
focus on the general picture for the end user: algebraic effects as
effectively "resumable" exceptions.<sup><a id="fnr.3" href="#fn.3">3</a></sup>
</p>

<p>
When defining an effect, the user specifies the type of the input
supplied by the caller, and the type of the output that the effect
should return on completion:
</p>


<p>
To perform an effect, we can use the builtin primitive perform:
</p>

<p>
At this point, the execution of the current program is stopped (much
like an exception), and control changes up the stack until the nearest
effect handler:
</p>
<div>
<pre><span>try</span> 
   <span>...</span>
   perform <span>(</span><span>A</span> 1<span>)</span>
   <span>...</span>   
<span>with</span> 
  <span>|</span> effect <span>(</span><span>A</span> v<span>)</span> k <span>-&gt;</span>
    <span>(* </span><span>control changes to here </span><span>*)</span>
</pre>
</div>
<p>
At the site of the effect handler, the user …</p></div></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://gopiandcode.uk/logs/log-bye-bye-monads-algebraic-effects.html">https://gopiandcode.uk/logs/log-bye-bye-monads-algebraic-effects.html</a></em></p>]]>
            </description>
            <link>https://gopiandcode.uk/logs/log-bye-bye-monads-algebraic-effects.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25670916</guid>
            <pubDate>Thu, 07 Jan 2021 13:45:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learn to code in 2021, get hired, and have fun along the way]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25670779">thread link</a>) | @evantai
<br/>
January 7, 2021 | https://zerotomastery.io/blog/learn-to-code-in-2021-get-hired-and-have-fun-along-the-way | <a href="https://web.archive.org/web/*/https://zerotomastery.io/blog/learn-to-code-in-2021-get-hired-and-have-fun-along-the-way">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>For the past several years, I have been writing a guide (<a href="https://zerotomastery.io/blog/learn-to-code-in-2020-get-hired-and-have-fun-along-the-way" target="_blank" rel="follow">this is last year's edition</a>) that goes viral every year which gives you step by step instructions on how to become a Web Developer from scratch, <strong>for free</strong>. Thousands of students have followed these steps since then and <a href="https://zerotomastery.io/testimonials" target="_blank" rel="follow">have gotten hired</a>. However, a lot has changed since last year's edition, so I wanted to share with you the updated guide and changes for 2021 (with new resources)! The focus is on efficiency: Learn the right topics that are in demand right now so you can get hired as soon as possible.</p>
<p><strong>These are the steps that you should be taking if you want to learn to code in 2021, change your career, and become a Web Developer (or get into the tech industry).</strong></p>
<p>This is <strong>part 1</strong> of a 2 part series. You can read the second part <a href="https://zerotomastery.io/blog/dont-be-a-junior-developer" target="_blank" rel="follow">here</a>.</p>
<p>If you are a complete beginner, junior developer, or are curious about this industry, this post is for you. However, if you are an established developer, you may find some useful links in here as I list the best free resources to supercharge your skills, but I also wrote a post on <a href="https://zerotomastery.io/blog/developers-edge-how-to-become-a-senior-developer" target="_blank" rel="follow">how to become a senior software developer</a> that may be more useful to you.</p>
<p>If you find this post too long, you can skip over and start from the <strong>5 Months, Step By Step Section</strong>. But you’ll hurt my feelings… so you know, you can live with that guilt.</p>
<blockquote>
<h4>Ok you’re still here. Great! I like you already. Let’s keep going…</h4>
</blockquote>
<p>Using only free online courses, tutorials and free tools, you can gain a valuable skill that will allow you to be employed in a great industry that is rewarding, challenging, and with a lot of options to move around the world (more on this later). Best part? You don’t need a college degree or an expensive bootcamp. Nor do you need to give away part of your income once you get hired which some new schools are doing (which sounds great until you have to start giving away some of your paychecks).</p>
<p><strong>Important note:</strong> The post may seem like a step by step guide of what to do to become a developer, but if you look closely, it is a strategy that you can apply to any sort of learning.</p>
<p>Also... no pressure, but I don't want you getting mad at me for not telling you that if you want a downloadable version, you can sign up below and I'll email you a full PDF version of this guide that includes the month by month checklist!</p>

<h2>Why coding?</h2>
<p><img src="https://media.giphy.com/media/NWlBEcDW5evFS/source.gif"></p>
<center><i>one day you can build the best soccer goalie in the world…</i></center>
<p>Before we get into the steps you can take to become a developer, we must first dive into why you would want to go down this path. Every decision that will require significant time of your life should be justified. Time, after all, is the most important resource we have:</p>
<p><strong>A.</strong> You want to be working in an industry where there is a high demand for the skill and many possibilities to be in important roles at the top of the food chain.</p>
<p><strong>B.</strong> You love being location independent. You want a skill that allows you to go anywhere in the world and still be able to find a job easily. If you decide to move to Iceland tomorrow, you want to make sure that you won’t have issues finding a job.</p>
<p><strong>C.</strong> You’ve noticed the difference between 2010 and 2021 and how much of a technological progress we have made in those short 10 years. You want to be at the forefront of an industry that is impacting the world.</p>
<p><strong>D.</strong> The biggest industry growth in the last couple of years has been in the <a href="https://deepmind.com/blog/alphago-zero-learning-scratch/" target="_blank" rel="follow">artificial intelligence (Machine Learning)</a>, bio tech, autonomous cars, <a href="https://coinmarketcap.com/currencies/bitcoin/#charts" target="_blank" rel="follow">blockchain (Bitcoin)</a> space. We interact with technology on the daily, and you want to not be left behind in the dust as these take over our future. You want to understand and be able to pick up the skills underlying all of these: programming. Web Development is a great foot in the door to these industries.</p>
<p><strong>E.</strong> You think change is good, and learning should never stop. So why not do something new?</p>
<blockquote>
<h4>But I don’t have a computer science degree and I don’t even know how the internet works! Don’t worry, we will use that to your advantage. Keep reading…</h4>
</blockquote>
<p>When choosing a new career path here are some good must/nice to-haves:</p>
<p><strong>1.</strong> It must be relevant for the next 10+ years. This skill should be valued many years in the future guaranteeing you job security.</p>
<p><strong>2.</strong> Demand for people with this skill must be higher than the supply. The less available pool of skilled workers in the industry, the more control you can have over your job and companies you work for.</p>
<p><strong>3.</strong> Ability to have a high salary regardless of years in the industry. You don’t want to spend many years climbing the corporate ladder until you make a decent living.</p>
<p><strong>4.</strong> An industry that doesn’t require a specialized degree from a university. You don’t want to spend the next 4 years getting into debt and going to a graduate program before you start making money. And yes, I think there are better alternatives than going to an expensive coding bootcamp.</p>
<p><strong>5.</strong> Ability to catch up to the top performers in the industry in the shortest amount of time. Can little experience still get you employed? And can you close the gap as fast as possible to be considered a senior or an expert in the field?</p>
<p><strong>6.</strong> It must allow you to build foundational skills that will give you multiple career options no matter what the future holds. For example, by learning to code, you’re able to better understand new up-coming technologies like distributed applications, data science, machine learning (AI), and cloud computing, and choose which field you want to jump into next.</p>
<p><strong>7.</strong> Have fun. The most important one. Can you see yourself doing this 40 hours a week for a long time?</p>
<p>Coding hits every one of the points above in my experience. Your mileage may vary.</p>
<p>One of my favourite books is titled <a href="http://calnewport.com/books/so-good/" target="_blank" rel="follow">So Good They Can’t Ignore You</a>. In there, the author argues that passion is a myth. You shouldn’t go into the travel industry because you are “passionate” about travel. Most people find passion by struggling and working hard to master a skill. Once people start acknowledging your valuable skills, and you are able to feel respected for these skills, that’s when you develop passion for what you do.</p>
<blockquote>
<h4>Still with me? I haven’t scared you off? Ok, we shall keep going then….</h4>
</blockquote>
<p><strong>IMPORTANT POINT READ IT</strong>: keep in mind that the first 2 months will feel like you are climbing an insurmountable mountain. Every tutorial, course or lesson you do will make you feel like you are the only person in the world that doesn’t know this stuff. Stay strong. You will get there and you will have more and more ‘AHA!’ moments as time progresses. We call this the Impostor Syndrome: you feel like you are the only one who doesn’t know this information and you are surrounded by self-doubt. Rest assured we all feel this way when we learn something new. This is good. This is how we know we are stetching our boundaries.</p>
<p>What you will learn at the end of it all is that being a good developer isn’t necessarily memorizing a whole bunch of documentation. It’s about learning how to solve problems using all of the tools that are available to you. It’s about being a problem solver and getting from a state of not knowing to knowing. This guide will help you get those skills.</p>
<h2>Who are you and why should I listen to you?</h2>
<p><img src="https://media.giphy.com/media/H7JD0pfyksePe/giphy.gif"></p>
<center><i>always wave back…</i></center>
<p>Wow, you’re direct, but I guess that’s a fair question. First off, I’m a senior software developer that has worked in various locations including Silicon Valley and Toronto at some of the top tech firms. I’ve been very fortunate in my career and for the past 3 years I have taught <a href="https://academy.zerotomastery.io/p/complete-web-developer-zero-to-mastery" target="_blank" rel="follow">400,000+ people around the world how to become developers from scratch</a>. Many of those Zero To Mastery graduates now work at companies like <a href="https://zerotomastery.io/testimonials" target="_blank" rel="follow">Google and Amazon</a>. But I wasn’t born a computer wiz. I didn’t graduate with a computer science degree. I am completely self-taught.</p>
<p><em>P.S. This part is all about me, so if you don’t care (totally fair point), just skip this section. I’ll get over it eventually.</em></p>
<p>It all started many years ago…I wanted a career change and decided to teach myself computer programming.</p>
<p>I spent the first month avoiding any tutorials or books. Instead, I spent this month looking at the best way for me to learn and get hired. I wanted to be efficient, not waste my time and learn outdated technologies, or learn things that I would forget after a month. I studied other people’s experiences, looked at job postings, spoke to established developers, reviewed online courses, looked at bootcamps, and even read articles by futurists on where we will be with technology in 20 years. Based on those, I created a curriculum for myself focused on efficiency: <strong>The critical amount of learning in order to be employable in the shortest amount of time.</strong></p>
<p>If you love the works of <strong>Tim Ferriss</strong> as much as I do, you’re going to love this. The curriculum isn’t focused on doing the least amount of work. Instead, it is focused on working really hard at the things that matter most in order to be employed in the optimum way. This doesn’t mean doing the bare minimum and being hired as a junior developer. If you can work hard and skip the line by jumping straight into an intermediate developer role, that is a better outcome. Luckily for you, I have already sifted through everything for you.</p>
<p>Although I spent one month planning my studying instead of actually studying, it was a benefit in the long run because I wasn’t running blind. I knew where I was going, and I had a map to the finish line. You will too.</p>
<p>So yes, I have been where you are and I know what it takes. When I was getting started, I wish there was something like this that outlined things for me step by step. I also found many tutorials were taught by people with a lot of technical knowledge but without being able to properly teach a beginner. Alternatively, some courses were taught by people who took advantage of beginners not knowing much about the industry and selling them a course that sounds great but doesn't actually teach you how to succeed (we call these superficial skills). I’ve read and studied every single video, tutorial and course that time …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://zerotomastery.io/blog/learn-to-code-in-2021-get-hired-and-have-fun-along-the-way">https://zerotomastery.io/blog/learn-to-code-in-2021-get-hired-and-have-fun-along-the-way</a></em></p>]]>
            </description>
            <link>https://zerotomastery.io/blog/learn-to-code-in-2021-get-hired-and-have-fun-along-the-way</link>
            <guid isPermaLink="false">hacker-news-small-sites-25670779</guid>
            <pubDate>Thu, 07 Jan 2021 13:32:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Aaarrrp Developer Relations Strategy Framework]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25670758">thread link</a>) | @mooreds
<br/>
January 7, 2021 | https://www.leggetter.co.uk/aaarrrp/ | <a href="https://web.archive.org/web/*/https://www.leggetter.co.uk/aaarrrp/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
      <div>
        <div>
          <div id="content">
            

<p><strong>AAARRRP</strong> is a framework that helps you define your Developer Relations strategy. In its simplest form it provides a mechanism for <strong>mapping the company goals for developer relations at a company through to the activities that will help you achieve those goals</strong>. Since activities for some goals naturally feed into helping you achieve other goals you can adopt AAARRRP as a funnel or a loop.</p>

<h3>What does the acronym AAARRRP stand for?</h3>

<p>AAARRRP was adapted and inspired by <a href="https://www.slideshare.net/dmc500hats/startup-metrics-for-pirates-long-version">AARRR pirate metrics</a> in 2016 by <a href="https://twitter.com/leggetter">Phil Leggetter</a>. But, where as AARRR was focused on "Startup metrics for Product Marketing and Product Management" and stood for:</p>

<ul>
<li><strong>Acquisition</strong> - users come to the site from various channels</li>
<li><strong>Activation</strong> - users enjoy 1st visit: "happy user experience"</li>
<li><strong>Retention</strong> - users come back, visit multiple times</li>
<li><strong>Referral</strong> - users like product enough to refer others</li>
<li><strong>Revenue</strong> - users conduct some monetizing behavior</li>
</ul>

<p>AAARRRP is a framework for defining a Developer Relations strategy where each acronym identifies a potential business goal for a Developer Relations team. Additionally, the definitions change slightly and two further business goals, Awareness and Product, are added:</p>

<ul>
<li><strong>Awareness</strong> - users become aware of your product</li>
<li><strong>Acquisition</strong> - users signup for your product</li>
<li><strong>Activation</strong> - users successfully use your product</li>
<li><strong>Referral</strong> - users like product and company brand enough to refer others</li>
<li><strong>Revenue</strong> - users conduct some monetizing behavior</li>
<li><strong>Product</strong> - users and the developer relations team help define and build the product as well as gathering feedback from users to enhance your product</li>
</ul>

<h3>AAARRRP Goals</h3>

<p>Each acronym in AAARRRP represents a potential goal that your company can have for your Developer Relations team.</p>

<p>Here are a few different scenarios where a company will have different AAARRP goals:</p>

<ul>
<li>An <strong>API platform startup</strong> with an overarching goal of demonstrating clear interest in a product to their investors may have goals of Awareness, Acquisition and Referral to drive further awareness and acquisition.</li>
<li>A <strong>SaaS company with an API product offering</strong> may want to see increased Activation, Product enhancements that will enable that activation and Revenue from the increase in activations.
An open source framework may be looking to build a community through Referral to then help improve the Product offering through feedback and contribution.</li>
</ul>

<p>The company goals for a Developer Relations team may also change depending on a number of other factors.</p>

<ul>
<li>Has a product-market fit been determined?</li>
<li>Where is the product within the product development lifecycle?</li>
<li>What investment has been allocated to the Developer Relations program?</li>
<li>Who owns the Developer Relations budget within the organisation?</li>
<li>Are other teams delivering on some of the activities meaning Developer Relations should focus elsewhere?</li>
</ul>

<p><strong>The lifecycle of your product significantly influences Developer Relations goals</strong>. Early on in a product's existence it's important to determine product market fit; is there a clear demand for the product? Or to ensure the product meets some fundamental requirements such as following basic API guidelines, having documentation and sample code to help prospective customers get started, or demos to show what the product makes possible and as a sales-enablement tool. In later stages of product development the focus may be more on growth and the Developer Relations goals and associated activites will follow suit.</p>

<h3>Mapping AAARRRP Goals to Activities</h3>

<p>In it's simplest form AAARRRP can be seen as a mechanism of mapping company goals to Developer Relations activites. Activities are the pieces of work that a Developer Relations team will undertake and those activities will differ depending on the company goals.</p>

<p>If the Developer Relations goals focus on Product then activities are likely to be around documentation, sample code, libraries and SDKs. If Awareness and Acquisition are the goals then blog content, events, webinars, live streams (e.g. Twitch) and talk are the types of activities that will align with those goals.</p>

<p>The image below (from <a href="https://docs.google.com/spreadsheets/d/1HeKG9-h2yT4ahpaSsq6_6z6uDt7RWVtlRcj7jBMxEQI/edit#gid=0">a Nexmo AAARRRP Google Sheet</a>) shows the work we did a Nexmo in 2016 to 2017 where are goals were <strong>Product</strong>, <strong>Awareness</strong> and <strong>Activation</strong> with Product and Awareness being the priority goals.</p>

<p><img src="https://www.leggetter.co.uk/images/aaarrrp/aaarrrp-goal-to-activity-mapping.png" alt="Mapping AAARRRP Goals to Activities"></p>

<p>We added some additional columns to the spreadsheet:</p>

<ul>
<li><strong>Product Weighting</strong>: to provide a deeper indication of how well the activity aligned with the Product goal</li>
<li><strong>Awareness Weighting</strong>: to provide a deeper indication of how well the activity aligned with the Awareness goal</li>
<li><strong>Goal Alignment</strong>: counting how many of the goals (Awareness, Activation &amp; Product) the activity aligned with</li>
<li><strong>Score</strong>: A forumla to help us identify which activities we should choose (<code>(Product Weighting + Awareness Weighting) * Goal Alignment</code>).</li>
</ul>

<p>This helped us identify that we should focus on the following to achieve the company goals:</p>

<ul>
<li>Docs -&gt; Tutorials</li>
<li>Sample Apps</li>
<li>Blog -&gt; Tutorials</li>
<li>Events -&gt; Hackathons</li>
</ul>

<h3>An Introduction to AAARRRP (Video)</h3>

<p>The following description and video is from a talk given at DevRelCon London 2016.</p>

<blockquote>
<p>Building a DevRel programme is hard. What are the goals of the programme, how do they align with the company goals, what activities should the new Developer Relations team undertake, how do those activities help other departments within the company and how should the success of the team be measured?</p>

<p>In this talk from DevRelCon London 2016, Phil Leggetter describes his AAARRRP framework for developer relations strategy.</p>
</blockquote>

<p>
    <iframe width="560" height="315" src="https://www.youtube.com/embed/i7EZDYYfFmc" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>

<h3>AAARRRP Resources</h3>

<ul>
<li><a href="https://devrel.net/strategy-and-metrics/introducing-aaarrrp-devrel-strategy">Introducing the AAARRRP devrel strategy framework on devrel.net</a></li>
<li><a href="https://docs.google.com/spreadsheets/d/1nUGvs7cmN9shWcA57cIESVqHuXliNa7NywXGviCuwNE/edit#gid=0">AAARRRP Google Sheets template</a></li>
<li><a href="https://docs.google.com/spreadsheets/d/1HeKG9-h2yT4ahpaSsq6_6z6uDt7RWVtlRcj7jBMxEQI/edit?usp=sharing">AAARRRP applied at Nexmo: 2016 - 2017</a></li>
<li><a href="https://www.leggetter.co.uk/2016/02/03/defining-developer-relations.html">Original "Defining Developer Relations" blog post</a></li>
</ul>

          </div>
        </div>
      </div>
    </div></div>]]>
            </description>
            <link>https://www.leggetter.co.uk/aaarrrp/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25670758</guid>
            <pubDate>Thu, 07 Jan 2021 13:29:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Neurology of Flow States]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25670675">thread link</a>) | @kawera
<br/>
January 7, 2021 | http://m.nautil.us/issue/91/the-amazing-brain/the-neurology-of-flow-states | <a href="https://web.archive.org/web/*/http://m.nautil.us/issue/91/the-amazing-brain/the-neurology-of-flow-states">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
			<p><span>D</span>on’t look at the clock! Now tell me: How much time has passed since you first logged on to your computer today? Time may be a property of physics, but it is also a property of the mind, which ultimately makes it a product of the brain. Time measures out and shapes our lives, and how we live our lives in turn affects how we perceive the passage of time. Your sense of time is malleable and subjective—it changes in response to changing contexts and input, and it can be distorted when the brain is damaged, or affected by drugs, disease, sleep deprivation, or naturally altered states of consciousness.&nbsp;However, a new set of neuroscience research findings suggests that losing track of time is also intimately bound up with creativity, beauty, and rapture.</p> <p>Time is most commonly manipulated by the kinds of things we do to fill it. When our minds are under-stimulated, time often feels like it is moving in slow motion, as in the scene in <i>The Simpsons</i> where Bart is made to lick envelopes for Principal Skinner all afternoon and groans when the clock starts ticking backward. On the other hand, when we are fully engaged, especially in the kind of “flow state” familiar to artists, athletes, and other top performers, our sense of time appears to speed up, or even to disappear entirely.</p> <p>Many people describe being “enchanted” or “transfixed” when watching a live performance or viewing their favorite work of art. For example, when exploring the European paintings section of the Metropolitan Museum of Art, I enter into a kind of dissociated, transcendent state, which many people report experiencing. All of our cares and worries disappear and time seems to stand still or fade away as we become lost in the world of the story, or work of art, or the virtuosity of the performer. This loss of time-awareness mirrors the process occurring in the brains of the performers or artists while they create.</p><blockquote><p>The inner critic must be shut down, and the inner Picasso turned up.</p> </blockquote><p>During what psychologists call “flow states,” where one is completely immersed and absorbed in a mental or physical act, people often report an altered sense of time, place, and self. It’s a transportive and pleasurable experience that people seek to achieve, and that neuroscience is now seeking to understand. A great example of flow state is found in many improvised art forms, from music to acting to comedy to poetry, also known as “spontaneous creativity.” Improvisation is a highly complex form of creative behavior that justly inspires our awe and admiration. The ability to improvise requires cognitive flexibility, divergent thinking and discipline-specific skills, and it improves with training.<br></p> <p>Not surprisingly, the frontal regions of the brain that have been shown to be involved in time perception and impulse control are also involved in spontaneous creativity. Improvisation appears to take place in an altered state of mind/brain, and studies of the neural mechanisms of musical improvisation have identified a network of prefrontal brain regions linked to improvisation. The creative act of improvisation, at least in the musical realm, appears to be a result of changing patterns of activity in two key areas of the prefrontal cortex (PFC).</p><div>
<article>
<p><a href="http://m.nautil.us/issue/45/Power/time-is-contagious" data-trval="time-is-contagious" data-trlbl="foc_rec" data-tract="internal_art">
<img src="http://static.nautil.us/11529_fcbc95ccdd551da181207c0c1400c655.jpg" alt="Sapolsky_TH-F1" width="314" height="177">
</a>
</p>
<div>
<p><span>
<span>

<span><a href="http://m.nautil.us/term/f/Neuroscience">Also in Neuroscience</a></span>&nbsp;&nbsp;</span>
</span></p><h4><a href="http://m.nautil.us/issue/45/Power/time-is-contagious" data-trval="time-is-contagious" data-trlbl="foc_rec" data-tract="internal_art">Time Is Contagious</a></h4>
<p>By Alan Burdick</p>
<p>
On a recent Saturday morning, my wife, Susan, and I slipped into the city to visit the Metropolitan Museum of Art, a place we hadn’t gone together since before our sons were born. The crowds hadn’t yet descended and for...<strong><a href="http://m.nautil.us/issue/45/Power/time-is-contagious" data-trval="time-is-contagious" data-trlbl="foc_rec" data-tract="internal_art">READ MORE</a></strong>
</p>

</div>

</article>
</div> <p>During musical improvisation, in jazz or freestyle rap, studies show a distinctive increase in medial prefrontal cortex activation. The medial prefrontal cortex (mPFC) is a brain area known to be involved in intentional, internally generated self-expression and the pursuit of goal-oriented behaviors. This makes sense, since improvised performance requires you to come up with new material in a rapid stream, and deploy it just as quickly for a listening or watching audience. The other aspect to this pattern is a decrease in lateral orbitofrontal cortex and dorsolateral prefrontal cortex activation (DLPFC). The lateral orbitofrontal cortex (OFC) and dorsolateral prefrontal cortex are brain areas involved in conscious self-monitoring, effortful problem solving, focused attention, and evaluation and regulation of goal-directed or planned behaviors. These lateral areas assess whether behaviors conform to social norms, and exert inhibitory control over inappropriate or maladaptive behavior. But as any skilled performer will tell you, inhibitions are the enemy of improvisation.</p> <p>When mPFC activation is turned up, it encourages the internal generation of ideas. And when lateral PFC brain areas are simultaneously turned down, it allows novel thoughts and behaviors to emerge uninhibited, leading to divergent thinking and unfiltered creativity. In other words, the inner critic must be shut down, and the inner Picasso turned up. Deactivation of lateral PFC regions is associated with free-floating, defocused attention, allowing spontaneous associations between ideas to arise, and sudden realizations or insights to occur. Creativity appears to occur when the DLPFC decreases its regulation of the contents of consciousness, allowing for unconscious, unfiltered, or random sensations and thoughts to arise in the flow state. Just as children will play more wildly when the teacher isn’t watching, when we reduce the influence of the DLPFC on our behavior, it allows us to think more like artists.</p><blockquote><p>Improvisation appears to take place in an altered state of mind.</p> </blockquote><p>Future research could explore whether this pattern of brain activity is in fact a neural signature of improvisation that occurs across all art forms, for instance during painting, theater, comedy, and dance improvisation, or whether the signature is unique to the musical and verbal forms it has been found in so far. When the lateral PFC regions—where our sense of agency is created after ongoing actions take place—decrease in activation, a performer’s moment-to-moment decisions and actions may feel as if they are occurring outside of time and without conscious intention, as if they are “coming from somewhere else.” This is consistent with the sentiment many artists express that their creative process is being directed by a “muse” or outside agent.<br></p> <p>However, improvising performers are not oblivious; momentary “check-ins” to see how your performance is going can provide necessary environmental (or audience) feedback, helping to revise your approach and optimize performance in real-time. Creative thought also involves the “default mode network” (DMN), a set of brain regions active when attention is directed internally and suppressed when a person engages in externally directed tasks. The DMN is active when you’re daydreaming, but not when you’re filling out an application form, which requires executive control areas like the DLFPC. Improvisation requires a balance in activation between these two networks, reflecting the extent to which creative thought and behavior needs to be responsive to environmental input, and constrained by certain rules to meet the specific goals of the task at hand. But if you become overly self-aware or self-conscious for too long, you can lose the flow state and the performance will suffer. Of course, you don’t need a cognitive neuroscientist to tell you that. Just listen to Eminem:</p> <p>You better lose yourself in the music, the moment<br>You own it, you better never let it go<br>You only get one shot, do not miss your chance to blow<br>This opportunity comes once in a lifetime&nbsp;&nbsp;</p> <p>Luckily, you do not need to be able to improvise (or take drugs) to achieve flow states. Deactivation of the lateral PFC also occurs during other altered states of consciousness such as meditation, hypnosis, and daydreaming. And a similar pattern of dissociated activation in PFC has been identified during REM sleep, where dreaming usually occurs. Dreaming involves unplanned, irrational associations, defocused attention, an altered sense of time, and a feeling of lack of agency or volitional control (with the exception of lucid dreaming). These same characteristics are associated with creativity when one is fully awake.</p> <p>The sense of time passing, producing its changes and progressions, is a capacity our brains evolved for adaptive reasons. How long have I been sleeping? How soon do the kids need to eat? How fast will I have to walk to make it home before dark? Keeping track of time is something we do instinctively, and our instincts have recently been supplemented by cultural inventions such as clocks and calendars, which train our brains to map its instincts onto scales and increments. However, we have also evolved the ability to turn off this constant time-keeping, in moments of artistic rapture or contemplation, and that adaptive sense of timelessness gives our lives much of its beauty and meaning. How we choose to spend our time, which remains our most limited and valuable resource, is one of the greatest gifts, and responsibilities, we are given.</p><p><i>Heather Berlin, Ph.D., MPH is a cognitive neuroscientist and assistant professor of psychiatry at the Icahn School of Medicine at Mount Sinai. She practices clinical neuropsychology at Weill Cornell Medicine in the Department of Neurological Surgery, and is a Visiting Scholar at the New York Psychoanalytic Society and Institute. She hosts Startalk All-Stars with Neil DeGrasse Tyson, and has hosted series on PBS and the Discovery Channel.</i></p><p><i>Lead image: Ricardo Ferrando / Shutterstock</i></p><p><i>This article first appeared online in our “Coordinates” issue in June, 2018.</i></p>
			



						
			

		</div></div>]]>
            </description>
            <link>http://m.nautil.us/issue/91/the-amazing-brain/the-neurology-of-flow-states</link>
            <guid isPermaLink="false">hacker-news-small-sites-25670675</guid>
            <pubDate>Thu, 07 Jan 2021 13:21:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Elementary OS launches early access Raspberry Pi builds]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25670591">thread link</a>) | @j-james
<br/>
January 7, 2021 | https://blog.elementary.io/elementary-os-on-raspberry-pi/ | <a href="https://web.archive.org/web/*/https://blog.elementary.io/elementary-os-on-raspberry-pi/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  
  <header>
    
    
      <h2>



   Continuing our experimental Early Access&nbsp;builds

</h2>
    

    



<div>
  <p><img srcset="https://www.gravatar.com/avatar/41275ecc8271aca852ce2c0ff72d2610?s=96&amp;d=blank 2x" src="https://www.gravatar.com/avatar/41275ecc8271aca852ce2c0ff72d2610?s=48&amp;d=blank" alt="Avatar for Cassidy James Blaede">
  </p>
  
  <p><time datetime="2020-12-04">Fri, Dec  4, 2020</time>
  
    <span title="Estimated read time">
  
  5 min read
</span>


  
</p></div>


    


  </header>

  <section>
    <p>Following our <a href="https://blog.elementary.io/elementary-os-on-pinebook-pro">efforts to bring elementary OS to the ARM-based Pinebook Pro</a>, we’ve added experimental builds for the ARM-based Raspberry Pi 4 series—including the recently-launched Raspberry Pi 400—to our <a rel="nofollow noopener noreferrer" target="_blank" href="https://builds.elementary.io/">Early Access</a> program. Like Pinebook Pro builds, Raspberry Pi support is considered an experiment and is not something we have committed to officially support indefinitely. However, if you’re one of the many folks with a Raspberry Pi 4 sitting around and wanted to see how a full, modern desktop operating system runs, elementary OS is now an option!</p>

<figure>
  <p><img src="https://blog.elementary.io/images/elementary-os-on-raspberry-pi/desktop.jpg" alt="Raspberry Pi 4 running elementary OS"></p>
  <figcaption>My current desktop, powered by a Raspberry Pi 4 running elementary OS</figcaption>
</figure>

<p>Personally, I typically use Raspberry Pi 4 as a network device, e.g. a DNS server and for network-attached storage. However, I’ve been using elementary OS builds on it for the past week, and I’m impressed. While it won’t compete experience-wise with a high end desktop, it is a real option for casual computing, development, and writing. In fact, this blog post was written entirely on my Raspberry Pi 4 running elementary OS. It would even be possible to run the same network services on the hardware from within elementary OS just so you get a nice modern GUI when doing any local management.</p>

<p>Like with <a href="https://blog.elementary.io/elementary-os-on-pinebook-pro">Pinebook Pro</a>, there are some things you should know if you plan to use elementary OS Early Access builds on Raspberry Pi:</p>

<h2 id="kernel">Kernel</h2>

<p>Since Ubuntu has released Raspberry Pi images, we are able to rely on that work to ship a supported and updated kernel. Thanks to all of the folks at Canonical and in the Ubuntu community who have worked to make that happen!</p>

<h2 id="performance">Performance</h2>

<p>elementary OS on Raspberry Pi 4 is not going to match the polished experience of a full modern desktop computer, largely due to our current software stack. GTK3 does not offer GPU-accelerated animations, so animations within apps are less smooth than we would like. Still, for a computer coming in at under $100, it’s impressive and perfectly usable for several tasks.</p>

<p>There are also some things you can do to improve performance. We would definitely recommend using some sort of cooling with your Raspberry Pi, whether that’s a a heatsink and fan (like the recently-announced <a rel="nofollow noopener noreferrer" target="_blank" href="https://www.raspberrypi.org/blog/new-raspberry-pi-4-case-fan/">Raspberry Pi 4 Case Fan</a>), or a passive case like one from <a rel="nofollow noopener noreferrer" target="_blank" href="https://flirc.tv/">Flirc</a>—my favorite for its looks and silence. Since Raspberry Pi 4 tends to throttle due to heat under desktop loads, cooling will help it stay more responsive. We also recommend trying USB3 storage as your boot drive, as it should be faster than a microSD card. Using a 1080p (or lower) resolution also works a fair bit better than trying to push a 1440p or 4K display, but your mileage may vary based on your use case.</p>

<h2 id="supported-raspberry-pi-models">Supported Raspberry Pi Models</h2>

<p>We recommend Raspberry Pi 4 or Raspberry Pi 400 with 4 GB RAM at a minimum—but the more, the better. (We don’t even recommend less than 8 GB for computers with much faster CPUs, graphics, and storage.)</p>

<p>Older models of Raspberry Pi (like the original, Raspberry Pi Zero, Raspberry Pi 2 series, and Raspberry Pi 3 series) are not supported; elementary OS requires the faster processor, additional RAM, and 64-bit architecture of the Raspberry Pi 4 series. For older models, we recommend sticking to Raspberry Pi OS or a “headless” OS like Ubuntu Server.</p>

<h2 id="run-elementary-os-on-raspberry-pi">Run elementary OS on Raspberry Pi</h2>

<p>In its current state, we would not consider elementary OS on Raspberry Pi as polished of an experience as running on well-supported AMD- or Intel-based hardware.</p>

<p>That said, the audience for Raspberry Pi leans toward tinkerers and experimenters; as such, we’ve decided to publish our builds under our <a rel="nofollow noopener noreferrer" target="_blank" href="https://builds.elementary.io/">Early Access builds</a> program. This means dedicated <a rel="nofollow noopener noreferrer" target="_blank" href="https://github.com/sponsors/elementary">sponsors</a> of elementary OS who wish to run elementary OS on Raspberry Pi can download it from the same place as Early Access builds of elementary OS. As a note, all of this work has been focused on bringing the <strong>pre-release of elementary OS 6</strong> to Raspberry Pi, so all the usual disclaimers about pre-release builds apply here as well.</p>



<p>Once you have access to Early Access builds, head over to the <a rel="nofollow noopener noreferrer" target="_blank" href="https://github.com/elementary/os/wiki/Raspberry-Pi">elementary OS wiki</a> to get it installed on your own hardware. If you find and file any issues, please remember to specify the build of the OS you downloaded as well as that you are running on Raspberry Pi—it will help us validate and triage issues much more quickly.</p>

<h2 id="thanks-to-andrew-david-hewitt-and-marius-meisenzahl">Thanks to Andrew, David Hewitt, and Marius Meisenzahl</h2>

<p>Bringing elementary OS to Raspberry Pi was a collaborative effort. <a rel="nofollow noopener noreferrer" target="_blank" href="https://github.com/andrewc910">Andrew</a>, <a rel="nofollow noopener noreferrer" target="_blank" href="https://github.com/davidmhewitt">David Hewitt</a>, and <a rel="nofollow noopener noreferrer" target="_blank" href="https://github.com/meisenzahl">Marius Meisenzahl</a> specifically worked to prototype, improve, and ultimately ship these builds. And of course countless folks across the Raspberry Pi Foundation, Debian, Canonical, Ubuntu, and more have worked for years on making the underlying system work well for us to build on.</p>


  </section>

  <div>
  <hr>

  
    <h2>Thank You</h2>
    <p>Thanks to all of our supporters, backers, and customers! Your contributions make elementary possible. If you’d like to help build and improve elementary OS, don’t hesitate to <a rel="nofollow noopener noreferrer" target="_blank" href="https://elementary.io/get-involved" onclick="plausible('Link: Get Involved')">Get Involved</a>.</p>
  

  
</div>



</article></div>]]>
            </description>
            <link>https://blog.elementary.io/elementary-os-on-raspberry-pi/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25670591</guid>
            <pubDate>Thu, 07 Jan 2021 13:12:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[MakAir: Covid-19 ventilator with a Raspberry Pi]]>
            </title>
            <description>
<![CDATA[
Score 92 | Comments 61 (<a href="https://news.ycombinator.com/item?id=25670303">thread link</a>) | @mtmail
<br/>
January 7, 2021 | https://blog.senx.io/makair-covid-19-ventilator-with-a-raspberry-pi/ | <a href="https://web.archive.org/web/*/https://blog.senx.io/makair-covid-19-ventilator-with-a-raspberry-pi/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>During the COVID-19 crisis, The birth of the first open source data enabled ventilator. </p><article>
      
<p>Back to March 20, 2020. <a href="https://twitter.com/waxzce" target="_blank" rel="noreferrer noopener">Quentin Adam</a>, with some friends living in Nantes, is trying to build a ventilator prototype with 3D printing and Arduino, in response to a shortage of equipment. </p>



<p><strong>Project MakAir is started</strong>. </p>



<p>Quentin, a software expert and CEO of <a href="https://www.clever-cloud.com/" target="_blank" rel="noreferrer noopener">Clever Cloud</a>, is struggling with the electronics part and looking for electronics engineers. Among his friends is Mathias, SenX CTO. That is how Mathias asked me to review the electronics part of the project. My first call with Quentin was to help him connect an old pressure sensor to an Arduino, during the late evening of March 20.</p>



<p><strong>The goal was clear: to mass-produce an open-source medical ventilator</strong>. Crazy! Looking at the project that day, it looked like an "amateur" project. So I did the first real schematics, the first BOM, the first Radiospares, and Farnell reference list during the weekend, discussing with more and more people on the MakAir Slack. </p>



<figure></figure>



<h3>Amateur? Not really...</h3>



<p>Next Thursday, I understood that the small "amateur" project is quickly getting big. Two electronics companies detached people, and a whole regulatory team was up. In this team, there were some experts in medical devices. We also knew that we were on a shortlist of projects that the French government is looking at closely.</p>



<p>I soon realized that in Nantes, there is no one able to actually make the prototypes. <a href="https://blog.senx.io/connecting-a-beertender-to-warp-10-using-mqtt-on-lorawan-with-thethingsnetwork/" target="_blank" rel="noreferrer noopener">Engineers with prototyping knowledge</a> are scarce, I just know a few of them like me. So, on the 25th during the evening, in a few minutes, I convinced Cherine, a former Renault Sport colleague living near Paris who has the same knowledge of prototyping as me, to join the project as well.</p>



<p><strong>On the 26th, I joined the MakAir core team, choosing to confine myself with 17 other people to make project MakAir a reality</strong>. Cherine came from Paris the same day I came from Brest. At the same time in France, 100 people were already helping us remotely. </p>



<p>I brought with me all my personal tools, from soldering iron to oscilloscope, and tons of components. </p>



<figure><blockquote><p>If I had been told this would last 25 days, I would have brought more than 3 days of clothing!</p></blockquote></figure>



<div><figure><img loading="lazy" src="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328-1024x682.jpg" data-src="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328-1024x682.jpg" alt="working in the Palace, Nantes" width="509" height="339" data-srcset="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328-1024x682.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328-300x200.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328-768x512.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328-1536x1024.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328-600x400.jpg 600w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328.jpg 2000w" data-sizes="(max-width: 509px) 100vw, 509px" srcset="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328-1024x682.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328-300x200.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328-768x512.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328-1536x1024.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328-600x400.jpg 600w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328.jpg 2000w"><figcaption>One sleepless night later, the first functional prototype was up.</figcaption></figure></div>







<p>Three days later, <strong>the <a href="http://www.cea.fr/" target="_blank" rel="noreferrer noopener">CEA</a></strong> (french government agency for atomic energy) is now supporting us. On the 31<sup>st</sup> of March, we all moved from Nantes to Grenoble CEA facility, traveling on a nearly empty motorway.</p>



<p>The first prototype had basic electronics: STM32 Nucleo, a small 4 lines screen, a few buttons, a good precision pressure sensor, and several servo outputs. <strong>This first prototype allows us to make a pig breath for 4 hours</strong> on the 3rd of April, only 2 weeks after the project started.</p>



<figure><ul><li><figure><img loading="lazy" width="1024" height="682" src="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336-1024x682.jpg" data-src="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336-1024x682.jpg" alt="" data-id="11640" data-link="https://blog.senx.io/?attachment_id=11640" data-srcset="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336-1024x682.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336-300x200.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336-768x512.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336-1536x1024.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336-600x400.jpg 600w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336.jpg 2000w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336-1024x682.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336-300x200.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336-768x512.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336-1536x1024.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336-600x400.jpg 600w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336.jpg 2000w"><figcaption>The first prototype board...</figcaption></figure></li><li><figure><img loading="lazy" width="1024" height="682" src="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337-1024x682.jpg" data-src="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337-1024x682.jpg" alt="" data-id="11641" data-link="https://blog.senx.io/?attachment_id=11641" data-srcset="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337-1024x682.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337-300x200.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337-768x512.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337-1536x1024.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337-600x400.jpg 600w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337.jpg 2000w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337-1024x682.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337-300x200.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337-768x512.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337-1536x1024.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337-600x400.jpg 600w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337.jpg 2000w"><figcaption>Stacking a Nucleo F411 with pressure sensor, keyboard, screen.</figcaption></figure></li><li><figure><img loading="lazy" width="1024" height="768" src="https://blog.senx.io/wp-content/uploads/2020/09/4C103809-C6CC-423D-B054-48B8C853F29E_1_105_c.jpeg" data-src="https://blog.senx.io/wp-content/uploads/2020/09/4C103809-C6CC-423D-B054-48B8C853F29E_1_105_c.jpeg" alt="" data-id="11748" data-full-url="https://blog.senx.io/wp-content/uploads/2020/09/4C103809-C6CC-423D-B054-48B8C853F29E_1_105_c.jpeg" data-link="https://blog.senx.io/?attachment_id=11748" data-srcset="https://blog.senx.io/wp-content/uploads/2020/09/4C103809-C6CC-423D-B054-48B8C853F29E_1_105_c.jpeg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/4C103809-C6CC-423D-B054-48B8C853F29E_1_105_c-300x225.jpeg 300w, https://blog.senx.io/wp-content/uploads/2020/09/4C103809-C6CC-423D-B054-48B8C853F29E_1_105_c-768x576.jpeg 768w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://blog.senx.io/wp-content/uploads/2020/09/4C103809-C6CC-423D-B054-48B8C853F29E_1_105_c.jpeg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/4C103809-C6CC-423D-B054-48B8C853F29E_1_105_c-300x225.jpeg 300w, https://blog.senx.io/wp-content/uploads/2020/09/4C103809-C6CC-423D-B054-48B8C853F29E_1_105_c-768x576.jpeg 768w"><figcaption>First wood prototype</figcaption></figure></li></ul></figure>



<h2>Enters the Raspberry Pi</h2>



<p>What we learned from the first test on a pig:</p>



<ul><li>The ventilator did the job. The pig was alive and woke up correctly.</li><li><strong>There is a huge UX problem.</strong></li><li>The airflow measurement is really helpful.</li></ul>



<p>The experts from the medical world are now used to high-tech screens displaying curves with not only pressure, but real-time air volume blown into the patient lungs. Even in crisis time, we understand that our product does not meet their minimum UI/UX needs.</p>



<figure><img loading="lazy" width="1024" height="418" src="https://blog.senx.io/wp-content/uploads/2020/09/image-4-1024x418.jpg" data-src="https://blog.senx.io/wp-content/uploads/2020/09/image-4-1024x418.jpg" alt="difference of UX between first MakAir screen and a recent ventilator" data-srcset="https://blog.senx.io/wp-content/uploads/2020/09/image-4-1024x418.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/image-4-300x123.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/image-4-768x314.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/image-4-1536x627.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/image-4.jpg 1660w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://blog.senx.io/wp-content/uploads/2020/09/image-4-1024x418.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/image-4-300x123.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/image-4-768x314.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/image-4-1536x627.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/image-4.jpg 1660w"><figcaption>Makair prototype on the left, a recent ventilator on the right. <br>Both can save life, but UX gap is huge!</figcaption></figure>



<p>Always listen to the users. Even if we succeed in mass production of an open-source ventilator, if doctors want curves and measures of the number of air liters entering the lungs, we must do it. </p>



<p>Since the beginning, this project is time driven. We never consider the price, but we always look at worldwide stocks. In a time where lots of plants are closed in Europe, <strong>the supply chain is leading the project.</strong></p>



<div><figure><img loading="lazy" src="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6374-edited.jpg" data-src="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6374-edited.jpg" alt="inside the v1 of the MakAir" width="522" height="347" data-srcset="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6374-edited.jpg 1378w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6374-edited-300x200.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6374-edited-1024x683.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6374-edited-768x512.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6374-edited-600x400.jpg 600w" data-sizes="(max-width: 522px) 100vw, 522px" srcset="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6374-edited.jpg 1378w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6374-edited-300x200.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6374-edited-1024x683.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6374-edited-768x512.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6374-edited-600x400.jpg 600w"><figcaption>Scooter lead-acid batteries. Because these are the most available batteries in the word.</figcaption></figure></div>



<p>So, what is the world's most available touch screen? </p>



<div><figure><img loading="lazy" src="https://blog.senx.io/wp-content/uploads/2020/09/image-2.png" data-src="https://blog.senx.io/wp-content/uploads/2020/09/image-2.png" alt="farnell stocks" width="616" height="217" data-srcset="https://blog.senx.io/wp-content/uploads/2020/09/image-2.png 832w, https://blog.senx.io/wp-content/uploads/2020/09/image-2-300x106.png 300w, https://blog.senx.io/wp-content/uploads/2020/09/image-2-768x270.png 768w" data-sizes="(max-width: 616px) 100vw, 616px" srcset="https://blog.senx.io/wp-content/uploads/2020/09/image-2.png 832w, https://blog.senx.io/wp-content/uploads/2020/09/image-2-300x106.png 300w, https://blog.senx.io/wp-content/uploads/2020/09/image-2-768x270.png 768w"><figcaption>(and 18000 more at radiospares)</figcaption></figure></div>



<p>As I just said, the supply chain rules the project. MakAir will have a raspberry to display curves. Nice coincidence for an open-source project!</p>



<p>By the way, the mass flow meter sensor was a huge problem. Since the beginning, MakAir did not want to disturb the production of existing ventilators. But this component is on the airway, it should be approved for medical use. In April, it was impossible to source any Sensirion or Honeywell mass flow sensors... Anyway, the next test will be done with a raspberry connected to the STM32. </p>







<h2>Enter Warp&nbsp;10</h2>



<p>On the 17th of April, the first batch of ventilators built in the CEA clean-rooms was ready. This batch was used for the 1st clinical tests. </p>



<p><strong>The pressure switches from the technical team to the regulatory team, remotely working on the project since the beginning. </strong></p>



<p>To prepare the next batch, we came back to Nantes. After 25 days, we switched from commando mode (18h/day, 7 days a week) to a more standard week (14h/day, the weekends with the family).</p>



<div><figure><img loading="lazy" src="https://blog.senx.io/wp-content/uploads/2020/09/IMG_5752-1024x768.jpg" data-src="https://blog.senx.io/wp-content/uploads/2020/09/IMG_5752-1024x768.jpg" alt="MakAir team in the CEA cleanroom with prototypes" width="521" height="390" data-srcset="https://blog.senx.io/wp-content/uploads/2020/09/IMG_5752-1024x768.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_5752-300x225.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_5752-768x576.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_5752-1536x1152.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_5752.jpg 2016w" data-sizes="(max-width: 521px) 100vw, 521px" srcset="https://blog.senx.io/wp-content/uploads/2020/09/IMG_5752-1024x768.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_5752-300x225.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_5752-768x576.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_5752-1536x1152.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_5752.jpg 2016w"><figcaption>Tyvek sterile clothing in a cleanroom. Could not be better for medical device assembly. Thanks to the CEA.</figcaption></figure></div>



<p>On the 30<sup>th</sup> of April, the prototype with a Raspberry Pi is ready for the next animal test. Two people had to fly to Grenoble CEA with this prototype, but the rest of us, and all the people remotely working on the project wanted to follow the experience. </p>



<p>So, the night before the test, I quickly deployed Warp&nbsp;10 on the raspberry and wrote a small script to copy data every 10s to another Warp&nbsp;10 server.</p>


<span><span><a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fblog.senx.io%2F%3Fp%3D11630&amp;text=MakAir%3A%20the%20birth%20of%20the%20first%20open-source%20data-enabled%20ventilator.%20From%20the%20first%20prototype%20to%20more%20modern%20UX%2C%20thanks%20to%20Raspberry%20Pi.&amp;via=SenXHQ&amp;related=SenXHQ" target="_blank" rel="noopener noreferrer">MakAir: the birth of the first open-source data-enabled ventilator. From the first prototype to more modern UX, thanks to Raspberry Pi. </a></span><a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fblog.senx.io%2F%3Fp%3D11630&amp;text=MakAir%3A%20the%20birth%20of%20the%20first%20open-source%20data-enabled%20ventilator.%20From%20the%20first%20prototype%20to%20more%20modern%20UX%2C%20thanks%20to%20Raspberry%20Pi.&amp;via=SenXHQ&amp;related=SenXHQ" target="_blank" rel="noopener noreferrer">Click To Tweet</a></span>


<p>What is <a href="https://www.warp10.io/" target="_blank" rel="noreferrer noopener">Warp&nbsp;10</a>? It is a time series platform. But unlike other TSDB (Time Series Database), there is a full analysis environment behind, and even a task scheduler. Compress time series, replicate to another server while managing network outage is really easy. Same tooling on the server and the connected object, that what I call easy IoT. To stream data, you just need a few WarpScript functions among <a href="https://www.warp10.io/doc/functionList" target="_blank" rel="noreferrer noopener">the thousand available</a>.</p>



<p>Basically, the WarpScript pseudo code is:</p>



<pre><code>- Read the last value of makair.lastupload GTS
- take the last tick as start
- take now as end
- fetch locally all the makair GTS from start to end
- WRAP all the GTS
- build a script that UNWRAP and UPDATE the data
- do a remote execution of the script with REXEC 
- if the REXEC was a success, store end in makair.lastupload</code></pre>



<p>You can follow the <a href="https://www.warp10.io/content/04_Tutorials/01_WarpScript/30_Server_to_Server" target="_blank" rel="noreferrer noopener">server to server tutorial</a> to implement such a WarpScript, then save it as $WARP10HOME/warpscripts/makair/10000/upload_data.mc2 to schedule an execution every 10s.</p>



<p>To display data in real-time, <a href="http://studio.senx.io/" target="_blank" rel="noreferrer noopener">WarpStudio</a> did the job easily too. Autorefresh of the DataViz every 10s is a built-in function:</p>



<div><figure><img loading="lazy" src="https://blog.senx.io/wp-content/uploads/2020/09/image-3.png" data-src="https://blog.senx.io/wp-content/uploads/2020/09/image-3.png" alt="autorefresh settings of the MakAir test" width="522" height="385" data-srcset="https://blog.senx.io/wp-content/uploads/2020/09/image-3.png 575w, https://blog.senx.io/wp-content/uploads/2020/09/image-3-300x221.png 300w" data-sizes="(max-width: 522px) 100vw, 522px" srcset="https://blog.senx.io/wp-content/uploads/2020/09/image-3.png 575w, https://blog.senx.io/wp-content/uploads/2020/09/image-3-300x221.png 300w"><figcaption>In the dataviz tab of WarpStudio.</figcaption></figure></div>







<p>Around 30 lines of code to allow all the MakAir team to follow the pressure inside the pig lungs in real-time!</p>



<div><figure><img loading="lazy" src="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-1024x683.jpg" data-src="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-1024x683.jpg" alt="real time display" width="516" height="343" data-srcset="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-1024x683.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-300x200.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-768x512.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-1536x1024.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-2048x1365.jpg 2048w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-600x400.jpg 600w" data-sizes="(max-width: 516px) 100vw, 516px" srcset="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-1024x683.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-300x200.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-768x512.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-1536x1024.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-2048x1365.jpg 2048w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-600x400.jpg 600w"><figcaption>WarpStudio on a 60" 4k display, that's a nice dashboard.</figcaption></figure></div>







<h2>Next steps</h2>



<p>MakAir ventilators are designed to store everything in the <a href="https://warp10.io/" target="_blank" rel="noreferrer noopener">Warp&nbsp;10</a> time series database. They also have built-in WiFi and LoRa. All these features are not yet available, because the priority is still to make an open-source approved ventilator. </p>



<figure><ul><li><figure><img loading="lazy" width="225" height="300" src="https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171307-scaled.jpg" data-src="https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171307-225x300.jpg" alt="" data-id="11728" data-full-url="https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171307-scaled.jpg" data-link="https://blog.senx.io/?attachment_id=11728" data-srcset="https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171307-225x300.jpg 225w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171307-768x1024.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171307-1152x1536.jpg 1152w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171307-1536x2048.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171307-scaled.jpg 1920w" data-sizes="(max-width: 225px) 100vw, 225px" srcset="https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171307-225x300.jpg 225w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171307-768x1024.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171307-1152x1536.jpg 1152w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171307-1536x2048.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171307-scaled.jpg 1920w"><figcaption>Revision 3 has a Raspberry screen on top of the small screen.</figcaption></figure></li><li><figure><img loading="lazy" width="225" height="300" src="https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171259-scaled.jpg" data-src="https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171259-225x300.jpg" alt="" data-id="11727" data-full-url="https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171259-scaled.jpg" data-link="https://blog.senx.io/?attachment_id=11727" data-srcset="https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171259-225x300.jpg 225w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171259-768x1024.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171259-1152x1536.jpg 1152w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171259-1536x2048.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171259-scaled.jpg 1920w" data-sizes="(max-width: 225px) 100vw, 225px" srcset="https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171259-225x300.jpg 225w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171259-768x1024.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171259-1152x1536.jpg 1152w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171259-1536x2048.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171259-scaled.jpg 1920w"><figcaption>The Raspberry Pi connected to the mainboard</figcaption></figure></li></ul></figure>



<p>Connected features + open-source software is an enabler for doctors and researchers to perform extensive data collection and try new algorithms in the machine. Warp&nbsp;10 is the best open source time series database to <a href="https://blog.senx.io/warp-10-for-iot-gdpr-compliant-before-gdpr-even-existed/" target="_blank" rel="noreferrer noopener">securely</a> store medical data and analyze it. It's not a walled garden.</p>



<p>If you need to connect medical devices to a time series database, <a href="mailto:contact@senx.io" target="_blank" rel="noreferrer noopener">just ask us</a>.</p>



<p>MakAir is now entering the second phase of clinical tests. We can consider we are halfway to the goal. Keep in mind that among all the projects of ventilators announced by big companies, MakAir is the only one to reach the clinical tests step. <a href="https://makair.life/" target="_blank" rel="noreferrer noopener">200 people, backed up by CEA and a few french companies</a> are about to make a commercially available open source ventilator... </p>



<p>That's crazy when you think about it!</p>



<p>Learn more about the MakAir project on <a href="http://makair.life/" target="_blank" rel="noreferrer noopener">makair.life</a>.</p>
<!-- relpost-thumb-wrapper --><!-- close relpost-thumb-wrapper -->      
           
    </article></div>]]>
            </description>
            <link>https://blog.senx.io/makair-covid-19-ventilator-with-a-raspberry-pi/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25670303</guid>
            <pubDate>Thu, 07 Jan 2021 12:34:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Data Science in Marketing Optimization – Lessons from Airbnb, Lyft, DoorDash]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25670229">thread link</a>) | @eric_cartman
<br/>
January 7, 2021 | https://blogboard.io/blog/data-science-in-marketing-optimization/ | <a href="https://web.archive.org/web/*/https://blogboard.io/blog/data-science-in-marketing-optimization/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://images.unsplash.com/photo-1563705883268-eb58ab6f505d?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDE1fHx0YXJnZXR8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000 300w,
                            https://images.unsplash.com/photo-1563705883268-eb58ab6f505d?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDE1fHx0YXJnZXR8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000 600w,
                            https://images.unsplash.com/photo-1563705883268-eb58ab6f505d?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDE1fHx0YXJnZXR8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000 1000w,
                            https://images.unsplash.com/photo-1563705883268-eb58ab6f505d?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDE1fHx0YXJnZXR8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://images.unsplash.com/photo-1563705883268-eb58ab6f505d?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDE1fHx0YXJnZXR8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000" alt="Data Science for Marketing Optimization - Case Studies from Airbnb, Lyft, DoorDash">
            </figure>

            <section>
                <div>
                    <p>In this article we'll look at several case studies of data science being used to optimize marketing efforts at companies like Lyft, Airbnb, Netflix, Doordash, Wolt, Rovio Entertainment.</p><p>In large and analytically mature organizations, the <em>optimization</em> piece usually comes as a part of a larger <em>marketing automation</em> system, but as we'll see it's not always the case. Doing budget allocation to channels and campaign manually, but with the aid of data science tool set can be hugely profitable and might be a good first step towards a fully automated workflow.</p><p>Before diving into details, let's look at high level architecture of an automated process for online marketing. As a result of streamlining the process that's largely determined by the way online advertising platforms work, marketing automation platforms look very much alike across different companies. In general, these platforms are large systems that comprise the following:</p><ol><li>Data tracking system <br>Track conversion events (customer signups, payment events, subscriptions, micro-transactions, etc).</li><li>Attribution system<br>Connect conversion events with the user acquisition source. That is, for each user we want to know exactly the marketing channel and the campaign that brought them in.</li><li>Performance estimation system<br>Let's say a campaign brought in 1000 users. We want to know if it paid off. We know how much we spent on it, but how do we know how much revenue the users will bring us over their lifetime. LTV and conversion modelling comes into play here.</li><li>Campaign management system<br>Online ads are a very fertile field for variation testing and content generation. But even without testing multiple you variations of the same ad, companies typically target different segments in different ways, easily resulting in dozens or hundreds ads running simultaneously. Companies like Airbnb and Netflix invest heavily in systems that support ad creation and management (<a href="https://medium.com/airbnb-engineering/growing-our-host-community-with-online-marketing-9b2302299324">Airbnb article</a>, <a href="https://netflixtechblog.com/https-medium-com-netflixtechblog-engineering-to-improve-marketing-effectiveness-part-2-7dd933974f5e">Netflix article</a>).</li><li>Automated bidding and budget optimization<br>The largest ad serving platforms provide you with near real-time feedback on your ad performance. Connect this with the spend and projected LTV and you can get your ROI predictions and adjust budgets accordingly. With dozens or hundreds of campaigns and variations, the benefits of automation and optimization at this steps can be huge.</li></ol><p>In article we're interested in what role data science can play in the overall ad lifecycle, so we'll focus on the two parts that tend to benefit the most from mixing in data science: 1) performance estimation and 2) automated bidding and budgeting.</p><p>Before diving in, it's imporant to understand the<em> channel/campaign </em>nomenclature. By <em>channel</em> we consider an advertising platform, such as Google AdWords, Facebook, Youtube, etc. A <em>campaign</em> is a single piece of advertising aimed at specific audience, according to segments available on the <em>channel, </em>with a preset starting and end time.</p><p>When evaluating marketing performance, we might want to look at investment and ROI at the level of a channel, a single campaign or a group of similar campaigns. We'll see how these different levels of granularity influence the amount and quality of available data, and in consequence how that determines the approaches that can be taken.</p><h2 id="performance-estimation">Performance Estimation</h2><p>Ideally, for the purpose of marketing optimization we're interested in LTV and CAC (Customer Acquisition Cost) as the factor in the ROI equation: $$ROI=\frac{LTV}{CAC}$$</p><p>LTV modelling is a fundamental problem in business analytics and it is far from trivial to get it completely right. The exact models depend heavily on the type of business and the intended application. LTV models are generally more valuable if we can give good estimates very early in the user lifetime. However, the earlier we do it the less data we have at our disposal.</p><p>In <a href="https://www.appsflyer.com/blog/overcoming-ltv-modeling-pitfalls/">Pitfalls of Modeling LTV and How to Overcome Them</a>, Dmitry Yudovsky outlines several challenges that make it impossible for a cookie-cutter approach for LTV estimation to exist:</p><ul><li>Machine learning approaches are sometimes completely inadequate.<br>There might be lack of data necessary for long term LTV predictions. Also, even if we do have a large business with tons of historical data, there are cases when training models on year old data doesn't work well - maybe the product or the entire market is very different than a year or two ago.</li><li>Depending on whether we want to use LTV estimates for ad optimization, CRM efforts or corporate financial projections, we might have different requirements for model accuracy and cohort granularity at which we're making predictions (eg. single user, single campaign, group of campaigns, all users, etc.)</li></ul><p>Of course the problem is not intractable, and there are several common approaches. We'll look at a few case studies found in tech blogs from DoorDash, Airbnb and Lyft Engineering teams.</p><p>In <a href="https://doordash.engineering/2020/07/31/optimizing-marketing-spend-with-ml/">Optimizing DoorDash’s Marketing Spend with Machine Learning</a>, Doordash Engineering present their approach, where instead of directly estimating LTV, they model conversion rates as a function of marketing spend. We'll see later how these cost curves help to neatly optimize budget allocation across channels and campaigns.</p><p>Experience (data) tells us that any marketing channel will reach saturation at some point, so we can model cost curves, ie. $Conversion=f(Spend)$<em> </em>using a power function of the form $a\cdot Spend^{b}$.</p><figure><img src="https://blogboard.io/blog/content/images/2021/01/image.png" alt=""><figcaption>Cost curve of the shape $a\cdot Spend^{b}$. Image credit: <a href="https://doordash.engineering/2020/07/31/optimizing-marketing-spend-with-ml/">DoorDash Engineering</a></figcaption></figure><p>We can fit cost curves at any cohort level, and it's typically done at the granularity of a channel or campaign. Simply put, if for a given campaign we spent $x$ amount of money, and that brought us $y$ users, we have one data point, $(x, y)$.</p><p>However, when allocating budgets at a later stage, we might need to make decisions at the <em>campaign </em>level, which cause problems with insufficient amount of data. In the DoorDash Engineering article, Aman Dhesi explains this problem:</p><blockquote>For some channels like search engine marketing, we have thousands of campaigns that spend a small amount of money every week. This makes the weekly attribution data noisy. Some weeks these campaigns don’t spend at all, which makes the data sparse. Using this data as-is will result in unreliable cost curves and in turn suboptimal (potentially wildly so) allocation.</blockquote><p>At DoorDash they solve this problem by training separate models which use similar campaigns to fill in the gaps in the dataset with synthetic data. This approach brings with itself certain tradeoffs, described in the <a href="https://doordash.engineering/2020/07/31/optimizing-marketing-spend-with-ml/">original article</a>.</p><p>In a similar manner, as described in <a href="https://eng.lyft.com/lyft-marketing-automation-b43b7b7537cc">Building Lyft’s Marketing Automation Platform</a>, data scientists at Lyft would fit an LTV curve of the shape $LTV=a\cdot Spend^{b}$. However, they incorporate an additional degree of randomness by modelling $a$ and $b$ as random variables and estimating their parameters $(\mu_a, \sigma_a)$ and $(\mu_b, \sigma_b)$ from historical data. This helps them implement an explore-exploit approach in the bidding step, by instantiating LTV curves after sampling $a$ and $b$ from their respective distributions. We'll revisit this approach briefly at the end of next section.</p><p>As described in <a href="https://medium.com/airbnb-engineering/growing-our-host-community-with-online-marketing-9b2302299324">Growing Our Host Community with Online Marketing</a>, at Airbnb they face a problem stemming from the nature of their product and the market. When predicting LTV for an Airbnb home listing, two major problems are:</p><ol><li>Ad conversions for hosts are a very rare event. This poses problems with building large enough data sets. It also influences data tracking and attribution, where these systems have to be as precise as possible in order not to lose or wrongly attribute any data points.</li><li>Time from ad impression (user seeing an ad) to conversion (home listed on Airbnb) can be very long, sometimes weeks. This is a problem if you want to optimize and re-budget your campaigns soon after rollout - you simply don't have enough data yet.</li></ol><p>In the same post, Tao Cui describes the architecture of each part of Airbnb's marketing platform as well as the motivation for building the entire thing, along with choices of tech stack. </p><p>In another article dating from 2017, <a href="https://medium.com/airbnb-engineering/using-machine-learning-to-predict-value-of-homes-on-airbnb-9272d3d4739d">Using Machine Learning to Predict Value of Homes On Airbnb</a>, Robert Chang describes how they use machine learning (ending up using XGBoost in production) to estimate LTV of each listing. Framing it as a typical regression problem, they use hundreds of features, such as <em>location data, price with all the partial costs (eg. cleaning fee, discounts), availability, previous bookings, </em>to predict revenue from a listing after some fixed amount of time (eg. 1-year revenue). If you're curious, the post also describes some of the pieces of infrastructure used by the system and gives a high-level code examples of training pipeline construction.</p><p>In <a href="https://www.appsflyer.com/resources/gaming/predictive-modeling-app-marketers-guide/pros-and-cons-of-different-ltv-based-predictive-models-insights-from-top-marketers/">Insights on the Pros and Cons of LTV-based Predictive Models</a> an article from AppsFlyer, we can find a summary of pros and cons of the three common LTV modelling approaches for app-based businesses:</p><ol><li>Retention/ARPDAU model<br>If we have a fairly old and stable product with some historical data, we can leverage the fact that we know the shape of the retention curve and can fit a power curve to several early-retention data points. We also know the <em>Average Revenue Per Daily Active User (ARPDAU) </em>which tends to be stable over time for most freemium and micro-transaction apps (such as free to play games). With some math we can arrive at an estimate of the expected LTV using these two measures. For example, to estimate LTV by day 90 of user's lifetime we would use the following equation: &nbsp;$$LTV_{90}=ARPDAU\cdot\sum_{d=0}^{90}retention[d]$$</li><li>LTV ratio model<br>As a simple example, in order to get $LTV_{90}$ we'll use historical data to estimate the ratio $\frac{LTV_{90}}{LTV_{7}}$ and use the observed 7-day LTV to predict the 90-day LTV</li><li>Behavior driven/user-level models<br>We'd use user-level features to train our favorite machine learning model for regression. …</li></ol></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blogboard.io/blog/data-science-in-marketing-optimization/">https://blogboard.io/blog/data-science-in-marketing-optimization/</a></em></p>]]>
            </description>
            <link>https://blogboard.io/blog/data-science-in-marketing-optimization/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25670229</guid>
            <pubDate>Thu, 07 Jan 2021 12:25:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rousseau and the Republicanization of Money]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25669738">thread link</a>) | @werner17
<br/>
January 7, 2021 | https://jhiblog.org/2021/01/06/rousseau-and-the-republicanization-of-money/ | <a href="https://web.archive.org/web/*/https://jhiblog.org/2021/01/06/rousseau-and-the-republicanization-of-money/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div>
<p>In order to stabilize the tumbling financial markets and maintain the liquidity of companies and states, central banks around the world responded to the Covid-19 pandemic by <a href="https://www.reuters.com/article/us-health-coronavirus-liquidity/central-banks-flash-the-cash-as-market-panic-drives-liquidity-squeeze-idUSKBN210174">increasing the money supply</a>.&nbsp; The public discussion about these fiscal and monetary decisions, from their sufficiency to their potential for triggering future inflation, are dominated by economists. The advice of political philosophers, meanwhile, especially those from centuries ago, is not particularly sought after.</p>



<p>Yet this was not always the case. From antiquity until well into the 19th century, European and North American political philosophy revolved around <a href="https://www.cambridge.org/core/books/cambridge-history-of-eighteenthcentury-political-thought/early-enlightenment-debate-on-commerce-and-luxury/23B4652A6F7A7CFDF1125578A8457E24">questions</a> of state financing, debt, property, and money. In other words, the relationship between economics and politics was at the heart of the theoretical debate. As such, it was also central for <a href="https://plato.stanford.edu/entries/rousseau/">Jean-Jacques Rousseau</a>, who wrote the entry “<a href="http://classiques.uqac.ca/classiques/Rousseau_jj/discours_economie_politique/discours_eco_pol.pdf">Économie politique</a>” for Diderot’s and d’Alembert’s <a href="https://quod.lib.umich.edu/d/did/"><em>Encyclopédie</em></a>, <a href="https://books.google.de/books?id=D_HJDwAAQBAJ&amp;lpg=PR1&amp;dq=Michael%20Sonenscher%2C%20Jean-Jacques%20Rousseau%3A&amp;hl=de&amp;pg=PA48#v=onepage&amp;q=Physiocrats%20letter&amp;f=false">corresponded with the Physiocrats</a>, and had none other than Adam Smith attentively <a href="https://books.google.de/books?id=Tb7FCQAAQBAJ&amp;printsec=frontcover&amp;dq=Politics+in+Commercial+Society&amp;hl=de&amp;sa=X&amp;ved=2ahUKEwicn_W61eLtAhVPCewKHVWsBLYQ6AEwAHoECAQQAg#v=onepage&amp;q=Politics%20in%20Commercial%20Society&amp;f=false">review</a> parts of his discourse on inequality.</p>



<p>Today, Rousseau is best known for his advocacy of strong republican ideals, and his focus on the common will and personal presence of the people in contrast to the principle of representation that characterizes the modern, liberal organization of state and government. It is this Rousseau whom Jürgen Habermas famously criticized in <a href="https://mitpress.mit.edu/books/between-facts-and-norms"><em>Between Facts and Norms</em></a> for overburdening citizens with demands for virtue and the common good. But when re-reading Rousseau’s works in the context of his time, it is striking that, much more so than political principles, economic considerations abound and place Rousseau at a great distance from our contemporary conditions.</p>







<p>In Rousseau’s mind, the Enlightenment thinkers, with whom he otherwise sided to considerable extent on political questions, articulated paradoxical economic and political demands. <a href="https://plato.stanford.edu/entries/montesquieu/">Montesquieu</a>, for example, considered it his political task to revive ancient ideas of a free state, so that the freedom of citizens would no longer be threatened by royal and feudal despotism. But unlike their ancient predecessors, Enlightenment intellectuals no longer sought to organize this republicanization on the basis of the self-sufficient <em>oikoi</em> of an agrarian economy, but instead with the help of the modern opportunities of trade and manufacture. As <a href="https://www.polthought.cam.ac.uk/seminar/introductions/intros2010-2011/hont">Istvan Hont</a> has <a href="https://books.google.de/books?id=Tb7FCQAAQBAJ&amp;printsec=frontcover&amp;dq=Politics+in+Commercial+Society&amp;hl=de&amp;sa=X&amp;ved=2ahUKEwicn_W61eLtAhVPCewKHVWsBLYQ6AEwAHoECAQQAg#v=onepage&amp;q=Politics%20in%20Commercial%20Society&amp;f=false">noted</a>, Rousseau turned against this idea of a commercial republicanism in the most resolute form.</p>



<p>In his <a href="https://books.google.de/books?id=kd2I5Fop3WMC&amp;printsec=frontcover&amp;dq=rousseau+discourse+on+inequality&amp;hl=de&amp;sa=X&amp;ved=2ahUKEwjdtY_A7vLtAhWOzqQKHeOfAUEQ6AEwAHoECAUQAg#v=onepage&amp;q=rousseau%20discourse%20on%20inequality&amp;f=false"><em>Discourse on Inequality</em></a>, Rousseau described how a society that accepted a liberalized economic sphere would also inevitably find itself in despotic political waters. Natural man’, who historically was in a harmonious balance with outer and inner nature in Rousseau’s formulation, became dangerously unbalanced when beginning to practice the division of labour, agriculture, and metallurgy. In this way, Rousseau <a href="https://www.degruyter.com/view/journals/dzph/60/6/article-p861.xml">made use of the dominant colonial discourses of his time, not to overturn them, but to reverse them</a>: Instead of tracking progress from “savage” to “civilised” man, Rousseau told a story of human degeneration. According to him, an economy based on the division of labour meant nothing other than individuals no longer being able to provide for their own subsistence from their own resources and, as a consequence, becoming dependent on one another. “From the moment that one man needed the help of another […] equality disappeared, property arose, labour became necessary” (<a href="https://www.marxists.org/reference/subject/economics/rousseau/inequality/ch02.htm">OC III, p. 171</a>). And this mutual dependence was never symmetric: instead, talents, skill, diligence, and physical abilities inevitably caused differences in property and conduct, such that social inequality arose. Having become dependent on his fellow men, a once ‘natural’ man could thus only relate to himself by way of relating to others, which deepened the state of interdependence.</p>



<p>Over time, Rousseau reasoned, the poor thus became dependent on being paid by the rich or on robbing them, and the rich became dependent on the poor remaining dependent. Conflicts would then arise within society. In his reading, this socialized state perpetually threatened to bring about the <a href="https://books.google.de/books?id=Tb7FCQAAQBAJ&amp;printsec=frontcover&amp;dq=Politics+in+Commercial+Society&amp;hl=de&amp;sa=X&amp;ved=2ahUKEwicn_W61eLtAhVPCewKHVWsBLYQ6AEwAHoECAQQAg#v=onepage&amp;q=Hobbesian%20outcome&amp;f=false">Hobbesian war of all against all</a> (45), which was only half-heartedly prevented by the &nbsp;introduction of formal equality before the law, even if only in order to make economic inequality permanent. But such a state is destined to slide down the same slippery slope as society already did: lawbreakers made magistrates necessary, which in turn necessitated elections, elections required political parties, these provoked civil wars, from which followed perpetual dictatorship and, finally, despotism. In essence, Rousseau’s message to his Enlightenment contemporaries was that no republic could be built on the basis of asymmetrical economic interdependence — and to him, trade, division of labor and money regimes were just that.</p>







<p>In so arguing, Rousseau wrote explicitly against the major political-economic theories of his time: against the physiocrats, against mercantilist ideas, but above all against Montesquieu’s idea that trade and commerce brought about a liberalization and pacification of the political sphere—an idea that would inspire <a href="https://www.britannica.com/biography/Sir-James-Steuart-Denham-4th-Baronet">James Denham-Steuart</a>, <a href="https://www.oxfordreference.com/view/10.1093/oi/authority.20110803100158190">John Millar</a>, <a href="https://plato.stanford.edu/entries/hume/">David Hume</a> and, later on, <a href="https://plato.stanford.edu/entries/smith-moral-political/">Adam Smith</a>. Montesquieu <a href="https://books.google.de/books?id=nW0PAAAAQBAJ&amp;printsec=frontcover&amp;dq=Hirschman+the+passions&amp;hl=de&amp;sa=X&amp;ved=2ahUKEwiwjMur1-LtAhXI-aQKHTAACOoQ6AEwAHoECAAQAg#v=onepage&amp;q=montesquieu&amp;f=false">reasoned</a> that modern commerce and manufactures made citizens independent of their rulers. If these rulers transgressed the limits of civic consent, one could easily withdraw one’s possessions, mobile capital or even money from the grasp of the crown. This threat to the control exercised by monarchy and feudal nobility automatically limited governmental power. Adam Smith thought <a href="https://books.google.de/books?id=Tb7FCQAAQBAJ&amp;printsec=frontcover&amp;dq=Politics+in+Commercial+Society&amp;hl=de&amp;sa=X&amp;ved=2ahUKEwicn_W61eLtAhVPCewKHVWsBLYQ6AEwAHoECAQQAg#v=onepage&amp;q=Politics%20in%20Commercial%20Society&amp;f=false">along similar lines</a> and expanded this argument: If cleverly managed, he wrote, even the rulers’ exorbitant claims to luxury and consumption could be used to create work and prosperity and, at the same time, bring about the rule of law. According to him, the complexity of flourishing trade in the cities and the growth of mutual interdependence overwhelmed the power that despots could muster to govern. &nbsp;With this, Montesquieu (like Smith later) turned against absolute monarchy from the outside, i.e. politically, in order to discipline it from the inside, i.e. economically.</p>



<p>Rousseau, however, turned these arguments against their proponents. His discussion of political economy in the <a href="https://www.marxists.org/reference/subject/economics/rousseau/inequality/ch02.htm"><em>Second Discourse</em></a> was precisely aimed at showing that what Montesquieu and Smith considered the disciplinary threat that citizens posed to their monarchs would turn into a disciplinary order that benefits the rich at the expense of the republic. For Rousseau, economic inequality, asymmetric economic interdependencies, and private interests prevented the formation of a common will. Therefore, it was perfectly consistent to him that, just as there should be no partisanship in the political world, the republic must presuppose the material self-sufficiency of its citizens. Thus, he ordered in the <a href="http://www.ibiblio.org/ml/libri/r/RousseauJJ_ContratSocial_s.pdf"><em>Contrat social</em></a> that no citizen of his ideal republic should be “so wealthy as to be able to buy another, and none so poor as to be forced to sell himself” (OC III, p. 391). Notably, this seemingly economic argument was premised on a political observation: the rich and the poor were equally dangerous to the common good, “from the one come the abettors of tyranny, from the other the tyrants; the trade in public liberty is always between them; the one buys and the other sells it” (OC III, p. 392).</p>



<p>However, anyone who thinks that Rousseau considered himself utopian is mistaken. Already in the <em>Contrat social</em>, he praised Corsica as one of the few exceptions that, under the historical conditions of his time, would still be capable of forming a republic along the lines he set forth — not least <a href="http://eprints.lse.ac.uk/69838/1/Hill_Enlightened%20savages_author_2017_Final.pdf">because, in the eyes of Rousseau</a>, Corsicans appeared uncivilized. After the latter had made some gains in the fight for Corsican independence, Matteo Buttafuoco approached Rousseau in 1764 with the <a href="https://journals.sagepub.com/doi/abs/10.1111/1467-9248.00322">request to draft a constitution for Corsica</a>. Rousseau enthusiastically agreed. Interestingly, his proposed constitution, which survived through his estate, is largely devoted to the economic rather than the political situation in Corsica. Rousseau recommended, for example, that a prerequisite for citizenship&nbsp; should be the possession of sufficient land to provide for oneself and one’s family, and so that the asymmetrical dependence described in the <em>Second Discourse </em>would not occur. Rousseau believed that there was enough territory available in Corsica to allow every inhabitant to own farmland.</p>







<p>But Rousseau knew, of course, how far modern conditions had advanced in comparison to antiquity. Large empires in the island’s geographical neighborhood, monetary and fiscal systems, trade, and manufactures were obstacles to the peaceful republicanization of the Corsicans. Rousseau’s response to these unfavorable conditions was as radical as it was consequential: limited foreign trade to prevent a dependence on neighboring territories, hardly any internal trade in order to conserve the independence of citizens from one another, and a requirement that manufacturers and craftsmen had to settle far away from the trading places to make their businesses costly and burdensome. Expressed in modern economic vocabulary: Rousseau tried to internalize the politically external costs of the economy—for the good of the republic.</p>



<p>It was the financial and monetary system that worried Rousseau the most. The virtualization of goods in the form of money provided the conditions for a limitless accumulation of wealth and thus disconnection from the polity. Money — although supplied and guaranteed for by the state — could become a vehicle for particular interests and, in the last consequence, for anti-republican developments. Therefore, according to Rousseau, money was to be kept to a minimum in Corsica and to be replaced as far as possible by a local barter economy that was to be administered by …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jhiblog.org/2021/01/06/rousseau-and-the-republicanization-of-money/">https://jhiblog.org/2021/01/06/rousseau-and-the-republicanization-of-money/</a></em></p>]]>
            </description>
            <link>https://jhiblog.org/2021/01/06/rousseau-and-the-republicanization-of-money/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25669738</guid>
            <pubDate>Thu, 07 Jan 2021 11:13:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Is Metacognition?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25669594">thread link</a>) | @jrmorson
<br/>
January 7, 2021 | https://trendrep.net/metacognition-learning/ | <a href="https://web.archive.org/web/*/https://trendrep.net/metacognition-learning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="mvp-content-main">
<br>
<figure id="metacognition"><img src="https://trendrep.net/wp-content/uploads/2020/12/Metacognition-1-1024x493.jpg" alt="what is metacognition learning" width="768" height="370" title="what is metacognition learning" srcset="https://trendrep.net/wp-content/uploads/2020/12/Metacognition-1-1024x493.jpg 1024w, https://trendrep.net/wp-content/uploads/2020/12/Metacognition-1-300x144.jpg 300w, https://trendrep.net/wp-content/uploads/2020/12/Metacognition-1-768x370.jpg 768w, https://trendrep.net/wp-content/uploads/2020/12/Metacognition-1.jpg 1350w" sizes="(max-width: 768px) 100vw, 768px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20768%20370'%3E%3C/svg%3E" data-lazy-srcset="https://trendrep.net/wp-content/uploads/2020/12/Metacognition-1-1024x493.jpg 1024w, https://trendrep.net/wp-content/uploads/2020/12/Metacognition-1-300x144.jpg 300w, https://trendrep.net/wp-content/uploads/2020/12/Metacognition-1-768x370.jpg 768w, https://trendrep.net/wp-content/uploads/2020/12/Metacognition-1.jpg 1350w" data-lazy-src="https://trendrep.net/wp-content/uploads/2020/12/Metacognition-1-1024x493.jpg"></figure>
<h2>Metacognition definition</h2>
<p>Metacognition refers to “thinking about thinking” and was initiated as a notion by John Flavell, who is generally known as a founding <a href="https://trendrep.net/keri-hilson-pregancy/">father</a> of the field. Flavell explained that metacognition is the understanding you have of your own cognitive processes (your thinking), Flavell (1979). It is your capability to monitor your thinking processes through several strategies, like organizing, monitoring, and adapting. In addition, it is your capability to reflect upon the tasks or processes you undertake and to select and use the adequate strategies in your intercultural interactions.</p>
<p>Metacognition is considered a crucial element of successful learning. It includes self-regulation and self-reflection of strengths, weaknesses, and the types of strategies you develop. It is an essential instauration in culturally intelligent leadership because it emphasizes how you think along an issue or situation and the strategies you develop to treat this situation or problem.</p>
<p>Some people become habitual to getting trainers and consultants offer them the knowledge about cultures to the point where they are reliant on the coach, mentor, trainer, or consultant. However, they must learn to be experts in cultural scenarios themselves over metacognitive strategies like adapting, monitoring, self-regulation, and self-reflection. Culturally intelligent leaders may utilize metacognition to aid and teach themselves to reflect through their thinking.</p>
<p>Metacognition includes three components: metacognitive knowledge, metacognitive and emotions, and metacognitive strategies. Each of these is addressed in the next paragraphs.</p>
<h2>Why Teach Metacognitive Skills?</h2>
<p>Research demonstrates that metacognitive skills may be tutored to students to ameliorate their learning (Nietfeld &amp; Shraw, 2002; Thiede, Anderson, &amp; Therriault, 2003).</p>
<p>Constructing understanding necessitates both cognitive and metacognitive components. Trainees “construct knowledge” utilizing cognitive strategies, and they orientate, modulate, and assess their learning utilizing metacognitive strategies. It is through this “thinking about thinking,” this use of metacognitive strategies, that real learning happens. As students become more skilled at utilizing metacognitive strategies, they attain confidence and become more autonomous as learners.</p>
<p>Individuals with well-developed metacognitive competencies may analyze a problem or approach a learning task, choose adequate strategies, and decide about a course of measures to solve the problem or efficiently execute the task. They frequently reflect about their own thinking processes, taking time to reflect about and learn from mistakes&nbsp; (North Central Regional Educational Laboratory, 1995). Some pedagogical programs motivate students to participate in “metacognitive conversations” with themselves so that they can “talk” with themselves about their learning, the challenges they meet, and the ways in which they may self-compensate and continue learning.</p>
<p>Furthermore, individuals who prove a wide diversity of metacognitive competencies execute better on exams and accomplish work more efficiently—they use the right tool for the job, and they modify learning strategies as required, defining blocks to learning and changing tools or strategies to assure objectives accomplishment. Because Metacognition plays a crucial function in productive learning, it is insistent that mentors assist learners create metacognitively.</p>
<h2>Metacognitive Knowledge</h2>
<p>Metacognitive knowledge includes:</p>
<p> 1) learning processes and your confidence about how you learn and how you reflect others learn.</p>
<p> 2) the task of learning and how you process information.</p>
<p> 3) the strategies you develop and when you will utilize them.</p>
<p> Let us say you should to learn a new language in six months. Here is how you would reflect about it, using metacognitive knowledge:</p>
<ul><li>Learning Process: I am good at learning new languages and I think I may do this in the time period I have been given.</li></ul>
<ul><li> Task of Learning: To accomplish this task, I will need to reflect about the following:</li></ul>
<ol><li>&nbsp; &nbsp; How soon may I get information to begin learning the language?</li></ol>
<ol reversed="" start="2"><li>&nbsp; &nbsp; How much time would it take to learn the new language?</li></ol>
<ol reversed="" start="3"><li>&nbsp; &nbsp; What information is accessible to me to learn this new language?</li></ol>
<ol reversed="" start="4"><li>&nbsp; &nbsp; Is this language comparable to any language I have learned before?</li></ol>
<ol reversed="" start="5"><li>&nbsp; &nbsp; Will I be capable to learn the language in time?</li></ol>
<ol reversed="" start="6"><li>&nbsp; &nbsp; How difficult will it be for me to learn this language?</li></ol>
<ol reversed="" start="7"><li>&nbsp; &nbsp; What I have to do to learn the language?</li></ol>
<ul><li>The Strategies: I think learning this new language will take&nbsp; 12 months, but I only have 6 months to do it. I better check other ways to meet this goal. I think I will check if there is an accelerated language class that I may take. Maybe I must consider hiring a private tutor, or maybe I will just concentrate on learning the basics of the language.</li></ul>
<h2>Metacognition and Emotions&nbsp;</h2>
<p>Arnold Bennett, a British writer, explained that one may not have knowledge without having <a href="https://trendrep.net/what-is-teratogen-pregnancy/">emotions</a>, Bennett (1933). In metacognition, there are feelings and emotions present that are related to the objectives and tasks of learning. These elements of metacognition speaks to metacognitive experience, which is your internal response to learning. Your feelings and emotions serve as a feedback system to help you understand your progress and estimates, and your comprehension and connection of new information to the old, among other things.</p>
<p>When you learn a new language, for example, you can recall memories, information, and earlier experiences in your life to help you resolve the task of learning a new language. In doing this, your internal responses (metacognitive experience) might be frustration, disappointment, happiness, or satisfaction. Each of these internal responses may impact the task of learning a new language and determine your willingness to continue. Critical to metacognition is the capability to purposely nurture a positive mindset and positive feelings toward your learning.</p>
<h2>Metacognitive Strategies</h2>
<p>Metacognitive strategies are what you design to supervise your progress correlated with your learning and the tasks at hand. It is a process for controlling your thinking activities and to assure you are meeting your objectives. Metacognitive strategies for learning a new language may comprise the following:</p>
<ul><li>Monitoring whether you understand the language lessons;</li></ul>
<ul><li>Realizing when you fail to comprehend information addressed to you in the new language;</li></ul>
<ul><li>Identifying strategies that help you to develop your comprehension;</li></ul>
<ul><li>Adjusting your speed for learning the information (for example, studying for 2 hours, instead of 1 hour, every day);</li></ul>
<ul><li>Maintaining the attitude necessary to assure you accomplish the lessons in a timely manner;</li></ul>
<ul><li>Creating a check-in system at the end of each week to make sure you understand what you have learned.</li></ul>
<p>As one business manager of a reputed company told me:</p>
<p>Understanding cultural strategic reflecting is like this: When I work with people from various cultures, this is a framework and approach to help me comprehend how I think when I work with them. It helps me to recognize the cultural experiences I have had, and to identify preconceived notions I could have about their culture, whether it’s race/ethnicity, social culture, age group—you name it. Cultural strategic reflecting pushes me to develop experiences and new learning that helps me to complete my objectives as a global manager.G. Menefee (personal communication, May 12, 2010).</p>
<p>Individuals like this leader are good at applying strategies that focus their attention on the target at hand. They look for, and derive meaning from, cultural interacts and situations, and they adjust themselves to the situation when things do not pan out as they expected. Culturally intelligent leaders also supervise and organize their own learning processes. They have established a high motivation for learning the metacognitive mechanism, either because they know it is a benefit or because others tell them it is beneficial to them.</p>
<p>Knowledge of actual information and basic competences offers a foundation for developing metacognition. Metacognition empowers leaders to master information and solve problems more easily. When a leader has learned the fundamental competences required for intercultural interacts, they may strongly engage in the interaction because they do not have to consider the other dynamics and demands of the situation. Culturally intelligent leaders are capable to apply metacognition, and they are not afraid to use it in their daily life.</p>
<p>For those who lack basic intercultural skills, it is more hard for them to engage in the interaction. They are more occupied with finding the “right information,” the “right skills,” and the “right facts” required to solve the problem. In such situations, these kinds of leaders spend little time improving their metacognitive competencies, and the result is probably an inefficient solution to a problem. Designing a laundry list or checklist of do’s and don’ts will not help leaders improving their cultural intelligences.</p>
<br> </div></div>]]>
            </description>
            <link>https://trendrep.net/metacognition-learning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25669594</guid>
            <pubDate>Thu, 07 Jan 2021 10:52:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Making policy for a low-trust world]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25669507">thread link</a>) | @zby
<br/>
January 7, 2021 | https://www.slowboring.com/p/making-policy-for-a-low-trust-world | <a href="https://web.archive.org/web/*/https://www.slowboring.com/p/making-policy-for-a-low-trust-world">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa3287f0c-8bd8-40ac-8040-8857ddb7e9ba_569x350.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa3287f0c-8bd8-40ac-8040-8857ddb7e9ba_569x350.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/a3287f0c-8bd8-40ac-8040-8857ddb7e9ba_569x350.jpeg&quot;,&quot;height&quot;:350,&quot;width&quot;:569,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:35572,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>The United States of America has become a country with low and falling levels of social trust. This is in some ways a rational response to elite failures, in some ways an inevitable consequence of the public becoming better educated, in some ways an unavoidable side effect of better information technology, and in some ways a deplorable thing that we should try to reverse. </p><p>But something I’ve become increasingly convinced of is that policymakers need to acknowledge that it’s a real feature of the landscape and adjust their decision-making accordingly. </p><p>In particular, they need to adjust it in an appropriate way. A very large share of the people involved in politics and government are lawyers, and their lawyerly instinct about the problem seems to be that you need to layer on more layers of process. If people are worried about the discretionary use of power, you need to make sure the decision-makers go through an elaborate compliance checklist. But as Princess Leia tried to explain to Grand Moff Tarkin, <a href="https://www.youtube.com/watch?v=-wntX-a3jSY">“the more you tighten your grip, the more star systems will slip through your fingers.”</a> </p><p>When you try to address low trust through compliance, you end up where Andrew Cuomo is —&nbsp;he’s creating an elaborate checklist for vaccine prioritization which is hard to follow, so he’s ramping up penalties for people who don’t comply, which is slowing vaccine administration and further eroding trust. </p><p>But the same basic problem pops up everywhere from fiscal stimulus and quantitative easing to <a href="https://pedestrianobservations.com/2020/12/31/streets-before-trust/">bike lanes</a>. </p><p>The correct way to respond to a low-trust environment is not to double down on proceduralism, but to commit yourself to the <a href="https://pedestrianobservations.com/2020/12/31/streets-before-trust/">“it does exactly what it says on the tin”</a> principle and implement policies that have the following characteristics:</p><ul><li><p>It’s easy for everyone, whether they agree with you or disagree with you, to understand what it is you say you are doing. </p></li><li><p>It’s easy for everyone to see whether or not you are, in fact, doing what you said you would do. </p></li><li><p>It’s easy for you and your team to meet the goal of doing the thing that you said you would do. </p></li></ul><p>That’s not a guarantee of political or policy success. Maybe you will pick terrible ideas and be a huge failure anyway. But this triad for success under conditions of distrust at least creates the <em>possibility</em> of success, where people will look back and decide that what you did worked. Committing yourself to that triad may involve some waste and inefficiency relative to a more theoretically optimal scheme with more means-testing. </p><p>And it will almost certainly involve a bit more high-handedness and less community consultation. But it allows you to establish yourself as conditionally trustworthy in the sense that your policies do exactly what it says on the tin. And if you pick policies that work, you’re then in a position to rebuild trust as people see that confidence in you is rewarded.</p><h4>The vaccine prioritization fiasco</h4><p>In my December 18 post, <a href="https://www.slowboring.com/p/vaccinate-elderly">“Give The Vaccine To The Elderly,”</a> I argued in favor of a pretty strict age-based prioritization system primarily because that would be a transparent and easy to implement mechanism. </p><p>As I researched it, I came across the fact — which has been flagged by others as well — that the Advisory Committee on Immunization Practices was recommending a more complicated scheme in part on racial justice grounds. Because everyone loves culture war arguments, this became a huge controversy and several conservative states like Texas made big shows of rejecting the Social Justice Warrior concepts. That’s fine, but unfortunately, they did not accept the wisdom of implementing a transparent and easy to implement mechanism. </p><p>Instead, operating under the principle that everyone wants to be vaccinated in Group 1 they have divided Group 1 into three subgroups — 1A, 1B, and 1C. But then Group 1A is <a href="https://dshs.texas.gov/coronavirus/immunize/vaccine/EVAP-Phase1A.pdf">subdivided into two separate tiers</a>, and we’re still awaiting word on how Group 1C will be subdivided, to say nothing of Group 2 or Group 3. </p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fc22295e8-22ca-4271-b6f1-392f1e0b1c59_1286x540.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fc22295e8-22ca-4271-b6f1-392f1e0b1c59_1286x540.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/c22295e8-22ca-4271-b6f1-392f1e0b1c59_1286x540.png&quot;,&quot;height&quot;:540,&quot;width&quot;:1286,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:280147,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>So while New York and California, with their presumably more social justice-inflected vaccine distributions, have managed to disburse only 31 percent and 28 percent of their vaccine doses (<a href="https://www.nytimes.com/interactive/2020/us/covid-19-vaccine-doses.html">I’m going by New York Times data</a>), Texas and Florida, who made a big deal of rejecting ACIP, are not doing much better at 36 percent and 31 percent. The very worst performances are in Kansas, Georgia, Arizona, Mississippi, and Idaho, so there’s clearly a lot more afoot here than pure partisan politics. </p><p>And in many ways we still haven’t gotten to the real pain point of prioritization systems, which is going to be where people with “at least one chronic medical condition” get to cut the line. In the abstract, of course if you’re 52 and have a bad heart then you need the vaccine more than someone who’s 64 and in perfect health. But in practice, this means you are allocating vaccines not based on <em>actual</em> population health, but based on who is in possession of a note from their doctor. </p><p>The system, as implemented, will not do what it says on the tin. As people notice that, they will become more aggressive about wanting to cheat the system. And as backlash builds, pressure will build for tighter enforcement, which will further slow down administration. </p><p>A pure age-based system — “show up at CVS or Walgreens and they’ll give you the shot if you’re over 75” with the age cutoff steadily dropping over time —&nbsp;is not perfect. But it’s really easy to check people’s IDs, the rich and powerful have no good way to game that system, and the smooth operation of the system itself will build trust.</p><h4>Checks for everyone </h4><p>I cover American public policy professionally, and I would have trouble explaining to you exactly how the <a href="https://www.sba.gov/funding-programs/loans/coronavirus-relief-options/paycheck-protection-program">Paycheck Protection Program</a> works. </p><p>Formally speaking, it’s a Small Business Administration loan guarantee program rather than a direct payroll subsidy like many European countries did. But when you peak under the hood, one of the key advantages of the PPP loan is that it will be forgiven if you meet certain criteria, including <a href="https://onpay.com/covid-19/ppp-loan-forgiveness">not laying off your employees</a> and using the money for certain <a href="https://www.sba.gov/funding-programs/loans/coronavirus-relief-options/paycheck-protection-program#section-header-5">specific eligible expenses</a>. </p><p>Because the program is complicated, it’s generated an endless series of compliance complaints:</p><ul><li><p>Because it’s supposed to be a small business program, a whole genre of journalism emerged complaining that too much PPP money was going to bigger companies —&nbsp;but of course, bigger companies employ more people.</p></li><li><p>Because it’s supposed to be a loan program but in practice a lot of the loans are forgiven, you get complaints about monetary losses to the government.</p></li><li><p>Because you’re <em>allowed</em> to accept a loan without applying for full forgiveness, some PPP recipients got money and did layoffs, generating complaints that it didn’t really protect payrolls.</p></li></ul><p>And on top of all that, there were significant administrative burdens associated with the program which generated a lot of complaints from business owners, the very people who are supposed to be enthusiastic about PPP.</p><p>Instead, a myth developed that the government — which put hundreds of billions of dollars in small business assistance on the table — was barely doing anything.</p><p>Fundamentally, I would say that the problem with the program is that it didn’t do what it says on the tin, in part because it’s not at all clear what it said on the tin. It seems to have started with the thought that the Fed keeping interest rates low was helping big businesses because they could sell bonds to ride out the pandemic, so there should be a comparable lending program for smaller companies. But if the government is going to help out smaller companies, it should make sure that it’s actually saving jobs. And if we’re going to give companies loans to maintain payroll, but they’re often not going to be able to pay the loan back, there should be loan forgiveness. In the end, Congress backed itself into something that was a lot closer to a European-style payroll subsidy program than to a loan program, but with most of the trappings of a loan program.</p><p>By contrast, sending $1,200 to almost everyone was seen as a huge success, and <a href="https://www.dataforprogress.org/blog/2020/12/28/78-of-likely-voters-support-2000-relief-checks">sending more checks is wildly popular</a>. </p><p>The checks did what they said on the tin. They didn’t attempt to distinguish between the deserving and the undeserving. They didn’t specify whether you had to use the check to make rent or could just blow it on a new iPhone. And they <em>also</em> didn’t attempt to address any particular racial social justice concerns. Critically, they didn’t claim to do any of these things. The only claim was that almost everyone would get some money, and they did. </p><h4>QE for the people </h4><p>A policy from the Great Recession that really flunked the “what it says on the tin” test was quantitative easing. </p><p>I think if you really understand how monetary policy works and have confidence in the Federal Reserve staff, then you’ll see that having the Fed buy a bunch of longer-term bonds is really not that exciting or weird. But most people don’t. </p><p>And unfortunately, as you become better-informed about monetary issues, it doesn’t actually become that much clearer why the Fed decided this would be a good thing to do. During a funny 2014 Brookings appearance, Ben Bernanke <a href="https://www.ft.com/content/3b164d2e-4f03-11e4-9c88-00144feab7de">quipped</a> that “the problem with quantitative easing is that it works in practice, but it doesn’t work in theory.”</p><p>But think about that in terms of a low-trust society; the guy we’re supposed to trust to do the QE himself says he can’t give an explanation of how it works. </p><ul><li><p>Now of course you can read <a href="https://economistsview.typepad.com/economistsview/2010/10/bernankes-speech-how-does-quantitative-easing-work-will-it-work.html">Tim Duy offer five mechanisms through which QE could work</a> back in 2010 — but he’s skeptical that the tools are powerful.</p></li><li><p>By 2016, Roger Farmer says that Bernanke is wrong and QE <em>does</em> work in theory, and <a href="https://voxeu.org/article/why-unconventional-monetary-policy-works-theory">offers a theoretical account of why it works</a> that is somewhat different from any of Duy’s theories.</p></li><li><p>By 2020, Bernanke has come around to the view that <a href="https://www.brookings.edu/blog/ben-bernanke/2020/01/04/the-new-tools-of-monetary-policy/">he now understands why QE works in theory</a>, though his view is closer to Duy’s than to Farmer’s. </p></li></ul><p>If you’re an insider to macroeconomic policy discussions, Bernanke’s quote is funny. But I think given all this, it’s …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.slowboring.com/p/making-policy-for-a-low-trust-world">https://www.slowboring.com/p/making-policy-for-a-low-trust-world</a></em></p>]]>
            </description>
            <link>https://www.slowboring.com/p/making-policy-for-a-low-trust-world</link>
            <guid isPermaLink="false">hacker-news-small-sites-25669507</guid>
            <pubDate>Thu, 07 Jan 2021 10:37:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Quorum Availability]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25669327">thread link</a>) | @r4um
<br/>
January 7, 2021 | http://brooker.co.za/blog/2021/01/06/quorum-availability.html | <a href="https://web.archive.org/web/*/http://brooker.co.za/blog/2021/01/06/quorum-availability.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post">


<p>It's counterintuitive, but is it right?</p>


<p>In our paper <a href="https://www.usenix.org/conference/nsdi20/presentation/brooker">Millions of Tiny Databases</a>, we say this about the availability of quorum systems of various sizes:</p>

<blockquote><p>As illustrated in Figure 4, smaller cells offer lower availability in the face of small numbers of uncorrelated node failures, but better availability when the proportion of node failure exceeds 50%. While such high failure rates are rare, they do happen in practice, and a key design concern for Physalia.</p></blockquote>

<p>And this is what Figure 4 looks like:</p>

<p><img src="https://mbrooker-blog-images.s3.amazonaws.com/mtb_fig_4.png" alt=""></p>

<p>The context here is that a <em>cell</em> is a Paxos cluster, and the system needs a majority quorum for the cluster to be able to process requests<sup><a href="#foot1">1</a></sup>. A cluster of one box needs one box available, five boxes need three available and so on. The surprising thing here is the claim that having smaller clusters is actually <em>better</em> if the probability of any given machine failing is very high. The paper doesn't explain it well, and I've gotten a few questions about it. This post attempts to do better.</p>

<p>Let's start by thinking about what happens for a cluster of one machine (<em>n=1</em>), in a datacenter of <em>N</em> machines (for very large <em>N</em>). We then fail each machine independently with probability <em>p</em>. What is the probability that our one machine failed? That's trivial: it's <em>p</em>. Now, let's take all <em>N</em> machines and put them into a cluster of <em>n=N</em>. What's the probability that a majority of the cluster is available? For large <em>N</em>, it's 1 for <em>p &lt; 0.5</em>, and 0 for <em>p &gt; 0.5</em>. If less than half the machines fail, less than half have failed. If more than half the machines fail, more than half have failed. Ok?</p>

<p><img src="https://mbrooker-blog-images.s3.amazonaws.com/quorum_avail_a.png" alt=""></p>

<p>Notice how a cluster size of 1 is worse than N up until <em>p = 0.5</em> then better after. <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.38.5629&amp;rep=rep1&amp;type=pdf">Peleg and Wool</a> say:</p>

<blockquote><p>... for <em>0 &lt; p &lt; ½</em> the most available NDC<sup><a href="#foot2">2</a></sup> is shown to be the "democracy" (namely, the minimal majority system), while the "monarchy" (singleton system) is least available. Due to symmetry, the picture reverses for <em>½ &lt; p &lt; 1</em>.</p></blockquote>

<p>Here, the <em>minimal majority system</em> is the one I'd call a <em>majority quorum</em>, and is used by Physalia (and, indeed, most Paxos implementations). The <em>monarchy</em> is where you have one leader node.</p>

<p>What about real practical cluster sizes like <em>n=3</em>, 5, and 7? There are three ways we can do this math. In <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.38.5629&amp;rep=rep1&amp;type=pdf">The Availability of Quorum Systems</a>, Peleg and Wool derive closed-form solutions to this problem<sup><a href="#foot3">3</a></sup>. Our second approach is to observe that the failures of the nodes are Bernoulli trials with probability <em>p</em>, and therefore we can read the answer to "what is the probability that 0 or 1 of 3 fail for probability <em>p</em>" from the distribution function of the <a href="https://en.wikipedia.org/wiki/Binomial_distribution">binomial distribution</a>. Finally, we can be lazy and do it with Monte Carlo. That's normally my favorite method, because it's easier to include correlation and various "what if?" questions as we go.</p>

<p>Whichever way you calculate it, what do you expect it to look like? For small <em>n</em> you may expect it to be closer in shape to <em>n=1</em>, and for large <em>n</em> you may expect it to approach the shape of <em>n=N</em>. If that's what you expect, you'd be right.</p>

<p><img src="https://mbrooker-blog-images.s3.amazonaws.com/quorum_avail_b.png" alt=""></p>

<p>I'll admit that I find this result deeply deeply counter-intuitive. I think it's right, because I've approached it multiple ways, but it still kind of bends my mind a little. That may just be me. I've discussed it with friends and colleagues over the years, and they seem to think it matches their intuition. It's counter-intuitive to me because it suggests that smaller <em>n</em> (smaller clusters, or smaller cells in Physalia's parlance) is better for high <em>p</em>! If you think a lot of your boxes are going to fail, you may get better availability (not durability, though) from smaller clusters.</p>

<p>Weird.</p>

<p><strong>Correlation to the rescue!</strong></p>

<p>It's not often that my statistical intuition is saved by introducing correlation, but in this case it helps. I'd argue that, in practice, that you only lose machines in an uncorrelated Bernoulli trial way for small <em>p</em>. Above a certain <em>p</em>, it's likely that the failures have some shared cause (power, network, clumsy people, etc) and so the failures are likely to be correlated in some way. In which case, we're back into the game we're playing with Physalia of avoiding those correlated failures by optimizing placement.</p>

<p>In many other kinds of systems, like ones you deploy across multiple datacenters (we'd call that <em>regional</em> in AWS, deployed across multiple <em>availability zones</em>), you end up treating the datacenters as units of failure. In that case, for 3 datacenters you'd pick something like <em>n=9</em> because you can keep quorum after the failure of an entire datacenter (3 machines) and any one other machine. As soon as there's correlation, the math above is mostly useless and the correlation's cause is all that really matters.</p>

<p>Availability also isn't the only thing to think about with cluster size for quorum systems. Durability, latency, cost, operations, and contention on leader election also come into play. Those are topics for another post (or section 2.2 of <a href="https://www.usenix.org/conference/nsdi20/presentation/brooker">Millions of Tiny Databases</a>).</p>

<p><strong>Updates</strong></p>

<p>JP Longmore sent me this intuitive explanation, which makes a lot of sense:</p>

<blockquote><p>Probability of achieving a quorum will increase when removing 2 nodes from a cluster, each with failure rate p&gt;.5, since on average you're removing 2 bad nodes instead of 2 good nodes. Other cases with 1 good node &amp; 1 bad node don't change the outcome (quorum/not). Repeat reasoning till N=1 or all remaining nodes have p&lt;=.5 (if failure rate isn’t uniform).</p></blockquote>

<p><strong>Footnotes</strong></p>

<ol>
<li><a name="foot1"></a> Physalia uses a very naive Paxos implementation, intentionally optimized for testability and simplicity. The quorum intersection requirements of Paxos (or Paxos-like protocols) are more subtle than this, and work like Heidi Howard et al's <a href="https://fpaxos.github.io/">Flexible Paxos</a> has been pushing the envelope here recently. <a href="https://arxiv.org/pdf/1608.06696v1.pdf">Flexible Paxos:  Quorum intersection revisited</a> is a good place to start.</li>
<li><a name="foot2"></a> Here, an NDC is a <em>non-dominated coterie</em>, and a <em>coterie</em> is a set of groups of nodes (like <em>{{a, b}, {b, c}, {a, c}}</em>). See Definition 2.2 in <a href="https://www.cs.purdue.edu/homes/bb/cs542-20Spr/readings/reliability/How%20to%20assign%20Votes-JACM-garcia-molina.pdf">How to Assign Votes in a Distributed System</a> for the technical definition of domination. What's important, though, is that for each <em>dominated coterie</em> there's a <em>non-dominated coterie</em> that provides the same mutual exclusion properties, but superior availability under partitions. The details are not particularly important here, but are very interesting if you want to do tricky things with quorum intersection.</li>
<li><a name="foot3"></a> Along with a whole lot of other interesting facts about quorums, majority quorums and other things. It's a very interesting paper. Another good read in this space is Garcia-Molina and Barbara's <a href="https://www.cs.purdue.edu/homes/bb/cs542-20Spr/readings/reliability/How%20to%20assign%20Votes-JACM-garcia-molina.pdf">How to Assign Votes in a Distributed System</a>, which both does a better job than Peleg and Wool of defining the terms it uses, but also explores the general idea of assigning <em>votes</em> to machines, rather than simply forming quorums of machines. As you read it, it's worth remembering that it predates Paxos, and many of the terms might not mean what you expect.</li>
</ol>


</div></div>]]>
            </description>
            <link>http://brooker.co.za/blog/2021/01/06/quorum-availability.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25669327</guid>
            <pubDate>Thu, 07 Jan 2021 10:09:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mocking and testing event-driven architectures with Microcks and AsyncAPI]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25669287">thread link</a>) | @fmvilas
<br/>
January 7, 2021 | https://www.asyncapi.com/blog/microcks-asyncapi-part2 | <a href="https://web.archive.org/web/*/https://www.asyncapi.com/blog/microcks-asyncapi-part2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><img src="https://www.asyncapi.com/img/posts/microcks-asyncapi-part2/microcks-kafka-distribs.webp" alt="Post cover image"><p>On our <a href="https://www.asyncapi.com/blog/microcks-asyncapi-part1">first AsyncAPI blog post</a> we have introduced <a href="https://microcks.io/blog/microcks-1.0.0-release/">Microcks 1.0 General Availability (GA)</a> as a unique milestone for mocking and testing event-driven API like any other APIs through the support of AsyncAPI specification.</p><p>In case you missed it, we have already released <a href="https://microcks.io/blog/microcks-1.1.0-release/">version 1.1.0</a> in the meantime. This release includes some nice enhancements related to the topic of the day: <strong>Microcks + AsyncAPI use cases using Apache Kafka</strong>. This post will show you how Microcks is leveraging the AsyncAPI specification on Kafka in a very pragmatic and powerful approach: way beyond documentation or code generation! We will also go through the different business use-cases implemented by users integrating Microcks in their asynchronous API toolchain.</p><p>When we are talking about Kafka we mean all Kafka distributions translated into <em>the choice is yours</em>: from vanilla Apache upstream distribution, to enterprise products and also cloud providers’ managed distributions!</p><p><img src="https://www.asyncapi.com/img/posts/microcks-asyncapi-part2/microcks-kafka-distribs.webp" alt="microcks-kafka-distribs"></p><blockquote><p>By the way, we will be happy to have some QA <a href="https://github.com/microcks/microcks/blob/master/CONTRIBUTING.md">contributors and reports</a><undefined> on more brokers and AsyncAPI supported protocols <span role="img" aria-label="winking face">😉</span></undefined></p></blockquote><p>Before diving into AsyncAPI on Apache Kafka, let first see why simulating producers is a key project success factor.</p><h2 id="why-simulating-producers-is-a-key-project-success-factor">Why simulating producers is a key project success factor?</h2><p><undefined>As good developers, we are lazy - in a very good way <span role="img" aria-label="winking face">😉</span> - and hate to restart from scratch our beautiful code implementations due to misunderstanding with Product Owners. However, nowadays Product Owners adopted and love the </undefined><a href="https://www.forbes.com/sites/danpontefract/2018/09/15/the-foolishness-of-fail-fast-fail-often/">Fail-Fast Principle</a>. We can't rely on functional implementations to start beta testing with consumers, we should fail fast and make them change requirements before we start implementation.</p><p>Apart from generating frustrations, this above situation is also very inefficient from a cost and time to market point of view for the organization. </p><p>The contract-first approach is a wonderful way to create strong and efficient agreements between functional / business / product owners and developers! But it represents only a partial answer to the above situation</p><p><img src="https://www.asyncapi.com/img/posts/microcks-asyncapi-part2/time-money-quality.webp" alt="time-money-quality"></p><p>To avoid unnecessary work from developers and speed-up feedback gathering from consumers, simulation is the second part of the answer. That is why Microck's first use case and the killer feature is mocking!</p><p>These are some of the reasons why the way to do mocking with Microcks is highly scalable: </p><ul><li>We rely 100% on Product Owners contracts </li><li>We rely 100% on standards and specifications to describe contracts</li><li>We automatically generate all APIs mocks from contracts: no code!</li><li>We publish APIs mocks like real implementations using specifications examples </li><li>We centralize all contracts and are the single point of trust</li><li>We are always in sync with your repositories: no drift anymore!</li><li>We provide sandbox at scale. You can heavily stress tests your business rules. Remember, we are Kubernetes-native!</li></ul><p>This is why Microcks is the ultimate way to test, iterate and speed-up your APIs validations before asking developers to code the real implementation! And this certainly applies to asynchronous API on Kafka too: thanks to <a href="https://www.asyncapi.com/docs/specifications/2.0.0">AsyncAPI specification</a>.</p><p>Now let’s start with first feature: mocking asynchronous API.</p><h2 id="mocking-asynchronous-api-on-top-of-apache-kafka">Mocking asynchronous API on top of Apache Kafka</h2><p>This is how Microcks value proposition of accelerating Kafka asynchronous API simulation looks like:</p><p><img src="https://www.asyncapi.com/img/posts/microcks-asyncapi-part2/microcks-kafka-mocking.webp" alt="microcks-kafka-mocking"></p><p>In a very pragmatic approach, Microcks uses your AsyncAPI specification as the source of truth for your simulation. As soon as it is imported into Microcks, it manages to create a topic for your API version on the connected Kafka broker and starts publishing mock messages. Messages are published at a configured frequency and thus consumers immediately start receiving event messages as if it is published by a real application. Thanks to Microcks’ <a href="https://microcks.io/documentation/using/advanced/templates/">message templating</a> you can also easily include dynamic content in the sample messages.</p><p>Mocking event-driven architecture using Microcks is a game-changer as you do not need to write code nor set up complex infrastructure! Your consumers can receive messages in the minute. Testing some changes is just one commit away. You update the AsyncAPI specification in the Git repository and Microcks will take care of updating everything! It's even capable of providing and managing the Kafka infrastructure thanks to the excellent <a href="https://strimzi.io/">Strimzi.io</a> operator if you wish! See our <a href="https://microcks.io/documentation/installing/deployment-options/#everything-managed-by-microcks">Everything managed by Microcks</a><undefined> deployment option <span role="img" aria-label="rocket">🚀</span></undefined></p><p>Our second feature is testing or how to make your delivery lifecycle reliable.</p><h2 id="how-to-make-your-delivery-lifecycle-reliable">How to make your delivery lifecycle reliable?</h2><p>As the number of event producers and subscribers is exploding, managing changes and taking care of versioning compatibility is essential. And what about checking that business rules implying event triggering are correctly implemented? The fact it produces syntactically correct events and all this in a fully automated way based on each change and new commit in your source code repository?</p><p>Again this is all provided by Microcks thanks to its capability to interoperate with your CI/CD pipeline using our plugins for <a href="https://microcks.io/documentation/automating/jenkins/">Jenkins</a>, <a href="https://microcks.io/documentation/automating/tekton/">Tekton</a> or <a href="https://microcks.io/documentation/automating/cli/">any other CI pipeline technology like GitLab</a>. You'll typically use these plugins to trigger a Kafka test in Microcks.</p><p><img src="https://www.asyncapi.com/img/posts/microcks-asyncapi-part2/microcks-kafka-testing.webp" alt="microcks-kafka-testing"></p><p>In Microcks, testing Kafka endpoints means connecting to a remote Kafka topic on an existing broker in the organization, listening for incoming messages, and checking that received messages are valid against the event-based API schema that is referenced in your source of truth: the AsyncAPI specification. You can find further technical details on the blog post <a href="https://microcks.io/blog/apache-kafka-mocking-testing/">mocking and testing Apache Kafka API using Microcks</a>.</p><p>Testing of event-driven architecture is no longer a nightmare with Microcks! Microcks can connect to the Kafka brokers in your organization and tell you if the received messages are valid according to your specification. No drifting risks anymore or way to introduce regression in production! You'll drive and control everything from your pipeline.</p><p>What are the business use-cases of AsyncAPI? Where can you use Microcks as an essential part of your toolchain?</p><h2 id="business-use-cases-of-asyncapi">Business use-cases of AsyncAPI</h2><p>As said before, event-driven and asynchronous APIs are becoming mainstream because we truly understand the decoupling level - and thus power and agility - it brings within our products. We see the need for asynchronous APIs and Apache Kafka's presence as the de facto standard for message brokering - everywhere.</p><ul><li>In every business vertical: to decouple a recording action (registration, purchase, like) to a marketing reaction (CRM update, behavioral analysis, marketing notification, renewal process management, etc...)</li><li>In Governmental organizations: to synchronize complex and partitioned repositories using master data management and staging pipelines techniques</li><li>In Financial Services: to streamline the sharing of information between core platforms and distribution ecosystems of partners,</li><li>In Industry: to enable Industry 4.0 to use IoT and become more agile to respond to market unpredictability and improve quality,</li><li>Soon in every Citizen's life: to power tomorrow Smart Cities with IoT and enable smart real-time insights and decision making.</li></ul><p>These use cases come from companies using Microcks for simulating and testing their API implementation, and we are thankful to our users and community.</p><h2 id="summary">Summary</h2><p>We are convinced that cutting edge developers understand the purpose, usages, and efficiency of asynchronous mechanisms. To take all its advantages and especially to use an AsyncAPI contract-first approach: developers must work hand in hand with software architects, business/product owners within the enterprise. In our humble opinion, this is clearly a strong point of attention to improve collaboration between enterprise silos and take the quintessence of AsyncAPI specification for a contract-first approach using Microcks as the ultimate tooling for mocking and testing purposes. Please read our <a href="https://microcks.io/blog/continuous-testing-all-your-apis/">previous blog post on this topic</a><undefined> and share it with your software architects <span role="img" aria-label="winking face">😉</span></undefined></p><p>We hope these two Microcks features - mocking and testing - and application use-cases are clear and you now better understand our value proposition. Microcks proposes a very pragmatic and powerful usage of AsyncAPI specification: way beyond documentation or code generation! It allows you to speed-up and makes your delivery of Kafka event-driven architectures reliable.</p><p>The roadmap ahead is also full of exciting new features we are looking forward to: </p><ul><li>Continuing to make AsyncAPI full potential bloom through implementing multiple schema format supports - like Apache Avro - and <a href="https://github.com/asyncapi/asyncapi/issues/329">adding examples in the spec</a>,</li><li>Taking advantage of multiple protocol binding capabilities, releasing very soon a <a href="https://github.com/microcks/microcks/issues/293">MQTT implementation</a> to support our users and prospects on the IoT landscape,</li><li>Solidifying an initiative we started a long time ago about a shared repository of simulation and test suites for standards or products APIs...</li></ul><p>We are open and you can help make Microcks an even greater tool! Please spread the word, send us some love through <a href="https://github.com/microcks/microcks">GitHub stars</a>, follow us on <a href="https://twitter.com/microcksio">Twitter</a> or join our chat room on <a href="https://microcksio.zulipchat.com/login/">Zulip</a>.</p></article></div>]]>
            </description>
            <link>https://www.asyncapi.com/blog/microcks-asyncapi-part2</link>
            <guid isPermaLink="false">hacker-news-small-sites-25669287</guid>
            <pubDate>Thu, 07 Jan 2021 10:03:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Backup Interchange Format]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25669245">thread link</a>) | @ColinWright
<br/>
January 7, 2021 | https://blog.liw.fi/posts/2021/01/07/backup_interchange_format/ | <a href="https://web.archive.org/web/*/https://blog.liw.fi/posts/2021/01/07/backup_interchange_format/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article class="page">







<div id="pagebody">

<section id="content" role="main">
<p>Backup systems could do with a common backup interchange format.</p>
<p>Many version control systems support the git “<a href="https://www.git-scm.com/docs/git-fast-export">fast-export</a>” format. It’s a simple format for exporting the contents of a version control repository so that it can be imported into another. It’s a fundamental basis for converting from one system to another.</p>
<p>Backup systems could have something similar. It would be a good to everyone as it frees people to change backup systems without having their backup history locked into their old system. There are several scenarios in which this could be useful:</p>
<ul>
<li><p>Migrating to a new backup system that can’t read backups made with the old backup system.</p></li>
<li><p>Migrating from one backup repository to another, when a straight copy of the repository files is not possible, for whatever reason. For example, if there is no file-level access to the backup repository, only a constrained API.</p></li>
<li><p>Migrating to a new configuration that can’t read backups made with the old backup system. For example, changing encryption secrets in a system that only allows one per repository.</p></li>
</ul>
<p>My initial requirements for such a format:</p>
<ul>
<li><p>It’s as simple as possible while still working. It doesn’t need to be efficient, only efficient enough to be practical to use.</p></li>
<li><p>It’s possible to stream the format: something like <code>oldbackup export | newbackup import</code> should be possible.</p></li>
<li><p>It’s as independent of the backup systems as possible, and doesn’t embed unnecessary assumptions of the design or implementation of the system.</p></li>
</ul>
<p>My first sketch of a backup interchange format:</p>
<ul>
<li>A sequence of backup generations in order they were made.</li>
<li>Each generation has some metadata, and a list of files and hardlinhks.</li>
<li>Each file has an identifie unique to the generation, metadata (inode) and file content.</li>
<li>File content is a sequence of (offset, blob) pairs, to support sparse files.</li>
<li>Hard links are represented as (pathname, inode) pairs, where the first pathname is the name of the hard link, the</li>
<li>No attempt at de-duplication or re-using files from a previous generation.</li>
</ul>
<p>As YAML, this would look something like this:</p>

<p>YAML used here as an example, actual format may be something else.</p>

</section>







</div>



</article></div>]]>
            </description>
            <link>https://blog.liw.fi/posts/2021/01/07/backup_interchange_format/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25669245</guid>
            <pubDate>Thu, 07 Jan 2021 09:56:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cure for Imposter Syndrome]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25669154">thread link</a>) | @supr_strudl
<br/>
January 7, 2021 | https://hadalin.me/blog/cure-for-imposter-syndrome | <a href="https://web.archive.org/web/*/https://hadalin.me/blog/cure-for-imposter-syndrome">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
<p>Most likely, it’s only you who thinks you're not good enough. Your “operating system” has a bug that raises too many instances of <code>NotGoodEnoughException</code>.</p>
<p>Even if someone else thinks you're not good enough, it's probably because they have this bug too. People climb many hierarchies—power, money, popularity, etc., and in doing so, they advertently, but more often than not, inadvertently put other people down to lift themselves. Have this in mind when someone is rude to you.</p>
<p>How to fix this bug? The solution is not that hard, but it requires time + effort. What you have to do is first install the <code><a href="https://duckduckgo.com/?q=eckhart+tolle">mindfulness</a></code> module. This module interrupts the cognitive module each time NotGoodEnoughException is raised and puts the handling of this exception at the top of the priority queue. In a sense, good mindfulness could be compared to having decent server logs—situational awareness for the self.</p>
<p>If you think the above paragraph is written poorly, your “OS” probably raised NotGoodEnoughException just now ;)</p>
<p>You handle the exception as follows. Get familiar with the <code>/self/v2/mind</code> API endpoint and make a POST request with the following body each time NotGoodEnoughException is raised:</p>
<pre>{
  "youAreEnough": true
}
</pre>
<p>It might take weeks, months, or even years before the number of exceptions starts to drop, but it <em>does</em> drop. The reason this works is that it’s the real you, the one who experiences pain, joy, and life, the one above thoughts, emotions, and sensations, who decides to “program” your “kernel”. The key is within you.</p>
<p>To supercharge, consider running <code>install patience --save-dev</code> and opening an issue at the <code>friend/talk</code> repository.</p>
<p>Take care!</p>
</div></div>]]>
            </description>
            <link>https://hadalin.me/blog/cure-for-imposter-syndrome</link>
            <guid isPermaLink="false">hacker-news-small-sites-25669154</guid>
            <pubDate>Thu, 07 Jan 2021 09:41:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I closed my Facebook account, and you should too]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25669051">thread link</a>) | @garritfra
<br/>
January 7, 2021 | https://slashdev.space/posts/2021-01-07-delete-facebook | <a href="https://web.archive.org/web/*/https://slashdev.space/posts/2021-01-07-delete-facebook">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I know I should have done this a while ago, but with ever-increasing scandals about data privacy surrounding Facebook, I finally decided to get rid of it.</p><p>I haven't used the service in a long time anyway, but I always told myself "what if I needed the data later?", or "what if a friend contacted me, and I didn't respond?", "what if I missed the birthday of someone I'm close with?!". Well, according to my facebook inbox, the only messages I received lately were some random links from people I'm not really in touch with anymore. Birthdays? Do you think someone you haven't talked to in over three years will get mad at you, for forgetting their birthday? And regarding your data: you won't loose it! <a href="https://www.facebook.com/help/212802592074644">This guide</a> describes how you can download a copy of your data as html and/or json.</p><p>Go ahead and ask yourself: Is there anything holding you back from deleting your Facebook account? What would you loose? How often do you even use the service? Do the social benefits of Facebook <strong>really</strong> outweigh the negative aspects (privacy concerns, data collection, etc.)?</p><p>Comments? Drop a mail in my<!-- --> <a href="https://lists.sr.ht/~garritfra/public-inbox">public inbox</a>, or send me a message on<!-- --> <a href="https://matrix.to/#/@garrit:matrix.slashdev.space">Matrix</a>.</p></div></div>]]>
            </description>
            <link>https://slashdev.space/posts/2021-01-07-delete-facebook</link>
            <guid isPermaLink="false">hacker-news-small-sites-25669051</guid>
            <pubDate>Thu, 07 Jan 2021 09:28:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Can we afford to ignore Bitcoin?]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25669029">thread link</a>) | @Arturclancy
<br/>
January 7, 2021 | https://orujaliev.com/invest-in-bitcoin/ | <a href="https://web.archive.org/web/*/https://orujaliev.com/invest-in-bitcoin/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="mainContentOfPage">
		
<p><em>It is interesting again at the cryptocurrency market if you have missed the latest news. The price of Bitcoin has broken records of the three-year remoteness, with a rate of over $30,000. Opinions about the future of the coin are divided – some believe that we are facing another bubble. In contrast, others believe that the financial market will no longer be the same and that Bitcoin will be much more expensive in the long run. I admit I am not quite sure what is going on. But I am sure ignoring it is at least weird, so I tried to figure out a little bit about what is going on, and in this article, I am going to share my thoughts on whether it is worth invest in Bitcoin.</em></p>



<figure><img loading="lazy" width="1024" height="846" src="http://orujaliev.com/wp-content/uploads/2021/01/coindesk-BTC-chart-2021-01-05-1024x846.png" alt="Bitcoin to dollar rate - Should you invest in Bitcoin?" title="Bitcoin to dollar rate" srcset="https://orujaliev.com/wp-content/uploads/2021/01/coindesk-BTC-chart-2021-01-05-1024x846.png 1024w, https://orujaliev.com/wp-content/uploads/2021/01/coindesk-BTC-chart-2021-01-05-300x248.png 300w, https://orujaliev.com/wp-content/uploads/2021/01/coindesk-BTC-chart-2021-01-05-768x634.png 768w, https://orujaliev.com/wp-content/uploads/2021/01/coindesk-BTC-chart-2021-01-05-1536x1269.png 1536w, https://orujaliev.com/wp-content/uploads/2021/01/coindesk-BTC-chart-2021-01-05-700x578.png 700w, https://orujaliev.com/wp-content/uploads/2021/01/coindesk-BTC-chart-2021-01-05.png 1770w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption><strong><em>Bitcoin to dollar rate</em></strong></figcaption></figure>



<h2>Reasons to pay attention to Bitcoin</h2>



<p>If you have entirely closed financial affairs, enough life savings, and complete confidence in the reliability of the financial instruments you use, then you do not have to.</p>



<p>Similarly, if you believe that your daily needs are at the level you need at any time in your life, they will always be closed by your salary or business income. Namely, you are the kind of person who believes that there is real stability in our rapidly changing world with the regularly appearing “The Black Swan”.</p>



<p>Put, you either have enough money, or you have modest needs and indiscreet self-confidence. In that case, I guess you do not have to.</p>



<p>I am in a different situation. I do not believe in stability and see the absence of demand for many “lifelong professions” and the devaluation of savings and the meager pensions that people have worked for decades.</p>



<p>For that reason, I am interested in risk diversification. In professions, in businesses, in financial instruments. The latter today is the talk. I am willing to explore and consider any possibility to save the money I make and multiply it.</p>



<p>Bitcoin is such a tool. Subprime, perhaps with a foggy future – but a tool. And therefore – it is, at least, worthy of study.</p>



<h2>How to save money</h2>



<p>Some «experts» <a href="https://cointelegraph.com/news/top-6-bitcoin-price-predictions-to-watch-in-2021">claim</a> that the price of Bitcoin will reach $100,000, others forecast $300,000, of course, some say that even the figure of $1,000,000 for BTC is quite real. But what (and when, which is no less critical) will be the course, no one knows. All these statements are more like the publicity move of those who make them.</p>



<p>I am more interested in the other thing. When we talk about the Bitcoin rate, we peg it, for example, to US dollar. As we think it is the most reliable currency. But if we are talking about retaining the money for a long time, no financial advisor will ever advise you to keep all the money in it. The investment code indicates that it is necessary to buy different currencies and use other financial instruments (for example, stocks and bonds) to cover risks.</p>



<p>The dollar is rapidly going cheaper. Or everything becomes expensive. You can call it anything you want, but the point is the same. Everyone has examples. Some people rely on official statistics. I will bring out my life’s specifics by just looking at the significant expenses in my wallet. Ten years ago, the iPhone was sold for $499. A standard hotel room could be rented for $50. The price of real estate 20-30 years ago is not even worth remembering.</p>



<p>It is about inflation and about the complex interest that is often the problem. We may think that the numbers are changing slowly, but how in investment capitalisation of interest rates creates miracles and inflation produces a rapid depreciation of savings.</p>



<p>Let us talk about the US. The country with a strong economy, producing the dollar we are talking about. The average annual official <a href="https://www.usinflationcalculator.com/inflation/current-inflation-rates/">inflation</a> is 2.06%. Many may even say that it can be neglected. Perhaps. If it were not for the capitalization of interest. The purchasing power of $100 in 2000 is equal to the purchasing power of $150 in 2020. And that’s average, groceries have gone up less, and for example, education have gone up much more.</p>



<figure><img loading="lazy" width="1024" height="649" src="http://orujaliev.com/wp-content/uploads/2021/01/usdinflation-1024x649.png" alt="The purchasing power of the dollar considering «small» inflation 2% annual - Should you invest in Bitcoin?" title="The purchasing power of the dollar considering «small» inflation 2% annual - Should you invest in Bitcoin?" srcset="https://orujaliev.com/wp-content/uploads/2021/01/usdinflation-1024x649.png 1024w, https://orujaliev.com/wp-content/uploads/2021/01/usdinflation-300x190.png 300w, https://orujaliev.com/wp-content/uploads/2021/01/usdinflation-768x487.png 768w, https://orujaliev.com/wp-content/uploads/2021/01/usdinflation-1536x974.png 1536w, https://orujaliev.com/wp-content/uploads/2021/01/usdinflation-700x444.png 700w, https://orujaliev.com/wp-content/uploads/2021/01/usdinflation.png 1820w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption><strong><em><strong><em>The purchasing power of the dollar considering «small» inflation 2% annual&nbsp;</em></strong></em></strong></figcaption></figure>



<p>And so, again, back to the primary council on finance: to save, you must diversify risks. Real estate, gold, stocks – everyone chooses their instruments.</p>



<blockquote><p>We must remember – person who does not choose any financial instruments and keeps his dollars in bank account is getting poorer.</p></blockquote>



<p>The stock market has been considered a haven for many years. If you do not take a significant risk and do not try to overplay the market – it does help save, at least by covering inflation and, as a maximum allowing you to make money on investments.</p>



<p>But what we see today? Because of the Covid-19 pandemic, vast numbers of people were unemployed, and governments began to pay them various benefits. To cover the budget deficit, $3.5 trillion was <a href="https://www.usatoday.com/in-depth/money/2020/05/12/coronavirushow-u-s-printing-dollars-save-economy-during-crisis-fed/3038117001/">printed</a> only in the United States. Just think about the number of new money that was newly printed and put on the market. We will not even talk about the fact that the dollar <a href="https://www.investopedia.com/ask/answers/09/gold-standard.asp">has not been backed </a>by gold for 50 years.&nbsp;</p>



<p>What happened in the stock market in 2020 could not be imagined by even the most optimistic analyst. In a year of pandemics, mass unemployment, and stagnant economies, it grows like crazy.</p>



<figure><img loading="lazy" width="1024" height="655" src="http://orujaliev.com/wp-content/uploads/2021/01/dowjoneschart2020-1-1024x655.png" alt="Dow Jones index in 2020 - Should you invest in Bitcoin?
" title="Dow Jones index in 2020 - Should you invest in Bitcoin?" srcset="https://orujaliev.com/wp-content/uploads/2021/01/dowjoneschart2020-1-1024x655.png 1024w, https://orujaliev.com/wp-content/uploads/2021/01/dowjoneschart2020-1-300x192.png 300w, https://orujaliev.com/wp-content/uploads/2021/01/dowjoneschart2020-1-768x491.png 768w, https://orujaliev.com/wp-content/uploads/2021/01/dowjoneschart2020-1-1536x983.png 1536w, https://orujaliev.com/wp-content/uploads/2021/01/dowjoneschart2020-1-700x448.png 700w, https://orujaliev.com/wp-content/uploads/2021/01/dowjoneschart2020-1.png 1744w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption><em>Dow Jones index in 2020</em><br></figcaption></figure>



<p>There is no tourism. Restaurants are closed. The State prints and gives out money. People spend it on stocks. Now it’s so conveniently done on the mobile app that even regulators already have <a href="https://edition.cnn.com/2020/12/17/investing/robinhood-sec-settlement-deceptive-practices/index.html">questions</a> about this simplicity and gameplay.</p>



<p>People who never cared about stocks went to the stock market. And they started buying familiar brands. Economics? No, no one else cares. All that matters are the names that are in the public eye. Tesla’s case study is that the capitalization of the company has grown almost tenfold over the year. And its sales <a href="https://www.macrotrends.net/stocks/charts/TSLA/tesla/revenue">went</a> up…15 percent.</p>



<figure><img loading="lazy" width="1024" height="518" src="http://orujaliev.com/wp-content/uploads/2021/01/teslachart2020-2048x1035-1-1024x518.png" alt="Tesla stock price in 2020 - Should you invest in Bitcoin?" title="Tesla stock price in 2020 - Should you invest in Bitcoin?" srcset="https://orujaliev.com/wp-content/uploads/2021/01/teslachart2020-2048x1035-1-1024x518.png 1024w, https://orujaliev.com/wp-content/uploads/2021/01/teslachart2020-2048x1035-1-300x152.png 300w, https://orujaliev.com/wp-content/uploads/2021/01/teslachart2020-2048x1035-1-768x388.png 768w, https://orujaliev.com/wp-content/uploads/2021/01/teslachart2020-2048x1035-1-1536x776.png 1536w, https://orujaliev.com/wp-content/uploads/2021/01/teslachart2020-2048x1035-1-700x354.png 700w, https://orujaliev.com/wp-content/uploads/2021/01/teslachart2020-2048x1035-1.png 2048w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption><strong><em>Tesla stock price in 2020</em></strong></figcaption></figure>



<p>Whether there will be a collapse is not a valid question. A more appropriate question is when it will be. Even the most experienced experts are difficult to answer. Politicians have come into play, and the printing press is not yet scheduled to shut down. I do not doubt that there is a bubble in the stock market.</p>



<h2>And Bitcoin growth in 2020 is not a bubble?</h2>



<p>Now let us look at what is going on in the cryptocurrency market. At first glance, the situation there is remarkably similar to the stock market. Coins are rapidly expensive, and events are reminiscent of 2017. But there are several significant differences.</p>



<h3>Bitcoin has not risen in price due to media publications</h3>



<p>It only got on the news agenda after the price exceeded the three-year-old record. And if in 2017 the attention of «housewives» was focused on cryptocurrencies, today they do not invest in bitcoin – their focus is the stock market. In Google Trends, Bitcoin awareness has <a href="https://trends.google.com/trends/explore?date=today%205-y&amp;geo=US&amp;q=bitcoin">increased</a>, but it is by order of magnitude less than three years earlier.</p>



<figure><img loading="lazy" width="1024" height="361" src="http://orujaliev.com/wp-content/uploads/2021/01/bitcoingoogletrends-2048x721-1-1024x361.png" alt="Interest to Bitcoin in Google Trends - Should you invest in Bitcoin?" title="Interest to Bitcoin in Google Trends - Should you invest in Bitcoin?" srcset="https://orujaliev.com/wp-content/uploads/2021/01/bitcoingoogletrends-2048x721-1-1024x361.png 1024w, https://orujaliev.com/wp-content/uploads/2021/01/bitcoingoogletrends-2048x721-1-300x106.png 300w, https://orujaliev.com/wp-content/uploads/2021/01/bitcoingoogletrends-2048x721-1-768x270.png 768w, https://orujaliev.com/wp-content/uploads/2021/01/bitcoingoogletrends-2048x721-1-1536x541.png 1536w, https://orujaliev.com/wp-content/uploads/2021/01/bitcoingoogletrends-2048x721-1-700x246.png 700w, https://orujaliev.com/wp-content/uploads/2021/01/bitcoingoogletrends-2048x721-1.png 2048w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption><strong><em>Interest to Bitcoin in Google Trends</em></strong></figcaption></figure>



<h3>Institutional investors join the Bitcoin market</h3>



<p>The growth of 2020 is mainly due to the investment business entry. Quoted on the stock market, MicroStrategy also invest in bitcoin – company <a href="https://www.bloomberg.com/news/articles/2020-12-07/microstrategy-to-raise-400-million-to-buy-even-more-bitcoin">purchased</a> 38,250 btc this year (at current rates of $1 billion). The largest payment services, Stripe and PayPal, began working with this cryptocurrency. Square allows customers to use the cryptocurrency as payment, and PayPal <a href="https://newsroom.paypal-corp.com/2020-10-21-PayPal-Launches-New-Service-Enabling-Users-to-Buy-Hold-and-Sell-Cryptocurrency">permitted</a> customers to buy Bitcoin directly from their PayPal accounts.</p>



<p>More and more professional invest in Bitcoin. Even the conservative Ray Dalio (the CEO of one of the largest funds) recently stated that he might have been very categorical and not even right about the future of Bitcoin. “I need to look at the Bitcoin and study it more”, – he recently <a href="https://news.bitcoin.com/ray-dalio-bitcoin/">stated</a>. Cryptocurrencies are added to the portfolios of Ark Investment Management, Fidelity Investments, and other funds. And not just investments funds. Even some pension funds are <a href="https://www.coindesk.com/pension-funds-double-crypto-asset-exposure-in-morgan-creeks-fund-to-1">starting</a> to invest in Bitcoin a small portion of their capital.</p>



<h3>Bitcoin is an alternative</h3>



<p>As mentioned earlier, in 2020, everything around us is volatile. Everything is feverish. Somewhere, bubbles are blowing up; somewhere; economies are falling. And capital, again, is looking for diversification. Because there is a lot of money globally, even a tiny fraction of it going to Bitcoin can cause the too high growth we see right now. Growth is driven by investment demand.</p>



<h2>Why bitcoin?</h2>



<p>Even those who are not familiar with the subject of cryptocurrencies have heard that <a href="https://orujaliev.com/invest-in-bitcoin/">Bitcoin is not the only cryptocurrency</a>. There are thousands of cryptocurrencies. So why we talk about Bitcoin?</p>



<p>Bitcoin is finite. It is digital gold. Only much more convenient and liquid. The algorithm is programmed to make just 21 million coins. Now 18.5 million have been mined, but let us not forget that about 4 million are irretrievably lost according to various estimates. Theoretically, the algorithm can be modified, but to do so, 51% of the miners must join and vote for it. The situation is almost impossible because it will make their assets cheaper. </p>



<p>If you invest in bitcoin, bought one coin, you have and will have one. No State or politician can turn on the printing press and blur your share. Bitcoin is popular. There are hundreds of social networks globally, but Facebook owns the market because it overcame the critical group of users, and eventually, more people come there. Cryptocurrencies are similar. There are thousands coins. But <a href="https://www.tradingview.com/markets/cryptocurrencies/global-charts/">70 percent of all capitalization is Bitcoin</a>. If I may say so, it is a market standard. Attempts to create an alternative have been made and are underway, but none of them have succeeded precisely for that reason.</p>



<figure><img loading="lazy" width="1024" height="724" src="http://orujaliev.com/wp-content/uploads/2021/01/bitcoinmarketshare-1024x724.png" alt="The share of bitcoin in the cryptocurrency market exceeds 70%
" srcset="https://orujaliev.com/wp-content/uploads/2021/01/bitcoinmarketshare-1024x724.png 1024w, https://orujaliev.com/wp-content/uploads/2021/01/bitcoinmarketshare-300x212.png 300w, https://orujaliev.com/wp-content/uploads/2021/01/bitcoinmarketshare-768x543.png 768w, https://orujaliev.com/wp-content/uploads/2021/01/bitcoinmarketshare-1536x1087.png 1536w, https://orujaliev.com/wp-content/uploads/2021/01/bitcoinmarketshare-700x495.png 700w, https://orujaliev.com/wp-content/uploads/2021/01/bitcoinmarketshare.png 1764w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption><strong><em>The share of bitcoin in the cryptocurrency market exceeds 70%</em></strong></figcaption></figure>



<p>Bitcoin is convenient. No, it is not suitable to buy pizza in a restaurant. It has other challenges and opportunities. For example, it is useful to transfer large amounts of money between countries or to carry capital. You can have as many millions as you want in the account, fly to wherever you want …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://orujaliev.com/invest-in-bitcoin/">https://orujaliev.com/invest-in-bitcoin/</a></em></p>]]>
            </description>
            <link>https://orujaliev.com/invest-in-bitcoin/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25669029</guid>
            <pubDate>Thu, 07 Jan 2021 09:25:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Beijing-Shanghai Quantum Communication Network Put into Use]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25668921">thread link</a>) | @mardiyah
<br/>
January 7, 2021 | http://english.cas.cn/newsroom/archive/news_archive/nu2017/201703/t20170324_175288.shtml | <a href="https://web.archive.org/web/*/http://english.cas.cn/newsroom/archive/news_archive/nu2017/201703/t20170324_175288.shtml">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              <!--文章正文--><div><div><div><p><span lang="EN-US"><span size="+0"><p><span lang="EN-US"><span size="+0">The Beijing-Shanghai Backbone Network (BSBN), the world’s first long-distance quantum-secured communication route, was put into service on Aug. 30. It links the two cities with a highly-reliable and expandable secure communication expressway</span></span>.</p><p><span size="+0"><span size="+0"><span lang="EN-US">The node in Beijing will also cooperate with Micius, an experimental quantum satellite launched early last year, to lay the foundation for </span><span lang="EN-US">an integrated space-earth</span><span lang="EN-US"> quantum communication network as well as a global quantum communication network.</span></span></span>&nbsp;</p><p><span lang="EN-US"><span size="+0">BSBN was developed under the leadership of the University of Science and Technology of China (USTC). Several organizations have cooperated in the construction of BSBN, including the China Cable TV Network Co. Ltd., the Shandong Institute of Information and Communication Technology, the USTC Advanced Technology Institute, and the China Bank Regulatory Commission, among others.</span></span>&nbsp;</p><p><b><span lang="EN-US"><span size="+0">What is BSBN?</span></span></b>&nbsp;</p><p><span lang="EN-US"><span size="+0">BSBN, known officially as the National Demonstration Project of Verification and Application of Quantum Secure Communication between Beijing and Shanghai, has been called the “information security expressway.” </span></span>&nbsp;</p><p><span lang="EN-US"><span size="+0">The inter-city quantum communication line, which measures over 2000 km and comprises 32 relay stations, connects the cities of Beijing, Jinan, Hefei and Shanghai. Data can be transferred through the network with absolute security.</span></span>&nbsp;</p><p><span size="+0"><span size="+0"><span>“</span><span lang="EN-US">On the basis of the original fiber line, we utilized quantum key technology to give every message a unique encryption, and then transferred [the messages] through the traditional communication network,” said CHEN Yu’ao, a professor from the University of Science and Technology of China (USTC), and also Chief Designer of BSBN.</span></span></span>&nbsp;</p><p><span lang="EN-US"><span size="+0">Relay stations were built to solve the problem of signal attenuation during the transmission of the quantum key. In contrast with traditional transmission technology, BSBN’s relay stations will not receive then resend messages in transit. As a result, the whole transfer process will remain under direct control, according to CHEN.</span></span>&nbsp;</p><p><b><span lang="EN-US"><span size="+0">Promising Prospect</span></span></b>&nbsp;</p><p><span lang="EN-US"><span size="+0">A pilot project of BSBN was launched in January in Shanghai. The network uses quantum-secured fiber lines to connect seven financial institutes in Lujiazui’s Quantum Communication Industrial Park. Already, device adjustment for two of the institutes has been completed.</span></span>&nbsp;</p><p><span lang="EN-US"><span size="+0">Meanwhile, a command center and a big data center are also under construction.</span></span>&nbsp;</p><p><span lang="EN-US"><span size="+0">As part of the project, embedded control software for high-speed detection and quantum key distribution were developed for these centers, respectively.</span></span>&nbsp;</p><p><span lang="EN-US"><span size="+0">Several trials for the quantum communication network are now under way. As part of this process, data is transferred from the data center to another server in the same city, with quantum encryption by USTC. “Theoretically, it is impossible for data encrypted with quantum keys to be intercepted or interpreted. This is critically important for the transfer of financial data,” said REN Changqing, manager of the ICBC Data Center Network Department, one of the units involved in the trials.</span></span>&nbsp;</p><p><span lang="EN-US"><span size="+0">BSBN was constructed with fiber lines at relatively low cost, offering many promising application prospects. According to Prof. CHEN, BSBN can currently provide bandwidth of 100G, with a base project cost of less than RMB 600 million. In contrast, the current cost of comparable bandwidth is RMB 2 billion.</span></span>&nbsp;</p><p><span lang="EN-US"><span size="+0">More quantum communication lines will be built in the future to finally form a network, according to CHEN. “The changes will take place unnoticed; people will enjoy absolute information security without even realizing it,” he said.</span></span>&nbsp;</p><p><span lang="EN-US"><span size="+0">Prof. LU Zhaoyang, also from USTC, said he is expecting mass practical use of quantum communication within a few years. Traditional communication network hardware will be improved, rather than replaced. By installing quantum encrypting devices such as single photon detectors and quantum gateways on both the sender and receiver of the transmission, traditional communication networks can also conduct quantum communication, with obvious security improvements.</span></span>&nbsp;</p></span></span></p></div></div></div><!--文章正文-->

<!--<img src="../../../../../images/z19_contact_img.jpg" />-->
<!--<h5 class="xl_imgtxt">German Scientist Sees Unprecedented Opportunities in China</h5>-->

            </div></div>]]>
            </description>
            <link>http://english.cas.cn/newsroom/archive/news_archive/nu2017/201703/t20170324_175288.shtml</link>
            <guid isPermaLink="false">hacker-news-small-sites-25668921</guid>
            <pubDate>Thu, 07 Jan 2021 09:10:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Avro, Kafka and the Schema Registry: Clearing Things Up]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25668916">thread link</a>) | @dhet
<br/>
January 7, 2021 | https://davidhettler.net/blog/avro-kafka-schema-registry/ | <a href="https://web.archive.org/web/*/https://davidhettler.net/blog/avro-kafka-schema-registry/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
        <header>
          
          
            <p> 




  10 minute read

</p>
          
          <p>
          <strong>Demystifying Avro and the secret schema registry protocol</strong>
          </p>
        </header>
      

      <section itemprop="text">
        
        <p>From a bird’s-eye view, Avro is a binary serialization format just like many others: structured data can be serialized into a compact binary format to speed up the transport of data and to save storage space. However, when you take a closer look at Avro, fundamental differences to other established serialization schemes like Protobuf or Thrift become evident. In practice, those differences manifest themselves in a comparatively high compression ratio on the one hand, but an increase in complexity on the other.</p>

<p>Especially when employed in a distributed system, where serialized data is pushed over the wire, dealing with Avro becomes tricky. In particular, the concept of <strong>schema registries</strong> seems to be a common cause of confusion.</p>

<p>Everybody who has worked with an Avro/Kafka setup has probably at some point wondered:</p>
<ul>
  <li>When in the application’s lifecycle should a schema be registered?</li>
  <li>When is a schema pulled from the schema registry?</li>
  <li>When does the compatibility check take place?</li>
  <li>Why do I even need to pull a schema when the schema is already baked into the application?</li>
  <li>Why did my application crash with a deserialization exception again?</li>
  <li>Can we use JSON, please?</li>
</ul>

<p>This blog post may not have an answer to all of these questions but it’s a good starting point if you want to find out what goes on under the covers.</p>

<h2 id="whats-the-point">What’s the point?</h2>
<p>Why are schema registries a thing? And why do you hear the term mostly in the context of Avro and not so much in the context of, say, Protobuf? 
In order to answer this we first have to understand how Avro is different from other protocols. One of the key differences is that binary protocols such as Protobuf and Thrift rely on <strong>tags</strong> as means to match byte sequences to fields, whereas in Avro, such a concept does not exist.</p>

<h3 id="tags-vs-no-tags">Tags vs. no tags</h3>
<p>Tags are a way of mapping each field of a schema to a unique number, an ID. Within a serialized record, we can refer to a field by its ID and not say, by it’s name as it is the case for JSON. The result is that the serialized byte sequence is a lot more concise (compare a single integer to variable-length string). When the deserializer traverses a binary record and encounters a tag then it knows that the byte sequence that follows belongs to the field associated with that tag.</p>

<p>Here’s an example…</p>

<figure>
  <img src="https://davidhettler.net/assets/images/protobuf.png" alt="A serialized Protobuf record and its associated schema to demonstrate the use of tags">
  
    <figcaption>
      A serialized Protobuf record and its associated schema

    </figcaption></figure>

<p>On the left-hand side, you can see a Protobuf schema for the type “Animal” with three tags: the tags 1, 2 and 3 correspond to the fields “name”, “legs” and “hasTail”, respectively. On the right hand side, you can see a record which was serialized with that schema. We easily find that the animal in question is named “Lucy”, has four legs and a tail. You don’t have to understand every detail of the binary output, just know that the tags (marked in orange) tell the deserializer which bytes correspond to which field. This is important because the fields in the byte sequence are not in the same order as they were defined in the schema.</p>

<p>A disadvantage of tags is that they take up quite a bit of space (in the case of Protobuf it’s one byte per tag). In the image above, all bytes related to “meta data” are marked in grey, the remaining white boxes are the actual payload. You can see that the ratio between meta data (overhead) and payload data is not ideal. Can’t we reduce the number of grey boxes, e.g. by getting rid of tags? With Avro, we can. Avro does not rely on tags to identify fields. Instead, in the serialized byte sequence, all fields are appended back to back.</p>

<p>Here’s is the Avro equivalent of the Lucy example:</p>

<figure>
  <img src="https://davidhettler.net/assets/images/avro-record.png" alt="A serialized Avro record and its associated schema to demonstrate the use of tags">
  
    <figcaption>
      A serialized Avro record and its associated schema

    </figcaption></figure>

<p>Again, on the left hand side we see the schema, the <em>reader’s</em> schema to be precise. On the right hand side, the serialized record.</p>

<p>The first thing you might notice is that the record is quite a bit more compact. It takes up 30% less space than the Protobuf equivalent: 7 bytes vs. 10 bytes. The field values are marshaled byte-after-byte and there’s a lot less meta data within the record (fewer grey boxes).</p>

<p>Now you might be wondering: how does the deserializer know which byte sequence belongs to which field when there is no way of identifying the fields? How do we know that Lucy has four legs and not just one? Just by looking at the reader’s schema we cannot possibly know. In order to find out we need to look at the schema which the <strong>writer</strong> used when serializing the record. With both schemas side-by-side, we can make a comparison and find out the correct order of the fields.</p>

<figure>
  <img src="https://davidhettler.net/assets/images/side-by-side.png" alt="The writer's schema on the left and the reader's schema on the right. The order of records is mixed up.">
  
    <figcaption>
      Comparing the writer’s and the reader’s schema side-by-side

    </figcaption></figure>

<p>The order is all mixed up. According to the writer, <code>hasTail</code> should be at position one whereas according to the reader, it should be at position three, etc. But this is not a problem since the reader now has both schemas, they can reorder the fields and deserialize the record.</p>

<p>This approach, however, poses another problem: <strong>How does a reader know the writer’s schema?</strong> Here’s where the schema registry comes in.</p>

<h3 id="schema-registry-to-the-rescue">Schema registry to the rescue</h3>
<p>As the name suggests, a schema registry is a store for schemas. It provides an interface that allows you to retrieve and register schemas and check each of the schemas for compatibility. Effectively, it is nothing more than a CRUD application with a RESTful API and a persistent storage for schema definitions. Within the schema registry, each schema is assigned a unique ID. The reader can simply query the schema registry for the writer’s schema ID and retrieve the schema definition.</p>

<p>Now, we still haven’t clarified how the writer tells the reader <em>which</em> schema was used for serialization. There are several ways to do this. In the context of Kafka, there is one established method which relies on the convention that the writer <strong>prepends each serialized record with its respective schema ID</strong> before it is sent over the wire. The reader can then parse the first few bytes to find out the schema ID and ask the schema registry for the schema definition. Only then, the reader can determine schema compatibility, reorder the schema’s fields and start deserializing.</p>

<p>I know this might be a bit confusing (at least it was for me) so let’s have a look at an example.</p>

<h2 id="the-protocol">The protocol</h2>
<p>In this example scenario, we’ll look at a publisher who wants to write the Avro-serialized message “Foo” to the topic “my_topic” and a subscriber who wants to read that record.</p>

<figure>
  <img src="https://davidhettler.net/assets/images/example.png" alt="The example scenario expressed as diagram. A publisher sends a message to a subscriber over a Kafka topic.">
  
    <figcaption>
      An example scenario

    </figcaption></figure>

<h3 id="the-writers-side">The writer’s side</h3>

<p>Let’s first have a look at the left half of the image and take the writer’s perspective.</p>

<figure>
  <img src="https://davidhettler.net/assets/images/publisher.png" alt="A diagram depicing the protocol flow from the publisher's perspective.">
  
    <figcaption>
      The writer’s side

    </figcaption></figure>

<ol>
  <li>So we want to write the message “Foo” to the topic “my_topic”. While developing the application, we already determined the schema that we want to use. So technically, we could already serialize the record and publish it. Except, we can’t. Remember: With Avro, we need to signal which schema was used for serialization so that readers can check for compatibility and deserialize. In order to do this, we need the schema’s unique ID. How do we know the correct schema ID? Only the schema registry knows, so let’s ask it.</li>
  <li>We ask the schema registry: “Hey, I want to publish a record to “my_topic” using <em>this particular</em> schema. Is that alright, and if so could you tell me which schema ID to use?”. We do this by calling the <a href="https://docs.confluent.io/current/schema-registry/develop/api.html#post--subjects-(string-%20subject)-versions">API’s registration endpoint</a>. The endpoint expects an Avro schema in the request body. We’re going to put the schema we planned to use inside of it.</li>
  <li>The schema registry receives the request and looks up the schema in its persistent storage (a log-compacted topic named “_schemas”). If no schema is yet registered for the topic (what I refer to as “topic” is actually “subject” in schema registry terms) then the schema is registered and persisted.</li>
  <li>The schema registry compares the schema that it just looked up with the schema that we POSTed. If the schemas are incompatible according to <a href="https://docs.confluent.io/current/schema-registry/avro.html#schema-evolution-and-compatibility">Avro’s schema compatibility rules</a>, a client error (409) is returned to us. But in this example we’re good, the schemas are compatible and the schema ID is returned. Let’s assume that the ID is “5”.</li>
  <li>Great, so we have green light to use our schema for serialization. We serialize the record and find its binary repesentation is “<code>06 46 6F 6F</code>”.</li>
  <li>Now we can prepend the message with the schema ID and publish the record. Off we go!</li>
</ol>

<h3 id="the-readers-side">The reader’s side</h3>

<p>Now let’s look at the other half of the image and slip into the role of the consumer.</p>

<figure>
  <img src="https://davidhettler.net/assets/images/subscriber.png" alt="A diagram depicing the protocol flow from the subscriber's perspective.">
  
    <figcaption>
      The reader’s side

    </figcaption></figure>

<ol>
  <li>As a consumer we’re notified about a new record in the “my_topic” topic that the writer previously published to. How do we deserialize the record? We already <em>know</em> which schema to use for deserialization: while writing the application we defined that “for <em>this</em> particular topic we use <em>that</em> particular schema”. But why can’t we just use our own schema and be done with it? The answer is that, again, <strong>Avro needs both the writer and the reader schema in order to identify which bytes correspond to which field</strong> and to determine whether the schemas are compatible. So we need to retrieve the writer’s schema from the schema registry. We look at the first few bytes of the message and discover that the writer used the schema ID “5”.</li>
  <li>We ask the schema registry which schema is associated with schema “5” by calling the corresponding <a href="https://docs.confluent.io/current/schema-registry/develop/api.html#get--schemas-ids-int-%20id">API endpoint</a>.</li>
  <li>Again, a lookup in the persistent store is made.</li>
  <li>The endpoint returns the schema definition associated with schema ID 5.</li>
  <li>We compare the returned schema with the schema that we planned to use. By looking at the two schemas side-by-side we can identify each field and also determine whether the schemas are compatible. If everything is ok we can finally deserialize the record and read the original message.</li>
</ol>

<p><strong>Note…</strong></p></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://davidhettler.net/blog/avro-kafka-schema-registry/">https://davidhettler.net/blog/avro-kafka-schema-registry/</a></em></p>]]>
            </description>
            <link>https://davidhettler.net/blog/avro-kafka-schema-registry/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25668916</guid>
            <pubDate>Thu, 07 Jan 2021 09:09:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[dd, bs= and why you should use conv=fsync]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25668802">thread link</a>) | @mg
<br/>
January 7, 2021 | https://abbbi.github.io/dd/ | <a href="https://web.archive.org/web/*/https://abbbi.github.io/dd/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>This story starts with me having to simulate a faulty disk device for testing.
The Linux Kernel Device mapper is a good solution for this, so i created a
faulty device with a simple file backend:</p>

<figure><pre><code data-lang="bash"> <span>truncate</span> <span>-s</span> 1G /tmp/baddisk
 losetup /dev/loop2 /tmp/baddisk
 dmsetup create baddisk <span>&lt;&lt;</span> <span>EOF</span><span> 
    0 6050 linear /dev/loop2 0
    6050 155 error
    6205 2090947 linear /dev/loop2 6205 
 EOF</span></code></pre></figure>

<p>These commands setup a new device on <em>/dev/mapper/baddisk</em> with <em>1GB</em> of size.
Starting from sector <em>6050</em>, there are <em>155</em> faulty sectors, where any write and
read operation should cause I/O errors.</p>

<p>I went on and used <em>dd</em> to write to the device, as the first faulty block
should start around <em>3MB</em>, i used the following command:</p>

<figure><pre><code data-lang="bash">  <span>dd </span><span>if</span><span>=</span>/dev/zero <span>of</span><span>=</span>/dev/mapper/baddisk <span>bs</span><span>=</span>4096 <span>count</span><span>=</span>1000
  4096000 bytes <span>(</span>4.1 MB, 3.9 MiB<span>)</span> copied, 0.0107267 s, 382 MB/s</code></pre></figure>

<p>To my surprise, the command succeeded. I assumed some error in my setup and
after re-creating the device mapper target, i tried again. This time with the
following command:</p>

<figure><pre><code data-lang="bash"> <span>dd </span><span>if</span><span>=</span>/dev/zero <span>of</span><span>=</span>/dev/mapper/baddisk
 <span>dd</span>: writing to <span>'/dev/mapper/baddisk'</span>: Input/output error
 3096576 bytes <span>(</span>3.1 MB, 3.0 MiB<span>)</span> copied, 0.0238947 s, 130 MB/s</code></pre></figure>

<p>Nice, the device behaves as expected! While taking notes in another terminal
and switching back and forth workspaces, i issued the following command again:</p>

<figure><pre><code data-lang="bash">  <span>dd </span><span>if</span><span>=</span>/dev/zero <span>of</span><span>=</span>/dev/mapper/baddisk <span>bs</span><span>=</span>4096 <span>count</span><span>=</span>1000
  4096000 bytes <span>(</span>4.1 MB, 3.9 MiB<span>)</span> copied, 0.0107267 s, 382 MB/s</code></pre></figure>

<p>What? It succeeded writing <em>4.1MB</em> of data to a faulty segment of the disk
which should clearly fail! This was strange, but still, after many attempts
with this command writing to the complete device until it got end of space, no
I/O errors were reported by <em>dd</em>.</p>

<p>Looking at the <em>dmesg</em> output, the kernel correctly reported errors with the
underlying device:</p>

<figure><pre><code data-lang="bash"> Buffer I/O error on dev dm-3, logical block 757, lost async page write
 <span>[</span>..]</code></pre></figure>

<p>And running <em>badblocks</em> on the device also correctly reported them.</p>

<p><em>Why</em> does dd not report this error?</p>

<p>The difference between the commands is the used block size, so i assumed some
caching beeing the cause for this situation, or maybe dd opening the file with
different flags like O_DIRECT or O_SYNC if smaller block sizes are used?</p>

<p>I straced the <em>dd</em> command and the openat/write and close functions behaved
exacly the same, this time i used a <em>5MB</em> block size for simpler debugging:</p>

<figure><pre><code data-lang="bash"> openat<span>(</span>AT_FDCWD, <span>"/dev/mapper/baddisk"</span>, O_WRONLY|O_CREAT|O_TRUNC, 0666<span>)</span> <span>=</span> 3
 write<span>(</span>1, <span>"</span><span>\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0</span><span>"</span>..., 5242880<span>)</span> <span>=</span> 5242880
 close<span>(</span>1<span>)</span>                                <span>=</span> 0</code></pre></figure>

<p>The strace output shows that the succeeding command opens the file without any
notable difference to the command writing with 512 bytes block size.  The write
and close functions return with no error whatsoever. <em>dd</em> simply does not
notice the data loss while writing to the storage!</p>

<p>Making <em>dd</em> use the <em>O_DIRECT</em> flag during file open, or the <em>O_SYNC</em> option
catches the error:</p>

<figure><pre><code data-lang="bash"> <span>dd </span><span>if</span><span>=</span>/dev/zero <span>of</span><span>=</span>/dev/mapper/baddisk <span>bs</span><span>=</span>5M <span>oflag</span><span>=</span>direct
 <span>dd</span>: error writing <span>'/dev/mapper/baddisk'</span>: Input/output error</code></pre></figure>

<p>What is the reason for this? I assume dd, with its standard block size of 512
bytes does not the hit the linux kernels buffered I/O. And with bigger block
sizes, the I/O becomes buffered, async, and as it stands, dd as user space
application does not validate the write operation (using fsync) to notice
errors during buffered I/O operations by default.</p>

<p>This leads us to my next finding: “the linux fsync() gate” that dates back to
2018, starting with the following question on stackoverflow:</p>

<p><a href="https://stackoverflow.com/questions/42434872/writing-programs-to-cope-with-i-o-errors-causing-lost-writes-on-linux">Writing programs to cope with I/O errors causing lost writes on Linux
</a></p>

<p>And resulting LWN articles:</p>

<p><a href="https://lwn.net/Articles/724307/">Improved block-layer error handling</a></p>

<p><a href="https://lwn.net/Articles/752063/">PostgreSQL’s fsync() surprise</a></p>

<p>which provide great insight into the linux kernels error handling and how these
errors are upstreamed to user space applications while writing data to faulty
devices.</p>

<p>Long story short: If one uses <em>dd</em> with a bigger block size <em>(&gt;= 4096)</em>, be
sure to use either the <em>oflag=direct</em> or <em>conv=fsync</em> option to have proper
error reporting while writing data to a device. I would prefer <em>conv=fsync</em>, dd
will then <em>fsync()</em> the file handle once and report the error, without having
the performance impact which <em>oflag=direct</em> has.</p>

<figure><pre><code data-lang="bash"><span>dd </span><span>if</span><span>=</span>/dev/zero <span>of</span><span>=</span>/dev/mapper/baddisk <span>bs</span><span>=</span>4096 <span>count</span><span>=</span>1500 <span>conv</span><span>=</span>fsync
<span>dd</span>: fsync failed <span>for</span> <span>'/dev/mapper/baddisk'</span>: Input/output error</code></pre></figure>


  </div></div>]]>
            </description>
            <link>https://abbbi.github.io/dd/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25668802</guid>
            <pubDate>Thu, 07 Jan 2021 08:50:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pest PHP v1.0 has been released]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25668737">thread link</a>) | @nunomaduro
<br/>
January 7, 2021 | https://nunomaduro.com/pest-v1-released/ | <a href="https://web.archive.org/web/*/https://nunomaduro.com/pest-v1-released/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<p>After 400+ commits, 3 betas, seven months - and endless hours of open-source contributions - <a href="https://pestphp.com/"><strong>PEST</strong></a> has finally reached its first stable public release. 🥳</p><p>Of course, it would not have been possible without all the community support.</p><blockquote>No worries, upgrading to 1.0 takes 2 minutes: <a href="https://pestphp.com/docs/upgrade-guide"><strong>Upgrade Guide</strong></a>.</blockquote><p><strong>Pest is a Testing Framework</strong> with a focus on simplicity. It was carefully crafted to bring the joy of testing to PHP. Check the website: <a href="https://pestphp.com/"><strong>pestphp.com</strong></a>. While in beta, over seven months we released three beta versions before the stable v1.0 release:</p><p><strong>v0.1</strong> - May 20, 2020: PEST got open-sourced under the <a href="https://opensource.org/licenses/MIT">MIT license</a>. Besides the new elegant testing API with a focus on simplicity, it added a new testing output, coverage report in the terminal, higher-order testing, and more. The release got featured in important websites and newsletters such as <a href="https://laravel-news.com/pestphp-released-as-open-source">Laravel News</a>. Besides, <a href="https://twitter.com/michaeldyrynda">Michael Dyrynda</a> created a YouTube series called <a href="https://laravel-news.com/pestphp-video-series">Introducing PEST PHP</a>.</p><figure><a href="https://github.com/pestphp/pest"><div><p>pestphp/pest</p><p>Pest is an elegant PHP Testing Framework with a focus on simplicity - pestphp/pest</p><p><img src="https://github.githubassets.com/favicons/favicon.svg"><span>GitHub</span></p></div><p><img src="https://repository-images.githubusercontent.com/246674913/a1b60f80-9a3c-11ea-9740-7ff5bec21d98"></p></a></figure><p><strong>v0.2</strong> - Jun 14, 2020: PEST got a plugin API, and multiple plugins were added to the ecosystem: Laravel, Livewire, Faker, Snapshots, and more. Also, a <a href="https://laravel-news.com/pestphp-phpstorm">PHPStorm Plugin</a> was added and it got featured in the <a href="https://blog.jetbrains.com/phpstorm/2020/10/how-the-pest-phpstorm-plugin-will-improve-your-testing-workflow/">JetBrains Blog</a>. Also, PEST got covered in conference talks, including at Laracon EU: <a href="https://youtu.be/lEvau6CgqPE?t=125">Introducing PEST - Nuno Maduro</a>.</p><figure><iframe width="200" height="113" src="https://www.youtube.com/embed/lEvau6CgqPE?start=126&amp;feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><p><strong>v0.3</strong> - Aug 27, 2020: PEST got the <a href="https://pestphp.com/docs/expectations">Expectation API</a>, a brand new documentation <a href="https://pestphp.com/docs/installation">website</a>, and enterprise sponsors <a href="https://scoutapm.com/">ScoutAPM</a> and <a href="https://akaunting.com/">Akaunting</a>. Meanwhile, PEST gathered a <a href="https://discord.com/invite/bMAJv82">Discord</a> community server with more than 350 people, 2k stars on <a href="https://github.com/pestphp/pest">Github</a>, and 220k downloads on <a href="https://packagist.org/packages/pestphp/pest">Packagist</a>.</p><figure><img src="https://nunomaduro.com/content/images/2021/01/Screenshot-2021-01-06-at-22.52.11.png"><figcaption>pestphp/pest install statistics</figcaption></figure><p><strong>v1.0</strong> - Jan 3, 2021: PEST got its first stable release, and hopefully a bright future. 🚀</p><p><strong>What’s next?</strong> As v1.0 usually suggests, PEST will stay stable for the foreseeable future and the library is ready for production use. Future development will focus more on learning resources such as videos, tutorials, and examples.</p><p><strong>Get involved!</strong> Pest is a community project, there are many <a href="https://github.com/pestphp">opportunities to contribute</a> to the whole ecosystem.</p><ul><li>Explore the docs: <a href="https://pestphp.com/"><strong>pestphp.com</strong> »</a></li><li>Follow us on Twitter: <a href="https://twitter.com/pestphp"><strong>@pestphp</strong> »</a></li><li>Join us on the Discord Server: <a href="https://discord.gg/bMAJv82"><strong>discord.gg/bMAJv82</strong> »</a></li></ul>
			</section></div>]]>
            </description>
            <link>https://nunomaduro.com/pest-v1-released/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25668737</guid>
            <pubDate>Thu, 07 Jan 2021 08:41:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Brief Guide to CLOS]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25668692">thread link</a>) | @Tomte
<br/>
January 7, 2021 | http://www.n-a-n-o.com/lisp/cmucl-tutorials/CLOS-guide.html | <a href="https://web.archive.org/web/*/http://www.n-a-n-o.com/lisp/cmucl-tutorials/CLOS-guide.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<img src="http://www.n-a-n-o.com/lisp/cmucl-tutorials/prev.gif" alt="Previous">
<a href="http://www.n-a-n-o.com/lisp/cmucl-tutorials/CLOS-guide-1.html"><img src="http://www.n-a-n-o.com/lisp/cmucl-tutorials/next.gif" alt="Next"></a>
<img src="http://www.n-a-n-o.com/lisp/cmucl-tutorials/toc.gif" alt="Contents">
<hr>


<h2>Jeff Dalton, University of Edinburgh, &lt;J.Dalton@ed.ac.uk&gt;
         Modified by  Bruno Haible &lt;haible@ma2s2.mathematik.uni-karlsruhe.de&gt;
          and Peter Van Eynde &lt;s950045@uia.ua.ac.be&gt;</h2>
<h2><a name="toc1">1.</a> <a href="http://www.n-a-n-o.com/lisp/cmucl-tutorials/CLOS-guide-1.html">Conventions </a></h2>

<h2><a name="toc2">2.</a> <a href="http://www.n-a-n-o.com/lisp/cmucl-tutorials/CLOS-guide-2.html">Defining classes.</a></h2>

<h2><a name="toc3">3.</a> <a href="http://www.n-a-n-o.com/lisp/cmucl-tutorials/CLOS-guide-3.html">Instances</a></h2>

<h2><a name="toc4">4.</a> <a href="http://www.n-a-n-o.com/lisp/cmucl-tutorials/CLOS-guide-4.html">Inheritance of slot options</a></h2>

<h2><a name="toc5">5.</a> <a href="http://www.n-a-n-o.com/lisp/cmucl-tutorials/CLOS-guide-5.html">Multiple inheritance</a></h2>

<h2><a name="toc6">6.</a> <a href="http://www.n-a-n-o.com/lisp/cmucl-tutorials/CLOS-guide-6.html">Generic functions and methods</a></h2>

<h2><a name="toc7">7.</a> <a href="http://www.n-a-n-o.com/lisp/cmucl-tutorials/CLOS-guide-7.html">Method combination.</a></h2>

<h2><a name="toc8">8.</a> <a href="http://www.n-a-n-o.com/lisp/cmucl-tutorials/CLOS-guide-8.html">Quick reference</a></h2>
<ul>
<li><a href="http://www.n-a-n-o.com/lisp/cmucl-tutorials/CLOS-guide-8.html#ss8.1">8.1 Defining a class</a>
</li><li><a href="http://www.n-a-n-o.com/lisp/cmucl-tutorials/CLOS-guide-8.html#ss8.2">8.2 Slot descriptions</a>
</li><li><a href="http://www.n-a-n-o.com/lisp/cmucl-tutorials/CLOS-guide-8.html#ss8.3">8.3 Making instances</a>
</li><li><a href="http://www.n-a-n-o.com/lisp/cmucl-tutorials/CLOS-guide-8.html#ss8.4">8.4 Method definitions</a>
</li><li><a href="http://www.n-a-n-o.com/lisp/cmucl-tutorials/CLOS-guide-8.html#ss8.5">8.5 Some functions</a>
</li></ul>


<hr>
<img src="http://www.n-a-n-o.com/lisp/cmucl-tutorials/prev.gif" alt="Previous">
<a href="http://www.n-a-n-o.com/lisp/cmucl-tutorials/CLOS-guide-1.html"><img src="http://www.n-a-n-o.com/lisp/cmucl-tutorials/next.gif" alt="Next"></a>
<img src="http://www.n-a-n-o.com/lisp/cmucl-tutorials/toc.gif" alt="Contents">


</div>]]>
            </description>
            <link>http://www.n-a-n-o.com/lisp/cmucl-tutorials/CLOS-guide.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25668692</guid>
            <pubDate>Thu, 07 Jan 2021 08:36:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AI Melody Generator]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25668437">thread link</a>) | @rcarmo
<br/>
January 6, 2021 | https://dopeloop.ai/melody-generator/?s=9318976178695285&i=102 | <a href="https://web.archive.org/web/*/https://dopeloop.ai/melody-generator/?s=9318976178695285&i=102">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="app">
      <div id="loader">
        <p><img src="https://dopeloop.ai/melody-generator/img/icon.png" id="logo"></p>
        
        <p>
          This app is a random midi melody generator which you can use to create melodies.
          The melodies are procedurally generated and are royalty free.
          You are free to download the midi files and use them in your own music.
        </p>
        <p><a href="https://dopeloop.ai/">get more music apps</a>
      </p></div>
    </div></div>]]>
            </description>
            <link>https://dopeloop.ai/melody-generator/?s=9318976178695285&amp;i=102</link>
            <guid isPermaLink="false">hacker-news-small-sites-25668437</guid>
            <pubDate>Thu, 07 Jan 2021 07:53:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[About tray: a casual personal space on the internet]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25668423">thread link</a>) | @polm23
<br/>
January 6, 2021 | https://tray.club/@bgdotjpg/7946803587 | <a href="https://web.archive.org/web/*/https://tray.club/@bgdotjpg/7946803587">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://tray.club/@bgdotjpg/7946803587</link>
            <guid isPermaLink="false">hacker-news-small-sites-25668423</guid>
            <pubDate>Thu, 07 Jan 2021 07:51:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google launches QuestionHub to tackle niche and long tail keywords]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25667807">thread link</a>) | @rukshn
<br/>
January 6, 2021 | https://ruky.me/2021/01/07/google-launches-question-hub-to-tackle-niche-and-long-tail-keyword-queries/ | <a href="https://web.archive.org/web/*/https://ruky.me/2021/01/07/google-launches-question-hub-to-tackle-niche-and-long-tail-keyword-queries/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>You are able to find answers to almost all common questions on Google. But there are some areas where Google fails to provide good answers.</p>
<p>Personally or me when it comes to looking for an answer for a highly technical question in medicine, Google doesn’t do well in providing good answers.</p>
<p>Most of the results are not directing me to pages that I’m looking for, or they show me research articles that are not scientifically validates or are not included in the guidelines. So both occasions are not valuable for me.</p>
<p>But the answers can be found in text books if you can look hard enough. The answer is not available on Google not because that there is an answer, but because either no one has put the answer to the internet or not discovered by Google.</p>
<p>Yes, highly niche searches may not have a good market, because doctors and medical students looking for answers does not count for a huge traffic.</p>
<p><strong>But still if someone wants to build a good search engine, a good starting point maybe to look for a very niche field where Google is not performing well, and build on top of it.</strong></p>
<h2>QuestionHub by Google</h2>
<p>Google also maybe understanding the fact that that their systems and AI is not good enough to find answers to some highly specific questions or long tail keywords.</p>
<p><a rel="noreferrer noopener" href="https://questionhub.withgoogle.com/intl/en/" target="_blank">Question Hub by Google</a> is a service quietly launched by Google to improve their search engine when it comes to these non specific or highly specific questions, and long tail keywords .</p>
<figure><img data-attachment-id="143" data-permalink="https://ruky.me/2021/01/07/google-launches-question-hub-to-tackle-niche-and-long-tail-keyword-queries/img_0080/" data-orig-file="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0080.png?fit=2048%2C1536&amp;ssl=1" data-orig-size="2048,1536" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="img_0080" data-image-description="" data-medium-file="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0080.png?fit=300%2C225&amp;ssl=1" data-large-file="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0080.png?fit=1024%2C768&amp;ssl=1" loading="lazy" width="1024" height="768" src="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0080.png?resize=1024%2C768&amp;ssl=1" alt="" srcset="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0080.png?resize=1024%2C768&amp;ssl=1 1024w, https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0080.png?resize=300%2C225&amp;ssl=1 300w, https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0080.png?resize=768%2C576&amp;ssl=1 768w, https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0080.png?resize=1536%2C1152&amp;ssl=1 1536w, https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0080.png?w=2048&amp;ssl=1 2048w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0080.png?resize=1024%2C768&amp;ssl=1 1024w, https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0080.png?resize=300%2C225&amp;ssl=1 300w, https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0080.png?resize=768%2C576&amp;ssl=1 768w, https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0080.png?resize=1536%2C1152&amp;ssl=1 1536w, https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0080.png?w=2048&amp;ssl=1 2048w" data-lazy-src="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0080.png?resize=1024%2C768&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP/yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 "><figcaption>Benefits of Question Hub according to Google</figcaption></figure>
<p>With Question Hub, Google is hoping to get help from people to improve their search experience for these kinds of queries.</p>
<p>Currently users from the USA, India, Nigeria, and Indonesia can contribute to Questions by Google. However, someone accessed the platform by using a VPN and shared this screenshot in one Facebook group.</p>
<figure><img data-attachment-id="142" data-permalink="https://ruky.me/2021/01/07/google-launches-question-hub-to-tackle-niche-and-long-tail-keyword-queries/img_0079/" data-orig-file="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0079.jpg?fit=1080%2C1920&amp;ssl=1" data-orig-size="1080,1920" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="img_0079" data-image-description="" data-medium-file="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0079.jpg?fit=169%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0079.jpg?fit=576%2C1024&amp;ssl=1" loading="lazy" width="576" height="1024" src="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0079.jpg?resize=576%2C1024&amp;ssl=1" alt="" srcset="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0079.jpg?resize=576%2C1024&amp;ssl=1 576w, https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0079.jpg?resize=169%2C300&amp;ssl=1 169w, https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0079.jpg?resize=768%2C1365&amp;ssl=1 768w, https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0079.jpg?resize=864%2C1536&amp;ssl=1 864w, https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0079.jpg?w=1080&amp;ssl=1 1080w" sizes="(max-width: 576px) 100vw, 576px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0079.jpg?resize=576%2C1024&amp;ssl=1 576w, https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0079.jpg?resize=169%2C300&amp;ssl=1 169w, https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0079.jpg?resize=768%2C1365&amp;ssl=1 768w, https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0079.jpg?resize=864%2C1536&amp;ssl=1 864w, https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0079.jpg?w=1080&amp;ssl=1 1080w" data-lazy-src="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0079.jpg?resize=576%2C1024&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP/yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 "><figcaption>Question Hub by Google</figcaption></figure>
<p>By looking at the screenshot, it appears that it’s a Quora like service, where people can add questions, and also contribute with answers and content.</p>
<p>People who rely on advertising can find commonly asked questions and and create content for it, and in turn get traffic and increase their ad revenue.</p>
<p>And Google can improve their knowledge graph and improve their service by providing a better service for its users.</p>
<p>It can be a win win situation for advertises, Google, users and content creators.</p>
<h2><strong>Downside</strong> </h2>
<p>Question Hub can have its shortcomings. For example, this can lead to more <strong>blog spam or SEO spam</strong>, because content creators can create spammy content for these questions.</p>
<p>Google also has a history of killing services once they achieved their targets (bait and switch). Who knows whether Google will do the same for their Question Hub platform, and kill it once they get enough information for their knowledge graph.</p>
<p>So what’s your idea about Question Hub? Can it lead to a better web?</p>
</div></div>]]>
            </description>
            <link>https://ruky.me/2021/01/07/google-launches-question-hub-to-tackle-niche-and-long-tail-keyword-queries/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25667807</guid>
            <pubDate>Thu, 07 Jan 2021 06:10:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bondic(tm) – Forget glue, this liquid plastic welder is 50X stronger]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25667598">thread link</a>) | @peter_d_sherman
<br/>
January 6, 2021 | https://now.getbondic.io/homepage/US/vsl-73-rv-oudintr/ | <a href="https://web.archive.org/web/*/https://now.getbondic.io/homepage/US/vsl-73-rv-oudintr/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<!-- End Facebook Pixel Code -->
<!-- Global site tag (gtag.js) - Google Ads: 721118076 -->


    



	

    <!--==========Preloader==========-->
    

    <!--==========Header==========-->
    

    <!--==========The Product==========-->
    <section id="product">
        
    </section>
    
       <section id="product2">
        
            </section>

    <!--==========The Product2==========-->
    <section id="product2">
        <div>
            
            <div>
                <p><img src="https://i.imgur.com/jyAllS4.png" width="600" alt=""></p><!--==========Feature Noted top right==========-->
                
                <!--==========Feature Noted top left==========-->
                
                <!--==========Feature Noted bottom right==========-->
                
                <!--==========Feature Noted bottom left==========-->
                
            </div>
        </div>
    </section>
    
 <section id="product2">
        
            </section>
            
             <!--==========How its Works==========-->
    <section>
        <div>
            
            <div>
                <!--==========Work Process==========-->
                <div>
                    <p><img src="https://i.imgur.com/BE80VMv.jpg" alt="">
                    </p>
                    <h3>Step 1</h3>
                    <p><strong>Sand the surface of the object you want to repair.</strong> Create a rough surface for a strong permanent bond.</p>
                </div>
                <!--==========Work Process==========-->
                <div data-wow-delay="0.5s">
                    <p><img src="https://i.imgur.com/pg7c4m2.jpg" alt="">
                    </p>
                    <h3>Step 2</h3>
                    <p><strong>Apply the liquid plastic to the desired area.</strong> Apply multiple layers for a strong bond.</p>
                </div>
                <!--==========Work Process==========-->
                <div data-wow-delay="1s">
                    <p><img src="https://i.imgur.com/uMkk2h6.jpg" alt="">
                    </p>
                    <h3>Step 3</h3>
                    <p><strong>Cure the liquid plastic with the UV light.</strong> It only takes 4 seconds before it gets as hard as a rock.</p>
                </div>
            </div>
        </div>
    </section>

            
            <section id="product2">
        
            </section>
            
            <section id="product2">
        </section>

       


    

    <!--==========The Benefits==========-->
    <section id="features">
        
    </section>

    <!--==========Get wonda==========-->
    <section>
        <div>
              <div>
                
                
                <ul>
                    <li data-wow-delay="0.2s"><strong>30-day money-back guarantee</strong></li>
                    <li data-wow-delay="0.4s"><strong>2-years warranty</strong></li>
                </ul>
            </div>
            
        </div>
    </section>

    <!--==========Reviews==========-->
    <section id="reviews">
        <div>
            
            <div>
                <!--==========Review==========-->
                <div>
                    <div>
                        <p><img src="https://i.imgur.com/LksiuA7.png" alt=""></p>
                    </div>
                    
                    <p>Received my Bondic kit yesterday and it has exceeded my expectations. I tested it on some bolts, a couple pieces of wood and metal, and it did a great job. Also, it’s very easy to use and cures in seconds.</p>
                </div>
                <!--==========Review==========-->
                <div>
                    <div>
                        <p><img src="https://i.imgur.com/K7svOBo.png" alt=""></p>
                    </div>
                    
                    <p>Fast shipping and it comes in a nice little case! I’ve used it a couple times now and I have to admit that it’s a great alternative to glue.</p>
                </div>
                <!--==========Review==========-->
                <div>
                    <div>
                        <p><img src="https://i.imgur.com/AnjZzN4.jpg" alt=""></p>
                    </div>
                    
                    <p>I’ve been using Bondic for the last couple months. I’ve used up the first tube for about 8-12 repairs and little projects which is pretty nice. But it all depends on the size of the object and the amount you use. I’ve already ordered an extra pack of refills with 50% off.</p>
                </div>
                <!--==========Review==========-->
                <div>
                    <div>
                        <p><img src="https://i.imgur.com/AnjZzN4.jpg" alt=""></p>
                    </div>
                    
                    <p>I was a bit worried that this wouldn’t work for the project I’m working on, but it worked just fine! Using Bondic is easier and faster than glue.</p>
                </div>
                <!--==========Review==========-->
                <div>
                    <div>
                        <p><img src="https://i.imgur.com/wfAFqRP.png" alt=""></p>
                    </div>
                    
                    <p>Mine came in a few weeks ago. Works fine! I’ve used it to repair and insulate a couple wires and I must say that I’m impressed. It’s cures superfast and it’s very easy to use. I definitely recommend this product.</p>
                </div>
                <!--==========Review==========-->
                <div>
                    <div>
                        <p><img src="https://i.imgur.com/AjWYeWm.png" alt=""></p>
                    </div>
                    
                    <p>Works much better than superglue. It doesn’t make a mess and you can reposition the parts until you want to harden the repair and make it permanent. Also, it works right out of the box, so no need to buy batteries for the UV light.</p>
                </div>

             <!--==========Review==========-->
                <div>
                    <div>
                        <p><img src="https://i.imgur.com/AnjZzN4.jpg" alt=""></p>
                    </div>
                    
                    <p>This is perfect for crafts and repairs. It can do so much more than glue and it comes in a nice little box!</p>
                </div>
                <!--==========Review==========-->
                <div>
                    <div>
                        <p><img src="https://i.imgur.com/9iaFjIb.png" alt=""></p>
                    </div>
                    
                    <p>It works like a charm, but shipping was quite slow. It took more than 2 weeks.</p>
                </div>
                <!--==========Review==========-->
                <div>
                    <div>
                        <p><img src="https://i.imgur.com/qb4gq6j.png" alt=""></p>
                    </div>
                    
                    <p>Bondic works fine, and I’m using it a lot! The repairs that I’ve done seem to be very strong and hold up nicely.</p>
                </div>
                <!--==========Review==========-->
                <div>
                    <div>
                        <p><img src="https://i.imgur.com/t1KqNv0.png" alt=""></p>
                    </div>
                    
                    <p>Bondic is a gamechanger! It cures in 4 seconds, doesn’t make a mess and it’s cheaper than most superglues. I would recommend it!</p>
                </div>
                <!--==========Review==========-->
                <div>
                    <div>
                        <p><img src="https://i.imgur.com/AnjZzN4.jpg" alt=""></p>
                    </div>
                    
                    <p>Great service and fast delivery! It’s just what I needed to finish my project. I’m 100% satisfied with the result thanks to Bondic.</p>
                </div>
               
            </div>
            
        </div>
    </section>

    <!--==========Footer==========-->
    

    <!--========== Javascript Files ==========-->
    <!-- jQuery Latest -->
    
    <!-- Bootstrap JS -->
    
    <!-- Plugins -->
    
    
    
    
    
    
    <!-- <script src="js/plugins/validate.js"></script> -->
    <!-- Includes -->
    <!-- <script src="js/includes/pre-order.js"></script> -->
    <!-- <script src="js/includes/subscribe.js"></script> -->
    <!-- <script src="js/includes/contact.js"></script> -->
    <!-- Main JS -->
    




</div>]]>
            </description>
            <link>https://now.getbondic.io/homepage/US/vsl-73-rv-oudintr/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25667598</guid>
            <pubDate>Thu, 07 Jan 2021 05:29:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: How to setup contact form on static page with Amazon Lambda]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25666891">thread link</a>) | @jpomykala
<br/>
January 6, 2021 | https://jpomykala.com/2018/08/04/serverless-contact-form-on-static-page | <a href="https://web.archive.org/web/*/https://jpomykala.com/2018/08/04/serverless-contact-form-on-static-page">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
<p>If you are here I assume that you probably donâ€™t know PHP nor Wordpress, and so you decided to built a static web page or use some static
page generator like Jekyll, Grav or GatsbyJS. Right now your obvious option to provide ability to create a
contact from is using a <a href="https://formspree.io/">formspree.io</a> or something similar. Iâ€™m going to show you how to write your own contact form â€˜backendâ€™ in very short time.</p>
<p><img src="https://jpomykala.com/assets/2018-08-04/lambda.png" alt="lambda"></p>
<p>Please remember that this is not a step by step tutorial, Iâ€™m describing overall architecture with the code (<em>copy-paste ready</em> certification).
If you have any remarks, write a comment in section below or <a href="https://github.com/jpomykala/jpomykala.github.io/blob/master/_posts/2018-08-04-serverless-contact-form-on-static-page.md">create a Github issue</a>. ðŸ˜‰</p>
<h3 id="requirements">Requirements</h3>
<ul>
<li>minimal knowledge about <a href="https://aws.amazon.com/">Amazon Web Services</a></li>
<li>basic JavaScript skills</li>
</ul>
<h3 id="used-technologies">Used technologies</h3>
<ul>
<li><a href="https://aws.amazon.com/lambda/">Amazon Lambda</a></li>
<li><a href="https://aws.amazon.com/ses/">Amazon SES</a></li>
<li><a href="https://aws.amazon.com/api-gateway/">Amazon API Gateway</a></li>
</ul>
<h3 id="demo">Demo</h3>
<p>Same technique I used in many websites, here is one example.</p>
<p><a href="https://vendingmetrics.com/contact">https://vendingmetrics.com/contact</a></p>
<p>So far I didnâ€™t have any issue with this solution.</p>
<h3 id="build-environment">Build environment</h3>
<p>If you are familiar with used technologies the diagram should be pretty straightforward for you.</p>
<p><img src="https://jpomykala.com/assets/2018-08-04/architecture-diagram.png" alt="aws-lambda-function"></p>
<p>Static web page should be gathering data from contact form, validate and send them using XHR Fetch, jQuery or in
other way to API Gateway by POST method. API Gateway will invoke Lambda function, and the Lambda function will invoke
our JavaScript code where we parse POST request, do some custom logic and call <code>sendEmail(...)</code> on SES service.</p>
<h3 id="0-verify-e-mail-address">0. Verify e-mail address</h3>
<p>E-mail address verification can be done <a href="https://eu-west-1.console.aws.amazon.com/ses/home?region=eu-west-1#verified-senders-email:">here (eu-west-1)</a></p>
<p><img src="https://jpomykala.com/assets/2018-08-04/ses-verification.png" alt="ses-verification"></p>
<h3 id="1-lambda-function">1. Lambda Function</h3>
<p>We will start with creating Lambda function and choosing NodeJS 8.1 environment.</p>
<p><a href="https://gist.github.com/jpomykala/a3548903e3454f7d65443053ec412b65">The full code can be found on GitHub Gist</a></p>
<h6 id="import-aws-sdk">import <code>aws-sdk</code></h6>
<p>When we have prepared environment we can start to implement the function. First important thing is that we need to import <code>aws-sdk</code> to use SES and other Amazon services.</p>
<figure><pre><code data-lang="javascript"><span>var</span> <span>aws</span> <span>=</span> <span>require</span><span>(</span><span>"</span><span>aws-sdk</span><span>"</span><span>);</span></code></pre></figure>
<p><a href="https://docs.aws.amazon.com/sdk-for-javascript/index.html">Link to <code>aws-sdk</code> documentation</a></p>
<h6 id="lambda-responses">Lambda responses</h6>
<p>Success and error responses. This part is more important than you think. If we return wrong JSON from lambda function to API Gateway,
the client (contact form in this case) will get HTTP 500 status. Code will be invoked and email sent anyway, but itâ€™s just a good practise to
follow the documentation.</p>
<figure><pre><code data-lang="javascript"><span>const</span> <span>successResponse</span> <span>=</span> <span>{</span>
    <span>"</span><span>statusCode</span><span>"</span><span>:</span> <span>200</span><span>,</span>
    <span>"</span><span>headers</span><span>"</span><span>:</span> <span>{</span>
        <span>"</span><span>Content-Type</span><span>"</span><span>:</span> <span>"</span><span>application/json</span><span>"</span><span>,</span>
    <span>},</span>
    <span>"</span><span>body</span><span>"</span><span>:</span> <span>JSON</span><span>.</span><span>stringify</span><span>({</span> <span>message</span><span>:</span> <span>"</span><span>:)</span><span>"</span> <span>}),</span>
    <span>"</span><span>isBase64Encoded</span><span>"</span><span>:</span> <span>false</span>
<span>};</span>

<span>const</span> <span>errorResponse</span> <span>=</span> <span>{</span>
    <span>"</span><span>statusCode</span><span>"</span><span>:</span> <span>500</span><span>,</span>
    <span>"</span><span>headers</span><span>"</span><span>:</span> <span>{</span>
        <span>"</span><span>Content-Type</span><span>"</span><span>:</span> <span>"</span><span>application/json</span><span>"</span><span>,</span>
    <span>},</span>
    <span>"</span><span>body</span><span>"</span><span>:</span> <span>JSON</span><span>.</span><span>stringify</span><span>({</span> <span>message</span><span>:</span> <span>"</span><span>something bad happen, check logs</span><span>"</span> <span>}),</span>
    <span>"</span><span>isBase64Encoded</span><span>"</span><span>:</span> <span>false</span>
<span>};</span></code></pre></figure>
<h6 id="check-is-domain-allowed">Check is domain allowed</h6>
<p>By using this function we can easily turn on and off e-mail sending from certain domains.</p>
<figure><pre><code data-lang="javascript"><span>const</span> <span>extractDomain</span> <span>=</span> <span>(</span><span>emailAddress</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>const</span> <span>emailSplit</span> <span>=</span> <span>emailAddress</span><span>.</span><span>split</span><span>(</span><span>'</span><span>@</span><span>'</span><span>);</span>
    <span>const</span> <span>arraySize</span> <span>=</span> <span>emailSplit</span><span>.</span><span>length</span><span>;</span>
    <span>if</span><span>(</span><span>arraySize</span> <span>&lt;</span> <span>2</span><span>){</span>
        <span>console</span><span>.</span><span>warn</span><span>(</span><span>"</span><span>Domain not found for email:</span><span>"</span><span>,</span> <span>emailAddress</span><span>);</span>
        <span>return</span> <span>""</span><span>;</span>
    <span>}</span>
    
    <span>return</span> <span>emailSplit</span><span>[</span><span>arraySize</span> <span>-</span> <span>1</span><span>];</span>
<span>}</span>

 <span>const</span> <span>allowedDomains</span> <span>=</span> <span>[</span><span>'</span><span>example.com</span><span>'</span><span>,</span> <span>'</span><span>jpomykala.me</span><span>'</span><span>,</span> <span>'</span><span>yourdomain.com</span><span>'</span><span>];</span>
 <span>const</span> <span>isDomainAllowed</span> <span>=</span> <span>(</span><span>domain</span><span>)</span> <span>=&gt;</span> <span>allowedDomains</span><span>.</span><span>includes</span><span>(</span><span>domain</span><span>);</span></code></pre></figure>
<h6 id="e-mail-message">E-mail message</h6>
<p>This is a true strength of this solution. We are passing whole Javascript object from contact form to e-mail formatted
with <code>&lt;pre&gt;&lt;/pre&gt;</code> tags and <code>JSON.stringify</code>.</p>
<figure><pre><code data-lang="javascript"><span>const</span> <span>getEmailMessage</span> <span>=</span> <span>(</span><span>request</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>return</span> <span>{</span>
        <span>Body</span><span>:</span> <span>{</span>
            <span>Html</span><span>:</span> <span>{</span>
                <span>Charset</span><span>:</span> <span>"</span><span>UTF-8</span><span>"</span><span>,</span>
                <span>Data</span><span>:</span> <span>`
                    &lt;body&gt;
                    &lt;p&gt;</span><span>${</span><span>request</span><span>.</span><span>message</span><span>}</span><span>&lt;/p&gt;
                    &lt;pre&gt;</span><span>${</span><span>JSON</span><span>.</span><span>stringify</span><span>(</span><span>request</span><span>,</span> <span>undefined</span><span>,</span> <span>2</span><span>)}</span><span>&lt;/pre&gt;
                    &lt;/body&gt;
                    `</span>
            <span>}</span>
        <span>},</span>
        <span>Subject</span><span>:</span> <span>{</span>
            <span>Charset</span><span>:</span> <span>"</span><span>UTF-8</span><span>"</span><span>,</span>
            <span>Data</span><span>:</span> <span>`New submission`</span>
        <span>}</span>
    <span>}</span>
<span>}</span></code></pre></figure>
<h6 id="send-e-mail-by-ses">Send e-mail by SES</h6>
<p>The most important part of this function is of course sending email by SES. We create a params with message,
subject and <a href="https://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/SES.html">all other options which can be found here.</a></p>
<figure><pre><code data-lang="javascript"> <span>const</span> <span>params</span> <span>=</span> <span>{</span>
        <span>Destination</span><span>:</span> <span>{</span>
            <span>ToAddresses</span><span>:</span> <span>[</span><span>sendToEmail</span><span>]</span>
        <span>},</span>
        <span>Message</span><span>:</span> <span>emailMessage</span><span>,</span>
        <span>Source</span><span>:</span> <span>`</span><span>${</span><span>request</span><span>.</span><span>name</span> <span>||</span> <span>"</span><span>Unknown</span><span>"</span><span>}</span><span> &lt;<a href="https://jpomykala.com/cdn-cgi/l/email-protection" data-cfemail="6d1402181f321b081f040b0408093208000c0401320403321e081e2d0a000c0401430e0200">[email&nbsp;protected]</a>&gt;`</span><span>,</span>
        <span>ReplyToAddresses</span><span>:</span> <span>[</span><span>request</span><span>.</span><span>_replyTo</span><span>]</span>
    <span>};</span>


    <span>const</span> <span>sendPromise</span> <span>=</span> <span>new</span> <span>aws</span><span>.</span><span>SES</span><span>()</span>
        <span>.</span><span>sendEmail</span><span>(</span><span>params</span><span>)</span>
        <span>.</span><span>promise</span><span>();</span>

    <span>await</span> <span>sendPromise</span>
        <span>.</span><span>then</span><span>(</span><span>data</span> <span>=&gt;</span> <span>{</span>
            <span>console</span><span>.</span><span>log</span><span>(</span><span>`E-mail sent to </span><span>${</span><span>sendToEmail</span><span>}</span><span>`</span><span>);</span>
            <span>console</span><span>.</span><span>log</span><span>(</span><span>successResponse</span><span>);</span>
            <span>callback</span><span>(</span><span>null</span><span>,</span> <span>successResponse</span><span>);</span>
        <span>})</span>
        <span>.</span><span>catch</span><span>(</span><span>err</span> <span>=&gt;</span> <span>{</span>
            <span>console</span><span>.</span><span>log</span><span>(</span><span>"</span><span>E-mail NOT sent</span><span>"</span><span>,</span> <span>err</span><span>);</span>
            <span>console</span><span>.</span><span>log</span><span>(</span><span>errorResponse</span><span>);</span>
            <span>callback</span><span>(</span><span>errorResponse</span><span>);</span>
        <span>});</span></code></pre></figure>
<p>Now we can deploy our function and move to API Gateway.</p>
<p><img src="https://jpomykala.com/assets/2018-08-04/send-mail-fuction-aws.png" alt="aws-lambda-function"></p>
<h3 id="2-api-gateway">2. API Gateway</h3>
<p>Setting up API Gateway for Lambda functions, should be straightforward. There is no need to code any thing, just click-and-play configuration.
In this case I setup my endpoint to receive any http method. For working contact form you will need only <code>http/post</code> method.
<img src="https://jpomykala.com/assets/2018-08-04/api-gateway.png" alt="api-gateway"></p>
<h6 id="things-to-remember">Things to remember</h6>
<ul>
<li>Every time we change something on endpoint configuration we need deploy API again to see changes. <code>Actions -&gt; Deploy API</code></li>
<li>Remember about setting up CORS while using API Gateway. <code>Actions -&gt; Enable CORS</code></li>
</ul>
<h3 id="3-contact-form-example">3. Contact form example</h3>
<h6 id="html-form">HTML form</h6>
<figure><pre><code data-lang="html"><span>&lt;form</span> <span>action=</span><span>"#"</span> <span>id=</span><span>"callbackForm"</span> <span>class=</span><span>"contact-form"</span><span>&gt;</span>
    <span>&lt;div</span> <span>class=</span><span>"form-group"</span><span>&gt;</span>
        <span>&lt;label</span> <span>for=</span><span>"email"</span><span>&gt;</span>Email<span>&lt;/label&gt;</span>
        <span>&lt;input</span> <span>type=</span><span>"email"</span> <span>required</span> <span>id=</span><span>"email"</span> <span>class=</span><span>"form-control"</span> <span>placeholder=</span><span>""</span> <span>autocomplete=</span><span>"email"</span> <span>name=</span><span>"email"</span> <span>/&gt;</span>
    <span>&lt;/div&gt;</span>
    <span>&lt;div</span> <span>class=</span><span>"form-group"</span><span>&gt;</span>
        <span>&lt;label</span> <span>for=</span><span>"name"</span><span>&gt;</span>Message<span>&lt;/label&gt;</span>
        <span>&lt;input</span> <span>id=</span><span>"message"</span> <span>type=</span><span>"text"</span> <span>class=</span><span>"form-control"</span> <span>placeholder=</span><span>""</span> <span>name=</span><span>"message"</span> <span>/&gt;</span>
    <span>&lt;/div&gt;</span>
    <span>&lt;button</span> <span>type=</span><span>"submit"</span> <span>id=</span><span>"sendMessageButton"</span> <span>class=</span><span>"btn btn-primary btn-block"</span><span>&gt;</span>
        Send message
    <span>&lt;/button&gt;</span>
<span>&lt;/form&gt;</span></code></pre></figure>
<h6 id="javascript">JavaScript</h6>
<figure><pre><code data-lang="html"><span>&lt;script&gt;</span>
        <span>$</span><span>(</span><span>"</span><span>#callbackForm</span><span>"</span><span>).</span><span>submit</span><span>(</span><span>function</span><span>(</span><span>e</span><span>)</span> <span>{</span>
            <span>e</span><span>.</span><span>preventDefault</span><span>();</span>
            <span>var</span> <span>replyTo</span> <span>=</span> <span>$</span><span>(</span><span>"</span><span>#email</span><span>"</span><span>);</span>
            <span>var</span> <span>message</span> <span>=</span> <span>$</span><span>(</span><span>"</span><span>#message</span><span>"</span><span>);</span>
            <span>var</span> <span>data</span> <span>=</span> <span>{</span>
                <span>"</span><span>_sendTo</span><span>"</span><span>:</span> <span>"</span><span>&lt;your_email&gt;</span><span>"</span><span>,</span>
                <span>"</span><span>_replyTo</span><span>"</span><span>:</span> <span>replyTo</span><span>.</span><span>val</span><span>(),</span>
                <span>"</span><span>message</span><span>"</span><span>:</span> <span>message</span><span>.</span><span>val</span><span>()</span>
            <span>};</span>
            <span>var</span> <span>url</span> <span>=</span> <span>"</span><span>&lt;API_GATEWAY_URL&gt;</span><span>"</span><span>;</span>
            <span>$</span><span>.</span><span>ajax</span><span>({</span>
                <span>url</span><span>:</span> <span>url</span><span>,</span>
                <span>type</span><span>:</span> <span>'</span><span>POST</span><span>'</span><span>,</span>
                <span>crossDomain</span><span>:</span> <span>true</span><span>,</span>
                <span>data</span><span>:</span> <span>JSON</span><span>.</span><span>stringify</span><span>(</span><span>data</span><span>),</span>
                <span>dataType</span><span>:</span> <span>'</span><span>json</span><span>'</span><span>,</span>
                <span>contentType</span><span>:</span> <span>"</span><span>application/json</span><span>"</span>
            <span>});</span>
        <span>});</span>
<span>&lt;/script&gt;</span></code></pre></figure>
<h3 id="conclusion">Conclusion</h3>
<p>We can scale this technique to multiple web pages with ease, but this solution in current form has few downsides.
For now the only one protection against DDoS or some similar attack is rate limiter included in Lambda function.
Right now there is no bot protection, no captcha or something like that. We can add Google re-captcha on the contact
form and setup rate limiting on both API Gateway and Lambda function, to avoid unnecessary costs.</p>
</div></div>]]>
            </description>
            <link>https://jpomykala.com/2018/08/04/serverless-contact-form-on-static-page</link>
            <guid isPermaLink="false">hacker-news-small-sites-25666891</guid>
            <pubDate>Thu, 07 Jan 2021 03:22:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Devastating Decline of a Brilliant Young Coder]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25666855">thread link</a>) | @mraza007
<br/>
January 6, 2021 | https://weekly.statuscode.com/link/100809/ac1fb866f8 | <a href="https://web.archive.org/web/*/https://weekly.statuscode.com/link/100809/ac1fb866f8">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><figure><div></div></figure><p><span>On Friday, September</span> 13, 2019, Matthew Prince and Michelle Zatlyn, cofounders of the San Francisco  <a href="https://www.wired.com/tag/cloudflare/">internet security firm Cloudflare</a>, stood on a slim marble balcony overlooking the floor of the New York Stock Exchange. A cluster of the company's executives stood near Prince, ready to shout out a countdown. “Louder! Loud!” Prince urged them. “Five! Four! Three! …” At 9:30 am sharp, the founders reached down to ring the exchange's famous bell, kicking off the day's trading and offering their 10-year-old company on the public market. It was a rite of passage and also their payday, a moment that unlocked many millions of dollars in newfound wealth.</p><p>More than 100 employees and investors cheered from the trading floor below, their phones held high to capture the scene. Kristin Holloway, employee number 11, looked up at the balcony and snapped photos, then popped them into a text to her husband, Lee Holloway, the company's third cofounder. He was home in California. Every so often, a familiar face pushed through the throng to say to her, “Lee should be here.”</p><p>In Cloudflare's early years, Lee Holloway had been the resident genius, the guy who could focus for hours, code pouring from his fingertips while death metal blasted in his headphones. He was the master architect whose vision had guided what began as a literal sketch on a napkin into a tech giant with some 1,200 employees and 83,000 paying customers. He laid the groundwork for a system that now handles more than 10 percent of all internet requests and <a href="https://www.wired.com/story/cloudflare-matthew-prince-wired25/">blocks billions of cyberthreats</a> per day. Much of the architecture he dreamed up is still in place.</p><p>But some years before the IPO, his behavior began to change. He lost interest in his projects and coworkers. He stopped paying attention in meetings. His colleagues noticed he was growing increasingly rigid and belligerent, resisting others' ideas, and ignoring their feedback.</p><p>Lee's rudeness perplexed his old friends. He had built his life around Cloudflare, once vowing to not cut his hair until the startup's web traffic surpassed that of Yahoo. (It took a few short months, or about 4 inches of hair.) He had always been easygoing, happy to mentor his colleagues or hang out over lunch. At a birthday party for Zatlyn, he enchanted some children, regaling them with stories about the joys of coding. The idea of Lee picking fights simply didn't compute.</p></div></div><div><div><p>He was becoming erratic in other ways too. Some of his colleagues were surprised when Lee separated from his first wife and soon after paired up with a coworker. They figured his enormous success and wealth must have gone to his head. “All of us were just thinking he made a bunch of money, married his new girl,” Prince says. “He kind of reassessed his life and had just become a jerk.”</p><p>The people close to Lee felt tossed aside. They thought he'd chosen to shed his old life. In fact, it was anything but a choice. Over the next few years, Lee's personality would warp and twist even more, until he became almost unrecognizable to the people who knew him best. Rooting out the cause took years of detective work—and forced his family to confront the trickiest questions of selfhood.</p><p>On the floor of the stock exchange that September morning, Lee's younger brother Alaric weathered the morning in a state of low-grade panic. He snapped selfies with early employees and fired them off in texts to his brother. Alaric had never worked at Cloudflare, and he knew barely anyone there. But his dark hair flopped over his forehead with the same distinctive swoop as his brother's, and his long, tapering face had the same dark eyes and olive skin. “It was surreal,” Alaric says. “People kept looking at me like they knew me.”</p><p>At home with his parents in San Jose, Lee, 38, was restless. He paced the rooms and hallways of the 1,550-square-foot house, a loop he'd been tracing since he'd moved in with them two years earlier. He didn't speak. His parents had the TV on, and they called him over whenever Prince or Zatlyn appeared onscreen.</p><p>Later, he paused at the family's Roku to search YouTube for videos of Cloudflare. Then he resumed his circuit: walking the halls, buzzing his lips, snacking on cashews.</p><figure><figcaption><span>Lee Holloway spends time with his youngest son at home on California's Central Coast.</span><span>Artwork by Amy Friend; Photograph by Jack Bool</span></figcaption></figure><p><span>What makes you</span>  <em>you</em>? The question cuts to the core of who we are, the things that make us special in this universe. The converse of the question raises another kind of philosophical dilemma: If a person <em>isn't</em> himself, who is he?</p><p>Countless philosophers have taken a swing at this elusive piñata. In the 17th century, John Locke pinned selfhood <a href="https://www.wired.com/tag/memory/">on memory</a>, using recollections as the thread connecting a person's past with their present. That holds some intuitive appeal: Memory, after all, is how most of us register our continued existence. But memory is unreliable. Writing in the 1970s, renowned philosopher Derek Parfit recast Locke's idea to argue that personhood emerges from a more complex view of psychological connectedness across time. He suggested that a host of mental phenomena—memories, intentions, beliefs, and so on—forge chains that bind us to our past selves. A person today has many of the same psychological states as that person a day ago. Yesterday's human enjoys similar overlap with an individual of two days prior. Each memory or belief is a chain that stretches back through time, holding a person together in the face of inevitable flux.</p></div></div><div><div><p>The gist, then, is that someone is “himself” because countless mental artifacts stay firm from one day to the next, anchoring that person's character over time. It's a less crisp definition than the old idea of a soul, offering no firm threshold where selfhood breaks down. It doesn't pinpoint, for example, how many psychological chains you can lose before you stop being yourself. <a href="https://www.wired.com/tag/neuroscience/">Neuroscience</a> also offers only a partial answer to the question of what makes you <em>you</em>.</p><p><a href="https://www.wired.com/tag/neural-networks/">Neural networks</a> encode our mental artifacts, which together form the foundation of behavior. A stimulus enters the brain, and electrochemical signals swoosh through your neurons, culminating in an action: Hug a friend. Sit and brood. Tilt your head up at the sun and smile. Losing some brain cells here or there is no big deal; the networks are resilient enough to keep a person's behaviors and sense of self consistent.</p><p>But not always. Mess with the biological Jell-O in just the right ways and the structure of the self reveals its fragility.</p><p>Lee's personality had been consistent for decades—until it wasn't.</p><p>From an early age, he was a person who could visualize sprawling structures in his mind. Growing up in the 1990s in Cupertino, where his dad worked at Apple, Lee had early access to the latest computers, and he and his brother grew up bingeing on videogames. As a gamer, he was legendary among his friends for being able to read a complex situation, rapidly adjust strategies, and win match after match. And it wasn't just videogames. His childhood friend Justin Powell remembers Lee strolling into a middle school chess club tournament cold. He wasn't a member of the club, but he won the tournament anyway. Lee avoided becoming insufferable by channeling his wit into snarky commentary. “Watching a movie with him was like a version of <em>Mystery Science Theater 3000</em>,” Powell says. “His very presence challenged you to keep up with him.”</p><p>Lee and his friends would cart their computers to each other's houses to play games together. He became curious about the machines themselves and started learning computer science, first in high school, then at a local community college and UC Santa Cruz, where an unlikely set of circumstances connected him with Matthew Prince.</p><p>Then a young entrepreneur, Prince was pursuing an idea for an antispam software tool when he encountered Arthur Keller, a UC Santa Cruz computer science professor. Keller and his students had already worked out a very similar concept. Prince and Keller agreed to share a patent, along with Keller's students. One of those students was Lee, and Prince hired him on the spot. “I had no idea this school project would turn into something much bigger,” Lee later said in a video interview with a group called Founderly.</p><p>Prince set up the company, Unspam Technologies, in Park City, Utah, about a mile from a cluster of slopes where he could indulge his passion for skiing. Lee moved into Prince's basement, at first working for free in exchange for food and housing. But Lee and the other Unspam engineers grew restless, and they started spinning up side projects, including one called Project Honey Pot, which tracked spammers as they crawled the web. That's all it did—it collected and published data on spammers, but it didn't do anything to stop them. Still, the project quickly amassed a loyal following.</p><p>In 2007, Prince left Utah to start business school at Harvard, and Lee moved to California to live with his girlfriend, Alexandra Carey. They'd known each other as undergrads, when she was a teaching assistant in his computer architecture class. Lee had goofed off in that class, once pranking the professor by scrawling childish notes on the transparencies of an overhead projector. Alexandra had been amused, but it wasn't until after college that a relationship bloomed. Living in different cities, they fell for each other while playing and chatting within a multiplayer videogame called <em>Savage</em>. Now, with Prince leaving Utah, it seemed a natural time for Lee to join Alexandra. They married in 2008.</p><div><div><p><span><picture><img alt="This image may contain Electronics, Computer, and Pc" src="https://media.wired.com/photos/5c098e5fd146d62d209935fc/1:1/w_775%2Cc_limit/Data-Breaches.png" srcset="https://media.wired.com/photos/5c098e5fd146d62d209935fc/1:1/w_775%2Cc_limit/Data-Breaches.png 775w, https://media.wired.com/photos/5c098e5fd146d62d209935fc/1:1/w_775%2Cc_limit/Data-Breaches.png 775w, https://media.wired.com/photos/5c098e5fd146d62d209935fc/1:1/w_768%2Cc_limit/Data-Breaches.png 768w, https://media.wired.com/photos/5c098e5fd146d62d209935fc/1:1/w_768%2Cc_limit/Data-Breaches.png 768w, https://media.wired.com/photos/5c098e5fd146d62d209935fc/1:1/w_640%2Cc_limit/Data-Breaches.png 640w" sizes="100vw"></picture></span></p><div><h3><a href="https://weekly.statuscode.com/story/wired-guide-to-data-breaches">The WIRED Guide to Data Breaches</a></h3><p>Everything you ever wanted to know about Equifax, Mariott, and the problem with social security numbers.</p></div></div></div><p>Lee and Prince kept working at Unspam from their respective cities, but as Prince was wrapping up business school, Lee called to tell him he was considering other job offers. Prince countered with a new and rather audacious pitch: He and a classmate, Michelle Zatlyn, had hit on a startup idea they thought had potential. What if they …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://weekly.statuscode.com/link/100809/ac1fb866f8">https://weekly.statuscode.com/link/100809/ac1fb866f8</a></em></p>]]>
            </description>
            <link>https://weekly.statuscode.com/link/100809/ac1fb866f8</link>
            <guid isPermaLink="false">hacker-news-small-sites-25666855</guid>
            <pubDate>Thu, 07 Jan 2021 03:16:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reed-Solomon error recovery in RAID-6]]>
            </title>
            <description>
<![CDATA[
Score 99 | Comments 37 (<a href="https://news.ycombinator.com/item?id=25666830">thread link</a>) | @signa11
<br/>
January 6, 2021 | http://anadoxin.org/blog/error-recovery-in-raid6.html/ | <a href="https://web.archive.org/web/*/http://anadoxin.org/blog/error-recovery-in-raid6.html/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        

        

        <p>
            <h3>Reed-Solomon error recovery in RAID-6</h3>
        </p>

        <p>
            https://anadoxin.org/blog/error-recovery-in-raid6.html
        </p>

        
        
        
        

        
        
        
        

        
        <p>There are lots of resources on the Internet about RAID-6 error recovery and how you can create your own implementation of it, but most of those resources require spending a lot of time fighting with mathematical equations and figuring out the real algorithm.</p>
<p>In this post I'll try to give you a simple example how you can create your own error recovery solution based on what is used in RAID-6. More specifically, if you need to provide rendundancy across your mediums so that a failure of 1 or 2 mediums will be tolerated, look no further! ;)</p>
<p>If you'll read this post, as a bonus you'll gain knowledge about how RAID-5 error recovery works, because RAID-6 is an improved version of RAID-5 error recovery system.</p>

<p>Let's assume you have 3 disk drives with some data. Let's name those drives as <code>D1</code>, <code>D2</code> and <code>D3</code>. In order to use the same error recovery technique as RAID-6 uses, you'll need two additional disk drives, the <code>PD</code> drive, and the <code>RS</code> drive. I'll describe what <code>PD</code> and <code>RS</code> means in few moments. So, you'll need a total of 5 disk drives: <code>D1</code>, <code>D2</code>, <code>D3</code>, <code>PD</code> and <code>RS</code>.</p>
<p><img src="https://anadoxin.org/blog/error-recovery-in-raid6.html/image1.svg" alt=""></p>
<p>So, here's the situation:</p>
<ul>
<li><code>D1</code>, <code>D2</code> and <code>D3</code> contain <em>arbitrary user data</em>, and it doesn't matter what their contents are. FWIW you can assume those drives are full of cat pictures.</li>
<li>The special <code>PD</code> drive (named after <code>Parity Drive</code>, sometimes called <code>P</code> in whitepapers) contains the XOR data, generated automatically from <code>D1</code>, <code>D2</code> and <code>D3</code>.</li>
<li>The second special <code>RS</code> drive (named after <code>Reed-Solomon Drive</code>, sometimes also called <code>Q</code>) contains the Reed-Solomon codes, calculated from the same data as <code>PD</code>, namely from drives <code>D1</code>, <code>D2</code> and <code>D3</code>.</li>
</ul>
<p>Let's see how we can perform some basic operations on such disk array.</p>

<p>If we have properly calculated <code>PD</code> and <code>RS</code> drives, we can lose up to 2 drives. How we recover from failures depends on which drives will fail. There are generally 7 cases that RAID-6 can handle. Next points will describe the scenarios, sorted from the easiest case, to the most complicated.</p>
<ol>
<li>
<p>Loss of the <code>PD</code> drive (failure of only one drive).</p>
<p><img src="https://anadoxin.org/blog/error-recovery-in-raid6.html/image-losspd.svg" alt=""></p>
<p>This case is very straightforward. The <code>PD</code> drive contains only autogenerated data, so in case we lose the <code>PD</code> drive, we can regenerate it by using only user data (stored on disks <code>D1</code>, <code>D2</code> and <code>D3</code>).</p>
</li>
<li>
<p>Loss of one of the data drives: either <code>D1</code>, <code>D2</code> or <code>D3</code> (failure of only one drive).</p>
<p><img src="https://anadoxin.org/blog/error-recovery-in-raid6.html/image-datadrive.svg" alt=""></p>
<p>In this case we're losing data, but since we only lose 1 disk, the recovery scenario is the same as in RAID-5 error recovery: we'll use <code>PD</code> drive <em>together with two non-missing data drives</em> to recover data from the missing data drive. It doesn't matter which data drive we lose, because if we have 2 data drives and the <code>PD</code> drive, we can always generate data for the third drive. The <code>RS</code> drive is not needed to regenerate the data drive in this case (and is not used at all in this failure case).</p>
</li>
<li>
<p>Loss of the <code>RS</code> drive (failure of only one drive).</p>
<p><img src="https://anadoxin.org/blog/error-recovery-in-raid6.html/image-lossrs.svg" alt=""></p>
<p>Similar to the situation from point 1: we have all the data drives, and we can simply regenerate the <code>RS</code> drive by calculating Reed-Solomon codes from drives that did not fail.</p>
</li>
<li>
<p>Loss of the <code>PD</code> drive and the <code>RS</code> drive (failure of two drives).</p>
<p><img src="https://anadoxin.org/blog/error-recovery-in-raid6.html/image-losspdrs.svg" alt=""></p>
<p>This case is very similar to points 1 or 3, we have all the data intact, so we can generate contents of <code>PD</code> drive and then <code>RS</code> drive very easily.</p>
</li>
<li>
<p>Loss of the <code>RS</code> drive and one data drive (failure of two drives).</p>
<p><img src="https://anadoxin.org/blog/error-recovery-in-raid6.html/image-lossdatars.svg" alt=""></p>
<p>In this case we're losing two disks, but only one lost disk is filled with data. Since we have <code>PD</code> drive intact, we can use it to regenerate data from missing data drive, so this case is not so different than case #2. After that, we will have all the data drives, so we can regenerate the <code>RS</code> drive easily.</p>
</li>
<li>
<p>Loss of the <code>PD</code> drive and one data drive (failure of two drives).</p>
<p><img src="https://anadoxin.org/blog/error-recovery-in-raid6.html/image-lossdatapd.svg" alt=""></p>
<p>This case is more complicated. We lose one user data drive (in this example <code>D3</code>), and we don't have the <code>PD</code> drive to aid with recovery, because we've lost it as well. We have to use the <code>RS</code> drive in conjunction with all user data drives that are still available (<code>D1</code> and <code>D2</code>) to regenerate the missing data drive <code>D3</code>. After we'll have all data drives regenerated, we can calculate the missing <code>PD</code> drive. This is the first case where recovery using Reed-Solomon codes comes into play.</p>
</li>
<li>
<p>Loss of two data drives (failure of two drives).</p>
<p><img src="https://anadoxin.org/blog/error-recovery-in-raid6.html/image-lossdatadata.svg" alt=""></p>
<p>This is the most complicated scenario. We need to use both <code>PD</code> and <code>RS</code> to regenerate both data drives. Reed-Solomon coding makes this case possible.</p>
</li>
</ol>
<p>In the following sections, I'll try to describe those cases above with more detail, and provide some source code (in Python :P) that will perform actual recovery of data.</p>
<p>Please keep in mind that real RAID-6 arrays don't really dedicate whole disk for <code>PD</code> or <code>RS</code>. Real arrays span this additional checksum data across all disks. There are multiple methods used by various controllers: left asynchronous, right synchronous, there can be an offset to the RAID data, there can be pattern delays, etc. Why it's done this way, and how exactly RAID-6 stripes looks like is beyond the scope of this blog post. So let's stick only to Reed-Solomon codes.</p>
<h2 id="test-data">Test data</h2>
<p>Let's define how our "user data" looks like. To keep things simple, let's pretend that our "disk drives" are 5 bytes big.</p>
<table><thead><tr><th>Disk</th><th>Data in ASCII</th><th>Data in HEX</th></tr></thead><tbody>
<tr><td><code>D1</code></td><td>f i r s t</td><td>0x66, 0x69, 0x72, 0x73, 0x74</td></tr>
<tr><td><code>D2</code></td><td>s e c n d</td><td>0x73, 0x65, 0x63, 0x6e, 0x64</td></tr>
<tr><td><code>D3</code></td><td>t h i r d</td><td>0x74, 0x68, 0x69, 0x72, 0x64</td></tr>
</tbody></table>
<p>Let's go into the scenarios mentioned above in more details.</p>

<p>In order to generate the <code>PD</code> data, we need only the user data drives. In our case it's <code>D1</code>, <code>D2</code> and <code>D3</code>. The <code>PD</code> drive consists of nothing more than <a href="https://en.wikipedia.org/wiki/Bitwise_operation#XOR">XOR</a> of all user data.</p>
<ul>
<li>To generate offset 0 of the <code>PD</code> drive, you need to XOR all bytes from offset 0 from all disk drives.</li>
<li>Then, to generate offset 1 of the <code>PD</code> drive, you need to XOR bytes from offset 1 from all disk drives. E.g.:</li>
</ul>
<pre><code><span>PD[0] = D1[0] xor D2[0] xor D3[0]
PD[1] = D1[1] xor D2[1] xor D3[1]
PD[2] = D1[2] xor D2[2] xor D3[2]
PD[3] = D1[3] xor D2[3] xor D3[3]
PD[4] = D1[4] xor D2[4] xor D3[4]
</span></code></pre>
<p>Example:</p>
<pre><code><span>PD[0] = 0x66 xor 0x73 xor 0x74  =&gt;  0x61
PD[1] = 0x69 xor 0x65 xor 0x63  =&gt;  0x64
PD[2] = 0x72 xor 0x63 xor 0x69  =&gt;  0x78
PD[3] = 0x73 xor 0x6e xor 0x72  =&gt;  0x6f
PD[4] = 0x74 xor 0x64 xor 0x64  =&gt;  0x74
</span></code></pre>
<p>Yes, it's that simple. Do it for the whole drives (in our case, 5 bytes), and you'll have the properly generated <code>PD</code> drive:</p>
<table><thead><tr><th>Disk</th><th>Data in HEX</th></tr></thead><tbody>
<tr><td><code>PD</code></td><td>0x61, 0x64, 0x78, 0x6f, 0x74</td></tr>
</tbody></table>
<p>So, in case when only your <code>PD</code> drive will fail, you can see it's trivial to regenerate it from the data drives <code>D1</code>, <code>D2</code> and <code>D3</code>.</p>

<p>By the way, this is how RAID-5 error recovery works. If only one drive with user data will fail, we can use the <code>PD</code> drive to recalculate missing user data.</p>
<p>Let's say we're losing <code>D2</code>, so the drives that are still working are: <code>D1</code>, <code>D3</code>, <code>PD</code> and <code>RS</code>. In this case, we don't even look at <code>RS</code>. All we need are the <code>D1</code>, <code>D3</code> and <code>PD</code> drives. To calculate missing data, you can use the XOR function again, like in the previous point.</p>
<p>To recover user data from offset 0, XOR the bytes from offsets 0 of disks with user data you haven't lost (<code>D1</code> and <code>D3</code>) together with the byte from offset 0 from the <code>PD</code> drive. Do the same thing for offset 1, like this:</p>
<pre><code><span>D2[0] = D1[0] xor D3[0] xor PD[0]
D2[1] = D1[1] xor D3[1] xor PD[1]
D2[2] = D1[2] xor D3[2] xor PD[2]
D2[3] = D1[3] xor D3[3] xor PD[3]
D2[4] = D1[4] xor D3[4] xor PD[4]
</span></code></pre>
<p>Example:</p>
<pre><code><span>D2[0] = 0x66 xor 0x74 xor 0x61  =&gt;  0x73 (s)
D2[1] = 0x69 xor 0x63 xor 0x64  =&gt;  0x65 (e)
D2[2] = 0x72 xor 0x69 xor 0x78  =&gt;  0x63 (c)
D2[3] = 0x73 xor 0x72 xor 0x6f  =&gt;  0x6e (n)
D2[4] = 0x74 xor 0x64 xor 0x74  =&gt;  0x64 (d)
</span></code></pre>
<p>As you can see, we can easily recover data from the missing drive. It doesn't matter which drive is missing; the <a href="https://en.wikipedia.org/wiki/Bitwise_operation#XOR">XOR function</a> will work anyway.</p>

<p>Now we enter the realm of the Reed-Solomon codes and Galois fields. But don't worry, you don't have to be a mathematician in order to <em>use</em> it.</p>
<p>When we lose only <code>RS</code> drive, or when we initialize a new RAID-6-like redundation system, we simply need to regenerate it. In order to do that, we need to use the <code>gflog</code> and <code>gfilog</code> tables, which are always constant, plus data from our existing data drives <code>D1</code>, <code>D2</code> and <code>D3</code>.</p>
<p>This is the <code>gflog</code> table, it always stays the same:</p>
<pre><code><span>    0x00, 0x00, 0x01, 0x19, 0x02, 0x32, 0x1a, 0xc6, 0x03, 0xdf, 0x33, 0xee, 0x1b, 0x68, 0xc7, 0x4b,
    0x04, 0x64, 0xe0, 0x0e, 0x34, 0x8d, 0xef, 0x81, 0x1c, 0xc1, 0x69, 0xf8, 0xc8, 0x08, 0x4c, 0x71,
    0x05, 0x8a, 0x65, 0x2f, 0xe1, 0x24, 0x0f, 0x21, 0x35, 0x93, 0x8e, 0xda, 0xf0, 0x12, 0x82, 0x45,
    0x1d, 0xb5, 0xc2, 0x7d, 0x6a, 0x27, 0xf9, 0xb9, 0xc9, 0x9a, 0x09, 0x78, 0x4d, 0xe4, 0x72, 0xa6,
    0x06, 0xbf, 0x8b, 0x62, 0x66, 0xdd, 0x30, 0xfd, 0xe2, 0x98, 0x25, 0xb3, 0x10, 0x91, 0x22, 0x88,
    0x36, 0xd0, 0x94, 0xce, 0x8f, 0x96, 0xdb, 0xbd, 0xf1, 0xd2, 0x13, 0x5c, 0x83, 0x38, 0x46, 0x40,
    0x1e, 0x42, 0xb6, 0xa3, 0xc3, 0x48, 0x7e, 0x6e, 0x6b, 0x3a, 0x28, 0x54, 0xfa, 0x85, 0xba, 0x3d,
    0xca, 0x5e, 0x9b, 0x9f, 0x0a, 0x15, 0x79, 0x2b, 0x4e, 0xd4, 0xe5, 0xac, 0x73, 0xf3, 0xa7, 0x57,
    0x07, 0x70, 0xc0, 0xf7, 0x8c, 0x80, 0x63, 0x0d, 0x67, 0x4a, 0xde, 0xed, 0x31, 0xc5, 0xfe, 0x18,
    0xe3, 0xa5, 0x99, 0x77, 0x26, 0xb8, 0xb4, 0x7c, 0x11, 0x44, 0x92, 0xd9, 0x23, 0x20, 0x89, 0x2e,
    0x37, 0x3f, 0xd1, 0x5b, 0x95, 0xbc, 0xcf, 0xcd, 0x90, 0x87, 0x97, 0xb2, 0xdc, 0xfc, 0xbe, 0x61,
    0xf2, 0x56, 0xd3, 0xab, 0x14, 0x2a, 0x5d, 0x9e, 0x84, 0x3c, 0x39, 0x53, 0x47, 0x6d, 0x41, 0xa2,
    0x1f, 0x2d, 0x43, 0xd8, 0xb7, 0x7b, 0xa4, 0x76, 0xc4, 0x17, 0x49, 0xec, 0x7f, 0x0c, 0x6f, 0xf6,
    0x6c, 0xa1, 0x3b, 0x52, 0x29, 0x9d, 0x55, 0xaa, 0xfb, 0x60, 0x86, 0xb1, 0xbb, 0xcc, 0x3e, 0x5a,
    0xcb, 0x59, 0x5f, 0xb0, 0x9c, 0xa9, 0xa0, 0x51, 0x0b, 0xf5, 0x16, 0xeb, 0x7a, 0x75, 0x2c, 0xd7,
    0x4f, 0xae, 0xd5, 0xe9, 0xe6, 0xe7, 0xad, 0xe8, 0x74, 0xd6, 0xf4, 0xea, 0xa8, 0x50, 0x58, 0xaf.
</span></code></pre>
<p>This is the <code>gfilog</code> table, it's also constant:</p>
<pre><code><span>    0x01, 0x02, 0x04, 0x08, 0x10, 0x20, 0x40, 0x80, 0x1d, 0x3a, 0x74, 0xe8, …</span></code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://anadoxin.org/blog/error-recovery-in-raid6.html/">http://anadoxin.org/blog/error-recovery-in-raid6.html/</a></em></p>]]>
            </description>
            <link>http://anadoxin.org/blog/error-recovery-in-raid6.html/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25666830</guid>
            <pubDate>Thu, 07 Jan 2021 03:13:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Replacing OpenSSL, Part 1: WolfSSL]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25666301">thread link</a>) | @harporoeder
<br/>
January 6, 2021 | https://danyspin97.org/blog/replacing-openssl-part-1-wolfssl/ | <a href="https://web.archive.org/web/*/https://danyspin97.org/blog/replacing-openssl-part-1-wolfssl/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>This post highlight my experiment of replacing OpenSSL cryptographic library
with its embedded competitor: <code>wolfssl</code>.</p><p><em><strong>Prerequites</strong></em>: <em>Basic knowledge about C/C++ programming</em>.</p><h2 id="a-bit-of-background-about-openssl">A bit of background about OpenSSL</h2><p>OpenSSL is one of the most crucial libraries on a Unix system: it performs
cryptographic functions and it provides <em>Transport Layer Security</em> (<em>TLS</em>) and <em>Secure Sockets Layer</em> (<em>SSL</em>) protocols to applications.</p><p>According to the <em>Arch Linux</em> <a href="https://archlinux.org/packages/core/x86_64/openssl/">OpenSSL package</a>, <strong>355</strong> packages, out of the
<em>11523</em> available, depend on it. You can find it installed on any Unix system
(and on Windows too!).</p><p>It started in 1998 as a fork of <a href="https://en.wikipedia.org/wiki/SSLeay">SSLeay</a> and it has been in development since.
Two full-time developers work on it, as well as many volunteers.</p><p>Fast forward to 2014: a <em><a href="https://en.wikipedia.org/wiki/Common_Vulnerabilities_and_Exposures">CVE</a></em> had been issued regarding a high risk
vulnerability found in OpenSSL. It has been given the name <strong><a href="https://heartbleed.com/">Heartbleed</a></strong>,
because it has been found in the <em>TLS</em>/<em>DTLS</em> heartbeat extension (<a href="https://tools.ietf.org/html/rfc6520">RFC6520</a>).
This vulnerability allowed attackers to steal sensitive data, such as secret
keys, user names and passwords.</p><p>All the community turned to the OpenSSL project, weighting its implementation
and security policy. Heartbleed have been promptly fixed, but there could be new
vulnerabilities in the future, if security was not properly prioritized during
development.</p><p>At this point, OpenBSD’s folks forked OpenSSL and started a new project:
<a href="https://www.libressl.org/">LibreSSL</a>. It primary goals were to <strong>modernize the codebase and to improve
its security</strong>. This new project hasn’t been adopted by big distributions such
Ubuntu and Arch Linux; instead smaller distributions (at that time) replaced
OpenSSL with LibreSSL on their default configuration, such as Alpine and Void.</p><p>In the last years, LibreSSL have seen a decline in its usage. Alpine switched
back to OpenSSL (<a href="https://lists.alpinelinux.org/~alpine/devel/%3C20181011171746.4c01f758%40ncopa-desktop.copa.dup.pw%3E">link to the thread</a>). Many people and distributions are
considering doing the same, since OpenSSL got the improvement that LibreSSL
aimed for. And it’s still the <em>de facto standard</em> cryptographic library on Unix.</p><h2 id="why-replacing-openssl-now">Why replacing OpenSSL now?</h2><p>OpenSSL works fine, there is no denying that. Every software has <em>out of the box
support for it</em> so it costs no effort in term of additional mainteinance.
However, there are <strong>newer and lighter TLS and SSL implementations</strong>, which many
folks might prefer over the heavy OpenSSL’s one. I, too, prefer lightweight
libraries.</p><p>I am uninstalling LibreSSL on my systems, therefore this might be the perfect
time to experiment with something different. I have found an interesting (and
well done!) library called <em><strong><a href="https://wolfssl.com/">wolfSSL</a></strong></em> that claims to have an <em>OpenSSL
compatibility layer</em>. It also claims to be 20 times smaller than OpenSSL.</p><h2 id="installation">Installation</h2><p><strong>wolfSSL</strong> is a small C library; It uses <em>autotools</em> to build and <strong>CMake</strong>
support is being added (sigh!). Upon running <code>configure</code>, I am overwhelmed by
the quantity of compile options available.</p><figure><img src="https://danyspin97.org/img/replacing-openssl-part-1-wolfssl/wolf-ssl-configure.jpg" alt=""><figcaption>some of the wolfSSL configure options</figcaption></figure><p>Fortunately, there is one comfy option which I’ve used
when compiling wolfSSL: <code>--enable-all</code>. It enables all options, including
the OpenSSL compatibility layer and leaves out the <em>SSL 3</em> protocol.</p><p>Upon completing the build and installation (which takes a couple of
minutes), a library <code>libwolfssl.so</code> will be installed into <code>/usr/lib</code>, as
well as a pkgconfig file (<code>wolfssl.pc</code>) and all the headers.</p><h2 id="out-of-the-box-support">Out of the box support</h2><p>Key applications provide support for different SSL implementations other than
OpenSSL. For example <em>curl</em> supports <em>mbedTLS</em>, <em>BearSSL</em> and our <strong>wolfSSL</strong>.
To compile <em>curl</em> using wolfSSL, we just need to add <code>--with-ssl=wolfssl</code> and
we’re done. I am aware of only two packages that have out of the box support
for wolfSSL and they are <em>curl</em> and <em><a href="https://gitlab.com/gnuwget/wget2">wget2</a></em> (not the legacy version!).</p><h2 id="openssl-compatibility">OpenSSL compatibility</h2><p><code>--enable-all</code> configure option enabled the OpenSSL compatibility layer.
To use this layer, according to the <a href="https://www.wolfssl.com/docs/wolfssl-manual/ch13/">documentation</a>, we need to link the wolfssl
library manually by adding <code>-lwolfssl</code> as link argument. We also need to
include the path <code>/usr/include/wolfssl</code> so that the OpenSSL headers in
<code>/usr/include/wolfssl/openssl</code> will be picked up.</p><p>This way both wolfSSL and OpenSSL can coexist on the same system and the latter
can be replaced on a per project basis. However, that’s not what we want since
want to replace OpenSSL at a system level.</p><p>Adding the link flag to each package on the system or patching one by one
is not an option as it would take too much time. Let’s instead apply some
workarounds.</p><p>First, we create a symlink for the headers:</p><div><pre><code data-lang="bash">$ sudo ln -sf /usr/include/wolfssl/openssl /usr/include/openssl
</code></pre></div><p>Then we create a symlink for each library. OpenSSL provides the following
libraries:</p><ul><li><code>libssl.so</code></li><li><code>libcrypto.so</code></li></ul><p>So we can run:</p><div><pre><code data-lang="bash">$ sudo ln -sf /usr/lib/libwolfssl.so /usr/lib/libssl.so
$ sudo ln -sf /usr/lib/libwolfssl.so /usr/lib/libcrypto.so
</code></pre></div><h3 id="fixing-pkg-config">Fixing pkg-config</h3><p>Some software rely on pkg-config for checking OpenSSL dependency since
it provides the following pkg-config files:</p><ul><li><code>libssl.pc</code></li><li><code>libcrypto.pc</code></li><li><code>openssl.pc</code></li></ul><p>My system doesn’t currently have either OpenSSL or LibreSSL installed, so any
attempt to include OpenSSL by using pkg-config will fail. We can fix this by
adding a pkg-config file in <code>/usr/lib/pkgconfig/openssl.pc</code>:</p><pre><code>prefix=/usr/x86_64-pc-linux-musl
includedir=${prefix}/include/wolfssl

Name: openssl
Description: wolfssl C library.
Version: 4.6.0
Requires: wolfssl
Cflags: -I${includedir}
</code></pre><p>Our pkg-config file will include the correct directory containing the OpenSSL
headers. It will also import cflags and link flags from the wolfssl pkg-config.
Let’s try if it works as intended:</p><div><pre><code data-lang="bash">$ pkg-config --cflags --libs openssl
-I/usr/x86_64-pc-linux-musl/include/wolfssl -lwolfssl
</code></pre></div><p>Yes! Now we just need create symlinks the other two pkg-config files:</p><div><pre><code data-lang="bash">$ sudo ln -sf /usr/lib/pkgconfig/openssl.pc /usr/lib/pkgconfig/libssl.pc
$ sudo ln -sf /usr/lib/pkgconfig/openssl.pc /usr/lib/pkgconfig/libcrypto.pc
</code></pre></div><p>Now we’re ready to compile system packages.</p><h2 id="compiling-system-packages">Compiling system packages</h2><p>Before actually going further into the various compile results, there are few
general changes that I’ve done:</p><ol><li>Include the default <code>/usr/include/wolfssl/option.h</code> provided in
<code>/usr/include/wolfssl/wolfcrypt/setting.h</code>. This way we will have a bunch of
defines already included that enable many wolfSSL features.</li><li>Remove some defines from <code>option.h</code> that disable old OpenSSL features, like
old SSL names. While I understand that these features are plainly old (or even
deprecated), projects will still use them as long as they haven’t been
removed upstream.</li><li>Define <code>OPENSSL_NO_WHIRPOOL</code> in the same header as above, since this feature
ins’t implemented in wolfSSL. There are other <code>OPENSSL_NO_*</code> defines there for
unimplemented features, but this one was missing.</li></ol><h3 id="wget">wget</h3><p><em><a href="https://www.gnu.org/software/wget/">wget</a></em>, which comes installed on any Unix system, is the first software we’ll
try building with wolfSSL and its OpenSSL compatibility layer.</p><figure><img src="https://danyspin97.org/img/replacing-openssl-part-1-wolfssl/wget-error-1.jpg" alt=""><figcaption>wget compile error</figcaption></figure><p>wget complains about two undeclared identifiers:</p><ul><li><code>CONF_MFLAGS_DEFAULT_SECTION</code></li><li><code>CONF_MFLAGS_IGNORE_MISSING_FILE</code></li></ul><p>We can fix this by adding the defines from the OpenSSL file <code>openssl/conf.h</code>
to <code>/usr/include/wolfssl/option.h</code>:</p><div><pre><code data-lang="c"><span># define CONF_MFLAGS_IGNORE_MISSING_FILE 0x10
</span><span># define CONF_MFLAGS_DEFAULT_SECTION     0x20
</span></code></pre></div><figure><img src="https://danyspin97.org/img/replacing-openssl-part-1-wolfssl/wget-error-2.jpg" alt=""><figcaption>wget link-time errors about missing symbols</figcaption></figure><p>We arrived at link-time, that’s huge! However, there are 8 undefined symbols:
6 symbols about unimplemented features in wolfSSL, such as <code>i2d_x509_PUBKEY</code>
and <code>a2i_IPADDRESS</code>; 2 symbols regarding wolfSSL functions. The latter could
probably be fixed by adding the proper compile time option to wolfSSL, like
<code>--enable-sslv3</code>.</p><h3 id="rhash">rhash</h3><p>rhash is an utility that calculates and verifies message digests, such as
<em>SHA256</em> and <em>MD5</em>. It is required by CMake, so we can consider it an essential
package. Compiling rhash led to many errors. Let’s look in depth at some of
them.</p><figure><img src="https://danyspin97.org/img/replacing-openssl-part-1-wolfssl/rhash-error-1.jpg" alt=""><figcaption>rhash compile error about RIPEMD160_CTX</figcaption></figure><p><em>rhash</em> uses <code>RIPEMD160_CTX</code> which is not implemented by wolfSSL.</p><figure><img src="https://danyspin97.org/img/replacing-openssl-part-1-wolfssl/rhash-error-2.jpg" alt=""><figcaption>rhash compile error about WOLFSSL_MD5_CTX</figcaption></figure><p>This time, rhash access a member of <code>MD5_CTX</code> (which wolfSSL has replaced by
<code>WOLFSSL_MD5_CTX</code>) using <code>offsetof</code>. The original <code>MD5_CTX</code> struct looks like
this:</p><div><pre><code data-lang="c"><span>typedef</span> <span>struct</span> <span>MD5state_st</span> <span>{</span>
    <span>MD5_LONG</span> <span>A</span><span>,</span> <span>B</span><span>,</span> <span>C</span><span>,</span> <span>D</span><span>;</span>
    <span>MD5_LONG</span> <span>Nl</span><span>,</span> <span>Nh</span><span>;</span>
    <span>MD5_LONG</span> <span>data</span><span>[</span><span>MD5_LBLOCK</span><span>];</span>
    <span>unsigned</span> <span>int</span> <span>num</span><span>;</span>
<span>}</span> <span>MD5_CTX</span><span>;</span>
</code></pre></div><p><code>WOLFSSL_MD5_CTX</code> instead looks like this:</p><div><pre><code data-lang="c"><span>typedef</span> <span>struct</span> <span>WOLFSSL_MD5_CTX</span> <span>{</span>
    <span>/* big enough to hold wolfcrypt md5, but check on init */</span>
<span>#ifdef STM32_HASH
</span><span></span>    <span>void</span><span>*</span> <span>holder</span><span>[(</span><span>112</span> <span>+</span> <span>WC_ASYNC_DEV_SIZE</span> <span>+</span> <span>sizeof</span><span>(</span><span>STM32_HASH_Context</span><span>))</span> <span>/</span> <span>sizeof</span><span>(</span><span>void</span><span>*</span><span>)];</span>
<span>#else
</span><span></span>    <span>void</span><span>*</span> <span>holder</span><span>[(</span><span>112</span> <span>+</span> <span>WC_ASYNC_DEV_SIZE</span><span>)</span> <span>/</span> <span>sizeof</span><span>(</span><span>void</span><span>*</span><span>)];</span>
<span>#endif
</span><span></span><span>}</span> <span>WOLFSSL_MD5_CTX</span><span>;</span>
</code></pre></div><p>I think that this incosistency between OpenSSL and wolfSSL structs <em>will</em>
happen again with different data types.</p><h3 id="libssh2">libssh2</h3><p>From the official <a href="https://www.libssh2.org/">libssh2</a> site:</p><blockquote><p><em>libssh2 a client-side C library implementing the SSH2 protocol</em></p></blockquote><p>curl has a hard dependency on libssh2, so we can consider it another essential
package.</p><figure><img src="https://danyspin97.org/img/replacing-openssl-part-1-wolfssl/libssh2-error-1.jpg" alt=""><figcaption>libssh2 build errors</figcaption></figure><p>This time there are only 2 errors, both about unimplemented features:
<code>EVP_bf_cbc</code> and <code>EVP_cast5_cbc</code>. The man pages are the best source of
information about OpenSSL functions; we can browse them by running:</p><div><pre><code data-lang="bash">$ man EVP
$ man EVP_bf_cbc
$ man EVP_cast5_cbc
</code></pre></div><p>Let’s split the names and study each part:</p><ul><li><code>EVP</code> is a high-level interface to cryptographic functions</li><li><code>bf</code> and <code>cast5</code> are the name of the algorithms, <em><a href="https://en.wikipedia.org/wiki/Blowfish_(cipher)">blowfish</a></em> and <em><a href="https://en.wikipedia.org/wiki/CAST-128">CAST</a></em>
respectively.</li><li><code>cbc</code>, <em><a href="https://en.wikipedia.org/wiki/Block_cipher_mode_of_operation#:~:text=Cipher%20block%20chaining%20(CBC),-CBC&amp;text=In%20CBC%20mode%2C%20each%20block,used%20in%20the%20first%20block.">Cipher Block Chaining</a></em>, is a mode of operation that tells OpenSSL
to operate on each block seperately from the others.</li></ul><p>Operating cryptographic functions in <em>CBC</em> mode isn’t really safe nor the
two algorithms above are really popular, so I understand why wolfSSL developers
might have prioritized other things over implementing the two functions above.</p><h3 id="ffmpeg">ffmpeg</h3><p><em><a href="https://ffmpeg.org/">ffmpeg</a></em> is a powerful library and a collection of utilities for handling
images, audio and videos. It is required by <em>Firefox</em>, <em>Chromium</em>, <em>mpv</em> and
another hundred and a half software (at least). We surely don’t want a system
without this library.</p><figure><img src="https://danyspin97.org/img/replacing-openssl-part-1-wolfssl/ffmpeg-error.jpg" alt=""><figcaption>ffmpeg build error</figcaption></figure><p>This time there is only one error (but others may still pop up later while
building!). The function <code>BN_sub_word</code> is missing. According to the man pages,
it is the arithmetic function that perform subtractions on big integers.
This seems pretty straightforward …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://danyspin97.org/blog/replacing-openssl-part-1-wolfssl/">https://danyspin97.org/blog/replacing-openssl-part-1-wolfssl/</a></em></p>]]>
            </description>
            <link>https://danyspin97.org/blog/replacing-openssl-part-1-wolfssl/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25666301</guid>
            <pubDate>Thu, 07 Jan 2021 02:01:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Shooting photos with an IMAX projector lens]]>
            </title>
            <description>
<![CDATA[
Score 166 | Comments 63 (<a href="https://news.ycombinator.com/item?id=25666217">thread link</a>) | @dmitrygr
<br/>
January 6, 2021 | https://theslantedlens.com/2021/crazy-huge-imax-lens-amazing-street-portraits/ | <a href="https://web.archive.org/web/*/https://theslantedlens.com/2021/crazy-huge-imax-lens-amazing-street-portraits/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><p>What the heck is that huge lens? That Crazy Huge Lens is an IMAX Lens. You will be surprised at the cool street portraits we got with this thing. Take a look at how Jay P rigged this with his <a href="https://bhpho.to/38bRbgL">Canon EOS R</a> camera and the amazing results.</p>
<p><iframe width="750" height="450" src="https://www.youtube.com/embed/D-ihZrP4C0A" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="allowfullscreen"></iframe></p>
<p>This is Jay P Morgan. Today on The Slanted Lens we are in Santa Monica at a skate park. <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_8.png" alt="" width="1092" height="611" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_8.png 1092w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_8-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_8-768x430.png 768w" sizes="(max-width: 1092px) 100vw, 1092px">This is a great skate park. I’ve been here before with my daughter who comes down to skate. <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_35.png" alt="" width="1070" height="600" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_35.png 1070w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_35-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_35-768x431.png 768w" sizes="(max-width: 1070px) 100vw, 1070px">This time I came with this huge IMAX lens. <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_1.png" alt="" width="1072" height="598" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_1.png 1072w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_1-300x167.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_1-768x428.png 768w" sizes="(max-width: 1072px) 100vw, 1072px">This thing is a beast. It’s an IMAX lens and it was made by Iwerks. I’ve had it in a huge hard case in my storage for a long, long time. I’ve always wanted to adapt this to a camera and take portraits with it. <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_2.png" alt="" width="1071" height="601" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_2.png 1071w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_2-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_2-768x431.png 768w" sizes="(max-width: 1071px) 100vw, 1071px">So I want to do street portraits with an IMAX Lens using my Canon EOS R Camera. So here’s the process I went through to get this lens adapted, so I’ll be able to focus it and work with it.</p>
<p><img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_9.png" alt="" width="1090" height="611" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_9.png 1090w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_9-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_9-768x431.png 768w" sizes="(max-width: 1090px) 100vw, 1090px"> <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_10.png" alt="" width="1093" height="612" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_10.png 1093w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_10-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_10-768x430.png 768w" sizes="(max-width: 1093px) 100vw, 1093px"> <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_11.png" alt="" width="1092" height="612" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_11.png 1092w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_11-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_11-768x430.png 768w" sizes="(max-width: 1092px) 100vw, 1092px"> <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_12.png" alt="" width="1091" height="612" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_12.png 1091w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_12-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_12-768x431.png 768w" sizes="(max-width: 1091px) 100vw, 1091px"> <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_14.png" alt="" width="1091" height="611" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_14.png 1091w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_14-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_14-768x430.png 768w" sizes="(max-width: 1091px) 100vw, 1091px"> <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_15.png" alt="" width="1086" height="610" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_15.png 1086w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_15-300x169.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_15-768x431.png 768w" sizes="(max-width: 1086px) 100vw, 1086px"> <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_16.png" alt="" width="1094" height="610" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_16.png 1094w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_16-300x167.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_16-768x428.png 768w" sizes="(max-width: 1094px) 100vw, 1094px"> <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_17.png" alt="" width="1091" height="610" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_17.png 1091w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_17-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_17-768x429.png 768w" sizes="(max-width: 1091px) 100vw, 1091px"> <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_18.png" alt="" width="1088" height="610" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_18.png 1088w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_18-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_18-768x431.png 768w" sizes="(max-width: 1088px) 100vw, 1088px">Let’s take some pictures. The way I focus this thing is so silly. <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_20.png" alt="" width="1092" height="611" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_20.png 1092w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_20-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_20-768x430.png 768w" sizes="(max-width: 1092px) 100vw, 1092px">I have a track that I can release here and I can move my camera back and forth inside this tape I put around the lens. Then I find the point where it focuses. It’s pretty gorilla. Very, very gorilla, but it works.<img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_25.png" alt="" width="1072" height="599" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_25.png 1072w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_25-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_25-768x429.png 768w" sizes="(max-width: 1072px) 100vw, 1072px"></p>
<p>So in this situation I don’t have a lens on the front of the camera. So if the camera is going to fire without a lens on it, you have to go to the menus and you’ve have to turn on the setting which will allow the camera to fire when there’s no lens attached. There’s no coupling here. <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_26.png" alt="" width="1071" height="600" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_26.png 1071w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_26-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_26-768x430.png 768w" sizes="(max-width: 1071px) 100vw, 1071px">This is just a space between the lens and the front of the camera. I did have to turn that feature on that will allow me to shoot without a lens in order to make this work.</p>
<p><img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_28.png" alt="" width="1070" height="599" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_28.png 1070w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_28-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_28-768x430.png 768w" sizes="(max-width: 1070px) 100vw, 1070px"> <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_29.png" alt="" width="1070" height="597" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_29.png 1070w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_29-300x167.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_29-768x429.png 768w" sizes="(max-width: 1070px) 100vw, 1070px">This lens is so interesting because it has a 180 degree angle of view. So I can get right here close and to the side and I’m in the shot. And I am in the shot when I move all the way around to the other side.</p>
<p><img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_30.png" alt="" width="1071" height="599" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_30.png 1071w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_30-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_30-768x430.png 768w" sizes="(max-width: 1071px) 100vw, 1071px">This lens has a really strange quality because my face is in focus, but the area around it is out of focus. It almost has a tilt shift kind of quality like it’s you’re focusing on one point. <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_31.png" alt="" width="1072" height="599" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_31.png 1072w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_31-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_31-768x429.png 768w" sizes="(max-width: 1072px) 100vw, 1072px">When you get somebody up front like this, it gives you a blur all the way around. It’s very cool looking.</p>
<p><img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_37.png" alt="" width="1070" height="600" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_37.png 1070w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_37-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_37-768x431.png 768w" sizes="(max-width: 1070px) 100vw, 1070px"> <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_38.png" alt="" width="1071" height="600" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_38.png 1071w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_38-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_38-768x430.png 768w" sizes="(max-width: 1071px) 100vw, 1071px"></p>
<p>I’m learning as we go along here, it doesn’t have a flat plane of focus, but I think that’s because of the way I mounted the camera back there. It’s a little bit like a tilt shift. So I didn’t get them quite square, which is kind of cool because I get the face in focus, but the hands or the body go out of focus in the foreground. It’s just kind of cool looking.</p>
<p><img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_39.png" alt="" width="1067" height="596" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_39.png 1067w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_39-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_39-768x429.png 768w" sizes="(max-width: 1067px) 100vw, 1067px"></p>
<p>One of the reasons I love to carry a light in my bag is anytime I’m doing a street portrait or something, a continuous light is so easy to flip up really fast. It gives us a little bit of light on the face and opens up the shadows. The <a href="https://bhpho.to/32nCIvK">LitraStudio</a> is perfect for that because it’s easy. <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_40.png" alt="" width="1074" height="601" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_40.png 1074w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_40-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_40-768x430.png 768w" sizes="(max-width: 1074px) 100vw, 1074px">Turn it on and it’s so powerful, it’s worth the weight. It’s not like one of the little tiny ones Litra makes. I like the bigger heavier light because it just gives me so much more power. Especially in a situation like this where you have the sun to deal with.</p>
<p><img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_42.png" alt="" width="1072" height="601" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_42.png 1072w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_42-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_42-768x431.png 768w" sizes="(max-width: 1072px) 100vw, 1072px"></p>
<p>So there you have it. I’m going to do more of this. <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_44.png" alt="" width="1072" height="602" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_44.png 1072w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_44-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_44-768x431.png 768w" sizes="(max-width: 1072px) 100vw, 1072px">I want to adapt some other lenses to my EOS R and just try to get weird views and that kind of gritty look. This actually was way cleaner than I thought it was going to be. <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_46.png" alt="" width="1071" height="600" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_46.png 1071w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_46-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_46-768x430.png 768w" sizes="(max-width: 1071px) 100vw, 1071px">I don’t even have something blocking the light between the camera and the lens. I used just a little bit of tape in here. But it projects a great image on the sensor. It’s a little hard to focus but a lot of fun to shoot. <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_48.png" alt="" width="1071" height="600" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_48.png 1071w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_48-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_48-768x430.png 768w" sizes="(max-width: 1071px) 100vw, 1071px">So I hope you enjoyed this. Make sure you subscribe to the channel and ring that bell. Keep those cameras rollin’ and keep on clickin’.</p>
<p>Check out <a href="https://bhpho.to/32nCIvK">LitraStudio lights</a>:</p>
<p><img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_50.png" alt="" width="1073" height="599" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_50.png 1073w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_50-300x167.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_50-768x429.png 768w" sizes="(max-width: 1073px) 100vw, 1073px"> <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_51.png" alt="" width="1070" height="600" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_51.png 1070w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_51-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_51-768x431.png 768w" sizes="(max-width: 1070px) 100vw, 1070px"> <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_52.png" alt="" width="1072" height="597" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_52.png 1072w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_52-300x167.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_52-768x428.png 768w" sizes="(max-width: 1072px) 100vw, 1072px"> <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_53.png" alt="" width="1071" height="598" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_53.png 1071w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_53-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_53-768x429.png 768w" sizes="(max-width: 1071px) 100vw, 1071px"></p>
<!-- AddThis Advanced Settings above via filter on the_content --><!-- AddThis Advanced Settings below via filter on the_content --><!-- AddThis Advanced Settings generic via filter on the_content --><!-- AddThis Share Buttons above via filter on the_content --><!-- AddThis Share Buttons below via filter on the_content --><!-- AddThis Share Buttons generic via filter on the_content --><!-- AddThis Related Posts below via filter on the_content --><!-- AddThis Related Posts generic via filter on the_content --><!--<rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
			xmlns:dc="http://purl.org/dc/elements/1.1/"
			xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/">
		<rdf:Description rdf:about="https://theslantedlens.com/2021/crazy-huge-imax-lens-amazing-street-portraits/"
    dc:identifier="https://theslantedlens.com/2021/crazy-huge-imax-lens-amazing-street-portraits/"
    dc:title="Crazy Huge Imax Lens &#8211; Amazing Street Portraits"
    trackback:ping="https://theslantedlens.com/2021/crazy-huge-imax-lens-amazing-street-portraits/trackback/" />
</rdf:RDF>-->
</div></article></div>]]>
            </description>
            <link>https://theslantedlens.com/2021/crazy-huge-imax-lens-amazing-street-portraits/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25666217</guid>
            <pubDate>Thu, 07 Jan 2021 01:50:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A developer's perspective: the problem with screen reader testing]]>
            </title>
            <description>
<![CDATA[
Score 69 | Comments 52 (<a href="https://news.ycombinator.com/item?id=25665851">thread link</a>) | @jacobtracey
<br/>
January 6, 2021 | https://jaketracey.com/a-developers-perspective-the-problem-with-screen-reader-testing/ | <a href="https://web.archive.org/web/*/https://jaketracey.com/a-developers-perspective-the-problem-with-screen-reader-testing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/Article"><header><p>January 06, 2021</p></header><section itemprop="articleBody"><p>Screen readers are an essential part of using the web for people who are vision impaired, illiterate or have a learning disability.</p>
<p>Today’s screen readers traverse web pages and applications and read out user interface elements, content and allow users to navigate and interact with the web.</p>
<p>There are many screen readers available for different devices and platforms, each with differing levels of functionality, interfaces and features. The most common are JAWS, NVDA, VoiceOver and TalkBack.</p>
<p>According to the latest <a href="https://webaim.org/projects/screenreadersurvey8/">WebAIM Screen Reader User Survey</a>, when it comes to desktop screen reader usage, JAWS and NVDA are practically equal in usage, with around 40% of respondents reporting that they use one or the other.</p>
<figure>
<img src="https://jaketracey.com/webaim-graph.png" alt="Line chart of primary screen reader usage since October 2009. JAWS has steady decline from 68% to 40%. NVDA has steady incline from 3% to 41%. VoiceOver has a slow incline from 10% to 13%.">
<figcaption>Source: WebAIM</figcaption>
</figure>
<p>Based on the graph above, there’s a clear pattern over the course of the last 10 years, with NVDA usage increasing as JAWS usage drops, culminating in an inflection point in 2019 when NVDA surpassed JAWS usage for the first time.</p>
<p>As a developer regularly faced with time constraints, I have often wondered: what should be the baseline in terms of testing for screen readers, and what browser and screen reader combinations are the most important to cover in order to achieve the greatest level of WCAG compliance?</p>
<h2>An issue of time</h2>
<p>Given that almost all web applications developed in 2021 are also used on mobile and therefore require testing on both iOS and Android devices, as well as Windows and macOS for desktop users, providing adequate support for such a broad range of scenarios becomes quite difficult to manage.</p>
<p>Let’s say in a best-case scenario, a given page or feature will be tested on the following combinations:</p>
<ul>
<li>iOS / VoiceOver</li>
<li>Android / TalkBack</li>
<li>macOS / Chrome / VoiceOver</li>
<li>macOS / Safari / VoiceOver</li>
<li>macOS / Firefox / VoiceOver</li>
<li>Windows / Microsoft Edge / NVDA</li>
<li>Windows / Chrome / NVDA</li>
<li>Windows / Firefox / NVDA</li>
<li>Windows / Microsoft Edge / JAWS</li>
<li>Windows / Chrome / JAWS</li>
<li>Windows / Firefox / JAWS</li>
</ul>
<p>I should clarify that by “best-case”, I am conveniently leaving out any versions of Internet Explorer, but as frustrating as it may be, including it would add at least another 2 rounds of testing.</p>
<p>It’s also worth noting that WebAIM also recommends using Microsoft Edge with Narrator, but given its low usage, we’ll leave it out (more on this later).</p>
<p>Hypothetically, depending on the size of the functionality or page implemented, let’s say each round of testing takes one hour to complete, assuming the developer has experience with each of these browsers and screen readers.</p>
<p>In this scenario, comprehensively testing screen reader support across all these combinations adds 11 hours of development work – and that’s just to test!</p>
<h2>An issue of fragmentation</h2>
<p>Web developers will be familiar with the issues surrounding browser version fragmentation, and this problem is compounded when testing with screen readers. Contending with not only varying levels of HTML, Javascript and CSS support in the browser can be tough, and to combat this, polyfills and tools like <a href="https://caniuse.com/">caniuse.com</a> have made life a lot easier.</p>
<p>When it comes to screen reader version fragmentation, there is very little in the way of either documentation or support for developers. Fixing issues often comes down to a case of trial and error, retesting and hoping for the best.</p>
<p>A piece of information that would be incredibly useful in this area would be <em>penetration of screen reader updates</em> from the vendors. If, for instance, developers knew that there was a high adoption rate of updates among screen reader users, they could be confident that if a screen reader update resolved an issue, patches for older versions could be sunsetted. This approach has worked exceptionally well for browsers such as Chrome and Firefox.</p>
<p>Sadly, there’s not currently any way for a developer to identify the type or version of a screen reader that is being used, so implementing targeted fixes isn’t an option anyway right now.</p>
<h2>A case for dedicated accessibility testers</h2>
<p>Given the scope and time it takes to properly test across so many devices, browsers and screen readers, having dedicated accessibility testers embedded into teams can significantly increase the quality and speed with which properly accessible applications can be produced.</p>
<p>Let’s face it: developers already have a hard time keeping up with the pace of change in their own domain, let alone the level of knowledge required for comprehensive accessibility auditing.</p>
<p>That is not to say that developers should ignore accessibility completely. However, expecting someone to know about a specific bug on a particular combination of code, browser and screen reader is too much, even for the most experienced accessibility-focused developer.</p>
<h2>Why automation isn’t enough</h2>
<p>The old saying "a good programmer is a lazy programmer" comes to mind when I think about testing here. Being lazy myself (although possibly not that great of a programmer), I rely on automated tools like <a href="https://www.deque.com/axe/">axe</a> to do most of my accessibility for me. While the current range of tooling is excellent, and picks up the most obvious issues, when it comes to screen readers there’s no way around it: you need to manually test.</p>
<p>Why? Well, the current state of both browsers and screen reader support is all over the place. To highlight this, the Powermapper website has a neat <a href="https://www.powermapper.com/tests/screen-readers/aria/">list of screen reader support for WAI-ARIA attributes</a>. Not throwing shade at any one – things are continuously improving with updates to browsers and screen readers – but the point stands. Current automated testing tools are not going to catch these problems because they essentially test the validity of code, in much the same way as a code linter does.</p>
<h2>A compromise, so we can all still get stuff done</h2>
<p>Not every team has the luxury of a dedicated accessibility tester, or even a dedicated tester for that matter. Sometimes, you just need to do the best you can, with the resources that you have available.</p>
<p>"When can we stop supporting this?" has been the desperate cry of developers for years when it comes to Internet Explorer 9/10 and most recently 11, and as their usage has dropped, so has the rate of developers losing their hair trying to get their code working.</p>
<p>Which brings me back to Microsoft Edge with Narrator, as mentioned earlier. With 1% of users in that survey, and possibly 0% of users for your application or site, is it worth testing on this combination at all? More specifically, what number of users justifies support, and the testing and development overhead that comes with it?</p>
<h3>Windows - Chrome (latest version), NVDA</h3>
<p>As of December 2020, Chrome is by far the most popular browser in the world, with 65.3% of users. Later versions of Microsoft Edge utilize the same rendering engine, so there is a high likelihood that if it works in Chrome, it will work similarly in Edge.</p>
<p>Based on the WebAIM stats, it is a safe bet that NVDA will begin to increase its lead over JAWS over the next few years. Given that it is also open-source and free, I can’t help but draw a comparison to the way Firefox overtook Internet Explorer in the 2000s browser wars.</p>
<h3>macOS - Safari (latest version), VoiceOver</h3>
<p>Safari is a fair distance behind Chrome in terms of users, with 16.7% share as of writing, but it has the benefit of being the default browser in macOS. It is also free, and the support for accessibility features with VoiceOver is second to none. In addition to this, because of the similarity with its mobile counterpart, most likely any issues that are identified in the desktop version will have similar fixes.</p>
<h3>iOS - Safari (latest version), VoiceOver</h3>
<p>Safari is by far the most popular browser on iOS and all other browsers on iOS use the WebKit rendering engine. VoiceOver is the gold standard for mobile screen readers (and the only option for iOS devices), and as such it makes sense to use this combination for testing iOS accessibility.</p>
<h3>Android - Chrome (latest version), TalkBack</h3>
<p>In a similar vein to iOS, being the default browser and screen reader combination for Android makes this a simple choice, as it will cover the vast majority of users on this platform. Although manufacturers do include their own browsers and there are quite a few other options on Android, the vast majority of the time they use the inbuilt rendering engine, so the expectation in terms of accessibility should be similar, if not identical, to the Chrome experience.</p>
<p>This is by no means a catch-all solution for everyone. Each circumstance will be different, and the best course of action would be to engage your users and ask rather than trying to make the decision for them.</p>
<p>The reality is that if your site or application’s design or functionality looks bad or works poorly for a large enough number of your users because it does not support the software that they use, it can have potential ramifications to your business, through sales or reputation. Similarly, poor accessibility will have a negative impact if your users are using older versions of screen readers and browser combinations.</p>
<h2>But what about JAWS, ZoomText, System Access, <em>insert screen reader here</em>?</h2>
<p>At the risk of being slightly incendiary, I dislike the idea of paying for something that I can get for free. NVDA is a project that has brought screen readers to everybody – including those without the financial means to pay for it – so I support it. Along with the clear trajectory of its usage uptake, it is not unreasonable to expect that the majority of users will adopt it in the next 5 to 10 years.</p>
<p>At the end of the day, however, your best bet when it comes to identifying where your testing efforts should be placed is to talk to your users to find out what their needs are and what software they use. If you don’t have access to this information, the proposed testing scope above will suffice for the vast majority of your site or application’s users, and most likely will continue to do so in the years to come.</p></section></article></div>]]>
            </description>
            <link>https://jaketracey.com/a-developers-perspective-the-problem-with-screen-reader-testing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25665851</guid>
            <pubDate>Thu, 07 Jan 2021 01:12:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A 1996 Interview with Donald Knuth – On programmer vs. scientist, Dijkstra, C++ [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25665674">thread link</a>) | @eric_cartman
<br/>
January 6, 2021 | http://www.ntg.nl/maps/16/14.pdf | <a href="https://web.archive.org/web/*/http://www.ntg.nl/maps/16/14.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://www.ntg.nl/maps/16/14.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25665674</guid>
            <pubDate>Thu, 07 Jan 2021 00:57:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Takedown of Anna Wiener's Uncanny Valley]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25665352">thread link</a>) | @botoxparty
<br/>
January 6, 2021 | https://min.report/sally-olds/bourgeois-see-bourgeois-do | <a href="https://web.archive.org/web/*/https://min.report/sally-olds/bourgeois-see-bourgeois-do">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://min.report/sally-olds/bourgeois-see-bourgeois-do</link>
            <guid isPermaLink="false">hacker-news-small-sites-25665352</guid>
            <pubDate>Thu, 07 Jan 2021 00:38:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Love’s contradictions: Catullus on the agony of infatuation]]>
            </title>
            <description>
<![CDATA[
Score 50 | Comments 10 (<a href="https://news.ycombinator.com/item?id=25664867">thread link</a>) | @diodorus
<br/>
January 6, 2021 | https://psyche.co/ideas/loves-contradictions-catullus-on-the-agony-of-infatuation | <a href="https://web.archive.org/web/*/https://psyche.co/ideas/loves-contradictions-catullus-on-the-agony-of-infatuation">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><blockquote>I hate and love. If you ask me to explain<br>The contradiction,<br>I canâ€™t, but I can feel it, and the pain<br>Is crucifixion.</blockquote>
<blockquote> <em>Odi et amo: quare id faciam fortasse requiris.</em><br><em>Nescio, sed fieri sentio et excrucior.</em> </blockquote>
<p><strong>This simple but heartfelt</strong> couplet (translation above by James Michie in 1969) is the best-known Latin love epigram â€“ a short poem in elegiac metre â€“ that survives from Ancient Rome. Composed by the poet Catullus around <span>55 BCE,</span> <span>number 85</span> of his book of <span>116 poems,</span> it pithily encapsulates the searing conflict of emotions that he claims to be experiencing in the course of his affair with a younger married woman, who is addressed in other poems as his â€˜girlâ€™ (<em>puella</em>) and by the pseudonym â€˜Lesbiaâ€™. But for such a short poem â€“ just 14 words in Latin â€“ it has raised a whole host of questions, and hundreds of pages have been written about it. What is the point of the poem? How should it be translated from the Latin? How does it relate to the poetâ€™s life and feelings? Its psychology comes across as complex and strikingly modern, as does much of Catullusâ€™s poetry; to some, the questions it raises might seem more suited to a post-FreudÂ­ian examination of mental conflict than to the concerns of an ancient poet. We might recognise that the opposite emotions of love and hate can be simultaneously entertained; but how, after all, does that work?</p>
<p>In its original Latin, <span>Poem 85</span> is a so-called elegiac couplet, in which a longer line (hexameter) is followed by a shorter one (pentameter). The words of the poem have been placed with care. The couplet is composed in a criss-cross pattern, beginning and ending with two verbs of intense emotional connotation: <em>odi</em>, â€˜I hateâ€™; and <em>excrucior</em>, â€˜Iâ€™m rackedâ€™. The first line concludes with the questÂ­ioning <em>requiris</em>, â€˜you askâ€™; the second opens with the answer <em>nescio</em>, â€˜I donâ€™t knowâ€™. The middle of the first line has <em>faciam</em>, â€˜I doâ€™; the middle of the second has its passive counterÂ­part <em>fieri</em>, â€˜is being doneâ€™ (related to <em>fiat</em> â€“ literally, â€˜let it be doneâ€™).</p>
<p>The couplet thus mimics by its shape the image of the poet being pulled apart in opposite directions, an image made explicit by the verb <em>excrucior</em>. That word (the root of our â€˜excruciatingâ€™) will have evoked for Romans the noun <em>crux</em> (plural <em>cruces</em>). Although in the <span>1st millennium CE</span> <em>crux</em> came to be heard almost exclusively to mean â€˜crossâ€™ with reference to the crucifixion of Christ, in CatullÂ­usâ€™s time it was more commonly used to signify the â€˜rackâ€™. This was the standard instrument of torture in the Roman world, to which unfortÂ­unate victims were bound by their hands and legs so that their bodies might literally be pulled apart.</p>
<p>While Catullus remains utterly infatuated with Lesbia, she has proved to be <br>distressÂ­ingly fickle to him</p>
<p>No less cruel and visible as a method of executÂ­ion in the Roman world was crucifixion. Catullus was in his teens when in <span>71 BCE</span> the slave-revolt led by Spartacus was quelled, and he would probably have witnessed at first hand the gruesome sight of 6,000 captured slaves being nailed or strung up to die on wooden crosses along the Appian Way leading from Rome to Capua. WhatÂ­ever the precise image intended by Catullus as a parallel to his own feeling of torment, what is evident is that the combination of hate and love, pulling him in different directions, is making him feel as if he is being â€˜racked to deathâ€™: the <em>ex</em> of <em>excrucÂ­ior</em> connotes a process leading towards expiry and extinction, as well as extenÂ­sion â€“ both in time and across space. Moreover, Catullus claims, thereâ€™s nothing he can <em>do</em> about it: heâ€™s simply the object of this torturous and self-contradictory feeling. His response to someone who might wish to enquire (<em>requiÂ­ris</em>) about what heâ€™s â€˜doingâ€™ (<em>faciam</em>) is that heâ€™s not â€˜doingâ€™ anything, but that he senses (<em>sentio</em>) it â€˜being doneâ€™ (<em>fieri</em>) to him: the passive form of the verb corresÂ­ponds to his own passivÂ­ity in the process heâ€™s describing.</p>
<p>However, just before Catullus presents himself as the helpless victim of opposing emotÂ­ions, the answer he gives to the imagined question is unequivocal: â€˜I donâ€™t knowâ€™. The implication of <em>nescio</em> (the negative of <em>scio</em>, â€˜knowâ€™, whence comes our word â€˜scienceâ€™) has been overlooked by generations of translators from the Latin, who have rendered the word <em>quare</em> as â€˜whyâ€™ or â€˜the reason whyâ€™ rather than â€˜howâ€™ â€“ even though itâ€™s clear that Catullus does know, as do his readÂ­ers, why or for what reason heâ€™s prey to emotional conflict. For instance, one of the poemâ€™s earliest English transÂ­lators, the poet Richard Lovelace (1617-57), renders it as:</p>
<blockquote>I hate and love; wouldâ€™st thou the reason know?<br>I know not, but I burn, and feel it so.</blockquote>
<p>Similarly, the translator in the popular Loeb series, which prints classical texts with facing versions in straightforward English, in 1976 had it as:</p>
<blockquote>I hate and love. Why I do so, perhaps you ask? <br>I know not, but I feel it, and I am in torment.</blockquote>
<p>Such translations using â€˜whyâ€™ followed by â€˜I donâ€™t knowâ€™ ask us to suppÂ­ose that Catullus is claiming an inability to understand the reason for his painful emotional turmoil. Yet the poet has already made it abundantly clear, in several other poems describing his affair with Lesbia, that he knows the reason only too well: while he remains utterly infatuated with her, she has proved distressÂ­ingly fickle to him, willing to be unfaithful not only to her husband but to her adultÂ­erous liaison with the poet too. In <span>Poem 72</span> (my translation), Catullus analyses the effect on him of Lesbiaâ€™s infidelity:</p>
<blockquote>You used to say you had eyes for Catullus alone, <br>Lesbia, and would rather hold me in your arms than Jove. <br>My feelings for you then were not just vulgar lust,<br>but the kind of love a father feels for his children and their kin. <br>Now that I know your ways, my desire for you burns ever fiercer,<br>even though youâ€™re far shabbier in my eyes, and flightier. <br>How can this be, you say: itâ€™s because such hurtful treatment <br>is bound to make one desire oneâ€™s lover more, but like them less.</blockquote>
<p>How is it possible, in terms of logic or emotion, to feel both hate and love towards the same person at the same time?</p>
<p>In the final couplet here, Catullus explains to the reader, in terms very similar to those he uses in <span>Poem 85,</span> the paradox of his feelings. The enquirer doesnâ€™t need to ask the cause of the poetâ€™s pain, here described as <em>iniuria</em> (â€˜hurtful treatmentâ€™) because itâ€™s easy to understand: Catullus is wounded by Lesbiaâ€™s sexual intimacy with other lovers and hotly resents her behaviour; but his desire for her, perhaps intensified by the prospect of losing her to a love-rival, is even stronger.</p>
<p><strong>The reader might still </strong>ask how such divergent feelings as love and dislike can coexist in a lover and be directed towards the same object â€“ indeed, the final line above describes someÂ­thing that feels like such an emotional contradiction, the combinÂ­ation of desire with disliking. That divergence is, in <span>Poem 85,</span> yet more starkly expressed with â€˜I hate and loveâ€™ (rendered more emphatically in translations that repeat the â€˜Iâ€™: â€˜I hate and I loveâ€™). But, again, Catullus would expect the reader to ask not â€˜whyâ€™, but â€˜howâ€™; that is, how is it possible, whether in terms of logic or emotion, for someone to feel both hate and love towards the same person at the same time? Since Catullus knows, as do his readers, <em>why</em> heâ€™s prey to these contradictory feelings, only in answer to the question â€˜howâ€™ can it be reasonable for him to follow up, as he does, with â€˜I donâ€™t knowâ€™. Having declared his ignorance of how the perplexing phenomenon of simultaneous opposing emotions can arise, he then abandons analysis and simply testifies to his own torment.</p>
<p>The correctness of the translation of <em>quare</em> as â€˜howâ€™ is confirmed by lexical data. In Catullusâ€™s time and before (as found, for example, in passages written by Catullusâ€™s older contempÂ­orary, the orator Cicero) <em>quare</em> is used to mean â€˜howâ€™ or â€˜in what wayâ€™. It comes to mean â€˜whyâ€™ in the course of the languageâ€™s histÂ­Â­ory; but given the compelling contextual and linguistic arguments for the understanding of what Catullus is asking in <span>Poem 85,</span> what explanation can there be for the persistÂ­ent mistranslation of <em>quare</em> as â€˜whyâ€™ rather than as â€˜howâ€™ in English? (TransÂ­lations into other languages such as Italian, German and French also tend to fluctuate between rendering <em>quare</em> as â€˜whyâ€™ and â€˜howâ€™).</p>
<p>One answer must be that translators have been influenced by a later Latin couplet thatâ€™s as famous as Catullusâ€™s, and indeed alludes to it. A satirical squib <span>(number 32)</span> composed by the poet Martial in the late <span>1st century CE,</span> more than <span>100 years</span> after Catullusâ€™s death, uses the same couplet form:</p>
<blockquote>I donâ€™t like you, Sabidius, and Iâ€™m unable to say why:<br>All I can say is this: I donâ€™t like you.</blockquote>
<blockquote> <em>Non amo te, Sabidi, nec possum dicere quare: </em><br><em>Hoc tantum possum dicere: non amo te</em>.</blockquote>
<p>Nothing is known of the context of the epigram or of the implied feud between the poet and the otherwise unknown Sabidius. But the poem has won a firm, if anecdotal, place in the annals of Latin studies in England. The story (undoubÂ­tedly apocryphal) is told how, as a student at Christ Church College, Oxford, the writer Thomas Brown (1662-1704) committed a misdeÂ­meanour and was sent for punishment to the college dean, a <span>Dr Fell.</span> The dean required Brown to transÂ­late some Latin verse on the spot, and opened a book of epigrams at random to present him with Martialâ€™s couplet. After a momentâ€™s thought, Brown recited, allegedly to the deanâ€™s delight, his witty and memorable version of the poem:</p>
<blockquote>I do not like thee, Doctor Fell, <br>The reason why I cannot tell; <br>But this I know, and know full well, <br>I do not like thee, Doctor Fell.</blockquote>
<p>In the case of Martialâ€™s epigram, â€˜the reason whyâ€™ is a …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://psyche.co/ideas/loves-contradictions-catullus-on-the-agony-of-infatuation">https://psyche.co/ideas/loves-contradictions-catullus-on-the-agony-of-infatuation</a></em></p>]]>
            </description>
            <link>https://psyche.co/ideas/loves-contradictions-catullus-on-the-agony-of-infatuation</link>
            <guid isPermaLink="false">hacker-news-small-sites-25664867</guid>
            <pubDate>Thu, 07 Jan 2021 00:15:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Defending Journalism to Defend the Republic]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25664719">thread link</a>) | @jaredwiener
<br/>
January 6, 2021 | https://blog.nillium.com/defending-journalism-to-defend-the-republic/ | <a href="https://web.archive.org/web/*/https://blog.nillium.com/defending-journalism-to-defend-the-republic/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://images.unsplash.com/photo-1575320181282-9afab399332c?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDI2fHxjYXBpdG9sfGVufDB8fHw&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000 300w,
                            https://images.unsplash.com/photo-1575320181282-9afab399332c?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDI2fHxjYXBpdG9sfGVufDB8fHw&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000 600w,
                            https://images.unsplash.com/photo-1575320181282-9afab399332c?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDI2fHxjYXBpdG9sfGVufDB8fHw&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000 1000w,
                            https://images.unsplash.com/photo-1575320181282-9afab399332c?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDI2fHxjYXBpdG9sfGVufDB8fHw&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://images.unsplash.com/photo-1575320181282-9afab399332c?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDI2fHxjYXBpdG9sfGVufDB8fHw&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000" alt="Defending Journalism to Defend the Republic">
            </figure>

            <section>
                <div>
                    <p>Today is a difficult day in America, a difficult day to be an American.</p><p>Watching the videos of my fellow countrymen breaking windows to get into the U.S. Capitol, seeing the photos of our elected lawmakers huddling under chairs in the House chamber: these are images of our very democracy under attack -- all in an attempt to disrupt what is usually a ceremonial certification of an election.</p><p>As sad and disappointing as the situation is, what is worse is what got us here. &nbsp;Disinformation is real. The vilification of the news media is real. &nbsp;At some point in the last few years, we’ve bifurcated reality, politicizing verifiable facts and even the act of journalism itself.</p><figure><blockquote data-width="550"><p lang="en" dir="ltr">After I called them rioters just now on air, the crowd converged on the area press had gathered so we took off. This is a mob of violent rioters, no other way to put it.</p>— Alexander Marquardt (@MarquardtA) <a href="https://twitter.com/MarquardtA/status/1346940341409226754?ref_src=twsrc%5Etfw">January 6, 2021</a></blockquote>

</figure><p>America is a democracy -- a government by the people, for the people. &nbsp;And in order for the people to govern themselves, we need a well equipped press corps to keep us informed. &nbsp;There cannot be two sets of facts, two universes of truth. &nbsp;We need the reliable journalists to win, to keep us informed, so we can debate ideas, not facts.</p><p>Reporting is not a political act, but it’s also not simply stenography for the powerful. &nbsp;Digging, investigating, holding those in power accountable -- these are the ideals that journalism holds in the highest regard. </p><p>Most who work for reputable news organizations are obsessive in their caution to limit any appearance of impropriety. &nbsp;They adhere to strict editorial standards that the audience is largely unaware of. They are bound by policies and standards that guide how and what they report all designed to ensure credibility in the information they share.</p><p>And yet, disinformation runs wild. &nbsp;The downside of a platform where anyone can post anything, is that anyone can post anything. &nbsp;</p><p>I know many people do not like to pay for news. &nbsp;Frankly, it makes fiscal sense not to when you view it as a commodity and so much is available for free. &nbsp;But when news is commoditized, and taken from an aggregator or a social network, the provenance &nbsp;-- and credibility - can be a gamble.</p><p>It also means that there is ever less money funding the responsible reporting that we need so much. &nbsp;There are technical means to disable ads; there are methods to sneak around paywalls. &nbsp;But each of these actions means that journalism is ever so slightly less economically viable, with dire consequences.</p><p>Newspapers go bankrupt. &nbsp;</p><p>News websites turn to clickbait to attract the remaining ad-viewing traffic they so desperately need.</p><p>And others who abide by no ethics step up to fill the void, which can lead to plagiarizing total fabrication or conspiracy minded fantasists, breathlessly reporting the intricate details of insane theories about the dark side of our leaders. </p><p>All of this makes trust in all media decline (even those that are obsessively reliable), makes the profession less viable, and makes our democracy less informed.</p><p>All of this makes today’s scenes on Capitol Hill possible.</p><p>Journalism is not the enemy. &nbsp;It is the shield that protects us from those that wish to turn us against each other.</p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.nillium.com/defending-journalism-to-defend-the-republic/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25664719</guid>
            <pubDate>Thu, 07 Jan 2021 00:06:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Generational references: 2.3x faster than reference counting (unoptimized)]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25664708">thread link</a>) | @verdagon
<br/>
January 6, 2021 | https://vale.dev/blog/generational-memory | <a href="https://web.archive.org/web/*/https://vale.dev/blog/generational-memory">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div class="page">
    <div>
  

        <div>
          <div>
  

          <div>
            
    
<p>2.3x faster than reference counting, unoptimized!</p>

              <p><span>Jan 5 2021</span> </p>
      
</div>
<section>
<p>
<b>Generational references</b> are a new memory management technique that's easy, deterministic, and <i>very</i> fast.
</p>

</section>
<section>
<p>
This technique is the first ingredient in Vale's final <a href="https://vale.dev/blog/hybrid-generational-memory">hybrid-generational memory</a> design, which is even faster. Our eventual goal is to be as fast as Rust, and perhaps even as fast as C++, while being safer than both. <a href="#note0" data-noteid="0">0</a>
</p>
<p>
This article explains how generational references work, how they compare to reference counting, and what makes it all so fast. <a href="#note1" data-noteid="1">1</a>
</p>

</section>
<section>
<h2 id="built-on-single-ownership">
 Built on Single Ownership</h2>
<p>
Recall that in Vale, an object is freed when its <b>owning reference</b> goes out of scope. An object always has exactly one owning reference pointing to it.
</p>
<p>
We can have as many <b>non-owning</b> references as we want. <a href="#note2" data-noteid="2">2</a>
</p>
<p>
In other languages, when a programmer frees an object and then accidentally dereferences a non-owning reference to it, it can cause memory unsafety and vulnerabilities. <a href="#note3" data-noteid="3">3</a>
</p>
<p>
Our goal is to detect this situation and react to it safely. <a href="#note4" data-noteid="4">4</a>
</p>

</section>
<section>
<h2 id="generational-malloc-and-the-sacred-integer">
 Generational Malloc and the Sacred Integer</h2>
<p>
Generational references use <b>generational malloc</b>, which is like regular malloc, except at the top of every allocation is a <b>generation number</b>, which tracks how many objects have previously been at this memory location.
</p>
<p>
One could also think of it as describing "I am the <b>n</b>th inhabitant of this memory location".
</p>
<p>
Freeing an object will increment its generation number. Nobody else ever modifies it.
</p>

</section>
<section>
<p>
Later on, we use this number to see if a particular object is still alive, explained further below.
</p>

</section>
<section>
<p>
Generational malloc would normally be an adjustment to mimalloc or jemalloc, but we can simulate it with our own <span>genMalloc</span> and <span>genFree</span> functions:
</p>
<ul>
<li>
<span>genFree</span> increments the generation number, and instead of calling <span>free</span> <a href="#note5" data-noteid="5">5</a><a href="#note6" data-noteid="6">6</a>, remembers the allocation in a free-list. There's a free-list for every size class (16b, 24b, 32b, &lt;=48b, &lt;=64b, &lt;=128b, etc).
</li>
<li>
<span>genMalloc</span> pulls from a free-list if possible. If it's empty, it calls <span>malloc</span> and initializes the generation number to 1.
</li>
</ul>
<p>
You can find our experimental implementation in <a href="https://github.com/ValeLang/Vale/blob/master/Midas/src/builtins/genHeap.c">genHeap.c</a>.
</p>

</section>

      </div>
  
<div>

      <nav>
      <p>Generational References</p>
    


      </nav>
      
    

      <div>
        <div>
    
<div id="note0" data-noteid="0">
<p><span>0</span></p><section>
<p>
See <a href="https://vale.dev/blog/hybrid-generational-memory">HGM</a>'s afterword for a hypothetical comparison with Rust!
</p>

</section>
</div>
<div id="note1" data-noteid="1">
<p><span>1</span></p><section>
<p>
 Vale has three release modes:
</p>
<ul>
<li>
<b>Resilient:</b> Fast and 100% safe.
</li>
<li>
<b>Assist:</b> for development, detects logic problems.
</li>
<li>
<b>Unsafe:</b> turns off all safety.
</li>
</ul>
<p>
Resilient mode uses hybrid-generational memory.
</p>

</section>
</div>
<div id="note2" data-noteid="2">
<p><span>2</span></p><section>
<p>
This distinction is similar to C++'s <span>unique_ptr&lt;T&gt;</span> and <span>T*</span>.
</p>

</section>
</div>
<div id="note3" data-noteid="3">
<p><span>3</span></p><section>
<p>
Rust partially solves this, but forces complexity on the programmer and doesn't solve the <a href="https://en.wikipedia.org/wiki/ABA_problem">ABA problem</a>. We'd like a solution that's simpler, solves the whole problem, with as little <a href="https://vale.dev/blog/hybrid-generational-memory#afterword-how-might-it-compare-to-rust">run-time overhead as Rust</a>.
</p>

</section>
</div>
<div id="note4" data-noteid="4">
<p><span>4</span></p><section>
<p>
Such as by halting or stack unwinding.
</p>

</section>
</div>
<div id="note5" data-noteid="5">
<p><span>5</span></p><section>
<p>
 Our experimental implementation doesn't release memory back to the OS until exit, but when a page is empty, the final version will release the page back to the operating system and map its virtual memory to a read-only page containing all 0xFF.
</p>

</section>
</div>
<div id="note6" data-noteid="6">
<p><span>6</span></p><section>
<p>
 When an allocation's generation can't be incremented any more, it's not used again (at least until we can re-map the page).

</p>

</section>
</div>

        </div>
      </div>
    
</div>

    </div>
    <div>
      <div>
  
<section>
<h2 id="generational-reference-more-than-just-a-pointer">
 Generational Reference: More than just a pointer!</h2>

</section>
<section>
<p>
Vale's references are <b>generational references</b>. A generational reference has two things:
</p>
<ul>
<li>
A pointer to the object.
</li>
<li>
A "target generation" integer.
</li>
</ul>
<p>
To create a reference to an object, we get its allocation's generation number, and include it in the reference.
</p>

</section>

      </div>
  


    </div>
    <div>
      <div>
  
<section>
<h3 id="dereferencing">
 Dereferencing</h3>

</section>
<section>
<p>
To dereference a generational reference, we do a "liveness check" to see whether the allocation's generation number <b>still matches</b> our reference's target generation. <a href="#note7" data-noteid="7">7</a>
</p>
<p>
This prevents use-after-free problems, and makes Vale completely memory safe.
</p>

</section>
<section>
<p>
It's as if the reference is saying:
</p>
<p><b>"Hello! I'm looking for the 11th inhabitant of this house, are they still around?"</b>
</p>

</section>
<section>
<p>
and the person who opens the door says:
</p>
<p><b>"No, sorry, I'm the 12th inhabitant of this house, the 11th inhabitant is no more."</b> <a href="#note8" data-noteid="8">8</a>
</p>
<p>
or instead:
</p>
<p><b>"Yes! That is me. Which of my fields would you like to access?"</b>
</p>

</section>

      </div>
  
<div>

      <div>
        <div>
    
<div id="note7" data-noteid="7">
<p><span>7</span></p><section>
<p>
 This is similar to the "generational indices" technique from C++ and Rust, but applied to the entire world instead of just a specific vector.
</p>

</section>
</div>
<div id="note8" data-noteid="8">
<p><span>8</span></p><section>
<p>
 This will safely halt the program, unless the user is explicitly checking whether something is alive (such as for a weak reference).

</p>

</section>
</div>

        </div>
      </div>
    
</div>

    </div>
    <div>
      <div>
  
<section>
<h2 id="speed">
 Speed</h2>

</section>
<section>
<p>
Generational references are only the first steps towards hybrid-generational memory, but we decided to run some early experiments to see how it compares to existing memory models.
</p>
<p>
For this experiment, we benchmarked <a href="#note9" data-noteid="9">9</a> <a href="#note10" data-noteid="10">10</a> three flavors of Vale:
</p>
<ul>
<li>
<b>Unsafe</b>, with no memory safety, the equivalent of C++ (minus caveats, see below!)
</li>
<li>
<b>RC</b>, where we use naive reference counting for all our objects.
</li>
<li>
<b>GM</b>, which uses generational references.
</li>
</ul>

</section>
<section>
<div>
  <table>
    <thead>
      <tr>
        <th>Mode</th>
        <th>Speed&nbsp;(seconds)</th>
        <th>Overhead Compared to Unsafe (seconds)</th>
        <th>Overhead Compared to Unsafe (%)</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <th>Unsafe</th>
        <td>43.82&nbsp;seconds</td>
        <td>n/a</td>
        <td>n/a</td>
      </tr>
      <tr>
        <th>RC</th>
        <td>54.90&nbsp;seconds</td>
        <td>+11.08&nbsp;seconds</td>
        <td>+25.29%</td>
      </tr>
      <tr>
        <th>GM</th>
        <td>48.57&nbsp;seconds</td>
        <td>+4.75&nbsp;seconds</td>
        <td>+10.84%</td>
      </tr>
    </tbody>
  </table>
</div>


</section>

      </div>
  
<div>

      <div>
        <div>
    
<div id="note9" data-noteid="9">
<p><span>9</span></p><section>
<p>
 We used the <a href="https://github.com/ValeLang/Vale/tree/master/benchmarks/BenchmarkRL/vale">BenchmarkRL</a> terrain generator to gather these numbers, with different values for the <span>--region-override</span> flag: <span>unsafe-fast</span>, <span>naive-rc</span>, and <span>resilient-v3</span> respectively.
</p>

</section>
</div>
<div id="note10" data-noteid="10">
<p><span>10</span></p><section>
<p>
 Here, we benchmarked against other flavors of Vale, to isolate the differences between unsafe, reference-counting, and generational references.
</p>
<p>
Once we implement full hybrid-generational memory, we'll be benchmarking against C++ and Rust, stay tuned!

</p>

</section>
</div>

        </div>
      </div>
    
</div>

    </div>
    <div>
      <div>
  
<section>
<p>
Generational references have only 10.84% overhead, <b>less than half the cost of reference counting!</b> These are very promising results, and suggest that full hybrid-generational memory could be incredibly fast.
</p>

</section>
<section>
<p>
Try it out! In the Vale release, you can find a benchmark folder with scripts to run the benchmarks. You can find the source code for the various approaches <a href="https://github.com/ValeLang/Vale/tree/master/Midas/src/c-compiler/region">here</a> (feel free to swing by the <a href="https://discord.gg/SNB8yGH">discord server</a> and we can point you to the right files).
</p>

</section>

      </div>
  


    </div>
    <div>
      <div>
  
<section>
<p>
<b>Note these caveats!</b> To isolate the difference between generational references and the other approaches:
</p>
<ul>
<li>
In all flavors, we only allocate objects on the heap, except for primitives. Future versions will add stack allocations.
</li>
<li>
We used <a href="https://github.com/ValeLang/Vale/blob/master/Midas/src/builtins/genHeap.c">genHeap.c</a> for all versions, though only GM ever touches the generation number, the other versions ignore it. Future versions will integrate generational malloc into jemalloc or mimalloc directly.
</li>
</ul>
<p>
Once we address these limitations, we can get more precise benchmarks against the other approaches.
</p>

</section>

      </div>
  


    </div>
    <div>
      <div>
  
<section>
<h2 id="why-is-this-so-fast">
 Why is this so fast?</h2>

</section>
<section>
<p>
Generational references are much easier for the CPU to handle than reference-counted references, because:
</p>
<ul>
<li>
Generational references have no aliasing/dealiasing overhead, just on dereference.
</li>
<li>
Generational references cause less cache misses.
</li>
<li>
Liveness checks' branching is easier to predict than RC decrements' branching.
</li>
</ul>

</section>
<section>
<p>
We explain these two differences more below.
</p>

</section>

      </div>
  


    </div>
    <div>
      <div>
  
<section>
<h3 id="no-aliasing-costs">
 No Aliasing Costs</h3>

</section>
<section>
<p>
Reference counting is costly:
</p>
<ul>
<li>
Whenever we "alias" (make a new reference to an object), we have to dereference the object to increment its counter.
</li>
<li>
Whenever we "dealias" (throw away a reference), we have to:
</li>
<ul>
<li>
Dereference the object to decrement its counter,
</li>
<li>
If the counter is zero, deallocate it.
</li>
</ul>
</ul>
<p>
For example:
</p>

    <div>
      
      <p><span><span>fn <span>launchShip</span><span>(<span><span><span>ships</span></span> <span>&amp;<span><span>Map</span>&lt;<span>int</span>, <span>&amp;<span>Spaceship</span></span>&gt;</span></span></span>, <span><span><span>id</span></span> <span>int</span></span>, <span><span><span>armada</span></span> <span>&amp;<span><span>List</span>&lt;<span>&amp;<span>Spaceship</span></span>&gt;</span></span></span>)</span> <span>{<br>  <span><span><span><span>ship</span></span></span> = <span><span>ships</span><span>.</span><span>get</span>(<span>id</span>)</span></span>;<br>    <p>  <span><span>armada</span><span>.</span><span>add</span>(<span>ship</span>)</span>;</p><p>  <br>  <br>  <br>  <br>  <br>  <br>}</p></span></span></span></p>
    </div>
  
<p>
As you can see, reference counting incurs a cost whenever we alias or dealias. <b>Generational references don't have that cost.</b> The above snippet would have zero overhead if it used generational references.
</p>

</section>

      </div>
  


    </div>
    <div>
      <div>
  
<section>
<p>
Instead, generational references incur a cost whenever we dereference an object:
</p>

    <div>
      
      <p><span><span>fn <span>getShipName</span><span>(<span><span><span>ships</span></span> <span>&amp;<span><span>Map</span>&lt;<span>int</span>, <span>&amp;<span>Spaceship</span></span>&gt;</span></span></span>, <span><span><span>id</span></span> <span>int</span></span>)</span> <span><span>str</span> </span><span>{<br>  <span><span><span><span>ship</span></span></span> = <span><span>ships</span><span>.</span><span>get</span>(<span>id</span>)</span></span>;<p>  <br>  <br>  <span>ret <span><span>ship</span><span>.</span><span>name</span></span>;</span><br>}</p></span></span></span></p>
    </div>
  

</section>
<section>
<p>
This is cheaper because <b>programs dereference less than they alias and dealias:</b> our sample program had 4.7 million counter adjustments, but only 1.3 million liveness checks. <a href="#note11" data-noteid="11">11</a> <a href="#note12" data-noteid="12">12</a>
</p>

</section>
<section>
<h3 id="more-cache-friendly">
 More Cache Friendly</h3>
<p>
Reference counting is not very "cache friendly". Adding and subtracting integers is basically free on modern CPUs, but the real bottleneck in modern programs is how <i>far</i> those integers are: if it's been recently accessed, it's in the nearby cache, and only takes a few CPU cycles to fetch. Otherwise the CPU will "cache miss" and have to bring it in all the way from RAM, which could take <b>hundreds</b> of cycles. <a href="#note13" data-noteid="13">13</a>
</p>
<p>
In our reference-counted <span>launchShip</span> example, the <span>ship.__ref_count++</span> could take a few cycles if <span>ship</span> is already in the cache, or hundreds of cycles if it's not.
</p>

</section>
<section>
<p>
Generational references are more cache friendly:
</p>
<ul>
<li>
When a generational reference goes away, we don't need to reach into memory (unlike RC, where we have to decrement a counter).
</li>
<li>
We don't need to increment when aliasing (see previous section); we don't need to reach into memory to increment.
</li>
</ul>

</section>

      </div>
  
<div>

      <div>
        <div>
    
<div id="note11" data-noteid="11">
<p><span>11</span></p><section>
<p>
 Half of these are aliasings and half are dealiasings. Aliasing happens whenever we access a member (e.g. <span>person.name</span>) or make a new reference (e.g. <span>&amp;person</span>).
</p>

</section>
</div>
<div id="note12" data-noteid="12">
<p><span>12</span></p><section>
<p>
 Many languages are able to skip a lot of the adjustments, using static analysis. For example, Lobster can remove up to 95%. Our experiment doesn't have those optimizations; it compares naive RC to naive generational references.
</p>

</section>
</div>


        </div>
      </div>
    
</div>

    </div>
    <div>
      <div>
  
<section>
<h3 id="better-branch-prediction">
 Better Branch Prediction</h3>
<p>
For a given if-statement, CPUs will predict whether we'll go down the "then" branch or the "else" branch. This is called …</p></section></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vale.dev/blog/generational-memory">https://vale.dev/blog/generational-memory</a></em></p>]]>
            </description>
            <link>https://vale.dev/blog/generational-memory</link>
            <guid isPermaLink="false">hacker-news-small-sites-25664708</guid>
            <pubDate>Thu, 07 Jan 2021 00:05:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A technical founder's guide to design]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25664671">thread link</a>) | @jmilinovich
<br/>
January 6, 2021 | https://blog.aesthetic.com/blog/founder-guide-design/ | <a href="https://web.archive.org/web/*/https://blog.aesthetic.com/blog/founder-guide-design/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="__next"><div><div><div><div><p>We’ve learned a lot at Aesthetic about how early stage companies can best leverage design to become more valuable. We’re excited to share our learnings from working with 100+ companies over the last 18 months. We hope this will be helpful to the entire startup community, especially founders that are just getting started on their journey and are new to design.</p><p>Design is a highly diverse discipline, with dozens of different fields and specialties. Similar to software product development, the scope and scale of design teams is highly variant and meant to reflect the needs of their organization. For early stage startups — those that are pre product-market fit, or have early market traction — the design needs tend to follow a similar pattern, and then tends to vary based on the specific business model of strong product market fit companies.</p><h2>The 3 most important types of design for early-stage companies</h2><p>At the highest level, founders of early stage companies should focus on:</p><ol><li>Product design</li><li>Web design</li><li>Brand design</li></ol><p>Here’s a breakdown of what each of these types of design means:</p><ul><li><strong>Product design is the user experience for your service or product.</strong> This doesn’t just include software that you build yourself, but also includes every other touchpoint you have with your customers or prospects. Product design isn’t just about creating user interfaces, but also developing wireframes, user research, and user experience testing.</li><li><strong>Web design is a company’s front door to the world.</strong> In 2020, your website is the most basic currency of reputation for every company, and needs to make it clear what you do and what people should care. For most companies, a website is step 0 for starting to get customers.</li><li><strong>Brand design is the why behind your company’s what.</strong> It’s how you explain who you are to people, by codifying the way you represent yourself across every surface. As <a href="https://en.wikipedia.org/wiki/Paul_Rand">Paul Rand</a> says, it’s “what people say about you when you’re not in the room.” This isn’t just your logo, fonts, colors, aesthetic and tone, but also the slide decks, emails, ads, and one pagers that you put out into the world.</li></ul><h2>What kind of design should my early-stage company focus on?</h2><p>How much effort should companies apply to each of these three types of design? It of course depends, but there are some easy rules-of-thumb you can follow:</p><ul><li><strong>Pre-product-market fit companies should focus almost entirely on product design</strong> — with less effort on web design and brand design. This means spending as much time as you possibly can working on your product, and then bookmarking a few hours each week to make copy edits to your website. Don’t focus too much on the visuals at this stage, but rather your messaging and information architecture.</li><li><strong>Early-market-traction companies should maintain focus on product design, but start to ramp up web and brand design.</strong> These companies should do spike projects to develop more website content and begin developing their first marketing channel(s) and content roadmap(s) to activate their audience.</li><li><strong>Strong-product-market-fit companies should focus across the board.</strong> Spend time clarifying your brand identity, and take the time to review your entire user experience. Then, up the ante on production across all channels by turning brand design into a service center that can be consumed by your cross-functional orgs (ie, marketing and sales).</li></ul><p>It depends on the current phase your company is in:</p><ul><li><strong>Pre-product-market fit companies should focus on talking to customers.</strong> You should be spending most of your time talking to users to understand their problems. All of the tools listed above are approachable, even if you’ve never “done design” before. You can read <a href="https://www.amazon.com/Dont-Make-Think-Revisited-Usability/dp/0321965515">Don’t Make Me Think</a>, <a href="https://www.amazon.com/Design-Everyday-Things-Revised-Expanded/dp/B07L5Y9HND/ref=sr_1_1?crid=260ZQHLO710HE&amp;keywords=design+of+everyday+things&amp;qid=1578340207&amp;s=books&amp;sprefix=design+of+%2Cstripbooks%2C270&amp;sr=1-1">Design of Everyday Things</a>, <a href="https://abookapart.com/products/just-enough-research">Just Enough Research</a> and watch <a href="https://www.youtube.com/watch?v=9urYWGx2uNk">Gary Tan’s YouTube lectures</a> as good primers on the subject if you’re interested.</li><li><strong>Early-market-traction companies should consider hiring contractors to help with web and brand design.</strong> At this stage, it’d be hard to justify staffing for product design unless the founding team still maintained all user research, and just needed support with UI/UX. It might also make sense to staff web design if you have proof it’s a really useful channel for you today.</li><li><strong>Strong-product-market-fit companies should start hiring staff designers.</strong> Think of the trade-offs for hiring full-time versus working with outside support. Think of how you’d invest into these three areas of design, and what the top goals would be from anyone you worked with to get help. Then, start staffing by hiring full-time design, freelancers, and/or working with an agency.</li></ul><p>If you’re new to design, here are a few concrete actions and tools we recommend:</p><ul><li><strong>User research:</strong> The Aesthetic team recommends scheduling 2–3 user research interviews each week, ideally at the end of the week so you can also do usability testing on new features from the week.</li><li><strong>Take notes and record sessions:</strong> Make sure the entire team’s in each interview and take notes, record the sessions and do an affinity mapping exercise to formalize your learnings. We recommend <a href="https://fullstory.com/">Fullstory</a> for recording app and website user sessions.</li><li><strong>Design your website:</strong> Aesthetic loves <a href="http://webflow.com/">Webflow</a> for this phase, not just because they’ve built an awesome product and great people, but also because they’re YC alum and former batchmates :)</li><li><strong>Iterate on your brand design:</strong> Aesthetic uses <a href="http://figma.com/">Figma</a> for all of our marketing template designs, and the Adobe suite for developing our (vector based) brand identities. Depending on the specific tech stack, there’s a wide variety of solutions for helping deploy design systems to enable reusability and consistency across your product teams. Figma’s collaboration and animation support is second to none.</li></ul></div></div></div></div></div></div>]]>
            </description>
            <link>https://blog.aesthetic.com/blog/founder-guide-design/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25664671</guid>
            <pubDate>Thu, 07 Jan 2021 00:03:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I made a free iOS 14 home screen icon generator]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25664646">thread link</a>) | @millibar
<br/>
January 6, 2021 | https://myicon.io/ios-14-icon-editor | <a href="https://web.archive.org/web/*/https://myicon.io/ios-14-icon-editor">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://myicon.io/ios-14-icon-editor</link>
            <guid isPermaLink="false">hacker-news-small-sites-25664646</guid>
            <pubDate>Thu, 07 Jan 2021 00:01:12 GMT</pubDate>
        </item>
    </channel>
</rss>
